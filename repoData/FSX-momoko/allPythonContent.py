__FILENAME__ = conf
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Momoko documentation build configuration file, created by
# sphinx-quickstart on Tue Dec 11 22:52:15 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('..'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = 'Momoko'
copyright = '2011-2014, Frank Smit & Zaar Hai'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '1.1.3'
# The full version, including alpha/beta/rc tags.
release = '1.1.3'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
# html_theme = 'default'
# html_theme = 'michiko'
on_rtd = os.environ.get('READTHEDOCS', None) == 'True'
if on_rtd:
    html_theme = 'default'
else:
    html_theme = 'nature'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
# html_theme_path = []
# html_theme_path = ['_themes']

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
# html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Momokodoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Momoko.tex', 'Momoko Documentation',
   'Frank Smit', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'momoko', 'Momoko Documentation',
     ['Frank Smit'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Momoko', 'Momoko Documentation',
   'Frank Smit', 'Momoko', "Momoko wraps Psycopg2's functionality for use in Tornado.",
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = gen_example
#!/usr/bin/env python

"""
This example uses Tornado's gen_.

.. _gen: http://www.tornadoweb.org/documentation/gen.html
"""

import os

import tornado.web
import tornado.ioloop
import tornado.options
from tornado import gen
import tornado.httpserver

import momoko


db_database = os.environ.get('MOMOKO_TEST_DB', 'momoko_test')
db_user = os.environ.get('MOMOKO_TEST_USER', 'postgres')
db_password = os.environ.get('MOMOKO_TEST_PASSWORD', '')
db_host = os.environ.get('MOMOKO_TEST_HOST', '')
db_port = os.environ.get('MOMOKO_TEST_PORT', 5432)
enable_hstore = True if os.environ.get('MOMOKO_TEST_HSTORE', False) == '1' else False
dsn = 'dbname=%s user=%s password=%s host=%s port=%s' % (
    db_database, db_user, db_password, db_host, db_port)

assert (db_database or db_user or db_password or db_host or db_port) is not None, (
    'Environment variables for the examples are not set. Please set the following '
    'variables: MOMOKO_TEST_DB, MOMOKO_TEST_USER, MOMOKO_TEST_PASSWORD, '
    'MOMOKO_TEST_HOST, MOMOKO_TEST_PORT')


class BaseHandler(tornado.web.RequestHandler):
    @property
    def db(self):
        return self.application.db


class OverviewHandler(BaseHandler):
    def get(self):
        self.write('''
<ul>
    <li><a href="/mogrify">Mogrify</a></li>
    <li><a href="/query">A single query</a></li>
    <li><a href="/hstore">An hstore query</a></li>
    <li><a href="/transaction">A transaction</a></li>
    <li><a href="/multi_query">Multiple queries executed with gen.Task</a></li>
    <li><a href="/callback_and_wait">Multiple queries executed with gen.Callback and gen.Wait</a></li>
</ul>
        ''')
        self.finish()


class MogrifyHandler(BaseHandler):
    @gen.coroutine
    def get(self):
        try:
            sql = yield momoko.Op(self.db.mogrify, 'SELECT %s;', (1,))
            self.write('SQL: %s<br>' % sql)
        except Exception as error:
            self.write(str(error))

        self.finish()


class SingleQueryHandler(BaseHandler):
    @gen.coroutine
    def get(self):
        try:
            cursor = yield momoko.Op(self.db.execute, 'SELECT pg_sleep(%s);', (1,))
            self.write('Query results: %s<br>\n' % cursor.fetchall())
        except Exception as error:
            self.write(str(error))

        self.finish()


class HstoreQueryHandler(BaseHandler):
    @gen.coroutine
    def get(self):
        if enable_hstore:
            try:
                cursor = yield momoko.Op(self.db.execute, "SELECT 'a=>b, c=>d'::hstore;")
                self.write('Query results: %s<br>' % cursor.fetchall())
                cursor = yield momoko.Op(self.db.execute, "SELECT %s;",
                                         ({'e': 'f', 'g': 'h'},))
                self.write('Query results: %s<br>' % cursor.fetchall())
            except Exception as error:
                self.write(str(error))
        else:
            self.write('hstore is not enabled')

        self.finish()


class MultiQueryHandler(BaseHandler):
    @gen.coroutine
    def get(self):
        cursor1, cursor2, cursor3 = yield [
            momoko.Op(self.db.execute, 'SELECT 1;'),
            momoko.Op(self.db.mogrify, 'SELECT 2;'),
            momoko.Op(self.db.execute, 'SELECT %s;', (3*1,))
        ]

        self.write('Query 1 results: %s<br>' % cursor1.fetchall())
        self.write('Query 2 results: %s<br>' % cursor2)
        self.write('Query 3 results: %s' % cursor3.fetchall())

        self.finish()


class TransactionHandler(BaseHandler):
    @gen.coroutine
    def get(self):
        try:
            cursors = yield momoko.Op(self.db.transaction, (
                'SELECT 1, 12, 22, 11;',
                'SELECT 55, 22, 78, 13;',
                'SELECT 34, 13, 12, 34;',
                'SELECT 23, 12, 22, 23;',
                'SELECT 42, 23, 22, 11;',
                ('SELECT 49, %s, 23, 11;', ('STR',)),
            ))

            for i, cursor in enumerate(cursors):
                self.write('Query %s results: %s<br>' % (i, cursor.fetchall()))
        except Exception as error:
            self.write(str(error))

        self.finish()


class CallbackWaitHandler(BaseHandler):
    @gen.coroutine
    def get(self):

        self.db.execute('SELECT 42, 12, %s, 11;', (25,),
                        callback=(yield gen.Callback('q1')))
        self.db.execute('SELECT 42, 12, %s, %s;', (23, 56),
                        callback=(yield gen.Callback('q2')))
        self.db.execute('SELECT 465767, 4567, 3454;',
                        callback=(yield gen.Callback('q3')))

        # Separately...
        # cursor1 = yield momoko.WaitOp('q1')
        # cursor2 = yield momoko.WaitOp('q2')
        # cursor3 = yield momoko.WaitOp('q3')

        # Or all at once
        cursor1, cursor2, cursor3 = yield momoko.WaitAllOps(('q1', 'q2', 'q3'))

        self.write('Query 1 results: %s<br>' % cursor1.fetchall())
        self.write('Query 2 results: %s<br>' % cursor2.fetchall())
        self.write('Query 3 results: %s' % cursor3.fetchall())

        self.finish()


class ConnectionQueryHandler(BaseHandler):
    def __init__(self, *args, **kwargs):
        self.http_connection_closed = False
        super(ConnectionQueryHandler, self).__init__(*args, **kwargs)

    @gen.coroutine
    def get(self):
        try:
            connection = yield momoko.Op(self.db.getconn)
            with self.db.manage(connection):
                for i in range(5):
                    if self.http_connection_closed:
                        break
                    cursor = yield momoko.Op(connection.execute, 'SELECT pg_sleep(1);')
                    self.write('Query %d results: %s<br>\n' % (i+1, cursor.fetchall()))
                    self.flush()
        except Exception as error:
            self.write(str(error))

        self.finish()

    def on_connection_close(self):
        self.http_connection_closed = True


def main():
    try:
        tornado.options.parse_command_line()
        application = tornado.web.Application([
            (r'/', OverviewHandler),
            (r'/mogrify', MogrifyHandler),
            (r'/query', SingleQueryHandler),
            (r'/hstore', HstoreQueryHandler),
            (r'/transaction', TransactionHandler),
            (r'/multi_query', MultiQueryHandler),
            (r'/callback_and_wait', CallbackWaitHandler),
            (r'/connection', ConnectionQueryHandler),
        ], debug=True)

        application.db = momoko.Pool(
            dsn=dsn,
            size=1,
            max_size=3,
            setsession=("SET TIME ZONE UTC",),
            raise_connect_errors=False,
        )

        if enable_hstore:
            application.db.register_hstore()

        http_server = tornado.httpserver.HTTPServer(application)
        http_server.listen(8888, 'localhost')
        tornado.ioloop.IOLoop.instance().start()
    except KeyboardInterrupt:
        print('Exit')


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = connection
# -*- coding: utf-8 -*-
"""
momoko.connection
=================

Connection handling.

Copyright 2011-2013 by Frank Smit.
MIT, see LICENSE for more details.
"""

import sys
if sys.version_info[0] >= 3:
    basestring = str

from functools import partial
from collections import deque
import datetime
from functools import wraps
from contextlib import contextmanager

import psycopg2
from psycopg2.extras import register_hstore as _psy_register_hstore
from psycopg2.extensions import POLL_OK, POLL_READ, POLL_WRITE, POLL_ERROR, TRANSACTION_STATUS_IDLE

from tornado import gen
from tornado.ioloop import IOLoop
from tornado.stack_context import wrap
from tornado.concurrent import Future

from .exceptions import PoolError

from .utils import log


# The dummy callback is used to keep the asynchronous cursor alive in case no
# callback has been specified. This will prevent the cursor from being garbage
# collected once, for example, ``Pool.execute`` has finished.
# Symptom: you'll get
#     InterfaceError: the asynchronous cursor has disappeared
# exceptions
def _dummy_callback(cursor, error):
    pass


class Pool(object):
    """
    Asynchronous connection pool.

    The pool manages database connections and passes operations to connections.

    See :py:class:`momoko.Connection` for documentation about the ``dsn``,
    ``connection_factory`` and ``cursor_factory`` parameters.
    These are used by the connection pool when a new connection is created.

    :param integer size: Amount of connections created upon initialization. Defaults to ``1``.
    :param integer max_size: Allow number of connection to grow under load up to given size. Defaults to ``size``.
    :param callable callback:
        A callable that's called after all the connections are created. Defaults to ``None``.
    :param ioloop: An instance of Tornado's IOLoop. Defaults to ``None``, ``IOLoop.instance()`` will be used.
    :param bool raise_connect_errors:
        Whether to raise exception if database connection fails. Set to ``False`` to enable
        automatic reconnection attempts. Defaults to ``True``.
    :param integer reconnect_interval:
        When using automatic reconnects, set minimum reconnect interval, in milliseconds,
        before retrying connection attempt. Don't set this value too low to prevent "banging"
        the database server with connection attempts. Defaults to ``500``.
    :param list setsession:
        List of intial sql commands to be executed once connection is established.
        If any of the commands failes, the connection will be closed.
        **NOTE:** The commands will be executed as one transaction block.
    """

    class Connections(object):
        def __init__(self, reconnect_interval, ioloop):
            self.ioloop = ioloop

            self.reconnect_interval = reconnect_interval
            self.last_connect_attempt_ts = ioloop.time()
            self.last_connect_attempt_success = False
            self.reconnect_in_progress = False

            self.empty()

        def empty(self):
            self.free = set()
            self.busy = set()
            self.dead = set()
            self.pending = set()
            self.waiting_queue = deque()

        def remove_pending(func):
            @wraps(func)
            def wrapper(self, conn):
                self.pending.discard(conn)
                func(self, conn)
            return wrapper

        def get_free(self):
            if not self.free:
                return
            conn = self.free.pop()
            self.busy.add(conn)
            return conn

        def return_busy(self, conn):
            if self.waiting_queue:
                self.waiting_queue.pop().set_result(conn)
            else:
                self.busy.remove(conn)
                self.free.add(conn)

        @remove_pending
        def add_free(self, conn):
            if self.waiting_queue:
                self.busy.add(conn)
                self.waiting_queue.pop().set_result(conn)
            else:
                self.free.add(conn)

        @remove_pending
        def add_dead(self, conn):
            self.dead.add(conn)
            self.busy.discard(conn)
            # free connections are most probably dead by now
            while self.free:
                self.dead.add(self.free.pop())

        def add_pending(self, conn):
            self.last_connect_attempt_ts = self.ioloop.time()
            self.reconnect_in_progress = True
            self.pending.add(conn)

        def get_alive(self):
            return self.free.union(self.busy)

        def close_alive(self):
            for conn in self.get_alive():
                if not conn.closed:
                    conn.close()

        @property
        def total(self):
            return len(self.free) + len(self.busy) + len(self.dead) + len(self.pending)

        def is_time_to_reconnect(self):
            now = self.ioloop.time()
            if not (self.last_connect_attempt_success or
                    now - self.last_connect_attempt_ts > self.reconnect_interval):
                return False
            return True

        def on_reconnect_complete(self, connection):
            if not connection.closed:
                self.add_free(connection)
            else:
                self.add_dead(connection)
            self.last_connect_attempt_success = not connection.closed
            self.reconnect_in_progress = False
            if not self.last_connect_attempt_success:
                self.abort_waiting_queue()

        def abort_waiting_queue(self):
            while self.waiting_queue:
                future = self.waiting_queue.pop()
                future.set_result(None)  # Send None to signify that all who waits should abort

    def __init__(self,
                 dsn,
                 connection_factory=None,
                 cursor_factory=None,
                 size=1,
                 max_size=None,
                 callback=None,
                 ioloop=None,
                 raise_connect_errors=True,
                 reconnect_interval=500,
                 setsession=[]):
        assert size > 0, "The connection pool size must be a number above 0."

        self.size = size
        self.max_size = max_size or size
        assert self.size <= self.max_size, "The connection pool max size must be of at least 'size'."

        self.dsn = dsn
        self.closed = False
        self.connection_factory = connection_factory
        self.cursor_factory = cursor_factory

        self.raise_connect_errors = raise_connect_errors

        self._ioloop = ioloop or IOLoop.instance()

        reconnect_interval = float(reconnect_interval)/1000  # the parameter is in milliseconds
        self._conns = self.Connections(reconnect_interval, self._ioloop)

        self.setsession = setsession
        self.connected = False

        self.server_version = None

        # Create connections
        def after_pool_creation(connection):
            if not self._conns.pending:  # all connections "connected" on way or the other
                if callback:
                    callback()

        for i in range(self.size):
            self._new(after_pool_creation)

    def _new(self, callback=None):
        conn = Connection()
        self._conns.add_pending(conn)
        conn.connect(self.dsn,
                     connection_factory=self.connection_factory,
                     cursor_factory=self.cursor_factory,
                     callback=partial(self._post_connect_callback, callback),
                     ioloop=self._ioloop,
                     setsession=self.setsession)

    def _post_connect_callback(self, callback, connection, error):
        if error:
            if not connection.closed:
                connection.close()
            if self.raise_connect_errors:
                raise error
            else:
                logger = log.error if self.log_connect_errors else log.info
                logger("Failed opening connection to database: %s", error)
        else:
            self.server_version = connection.connection.server_version

        self._conns.on_reconnect_complete(connection)
        log.debug("Connection attempt complete. Success: %s", self._conns.last_connect_attempt_success)

        if self._conns.last_connect_attempt_success:
            # Connection to db is OK. If we have waiting requests
            # and some dead conncetions, we can serve requests faster
            # if we reanimate dead connections
            num_conns_to_reconnect = min(len(self._conns.dead), len(self._conns.waiting_queue))
            for i in range(num_conns_to_reconnect):
                self._conns.dead.pop()
                self._new()

        self._stretch_if_needed()

        if callback:
            callback(connection)

    def _get_connection(self):

        log.debug("Getting connection")
        self.connected = True

        # if there are free connections - just return one
        connection = self._conns.get_free()
        if connection:
            return connection

        # if there are dead connections - try to reanimate them
        if self._conns.dead:
            if self._conns.is_time_to_reconnect():
                log.debug("Trying to reconnect dead connection")
                self._conns.dead.pop()
                self._new()
                return

        if self._conns.busy:
            # We may be maxed out here. Try to stretch if approprate
            self._stretch_if_needed(new_request=True)
            # At least some connections are alive, so wait for them
            log.debug("There are busy connections")
            return

        if self._conns.reconnect_in_progress:
            # We are connecting - wait more
            log.debug("Reconnect in progress")
            return

        log.debug("no connections are available or expected in near future")
        self.connected = False

    def _stretch_if_needed(self, new_request=False):
        if self._conns.total == self.max_size:
            return  # max size reached
        if self._conns.dead or self._conns.free:
            return  # no point to stretch if we heave free conns to use / dead conns to reanimate
        if not (new_request or (self._conns.waiting_queue and self._conns.busy)):
            return
        if self._conns.pending:
            if len(self._conns.pending) >= len(self._conns.waiting_queue) + int(new_request):
                return
        log.debug("Stretching pool")
        self._new()

    def _retry_action(self, method, callback, *args, **kwargs):
        action = partial(self._operate, method, callback, *args, **kwargs)
        future = Future()
        self._conns.waiting_queue.appendleft(future)

        def on_connection_available(future):
            connection = future.result()
            if not connection:
                log.debug("Aborting - as instructed")
                raise psycopg2.DatabaseError("No database connection available")
            action(connection=connection)
        return self._ioloop.add_future(future, on_connection_available)

    def _reconnect_and_retry(self, connection, method, callback, *args, **kwargs):
        self._conns.add_dead(connection)
        log.debug("Tried over dead connection. Retrying once")
        self._retry_action(method, callback, *args, **kwargs)
        self._conns.dead.pop()
        self._new()

    def _operate(self, method, callback, *args, **kwargs):

        connection = kwargs.pop("connection", None) or self._get_connection()
        if not connection:
            if self.connected:
                log.debug("No connection available right now - will try again later")
                return self._retry_action(method, callback, *args, **kwargs)
            else:
                log.debug("Aborting - not connected")
                raise psycopg2.DatabaseError("No database connection available")

        log.debug("Connection obtained, proceeding")

        if kwargs.pop("get_connection_only", False):
            return callback(connection, None)

        the_callback = partial(self._operate_callback, connection, method, callback, args, kwargs)
        method(connection, *args, callback=the_callback, **kwargs)

    def _operate_callback(self, connection, method, orig_callback, args, kwargs, *_args, **_kwargs):
        """
        Wrap real callback coming from invoker with our own one
        that will check connection status after the end of the call
        and recycle connection / retry operation
        """
        if connection.closed:
            self._reconnect_and_retry(connection, method, orig_callback, *args, **kwargs)
            return

        if not getattr(method, "_keep_connection", False):
            self._conns.return_busy(connection)

        if orig_callback:
            return orig_callback(*_args, **_kwargs)

    def ping(self, connection, callback=None):
        """
        Ping given connection object to make sure its alive (involves roundtrip to the database server).

        See :py:meth:`momoko.Connection.ping` for documentation about the details.
        """
        self._operate(Connection.ping, callback,
                      connection=connection)

    def transaction(self,
                    statements,
                    cursor_factory=None,
                    callback=None):
        """
        Run a sequence of SQL queries in a database transaction.

        See :py:meth:`momoko.Connection.transaction` for documentation about the
        parameters.
        """
        self._operate(Connection.transaction, callback,
                      statements, cursor_factory=cursor_factory)

    def execute(self,
                operation,
                parameters=(),
                cursor_factory=None,
                callback=None):
        """
        Prepare and execute a database operation (query or command).

        See :py:meth:`momoko.Connection.execute` for documentation about the
        parameters.
        """
        self._operate(Connection.execute, callback,
                      operation, parameters, cursor_factory=cursor_factory)

    def callproc(self,
                 procname,
                 parameters=(),
                 cursor_factory=None,
                 callback=None):
        """
        Call a stored database procedure with the given name.

        See :py:meth:`momoko.Connection.callproc` for documentation about the
        parameters.
        """
        self._operate(Connection.callproc, callback,
                      procname, parameters=parameters, cursor_factory=cursor_factory)

    def mogrify(self,
                operation,
                parameters=(),
                callback=None):
        """
        Return a query string after arguments binding.

        See :py:meth:`momoko.Connection.mogrify` for documentation about the
        parameters.
        """
        self._operate(Connection.mogrify, callback,
                      operation, parameters=parameters)

    def register_hstore(self, unicode=False, callback=None):
        """
        Register adapter and typecaster for ``dict-hstore`` conversions.

        See :py:meth:`momoko.Connection.register_hstore` for documentation about
        the parameters. This method has no ``globally`` parameter, because it
        already registers hstore to all the connections in the pool.
        """
        self._operate(Connection.register_hstore, callback,
                      globally=True, unicode=unicode)

    def getconn(self, ping=True, callback=None):
        """
        Acquire connection from the pool.

        You can then use this connection for subsequest queries.
        Just supply, for example, ``connection.execute`` instead of ``Pool.execute``
        to ``momoko.Op``.

        Make sure to return connection to the pool by calling :py:meth:`momoko.Pool.putconn`,
        otherwise the connection will remain forever-busy and you'll starvate your pool quickly.

        :param boolean ping:
            Whether to ping connection before returning it by executing :py:meth:`momoko.Pool.ping`.
        """
        def ping_callback(connection, error):
            self.ping(connection, callback)
        the_callback = ping_callback if ping else callback
        self._operate("getconn", the_callback, get_connection_only=True)

    def putconn(self, connection):
        """
        Retrun busy connection back to the pool.

        :param Connection connection:
            Connection object previously returned by :py:meth:`momoko.Pool.getconn`.
        """

        if connection.closed:
            self._conns.add_dead(connection)
        else:
            self._conns.return_busy(connection)

    @contextmanager
    def manage(self, connection):
        """
        Context manager that automatically returns connection to the pool.
        You can use it instead of :py:meth:`momoko.Pool.putconn`::

            connection = yield momoko.Op(self.db.getconn)
            with self.db.manage(connection):
                cursor = yield momoko.Op(connection.execute, "BEGIN")
                ...
        """
        assert connection in self._conns.busy, "Can not manage non-busy connection. Where did you get it from?"
        try:
            yield connection
        finally:
            self.putconn(connection)

    def close(self):
        """
        Close the connection pool.
        """
        if self.closed:
            raise PoolError('connection pool is already closed')

        self._conns.close_alive()
        self._conns.empty()
        self.closed = True

    log_connect_errors = True  # Unittest monkey patches it for silent output


class Connection(object):
    """
    Initiate an asynchronous connect.

    :param string dsn:
        A `Data Source Name`_ string containing one of the following values:

        * **dbname** - the database name
        * **user** - user name used to authenticate
        * **password** - password used to authenticate
        * **host** - database host address (defaults to UNIX socket if not provided)
        * **port** - connection port number (defaults to 5432 if not provided)

        Or any other parameter supported by PostgreSQL. See the PostgreSQL
        documentation for a complete list of supported parameters_.

    :param connection_factory:
        The ``connection_factory`` argument can be used to create non-standard
        connections. The class returned should be a subclass of `psycopg2.extensions.connection`_.
        See `Connection and cursor factories`_ for details. Defaults to ``None``.

    :param cursor_factory:
        The ``cursor_factory`` argument can be used to return non-standart cursor class
        The class returned should be a subclass of `psycopg2.extensions.cursor`_.
        See `Connection and cursor factories`_ for details. Defaults to ``None``.

    :param callable callback:
        A callable that's called after the connection is created. It accepts one
        paramater: an instance of :py:class:`momoko.Connection`. Defaults to ``None``.
    :param ioloop: An instance of Tornado's IOLoop. Defaults to ``None``.

    :param list setsession:
        List of intial sql commands to be executed once connection is established.
        If any of the commands failes, the connection will be closed.
        **NOTE:** The commands will be executed as one transaction block.

    .. _Data Source Name: http://en.wikipedia.org/wiki/Data_Source_Name
    .. _parameters: http://www.postgresql.org/docs/current/static/libpq-connect.html#LIBPQ-PQCONNECTDBPARAMS
    .. _psycopg2.extensions.connection: http://initd.org/psycopg/docs/connection.html#connection
    .. _Connection and cursor factories: http://initd.org/psycopg/docs/advanced.html#subclassing-cursor
    """
    def connect(self,
                dsn,
                connection_factory=None,
                cursor_factory=None,
                callback=None,
                ioloop=None,
                setsession=[]):
        log.info("Opening new database connection")

        kwargs = {"async": True}
        if connection_factory:
            kwargs["connection_factory"] = connection_factory
        if cursor_factory:
            kwargs["cursor_factory"] = cursor_factory

        self.connection = None
        try:
            self.connection = psycopg2.connect(dsn, **kwargs)
        except psycopg2.Error as error:
            if callback:
                callback(self, error)
                return
            else:
                raise
        self.fileno = self.connection.fileno()
        self._transaction_status = self.connection.get_transaction_status
        self.ioloop = ioloop or IOLoop.instance()

        self._on_connect_callback = partial(callback, self) if callback else None

        if setsession:
            self.callback = self._setsession_callback
            self.setsession = setsession
        else:
            self.callback = self._on_connect_callback

        self.ioloop.add_handler(self.fileno, self.io_callback, IOLoop.WRITE)

    def _setsession_callback(self, error):
        """Custom post-connect callback to trigger setsession commands execution in transaction"""
        if error:
            return self._on_connect_callback(error)
        log.debug("Running setsession commands")
        return self.transaction(self.setsession, callback=self._setsession_transaction_callback)

    def _setsession_transaction_callback(self, cursor, error):
        """
        Call back that check results of setsession transaction commands and
        call the real post_connect callback. Closes connection if transaction failed.
        """
        if error:
            log.debug("Closing connection since set session commands failed")
            self.close()
        self._on_connect_callback(error)

    def io_callback(self, fd=None, events=None):
        try:
            state = self.connection.poll()
        except (psycopg2.Warning, psycopg2.Error) as error:
            self.ioloop.remove_handler(self.fileno)
            if self.callback:
                self.callback(error)
        else:
            if state == POLL_OK:
                self.ioloop.remove_handler(self.fileno)
                if self.callback:
                    self.callback(None)
            elif state == POLL_READ:
                self.ioloop.update_handler(self.fileno, IOLoop.READ)
            elif state == POLL_WRITE:
                self.ioloop.update_handler(self.fileno, IOLoop.WRITE)
            else:
                raise psycopg2.OperationalError('poll() returned {0}'.format(state))

    def _catch_early_errors(func):
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            callback = kwargs.get("callback", _dummy_callback)
            try:
                return func(self, *args, **kwargs)
            except psycopg2.Error as error:
                callback(None, error)
        return wrapper

    def _keep_connection(func):
        """
        Use this decorator on Connection methods to hint the Pool to not
        release connection when operation is complete
        """
        func._keep_connection = True
        return func

    @_catch_early_errors
    @_keep_connection
    def ping(self, callback=None):
        """
        Make sure this connection is alive by executing SELECT 1 statement -
        i.e. roundtrip to the database.

        **NOTE:** On the contrary to other methods, callback function signature is
              ``callback(self, error)`` and not ``callback(cursor, error)``.

        **NOTE:** `callback` should always passed as keyword argument

        """
        cursor = self.connection.cursor()
        cursor.execute("SELECT 1")
        self.callback = partial(self._ping_callback, callback or _dummy_callback, cursor)
        self.ioloop.add_handler(self.fileno, self.io_callback, IOLoop.WRITE)

    def _ping_callback(self, callback, cursor, error):
        if not error:
            cursor.fetchall()
        return callback(self, error)

    @_catch_early_errors
    def execute(self,
                operation,
                parameters=(),
                cursor_factory=None,
                callback=None):
        """
        Prepare and execute a database operation (query or command).

        :param string operation: An SQL query.
        :param tuple/list parameters:
            A list or tuple with query parameters. See `Passing parameters to SQL queries`_
            for more information. Defaults to an empty tuple.
        :param cursor_factory:
            The ``cursor_factory`` argument can be used to create non-standard cursors.
            The class returned must be a subclass of `psycopg2.extensions.cursor`_.
            See `Connection and cursor factories`_ for details. Defaults to ``None``.
        :param callable callback:
            A callable that is executed when the query has finished. It must accept
            two positional parameters. The first one being the cursor and the second
            one ``None`` or an instance of an exception if an error has occurred,
            in that case the first parameter will be ``None``. Defaults to ``None``.
            **NOTE:** `callback` should always passed as keyword argument

        .. _Passing parameters to SQL queries: http://initd.org/psycopg/docs/usage.html#query-parameters
        .. _psycopg2.extensions.cursor: http://initd.org/psycopg/docs/extensions.html#psycopg2.extensions.cursor
        .. _Connection and cursor factories: http://initd.org/psycopg/docs/advanced.html#subclassing-cursor
        """
        kwargs = {"cursor_factory": cursor_factory} if cursor_factory else {}
        cursor = self.connection.cursor(**kwargs)
        cursor.execute(operation, parameters)
        self.callback = partial(callback or _dummy_callback, cursor)
        self.ioloop.add_handler(self.fileno, self.io_callback, IOLoop.WRITE)

    @_catch_early_errors
    def callproc(self,
                 procname,
                 parameters=(),
                 cursor_factory=None,
                 callback=None):
        """
        Call a stored database procedure with the given name.

        The sequence of parameters must contain one entry for each argument that
        the procedure expects. The result of the call is returned as modified copy
        of the input sequence. Input parameters are left untouched, output and
        input/output parameters replaced with possibly new values.

        The procedure may also provide a result set as output. This must then be
        made available through the standard `fetch*()`_ methods.

        :param string procname: The name of the database procedure.
        :param tuple/list parameters:
            A list or tuple with query parameters. See `Passing parameters to SQL queries`_
            for more information. Defaults to an empty tuple.
        :param cursor_factory:
            The ``cursor_factory`` argument can be used to create non-standard cursors.
            The class returned must be a subclass of `psycopg2.extensions.cursor`_.
            See `Connection and cursor factories`_ for details. Defaults to ``None``.
        :param callable callback:
            A callable that is executed when the query has finished. It must accept
            two positional parameters. The first one being the cursor and the second
            one ``None`` or an instance of an exception if an error has occurred,
            in that case the first parameter will be ``None``. Defaults to ``None``.
            **NOTE:** `callback` should always passed as keyword argument

        .. _fetch*(): http://initd.org/psycopg/docs/cursor.html#fetch
        .. _Passing parameters to SQL queries: http://initd.org/psycopg/docs/usage.html#query-parameters
        .. _psycopg2.extensions.cursor: http://initd.org/psycopg/docs/extensions.html#psycopg2.extensions.cursor
        .. _Connection and cursor factories: http://initd.org/psycopg/docs/advanced.html#subclassing-cursor
        """
        kwargs = {"cursor_factory": cursor_factory} if cursor_factory else {}
        cursor = self.connection.cursor(**kwargs)
        cursor.callproc(procname, parameters)
        self.callback = partial(callback or _dummy_callback, cursor)
        self.ioloop.add_handler(self.fileno, self.io_callback, IOLoop.WRITE)

    @_catch_early_errors
    def mogrify(self, operation, parameters=(), callback=None):
        """
        Return a query string after arguments binding.

        The string returned is exactly the one that would be sent to the database
        running the execute() method or similar.

        :param string operation: An SQL query.
        :param tuple/list parameters:
            A list or tuple with query parameters. See `Passing parameters to SQL queries`_
            for more information. Defaults to an empty tuple.
        :param callable callback:
            A callable that is executed when the query has finished. It must accept
            two positional parameters. The first one being the resulting query as
            a byte string and the second one ``None`` or an instance of an exception
            if an error has occurred. Defaults to ``None``.
            **NOTE:** `callback` should always passed as keyword argument

        .. _Passing parameters to SQL queries: http://initd.org/psycopg/docs/usage.html#query-parameters
        .. _Connection and cursor factories: http://initd.org/psycopg/docs/advanced.html#subclassing-cursor
        """
        cursor = self.connection.cursor()
        try:
            result = cursor.mogrify(operation, parameters)
            self.ioloop.add_callback(partial(callback or _dummy_callback, result, None))
        except (psycopg2.Warning, psycopg2.Error) as error:
            self.ioloop.add_callback(partial(callback or _dummy_callback, b'', error))

    def transaction(self,
                    statements,
                    cursor_factory=None,
                    callback=None):
        """
        Run a sequence of SQL queries in a database transaction.

        :param tuple/list statements:
            List or tuple containing SQL queries with or without parameters. An item
            can be a string (SQL query without parameters) or a tuple/list with two items,
            an SQL query and a tuple/list wuth parameters.

            See `Passing parameters to SQL queries`_ for more information.
        :param cursor_factory:
            The ``cursor_factory`` argument can be used to create non-standard cursors.
            The class returned must be a subclass of `psycopg2.extensions.cursor`_.
            See `Connection and cursor factories`_ for details. Defaults to ``None``.
        :param callable callback:
            A callable that is executed when the transaction has finished. It must accept
            two positional parameters. The first one being a list of cursors in the same
            order as the given statements and the second one ``None`` or an instance of
            an exception if an error has occurred, in that case the first parameter is
            an empty list. Defaults to ``None``.
            **NOTE:** `callback` should always passed as keyword argument

        .. _Passing parameters to SQL queries: http://initd.org/psycopg/docs/usage.html#query-parameters
        .. _psycopg2.extensions.cursor: http://initd.org/psycopg/docs/extensions.html#psycopg2.extensions.cursor
        .. _Connection and cursor factories: http://initd.org/psycopg/docs/advanced.html#subclassing-cursor
        """
        cursors = []
        queue = deque()
        callback = callback or _dummy_callback

        for statement in statements:
            if isinstance(statement, basestring):
                queue.append((statement, ()))
            else:
                queue.append(statement[:2])

        queue.appendleft(('BEGIN;', ()))
        queue.append(('COMMIT;', ()))

        def error_callback(statement_error, cursor, rollback_error):
            callback(None, rollback_error or statement_error)

        def exec_statement(cursor=None, error=None):
            if error:
                try:
                    self.execute('ROLLBACK;', callback=partial(error_callback, error))
                except psycopg2.Error as rollback_error:
                    error_callback(error, cursor, rollback_error)
                return
            if cursor:
                cursors.append(cursor)
            if not queue:
                callback(cursors[1:-1], None)
                return

            operation, parameters = queue.popleft()
            self.execute(operation, parameters, cursor_factory, callback=exec_statement)

        self.ioloop.add_callback(exec_statement)

    @_catch_early_errors
    def register_hstore(self, globally=False, unicode=False, callback=None):
        """
        Register adapter and typecaster for ``dict-hstore`` conversions.

        More information on the hstore datatype can be found on the
        Psycopg2 documentation_.

        :param boolean globally:
            Register the adapter globally, not only on this connection.
        :param boolean unicode:
            If ``True``, keys and values returned from the database will be ``unicode``
            instead of ``str``. The option is not available on Python 3.

        **NOTE:** `callback` should always passed as keyword argument

        .. _documentation: http://initd.org/psycopg/docs/extras.html#hstore-data-type
        """
        def _hstore_callback(cursor, error):
            oid, array_oid = cursor.fetchone()
            _psy_register_hstore(None, globally, unicode, oid, array_oid)

            if callback:
                callback(None, error)

        self.execute(
            "SELECT 'hstore'::regtype::oid, 'hstore[]'::regtype::oid",
            callback=_hstore_callback)

    def busy(self):
        """
        **(Deprecated)** Check if the connection is busy or not.
        """
        return self.connection.isexecuting() or (self.connection.closed == 0 and
                                                 self._transaction_status() != TRANSACTION_STATUS_IDLE)

    @property
    def closed(self):
        """
        Indicates whether the connection is closed or not.
        """
        # 0 = open, 1 = closed, 2 = 'something horrible happened'
        return self.connection.closed > 0 if self.connection else True

    def close(self):
        """
        Remove the connection from the IO loop and close it.
        """
        if self.connection:
            self.connection.close()

########NEW FILE########
__FILENAME__ = exceptions
# -*- coding: utf-8 -*-
"""
momoko.exceptions
=================

Exceptions.

Copyright 2011-2013 by Frank Smit.
MIT, see LICENSE for more details.
"""


class PoolError(Exception):
    """
    The ``PoolError`` exception is raised when something goes wrong in the connection
    pool. When the maximum amount is exceeded for example.
    """
    pass

########NEW FILE########
__FILENAME__ = utils
# -*- coding: utf-8 -*-
"""
momoko.utils
============

Utilities that make life easier.

Copyright 2011-2013 by Frank Smit.
MIT, see LICENSE for more details.
"""

import sys
import logging
from tornado import gen
from functools import partial
from collections import deque


if sys.version_info[0] < 3:
    is_python_3k = False
else:
    is_python_3k = True


log = logging.getLogger('momoko')


class Op(gen.Task):
    """
    Run a single asynchronous operation.

    Behaves like `tornado.gen.Task`_, but raises an exception (one of Psycop2's
    exceptions_) when an error occurs related to Psycopg2 or PostgreSQL.

    .. _exceptions: http://initd.org/psycopg/docs/module.html#exceptions
    .. _tornado.gen.Task: http://www.tornadoweb.org/documentation/gen.html#tornado.gen.Task
    """
    def get_result(self):
        (result, error), _ = super(Op, self).get_result()
        if error:
            raise error
        return result


class WaitOp(gen.Wait):
    """
    Return the argument passed to the result of a previous `tornado.gen.Callback`_.

    Behaves like `tornado.gen.Wait`_, but raises an exception (one of Psycop2's
    exceptions_) when an error occurs related to Psycopg2 or PostgreSQL.

    .. _exceptions: http://initd.org/psycopg/docs/module.html#exceptions
    .. _tornado.gen.Callback: http://www.tornadoweb.org/documentation/gen.html#tornado.gen.Callback
    .. _tornado.gen.Wait: http://www.tornadoweb.org/documentation/gen.html#tornado.gen.Wait
    """
    def get_result(self):
        (result, error), _ = super(WaitOp, self).get_result()
        if error:
            raise error
        return result


class WaitAllOps(gen.WaitAll):
    """
    Return the results of multiple previous `tornado.gen.Callback`_.

    Behaves like `tornado.gen.WaitAll`_, but raises an exception (one of Psycop2's
    exceptions_) when an error occurs related to Psycopg2 or PostgreSQL.

    .. _exceptions: http://initd.org/psycopg/docs/module.html#exceptions
    .. _tornado.gen.Callback: http://www.tornadoweb.org/documentation/gen.html#tornado.gen.Callback
    .. _tornado.gen.WaitAll: http://www.tornadoweb.org/documentation/gen.html#tornado.gen.WaitAll
    """
    def get_result(self):
        super_results = super(WaitAllOps, self).get_result()

        results = []
        for (result, error), _ in super_results:
            if error:
                raise error
            else:
                results.append(result)

        return results

########NEW FILE########
__FILENAME__ = tests
import os
import string
import random
import time
import unittest
from collections import deque

from tornado import gen
from tornado.testing import AsyncTestCase

import sys
if sys.version_info[0] >= 3:
    unicode = str

db_database = os.environ.get('MOMOKO_TEST_DB', 'momoko_test')
db_user = os.environ.get('MOMOKO_TEST_USER', 'postgres')
db_password = os.environ.get('MOMOKO_TEST_PASSWORD', '')
db_host = os.environ.get('MOMOKO_TEST_HOST', '')
db_port = os.environ.get('MOMOKO_TEST_PORT', 5432)
test_hstore = True if os.environ.get('MOMOKO_TEST_HSTORE', False) == '1' else False
good_dsn = 'dbname=%s user=%s password=%s host=%s port=%s' % (
    db_database, db_user, db_password, db_host, db_port)
bad_dsn = 'dbname=%s user=%s password=xx%s host=%s port=%s' % (
    'db', 'user', 'password', "127.0.0.127", 11111)
local_bad_dsn = 'dbname=%s user=%s password=xx%s' % (
    'db', 'user', 'password')

assert (db_database or db_user or db_password or db_host or db_port) is not None, (
    'Environment variables for the unit tests are not set. Please set the following '
    'variables: MOMOKO_TEST_DB, MOMOKO_TEST_USER, MOMOKO_TEST_PASSWORD, '
    'MOMOKO_TEST_HOST, MOMOKO_TEST_PORT')


psycopg2_impl = os.environ.get('MOMOKO_PSYCOPG2_IMPL', 'psycopg2')

if psycopg2_impl == 'psycopg2cffi':
    from psycopg2cffi import compat
    compat.register()
elif psycopg2_impl == 'psycopg2ct':
    from psycopg2ct import compat
    compat.register()


import momoko
import psycopg2
from psycopg2.extras import RealDictConnection, RealDictCursor

# Suspress connection errors on volatile db tests
momoko.Pool.log_connect_errors = False


class BaseTest(AsyncTestCase):
    pool_size = 3
    max_size = None
    raise_connect_errors = True
    dsn = good_dsn

    def __init__(self, *args, **kwargs):
        self.assert_equal = self.assertEqual
        self.assert_raises = self.assertRaises
        self.assert_is_instance = lambda object, classinfo: self.assertTrue(isinstance(object, classinfo))
        super(BaseTest, self).__init__(*args, **kwargs)

    if not hasattr(AsyncTestCase, "assertLess"):
        def assertLess(self, a, b, msg):
            return self.assertTrue(a < b, msg=msg)

    def setUp(self):
        super(BaseTest, self).setUp()
        self.set_up()

    def tearDown(self):
        self.tear_down()
        super(BaseTest, self).tearDown()

    def set_up(self):
        pass

    def tear_down(self):
        pass

    def stop_callback(self, result, error):
        self.stop((result, error))

    def run_gen(self, func):
        func()
        self.wait()

    def wait_for_result(self):
        cursor, error = self.wait()
        if error:
            raise error
        return cursor

    def build_pool(self, dsn=None, setsession=[], con_factory=None, cur_factory=None):
        db = momoko.Pool(
            dsn=(dsn or self.dsn),
            size=self.pool_size,
            max_size=self.max_size,
            callback=self.stop,
            ioloop=self.io_loop,
            setsession=setsession,
            raise_connect_errors=self.raise_connect_errors,
            connection_factory=con_factory,
            cursor_factory=cur_factory,
        )
        self.wait()
        return db

    def kill_connections(self, db, amount=None):
        amount = amount or len(db._conns.free)
        for conn in db._conns.free:
            if not amount:
                break
            if not conn.closed:
                conn.close()
                amount -= 1

    def run_and_check_query(self, db):
        db.execute('SELECT 6, 19, 24;', callback=self.stop_callback)
        cursor = self.wait_for_result()
        self.assert_equal(cursor.fetchall(), [(6, 19, 24)])


class MomokoBaseTest(BaseTest):

    def set_up(self):
        self.db = self.build_pool()

    def tear_down(self):
        self.db.close()


class MomokoBaseDataTest(MomokoBaseTest):
    def clean_db(self):
        self.db.execute('DROP TABLE IF EXISTS unit_test_large_query;',
                        callback=self.stop_callback)
        self.wait_for_result()
        self.db.execute('DROP TABLE IF EXISTS unit_test_transaction;',
                        callback=self.stop_callback)
        self.wait_for_result()
        self.db.execute('DROP TABLE IF EXISTS  unit_test_int_table;',
                        callback=self.stop_callback)
        self.wait_for_result()
        self.db.execute('DROP FUNCTION IF EXISTS  unit_test_callproc(integer);',
                        callback=self.stop_callback)
        self.wait_for_result()

    def prepare_db(self):
        self.clean_db()

        self.db.execute(
            'CREATE TABLE unit_test_large_query ('
            'id serial NOT NULL, name character varying, data text);',
            callback=self.stop_callback)
        self.wait_for_result()

        self.db.execute(
            'CREATE TABLE unit_test_transaction ('
            'id serial NOT NULL, name character varying, data text);',
            callback=self.stop_callback)
        self.wait_for_result()

        self.db.execute(
            'CREATE TABLE unit_test_int_table (id integer);',
            callback=self.stop_callback)
        self.wait_for_result()

        self.db.execute(
            'CREATE OR REPLACE FUNCTION unit_test_callproc(n integer)\n'
            'RETURNS integer AS $BODY$BEGIN\n'
            'RETURN n*n;\n'
            'END;$BODY$ LANGUAGE plpgsql VOLATILE;',
            callback=self.stop_callback)
        self.wait_for_result()

    def fill_int_data(self, amount=1000):
        self.db.transaction([
            "INSERT INTO unit_test_int_table VALUES %s" % ",".join("(%s)" % i for i in range(amount)),
        ], callback=self.stop_callback)
        self.wait_for_result()

    def set_up(self):
        super(MomokoBaseDataTest, self).set_up()
        self.prepare_db()

    def tear_down(self):
        self.clean_db()
        super(MomokoBaseDataTest, self).tear_down()


class MomokoTest(MomokoBaseDataTest):

    def test_single_query(self):
        """Testing single query"""
        self.run_and_check_query(self.db)

    def test_large_query(self):
        """Testing support for large queries"""
        query_size = 100000
        chars = string.ascii_letters + string.digits + string.punctuation

        for n in range(5):
            random_data = ''.join([random.choice(chars) for i in range(query_size)])
            self.db.execute('INSERT INTO unit_test_large_query (data) VALUES (%s) '
                            'RETURNING data;', (random_data,), callback=self.stop_callback)
            cursor = self.wait_for_result()
            self.assert_equal(cursor.fetchone(), (random_data,))

        self.db.execute('SELECT COUNT(*) FROM unit_test_large_query;',
                        callback=self.stop_callback)
        cursor = self.wait_for_result()
        self.assert_equal(cursor.fetchone(), (5,))

    if test_hstore:
        def test_hstore(self):
            """Testing hstore"""
            self.db.register_hstore(callback=self.stop_callback)
            self.wait()

            self.db.execute('SELECT \'a=>b, c=>d\'::hstore;', callback=self.stop_callback)
            cursor = self.wait_for_result()
            self.assert_equal(cursor.fetchall(), [({'a': 'b', 'c': 'd'},)])

            self.db.execute('SELECT %s;', ({'e': 'f', 'g': 'h'},), callback=self.stop_callback)
            cursor = self.wait_for_result()
            self.assert_equal(cursor.fetchall(), [({'e': 'f', 'g': 'h'},)])

    def test_callproc(self):
        """Testing callproc"""
        self.db.callproc('unit_test_callproc', (64,), callback=self.stop_callback)
        cursor = self.wait_for_result()
        self.assert_equal(cursor.fetchone(), (4096,))

    def test_query_error(self):
        """Testing that execute method propages exception properly"""
        self.db.execute('SELECT DOES NOT WORK!;', callback=self.stop_callback)
        _, error = self.wait()
        self.assert_is_instance(error, psycopg2.ProgrammingError)

    def test_mogrify(self):
        """Testing mogrify"""
        self.db.mogrify('SELECT %s, %s;', ('\'"test"\'', 'SELECT 1;'),
                        callback=self.stop_callback)
        sql = self.wait_for_result()
        if self.db.server_version < 90100:
            self.assert_equal(sql, b'SELECT E\'\'\'"test"\'\'\', E\'SELECT 1;\';')
        else:
            self.assert_equal(sql, b'SELECT \'\'\'"test"\'\'\', \'SELECT 1;\';')

        self.db.execute(sql, callback=self.stop_callback)
        _, error = self.wait()
        self.assert_equal(error, None)

    def test_mogrify_error(self):
        """Testing that mogri propagates exception properly"""
        self.db.mogrify('SELECT %(foos;', {'foo': 'bar'},
                        callback=self.stop_callback)
        _, error = self.wait()
        self.assert_is_instance(error, psycopg2.ProgrammingError)

    def build_transaction_query(self, ucode=False):
        return (
            unicode('SELECT 1, 2, 3, 4;') if ucode else 'SELECT 1, 2, 3, 4;',
            unicode('SELECT 5, 6, 7, 8;') if ucode else 'SELECT 5, 6, 7, 8;',
            'SELECT 9, 10, 11, 12;',
            ('SELECT %s+10, %s+10, %s+10, %s+10;', (3, 4, 5, 6)),
            'SELECT 17, 18, 19, 20;',
            ('SELECT %s+20, %s+20, %s+20, %s+20;', (1, 2, 3, 4)),
        )

    def compare_transaction_cursors(self, cursors):
        self.assert_equal(len(cursors), 6)
        self.assert_equal(cursors[0].fetchone(), (1, 2, 3, 4))
        self.assert_equal(cursors[1].fetchone(), (5, 6, 7, 8))
        self.assert_equal(cursors[2].fetchone(), (9, 10, 11, 12))
        self.assert_equal(cursors[3].fetchone(), (13, 14, 15, 16))
        self.assert_equal(cursors[4].fetchone(), (17, 18, 19, 20))
        self.assert_equal(cursors[5].fetchone(), (21, 22, 23, 24))

    def test_transaction(self):
        """Testing transaction functionality"""
        self.db.transaction(self.build_transaction_query(), callback=self.stop_callback)
        cursors = self.wait_for_result()
        self.compare_transaction_cursors(cursors)

    def test_unicode_transaction(self):
        """Testing transaction functionality"""
        self.db.transaction(self.build_transaction_query(True), callback=self.stop_callback)
        cursors = self.wait_for_result()
        self.compare_transaction_cursors(cursors)

    def test_transaction_rollback(self):
        """Testing transaction auto-rollback functionality"""
        chars = string.ascii_letters + string.digits + string.punctuation
        data = ''.join([random.choice(chars) for i in range(100)])

        self.db.transaction((
            ('INSERT INTO unit_test_transaction (data) VALUES (%s);', (data,)),
            'SELECT DOES NOT WORK!;'
        ), callback=self.stop_callback)
        _, error = self.wait()
        self.assert_is_instance(error, psycopg2.ProgrammingError)

        self.db.execute('SELECT COUNT(*) FROM unit_test_transaction;',
                        callback=self.stop_callback)
        cursor = self.wait_for_result()
        self.assert_equal(cursor.fetchone(), (0,))

    def test_op(self):
        """Testing Op"""
        @gen.engine
        def func():
            cursor = yield momoko.Op(self.db.execute, 'SELECT 1;')
            self.assert_equal(cursor.fetchone(), (1,))
            self.stop()

        self.run_gen(func)

    def test_op_exception(self):
        """Testing that Op propagates exception properly"""
        @gen.engine
        def func():
            cursor = yield momoko.Op(self.db.execute, 'SELECT DOES NOT WORK!;')
            self.stop()

        self.assert_raises(psycopg2.ProgrammingError, self.run_gen, func)

    def test_wait_op(self):
        """Testing WaitOp"""
        @gen.engine
        def func():
            self.db.execute('SELECT 1;', callback=(yield gen.Callback('q1')))
            cursor = yield momoko.WaitOp('q1')
            self.assert_equal(cursor.fetchone(), (1,))
            self.stop()

        self.run_gen(func)

    def test_wait_op_exception(self):
        """Testing that WaitOp propagates exception properly"""
        @gen.engine
        def func():
            self.db.execute('SELECT DOES NOT WORK!;', callback=(yield gen.Callback('q1')))
            cursor = yield momoko.WaitOp('q1')
            self.stop()

        self.assert_raises(psycopg2.ProgrammingError, self.run_gen, func)

    def test_wait_all_ops(self):
        """Testing WaitAllOps"""
        @gen.engine
        def func():
            self.db.execute('SELECT 1;', callback=(yield gen.Callback('q1')))
            self.db.execute('SELECT 2;', callback=(yield gen.Callback('q2')))
            self.db.execute('SELECT 3;', callback=(yield gen.Callback('q3')))

            cursor1, cursor2, cursor3 = yield momoko.WaitAllOps(('q1', 'q2', 'q3'))

            self.assert_equal(cursor1.fetchone(), (1,))
            self.assert_equal(cursor2.fetchone(), (2,))
            self.assert_equal(cursor3.fetchone(), (3,))
            self.stop()

        self.run_gen(func)

    def test_wait_all_ops_exception(self):
        """Testing that WaitAllOps propagates exception properly"""
        @gen.engine
        def func():
            self.db.execute('SELECT asfdsfe;', callback=(yield gen.Callback('q1')))
            self.db.execute('SELECT DOES NOT WORK!;', callback=(yield gen.Callback('q2')))
            self.db.execute('SELECT 1;', callback=(yield gen.Callback('q3')))

            cursor1, cursor2, cursor3 = yield momoko.WaitAllOps(('q1', 'q2', 'q3'))

            self.stop()

        self.assert_raises(psycopg2.ProgrammingError, self.run_gen, func)

    def test_transaction_with_reconnect(self):
        """Test whether transaction works after reconnect"""

        # Added result counting, since there was a bug in retry mechanism that caused
        # double-execution of query after reconnect
        self.kill_connections(self.db)
        self.db.transaction(("INSERT INTO unit_test_int_table VALUES (1)",),
                            callback=self.stop_callback)
        self.wait_for_result()
        self.db.execute("SELECT COUNT(1) FROM unit_test_int_table", callback=self.stop_callback)
        cursor = self.wait_for_result()
        self.assert_equal(cursor.fetchall(), [(1,)])

    def test_getconn_putconn(self):
        """Testing getconn/putconn functionality"""
        for i in range(self.pool_size * 2):
            # Run many times to check that connections get recycled properly
            self.db.getconn(callback=self.stop_callback)
            connection = self.wait_for_result()
            for j in range(10):
                connection.execute("SELECT %s", (j,), callback=self.stop_callback)
                cursor = self.wait_for_result()
                self.assert_equal(cursor.fetchall(), [(j, )])
            self.db.putconn(connection)

    def test_getconn_manage(self):
        """Testing getconn + context manager functionality"""
        for i in range(self.pool_size * 2):
            # Run many times to check that connections get recycled properly
            self.db.getconn(callback=self.stop_callback)
            connection = self.wait_for_result()
            with self.db.manage(connection):
                for j in range(10):
                    connection.execute("SELECT %s", (j,), callback=self.stop_callback)
                    cursor = self.wait_for_result()
                    self.assert_equal(cursor.fetchall(), [(j, )])


class MomokoServerSideCursorTest(MomokoBaseDataTest):
    def execute(self, connection, query, params=()):
        connection.execute(query, params, callback=self.stop_callback)
        return self.wait_for_result()

    def test_server_side_cursor(self):
        """Testing server side cursors support"""
        int_count = 1000
        offset = 0
        chunk = 10
        self.fill_int_data(int_count)

        self.db.getconn(callback=self.stop_callback)
        connection = self.wait_for_result()
        with self.db.manage(connection):
            self.execute(connection, "BEGIN")
            self.execute(connection, "DECLARE all_ints CURSOR FOR SELECT * FROM unit_test_int_table")
            while offset < int_count:
                cursor = self.execute(connection, "FETCH %s FROM all_ints", (chunk,))
                self.assert_equal(cursor.fetchall(), [(i, ) for i in range(offset, offset+chunk)])
                offset += chunk
            self.execute(connection, "CLOSE all_ints")
            self.execute(connection, "COMMIT")


class MomokoParallelTest(MomokoBaseTest):
    def test_parallel_queries(self, jobs=None):
        """Testing that pool queries database in parallel"""
        sleep_time = 2

        @gen.engine
        def func():
            qnum = jobs or max(self.pool_size, self.max_size if self.max_size else 0)
            for i in range(qnum):
                self.db.execute('SELECT pg_sleep(%s);' % sleep_time,
                                callback=(yield gen.Callback('q%s' % i)))

            yield momoko.WaitAllOps(["q%s" % i for i in range(qnum)])
            self.stop()

        start_time = time.time()
        self.run_gen(func)
        execution_time = time.time() - start_time
        self.assertLess(execution_time, sleep_time*1.10, msg="Query execution was too long")

    def test_parallel_queries_after_reconnect_all(self):
        """Testing that pool still queries database in parallel after ALL connections were killed"""
        self.kill_connections(self.db)
        self.test_parallel_queries()

    def test_parallel_queries_after_reconnect_some(self):
        """Testing that pool still queries database in parallel after SOME connections were killed"""
        self.kill_connections(self.db)
        self.kill_connections(self.db, amount=self.pool_size/2)
        self.test_parallel_queries()


class MomokoStretchTest(MomokoParallelTest):
    pool_size = 1
    max_size = 5

    def test_parallel_queries(self):
        """Run parallel queies and check that pool size matches number of jobs"""
        jobs = self.max_size - 1
        super(MomokoStretchTest, self).test_parallel_queries(jobs)
        self.assert_equal(self.db._conns.total, jobs)

    def test_dont_stretch(self):
        """Testing that we do not stretch unless needed"""
        self.run_and_check_query(self.db)
        self.assert_equal(self.db._conns.total, self.pool_size)

    def test_dont_stretch_after_reconnect(self):
        """Testing that reconnecting dead connection does not trigger pool stretch"""
        self.kill_connections(self.db)
        self.test_dont_stretch()

    def test_stretch_after_disonnect(self):
        """Testing that stretch works after disconnect"""
        self.kill_connections(self.db)
        self.test_parallel_queries()

    def test_stretch_genconn(self):
        """Testing that stretch works together with get/putconn"""
        @gen.engine
        def func():
            self.db.getconn(callback=(yield gen.Callback('q1')))
            self.db.getconn(callback=(yield gen.Callback('q2')))
            self.db.getconn(callback=(yield gen.Callback('q3')))

            conn1, conn2, conn3 = yield momoko.WaitAllOps(('q1', 'q2', 'q3'))

            conn1.execute('SELECT 1;', callback=(yield gen.Callback('q1')))
            conn2.execute('SELECT 2;', callback=(yield gen.Callback('q2')))
            conn3.execute('SELECT 3;', callback=(yield gen.Callback('q3')))

            cursor1, cursor2, cursor3 = yield momoko.WaitAllOps(('q1', 'q2', 'q3'))

            self.assert_equal(cursor1.fetchone(), (1,))
            self.assert_equal(cursor2.fetchone(), (2,))
            self.assert_equal(cursor3.fetchone(), (3,))

            for conn in conn1, conn2, conn3:
                self.db.putconn(conn)

            self.stop()

        self.run_gen(func)
        self.assert_equal(self.db._conns.total, 3)


class MomokoSetsessionTest(BaseTest):
    pool_size = 1

    def test_setsession(self):
        """Testing that setssion parameter is honoured"""
        setsession = deque([None, "SELECT 1", "SELECT 2"])
        time_zones = ["UTC", "Israel", "Europe/London"]

        for i in range(len(time_zones)):
            setsession[i] = "SET TIME ZONE '%s'" % time_zones[i]
            db = self.build_pool(setsession=setsession)
            db.execute("SELECT current_setting('TIMEZONE');", callback=self.stop_callback)
            cursor = self.wait_for_result()
            self.assert_equal(cursor.fetchall(), [(time_zones[i],)])
            db.close()
            setsession.rotate(1)


class MomokoVolatileDbTest(BaseTest):
    raise_connect_errors = False
    pool_size = 3

    def test_startup(self):
        """Testing that all connections are dead after pool init with bad dsn"""
        db = self.build_pool(dsn=bad_dsn)
        self.assert_equal(self.pool_size, len(db._conns.dead))

    def test_startup_local(self):
        """Testing that we catch early exeception with local connections"""
        db = self.build_pool(dsn=local_bad_dsn)
        self.assert_equal(self.pool_size, len(db._conns.dead))

    def test_reconnect(self):
        """Testing if we can reconnect if connections die"""
        db = self.build_pool(dsn=good_dsn)
        self.kill_connections(db)
        self.run_and_check_query(db)

    def test_reconnect_interval_good_path(self):
        """Testing that we can recover if database was down during startup"""
        db = self.build_pool(dsn=bad_dsn)
        db.dsn = good_dsn
        time.sleep(db._conns.reconnect_interval)
        self.run_and_check_query(db)

    def test_reconnect_interval_bad_path(self):
        """Testing that pool does not try to reconnect right after last connection attempt failed"""
        db = self.build_pool(dsn=bad_dsn)
        try:
            self.run_and_check_query(db)
        except psycopg2.DatabaseError:
            pass


class MomokoFactoriesTest(BaseTest):
    def run_and_check_dict(self, db):
        db.execute("SELECT 1 AS a", callback=self.stop_callback)
        cursor = self.wait_for_result()
        self.assert_equal(cursor.fetchone(), {"a": 1})

    def test_cursor_factory(self):
        """Testing that cursor_factory parameter is properly propagated"""
        if psycopg2_impl == "psycopg2ct":
            # Known bug: https://github.com/mvantellingen/psycopg2-ctypes/issues/31
            return
        db = self.build_pool(cur_factory=RealDictCursor)
        self.run_and_check_dict(db)

    def test_connection_factory(self):
        """Testing that connection_factory parameter is properly propagated"""
        db = self.build_pool(con_factory=RealDictConnection)
        self.run_and_check_dict(db)


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
