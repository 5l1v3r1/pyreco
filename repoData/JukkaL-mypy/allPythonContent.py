__FILENAME__ = builtins
# Builtins for the native back end

# TODO this still in early stages of development

from typing import typevar, Generic, builtinclass

T = typevar('T')

@builtinclass
class object:
    def __init__(self) -> None: pass

@builtinclass
class type: pass
@builtinclass
class str: pass

# Primitive types are special in generated code.

@builtinclass
class int:
    def __add__(self, n: int) -> int: pass
    def __sub__(self, n: int) -> int: pass
    def __mul__(self, n: int) -> int: pass
    def __floordiv__(self, n: int) -> int: pass
    def __mod__(self, n: int) -> int: pass
    def __neg__(self) -> int: pass
    def __and__(self, n: int) -> int: pass
    def __or__(self, n: int) -> int: pass
    def __xor__(self, n: int) -> int: pass
    def __lshift__(self, n: int) -> int: pass
    def __rshift__(self, n: int) -> int: pass
    def __invert__(self) -> int: pass
    def __eq__(self, n: int) -> bool: pass
    def __ne__(self, n: int) -> bool: pass
    def __lt__(self, n: int) -> bool: pass
    def __gt__(self, n: int) -> bool: pass
    def __le__(self, n: int) -> bool: pass
    def __ge__(self, n: int) -> bool: pass

@builtinclass
class float: pass
@builtinclass
class bool: pass

@builtinclass
class list(Generic[T]): pass

def print(*object) -> None: pass

########NEW FILE########
__FILENAME__ = base64
#! /usr/bin/env python3

"""RFC 3548: Base16, Base32, Base64 Data Encodings"""

# Modified 04-Oct-1995 by Jack Jansen to use binascii module
# Modified 30-Dec-2003 by Barry Warsaw to add full RFC 3548 support
# Modified 22-May-2007 by Guido van Rossum to use bytes everywhere

import re
import struct
import binascii

from typing import Dict, List, AnyStr, IO


__all__ = [
    # Legacy interface exports traditional RFC 1521 Base64 encodings
    'encode', 'decode', 'encodebytes', 'decodebytes',
    # Generalized interface for other encodings
    'b64encode', 'b64decode', 'b32encode', 'b32decode',
    'b16encode', 'b16decode',
    # Standard Base64 encoding
    'standard_b64encode', 'standard_b64decode',
    # Some common Base64 alternatives.  As referenced by RFC 3458, see thread
    # starting at:
    #
    # http://zgp.org/pipermail/p2p-hackers/2001-September/000316.html
    'urlsafe_b64encode', 'urlsafe_b64decode',
    ]


bytes_types = (bytes, bytearray)  # Types acceptable as binary data


def _translate(s: bytes, altchars: Dict[AnyStr, bytes]) -> bytes:
    if not isinstance(s, bytes_types):
        raise TypeError("expected bytes, not %s" % s.__class__.__name__)
    translation = bytearray(range(256))
    for k, v in altchars.items():
        translation[ord(k)] = v[0]
    return s.translate(translation)



# Base64 encoding/decoding uses binascii

def b64encode(s: bytes, altchars: bytes = None) -> bytes:
    """Encode a byte string using Base64.

    s is the byte string to encode.  Optional altchars must be a byte
    string of length 2 which specifies an alternative alphabet for the
    '+' and '/' characters.  This allows an application to
    e.g. generate url or filesystem safe Base64 strings.

    The encoded byte string is returned.
    """
    if not isinstance(s, bytes_types):
        raise TypeError("expected bytes, not %s" % s.__class__.__name__)
    # Strip off the trailing newline
    encoded = binascii.b2a_base64(s)[:-1]
    if altchars is not None:
        if not isinstance(altchars, bytes_types):
            raise TypeError("expected bytes, not %s"
                            % altchars.__class__.__name__)
        assert len(altchars) == 2, repr(altchars)
        return _translate(encoded, {'+': altchars[0:1], '/': altchars[1:2]})
    return encoded


def b64decode(s: bytes, altchars: bytes = None,
              validate: bool = False) -> bytes:
    """Decode a Base64 encoded byte string.

    s is the byte string to decode.  Optional altchars must be a
    string of length 2 which specifies the alternative alphabet used
    instead of the '+' and '/' characters.

    The decoded string is returned.  A binascii.Error is raised if s is
    incorrectly padded.

    If validate is False (the default), non-base64-alphabet characters are
    discarded prior to the padding check.  If validate is True,
    non-base64-alphabet characters in the input result in a binascii.Error.
    """
    if not isinstance(s, bytes_types):
        raise TypeError("expected bytes, not %s" % s.__class__.__name__)
    if altchars is not None:
        if not isinstance(altchars, bytes_types):
            raise TypeError("expected bytes, not %s"
                            % altchars.__class__.__name__)
        assert len(altchars) == 2, repr(altchars)
        s = _translate(s, {chr(altchars[0]): b'+', chr(altchars[1]): b'/'})
    if validate and not re.match(b'^[A-Za-z0-9+/]*={0,2}$', s):
        raise binascii.Error('Non-base64 digit found')
    return binascii.a2b_base64(s)


def standard_b64encode(s: bytes) -> bytes:
    """Encode a byte string using the standard Base64 alphabet.

    s is the byte string to encode.  The encoded byte string is returned.
    """
    return b64encode(s)

def standard_b64decode(s: bytes) -> bytes:
    """Decode a byte string encoded with the standard Base64 alphabet.

    s is the byte string to decode.  The decoded byte string is
    returned.  binascii.Error is raised if the input is incorrectly
    padded or if there are non-alphabet characters present in the
    input.
    """
    return b64decode(s)

def urlsafe_b64encode(s: bytes) -> bytes:
    """Encode a byte string using a url-safe Base64 alphabet.

    s is the byte string to encode.  The encoded byte string is
    returned.  The alphabet uses '-' instead of '+' and '_' instead of
    '/'.
    """
    return b64encode(s, b'-_')

def urlsafe_b64decode(s: bytes) -> bytes:
    """Decode a byte string encoded with the standard Base64 alphabet.

    s is the byte string to decode.  The decoded byte string is
    returned.  binascii.Error is raised if the input is incorrectly
    padded or if there are non-alphabet characters present in the
    input.

    The alphabet uses '-' instead of '+' and '_' instead of '/'.
    """
    return b64decode(s, b'-_')



# Base32 encoding/decoding must be done in Python
_b32alphabet = {
    0: b'A',  9: b'J', 18: b'S', 27: b'3',
    1: b'B', 10: b'K', 19: b'T', 28: b'4',
    2: b'C', 11: b'L', 20: b'U', 29: b'5',
    3: b'D', 12: b'M', 21: b'V', 30: b'6',
    4: b'E', 13: b'N', 22: b'W', 31: b'7',
    5: b'F', 14: b'O', 23: b'X',
    6: b'G', 15: b'P', 24: b'Y',
    7: b'H', 16: b'Q', 25: b'Z',
    8: b'I', 17: b'R', 26: b'2',
    }

_b32tab = [v[0] for k, v in sorted(_b32alphabet.items())]
_b32rev = dict([(v[0], k) for k, v in _b32alphabet.items()])


def b32encode(s: bytes) -> bytes:
    """Encode a byte string using Base32.

    s is the byte string to encode.  The encoded byte string is returned.
    """
    if not isinstance(s, bytes_types):
        raise TypeError("expected bytes, not %s" % s.__class__.__name__)
    quanta, leftover = divmod(len(s), 5)
    # Pad the last quantum with zero bits if necessary
    if leftover:
        s = s + bytes(5 - leftover)  # Don't use += !
        quanta += 1
    encoded = bytes()
    for i in range(quanta):
        # c1 and c2 are 16 bits wide, c3 is 8 bits wide.  The intent of this
        # code is to process the 40 bits in units of 5 bits.  So we take the 1
        # leftover bit of c1 and tack it onto c2.  Then we take the 2 leftover
        # bits of c2 and tack them onto c3.  The shifts and masks are intended
        # to give us values of exactly 5 bits in width.
        c1, c2, c3 = struct.unpack('!HHB', s[i*5:(i+1)*5]) # type: (int, int, int)
        c2 += (c1 & 1) << 16 # 17 bits wide
        c3 += (c2 & 3) << 8  # 10 bits wide
        encoded += bytes([_b32tab[c1 >> 11],         # bits 1 - 5
                          _b32tab[(c1 >> 6) & 0x1f], # bits 6 - 10
                          _b32tab[(c1 >> 1) & 0x1f], # bits 11 - 15
                          _b32tab[c2 >> 12],         # bits 16 - 20 (1 - 5)
                          _b32tab[(c2 >> 7) & 0x1f], # bits 21 - 25 (6 - 10)
                          _b32tab[(c2 >> 2) & 0x1f], # bits 26 - 30 (11 - 15)
                          _b32tab[c3 >> 5],          # bits 31 - 35 (1 - 5)
                          _b32tab[c3 & 0x1f],        # bits 36 - 40 (1 - 5)
                          ])
    # Adjust for any leftover partial quanta
    if leftover == 1:
        return encoded[:-6] + b'======'
    elif leftover == 2:
        return encoded[:-4] + b'===='
    elif leftover == 3:
        return encoded[:-3] + b'==='
    elif leftover == 4:
        return encoded[:-1] + b'='
    return encoded


def b32decode(s: bytes, casefold: bool = False, map01: bytes = None) -> bytes:
    """Decode a Base32 encoded byte string.

    s is the byte string to decode.  Optional casefold is a flag
    specifying whether a lowercase alphabet is acceptable as input.
    For security purposes, the default is False.

    RFC 3548 allows for optional mapping of the digit 0 (zero) to the
    letter O (oh), and for optional mapping of the digit 1 (one) to
    either the letter I (eye) or letter L (el).  The optional argument
    map01 when not None, specifies which letter the digit 1 should be
    mapped to (when map01 is not None, the digit 0 is always mapped to
    the letter O).  For security purposes the default is None, so that
    0 and 1 are not allowed in the input.

    The decoded byte string is returned.  binascii.Error is raised if
    the input is incorrectly padded or if there are non-alphabet
    characters present in the input.
    """
    if not isinstance(s, bytes_types):
        raise TypeError("expected bytes, not %s" % s.__class__.__name__)
    quanta, leftover = divmod(len(s), 8)
    if leftover:
        raise binascii.Error('Incorrect padding')
    # Handle section 2.4 zero and one mapping.  The flag map01 will be either
    # False, or the character to map the digit 1 (one) to.  It should be
    # either L (el) or I (eye).
    if map01 is not None:
        if not isinstance(map01, bytes_types):
            raise TypeError("expected bytes, not %s" % map01.__class__.__name__)
        assert len(map01) == 1, repr(map01)
        s = _translate(s, {b'0': b'O', b'1': map01})
    if casefold:
        s = s.upper()
    # Strip off pad characters from the right.  We need to count the pad
    # characters because this will tell us how many null bytes to remove from
    # the end of the decoded string.
    padchars = 0
    mo = re.search(b'(?P<pad>[=]*)$', s)
    if mo:
        padchars = len(mo.group('pad'))
        if padchars > 0:
            s = s[:-padchars]
    # Now decode the full quanta
    parts = List[bytes]()
    acc = 0
    shift = 35
    for c in s:
        val = _b32rev.get(c)
        if val is None:
            raise TypeError('Non-base32 digit found')
        acc += _b32rev[c] << shift
        shift -= 5
        if shift < 0:
            parts.append(binascii.unhexlify(bytes('%010x' % acc, "ascii")))
            acc = 0
            shift = 35
    # Process the last, partial quanta
    last = binascii.unhexlify(bytes('%010x' % acc, "ascii"))
    if padchars == 0:
        last = b''                      # No characters
    elif padchars == 1:
        last = last[:-1]
    elif padchars == 3:
        last = last[:-2]
    elif padchars == 4:
        last = last[:-3]
    elif padchars == 6:
        last = last[:-4]
    else:
        raise binascii.Error('Incorrect padding')
    parts.append(last)
    return b''.join(parts)



# RFC 3548, Base 16 Alphabet specifies uppercase, but hexlify() returns
# lowercase.  The RFC also recommends against accepting input case
# insensitively.
def b16encode(s: bytes) -> bytes:
    """Encode a byte string using Base16.

    s is the byte string to encode.  The encoded byte string is returned.
    """
    if not isinstance(s, bytes_types):
        raise TypeError("expected bytes, not %s" % s.__class__.__name__)
    return binascii.hexlify(s).upper()


def b16decode(s: bytes, casefold: bool = False) -> bytes:
    """Decode a Base16 encoded byte string.

    s is the byte string to decode.  Optional casefold is a flag
    specifying whether a lowercase alphabet is acceptable as input.
    For security purposes, the default is False.

    The decoded byte string is returned.  binascii.Error is raised if
    s were incorrectly padded or if there are non-alphabet characters
    present in the string.
    """
    if not isinstance(s, bytes_types):
        raise TypeError("expected bytes, not %s" % s.__class__.__name__)
    if casefold:
        s = s.upper()
    if re.search(b'[^0-9A-F]', s):
        raise binascii.Error('Non-base16 digit found')
    return binascii.unhexlify(s)



# Legacy interface.  This code could be cleaned up since I don't believe
# binascii has any line length limitations.  It just doesn't seem worth it
# though.  The files should be opened in binary mode.

MAXLINESIZE = 76 # Excluding the CRLF
MAXBINSIZE = (MAXLINESIZE//4)*3

def encode(input: IO[bytes], output: IO[bytes]) -> None:
    """Encode a file; input and output are binary files."""
    while True:
        s = input.read(MAXBINSIZE)
        if not s:
            break
        while len(s) < MAXBINSIZE:
            ns = input.read(MAXBINSIZE-len(s))
            if not ns:
                break
            s += ns
        line = binascii.b2a_base64(s)
        output.write(line)


def decode(input: IO[bytes], output: IO[bytes]) -> None:
    """Decode a file; input and output are binary files."""
    while True:
        line = input.readline()
        if not line:
            break
        s = binascii.a2b_base64(line)
        output.write(s)


def encodebytes(s: bytes) -> bytes:
    """Encode a bytestring into a bytestring containing multiple lines
    of base-64 data."""
    if not isinstance(s, bytes_types):
        raise TypeError("expected bytes, not %s" % s.__class__.__name__)
    pieces = List[bytes]()
    for i in range(0, len(s), MAXBINSIZE):
        chunk = s[i : i + MAXBINSIZE]
        pieces.append(binascii.b2a_base64(chunk))
    return b"".join(pieces)

def encodestring(s: bytes) -> bytes:
    """Legacy alias of encodebytes()."""
    import warnings
    warnings.warn("encodestring() is a deprecated alias, use encodebytes()",
                  DeprecationWarning, 2)
    return encodebytes(s)


def decodebytes(s: bytes) -> bytes:
    """Decode a bytestring of base-64 data into a bytestring."""
    if not isinstance(s, bytes_types):
        raise TypeError("expected bytes, not %s" % s.__class__.__name__)
    return binascii.a2b_base64(s)

def decodestring(s: bytes) -> bytes:
    """Legacy alias of decodebytes()."""
    import warnings
    warnings.warn("decodestring() is a deprecated alias, use decodebytes()",
                  DeprecationWarning, 2)
    return decodebytes(s)


# Usable as a script...
def main() -> None:
    """Small main program"""
    import sys, getopt
    try:
        opts, args = getopt.getopt(sys.argv[1:], 'deut')
    except getopt.error as msg:
        sys.stdout = sys.stderr
        print(msg)
        print("""usage: %s [-d|-e|-u|-t] [file|-]
        -d, -u: decode
        -e: encode (default)
        -t: encode and decode string 'Aladdin:open sesame'"""%sys.argv[0])
        sys.exit(2)
    func = encode
    for o, a in opts:
        if o == '-e': func = encode
        if o == '-d': func = decode
        if o == '-u': func = decode
        if o == '-t': test(); return
    if args and args[0] != '-':
        with open(args[0], 'rb') as f:
            func(f, sys.stdout.buffer)
    else:
        func(sys.stdin.buffer, sys.stdout.buffer)


def test() -> None:
    s0 = b"Aladdin:open sesame"
    print(repr(s0))
    s1 = encodebytes(s0)
    print(repr(s1))
    s2 = decodebytes(s1)
    print(repr(s2))
    assert s0 == s2


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = fnmatch
"""Filename matching with shell patterns.

fnmatch(FILENAME, PATTERN) matches according to the local convention.
fnmatchcase(FILENAME, PATTERN) always takes case in account.

The functions operate by translating the pattern into a regular
expression.  They cache the compiled regular expressions for speed.

The function translate(PATTERN) returns a regular expression
corresponding to PATTERN.  (It does not compile it.)
"""
import os
import posixpath
import re
import functools

from typing import Iterable, List, AnyStr, Any, Function, Match

__all__ = ["filter", "fnmatch", "fnmatchcase", "translate"]

def fnmatch(name: AnyStr, pat: AnyStr) -> bool:
    """Test whether FILENAME matches PATTERN.

    Patterns are Unix shell style:

    *       matches everything
    ?       matches any single character
    [seq]   matches any character in seq
    [!seq]  matches any char not in seq

    An initial period in FILENAME is not special.
    Both FILENAME and PATTERN are first case-normalized
    if the operating system requires it.
    If you don't want this, use fnmatchcase(FILENAME, PATTERN).
    """
    name = os.path.normcase(name)
    pat = os.path.normcase(pat)
    return fnmatchcase(name, pat)

@functools.lru_cache(maxsize=250)
def _compile_pattern(pat: AnyStr,
                     is_bytes: bool = False) -> Function[[AnyStr],
                                                         Match[AnyStr]]:
    if isinstance(pat, bytes):
        pat_str = str(pat, 'ISO-8859-1')
        res_str = translate(pat_str)
        res = bytes(res_str, 'ISO-8859-1')
    else:
        res = translate(pat)
    return re.compile(res).match

def filter(names: Iterable[AnyStr], pat: AnyStr) -> List[AnyStr]:
    """Return the subset of the list NAMES that match PAT."""
    result = List[AnyStr]()
    pat = os.path.normcase(pat)
    match = _compile_pattern(pat, isinstance(pat, bytes))
    if os.path is posixpath:
        # normcase on posix is NOP. Optimize it away from the loop.
        for name in names:
            if match(name):
                result.append(name)
    else:
        for name in names:
            if match(os.path.normcase(name)):
                result.append(name)
    return result

def fnmatchcase(name: AnyStr, pat: AnyStr) -> bool:
    """Test whether FILENAME matches PATTERN, including case.

    This is a version of fnmatch() which doesn't case-normalize
    its arguments.
    """
    match = _compile_pattern(pat, isinstance(pat, bytes))
    return match(name) is not None

def translate(pat: str) -> str:
    """Translate a shell PATTERN to a regular expression.

    There is no way to quote meta-characters.
    """

    i, n = 0, len(pat)
    res = ''
    while i < n:
        c = pat[i]
        i = i+1
        if c == '*':
            res = res + '.*'
        elif c == '?':
            res = res + '.'
        elif c == '[':
            j = i
            if j < n and pat[j] == '!':
                j = j+1
            if j < n and pat[j] == ']':
                j = j+1
            while j < n and pat[j] != ']':
                j = j+1
            if j >= n:
                res = res + '\\['
            else:
                stuff = pat[i:j].replace('\\','\\\\')
                i = j+1
                if stuff[0] == '!':
                    stuff = '^' + stuff[1:]
                elif stuff[0] == '^':
                    stuff = '\\' + stuff
                res = '%s[%s]' % (res, stuff)
        else:
            res = res + re.escape(c)
    return res + '\Z(?ms)'

########NEW FILE########
__FILENAME__ = genericpath
"""
Path operations common to more than one OS
Do not use directly.  The OS specific modules import the appropriate
functions from this module themselves.
"""
import os
import stat

from typing import (
    Any as Any_, List as List_, AnyStr as AnyStr_, Tuple as Tuple_
)

__all__ = ['commonprefix', 'exists', 'getatime', 'getctime', 'getmtime',
           'getsize', 'isdir', 'isfile']


# Does a path exist?
# This is false for dangling symbolic links on systems that support them.
def exists(path: AnyStr_) -> bool:
    """Test whether a path exists.  Returns False for broken symbolic links"""
    try:
        os.stat(path)
    except os.error:
        return False
    return True


# This follows symbolic links, so both islink() and isdir() can be true
# for the same path ono systems that support symlinks
def isfile(path: AnyStr_) -> bool:
    """Test whether a path is a regular file"""
    try:
        st = os.stat(path)
    except os.error:
        return False
    return stat.S_ISREG(st.st_mode)


# Is a path a directory?
# This follows symbolic links, so both islink() and isdir()
# can be true for the same path on systems that support symlinks
def isdir(s: AnyStr_) -> bool:
    """Return true if the pathname refers to an existing directory."""
    try:
        st = os.stat(s)
    except os.error:
        return False
    return stat.S_ISDIR(st.st_mode)


def getsize(filename: AnyStr_) -> int:
    """Return the size of a file, reported by os.stat()."""
    return os.stat(filename).st_size


def getmtime(filename: AnyStr_) -> float:
    """Return the last modification time of a file, reported by os.stat()."""
    return os.stat(filename).st_mtime


def getatime(filename: AnyStr_) -> float:
    """Return the last access time of a file, reported by os.stat()."""
    return os.stat(filename).st_atime


def getctime(filename: AnyStr_) -> float:
    """Return the metadata change time of a file, reported by os.stat()."""
    return os.stat(filename).st_ctime


# Return the longest prefix of all list elements.
def commonprefix(m: List_[AnyStr_]) -> Any_:
    "Given a list of pathnames, returns the longest common leading component"
    if not m: return ''
    s1 = min(m)
    s2 = max(m)
    for i, c in enumerate(s1):
        if c != s2[i]:
            return s1[:i]
    return s1


# Split a path in root and extension.
# The extension is everything starting at the last dot in the last
# pathname component; the root is everything before that.
# It is always true that root + ext == p.

# Generic implementation of splitext, to be parametrized with
# the separators
def _splitext(p: AnyStr_, sep: AnyStr_, altsep: AnyStr_,
              extsep: AnyStr_) -> Tuple_[AnyStr_, AnyStr_]:
    """Split the extension from a pathname.

    Extension is everything from the last dot to the end, ignoring
    leading dots.  Returns "(root, ext)"; ext may be empty."""
    # NOTE: This code must work for text and bytes strings.

    sepIndex = p.rfind(sep)
    if altsep:
        altsepIndex = p.rfind(altsep)
        sepIndex = max(sepIndex, altsepIndex)

    dotIndex = p.rfind(extsep)
    if dotIndex > sepIndex:
        # skip all leading dots
        filenameIndex = sepIndex + 1
        while filenameIndex < dotIndex:
            if p[filenameIndex:filenameIndex+1] != extsep:
                return p[:dotIndex], p[dotIndex:]
            filenameIndex += 1

    return p, p[:0]

########NEW FILE########
__FILENAME__ = getopt
"""Parser for command line options.

This module helps scripts to parse the command line arguments in
sys.argv.  It supports the same conventions as the Unix getopt()
function (including the special meanings of arguments of the form `-'
and `--').  Long options similar to those supported by GNU software
may be used as well via an optional third argument.  This module
provides two functions and an exception:

getopt() -- Parse command line options
gnu_getopt() -- Like getopt(), but allow option and non-option arguments
to be intermixed.
GetoptError -- exception (class) raised with 'opt' attribute, which is the
option involved with the exception.
"""

# Long option support added by Lars Wirzenius <liw@iki.fi>.
#
# Gerrit Holl <gerrit@nl.linux.org> moved the string-based exceptions
# to class-based exceptions.
#
# Peter Ãstrand <astrand@lysator.liu.se> added gnu_getopt().
#
# TODO for gnu_getopt():
#
# - GNU getopt_long_only mechanism
# - allow the caller to specify ordering
# - RETURN_IN_ORDER option
# - GNU extension with '-' as first character of option string
# - optional arguments, specified by double colons
# - a option string with a W followed by semicolon should
#   treat "-W foo" as "--foo"

__all__ = ["GetoptError","error","getopt","gnu_getopt"]

import os

from typing import List, Tuple, Iterable

class GetoptError(Exception):
    opt = ''
    msg = ''
    def __init__(self, msg: str, opt: str = '') -> None:
        self.msg = msg
        self.opt = opt
        Exception.__init__(self, msg, opt)

    def __str__(self) -> str:
        return self.msg

error = GetoptError # backward compatibility

def getopt(args: List[str], shortopts: str,
           longopts: Iterable[str]  =  []) -> Tuple[List[Tuple[str, str]],
                                                    List[str]]:
    """getopt(args, options[, long_options]) -> opts, args

    Parses command line options and parameter list.  args is the
    argument list to be parsed, without the leading reference to the
    running program.  Typically, this means "sys.argv[1:]".  shortopts
    is the string of option letters that the script wants to
    recognize, with options that require an argument followed by a
    colon (i.e., the same format that Unix getopt() uses).  If
    specified, longopts is a list of strings with the names of the
    long options which should be supported.  The leading '--'
    characters should not be included in the option name.  Options
    which require an argument should be followed by an equal sign
    ('=').

    The return value consists of two elements: the first is a list of
    (option, value) pairs; the second is the list of program arguments
    left after the option list was stripped (this is a trailing slice
    of the first argument).  Each option-and-value pair returned has
    the option as its first element, prefixed with a hyphen (e.g.,
    '-x'), and the option argument as its second element, or an empty
    string if the option has no argument.  The options occur in the
    list in the same order in which they were found, thus allowing
    multiple occurrences.  Long and short options may be mixed.

    """

    opts = List[Tuple[str, str]]()
    if isinstance(longopts, str):
        llongopts = [longopts]
    else:
        llongopts = list(longopts)
    while args and args[0].startswith('-') and args[0] != '-':
        if args[0] == '--':
            args = args[1:]
            break
        if args[0].startswith('--'):
            opts, args = do_longs(opts, args[0][2:], llongopts, args[1:])
        else:
            opts, args = do_shorts(opts, args[0][1:], shortopts, args[1:])

    return opts, args

def gnu_getopt(args: List[str], shortopts: str,
               longopts: Iterable[str]  =  []) -> Tuple[List[Tuple[str, str]],
                                                        List[str]]:
    """getopt(args, options[, long_options]) -> opts, args

    This function works like getopt(), except that GNU style scanning
    mode is used by default. This means that option and non-option
    arguments may be intermixed. The getopt() function stops
    processing options as soon as a non-option argument is
    encountered.

    If the first character of the option string is `+', or if the
    environment variable POSIXLY_CORRECT is set, then option
    processing stops as soon as a non-option argument is encountered.

    """

    opts = List[Tuple[str, str]]()
    prog_args = List[str]()
    if isinstance(longopts, str):
        llongopts = [longopts]
    else:
        llongopts = list(longopts)

    # Allow options after non-option arguments?
    if shortopts.startswith('+'):
        shortopts = shortopts[1:]
        all_options_first = True
    elif os.environ.get("POSIXLY_CORRECT"):
        all_options_first = True
    else:
        all_options_first = False

    while args:
        if args[0] == '--':
            prog_args += args[1:]
            break

        if args[0][:2] == '--':
            opts, args = do_longs(opts, args[0][2:], llongopts, args[1:])
        elif args[0][:1] == '-' and args[0] != '-':
            opts, args = do_shorts(opts, args[0][1:], shortopts, args[1:])
        else:
            if all_options_first:
                prog_args += args
                break
            else:
                prog_args.append(args[0])
                args = args[1:]

    return opts, prog_args

def do_longs(opts: List[Tuple[str, str]], opt: str,
             longopts: List[str],
             args: List[str]) -> Tuple[List[Tuple[str, str]], List[str]]:
    try:
        i = opt.index('=')
    except ValueError:
        optarg = None # type: str
    else:
        opt, optarg = opt[:i], opt[i+1:]

    has_arg, opt = long_has_args(opt, longopts)
    if has_arg:
        if optarg is None:
            if not args:
                raise GetoptError('option --%s requires argument' % opt, opt)
            optarg, args = args[0], args[1:]
    elif optarg is not None:
        raise GetoptError('option --%s must not have an argument' % opt, opt)
    opts.append(('--' + opt, optarg or ''))
    return opts, args

# Return:
#   has_arg?
#   full option name
def long_has_args(opt: str, longopts: List[str]) -> Tuple[bool, str]:
    possibilities = [o for o in longopts if o.startswith(opt)]
    if not possibilities:
        raise GetoptError('option --%s not recognized' % opt, opt)
    # Is there an exact match?
    if opt in possibilities:
        return False, opt
    elif opt + '=' in possibilities:
        return True, opt
    # No exact match, so better be unique.
    if len(possibilities) > 1:
        # XXX since possibilities contains all valid continuations, might be
        # nice to work them into the error msg
        raise GetoptError('option --%s not a unique prefix' % opt, opt)
    assert len(possibilities) == 1
    unique_match = possibilities[0]
    has_arg = unique_match.endswith('=')
    if has_arg:
        unique_match = unique_match[:-1]
    return has_arg, unique_match

def do_shorts(opts: List[Tuple[str, str]], optstring: str,
              shortopts: str, args: List[str]) -> Tuple[List[Tuple[str, str]],
                                                        List[str]]:
    while optstring != '':
        opt, optstring = optstring[0], optstring[1:]
        if short_has_arg(opt, shortopts):
            if optstring == '':
                if not args:
                    raise GetoptError('option -%s requires argument' % opt,
                                      opt)
                optstring, args = args[0], args[1:]
            optarg, optstring = optstring, ''
        else:
            optarg = ''
        opts.append(('-' + opt, optarg))
    return opts, args

def short_has_arg(opt: str, shortopts: str) -> bool:
    for i in range(len(shortopts)):
        if opt == shortopts[i] != ':':
            return shortopts.startswith(':', i+1)
    raise GetoptError('option -%s not recognized' % opt, opt)

if __name__ == '__main__':
    import sys
    print(getopt(sys.argv[1:], "a:b", ["alpha=", "beta"]))

########NEW FILE########
__FILENAME__ = glob
"""Filename globbing utility."""

import os
import re
import fnmatch

from typing import List, Iterator, Iterable, Any, AnyStr

__all__ = ["glob", "iglob"]

def glob(pathname: AnyStr) -> List[AnyStr]:
    """Return a list of paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la fnmatch.

    """
    return list(iglob(pathname))

def iglob(pathname: AnyStr) -> Iterator[AnyStr]:
    """Return an iterator which yields the paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la fnmatch.

    """
    if not has_magic(pathname):
        if os.path.lexists(pathname):
            yield pathname
        return
    dirname, basename = os.path.split(pathname)
    if not dirname:
        for name in glob1(None, basename):
            yield name
        return
    if has_magic(dirname):
        dirs = iglob(dirname) # type: Iterable[AnyStr]
    else:
        dirs = [dirname]
    if has_magic(basename):
        glob_in_dir = glob1 # type: Any
    else:
        glob_in_dir = glob0
    for dirname in dirs:
        for name in glob_in_dir(dirname, basename):
            yield os.path.join(dirname, name)

# These 2 helper functions non-recursively glob inside a literal directory.
# They return a list of basenames. `glob1` accepts a pattern while `glob0`
# takes a literal basename (so it only has to check for its existence).

def glob1(dirname: AnyStr, pattern: AnyStr) -> List[AnyStr]:
    if not dirname:
        if isinstance(pattern, bytes):
            dirname = bytes(os.curdir, 'ASCII')
        else:
            dirname = os.curdir
    try:
        names = os.listdir(dirname)
    except os.error:
        return []
    if pattern[0] != '.':
        names = [x for x in names if x[0] != '.']
    return fnmatch.filter(names, pattern)

def glob0(dirname: AnyStr, basename: AnyStr) -> List[AnyStr]:
    if basename == '':
        # `os.path.split()` returns an empty basename for paths ending with a
        # directory separator.  'q*x/' should match only directories.
        if os.path.isdir(dirname):
            return [basename]
    else:
        if os.path.lexists(os.path.join(dirname, basename)):
            return [basename]
    return []


magic_check = re.compile('[*?[]')
magic_check_bytes = re.compile(b'[*?[]')

def has_magic(s: AnyStr) -> bool:
    if isinstance(s, bytes):
        match = magic_check_bytes.search(s)
    else:
        match = magic_check.search(s)
    return match is not None

########NEW FILE########
__FILENAME__ = parse
"""Parse (absolute and relative) URLs.

urlparse module is based upon the following RFC specifications.

RFC 3986 (STD66): "Uniform Resource Identifiers" by T. Berners-Lee, R. Fielding
and L.  Masinter, January 2005.

RFC 2732 : "Format for Literal IPv6 Addresses in URLs" by R.Hinden, B.Carpenter
and L.Masinter, December 1999.

RFC 2396:  "Uniform Resource Identifiers (URI)": Generic Syntax by T.
Berners-Lee, R. Fielding, and L. Masinter, August 1998.

RFC 2368: "The mailto URL scheme", by P.Hoffman , L Masinter, J. Zawinski, July 1998.

RFC 1808: "Relative Uniform Resource Locators", by R. Fielding, UC Irvine, June
1995.

RFC 1738: "Uniform Resource Locators (URL)" by T. Berners-Lee, L. Masinter, M.
McCahill, December 1994

RFC 3986 is considered the current standard and any future changes to
urlparse module should conform with it.  The urlparse module is
currently not entirely compliant with this RFC due to defacto
scenarios for parsing, and for backward compatibility purposes, some
parsing quirks from older RFCs are retained. The testcases in
test_urlparse.py provides a good indicator of parsing behavior.
"""

import sys
import collections

__all__ = ["urlparse", "urlunparse", "urljoin", "urldefrag",
           "urlsplit", "urlunsplit", "urlencode", "parse_qs",
           "parse_qsl", "quote", "quote_plus", "quote_from_bytes",
           "unquote", "unquote_plus", "unquote_to_bytes"]

# A classification of schemes ('' means apply by default)
uses_relative = ['ftp', 'http', 'gopher', 'nntp', 'imap',
                 'wais', 'file', 'https', 'shttp', 'mms',
                 'prospero', 'rtsp', 'rtspu', '', 'sftp',
                 'svn', 'svn+ssh']
uses_netloc = ['ftp', 'http', 'gopher', 'nntp', 'telnet',
               'imap', 'wais', 'file', 'mms', 'https', 'shttp',
               'snews', 'prospero', 'rtsp', 'rtspu', 'rsync', '',
               'svn', 'svn+ssh', 'sftp', 'nfs', 'git', 'git+ssh']
non_hierarchical = ['gopher', 'hdl', 'mailto', 'news',
                    'telnet', 'wais', 'imap', 'snews', 'sip', 'sips']
uses_params = ['ftp', 'hdl', 'prospero', 'http', 'imap',
               'https', 'shttp', 'rtsp', 'rtspu', 'sip', 'sips',
               'mms', '', 'sftp']
uses_query = ['http', 'wais', 'imap', 'https', 'shttp', 'mms',
              'gopher', 'rtsp', 'rtspu', 'sip', 'sips', '']
uses_fragment = ['ftp', 'hdl', 'http', 'gopher', 'news',
                 'nntp', 'wais', 'https', 'shttp', 'snews',
                 'file', 'prospero', '']

# Characters valid in scheme names
scheme_chars = ('abcdefghijklmnopqrstuvwxyz'
                'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
                '0123456789'
                '+-.')

# XXX: Consider replacing with functools.lru_cache
MAX_CACHE_SIZE = 20
_parse_cache = {}

def clear_cache():
    """Clear the parse cache and the quoters cache."""
    _parse_cache.clear()
    _safe_quoters.clear()


# Helpers for bytes handling
# For 3.2, we deliberately require applications that
# handle improperly quoted URLs to do their own
# decoding and encoding. If valid use cases are
# presented, we may relax this by using latin-1
# decoding internally for 3.3
_implicit_encoding = 'ascii'
_implicit_errors = 'strict'

def _noop(obj):
    return obj

def _encode_result(obj, encoding=_implicit_encoding,
                        errors=_implicit_errors):
    return obj.encode(encoding, errors)

def _decode_args(args, encoding=_implicit_encoding,
                       errors=_implicit_errors):
    return tuple(x.decode(encoding, errors) if x else '' for x in args)

def _coerce_args(*args):
    # Invokes decode if necessary to create str args
    # and returns the coerced inputs along with
    # an appropriate result coercion function
    #   - noop for str inputs
    #   - encoding function otherwise
    str_input = isinstance(args[0], str)
    for arg in args[1:]:
        # We special-case the empty string to support the
        # "scheme=''" default argument to some functions
        if arg and isinstance(arg, str) != str_input:
            raise TypeError("Cannot mix str and non-str arguments")
    if str_input:
        return args + (_noop,)
    return _decode_args(args) + (_encode_result,)

# Result objects are more helpful than simple tuples
class _ResultMixinStr(object):
    """Standard approach to encoding parsed results from str to bytes"""
    __slots__ = ()

    def encode(self, encoding='ascii', errors='strict'):
        return self._encoded_counterpart(*(x.encode(encoding, errors) for x in self))


class _ResultMixinBytes(object):
    """Standard approach to decoding parsed results from bytes to str"""
    __slots__ = ()

    def decode(self, encoding='ascii', errors='strict'):
        return self._decoded_counterpart(*(x.decode(encoding, errors) for x in self))


class _NetlocResultMixinBase(object):
    """Shared methods for the parsed result objects containing a netloc element"""
    __slots__ = ()

    @property
    def username(self):
        return self._userinfo[0]

    @property
    def password(self):
        return self._userinfo[1]

    @property
    def hostname(self):
        hostname = self._hostinfo[0]
        if not hostname:
            hostname = None
        elif hostname is not None:
            hostname = hostname.lower()
        return hostname

    @property
    def port(self):
        port = self._hostinfo[1]
        if port is not None:
            port = int(port, 10)
        return port


class _NetlocResultMixinStr(_NetlocResultMixinBase, _ResultMixinStr):
    __slots__ = ()

    @property
    def _userinfo(self):
        netloc = self.netloc
        userinfo, have_info, hostinfo = netloc.rpartition('@')
        if have_info:
            username, have_password, password = userinfo.partition(':')
            if not have_password:
                password = None
        else:
            username = password = None
        return username, password

    @property
    def _hostinfo(self):
        netloc = self.netloc
        _, _, hostinfo = netloc.rpartition('@')
        _, have_open_br, bracketed = hostinfo.partition('[')
        if have_open_br:
            hostname, _, port = bracketed.partition(']')
            _, have_port, port = port.partition(':')
        else:
            hostname, have_port, port = hostinfo.partition(':')
        if not have_port:
            port = None
        return hostname, port


class _NetlocResultMixinBytes(_NetlocResultMixinBase, _ResultMixinBytes):
    __slots__ = ()

    @property
    def _userinfo(self):
        netloc = self.netloc
        userinfo, have_info, hostinfo = netloc.rpartition(b'@')
        if have_info:
            username, have_password, password = userinfo.partition(b':')
            if not have_password:
                password = None
        else:
            username = password = None
        return username, password

    @property
    def _hostinfo(self):
        netloc = self.netloc
        _, _, hostinfo = netloc.rpartition(b'@')
        _, have_open_br, bracketed = hostinfo.partition(b'[')
        if have_open_br:
            hostname, _, port = bracketed.partition(b']')
            _, have_port, port = port.partition(b':')
        else:
            hostname, have_port, port = hostinfo.partition(b':')
        if not have_port:
            port = None
        return hostname, port


from collections import namedtuple

_DefragResultBase = namedtuple('DefragResult', 'url fragment')
_SplitResultBase = namedtuple('SplitResult', 'scheme netloc path query fragment')
_ParseResultBase = namedtuple('ParseResult', 'scheme netloc path params query fragment')

# For backwards compatibility, alias _NetlocResultMixinStr
# ResultBase is no longer part of the documented API, but it is
# retained since deprecating it isn't worth the hassle
ResultBase = _NetlocResultMixinStr

# Structured result objects for string data
class DefragResult(_DefragResultBase, _ResultMixinStr):
    __slots__ = ()
    def geturl(self):
        if self.fragment:
            return self.url + '#' + self.fragment
        else:
            return self.url

class SplitResult(_SplitResultBase, _NetlocResultMixinStr):
    __slots__ = ()
    def geturl(self):
        return urlunsplit(self)

class ParseResult(_ParseResultBase, _NetlocResultMixinStr):
    __slots__ = ()
    def geturl(self):
        return urlunparse(self)

# Structured result objects for bytes data
class DefragResultBytes(_DefragResultBase, _ResultMixinBytes):
    __slots__ = ()
    def geturl(self):
        if self.fragment:
            return self.url + b'#' + self.fragment
        else:
            return self.url

class SplitResultBytes(_SplitResultBase, _NetlocResultMixinBytes):
    __slots__ = ()
    def geturl(self):
        return urlunsplit(self)

class ParseResultBytes(_ParseResultBase, _NetlocResultMixinBytes):
    __slots__ = ()
    def geturl(self):
        return urlunparse(self)

# Set up the encode/decode result pairs
def _fix_result_transcoding():
    _result_pairs = (
        (DefragResult, DefragResultBytes),
        (SplitResult, SplitResultBytes),
        (ParseResult, ParseResultBytes),
    )
    for _decoded, _encoded in _result_pairs:
        _decoded._encoded_counterpart = _encoded
        _encoded._decoded_counterpart = _decoded

_fix_result_transcoding()
del _fix_result_transcoding

def urlparse(url, scheme='', allow_fragments=True):
    """Parse a URL into 6 components:
    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>
    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).
    Note that we don't break the components up in smaller bits
    (e.g. netloc is a single string) and we don't expand % escapes."""
    url, scheme, _coerce_result = _coerce_args(url, scheme)
    tuple = urlsplit(url, scheme, allow_fragments)
    scheme, netloc, url, query, fragment = tuple
    if scheme in uses_params and ';' in url:
        url, params = _splitparams(url)
    else:
        params = ''
    result = ParseResult(scheme, netloc, url, params, query, fragment)
    return _coerce_result(result)

def _splitparams(url):
    if '/'  in url:
        i = url.find(';', url.rfind('/'))
        if i < 0:
            return url, ''
    else:
        i = url.find(';')
    return url[:i], url[i+1:]

def _splitnetloc(url, start=0):
    delim = len(url)   # position of end of domain part of url, default is end
    for c in '/?#':    # look for delimiters; the order is NOT important
        wdelim = url.find(c, start)        # find first of this delim
        if wdelim >= 0:                    # if found
            delim = min(delim, wdelim)     # use earliest delim position
    return url[start:delim], url[delim:]   # return (domain, rest)

def urlsplit(url, scheme='', allow_fragments=True):
    """Parse a URL into 5 components:
    <scheme>://<netloc>/<path>?<query>#<fragment>
    Return a 5-tuple: (scheme, netloc, path, query, fragment).
    Note that we don't break the components up in smaller bits
    (e.g. netloc is a single string) and we don't expand % escapes."""
    url, scheme, _coerce_result = _coerce_args(url, scheme)
    allow_fragments = bool(allow_fragments)
    key = url, scheme, allow_fragments, type(url), type(scheme)
    cached = _parse_cache.get(key, None)
    if cached:
        return _coerce_result(cached)
    if len(_parse_cache) >= MAX_CACHE_SIZE: # avoid runaway growth
        clear_cache()
    netloc = query = fragment = ''
    i = url.find(':')
    if i > 0:
        if url[:i] == 'http': # optimize the common case
            scheme = url[:i].lower()
            url = url[i+1:]
            if url[:2] == '//':
                netloc, url = _splitnetloc(url, 2)
                if (('[' in netloc and ']' not in netloc) or
                        (']' in netloc and '[' not in netloc)):
                    raise ValueError("Invalid IPv6 URL")
            if allow_fragments and '#' in url:
                url, fragment = url.split('#', 1)
            if '?' in url:
                url, query = url.split('?', 1)
            v = SplitResult(scheme, netloc, url, query, fragment)
            _parse_cache[key] = v
            return _coerce_result(v)
        for c in url[:i]:
            if c not in scheme_chars:
                break
        else:
            try:
                # make sure "url" is not actually a port number (in which case
                # "scheme" is really part of the path
                _testportnum = int(url[i+1:])
            except ValueError:
                scheme, url = url[:i].lower(), url[i+1:]

    if url[:2] == '//':
        netloc, url = _splitnetloc(url, 2)
        if (('[' in netloc and ']' not in netloc) or
                (']' in netloc and '[' not in netloc)):
            raise ValueError("Invalid IPv6 URL")
    if allow_fragments and scheme in uses_fragment and '#' in url:
        url, fragment = url.split('#', 1)
    if scheme in uses_query and '?' in url:
        url, query = url.split('?', 1)
    v = SplitResult(scheme, netloc, url, query, fragment)
    _parse_cache[key] = v
    return _coerce_result(v)

def urlunparse(components):
    """Put a parsed URL back together again.  This may result in a
    slightly different, but equivalent URL, if the URL that was parsed
    originally had redundant delimiters, e.g. a ? with an empty query
    (the draft states that these are equivalent)."""
    scheme, netloc, url, params, query, fragment, _coerce_result = (
                                                  _coerce_args(*components))
    if params:
        url = "%s;%s" % (url, params)
    return _coerce_result(urlunsplit((scheme, netloc, url, query, fragment)))

def urlunsplit(components):
    """Combine the elements of a tuple as returned by urlsplit() into a
    complete URL as a string. The data argument can be any five-item iterable.
    This may result in a slightly different, but equivalent URL, if the URL that
    was parsed originally had unnecessary delimiters (for example, a ? with an
    empty query; the RFC states that these are equivalent)."""
    scheme, netloc, url, query, fragment, _coerce_result = (
                                          _coerce_args(*components))
    if netloc or (scheme and scheme in uses_netloc and url[:2] != '//'):
        if url and url[:1] != '/': url = '/' + url
        url = '//' + (netloc or '') + url
    if scheme:
        url = scheme + ':' + url
    if query:
        url = url + '?' + query
    if fragment:
        url = url + '#' + fragment
    return _coerce_result(url)

def urljoin(base, url, allow_fragments=True):
    """Join a base URL and a possibly relative URL to form an absolute
    interpretation of the latter."""
    if not base:
        return url
    if not url:
        return base
    base, url, _coerce_result = _coerce_args(base, url)
    bscheme, bnetloc, bpath, bparams, bquery, bfragment = \
            urlparse(base, '', allow_fragments)
    scheme, netloc, path, params, query, fragment = \
            urlparse(url, bscheme, allow_fragments)
    if scheme != bscheme or scheme not in uses_relative:
        return _coerce_result(url)
    if scheme in uses_netloc:
        if netloc:
            return _coerce_result(urlunparse((scheme, netloc, path,
                                              params, query, fragment)))
        netloc = bnetloc
    if path[:1] == '/':
        return _coerce_result(urlunparse((scheme, netloc, path,
                                          params, query, fragment)))
    if not path and not params:
        path = bpath
        params = bparams
        if not query:
            query = bquery
        return _coerce_result(urlunparse((scheme, netloc, path,
                                          params, query, fragment)))
    segments = bpath.split('/')[:-1] + path.split('/')
    # XXX The stuff below is bogus in various ways...
    if segments[-1] == '.':
        segments[-1] = ''
    while '.' in segments:
        segments.remove('.')
    while 1:
        i = 1
        n = len(segments) - 1
        while i < n:
            if (segments[i] == '..'
                and segments[i-1] not in ('', '..')):
                del segments[i-1:i+1]
                break
            i = i+1
        else:
            break
    if segments == ['', '..']:
        segments[-1] = ''
    elif len(segments) >= 2 and segments[-1] == '..':
        segments[-2:] = ['']
    return _coerce_result(urlunparse((scheme, netloc, '/'.join(segments),
                                      params, query, fragment)))

def urldefrag(url):
    """Removes any existing fragment from URL.

    Returns a tuple of the defragmented URL and the fragment.  If
    the URL contained no fragments, the second element is the
    empty string.
    """
    url, _coerce_result = _coerce_args(url)
    if '#' in url:
        s, n, p, a, q, frag = urlparse(url)
        defrag = urlunparse((s, n, p, a, q, ''))
    else:
        frag = ''
        defrag = url
    return _coerce_result(DefragResult(defrag, frag))

def unquote_to_bytes(string):
    """unquote_to_bytes('abc%20def') -> b'abc def'."""
    # Note: strings are encoded as UTF-8. This is only an issue if it contains
    # unescaped non-ASCII characters, which URIs should not.
    if not string:
        # Is it a string-like object?
        string.split
        return b''
    if isinstance(string, str):
        string = string.encode('utf-8')
    res = string.split(b'%')
    if len(res) == 1:
        return string
    string = res[0]
    for item in res[1:]:
        try:
            string += bytes([int(item[:2], 16)]) + item[2:]
        except ValueError:
            string += b'%' + item
    return string

def unquote(string, encoding='utf-8', errors='replace'):
    """Replace %xx escapes by their single-character equivalent. The optional
    encoding and errors parameters specify how to decode percent-encoded
    sequences into Unicode characters, as accepted by the bytes.decode()
    method.
    By default, percent-encoded sequences are decoded with UTF-8, and invalid
    sequences are replaced by a placeholder character.

    unquote('abc%20def') -> 'abc def'.
    """
    if string == '':
        return string
    res = string.split('%')
    if len(res) == 1:
        return string
    if encoding is None:
        encoding = 'utf-8'
    if errors is None:
        errors = 'replace'
    # pct_sequence: contiguous sequence of percent-encoded bytes, decoded
    pct_sequence = b''
    string = res[0]
    for item in res[1:]:
        try:
            if not item:
                raise ValueError
            pct_sequence += bytes.fromhex(item[:2])
            rest = item[2:]
            if not rest:
                # This segment was just a single percent-encoded character.
                # May be part of a sequence of code units, so delay decoding.
                # (Stored in pct_sequence).
                continue
        except ValueError:
            rest = '%' + item
        # Encountered non-percent-encoded characters. Flush the current
        # pct_sequence.
        string += pct_sequence.decode(encoding, errors) + rest
        pct_sequence = b''
    if pct_sequence:
        # Flush the final pct_sequence
        string += pct_sequence.decode(encoding, errors)
    return string

def parse_qs(qs, keep_blank_values=False, strict_parsing=False,
             encoding='utf-8', errors='replace'):
    """Parse a query given as a string argument.

        Arguments:

        qs: percent-encoded query string to be parsed

        keep_blank_values: flag indicating whether blank values in
            percent-encoded queries should be treated as blank strings.
            A true value indicates that blanks should be retained as
            blank strings.  The default false value indicates that
            blank values are to be ignored and treated as if they were
            not included.

        strict_parsing: flag indicating what to do with parsing errors.
            If false (the default), errors are silently ignored.
            If true, errors raise a ValueError exception.

        encoding and errors: specify how to decode percent-encoded sequences
            into Unicode characters, as accepted by the bytes.decode() method.
    """
    dict = {}
    pairs = parse_qsl(qs, keep_blank_values, strict_parsing,
                      encoding=encoding, errors=errors)
    for name, value in pairs:
        if name in dict:
            dict[name].append(value)
        else:
            dict[name] = [value]
    return dict

def parse_qsl(qs, keep_blank_values=False, strict_parsing=False,
              encoding='utf-8', errors='replace'):
    """Parse a query given as a string argument.

    Arguments:

    qs: percent-encoded query string to be parsed

    keep_blank_values: flag indicating whether blank values in
        percent-encoded queries should be treated as blank strings.  A
        true value indicates that blanks should be retained as blank
        strings.  The default false value indicates that blank values
        are to be ignored and treated as if they were  not included.

    strict_parsing: flag indicating what to do with parsing errors. If
        false (the default), errors are silently ignored. If true,
        errors raise a ValueError exception.

    encoding and errors: specify how to decode percent-encoded sequences
        into Unicode characters, as accepted by the bytes.decode() method.

    Returns a list, as G-d intended.
    """
    qs, _coerce_result = _coerce_args(qs)
    pairs = []
    for s1 in qs.split('&'):
        for s2 in s1.split(';'):
            pairs.append(s2)
    r = []
    for name_value in pairs:
        if not name_value and not strict_parsing:
            continue
        nv = name_value.split('=', 1)
        if len(nv) != 2:
            if strict_parsing:
                raise ValueError("bad query field: %r" % (name_value,))
            # Handle case of a control-name with no equal sign
            if keep_blank_values:
                nv.append('')
            else:
                continue
        if len(nv[1]) or keep_blank_values:
            name = nv[0].replace('+', ' ')
            name = unquote(name, encoding=encoding, errors=errors)
            name = _coerce_result(name)
            value = nv[1].replace('+', ' ')
            value = unquote(value, encoding=encoding, errors=errors)
            value = _coerce_result(value)
            r.append((name, value))
    return r

def unquote_plus(string, encoding='utf-8', errors='replace'):
    """Like unquote(), but also replace plus signs by spaces, as required for
    unquoting HTML form values.

    unquote_plus('%7e/abc+def') -> '~/abc def'
    """
    string = string.replace('+', ' ')
    return unquote(string, encoding, errors)

_ALWAYS_SAFE = frozenset(b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
                         b'abcdefghijklmnopqrstuvwxyz'
                         b'0123456789'
                         b'_.-')
_ALWAYS_SAFE_BYTES = bytes(_ALWAYS_SAFE)
_safe_quoters = {}

class Quoter(collections.defaultdict):
    """A mapping from bytes (in range(0,256)) to strings.

    String values are percent-encoded byte values, unless the key < 128, and
    in the "safe" set (either the specified safe set, or default set).
    """
    # Keeps a cache internally, using defaultdict, for efficiency (lookups
    # of cached keys don't call Python code at all).
    def __init__(self, safe):
        """safe: bytes object."""
        self.safe = _ALWAYS_SAFE.union(safe)

    def __repr__(self):
        # Without this, will just display as a defaultdict
        return "<Quoter %r>" % dict(self)

    def __missing__(self, b):
        # Handle a cache miss. Store quoted string in cache and return.
        res = chr(b) if b in self.safe else '%{:02X}'.format(b)
        self[b] = res
        return res

def quote(string, safe='/', encoding=None, errors=None):
    """quote('abc def') -> 'abc%20def'

    Each part of a URL, e.g. the path info, the query, etc., has a
    different set of reserved characters that must be quoted.

    RFC 2396 Uniform Resource Identifiers (URI): Generic Syntax lists
    the following reserved characters.

    reserved    = ";" | "/" | "?" | ":" | "@" | "&" | "=" | "+" |
                  "$" | ","

    Each of these characters is reserved in some component of a URL,
    but not necessarily in all of them.

    By default, the quote function is intended for quoting the path
    section of a URL.  Thus, it will not encode '/'.  This character
    is reserved, but in typical usage the quote function is being
    called on a path where the existing slash characters are used as
    reserved characters.

    string and safe may be either str or bytes objects. encoding must
    not be specified if string is a str.

    The optional encoding and errors parameters specify how to deal with
    non-ASCII characters, as accepted by the str.encode method.
    By default, encoding='utf-8' (characters are encoded with UTF-8), and
    errors='strict' (unsupported characters raise a UnicodeEncodeError).
    """
    if isinstance(string, str):
        if not string:
            return string
        if encoding is None:
            encoding = 'utf-8'
        if errors is None:
            errors = 'strict'
        string = string.encode(encoding, errors)
    else:
        if encoding is not None:
            raise TypeError("quote() doesn't support 'encoding' for bytes")
        if errors is not None:
            raise TypeError("quote() doesn't support 'errors' for bytes")
    return quote_from_bytes(string, safe)

def quote_plus(string, safe='', encoding=None, errors=None):
    """Like quote(), but also replace ' ' with '+', as required for quoting
    HTML form values. Plus signs in the original string are escaped unless
    they are included in safe. It also does not have safe default to '/'.
    """
    # Check if ' ' in string, where string may either be a str or bytes.  If
    # there are no spaces, the regular quote will produce the right answer.
    if ((isinstance(string, str) and ' ' not in string) or
        (isinstance(string, bytes) and b' ' not in string)):
        return quote(string, safe, encoding, errors)
    if isinstance(safe, str):
        space = ' '
    else:
        space = b' '
    string = quote(string, safe + space, encoding, errors)
    return string.replace(' ', '+')

def quote_from_bytes(bs, safe='/'):
    """Like quote(), but accepts a bytes object rather than a str, and does
    not perform string-to-bytes encoding.  It always returns an ASCII string.
    quote_from_bytes(b'abc def\xab') -> 'abc%20def%AB'
    """
    if not isinstance(bs, (bytes, bytearray)):
        raise TypeError("quote_from_bytes() expected bytes")
    if not bs:
        return ''
    if isinstance(safe, str):
        # Normalize 'safe' by converting to bytes and removing non-ASCII chars
        safe = safe.encode('ascii', 'ignore')
    else:
        safe = bytes([c for c in safe if c < 128])
    if not bs.rstrip(_ALWAYS_SAFE_BYTES + safe):
        return bs.decode()
    try:
        quoter = _safe_quoters[safe]
    except KeyError:
        _safe_quoters[safe] = quoter = Quoter(safe).__getitem__
    return ''.join([quoter(char) for char in bs])

def urlencode(query, doseq=False, safe='', encoding=None, errors=None):
    """Encode a sequence of two-element tuples or dictionary into a URL query string.

    If any values in the query arg are sequences and doseq is true, each
    sequence element is converted to a separate parameter.

    If the query arg is a sequence of two-element tuples, the order of the
    parameters in the output will match the order of parameters in the
    input.

    The query arg may be either a string or a bytes type. When query arg is a
    string, the safe, encoding and error parameters are sent the quote_plus for
    encoding.
    """

    if hasattr(query, "items"):
        query = query.items()
    else:
        # It's a bother at times that strings and string-like objects are
        # sequences.
        try:
            # non-sequence items should not work with len()
            # non-empty strings will fail this
            if len(query) and not isinstance(query[0], tuple):
                raise TypeError
            # Zero-length sequences of all types will get here and succeed,
            # but that's a minor nit.  Since the original implementation
            # allowed empty dicts that type of behavior probably should be
            # preserved for consistency
        except TypeError:
            ty, va, tb = sys.exc_info()
            raise TypeError("not a valid non-string sequence "
                            "or mapping object").with_traceback(tb)

    l = []
    if not doseq:
        for k, v in query:
            if isinstance(k, bytes):
                k = quote_plus(k, safe)
            else:
                k = quote_plus(str(k), safe, encoding, errors)

            if isinstance(v, bytes):
                v = quote_plus(v, safe)
            else:
                v = quote_plus(str(v), safe, encoding, errors)
            l.append(k + '=' + v)
    else:
        for k, v in query:
            if isinstance(k, bytes):
                k = quote_plus(k, safe)
            else:
                k = quote_plus(str(k), safe, encoding, errors)

            if isinstance(v, bytes):
                v = quote_plus(v, safe)
                l.append(k + '=' + v)
            elif isinstance(v, str):
                v = quote_plus(v, safe, encoding, errors)
                l.append(k + '=' + v)
            else:
                try:
                    # Is this a sufficient test for sequence-ness?
                    x = len(v)
                except TypeError:
                    # not a sequence
                    v = quote_plus(str(v), safe, encoding, errors)
                    l.append(k + '=' + v)
                else:
                    # loop over the sequence
                    for elt in v:
                        if isinstance(elt, bytes):
                            elt = quote_plus(elt, safe)
                        else:
                            elt = quote_plus(str(elt), safe, encoding, errors)
                        l.append(k + '=' + elt)
    return '&'.join(l)

# Utilities to parse URLs (most of these return None for missing parts):
# unwrap('<URL:type://host/path>') --> 'type://host/path'
# splittype('type:opaquestring') --> 'type', 'opaquestring'
# splithost('//host[:port]/path') --> 'host[:port]', '/path'
# splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'
# splitpasswd('user:passwd') -> 'user', 'passwd'
# splitport('host:port') --> 'host', 'port'
# splitquery('/path?query') --> '/path', 'query'
# splittag('/path#tag') --> '/path', 'tag'
# splitattr('/path;attr1=value1;attr2=value2;...') ->
#   '/path', ['attr1=value1', 'attr2=value2', ...]
# splitvalue('attr=value') --> 'attr', 'value'
# urllib.parse.unquote('abc%20def') -> 'abc def'
# quote('abc def') -> 'abc%20def')

def to_bytes(url):
    """to_bytes(u"URL") --> 'URL'."""
    # Most URL schemes require ASCII. If that changes, the conversion
    # can be relaxed.
    # XXX get rid of to_bytes()
    if isinstance(url, str):
        try:
            url = url.encode("ASCII").decode()
        except UnicodeError:
            raise UnicodeError("URL " + repr(url) +
                               " contains non-ASCII characters")
    return url

def unwrap(url):
    """unwrap('<URL:type://host/path>') --> 'type://host/path'."""
    url = str(url).strip()
    if url[:1] == '<' and url[-1:] == '>':
        url = url[1:-1].strip()
    if url[:4] == 'URL:': url = url[4:].strip()
    return url

_typeprog = None
def splittype(url):
    """splittype('type:opaquestring') --> 'type', 'opaquestring'."""
    global _typeprog
    if _typeprog is None:
        import re
        _typeprog = re.compile('^([^/:]+):')

    match = _typeprog.match(url)
    if match:
        scheme = match.group(1)
        return scheme.lower(), url[len(scheme) + 1:]
    return None, url

_hostprog = None
def splithost(url):
    """splithost('//host[:port]/path') --> 'host[:port]', '/path'."""
    global _hostprog
    if _hostprog is None:
        import re
        _hostprog = re.compile('^//([^/?]*)(.*)$')

    match = _hostprog.match(url)
    if match:
        host_port = match.group(1)
        path = match.group(2)
        if path and not path.startswith('/'):
            path = '/' + path
        return host_port, path
    return None, url

_userprog = None
def splituser(host):
    """splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'."""
    global _userprog
    if _userprog is None:
        import re
        _userprog = re.compile('^(.*)@(.*)$')

    match = _userprog.match(host)
    if match: return match.group(1, 2)
    return None, host

_passwdprog = None
def splitpasswd(user):
    """splitpasswd('user:passwd') -> 'user', 'passwd'."""
    global _passwdprog
    if _passwdprog is None:
        import re
        _passwdprog = re.compile('^([^:]*):(.*)$',re.S)

    match = _passwdprog.match(user)
    if match: return match.group(1, 2)
    return user, None

# splittag('/path#tag') --> '/path', 'tag'
_portprog = None
def splitport(host):
    """splitport('host:port') --> 'host', 'port'."""
    global _portprog
    if _portprog is None:
        import re
        _portprog = re.compile('^(.*):([0-9]+)$')

    match = _portprog.match(host)
    if match: return match.group(1, 2)
    return host, None

_nportprog = None
def splitnport(host, defport=-1):
    """Split host and port, returning numeric port.
    Return given default port if no ':' found; defaults to -1.
    Return numerical port if a valid number are found after ':'.
    Return None if ':' but not a valid number."""
    global _nportprog
    if _nportprog is None:
        import re
        _nportprog = re.compile('^(.*):(.*)$')

    match = _nportprog.match(host)
    if match:
        host, port = match.group(1, 2)
        try:
            if not port: raise ValueError("no digits")
            nport = int(port)
        except ValueError:
            nport = None
        return host, nport
    return host, defport

_queryprog = None
def splitquery(url):
    """splitquery('/path?query') --> '/path', 'query'."""
    global _queryprog
    if _queryprog is None:
        import re
        _queryprog = re.compile('^(.*)\?([^?]*)$')

    match = _queryprog.match(url)
    if match: return match.group(1, 2)
    return url, None

_tagprog = None
def splittag(url):
    """splittag('/path#tag') --> '/path', 'tag'."""
    global _tagprog
    if _tagprog is None:
        import re
        _tagprog = re.compile('^(.*)#([^#]*)$')

    match = _tagprog.match(url)
    if match: return match.group(1, 2)
    return url, None

def splitattr(url):
    """splitattr('/path;attr1=value1;attr2=value2;...') ->
        '/path', ['attr1=value1', 'attr2=value2', ...]."""
    words = url.split(';')
    return words[0], words[1:]

_valueprog = None
def splitvalue(attr):
    """splitvalue('attr=value') --> 'attr', 'value'."""
    global _valueprog
    if _valueprog is None:
        import re
        _valueprog = re.compile('^([^=]*)=(.*)$')

    match = _valueprog.match(attr)
    if match: return match.group(1, 2)
    return attr, None

########NEW FILE########
__FILENAME__ = posixpath
"""Common operations on Posix pathnames.

Instead of importing this module directly, import os and refer to
this module as os.path.  The "os.path" name is an alias for this
module on Posix systems; on other systems (e.g. Mac, Windows),
os.path provides the same operations in a manner specific to that
platform, and is an alias to another module (e.g. macpath, ntpath).

Some of this can actually be useful on non-Posix systems too, e.g.
for manipulation of the pathname component of URLs.
"""

import os
import sys
import stat
import genericpath
from genericpath import *

from typing import (
    Tuple, BinaryIO, TextIO, Pattern, AnyStr, List, Set, Any
)

__all__ = ["normcase","isabs","join","splitdrive","split","splitext",
           "basename","dirname","commonprefix","getsize","getmtime",
           "getatime","getctime","islink","exists","lexists","isdir","isfile",
           "ismount", "expanduser","expandvars","normpath","abspath",
           "samefile","sameopenfile","samestat",
           "curdir","pardir","sep","pathsep","defpath","altsep","extsep",
           "devnull","realpath","supports_unicode_filenames","relpath"]

# Strings representing various path-related bits and pieces.
# These are primarily for export; internally, they are hardcoded.
curdir = '.'
pardir = '..'
extsep = '.'
sep = '/'
pathsep = ':'
defpath = ':/bin:/usr/bin'
altsep = None # type: str
devnull = '/dev/null'

def _get_sep(path: AnyStr) -> AnyStr:
    if isinstance(path, bytes):
        return b'/'
    else:
        return '/'

# Normalize the case of a pathname.  Trivial in Posix, string.lower on Mac.
# On MS-DOS this may also turn slashes into backslashes; however, other
# normalizations (such as optimizing '../' away) are not allowed
# (another function should be defined to do that).

def normcase(s: AnyStr) -> AnyStr:
    """Normalize case of pathname.  Has no effect under Posix"""
    # TODO: on Mac OS X, this should really return s.lower().
    if not isinstance(s, (bytes, str)):
        raise TypeError("normcase() argument must be str or bytes, "
                        "not '{}'".format(s.__class__.__name__))
    return s


# Return whether a path is absolute.
# Trivial in Posix, harder on the Mac or MS-DOS.

def isabs(s: AnyStr) -> bool:
    """Test whether a path is absolute"""
    sep = _get_sep(s)
    return s.startswith(sep)


# Join pathnames.
# Ignore the previous parts if a part is absolute.
# Insert a '/' unless the first part is empty or already ends in '/'.

def join(a: AnyStr, *p: AnyStr) -> AnyStr:
    """Join two or more pathname components, inserting '/' as needed.
    If any component is an absolute path, all previous path components
    will be discarded."""
    sep = _get_sep(a)
    path = a
    for b in p:
        if b.startswith(sep):
            path = b
        elif not path or path.endswith(sep):
            path +=  b
        else:
            path += sep + b
    return path


# Split a path in head (everything up to the last '/') and tail (the
# rest).  If the path ends in '/', tail will be empty.  If there is no
# '/' in the path, head  will be empty.
# Trailing '/'es are stripped from head unless it is the root.

def split(p: AnyStr) -> Tuple[AnyStr, AnyStr]:
    """Split a pathname.  Returns tuple "(head, tail)" where "tail" is
    everything after the final slash.  Either part may be empty."""
    sep = _get_sep(p)
    i = p.rfind(sep) + 1
    head, tail = p[:i], p[i:]
    if head and head != sep*len(head):
        head = head.rstrip(sep)
    return head, tail


# Split a path in root and extension.
# The extension is everything starting at the last dot in the last
# pathname component; the root is everything before that.
# It is always true that root + ext == p.

def splitext(p: AnyStr) -> Tuple[AnyStr, AnyStr]:
    if isinstance(p, bytes):
        sep = b'/'
        extsep = b'.'
    else:
        sep = '/'
        extsep = '.'
    return genericpath._splitext(p, sep, None, extsep)
splitext.__doc__ = genericpath._splitext.__doc__

# Split a pathname into a drive specification and the rest of the
# path.  Useful on DOS/Windows/NT; on Unix, the drive is always empty.

def splitdrive(p: AnyStr) -> Tuple[AnyStr, AnyStr]:
    """Split a pathname into drive and path. On Posix, drive is always
    empty."""
    return p[:0], p


# Return the tail (basename) part of a path, same as split(path)[1].

def basename(p: AnyStr) -> AnyStr:
    """Returns the final component of a pathname"""
    sep = _get_sep(p)
    i = p.rfind(sep) + 1
    return p[i:]


# Return the head (dirname) part of a path, same as split(path)[0].

def dirname(p: AnyStr) -> AnyStr:
    """Returns the directory component of a pathname"""
    sep = _get_sep(p)
    i = p.rfind(sep) + 1
    head = p[:i]
    if head and head != sep*len(head):
        head = head.rstrip(sep)
    return head


# Is a path a symbolic link?
# This will always return false on systems where os.lstat doesn't exist.

def islink(path: AnyStr) -> bool:
    """Test whether a path is a symbolic link"""
    try:
        st = os.lstat(path)
    except (os.error, AttributeError):
        return False
    return stat.S_ISLNK(st.st_mode)

# Being true for dangling symbolic links is also useful.

def lexists(path: AnyStr) -> bool:
    """Test whether a path exists.  Returns True for broken symbolic links"""
    try:
        os.lstat(path)
    except os.error:
        return False
    return True


# Are two filenames really pointing to the same file?

def samefile(f1: AnyStr, f2: AnyStr) -> bool:
    """Test whether two pathnames reference the same actual file"""
    s1 = os.stat(f1)
    s2 = os.stat(f2)
    return samestat(s1, s2)


# Are two open files really referencing the same file?
# (Not necessarily the same file descriptor!)

def sameopenfile(fp1: int, fp2: int) -> bool:
    """Test whether two open file objects reference the same file"""
    s1 = os.fstat(fp1)
    s2 = os.fstat(fp2)
    return samestat(s1, s2)


# Are two stat buffers (obtained from stat, fstat or lstat)
# describing the same file?

def samestat(s1: os.stat_result, s2: os.stat_result) -> bool:
    """Test whether two stat buffers reference the same file"""
    return s1.st_ino == s2.st_ino and \
           s1.st_dev == s2.st_dev


# Is a path a mount point?
# (Does this work for all UNIXes?  Is it even guaranteed to work by Posix?)

def ismount(path: AnyStr) -> bool:
    """Test whether a path is a mount point"""
    if islink(path):
        # A symlink can never be a mount point
        return False
    try:
        s1 = os.lstat(path)
        if isinstance(path, bytes):
            parent = join(path, b'..')
        else:
            parent = join(path, '..')
        s2 = os.lstat(parent)
    except os.error:
        return False # It doesn't exist -- so not a mount point :-)
    dev1 = s1.st_dev
    dev2 = s2.st_dev
    if dev1 != dev2:
        return True     # path/.. on a different device as path
    ino1 = s1.st_ino
    ino2 = s2.st_ino
    if ino1 == ino2:
        return True     # path/.. is the same i-node as path
    return False


# Expand paths beginning with '~' or '~user'.
# '~' means $HOME; '~user' means that user's home directory.
# If the path doesn't begin with '~', or if the user or $HOME is unknown,
# the path is returned unchanged (leaving error reporting to whatever
# function is called with the expanded path as argument).
# See also module 'glob' for expansion of *, ? and [...] in pathnames.
# (A function should also be defined to do full *sh-style environment
# variable expansion.)

def expanduser(path: AnyStr) -> AnyStr:
    """Expand ~ and ~user constructions.  If user or $HOME is unknown,
    do nothing."""
    if isinstance(path, bytes):
        tilde = b'~'
    else:
        tilde = '~'
    if not path.startswith(tilde):
        return path
    sep = _get_sep(path)
    i = path.find(sep, 1)
    if i < 0:
        i = len(path)
    if i == 1:
        if 'HOME' not in os.environ:
            import pwd
            userhome = pwd.getpwuid(os.getuid()).pw_dir
        else:
            userhome = os.environ['HOME']
    else:
        import pwd
        name = path[1:i]
        if isinstance(name, bytes):
            name2 = str(name, 'ASCII')
        else:
            name2 = name
        try:
            pwent = pwd.getpwnam(name2)
        except KeyError:
            return path
        userhome = pwent.pw_dir
    if isinstance(path, bytes):
        userhome2 = os.fsencode(userhome)
        root = b'/'
    else:
        userhome2 = userhome
        root = '/'
    userhome2 = userhome2.rstrip(root) or userhome2
    return userhome2 + path[i:]


# Expand paths containing shell variable substitutions.
# This expands the forms $variable and ${variable} only.
# Non-existent variables are left unchanged.

_varprog = None # type: Pattern[str]
_varprogb = None # type: Pattern[bytes]

def expandvars(path: AnyStr) -> AnyStr:
    """Expand shell variables of form $var and ${var}.  Unknown variables
    are left unchanged."""
    global _varprog, _varprogb
    if isinstance(path, bytes):
        if b'$' not in path:
            return path
        if not _varprogb:
            import re
            _varprogb = re.compile(br'\$(\w+|\{[^}]*\})', re.ASCII)
        search = _varprogb.search
        start = b'{'
        end = b'}'
    else:
        if '$' not in path:
            return path
        if not _varprog:
            import re
            _varprog = re.compile(r'\$(\w+|\{[^}]*\})', re.ASCII)
        search = _varprog.search
        start = '{'
        end = '}'
    i = 0
    while True:
        m = search(path, i)
        if not m:
            break
        i, j = m.span(0)
        name = m.group(1)
        if name.startswith(start) and name.endswith(end):
            name = name[1:-1]
        if isinstance(name, bytes):
            namestr = str(name, 'ASCII')
        else:
            namestr = name
        if namestr in os.environ:
            tail = path[j:]
            valuestr = os.environ[namestr]
            if isinstance(path, bytes):
                value = valuestr.encode('ASCII')
            else:
                value = valuestr
            path = path[:i] + value
            i = len(path)
            path += tail
        else:
            i = j
    return path


# Normalize a path, e.g. A//B, A/./B and A/foo/../B all become A/B.
# It should be understood that this may change the meaning of the path
# if it contains symbolic links!

def normpath(path: AnyStr) -> AnyStr:
    """Normalize path, eliminating double slashes, etc."""
    if isinstance(path, bytes):
        sep = b'/'
        empty = b''
        dot = b'.'
        dotdot = b'..'
    else:
        sep = '/'
        empty = ''
        dot = '.'
        dotdot = '..'
    if path == empty:
        return dot
    initial_slashes = path.startswith(sep) # type: int
    # POSIX allows one or two initial slashes, but treats three or more
    # as single slash.
    if (initial_slashes and
        path.startswith(sep*2) and not path.startswith(sep*3)):
        initial_slashes = 2
    comps = path.split(sep)
    new_comps = List[AnyStr]()
    for comp in comps:
        if comp in (empty, dot):
            continue
        if (comp != dotdot or (not initial_slashes and not new_comps) or
             (new_comps and new_comps[-1] == dotdot)):
            new_comps.append(comp)
        elif new_comps:
            new_comps.pop()
    comps = new_comps
    path = sep.join(comps)
    if initial_slashes:
        path = sep*initial_slashes + path
    return path or dot


def abspath(path: AnyStr) -> AnyStr:
    """Return an absolute path."""
    if not isabs(path):
        if isinstance(path, bytes):
            cwd = os.getcwdb()
        else:
            cwd = os.getcwd()
        path = join(cwd, path)
    return normpath(path)


# Return a canonical path (i.e. the absolute location of a file on the
# filesystem).

def realpath(filename: AnyStr) -> AnyStr:
    """Return the canonical path of the specified filename, eliminating any
symbolic links encountered in the path."""
    if isinstance(filename, bytes):
        sep = b'/'
        empty = b''
    else:
        sep = '/'
        empty = ''
    if isabs(filename):
        bits = [sep] + filename.split(sep)[1:]
    else:
        bits = [empty] + filename.split(sep)

    for i in range(2, len(bits)+1):
        component = join(*bits[0:i])
        # Resolve symbolic links.
        if islink(component):
            resolved = _resolve_link(component)
            if resolved is None:
                # Infinite loop -- return original component + rest of the path
                return abspath(join(*([component] + bits[i:])))
            else:
                newpath = join(*([resolved] + bits[i:]))
                return realpath(newpath)

    return abspath(filename)


def _resolve_link(path: AnyStr) -> AnyStr:
    """Internal helper function.  Takes a path and follows symlinks
    until we either arrive at something that isn't a symlink, or
    encounter a path we've seen before (meaning that there's a loop).
    """
    paths_seen = Set[AnyStr]()
    while islink(path):
        if path in paths_seen:
            # Already seen this path, so we must have a symlink loop
            return None
        paths_seen.add(path)
        # Resolve where the link points to
        resolved = os.readlink(path)
        if not isabs(resolved):
            dir = dirname(path)
            path = normpath(join(dir, resolved))
        else:
            path = normpath(resolved)
    return path

supports_unicode_filenames = (sys.platform == 'darwin')

def relpath(path: AnyStr, start: AnyStr = None) -> AnyStr:
    """Return a relative version of a path"""

    if not path:
        raise ValueError("no path specified")

    if isinstance(path, bytes):
        curdir = b'.'
        sep = b'/'
        pardir = b'..'
    else:
        curdir = '.'
        sep = '/'
        pardir = '..'

    if start is None:
        start = curdir

    start_list = [x for x in abspath(start).split(sep) if x]
    path_list = [x for x in abspath(path).split(sep) if x]

    # Work out how much of the filepath is shared by start and path.
    i = len(commonprefix(Any([start_list, path_list])))

    rel_list = [pardir] * (len(start_list)-i) + path_list[i:]
    if not rel_list:
        return curdir
    return join(*rel_list)

########NEW FILE########
__FILENAME__ = pprint
#  Author:      Fred L. Drake, Jr.
#               fdrake@acm.org
#
#  This is a simple little module I wrote to make life easier.  I didn't
#  see anything quite like it in the library, though I may have overlooked
#  something.  I wrote this when I was trying to read some heavily nested
#  tuples with fairly non-descriptive content.  This is modeled very much
#  after Lisp/Scheme - style pretty-printing of lists.  If you find it
#  useful, thank small children who sleep at night.

"""Support to pretty-print lists, tuples, & dictionaries recursively.

Very simple, but useful, especially in debugging data structures.

Classes
-------

PrettyPrinter()
    Handle pretty-printing operations onto a stream using a configured
    set of formatting parameters.

Functions
---------

pformat()
    Format a Python object into a pretty-printed representation.

pprint()
    Pretty-print a Python object to a stream [default is sys.stdout].

saferepr()
    Generate a 'standard' repr()-like value, but protect against recursive
    data structures.

"""

import sys as _sys
from collections import OrderedDict as _OrderedDict
from io import StringIO as _StringIO

from typing import Any, Tuple, Dict, TextIO, cast, List

__all__ = ["pprint","pformat","isreadable","isrecursive","saferepr",
           "PrettyPrinter"]

# cache these for faster access:
_commajoin = ", ".join
_id = id
_len = len
_type = type


def pprint(object: object, stream: TextIO = None, indent: int = 1,
           width: int = 80, depth: int = None) -> None:
    """Pretty-print a Python object to a stream [default is sys.stdout]."""
    printer = PrettyPrinter(
        stream=stream, indent=indent, width=width, depth=depth)
    printer.pprint(object)

def pformat(object: object, indent: int = 1, width: int = 80,
            depth: int = None) -> str:
    """Format a Python object into a pretty-printed representation."""
    return PrettyPrinter(indent=indent, width=width, depth=depth).pformat(object)

def saferepr(object: object) -> str:
    """Version of repr() which can handle recursive data structures."""
    return _safe_repr(object, {}, None, 0)[0]

def isreadable(object: object) -> bool:
    """Determine if saferepr(object) is readable by eval()."""
    return _safe_repr(object, {}, None, 0)[1]

def isrecursive(object: object) -> bool:
    """Determine if object requires a recursive representation."""
    return _safe_repr(object, {}, None, 0)[2]

class _safe_key:
    """Helper function for key functions when sorting unorderable objects.

    The wrapped-object will fallback to an Py2.x style comparison for
    unorderable types (sorting first comparing the type name and then by
    the obj ids).  Does not work recursively, so dict.items() must have
    _safe_key applied to both the key and the value.

    """

    __slots__ = ['obj']

    def __init__(self, obj: Any) -> None:
        self.obj = obj

    def __lt__(self, other: Any) -> Any:
        rv = self.obj.__lt__(other.obj) # type: Any
        if rv is NotImplemented:
            rv = (str(type(self.obj)), id(self.obj)) < \
                 (str(type(other.obj)), id(other.obj))
        return rv

def _safe_tuple(t: Tuple[Any, Any]) -> Tuple[_safe_key, _safe_key]:
    "Helper function for comparing 2-tuples"
    return _safe_key(t[0]), _safe_key(t[1])

class PrettyPrinter:
    def __init__(self, indent: int = 1, width: int = 80, depth: int = None,
                 stream: TextIO = None) -> None:
        """Handle pretty printing operations onto a stream using a set of
        configured parameters.

        indent
            Number of spaces to indent for each level of nesting.

        width
            Attempted maximum number of columns in the output.

        depth
            The maximum depth to print out nested structures.

        stream
            The desired output stream.  If omitted (or false), the standard
            output stream available at construction will be used.

        """
        indent = int(indent)
        width = int(width)
        assert indent >= 0, "indent must be >= 0"
        assert depth is None or depth > 0, "depth must be > 0"
        assert width, "width must be != 0"
        self._depth = depth
        self._indent_per_level = indent
        self._width = width
        if stream is not None:
            self._stream = stream
        else:
            self._stream = _sys.stdout

    def pprint(self, object: object) -> None:
        self._format(object, self._stream, 0, 0, {}, 0)
        self._stream.write("\n")

    def pformat(self, object: object) -> str:
        sio = _StringIO()
        self._format(object, sio, 0, 0, {}, 0)
        return sio.getvalue()

    def isrecursive(self, object: object) -> int:
        return self.format(object, {}, 0, 0)[2]

    def isreadable(self, object: object) -> int:
        s, readable, recursive = self.format(object, {}, 0, 0)
        return readable and not recursive

    def _format(self, object: object, stream: TextIO, indent: int,
                allowance: int, context: Dict[int, int], level: int) -> None:
        level = level + 1
        objid = _id(object)
        if objid in context:
            stream.write(_recursion(object))
            self._recursive = True
            self._readable = False
            return
        rep = self._repr(object, context, level - 1)
        typ = _type(object)
        sepLines = _len(rep) > (self._width - 1 - indent - allowance)
        write = stream.write

        if self._depth and level > self._depth:
            write(rep)
            return

        if sepLines:
            r = getattr(typ, "__repr__", None)
            if isinstance(object, dict):
                write('{')
                if self._indent_per_level > 1:
                    write((self._indent_per_level - 1) * ' ')
                length = _len(object)
                if length:
                    context[objid] = 1
                    indent = indent + self._indent_per_level
                    if issubclass(typ, _OrderedDict):
                        items = list(object.items())
                    else:
                        items = sorted(object.items(), key=_safe_tuple)
                    key, ent = items[0]
                    rep = self._repr(key, context, level)
                    write(rep)
                    write(': ')
                    self._format(ent, stream, indent + _len(rep) + 2,
                                  allowance + 1, context, level)
                    if length > 1:
                        for key, ent in items[1:]:
                            rep = self._repr(key, context, level)
                            write(',\n%s%s: ' % (' '*indent, rep))
                            self._format(ent, stream, indent + _len(rep) + 2,
                                          allowance + 1, context, level)
                    indent = indent - self._indent_per_level
                    del context[objid]
                write('}')
                return

            if ((issubclass(typ, list) and r is list.__repr__) or
                (issubclass(typ, tuple) and r is tuple.__repr__) or
                (issubclass(typ, set) and r is set.__repr__) or
                (issubclass(typ, frozenset) and r is frozenset.__repr__)
               ):
                anyobj = Any(object) # TODO Collection?
                length = _len(anyobj)
                if issubclass(typ, list):
                    write('[')
                    endchar = ']'
                    lst = anyobj
                elif issubclass(typ, set):
                    if not length:
                        write('set()')
                        return
                    write('{')
                    endchar = '}'
                    lst = sorted(anyobj, key=_safe_key)
                elif issubclass(typ, frozenset):
                    if not length:
                        write('frozenset()')
                        return
                    write('frozenset({')
                    endchar = '})'
                    lst = sorted(anyobj, key=_safe_key)
                    indent += 10
                else:
                    write('(')
                    endchar = ')'
                    lst = list(anyobj)
                if self._indent_per_level > 1:
                    write((self._indent_per_level - 1) * ' ')
                if length:
                    context[objid] = 1
                    indent = indent + self._indent_per_level
                    self._format(lst[0], stream, indent, allowance + 1,
                                 context, level)
                    if length > 1:
                        for ent in lst[1:]:
                            write(',\n' + ' '*indent)
                            self._format(ent, stream, indent,
                                          allowance + 1, context, level)
                    indent = indent - self._indent_per_level
                    del context[objid]
                if issubclass(typ, tuple) and length == 1:
                    write(',')
                write(endchar)
                return

        write(rep)

    def _repr(self, object: object, context: Dict[int, int],
              level: int) -> str:
        repr, readable, recursive = self.format(object, context.copy(),
                                                self._depth, level)
        if not readable:
            self._readable = False
        if recursive:
            self._recursive = True
        return repr

    def format(self, object: object, context: Dict[int, int],
               maxlevels: int, level: int) -> Tuple[str, int, int]:
        """Format object for a specific context, returning a string
        and flags indicating whether the representation is 'readable'
        and whether the object represents a recursive construct.
        """
        return _safe_repr(object, context, maxlevels, level)


# Return triple (repr_string, isreadable, isrecursive).

def _safe_repr(object: object, context: Dict[int, int],
               maxlevels: int, level: int) -> Tuple[str, bool, bool]:
    typ = _type(object)
    if typ is str:
        s = cast(str, object)
        if 'locale' not in _sys.modules:
            return repr(object), True, False
        if "'" in s and '"' not in s:
            closure = '"'
            quotes = {'"': '\\"'}
        else:
            closure = "'"
            quotes = {"'": "\\'"}
        qget = quotes.get
        sio = _StringIO()
        write = sio.write
        for char in s:
            if char.isalpha():
                write(char)
            else:
                write(qget(char, repr(char)[1:-1]))
        return ("%s%s%s" % (closure, sio.getvalue(), closure)), True, False

    r = getattr(typ, "__repr__", None)
    if issubclass(typ, dict) and r is dict.__repr__:
        if not object:
            return "{}", True, False
        objid = _id(object)
        if maxlevels and level >= maxlevels:
            return "{...}", False, objid in context
        if objid in context:
            return _recursion(object), False, True
        context[objid] = 1
        readable = True
        recursive = False
        components = List[str]()
        append = components.append
        level += 1
        saferepr = _safe_repr
        items = sorted((cast(dict, object)).items(), key=_safe_tuple)
        for k, v in items:
            krepr, kreadable, krecur = saferepr(k, context, maxlevels, level)
            vrepr, vreadable, vrecur = saferepr(v, context, maxlevels, level)
            append("%s: %s" % (krepr, vrepr))
            readable = readable and kreadable and vreadable
            if krecur or vrecur:
                recursive = True
        del context[objid]
        return "{%s}" % _commajoin(components), readable, recursive

    if (issubclass(typ, list) and r is list.__repr__) or \
       (issubclass(typ, tuple) and r is tuple.__repr__):
        anyobj = Any(object) # TODO Sequence?
        if issubclass(typ, list):
            if not object:
                return "[]", True, False
            format = "[%s]"
        elif _len(anyobj) == 1:
            format = "(%s,)"
        else:
            if not object:
                return "()", True, False
            format = "(%s)"
        objid = _id(object)
        if maxlevels and level >= maxlevels:
            return format % "...", False, objid in context
        if objid in context:
            return _recursion(object), False, True
        context[objid] = 1
        readable = True
        recursive = False
        components = []
        append = components.append
        level += 1
        for o in anyobj:
            orepr, oreadable, orecur = _safe_repr(o, context, maxlevels, level)
            append(orepr)
            if not oreadable:
                readable = False
            if orecur:
                recursive = True
        del context[objid]
        return format % _commajoin(components), readable, recursive

    rep = repr(object)
    return rep, bool(rep and not rep.startswith('<')), False


def _recursion(object: object) -> str:
    return ("<Recursion on %s with id=%s>"
            % (_type(object).__name__, _id(object)))


def _perfcheck(object: object = None) -> None:
    import time
    if object is None:
        object = [("string", (1, 2), [3, 4], {5: 6, 7: 8})] * 100000
    p = PrettyPrinter()
    t1 = time.time()
    _safe_repr(object, {}, None, 0)
    t2 = time.time()
    p.pformat(object)
    t3 = time.time()
    print("_safe_repr:", t2 - t1)
    print("pformat:", t3 - t2)

if __name__ == "__main__":
    _perfcheck()

########NEW FILE########
__FILENAME__ = random
"""Random variable generators.

    integers
    --------
           uniform within range

    sequences
    ---------
           pick random element
           pick random sample
           generate random permutation

    distributions on the real line:
    ------------------------------
           uniform
           triangular
           normal (Gaussian)
           lognormal
           negative exponential
           gamma
           beta
           pareto
           Weibull

    distributions on the circle (angles 0 to 2pi)
    ---------------------------------------------
           circular uniform
           von Mises

General notes on the underlying Mersenne Twister core generator:

* The period is 2**19937-1.
* It is one of the most extensively tested generators in existence.
* The random() method is implemented in C, executes in a single Python step,
  and is, therefore, threadsafe.

"""

from warnings import warn as _warn
from types import MethodType as _MethodType, BuiltinMethodType as _BuiltinMethodType
from math import log as _log, exp as _exp, pi as _pi, e as _e, ceil as _ceil
from math import sqrt as _sqrt, acos as _acos, cos as _cos, sin as _sin
from os import urandom as _urandom
from collections import Set as _Set, Sequence as _Sequence
from hashlib import sha512 as _sha512

from typing import (
    Any, typevar, Iterable, Sequence, List, Function, Set, cast, SupportsInt
)

__all__ = ["Random","seed","random","uniform","randint","choice","sample",
           "randrange","shuffle","normalvariate","lognormvariate",
           "expovariate","vonmisesvariate","gammavariate","triangular",
           "gauss","betavariate","paretovariate","weibullvariate",
           "getstate","setstate", "getrandbits",
           "SystemRandom"]

NV_MAGICCONST = 4 * _exp(-0.5)/_sqrt(2.0)
TWOPI = 2.0*_pi
LOG4 = _log(4.0)
SG_MAGICCONST = 1.0 + _log(4.5)
BPF = 53        # Number of bits in a float
RECIP_BPF = 2**-BPF # type: float


# Translated by Guido van Rossum from C source provided by
# Adrian Baddeley.  Adapted by Raymond Hettinger for use with
# the Mersenne Twister  and os.urandom() core generators.

import _random

T = typevar('T')

class Random(_random.Random):
    """Random number generator base class used by bound module functions.

    Used to instantiate instances of Random to get generators that don't
    share state.

    Class Random can also be subclassed if you want to use a different basic
    generator of your own devising: in that case, override the following
    methods:  random(), seed(), getstate(), and setstate().
    Optionally, implement a getrandbits() method so that randrange()
    can cover arbitrarily large ranges.

    """

    VERSION = 3     # used by getstate/setstate
    gauss_next = 0.0

    def __init__(self, x: object = None) -> None:
        """Initialize an instance.

        Optional argument x controls seeding, as for Random.seed().
        """

        self.seed(x)
        self.gauss_next = None

    def seed(self, a: Any = None, version: int = 2) -> None:
        """Initialize internal state from hashable object.

        None or no argument seeds from current time or from an operating
        system specific randomness source if available.

        For version 2 (the default), all of the bits are used if *a *is a str,
        bytes, or bytearray.  For version 1, the hash() of *a* is used instead.

        If *a* is an int, all bits are used.

        """

        if a is None:
            try:
                a = int.from_bytes(_urandom(32), 'big')
            except NotImplementedError:
                import time
                a = int(time.time() * 256) # use fractional seconds

        if version == 2:
            if isinstance(a, (str, bytes, bytearray)):
                s = a
                if isinstance(s, str):
                    a = s.encode()
                else:
                    a = s
                a += _sha512(a).digest()
                a = int.from_bytes(a, 'big')

        super().seed(a)
        self.gauss_next = None

    def getstate(self) -> tuple:
        """Return internal state; can be passed to setstate() later."""
        return self.VERSION, super().getstate(), self.gauss_next

    def setstate(self, state: tuple) -> None:
        """Restore internal state from object returned by getstate()."""
        version = state[0]
        if version == 3:
            version, internalstate, self.gauss_next = state
            super().setstate(internalstate)
        elif version == 2:
            version, internalstate, self.gauss_next = state
            # In version 2, the state was saved as signed ints, which causes
            #   inconsistencies between 32/64-bit systems. The state is
            #   really unsigned 32-bit ints, so we convert negative ints from
            #   version 2 to positive longs for version 3.
            try:
                internalstate = tuple(x % (2**32) for x in internalstate)
            except ValueError as e:
                raise TypeError()
            super().setstate(internalstate)
        else:
            raise ValueError("state with version %s passed to "
                             "Random.setstate() of version %s" %
                             (version, self.VERSION))

## ---- Methods below this point do not need to be overridden when
## ---- subclassing for the purpose of using a different core generator.

## -------------------- pickle support  -------------------

    def __getstate__(self) -> object: # for pickle
        return self.getstate()

    def __setstate__(self, state: Any) -> None:  # for pickle
        self.setstate(state)

    def __reduce__(self) -> object:
        return self.__class__, (), self.getstate()

## -------------------- integer methods  -------------------

    def randrange(self, start: SupportsInt, stop: SupportsInt = None,
                  step: int = 1, int: Function[[SupportsInt],
                                               int] = int) -> int:
        """Choose a random item from range(start, stop[, step]).

        This fixes the problem with randint() which includes the
        endpoint; in Python this is usually not what you want.

        Do not supply the 'int' argument.
        """

        # This code is a bit messy to make it fast for the
        # common case while still doing adequate error checking.
        istart = int(start)
        if istart != start:
            raise ValueError("non-integer arg 1 for randrange()")
        if stop is None:
            if istart > 0:
                return self._randbelow(istart)
            raise ValueError("empty range for randrange()")

        # stop argument supplied.
        istop = int(stop)
        if istop != stop:
            raise ValueError("non-integer stop for randrange()")
        width = istop - istart
        if step == 1 and width > 0:
            return istart + self._randbelow(width)
        if step == 1:
            raise ValueError("empty range for randrange() (%d,%d, %d)" % (istart, istop, width))

        # Non-unit step argument supplied.
        istep = int(step)
        if istep != step:
            raise ValueError("non-integer step for randrange()")
        if istep > 0:
            n = (width + istep - 1) // istep
        elif istep < 0:
            n = (width + istep + 1) // istep
        else:
            raise ValueError("zero step for randrange()")

        if n <= 0:
            raise ValueError("empty range for randrange()")

        return istart + istep*self._randbelow(n)

    def randint(self, a: int, b: int) -> int:
        """Return random integer in range [a, b], including both end points.
        """

        return self.randrange(a, b+1)

    def _randbelow(self, n: int, int: Function[[float], int] = int,
                   maxsize: int = 1<<BPF,
                   type: Function[[object], type] = type,
                   Method: type = _MethodType,
                   BuiltinMethod: type = _BuiltinMethodType) -> int:
        "Return a random int in the range [0,n).  Raises ValueError if n==0."

        getrandbits = self.getrandbits
        # Only call self.getrandbits if the original random() builtin method
        # has not been overridden or if a new getrandbits() was supplied.
        if type(self.random) is BuiltinMethod or type(getrandbits) is Method:
            k = n.bit_length()  # don't use (n-1) here because n can be 1
            r = getrandbits(k)          # 0 <= r < 2**k
            while r >= n:
                r = getrandbits(k)
            return r
        # There's an overriden random() method but no new getrandbits() method,
        # so we can only use random() from here.
        random = self.random
        if n >= maxsize:
            _warn("Underlying random() generator does not supply \n"
                "enough bits to choose from a population range this large.\n"
                "To remove the range limitation, add a getrandbits() method.")
            return int(random() * n)
        rem = maxsize % n
        limit = (maxsize - rem) / maxsize   # int(limit * maxsize) % n == 0
        s = random()
        while s >= limit:
            s = random()
        return int(s*maxsize) % n

## -------------------- sequence methods  -------------------

    def choice(self, seq: Sequence[T]) -> T:
        """Choose a random element from a non-empty sequence."""
        try:
            i = self._randbelow(len(seq))
        except ValueError:
            raise IndexError('Cannot choose from an empty sequence')
        return seq[i]

    def shuffle(self, x: List[T],
                random: Function[[], float] = None,
                int: Function[[float], int] = int) -> None:
        """x, random=random.random -> shuffle list x in place; return None.

        Optional arg random is a 0-argument function returning a random
        float in [0.0, 1.0); by default, the standard random.random.
        """

        randbelow = self._randbelow
        for i in reversed(range(1, len(x))):
            # pick an element in x[:i+1] with which to exchange x[i]
            j = randbelow(i+1) if random is None else int(random() * (i+1))
            x[i], x[j] = x[j], x[i]

    def sample(self, population: Iterable[T], k: int) -> List[T]:
        """Chooses k unique random elements from a population sequence or set.

        Returns a new list containing elements from the population while
        leaving the original population unchanged.  The resulting list is
        in selection order so that all sub-slices will also be valid random
        samples.  This allows raffle winners (the sample) to be partitioned
        into grand prize and second place winners (the subslices).

        Members of the population need not be hashable or unique.  If the
        population contains repeats, then each occurrence is a possible
        selection in the sample.

        To choose a sample in a range of integers, use range as an argument.
        This is especially fast and space efficient for sampling from a
        large population:   sample(range(10000000), 60)
        """

        # Sampling without replacement entails tracking either potential
        # selections (the pool) in a list or previous selections in a set.

        # When the number of selections is small compared to the
        # population, then tracking selections is efficient, requiring
        # only a small set and an occasional reselection.  For
        # a larger number of selections, the pool tracking method is
        # preferred since the list takes less space than the
        # set and it doesn't suffer from frequent reselections.

        if isinstance(population, _Sequence):
            populationseq = population
        elif isinstance(population, _Set):
            populationseq = list(population)
        else:
            raise TypeError("Population must be a sequence or set.  For dicts, use list(d).")
        randbelow = self._randbelow
        n = len(populationseq)
        if not (0 <= k and k <= n):
            raise ValueError("Sample larger than population")
        result = [cast(T, None)] * k
        setsize = 21        # size of a small set minus size of an empty list
        if k > 5:
            setsize += 4 ** _ceil(_log(k * 3, 4)) # table size for big sets
        if n <= setsize:
            # An n-length list is smaller than a k-length set
            pool = list(populationseq)
            for i in range(k):         # invariant:  non-selected at [0,n-i)
                j = randbelow(n-i)
                result[i] = pool[j]
                pool[j] = pool[n-i-1]   # move non-selected item into vacancy
        else:
            selected = Set[int]()
            selected_add = selected.add
            for i in range(k):
                j = randbelow(n)
                while j in selected:
                    j = randbelow(n)
                selected_add(j)
                result[i] = populationseq[j]
        return result

## -------------------- real-valued distributions  -------------------

## -------------------- uniform distribution -------------------

    def uniform(self, a: float, b: float) -> float:
        "Get a random number in the range [a, b) or [a, b] depending on rounding."
        return a + (b-a) * self.random()

## -------------------- triangular --------------------

    def triangular(self, low: float = 0.0, high: float = 1.0,
                   mode: float = None) -> float:
        """Triangular distribution.

        Continuous distribution bounded by given lower and upper limits,
        and having a given mode value in-between.

        http://en.wikipedia.org/wiki/Triangular_distribution

        """
        u = self.random()
        c = 0.5 if mode is None else (mode - low) / (high - low)
        if u > c:
            u = 1.0 - u
            c = 1.0 - c
            low, high = high, low
        return low + (high - low) * (u * c) ** 0.5

## -------------------- normal distribution --------------------

    def normalvariate(self, mu: float, sigma: float) -> float:
        """Normal distribution.

        mu is the mean, and sigma is the standard deviation.

        """
        # mu = mean, sigma = standard deviation

        # Uses Kinderman and Monahan method. Reference: Kinderman,
        # A.J. and Monahan, J.F., "Computer generation of random
        # variables using the ratio of uniform deviates", ACM Trans
        # Math Software, 3, (1977), pp257-260.

        random = self.random
        while 1:
            u1 = random()
            u2 = 1.0 - random()
            z = NV_MAGICCONST*(u1-0.5)/u2
            zz = z*z/4.0
            if zz <= -_log(u2):
                break
        return mu + z*sigma

## -------------------- lognormal distribution --------------------

    def lognormvariate(self, mu: float, sigma: float) -> float:
        """Log normal distribution.

        If you take the natural logarithm of this distribution, you'll get a
        normal distribution with mean mu and standard deviation sigma.
        mu can have any value, and sigma must be greater than zero.

        """
        return _exp(self.normalvariate(mu, sigma))

## -------------------- exponential distribution --------------------

    def expovariate(self, lambd: float) -> float:
        """Exponential distribution.

        lambd is 1.0 divided by the desired mean.  It should be
        nonzero.  (The parameter would be called "lambda", but that is
        a reserved word in Python.)  Returned values range from 0 to
        positive infinity if lambd is positive, and from negative
        infinity to 0 if lambd is negative.

        """
        # lambd: rate lambd = 1/mean
        # ('lambda' is a Python reserved word)

        # we use 1-random() instead of random() to preclude the
        # possibility of taking the log of zero.
        return -_log(1.0 - self.random())/lambd

## -------------------- von Mises distribution --------------------

    def vonmisesvariate(self, mu: float, kappa: float) -> float:
        """Circular data distribution.

        mu is the mean angle, expressed in radians between 0 and 2*pi, and
        kappa is the concentration parameter, which must be greater than or
        equal to zero.  If kappa is equal to zero, this distribution reduces
        to a uniform random angle over the range 0 to 2*pi.

        """
        # mu:    mean angle (in radians between 0 and 2*pi)
        # kappa: concentration parameter kappa (>= 0)
        # if kappa = 0 generate uniform random angle

        # Based upon an algorithm published in: Fisher, N.I.,
        # "Statistical Analysis of Circular Data", Cambridge
        # University Press, 1993.

        # Thanks to Magnus Kessler for a correction to the
        # implementation of step 4.

        random = self.random
        if kappa <= 1e-6:
            return TWOPI * random()

        a = 1.0 + _sqrt(1.0 + 4.0 * kappa * kappa)
        b = (a - _sqrt(2.0 * a))/(2.0 * kappa)
        r = (1.0 + b * b)/(2.0 * b)

        while 1:
            u1 = random()

            z = _cos(_pi * u1)
            f = (1.0 + r * z)/(r + z)
            c = kappa * (r - f)

            u2 = random()

            if u2 < c * (2.0 - c) or u2 <= c * _exp(1.0 - c):
                break

        u3 = random()
        if u3 > 0.5:
            theta = (mu % TWOPI) + _acos(f)
        else:
            theta = (mu % TWOPI) - _acos(f)

        return theta

## -------------------- gamma distribution --------------------

    def gammavariate(self, alpha: float, beta: float) -> float:
        """Gamma distribution.  Not the gamma function!

        Conditions on the parameters are alpha > 0 and beta > 0.

        The probability distribution function is:

                    x ** (alpha - 1) * math.exp(-x / beta)
          pdf(x) =  --------------------------------------
                      math.gamma(alpha) * beta ** alpha

        """

        # alpha > 0, beta > 0, mean is alpha*beta, variance is alpha*beta**2

        # Warning: a few older sources define the gamma distribution in terms
        # of alpha > -1.0
        if alpha <= 0.0 or beta <= 0.0:
            raise ValueError('gammavariate: alpha and beta must be > 0.0')

        random = self.random
        if alpha > 1.0:

            # Uses R.C.H. Cheng, "The generation of Gamma
            # variables with non-integral shape parameters",
            # Applied Statistics, (1977), 26, No. 1, p71-74

            ainv = _sqrt(2.0 * alpha - 1.0)
            bbb = alpha - LOG4
            ccc = alpha + ainv

            while 1:
                u1 = random()
                if not (1e-7 < u1 and u1 < .9999999):
                    continue
                u2 = 1.0 - random()
                v = _log(u1/(1.0-u1))/ainv
                x = alpha*_exp(v)
                z = u1*u1*u2
                r = bbb+ccc*v-x
                if r + SG_MAGICCONST - 4.5*z >= 0.0 or r >= _log(z):
                    return x * beta

        elif alpha == 1.0:
            # expovariate(1)
            u = random()
            while u <= 1e-7:
                u = random()
            return -_log(u) * beta

        else:   # alpha is between 0 and 1 (exclusive)

            # Uses ALGORITHM GS of Statistical Computing - Kennedy & Gentle

            while 1:
                u = random()
                b = (_e + alpha)/_e
                p = b*u
                if p <= 1.0:
                    x = p ** (1.0/alpha)
                else:
                    x = -_log((b-p)/alpha)
                u1 = random()
                if p > 1.0:
                    if u1 <= x ** (alpha - 1.0):
                        break
                elif u1 <= _exp(-x):
                    break
            return x * beta

## -------------------- Gauss (faster alternative) --------------------

    def gauss(self, mu: float, sigma: float) -> float:
        """Gaussian distribution.

        mu is the mean, and sigma is the standard deviation.  This is
        slightly faster than the normalvariate() function.

        Not thread-safe without a lock around calls.

        """

        # When x and y are two variables from [0, 1), uniformly
        # distributed, then
        #
        #    cos(2*pi*x)*sqrt(-2*log(1-y))
        #    sin(2*pi*x)*sqrt(-2*log(1-y))
        #
        # are two *independent* variables with normal distribution
        # (mu = 0, sigma = 1).
        # (Lambert Meertens)
        # (corrected version; bug discovered by Mike Miller, fixed by LM)

        # Multithreading note: When two threads call this function
        # simultaneously, it is possible that they will receive the
        # same return value.  The window is very small though.  To
        # avoid this, you have to use a lock around all calls.  (I
        # didn't want to slow this down in the serial case by using a
        # lock here.)

        random = self.random
        z = self.gauss_next
        self.gauss_next = None
        if z is None:
            x2pi = random() * TWOPI
            g2rad = _sqrt(-2.0 * _log(1.0 - random()))
            z = _cos(x2pi) * g2rad
            self.gauss_next = _sin(x2pi) * g2rad

        return mu + z*sigma

## -------------------- beta --------------------
## See
## http://mail.python.org/pipermail/python-bugs-list/2001-January/003752.html
## for Ivan Frohne's insightful analysis of why the original implementation:
##
##    def betavariate(self, alpha, beta):
##        # Discrete Event Simulation in C, pp 87-88.
##
##        y = self.expovariate(alpha)
##        z = self.expovariate(1.0/beta)
##        return z/(y+z)
##
## was dead wrong, and how it probably got that way.

    def betavariate(self, alpha: float, beta: float) -> 'float':
        """Beta distribution.

        Conditions on the parameters are alpha > 0 and beta > 0.
        Returned values range between 0 and 1.

        """

        # This version due to Janne Sinkkonen, and matches all the std
        # texts (e.g., Knuth Vol 2 Ed 3 pg 134 "the beta distribution").
        y = self.gammavariate(alpha, 1.)
        if y == 0:
            return 0.0
        else:
            return y / (y + self.gammavariate(beta, 1.))

## -------------------- Pareto --------------------

    def paretovariate(self, alpha: float) -> float:
        """Pareto distribution.  alpha is the shape parameter."""
        # Jain, pg. 495

        u = 1.0 - self.random()
        return 1.0 / u ** (1.0/alpha)

## -------------------- Weibull --------------------

    def weibullvariate(self, alpha: float, beta: float) -> float:
        """Weibull distribution.

        alpha is the scale parameter and beta is the shape parameter.

        """
        # Jain, pg. 499; bug fix courtesy Bill Arms

        u = 1.0 - self.random()
        return alpha * (-_log(u)) ** (1.0/beta)

## --------------- Operating System Random Source  ------------------

class SystemRandom(Random):
    """Alternate random number generator using sources provided
    by the operating system (such as /dev/urandom on Unix or
    CryptGenRandom on Windows).

     Not available on all systems (see os.urandom() for details).
    """

    def random(self) -> float:
        """Get the next random number in the range [0.0, 1.0)."""
        return (int.from_bytes(_urandom(7), 'big') >> 3) * RECIP_BPF

    def getrandbits(self, k: int) -> int:
        """getrandbits(k) -> x.  Generates a long int with k random bits."""
        if k <= 0:
            raise ValueError('number of bits must be greater than zero')
        if k != int(k):
            raise TypeError('number of bits should be an integer')
        numbytes = (k + 7) // 8                       # bits / 8 and rounded up
        x = int.from_bytes(_urandom(numbytes), 'big')
        return x >> (numbytes * 8 - k)                # trim excess bits

    def seed(self, a: object = None, version: int = None) -> None:
        "Stub method.  Not used for a system random number generator."
        return

    def _notimplemented(self, *args: Any, **kwds: Any) -> Any:
        "Method should not be called for a system random number generator."
        raise NotImplementedError('System entropy source does not have state.')
    getstate = setstate = _notimplemented

# Create one instance, seeded from current time, and export its methods
# as module-level functions.  The functions share state across all uses
#(both in the user's code and in the Python libraries), but that's fine
# for most programs and is easier for the casual user than making them
# instantiate their own Random() instance.

_inst = Random()
seed = _inst.seed
random = _inst.random
uniform = _inst.uniform
triangular = _inst.triangular
randint = _inst.randint
choice = _inst.choice
randrange = _inst.randrange
sample = _inst.sample
shuffle = _inst.shuffle
normalvariate = _inst.normalvariate
lognormvariate = _inst.lognormvariate
expovariate = _inst.expovariate
vonmisesvariate = _inst.vonmisesvariate
gammavariate = _inst.gammavariate
gauss = _inst.gauss
betavariate = _inst.betavariate
paretovariate = _inst.paretovariate
weibullvariate = _inst.weibullvariate
getstate = _inst.getstate
setstate = _inst.setstate
getrandbits = _inst.getrandbits

## -------------------- test program --------------------

def _test_generator(n: int, func: Any, args: tuple) -> None:
    import time
    print(n, 'times', func.__name__)
    total = 0.0
    sqsum = 0.0
    smallest = 1e10
    largest = -1e10
    t0 = time.time()
    for i in range(n):
        x = func(*args) # type: float
        total += x
        sqsum = sqsum + x*x
        smallest = min(x, smallest)
        largest = max(x, largest)
    t1 = time.time()
    print(round(t1-t0, 3), 'sec,', end=' ')
    avg = total/n
    stddev = _sqrt(sqsum/n - avg*avg)
    print('avg %g, stddev %g, min %g, max %g' % \
              (avg, stddev, smallest, largest))


def _test(N: int = 2000) -> None:
    _test_generator(N, random, ())
    _test_generator(N, normalvariate, (0.0, 1.0))
    _test_generator(N, lognormvariate, (0.0, 1.0))
    _test_generator(N, vonmisesvariate, (0.0, 1.0))
    _test_generator(N, gammavariate, (0.01, 1.0))
    _test_generator(N, gammavariate, (0.1, 1.0))
    _test_generator(N, gammavariate, (0.1, 2.0))
    _test_generator(N, gammavariate, (0.5, 1.0))
    _test_generator(N, gammavariate, (0.9, 1.0))
    _test_generator(N, gammavariate, (1.0, 1.0))
    _test_generator(N, gammavariate, (2.0, 1.0))
    _test_generator(N, gammavariate, (20.0, 1.0))
    _test_generator(N, gammavariate, (200.0, 1.0))
    _test_generator(N, gauss, (0.0, 1.0))
    _test_generator(N, betavariate, (3.0, 3.0))
    _test_generator(N, triangular, (0.0, 1.0, 1.0/3.0))

if __name__ == '__main__':
    _test()

########NEW FILE########
__FILENAME__ = shutil
"""Utility functions for copying and archiving files and directory trees.

XXX The functions here don't copy the resource fork or other metadata on Mac.

"""

import os
import sys
import stat
from os.path import abspath
import fnmatch
import collections
import errno
import tarfile
import builtins

from typing import (
    Any, AnyStr, IO, List, Iterable, Function, Tuple, Dict, Sequence, cast,
    Traceback
)

try:
    import bz2
    _BZ2_SUPPORTED = True
except ImportError:
    _BZ2_SUPPORTED = False

try:
    from pwd import getpwnam as _getpwnam
    getpwnam = _getpwnam
except ImportError:
    getpwnam = None

try:
    from grp import getgrnam as _getgrnam
    getgrnam = _getgrnam
except ImportError:
    getgrnam = None

__all__ = ["copyfileobj", "copyfile", "copymode", "copystat", "copy", "copy2",
           "copytree", "move", "rmtree", "Error", "SpecialFileError",
           "ExecError", "make_archive", "get_archive_formats",
           "register_archive_format", "unregister_archive_format",
           "get_unpack_formats", "register_unpack_format",
           "unregister_unpack_format", "unpack_archive", "ignore_patterns"]

class Error(EnvironmentError):
    pass

class SpecialFileError(EnvironmentError):
    """Raised when trying to do a kind of operation (e.g. copying) which is
    not supported on a special file (e.g. a named pipe)"""

class ExecError(EnvironmentError):
    """Raised when a command could not be executed"""

class ReadError(EnvironmentError):
    """Raised when an archive cannot be read"""

class RegistryError(Exception):
    """Raised when a registery operation with the archiving
    and unpacking registeries fails"""


try:
    _WindowsError = WindowsError
except NameError:
    _WindowsError = None


# Function aliases to be patched in test cases
rename = os.rename
open = builtins.open


def copyfileobj(fsrc: IO[AnyStr], fdst: IO[AnyStr],
                length: int = 16*1024) -> None:
    """copy data from file-like object fsrc to file-like object fdst"""
    while 1:
        buf = fsrc.read(length)
        if not buf:
            break
        fdst.write(buf)

def _samefile(src: str, dst: str) -> bool:
    # Macintosh, Unix.
    if hasattr(os.path, 'samefile'):
        try:
            return os.path.samefile(src, dst)
        except OSError:
            return False

    # All other platforms: check for same pathname.
    return (os.path.normcase(os.path.abspath(src)) ==
            os.path.normcase(os.path.abspath(dst)))

def copyfile(src: str, dst: str) -> None:
    """Copy data from src to dst"""
    if _samefile(src, dst):
        raise Error("`%s` and `%s` are the same file" % (src, dst))

    for fn in [src, dst]:
        try:
            st = os.stat(fn)
        except OSError:
            # File most likely does not exist
            pass
        else:
            # XXX What about other special files? (sockets, devices...)
            if stat.S_ISFIFO(st.st_mode):
                raise SpecialFileError("`%s` is a named pipe" % fn)

    with open(src, 'rb') as fsrc:
        with open(dst, 'wb') as fdst:
            copyfileobj(fsrc, fdst)

def copymode(src: str, dst: str) -> None:
    """Copy mode bits from src to dst"""
    if hasattr(os, 'chmod'):
        st = os.stat(src)
        mode = stat.S_IMODE(st.st_mode)
        os.chmod(dst, mode)

def copystat(src: str, dst: str) -> None:
    """Copy all stat info (mode bits, atime, mtime, flags) from src to dst"""
    st = os.stat(src)
    mode = stat.S_IMODE(st.st_mode)
    if hasattr(os, 'utime'):
        os.utime(dst, (st.st_atime, st.st_mtime))
    if hasattr(os, 'chmod'):
        os.chmod(dst, mode)
    if hasattr(os, 'chflags') and hasattr(st, 'st_flags'):
        try:
            os.chflags(dst, st.st_flags)
        except OSError as why:
            if (not hasattr(errno, 'EOPNOTSUPP') or
                why.errno != errno.EOPNOTSUPP):
                raise

def copy(src: str, dst: str) -> None:
    """Copy data and mode bits ("cp src dst").

    The destination may be a directory.

    """
    if os.path.isdir(dst):
        dst = os.path.join(dst, os.path.basename(src))
    copyfile(src, dst)
    copymode(src, dst)

def copy2(src: str, dst: str) -> None:
    """Copy data and all stat info ("cp -p src dst").

    The destination may be a directory.

    """
    if os.path.isdir(dst):
        dst = os.path.join(dst, os.path.basename(src))
    copyfile(src, dst)
    copystat(src, dst)

def ignore_patterns(*patterns: str) -> Function[[str, List[str]],
                                                Iterable[str]]:
    """Function that can be used as copytree() ignore parameter.

    Patterns is a sequence of glob-style patterns
    that are used to exclude files"""
    def _ignore_patterns(path: str, names: List[str]) -> Iterable[str]:
        ignored_names = List[str]()
        for pattern in patterns:
            ignored_names.extend(fnmatch.filter(names, pattern))
        return set(ignored_names)
    return _ignore_patterns

def copytree(src: str, dst: str, symlinks: bool = False,
             ignore: Function[[str, List[str]], Iterable[str]] = None,
             copy_function: Function[[str, str], None] = copy2,
             ignore_dangling_symlinks: bool = False) -> None:
    """Recursively copy a directory tree.

    The destination directory must not already exist.
    If exception(s) occur, an Error is raised with a list of reasons.

    If the optional symlinks flag is true, symbolic links in the
    source tree result in symbolic links in the destination tree; if
    it is false, the contents of the files pointed to by symbolic
    links are copied. If the file pointed by the symlink doesn't
    exist, an exception will be added in the list of errors raised in
    an Error exception at the end of the copy process.

    You can set the optional ignore_dangling_symlinks flag to true if you
    want to silence this exception. Notice that this has no effect on
    platforms that don't support os.symlink.

    The optional ignore argument is a callable. If given, it
    is called with the `src` parameter, which is the directory
    being visited by copytree(), and `names` which is the list of
    `src` contents, as returned by os.listdir():

        callable(src, names) -> ignored_names

    Since copytree() is called recursively, the callable will be
    called once for each directory that is copied. It returns a
    list of names relative to the `src` directory that should
    not be copied.

    The optional copy_function argument is a callable that will be used
    to copy each file. It will be called with the source path and the
    destination path as arguments. By default, copy2() is used, but any
    function that supports the same signature (like copy()) can be used.

    """
    names = os.listdir(src)
    if ignore is not None:
        ignored_names = set(ignore(src, names))   # see #203
    else:
        ignored_names = set()

    os.makedirs(dst)
    errors = List[Tuple[str, str, str]]()
    for name in names:
        if name in ignored_names:
            continue
        srcname = os.path.join(src, name)
        dstname = os.path.join(dst, name)
        try:
            if os.path.islink(srcname):
                linkto = os.readlink(srcname)
                if symlinks:
                    os.symlink(linkto, dstname)
                else:
                    # ignore dangling symlink if the flag is on
                    if not os.path.exists(linkto) and ignore_dangling_symlinks:
                        continue
                    # otherwise let the copy occurs. copy2 will raise an error
                    copy_function(srcname, dstname)
            elif os.path.isdir(srcname):
                copytree(srcname, dstname, symlinks, ignore, copy_function)
            else:
                # Will raise a SpecialFileError for unsupported file types
                copy_function(srcname, dstname)
        # catch the Error from the recursive copytree so that we can
        # continue with other files
        except Error as err:
            errors.extend(err.args[0])
        except EnvironmentError as why:
            errors.append((srcname, dstname, str(why)))
    try:
        copystat(src, dst)
    except OSError as why:
        if _WindowsError is not None and isinstance(why, _WindowsError):
            # Copying file access times may fail on Windows
            pass
        else:
            errors.append((src, dst, str(why)))
    if errors:
        raise Error(errors)

def rmtree(path: str, ignore_errors: bool = False,
           onerror: Function[[Any, str, Tuple[type, BaseException, Traceback]],
                              None] = None) -> None:
    """Recursively delete a directory tree.

    If ignore_errors is set, errors are ignored; otherwise, if onerror
    is set, it is called to handle the error with arguments (func,
    path, exc_info) where func is os.listdir, os.remove, or os.rmdir;
    path is the argument to that function that caused it to fail; and
    exc_info is a tuple returned by sys.exc_info().  If ignore_errors
    is false and onerror is None, an exception is raised.

    """
    if ignore_errors:
        def _onerror(x: Any, y: str,
                     z: Tuple[type, BaseException, Traceback]) -> None:
            pass
        onerror = _onerror
    elif onerror is None:
        def __onerror(x: Any, y: str,
                      z: Tuple[type, BaseException, Traceback]) -> None:
            raise
        onerror = __onerror
    try:
        if os.path.islink(path):
            # symlinks to directories are forbidden, see bug #1669
            raise OSError("Cannot call rmtree on a symbolic link")
    except OSError:
        onerror(os.path.islink, path, sys.exc_info())
        # can't continue even if onerror hook returns
        return
    names = List[str]()
    try:
        names = os.listdir(path)
    except os.error as err:
        onerror(os.listdir, path, sys.exc_info())
    for name in names:
        fullname = os.path.join(path, name)
        try:
            mode = os.lstat(fullname).st_mode
        except os.error:
            mode = 0
        if stat.S_ISDIR(mode):
            rmtree(fullname, ignore_errors, onerror)
        else:
            try:
                os.remove(fullname)
            except os.error as err:
                onerror(os.remove, fullname, sys.exc_info())
    try:
        os.rmdir(path)
    except os.error:
        onerror(os.rmdir, path, sys.exc_info())


def _basename(path: str) -> str:
    # A basename() variant which first strips the trailing slash, if present.
    # Thus we always get the last component of the path, even for directories.
    return os.path.basename(path.rstrip(os.path.sep))

def move(src: str, dst: str) -> None:
    """Recursively move a file or directory to another location. This is
    similar to the Unix "mv" command.

    If the destination is a directory or a symlink to a directory, the source
    is moved inside the directory. The destination path must not already
    exist.

    If the destination already exists but is not a directory, it may be
    overwritten depending on os.rename() semantics.

    If the destination is on our current filesystem, then rename() is used.
    Otherwise, src is copied to the destination and then removed.
    A lot more could be done here...  A look at a mv.c shows a lot of
    the issues this implementation glosses over.

    """
    real_dst = dst
    if os.path.isdir(dst):
        if _samefile(src, dst):
            # We might be on a case insensitive filesystem,
            # perform the rename anyway.
            os.rename(src, dst)
            return

        real_dst = os.path.join(dst, _basename(src))
        if os.path.exists(real_dst):
            raise Error("Destination path '%s' already exists" % real_dst)
    try:
        os.rename(src, real_dst)
    except OSError as exc:
        if os.path.isdir(src):
            if _destinsrc(src, dst):
                raise Error("Cannot move a directory '%s' into itself '%s'." % (src, dst))
            copytree(src, real_dst, symlinks=True)
            rmtree(src)
        else:
            copy2(src, real_dst)
            os.unlink(src)

def _destinsrc(src: str, dst: str) -> bool:
    src = abspath(src)
    dst = abspath(dst)
    if not src.endswith(os.path.sep):
        src += os.path.sep
    if not dst.endswith(os.path.sep):
        dst += os.path.sep
    return dst.startswith(src)

def _get_gid(name: str) -> int:
    """Returns a gid, given a group name."""
    if getgrnam is None or name is None:
        return None
    try:
        result = getgrnam(name)
    except KeyError:
        result = None
    if result is not None:
        return result.gr_gid
    return None

def _get_uid(name: str) -> int:
    """Returns an uid, given a user name."""
    if getpwnam is None or name is None:
        return None
    try:
        result = getpwnam(name)
    except KeyError:
        result = None
    if result is not None:
        return result.pw_uid
    return None

def _make_tarball(base_name: str, base_dir: str, compress: str = "gzip",
                  verbose: bool = False, dry_run: bool = False,
                  owner: str = None, group: str = None,
                  logger: Any = None) -> str:
    """Create a (possibly compressed) tar file from all the files under
    'base_dir'.

    'compress' must be "gzip" (the default), "bzip2", or None.

    'owner' and 'group' can be used to define an owner and a group for the
    archive that is being built. If not provided, the current owner and group
    will be used.

    The output tar file will be named 'base_name' +  ".tar", possibly plus
    the appropriate compression extension (".gz", or ".bz2").

    Returns the output filename.
    """
    tar_compression = {'gzip': 'gz', None: ''}
    compress_ext = {'gzip': '.gz'}

    if _BZ2_SUPPORTED:
        tar_compression['bzip2'] = 'bz2'
        compress_ext['bzip2'] = '.bz2'

    # flags for compression program, each element of list will be an argument
    if compress is not None and compress not in compress_ext.keys():
        raise ValueError("bad value for 'compress', or compression format not "
                         "supported : {0}".format(compress))

    archive_name = base_name + '.tar' + compress_ext.get(compress, '')
    archive_dir = os.path.dirname(archive_name)

    if not os.path.exists(archive_dir):
        if logger is not None:
            logger.info("creating %s", archive_dir)
        if not dry_run:
            os.makedirs(archive_dir)

    # creating the tarball
    if logger is not None:
        logger.info('Creating tar archive')

    uid = _get_uid(owner)
    gid = _get_gid(group)

    def _set_uid_gid(tarinfo):
        if gid is not None:
            tarinfo.gid = gid
            tarinfo.gname = group
        if uid is not None:
            tarinfo.uid = uid
            tarinfo.uname = owner
        return tarinfo

    if not dry_run:
        tar = tarfile.open(archive_name, 'w|%s' % tar_compression[compress])
        try:
            tar.add(base_dir, filter=_set_uid_gid)
        finally:
            tar.close()

    return archive_name

def _call_external_zip(base_dir: str, zip_filename: str, verbose: bool = False,
                       dry_run: bool = False) -> None:
    # XXX see if we want to keep an external call here
    if verbose:
        zipoptions = "-r"
    else:
        zipoptions = "-rq"
    from distutils.errors import DistutilsExecError
    from distutils.spawn import spawn
    try:
        spawn(["zip", zipoptions, zip_filename, base_dir], dry_run=dry_run)
    except DistutilsExecError:
        # XXX really should distinguish between "couldn't find
        # external 'zip' command" and "zip failed".
        raise ExecError(("unable to create zip file '%s': "
            "could neither import the 'zipfile' module nor "
            "find a standalone zip utility") % zip_filename)

def _make_zipfile(base_name: str, base_dir: str, verbose: bool = False,
                  dry_run: bool = False, logger: Any = None) -> str:
    """Create a zip file from all the files under 'base_dir'.

    The output zip file will be named 'base_name' + ".zip".  Uses either the
    "zipfile" Python module (if available) or the InfoZIP "zip" utility
    (if installed and found on the default search path).  If neither tool is
    available, raises ExecError.  Returns the name of the output zip
    file.
    """
    zip_filename = base_name + ".zip"
    archive_dir = os.path.dirname(base_name)

    if not os.path.exists(archive_dir):
        if logger is not None:
            logger.info("creating %s", archive_dir)
        if not dry_run:
            os.makedirs(archive_dir)

    # If zipfile module is not available, try spawning an external 'zip'
    # command.
    try:
        import zipfile
    except ImportError:
        zipfile = None

    if zipfile is None:
        _call_external_zip(base_dir, zip_filename, verbose, dry_run)
    else:
        if logger is not None:
            logger.info("creating '%s' and adding '%s' to it",
                        zip_filename, base_dir)

        if not dry_run:
            zip = zipfile.ZipFile(zip_filename, "w",
                                  compression=zipfile.ZIP_DEFLATED)

            for dirpath, dirnames, filenames in os.walk(base_dir):
                for name in filenames:
                    path = os.path.normpath(os.path.join(dirpath, name))
                    if os.path.isfile(path):
                        zip.write(path, path)
                        if logger is not None:
                            logger.info("adding '%s'", path)
            zip.close()

    return zip_filename

_ARCHIVE_FORMATS = {
    'gztar': (_make_tarball, [('compress', 'gzip')], "gzip'ed tar-file"),
    'tar':   (_make_tarball, [('compress', None)], "uncompressed tar file"),
    'zip':   (_make_zipfile, [],"ZIP file")
    } # type: Dict[str, Tuple[Any, Sequence[Tuple[str, str]], str]]

if _BZ2_SUPPORTED:
    _ARCHIVE_FORMATS['bztar'] = (_make_tarball, [('compress', 'bzip2')],
                                "bzip2'ed tar-file")

def get_archive_formats() -> List[Tuple[str, str]]:
    """Returns a list of supported formats for archiving and unarchiving.

    Each element of the returned sequence is a tuple (name, description)
    """
    formats = [(name, registry[2]) for name, registry in
               _ARCHIVE_FORMATS.items()]
    formats.sort()
    return formats

def register_archive_format(name: str, function: Any,
                            extra_args: Sequence[Tuple[str, Any]] = None,
                            description: str = '') -> None:
    """Registers an archive format.

    name is the name of the format. function is the callable that will be
    used to create archives. If provided, extra_args is a sequence of
    (name, value) tuples that will be passed as arguments to the callable.
    description can be provided to describe the format, and will be returned
    by the get_archive_formats() function.
    """
    if extra_args is None:
        extra_args = []
    if not callable(function):
        raise TypeError('The %s object is not callable' % function)
    if not isinstance(extra_args, (tuple, list)):
        raise TypeError('extra_args needs to be a sequence')
    for element in extra_args:
        if not isinstance(element, (tuple, list)) or len(cast(tuple, element)) !=2 :
            raise TypeError('extra_args elements are : (arg_name, value)')

    _ARCHIVE_FORMATS[name] = (function, extra_args, description)

def unregister_archive_format(name: str) -> None:
    del _ARCHIVE_FORMATS[name]

def make_archive(base_name: str, format: str, root_dir: str = None,
                 base_dir: str = None, verbose: bool = False,
                 dry_run: bool = False, owner: str = None,
                 group: str = None, logger: Any = None) -> str:
    """Create an archive file (eg. zip or tar).

    'base_name' is the name of the file to create, minus any format-specific
    extension; 'format' is the archive format: one of "zip", "tar", "bztar"
    or "gztar".

    'root_dir' is a directory that will be the root directory of the
    archive; ie. we typically chdir into 'root_dir' before creating the
    archive.  'base_dir' is the directory where we start archiving from;
    ie. 'base_dir' will be the common prefix of all files and
    directories in the archive.  'root_dir' and 'base_dir' both default
    to the current directory.  Returns the name of the archive file.

    'owner' and 'group' are used when creating a tar archive. By default,
    uses the current owner and group.
    """
    save_cwd = os.getcwd()
    if root_dir is not None:
        if logger is not None:
            logger.debug("changing into '%s'", root_dir)
        base_name = os.path.abspath(base_name)
        if not dry_run:
            os.chdir(root_dir)

    if base_dir is None:
        base_dir = os.curdir

    kwargs = {'dry_run': dry_run, 'logger': logger}

    try:
        format_info = _ARCHIVE_FORMATS[format]
    except KeyError:
        raise ValueError("unknown archive format '%s'" % format)

    func = format_info[0]
    for arg, val in format_info[1]:
        kwargs[arg] = val

    if format != 'zip':
        kwargs['owner'] = owner
        kwargs['group'] = group

    try:
        filename = func(base_name, base_dir, **kwargs)
    finally:
        if root_dir is not None:
            if logger is not None:
                logger.debug("changing back to '%s'", save_cwd)
            os.chdir(save_cwd)

    return filename


def get_unpack_formats() -> List[Tuple[str, List[str], str]]:
    """Returns a list of supported formats for unpacking.

    Each element of the returned sequence is a tuple
    (name, extensions, description)
    """
    formats = [(name, info[0], info[3]) for name, info in
               _UNPACK_FORMATS.items()]
    formats.sort()
    return formats

def _check_unpack_options(extensions: List[str], function: Any,
                          extra_args: Sequence[Tuple[str, Any]]) -> None:
    """Checks what gets registered as an unpacker."""
    # first make sure no other unpacker is registered for this extension
    existing_extensions = Dict[str, str]()
    for name, info in _UNPACK_FORMATS.items():
        for ext in info[0]:
            existing_extensions[ext] = name

    for extension in extensions:
        if extension in existing_extensions:
            msg = '%s is already registered for "%s"'
            raise RegistryError(msg % (extension,
                                       existing_extensions[extension]))

    if not callable(function):
        raise TypeError('The registered function must be a callable')


def register_unpack_format(name: str, extensions: List[str], function: Any,
                           extra_args: Sequence[Tuple[str, Any]] = None,
                           description: str = '') -> None:
    """Registers an unpack format.

    `name` is the name of the format. `extensions` is a list of extensions
    corresponding to the format.

    `function` is the callable that will be
    used to unpack archives. The callable will receive archives to unpack.
    If it's unable to handle an archive, it needs to raise a ReadError
    exception.

    If provided, `extra_args` is a sequence of
    (name, value) tuples that will be passed as arguments to the callable.
    description can be provided to describe the format, and will be returned
    by the get_unpack_formats() function.
    """
    if extra_args is None:
        extra_args = []
    _check_unpack_options(extensions, function, extra_args)
    _UNPACK_FORMATS[name] = extensions, function, extra_args, description

def unregister_unpack_format(name: str) -> None:
    """Removes the pack format from the registery."""
    del _UNPACK_FORMATS[name]

def _ensure_directory(path: str) -> None:
    """Ensure that the parent directory of `path` exists"""
    dirname = os.path.dirname(path)
    if not os.path.isdir(dirname):
        os.makedirs(dirname)

def _unpack_zipfile(filename: str, extract_dir: str) -> None:
    """Unpack zip `filename` to `extract_dir`
    """
    try:
        import zipfile
    except ImportError:
        raise ReadError('zlib not supported, cannot unpack this archive.')

    if not zipfile.is_zipfile(filename):
        raise ReadError("%s is not a zip file" % filename)

    zip = zipfile.ZipFile(filename)
    try:
        for info in zip.infolist():
            name = info.filename

            # don't extract absolute paths or ones with .. in them
            if name.startswith('/') or '..' in name:
                continue

            target = os.path.join(extract_dir, *name.split('/'))
            if not target:
                continue

            _ensure_directory(target)
            if not name.endswith('/'):
                # file
                data = zip.read(info.filename)
                f = open(target,'wb')
                try:
                    f.write(data)
                finally:
                    f.close()
                    data = None
    finally:
        zip.close()

def _unpack_tarfile(filename: str, extract_dir: str) -> None:
    """Unpack tar/tar.gz/tar.bz2 `filename` to `extract_dir`
    """
    try:
        tarobj = tarfile.open(filename)
    except tarfile.TarError:
        raise ReadError(
            "%s is not a compressed or uncompressed tar file" % filename)
    try:
        tarobj.extractall(extract_dir)
    finally:
        tarobj.close()

_UNPACK_FORMATS = {
    'gztar': (['.tar.gz', '.tgz'], _unpack_tarfile, [], "gzip'ed tar-file"),
    'tar':   (['.tar'], _unpack_tarfile, [], "uncompressed tar file"),
    'zip':   (['.zip'], _unpack_zipfile, [], "ZIP file")
    } # type: Dict[str, Tuple[List[str], Any, Sequence[Tuple[str, Any]], str]]

if _BZ2_SUPPORTED:
    _UNPACK_FORMATS['bztar'] = (['.bz2'], _unpack_tarfile, [],
                                "bzip2'ed tar-file")

def _find_unpack_format(filename: str) -> str:
    for name, info in _UNPACK_FORMATS.items():
        for extension in info[0]:
            if filename.endswith(extension):
                return name
    return None

def unpack_archive(filename: str, extract_dir: str = None,
                   format: str = None) -> None:
    """Unpack an archive.

    `filename` is the name of the archive.

    `extract_dir` is the name of the target directory, where the archive
    is unpacked. If not provided, the current working directory is used.

    `format` is the archive format: one of "zip", "tar", or "gztar". Or any
    other registered format. If not provided, unpack_archive will use the
    filename extension and see if an unpacker was registered for that
    extension.

    In case none is found, a ValueError is raised.
    """
    if extract_dir is None:
        extract_dir = os.getcwd()

    if format is not None:
        try:
            format_info = _UNPACK_FORMATS[format]
        except KeyError:
            raise ValueError("Unknown unpack format '{0}'".format(format))

        func = format_info[1]
        func(filename, extract_dir, **dict(format_info[2]))
    else:
        # we need to look at the registered unpackers supported extensions
        format = _find_unpack_format(filename)
        if format is None:
            raise ReadError("Unknown archive format '{0}'".format(filename))

        func = _UNPACK_FORMATS[format][1]
        kwargs = dict(_UNPACK_FORMATS[format][2])
        func(filename, extract_dir, **kwargs)

########NEW FILE########
__FILENAME__ = subprocess
# subprocess - Subprocesses with accessible I/O streams
#
# For more information about this module, see PEP 324.
#
# Copyright (c) 2003-2005 by Peter Astrand <astrand@lysator.liu.se>
#
# Licensed to PSF under a Contributor Agreement.
# See http://www.python.org/2.4/license for licensing details.

r"""subprocess - Subprocesses with accessible I/O streams

This module allows you to spawn processes, connect to their
input/output/error pipes, and obtain their return codes.  This module
intends to replace several other, older modules and functions, like:

os.system
os.spawn*

Information about how the subprocess module can be used to replace these
modules and functions can be found below.



Using the subprocess module
===========================
This module defines one class called Popen:

class Popen(args, bufsize=0, executable=None,
            stdin=None, stdout=None, stderr=None,
            preexec_fn=None, close_fds=True, shell=False,
            cwd=None, env=None, universal_newlines=False,
            startupinfo=None, creationflags=0,
            restore_signals=True, start_new_session=False, pass_fds=()):


Arguments are:

args should be a string, or a sequence of program arguments.  The
program to execute is normally the first item in the args sequence or
string, but can be explicitly set by using the executable argument.

On POSIX, with shell=False (default): In this case, the Popen class
uses os.execvp() to execute the child program.  args should normally
be a sequence.  A string will be treated as a sequence with the string
as the only item (the program to execute).

On POSIX, with shell=True: If args is a string, it specifies the
command string to execute through the shell.  If args is a sequence,
the first item specifies the command string, and any additional items
will be treated as additional shell arguments.

On Windows: the Popen class uses CreateProcess() to execute the child
program, which operates on strings.  If args is a sequence, it will be
converted to a string using the list2cmdline method.  Please note that
not all MS Windows applications interpret the command line the same
way: The list2cmdline is designed for applications using the same
rules as the MS C runtime.

bufsize, if given, has the same meaning as the corresponding argument
to the built-in open() function: 0 means unbuffered, 1 means line
buffered, any other positive value means use a buffer of
(approximately) that size.  A negative bufsize means to use the system
default, which usually means fully buffered.  The default value for
bufsize is 0 (unbuffered).

stdin, stdout and stderr specify the executed programs' standard
input, standard output and standard error file handles, respectively.
Valid values are PIPE, an existing file descriptor (a positive
integer), an existing file object, and None.  PIPE indicates that a
new pipe to the child should be created.  With None, no redirection
will occur; the child's file handles will be inherited from the
parent.  Additionally, stderr can be STDOUT, which indicates that the
stderr data from the applications should be captured into the same
file handle as for stdout.

On POSIX, if preexec_fn is set to a callable object, this object will be
called in the child process just before the child is executed.  The use
of preexec_fn is not thread safe, using it in the presence of threads
could lead to a deadlock in the child process before the new executable
is executed.

If close_fds is true, all file descriptors except 0, 1 and 2 will be
closed before the child process is executed.  The default for close_fds
varies by platform:  Always true on POSIX.  True when stdin/stdout/stderr
are None on Windows, false otherwise.

pass_fds is an optional sequence of file descriptors to keep open between the
parent and child.  Providing any pass_fds implicitly sets close_fds to true.

if shell is true, the specified command will be executed through the
shell.

If cwd is not None, the current directory will be changed to cwd
before the child is executed.

On POSIX, if restore_signals is True all signals that Python sets to
SIG_IGN are restored to SIG_DFL in the child process before the exec.
Currently this includes the SIGPIPE, SIGXFZ and SIGXFSZ signals.  This
parameter does nothing on Windows.

On POSIX, if start_new_session is True, the setsid() system call will be made
in the child process prior to executing the command.

If env is not None, it defines the environment variables for the new
process.

If universal_newlines is true, the file objects stdout and stderr are
opened as a text files, but lines may be terminated by any of '\n',
the Unix end-of-line convention, '\r', the old Macintosh convention or
'\r\n', the Windows convention.  All of these external representations
are seen as '\n' by the Python program.  Note: This feature is only
available if Python is built with universal newline support (the
default).  Also, the newlines attribute of the file objects stdout,
stdin and stderr are not updated by the communicate() method.

The startupinfo and creationflags, if given, will be passed to the
underlying CreateProcess() function.  They can specify things such as
appearance of the main window and priority for the new process.
(Windows only)


This module also defines some shortcut functions:

call(*popenargs, **kwargs):
    Run command with arguments.  Wait for command to complete, then
    return the returncode attribute.

    The arguments are the same as for the Popen constructor.  Example:

    >>> retcode = subprocess.call(["ls", "-l"])

check_call(*popenargs, **kwargs):
    Run command with arguments.  Wait for command to complete.  If the
    exit code was zero then return, otherwise raise
    CalledProcessError.  The CalledProcessError object will have the
    return code in the returncode attribute.

    The arguments are the same as for the Popen constructor.  Example:

    >>> subprocess.check_call(["ls", "-l"])
    0

getstatusoutput(cmd):
    Return (status, output) of executing cmd in a shell.

    Execute the string 'cmd' in a shell with os.popen() and return a 2-tuple
    (status, output).  cmd is actually run as '{ cmd ; } 2>&1', so that the
    returned output will contain output or error messages. A trailing newline
    is stripped from the output. The exit status for the command can be
    interpreted according to the rules for the C function wait().  Example:

    >>> subprocess.getstatusoutput('ls /bin/ls')
    (0, '/bin/ls')
    >>> subprocess.getstatusoutput('cat /bin/junk')
    (256, 'cat: /bin/junk: No such file or directory')
    >>> subprocess.getstatusoutput('/bin/junk')
    (256, 'sh: /bin/junk: not found')

getoutput(cmd):
    Return output (stdout or stderr) of executing cmd in a shell.

    Like getstatusoutput(), except the exit status is ignored and the return
    value is a string containing the command's output.  Example:

    >>> subprocess.getoutput('ls /bin/ls')
    '/bin/ls'

check_output(*popenargs, **kwargs):
    Run command with arguments and return its output as a byte string.

    If the exit code was non-zero it raises a CalledProcessError.  The
    CalledProcessError object will have the return code in the returncode
    attribute and output in the output attribute.

    The arguments are the same as for the Popen constructor.  Example:

    >>> output = subprocess.check_output(["ls", "-l", "/dev/null"])


Exceptions
----------
Exceptions raised in the child process, before the new program has
started to execute, will be re-raised in the parent.  Additionally,
the exception object will have one extra attribute called
'child_traceback', which is a string containing traceback information
from the childs point of view.

The most common exception raised is OSError.  This occurs, for
example, when trying to execute a non-existent file.  Applications
should prepare for OSErrors.

A ValueError will be raised if Popen is called with invalid arguments.

check_call() and check_output() will raise CalledProcessError, if the
called process returns a non-zero return code.


Security
--------
Unlike some other popen functions, this implementation will never call
/bin/sh implicitly.  This means that all characters, including shell
metacharacters, can safely be passed to child processes.


Popen objects
=============
Instances of the Popen class have the following methods:

poll()
    Check if child process has terminated.  Returns returncode
    attribute.

wait()
    Wait for child process to terminate.  Returns returncode attribute.

communicate(input=None)
    Interact with process: Send data to stdin.  Read data from stdout
    and stderr, until end-of-file is reached.  Wait for process to
    terminate.  The optional input argument should be a string to be
    sent to the child process, or None, if no data should be sent to
    the child.

    communicate() returns a tuple (stdout, stderr).

    Note: The data read is buffered in memory, so do not use this
    method if the data size is large or unlimited.

The following attributes are also available:

stdin
    If the stdin argument is PIPE, this attribute is a file object
    that provides input to the child process.  Otherwise, it is None.

stdout
    If the stdout argument is PIPE, this attribute is a file object
    that provides output from the child process.  Otherwise, it is
    None.

stderr
    If the stderr argument is PIPE, this attribute is file object that
    provides error output from the child process.  Otherwise, it is
    None.

pid
    The process ID of the child process.

returncode
    The child return code.  A None value indicates that the process
    hasn't terminated yet.  A negative value -N indicates that the
    child was terminated by signal N (POSIX only).


Replacing older functions with the subprocess module
====================================================
In this section, "a ==> b" means that b can be used as a replacement
for a.

Note: All functions in this section fail (more or less) silently if
the executed program cannot be found; this module raises an OSError
exception.

In the following examples, we assume that the subprocess module is
imported with "from subprocess import *".


Replacing /bin/sh shell backquote
---------------------------------
output=`mycmd myarg`
==>
output = Popen(["mycmd", "myarg"], stdout=PIPE).communicate()[0]


Replacing shell pipe line
-------------------------
output=`dmesg | grep hda`
==>
p1 = Popen(["dmesg"], stdout=PIPE)
p2 = Popen(["grep", "hda"], stdin=p1.stdout, stdout=PIPE)
output = p2.communicate()[0]


Replacing os.system()
---------------------
sts = os.system("mycmd" + " myarg")
==>
p = Popen("mycmd" + " myarg", shell=True)
pid, sts = os.waitpid(p.pid, 0)

Note:

* Calling the program through the shell is usually not required.

* It's easier to look at the returncode attribute than the
  exitstatus.

A more real-world example would look like this:

try:
    retcode = call("mycmd" + " myarg", shell=True)
    if retcode < 0:
        print("Child was terminated by signal", -retcode, file=sys.stderr)
    else:
        print("Child returned", retcode, file=sys.stderr)
except OSError as e:
    print("Execution failed:", e, file=sys.stderr)


Replacing os.spawn*
-------------------
P_NOWAIT example:

pid = os.spawnlp(os.P_NOWAIT, "/bin/mycmd", "mycmd", "myarg")
==>
pid = Popen(["/bin/mycmd", "myarg"]).pid


P_WAIT example:

retcode = os.spawnlp(os.P_WAIT, "/bin/mycmd", "mycmd", "myarg")
==>
retcode = call(["/bin/mycmd", "myarg"])


Vector example:

os.spawnvp(os.P_NOWAIT, path, args)
==>
Popen([path] + args[1:])


Environment example:

os.spawnlpe(os.P_NOWAIT, "/bin/mycmd", "mycmd", "myarg", env)
==>
Popen(["/bin/mycmd", "myarg"], env={"PATH": "/usr/bin"})
"""

import sys
mswindows = (sys.platform == "win32")

import io
import os
import traceback
import gc
import signal
import builtins
import warnings
import errno

from typing import (
    Any, Tuple, List, Sequence, Undefined, Function, Mapping, cast, Set, Dict,
    IO, TextIO, Traceback, AnyStr
)

# Exception classes used by this module.
class CalledProcessError(Exception):
    """This exception is raised when a process run by check_call() or
    check_output() returns a non-zero exit status.
    The exit status will be stored in the returncode attribute;
    check_output() will also store the output in the output attribute.
    """
    def __init__(self, returncode: int, cmd: str, output: Any = None) -> None:
        self.returncode = returncode
        self.cmd = cmd
        self.output = output
    def __str__(self) -> str:
        return "Command '%s' returned non-zero exit status %d" % (self.cmd, self.returncode)


if mswindows:
    import threading
    import msvcrt
    import _subprocess
    class STARTUPINFO:
        dwFlags = 0
        hStdInput = Any(None)
        hStdOutput = Any(None)
        hStdError = Any(None)
        wShowWindow = 0
    class pywintypes:
        error = IOError
else:
    import select
    _has_poll = hasattr(select, 'poll')
    import fcntl
    import pickle

    try:
        import _posixsubprocess
        have_posixsubprocess = True
    except ImportError:
        have_posixsubprocess = False
        warnings.warn("The _posixsubprocess module is not being used. "
                      "Child process reliability may suffer if your "
                      "program uses threads.", RuntimeWarning)

    # When select or poll has indicated that the file is writable,
    # we can write up to _PIPE_BUF bytes without risk of blocking.
    # POSIX defines PIPE_BUF as >= 512.
    _PIPE_BUF = getattr(select, 'PIPE_BUF', 512) # type: int

    _FD_CLOEXEC = getattr(fcntl, 'FD_CLOEXEC', 1) # type: int

    def _set_cloexec(fd: int, cloexec: bool) -> None:
        old = fcntl.fcntl(fd, fcntl.F_GETFD)
        if cloexec:
            fcntl.fcntl(fd, fcntl.F_SETFD, old | _FD_CLOEXEC)
        else:
            fcntl.fcntl(fd, fcntl.F_SETFD, old & ~_FD_CLOEXEC)

    if have_posixsubprocess:
        _create_pipe = _posixsubprocess.cloexec_pipe
    else:
        def __create_pipe() -> Tuple[int, int]:
            fds = os.pipe()
            _set_cloexec(fds[0], True)
            _set_cloexec(fds[1], True)
            return fds
        _create_pipe = __create_pipe

__all__ = ["Popen", "PIPE", "STDOUT", "call", "check_call", "getstatusoutput",
           "getoutput", "check_output", "CalledProcessError"]

if mswindows:
    from _subprocess import (CREATE_NEW_CONSOLE, CREATE_NEW_PROCESS_GROUP,
                             STD_INPUT_HANDLE, STD_OUTPUT_HANDLE,
                             STD_ERROR_HANDLE, SW_HIDE,
                             STARTF_USESTDHANDLES, STARTF_USESHOWWINDOW)

    __all__.extend(["CREATE_NEW_CONSOLE", "CREATE_NEW_PROCESS_GROUP",
                    "STD_INPUT_HANDLE", "STD_OUTPUT_HANDLE",
                    "STD_ERROR_HANDLE", "SW_HIDE",
                    "STARTF_USESTDHANDLES", "STARTF_USESHOWWINDOW"])
try:
    MAXFD = os.sysconf("SC_OPEN_MAX")
except:
    MAXFD = 256

# This lists holds Popen instances for which the underlying process had not
# exited at the time its __del__ method got called: those processes are wait()ed
# for synchronously from _cleanup() when a new Popen object is created, to avoid
# zombie processes.
_active = List['Popen']()

def _cleanup() -> None:
    for inst in _active[:]:
        res = inst._internal_poll(_deadstate=sys.maxsize)
        if res is not None:
            try:
                _active.remove(inst)
            except ValueError:
                # This can happen if two threads create a new Popen instance.
                # It's harmless that it was already removed, so ignore.
                pass

PIPE = -1
STDOUT = -2


def _eintr_retry_call(func: Any, *args: Any) -> Any:
    while True:
        try:
            return func(*args)
        except (OSError, IOError) as e:
            if e.errno == errno.EINTR:
                continue
            raise


def call(*popenargs: Any, **kwargs: Any) -> int:
    """Run command with arguments.  Wait for command to complete, then
    return the returncode attribute.

    The arguments are the same as for the Popen constructor.  Example:

    retcode = call(["ls", "-l"])
    """
    return Popen(*popenargs, **kwargs).wait()


def check_call(*popenargs: Any, **kwargs: Any) -> int:
    """Run command with arguments.  Wait for command to complete.  If
    the exit code was zero then return, otherwise raise
    CalledProcessError.  The CalledProcessError object will have the
    return code in the returncode attribute.

    The arguments are the same as for the Popen constructor.  Example:

    check_call(["ls", "-l"])
    """
    retcode = call(*popenargs, **kwargs)
    if retcode:
        cmd = kwargs.get("args")
        if cmd is None:
            cmd = popenargs[0]
        raise CalledProcessError(retcode, cmd)
    return 0


def check_output(*popenargs: Any, **kwargs: Any) -> bytes:
    r"""Run command with arguments and return its output as a byte string.

    If the exit code was non-zero it raises a CalledProcessError.  The
    CalledProcessError object will have the return code in the returncode
    attribute and output in the output attribute.

    The arguments are the same as for the Popen constructor.  Example:

    >>> check_output(["ls", "-l", "/dev/null"])
    b'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\n'

    The stdout argument is not allowed as it is used internally.
    To capture standard error in the result, use stderr=STDOUT.

    >>> check_output(["/bin/sh", "-c",
    ...               "ls -l non_existent_file ; exit 0"],
    ...              stderr=STDOUT)
    b'ls: non_existent_file: No such file or directory\n'
    """
    if 'stdout' in kwargs:
        raise ValueError('stdout argument not allowed, it will be overridden.')
    kwargs['stdout'] = PIPE
    process = Popen(*popenargs, **kwargs)
    output, unused_err = process.communicate()
    retcode = process.poll()
    if retcode:
        cmd = kwargs.get("args")
        if cmd is None:
            cmd = popenargs[0]
        raise CalledProcessError(retcode, cmd, output=output)
    return output


def list2cmdline(seq: Sequence[str]) -> str:
    """
    Translate a sequence of arguments into a command line
    string, using the same rules as the MS C runtime:

    1) Arguments are delimited by white space, which is either a
       space or a tab.

    2) A string surrounded by double quotation marks is
       interpreted as a single argument, regardless of white space
       contained within.  A quoted string can be embedded in an
       argument.

    3) A double quotation mark preceded by a backslash is
       interpreted as a literal double quotation mark.

    4) Backslashes are interpreted literally, unless they
       immediately precede a double quotation mark.

    5) If backslashes immediately precede a double quotation mark,
       every pair of backslashes is interpreted as a literal
       backslash.  If the number of backslashes is odd, the last
       backslash escapes the next double quotation mark as
       described in rule 3.
    """

    # See
    # http://msdn.microsoft.com/en-us/library/17w5ykft.aspx
    # or search http://msdn.microsoft.com for
    # "Parsing C++ Command-Line Arguments"
    result = List[str]()
    needquote = False
    for arg in seq:
        bs_buf = List[str]()

        # Add a space to separate this argument from the others
        if result:
            result.append(' ')

        needquote = (" " in arg) or ("\t" in arg) or not arg
        if needquote:
            result.append('"')

        for c in arg:
            if c == '\\':
                # Don't know if we need to double yet.
                bs_buf.append(c)
            elif c == '"':
                # Double backslashes.
                result.append('\\' * len(bs_buf)*2)
                bs_buf = []
                result.append('\\"')
            else:
                # Normal char
                if bs_buf:
                    result.extend(bs_buf)
                    bs_buf = []
                result.append(c)

        # Add remaining backslashes, if any.
        if bs_buf:
            result.extend(bs_buf)

        if needquote:
            result.extend(bs_buf)
            result.append('"')

    return ''.join(result)


# Various tools for executing commands and looking at their output and status.
#
# NB This only works (and is only relevant) for POSIX.

def getstatusoutput(cmd: str) -> Tuple[int, str]:
    """Return (status, output) of executing cmd in a shell.

    Execute the string 'cmd' in a shell with os.popen() and return a 2-tuple
    (status, output).  cmd is actually run as '{ cmd ; } 2>&1', so that the
    returned output will contain output or error messages.  A trailing newline
    is stripped from the output.  The exit status for the command can be
    interpreted according to the rules for the C function wait().  Example:

    >>> import subprocess
    >>> subprocess.getstatusoutput('ls /bin/ls')
    (0, '/bin/ls')
    >>> subprocess.getstatusoutput('cat /bin/junk')
    (256, 'cat: /bin/junk: No such file or directory')
    >>> subprocess.getstatusoutput('/bin/junk')
    (256, 'sh: /bin/junk: not found')
    """
    pipe = os.popen('{ ' + cmd + '; } 2>&1', 'r')
    text = pipe.read()
    sts = pipe.close()
    if sts is None: sts = 0
    if text[-1:] == '\n': text = text[:-1]
    return sts, text


def getoutput(cmd: str) -> str:
    """Return output (stdout or stderr) of executing cmd in a shell.

    Like getstatusoutput(), except the exit status is ignored and the return
    value is a string containing the command's output.  Example:

    >>> import subprocess
    >>> subprocess.getoutput('ls /bin/ls')
    '/bin/ls'
    """
    return getstatusoutput(cmd)[1]


_PLATFORM_DEFAULT_CLOSE_FDS = object()


class Popen(object):
    def __init__(self, args: Sequence[Any], bufsize: int = 0,
                 executable: str = None, stdin: Any = None,
                 stdout: Any = None, stderr: Any = None,
                 preexec_fn: Function[[], Any] = None,
                 close_fds: Any = _PLATFORM_DEFAULT_CLOSE_FDS,
                 shell: int = False, cwd: str = None,
                 env: Mapping[str, str] = None,
                 universal_newlines: int = False,
                 startupinfo: 'STARTUPINFO' = None, creationflags: int = 0,
                 restore_signals: bool = True, start_new_session: bool = False,
                 pass_fds: Any = ()) -> None:
        """Create new Popen instance."""
        _cleanup()

        self._child_created = False
        if bufsize is None:
            bufsize = 0  # Restore default
        if not isinstance(bufsize, int):
            raise TypeError("bufsize must be an integer")

        if mswindows:
            if preexec_fn is not None:
                raise ValueError("preexec_fn is not supported on Windows "
                                 "platforms")
            any_stdio_set = (stdin is not None or stdout is not None or
                             stderr is not None)
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                if any_stdio_set:
                    close_fds = False
                else:
                    close_fds = True
            elif close_fds and any_stdio_set:
                raise ValueError(
                        "close_fds is not supported on Windows platforms"
                        " if you redirect stdin/stdout/stderr")
        else:
            # POSIX
            if close_fds is _PLATFORM_DEFAULT_CLOSE_FDS:
                close_fds = True
            if pass_fds and not close_fds:
                warnings.warn("pass_fds overriding close_fds.", RuntimeWarning)
                close_fds = True
            if startupinfo is not None:
                raise ValueError("startupinfo is only supported on Windows "
                                 "platforms")
            if creationflags != 0:
                raise ValueError("creationflags is only supported on Windows "
                                 "platforms")

        self.stdin = None # type: IO[Any]
        self.stdout = None # type: IO[Any]
        self.stderr = None # type: IO[Any]
        self.pid = None # type: int
        self.returncode = None # type: int
        self.universal_newlines = universal_newlines

        # Input and output objects. The general principle is like
        # this:
        #
        # Parent                   Child
        # ------                   -----
        # p2cwrite   ---stdin--->  p2cread
        # c2pread    <--stdout---  c2pwrite
        # errread    <--stderr---  errwrite
        #
        # On POSIX, the child objects are file descriptors.  On
        # Windows, these are Windows file handles.  The parent objects
        # are file descriptors on both platforms.  The parent objects
        # are -1 when not using PIPEs. The child objects are -1
        # when not redirecting.

        (p2cread, p2cwrite,
         c2pread, c2pwrite,
         errread, errwrite) = self._get_handles(stdin, stdout, stderr)

        # We wrap OS handles *before* launching the child, otherwise a
        # quickly terminating child could make our fds unwrappable
        # (see #8458).

        if mswindows:
            if p2cwrite != -1:
                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)
            if c2pread != -1:
                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)
            if errread != -1:
                errread = msvcrt.open_osfhandle(errread.Detach(), 0)

        if p2cwrite != -1:
            self.stdin = io.open(p2cwrite, 'wb', bufsize)
            if self.universal_newlines:
                self.stdin = io.TextIOWrapper(self.stdin, write_through=True)
        if c2pread != -1:
            self.stdout = io.open(c2pread, 'rb', bufsize)
            if universal_newlines:
                self.stdout = io.TextIOWrapper(self.stdout)
        if errread != -1:
            self.stderr = io.open(errread, 'rb', bufsize)
            if universal_newlines:
                self.stderr = io.TextIOWrapper(self.stderr)

        try:
            self._execute_child(args, executable, preexec_fn, close_fds,
                                pass_fds, cwd, env, universal_newlines,
                                startupinfo, creationflags, shell,
                                p2cread, p2cwrite,
                                c2pread, c2pwrite,
                                errread, errwrite,
                                restore_signals, start_new_session)
        except:
            # Cleanup if the child failed starting
            for f in filter(None, [self.stdin, self.stdout, self.stderr]):
                try:
                    f.close()
                except EnvironmentError:
                    # Ignore EBADF or other errors
                    pass
            raise


    def _translate_newlines(self, data: bytes, encoding: str) -> str:
        data = data.replace(b"\r\n", b"\n").replace(b"\r", b"\n")
        return data.decode(encoding)

    def __enter__(self) -> 'Popen':
        return self

    def __exit__(self, type: type, value: BaseException,
                 traceback: Traceback) -> bool:
        if self.stdout:
            self.stdout.close()
        if self.stderr:
            self.stderr.close()
        if self.stdin:
            self.stdin.close()
        # Wait for the process to terminate, to avoid zombies.
        self.wait()

    def __del__(self, _maxsize: int = sys.maxsize,
                _active: List['Popen'] = _active) -> None:
        # If __init__ hasn't had a chance to execute (e.g. if it
        # was passed an undeclared keyword argument), we don't
        # have a _child_created attribute at all.
        if not getattr(self, '_child_created', False):
            # We didn't get to successfully create a child process.
            return
        # In case the child hasn't been waited on, check if it's done.
        self._internal_poll(_deadstate=_maxsize)
        if self.returncode is None and _active is not None:
            # Child is still running, keep us alive until we can wait on it.
            _active.append(self)


    def communicate(self, input: Any = None) -> Tuple[Any, Any]:
        """Interact with process: Send data to stdin.  Read data from
        stdout and stderr, until end-of-file is reached.  Wait for
        process to terminate.  The optional input argument should be a
        string to be sent to the child process, or None, if no data
        should be sent to the child.

        communicate() returns a tuple (stdout, stderr)."""

        # Optimization: If we are only using one pipe, or no pipe at
        # all, using select() or threads is unnecessary.
        if [self.stdin, self.stdout, self.stderr].count(None) >= 2:
            stdout = None # type: IO[Any]
            stderr = None # type: IO[Any]
            if self.stdin:
                if input:
                    try:
                        self.stdin.write(input)
                    except IOError as e:
                        if e.errno != errno.EPIPE and e.errno != errno.EINVAL:
                            raise
                self.stdin.close()
            elif self.stdout:
                stdout = _eintr_retry_call(self.stdout.read)
                self.stdout.close()
            elif self.stderr:
                stderr = _eintr_retry_call(self.stderr.read)
                self.stderr.close()
            self.wait()
            return (stdout, stderr)

        return self._communicate(input)


    def poll(self) -> int:
        return self._internal_poll()


    if mswindows:
        #
        # Windows methods
        #
        def _get_handles(self, stdin: Any, stdout: Any,
                         stderr: Any) -> Tuple[Any, Any, Any, Any, Any, Any]:
            """Construct and return tuple with IO objects:
            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite
            """
            if stdin is None and stdout is None and stderr is None:
                return (-1, -1, -1, -1, -1, -1)

            p2cread, p2cwrite = -1, -1 # type: (Any, Any)
            c2pread, c2pwrite = -1, -1 # type: (Any, Any)
            errread, errwrite = -1, -1 # type: (Any, Any)

            if stdin is None:
                p2cread = _subprocess.GetStdHandle(_subprocess.STD_INPUT_HANDLE)
                if p2cread is None:
                    p2cread, _ = _subprocess.CreatePipe(None, 0)
            elif stdin == PIPE:
                p2cread, p2cwrite = _subprocess.CreatePipe(None, 0)
            elif isinstance(stdin, int):
                p2cread = msvcrt.get_osfhandle(stdin)
            else:
                # Assuming file-like object
                p2cread = msvcrt.get_osfhandle(stdin.fileno())
            p2cread = self._make_inheritable(p2cread)

            if stdout is None:
                c2pwrite = _subprocess.GetStdHandle(_subprocess.STD_OUTPUT_HANDLE)
                if c2pwrite is None:
                    _, c2pwrite = _subprocess.CreatePipe(None, 0)
            elif stdout == PIPE:
                c2pread, c2pwrite = _subprocess.CreatePipe(None, 0)
            elif isinstance(stdout, int):
                c2pwrite = msvcrt.get_osfhandle(stdout)
            else:
                # Assuming file-like object
                c2pwrite = msvcrt.get_osfhandle(stdout.fileno())
            c2pwrite = self._make_inheritable(c2pwrite)

            if stderr is None:
                errwrite = _subprocess.GetStdHandle(_subprocess.STD_ERROR_HANDLE)
                if errwrite is None:
                    _, errwrite = _subprocess.CreatePipe(None, 0)
            elif stderr == PIPE:
                errread, errwrite = _subprocess.CreatePipe(None, 0)
            elif stderr == STDOUT:
                errwrite = c2pwrite
            elif isinstance(stderr, int):
                errwrite = msvcrt.get_osfhandle(stderr)
            else:
                # Assuming file-like object
                errwrite = msvcrt.get_osfhandle(stderr.fileno())
            errwrite = self._make_inheritable(errwrite)

            return (p2cread, p2cwrite,
                    c2pread, c2pwrite,
                    errread, errwrite)


        def _make_inheritable(self, handle: _subprocess.Handle) -> int:
            """Return a duplicate of handle, which is inheritable"""
            return _subprocess.DuplicateHandle(_subprocess.GetCurrentProcess(),
                                handle, _subprocess.GetCurrentProcess(), 0, 1,
                                _subprocess.DUPLICATE_SAME_ACCESS)


        def _find_w9xpopen(self) -> str:
            """Find and return absolut path to w9xpopen.exe"""
            w9xpopen = os.path.join(
                            os.path.dirname(_subprocess.GetModuleFileName(0)),
                                    "w9xpopen.exe")
            if not os.path.exists(w9xpopen):
                # Eeek - file-not-found - possibly an embedding
                # situation - see if we can locate it in sys.exec_prefix
                w9xpopen = os.path.join(os.path.dirname(sys.exec_prefix),
                                        "w9xpopen.exe")
                if not os.path.exists(w9xpopen):
                    raise RuntimeError("Cannot locate w9xpopen.exe, which is "
                                       "needed for Popen to work with your "
                                       "shell or platform.")
            return w9xpopen


        def _execute_child(self, args: Sequence[str], executable: str,
                           preexec_fn: Function[[], Any], close_fds: Any,
                           pass_fds: Any, cwd: str, env: Mapping[str, str],
                           universal_newlines: int,
                           startupinfo: STARTUPINFO, creationflags: int,
                           shell: int,
                           p2cread: Any, p2cwrite: Any,
                           c2pread: Any, c2pwrite: Any,
                           errread: Any, errwrite: Any,
                           restore_signals: bool,
                           start_new_session: bool) -> None:
            """Execute program (MS Windows version)"""

            assert not pass_fds, "pass_fds not supported on Windows."

            if not isinstance(args, str):
                args = list2cmdline(args)

            # Process startup details
            if startupinfo is None:
                startupinfo = STARTUPINFO()
            if -1 not in (p2cread, c2pwrite, errwrite):
                startupinfo.dwFlags |= _subprocess.STARTF_USESTDHANDLES
                startupinfo.hStdInput = p2cread
                startupinfo.hStdOutput = c2pwrite
                startupinfo.hStdError = errwrite

            if shell:
                startupinfo.dwFlags |= _subprocess.STARTF_USESHOWWINDOW
                startupinfo.wShowWindow = _subprocess.SW_HIDE
                comspec = os.environ.get("COMSPEC", "cmd.exe")
                args = '{} /c "{}"'.format (comspec, args)
                if (_subprocess.GetVersion() >= 0x80000000 or
                        os.path.basename(comspec).lower() == "command.com"):
                    # Win9x, or using command.com on NT. We need to
                    # use the w9xpopen intermediate program. For more
                    # information, see KB Q150956
                    # (http://web.archive.org/web/20011105084002/http://support.microsoft.com/support/kb/articles/Q150/9/56.asp)
                    w9xpopen = self._find_w9xpopen()
                    args = '"%s" %s' % (w9xpopen, args)
                    # Not passing CREATE_NEW_CONSOLE has been known to
                    # cause random failures on win9x.  Specifically a
                    # dialog: "Your program accessed mem currently in
                    # use at xxx" and a hopeful warning about the
                    # stability of your system.  Cost is Ctrl+C won't
                    # kill children.
                    creationflags |= _subprocess.CREATE_NEW_CONSOLE

            # Start the process
            try:
                hp, ht, pid, tid = _subprocess.CreateProcess(executable,
                                         cast(str, args),
                                         # no special security
                                         None, None,
                                         int(not close_fds),
                                         creationflags,
                                         env,
                                         cwd,
                                         startupinfo)
            except pywintypes.error as e:
                # Translate pywintypes.error to WindowsError, which is
                # a subclass of OSError.  FIXME: We should really
                # translate errno using _sys_errlist (or similar), but
                # how can this be done from Python?
                raise WindowsError(*e.args)
            finally:
                # Child is launched. Close the parent's copy of those pipe
                # handles that only the child should have open.  You need
                # to make sure that no handles to the write end of the
                # output pipe are maintained in this process or else the
                # pipe will not close when the child process exits and the
                # ReadFile will hang.
                if p2cread != -1:
                    p2cread.Close()
                if c2pwrite != -1:
                    c2pwrite.Close()
                if errwrite != -1:
                    errwrite.Close()

            # Retain the process handle, but close the thread handle
            self._child_created = True
            self._handle = hp
            self.pid = pid
            ht.Close()

        def _internal_poll(self, _deadstate: int = None) -> int:
            """Check if child process has terminated.  Returns returncode
            attribute.

            This method is called by __del__, so it can only refer to objects
            in its local scope.

            """
            return self._internal_poll_win(_deadstate)

        from _subprocess import Handle
            
        def _internal_poll_win(self, _deadstate: int = None,
                _WaitForSingleObject: Function[[Handle, int], int] =
                               _subprocess.WaitForSingleObject,
                _WAIT_OBJECT_0: int = _subprocess.WAIT_OBJECT_0,
                _GetExitCodeProcess: Function[[Handle], int] =
                                    _subprocess.GetExitCodeProcess) -> int:
            if self.returncode is None:
                if _WaitForSingleObject(self._handle, 0) == _WAIT_OBJECT_0:
                    self.returncode = _GetExitCodeProcess(self._handle)
            return self.returncode


        def wait(self) -> int:
            """Wait for child process to terminate.  Returns returncode
            attribute."""
            if self.returncode is None:
                _subprocess.WaitForSingleObject(self._handle,
                                                _subprocess.INFINITE)
                self.returncode = _subprocess.GetExitCodeProcess(self._handle)
            return self.returncode


        def _readerthread(self, fh: IO[AnyStr], buffer: List[AnyStr]) -> None:
            buffer.append(fh.read())
            fh.close()


        def _communicate(self, input: Any) -> Tuple[Any, Any]:
            stdout = Any(None) # Return
            stderr = Any(None) # Return

            if self.stdout:
                stdout = []
                stdout_thread = threading.Thread(target=self._readerthread,
                                                 args=(self.stdout, stdout))
                stdout_thread.daemon = True
                stdout_thread.start()
            if self.stderr:
                stderr = []
                stderr_thread = threading.Thread(target=self._readerthread,
                                                 args=(self.stderr, stderr))
                stderr_thread.daemon = True
                stderr_thread.start()

            if self.stdin:
                if input is not None:
                    try:
                        self.stdin.write(input)
                    except IOError as e:
                        if e.errno != errno.EPIPE:
                            raise
                self.stdin.close()

            if self.stdout:
                stdout_thread.join()
            if self.stderr:
                stderr_thread.join()

            # All data exchanged.  Translate lists into strings.
            if stdout is not None:
                stdout = stdout[0]
            if stderr is not None:
                stderr = stderr[0]

            self.wait()
            return (stdout, stderr)

        def send_signal(self, sig: int) -> None:
            """Send a signal to the process
            """
            if sig == signal.SIGTERM:
                self.terminate()
            elif sig == signal.CTRL_C_EVENT:
                os.kill(self.pid, signal.CTRL_C_EVENT)
            elif sig == signal.CTRL_BREAK_EVENT:
                os.kill(self.pid, signal.CTRL_BREAK_EVENT)
            else:
                raise ValueError("Unsupported signal: {}".format(sig))

        def terminate(self) -> None:
            """Terminates the process
            """
            _subprocess.TerminateProcess(self._handle, 1)

        def kill(self) -> None:
            """Terminates the process
            """
            self.terminate()

    else:
        #
        # POSIX methods
        #
        def _get_handles(self, stdin: Any, stdout: Any,
                         stderr: Any) -> Tuple[Any, Any, Any, Any, Any, Any]:
            """Construct and return tuple with IO objects:
            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite
            """
            p2cread, p2cwrite = -1, -1
            c2pread, c2pwrite = -1, -1
            errread, errwrite = -1, -1

            if stdin is None:
                pass
            elif stdin == PIPE:
                p2cread, p2cwrite = _create_pipe()
            elif isinstance(stdin, int):
                p2cread = stdin
            else:
                # Assuming file-like object
                p2cread = stdin.fileno()

            if stdout is None:
                pass
            elif stdout == PIPE:
                c2pread, c2pwrite = _create_pipe()
            elif isinstance(stdout, int):
                c2pwrite = stdout
            else:
                # Assuming file-like object
                c2pwrite = stdout.fileno()

            if stderr is None:
                pass
            elif stderr == PIPE:
                errread, errwrite = _create_pipe()
            elif stderr == STDOUT:
                errwrite = c2pwrite
            elif isinstance(stderr, int):
                errwrite = stderr
            else:
                # Assuming file-like object
                errwrite = stderr.fileno()

            return (p2cread, p2cwrite,
                    c2pread, c2pwrite,
                    errread, errwrite)


        def _close_fds(self, fds_to_keep: Set[int]) -> None:
            start_fd = 3
            for fd in sorted(fds_to_keep):
                if fd >= start_fd:
                    os.closerange(start_fd, fd)
                    start_fd = fd + 1
            if start_fd <= MAXFD:
                os.closerange(start_fd, MAXFD)


        def _execute_child(self, args: Sequence[str], executable: str,
                           preexec_fn: Function[[], Any], close_fds: Any,
                           pass_fds: Any, cwd: str, env: Mapping[str, str],
                           universal_newlines: int,
                           startupinfo: 'STARTUPINFO', creationflags: int,
                           shell: int,
                           p2cread: Any, p2cwrite: Any,
                           c2pread: Any, c2pwrite: Any,
                           errread: Any, errwrite: Any,
                           restore_signals: bool,
                           start_new_session: bool) -> None:
            """Execute program (POSIX version)"""

            if isinstance(args, str):
                arglist = [args]
            else:
                arglist = list(args)

            if shell:
                arglist = ["/bin/sh", "-c"] + arglist
                if executable:
                    arglist[0] = executable

            if executable is None:
                executable = arglist[0]

            # For transferring possible exec failure from child to parent.
            # Data format: "exception name:hex errno:description"
            # Pickle is not used; it is complex and involves memory allocation.
            errpipe_read, errpipe_write = _create_pipe()
            try:
                try:

                    if have_posixsubprocess:
                        # We must avoid complex work that could involve
                        # malloc or free in the child process to avoid
                        # potential deadlocks, thus we do all this here.
                        # and pass it to fork_exec()

                        if env is not None:
                            env_list = [os.fsencode(k) + b'=' + os.fsencode(v)
                                        for k, v in env.items()]
                        else:
                            env_list = None  # Use execv instead of execve.
                        executable_enc = os.fsencode(executable)
                        if os.path.dirname(executable_enc):
                            executable_list = (executable_enc,) # type: tuple
                        else:
                            # This matches the behavior of os._execvpe().
                            executable_list = tuple(
                                os.path.join(os.fsencode(dir), executable_enc)
                                for dir in os.get_exec_path(env))
                        fds_to_keep = set(pass_fds)
                        fds_to_keep.add(errpipe_write)
                        self.pid = _posixsubprocess.fork_exec(
                                arglist, executable_list,
                                close_fds, sorted(fds_to_keep), cwd, env_list,
                                p2cread, p2cwrite, c2pread, c2pwrite,
                                errread, errwrite,
                                errpipe_read, errpipe_write,
                                restore_signals, start_new_session, preexec_fn)
                        self._child_created = True
                    else:
                        # Pure Python implementation: It is not thread safe.
                        # This implementation may deadlock in the child if your
                        # parent process has any other threads running.

                        gc_was_enabled = gc.isenabled()
                        # Disable gc to avoid bug where gc -> file_dealloc ->
                        # write to stderr -> hang.  See issue1336
                        gc.disable()
                        try:
                            self.pid = os.fork()
                        except:
                            if gc_was_enabled:
                                gc.enable()
                            raise
                        self._child_created = True
                        if self.pid == 0:
                            # Child
                            try:
                                # Close parent's pipe ends
                                if p2cwrite != -1:
                                    os.close(p2cwrite)
                                if c2pread != -1:
                                    os.close(c2pread)
                                if errread != -1:
                                    os.close(errread)
                                os.close(errpipe_read)

                                # When duping fds, if there arises a situation
                                # where one of the fds is either 0, 1 or 2, it
                                # is possible that it is overwritten (#12607).
                                if c2pwrite == 0:
                                    c2pwrite = os.dup(c2pwrite)
                                if errwrite == 0 or errwrite == 1:
                                    errwrite = os.dup(errwrite)

                                # Dup fds for child
                                def _dup2(a: int, b: int) -> None:
                                    # dup2() removes the CLOEXEC flag but
                                    # we must do it ourselves if dup2()
                                    # would be a no-op (issue #10806).
                                    if a == b:
                                        _set_cloexec(a, False)
                                    elif a != -1:
                                        os.dup2(a, b)
                                _dup2(p2cread, 0)
                                _dup2(c2pwrite, 1)
                                _dup2(errwrite, 2)

                                # Close pipe fds.  Make sure we don't close the
                                # same fd more than once, or standard fds.
                                closed = Set[int]()
                                for fd in [p2cread, c2pwrite, errwrite]:
                                    if fd > 2 and fd not in closed:
                                        os.close(fd)
                                        closed.add(fd)

                                # Close all other fds, if asked for
                                if close_fds:
                                    fds_to_keep = set(pass_fds)
                                    fds_to_keep.add(errpipe_write)
                                    self._close_fds(fds_to_keep)


                                if cwd is not None:
                                    os.chdir(cwd)

                                # This is a copy of Python/pythonrun.c
                                # _Py_RestoreSignals().  If that were exposed
                                # as a sys._py_restoresignals func it would be
                                # better.. but this pure python implementation
                                # isn't likely to be used much anymore.
                                if restore_signals:
                                    signals = ('SIGPIPE', 'SIGXFZ', 'SIGXFSZ')
                                    for sig in signals:
                                        if hasattr(signal, sig):
                                            signal.signal(getattr(signal, sig),
                                                          signal.SIG_DFL)

                                if start_new_session and hasattr(os, 'setsid'):
                                    os.setsid()

                                if preexec_fn:
                                    preexec_fn()

                                if env is None:
                                    os.execvp(executable, arglist)
                                else:
                                    os.execvpe(executable, arglist, env)

                            except:
                                try:
                                    exc_type, exc_value, _ = sys.exc_info()
                                    if isinstance(exc_value, OSError):
                                        errno_num = exc_value.errno
                                    else:
                                        errno_num = 0
                                    message = '%s:%x:%s' % (exc_type.__name__,
                                                            errno_num, exc_value)
                                    messageb = message.encode(errors="surrogatepass")
                                    os.write(errpipe_write, messageb)
                                except Exception:
                                    # We MUST not allow anything odd happening
                                    # above to prevent us from exiting below.
                                    pass

                            # This exitcode won't be reported to applications
                            # so it really doesn't matter what we return.
                            os._exit(255)

                        # Parent
                        if gc_was_enabled:
                            gc.enable()
                finally:
                    # be sure the FD is closed no matter what
                    os.close(errpipe_write)

                if p2cread != -1 and p2cwrite != -1:
                    os.close(p2cread)
                if c2pwrite != -1 and c2pread != -1:
                    os.close(c2pwrite)
                if errwrite != -1 and errread != -1:
                    os.close(errwrite)

                # Wait for exec to fail or succeed; possibly raising an
                # exception (limited in size)
                data = bytearray()
                while True:
                    part = _eintr_retry_call(os.read, errpipe_read, 50000)
                    data += part
                    if not part or len(data) > 50000:
                        break
            finally:
                # be sure the FD is closed no matter what
                os.close(errpipe_read)

            if data:
                try:
                    _eintr_retry_call(os.waitpid, self.pid, 0)
                except OSError as e:
                    if e.errno != errno.ECHILD:
                        raise
                try:
                    (exception_name, hex_errno,
                     err_msg_b) = bytes(data).split(b':', 2)
                except ValueError:
                    print('Bad exception data:', repr(data))
                    exception_name = b'RuntimeError'
                    hex_errno = b'0'
                    err_msg_b = b'Unknown'
                child_exception_type = getattr(
                        builtins, exception_name.decode('ascii'),
                        RuntimeError)
                for fd in (p2cwrite, c2pread, errread):
                    if fd != -1:
                        os.close(fd)
                err_msg = err_msg_b.decode(errors="surrogatepass")
                if issubclass(child_exception_type, OSError) and hex_errno:
                    errno_num = int(hex_errno, 16)
                    if errno_num != 0:
                        err_msg = os.strerror(errno_num)
                        if errno_num == errno.ENOENT:
                            err_msg += ': ' + repr(arglist[0])
                    raise child_exception_type(errno_num, err_msg)
                raise child_exception_type(err_msg)


        def _handle_exitstatus(
                self, sts: int,
                _WIFSIGNALED: Function[[int], bool] = os.WIFSIGNALED,
                _WTERMSIG: Function[[int], bool] = os.WTERMSIG,
                _WIFEXITED: Function[[int], bool] = os.WIFEXITED,
                _WEXITSTATUS: Function[[int], bool] = os.WEXITSTATUS) -> None:
            # This method is called (indirectly) by __del__, so it cannot
            # refer to anything outside of its local scope."""
            if _WIFSIGNALED(sts):
                self.returncode = -_WTERMSIG(sts)
            elif _WIFEXITED(sts):
                self.returncode = _WEXITSTATUS(sts)
            else:
                # Should never happen
                raise RuntimeError("Unknown child exit status!")


        def _internal_poll(self, _deadstate: int = None) -> int:
            """Check if child process has terminated.  Returns returncode
            attribute.

            This method is called by __del__, so it cannot reference anything
            outside of the local scope (nor can any methods it calls).

            """
            return self._internal_poll_posix(_deadstate)
            
        def _internal_poll_posix(self, _deadstate: int = None,
                                 _waitpid: Function[[int, int],
                                                 Tuple[int, int]] = os.waitpid,
                                 _WNOHANG: int = os.WNOHANG,
                                 _os_error: Any = os.error) -> int:
            if self.returncode is None:
                try:
                    pid, sts = _waitpid(self.pid, _WNOHANG)
                    if pid == self.pid:
                        self._handle_exitstatus(sts)
                except _os_error:
                    if _deadstate is not None:
                        self.returncode = _deadstate
            return self.returncode


        def wait(self) -> int:
            """Wait for child process to terminate.  Returns returncode
            attribute."""
            if self.returncode is None:
                try:
                    pid, sts = _eintr_retry_call(os.waitpid, self.pid, 0)
                except OSError as e:
                    if e.errno != errno.ECHILD:
                        raise
                    # This happens if SIGCLD is set to be ignored or waiting
                    # for child processes has otherwise been disabled for our
                    # process.  This child is dead, we can't get the status.
                    sts = 0
                self._handle_exitstatus(sts)
            return self.returncode


        def _communicate(self, input: Any) -> Tuple[Any, Any]:
            if self.stdin:
                # Flush stdio buffer.  This might block, if the user has
                # been writing to .stdin in an uncontrolled fashion.
                self.stdin.flush()
                if not input:
                    self.stdin.close()

            if _has_poll:
                stdout, stderr = self._communicate_with_poll(input)
            else:
                stdout, stderr = self._communicate_with_select(input)

            # All data exchanged.  Translate lists into strings.
            if stdout is not None:
                stdout2 = b''.join(stdout)
            else:
                stdout2 = None
            if stderr is not None:
                stderr2 = b''.join(stderr)
            else:
                stderr2 = None

            # Translate newlines, if requested.
            # This also turns bytes into strings.
            stdout3 = Any(stdout2)
            stderr3 = Any(stderr2)
            if self.universal_newlines:
                if stdout is not None:
                    stdout3 = self._translate_newlines(
                        stdout2, cast(TextIO, self.stdout).encoding)
                if stderr is not None:
                    stderr3 = self._translate_newlines(
                        stderr2, cast(TextIO, self.stderr).encoding)

            self.wait()
            return (stdout3, stderr3)


        def _communicate_with_poll(self, input: Any) -> Tuple[List[bytes],
                                                              List[bytes]]:
            stdout = None # type: List[bytes] # Return
            stderr = None # type: List[bytes] # Return
            fd2file = Dict[int, Any]()
            fd2output = Dict[int, List[bytes]]()

            poller = select.poll()
            def register_and_append(file_obj: IO[Any], eventmask: int) -> None:
                poller.register(file_obj.fileno(), eventmask)
                fd2file[file_obj.fileno()] = file_obj

            def close_unregister_and_remove(fd: int) -> None:
                poller.unregister(fd)
                fd2file[fd].close()
                fd2file.pop(fd)

            if self.stdin and input:
                register_and_append(self.stdin, select.POLLOUT)

            select_POLLIN_POLLPRI = select.POLLIN | select.POLLPRI
            if self.stdout:
                register_and_append(self.stdout, select_POLLIN_POLLPRI)
                fd2output[self.stdout.fileno()] = stdout = []
            if self.stderr:
                register_and_append(self.stderr, select_POLLIN_POLLPRI)
                fd2output[self.stderr.fileno()] = stderr = []

            input_offset = 0
            while fd2file:
                try:
                    ready = poller.poll()
                except select.error as e:
                    if e.args[0] == errno.EINTR:
                        continue
                    raise

                # XXX Rewrite these to use non-blocking I/O on the
                # file objects; they are no longer using C stdio!

                for fd, mode in ready:
                    if mode & select.POLLOUT:
                        chunk = input[input_offset : input_offset + _PIPE_BUF]
                        try:
                            input_offset += os.write(fd, chunk)
                        except OSError as oe:
                            if oe.errno == errno.EPIPE:
                                close_unregister_and_remove(fd)
                            else:
                                raise
                        else:
                            if input_offset >= len(input):
                                close_unregister_and_remove(fd)
                    elif mode & select_POLLIN_POLLPRI:
                        data = os.read(fd, 4096)
                        if not data:
                            close_unregister_and_remove(fd)
                        fd2output[fd].append(data)
                    else:
                        # Ignore hang up or errors.
                        close_unregister_and_remove(fd)

            return (stdout, stderr)


        def _communicate_with_select(self, input: Any) -> Tuple[List[bytes],
                                                                List[bytes]]:
            read_set = List[IO[Any]]()
            write_set = List[IO[Any]]()
            stdout = None # type: List[bytes] # Return
            stderr = None # type: List[bytes] # Return

            if self.stdin and input:
                write_set.append(self.stdin)
            if self.stdout:
                read_set.append(self.stdout)
                stdout = []
            if self.stderr:
                read_set.append(self.stderr)
                stderr = []

            input_offset = 0
            while read_set or write_set:
                try:
                    rlist, wlist, xlist = select.select(read_set, write_set, [])
                except select.error as e:
                    if e.args[0] == errno.EINTR:
                        continue
                    raise

                # XXX Rewrite these to use non-blocking I/O on the
                # file objects; they are no longer using C stdio!

                if self.stdin in wlist:
                    chunk = input[input_offset : input_offset + _PIPE_BUF]
                    try:
                        bytes_written = os.write(self.stdin.fileno(), chunk)
                    except OSError as oe:
                        if oe.errno == errno.EPIPE:
                            self.stdin.close()
                            write_set.remove(self.stdin)
                        else:
                            raise
                    else:
                        input_offset += bytes_written
                        if input_offset >= len(input):
                            self.stdin.close()
                            write_set.remove(self.stdin)

                if self.stdout in rlist:
                    data = os.read(self.stdout.fileno(), 1024)
                    if not data:
                        self.stdout.close()
                        read_set.remove(self.stdout)
                    stdout.append(data)

                if self.stderr in rlist:
                    data = os.read(self.stderr.fileno(), 1024)
                    if not data:
                        self.stderr.close()
                        read_set.remove(self.stderr)
                    stderr.append(data)

            return (stdout, stderr)


        def send_signal(self, sig: int) -> None:
            """Send a signal to the process
            """
            os.kill(self.pid, sig)

        def terminate(self) -> None:
            """Terminate the process with SIGTERM
            """
            self.send_signal(signal.SIGTERM)

        def kill(self) -> None:
            """Kill the process with SIGKILL
            """
            self.send_signal(signal.SIGKILL)


def _demo_posix() -> None:
    #
    # Example 1: Simple redirection: Get process list
    #
    plist = Popen(["ps"], stdout=PIPE).communicate()[0]
    print("Process list:")
    print(plist)

    #
    # Example 2: Change uid before executing child
    #
    if os.getuid() == 0:
        p = Popen(["id"], preexec_fn=lambda: os.setuid(100))
        p.wait()

    #
    # Example 3: Connecting several subprocesses
    #
    print("Looking for 'hda'...")
    p1 = Popen(["dmesg"], stdout=PIPE)
    p2 = Popen(["grep", "hda"], stdin=p1.stdout, stdout=PIPE)
    print(repr(p2.communicate()[0]))

    #
    # Example 4: Catch execution error
    #
    print()
    print("Trying a weird file...")
    try:
        print(Popen(["/this/path/does/not/exist"]).communicate())
    except OSError as e:
        if e.errno == errno.ENOENT:
            print("The file didn't exist.  I thought so...")
        else:
            print("Error", e.errno)
    else:
        print("Gosh.  No error.", file=sys.stderr)


def _demo_windows() -> None:
    #
    # Example 1: Connecting several subprocesses
    #
    print("Looking for 'PROMPT' in set output...")
    p1 = Popen("set", stdout=PIPE, shell=True)
    p2 = Popen('find "PROMPT"', stdin=p1.stdout, stdout=PIPE)
    print(repr(p2.communicate()[0]))

    #
    # Example 2: Simple execution of program
    #
    print("Executing calc...")
    p = Popen("calc")
    p.wait()


if __name__ == "__main__":
    if mswindows:
        _demo_windows()
    else:
        _demo_posix()

########NEW FILE########
__FILENAME__ = tempfile
"""Temporary files.

This module provides generic, low- and high-level interfaces for
creating temporary files and directories.  The interfaces listed
as "safe" just below can be used without fear of race conditions.
Those listed as "unsafe" cannot, and are provided for backward
compatibility only.

This module also provides some data items to the user:

  TMP_MAX  - maximum number of names that will be tried before
             giving up.
  template - the default prefix for all temporary names.
             You may change this to control the default prefix.
  tempdir  - If this is set to a string before the first use of
             any routine from this module, it will be considered as
             another candidate location to store temporary files.
"""

__all__ = [
    "NamedTemporaryFile", "TemporaryFile", # high level safe interfaces
    "SpooledTemporaryFile", "TemporaryDirectory",
    "mkstemp", "mkdtemp",                  # low level safe interfaces
    "mktemp",                              # deprecated unsafe interface
    "TMP_MAX", "gettempprefix",            # constants
    "tempdir", "gettempdir"
   ]


# Imports.

import warnings as _warnings
import sys as _sys
import io as _io
import os as _os
import errno as _errno
from random import Random as _Random

from typing import (
    Any as _Any, Function as _Function, Iterator as _Iterator,
    Undefined as _Undefined, List as _List, Tuple as _Tuple, Dict as _Dict,
    Iterable as _Iterable, IO as _IO, ducktype as _ducktype,
    Traceback as _Traceback
)

try:
    import fcntl as _fcntl
except ImportError:
    def _set_cloexec(fd: int) -> None:
        pass
else:
    def _set_cloexec(fd: int) -> None:
        try:
            flags = _fcntl.fcntl(fd, _fcntl.F_GETFD, 0)
        except IOError:
            pass
        else:
            # flags read successfully, modify
            flags |= _fcntl.FD_CLOEXEC
            _fcntl.fcntl(fd, _fcntl.F_SETFD, flags)


try:
    import _thread
    _allocate_lock = _thread.allocate_lock # type: _Function[[], _Any]
except ImportError:
    import _dummy_thread
    _allocate_lock = _dummy_thread.allocate_lock

_text_openflags = _os.O_RDWR | _os.O_CREAT | _os.O_EXCL
if hasattr(_os, 'O_NOINHERIT'):
    _text_openflags |= _os.O_NOINHERIT
if hasattr(_os, 'O_NOFOLLOW'):
    _text_openflags |= _os.O_NOFOLLOW

_bin_openflags = _text_openflags
if hasattr(_os, 'O_BINARY'):
    _bin_openflags |= _os.O_BINARY

if hasattr(_os, 'TMP_MAX'):
    TMP_MAX = _os.TMP_MAX
else:
    TMP_MAX = 10000

template = "tmp"

# Internal routines.

_once_lock = _allocate_lock()

if hasattr(_os, "lstat"):
    _stat = _os.lstat # type: _Function[[str], object]
elif hasattr(_os, "stat"):
    _stat = _os.stat
else:
    # Fallback.  All we need is something that raises os.error if the
    # file doesn't exist.
    def __stat(fn: str) -> object:
        try:
            f = open(fn)
        except IOError:
            raise _os.error()
        f.close()
    _stat = __stat

def _exists(fn: str) -> bool:
    try:
        _stat(fn)
    except _os.error:
        return False
    else:
        return True

class _RandomNameSequence(_Iterator[str]):
    """An instance of _RandomNameSequence generates an endless
    sequence of unpredictable strings which can safely be incorporated
    into file names.  Each string is six characters long.  Multiple
    threads can safely use the same instance at the same time.

    _RandomNameSequence is an iterator."""

    characters = "abcdefghijklmnopqrstuvwxyz0123456789_"

    @property
    def rng(self) -> _Random:
        cur_pid = _os.getpid()
        if cur_pid != getattr(self, '_rng_pid', None):
            self._rng = _Random()
            self._rng_pid = cur_pid
        return self._rng

    def __iter__(self) -> _Iterator[str]:
        return self

    def __next__(self) -> str:
        c = self.characters
        choose = self.rng.choice
        letters = [choose(c) for dummy in "123456"]
        return ''.join(letters)

def _candidate_tempdir_list() -> _List[str]:
    """Generate a list of candidate temporary directories which
    _get_default_tempdir will try."""

    dirlist = [] # type: _List[str]

    # First, try the environment.
    for envname in 'TMPDIR', 'TEMP', 'TMP':
        dirname = _os.getenv(envname)
        if dirname: dirlist.append(dirname)

    # Failing that, try OS-specific locations.
    if _os.name == 'nt':
        dirlist.extend([ r'c:\temp', r'c:\tmp', r'\temp', r'\tmp' ])
    else:
        dirlist.extend([ '/tmp', '/var/tmp', '/usr/tmp' ])

    # As a last resort, the current directory.
    try:
        dirlist.append(_os.getcwd())
    except (AttributeError, _os.error):
        dirlist.append(_os.curdir)

    return dirlist

def _get_default_tempdir() -> str:
    """Calculate the default directory to use for temporary files.
    This routine should be called exactly once.

    We determine whether or not a candidate temp dir is usable by
    trying to create and write to a file in that directory.  If this
    is successful, the test file is deleted.  To prevent denial of
    service, the name of the test file must be randomized."""

    namer = _RandomNameSequence()
    dirlist = _candidate_tempdir_list()

    for dir in dirlist:
        if dir != _os.curdir:
            dir = _os.path.normcase(_os.path.abspath(dir))
        # Try only a few names per directory.
        for seq in range(100):
            name = next(namer)
            filename = _os.path.join(dir, name)
            try:
                fd = _os.open(filename, _bin_openflags, 0o600)
                fp = _io.open(fd, 'wb')
                fp.write(b'blat')
                fp.close()
                _os.unlink(filename)
                fp = fd = None
                return dir
            except (OSError, IOError) as e:
                if e.args[0] != _errno.EEXIST:
                    break # no point trying more names in this directory
                pass
    raise IOError(_errno.ENOENT,
                  "No usable temporary directory found in %s" % dirlist)

_name_sequence = None # type: _RandomNameSequence

def _get_candidate_names() -> _RandomNameSequence:
    """Common setup sequence for all user-callable interfaces."""

    global _name_sequence
    if _name_sequence is None:
        _once_lock.acquire()
        try:
            if _name_sequence is None:
                _name_sequence = _RandomNameSequence()
        finally:
            _once_lock.release()
    return _name_sequence


def _mkstemp_inner(dir: str, pre: str, suf: str,
                   flags: int) -> _Tuple[int, str]:
    """Code common to mkstemp, TemporaryFile, and NamedTemporaryFile."""

    names = _get_candidate_names()

    for seq in range(TMP_MAX):
        name = next(names)
        file = _os.path.join(dir, pre + name + suf)
        try:
            fd = _os.open(file, flags, 0o600)
            _set_cloexec(fd)
            return (fd, _os.path.abspath(file))
        except OSError as e:
            if e.errno == _errno.EEXIST:
                continue # try again
            raise

    raise IOError(_errno.EEXIST, "No usable temporary file name found")


# User visible interfaces.

def gettempprefix() -> str:
    """Accessor for tempdir.template."""
    return template

tempdir = None # type: str

def gettempdir() -> str:
    """Accessor for tempfile.tempdir."""
    global tempdir
    if tempdir is None:
        _once_lock.acquire()
        try:
            if tempdir is None:
                tempdir = _get_default_tempdir()
        finally:
            _once_lock.release()
    return tempdir

def mkstemp(suffix: str = "", prefix: str = template, dir: str = None,
            text: bool = False) -> _Tuple[int, str]:
    """User-callable function to create and return a unique temporary
    file.  The return value is a pair (fd, name) where fd is the
    file descriptor returned by os.open, and name is the filename.

    If 'suffix' is specified, the file name will end with that suffix,
    otherwise there will be no suffix.

    If 'prefix' is specified, the file name will begin with that prefix,
    otherwise a default prefix is used.

    If 'dir' is specified, the file will be created in that directory,
    otherwise a default directory is used.

    If 'text' is specified and true, the file is opened in text
    mode.  Else (the default) the file is opened in binary mode.  On
    some operating systems, this makes no difference.

    The file is readable and writable only by the creating user ID.
    If the operating system uses permission bits to indicate whether a
    file is executable, the file is executable by no one. The file
    descriptor is not inherited by children of this process.

    Caller is responsible for deleting the file when done with it.
    """

    if dir is None:
        dir = gettempdir()

    if text:
        flags = _text_openflags
    else:
        flags = _bin_openflags

    return _mkstemp_inner(dir, prefix, suffix, flags)


def mkdtemp(suffix: str = "", prefix: str = template, dir: str = None) -> str:
    """User-callable function to create and return a unique temporary
    directory.  The return value is the pathname of the directory.

    Arguments are as for mkstemp, except that the 'text' argument is
    not accepted.

    The directory is readable, writable, and searchable only by the
    creating user.

    Caller is responsible for deleting the directory when done with it.
    """

    if dir is None:
        dir = gettempdir()

    names = _get_candidate_names()

    for seq in range(TMP_MAX):
        name = next(names)
        file = _os.path.join(dir, prefix + name + suffix)
        try:
            _os.mkdir(file, 0o700)
            return file
        except OSError as e:
            if e.errno == _errno.EEXIST:
                continue # try again
            raise

    raise IOError(_errno.EEXIST, "No usable temporary directory name found")

def mktemp(suffix: str = "", prefix: str = template, dir: str = None) -> str:
    """User-callable function to return a unique temporary file name.  The
    file is not created.

    Arguments are as for mkstemp, except that the 'text' argument is
    not accepted.

    This function is unsafe and should not be used.  The file name
    refers to a file that did not exist at some point, but by the time
    you get around to creating it, someone else may have beaten you to
    the punch.
    """

##    from warnings import warn as _warn
##    _warn("mktemp is a potential security risk to your program",
##          RuntimeWarning, stacklevel=2)

    if dir is None:
        dir = gettempdir()

    names = _get_candidate_names()
    for seq in range(TMP_MAX):
        name = next(names)
        file = _os.path.join(dir, prefix + name + suffix)
        if not _exists(file):
            return file

    raise IOError(_errno.EEXIST, "No usable temporary filename found")


@_ducktype(_IO[_Any])
class _TemporaryFileWrapper:
    """Temporary file wrapper

    This class provides a wrapper around files opened for
    temporary use.  In particular, it seeks to automatically
    remove the file when it is no longer needed.
    """

    def __init__(self, file: _IO[_Any], name: str,
                 delete: bool = True) -> None:
        self.file = file
        self.name = name
        self.close_called = False
        self.delete = delete

        if _os.name != 'nt':
            # Cache the unlinker so we don't get spurious errors at
            # shutdown when the module-level "os" is None'd out.  Note
            # that this must be referenced as self.unlink, because the
            # name TemporaryFileWrapper may also get None'd out before
            # __del__ is called.
            self.unlink = _os.unlink

    def __getattr__(self, name: str) -> _Any:
        # Attribute lookups are delegated to the underlying file
        # and cached for non-numeric results
        # (i.e. methods are cached, closed and friends are not)
        file = _Any(self).__dict__['file'] # type: _IO[_Any]
        a = getattr(file, name)
        if not isinstance(a, int):
            setattr(self, name, a)
        return a

    # The underlying __enter__ method returns the wrong object
    # (self.file) so override it to return the wrapper
    def __enter__(self) -> '_TemporaryFileWrapper':
        self.file.__enter__()
        return self

    # iter() doesn't use __getattr__ to find the __iter__ method
    def __iter__(self) -> _Iterator[_Any]:
        return iter(self.file)

    # NT provides delete-on-close as a primitive, so we don't need
    # the wrapper to do anything special.  We still use it so that
    # file.name is useful (i.e. not "(fdopen)") with NamedTemporaryFile.
    if _os.name != 'nt':
        def close(self) -> None:
            if not self.close_called:
                self.close_called = True
                self.file.close()
                if self.delete:
                    self.unlink(self.name)

        def __del__(self) -> None:
            self.close()

        # Need to trap __exit__ as well to ensure the file gets
        # deleted when used in a with statement
        def __exit__(self, exc: type, value: BaseException,
                     tb: _Traceback) -> bool:
            result = self.file.__exit__(exc, value, tb)
            self.close()
            return result
    else:
        def __exit__(self, exc: type, value: BaseException,
                     tb: _Traceback) -> bool:
            self.file.__exit__(exc, value, tb)


def NamedTemporaryFile(mode: str = 'w+b', buffering: int = -1,
                       encoding: str = None, newline: str = None,
                       suffix: str = "", prefix: str = template,
                       dir: str = None, delete: bool = True) -> _IO[_Any]:
    """Create and return a temporary file.
    Arguments:
    'prefix', 'suffix', 'dir' -- as for mkstemp.
    'mode' -- the mode argument to io.open (default "w+b").
    'buffering' -- the buffer size argument to io.open (default -1).
    'encoding' -- the encoding argument to io.open (default None)
    'newline' -- the newline argument to io.open (default None)
    'delete' -- whether the file is deleted on close (default True).
    The file is created as mkstemp() would do it.

    Returns an object with a file-like interface; the name of the file
    is accessible as file.name.  The file will be automatically deleted
    when it is closed unless the 'delete' argument is set to False.
    """

    if dir is None:
        dir = gettempdir()

    flags = _bin_openflags

    # Setting O_TEMPORARY in the flags causes the OS to delete
    # the file when it is closed.  This is only supported by Windows.
    if _os.name == 'nt' and delete:
        flags |= _os.O_TEMPORARY

    (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags)
    file = _io.open(fd, mode, buffering=buffering,
                    newline=newline, encoding=encoding)

    return _TemporaryFileWrapper(file, name, delete)

if _os.name != 'posix' or _sys.platform == 'cygwin':
    # On non-POSIX and Cygwin systems, assume that we cannot unlink a file
    # while it is open.
    TemporaryFile = NamedTemporaryFile

else:
    def _TemporaryFile(mode: str = 'w+b', buffering: int = -1,
                       encoding: str = None, newline: str = None,
                       suffix: str = "", prefix: str = template,
                       dir: str = None, delete: bool = True) -> _IO[_Any]:
        """Create and return a temporary file.
        Arguments:
        'prefix', 'suffix', 'dir' -- as for mkstemp.
        'mode' -- the mode argument to io.open (default "w+b").
        'buffering' -- the buffer size argument to io.open (default -1).
        'encoding' -- the encoding argument to io.open (default None)
        'newline' -- the newline argument to io.open (default None)
        The file is created as mkstemp() would do it.

        Returns an object with a file-like interface.  The file has no
        name, and will cease to exist when it is closed.
        """

        if dir is None:
            dir = gettempdir()

        flags = _bin_openflags

        (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags)
        try:
            _os.unlink(name)
            return _io.open(fd, mode, buffering=buffering,
                            newline=newline, encoding=encoding)
        except:
            _os.close(fd)
            raise
    TemporaryFile = _TemporaryFile

class SpooledTemporaryFile:
    """Temporary file wrapper, specialized to switch from
    StringIO to a real file when it exceeds a certain size or
    when a fileno is needed.
    """
    _rolled = False
    _file = _Undefined # type: _Any   # BytesIO, StringIO or TemporaryFile

    def __init__(self, max_size: int = 0, mode: str = 'w+b',
                 buffering: int = -1, encoding: str = None,
                 newline: str = None, suffix: str = "",
                 prefix: str = template, dir: str = None) -> None:
        if 'b' in mode:
            self._file = _io.BytesIO()
        else:
            # Setting newline="\n" avoids newline translation;
            # this is important because otherwise on Windows we'd
            # hget double newline translation upon rollover().
            self._file = _io.StringIO(newline="\n")
        self._max_size = max_size
        self._rolled = False
        self._TemporaryFileArgs = {
                                   'mode': mode, 'buffering': buffering,
                                   'suffix': suffix, 'prefix': prefix,
                                   'encoding': encoding, 'newline': newline,
                                   'dir': dir} # type: Dict[str, _Any]

    def _check(self, file: _IO[_Any]) -> None:
        if self._rolled: return
        max_size = self._max_size
        if max_size and file.tell() > max_size:
            self.rollover()

    def rollover(self) -> None:
        if self._rolled: return
        file = self._file
        newfile = self._file = TemporaryFile(**self._TemporaryFileArgs)
        self._TemporaryFileArgs = None

        newfile.write(file.getvalue())
        newfile.seek(file.tell(), 0)

        self._rolled = True

    # The method caching trick from NamedTemporaryFile
    # won't work here, because _file may change from a
    # _StringIO instance to a real file. So we list
    # all the methods directly.

    # Context management protocol
    def __enter__(self) -> 'SpooledTemporaryFile':
        if self._file.closed:
            raise ValueError("Cannot enter context with closed file")
        return self

    def __exit__(self, exc: type, value: BaseException,
                 tb: _Traceback) -> bool:
        self._file.close()

    # file protocol
    def __iter__(self) -> _Iterable[_Any]:
        return self._file.__iter__()

    def close(self) -> None:
        self._file.close()

    @property
    def closed(self) -> bool:
        return self._file.closed

    @property
    def encoding(self) -> str:
        return self._file.encoding

    def fileno(self) -> int:
        self.rollover()
        return self._file.fileno()

    def flush(self) -> None:
        self._file.flush()

    def isatty(self) -> bool:
        return self._file.isatty()

    @property
    def mode(self) -> str:
        return self._file.mode

    @property
    def name(self) -> str:
        return self._file.name

    @property
    def newlines(self) -> _Any:
        return self._file.newlines

    #def next(self):
    #    return self._file.next

    def read(self, n: int = -1) -> _Any:
        return self._file.read(n)

    def readline(self, limit: int = -1) -> _Any:
        return self._file.readline(limit)

    def readlines(self, *args) -> _List[_Any]:
        return self._file.readlines(*args)

    def seek(self, offset: int, whence: int = 0) -> None:
        self._file.seek(offset, whence)

    @property
    def softspace(self) -> bool:
        return self._file.softspace

    def tell(self) -> int:
        return self._file.tell()

    def truncate(self) -> None:
        self._file.truncate()

    def write(self, s: _Any) -> int:
        file = self._file # type: _IO[_Any]
        rv = file.write(s)
        self._check(file)
        return rv

    def writelines(self, iterable: _Iterable[_Any]) -> None:
        file = self._file # type: _IO[_Any]
        file.writelines(iterable)
        self._check(file)

    #def xreadlines(self, *args) -> _Any:
    #    return self._file.xreadlines(*args)


class TemporaryDirectory(object):
    """Create and return a temporary directory.  This has the same
    behavior as mkdtemp but can be used as a context manager.  For
    example:

        with TemporaryDirectory() as tmpdir:
            ...

    Upon exiting the context, the directory and everthing contained
    in it are removed.
    """

    def __init__(self, suffix: str = "", prefix: str = template,
                 dir: str = None) -> None:
        self._closed = False
        self.name = None # type: str # Handle mkdtemp throwing an exception
        self.name = mkdtemp(suffix, prefix, dir)

        # XXX (ncoghlan): The following code attempts to make
        # this class tolerant of the module nulling out process
        # that happens during CPython interpreter shutdown
        # Alas, it doesn't actually manage it. See issue #10188
        self._listdir = _os.listdir
        self._path_join = _os.path.join
        self._isdir = _os.path.isdir
        self._islink = _os.path.islink
        self._remove = _os.remove
        self._rmdir = _os.rmdir
        self._os_error = _os.error
        self._warn = _warnings.warn

    def __repr__(self) -> str:
        return "<{} {!r}>".format(self.__class__.__name__, self.name)

    def __enter__(self) -> str:
        return self.name

    def cleanup(self, _warn: bool = False) -> None:
        if self.name and not self._closed:
            try:
                self._rmtree(self.name)
            except (TypeError, AttributeError) as ex:
                # Issue #10188: Emit a warning on stderr
                # if the directory could not be cleaned
                # up due to missing globals
                if "None" not in str(ex):
                    raise
                print("ERROR: {!r} while cleaning up {!r}".format(ex, self,),
                      file=_sys.stderr)
                return
            self._closed = True
            if _warn:
                self._warn("Implicitly cleaning up {!r}".format(self),
                           ResourceWarning)

    def __exit__(self, exc: type, value: BaseException,
                 tb: _Traceback) -> bool:
        self.cleanup()

    def __del__(self) -> None:
        # Issue a ResourceWarning if implicit cleanup needed
        self.cleanup(_warn=True)

    def _rmtree(self, path: str) -> None:
        # Essentially a stripped down version of shutil.rmtree.  We can't
        # use globals because they may be None'ed out at shutdown.
        for name in self._listdir(path):
            fullname = self._path_join(path, name)
            try:
                isdir = self._isdir(fullname) and not self._islink(fullname)
            except self._os_error:
                isdir = False
            if isdir:
                self._rmtree(fullname)
            else:
                try:
                    self._remove(fullname)
                except self._os_error:
                    pass
        try:
            self._rmdir(path)
        except self._os_error:
            pass

########NEW FILE########
__FILENAME__ = fd_status
"""When called as a script, print a comma-separated list of the open
file descriptors on stdout."""

import errno
import os

try:
    _MAXFD = os.sysconf("SC_OPEN_MAX")
except:
    _MAXFD = 256

if __name__ == "__main__":
    fds = []
    for fd in range(0, _MAXFD):
        try:
            st = os.fstat(fd)
        except OSError as e:
            if e.errno == errno.EBADF:
                continue
            raise
        # Ignore Solaris door files
        if st.st_mode & 0xF000 != 0xd000:
            fds.append(fd)
    print(','.join(map(str, fds)))

########NEW FILE########
__FILENAME__ = input_reader
"""When called as a script, consumes the input"""

import sys

if __name__ == "__main__":
    for line in sys.stdin:
        pass

########NEW FILE########
__FILENAME__ = qcat
"""When ran as a script, simulates cat with no arguments."""

import sys

if __name__ == "__main__":
    for line in sys.stdin:
        sys.stdout.write(line)

########NEW FILE########
__FILENAME__ = qgrep
"""When called with a single argument, simulated fgrep with a single
argument and no options."""

import sys

if __name__ == "__main__":
    pattern = sys.argv[1]
    for line in sys.stdin:
        if pattern in line:
            sys.stdout.write(line)

########NEW FILE########
__FILENAME__ = sigchild_ignore
import signal, subprocess, sys
# On Linux this causes os.waitpid to fail with OSError as the OS has already
# reaped our child process.  The wait() passing the OSError on to the caller
# and causing us to exit with an error is what we are testing against.
signal.signal(signal.SIGCHLD, signal.SIG_IGN)
subprocess.Popen([sys.executable, '-c', 'print("albatross")']).wait()

########NEW FILE########
__FILENAME__ = support
"""Supporting definitions for the Python regression tests."""

if __name__ != 'test.support':
    raise ImportError('support must be imported from the test package')

import contextlib
import errno
import functools
import gc
import socket
import sys
import os
import platform
import shutil
import warnings
import unittest
import importlib
import collections
import re
import subprocess
import imp
import time
import sysconfig
import fnmatch
import logging.handlers

import _thread, threading
from typing import Any, Dict
#try:
#    import multiprocessing.process
#except ImportError:
#    multiprocessing = None


__all__ = [
    "Error", "TestFailed", "ResourceDenied", "import_module",
    "verbose", "use_resources", "max_memuse", "record_original_stdout",
    "get_original_stdout", "unload", "unlink", "rmtree", "forget",
    "is_resource_enabled", "requires", "requires_mac_ver",
    "find_unused_port", "bind_port",
    "fcmp", "is_jython", "TESTFN", "HOST", "FUZZ", "SAVEDCWD", "temp_cwd",
    "findfile", "sortdict", "check_syntax_error", "open_urlresource",
    "check_warnings", "CleanImport", "EnvironmentVarGuard",
    "TransientResource", "captured_output", "captured_stdout",
    "captured_stdin", "captured_stderr",
    "time_out", "socket_peer_reset", "ioerror_peer_reset",
    "run_with_locale", 'temp_umask', "transient_internet",
    "set_memlimit", "bigmemtest", "bigaddrspacetest", "BasicTestRunner",
    "run_unittest", "run_doctest", "threading_setup", "threading_cleanup",
    "reap_children", "cpython_only", "check_impl_detail", "get_attribute",
    "swap_item", "swap_attr", "requires_IEEE_754",
    "TestHandler", "Matcher", "can_symlink", "skip_unless_symlink",
    "import_fresh_module", "failfast",
    ]

class Error(Exception):
    """Base class for regression test exceptions."""

class TestFailed(Error):
    """Test failed."""

class ResourceDenied(unittest.SkipTest):
    """Test skipped because it requested a disallowed resource.

    This is raised when a test calls requires() for a resource that
    has not be enabled.  It is used to distinguish between expected
    and unexpected skips.
    """

@contextlib.contextmanager
def _ignore_deprecated_imports(ignore=True):
    """Context manager to suppress package and module deprecation
    warnings when importing them.

    If ignore is False, this context manager has no effect."""
    if ignore:
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", ".+ (module|package)",
                                    DeprecationWarning)
            yield None
    else:
        yield None


def import_module(name, deprecated=False):
    """Import and return the module to be tested, raising SkipTest if
    it is not available.

    If deprecated is True, any module or package deprecation messages
    will be suppressed."""
    with _ignore_deprecated_imports(deprecated):
        try:
            return importlib.import_module(name)
        except ImportError as msg:
            raise unittest.SkipTest(str(msg))


def _save_and_remove_module(name, orig_modules):
    """Helper function to save and remove a module from sys.modules

       Raise ImportError if the module can't be imported."""
    # try to import the module and raise an error if it can't be imported
    if name not in sys.modules:
        __import__(name)
        del sys.modules[name]
    for modname in list(sys.modules):
        if modname == name or modname.startswith(name + '.'):
            orig_modules[modname] = sys.modules[modname]
            del sys.modules[modname]

def _save_and_block_module(name, orig_modules):
    """Helper function to save and block a module in sys.modules

       Return True if the module was in sys.modules, False otherwise."""
    saved = True
    try:
        orig_modules[name] = sys.modules[name]
    except KeyError:
        saved = False
    sys.modules[name] = None
    return saved


def import_fresh_module(name, fresh=(), blocked=(), deprecated=False):
    """Imports and returns a module, deliberately bypassing the sys.modules cache
    and importing a fresh copy of the module. Once the import is complete,
    the sys.modules cache is restored to its original state.

    Modules named in fresh are also imported anew if needed by the import.
    If one of these modules can't be imported, None is returned.

    Importing of modules named in blocked is prevented while the fresh import
    takes place.

    If deprecated is True, any module or package deprecation messages
    will be suppressed."""
    # NOTE: test_heapq, test_json and test_warnings include extra sanity checks
    # to make sure that this utility function is working as expected
    with _ignore_deprecated_imports(deprecated):
        # Keep track of modules saved for later restoration as well
        # as those which just need a blocking entry removed
        orig_modules = {}
        names_to_remove = []
        _save_and_remove_module(name, orig_modules)
        try:
            for fresh_name in fresh:
                _save_and_remove_module(fresh_name, orig_modules)
            for blocked_name in blocked:
                if not _save_and_block_module(blocked_name, orig_modules):
                    names_to_remove.append(blocked_name)
            fresh_module = importlib.import_module(name)
        except ImportError:
            fresh_module = None
        finally:
            for orig_name, module in orig_modules.items():
                sys.modules[orig_name] = module
            for name_to_remove in names_to_remove:
                del sys.modules[name_to_remove]
        return fresh_module


def get_attribute(obj, name):
    """Get an attribute, raising SkipTest if AttributeError is raised."""
    try:
        attribute = getattr(obj, name)
    except AttributeError:
        raise unittest.SkipTest("module %s has no attribute %s" % (
            obj.__name__, name))
    else:
        return attribute

verbose = 1              # Flag set to 0 by regrtest.py
use_resources = None # type: Any     # Flag set to [] by regrtest.py
max_memuse = 0           # Disable bigmem tests (they will still be run with
                         # small sizes, to make sure they work.)
real_max_memuse = 0
failfast = False
match_tests = None # type: Any

# _original_stdout is meant to hold stdout at the time regrtest began.
# This may be "the real" stdout, or IDLE's emulation of stdout, or whatever.
# The point is to have some flavor of stdout the user can actually see.
_original_stdout = None # type: 'Any'
def record_original_stdout(stdout):
    global _original_stdout
    _original_stdout = stdout

def get_original_stdout():
    return _original_stdout or sys.stdout

def unload(name):
    try:
        del sys.modules[name]
    except KeyError:
        pass

def unlink(filename):
    try:
        os.unlink(filename)
    except OSError as error:
        # The filename need not exist.
        if error.errno not in (errno.ENOENT, errno.ENOTDIR):
            raise

def rmtree(path):
    try:
        shutil.rmtree(path)
    except OSError as error:
        # Unix returns ENOENT, Windows returns ESRCH.
        if error.errno not in (errno.ENOENT, errno.ESRCH):
            raise

def make_legacy_pyc(source):
    """Move a PEP 3147 pyc/pyo file to its legacy pyc/pyo location.

    The choice of .pyc or .pyo extension is done based on the __debug__ flag
    value.

    :param source: The file system path to the source file.  The source file
        does not need to exist, however the PEP 3147 pyc file must exist.
    :return: The file system path to the legacy pyc file.
    """
    pyc_file = imp.cache_from_source(source)
    up_one = os.path.dirname(os.path.abspath(source))
    if __debug__:
        ch = 'c'
    else:
        ch = 'o'
    legacy_pyc = os.path.join(up_one, source + ch)
    os.rename(pyc_file, legacy_pyc)
    return legacy_pyc

def forget(modname):
    """'Forget' a module was ever imported.

    This removes the module from sys.modules and deletes any PEP 3147 or
    legacy .pyc and .pyo files.
    """
    unload(modname)
    for dirname in sys.path:
        source = os.path.join(dirname, modname + '.py')
        # It doesn't matter if they exist or not, unlink all possible
        # combinations of PEP 3147 and legacy pyc and pyo files.
        unlink(source + 'c')
        unlink(source + 'o')
        unlink(imp.cache_from_source(source, debug_override=True))
        unlink(imp.cache_from_source(source, debug_override=False))

# On some platforms, should not run gui test even if it is allowed
# in `use_resources'.
#if sys.platform.startswith('win'):
    #import ctypes
    #import ctypes.wintypes
    #def _is_gui_available():
    #    UOI_FLAGS = 1
    #    WSF_VISIBLE = 0x0001
    #    class USEROBJECTFLAGS(ctypes.Structure):
    #        _fields_ = [("fInherit", ctypes.wintypes.BOOL),
    #                    ("fReserved", ctypes.wintypes.BOOL),
    #                    ("dwFlags", ctypes.wintypes.DWORD)]
    #    dll = ctypes.windll.user32
    #    h = dll.GetProcessWindowStation()
    #    if not h:
    #        raise ctypes.WinError()
    #    uof = USEROBJECTFLAGS()
    #    needed = ctypes.wintypes.DWORD()
    #    res = dll.GetUserObjectInformationW(h,
    #        UOI_FLAGS,
    #        ctypes.byref(uof),
    #        ctypes.sizeof(uof),
    #        ctypes.byref(needed))
    #    if not res:
    #        raise ctypes.WinError()
    #    return bool(uof.dwFlags & WSF_VISIBLE)
#else:
def _is_gui_available():
    return True

def is_resource_enabled(resource):
    """Test whether a resource is enabled.  Known resources are set by
    regrtest.py."""
    return use_resources is not None and resource in use_resources

def requires(resource, msg=None):
    """Raise ResourceDenied if the specified resource is not available.

    If the caller's module is __main__ then automatically return True.  The
    possibility of False being returned occurs when regrtest.py is
    executing.
    """
    if resource == 'gui' and not _is_gui_available():
        raise unittest.SkipTest("Cannot use the 'gui' resource")
    # see if the caller's module is __main__ - if so, treat as if
    # the resource was set
    if sys._getframe(1).f_globals.get("__name__") == "__main__":
        return
    if not is_resource_enabled(resource):
        if msg is None:
            msg = "Use of the `%s' resource not enabled" % resource
        raise ResourceDenied(msg)

def requires_mac_ver(*min_version):
    """Decorator raising SkipTest if the OS is Mac OS X and the OS X
    version if less than min_version.

    For example, @requires_mac_ver(10, 5) raises SkipTest if the OS X version
    is lesser than 10.5.
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kw):
            if sys.platform == 'darwin':
                version_txt = platform.mac_ver()[0]
                try:
                    version = tuple(map(int, version_txt.split('.')))
                except ValueError:
                    pass
                else:
                    if version < min_version:
                        min_version_txt = '.'.join(map(str, min_version))
                        raise unittest.SkipTest(
                            "Mac OS X %s or higher required, not %s"
                            % (min_version_txt, version_txt))
            return func(*args, **kw)
        wrapper.min_version = min_version
        return wrapper
    return decorator

HOST = 'localhost'

def find_unused_port(family=socket.AF_INET, socktype=socket.SOCK_STREAM):
    """Returns an unused port that should be suitable for binding.  This is
    achieved by creating a temporary socket with the same family and type as
    the 'sock' parameter (default is AF_INET, SOCK_STREAM), and binding it to
    the specified host address (defaults to 0.0.0.0) with the port set to 0,
    eliciting an unused ephemeral port from the OS.  The temporary socket is
    then closed and deleted, and the ephemeral port is returned.

    Either this method or bind_port() should be used for any tests where a
    server socket needs to be bound to a particular port for the duration of
    the test.  Which one to use depends on whether the calling code is creating
    a python socket, or if an unused port needs to be provided in a constructor
    or passed to an external program (i.e. the -accept argument to openssl's
    s_server mode).  Always prefer bind_port() over find_unused_port() where
    possible.  Hard coded ports should *NEVER* be used.  As soon as a server
    socket is bound to a hard coded port, the ability to run multiple instances
    of the test simultaneously on the same host is compromised, which makes the
    test a ticking time bomb in a buildbot environment. On Unix buildbots, this
    may simply manifest as a failed test, which can be recovered from without
    intervention in most cases, but on Windows, the entire python process can
    completely and utterly wedge, requiring someone to log in to the buildbot
    and manually kill the affected process.

    (This is easy to reproduce on Windows, unfortunately, and can be traced to
    the SO_REUSEADDR socket option having different semantics on Windows versus
    Unix/Linux.  On Unix, you can't have two AF_INET SOCK_STREAM sockets bind,
    listen and then accept connections on identical host/ports.  An EADDRINUSE
    socket.error will be raised at some point (depending on the platform and
    the order bind and listen were called on each socket).

    However, on Windows, if SO_REUSEADDR is set on the sockets, no EADDRINUSE
    will ever be raised when attempting to bind two identical host/ports. When
    accept() is called on each socket, the second caller's process will steal
    the port from the first caller, leaving them both in an awkwardly wedged
    state where they'll no longer respond to any signals or graceful kills, and
    must be forcibly killed via OpenProcess()/TerminateProcess().

    The solution on Windows is to use the SO_EXCLUSIVEADDRUSE socket option
    instead of SO_REUSEADDR, which effectively affords the same semantics as
    SO_REUSEADDR on Unix.  Given the propensity of Unix developers in the Open
    Source world compared to Windows ones, this is a common mistake.  A quick
    look over OpenSSL's 0.9.8g source shows that they use SO_REUSEADDR when
    openssl.exe is called with the 's_server' option, for example. See
    http://bugs.python.org/issue2550 for more info.  The following site also
    has a very thorough description about the implications of both REUSEADDR
    and EXCLUSIVEADDRUSE on Windows:
    http://msdn2.microsoft.com/en-us/library/ms740621(VS.85).aspx)

    XXX: although this approach is a vast improvement on previous attempts to
    elicit unused ports, it rests heavily on the assumption that the ephemeral
    port returned to us by the OS won't immediately be dished back out to some
    other process when we close and delete our temporary socket but before our
    calling code has a chance to bind the returned port.  We can deal with this
    issue if/when we come across it.
    """

    tempsock = socket.socket(family, socktype)
    port = bind_port(tempsock)
    tempsock.close()
    #del tempsock
    return port

def bind_port(sock, host=HOST):
    """Bind the socket to a free port and return the port number.  Relies on
    ephemeral ports in order to ensure we are using an unbound port.  This is
    important as many tests may be running simultaneously, especially in a
    buildbot environment.  This method raises an exception if the sock.family
    is AF_INET and sock.type is SOCK_STREAM, *and* the socket has SO_REUSEADDR
    or SO_REUSEPORT set on it.  Tests should *never* set these socket options
    for TCP/IP sockets.  The only case for setting these options is testing
    multicasting via multiple UDP sockets.

    Additionally, if the SO_EXCLUSIVEADDRUSE socket option is available (i.e.
    on Windows), it will be set on the socket.  This will prevent anyone else
    from bind()'ing to our host/port for the duration of the test.
    """

    if sock.family == socket.AF_INET and sock.type == socket.SOCK_STREAM:
        if hasattr(socket, 'SO_REUSEADDR'):
            if sock.getsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR) == 1:
                raise TestFailed("tests should never set the SO_REUSEADDR "   \
                                 "socket option on TCP/IP sockets!")
        if hasattr(socket, 'SO_REUSEPORT'):
            if sock.getsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT) == 1:
                raise TestFailed("tests should never set the SO_REUSEPORT "   \
                                 "socket option on TCP/IP sockets!")
        if hasattr(socket, 'SO_EXCLUSIVEADDRUSE'):
            sock.setsockopt(socket.SOL_SOCKET, socket.SO_EXCLUSIVEADDRUSE, 1)

    sock.bind((host, 0))
    port = sock.getsockname()[1]
    return port

FUZZ = 1e-6

def fcmp(x, y): # fuzzy comparison function
    if isinstance(x, float) or isinstance(y, float):
        try:
            fuzz = (abs(x) + abs(y)) * FUZZ
            if abs(x-y) <= fuzz:
                return 0
        except:
            pass
    elif type(x) == type(y) and isinstance(x, (tuple, list)):
        for i in range(min(len(x), len(y))):
            outcome = fcmp(x[i], y[i])
            if outcome != 0:
                return outcome
        return (len(x) > len(y)) - (len(x) < len(y))
    return (x > y) - (x < y)

# decorator for skipping tests on non-IEEE 754 platforms
requires_IEEE_754 = unittest.skipUnless(
    (Any(float)).__getformat__("double").startswith("IEEE"),
    "test requires IEEE 754 doubles")

is_jython = sys.platform.startswith('java')

TESTFN = ''
# Filename used for testing
if os.name == 'java':
    # Jython disallows @ in module names
    TESTFN = '$test'
else:
    TESTFN = '@test'

# Disambiguate TESTFN for parallel testing, while letting it remain a valid
# module name.
TESTFN = "{}_{}_tmp".format(TESTFN, os.getpid())


# TESTFN_UNICODE is a non-ascii filename
TESTFN_UNICODE = TESTFN + "-\xe0\xf2\u0258\u0141\u011f"
if sys.platform == 'darwin':
    # In Mac OS X's VFS API file names are, by definition, canonically
    # decomposed Unicode, encoded using UTF-8. See QA1173:
    # http://developer.apple.com/mac/library/qa/qa2001/qa1173.html
    import unicodedata
    TESTFN_UNICODE = unicodedata.normalize('NFD', TESTFN_UNICODE)
TESTFN_ENCODING = sys.getfilesystemencoding()

# TESTFN_UNENCODABLE is a filename (str type) that should *not* be able to be
# encoded by the filesystem encoding (in strict mode). It can be None if we
# cannot generate such filename.
TESTFN_UNENCODABLE = None # type: Any
if os.name in ('nt', 'ce'):
    # skip win32s (0) or Windows 9x/ME (1)
    if sys.getwindowsversion().platform >= 2:
        # Different kinds of characters from various languages to minimize the
        # probability that the whole name is encodable to MBCS (issue #9819)
        TESTFN_UNENCODABLE = TESTFN + "-\u5171\u0141\u2661\u0363\uDC80"
        try:
            TESTFN_UNENCODABLE.encode(TESTFN_ENCODING)
        except UnicodeEncodeError:
            pass
        else:
            print('WARNING: The filename %r CAN be encoded by the filesystem encoding (%s). '
                  'Unicode filename tests may not be effective'
                  % (TESTFN_UNENCODABLE, TESTFN_ENCODING))
            TESTFN_UNENCODABLE = None
# Mac OS X denies unencodable filenames (invalid utf-8)
elif sys.platform != 'darwin':
    try:
        # ascii and utf-8 cannot encode the byte 0xff
        b'\xff'.decode(TESTFN_ENCODING)
    except UnicodeDecodeError:
        # 0xff will be encoded using the surrogate character u+DCFF
        TESTFN_UNENCODABLE = TESTFN \
            + b'-\xff'.decode(TESTFN_ENCODING, 'surrogateescape')
    else:
        # File system encoding (eg. ISO-8859-* encodings) can encode
        # the byte 0xff. Skip some unicode filename tests.
        pass

# Save the initial cwd
SAVEDCWD = os.getcwd()

@contextlib.contextmanager
def temp_cwd(name='tempcwd', quiet=False, path=None):
    """
    Context manager that temporarily changes the CWD.

    An existing path may be provided as *path*, in which case this
    function makes no changes to the file system.

    Otherwise, the new CWD is created in the current directory and it's
    named *name*. If *quiet* is False (default) and it's not possible to
    create or change the CWD, an error is raised.  If it's True, only a
    warning is raised and the original CWD is used.
    """
    saved_dir = os.getcwd()
    is_temporary = False
    if path is None:
        path = name
        try:
            os.mkdir(name)
            is_temporary = True
        except OSError:
            if not quiet:
                raise
            warnings.warn('tests may fail, unable to create temp CWD ' + name,
                          RuntimeWarning, stacklevel=3)
    try:
        os.chdir(path)
    except OSError:
        if not quiet:
            raise
        warnings.warn('tests may fail, unable to change the CWD to ' + name,
                      RuntimeWarning, stacklevel=3)
    try:
        yield os.getcwd()
    finally:
        os.chdir(saved_dir)
        if is_temporary:
            rmtree(name)


@contextlib.contextmanager
def temp_umask(umask):
    """Context manager that temporarily sets the process umask."""
    oldmask = os.umask(umask)
    try:
        yield None
    finally:
        os.umask(oldmask)


def findfile(file, here=__file__, subdir=None):
    """Try to find a file on sys.path and the working directory.  If it is not
    found the argument passed to the function is returned (this does not
    necessarily signal failure; could still be the legitimate path)."""
    if os.path.isabs(file):
        return file
    if subdir is not None:
        file = os.path.join(subdir, file)
    path = sys.path
    path = [os.path.dirname(here)] + path
    for dn in path:
        fn = os.path.join(dn, file)
        if os.path.exists(fn): return fn
    return file

def sortdict(dict):
    "Like repr(dict), but in sorted order."
    items = sorted(dict.items())
    reprpairs = ["%r: %r" % pair for pair in items]
    withcommas = ", ".join(reprpairs)
    return "{%s}" % withcommas

def make_bad_fd():
    """
    Create an invalid file descriptor by opening and closing a file and return
    its fd.
    """
    file = open(TESTFN, "wb")
    try:
        return file.fileno()
    finally:
        file.close()
        unlink(TESTFN)

def check_syntax_error(testcase, statement):
    raise NotImplementedError('no compile built-in')
    #testcase.assertRaises(SyntaxError, compile, statement,
    #                      '<test string>', 'exec')

def open_urlresource(url, *args, **kw):
    from urllib import request, parse

    check = kw.pop('check', None)

    filename = parse.urlparse(url)[2].split('/')[-1] # '/': it's URL!

    fn = os.path.join(os.path.dirname(__file__), "data", filename)

    def check_valid_file(fn):
        f = open(fn, *args, **kw)
        if check is None:
            return f
        elif check(f):
            f.seek(0)
            return f
        f.close()

    if os.path.exists(fn):
        f = check_valid_file(fn)
        if f is not None:
            return f
        unlink(fn)

    # Verify the requirement before downloading the file
    requires('urlfetch')

    print('\tfetching %s ...' % url, file=get_original_stdout())
    f = request.urlopen(url, timeout=15)
    try:
        with open(fn, "wb") as out:
            s = f.read()
            while s:
                out.write(s)
                s = f.read()
    finally:
        f.close()

    f = check_valid_file(fn)
    if f is not None:
        return f
    raise TestFailed('invalid resource "%s"' % fn)


class WarningsRecorder(object):
    """Convenience wrapper for the warnings list returned on
       entry to the warnings.catch_warnings() context manager.
    """
    def __init__(self, warnings_list):
        self._warnings = warnings_list
        self._last = 0

    def __getattr__(self, attr):
        if len(self._warnings) > self._last:
            return getattr(self._warnings[-1], attr)
        elif attr in warnings.WarningMessage._WARNING_DETAILS:
            return None
        raise AttributeError("%r has no attribute %r" % (self, attr))

    #@property
    #def warnings(self):
    #    return self._warnings[self._last:]

    def reset(self):
        self._last = len(self._warnings)


def _filterwarnings(filters, quiet=False):
    """Catch the warnings, then check if all the expected
    warnings have been raised and re-raise unexpected warnings.
    If 'quiet' is True, only re-raise the unexpected warnings.
    """
    # Clear the warning registry of the calling module
    # in order to re-raise the warnings.
    frame = sys._getframe(2)
    registry = frame.f_globals.get('__warningregistry__')
    if registry:
        registry.clear()
    with warnings.catch_warnings(record=True) as w:
        # Set filter "always" to record all warnings.  Because
        # test_warnings swap the module, we need to look up in
        # the sys.modules dictionary.
        sys.modules['warnings'].simplefilter("always")
        yield WarningsRecorder(w)
    # Filter the recorded warnings
    reraise = list(w)
    missing = []
    for msg, cat in filters:
        seen = False
        for w in reraise[:]:
            warning = w.message
            # Filter out the matching messages
            if (re.match(msg, str(warning), re.I) and
                issubclass(warning.__class__, cat)):
                seen = True
                reraise.remove(w)
        if not seen and not quiet:
            # This filter caught nothing
            missing.append((msg, cat.__name__))
    if reraise:
        raise AssertionError("unhandled warning %s" % reraise[0])
    if missing:
        raise AssertionError("filter (%r, %s) did not catch any warning" %
                             missing[0])


@contextlib.contextmanager
def check_warnings(*filters, **kwargs):
    """Context manager to silence warnings.

    Accept 2-tuples as positional arguments:
        ("message regexp", WarningCategory)

    Optional argument:
     - if 'quiet' is True, it does not fail if a filter catches nothing
        (default True without argument,
         default False if some filters are defined)

    Without argument, it defaults to:
        check_warnings(("", Warning), quiet=True)
    """
    quiet = kwargs.get('quiet')
    if not filters:
        filters = (("", Warning),)
        # Preserve backward compatibility
        if quiet is None:
            quiet = True
    return _filterwarnings(filters, quiet)


class CleanImport(object):
    """Context manager to force import to return a new module reference.

    This is useful for testing module-level behaviours, such as
    the emission of a DeprecationWarning on import.

    Use like this:

        with CleanImport("foo"):
            importlib.import_module("foo") # new reference
    """

    def __init__(self, *module_names):
        self.original_modules = sys.modules.copy()
        for module_name in module_names:
            if module_name in sys.modules:
                module = sys.modules[module_name]
                # It is possible that module_name is just an alias for
                # another module (e.g. stub for modules renamed in 3.x).
                # In that case, we also need delete the real module to clear
                # the import cache.
                if module.__name__ != module_name:
                    del sys.modules[module.__name__]
                del sys.modules[module_name]

    def __enter__(self):
        return self

    def __exit__(self, *ignore_exc):
        sys.modules.update(self.original_modules)


class EnvironmentVarGuard(dict):

    """Class to help protect the environment variable properly.  Can be used as
    a context manager."""

    def __init__(self):
        self._environ = os.environ
        self._changed = {}

    def __getitem__(self, envvar):
        return self._environ[envvar]

    def __setitem__(self, envvar, value):
        # Remember the initial value on the first access
        if envvar not in self._changed:
            self._changed[envvar] = self._environ.get(envvar)
        self._environ[envvar] = value

    def __delitem__(self, envvar):
        # Remember the initial value on the first access
        if envvar not in self._changed:
            self._changed[envvar] = self._environ.get(envvar)
        if envvar in self._environ:
            del self._environ[envvar]

    def keys(self):
        return self._environ.keys()

    def __iter__(self):
        return iter(self._environ)

    def __len__(self):
        return len(self._environ)

    def set(self, envvar, value):
        self[envvar] = value

    def unset(self, envvar):
        del self[envvar]

    def __enter__(self):
        return self

    def __exit__(self, *ignore_exc):
        for k, v in self._changed.items():
            if v is None:
                if k in self._environ:
                    del self._environ[k]
            else:
                self._environ[k] = v
        os.environ = self._environ


class DirsOnSysPath(object):
    """Context manager to temporarily add directories to sys.path.

    This makes a copy of sys.path, appends any directories given
    as positional arguments, then reverts sys.path to the copied
    settings when the context ends.

    Note that *all* sys.path modifications in the body of the
    context manager, including replacement of the object,
    will be reverted at the end of the block.
    """

    def __init__(self, *paths):
        self.original_value = sys.path[:]
        self.original_object = sys.path
        sys.path.extend(paths)

    def __enter__(self):
        return self

    def __exit__(self, *ignore_exc):
        sys.path = self.original_object
        sys.path[:] = self.original_value


class TransientResource(object):

    """Raise ResourceDenied if an exception is raised while the context manager
    is in effect that matches the specified exception and attributes."""

    def __init__(self, exc, **kwargs):
        self.exc = exc
        self.attrs = kwargs

    def __enter__(self):
        return self

    def __exit__(self, type_=None, value=None, traceback=None):
        """If type_ is a subclass of self.exc and value has attributes matching
        self.attrs, raise ResourceDenied.  Otherwise let the exception
        propagate (if any)."""
        if type_ is not None and issubclass(self.exc, type_):
            for attr, attr_value in self.attrs.items():
                if not hasattr(value, attr):
                    break
                if getattr(value, attr) != attr_value:
                    break
            else:
                raise ResourceDenied("an optional resource is not available")

# Context managers that raise ResourceDenied when various issues
# with the Internet connection manifest themselves as exceptions.
# XXX deprecate these and use transient_internet() instead
time_out = TransientResource(IOError, errno=errno.ETIMEDOUT)
socket_peer_reset = TransientResource(socket.error, errno=errno.ECONNRESET)
ioerror_peer_reset = TransientResource(IOError, errno=errno.ECONNRESET)


@contextlib.contextmanager
def transient_internet(resource_name, *, timeout=30.0, errnos=()):
    """Return a context manager that raises ResourceDenied when various issues
    with the Internet connection manifest themselves as exceptions."""
    default_errnos = [
        ('ECONNREFUSED', 111),
        ('ECONNRESET', 104),
        ('EHOSTUNREACH', 113),
        ('ENETUNREACH', 101),
        ('ETIMEDOUT', 110),
    ]
    default_gai_errnos = [
        ('EAI_AGAIN', -3),
        ('EAI_FAIL', -4),
        ('EAI_NONAME', -2),
        ('EAI_NODATA', -5),
        # Encountered when trying to resolve IPv6-only hostnames
        ('WSANO_DATA', 11004),
    ]

    denied = ResourceDenied("Resource '%s' is not available" % resource_name)
    captured_errnos = errnos
    gai_errnos = []
    if not captured_errnos:
        captured_errnos = [getattr(errno, name, num)
                           for name, num in default_errnos]
        gai_errnos = [getattr(socket, name, num)
                      for name, num in default_gai_errnos]

    def filter_error(err):
        n = getattr(err, 'errno', None)
        if (isinstance(err, socket.timeout) or
            (isinstance(err, socket.gaierror) and n in gai_errnos) or
            n in captured_errnos):
            if not verbose:
                sys.stderr.write(denied.args[0] + "\n")
            raise denied from err

    old_timeout = socket.getdefaulttimeout()
    try:
        if timeout is not None:
            socket.setdefaulttimeout(timeout)
        yield None
    except IOError as err:
        # urllib can wrap original socket errors multiple times (!), we must
        # unwrap to get at the original error.
        while True:
            a = err.args
            if len(a) >= 1 and isinstance(a[0], IOError):
                err = a[0]
            # The error can also be wrapped as args[1]:
            #    except socket.error as msg:
            #        raise IOError('socket error', msg).with_traceback(sys.exc_info()[2])
            elif len(a) >= 2 and isinstance(a[1], IOError):
                err = a[1]
            else:
                break
        filter_error(err)
        raise
    # XXX should we catch generic exceptions and look for their
    # __cause__ or __context__?
    finally:
        socket.setdefaulttimeout(old_timeout)


@contextlib.contextmanager
def captured_output(stream_name):
    """Return a context manager used by captured_stdout/stdin/stderr
    that temporarily replaces the sys stream *stream_name* with a StringIO."""
    import io
    orig_stdout = getattr(sys, stream_name)
    setattr(sys, stream_name, io.StringIO())
    try:
        yield getattr(sys, stream_name)
    finally:
        setattr(sys, stream_name, orig_stdout)

def captured_stdout():
    """Capture the output of sys.stdout:

       with captured_stdout() as s:
           print("hello")
       self.assertEqual(s.getvalue(), "hello")
    """
    return captured_output("stdout")

def captured_stderr():
    return captured_output("stderr")

def captured_stdin():
    return captured_output("stdin")


def gc_collect():
    """Force as many objects as possible to be collected.

    In non-CPython implementations of Python, this is needed because timely
    deallocation is not guaranteed by the garbage collector.  (Even in CPython
    this can be the case in case of reference cycles.)  This means that __del__
    methods may be called later than expected and weakrefs may remain alive for
    longer than expected.  This function tries its best to force all garbage
    objects to disappear.
    """
    gc.collect()
    if is_jython:
        time.sleep(0.1)
    gc.collect()
    gc.collect()


def python_is_optimized():
    """Find if Python was built with optimizations."""
    cflags = sysconfig.get_config_var('PY_CFLAGS') or ''
    final_opt = ""
    for opt in cflags.split():
        if opt.startswith('-O'):
            final_opt = opt
    return final_opt and final_opt != '-O0'


#=======================================================================
# Decorator for running a function in a different locale, correctly resetting
# it afterwards.

def run_with_locale(catstr, *locales):
    def decorator(func):
        def inner(*args, **kwds):
            try:
                import locale
                category = getattr(locale, catstr)
                orig_locale = locale.setlocale(category)
            except AttributeError:
                # if the test author gives us an invalid category string
                raise
            except:
                # cannot retrieve original locale, so do nothing
                locale = orig_locale = None
            else:
                for loc in locales:
                    try:
                        locale.setlocale(category, loc)
                        break
                    except:
                        pass

            # now run the function, resetting the locale on exceptions
            try:
                return func(*args, **kwds)
            finally:
                if locale and orig_locale:
                    locale.setlocale(category, orig_locale)
        inner.__name__ = func.__name__
        inner.__doc__ = func.__doc__
        return inner
    return decorator

#=======================================================================
# Big-memory-test support. Separate from 'resources' because memory use
# should be configurable.

# Some handy shorthands. Note that these are used for byte-limits as well
# as size-limits, in the various bigmem tests
_1M = 1024*1024
_1G = 1024 * _1M
_2G = 2 * _1G
_4G = 4 * _1G

MAX_Py_ssize_t = sys.maxsize

def set_memlimit(limit):
    global max_memuse
    global real_max_memuse
    sizes = {
        'k': 1024,
        'm': _1M,
        'g': _1G,
        't': 1024*_1G,
    }
    m = re.match(r'(\d+(\.\d+)?) (K|M|G|T)b?$', limit,
                 re.IGNORECASE | re.VERBOSE)
    if m is None:
        raise ValueError('Invalid memory limit %r' % (limit,))
    memlimit = int(float(m.group(1)) * sizes[m.group(3).lower()])
    real_max_memuse = memlimit
    if memlimit > MAX_Py_ssize_t:
        memlimit = MAX_Py_ssize_t
    if memlimit < _2G - 1:
        raise ValueError('Memory limit %r too low to be useful' % (limit,))
    max_memuse = memlimit

def _memory_watchdog(start_evt, finish_evt, period=10.0):
    """A function which periodically watches the process' memory consumption
    and prints it out.
    """
    # XXX: because of the GIL, and because the very long operations tested
    # in most bigmem tests are uninterruptible, the loop below gets woken up
    # much less often than expected.
    # The polling code should be rewritten in raw C, without holding the GIL,
    # and push results onto an anonymous pipe.
    try:
        page_size = os.sysconf('SC_PAGESIZE')
    except (ValueError, AttributeError):
        try:
            page_size = os.sysconf('SC_PAGE_SIZE')
        except (ValueError, AttributeError):
            page_size = 4096
    procfile = '/proc/{pid}/statm'.format(pid=os.getpid())
    try:
        f = open(procfile, 'rb')
    except IOError as e:
        warnings.warn('/proc not available for stats: {}'.format(e),
                      RuntimeWarning)
        sys.stderr.flush()
        return
    with f:
        start_evt.set()
        old_data = -1
        while not finish_evt.wait(period):
            f.seek(0)
            statm = f.read().decode('ascii')
            data = int(statm.split()[5])
            if data != old_data:
                old_data = data
                print(" ... process data size: {data:.1f}G"
                       .format(data=data * page_size / (1024 ** 3)))

def bigmemtest(size, memuse, dry_run=True):
    """Decorator for bigmem tests.

    'minsize' is the minimum useful size for the test (in arbitrary,
    test-interpreted units.) 'memuse' is the number of 'bytes per size' for
    the test, or a good estimate of it.

    if 'dry_run' is False, it means the test doesn't support dummy runs
    when -M is not specified.
    """
    def decorator(f):
        def wrapper(self):
            size = wrapper.size
            memuse = wrapper.memuse
            if not real_max_memuse:
                maxsize = 5147
            else:
                maxsize = size

            if ((real_max_memuse or not dry_run)
                and real_max_memuse < maxsize * memuse):
                raise unittest.SkipTest(
                    "not enough memory: %.1fG minimum needed"
                    % (size * memuse / (1024 ** 3)))

            if real_max_memuse and verbose and threading:
                print()
                print(" ... expected peak memory use: {peak:.1f}G"
                      .format(peak=size * memuse / (1024 ** 3)))
                sys.stdout.flush()
                start_evt = threading.Event()
                finish_evt = threading.Event()
                t = threading.Thread(target=_memory_watchdog,
                                     args=(start_evt, finish_evt, 0.5))
                t.daemon = True
                t.start()
                start_evt.set()
            else:
                t = None

            try:
                return f(self, maxsize)
            finally:
                if t:
                    finish_evt.set()
                    t.join()

        wrapper.size = size
        wrapper.memuse = memuse
        return wrapper
    return decorator

def bigaddrspacetest(f):
    """Decorator for tests that fill the address space."""
    def wrapper(self):
        if max_memuse < MAX_Py_ssize_t:
            if MAX_Py_ssize_t >= 2**63 - 1 and max_memuse >= 2**31:
                raise unittest.SkipTest(
                    "not enough memory: try a 32-bit build instead")
            else:
                raise unittest.SkipTest(
                    "not enough memory: %.1fG minimum needed"
                    % (MAX_Py_ssize_t / (1024 ** 3)))
        else:
            return f(self)
    return wrapper

#=======================================================================
# unittest integration.

class BasicTestRunner:
    def run(self, test):
        result = unittest.TestResult()
        test(result)
        return result

def _id(obj):
    return obj

def requires_resource(resource):
    if resource == 'gui' and not _is_gui_available():
        return unittest.skip("resource 'gui' is not available")
    if is_resource_enabled(resource):
        return _id
    else:
        return unittest.skip("resource {0!r} is not enabled".format(resource))

def cpython_only(test):
    """
    Decorator for tests only applicable on CPython.
    """
    return impl_detail(cpython=True)(test)

def impl_detail(msg=None, **guards):
    if check_impl_detail(**guards):
        return _id
    if msg is None:
        guardnames, default = _parse_guards(guards)
        if default:
            msg = "implementation detail not available on {0}"
        else:
            msg = "implementation detail specific to {0}"
        guardnames = sorted(guardnames.keys())
        msg = msg.format(' or '.join(guardnames))
    return unittest.skip(msg)

def _parse_guards(guards):
    # Returns a tuple ({platform_name: run_me}, default_value)
    if not guards:
        return ({'cpython': True}, False)
    is_true = list(guards.values())[0]
    assert list(guards.values()) == [is_true] * len(guards)   # all True or all False
    return (guards, not is_true)

# Use the following check to guard CPython's implementation-specific tests --
# or to run them only on the implementation(s) guarded by the arguments.
def check_impl_detail(**guards):
    """This function returns True or False depending on the host platform.
       Examples:
          if check_impl_detail():               # only on CPython (default)
          if check_impl_detail(jython=True):    # only on Jython
          if check_impl_detail(cpython=False):  # everywhere except on CPython
    """
    guards, default = _parse_guards(guards)
    return guards.get(platform.python_implementation().lower(), default)


def _filter_suite(suite, pred):
    """Recursively filter test cases in a suite based on a predicate."""
    newtests = []
    for test in suite._tests:
        if isinstance(test, unittest.TestSuite):
            _filter_suite(test, pred)
            newtests.append(test)
        else:
            if pred(test):
                newtests.append(test)
    suite._tests = newtests


def _run_suite(suite):
    """Run tests from a unittest.TestSuite-derived class."""
    if verbose:
        runner = unittest.TextTestRunner(sys.stdout, verbosity=2,
                                         failfast=failfast)
    else:
        runner = BasicTestRunner()

    result = runner.run(suite)
    if not result.wasSuccessful():
        if len(result.errors) == 1 and not result.failures:
            err = result.errors[0][1]
        elif len(result.failures) == 1 and not result.errors:
            err = result.failures[0][1]
        else:
            err = "multiple errors occurred"
            if not verbose: err += "; run in verbose mode for details"
        raise TestFailed(err)


def run_unittest(*classes):
    """Run tests from unittest.TestCase-derived classes."""
    valid_types = (unittest.TestSuite, unittest.TestCase)
    suite = unittest.TestSuite()
    for cls in classes:
        if isinstance(cls, str):
            if cls in sys.modules:
                suite.addTest(unittest.findTestCases(sys.modules[cls]))
            else:
                raise ValueError("str arguments must be keys in sys.modules")
        elif isinstance(cls, valid_types):
            suite.addTest(cls)
        else:
            suite.addTest(unittest.makeSuite(cls))
    def case_pred(test):
        if match_tests is None:
            return True
        for name in test.id().split("."):
            if fnmatch.fnmatchcase(name, match_tests):
                return True
        return False
    _filter_suite(suite, case_pred)
    _run_suite(suite)


#=======================================================================
# doctest driver.

def run_doctest(module, verbosity=None):
    """Run doctest on the given module.  Return (#failures, #tests).

    If optional argument verbosity is not specified (or is None), pass
    support's belief about verbosity on to doctest.  Else doctest's
    usual behavior is used (it searches sys.argv for -v).
    """

    import doctest

    if verbosity is None:
        verbosity = verbose
    else:
        verbosity = None

    f, t = doctest.testmod(module, verbose=verbosity)
    if f:
        raise TestFailed("%d of %d doctests failed" % (f, t))
    if verbose:
        print('doctest (%s) ... %d tests with zero failures' %
              (module.__name__, t))
    return f, t


#=======================================================================
# Support for saving and restoring the imported modules.

def modules_setup():
    return sys.modules.copy(),

def modules_cleanup(oldmodules):
    # Encoders/decoders are registered permanently within the internal
    # codec cache. If we destroy the corresponding modules their
    # globals will be set to None which will trip up the cached functions.
    encodings = [(k, v) for k, v in sys.modules.items()
                 if k.startswith('encodings.')]
    sys.modules.clear()
    sys.modules.update(encodings)
    # XXX: This kind of problem can affect more than just encodings. In particular
    # extension modules (such as _ssl) don't cope with reloading properly.
    # Really, test modules should be cleaning out the test specific modules they
    # know they added (ala test_runpy) rather than relying on this function (as
    # test_importhooks and test_pkg do currently).
    # Implicitly imported *real* modules should be left alone (see issue 10556).
    sys.modules.update(oldmodules)

#=======================================================================
# Threading support to prevent reporting refleaks when running regrtest.py -R

# NOTE: we use thread._count() rather than threading.enumerate() (or the
# moral equivalent thereof) because a threading.Thread object is still alive
# until its __bootstrap() method has returned, even after it has been
# unregistered from the threading module.
# thread._count(), on the other hand, only gets decremented *after* the
# __bootstrap() method has returned, which gives us reliable reference counts
# at the end of a test run.

def threading_setup():
    if _thread:
        return _thread._count(), threading._dangling.copy()
    else:
        return 1, ()

def threading_cleanup(*original_values):
    if not _thread:
        return
    _MAX_COUNT = 10
    for count in range(_MAX_COUNT):
        values = _thread._count(), threading._dangling
        if values == original_values:
            break
        time.sleep(0.1)
        gc_collect()
    # XXX print a warning in case of failure?

def reap_threads(func):
    """Use this function when threads are being used.  This will
    ensure that the threads are cleaned up even when the test fails.
    If threading is unavailable this function does nothing.
    """
    if not _thread:
        return func

    @functools.wraps(func)
    def decorator(*args):
        key = threading_setup()
        try:
            return func(*args)
        finally:
            threading_cleanup(*key)
    return decorator

def reap_children():
    """Use this function at the end of test_main() whenever sub-processes
    are started.  This will help ensure that no extra children (zombies)
    stick around to hog resources and create problems when looking
    for refleaks.
    """

    # Reap all our dead child processes so we don't leave zombies around.
    # These hog resources and might be causing some of the buildbots to die.
    if hasattr(os, 'waitpid'):
        any_process = -1
        while True:
            try:
                # This will raise an exception on Windows.  That's ok.
                pid, status = os.waitpid(any_process, os.WNOHANG)
                if pid == 0:
                    break
            except:
                break

@contextlib.contextmanager
def swap_attr(obj, attr, new_val):
    """Temporary swap out an attribute with a new object.

    Usage:
        with swap_attr(obj, "attr", 5):
            ...

        This will set obj.attr to 5 for the duration of the with: block,
        restoring the old value at the end of the block. If `attr` doesn't
        exist on `obj`, it will be created and then deleted at the end of the
        block.
    """
    if hasattr(obj, attr):
        real_val = getattr(obj, attr)
        setattr(obj, attr, new_val)
        try:
            yield None
        finally:
            setattr(obj, attr, real_val)
    else:
        setattr(obj, attr, new_val)
        try:
            yield None
        finally:
            delattr(obj, attr)

@contextlib.contextmanager
def swap_item(obj, item, new_val):
    """Temporary swap out an item with a new object.

    Usage:
        with swap_item(obj, "item", 5):
            ...

        This will set obj["item"] to 5 for the duration of the with: block,
        restoring the old value at the end of the block. If `item` doesn't
        exist on `obj`, it will be created and then deleted at the end of the
        block.
    """
    if item in obj:
        real_val = obj[item]
        obj[item] = new_val
        try:
            yield None
        finally:
            obj[item] = real_val
    else:
        obj[item] = new_val
        try:
            yield None
        finally:
            del obj[item]

def strip_python_stderr(stderr):
    """Strip the stderr of a Python process from potential debug output
    emitted by the interpreter.

    This will typically be run on the result of the communicate() method
    of a subprocess.Popen object.
    """
    stderr = re.sub(br"\[\d+ refs\]\r?\n?$", b"", stderr).strip()
    return stderr

def args_from_interpreter_flags():
    """Return a list of command-line arguments reproducing the current
    settings in sys.flags."""
    flag_opt_map = {
        'bytes_warning': 'b',
        'dont_write_bytecode': 'B',
        'hash_randomization': 'R',
        'ignore_environment': 'E',
        'no_user_site': 's',
        'no_site': 'S',
        'optimize': 'O',
        'verbose': 'v',
    }
    args = []
    for flag, opt in flag_opt_map.items():
        v = getattr(sys.flags, flag)
        if v > 0:
            args.append('-' + opt * v)
    return args

#============================================================
# Support for assertions about logging.
#============================================================

class TestHandler(logging.handlers.BufferingHandler):
    def __init__(self, matcher):
        # BufferingHandler takes a "capacity" argument
        # so as to know when to flush. As we're overriding
        # shouldFlush anyway, we can set a capacity of zero.
        # You can call flush() manually to clear out the
        # buffer.
        logging.handlers.BufferingHandler.__init__(self, 0)
        self.matcher = matcher

    def shouldFlush(self, record):
        return False

    def emit(self, record):
        self.format(record)
        self.buffer.append(record.__dict__)

    def matches(self, **kwargs):
        """
        Look for a saved dict whose keys/values match the supplied arguments.
        """
        result = False
        for d in self.buffer:
            if self.matcher.matches(d, **kwargs):
                result = True
                break
        return result

class Matcher(object):

    _partial_matches = ('msg', 'message')

    def matches(self, d, **kwargs):
        """
        Try to match a single dict with the supplied arguments.

        Keys whose values are strings and which are in self._partial_matches
        will be checked for partial (i.e. substring) matches. You can extend
        this scheme to (for example) do regular expression matching, etc.
        """
        result = True
        for k in kwargs:
            v = kwargs[k]
            dv = d.get(k)
            if not self.match_value(k, dv, v):
                result = False
                break
        return result

    def match_value(self, k, dv, v):
        """
        Try to match a single stored value (dv) with a supplied value (v).
        """
        if type(v) != type(dv):
            result = False
        elif type(dv) is not str or k not in self._partial_matches:
            result = (v == dv)
        else:
            result = dv.find(v) >= 0
        return result


_can_symlink = None # type: Any
def can_symlink():
    global _can_symlink
    if _can_symlink is not None:
        return _can_symlink
    symlink_path = TESTFN + "can_symlink"
    try:
        os.symlink(TESTFN, symlink_path)
        can = True
    except (OSError, NotImplementedError, AttributeError):
        can = False
    else:
        os.remove(symlink_path)
    _can_symlink = can
    return can

def skip_unless_symlink(test):
    """Skip decorator for tests that require functional symlink"""
    ok = can_symlink()
    msg = "Requires functional symlink implementation"
    if ok:
        return test
    else:
        return unittest.skip(msg)(test)

def patch(test_instance, object_to_patch, attr_name, new_value):
    """Override 'object_to_patch'.'attr_name' with 'new_value'.

    Also, add a cleanup procedure to 'test_instance' to restore
    'object_to_patch' value for 'attr_name'.
    The 'attr_name' should be a valid attribute for 'object_to_patch'.

    """
    # check that 'attr_name' is a real attribute for 'object_to_patch'
    # will raise AttributeError if it does not exist
    getattr(object_to_patch, attr_name)

    # keep a copy of the old value
    attr_is_local = False
    try:
        old_value = object_to_patch.__dict__[attr_name]
    except (AttributeError, KeyError):
        old_value = getattr(object_to_patch, attr_name, None)
    else:
        attr_is_local = True

    # restore the value when the test is done
    def cleanup():
        if attr_is_local:
            setattr(object_to_patch, attr_name, old_value)
        else:
            delattr(object_to_patch, attr_name)

    test_instance.addCleanup(cleanup)

    # actually override the attribute
    setattr(object_to_patch, attr_name, new_value)

########NEW FILE########
__FILENAME__ = test_base64
import unittest
from test import support
import base64
import binascii
import sys
import subprocess

from typing import Any



class LegacyBase64TestCase(unittest.TestCase):
    def test_encodebytes(self) -> None:
        eq = self.assertEqual
        eq(base64.encodebytes(b"www.python.org"), b"d3d3LnB5dGhvbi5vcmc=\n")
        eq(base64.encodebytes(b"a"), b"YQ==\n")
        eq(base64.encodebytes(b"ab"), b"YWI=\n")
        eq(base64.encodebytes(b"abc"), b"YWJj\n")
        eq(base64.encodebytes(b""), b"")
        eq(base64.encodebytes(b"abcdefghijklmnopqrstuvwxyz"
                               b"ABCDEFGHIJKLMNOPQRSTUVWXYZ"
                               b"0123456789!@#0^&*();:<>,. []{}"),
           b"YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXpBQkNE"
           b"RUZHSElKS0xNTk9QUVJTVFVWV1hZWjAxMjM0\nNT"
           b"Y3ODkhQCMwXiYqKCk7Ojw+LC4gW117fQ==\n")
        self.assertRaises(TypeError, base64.encodebytes, "")

    def test_decodebytes(self) -> None:
        eq = self.assertEqual
        eq(base64.decodebytes(b"d3d3LnB5dGhvbi5vcmc=\n"), b"www.python.org")
        eq(base64.decodebytes(b"YQ==\n"), b"a")
        eq(base64.decodebytes(b"YWI=\n"), b"ab")
        eq(base64.decodebytes(b"YWJj\n"), b"abc")
        eq(base64.decodebytes(b"YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXpBQkNE"
                               b"RUZHSElKS0xNTk9QUVJTVFVWV1hZWjAxMjM0\nNT"
                               b"Y3ODkhQCMwXiYqKCk7Ojw+LC4gW117fQ==\n"),
           b"abcdefghijklmnopqrstuvwxyz"
           b"ABCDEFGHIJKLMNOPQRSTUVWXYZ"
           b"0123456789!@#0^&*();:<>,. []{}")
        eq(base64.decodebytes(b''), b'')
        self.assertRaises(TypeError, base64.decodebytes, "")

    def test_encode(self) -> None:
        eq = self.assertEqual
        from io import BytesIO
        infp = BytesIO(b'abcdefghijklmnopqrstuvwxyz'
                       b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
                       b'0123456789!@#0^&*();:<>,. []{}')
        outfp = BytesIO()
        base64.encode(infp, outfp)
        eq(outfp.getvalue(),
           b'YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXpBQkNE'
           b'RUZHSElKS0xNTk9QUVJTVFVWV1hZWjAxMjM0\nNT'
           b'Y3ODkhQCMwXiYqKCk7Ojw+LC4gW117fQ==\n')

    def test_decode(self) -> None:
        from io import BytesIO
        infp = BytesIO(b'd3d3LnB5dGhvbi5vcmc=')
        outfp = BytesIO()
        base64.decode(infp, outfp)
        self.assertEqual(outfp.getvalue(), b'www.python.org')


class BaseXYTestCase(unittest.TestCase):
    def test_b64encode(self) -> None:
        eq = self.assertEqual
        # Test default alphabet
        eq(base64.b64encode(b"www.python.org"), b"d3d3LnB5dGhvbi5vcmc=")
        eq(base64.b64encode(b'\x00'), b'AA==')
        eq(base64.b64encode(b"a"), b"YQ==")
        eq(base64.b64encode(b"ab"), b"YWI=")
        eq(base64.b64encode(b"abc"), b"YWJj")
        eq(base64.b64encode(b""), b"")
        eq(base64.b64encode(b"abcdefghijklmnopqrstuvwxyz"
                            b"ABCDEFGHIJKLMNOPQRSTUVWXYZ"
                            b"0123456789!@#0^&*();:<>,. []{}"),
           b"YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXpBQkNE"
           b"RUZHSElKS0xNTk9QUVJTVFVWV1hZWjAxMjM0NT"
           b"Y3ODkhQCMwXiYqKCk7Ojw+LC4gW117fQ==")
        # Test with arbitrary alternative characters
        eq(base64.b64encode(b'\xd3V\xbeo\xf7\x1d', altchars=b'*$'), b'01a*b$cd')
        # Check if passing a str object raises an error
        self.assertRaises(TypeError, base64.b64encode, "")
        self.assertRaises(TypeError, base64.b64encode, b"", altchars="")
        # Test standard alphabet
        eq(base64.standard_b64encode(b"www.python.org"), b"d3d3LnB5dGhvbi5vcmc=")
        eq(base64.standard_b64encode(b"a"), b"YQ==")
        eq(base64.standard_b64encode(b"ab"), b"YWI=")
        eq(base64.standard_b64encode(b"abc"), b"YWJj")
        eq(base64.standard_b64encode(b""), b"")
        eq(base64.standard_b64encode(b"abcdefghijklmnopqrstuvwxyz"
                                     b"ABCDEFGHIJKLMNOPQRSTUVWXYZ"
                                     b"0123456789!@#0^&*();:<>,. []{}"),
           b"YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXpBQkNE"
           b"RUZHSElKS0xNTk9QUVJTVFVWV1hZWjAxMjM0NT"
           b"Y3ODkhQCMwXiYqKCk7Ojw+LC4gW117fQ==")
        # Check if passing a str object raises an error
        self.assertRaises(TypeError, base64.standard_b64encode, "")
        self.assertRaises(TypeError, base64.standard_b64encode, b"", altchars="")
        # Test with 'URL safe' alternative characters
        eq(base64.urlsafe_b64encode(b'\xd3V\xbeo\xf7\x1d'), b'01a-b_cd')
        # Check if passing a str object raises an error
        self.assertRaises(TypeError, base64.urlsafe_b64encode, "")

    def test_b64decode(self) -> None:
        eq = self.assertEqual
        eq(base64.b64decode(b"d3d3LnB5dGhvbi5vcmc="), b"www.python.org")
        eq(base64.b64decode(b'AA=='), b'\x00')
        eq(base64.b64decode(b"YQ=="), b"a")
        eq(base64.b64decode(b"YWI="), b"ab")
        eq(base64.b64decode(b"YWJj"), b"abc")
        eq(base64.b64decode(b"YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXpBQkNE"
                            b"RUZHSElKS0xNTk9QUVJTVFVWV1hZWjAxMjM0\nNT"
                            b"Y3ODkhQCMwXiYqKCk7Ojw+LC4gW117fQ=="),
           b"abcdefghijklmnopqrstuvwxyz"
           b"ABCDEFGHIJKLMNOPQRSTUVWXYZ"
           b"0123456789!@#0^&*();:<>,. []{}")
        eq(base64.b64decode(b''), b'')
        # Test with arbitrary alternative characters
        eq(base64.b64decode(b'01a*b$cd', altchars=b'*$'), b'\xd3V\xbeo\xf7\x1d')
        # Check if passing a str object raises an error
        self.assertRaises(TypeError, base64.b64decode, "")
        self.assertRaises(TypeError, base64.b64decode, b"", altchars="")
        # Test standard alphabet
        eq(base64.standard_b64decode(b"d3d3LnB5dGhvbi5vcmc="), b"www.python.org")
        eq(base64.standard_b64decode(b"YQ=="), b"a")
        eq(base64.standard_b64decode(b"YWI="), b"ab")
        eq(base64.standard_b64decode(b"YWJj"), b"abc")
        eq(base64.standard_b64decode(b""), b"")
        eq(base64.standard_b64decode(b"YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXpBQkNE"
                                     b"RUZHSElKS0xNTk9QUVJTVFVWV1hZWjAxMjM0NT"
                                     b"Y3ODkhQCMwXiYqKCk7Ojw+LC4gW117fQ=="),
           b"abcdefghijklmnopqrstuvwxyz"
           b"ABCDEFGHIJKLMNOPQRSTUVWXYZ"
           b"0123456789!@#0^&*();:<>,. []{}")
        # Check if passing a str object raises an error
        self.assertRaises(TypeError, base64.standard_b64decode, "")
        self.assertRaises(TypeError, base64.standard_b64decode, b"", altchars="")
        # Test with 'URL safe' alternative characters
        eq(base64.urlsafe_b64decode(b'01a-b_cd'), b'\xd3V\xbeo\xf7\x1d')
        self.assertRaises(TypeError, base64.urlsafe_b64decode, "")

    def test_b64decode_padding_error(self) -> None:
        self.assertRaises(binascii.Error, base64.b64decode, b'abc')

    def test_b64decode_invalid_chars(self) -> None:
        # issue 1466065: Test some invalid characters.
        tests = ((b'%3d==', b'\xdd'),
                 (b'$3d==', b'\xdd'),
                 (b'[==', b''),
                 (b'YW]3=', b'am'),
                 (b'3{d==', b'\xdd'),
                 (b'3d}==', b'\xdd'),
                 (b'@@', b''),
                 (b'!', b''),
                 (b'YWJj\nYWI=', b'abcab'))
        for bstr, res in tests:
            self.assertEqual(base64.b64decode(bstr), res)
            with self.assertRaises(binascii.Error):
                base64.b64decode(bstr, validate=True)

    def test_b32encode(self) -> None:
        eq = self.assertEqual
        eq(base64.b32encode(b''), b'')
        eq(base64.b32encode(b'\x00'), b'AA======')
        eq(base64.b32encode(b'a'), b'ME======')
        eq(base64.b32encode(b'ab'), b'MFRA====')
        eq(base64.b32encode(b'abc'), b'MFRGG===')
        eq(base64.b32encode(b'abcd'), b'MFRGGZA=')
        eq(base64.b32encode(b'abcde'), b'MFRGGZDF')
        self.assertRaises(TypeError, base64.b32encode, "")

    def test_b32decode(self) -> None:
        eq = self.assertEqual
        eq(base64.b32decode(b''), b'')
        eq(base64.b32decode(b'AA======'), b'\x00')
        eq(base64.b32decode(b'ME======'), b'a')
        eq(base64.b32decode(b'MFRA===='), b'ab')
        eq(base64.b32decode(b'MFRGG==='), b'abc')
        eq(base64.b32decode(b'MFRGGZA='), b'abcd')
        eq(base64.b32decode(b'MFRGGZDF'), b'abcde')
        self.assertRaises(TypeError, base64.b32decode, "")

    def test_b32decode_casefold(self) -> None:
        eq = self.assertEqual
        eq(base64.b32decode(b'', True), b'')
        eq(base64.b32decode(b'ME======', True), b'a')
        eq(base64.b32decode(b'MFRA====', True), b'ab')
        eq(base64.b32decode(b'MFRGG===', True), b'abc')
        eq(base64.b32decode(b'MFRGGZA=', True), b'abcd')
        eq(base64.b32decode(b'MFRGGZDF', True), b'abcde')
        # Lower cases
        eq(base64.b32decode(b'me======', True), b'a')
        eq(base64.b32decode(b'mfra====', True), b'ab')
        eq(base64.b32decode(b'mfrgg===', True), b'abc')
        eq(base64.b32decode(b'mfrggza=', True), b'abcd')
        eq(base64.b32decode(b'mfrggzdf', True), b'abcde')
        # Expected exceptions
        self.assertRaises(TypeError, base64.b32decode, b'me======')
        # Mapping zero and one
        eq(base64.b32decode(b'MLO23456'), b'b\xdd\xad\xf3\xbe')
        eq(base64.b32decode(b'M1023456', map01=b'L'), b'b\xdd\xad\xf3\xbe')
        eq(base64.b32decode(b'M1023456', map01=b'I'), b'b\x1d\xad\xf3\xbe')
        self.assertRaises(TypeError, base64.b32decode, b"", map01="")

    def test_b32decode_error(self) -> None:
        self.assertRaises(binascii.Error, base64.b32decode, b'abc')
        self.assertRaises(binascii.Error, base64.b32decode, b'ABCDEF==')

    def test_b16encode(self) -> None:
        eq = self.assertEqual
        eq(base64.b16encode(b'\x01\x02\xab\xcd\xef'), b'0102ABCDEF')
        eq(base64.b16encode(b'\x00'), b'00')
        self.assertRaises(TypeError, base64.b16encode, "")

    def test_b16decode(self) -> None:
        eq = self.assertEqual
        eq(base64.b16decode(b'0102ABCDEF'), b'\x01\x02\xab\xcd\xef')
        eq(base64.b16decode(b'00'), b'\x00')
        # Lower case is not allowed without a flag
        self.assertRaises(binascii.Error, base64.b16decode, b'0102abcdef')
        # Case fold
        eq(base64.b16decode(b'0102abcdef', True), b'\x01\x02\xab\xcd\xef')
        self.assertRaises(TypeError, base64.b16decode, "")

    def test_ErrorHeritage(self) -> None:
        self.assertTrue(issubclass(binascii.Error, ValueError))



class TestMain(unittest.TestCase):
    def get_output(self, *args: str, **options: Any) -> Any:
        args = [sys.executable, '-m', 'base64'] + list(args)
        return subprocess.check_output(args, **options)

    def test_encode_decode(self) -> None:
        output = self.get_output('-t')
        self.assertSequenceEqual(output.splitlines(), [
            b"b'Aladdin:open sesame'",
            br"b'QWxhZGRpbjpvcGVuIHNlc2FtZQ==\n'",
            b"b'Aladdin:open sesame'",
        ])

    def test_encode_file(self) -> None:
        with open(support.TESTFN, 'wb') as fp:
            fp.write(b'a\xffb\n')

        output = self.get_output('-e', support.TESTFN)
        self.assertEqual(output.rstrip(), b'Yf9iCg==')

        with open(support.TESTFN, 'rb') as fp:
            output = self.get_output('-e', stdin=fp)
        self.assertEqual(output.rstrip(), b'Yf9iCg==')

    def test_decode(self) -> None:
        with open(support.TESTFN, 'wb') as fp:
            fp.write(b'Yf9iCg==')
        output = self.get_output('-d', support.TESTFN)
        self.assertEqual(output.rstrip(), b'a\xffb')



def test_main() -> None:
    support.run_unittest(__name__)

if __name__ == '__main__':
    test_main()

########NEW FILE########
__FILENAME__ = test_fnmatch
"""Test cases for the fnmatch module."""

from test import support
import unittest

from fnmatch import fnmatch, fnmatchcase, translate, filter

from typing import Any, AnyStr, Function

class FnmatchTestCase(unittest.TestCase):

    def check_match(self, filename: AnyStr, pattern: AnyStr,
                    should_match: int = 1,
                    fn: Any = fnmatch) -> None:  # see #270
        if should_match:
            self.assertTrue(fn(filename, pattern),
                         "expected %r to match pattern %r"
                         % (filename, pattern))
        else:
            self.assertTrue(not fn(filename, pattern),
                         "expected %r not to match pattern %r"
                         % (filename, pattern))

    def test_fnmatch(self) -> None:
        check = self.check_match
        check('abc', 'abc')
        check('abc', '?*?')
        check('abc', '???*')
        check('abc', '*???')
        check('abc', '???')
        check('abc', '*')
        check('abc', 'ab[cd]')
        check('abc', 'ab[!de]')
        check('abc', 'ab[de]', 0)
        check('a', '??', 0)
        check('a', 'b', 0)

        # these test that '\' is handled correctly in character sets;
        # see SF bug #409651
        check('\\', r'[\]')
        check('a', r'[!\]')
        check('\\', r'[!\]', 0)

        # test that filenames with newlines in them are handled correctly.
        # http://bugs.python.org/issue6665
        check('foo\nbar', 'foo*')
        check('foo\nbar\n', 'foo*')
        check('\nfoo', 'foo*', False)
        check('\n', '*')

    def test_mix_bytes_str(self) -> None:
        self.assertRaises(TypeError, fnmatch, 'test', b'*')
        self.assertRaises(TypeError, fnmatch, b'test', '*')
        self.assertRaises(TypeError, fnmatchcase, 'test', b'*')
        self.assertRaises(TypeError, fnmatchcase, b'test', '*')

    def test_fnmatchcase(self) -> None:
        check = self.check_match
        check('AbC', 'abc', 0, fnmatchcase)
        check('abc', 'AbC', 0, fnmatchcase)

    def test_bytes(self) -> None:
        self.check_match(b'test', b'te*')
        self.check_match(b'test\xff', b'te*\xff')
        self.check_match(b'foo\nbar', b'foo*')

class TranslateTestCase(unittest.TestCase):

    def test_translate(self) -> None:
        self.assertEqual(translate('*'), '.*\Z(?ms)')
        self.assertEqual(translate('?'), '.\Z(?ms)')
        self.assertEqual(translate('a?b*'), 'a.b.*\Z(?ms)')
        self.assertEqual(translate('[abc]'), '[abc]\Z(?ms)')
        self.assertEqual(translate('[]]'), '[]]\Z(?ms)')
        self.assertEqual(translate('[!x]'), '[^x]\Z(?ms)')
        self.assertEqual(translate('[^x]'), '[\\^x]\Z(?ms)')
        self.assertEqual(translate('[x'), '\\[x\Z(?ms)')


class FilterTestCase(unittest.TestCase):

    def test_filter(self) -> None:
        self.assertEqual(filter(['a', 'b'], 'a'), ['a'])


def test_main() -> None:
    support.run_unittest(FnmatchTestCase,
                         TranslateTestCase,
                         FilterTestCase)


if __name__ == "__main__":
    test_main()

########NEW FILE########
__FILENAME__ = test_genericpath
"""
Tests common to genericpath, macpath, ntpath and posixpath
"""

import unittest
from test import support
import os

import genericpath
import imp
imp.reload(genericpath) # Make sure we are using the local copy

import sys
from typing import Any, List


def safe_rmdir(dirname: str) -> None:
    try:
        os.rmdir(dirname)
    except OSError:
        pass


class GenericTest(unittest.TestCase):
    # The path module to be tested
    pathmodule = genericpath # type: Any
    common_attributes = ['commonprefix', 'getsize', 'getatime', 'getctime',
                         'getmtime', 'exists', 'isdir', 'isfile']
    attributes = List[str]()

    def test_no_argument(self) -> None:
        for attr in self.common_attributes + self.attributes:
            with self.assertRaises(TypeError):
                getattr(self.pathmodule, attr)()
                self.fail("{}.{}() did not raise a TypeError"
                          .format(self.pathmodule.__name__, attr))

    def test_commonprefix(self) -> None:
        commonprefix = self.pathmodule.commonprefix
        self.assertEqual(
            commonprefix([]),
            ""
        )
        self.assertEqual(
            commonprefix(["/home/swenson/spam", "/home/swen/spam"]),
            "/home/swen"
        )
        self.assertEqual(
            commonprefix(["/home/swen/spam", "/home/swen/eggs"]),
            "/home/swen/"
        )
        self.assertEqual(
            commonprefix(["/home/swen/spam", "/home/swen/spam"]),
            "/home/swen/spam"
        )
        self.assertEqual(
            commonprefix(["home:swenson:spam", "home:swen:spam"]),
            "home:swen"
        )
        self.assertEqual(
            commonprefix([":home:swen:spam", ":home:swen:eggs"]),
            ":home:swen:"
        )
        self.assertEqual(
            commonprefix([":home:swen:spam", ":home:swen:spam"]),
            ":home:swen:spam"
        )

        self.assertEqual(
            commonprefix([b"/home/swenson/spam", b"/home/swen/spam"]),
            b"/home/swen"
        )
        self.assertEqual(
            commonprefix([b"/home/swen/spam", b"/home/swen/eggs"]),
            b"/home/swen/"
        )
        self.assertEqual(
            commonprefix([b"/home/swen/spam", b"/home/swen/spam"]),
            b"/home/swen/spam"
        )
        self.assertEqual(
            commonprefix([b"home:swenson:spam", b"home:swen:spam"]),
            b"home:swen"
        )
        self.assertEqual(
            commonprefix([b":home:swen:spam", b":home:swen:eggs"]),
            b":home:swen:"
        )
        self.assertEqual(
            commonprefix([b":home:swen:spam", b":home:swen:spam"]),
            b":home:swen:spam"
        )

        testlist = ['', 'abc', 'Xbcd', 'Xb', 'XY', 'abcd',
                    'aXc', 'abd', 'ab', 'aX', 'abcX']
        for s1 in testlist:
            for s2 in testlist:
                p = commonprefix([s1, s2])
                self.assertTrue(s1.startswith(p))
                self.assertTrue(s2.startswith(p))
                if s1 != s2:
                    n = len(p)
                    self.assertNotEqual(s1[n:n+1], s2[n:n+1])

    def test_getsize(self) -> None:
        f = open(support.TESTFN, "wb")
        try:
            f.write(b"foo")
            f.close()
            self.assertEqual(self.pathmodule.getsize(support.TESTFN), 3)
        finally:
            if not f.closed:
                f.close()
            support.unlink(support.TESTFN)

    def test_time(self) -> None:
        f = open(support.TESTFN, "wb")
        try:
            f.write(b"foo")
            f.close()
            f = open(support.TESTFN, "ab")
            f.write(b"bar")
            f.close()
            f = open(support.TESTFN, "rb")
            d = f.read()
            f.close()
            self.assertEqual(d, b"foobar")

            self.assertLessEqual(
                self.pathmodule.getctime(support.TESTFN),
                self.pathmodule.getmtime(support.TESTFN)
            )
        finally:
            if not f.closed:
                f.close()
            support.unlink(support.TESTFN)

    def test_exists(self) -> None:
        self.assertIs(self.pathmodule.exists(support.TESTFN), False)
        f = open(support.TESTFN, "wb")
        try:
            f.write(b"foo")
            f.close()
            self.assertIs(self.pathmodule.exists(support.TESTFN), True)
            if not self.pathmodule == genericpath:
                self.assertIs(self.pathmodule.lexists(support.TESTFN),
                              True)
        finally:
            if not f.closed:
                f.close()
            support.unlink(support.TESTFN)

    def test_isdir(self) -> None:
        self.assertIs(self.pathmodule.isdir(support.TESTFN), False)
        f = open(support.TESTFN, "wb")
        try:
            f.write(b"foo")
            f.close()
            self.assertIs(self.pathmodule.isdir(support.TESTFN), False)
            os.remove(support.TESTFN)
            os.mkdir(support.TESTFN)
            self.assertIs(self.pathmodule.isdir(support.TESTFN), True)
            os.rmdir(support.TESTFN)
        finally:
            if not f.closed:
                f.close()
            support.unlink(support.TESTFN)
            safe_rmdir(support.TESTFN)

    def test_isfile(self) -> None:
        self.assertIs(self.pathmodule.isfile(support.TESTFN), False)
        f = open(support.TESTFN, "wb")
        try:
            f.write(b"foo")
            f.close()
            self.assertIs(self.pathmodule.isfile(support.TESTFN), True)
            os.remove(support.TESTFN)
            os.mkdir(support.TESTFN)
            self.assertIs(self.pathmodule.isfile(support.TESTFN), False)
            os.rmdir(support.TESTFN)
        finally:
            if not f.closed:
                f.close()
            support.unlink(support.TESTFN)
            safe_rmdir(support.TESTFN)


# Following TestCase is not supposed to be run from test_genericpath.
# It is inherited by other test modules (macpath, ntpath, posixpath).

class CommonTest(GenericTest):
    # The path module to be tested
    pathmodule = None # type: Any
    common_attributes = GenericTest.common_attributes + [
        # Properties
        'curdir', 'pardir', 'extsep', 'sep',
        'pathsep', 'defpath', 'altsep', 'devnull',
        # Methods
        'normcase', 'splitdrive', 'expandvars', 'normpath', 'abspath',
        'join', 'split', 'splitext', 'isabs', 'basename', 'dirname',
        'lexists', 'islink', 'ismount', 'expanduser', 'normpath', 'realpath',
    ]

    def test_normcase(self) -> None:
        normcase = self.pathmodule.normcase
        # check that normcase() is idempotent
        for p in ["FoO/./BaR", b"FoO/./BaR"]:
            p = normcase(p)
            self.assertEqual(p, normcase(p))

        self.assertEqual(normcase(''), '')
        self.assertEqual(normcase(b''), b'')

        # check that normcase raises a TypeError for invalid types
        for path in (None, True, 0, 2.5, [], bytearray(b''), {'o','o'}):
            self.assertRaises(TypeError, normcase, path)

    def test_splitdrive(self) -> None:
        # splitdrive for non-NT paths
        splitdrive = self.pathmodule.splitdrive
        self.assertEqual(splitdrive("/foo/bar"), ("", "/foo/bar"))
        self.assertEqual(splitdrive("foo:bar"), ("", "foo:bar"))
        self.assertEqual(splitdrive(":foo:bar"), ("", ":foo:bar"))

        self.assertEqual(splitdrive(b"/foo/bar"), (b"", b"/foo/bar"))
        self.assertEqual(splitdrive(b"foo:bar"), (b"", b"foo:bar"))
        self.assertEqual(splitdrive(b":foo:bar"), (b"", b":foo:bar"))

    def test_expandvars(self) -> None:
        if self.pathmodule.__name__ == 'macpath':
            self.skipTest('macpath.expandvars is a stub')
        expandvars = self.pathmodule.expandvars
        with support.EnvironmentVarGuard() as env:
            env.clear()
            env["foo"] = "bar"
            env["{foo"] = "baz1"
            env["{foo}"] = "baz2"
            self.assertEqual(expandvars("foo"), "foo")
            self.assertEqual(expandvars("$foo bar"), "bar bar")
            self.assertEqual(expandvars("${foo}bar"), "barbar")
            self.assertEqual(expandvars("$[foo]bar"), "$[foo]bar")
            self.assertEqual(expandvars("$bar bar"), "$bar bar")
            self.assertEqual(expandvars("$?bar"), "$?bar")
            self.assertEqual(expandvars("${foo}bar"), "barbar")
            self.assertEqual(expandvars("$foo}bar"), "bar}bar")
            self.assertEqual(expandvars("${foo"), "${foo")
            self.assertEqual(expandvars("${{foo}}"), "baz1}")
            self.assertEqual(expandvars("$foo$foo"), "barbar")
            self.assertEqual(expandvars("$bar$bar"), "$bar$bar")

            self.assertEqual(expandvars(b"foo"), b"foo")
            self.assertEqual(expandvars(b"$foo bar"), b"bar bar")
            self.assertEqual(expandvars(b"${foo}bar"), b"barbar")
            self.assertEqual(expandvars(b"$[foo]bar"), b"$[foo]bar")
            self.assertEqual(expandvars(b"$bar bar"), b"$bar bar")
            self.assertEqual(expandvars(b"$?bar"), b"$?bar")
            self.assertEqual(expandvars(b"${foo}bar"), b"barbar")
            self.assertEqual(expandvars(b"$foo}bar"), b"bar}bar")
            self.assertEqual(expandvars(b"${foo"), b"${foo")
            self.assertEqual(expandvars(b"${{foo}}"), b"baz1}")
            self.assertEqual(expandvars(b"$foo$foo"), b"barbar")
            self.assertEqual(expandvars(b"$bar$bar"), b"$bar$bar")

    def test_abspath(self) -> None:
        self.assertIn("foo", self.pathmodule.abspath("foo"))
        self.assertIn(b"foo", self.pathmodule.abspath(b"foo"))

        # Abspath returns bytes when the arg is bytes
        for path in (b'', b'foo', b'f\xf2\xf2', b'/foo', b'C:\\'):
            self.assertIsInstance(self.pathmodule.abspath(path), bytes)

    def test_realpath(self) -> None:
        self.assertIn("foo", self.pathmodule.realpath("foo"))
        self.assertIn(b"foo", self.pathmodule.realpath(b"foo"))

    def test_normpath_issue5827(self) -> None:
        # Make sure normpath preserves unicode
        for path in ('', '.', '/', '\\', '///foo/.//bar//'):
            self.assertIsInstance(self.pathmodule.normpath(path), str)

    def test_abspath_issue3426(self) -> None:
        # Check that abspath returns unicode when the arg is unicode
        # with both ASCII and non-ASCII cwds.
        abspath = self.pathmodule.abspath
        for path in ('', 'fuu', 'f\xf9\xf9', '/fuu', 'U:\\'):
            self.assertIsInstance(abspath(path), str)

        unicwd = '\xe7w\xf0'
        try:
            fsencoding = support.TESTFN_ENCODING or "ascii"
            unicwd.encode(fsencoding)
        except (AttributeError, UnicodeEncodeError):
            # FS encoding is probably ASCII
            pass
        else:
            with support.temp_cwd(unicwd):
                for path in ('', 'fuu', 'f\xf9\xf9', '/fuu', 'U:\\'):
                    self.assertIsInstance(abspath(path), str)

    @unittest.skipIf(sys.platform == 'darwin',
        "Mac OS X denies the creation of a directory with an invalid utf8 name")
    def test_nonascii_abspath(self) -> None:
        # Test non-ASCII, non-UTF8 bytes in the path.
        with support.temp_cwd(b'\xe7w\xf0'):
            self.test_abspath()


def test_main() -> None:
    support.run_unittest(GenericTest)


if __name__=="__main__":
    test_main()

########NEW FILE########
__FILENAME__ = test_getopt
# test_getopt.py
# David Goodger <dgoodger@bigfoot.com> 2000-08-19

from test.support import verbose, run_doctest, run_unittest, EnvironmentVarGuard
import unittest

import getopt

from typing import Any

sentinel = object()

class GetoptTests(unittest.TestCase):
    def setUp(self) -> None:
        self.env = EnvironmentVarGuard()
        if "POSIXLY_CORRECT" in self.env:
            del self.env["POSIXLY_CORRECT"]

    def tearDown(self) -> None:
        self.env.__exit__()
        del self.env

    def assertError(self, *args: Any, **kwargs: Any) -> None:
        # JLe: work around mypy bug #229
        Any(self.assertRaises)(getopt.GetoptError, *args, **kwargs)

    def test_short_has_arg(self) -> None:
        self.assertTrue(getopt.short_has_arg('a', 'a:'))
        self.assertFalse(getopt.short_has_arg('a', 'a'))
        self.assertError(getopt.short_has_arg, 'a', 'b')

    def test_long_has_args(self) -> None:
        has_arg, option = getopt.long_has_args('abc', ['abc='])
        self.assertTrue(has_arg)
        self.assertEqual(option, 'abc')

        has_arg, option = getopt.long_has_args('abc', ['abc'])
        self.assertFalse(has_arg)
        self.assertEqual(option, 'abc')

        has_arg, option = getopt.long_has_args('abc', ['abcd'])
        self.assertFalse(has_arg)
        self.assertEqual(option, 'abcd')

        self.assertError(getopt.long_has_args, 'abc', ['def'])
        self.assertError(getopt.long_has_args, 'abc', [])
        self.assertError(getopt.long_has_args, 'abc', ['abcd','abcde'])

    def test_do_shorts(self) -> None:
        opts, args = getopt.do_shorts([], 'a', 'a', [])
        self.assertEqual(opts, [('-a', '')])
        self.assertEqual(args, [])

        opts, args = getopt.do_shorts([], 'a1', 'a:', [])
        self.assertEqual(opts, [('-a', '1')])
        self.assertEqual(args, [])

        #opts, args = getopt.do_shorts([], 'a=1', 'a:', [])
        #self.assertEqual(opts, [('-a', '1')])
        #self.assertEqual(args, [])

        opts, args = getopt.do_shorts([], 'a', 'a:', ['1'])
        self.assertEqual(opts, [('-a', '1')])
        self.assertEqual(args, [])

        opts, args = getopt.do_shorts([], 'a', 'a:', ['1', '2'])
        self.assertEqual(opts, [('-a', '1')])
        self.assertEqual(args, ['2'])

        self.assertError(getopt.do_shorts, [], 'a1', 'a', [])
        self.assertError(getopt.do_shorts, [], 'a', 'a:', [])

    def test_do_longs(self) -> None:
        opts, args = getopt.do_longs([], 'abc', ['abc'], [])
        self.assertEqual(opts, [('--abc', '')])
        self.assertEqual(args, [])

        opts, args = getopt.do_longs([], 'abc=1', ['abc='], [])
        self.assertEqual(opts, [('--abc', '1')])
        self.assertEqual(args, [])

        opts, args = getopt.do_longs([], 'abc=1', ['abcd='], [])
        self.assertEqual(opts, [('--abcd', '1')])
        self.assertEqual(args, [])

        opts, args = getopt.do_longs([], 'abc', ['ab', 'abc', 'abcd'], [])
        self.assertEqual(opts, [('--abc', '')])
        self.assertEqual(args, [])

        # Much like the preceding, except with a non-alpha character ("-") in
        # option name that precedes "="; failed in
        # http://python.org/sf/126863
        opts, args = getopt.do_longs([], 'foo=42', ['foo-bar', 'foo=',], [])
        self.assertEqual(opts, [('--foo', '42')])
        self.assertEqual(args, [])

        self.assertError(getopt.do_longs, [], 'abc=1', ['abc'], [])
        self.assertError(getopt.do_longs, [], 'abc', ['abc='], [])

    def test_getopt(self) -> None:
        # note: the empty string between '-a' and '--beta' is significant:
        # it simulates an empty string option argument ('-a ""') on the
        # command line.
        cmdline = ['-a', '1', '-b', '--alpha=2', '--beta', '-a', '3', '-a',
                   '', '--beta', 'arg1', 'arg2']

        opts, args = getopt.getopt(cmdline, 'a:b', ['alpha=', 'beta'])
        self.assertEqual(opts, [('-a', '1'), ('-b', ''),
                                ('--alpha', '2'), ('--beta', ''),
                                ('-a', '3'), ('-a', ''), ('--beta', '')])
        # Note ambiguity of ('-b', '') and ('-a', '') above. This must be
        # accounted for in the code that calls getopt().
        self.assertEqual(args, ['arg1', 'arg2'])

        self.assertError(getopt.getopt, cmdline, 'a:b', ['alpha', 'beta'])

    def test_gnu_getopt(self) -> None:
        # Test handling of GNU style scanning mode.
        cmdline = ['-a', 'arg1', '-b', '1', '--alpha', '--beta=2']

        # GNU style
        opts, args = getopt.gnu_getopt(cmdline, 'ab:', ['alpha', 'beta='])
        self.assertEqual(args, ['arg1'])
        self.assertEqual(opts, [('-a', ''), ('-b', '1'),
                                ('--alpha', ''), ('--beta', '2')])

        # recognize "-" as an argument
        opts, args = getopt.gnu_getopt(['-a', '-', '-b', '-'], 'ab:', [])
        self.assertEqual(args, ['-'])
        self.assertEqual(opts, [('-a', ''), ('-b', '-')])

        # Posix style via +
        opts, args = getopt.gnu_getopt(cmdline, '+ab:', ['alpha', 'beta='])
        self.assertEqual(opts, [('-a', '')])
        self.assertEqual(args, ['arg1', '-b', '1', '--alpha', '--beta=2'])

        # Posix style via POSIXLY_CORRECT
        self.env["POSIXLY_CORRECT"] = "1"
        opts, args = getopt.gnu_getopt(cmdline, 'ab:', ['alpha', 'beta='])
        self.assertEqual(opts, [('-a', '')])
        self.assertEqual(args, ['arg1', '-b', '1', '--alpha', '--beta=2'])

    def test_libref_examples(self) -> None:
        s = """
        Examples from the Library Reference:  Doc/lib/libgetopt.tex

        An example using only Unix style options:


        >>> import getopt
        >>> args = '-a -b -cfoo -d bar a1 a2'.split()
        >>> args
        ['-a', '-b', '-cfoo', '-d', 'bar', 'a1', 'a2']
        >>> optlist, args = getopt.getopt(args, 'abc:d:')
        >>> optlist
        [('-a', ''), ('-b', ''), ('-c', 'foo'), ('-d', 'bar')]
        >>> args
        ['a1', 'a2']

        Using long option names is equally easy:


        >>> s = '--condition=foo --testing --output-file abc.def -x a1 a2'
        >>> args = s.split()
        >>> args
        ['--condition=foo', '--testing', '--output-file', 'abc.def', '-x', 'a1', 'a2']
        >>> optlist, args = getopt.getopt(args, 'x', [
        ...     'condition=', 'output-file=', 'testing'])
        >>> optlist
        [('--condition', 'foo'), ('--testing', ''), ('--output-file', 'abc.def'), ('-x', '')]
        >>> args
        ['a1', 'a2']
        """

        import types
        m = types.ModuleType("libreftest", s)
        run_doctest(m, verbose)

    def test_issue4629(self) -> None:
        longopts, shortopts = getopt.getopt(['--help='], '', ['help='])
        self.assertEqual(longopts, [('--help', '')])
        longopts, shortopts = getopt.getopt(['--help=x'], '', ['help='])
        self.assertEqual(longopts, [('--help', 'x')])
        self.assertRaises(getopt.GetoptError, getopt.getopt, ['--help='], '', ['help'])

def test_main() -> None:
    run_unittest(GetoptTests)

if __name__ == "__main__":
    test_main()

########NEW FILE########
__FILENAME__ = test_glob
import unittest
from test.support import run_unittest, TESTFN, skip_unless_symlink, can_symlink
import glob
import os
import shutil

from typing import typevar, Iterable, List

T = typevar('T')

class GlobTests(unittest.TestCase):

    tempdir = ''

    # JLe: work around mypy issue #231
    def norm(self, first: str, *parts: str) -> str:
        return os.path.normpath(os.path.join(self.tempdir, first, *parts))

    def mktemp(self, *parts: str) -> None:
        filename = self.norm(*parts)
        base, file = os.path.split(filename)
        if not os.path.exists(base):
            os.makedirs(base)
        f = open(filename, 'w')
        f.close()

    def setUp(self) -> None:
        self.tempdir = TESTFN+"_dir"
        self.mktemp('a', 'D')
        self.mktemp('aab', 'F')
        self.mktemp('aaa', 'zzzF')
        self.mktemp('ZZZ')
        self.mktemp('a', 'bcd', 'EF')
        self.mktemp('a', 'bcd', 'efg', 'ha')
        if can_symlink():
            os.symlink(self.norm('broken'), self.norm('sym1'))
            os.symlink(self.norm('broken'), self.norm('sym2'))

    def tearDown(self) -> None:
        shutil.rmtree(self.tempdir)

    def glob(self, *parts: str) -> List[str]:
        if len(parts) == 1:
            pattern = parts[0]
        else:
            pattern = os.path.join(*parts)
        p = os.path.join(self.tempdir, pattern)
        res = glob.glob(p)
        self.assertEqual(list(glob.iglob(p)), res)
        return res

    def assertSequencesEqual_noorder(self, l1: Iterable[T],
                                     l2: Iterable[T]) -> None:
        self.assertEqual(set(l1), set(l2))

    def test_glob_literal(self) -> None:
        eq = self.assertSequencesEqual_noorder
        eq(self.glob('a'), [self.norm('a')])
        eq(self.glob('a', 'D'), [self.norm('a', 'D')])
        eq(self.glob('aab'), [self.norm('aab')])
        eq(self.glob('zymurgy'), List[str]()) # JLe: work around #230

        # test return types are unicode, but only if os.listdir
        # returns unicode filenames
        uniset = set([str])
        tmp = os.listdir('.')
        if set(type(x) for x in tmp) == uniset:
            u1 = glob.glob('*')
            u2 = glob.glob('./*')
            self.assertEqual(set(type(r) for r in u1), uniset)
            self.assertEqual(set(type(r) for r in u2), uniset)

    def test_glob_one_directory(self) -> None:
        eq = self.assertSequencesEqual_noorder
        eq(self.glob('a*'), map(self.norm, ['a', 'aab', 'aaa']))
        eq(self.glob('*a'), map(self.norm, ['a', 'aaa']))
        eq(self.glob('aa?'), map(self.norm, ['aaa', 'aab']))
        eq(self.glob('aa[ab]'), map(self.norm, ['aaa', 'aab']))
        eq(self.glob('*q'), List[str]())

    def test_glob_nested_directory(self) -> None:
        eq = self.assertSequencesEqual_noorder
        if os.path.normcase("abCD") == "abCD":
            # case-sensitive filesystem
            eq(self.glob('a', 'bcd', 'E*'), [self.norm('a', 'bcd', 'EF')])
        else:
            # case insensitive filesystem
            eq(self.glob('a', 'bcd', 'E*'), [self.norm('a', 'bcd', 'EF'),
                                             self.norm('a', 'bcd', 'efg')])
        eq(self.glob('a', 'bcd', '*g'), [self.norm('a', 'bcd', 'efg')])

    def test_glob_directory_names(self) -> None:
        eq = self.assertSequencesEqual_noorder
        eq(self.glob('*', 'D'), [self.norm('a', 'D')])
        eq(self.glob('*', '*a'), List[str]())
        eq(self.glob('a', '*', '*', '*a'),
           [self.norm('a', 'bcd', 'efg', 'ha')])
        eq(self.glob('?a?', '*F'), map(self.norm, [os.path.join('aaa', 'zzzF'),
                                                   os.path.join('aab', 'F')]))

    def test_glob_directory_with_trailing_slash(self) -> None:
        # We are verifying that when there is wildcard pattern which
        # ends with os.sep doesn't blow up.
        res = glob.glob(self.tempdir + '*' + os.sep)
        self.assertEqual(len(res), 1)
        # either of these results are reasonable
        self.assertIn(res[0], [self.tempdir, self.tempdir + os.sep])

    @skip_unless_symlink
    def test_glob_broken_symlinks(self) -> None:
        eq = self.assertSequencesEqual_noorder
        eq(self.glob('sym*'), [self.norm('sym1'), self.norm('sym2')])
        eq(self.glob('sym1'), [self.norm('sym1')])
        eq(self.glob('sym2'), [self.norm('sym2')])


def test_main() -> None:
    run_unittest(GlobTests)


if __name__ == "__main__":
    test_main()

########NEW FILE########
__FILENAME__ = test_posixpath
import unittest
from test import support, test_genericpath

import posixpath
import genericpath

import imp
imp.reload(posixpath) # Make sure we are using the local copy
imp.reload(genericpath)

import os
import sys
from posixpath import realpath, abspath, dirname, basename

import posix
from typing import Any, typevar, Function

T = typevar('T')

# An absolute path to a temporary filename for testing. We can't rely on TESTFN
# being an absolute path, so we need this.

ABSTFN = abspath(support.TESTFN)

def skip_if_ABSTFN_contains_backslash(
        test: Function[[T], None]) -> Function[[T], None]:
    """
    On Windows, posixpath.abspath still returns paths with backslashes
    instead of posix forward slashes. If this is the case, several tests
    fail, so skip them.
    """
    found_backslash = '\\' in ABSTFN
    msg = "ABSTFN is not a posix path - tests fail"
    return [test, unittest.skip(msg)(test)][found_backslash]

def safe_rmdir(dirname: str) -> None:
    try:
        os.rmdir(dirname)
    except OSError:
        pass

class PosixPathTest(unittest.TestCase):

    def setUp(self) -> None:
        self.tearDown()

    def tearDown(self) -> None:
        for suffix in ["", "1", "2"]:
            support.unlink(support.TESTFN + suffix)
            safe_rmdir(support.TESTFN + suffix)

    def test_join(self) -> None:
        self.assertEqual(posixpath.join("/foo", "bar", "/bar", "baz"),
                         "/bar/baz")
        self.assertEqual(posixpath.join("/foo", "bar", "baz"), "/foo/bar/baz")
        self.assertEqual(posixpath.join("/foo/", "bar/", "baz/"),
                         "/foo/bar/baz/")

        self.assertEqual(posixpath.join(b"/foo", b"bar", b"/bar", b"baz"),
                         b"/bar/baz")
        self.assertEqual(posixpath.join(b"/foo", b"bar", b"baz"),
                         b"/foo/bar/baz")
        self.assertEqual(posixpath.join(b"/foo/", b"bar/", b"baz/"),
                         b"/foo/bar/baz/")

        self.assertRaises(TypeError, posixpath.join, b"bytes", "str")
        self.assertRaises(TypeError, posixpath.join, "str", b"bytes")

    def test_split(self) -> None:
        self.assertEqual(posixpath.split("/foo/bar"), ("/foo", "bar"))
        self.assertEqual(posixpath.split("/"), ("/", ""))
        self.assertEqual(posixpath.split("foo"), ("", "foo"))
        self.assertEqual(posixpath.split("////foo"), ("////", "foo"))
        self.assertEqual(posixpath.split("//foo//bar"), ("//foo", "bar"))

        self.assertEqual(posixpath.split(b"/foo/bar"), (b"/foo", b"bar"))
        self.assertEqual(posixpath.split(b"/"), (b"/", b""))
        self.assertEqual(posixpath.split(b"foo"), (b"", b"foo"))
        self.assertEqual(posixpath.split(b"////foo"), (b"////", b"foo"))
        self.assertEqual(posixpath.split(b"//foo//bar"), (b"//foo", b"bar"))

    def splitextTest(self, path: str, filename: str, ext: str) -> None:
        self.assertEqual(posixpath.splitext(path), (filename, ext))
        self.assertEqual(posixpath.splitext("/" + path), ("/" + filename, ext))
        self.assertEqual(posixpath.splitext("abc/" + path),
                         ("abc/" + filename, ext))
        self.assertEqual(posixpath.splitext("abc.def/" + path),
                         ("abc.def/" + filename, ext))
        self.assertEqual(posixpath.splitext("/abc.def/" + path),
                         ("/abc.def/" + filename, ext))
        self.assertEqual(posixpath.splitext(path + "/"),
                         (filename + ext + "/", ""))

        pathb = bytes(path, "ASCII")
        filenameb = bytes(filename, "ASCII")
        extb = bytes(ext, "ASCII")

        self.assertEqual(posixpath.splitext(pathb), (filenameb, extb))
        self.assertEqual(posixpath.splitext(b"/" + pathb),
                         (b"/" + filenameb, extb))
        self.assertEqual(posixpath.splitext(b"abc/" + pathb),
                         (b"abc/" + filenameb, extb))
        self.assertEqual(posixpath.splitext(b"abc.def/" + pathb),
                         (b"abc.def/" + filenameb, extb))
        self.assertEqual(posixpath.splitext(b"/abc.def/" + pathb),
                         (b"/abc.def/" + filenameb, extb))
        self.assertEqual(posixpath.splitext(pathb + b"/"),
                         (filenameb + extb + b"/", b""))

    def test_splitext(self) -> None:
        self.splitextTest("foo.bar", "foo", ".bar")
        self.splitextTest("foo.boo.bar", "foo.boo", ".bar")
        self.splitextTest("foo.boo.biff.bar", "foo.boo.biff", ".bar")
        self.splitextTest(".csh.rc", ".csh", ".rc")
        self.splitextTest("nodots", "nodots", "")
        self.splitextTest(".cshrc", ".cshrc", "")
        self.splitextTest("...manydots", "...manydots", "")
        self.splitextTest("...manydots.ext", "...manydots", ".ext")
        self.splitextTest(".", ".", "")
        self.splitextTest("..", "..", "")
        self.splitextTest("........", "........", "")
        self.splitextTest("", "", "")

    def test_isabs(self) -> None:
        self.assertIs(posixpath.isabs(""), False)
        self.assertIs(posixpath.isabs("/"), True)
        self.assertIs(posixpath.isabs("/foo"), True)
        self.assertIs(posixpath.isabs("/foo/bar"), True)
        self.assertIs(posixpath.isabs("foo/bar"), False)

        self.assertIs(posixpath.isabs(b""), False)
        self.assertIs(posixpath.isabs(b"/"), True)
        self.assertIs(posixpath.isabs(b"/foo"), True)
        self.assertIs(posixpath.isabs(b"/foo/bar"), True)
        self.assertIs(posixpath.isabs(b"foo/bar"), False)

    def test_basename(self) -> None:
        self.assertEqual(posixpath.basename("/foo/bar"), "bar")
        self.assertEqual(posixpath.basename("/"), "")
        self.assertEqual(posixpath.basename("foo"), "foo")
        self.assertEqual(posixpath.basename("////foo"), "foo")
        self.assertEqual(posixpath.basename("//foo//bar"), "bar")

        self.assertEqual(posixpath.basename(b"/foo/bar"), b"bar")
        self.assertEqual(posixpath.basename(b"/"), b"")
        self.assertEqual(posixpath.basename(b"foo"), b"foo")
        self.assertEqual(posixpath.basename(b"////foo"), b"foo")
        self.assertEqual(posixpath.basename(b"//foo//bar"), b"bar")

    def test_dirname(self) -> None:
        self.assertEqual(posixpath.dirname("/foo/bar"), "/foo")
        self.assertEqual(posixpath.dirname("/"), "/")
        self.assertEqual(posixpath.dirname("foo"), "")
        self.assertEqual(posixpath.dirname("////foo"), "////")
        self.assertEqual(posixpath.dirname("//foo//bar"), "//foo")

        self.assertEqual(posixpath.dirname(b"/foo/bar"), b"/foo")
        self.assertEqual(posixpath.dirname(b"/"), b"/")
        self.assertEqual(posixpath.dirname(b"foo"), b"")
        self.assertEqual(posixpath.dirname(b"////foo"), b"////")
        self.assertEqual(posixpath.dirname(b"//foo//bar"), b"//foo")

    def test_islink(self) -> None:
        self.assertIs(posixpath.islink(support.TESTFN + "1"), False)
        self.assertIs(posixpath.lexists(support.TESTFN + "2"), False)
        f = open(support.TESTFN + "1", "wb")
        try:
            f.write(b"foo")
            f.close()
            self.assertIs(posixpath.islink(support.TESTFN + "1"), False)
            if support.can_symlink():
                os.symlink(support.TESTFN + "1", support.TESTFN + "2")
                self.assertIs(posixpath.islink(support.TESTFN + "2"), True)
                os.remove(support.TESTFN + "1")
                self.assertIs(posixpath.islink(support.TESTFN + "2"), True)
                self.assertIs(posixpath.exists(support.TESTFN + "2"), False)
                self.assertIs(posixpath.lexists(support.TESTFN + "2"), True)
        finally:
            if not f.closed:
                f.close()

    @staticmethod
    def _create_file(filename: str) -> None:
        with open(filename, 'wb') as f:
            f.write(b'foo')

    def test_samefile(self) -> None:
        test_fn = support.TESTFN + "1"
        self._create_file(test_fn)
        self.assertTrue(posixpath.samefile(test_fn, test_fn))
        self.assertRaises(TypeError, posixpath.samefile)

    @unittest.skipIf(
        sys.platform.startswith('win'),
        "posixpath.samefile does not work on links in Windows")
    @unittest.skipUnless(hasattr(os, "symlink"),
                         "Missing symlink implementation")
    def test_samefile_on_links(self) -> None:
        test_fn1 = support.TESTFN + "1"
        test_fn2 = support.TESTFN + "2"
        self._create_file(test_fn1)

        os.symlink(test_fn1, test_fn2)
        self.assertTrue(posixpath.samefile(test_fn1, test_fn2))
        os.remove(test_fn2)

        self._create_file(test_fn2)
        self.assertFalse(posixpath.samefile(test_fn1, test_fn2))


    def test_samestat(self) -> None:
        test_fn = support.TESTFN + "1"
        self._create_file(test_fn)
        test_fns = [test_fn]*2
        stats = map(os.stat, test_fns)
        self.assertTrue(posixpath.samestat(*stats))

    @unittest.skipIf(
        sys.platform.startswith('win'),
        "posixpath.samestat does not work on links in Windows")
    @unittest.skipUnless(hasattr(os, "symlink"),
                         "Missing symlink implementation")
    def test_samestat_on_links(self) -> None:
        test_fn1 = support.TESTFN + "1"
        test_fn2 = support.TESTFN + "2"
        self._create_file(test_fn1)
        test_fns = [test_fn1, test_fn2]
        Any(os.symlink)(*test_fns)
        stats = map(os.stat, test_fns)
        self.assertTrue(posixpath.samestat(*stats))
        os.remove(test_fn2)

        self._create_file(test_fn2)
        stats = map(os.stat, test_fns)
        self.assertFalse(posixpath.samestat(*stats))

        self.assertRaises(TypeError, posixpath.samestat)

    def test_ismount(self) -> None:
        self.assertIs(posixpath.ismount("/"), True)
        self.assertIs(posixpath.ismount(b"/"), True)

    def test_ismount_non_existent(self) -> None:
        # Non-existent mountpoint.
        self.assertIs(posixpath.ismount(ABSTFN), False)
        try:
            os.mkdir(ABSTFN)
            self.assertIs(posixpath.ismount(ABSTFN), False)
        finally:
            safe_rmdir(ABSTFN)

    @unittest.skipUnless(support.can_symlink(),
                         "Test requires symlink support")
    def test_ismount_symlinks(self) -> None:
        # Symlinks are never mountpoints.
        try:
            os.symlink("/", ABSTFN)
            self.assertIs(posixpath.ismount(ABSTFN), False)
        finally:
            os.unlink(ABSTFN)

    @unittest.skipIf(posix is None, "Test requires posix module")
    def test_ismount_different_device(self) -> None:
        # Simulate the path being on a different device from its parent by
        # mocking out st_dev.
        save_lstat = os.lstat
        def fake_lstat(path):
            st_ino = 0
            st_dev = 0
            if path == ABSTFN:
                st_dev = 1
                st_ino = 1
            return posix.stat_result((0, st_ino, st_dev, 0, 0, 0, 0, 0, 0, 0))
        try:
            setattr(os, 'lstat', fake_lstat) # mypy: can't modify os directly
            self.assertIs(posixpath.ismount(ABSTFN), True)
        finally:
            os.lstat = save_lstat

    def test_expanduser(self) -> None:
        self.assertEqual(posixpath.expanduser("foo"), "foo")
        self.assertEqual(posixpath.expanduser(b"foo"), b"foo")
        try:
            import pwd
        except ImportError:
            pass
        else:
            self.assertIsInstance(posixpath.expanduser("~/"), str)
            self.assertIsInstance(posixpath.expanduser(b"~/"), bytes)
            # if home directory == root directory, this test makes no sense
            if posixpath.expanduser("~") != '/':
                self.assertEqual(
                    posixpath.expanduser("~") + "/",
                    posixpath.expanduser("~/")
                )
                self.assertEqual(
                    posixpath.expanduser(b"~") + b"/",
                    posixpath.expanduser(b"~/")
                )
            self.assertIsInstance(posixpath.expanduser("~root/"), str)
            self.assertIsInstance(posixpath.expanduser("~foo/"), str)
            self.assertIsInstance(posixpath.expanduser(b"~root/"), bytes)
            self.assertIsInstance(posixpath.expanduser(b"~foo/"), bytes)

            with support.EnvironmentVarGuard() as env:
                env['HOME'] = '/'
                self.assertEqual(posixpath.expanduser("~"), "/")
                # expanduser should fall back to using the password database
                del env['HOME']
                home = pwd.getpwuid(os.getuid()).pw_dir
                self.assertEqual(posixpath.expanduser("~"), home)

    def test_normpath(self) -> None:
        self.assertEqual(posixpath.normpath(""), ".")
        self.assertEqual(posixpath.normpath("/"), "/")
        self.assertEqual(posixpath.normpath("//"), "//")
        self.assertEqual(posixpath.normpath("///"), "/")
        self.assertEqual(posixpath.normpath("///foo/.//bar//"), "/foo/bar")
        self.assertEqual(posixpath.normpath("///foo/.//bar//.//..//.//baz"),
                         "/foo/baz")
        self.assertEqual(posixpath.normpath("///..//./foo/.//bar"), "/foo/bar")

        self.assertEqual(posixpath.normpath(b""), b".")
        self.assertEqual(posixpath.normpath(b"/"), b"/")
        self.assertEqual(posixpath.normpath(b"//"), b"//")
        self.assertEqual(posixpath.normpath(b"///"), b"/")
        self.assertEqual(posixpath.normpath(b"///foo/.//bar//"), b"/foo/bar")
        self.assertEqual(posixpath.normpath(b"///foo/.//bar//.//..//.//baz"),
                         b"/foo/baz")
        self.assertEqual(posixpath.normpath(b"///..//./foo/.//bar"),
                         b"/foo/bar")

    @unittest.skipUnless(hasattr(os, "symlink"),
                         "Missing symlink implementation")
    @skip_if_ABSTFN_contains_backslash
    def test_realpath_basic(self) -> None:
        # Basic operation.
        try:
            os.symlink(ABSTFN+"1", ABSTFN)
            self.assertEqual(realpath(ABSTFN), ABSTFN+"1")
        finally:
            support.unlink(ABSTFN)

    @unittest.skipUnless(hasattr(os, "symlink"),
                         "Missing symlink implementation")
    @skip_if_ABSTFN_contains_backslash
    def test_realpath_relative(self) -> None:
        try:
            os.symlink(posixpath.relpath(ABSTFN+"1"), ABSTFN)
            self.assertEqual(realpath(ABSTFN), ABSTFN+"1")
        finally:
            support.unlink(ABSTFN)

    @unittest.skipUnless(hasattr(os, "symlink"),
                         "Missing symlink implementation")
    @skip_if_ABSTFN_contains_backslash
    def test_realpath_symlink_loops(self) -> None:
        # Bug #930024, return the path unchanged if we get into an infinite
        # symlink loop.
        try:
            old_path = abspath('.')
            os.symlink(ABSTFN, ABSTFN)
            self.assertEqual(realpath(ABSTFN), ABSTFN)

            os.symlink(ABSTFN+"1", ABSTFN+"2")
            os.symlink(ABSTFN+"2", ABSTFN+"1")
            self.assertEqual(realpath(ABSTFN+"1"), ABSTFN+"1")
            self.assertEqual(realpath(ABSTFN+"2"), ABSTFN+"2")

            # Test using relative path as well.
            os.chdir(dirname(ABSTFN))
            self.assertEqual(realpath(basename(ABSTFN)), ABSTFN)
        finally:
            os.chdir(old_path)
            support.unlink(ABSTFN)
            support.unlink(ABSTFN+"1")
            support.unlink(ABSTFN+"2")

    @unittest.skipUnless(hasattr(os, "symlink"),
                         "Missing symlink implementation")
    @skip_if_ABSTFN_contains_backslash
    def test_realpath_resolve_parents(self) -> None:
        # We also need to resolve any symlinks in the parents of a relative
        # path passed to realpath. E.g.: current working directory is
        # /usr/doc with 'doc' being a symlink to /usr/share/doc. We call
        # realpath("a"). This should return /usr/share/doc/a/.
        try:
            old_path = abspath('.')
            os.mkdir(ABSTFN)
            os.mkdir(ABSTFN + "/y")
            os.symlink(ABSTFN + "/y", ABSTFN + "/k")

            os.chdir(ABSTFN + "/k")
            self.assertEqual(realpath("a"), ABSTFN + "/y/a")
        finally:
            os.chdir(old_path)
            support.unlink(ABSTFN + "/k")
            safe_rmdir(ABSTFN + "/y")
            safe_rmdir(ABSTFN)

    @unittest.skipUnless(hasattr(os, "symlink"),
                         "Missing symlink implementation")
    @skip_if_ABSTFN_contains_backslash
    def test_realpath_resolve_before_normalizing(self) -> None:
        # Bug #990669: Symbolic links should be resolved before we
        # normalize the path. E.g.: if we have directories 'a', 'k' and 'y'
        # in the following hierarchy:
        # a/k/y
        #
        # and a symbolic link 'link-y' pointing to 'y' in directory 'a',
        # then realpath("link-y/..") should return 'k', not 'a'.
        try:
            old_path = abspath('.')
            os.mkdir(ABSTFN)
            os.mkdir(ABSTFN + "/k")
            os.mkdir(ABSTFN + "/k/y")
            os.symlink(ABSTFN + "/k/y", ABSTFN + "/link-y")

            # Absolute path.
            self.assertEqual(realpath(ABSTFN + "/link-y/.."), ABSTFN + "/k")
            # Relative path.
            os.chdir(dirname(ABSTFN))
            self.assertEqual(realpath(basename(ABSTFN) + "/link-y/.."),
                             ABSTFN + "/k")
        finally:
            os.chdir(old_path)
            support.unlink(ABSTFN + "/link-y")
            safe_rmdir(ABSTFN + "/k/y")
            safe_rmdir(ABSTFN + "/k")
            safe_rmdir(ABSTFN)

    @unittest.skipUnless(hasattr(os, "symlink"),
                         "Missing symlink implementation")
    @skip_if_ABSTFN_contains_backslash
    def test_realpath_resolve_first(self) -> None:
        # Bug #1213894: The first component of the path, if not absolute,
        # must be resolved too.

        try:
            old_path = abspath('.')
            os.mkdir(ABSTFN)
            os.mkdir(ABSTFN + "/k")
            os.symlink(ABSTFN, ABSTFN + "link")
            os.chdir(dirname(ABSTFN))

            base = basename(ABSTFN)
            self.assertEqual(realpath(base + "link"), ABSTFN)
            self.assertEqual(realpath(base + "link/k"), ABSTFN + "/k")
        finally:
            os.chdir(old_path)
            support.unlink(ABSTFN + "link")
            safe_rmdir(ABSTFN + "/k")
            safe_rmdir(ABSTFN)

    def test_relpath(self) -> None:
        real_getcwd = os.getcwd
        # mypy: can't modify os directly
        setattr(os, 'getcwd', lambda: r"/home/user/bar")
        try:
            curdir = os.path.split(os.getcwd())[-1]
            self.assertRaises(ValueError, posixpath.relpath, "")
            self.assertEqual(posixpath.relpath("a"), "a")
            self.assertEqual(posixpath.relpath(posixpath.abspath("a")), "a")
            self.assertEqual(posixpath.relpath("a/b"), "a/b")
            self.assertEqual(posixpath.relpath("../a/b"), "../a/b")
            self.assertEqual(posixpath.relpath("a", "../b"), "../"+curdir+"/a")
            self.assertEqual(posixpath.relpath("a/b", "../c"),
                             "../"+curdir+"/a/b")
            self.assertEqual(posixpath.relpath("a", "b/c"), "../../a")
            self.assertEqual(posixpath.relpath("a", "a"), ".")
            self.assertEqual(posixpath.relpath("/foo/bar/bat", "/x/y/z"), '../../../foo/bar/bat')
            self.assertEqual(posixpath.relpath("/foo/bar/bat", "/foo/bar"), 'bat')
            self.assertEqual(posixpath.relpath("/foo/bar/bat", "/"), 'foo/bar/bat')
            self.assertEqual(posixpath.relpath("/", "/foo/bar/bat"), '../../..')
            self.assertEqual(posixpath.relpath("/foo/bar/bat", "/x"), '../foo/bar/bat')
            self.assertEqual(posixpath.relpath("/x", "/foo/bar/bat"), '../../../x')
            self.assertEqual(posixpath.relpath("/", "/"), '.')
            self.assertEqual(posixpath.relpath("/a", "/a"), '.')
            self.assertEqual(posixpath.relpath("/a/b", "/a/b"), '.')
        finally:
            setattr(os, 'getcwd', real_getcwd)

    def test_relpath_bytes(self) -> None:
        real_getcwdb = os.getcwdb
        # mypy: can't modify os directly
        setattr(os, 'getcwdb', lambda: br"/home/user/bar")
        try:
            curdir = os.path.split(os.getcwdb())[-1]
            self.assertRaises(ValueError, posixpath.relpath, b"")
            self.assertEqual(posixpath.relpath(b"a"), b"a")
            self.assertEqual(posixpath.relpath(posixpath.abspath(b"a")), b"a")
            self.assertEqual(posixpath.relpath(b"a/b"), b"a/b")
            self.assertEqual(posixpath.relpath(b"../a/b"), b"../a/b")
            self.assertEqual(posixpath.relpath(b"a", b"../b"),
                             b"../"+curdir+b"/a")
            self.assertEqual(posixpath.relpath(b"a/b", b"../c"),
                             b"../"+curdir+b"/a/b")
            self.assertEqual(posixpath.relpath(b"a", b"b/c"), b"../../a")
            self.assertEqual(posixpath.relpath(b"a", b"a"), b".")
            self.assertEqual(posixpath.relpath(b"/foo/bar/bat", b"/x/y/z"), b'../../../foo/bar/bat')
            self.assertEqual(posixpath.relpath(b"/foo/bar/bat", b"/foo/bar"), b'bat')
            self.assertEqual(posixpath.relpath(b"/foo/bar/bat", b"/"), b'foo/bar/bat')
            self.assertEqual(posixpath.relpath(b"/", b"/foo/bar/bat"), b'../../..')
            self.assertEqual(posixpath.relpath(b"/foo/bar/bat", b"/x"), b'../foo/bar/bat')
            self.assertEqual(posixpath.relpath(b"/x", b"/foo/bar/bat"), b'../../../x')
            self.assertEqual(posixpath.relpath(b"/", b"/"), b'.')
            self.assertEqual(posixpath.relpath(b"/a", b"/a"), b'.')
            self.assertEqual(posixpath.relpath(b"/a/b", b"/a/b"), b'.')

            self.assertRaises(TypeError, posixpath.relpath, b"bytes", "str")
            self.assertRaises(TypeError, posixpath.relpath, "str", b"bytes")
        finally:
            setattr(os, 'getcwdb', real_getcwdb)

    def test_sameopenfile(self) -> None:
        fname = support.TESTFN + "1"
        with open(fname, "wb") as a, open(fname, "wb") as b:
            self.assertTrue(posixpath.sameopenfile(a.fileno(), b.fileno()))


class PosixCommonTest(test_genericpath.CommonTest):
    pathmodule = posixpath
    attributes = ['relpath', 'samefile', 'sameopenfile', 'samestat']


def test_main() -> None:
    support.run_unittest(PosixPathTest, PosixCommonTest)


if __name__=="__main__":
    test_main()

########NEW FILE########
__FILENAME__ = test_pprint
import pprint
import test.support
import unittest
import test.test_set
import random
import collections
import itertools

from typing import List, Any, Dict, Tuple, cast, Undefined, Function

# list, tuple and dict subclasses that do or don't overwrite __repr__
class list2(list):
    pass

class list3(list):
    def __repr__(self) -> str:
        return list.__repr__(self)

class tuple2(tuple):
    pass

class tuple3(tuple):
    def __repr__(self) -> str:
        return tuple.__repr__(self)

class dict2(dict):
    pass

class dict3(dict):
    def __repr__(self) -> str:
        return dict.__repr__(self)

class Unorderable:
    def __repr__(self) -> str:
        return str(id(self))

class QueryTestCase(unittest.TestCase):

    def setUp(self) -> None:
        self.a = List[Any](range(100))
        self.b = List[Any](range(200))
        self.a[-12] = self.b

    def test_basic(self) -> None:
        # Verify .isrecursive() and .isreadable() w/o recursion
        pp = pprint.PrettyPrinter()
        for safe in (2, 2.0, complex(0.0, 2.0), "abc", [3], (2,2), {3: 3}, "yaddayadda",
                     self.a, self.b):
            # module-level convenience functions
            self.assertFalse(pprint.isrecursive(safe),
                             "expected not isrecursive for %r" % (safe,))
            self.assertTrue(pprint.isreadable(safe),
                            "expected isreadable for %r" % (safe,))
            # PrettyPrinter methods
            self.assertFalse(pp.isrecursive(safe),
                             "expected not isrecursive for %r" % (safe,))
            self.assertTrue(pp.isreadable(safe),
                            "expected isreadable for %r" % (safe,))

    def test_knotted(self) -> None:
        # Verify .isrecursive() and .isreadable() w/ recursion
        # Tie a knot.
        self.b[67] = self.a
        # Messy dict.
        self.d = Dict[int, dict]()
        self.d[0] = self.d[1] = self.d[2] = self.d

        pp = pprint.PrettyPrinter()

        for icky in self.a, self.b, self.d, (self.d, self.d):
            self.assertTrue(pprint.isrecursive(icky), "expected isrecursive")
            self.assertFalse(pprint.isreadable(icky), "expected not isreadable")
            self.assertTrue(pp.isrecursive(icky), "expected isrecursive")
            self.assertFalse(pp.isreadable(icky), "expected not isreadable")

        # Break the cycles.
        self.d.clear()
        del self.a[:]
        del self.b[:]

        for safe in self.a, self.b, self.d, (self.d, self.d):
            # module-level convenience functions
            self.assertFalse(pprint.isrecursive(safe),
                             "expected not isrecursive for %r" % (safe,))
            self.assertTrue(pprint.isreadable(safe),
                            "expected isreadable for %r" % (safe,))
            # PrettyPrinter methods
            self.assertFalse(pp.isrecursive(safe),
                             "expected not isrecursive for %r" % (safe,))
            self.assertTrue(pp.isreadable(safe),
                            "expected isreadable for %r" % (safe,))

    def test_unreadable(self) -> None:
        # Not recursive but not readable anyway
        pp = pprint.PrettyPrinter()
        for unreadable in type(3), pprint, pprint.isrecursive:
            # module-level convenience functions
            self.assertFalse(pprint.isrecursive(unreadable),
                             "expected not isrecursive for %r" % (unreadable,))
            self.assertFalse(pprint.isreadable(unreadable),
                             "expected not isreadable for %r" % (unreadable,))
            # PrettyPrinter methods
            self.assertFalse(pp.isrecursive(unreadable),
                             "expected not isrecursive for %r" % (unreadable,))
            self.assertFalse(pp.isreadable(unreadable),
                             "expected not isreadable for %r" % (unreadable,))

    def test_same_as_repr(self) -> None:
        # Simple objects, small containers and classes that overwrite __repr__
        # For those the result should be the same as repr().
        # Ahem.  The docs don't say anything about that -- this appears to
        # be testing an implementation quirk.  Starting in Python 2.5, it's
        # not true for dicts:  pprint always sorts dicts by key now; before,
        # it sorted a dict display if and only if the display required
        # multiple lines.  For that reason, dicts with more than one element
        # aren't tested here.
        for simple in (0, 0, complex(0.0), 0.0, "", b"",
                       (), tuple2(), tuple3(),
                       [], list2(), list3(),
                       {}, dict2(), dict3(),
                       self.assertTrue, pprint,
                       -6, -6, complex(-6.,-6.), -1.5, "x", b"x", (3,), [3], {3: 6},
                       (1,2), [3,4], {5: 6},
                       tuple2((1,2)), tuple3((1,2)), tuple3(range(100)),
                       [3,4], list2(Any([3,4])), list3(Any([3,4])), list3(Any(range(100))),
                       dict2(Any({5: 6})), dict3(Any({5: 6})), # JLe: work around mypy issue #233
                       range(10, -11, -1)
                      ):
            native = repr(simple)
            for function in "pformat", "saferepr":
                f = getattr(pprint, function)
                got = f(simple)
                self.assertEqual(native, got,
                                 "expected %s got %s from pprint.%s" %
                                 (native, got, function))

    def test_basic_line_wrap(self) -> None:
        # verify basic line-wrapping operation
        o = {'RPM_cal': 0,
             'RPM_cal2': 48059,
             'Speed_cal': 0,
             'controldesk_runtime_us': 0,
             'main_code_runtime_us': 0,
             'read_io_runtime_us': 0,
             'write_io_runtime_us': 43690}
        exp = """\
{'RPM_cal': 0,
 'RPM_cal2': 48059,
 'Speed_cal': 0,
 'controldesk_runtime_us': 0,
 'main_code_runtime_us': 0,
 'read_io_runtime_us': 0,
 'write_io_runtime_us': 43690}"""
        # JLe: work around mypy issue #232
        for type in List[Any]([dict, dict2]):
            self.assertEqual(pprint.pformat(type(o)), exp)

        o2 = range(100)
        exp = '[%s]' % ',\n '.join(map(str, o2))
        for type in List[Any]([list, list2]):
            self.assertEqual(pprint.pformat(type(o2)), exp)

        o3 = tuple(range(100))
        exp = '(%s)' % ',\n '.join(map(str, o3))
        for type in List[Any]([tuple, tuple2]):
            self.assertEqual(pprint.pformat(type(o3)), exp)

        # indent parameter
        o4 = range(100)
        exp = '[   %s]' % ',\n    '.join(map(str, o4))
        for type in List[Any]([list, list2]):
            self.assertEqual(pprint.pformat(type(o4), indent=4), exp)

    def test_nested_indentations(self) -> None:
        o1 = list(range(10))
        o2 = {'first':1, 'second':2, 'third':3}
        o = [o1, o2]
        expected = """\
[   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
    {   'first': 1,
        'second': 2,
        'third': 3}]"""
        self.assertEqual(pprint.pformat(o, indent=4, width=42), expected)

    def test_sorted_dict(self) -> None:
        # Starting in Python 2.5, pprint sorts dict displays by key regardless
        # of how small the dictionary may be.
        # Before the change, on 32-bit Windows pformat() gave order
        # 'a', 'c', 'b' here, so this test failed.
        d = {'a': 1, 'b': 1, 'c': 1}
        self.assertEqual(pprint.pformat(d), "{'a': 1, 'b': 1, 'c': 1}")
        self.assertEqual(pprint.pformat([d, d]),
            "[{'a': 1, 'b': 1, 'c': 1}, {'a': 1, 'b': 1, 'c': 1}]")

        # The next one is kind of goofy.  The sorted order depends on the
        # alphabetic order of type names:  "int" < "str" < "tuple".  Before
        # Python 2.5, this was in the test_same_as_repr() test.  It's worth
        # keeping around for now because it's one of few tests of pprint
        # against a crazy mix of types.
        self.assertEqual(pprint.pformat({"xy\tab\n": (3,), 5: [[]], (): {}}),
            r"{5: [[]], 'xy\tab\n': (3,), (): {}}")

    def test_ordered_dict(self) -> None:
        words = 'the quick brown fox jumped over a lazy dog'.split()
        d = collections.OrderedDict(zip(words, itertools.count()))
        self.assertEqual(pprint.pformat(d),
"""\
{'the': 0,
 'quick': 1,
 'brown': 2,
 'fox': 3,
 'jumped': 4,
 'over': 5,
 'a': 6,
 'lazy': 7,
 'dog': 8}""")
    def test_subclassing(self) -> None:
        o = {'names with spaces': 'should be presented using repr()',
             'others.should.not.be': 'like.this'}
        exp = """\
{'names with spaces': 'should be presented using repr()',
 others.should.not.be: like.this}"""
        self.assertEqual(DottedPrettyPrinter().pformat(o), exp)

    @test.support.cpython_only
    def test_set_reprs(self) -> None:
        # This test creates a complex arrangement of frozensets and
        # compares the pretty-printed repr against a string hard-coded in
        # the test.  The hard-coded repr depends on the sort order of
        # frozensets.
        #
        # However, as the docs point out: "Since sets only define
        # partial ordering (subset relationships), the output of the
        # list.sort() method is undefined for lists of sets."
        #
        # In a nutshell, the test assumes frozenset({0}) will always
        # sort before frozenset({1}), but:
        #
        # >>> frozenset({0}) < frozenset({1})
        # False
        # >>> frozenset({1}) < frozenset({0})
        # False
        #
        # Consequently, this test is fragile and
        # implementation-dependent.  Small changes to Python's sort
        # algorithm cause the test to fail when it should pass.

        self.assertEqual(pprint.pformat(set()), 'set()')
        self.assertEqual(pprint.pformat(set(range(3))), '{0, 1, 2}')
        self.assertEqual(pprint.pformat(frozenset()), 'frozenset()')
        self.assertEqual(pprint.pformat(frozenset(range(3))), 'frozenset({0, 1, 2})')
        cube_repr_tgt = """\
{frozenset(): frozenset({frozenset({2}), frozenset({0}), frozenset({1})}),
 frozenset({0}): frozenset({frozenset(),
                            frozenset({0, 2}),
                            frozenset({0, 1})}),
 frozenset({1}): frozenset({frozenset(),
                            frozenset({1, 2}),
                            frozenset({0, 1})}),
 frozenset({2}): frozenset({frozenset(),
                            frozenset({1, 2}),
                            frozenset({0, 2})}),
 frozenset({1, 2}): frozenset({frozenset({2}),
                               frozenset({1}),
                               frozenset({0, 1, 2})}),
 frozenset({0, 2}): frozenset({frozenset({2}),
                               frozenset({0}),
                               frozenset({0, 1, 2})}),
 frozenset({0, 1}): frozenset({frozenset({0}),
                               frozenset({1}),
                               frozenset({0, 1, 2})}),
 frozenset({0, 1, 2}): frozenset({frozenset({1, 2}),
                                  frozenset({0, 2}),
                                  frozenset({0, 1})})}"""
        cube = test.test_set.cube(3)
        self.assertEqual(pprint.pformat(cube), cube_repr_tgt)
        cubo_repr_tgt = """\
{frozenset({frozenset({0, 2}), frozenset({0})}): frozenset({frozenset({frozenset({0,
                                                                                  2}),
                                                                       frozenset({0,
                                                                                  1,
                                                                                  2})}),
                                                            frozenset({frozenset({0}),
                                                                       frozenset({0,
                                                                                  1})}),
                                                            frozenset({frozenset(),
                                                                       frozenset({0})}),
                                                            frozenset({frozenset({2}),
                                                                       frozenset({0,
                                                                                  2})})}),
 frozenset({frozenset({0, 1}), frozenset({1})}): frozenset({frozenset({frozenset({0,
                                                                                  1}),
                                                                       frozenset({0,
                                                                                  1,
                                                                                  2})}),
                                                            frozenset({frozenset({0}),
                                                                       frozenset({0,
                                                                                  1})}),
                                                            frozenset({frozenset({1}),
                                                                       frozenset({1,
                                                                                  2})}),
                                                            frozenset({frozenset(),
                                                                       frozenset({1})})}),
 frozenset({frozenset({1, 2}), frozenset({1})}): frozenset({frozenset({frozenset({1,
                                                                                  2}),
                                                                       frozenset({0,
                                                                                  1,
                                                                                  2})}),
                                                            frozenset({frozenset({2}),
                                                                       frozenset({1,
                                                                                  2})}),
                                                            frozenset({frozenset(),
                                                                       frozenset({1})}),
                                                            frozenset({frozenset({1}),
                                                                       frozenset({0,
                                                                                  1})})}),
 frozenset({frozenset({1, 2}), frozenset({2})}): frozenset({frozenset({frozenset({1,
                                                                                  2}),
                                                                       frozenset({0,
                                                                                  1,
                                                                                  2})}),
                                                            frozenset({frozenset({1}),
                                                                       frozenset({1,
                                                                                  2})}),
                                                            frozenset({frozenset({2}),
                                                                       frozenset({0,
                                                                                  2})}),
                                                            frozenset({frozenset(),
                                                                       frozenset({2})})}),
 frozenset({frozenset(), frozenset({0})}): frozenset({frozenset({frozenset({0}),
                                                                 frozenset({0,
                                                                            1})}),
                                                      frozenset({frozenset({0}),
                                                                 frozenset({0,
                                                                            2})}),
                                                      frozenset({frozenset(),
                                                                 frozenset({1})}),
                                                      frozenset({frozenset(),
                                                                 frozenset({2})})}),
 frozenset({frozenset(), frozenset({1})}): frozenset({frozenset({frozenset(),
                                                                 frozenset({0})}),
                                                      frozenset({frozenset({1}),
                                                                 frozenset({1,
                                                                            2})}),
                                                      frozenset({frozenset(),
                                                                 frozenset({2})}),
                                                      frozenset({frozenset({1}),
                                                                 frozenset({0,
                                                                            1})})}),
 frozenset({frozenset({2}), frozenset()}): frozenset({frozenset({frozenset({2}),
                                                                 frozenset({1,
                                                                            2})}),
                                                      frozenset({frozenset(),
                                                                 frozenset({0})}),
                                                      frozenset({frozenset(),
                                                                 frozenset({1})}),
                                                      frozenset({frozenset({2}),
                                                                 frozenset({0,
                                                                            2})})}),
 frozenset({frozenset({0, 1, 2}), frozenset({0, 1})}): frozenset({frozenset({frozenset({1,
                                                                                        2}),
                                                                             frozenset({0,
                                                                                        1,
                                                                                        2})}),
                                                                  frozenset({frozenset({0,
                                                                                        2}),
                                                                             frozenset({0,
                                                                                        1,
                                                                                        2})}),
                                                                  frozenset({frozenset({0}),
                                                                             frozenset({0,
                                                                                        1})}),
                                                                  frozenset({frozenset({1}),
                                                                             frozenset({0,
                                                                                        1})})}),
 frozenset({frozenset({0}), frozenset({0, 1})}): frozenset({frozenset({frozenset(),
                                                                       frozenset({0})}),
                                                            frozenset({frozenset({0,
                                                                                  1}),
                                                                       frozenset({0,
                                                                                  1,
                                                                                  2})}),
                                                            frozenset({frozenset({0}),
                                                                       frozenset({0,
                                                                                  2})}),
                                                            frozenset({frozenset({1}),
                                                                       frozenset({0,
                                                                                  1})})}),
 frozenset({frozenset({2}), frozenset({0, 2})}): frozenset({frozenset({frozenset({0,
                                                                                  2}),
                                                                       frozenset({0,
                                                                                  1,
                                                                                  2})}),
                                                            frozenset({frozenset({2}),
                                                                       frozenset({1,
                                                                                  2})}),
                                                            frozenset({frozenset({0}),
                                                                       frozenset({0,
                                                                                  2})}),
                                                            frozenset({frozenset(),
                                                                       frozenset({2})})}),
 frozenset({frozenset({0, 1, 2}), frozenset({0, 2})}): frozenset({frozenset({frozenset({1,
                                                                                        2}),
                                                                             frozenset({0,
                                                                                        1,
                                                                                        2})}),
                                                                  frozenset({frozenset({0,
                                                                                        1}),
                                                                             frozenset({0,
                                                                                        1,
                                                                                        2})}),
                                                                  frozenset({frozenset({0}),
                                                                             frozenset({0,
                                                                                        2})}),
                                                                  frozenset({frozenset({2}),
                                                                             frozenset({0,
                                                                                        2})})}),
 frozenset({frozenset({1, 2}), frozenset({0, 1, 2})}): frozenset({frozenset({frozenset({0,
                                                                                        2}),
                                                                             frozenset({0,
                                                                                        1,
                                                                                        2})}),
                                                                  frozenset({frozenset({0,
                                                                                        1}),
                                                                             frozenset({0,
                                                                                        1,
                                                                                        2})}),
                                                                  frozenset({frozenset({2}),
                                                                             frozenset({1,
                                                                                        2})}),
                                                                  frozenset({frozenset({1}),
                                                                             frozenset({1,
                                                                                        2})})})}"""

        cubo = test.test_set.linegraph(cube)
        self.assertEqual(pprint.pformat(cubo), cubo_repr_tgt)

    def test_depth(self) -> None:
        nested_tuple = (1, (2, (3, (4, (5, 6)))))
        nested_dict = {1: {2: {3: {4: {5: {6: 6}}}}}}
        nested_list = [1, [2, [3, [4, [5, [6, []]]]]]]
        self.assertEqual(pprint.pformat(nested_tuple), repr(nested_tuple))
        self.assertEqual(pprint.pformat(nested_dict), repr(nested_dict))
        self.assertEqual(pprint.pformat(nested_list), repr(nested_list))

        lv1_tuple = '(1, (...))'
        lv1_dict = '{1: {...}}'
        lv1_list = '[1, [...]]'
        self.assertEqual(pprint.pformat(nested_tuple, depth=1), lv1_tuple)
        self.assertEqual(pprint.pformat(nested_dict, depth=1), lv1_dict)
        self.assertEqual(pprint.pformat(nested_list, depth=1), lv1_list)

    def test_sort_unorderable_values(self) -> None:
        # Issue 3976:  sorted pprints fail for unorderable values.
        n = 20
        keys = [Unorderable() for i in range(n)]
        random.shuffle(keys)
        skeys = sorted(keys, key=id)
        clean = Undefined(Function[[str], str])
        clean = lambda s: s.replace(' ', '').replace('\n','')

        self.assertEqual(clean(pprint.pformat(set(keys))),
            '{' + ','.join(map(repr, skeys)) + '}')
        self.assertEqual(clean(pprint.pformat(frozenset(keys))),
            'frozenset({' + ','.join(map(repr, skeys)) + '})')
        self.assertEqual(clean(pprint.pformat(dict.fromkeys(keys))),
            '{' + ','.join('%r:None' % k for k in skeys) + '}')

class DottedPrettyPrinter(pprint.PrettyPrinter):

    def format(self, object: object, context: Dict[int, Any], maxlevels: int,
               level: int) -> Tuple[str, int, int]:
        if isinstance(object, str):
            if ' ' in object:
                return repr(object), 1, 0
            else:
                return object, 0, 0
        else:
            return pprint.PrettyPrinter.format(
                self, object, context, maxlevels, level)


def test_main() -> None:
    test.support.run_unittest(QueryTestCase)


if __name__ == "__main__":
    test_main()

########NEW FILE########
__FILENAME__ = test_random
#!/usr/bin/env python3

import unittest
import random
import time
import pickle
import warnings
from math import log, exp, pi, fsum, sin
from test import support

from typing import Undefined, Any, Dict, List, Function, Generic, typevar

RT = typevar('RT', values=(random.Random, random.SystemRandom))

class TestBasicOps(unittest.TestCase, Generic[RT]):
    # Superclass with tests common to all generators.
    # Subclasses must arrange for self.gen to retrieve the Random instance
    # to be tested.

    gen = Undefined(RT) # Either Random or SystemRandom 

    def randomlist(self, n: int) -> List[float]:
        """Helper function to make a list of random numbers"""
        return [self.gen.random() for i in range(n)]

    def test_autoseed(self) -> None:
        self.gen.seed()
        state1 = self.gen.getstate()
        time.sleep(0.1)
        self.gen.seed()      # diffent seeds at different times
        state2 = self.gen.getstate()
        self.assertNotEqual(state1, state2)

    def test_saverestore(self) -> None:
        N = 1000
        self.gen.seed()
        state = self.gen.getstate()
        randseq = self.randomlist(N)
        self.gen.setstate(state)    # should regenerate the same sequence
        self.assertEqual(randseq, self.randomlist(N))

    def test_seedargs(self) -> None:
        for arg in [None, 0, 0, 1, 1, -1, -1, 10**20, -(10**20),
                    3.14, complex(1., 2.), 'a', tuple('abc')]:
            self.gen.seed(arg)
        for arg in [list(range(3)), {'one': 1}]:
            self.assertRaises(TypeError, self.gen.seed, arg)
        self.assertRaises(TypeError, self.gen.seed, 1, 2, 3, 4)
        self.assertRaises(TypeError, type(self.gen), [])

    def test_choice(self) -> None:
        choice = self.gen.choice
        with self.assertRaises(IndexError):
            choice([])
        self.assertEqual(choice([50]), 50)
        self.assertIn(choice([25, 75]), [25, 75])

    def test_sample(self) -> None:
        # For the entire allowable range of 0 <= k <= N, validate that
        # the sample is of the correct length and contains only unique items
        N = 100
        population = range(N)
        for k in range(N+1):
            s = self.gen.sample(population, k)
            self.assertEqual(len(s), k)
            uniq = set(s)
            self.assertEqual(len(uniq), k)
            self.assertTrue(uniq <= set(population))
        self.assertEqual(self.gen.sample([], 0), [])  # test edge case N==k==0

    def test_sample_distribution(self) -> None:
        # For the entire allowable range of 0 <= k <= N, validate that
        # sample generates all possible permutations
        n = 5
        pop = range(n)
        trials = 10000  # large num prevents false negatives without slowing normal case
        def factorial(n: int) -> int:
            if n == 0:
                return 1
            return n * factorial(n - 1)
        for k in range(n):
            expected = factorial(n) // factorial(n-k)
            perms = Dict[tuple, object]()
            for i in range(trials):
                perms[tuple(self.gen.sample(pop, k))] = None
                if len(perms) == expected:
                    break
            else:
                self.fail()

    def test_sample_inputs(self) -> None:
        # SF bug #801342 -- population can be any iterable defining __len__()
        self.gen.sample(set(range(20)), 2)
        self.gen.sample(range(20), 2)
        self.gen.sample(range(20), 2)
        self.gen.sample(str('abcdefghijklmnopqrst'), 2)
        self.gen.sample(tuple('abcdefghijklmnopqrst'), 2)

    def test_sample_on_dicts(self) -> None:
        self.assertRaises(TypeError, self.gen.sample, dict.fromkeys('abcdef'), 2)

    def test_gauss(self) -> None:
        # Ensure that the seed() method initializes all the hidden state.  In
        # particular, through 2.2.1 it failed to reset a piece of state used
        # by (and only by) the .gauss() method.

        for seed in 1, 12, 123, 1234, 12345, 123456, 654321:
            self.gen.seed(seed)
            x1 = self.gen.random()
            y1 = self.gen.gauss(0, 1)

            self.gen.seed(seed)
            x2 = self.gen.random()
            y2 = self.gen.gauss(0, 1)

            self.assertEqual(x1, x2)
            self.assertEqual(y1, y2)

    def test_pickling(self) -> None:
        state = pickle.dumps(self.gen)
        origseq = [self.gen.random() for i in range(10)]
        newgen = pickle.loads(state)
        restoredseq = [newgen.random() for i in range(10)]
        self.assertEqual(origseq, restoredseq)

    def test_bug_1727780(self) -> None:
        # verify that version-2-pickles can be loaded
        # fine, whether they are created on 32-bit or 64-bit
        # platforms, and that version-3-pickles load fine.
        files = [("randv2_32.pck", 780),
                 ("randv2_64.pck", 866),
                 ("randv3.pck", 343)]
        for file, value in files:
            f = open(support.findfile(file),"rb")
            r = pickle.load(f)
            f.close()
            self.assertEqual(int(r.random()*1000), value)

    def test_bug_9025(self) -> None:
        # Had problem with an uneven distribution in int(n*random())
        # Verify the fix by checking that distributions fall within expectations.
        n = 100000
        randrange = self.gen.randrange
        k = sum(randrange(6755399441055744) % 3 == 2 for i in range(n))
        self.assertTrue(0.30 < k/n and k/n < .37, (k/n))

class SystemRandom_TestBasicOps(TestBasicOps[random.SystemRandom]):
    gen = random.SystemRandom()

    def test_autoseed(self) -> None:
        # Doesn't need to do anything except not fail
        self.gen.seed()

    def test_saverestore(self) -> None:
        self.assertRaises(NotImplementedError, self.gen.getstate)
        self.assertRaises(NotImplementedError, self.gen.setstate, None)

    def test_seedargs(self) -> None:
        # Doesn't need to do anything except not fail
        self.gen.seed(100)

    def test_gauss(self) -> None:
        self.gen.gauss_next = None
        self.gen.seed(100)
        self.assertEqual(self.gen.gauss_next, None)

    def test_pickling(self) -> None:
        self.assertRaises(NotImplementedError, pickle.dumps, self.gen)

    def test_53_bits_per_float(self) -> None:
        # This should pass whenever a C double has 53 bit precision.
        span = 2 ** 53 # type: int
        cum = 0
        for i in range(100):
            cum |= int(self.gen.random() * span)
        self.assertEqual(cum, span-1)

    def test_bigrand(self) -> None:
        # The randrange routine should build-up the required number of bits
        # in stages so that all bit positions are active.
        span = 2 ** 500 # type: int
        cum = 0
        for i in range(100):
            r = self.gen.randrange(span)
            self.assertTrue(0 <= r < span)
            cum |= r
        self.assertEqual(cum, span-1)

    def test_bigrand_ranges(self) -> None:
        for i in [40,80, 160, 200, 211, 250, 375, 512, 550]:
            start = self.gen.randrange(2 ** i)
            stop = self.gen.randrange(2 ** (i-2))
            if stop <= start:
                return
            self.assertTrue(start <= self.gen.randrange(start, stop) < stop)

    def test_rangelimits(self) -> None:
        for start, stop in [(-2,0), (-(2**60)-2,-(2**60)), (2**60,2**60+2)]:
            self.assertEqual(set(range(start,stop)),
                set([self.gen.randrange(start,stop) for i in range(100)]))

    def test_genrandbits(self) -> None:
        # Verify ranges
        for k in range(1, 1000):
            self.assertTrue(0 <= self.gen.getrandbits(k) < 2**k)

        # Verify all bits active
        getbits = self.gen.getrandbits
        for span in [1, 2, 3, 4, 31, 32, 32, 52, 53, 54, 119, 127, 128, 129]:
            cum = 0
            for i in range(100):
                cum |= getbits(span)
            self.assertEqual(cum, 2**span-1)

        # Verify argument checking
        self.assertRaises(TypeError, self.gen.getrandbits)
        self.assertRaises(TypeError, self.gen.getrandbits, 1, 2)
        self.assertRaises(ValueError, self.gen.getrandbits, 0)
        self.assertRaises(ValueError, self.gen.getrandbits, -1)
        self.assertRaises(TypeError, self.gen.getrandbits, 10.1)

    def test_randbelow_logic(self, _log: Function[[float, float], float] = log,
                             int: Function[[float], int] = int) -> None:
        # check bitcount transition points:  2**i and 2**(i+1)-1
        # show that: k = int(1.001 + _log(n, 2))
        # is equal to or one greater than the number of bits in n
        for i in range(1, 1000):
            n = 1 << i # check an exact power of two
            numbits = i+1
            k = int(1.00001 + _log(n, 2))
            self.assertEqual(k, numbits)
            self.assertEqual(n, 2**(k-1))

            n += n - 1      # check 1 below the next power of two
            k = int(1.00001 + _log(n, 2))
            self.assertIn(k, [numbits, numbits+1])
            self.assertTrue(2**k > n > 2**(k-2))

            n -= n >> 15     # check a little farther below the next power of two
            k = int(1.00001 + _log(n, 2))
            self.assertEqual(k, numbits)        # note the stronger assertion
            self.assertTrue(2**k > n > 2**(k-1))   # note the stronger assertion


class MersenneTwister_TestBasicOps(TestBasicOps[random.Random]):
    gen = random.Random()

    def test_guaranteed_stable(self) -> None:
        # These sequences are guaranteed to stay the same across versions of python
        self.gen.seed(3456147, version=1)
        self.assertEqual([self.gen.random().hex() for i in range(4)],
            ['0x1.ac362300d90d2p-1', '0x1.9d16f74365005p-1',
             '0x1.1ebb4352e4c4dp-1', '0x1.1a7422abf9c11p-1'])
        self.gen.seed("the quick brown fox", version=2)
        self.assertEqual([self.gen.random().hex() for i in range(4)],
            ['0x1.1239ddfb11b7cp-3', '0x1.b3cbb5c51b120p-4',
             '0x1.8c4f55116b60fp-1', '0x1.63eb525174a27p-1'])

    def test_setstate_first_arg(self) -> None:
        self.assertRaises(ValueError, self.gen.setstate, (1, None, None))

    def test_setstate_middle_arg(self) -> None:
        # Wrong type, s/b tuple
        self.assertRaises(TypeError, self.gen.setstate, (2, None, None))
        # Wrong length, s/b 625
        self.assertRaises(ValueError, self.gen.setstate, (2, (1,2,3), None))
        # Wrong type, s/b tuple of 625 ints
        self.assertRaises(TypeError, self.gen.setstate, (2, tuple(['a',]*625), None))
        # Last element s/b an int also
        self.assertRaises(TypeError, self.gen.setstate, (2, Any((0,))*624+('a',), None))

    def test_referenceImplementation(self) -> None:
        # Compare the python implementation with results from the original
        # code.  Create 2000 53-bit precision random floats.  Compare only
        # the last ten entries to show that the independent implementations
        # are tracking.  Here is the main() function needed to create the
        # list of expected random numbers:
        #    void main(void){
        #         int i;
        #         unsigned long init[4]={61731, 24903, 614, 42143}, length=4;
        #         init_by_array(init, length);
        #         for (i=0; i<2000; i++) {
        #           printf("%.15f ", genrand_res53());
        #           if (i%5==4) printf("\n");
        #         }
        #     }
        expected = [0.45839803073713259,
                    0.86057815201978782,
                    0.92848331726782152,
                    0.35932681119782461,
                    0.081823493762449573,
                    0.14332226470169329,
                    0.084297823823520024,
                    0.53814864671831453,
                    0.089215024911993401,
                    0.78486196105372907]

        self.gen.seed(61731 + (24903<<32) + (614<<64) + (42143<<96))
        actual = self.randomlist(2000)[-10:]
        for a, e in zip(actual, expected):
            self.assertAlmostEqual(a,e,places=14)

    def test_strong_reference_implementation(self) -> None:
        # Like test_referenceImplementation, but checks for exact bit-level
        # equality.  This should pass on any box where C double contains
        # at least 53 bits of precision (the underlying algorithm suffers
        # no rounding errors -- all results are exact).
        from math import ldexp

        expected = [0x0eab3258d2231f,
                    0x1b89db315277a5,
                    0x1db622a5518016,
                    0x0b7f9af0d575bf,
                    0x029e4c4db82240,
                    0x04961892f5d673,
                    0x02b291598e4589,
                    0x11388382c15694,
                    0x02dad977c9e1fe,
                    0x191d96d4d334c6]
        self.gen.seed(61731 + (24903<<32) + (614<<64) + (42143<<96))
        actual = self.randomlist(2000)[-10:]
        for a, e in zip(actual, expected):
            self.assertEqual(int(ldexp(a, 53)), e)

    def test_long_seed(self) -> None:
        # This is most interesting to run in debug mode, just to make sure
        # nothing blows up.  Under the covers, a dynamically resized array
        # is allocated, consuming space proportional to the number of bits
        # in the seed.  Unfortunately, that's a quadratic-time algorithm,
        # so don't make this horribly big.
        seed = (1 << (10000 * 8)) - 1  # about 10K bytes
        self.gen.seed(seed)

    def test_53_bits_per_float(self) -> None:
        # This should pass whenever a C double has 53 bit precision.
        span = 2 ** 53 # type: int
        cum = 0
        for i in range(100):
            cum |= int(self.gen.random() * span)
        self.assertEqual(cum, span-1)

    def test_bigrand(self) -> None:
        # The randrange routine should build-up the required number of bits
        # in stages so that all bit positions are active.
        span = 2 ** 500 # type: int
        cum = 0
        for i in range(100):
            r = self.gen.randrange(span)
            self.assertTrue(0 <= r < span)
            cum |= r
        self.assertEqual(cum, span-1)

    def test_bigrand_ranges(self) -> None:
        for i in [40,80, 160, 200, 211, 250, 375, 512, 550]:
            start = self.gen.randrange(2 ** i)
            stop = self.gen.randrange(2 ** (i-2))
            if stop <= start:
                return
            self.assertTrue(start <= self.gen.randrange(start, stop) < stop)

    def test_rangelimits(self) -> None:
        for start, stop in [(-2,0), (-(2**60)-2,-(2**60)), (2**60,2**60+2)]:
            self.assertEqual(set(range(start,stop)),
                set([self.gen.randrange(start,stop) for i in range(100)]))

    def test_genrandbits(self) -> None:
        # Verify cross-platform repeatability
        self.gen.seed(1234567)
        self.assertEqual(self.gen.getrandbits(100),
                         97904845777343510404718956115)
        # Verify ranges
        for k in range(1, 1000):
            self.assertTrue(0 <= self.gen.getrandbits(k) < 2**k)

        # Verify all bits active
        getbits = self.gen.getrandbits
        for span in [1, 2, 3, 4, 31, 32, 32, 52, 53, 54, 119, 127, 128, 129]:
            cum = 0
            for i in range(100):
                cum |= getbits(span)
            self.assertEqual(cum, 2**span-1)

        # Verify argument checking
        self.assertRaises(TypeError, self.gen.getrandbits)
        self.assertRaises(TypeError, self.gen.getrandbits, 'a')
        self.assertRaises(TypeError, self.gen.getrandbits, 1, 2)
        self.assertRaises(ValueError, self.gen.getrandbits, 0)
        self.assertRaises(ValueError, self.gen.getrandbits, -1)

    def test_randbelow_logic(self,
                             _log: Function[[int, float], float] = log,
                             int: Function[[float], int] = int) -> None:
        # check bitcount transition points:  2**i and 2**(i+1)-1
        # show that: k = int(1.001 + _log(n, 2))
        # is equal to or one greater than the number of bits in n
        for i in range(1, 1000):
            n = 1 << i # check an exact power of two
            numbits = i+1
            k = int(1.00001 + _log(n, 2))
            self.assertEqual(k, numbits)
            self.assertEqual(n, 2**(k-1))

            n += n - 1      # check 1 below the next power of two
            k = int(1.00001 + _log(n, 2))
            self.assertIn(k, [numbits, numbits+1])
            self.assertTrue(2**k > n > 2**(k-2))

            n -= n >> 15     # check a little farther below the next power of two
            k = int(1.00001 + _log(n, 2))
            self.assertEqual(k, numbits)        # note the stronger assertion
            self.assertTrue(2**k > n > 2**(k-1))   # note the stronger assertion

    def test_randrange_bug_1590891(self) -> None:
        start = 1000000000000
        stop = -100000000000000000000
        step = -200
        x = self.gen.randrange(start, stop, step)
        self.assertTrue(stop < x <= start)
        self.assertEqual((x+stop)%step, 0)

def gamma(z: float, sqrt2pi: float = (2.0*pi)**0.5) -> float:
    # Reflection to right half of complex plane
    if z < 0.5:
        return pi / sin(pi*z) / gamma(1.0-z)
    # Lanczos approximation with g=7
    az = z + (7.0 - 0.5)
    return az ** (z-0.5) / exp(az) * sqrt2pi * fsum([
        0.9999999999995183,
        676.5203681218835 / z,
        -1259.139216722289 / (z+1.0),
        771.3234287757674 / (z+2.0),
        -176.6150291498386 / (z+3.0),
        12.50734324009056 / (z+4.0),
        -0.1385710331296526 / (z+5.0),
        0.9934937113930748e-05 / (z+6.0),
        0.1659470187408462e-06 / (z+7.0),
    ])

class TestDistributions(unittest.TestCase):
    def test_zeroinputs(self) -> None:
        # Verify that distributions can handle a series of zero inputs'
        g = random.Random()
        x = [g.random() for i in range(50)] + [0.0]*5
        def patch() -> None:
            setattr(g, 'random', x[:].pop)
        patch(); g.uniform(1.0,10.0)
        patch(); g.paretovariate(1.0)
        patch(); g.expovariate(1.0)
        patch(); g.weibullvariate(1.0, 1.0)
        patch(); g.normalvariate(0.0, 1.0)
        patch(); g.gauss(0.0, 1.0)
        patch(); g.lognormvariate(0.0, 1.0)
        patch(); g.vonmisesvariate(0.0, 1.0)
        patch(); g.gammavariate(0.01, 1.0)
        patch(); g.gammavariate(1.0, 1.0)
        patch(); g.gammavariate(200.0, 1.0)
        patch(); g.betavariate(3.0, 3.0)
        patch(); g.triangular(0.0, 1.0, 1.0/3.0)

    def test_avg_std(self) -> None:
        # Use integration to test distribution average and standard deviation.
        # Only works for distributions which do not consume variates in pairs
        g = random.Random()
        N = 5000
        x = [i/float(N) for i in range(1,N)]
        variate = Undefined(Any)
        for variate, args, mu, sigmasqrd in [
                (g.uniform, (1.0,10.0), (10.0+1.0)/2, (10.0-1.0)**2/12),
                (g.triangular, (0.0, 1.0, 1.0/3.0), 4.0/9.0, 7.0/9.0/18.0),
                (g.expovariate, (1.5,), 1/1.5, 1/1.5**2),
                (g.paretovariate, (5.0,), 5.0/(5.0-1),
                                  5.0/((5.0-1)**2*(5.0-2))),
                (g.weibullvariate, (1.0, 3.0), gamma(1+1/3.0),
                                  gamma(1+2/3.0)-gamma(1+1/3.0)**2) ]:
            setattr(g, 'random', x[:].pop)
            y = List[float]()
            for i in range(len(x)):
                try:
                    y.append(variate(*args))
                except IndexError:
                    pass
            s1 = s2 = 0.0
            for e in y:
                s1 += e
                s2 += (e - mu) ** 2
            N = len(y)
            self.assertAlmostEqual(s1/N, mu, places=2)
            self.assertAlmostEqual(s2/(N-1), sigmasqrd, places=2)

class TestModule(unittest.TestCase):
    def testMagicConstants(self) -> None:
        self.assertAlmostEqual(random.NV_MAGICCONST, 1.71552776992141)
        self.assertAlmostEqual(random.TWOPI, 6.28318530718)
        self.assertAlmostEqual(random.LOG4, 1.38629436111989)
        self.assertAlmostEqual(random.SG_MAGICCONST, 2.50407739677627)

    def test__all__(self) -> None:
        # tests validity but not completeness of the __all__ list
        self.assertTrue(set(random.__all__) <= set(dir(random)))

    def test_random_subclass_with_kwargs(self) -> None:
        # SF bug #1486663 -- this used to erroneously raise a TypeError
        class Subclass(random.Random):
            def __init__(self, newarg: object = None) -> None:
                random.Random.__init__(self)
        Subclass(newarg=1)


def test_main(verbose: bool = None) -> None:
    testclasses =    [MersenneTwister_TestBasicOps,
                      TestDistributions,
                      TestModule]

    try:
        random.SystemRandom().random()
    except NotImplementedError:
        pass
    else:
        testclasses.append(SystemRandom_TestBasicOps)

    support.run_unittest(*testclasses)

    # verify reference counting
    import sys
    if verbose and hasattr(sys, "gettotalrefcount"):
        counts = [None] * 5 # type: List[int]
        for i in range(len(counts)):
            support.run_unittest(*testclasses)
            counts[i] = sys.gettotalrefcount()
        print(counts)

if __name__ == "__main__":
    test_main(verbose=True)

########NEW FILE########
__FILENAME__ = test_set
import unittest
from test import support
import gc
import weakref
import operator
import copy
import pickle
from random import randrange, shuffle
import sys
import warnings
import collections
from typing import Set, Any, Undefined

class PassThru(Exception):
    pass

def check_pass_thru():
    raise PassThru
    yield 1

class BadCmp:
    def __hash__(self):
        return 1
    def __eq__(self, other):
        raise RuntimeError

class ReprWrapper:
    'Used to test self-referential repr() calls'
    def __repr__(self):
        return repr(self.value)

#class HashCountingInt(int):
#    'int-like object that counts the number of times __hash__ is called'
#    def __init__(self, *args):
#        self.hash_count = 0
#    def __hash__(self):
#        self.hash_count += 1
#        return int.__hash__(self)

class TestJointOps(unittest.TestCase):
    # Tests common to both set and frozenset

    def setUp(self):
        self.word = word = 'simsalabim'
        self.otherword = 'madagascar'
        self.letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
        self.s = self.thetype(word)
        self.d = dict.fromkeys(word)

    def test_new_or_init(self):
        self.assertRaises(TypeError, self.thetype, [], 2)
        self.assertRaises(TypeError, set().__init__, a=1)

    def test_uniquification(self):
        actual = sorted(self.s)
        expected = sorted(self.d)
        self.assertEqual(actual, expected)
        self.assertRaises(PassThru, self.thetype, check_pass_thru())
        self.assertRaises(TypeError, self.thetype, [[]])

    def test_len(self):
        self.assertEqual(len(self.s), len(self.d))

    def test_contains(self):
        for c in self.letters:
            self.assertEqual(c in self.s, c in self.d)
        self.assertRaises(TypeError, self.s.__contains__, [[]])
        s = self.thetype([frozenset(self.letters)])
        self.assertIn(self.thetype(self.letters), s)

    def test_union(self):
        u = self.s.union(self.otherword)
        for c in self.letters:
            self.assertEqual(c in u, c in self.d or c in self.otherword)
        self.assertEqual(self.s, self.thetype(self.word))
        self.assertEqual(type(u), self.basetype)
        self.assertRaises(PassThru, self.s.union, check_pass_thru())
        self.assertRaises(TypeError, self.s.union, [[]])
        for C in set, frozenset, dict.fromkeys, str, list, tuple:
            self.assertEqual(self.thetype('abcba').union(C('cdc')), set('abcd'))
            self.assertEqual(self.thetype('abcba').union(C('efgfe')), set('abcefg'))
            self.assertEqual(self.thetype('abcba').union(C('ccb')), set('abc'))
            self.assertEqual(self.thetype('abcba').union(C('ef')), set('abcef'))
            self.assertEqual(self.thetype('abcba').union(C('ef'), C('fg')), set('abcefg'))

        # Issue #6573
        x = self.thetype()
        self.assertEqual(x.union(set([1]), x, set([2])), self.thetype([1, 2]))

    def test_or(self):
        i = self.s.union(self.otherword)
        self.assertEqual(self.s | set(self.otherword), i)
        self.assertEqual(self.s | frozenset(self.otherword), i)
        try:
            self.s | self.otherword
        except TypeError:
            pass
        else:
            self.fail("s|t did not screen-out general iterables")

    def test_intersection(self):
        i = self.s.intersection(self.otherword)
        for c in self.letters:
            self.assertEqual(c in i, c in self.d and c in self.otherword)
        self.assertEqual(self.s, self.thetype(self.word))
        self.assertEqual(type(i), self.basetype)
        self.assertRaises(PassThru, self.s.intersection, check_pass_thru())
        for C in set, frozenset, dict.fromkeys, str, list, tuple:
            self.assertEqual(self.thetype('abcba').intersection(C('cdc')), set('cc'))
            self.assertEqual(self.thetype('abcba').intersection(C('efgfe')), set(''))
            self.assertEqual(self.thetype('abcba').intersection(C('ccb')), set('bc'))
            self.assertEqual(self.thetype('abcba').intersection(C('ef')), set(''))
            self.assertEqual(self.thetype('abcba').intersection(C('cbcf'), C('bag')), set('b'))
        s = self.thetype('abcba')
        z = s.intersection()
        if self.thetype == frozenset():
            self.assertEqual(id(s), id(z))
        else:
            self.assertNotEqual(id(s), id(z))

    def test_isdisjoint(self):
        def f(s1, s2):
            'Pure python equivalent of isdisjoint()'
            return not set(s1).intersection(s2)
        for larg in '', 'a', 'ab', 'abc', 'ababac', 'cdc', 'cc', 'efgfe', 'ccb', 'ef':
            s1 = self.thetype(larg)
            for rarg in '', 'a', 'ab', 'abc', 'ababac', 'cdc', 'cc', 'efgfe', 'ccb', 'ef':
                for C in set, frozenset, dict.fromkeys, str, list, tuple:
                    s2 = C(rarg)
                    actual = s1.isdisjoint(s2)
                    expected = f(s1, s2)
                    self.assertEqual(actual, expected)
                    self.assertTrue(actual is True or actual is False)

    def test_and(self):
        i = self.s.intersection(self.otherword)
        self.assertEqual(self.s & set(self.otherword), i)
        self.assertEqual(self.s & frozenset(self.otherword), i)
        try:
            self.s & self.otherword
        except TypeError:
            pass
        else:
            self.fail("s&t did not screen-out general iterables")

    def test_difference(self):
        i = self.s.difference(self.otherword)
        for c in self.letters:
            self.assertEqual(c in i, c in self.d and c not in self.otherword)
        self.assertEqual(self.s, self.thetype(self.word))
        self.assertEqual(type(i), self.basetype)
        self.assertRaises(PassThru, self.s.difference, check_pass_thru())
        self.assertRaises(TypeError, self.s.difference, [[]])
        for C in set, frozenset, dict.fromkeys, str, list, tuple:
            self.assertEqual(self.thetype('abcba').difference(C('cdc')), set('ab'))
            self.assertEqual(self.thetype('abcba').difference(C('efgfe')), set('abc'))
            self.assertEqual(self.thetype('abcba').difference(C('ccb')), set('a'))
            self.assertEqual(self.thetype('abcba').difference(C('ef')), set('abc'))
            self.assertEqual(self.thetype('abcba').difference(), set('abc'))
            self.assertEqual(self.thetype('abcba').difference(C('a'), C('b')), set('c'))

    def test_sub(self):
        i = self.s.difference(self.otherword)
        self.assertEqual(self.s - set(self.otherword), i)
        self.assertEqual(self.s - frozenset(self.otherword), i)
        try:
            self.s - self.otherword
        except TypeError:
            pass
        else:
            self.fail("s-t did not screen-out general iterables")

    def test_symmetric_difference(self):
        i = self.s.symmetric_difference(self.otherword)
        for c in self.letters:
            self.assertEqual(c in i, (c in self.d) ^ (c in self.otherword))
        self.assertEqual(self.s, self.thetype(self.word))
        self.assertEqual(type(i), self.basetype)
        self.assertRaises(PassThru, self.s.symmetric_difference, check_pass_thru())
        self.assertRaises(TypeError, self.s.symmetric_difference, [[]])
        for C in set, frozenset, dict.fromkeys, str, list, tuple:
            self.assertEqual(self.thetype('abcba').symmetric_difference(C('cdc')), set('abd'))
            self.assertEqual(self.thetype('abcba').symmetric_difference(C('efgfe')), set('abcefg'))
            self.assertEqual(self.thetype('abcba').symmetric_difference(C('ccb')), set('a'))
            self.assertEqual(self.thetype('abcba').symmetric_difference(C('ef')), set('abcef'))

    def test_xor(self):
        i = self.s.symmetric_difference(self.otherword)
        self.assertEqual(self.s ^ set(self.otherword), i)
        self.assertEqual(self.s ^ frozenset(self.otherword), i)
        try:
            self.s ^ self.otherword
        except TypeError:
            pass
        else:
            self.fail("s^t did not screen-out general iterables")

    def test_equality(self):
        self.assertEqual(self.s, set(self.word))
        self.assertEqual(self.s, frozenset(self.word))
        self.assertEqual(self.s == self.word, False)
        self.assertNotEqual(self.s, set(self.otherword))
        self.assertNotEqual(self.s, frozenset(self.otherword))
        self.assertEqual(self.s != self.word, True)

    def test_setOfFrozensets(self):
        t = map(frozenset, ['abcdef', 'bcd', 'bdcb', 'fed', 'fedccba'])
        s = self.thetype(t)
        self.assertEqual(len(s), 3)

    def test_sub_and_super(self):
        p, q, r = map(self.thetype, ['ab', 'abcde', 'def'])
        self.assertTrue(p < q)
        self.assertTrue(p <= q)
        self.assertTrue(q <= q)
        self.assertTrue(q > p)
        self.assertTrue(q >= p)
        self.assertFalse(q < r)
        self.assertFalse(q <= r)
        self.assertFalse(q > r)
        self.assertFalse(q >= r)
        self.assertTrue(set('a').issubset('abc'))
        self.assertTrue(set('abc').issuperset('a'))
        self.assertFalse(set('a').issubset('cbs'))
        self.assertFalse(set('cbs').issuperset('a'))

    def test_pickling(self):
        for i in range(pickle.HIGHEST_PROTOCOL + 1):
            p = pickle.dumps(self.s, i)
            dup = pickle.loads(p)
            self.assertEqual(self.s, dup, "%s != %s" % (self.s, dup))
            if type(self.s) not in (set, frozenset):
                self.s.x = 10
                p = pickle.dumps(self.s)
                dup = pickle.loads(p)
                self.assertEqual(self.s.x, dup.x)

    def test_deepcopy(self):
        class Tracer:
            def __init__(self, value):
                self.value = value
            def __hash__(self):
                return self.value
            def __deepcopy__(self, memo=None):
                return Tracer(self.value + 1)
        t = Tracer(10)
        s = self.thetype([t])
        dup = copy.deepcopy(s)
        self.assertNotEqual(id(s), id(dup))
        for elem in dup:
            newt = elem
        self.assertNotEqual(id(t), id(newt))
        self.assertEqual(t.value + 1, newt.value)

    def test_gc(self):
        # Create a nest of cycles to exercise overall ref count check
        class A:
            pass
        s = set(A() for i in range(1000))
        for elem in s:
            elem.cycle = s
            elem.sub = elem
            elem.set = set([elem])

    def test_subclass_with_custom_hash(self):
        raise NotImplementedError() # runtime computed base class below
        # Bug #1257731
        class H: # (self.thetype):
            def __hash__(self):
                return int(id(self) & 0x7fffffff)
        s=H()
        f=set()
        f.add(s)
        self.assertIn(s, f)
        f.remove(s)
        f.add(s)
        f.discard(s)

    def test_badcmp(self):
        s = self.thetype([BadCmp()])
        # Detect comparison errors during insertion and lookup
        self.assertRaises(RuntimeError, self.thetype, [BadCmp(), BadCmp()])
        self.assertRaises(RuntimeError, s.__contains__, BadCmp())
        # Detect errors during mutating operations
        if hasattr(s, 'add'):
            self.assertRaises(RuntimeError, s.add, BadCmp())
            self.assertRaises(RuntimeError, s.discard, BadCmp())
            self.assertRaises(RuntimeError, s.remove, BadCmp())

    def test_cyclical_repr(self):
        w = ReprWrapper()
        s = self.thetype([w])
        w.value = s
        if self.thetype == set:
            self.assertEqual(repr(s), '{set(...)}')
        else:
            name = repr(s).partition('(')[0]    # strip class name
            self.assertEqual(repr(s), '%s({%s(...)})' % (name, name))

    def test_cyclical_print(self):
        w = ReprWrapper()
        s = self.thetype([w])
        w.value = s
        fo = open(support.TESTFN, "w")
        try:
            fo.write(str(s))
            fo.close()
            fo = open(support.TESTFN, "r")
            self.assertEqual(fo.read(), repr(s))
        finally:
            fo.close()
            support.unlink(support.TESTFN)

    def test_do_not_rehash_dict_keys(self):
        raise NotImplementedError() # cannot subclass int
        n = 10
        d = None # dict.fromkeys(map(HashCountingInt, range(n)))
        self.assertEqual(sum(elem.hash_count for elem in d), n)
        s = self.thetype(d)
        self.assertEqual(sum(elem.hash_count for elem in d), n)
        s.difference(d)
        self.assertEqual(sum(elem.hash_count for elem in d), n)
        if hasattr(s, 'symmetric_difference_update'):
            s.symmetric_difference_update(d)
        self.assertEqual(sum(elem.hash_count for elem in d), n)
        d2 = dict.fromkeys(set(d))
        self.assertEqual(sum(elem.hash_count for elem in d), n)
        d3 = dict.fromkeys(frozenset(d))
        self.assertEqual(sum(elem.hash_count for elem in d), n)
        d3 = dict.fromkeys(frozenset(d), 123)
        self.assertEqual(sum(elem.hash_count for elem in d), n)
        self.assertEqual(d3, dict.fromkeys(d, 123))

    def test_container_iterator(self):
        # Bug #3680: tp_traverse was not implemented for set iterator object
        class C(object):
            pass
        obj = C()
        ref = weakref.ref(obj)
        container = set([obj, 1])
        obj.x = iter(container)
        obj = None
        container = None
        gc.collect()
        self.assertTrue(ref() is None, "Cycle was not collected")

class TestSet(TestJointOps):
    thetype = set
    basetype = set

    def test_init(self):
        s = self.thetype()
        s.__init__(self.word)
        self.assertEqual(s, set(self.word))
        s.__init__(self.otherword)
        self.assertEqual(s, set(self.otherword))
        self.assertRaises(TypeError, s.__init__, s, 2);
        self.assertRaises(TypeError, s.__init__, 1)

    def test_constructor_identity(self):
        s = self.thetype(range(3))
        t = self.thetype(s)
        self.assertNotEqual(id(s), id(t))

    def test_set_literal(self):
        raise NotImplementedError()
        #s = set([1,2,3])
        #t = {1,2,3}
        #self.assertEqual(s, t)

    def test_hash(self):
        self.assertRaises(TypeError, hash, self.s)

    def test_clear(self):
        self.s.clear()
        self.assertEqual(self.s, set())
        self.assertEqual(len(self.s), 0)

    def test_copy(self):
        dup = self.s.copy()
        self.assertEqual(self.s, dup)
        self.assertNotEqual(id(self.s), id(dup))
        self.assertEqual(type(dup), self.basetype)

    def test_add(self):
        self.s.add('Q')
        self.assertIn('Q', self.s)
        dup = self.s.copy()
        self.s.add('Q')
        self.assertEqual(self.s, dup)
        self.assertRaises(TypeError, self.s.add, [])

    def test_remove(self):
        self.s.remove('a')
        self.assertNotIn('a', self.s)
        self.assertRaises(KeyError, self.s.remove, 'Q')
        self.assertRaises(TypeError, self.s.remove, [])
        s = self.thetype([frozenset(self.word)])
        self.assertIn(self.thetype(self.word), s)
        s.remove(self.thetype(self.word))
        self.assertNotIn(self.thetype(self.word), s)
        self.assertRaises(KeyError, self.s.remove, self.thetype(self.word))

    def test_remove_keyerror_unpacking(self):
        # bug:  www.python.org/sf/1576657
        for v1 in ['Q', (1,)]:
            try:
                self.s.remove(v1)
            except KeyError as e:
                v2 = e.args[0]
                self.assertEqual(v1, v2)
            else:
                self.fail()

    def test_remove_keyerror_set(self):
        key = self.thetype([3, 4])
        try:
            self.s.remove(key)
        except KeyError as e:
            self.assertTrue(e.args[0] is key,
                         "KeyError should be {0}, not {1}".format(key,
                                                                  e.args[0]))
        else:
            self.fail()

    def test_discard(self):
        self.s.discard('a')
        self.assertNotIn('a', self.s)
        self.s.discard('Q')
        self.assertRaises(TypeError, self.s.discard, [])
        s = self.thetype([frozenset(self.word)])
        self.assertIn(self.thetype(self.word), s)
        s.discard(self.thetype(self.word))
        self.assertNotIn(self.thetype(self.word), s)
        s.discard(self.thetype(self.word))

    def test_pop(self):
        for i in range(len(self.s)):
            elem = self.s.pop()
            self.assertNotIn(elem, self.s)
        self.assertRaises(KeyError, self.s.pop)

    def test_update(self):
        retval = self.s.update(self.otherword)
        self.assertEqual(retval, None)
        for c in (self.word + self.otherword):
            self.assertIn(c, self.s)
        self.assertRaises(PassThru, self.s.update, check_pass_thru())
        self.assertRaises(TypeError, self.s.update, [[]])
        for p, q in (('cdc', 'abcd'), ('efgfe', 'abcefg'), ('ccb', 'abc'), ('ef', 'abcef')):
            for C in set, frozenset, dict.fromkeys, str, list, tuple:
                s = self.thetype('abcba')
                self.assertEqual(s.update(C(p)), None)
                self.assertEqual(s, set(q))
        for p in ('cdc', 'efgfe', 'ccb', 'ef', 'abcda'):
            q = 'ahi'
            for C in set, frozenset, dict.fromkeys, str, list, tuple:
                s = self.thetype('abcba')
                self.assertEqual(s.update(C(p), C(q)), None)
                self.assertEqual(s, set(s) | set(p) | set(q))

    def test_ior(self):
        self.s |= set(self.otherword)
        for c in (self.word + self.otherword):
            self.assertIn(c, self.s)

    def test_intersection_update(self):
        retval = self.s.intersection_update(self.otherword)
        self.assertEqual(retval, None)
        for c in (self.word + self.otherword):
            if c in self.otherword and c in self.word:
                self.assertIn(c, self.s)
            else:
                self.assertNotIn(c, self.s)
        self.assertRaises(PassThru, self.s.intersection_update, check_pass_thru())
        self.assertRaises(TypeError, self.s.intersection_update, [[]])
        for p, q in (('cdc', 'c'), ('efgfe', ''), ('ccb', 'bc'), ('ef', '')):
            for C in set, frozenset, dict.fromkeys, str, list, tuple:
                s = self.thetype('abcba')
                self.assertEqual(s.intersection_update(C(p)), None)
                self.assertEqual(s, set(q))
                ss = 'abcba'
                s = self.thetype(ss)
                t = 'cbc'
                self.assertEqual(s.intersection_update(C(p), C(t)), None)
                self.assertEqual(s, set('abcba')&set(p)&set(t))

    def test_iand(self):
        self.s &= set(self.otherword)
        for c in (self.word + self.otherword):
            if c in self.otherword and c in self.word:
                self.assertIn(c, self.s)
            else:
                self.assertNotIn(c, self.s)

    def test_difference_update(self):
        retval = self.s.difference_update(self.otherword)
        self.assertEqual(retval, None)
        for c in (self.word + self.otherword):
            if c in self.word and c not in self.otherword:
                self.assertIn(c, self.s)
            else:
                self.assertNotIn(c, self.s)
        self.assertRaises(PassThru, self.s.difference_update, check_pass_thru())
        self.assertRaises(TypeError, self.s.difference_update, [[]])
        self.assertRaises(TypeError, self.s.symmetric_difference_update, [[]])
        for p, q in (('cdc', 'ab'), ('efgfe', 'abc'), ('ccb', 'a'), ('ef', 'abc')):
            for C in set, frozenset, dict.fromkeys, str, list, tuple:
                s = self.thetype('abcba')
                self.assertEqual(s.difference_update(C(p)), None)
                self.assertEqual(s, set(q))

                s = self.thetype('abcdefghih')
                s.difference_update()
                self.assertEqual(s, self.thetype('abcdefghih'))

                s = self.thetype('abcdefghih')
                s.difference_update(C('aba'))
                self.assertEqual(s, self.thetype('cdefghih'))

                s = self.thetype('abcdefghih')
                s.difference_update(C('cdc'), C('aba'))
                self.assertEqual(s, self.thetype('efghih'))

    def test_isub(self):
        self.s -= set(self.otherword)
        for c in (self.word + self.otherword):
            if c in self.word and c not in self.otherword:
                self.assertIn(c, self.s)
            else:
                self.assertNotIn(c, self.s)

    def test_symmetric_difference_update(self):
        retval = self.s.symmetric_difference_update(self.otherword)
        self.assertEqual(retval, None)
        for c in (self.word + self.otherword):
            if (c in self.word) ^ (c in self.otherword):
                self.assertIn(c, self.s)
            else:
                self.assertNotIn(c, self.s)
        self.assertRaises(PassThru, self.s.symmetric_difference_update, check_pass_thru())
        self.assertRaises(TypeError, self.s.symmetric_difference_update, [[]])
        for p, q in (('cdc', 'abd'), ('efgfe', 'abcefg'), ('ccb', 'a'), ('ef', 'abcef')):
            for C in set, frozenset, dict.fromkeys, str, list, tuple:
                s = self.thetype('abcba')
                self.assertEqual(s.symmetric_difference_update(C(p)), None)
                self.assertEqual(s, set(q))

    def test_ixor(self):
        self.s ^= set(self.otherword)
        for c in (self.word + self.otherword):
            if (c in self.word) ^ (c in self.otherword):
                self.assertIn(c, self.s)
            else:
                self.assertNotIn(c, self.s)

    def test_inplace_on_self(self):
        t = self.s.copy()
        t |= t
        self.assertEqual(t, self.s)
        t &= t
        self.assertEqual(t, self.s)
        t -= t
        self.assertEqual(t, self.thetype())
        t = self.s.copy()
        t ^= t
        self.assertEqual(t, self.thetype())

    def test_weakref(self):
        s = self.thetype('gallahad')
        p = weakref.proxy(s)
        self.assertEqual(str(p), str(s))
        s = None
        self.assertRaises(ReferenceError, str, p)

    def test_rich_compare(self):
        class TestRichSetCompare:
            def __gt__(self, some_set):
                self.gt_called = True
                return False
            def __lt__(self, some_set):
                self.lt_called = True
                return False
            def __ge__(self, some_set):
                self.ge_called = True
                return False
            def __le__(self, some_set):
                self.le_called = True
                return False

        # This first tries the builtin rich set comparison, which doesn't know
        # how to handle the custom object. Upon returning NotImplemented, the
        # corresponding comparison on the right object is invoked.
        myset = {1, 2, 3}

        myobj = TestRichSetCompare()
        myset < myobj
        self.assertTrue(myobj.gt_called)

        myobj = TestRichSetCompare()
        myset > myobj
        self.assertTrue(myobj.lt_called)

        myobj = TestRichSetCompare()
        myset <= myobj
        self.assertTrue(myobj.ge_called)

        myobj = TestRichSetCompare()
        myset >= myobj
        self.assertTrue(myobj.le_called)

    # C API test only available in a debug build
    if hasattr(set, "test_c_api"):
        def test_c_api(self):
            self.assertEqual(set().test_c_api(), True)

class SetSubclass(set):
    pass

class TestSetSubclass(TestSet):
    thetype = SetSubclass
    basetype = set

class SetSubclassWithKeywordArgs(set):
    def __init__(self, iterable=[], newarg=None):
        set.__init__(self, iterable)

class TestSetSubclassWithKeywordArgs(TestSet):

    def test_keywords_in_subclass(self):
        'SF bug #1486663 -- this used to erroneously raise a TypeError'
        SetSubclassWithKeywordArgs(newarg=1)

class TestFrozenSet(TestJointOps):
    thetype = frozenset
    basetype = frozenset

    def test_init(self):
        s = self.thetype(self.word)
        s.__init__(self.otherword)
        self.assertEqual(s, set(self.word))

    def test_singleton_empty_frozenset(self):
        f = frozenset()
        efs = [frozenset(), frozenset([]), frozenset(()), frozenset(''),
               frozenset(), frozenset([]), frozenset(()), frozenset(''),
               frozenset(range(0)), frozenset(frozenset()),
               frozenset(f), f]
        # All of the empty frozensets should have just one id()
        self.assertEqual(len(set(map(id, efs))), 1)

    def test_constructor_identity(self):
        s = self.thetype(range(3))
        t = self.thetype(s)
        self.assertEqual(id(s), id(t))

    def test_hash(self):
        self.assertEqual(hash(self.thetype('abcdeb')),
                         hash(self.thetype('ebecda')))

        # make sure that all permutations give the same hash value
        n = 100
        seq = [randrange(n) for i in range(n)]
        results = set()
        for i in range(200):
            shuffle(seq)
            results.add(hash(self.thetype(seq)))
        self.assertEqual(len(results), 1)

    def test_copy(self):
        dup = self.s.copy()
        self.assertEqual(id(self.s), id(dup))

    def test_frozen_as_dictkey(self):
        seq = list(range(10)) + list('abcdefg') + ['apple']
        key1 = self.thetype(seq)
        key2 = self.thetype(reversed(seq))
        self.assertEqual(key1, key2)
        self.assertNotEqual(id(key1), id(key2))
        d = {}
        d[key1] = 42
        self.assertEqual(d[key2], 42)

    def test_hash_caching(self):
        f = self.thetype('abcdcda')
        self.assertEqual(hash(f), hash(f))

    def test_hash_effectiveness(self):
        n = 13
        hashvalues = set()
        addhashvalue = hashvalues.add
        elemmasks = [(i+1, 1<<i) for i in range(n)]
        for i in range(2**n):
            addhashvalue(hash(frozenset([e for e, m in elemmasks if m&i])))
        self.assertEqual(len(hashvalues), 2**n)

class FrozenSetSubclass(frozenset):
    pass

class TestFrozenSetSubclass(TestFrozenSet):
    thetype = FrozenSetSubclass
    basetype = frozenset

    def test_constructor_identity(self):
        s = self.thetype(range(3))
        t = self.thetype(s)
        self.assertNotEqual(id(s), id(t))

    def test_copy(self):
        dup = self.s.copy()
        self.assertNotEqual(id(self.s), id(dup))

    def test_nested_empty_constructor(self):
        s = self.thetype()
        t = self.thetype(s)
        self.assertEqual(s, t)

    def test_singleton_empty_frozenset(self):
        Frozenset = self.thetype
        f = frozenset()
        F = Frozenset()
        efs = [Frozenset(), Frozenset([]), Frozenset(()), Frozenset(''),
               Frozenset(), Frozenset([]), Frozenset(()), Frozenset(''),
               Frozenset(range(0)), Frozenset(Frozenset()),
               Frozenset(frozenset()), f, F, Frozenset(f), Frozenset(F)]
        # All empty frozenset subclass instances should have different ids
        self.assertEqual(len(set(map(id, efs))), len(efs))

# Tests taken from test_sets.py =============================================

empty_set = set() # type: Any

#==============================================================================

class TestBasicOps(unittest.TestCase):

    def test_repr(self):
        if self.repr is not None:
            self.assertEqual(repr(self.set), self.repr)

    def check_repr_against_values(self):
        text = repr(self.set)
        self.assertTrue(text.startswith('{'))
        self.assertTrue(text.endswith('}'))

        result = text[1:-1].split(', ')
        result.sort()
        sorted_repr_values = [repr(value) for value in self.values]
        sorted_repr_values.sort()
        self.assertEqual(result, sorted_repr_values)

    def test_print(self):
        try:
            fo = open(support.TESTFN, "w")
            fo.write(str(self.set))
            fo.close()
            fo = open(support.TESTFN, "r")
            self.assertEqual(fo.read(), repr(self.set))
        finally:
            fo.close()
            support.unlink(support.TESTFN)

    def test_length(self):
        self.assertEqual(len(self.set), self.length)

    def test_self_equality(self):
        self.assertEqual(self.set, self.set)

    def test_equivalent_equality(self):
        self.assertEqual(self.set, self.dup)

    def test_copy(self):
        self.assertEqual(self.set.copy(), self.dup)

    def test_self_union(self):
        result = self.set | self.set
        self.assertEqual(result, self.dup)

    def test_empty_union(self):
        result = self.set | empty_set
        self.assertEqual(result, self.dup)

    def test_union_empty(self):
        result = empty_set | self.set
        self.assertEqual(result, self.dup)

    def test_self_intersection(self):
        result = self.set & self.set
        self.assertEqual(result, self.dup)

    def test_empty_intersection(self):
        result = self.set & empty_set
        self.assertEqual(result, empty_set)

    def test_intersection_empty(self):
        result = empty_set & self.set
        self.assertEqual(result, empty_set)

    def test_self_isdisjoint(self):
        result = self.set.isdisjoint(self.set)
        self.assertEqual(result, not self.set)

    def test_empty_isdisjoint(self):
        result = self.set.isdisjoint(empty_set)
        self.assertEqual(result, True)

    def test_isdisjoint_empty(self):
        result = empty_set.isdisjoint(self.set)
        self.assertEqual(result, True)

    def test_self_symmetric_difference(self):
        result = self.set ^ self.set
        self.assertEqual(result, empty_set)

    def test_empty_symmetric_difference(self):
        result = self.set ^ empty_set
        self.assertEqual(result, self.set)

    def test_self_difference(self):
        result = self.set - self.set
        self.assertEqual(result, empty_set)

    def test_empty_difference(self):
        result = self.set - empty_set
        self.assertEqual(result, self.dup)

    def test_empty_difference_rev(self):
        result = empty_set - self.set
        self.assertEqual(result, empty_set)

    def test_iteration(self):
        for v in self.set:
            self.assertIn(v, self.values)
        setiter = iter(self.set)
        # note: __length_hint__ is an internal undocumented API,
        # don't rely on it in your own programs
        self.assertEqual(setiter.__length_hint__(), len(self.set))

    def test_pickling(self):
        p = pickle.dumps(self.set)
        copy = pickle.loads(p)
        self.assertEqual(self.set, copy,
                         "%s != %s" % (self.set, copy))

#------------------------------------------------------------------------------

class TestBasicOpsEmpty(TestBasicOps):
    def setUp(self):
        self.case   = "empty set"
        self.values = []
        self.set    = set(self.values)
        self.dup    = set(self.values)
        self.length = 0
        self.repr   = "set()"

#------------------------------------------------------------------------------

class TestBasicOpsSingleton(TestBasicOps):
    def setUp(self):
        self.case   = "unit set (number)"
        self.values = [3]
        self.set    = set(self.values)
        self.dup    = set(self.values)
        self.length = 1
        self.repr   = "{3}"

    def test_in(self):
        self.assertIn(3, self.set)

    def test_not_in(self):
        self.assertNotIn(2, self.set)

#------------------------------------------------------------------------------

class TestBasicOpsTuple(TestBasicOps):
    def setUp(self):
        self.case   = "unit set (tuple)"
        self.values = [(0, "zero")]
        self.set    = set(self.values)
        self.dup    = set(self.values)
        self.length = 1
        self.repr   = "{(0, 'zero')}"

    def test_in(self):
        self.assertIn((0, "zero"), self.set)

    def test_not_in(self):
        self.assertNotIn(9, self.set)

#------------------------------------------------------------------------------

class TestBasicOpsTriple(TestBasicOps):
    def setUp(self):
        self.case   = "triple set"
        self.values = [0, "zero", operator.add]
        self.set    = set(self.values)
        self.dup    = set(self.values)
        self.length = 3
        self.repr   = None

#------------------------------------------------------------------------------

class TestBasicOpsString(TestBasicOps):
    def setUp(self):
        self.case   = "string set"
        self.values = ["a", "b", "c"]
        self.set    = set(self.values)
        self.dup    = set(self.values)
        self.length = 3

    def test_repr(self):
        self.check_repr_against_values()

#------------------------------------------------------------------------------

class TestBasicOpsBytes(TestBasicOps):
    def setUp(self):
        self.case   = "string set"
        self.values = [b"a", b"b", b"c"]
        self.set    = set(self.values)
        self.dup    = set(self.values)
        self.length = 3

    def test_repr(self):
        self.check_repr_against_values()

#------------------------------------------------------------------------------

class TestBasicOpsMixedStringBytes(TestBasicOps):
    def setUp(self):
        self._warning_filters = support.check_warnings()
        self._warning_filters.__enter__()
        warnings.simplefilter('ignore', BytesWarning)
        self.case   = "string and bytes set"
        self.values = ["a", "b", b"a", b"b"]
        self.set    = set(self.values)
        self.dup    = set(self.values)
        self.length = 4

    def tearDown(self):
        self._warning_filters.__exit__(None, None, None)

    def test_repr(self):
        self.check_repr_against_values()

#==============================================================================

def baditer():
    raise TypeError
    yield True

def gooditer():
    yield True

class TestExceptionPropagation(unittest.TestCase):
    """SF 628246:  Set constructor should not trap iterator TypeErrors"""

    def test_instanceWithException(self):
        self.assertRaises(TypeError, set, baditer())

    def test_instancesWithoutException(self):
        # All of these iterables should load without exception.
        set([1,2,3])
        set((1,2,3))
        set({'one':1, 'two':2, 'three':3})
        set(range(3))
        set('abc')
        set(gooditer())

    def test_changingSizeWhileIterating(self):
        s = set([1,2,3])
        try:
            for i in s:
                s.update([4])
        except RuntimeError:
            pass
        else:
            self.fail("no exception when changing size during iteration")

#==============================================================================

class TestSetOfSets(unittest.TestCase):
    def test_constructor(self):
        inner = frozenset([1])
        outer = set([inner])
        element = outer.pop()
        self.assertEqual(type(element), frozenset)
        outer.add(inner)        # Rebuild set of sets with .add method
        outer.remove(inner)
        self.assertEqual(outer, set())   # Verify that remove worked
        outer.discard(inner)    # Absence of KeyError indicates working fine

#==============================================================================

class TestBinaryOps(unittest.TestCase):
    def setUp(self):
        self.set = set((2, 4, 6))

    def test_eq(self):              # SF bug 643115
        self.assertEqual(self.set, set({2:1,4:3,6:5}))

    def test_union_subset(self):
        result = self.set | set([2])
        self.assertEqual(result, set((2, 4, 6)))

    def test_union_superset(self):
        result = self.set | set([2, 4, 6, 8])
        self.assertEqual(result, set([2, 4, 6, 8]))

    def test_union_overlap(self):
        result = self.set | set([3, 4, 5])
        self.assertEqual(result, set([2, 3, 4, 5, 6]))

    def test_union_non_overlap(self):
        result = self.set | set([8])
        self.assertEqual(result, set([2, 4, 6, 8]))

    def test_intersection_subset(self):
        result = self.set & set((2, 4))
        self.assertEqual(result, set((2, 4)))

    def test_intersection_superset(self):
        result = self.set & set([2, 4, 6, 8])
        self.assertEqual(result, set([2, 4, 6]))

    def test_intersection_overlap(self):
        result = self.set & set([3, 4, 5])
        self.assertEqual(result, set([4]))

    def test_intersection_non_overlap(self):
        result = self.set & set([8])
        self.assertEqual(result, empty_set)

    def test_isdisjoint_subset(self):
        result = self.set.isdisjoint(set((2, 4)))
        self.assertEqual(result, False)

    def test_isdisjoint_superset(self):
        result = self.set.isdisjoint(set([2, 4, 6, 8]))
        self.assertEqual(result, False)

    def test_isdisjoint_overlap(self):
        result = self.set.isdisjoint(set([3, 4, 5]))
        self.assertEqual(result, False)

    def test_isdisjoint_non_overlap(self):
        result = self.set.isdisjoint(set([8]))
        self.assertEqual(result, True)

    def test_sym_difference_subset(self):
        result = self.set ^ set((2, 4))
        self.assertEqual(result, set([6]))

    def test_sym_difference_superset(self):
        result = self.set ^ set((2, 4, 6, 8))
        self.assertEqual(result, set([8]))

    def test_sym_difference_overlap(self):
        result = self.set ^ set((3, 4, 5))
        self.assertEqual(result, set([2, 3, 5, 6]))

    def test_sym_difference_non_overlap(self):
        result = self.set ^ set([8])
        self.assertEqual(result, set([2, 4, 6, 8]))

#==============================================================================

class TestUpdateOps(unittest.TestCase):
    def setUp(self):
        self.set = set((2, 4, 6))

    def test_union_subset(self):
        self.set |= set([2])
        self.assertEqual(self.set, set((2, 4, 6)))

    def test_union_superset(self):
        self.set |= set([2, 4, 6, 8])
        self.assertEqual(self.set, set([2, 4, 6, 8]))

    def test_union_overlap(self):
        self.set |= set([3, 4, 5])
        self.assertEqual(self.set, set([2, 3, 4, 5, 6]))

    def test_union_non_overlap(self):
        self.set |= set([8])
        self.assertEqual(self.set, set([2, 4, 6, 8]))

    def test_union_method_call(self):
        self.set.update(set([3, 4, 5]))
        self.assertEqual(self.set, set([2, 3, 4, 5, 6]))

    def test_intersection_subset(self):
        self.set &= set((2, 4))
        self.assertEqual(self.set, set((2, 4)))

    def test_intersection_superset(self):
        self.set &= set([2, 4, 6, 8])
        self.assertEqual(self.set, set([2, 4, 6]))

    def test_intersection_overlap(self):
        self.set &= set([3, 4, 5])
        self.assertEqual(self.set, set([4]))

    def test_intersection_non_overlap(self):
        self.set &= set([8])
        self.assertEqual(self.set, empty_set)

    def test_intersection_method_call(self):
        self.set.intersection_update(set([3, 4, 5]))
        self.assertEqual(self.set, set([4]))

    def test_sym_difference_subset(self):
        self.set ^= set((2, 4))
        self.assertEqual(self.set, set([6]))

    def test_sym_difference_superset(self):
        self.set ^= set((2, 4, 6, 8))
        self.assertEqual(self.set, set([8]))

    def test_sym_difference_overlap(self):
        self.set ^= set((3, 4, 5))
        self.assertEqual(self.set, set([2, 3, 5, 6]))

    def test_sym_difference_non_overlap(self):
        self.set ^= set([8])
        self.assertEqual(self.set, set([2, 4, 6, 8]))

    def test_sym_difference_method_call(self):
        self.set.symmetric_difference_update(set([3, 4, 5]))
        self.assertEqual(self.set, set([2, 3, 5, 6]))

    def test_difference_subset(self):
        self.set -= set((2, 4))
        self.assertEqual(self.set, set([6]))

    def test_difference_superset(self):
        self.set -= set((2, 4, 6, 8))
        self.assertEqual(self.set, set([]))

    def test_difference_overlap(self):
        self.set -= set((3, 4, 5))
        self.assertEqual(self.set, set([2, 6]))

    def test_difference_non_overlap(self):
        self.set -= set([8])
        self.assertEqual(self.set, set([2, 4, 6]))

    def test_difference_method_call(self):
        self.set.difference_update(set([3, 4, 5]))
        self.assertEqual(self.set, set([2, 6]))

#==============================================================================

class TestMutate(unittest.TestCase):
    def setUp(self):
        self.values = ["a", "b", "c"]
        self.set = set(self.values)

    def test_add_present(self):
        self.set.add("c")
        self.assertEqual(self.set, set("abc"))

    def test_add_absent(self):
        self.set.add("d")
        self.assertEqual(self.set, set("abcd"))

    def test_add_until_full(self):
        tmp = set()
        expected_len = 0
        for v in self.values:
            tmp.add(v)
            expected_len += 1
            self.assertEqual(len(tmp), expected_len)
        self.assertEqual(tmp, self.set)

    def test_remove_present(self):
        self.set.remove("b")
        self.assertEqual(self.set, set("ac"))

    def test_remove_absent(self):
        try:
            self.set.remove("d")
            self.fail("Removing missing element should have raised LookupError")
        except LookupError:
            pass

    def test_remove_until_empty(self):
        expected_len = len(self.set)
        for v in self.values:
            self.set.remove(v)
            expected_len -= 1
            self.assertEqual(len(self.set), expected_len)

    def test_discard_present(self):
        self.set.discard("c")
        self.assertEqual(self.set, set("ab"))

    def test_discard_absent(self):
        self.set.discard("d")
        self.assertEqual(self.set, set("abc"))

    def test_clear(self):
        self.set.clear()
        self.assertEqual(len(self.set), 0)

    def test_pop(self):
        popped = {}
        while self.set:
            popped[self.set.pop()] = None
        self.assertEqual(len(popped), len(self.values))
        for v in self.values:
            self.assertIn(v, popped)

    def test_update_empty_tuple(self):
        self.set.update(())
        self.assertEqual(self.set, set(self.values))

    def test_update_unit_tuple_overlap(self):
        self.set.update(("a",))
        self.assertEqual(self.set, set(self.values))

    def test_update_unit_tuple_non_overlap(self):
        self.set.update(("a", "z"))
        self.assertEqual(self.set, set(self.values + ["z"]))

#==============================================================================

class TestSubsets(unittest.TestCase):

    case2method = {"<=": "issubset",
                   ">=": "issuperset",
                  }

    reverse = {"==": "==",
               "!=": "!=",
               "<":  ">",
               ">":  "<",
               "<=": ">=",
               ">=": "<=",
              }

    def test_issubset(self):
        raise NotImplementedError() # eval not supported below
        x = self.left
        y = self.right
        for case in "!=", "==", "<", "<=", ">", ">=":
            expected = case in self.cases
            # Test the binary infix spelling.
            result = None ## eval("x" + case + "y", locals())
            self.assertEqual(result, expected)
            # Test the "friendly" method-name spelling, if one exists.
            if case in TestSubsets.case2method:
                method = getattr(x, TestSubsets.case2method[case])
                result = method(y)
                self.assertEqual(result, expected)

            # Now do the same for the operands reversed.
            rcase = TestSubsets.reverse[case]
            result = None ## eval("y" + rcase + "x", locals())
            self.assertEqual(result, expected)
            if rcase in TestSubsets.case2method:
                method = getattr(y, TestSubsets.case2method[rcase])
                result = method(x)
                self.assertEqual(result, expected)
#------------------------------------------------------------------------------

class TestSubsetEqualEmpty(TestSubsets):
    left  = set() # type: Any
    right = set() # type: Any
    name  = "both empty"
    cases = "==", "<=", ">="

#------------------------------------------------------------------------------

class TestSubsetEqualNonEmpty(TestSubsets):
    left  = set([1, 2])
    right = set([1, 2])
    name  = "equal pair"
    cases = "==", "<=", ">="

#------------------------------------------------------------------------------

class TestSubsetEmptyNonEmpty(TestSubsets):
    left  = set() # type: Any
    right = set([1, 2])
    name  = "one empty, one non-empty"
    cases = "!=", "<", "<="

#------------------------------------------------------------------------------

class TestSubsetPartial(TestSubsets):
    left  = set([1])
    right = set([1, 2])
    name  = "one a non-empty proper subset of other"
    cases = "!=", "<", "<="

#------------------------------------------------------------------------------

class TestSubsetNonOverlap(TestSubsets):
    left  = set([1])
    right = set([2])
    name  = "neither empty, neither contains"
    cases = "!="

#==============================================================================

class TestOnlySetsInBinaryOps(unittest.TestCase):

    def test_eq_ne(self):
        # Unlike the others, this is testing that == and != *are* allowed.
        self.assertEqual(self.other == self.set, False)
        self.assertEqual(self.set == self.other, False)
        self.assertEqual(self.other != self.set, True)
        self.assertEqual(self.set != self.other, True)

    def test_ge_gt_le_lt(self):
        self.assertRaises(TypeError, lambda: self.set < self.other)
        self.assertRaises(TypeError, lambda: self.set <= self.other)
        self.assertRaises(TypeError, lambda: self.set > self.other)
        self.assertRaises(TypeError, lambda: self.set >= self.other)

        self.assertRaises(TypeError, lambda: self.other < self.set)
        self.assertRaises(TypeError, lambda: self.other <= self.set)
        self.assertRaises(TypeError, lambda: self.other > self.set)
        self.assertRaises(TypeError, lambda: self.other >= self.set)

    def test_update_operator(self):
        try:
            self.set |= self.other
        except TypeError:
            pass
        else:
            self.fail("expected TypeError")

    def test_update(self):
        if self.otherIsIterable:
            self.set.update(self.other)
        else:
            self.assertRaises(TypeError, self.set.update, self.other)

    def test_union(self):
        self.assertRaises(TypeError, lambda: self.set | self.other)
        self.assertRaises(TypeError, lambda: self.other | self.set)
        if self.otherIsIterable:
            self.set.union(self.other)
        else:
            self.assertRaises(TypeError, self.set.union, self.other)

    def test_intersection_update_operator(self):
        try:
            self.set &= self.other
        except TypeError:
            pass
        else:
            self.fail("expected TypeError")

    def test_intersection_update(self):
        if self.otherIsIterable:
            self.set.intersection_update(self.other)
        else:
            self.assertRaises(TypeError,
                              self.set.intersection_update,
                              self.other)

    def test_intersection(self):
        self.assertRaises(TypeError, lambda: self.set & self.other)
        self.assertRaises(TypeError, lambda: self.other & self.set)
        if self.otherIsIterable:
            self.set.intersection(self.other)
        else:
            self.assertRaises(TypeError, self.set.intersection, self.other)

    def test_sym_difference_update_operator(self):
        try:
            self.set ^= self.other
        except TypeError:
            pass
        else:
            self.fail("expected TypeError")

    def test_sym_difference_update(self):
        if self.otherIsIterable:
            self.set.symmetric_difference_update(self.other)
        else:
            self.assertRaises(TypeError,
                              self.set.symmetric_difference_update,
                              self.other)

    def test_sym_difference(self):
        self.assertRaises(TypeError, lambda: self.set ^ self.other)
        self.assertRaises(TypeError, lambda: self.other ^ self.set)
        if self.otherIsIterable:
            self.set.symmetric_difference(self.other)
        else:
            self.assertRaises(TypeError, self.set.symmetric_difference, self.other)

    def test_difference_update_operator(self):
        try:
            self.set -= self.other
        except TypeError:
            pass
        else:
            self.fail("expected TypeError")

    def test_difference_update(self):
        if self.otherIsIterable:
            self.set.difference_update(self.other)
        else:
            self.assertRaises(TypeError,
                              self.set.difference_update,
                              self.other)

    def test_difference(self):
        self.assertRaises(TypeError, lambda: self.set - self.other)
        self.assertRaises(TypeError, lambda: self.other - self.set)
        if self.otherIsIterable:
            self.set.difference(self.other)
        else:
            self.assertRaises(TypeError, self.set.difference, self.other)

#------------------------------------------------------------------------------

class TestOnlySetsNumeric(TestOnlySetsInBinaryOps):
    def setUp(self):
        self.set   = set((1, 2, 3))
        self.other = 19
        self.otherIsIterable = False

#------------------------------------------------------------------------------

class TestOnlySetsDict(TestOnlySetsInBinaryOps):
    def setUp(self):
        self.set   = set((1, 2, 3))
        self.other = {1:2, 3:4}
        self.otherIsIterable = True

#------------------------------------------------------------------------------

class TestOnlySetsOperator(TestOnlySetsInBinaryOps):
    def setUp(self):
        self.set   = set((1, 2, 3))
        self.other = operator.add
        self.otherIsIterable = False

#------------------------------------------------------------------------------

class TestOnlySetsTuple(TestOnlySetsInBinaryOps):
    def setUp(self):
        self.set   = set((1, 2, 3))
        self.other = (2, 4, 6)
        self.otherIsIterable = True

#------------------------------------------------------------------------------

class TestOnlySetsString(TestOnlySetsInBinaryOps):
    def setUp(self):
        self.set   = set((1, 2, 3))
        self.other = 'abc'
        self.otherIsIterable = True

#------------------------------------------------------------------------------

class TestOnlySetsGenerator(TestOnlySetsInBinaryOps):
    def setUp(self):
        def gen():
            for i in range(0, 10, 2):
                yield i
        self.set   = set((1, 2, 3))
        self.other = gen()
        self.otherIsIterable = True

#==============================================================================

class TestCopying(unittest.TestCase):

    def test_copy(self):
        dup = self.set.copy()
        dup_list = sorted(dup, key=repr)
        set_list = sorted(self.set, key=repr)
        self.assertEqual(len(dup_list), len(set_list))
        for i in range(len(dup_list)):
            self.assertTrue(dup_list[i] is set_list[i])

    def test_deep_copy(self):
        dup = copy.deepcopy(self.set)
        ##print type(dup), repr(dup)
        dup_list = sorted(dup, key=repr)
        set_list = sorted(self.set, key=repr)
        self.assertEqual(len(dup_list), len(set_list))
        for i in range(len(dup_list)):
            self.assertEqual(dup_list[i], set_list[i])

#------------------------------------------------------------------------------

class TestCopyingEmpty(TestCopying):
    def setUp(self):
        self.set = set()

#------------------------------------------------------------------------------

class TestCopyingSingleton(TestCopying):
    def setUp(self):
        self.set = set(["hello"])

#------------------------------------------------------------------------------

class TestCopyingTriple(TestCopying):
    def setUp(self):
        self.set = set(["zero", 0, None])

#------------------------------------------------------------------------------

class TestCopyingTuple(TestCopying):
    def setUp(self):
        self.set = set([(1, 2)])

#------------------------------------------------------------------------------

class TestCopyingNested(TestCopying):
    def setUp(self):
        self.set = set([((1, 2), (3, 4))])

#==============================================================================

class TestIdentities(unittest.TestCase):
    def setUp(self):
        self.a = set('abracadabra')
        self.b = set('alacazam')

    def test_binopsVsSubsets(self):
        a, b = self.a, self.b
        self.assertTrue(a - b < a)
        self.assertTrue(b - a < b)
        self.assertTrue(a & b < a)
        self.assertTrue(a & b < b)
        self.assertTrue(a | b > a)
        self.assertTrue(a | b > b)
        self.assertTrue(a ^ b < a | b)

    def test_commutativity(self):
        a, b = self.a, self.b
        self.assertEqual(a&b, b&a)
        self.assertEqual(a|b, b|a)
        self.assertEqual(a^b, b^a)
        if a != b:
            self.assertNotEqual(a-b, b-a)

    def test_summations(self):
        # check that sums of parts equal the whole
        a, b = self.a, self.b
        self.assertEqual((a-b)|(a&b)|(b-a), a|b)
        self.assertEqual((a&b)|(a^b), a|b)
        self.assertEqual(a|(b-a), a|b)
        self.assertEqual((a-b)|b, a|b)
        self.assertEqual((a-b)|(a&b), a)
        self.assertEqual((b-a)|(a&b), b)
        self.assertEqual((a-b)|(b-a), a^b)

    def test_exclusion(self):
        # check that inverse operations show non-overlap
        a, b, zero = self.a, self.b, set()
        self.assertEqual((a-b)&b, zero)
        self.assertEqual((b-a)&a, zero)
        self.assertEqual((a&b)&(a^b), zero)

# Tests derived from test_itertools.py =======================================

def R(seqn):
    'Regular generator'
    for i in seqn:
        yield i

class G:
    'Sequence using __getitem__'
    def __init__(self, seqn):
        self.seqn = seqn
    def __getitem__(self, i):
        return self.seqn[i]

class I:
    'Sequence using iterator protocol'
    def __init__(self, seqn):
        self.seqn = seqn
        self.i = 0
    def __iter__(self):
        return self
    def __next__(self):
        if self.i >= len(self.seqn): raise StopIteration
        v = self.seqn[self.i]
        self.i += 1
        return v

class Ig:
    'Sequence using iterator protocol defined with a generator'
    def __init__(self, seqn):
        self.seqn = seqn
        self.i = 0
    def __iter__(self):
        for val in self.seqn:
            yield val

class X:
    'Missing __getitem__ and __iter__'
    def __init__(self, seqn):
        self.seqn = seqn
        self.i = 0
    def __next__(self):
        if self.i >= len(self.seqn): raise StopIteration
        v = self.seqn[self.i]
        self.i += 1
        return v

class N:
    'Iterator missing __next__()'
    def __init__(self, seqn):
        self.seqn = seqn
        self.i = 0
    def __iter__(self):
        return self

class E:
    'Test propagation of exceptions'
    def __init__(self, seqn):
        self.seqn = seqn
        self.i = 0
    def __iter__(self):
        return self
    def __next__(self):
        3 // 0

class S:
    'Test immediate stop'
    def __init__(self, seqn):
        pass
    def __iter__(self):
        return self
    def __next__(self):
        raise StopIteration

from itertools import chain
def L(seqn):
    'Test multiple tiers of iterators'
    return chain(map(lambda x:x, R(Ig(G(seqn)))))

class TestVariousIteratorArgs(unittest.TestCase):

    def test_constructor(self):
        for cons in (set, frozenset):
            for s in ("123", "", range(1000), ('do', 1.2), range(2000,2200,5)):
                for g in (G, I, Ig, S, L, R):
                    self.assertEqual(sorted(cons(g(s)), key=repr), sorted(g(s), key=repr))
                self.assertRaises(TypeError, cons , X(s))
                self.assertRaises(TypeError, cons , N(s))
                self.assertRaises(ZeroDivisionError, cons , E(s))

    def test_inline_methods(self):
        s = set('november')
        for data in ("123", "", range(1000), ('do', 1.2), range(2000,2200,5), 'december'):
            for meth in (s.union, s.intersection, s.difference, s.symmetric_difference, s.isdisjoint):
                for g in (G, I, Ig, L, R):
                    expected = meth(data)
                    actual = meth(G(data))
                    if isinstance(expected, bool):
                        self.assertEqual(actual, expected)
                    else:
                        self.assertEqual(sorted(actual, key=repr), sorted(expected, key=repr))
                self.assertRaises(TypeError, meth, X(s))
                self.assertRaises(TypeError, meth, N(s))
                self.assertRaises(ZeroDivisionError, meth, E(s))

    def test_inplace_methods(self):
        for data in ("123", "", range(1000), ('do', 1.2), range(2000,2200,5), 'december'):
            for methname in ('update', 'intersection_update',
                             'difference_update', 'symmetric_difference_update'):
                for g in (G, I, Ig, S, L, R):
                    s = set('january')
                    t = s.copy()
                    getattr(s, methname)(list(g(data)))
                    getattr(t, methname)(g(data))
                    self.assertEqual(sorted(s, key=repr), sorted(t, key=repr))

                self.assertRaises(TypeError, getattr(set('january'), methname), X(data))
                self.assertRaises(TypeError, getattr(set('january'), methname), N(data))
                self.assertRaises(ZeroDivisionError, getattr(set('january'), methname), E(data))

be_bad = set2 = dict2 = Undefined(Any)

class bad_eq:
    def __eq__(self, other):
        if be_bad:
            set2.clear()
            raise ZeroDivisionError
        return self is other
    def __hash__(self):
        return 0

class bad_dict_clear:
    def __eq__(self, other):
        if be_bad:
            dict2.clear()
        return self is other
    def __hash__(self):
        return 0

class TestWeirdBugs(unittest.TestCase):
    def test_8420_set_merge(self):
        # This used to segfault
        global be_bad, set2, dict2
        be_bad = False
        set1 = {bad_eq()}
        set2 = {bad_eq() for i in range(75)}
        be_bad = True
        self.assertRaises(ZeroDivisionError, set1.update, set2)

        be_bad = False
        set1 = {bad_dict_clear()}
        dict2 = {bad_dict_clear(): None}
        be_bad = True
        set1.symmetric_difference_update(dict2)

# Application tests (based on David Eppstein's graph recipes ====================================

def powerset(U):
    """Generates all subsets of a set or sequence U."""
    U = iter(U)
    try:
        x = frozenset([next(U)])
        for S in powerset(U):
            yield S
            yield S | x
    except StopIteration:
        yield frozenset()

def cube(n):
    """Graph of n-dimensional hypercube."""
    singletons = [frozenset([x]) for x in range(n)]
    return dict([(x, frozenset([x^s for s in singletons]))
                 for x in powerset(range(n))])

def linegraph(G):
    """Graph, the vertices of which are edges of G,
    with two vertices being adjacent iff the corresponding
    edges share a vertex."""
    L = {}
    for x in G:
        for y in G[x]:
            nx = [frozenset([x,z]) for z in G[x] if z != y]
            ny = [frozenset([y,z]) for z in G[y] if z != x]
            L[frozenset([x,y])] = frozenset(nx+ny)
    return L

def faces(G):
    'Return a set of faces in G.  Where a face is a set of vertices on that face'
    # currently limited to triangles,squares, and pentagons
    f = set()
    for v1, edges in G.items():
        for v2 in edges:
            for v3 in G[v2]:
                if v1 == v3:
                    continue
                if v1 in G[v3]:
                    f.add(frozenset([v1, v2, v3]))
                else:
                    for v4 in G[v3]:
                        if v4 == v2:
                            continue
                        if v1 in G[v4]:
                            f.add(frozenset([v1, v2, v3, v4]))
                        else:
                            for v5 in G[v4]:
                                if v5 == v3 or v5 == v2:
                                    continue
                                if v1 in G[v5]:
                                    f.add(frozenset([v1, v2, v3, v4, v5]))
    return f


class TestGraphs(unittest.TestCase):

    def test_cube(self):

        g = cube(3)                             # vert --> {v1, v2, v3}
        vertices1 = set(g)
        self.assertEqual(len(vertices1), 8)     # eight vertices
        for edge in g.values():
            self.assertEqual(len(edge), 3)      # each vertex connects to three edges
        vertices2 = set()
        for edges in g.values():
            for v in edges:
                vertices2.add(v)
        self.assertEqual(vertices1, vertices2)  # edge vertices in original set

        cubefaces = faces(g)
        self.assertEqual(len(cubefaces), 6)     # six faces
        for face in cubefaces:
            self.assertEqual(len(face), 4)      # each face is a square

    def test_cuboctahedron(self):

        # http://en.wikipedia.org/wiki/Cuboctahedron
        # 8 triangular faces and 6 square faces
        # 12 indentical vertices each connecting a triangle and square

        g = cube(3)
        cuboctahedron = linegraph(g)            # V( --> {V1, V2, V3, V4}
        self.assertEqual(len(cuboctahedron), 12)# twelve vertices

        vertices = set(cuboctahedron)
        for edges in cuboctahedron.values():
            self.assertEqual(len(edges), 4)     # each vertex connects to four other vertices
        othervertices = set(edge for edges in cuboctahedron.values() for edge in edges)
        self.assertEqual(vertices, othervertices)   # edge vertices in original set

        cubofaces = faces(cuboctahedron)
        facesizes = collections.defaultdict(int)
        for face in cubofaces:
            facesizes[len(face)] += 1
        self.assertEqual(facesizes[3], 8)       # eight triangular faces
        self.assertEqual(facesizes[4], 6)       # six square faces

        for vertex in cuboctahedron:
            edge = vertex                       # Cuboctahedron vertices are edges in Cube
            self.assertEqual(len(edge), 2)      # Two cube vertices define an edge
            for cubevert in edge:
                self.assertIn(cubevert, g)


#==============================================================================

def test_main(verbose=None):
    test_classes = (
        TestSet,
        TestSetSubclass,
        TestSetSubclassWithKeywordArgs,
        TestFrozenSet,
        TestFrozenSetSubclass,
        TestSetOfSets,
        TestExceptionPropagation,
        TestBasicOpsEmpty,
        TestBasicOpsSingleton,
        TestBasicOpsTuple,
        TestBasicOpsTriple,
        TestBasicOpsString,
        TestBasicOpsBytes,
        TestBasicOpsMixedStringBytes,
        TestBinaryOps,
        TestUpdateOps,
        TestMutate,
        TestSubsetEqualEmpty,
        TestSubsetEqualNonEmpty,
        TestSubsetEmptyNonEmpty,
        TestSubsetPartial,
        TestSubsetNonOverlap,
        TestOnlySetsNumeric,
        TestOnlySetsDict,
        TestOnlySetsOperator,
        TestOnlySetsTuple,
        TestOnlySetsString,
        TestOnlySetsGenerator,
        TestCopyingEmpty,
        TestCopyingSingleton,
        TestCopyingTriple,
        TestCopyingTuple,
        TestCopyingNested,
        TestIdentities,
        TestVariousIteratorArgs,
        TestGraphs,
        TestWeirdBugs,
        )

    support.run_unittest(*test_classes)

    # verify reference counting
    if verbose and hasattr(sys, "gettotalrefcount"):
        import gc
        counts = [None] * 5
        for i in range(len(counts)):
            support.run_unittest(*test_classes)
            gc.collect()
            counts[i] = sys.gettotalrefcount()
        print(counts)

if __name__ == "__main__":
    test_main(verbose=True)

########NEW FILE########
__FILENAME__ = test_shutil
# Copyright (C) 2003 Python Software Foundation

import unittest
import shutil
import tempfile
import sys
import stat
import os
import os.path
import functools
from test import support
from test.support import TESTFN
from os.path import splitdrive
from distutils.spawn import find_executable, spawn
from shutil import (_make_tarball, _make_zipfile, make_archive,
                    register_archive_format, unregister_archive_format,
                    get_archive_formats, Error, unpack_archive,
                    register_unpack_format, RegistryError,
                    unregister_unpack_format, get_unpack_formats)
import tarfile
import warnings

from test import support
from test.support import check_warnings, captured_stdout

from typing import (
    Any, Function, Tuple, List, Sequence, BinaryIO, overload, Traceback, IO,
    ducktype
)

import bz2
BZ2_SUPPORTED = True

TESTFN2 = TESTFN + "2"

import grp
import pwd
UID_GID_SUPPORT = True

import zlib

import zipfile
ZIP_SUPPORT = True

def _fake_rename(*args: Any, **kwargs: Any) -> None:
    # Pretend the destination path is on a different filesystem.
    raise OSError()

def mock_rename(func: Any) -> Any:
    @functools.wraps(func)
    def wrap(*args: Any, **kwargs: Any) -> Any:
        try:
            builtin_rename = shutil.rename
            shutil.rename = Any(_fake_rename)
            return func(*args, **kwargs)
        finally:
            shutil.rename = builtin_rename
    return wrap

class TestShutil(unittest.TestCase):

    def setUp(self) -> None:
        super().setUp()
        self.tempdirs = List[str]()

    def tearDown(self) -> None:
        super().tearDown()
        while self.tempdirs:
            d = self.tempdirs.pop()
            shutil.rmtree(d, os.name in ('nt', 'cygwin'))

    @overload
    def write_file(self, path: str, content: str = 'xxx') -> None:
        """Writes a file in the given path.


        path can be a string or a sequence.
        """
        f = open(path, 'w')
        try:
            f.write(content)
        finally:
            f.close()

    @overload
    def write_file(self, path: Sequence[str], content: str = 'xxx') -> None:
        # JLe: work around mypy issue #238
        self.write_file(os.path.join(*list(path)), content)

    def mkdtemp(self) -> str:
        """Create a temporary directory that will be cleaned up.

        Returns the path of the directory.
        """
        d = tempfile.mkdtemp()
        self.tempdirs.append(d)
        return d

    def test_rmtree_errors(self) -> None:
        # filename is guaranteed not to exist
        filename = tempfile.mktemp()
        self.assertRaises(OSError, shutil.rmtree, filename)

    # See bug #1071513 for why we don't run this on cygwin
    # and bug #1076467 for why we don't run this as root.
    if (hasattr(os, 'chmod') and sys.platform[:6] != 'cygwin'
        and not (hasattr(os, 'geteuid') and os.geteuid() == 0)):
        def test_on_error(self) -> None:
            self.errorState = 0
            os.mkdir(TESTFN)
            self.childpath = os.path.join(TESTFN, 'a')
            f = open(self.childpath, 'w')
            f.close()
            old_dir_mode = os.stat(TESTFN).st_mode
            old_child_mode = os.stat(self.childpath).st_mode
            # Make unwritable.
            os.chmod(self.childpath, stat.S_IREAD)
            os.chmod(TESTFN, stat.S_IREAD)

            shutil.rmtree(TESTFN, onerror=self.check_args_to_onerror)
            # Test whether onerror has actually been called.
            self.assertEqual(self.errorState, 2,
                             "Expected call to onerror function did not happen.")

            # Make writable again.
            os.chmod(TESTFN, old_dir_mode)
            os.chmod(self.childpath, old_child_mode)

            # Clean up.
            shutil.rmtree(TESTFN)

    def check_args_to_onerror(self, func: Function[[str], Any], arg: str,
                              exc: Tuple[type, BaseException,
                                         Traceback]) -> None:
        # test_rmtree_errors deliberately runs rmtree
        # on a directory that is chmod 400, which will fail.
        # This function is run when shutil.rmtree fails.
        # 99.9% of the time it initially fails to remove
        # a file in the directory, so the first time through
        # func is os.remove.
        # However, some Linux machines running ZFS on
        # FUSE experienced a failure earlier in the process
        # at os.listdir.  The first failure may legally
        # be either.
        if self.errorState == 0:
            if func is os.remove:
                self.assertEqual(arg, self.childpath)
            else:
                self.assertIs(func, os.listdir,
                              "func must be either os.remove or os.listdir")
                self.assertEqual(arg, TESTFN)
            self.assertTrue(issubclass(exc[0], OSError))
            self.errorState = 1
        else:
            self.assertEqual(func, os.rmdir)
            self.assertEqual(arg, TESTFN)
            self.assertTrue(issubclass(exc[0], OSError))
            self.errorState = 2

    def test_rmtree_dont_delete_file(self) -> None:
        # When called on a file instead of a directory, don't delete it.
        handle, path = tempfile.mkstemp()
        os.fdopen(handle).close()
        self.assertRaises(OSError, shutil.rmtree, path)
        os.remove(path)

    def _write_data(self, path: str, data: str) -> None:
        f = open(path, "w")
        f.write(data)
        f.close()

    def test_copytree_simple(self) -> None:

        def read_data(path: str) -> str:
            f = open(path)
            data = f.read()
            f.close()
            return data

        src_dir = tempfile.mkdtemp()
        dst_dir = os.path.join(tempfile.mkdtemp(), 'destination')
        self._write_data(os.path.join(src_dir, 'test.txt'), '123')
        os.mkdir(os.path.join(src_dir, 'test_dir'))
        self._write_data(os.path.join(src_dir, 'test_dir', 'test.txt'), '456')

        try:
            shutil.copytree(src_dir, dst_dir)
            self.assertTrue(os.path.isfile(os.path.join(dst_dir, 'test.txt')))
            self.assertTrue(os.path.isdir(os.path.join(dst_dir, 'test_dir')))
            self.assertTrue(os.path.isfile(os.path.join(dst_dir, 'test_dir',
                                                        'test.txt')))
            actual = read_data(os.path.join(dst_dir, 'test.txt'))
            self.assertEqual(actual, '123')
            actual = read_data(os.path.join(dst_dir, 'test_dir', 'test.txt'))
            self.assertEqual(actual, '456')
        finally:
            for path in (
                    os.path.join(src_dir, 'test.txt'),
                    os.path.join(dst_dir, 'test.txt'),
                    os.path.join(src_dir, 'test_dir', 'test.txt'),
                    os.path.join(dst_dir, 'test_dir', 'test.txt'),
                ):
                if os.path.exists(path):
                    os.remove(path)
            for path in (src_dir,
                    os.path.dirname(dst_dir)
                ):
                if os.path.exists(path):
                    shutil.rmtree(path)

    def test_copytree_with_exclude(self) -> None:

        def read_data(path: str) -> str:
            f = open(path)
            data = f.read()
            f.close()
            return data

        # creating data
        join = os.path.join
        exists = os.path.exists
        src_dir = tempfile.mkdtemp()
        try:
            dst_dir = join(tempfile.mkdtemp(), 'destination')
            self._write_data(join(src_dir, 'test.txt'), '123')
            self._write_data(join(src_dir, 'test.tmp'), '123')
            os.mkdir(join(src_dir, 'test_dir'))
            self._write_data(join(src_dir, 'test_dir', 'test.txt'), '456')
            os.mkdir(join(src_dir, 'test_dir2'))
            self._write_data(join(src_dir, 'test_dir2', 'test.txt'), '456')
            os.mkdir(join(src_dir, 'test_dir2', 'subdir'))
            os.mkdir(join(src_dir, 'test_dir2', 'subdir2'))
            self._write_data(join(src_dir, 'test_dir2', 'subdir', 'test.txt'),
                             '456')
            self._write_data(join(src_dir, 'test_dir2', 'subdir2', 'test.py'),
                             '456')


            # testing glob-like patterns
            try:
                patterns = shutil.ignore_patterns('*.tmp', 'test_dir2')
                shutil.copytree(src_dir, dst_dir, ignore=patterns)
                # checking the result: some elements should not be copied
                self.assertTrue(exists(join(dst_dir, 'test.txt')))
                self.assertTrue(not exists(join(dst_dir, 'test.tmp')))
                self.assertTrue(not exists(join(dst_dir, 'test_dir2')))
            finally:
                if os.path.exists(dst_dir):
                    shutil.rmtree(dst_dir)
            try:
                patterns = shutil.ignore_patterns('*.tmp', 'subdir*')
                shutil.copytree(src_dir, dst_dir, ignore=patterns)
                # checking the result: some elements should not be copied
                self.assertTrue(not exists(join(dst_dir, 'test.tmp')))
                self.assertTrue(not exists(join(dst_dir, 'test_dir2', 'subdir2')))
                self.assertTrue(not exists(join(dst_dir, 'test_dir2', 'subdir')))
            finally:
                if os.path.exists(dst_dir):
                    shutil.rmtree(dst_dir)

            # testing callable-style
            try:
                def _filter(src: str, names: Sequence[str]) -> List[str]:
                    res = List[str]()
                    for name in names:
                        path = os.path.join(src, name)

                        if (os.path.isdir(path) and
                            path.split()[-1] == 'subdir'):
                            res.append(name)
                        elif os.path.splitext(path)[-1] in ('.py'):
                            res.append(name)
                    return res

                shutil.copytree(src_dir, dst_dir, ignore=_filter)

                # checking the result: some elements should not be copied
                self.assertTrue(not exists(join(dst_dir, 'test_dir2', 'subdir2',
                                        'test.py')))
                self.assertTrue(not exists(join(dst_dir, 'test_dir2', 'subdir')))

            finally:
                if os.path.exists(dst_dir):
                    shutil.rmtree(dst_dir)
        finally:
            shutil.rmtree(src_dir)
            shutil.rmtree(os.path.dirname(dst_dir))

    @unittest.skipUnless(hasattr(os, 'link'), 'requires os.link')
    def test_dont_copy_file_onto_link_to_itself(self) -> None:
        # Temporarily disable test on Windows.
        if os.name == 'nt':
            return
        # bug 851123.
        os.mkdir(TESTFN)
        src = os.path.join(TESTFN, 'cheese')
        dst = os.path.join(TESTFN, 'shop')
        try:
            with open(src, 'w') as f:
                f.write('cheddar')
            os.link(src, dst)
            self.assertRaises(shutil.Error, shutil.copyfile, src, dst)
            with open(src, 'r') as f:
                self.assertEqual(f.read(), 'cheddar')
            os.remove(dst)
        finally:
            shutil.rmtree(TESTFN, ignore_errors=True)

    @support.skip_unless_symlink
    def test_dont_copy_file_onto_symlink_to_itself(self) -> None:
        # bug 851123.
        os.mkdir(TESTFN)
        src = os.path.join(TESTFN, 'cheese')
        dst = os.path.join(TESTFN, 'shop')
        try:
            with open(src, 'w') as f:
                f.write('cheddar')
            # Using `src` here would mean we end up with a symlink pointing
            # to TESTFN/TESTFN/cheese, while it should point at
            # TESTFN/cheese.
            os.symlink('cheese', dst)
            self.assertRaises(shutil.Error, shutil.copyfile, src, dst)
            with open(src, 'r') as f:
                self.assertEqual(f.read(), 'cheddar')
            os.remove(dst)
        finally:
            shutil.rmtree(TESTFN, ignore_errors=True)

    @support.skip_unless_symlink
    def test_rmtree_on_symlink(self) -> None:
        # bug 1669.
        os.mkdir(TESTFN)
        try:
            src = os.path.join(TESTFN, 'cheese')
            dst = os.path.join(TESTFN, 'shop')
            os.mkdir(src)
            os.symlink(src, dst)
            self.assertRaises(OSError, shutil.rmtree, dst)
        finally:
            shutil.rmtree(TESTFN, ignore_errors=True)

    if hasattr(os, "mkfifo"):
        # Issue #3002: copyfile and copytree block indefinitely on named pipes
        def test_copyfile_named_pipe(self) -> None:
            os.mkfifo(TESTFN)
            try:
                self.assertRaises(shutil.SpecialFileError,
                                  shutil.copyfile, TESTFN, TESTFN2)
                self.assertRaises(shutil.SpecialFileError,
                                  shutil.copyfile, __file__, TESTFN)
            finally:
                os.remove(TESTFN)

        @support.skip_unless_symlink
        def test_copytree_named_pipe(self) -> None:
            os.mkdir(TESTFN)
            try:
                subdir = os.path.join(TESTFN, "subdir")
                os.mkdir(subdir)
                pipe = os.path.join(subdir, "mypipe")
                os.mkfifo(pipe)
                try:
                    shutil.copytree(TESTFN, TESTFN2)
                except shutil.Error as e:
                    errors = e.args[0]
                    self.assertEqual(len(errors), 1)
                    src, dst, error_msg = errors[0]
                    self.assertEqual("`%s` is a named pipe" % pipe, error_msg)
                else:
                    self.fail("shutil.Error should have been raised")
            finally:
                shutil.rmtree(TESTFN, ignore_errors=True)
                shutil.rmtree(TESTFN2, ignore_errors=True)

    def test_copytree_special_func(self) -> None:

        src_dir = self.mkdtemp()
        dst_dir = os.path.join(self.mkdtemp(), 'destination')
        self._write_data(os.path.join(src_dir, 'test.txt'), '123')
        os.mkdir(os.path.join(src_dir, 'test_dir'))
        self._write_data(os.path.join(src_dir, 'test_dir', 'test.txt'), '456')

        copied = List[Tuple[str, str]]()
        def _copy(src: str, dst: str) -> None:
            copied.append((src, dst))

        shutil.copytree(src_dir, dst_dir, copy_function=_copy)
        self.assertEqual(len(copied), 2)

    @support.skip_unless_symlink
    def test_copytree_dangling_symlinks(self) -> None:

        # a dangling symlink raises an error at the end
        src_dir = self.mkdtemp()
        dst_dir = os.path.join(self.mkdtemp(), 'destination')
        os.symlink('IDONTEXIST', os.path.join(src_dir, 'test.txt'))
        os.mkdir(os.path.join(src_dir, 'test_dir'))
        self._write_data(os.path.join(src_dir, 'test_dir', 'test.txt'), '456')
        self.assertRaises(Error, shutil.copytree, src_dir, dst_dir)

        # a dangling symlink is ignored with the proper flag
        dst_dir = os.path.join(self.mkdtemp(), 'destination2')
        shutil.copytree(src_dir, dst_dir, ignore_dangling_symlinks=True)
        self.assertNotIn('test.txt', os.listdir(dst_dir))

        # a dangling symlink is copied if symlinks=True
        dst_dir = os.path.join(self.mkdtemp(), 'destination3')
        shutil.copytree(src_dir, dst_dir, symlinks=True)
        self.assertIn('test.txt', os.listdir(dst_dir))

    def _copy_file(self,
                   method: Function[[str, str], None]) -> Tuple[str, str]:
        fname = 'test.txt'
        tmpdir = self.mkdtemp()
        self.write_file([tmpdir, fname])
        file1 = os.path.join(tmpdir, fname)
        tmpdir2 = self.mkdtemp()
        method(file1, tmpdir2)
        file2 = os.path.join(tmpdir2, fname)
        return (file1, file2)

    @unittest.skipUnless(hasattr(os, 'chmod'), 'requires os.chmod')
    def test_copy(self) -> None:
        # Ensure that the copied file exists and has the same mode bits.
        file1, file2 = self._copy_file(shutil.copy)
        self.assertTrue(os.path.exists(file2))
        self.assertEqual(os.stat(file1).st_mode, os.stat(file2).st_mode)

    @unittest.skipUnless(hasattr(os, 'chmod'), 'requires os.chmod')
    @unittest.skipUnless(hasattr(os, 'utime'), 'requires os.utime')
    def test_copy2(self) -> None:
        # Ensure that the copied file exists and has the same mode and
        # modification time bits.
        file1, file2 = self._copy_file(shutil.copy2)
        self.assertTrue(os.path.exists(file2))
        file1_stat = os.stat(file1)
        file2_stat = os.stat(file2)
        self.assertEqual(file1_stat.st_mode, file2_stat.st_mode)
        for attr in 'st_atime', 'st_mtime':
            # The modification times may be truncated in the new file.
            self.assertLessEqual(getattr(file1_stat, attr),
                                 getattr(file2_stat, attr) + 1)
        if hasattr(os, 'chflags') and hasattr(file1_stat, 'st_flags'):
            self.assertEqual(getattr(file1_stat, 'st_flags'),
                             getattr(file2_stat, 'st_flags'))

    @unittest.skipUnless(zlib, "requires zlib")
    def test_make_tarball(self) -> None:
        # creating something to tar
        tmpdir = self.mkdtemp()
        self.write_file([tmpdir, 'file1'], 'xxx')
        self.write_file([tmpdir, 'file2'], 'xxx')
        os.mkdir(os.path.join(tmpdir, 'sub'))
        self.write_file([tmpdir, 'sub', 'file3'], 'xxx')

        tmpdir2 = self.mkdtemp()
        # force shutil to create the directory
        os.rmdir(tmpdir2)
        unittest.skipUnless(splitdrive(tmpdir)[0] == splitdrive(tmpdir2)[0],
                            "source and target should be on same drive")

        base_name = os.path.join(tmpdir2, 'archive')

        # working with relative paths to avoid tar warnings
        old_dir = os.getcwd()
        os.chdir(tmpdir)
        try:
            _make_tarball(splitdrive(base_name)[1], '.')
        finally:
            os.chdir(old_dir)

        # check if the compressed tarball was created
        tarball = base_name + '.tar.gz'
        self.assertTrue(os.path.exists(tarball))

        # trying an uncompressed one
        base_name = os.path.join(tmpdir2, 'archive')
        old_dir = os.getcwd()
        os.chdir(tmpdir)
        try:
            _make_tarball(splitdrive(base_name)[1], '.', compress=None)
        finally:
            os.chdir(old_dir)
        tarball = base_name + '.tar'
        self.assertTrue(os.path.exists(tarball))

    def _tarinfo(self, path: str) -> tuple:
        tar = tarfile.open(path)
        try:
            names = tar.getnames()
            names.sort()
            return tuple(names)
        finally:
            tar.close()

    def _create_files(self) -> Tuple[str, str, str]:
        # creating something to tar
        tmpdir = self.mkdtemp()
        dist = os.path.join(tmpdir, 'dist')
        os.mkdir(dist)
        self.write_file([dist, 'file1'], 'xxx')
        self.write_file([dist, 'file2'], 'xxx')
        os.mkdir(os.path.join(dist, 'sub'))
        self.write_file([dist, 'sub', 'file3'], 'xxx')
        os.mkdir(os.path.join(dist, 'sub2'))
        tmpdir2 = self.mkdtemp()
        base_name = os.path.join(tmpdir2, 'archive')
        return tmpdir, tmpdir2, base_name

    @unittest.skipUnless(zlib, "Requires zlib")
    @unittest.skipUnless(find_executable('tar') and find_executable('gzip'),
                         'Need the tar command to run')
    def test_tarfile_vs_tar(self) -> None:
        tmpdir, tmpdir2, base_name =  self._create_files()
        old_dir = os.getcwd()
        os.chdir(tmpdir)
        try:
            _make_tarball(base_name, 'dist')
        finally:
            os.chdir(old_dir)

        # check if the compressed tarball was created
        tarball = base_name + '.tar.gz'
        self.assertTrue(os.path.exists(tarball))

        # now create another tarball using `tar`
        tarball2 = os.path.join(tmpdir, 'archive2.tar.gz')
        tar_cmd = ['tar', '-cf', 'archive2.tar', 'dist']
        gzip_cmd = ['gzip', '-f9', 'archive2.tar']
        old_dir = os.getcwd()
        os.chdir(tmpdir)
        try:
            with captured_stdout() as s:
                spawn(tar_cmd)
                spawn(gzip_cmd)
        finally:
            os.chdir(old_dir)

        self.assertTrue(os.path.exists(tarball2))
        # let's compare both tarballs
        self.assertEqual(self._tarinfo(tarball), self._tarinfo(tarball2))

        # trying an uncompressed one
        base_name = os.path.join(tmpdir2, 'archive')
        old_dir = os.getcwd()
        os.chdir(tmpdir)
        try:
            _make_tarball(base_name, 'dist', compress=None)
        finally:
            os.chdir(old_dir)
        tarball = base_name + '.tar'
        self.assertTrue(os.path.exists(tarball))

        # now for a dry_run
        base_name = os.path.join(tmpdir2, 'archive')
        old_dir = os.getcwd()
        os.chdir(tmpdir)
        try:
            _make_tarball(base_name, 'dist', compress=None, dry_run=True)
        finally:
            os.chdir(old_dir)
        tarball = base_name + '.tar'
        self.assertTrue(os.path.exists(tarball))

    @unittest.skipUnless(zlib, "Requires zlib")
    @unittest.skipUnless(ZIP_SUPPORT, 'Need zip support to run')
    def test_make_zipfile(self) -> None:
        # creating something to tar
        tmpdir = self.mkdtemp()
        self.write_file([tmpdir, 'file1'], 'xxx')
        self.write_file([tmpdir, 'file2'], 'xxx')

        tmpdir2 = self.mkdtemp()
        # force shutil to create the directory
        os.rmdir(tmpdir2)
        base_name = os.path.join(tmpdir2, 'archive')
        _make_zipfile(base_name, tmpdir)

        # check if the compressed tarball was created
        tarball = base_name + '.zip'
        self.assertTrue(os.path.exists(tarball))


    def test_make_archive(self) -> None:
        tmpdir = self.mkdtemp()
        base_name = os.path.join(tmpdir, 'archive')
        self.assertRaises(ValueError, make_archive, base_name, 'xxx')

    @unittest.skipUnless(zlib, "Requires zlib")
    def test_make_archive_owner_group(self) -> None:
        # testing make_archive with owner and group, with various combinations
        # this works even if there's not gid/uid support
        if UID_GID_SUPPORT:
            group = grp.getgrgid(0).gr_name
            owner = pwd.getpwuid(0).pw_name
        else:
            group = owner = 'root'

        base_dir, root_dir, base_name =  self._create_files()
        base_name = os.path.join(self.mkdtemp() , 'archive')
        res = make_archive(base_name, 'zip', root_dir, base_dir, owner=owner,
                           group=group)
        self.assertTrue(os.path.exists(res))

        res = make_archive(base_name, 'zip', root_dir, base_dir)
        self.assertTrue(os.path.exists(res))

        res = make_archive(base_name, 'tar', root_dir, base_dir,
                           owner=owner, group=group)
        self.assertTrue(os.path.exists(res))

        res = make_archive(base_name, 'tar', root_dir, base_dir,
                           owner='kjhkjhkjg', group='oihohoh')
        self.assertTrue(os.path.exists(res))


    @unittest.skipUnless(zlib, "Requires zlib")
    @unittest.skipUnless(UID_GID_SUPPORT, "Requires grp and pwd support")
    def test_tarfile_root_owner(self) -> None:
        tmpdir, tmpdir2, base_name =  self._create_files()
        old_dir = os.getcwd()
        os.chdir(tmpdir)
        group = grp.getgrgid(0).gr_name
        owner = pwd.getpwuid(0).pw_name
        try:
            archive_name = _make_tarball(base_name, 'dist', compress=None,
                                         owner=owner, group=group)
        finally:
            os.chdir(old_dir)

        # check if the compressed tarball was created
        self.assertTrue(os.path.exists(archive_name))

        # now checks the rights
        archive = tarfile.open(archive_name)
        try:
            for member in archive.getmembers():
                self.assertEqual(member.uid, 0)
                self.assertEqual(member.gid, 0)
        finally:
            archive.close()

    def test_make_archive_cwd(self) -> None:
        current_dir = os.getcwd()
        def _breaks(*args: Any, **kw: Any) -> None:
            raise RuntimeError()

        register_archive_format('xxx', _breaks, [], 'xxx file')
        try:
            try:
                make_archive('xxx', 'xxx', root_dir=self.mkdtemp())
            except Exception:
                pass
            self.assertEqual(os.getcwd(), current_dir)
        finally:
            unregister_archive_format('xxx')

    def test_register_archive_format(self) -> None:

        self.assertRaises(TypeError, register_archive_format, 'xxx', 1)
        self.assertRaises(TypeError, register_archive_format, 'xxx',
                          lambda: 1/0,
                          1)
        self.assertRaises(TypeError, register_archive_format, 'xxx',
                          lambda: 1/0,
                          [(1, 2), (1, 2, 3)])

        register_archive_format('xxx', lambda: 1/0, [('x', 2)], 'xxx file')
        formats = [name for name, params in get_archive_formats()]
        self.assertIn('xxx', formats)

        unregister_archive_format('xxx')
        formats = [name for name, params in get_archive_formats()]
        self.assertNotIn('xxx', formats)

    def _compare_dirs(self, dir1: str, dir2: str) -> List[str]:
        # check that dir1 and dir2 are equivalent,
        # return the diff
        diff = List[str]()
        for root, dirs, files in os.walk(dir1):
            for file_ in files:
                path = os.path.join(root, file_)
                target_path = os.path.join(dir2, os.path.split(path)[-1])
                if not os.path.exists(target_path):
                    diff.append(file_)
        return diff

    @unittest.skipUnless(zlib, "Requires zlib")
    def test_unpack_archive(self) -> None:
        formats = ['tar', 'gztar', 'zip']
        if BZ2_SUPPORTED:
            formats.append('bztar')

        for format in formats:
            tmpdir = self.mkdtemp()
            base_dir, root_dir, base_name =  self._create_files()
            tmpdir2 = self.mkdtemp()
            filename = make_archive(base_name, format, root_dir, base_dir)

            # let's try to unpack it now
            unpack_archive(filename, tmpdir2)
            diff = self._compare_dirs(tmpdir, tmpdir2)
            self.assertEqual(diff, [])

            # and again, this time with the format specified
            tmpdir3 = self.mkdtemp()
            unpack_archive(filename, tmpdir3, format=format)
            diff = self._compare_dirs(tmpdir, tmpdir3)
            self.assertEqual(diff, [])
        self.assertRaises(shutil.ReadError, unpack_archive, TESTFN)
        self.assertRaises(ValueError, unpack_archive, TESTFN, format='xxx')

    def test_unpack_registery(self) -> None:

        formats = get_unpack_formats()

        def _boo(filename: str, extract_dir: str, extra: int) -> None:
            self.assertEqual(extra, 1)
            self.assertEqual(filename, 'stuff.boo')
            self.assertEqual(extract_dir, 'xx')

        register_unpack_format('Boo', ['.boo', '.b2'], _boo, [('extra', 1)])
        unpack_archive('stuff.boo', 'xx')

        # trying to register a .boo unpacker again
        self.assertRaises(RegistryError, register_unpack_format, 'Boo2',
                          ['.boo'], _boo)

        # should work now
        unregister_unpack_format('Boo')
        register_unpack_format('Boo2', ['.boo'], _boo)
        self.assertIn(('Boo2', ['.boo'], ''), get_unpack_formats())
        self.assertNotIn(('Boo', ['.boo'], ''), get_unpack_formats())

        # let's leave a clean state
        unregister_unpack_format('Boo2')
        self.assertEqual(get_unpack_formats(), formats)


class TestMove(unittest.TestCase):

    def setUp(self) -> None:
        filename = "foo"
        self.src_dir = tempfile.mkdtemp()
        self.dst_dir = tempfile.mkdtemp()
        self.src_file = os.path.join(self.src_dir, filename)
        self.dst_file = os.path.join(self.dst_dir, filename)
        with open(self.src_file, "wb") as f:
            f.write(b"spam")

    def tearDown(self) -> None:
        for d in (self.src_dir, self.dst_dir):
            try:
                if d:
                    shutil.rmtree(d)
            except:
                pass

    def _check_move_file(self, src: str, dst: str, real_dst: str) -> None:
        with open(src, "rb") as f:
            contents = f.read()
        shutil.move(src, dst)
        with open(real_dst, "rb") as f:
            self.assertEqual(contents, f.read())
        self.assertFalse(os.path.exists(src))

    def _check_move_dir(self, src: str, dst: str, real_dst: str) -> None:
        contents = sorted(os.listdir(src))
        shutil.move(src, dst)
        self.assertEqual(contents, sorted(os.listdir(real_dst)))
        self.assertFalse(os.path.exists(src))

    def test_move_file(self) -> None:
        # Move a file to another location on the same filesystem.
        self._check_move_file(self.src_file, self.dst_file, self.dst_file)

    def test_move_file_to_dir(self) -> None:
        # Move a file inside an existing dir on the same filesystem.
        self._check_move_file(self.src_file, self.dst_dir, self.dst_file)

    @mock_rename
    def test_move_file_other_fs(self) -> None:
        # Move a file to an existing dir on another filesystem.
        self.test_move_file()

    @mock_rename
    def test_move_file_to_dir_other_fs(self) -> None:
        # Move a file to another location on another filesystem.
        self.test_move_file_to_dir()

    def test_move_dir(self) -> None:
        # Move a dir to another location on the same filesystem.
        dst_dir = tempfile.mktemp()
        try:
            self._check_move_dir(self.src_dir, dst_dir, dst_dir)
        finally:
            try:
                shutil.rmtree(dst_dir)
            except:
                pass

    @mock_rename
    def test_move_dir_other_fs(self) -> None:
        # Move a dir to another location on another filesystem.
        self.test_move_dir()

    def test_move_dir_to_dir(self) -> None:
        # Move a dir inside an existing dir on the same filesystem.
        self._check_move_dir(self.src_dir, self.dst_dir,
            os.path.join(self.dst_dir, os.path.basename(self.src_dir)))

    @mock_rename
    def test_move_dir_to_dir_other_fs(self) -> None:
        # Move a dir inside an existing dir on another filesystem.
        self.test_move_dir_to_dir()

    def test_existing_file_inside_dest_dir(self) -> None:
        # A file with the same name inside the destination dir already exists.
        with open(self.dst_file, "wb"):
            pass
        self.assertRaises(shutil.Error, shutil.move, self.src_file, self.dst_dir)

    def test_dont_move_dir_in_itself(self) -> None:
        # Moving a dir inside itself raises an Error.
        dst = os.path.join(self.src_dir, "bar")
        self.assertRaises(shutil.Error, shutil.move, self.src_dir, dst)

    def test_destinsrc_false_negative(self) -> None:
        os.mkdir(TESTFN)
        try:
            for src, dst in [('srcdir', 'srcdir/dest')]:
                src = os.path.join(TESTFN, src)
                dst = os.path.join(TESTFN, dst)
                self.assertTrue(shutil._destinsrc(src, dst),
                             msg='_destinsrc() wrongly concluded that '
                             'dst (%s) is not in src (%s)' % (dst, src))
        finally:
            shutil.rmtree(TESTFN, ignore_errors=True)

    def test_destinsrc_false_positive(self) -> None:
        os.mkdir(TESTFN)
        try:
            for src, dst in [('srcdir', 'src/dest'), ('srcdir', 'srcdir.new')]:
                src = os.path.join(TESTFN, src)
                dst = os.path.join(TESTFN, dst)
                self.assertFalse(shutil._destinsrc(src, dst),
                            msg='_destinsrc() wrongly concluded that '
                            'dst (%s) is in src (%s)' % (dst, src))
        finally:
            shutil.rmtree(TESTFN, ignore_errors=True)


class TestCopyFile(unittest.TestCase):

    _delete = False

    @ducktype(IO[str])
    class Faux(object):
        _entered = False
        _exited_with = None # type: tuple
        _raised = False
        def __init__(self, raise_in_exit: bool = False,
                     suppress_at_exit: bool = True) -> None:
            self._raise_in_exit = raise_in_exit
            self._suppress_at_exit = suppress_at_exit
        def read(self, *args: Any) -> str:
            return ''
        def __enter__(self) -> None:
            self._entered = True
        def __exit__(self, exc_type: type, exc_val: BaseException,
                     exc_tb: Traceback) -> bool:
            self._exited_with = exc_type, exc_val, exc_tb
            if self._raise_in_exit:
                self._raised = True
                raise IOError("Cannot close")
            return self._suppress_at_exit

    def tearDown(self) -> None:
        shutil.open = open

    def _set_shutil_open(self, func: Any) -> None:
        shutil.open = func
        self._delete = True

    def test_w_source_open_fails(self) -> None:
        def _open(filename: str, mode: str= 'r') -> BinaryIO:
            if filename == 'srcfile':
                raise IOError('Cannot open "srcfile"')
            assert 0  # shouldn't reach here.

        self._set_shutil_open(_open)

        self.assertRaises(IOError, shutil.copyfile, 'srcfile', 'destfile')

    def test_w_dest_open_fails(self) -> None:

        srcfile = TestCopyFile.Faux()

        def _open(filename: str, mode: str = 'r') -> TestCopyFile.Faux:
            if filename == 'srcfile':
                return srcfile
            if filename == 'destfile':
                raise IOError('Cannot open "destfile"')
            assert 0  # shouldn't reach here.

        self._set_shutil_open(_open)

        shutil.copyfile('srcfile', 'destfile')
        self.assertTrue(srcfile._entered)
        self.assertTrue(srcfile._exited_with[0] is IOError)
        self.assertEqual(srcfile._exited_with[1].args,
                         ('Cannot open "destfile"',))

    def test_w_dest_close_fails(self) -> None:

        srcfile = TestCopyFile.Faux()
        destfile = TestCopyFile.Faux(True)

        def _open(filename: str, mode: str = 'r') -> TestCopyFile.Faux:
            if filename == 'srcfile':
                return srcfile
            if filename == 'destfile':
                return destfile
            assert 0  # shouldn't reach here.

        self._set_shutil_open(_open)

        shutil.copyfile('srcfile', 'destfile')
        self.assertTrue(srcfile._entered)
        self.assertTrue(destfile._entered)
        self.assertTrue(destfile._raised)
        self.assertTrue(srcfile._exited_with[0] is IOError)
        self.assertEqual(srcfile._exited_with[1].args,
                         ('Cannot close',))

    def test_w_source_close_fails(self) -> None:

        srcfile = TestCopyFile.Faux(True)
        destfile = TestCopyFile.Faux()

        def _open(filename: str, mode: str= 'r') -> TestCopyFile.Faux:
            if filename == 'srcfile':
                return srcfile
            if filename == 'destfile':
                return destfile
            assert 0  # shouldn't reach here.

        self._set_shutil_open(_open)

        self.assertRaises(IOError,
                          shutil.copyfile, 'srcfile', 'destfile')
        self.assertTrue(srcfile._entered)
        self.assertTrue(destfile._entered)
        self.assertFalse(destfile._raised)
        self.assertTrue(srcfile._exited_with[0] is None)
        self.assertTrue(srcfile._raised)

    def test_move_dir_caseinsensitive(self) -> None:
        # Renames a folder to the same name
        # but a different case.

        self.src_dir = tempfile.mkdtemp()
        dst_dir = os.path.join(
                os.path.dirname(self.src_dir),
                os.path.basename(self.src_dir).upper())
        self.assertNotEqual(self.src_dir, dst_dir)

        try:
            shutil.move(self.src_dir, dst_dir)
            self.assertTrue(os.path.isdir(dst_dir))
        finally:
            if os.path.exists(dst_dir):
                os.rmdir(dst_dir)



def test_main() -> None:
    support.run_unittest(TestShutil, TestMove, TestCopyFile)

if __name__ == '__main__':
    test_main()

########NEW FILE########
__FILENAME__ = test_subprocess
import unittest
from test import support
import subprocess
import sys
import signal
import io
import os
import errno
import tempfile
import time
import re
import sysconfig
import warnings
import select
import shutil
import gc

import resource

from typing import Any, Dict, Function, Iterable, List, Set, Tuple

mswindows = (sys.platform == "win32")

#
# Depends on the following external programs: Python
#

if mswindows:
    SETBINARY = ('import msvcrt; msvcrt.setmode(sys.stdout.fileno(), '
                                                'os.O_BINARY);')
else:
    SETBINARY = ''


try:
    mkstemp = tempfile.mkstemp
except AttributeError:
    # tempfile.mkstemp is not available
    def _mkstemp() -> Tuple[int, str]:
        """Replacement for mkstemp, calling mktemp."""
        fname = tempfile.mktemp()
        return os.open(fname, os.O_RDWR|os.O_CREAT), fname
    mkstemp = Any(_mkstemp)


class BaseTestCase(unittest.TestCase):
    def setUp(self) -> None:
        # Try to minimize the number of children we have so this test
        # doesn't crash on some buildbots (Alphas in particular).
        support.reap_children()

    def tearDown(self) -> None:
        for inst in subprocess._active:
            inst.wait()
        subprocess._cleanup()
        self.assertFalse(subprocess._active, "subprocess._active not empty")

    def assertStderrEqual(self, stderr: bytes, expected: bytes,
                          msg: object = None) -> None:
        # In a debug build, stuff like "[6580 refs]" is printed to stderr at
        # shutdown time.  That frustrates tests trying to check stderr produced
        # from a spawned Python process.
        actual = support.strip_python_stderr(stderr)
        self.assertEqual(actual, expected, msg)


class ProcessTestCase(BaseTestCase):

    def test_call_seq(self) -> None:
        # call() function with sequence argument
        rc = subprocess.call([sys.executable, "-c",
                              "import sys; sys.exit(47)"])
        self.assertEqual(rc, 47)

    def test_check_call_zero(self) -> None:
        # check_call() function with zero return code
        rc = subprocess.check_call([sys.executable, "-c",
                                    "import sys; sys.exit(0)"])
        self.assertEqual(rc, 0)

    def test_check_call_nonzero(self) -> None:
        # check_call() function with non-zero return code
        with self.assertRaises(subprocess.CalledProcessError) as c:
            subprocess.check_call([sys.executable, "-c",
                                   "import sys; sys.exit(47)"])
        self.assertEqual(c.exception.returncode, 47)

    def test_check_output(self) -> None:
        # check_output() function with zero return code
        output = subprocess.check_output(
                [sys.executable, "-c", "print('BDFL')"])
        self.assertIn(b'BDFL', Any(output)) # see #39

    def test_check_output_nonzero(self) -> None:
        # check_call() function with non-zero return code
        with self.assertRaises(subprocess.CalledProcessError) as c:
            subprocess.check_output(
                    [sys.executable, "-c", "import sys; sys.exit(5)"])
        self.assertEqual(c.exception.returncode, 5)

    def test_check_output_stderr(self) -> None:
        # check_output() function stderr redirected to stdout
        output = subprocess.check_output(
                [sys.executable, "-c", "import sys; sys.stderr.write('BDFL')"],
                stderr=subprocess.STDOUT)
        self.assertIn(b'BDFL', Any(output)) # see #39

    def test_check_output_stdout_arg(self) -> None:
        # check_output() function stderr redirected to stdout
        with self.assertRaises(ValueError) as c:
            output = subprocess.check_output(
                    [sys.executable, "-c", "print('will not be run')"],
                    stdout=sys.stdout)
            self.fail("Expected ValueError when stdout arg supplied.")
        self.assertIn('stdout', c.exception.args[0])

    def test_call_kwargs(self) -> None:
        # call() function with keyword args
        newenv = os.environ.copy()
        newenv["FRUIT"] = "banana"
        rc = subprocess.call([sys.executable, "-c",
                              'import sys, os;'
                              'sys.exit(os.getenv("FRUIT")=="banana")'],
                             env=newenv)
        self.assertEqual(rc, 1)

    def test_invalid_args(self) -> None:
        # Popen() called with invalid arguments should raise TypeError
        # but Popen.__del__ should not complain (issue #12085)
        with support.captured_stderr() as s:
            self.assertRaises(TypeError, subprocess.Popen, invalid_arg_name=1)
            argcount = subprocess.Popen.__init__.__code__.co_argcount
            too_many_args = [0] * (argcount + 1)
            self.assertRaises(TypeError, subprocess.Popen, *too_many_args)
        self.assertEqual(s.getvalue(), '')

    def test_stdin_none(self) -> None:
        # .stdin is None when not redirected
        p = subprocess.Popen([sys.executable, "-c", 'print("banana")'],
                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        self.addCleanup(p.stdout.close)
        self.addCleanup(p.stderr.close)
        p.wait()
        self.assertEqual(p.stdin, None)

    def test_stdout_none(self) -> None:
        # .stdout is None when not redirected
        p = subprocess.Popen([sys.executable, "-c",
                             'print("    this bit of output is from a '
                             'test of stdout in a different '
                             'process ...")'],
                             stdin=subprocess.PIPE, stderr=subprocess.PIPE)
        self.addCleanup(p.stdin.close)
        self.addCleanup(p.stderr.close)
        p.wait()
        self.assertEqual(p.stdout, None)

    def test_stderr_none(self) -> None:
        # .stderr is None when not redirected
        p = subprocess.Popen([sys.executable, "-c", 'print("banana")'],
                         stdin=subprocess.PIPE, stdout=subprocess.PIPE)
        self.addCleanup(p.stdout.close)
        self.addCleanup(p.stdin.close)
        p.wait()
        self.assertEqual(p.stderr, None)

    def test_executable_with_cwd(self) -> None:
        python_dir = os.path.dirname(os.path.realpath(sys.executable))
        p = subprocess.Popen(["somethingyoudonthave", "-c",
                              "import sys; sys.exit(47)"],
                             executable=sys.executable, cwd=python_dir)
        p.wait()
        self.assertEqual(p.returncode, 47)

    @unittest.skipIf(sysconfig.is_python_build(),
                     "need an installed Python. See #7774")
    def test_executable_without_cwd(self) -> None:
        # For a normal installation, it should work without 'cwd'
        # argument.  For test runs in the build directory, see #7774.
        p = subprocess.Popen(["somethingyoudonthave", "-c",
                              "import sys; sys.exit(47)"],
                             executable=sys.executable)
        p.wait()
        self.assertEqual(p.returncode, 47)

    def test_stdin_pipe(self) -> None:
        # stdin redirection
        p = subprocess.Popen([sys.executable, "-c",
                         'import sys; sys.exit(sys.stdin.read() == "pear")'],
                        stdin=subprocess.PIPE)
        p.stdin.write(b"pear")
        p.stdin.close()
        p.wait()
        self.assertEqual(p.returncode, 1)

    def test_stdin_filedes(self) -> None:
        # stdin is set to open file descriptor
        tf = tempfile.TemporaryFile()
        self.addCleanup(tf.close)
        d = tf.fileno()
        os.write(d, b"pear")
        os.lseek(d, 0, 0)
        p = subprocess.Popen([sys.executable, "-c",
                         'import sys; sys.exit(sys.stdin.read() == "pear")'],
                         stdin=d)
        p.wait()
        self.assertEqual(p.returncode, 1)

    def test_stdin_fileobj(self) -> None:
        # stdin is set to open file object
        tf = tempfile.TemporaryFile()
        self.addCleanup(tf.close)
        tf.write(b"pear")
        tf.seek(0)
        p = subprocess.Popen([sys.executable, "-c",
                         'import sys; sys.exit(sys.stdin.read() == "pear")'],
                         stdin=tf)
        p.wait()
        self.assertEqual(p.returncode, 1)

    def test_stdout_pipe(self) -> None:
        # stdout redirection
        p = subprocess.Popen([sys.executable, "-c",
                          'import sys; sys.stdout.write("orange")'],
                         stdout=subprocess.PIPE)
        self.addCleanup(p.stdout.close)
        self.assertEqual(p.stdout.read(), b"orange")

    def test_stdout_filedes(self) -> None:
        # stdout is set to open file descriptor
        tf = tempfile.TemporaryFile()
        self.addCleanup(tf.close)
        d = tf.fileno()
        p = subprocess.Popen([sys.executable, "-c",
                          'import sys; sys.stdout.write("orange")'],
                         stdout=d)
        p.wait()
        os.lseek(d, 0, 0)
        self.assertEqual(os.read(d, 1024), b"orange")

    def test_stdout_fileobj(self) -> None:
        # stdout is set to open file object
        tf = tempfile.TemporaryFile()
        self.addCleanup(tf.close)
        p = subprocess.Popen([sys.executable, "-c",
                          'import sys; sys.stdout.write("orange")'],
                         stdout=tf)
        p.wait()
        tf.seek(0)
        self.assertEqual(tf.read(), b"orange")

    def test_stderr_pipe(self) -> None:
        # stderr redirection
        p = subprocess.Popen([sys.executable, "-c",
                          'import sys; sys.stderr.write("strawberry")'],
                         stderr=subprocess.PIPE)
        self.addCleanup(p.stderr.close)
        self.assertStderrEqual(p.stderr.read(), b"strawberry")

    def test_stderr_filedes(self) -> None:
        # stderr is set to open file descriptor
        tf = tempfile.TemporaryFile()
        self.addCleanup(tf.close)
        d = tf.fileno()
        p = subprocess.Popen([sys.executable, "-c",
                          'import sys; sys.stderr.write("strawberry")'],
                         stderr=d)
        p.wait()
        os.lseek(d, 0, 0)
        self.assertStderrEqual(os.read(d, 1024), b"strawberry")

    def test_stderr_fileobj(self) -> None:
        # stderr is set to open file object
        tf = tempfile.TemporaryFile()
        self.addCleanup(tf.close)
        p = subprocess.Popen([sys.executable, "-c",
                          'import sys; sys.stderr.write("strawberry")'],
                         stderr=tf)
        p.wait()
        tf.seek(0)
        self.assertStderrEqual(tf.read(), b"strawberry")

    def test_stdout_stderr_pipe(self) -> None:
        # capture stdout and stderr to the same pipe
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys;'
                              'sys.stdout.write("apple");'
                              'sys.stdout.flush();'
                              'sys.stderr.write("orange")'],
                             stdout=subprocess.PIPE,
                             stderr=subprocess.STDOUT)
        self.addCleanup(p.stdout.close)
        self.assertStderrEqual(p.stdout.read(), b"appleorange")

    def test_stdout_stderr_file(self) -> None:
        # capture stdout and stderr to the same open file
        tf = tempfile.TemporaryFile()
        self.addCleanup(tf.close)
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys;'
                              'sys.stdout.write("apple");'
                              'sys.stdout.flush();'
                              'sys.stderr.write("orange")'],
                             stdout=tf,
                             stderr=tf)
        p.wait()
        tf.seek(0)
        self.assertStderrEqual(tf.read(), b"appleorange")

    def test_stdout_filedes_of_stdout(self) -> None:
        # stdout is set to 1 (#1531862).
        cmd = r"import sys, os; sys.exit(os.write(sys.stdout.fileno(), b'.\n'))"
        rc = subprocess.call([sys.executable, "-c", cmd], stdout=1)
        self.assertEqual(rc, 2)

    def test_cwd(self) -> None:
        tmpdir = tempfile.gettempdir()
        # We cannot use os.path.realpath to canonicalize the path,
        # since it doesn't expand Tru64 {memb} strings. See bug 1063571.
        cwd = os.getcwd()
        os.chdir(tmpdir)
        tmpdir = os.getcwd()
        os.chdir(cwd)
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys,os;'
                              'sys.stdout.write(os.getcwd())'],
                             stdout=subprocess.PIPE,
                             cwd=tmpdir)
        self.addCleanup(p.stdout.close)
        normcase = os.path.normcase
        self.assertEqual(normcase(p.stdout.read().decode("utf-8")),
                         normcase(tmpdir))

    def test_env(self) -> None:
        newenv = os.environ.copy()
        newenv["FRUIT"] = "orange"
        with subprocess.Popen([sys.executable, "-c",
                               'import sys,os;'
                               'sys.stdout.write(os.getenv("FRUIT"))'],
                              stdout=subprocess.PIPE,
                              env=newenv) as p:
            stdout, stderr = p.communicate()
            self.assertEqual(stdout, b"orange")

    # Windows requires at least the SYSTEMROOT environment variable to start
    # Python
    @unittest.skipIf(sys.platform == 'win32',
                     'cannot test an empty env on Windows')
    @unittest.skipIf(sysconfig.get_config_var('Py_ENABLE_SHARED') is not None,
                     'the python library cannot be loaded '
                     'with an empty environment')
    def test_empty_env(self) -> None:
        with subprocess.Popen([sys.executable, "-c",
                               'import os; '
                               'print(list(os.environ.keys()))'],
                              stdout=subprocess.PIPE,
                              env={}) as p:
            stdout, stderr = p.communicate()
            self.assertIn(stdout.strip(),
                [b"[]",
                 # Mac OS X adds __CF_USER_TEXT_ENCODING variable to an empty
                 # environment
                 b"['__CF_USER_TEXT_ENCODING']"])

    def test_communicate_stdin(self) -> None:
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys;'
                              'sys.exit(sys.stdin.read() == "pear")'],
                             stdin=subprocess.PIPE)
        p.communicate(b"pear")
        self.assertEqual(p.returncode, 1)

    def test_communicate_stdout(self) -> None:
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys; sys.stdout.write("pineapple")'],
                             stdout=subprocess.PIPE)
        (stdout, stderr) = p.communicate()
        self.assertEqual(stdout, b"pineapple")
        self.assertEqual(stderr, None)

    def test_communicate_stderr(self) -> None:
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys; sys.stderr.write("pineapple")'],
                             stderr=subprocess.PIPE)
        (stdout, stderr) = p.communicate()
        self.assertEqual(stdout, None)
        self.assertStderrEqual(stderr, b"pineapple")

    def test_communicate(self) -> None:
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys,os;'
                              'sys.stderr.write("pineapple");'
                              'sys.stdout.write(sys.stdin.read())'],
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)
        self.addCleanup(p.stdout.close)
        self.addCleanup(p.stderr.close)
        self.addCleanup(p.stdin.close)
        (stdout, stderr) = p.communicate(b"banana")
        self.assertEqual(stdout, b"banana")
        self.assertStderrEqual(stderr, b"pineapple")

    # Test for the fd leak reported in http://bugs.python.org/issue2791.
    def test_communicate_pipe_fd_leak(self) -> None:
        for stdin_pipe in (False, True):
            for stdout_pipe in (False, True):
                for stderr_pipe in (False, True):
                    options = Dict[str, Any]()
                    if stdin_pipe:
                        options['stdin'] = subprocess.PIPE
                    if stdout_pipe:
                        options['stdout'] = subprocess.PIPE
                    if stderr_pipe:
                        options['stderr'] = subprocess.PIPE
                    if not options:
                        continue
                    p = subprocess.Popen([sys.executable, "-c", "pass"], **options)
                    p.communicate()
                    if p.stdin is not None:
                        self.assertTrue(p.stdin.closed)
                    if p.stdout is not None:
                        self.assertTrue(p.stdout.closed)
                    if p.stderr is not None:
                        self.assertTrue(p.stderr.closed)

    def test_communicate_returns(self) -> None:
        # communicate() should return None if no redirection is active
        p = subprocess.Popen([sys.executable, "-c",
                              "import sys; sys.exit(47)"])
        (stdout, stderr) = p.communicate()
        self.assertEqual(stdout, None)
        self.assertEqual(stderr, None)

    def test_communicate_pipe_buf(self) -> None:
        # communicate() with writes larger than pipe_buf
        # This test will probably deadlock rather than fail, if
        # communicate() does not work properly.
        x, y = os.pipe()
        if mswindows:
            pipe_buf = 512
        else:
            pipe_buf = os.fpathconf(x, "PC_PIPE_BUF")
        os.close(x)
        os.close(y)
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys,os;'
                              'sys.stdout.write(sys.stdin.read(47));'
                              'sys.stderr.write("xyz"*%d);'
                              'sys.stdout.write(sys.stdin.read())' % pipe_buf],
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)
        self.addCleanup(p.stdout.close)
        self.addCleanup(p.stderr.close)
        self.addCleanup(p.stdin.close)
        string_to_write = b"abc"*pipe_buf
        (stdout, stderr) = p.communicate(string_to_write)
        self.assertEqual(stdout, string_to_write)

    def test_writes_before_communicate(self) -> None:
        # stdin.write before communicate()
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys,os;'
                              'sys.stdout.write(sys.stdin.read())'],
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)
        self.addCleanup(p.stdout.close)
        self.addCleanup(p.stderr.close)
        self.addCleanup(p.stdin.close)
        p.stdin.write(b"banana")
        (stdout, stderr) = p.communicate(b"split")
        self.assertEqual(stdout, b"bananasplit")
        self.assertStderrEqual(stderr, b"")

    def test_universal_newlines(self) -> None:
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys,os;' + SETBINARY +
                              'sys.stdout.write(sys.stdin.readline());'
                              'sys.stdout.flush();'
                              'sys.stdout.write("line2\\n");'
                              'sys.stdout.flush();'
                              'sys.stdout.write(sys.stdin.read());'
                              'sys.stdout.flush();'
                              'sys.stdout.write("line4\\n");'
                              'sys.stdout.flush();'
                              'sys.stdout.write("line5\\r\\n");'
                              'sys.stdout.flush();'
                              'sys.stdout.write("line6\\r");'
                              'sys.stdout.flush();'
                              'sys.stdout.write("\\nline7");'
                              'sys.stdout.flush();'
                              'sys.stdout.write("\\nline8");'],
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE,
                             universal_newlines=1)
        p.stdin.write("line1\n")
        self.assertEqual(p.stdout.readline(), "line1\n")
        p.stdin.write("line3\n")
        p.stdin.close()
        self.addCleanup(p.stdout.close)
        self.assertEqual(p.stdout.readline(),
                         "line2\n")
        self.assertEqual(p.stdout.read(6),
                         "line3\n")
        self.assertEqual(p.stdout.read(),
                         "line4\nline5\nline6\nline7\nline8")

    def test_universal_newlines_communicate(self) -> None:
        # universal newlines through communicate()
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys,os;' + SETBINARY +
                              'sys.stdout.write("line2\\n");'
                              'sys.stdout.flush();'
                              'sys.stdout.write("line4\\n");'
                              'sys.stdout.flush();'
                              'sys.stdout.write("line5\\r\\n");'
                              'sys.stdout.flush();'
                              'sys.stdout.write("line6\\r");'
                              'sys.stdout.flush();'
                              'sys.stdout.write("\\nline7");'
                              'sys.stdout.flush();'
                              'sys.stdout.write("\\nline8");'],
                             stderr=subprocess.PIPE,
                             stdout=subprocess.PIPE,
                             universal_newlines=1)
        self.addCleanup(p.stdout.close)
        self.addCleanup(p.stderr.close)
        # BUG: can't give a non-empty stdin because it breaks both the
        # select- and poll-based communicate() implementations.
        (stdout, stderr) = p.communicate()
        self.assertEqual(stdout,
                         "line2\nline4\nline5\nline6\nline7\nline8")

    def test_universal_newlines_communicate_stdin(self) -> None:
        # universal newlines through communicate(), with only stdin
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys,os;' + SETBINARY + '''\nif True:
                                  s = sys.stdin.readline()
                                  assert s == "line1\\n", repr(s)
                                  s = sys.stdin.read()
                                  assert s == "line3\\n", repr(s)
                              '''],
                             stdin=subprocess.PIPE,
                             universal_newlines=1)
        (stdout, stderr) = p.communicate("line1\nline3\n")
        self.assertEqual(p.returncode, 0)

    def test_no_leaking(self) -> None:
        # Make sure we leak no resources
        if not mswindows:
            max_handles = 1026 # too much for most UNIX systems
        else:
            max_handles = 2050 # too much for (at least some) Windows setups
        handles = List[int]()
        tmpdir = tempfile.mkdtemp()
        try:
            for i in range(max_handles):
                try:
                    tmpfile = os.path.join(tmpdir, support.TESTFN)
                    handles.append(os.open(tmpfile, os.O_WRONLY|os.O_CREAT))
                except OSError as e:
                    if e.errno != errno.EMFILE:
                        raise
                    break
            else:
                self.skipTest("failed to reach the file descriptor limit "
                    "(tried %d)" % max_handles)
            # Close a couple of them (should be enough for a subprocess)
            for i in range(10):
                os.close(handles.pop())
            # Loop creating some subprocesses. If one of them leaks some fds,
            # the next loop iteration will fail by reaching the max fd limit.
            for i in range(15):
                p = subprocess.Popen([sys.executable, "-c",
                                      "import sys;"
                                      "sys.stdout.write(sys.stdin.read())"],
                                     stdin=subprocess.PIPE,
                                     stdout=subprocess.PIPE,
                                     stderr=subprocess.PIPE)
                data = p.communicate(b"lime")[0]
                self.assertEqual(data, b"lime")
        finally:
            for h in handles:
                os.close(h)
            shutil.rmtree(tmpdir)

    def test_list2cmdline(self) -> None:
        self.assertEqual(subprocess.list2cmdline(['a b c', 'd', 'e']),
                         '"a b c" d e')
        self.assertEqual(subprocess.list2cmdline(['ab"c', '\\', 'd']),
                         'ab\\"c \\ d')
        self.assertEqual(subprocess.list2cmdline(['ab"c', ' \\', 'd']),
                         'ab\\"c " \\\\" d')
        self.assertEqual(subprocess.list2cmdline(['a\\\\\\b', 'de fg', 'h']),
                         'a\\\\\\b "de fg" h')
        self.assertEqual(subprocess.list2cmdline(['a\\"b', 'c', 'd']),
                         'a\\\\\\"b c d')
        self.assertEqual(subprocess.list2cmdline(['a\\\\b c', 'd', 'e']),
                         '"a\\\\b c" d e')
        self.assertEqual(subprocess.list2cmdline(['a\\\\b\\ c', 'd', 'e']),
                         '"a\\\\b\\ c" d e')
        self.assertEqual(subprocess.list2cmdline(['ab', '']),
                         'ab ""')


    def test_poll(self) -> None:
        p = subprocess.Popen([sys.executable,
                          "-c", "import time; time.sleep(1)"])
        count = 0
        while p.poll() is None:
            time.sleep(0.1)
            count += 1
        # We expect that the poll loop probably went around about 10 times,
        # but, based on system scheduling we can't control, it's possible
        # poll() never returned None.  It "should be" very rare that it
        # didn't go around at least twice.
        self.assertGreaterEqual(count, 2)
        # Subsequent invocations should just return the returncode
        self.assertEqual(p.poll(), 0)


    def test_wait(self) -> None:
        p = subprocess.Popen([sys.executable,
                          "-c", "import time; time.sleep(2)"])
        self.assertEqual(p.wait(), 0)
        # Subsequent invocations should just return the returncode
        self.assertEqual(p.wait(), 0)


    def test_invalid_bufsize(self) -> None:
        # an invalid type of the bufsize argument should raise
        # TypeError.
        with self.assertRaises(TypeError):
            subprocess.Popen([sys.executable, "-c", "pass"], Any("orange"))

    def test_bufsize_is_none(self) -> None:
        # bufsize=None should be the same as bufsize=0.
        p = subprocess.Popen([sys.executable, "-c", "pass"], None)
        self.assertEqual(p.wait(), 0)
        # Again with keyword arg
        p = subprocess.Popen([sys.executable, "-c", "pass"], bufsize=None)
        self.assertEqual(p.wait(), 0)

    def test_leaking_fds_on_error(self) -> None:
        # see bug #5179: Popen leaks file descriptors to PIPEs if
        # the child fails to execute; this will eventually exhaust
        # the maximum number of open fds. 1024 seems a very common
        # value for that limit, but Windows has 2048, so we loop
        # 1024 times (each call leaked two fds).
        for i in range(1024):
            # Windows raises IOError.  Others raise OSError.
            with self.assertRaises(EnvironmentError) as c:
                subprocess.Popen(['nonexisting_i_hope'],
                                 stdout=subprocess.PIPE,
                                 stderr=subprocess.PIPE)
            # ignore errors that indicate the command was not found
            if c.exception.errno not in (errno.ENOENT, errno.EACCES):
                raise c.exception

    def test_issue8780(self) -> None:
        # Ensure that stdout is inherited from the parent
        # if stdout=PIPE is not used
        code = ';'.join([
            'import subprocess, sys',
            'retcode = subprocess.call('
                "[sys.executable, '-c', 'print(\"Hello World!\")'])",
            'assert retcode == 0'])
        output = subprocess.check_output([sys.executable, '-c', code])
        self.assertTrue(output.startswith(b'Hello World!'), ascii(output))

    def test_handles_closed_on_exception(self) -> None:
        # If CreateProcess exits with an error, ensure the
        # duplicate output handles are released
        ifhandle, ifname = mkstemp()
        ofhandle, ofname = mkstemp()
        efhandle, efname = mkstemp()
        try:
            subprocess.Popen (["*"], stdin=ifhandle, stdout=ofhandle,
              stderr=efhandle)
        except OSError:
            os.close(ifhandle)
            os.remove(ifname)
            os.close(ofhandle)
            os.remove(ofname)
            os.close(efhandle)
            os.remove(efname)
        self.assertFalse(os.path.exists(ifname))
        self.assertFalse(os.path.exists(ofname))
        self.assertFalse(os.path.exists(efname))

    def test_communicate_epipe(self) -> None:
        # Issue 10963: communicate() should hide EPIPE
        p = subprocess.Popen([sys.executable, "-c", 'pass'],
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)
        self.addCleanup(p.stdout.close)
        self.addCleanup(p.stderr.close)
        self.addCleanup(p.stdin.close)
        p.communicate(b"x" * 2**20)

    def test_communicate_epipe_only_stdin(self) -> None:
        # Issue 10963: communicate() should hide EPIPE
        p = subprocess.Popen([sys.executable, "-c", 'pass'],
                             stdin=subprocess.PIPE)
        self.addCleanup(p.stdin.close)
        time.sleep(2)
        p.communicate(b"x" * 2**20)

    @unittest.skipUnless(hasattr(signal, 'SIGALRM'),
                         "Requires signal.SIGALRM")
    def test_communicate_eintr(self) -> None:
        # Issue #12493: communicate() should handle EINTR
        def handler(signum, frame):
            pass
        old_handler = signal.signal(signal.SIGALRM, handler)
        self.addCleanup(signal.signal, signal.SIGALRM, old_handler)

        # the process is running for 2 seconds
        args = [sys.executable, "-c", 'import time; time.sleep(2)']
        for stream in ('stdout', 'stderr'):
            kw = Dict[str, Any]({stream: subprocess.PIPE})
            with subprocess.Popen(args, **kw) as process:
                signal.alarm(1)
                # communicate() will be interrupted by SIGALRM
                process.communicate()


# context manager
class _SuppressCoreFiles(object):
    """Try to prevent core files from being created."""
    old_limit = None # type: Tuple[int, int]

    def __enter__(self) -> None:
        """Try to save previous ulimit, then set it to (0, 0)."""
        if resource is not None:
            try:
                self.old_limit = resource.getrlimit(resource.RLIMIT_CORE)
                resource.setrlimit(resource.RLIMIT_CORE, (0, 0))
            except (ValueError, resource.error):
                pass

        if sys.platform == 'darwin':
            # Check if the 'Crash Reporter' on OSX was configured
            # in 'Developer' mode and warn that it will get triggered
            # when it is.
            #
            # This assumes that this context manager is used in tests
            # that might trigger the next manager.
            value = subprocess.Popen(['/usr/bin/defaults', 'read',
                    'com.apple.CrashReporter', 'DialogType'],
                    stdout=subprocess.PIPE).communicate()[0]
            if value.strip() == b'developer':
                print("this tests triggers the Crash Reporter, "
                      "that is intentional", end='')
                sys.stdout.flush()

    def __exit__(self, *args: Any) -> None:
        """Return core file behavior to default."""
        if self.old_limit is None:
            return
        if resource is not None:
            try:
                resource.setrlimit(resource.RLIMIT_CORE, self.old_limit)
            except (ValueError, resource.error):
                pass


@unittest.skipIf(mswindows, "POSIX specific tests")
class POSIXProcessTestCase(BaseTestCase):

    def test_exceptions(self) -> None:
        nonexistent_dir = "/_this/pa.th/does/not/exist"
        try:
            os.chdir(nonexistent_dir)
        except OSError as e:
            # This avoids hard coding the errno value or the OS perror()
            # string and instead capture the exception that we want to see
            # below for comparison.
            desired_exception = e
            desired_exception.strerror += ': ' + repr(sys.executable)
        else:
            self.fail("chdir to nonexistant directory %s succeeded." %
                      nonexistent_dir)

        # Error in the child re-raised in the parent.
        try:
            p = subprocess.Popen([sys.executable, "-c", ""],
                                 cwd=nonexistent_dir)
        except OSError as e:
            # Test that the child process chdir failure actually makes
            # it up to the parent process as the correct exception.
            self.assertEqual(desired_exception.errno, e.errno)
            self.assertEqual(desired_exception.strerror, e.strerror)
        else:
            self.fail("Expected OSError: %s" % desired_exception)

    def test_restore_signals(self) -> None:
        # Code coverage for both values of restore_signals to make sure it
        # at least does not blow up.
        # A test for behavior would be complex.  Contributions welcome.
        subprocess.call([sys.executable, "-c", ""], restore_signals=True)
        subprocess.call([sys.executable, "-c", ""], restore_signals=False)

    def test_start_new_session(self) -> None:
        # For code coverage of calling setsid().  We don't care if we get an
        # EPERM error from it depending on the test execution environment, that
        # still indicates that it was called.
        try:
            output = subprocess.check_output(
                    [sys.executable, "-c",
                     "import os; print(os.getpgid(os.getpid()))"],
                    start_new_session=True)
        except OSError as e:
            if e.errno != errno.EPERM:
                raise
        else:
            parent_pgid = os.getpgid(os.getpid())
            child_pgid = int(output)
            self.assertNotEqual(parent_pgid, child_pgid)

    def test_run_abort(self) -> None:
        # returncode handles signal termination
        with _SuppressCoreFiles():
            p = subprocess.Popen([sys.executable, "-c",
                                  'import os; os.abort()'])
            p.wait()
        self.assertEqual(-p.returncode, signal.SIGABRT)

    def test_preexec(self) -> None:
        # DISCLAIMER: Setting environment variables is *not* a good use
        # of a preexec_fn.  This is merely a test.
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys,os;'
                              'sys.stdout.write(os.getenv("FRUIT"))'],
                             stdout=subprocess.PIPE,
                             preexec_fn=lambda: os.putenv("FRUIT", "apple"))
        self.addCleanup(p.stdout.close)
        self.assertEqual(p.stdout.read(), b"apple")

    def test_preexec_exception(self) -> None:
        def raise_it():
            raise ValueError("What if two swallows carried a coconut?")
        try:
            p = subprocess.Popen([sys.executable, "-c", ""],
                                 preexec_fn=raise_it)
        except RuntimeError as e:
            self.assertTrue(
                    subprocess._posixsubprocess,
                    "Expected a ValueError from the preexec_fn")
        except ValueError as e2:
            self.assertIn("coconut", e2.args[0])
        else:
            self.fail("Exception raised by preexec_fn did not make it "
                      "to the parent process.")

    def test_preexec_gc_module_failure(self) -> None:
        # This tests the code that disables garbage collection if the child
        # process will execute any Python.
        def raise_runtime_error():
            raise RuntimeError("this shouldn't escape")
        enabled = gc.isenabled()
        orig_gc_disable = gc.disable
        orig_gc_isenabled = gc.isenabled
        try:
            gc.disable()
            self.assertFalse(gc.isenabled())
            subprocess.call([sys.executable, '-c', ''],
                            preexec_fn=lambda: None)
            self.assertFalse(gc.isenabled(),
                             "Popen enabled gc when it shouldn't.")

            gc.enable()
            self.assertTrue(gc.isenabled())
            subprocess.call([sys.executable, '-c', ''],
                            preexec_fn=lambda: None)
            self.assertTrue(gc.isenabled(), "Popen left gc disabled.")

            setattr(gc, 'disable', raise_runtime_error)
            self.assertRaises(RuntimeError, subprocess.Popen,
                              [sys.executable, '-c', ''],
                              preexec_fn=lambda: None)

            del gc.isenabled  # force an AttributeError
            self.assertRaises(AttributeError, subprocess.Popen,
                              [sys.executable, '-c', ''],
                              preexec_fn=lambda: None)
        finally:
            setattr(gc, 'disable', orig_gc_disable)
            setattr(gc, 'isenabled', orig_gc_isenabled)
            if not enabled:
                gc.disable()

    def test_args_string(self) -> None:
        # args is a string
        fd, fname = mkstemp()
        # reopen in text mode
        with open(fd, "w", errors=Any("surrogateescape")) as fobj: # see #260
            fobj.write("#!/bin/sh\n")
            fobj.write("exec '%s' -c 'import sys; sys.exit(47)'\n" %
                       sys.executable)
        os.chmod(fname, 0o700)
        p = subprocess.Popen(fname)
        p.wait()
        os.remove(fname)
        self.assertEqual(p.returncode, 47)

    def test_invalid_args(self) -> None:
        # invalid arguments should raise ValueError
        self.assertRaises(ValueError, subprocess.call,
                          [sys.executable, "-c",
                           "import sys; sys.exit(47)"],
                          startupinfo=47)
        self.assertRaises(ValueError, subprocess.call,
                          [sys.executable, "-c",
                           "import sys; sys.exit(47)"],
                          creationflags=47)

    def test_shell_sequence(self) -> None:
        # Run command through the shell (sequence)
        newenv = os.environ.copy()
        newenv["FRUIT"] = "apple"
        p = subprocess.Popen(["echo $FRUIT"], shell=1,
                             stdout=subprocess.PIPE,
                             env=newenv)
        self.addCleanup(p.stdout.close)
        self.assertEqual(p.stdout.read().strip(b" \t\r\n\f"), b"apple")

    def test_shell_string(self) -> None:
        # Run command through the shell (string)
        newenv = os.environ.copy()
        newenv["FRUIT"] = "apple"
        p = subprocess.Popen("echo $FRUIT", shell=1,
                             stdout=subprocess.PIPE,
                             env=newenv)
        self.addCleanup(p.stdout.close)
        self.assertEqual(p.stdout.read().strip(b" \t\r\n\f"), b"apple")

    def test_call_string(self) -> None:
        # call() function with string argument on UNIX
        fd, fname = mkstemp()
        # reopen in text mode
        with open(fd, "w", errors=Any("surrogateescape")) as fobj: # see #260
            fobj.write("#!/bin/sh\n")
            fobj.write("exec '%s' -c 'import sys; sys.exit(47)'\n" %
                       sys.executable)
        os.chmod(fname, 0o700)
        rc = subprocess.call(fname)
        os.remove(fname)
        self.assertEqual(rc, 47)

    def test_specific_shell(self) -> None:
        # Issue #9265: Incorrect name passed as arg[0].
        shells = List[str]()
        for prefix in ['/bin', '/usr/bin/', '/usr/local/bin']:
            for name in ['bash', 'ksh']:
                sh = os.path.join(prefix, name)
                if os.path.isfile(sh):
                    shells.append(sh)
        if not shells: # Will probably work for any shell but csh.
            self.skipTest("bash or ksh required for this test")
        sh = '/bin/sh'
        if os.path.isfile(sh) and not os.path.islink(sh):
            # Test will fail if /bin/sh is a symlink to csh.
            shells.append(sh)
        for sh in shells:
            p = subprocess.Popen("echo $0", executable=sh, shell=True,
                                 stdout=subprocess.PIPE)
            self.addCleanup(p.stdout.close)
            self.assertEqual(p.stdout.read().strip(), bytes(sh, 'ascii'))

    def _kill_process(self, method: str, *args: Any) -> subprocess.Popen:
        # Do not inherit file handles from the parent.
        # It should fix failures on some platforms.
        p = subprocess.Popen([sys.executable, "-c", """if 1:
                             import sys, time
                             sys.stdout.write('x\\n')
                             sys.stdout.flush()
                             time.sleep(30)
                             """],
                             close_fds=True,
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)
        # Wait for the interpreter to be completely initialized before
        # sending any signal.
        p.stdout.read(1)
        getattr(p, method)(*args)
        return p

    def test_send_signal(self) -> None:
        p = self._kill_process('send_signal', signal.SIGINT)
        _, stderr = p.communicate()
        self.assertIn(b'KeyboardInterrupt', stderr)
        self.assertNotEqual(p.wait(), 0)

    def test_kill(self) -> None:
        p = self._kill_process('kill')
        _, stderr = p.communicate()
        self.assertStderrEqual(stderr, b'')
        self.assertEqual(p.wait(), -signal.SIGKILL)

    def test_terminate(self) -> None:
        p = self._kill_process('terminate')
        _, stderr = p.communicate()
        self.assertStderrEqual(stderr, b'')
        self.assertEqual(p.wait(), -signal.SIGTERM)

    def check_close_std_fds(self, fds: Iterable[int]) -> None:
        # Issue #9905: test that subprocess pipes still work properly with
        # some standard fds closed
        stdin = 0
        newfds = List[int]()
        for a in fds:
            b = os.dup(a)
            newfds.append(b)
            if a == 0:
                stdin = b
        try:
            for fd in fds:
                os.close(fd)
            out, err = subprocess.Popen([sys.executable, "-c",
                              'import sys;'
                              'sys.stdout.write("apple");'
                              'sys.stdout.flush();'
                              'sys.stderr.write("orange")'],
                       stdin=stdin,
                       stdout=subprocess.PIPE,
                       stderr=subprocess.PIPE).communicate()
            err = support.strip_python_stderr(err)
            self.assertEqual((out, err), (b'apple', b'orange'))
        finally:
            for b, a in zip(newfds, fds):
                os.dup2(b, a)
            for b in newfds:
                os.close(b)

    def test_close_fd_0(self) -> None:
        self.check_close_std_fds([0])

    def test_close_fd_1(self) -> None:
        self.check_close_std_fds([1])

    def test_close_fd_2(self) -> None:
        self.check_close_std_fds([2])

    def test_close_fds_0_1(self) -> None:
        self.check_close_std_fds([0, 1])

    def test_close_fds_0_2(self) -> None:
        self.check_close_std_fds([0, 2])

    def test_close_fds_1_2(self) -> None:
        self.check_close_std_fds([1, 2])

    def test_close_fds_0_1_2(self) -> None:
        # Issue #10806: test that subprocess pipes still work properly with
        # all standard fds closed.
        self.check_close_std_fds([0, 1, 2])

    def test_remapping_std_fds(self) -> None:
        # open up some temporary files
        temps = [mkstemp() for i in range(3)]
        try:
            temp_fds = [fd for fd, fname in temps]

            # unlink the files -- we won't need to reopen them
            for fd, fname in temps:
                os.unlink(fname)

            # write some data to what will become stdin, and rewind
            os.write(temp_fds[1], b"STDIN")
            os.lseek(temp_fds[1], 0, 0)

            # move the standard file descriptors out of the way
            saved_fds = [os.dup(fd) for fd in range(3)]
            try:
                # duplicate the file objects over the standard fd's
                for fd, temp_fd in enumerate(temp_fds):
                    os.dup2(temp_fd, fd)

                # now use those files in the "wrong" order, so that subprocess
                # has to rearrange them in the child
                p = subprocess.Popen([sys.executable, "-c",
                    'import sys; got = sys.stdin.read();'
                    'sys.stdout.write("got %s"%got); sys.stderr.write("err")'],
                    stdin=temp_fds[1],
                    stdout=temp_fds[2],
                    stderr=temp_fds[0])
                p.wait()
            finally:
                # restore the original fd's underneath sys.stdin, etc.
                for std, saved in enumerate(saved_fds):
                    os.dup2(saved, std)
                    os.close(saved)

            for fd in temp_fds:
                os.lseek(fd, 0, 0)

            out = os.read(temp_fds[2], 1024)
            err = support.strip_python_stderr(os.read(temp_fds[0], 1024))
            self.assertEqual(out, b"got STDIN")
            self.assertEqual(err, b"err")

        finally:
            for fd in temp_fds:
                os.close(fd)

    def check_swap_fds(self, stdin_no: int, stdout_no: int,
                       stderr_no: int) -> None:
        # open up some temporary files
        temps = [mkstemp() for i in range(3)]
        temp_fds = [fd for fd, fname in temps]
        try:
            # unlink the files -- we won't need to reopen them
            for fd, fname in temps:
                os.unlink(fname)

            # save a copy of the standard file descriptors
            saved_fds = [os.dup(fd) for fd in range(3)]
            try:
                # duplicate the temp files over the standard fd's 0, 1, 2
                for fd, temp_fd in enumerate(temp_fds):
                    os.dup2(temp_fd, fd)

                # write some data to what will become stdin, and rewind
                os.write(stdin_no, b"STDIN")
                os.lseek(stdin_no, 0, 0)

                # now use those files in the given order, so that subprocess
                # has to rearrange them in the child
                p = subprocess.Popen([sys.executable, "-c",
                    'import sys; got = sys.stdin.read();'
                    'sys.stdout.write("got %s"%got); sys.stderr.write("err")'],
                    stdin=stdin_no,
                    stdout=stdout_no,
                    stderr=stderr_no)
                p.wait()

                for fd in temp_fds:
                    os.lseek(fd, 0, 0)

                out = os.read(stdout_no, 1024)
                err = support.strip_python_stderr(os.read(stderr_no, 1024))
            finally:
                for std, saved in enumerate(saved_fds):
                    os.dup2(saved, std)
                    os.close(saved)

            self.assertEqual(out, b"got STDIN")
            self.assertEqual(err, b"err")

        finally:
            for fd in temp_fds:
                os.close(fd)

    # When duping fds, if there arises a situation where one of the fds is
    # either 0, 1 or 2, it is possible that it is overwritten (#12607).
    # This tests all combinations of this.
    def test_swap_fds(self) -> None:
        self.check_swap_fds(0, 1, 2)
        self.check_swap_fds(0, 2, 1)
        self.check_swap_fds(1, 0, 2)
        self.check_swap_fds(1, 2, 0)
        self.check_swap_fds(2, 0, 1)
        self.check_swap_fds(2, 1, 0)

    def test_surrogates_error_message(self) -> None:
        def prepare() -> None:
            raise ValueError("surrogate:\uDCff")

        try:
            subprocess.call(
                [sys.executable, "-c", "pass"],
                preexec_fn=prepare)
        except ValueError as err:
            # Pure Python implementations keeps the message
            self.assertIsNone(subprocess._posixsubprocess)
            self.assertEqual(str(err), "surrogate:\uDCff")
        except RuntimeError as err2:
            # _posixsubprocess uses a default message
            self.assertIsNotNone(subprocess._posixsubprocess)
            self.assertEqual(str(err2), "Exception occurred in preexec_fn.")
        else:
            self.fail("Expected ValueError or RuntimeError")

    def test_undecodable_env(self) -> None:
        for key, value in (('test', 'abc\uDCFF'), ('test\uDCFF', '42')):
            # test str with surrogates
            script = "import os; print(ascii(os.getenv(%s)))" % repr(key)
            env = os.environ.copy()
            env[key] = value
            # Use C locale to get ascii for the locale encoding to force
            # surrogate-escaping of \xFF in the child process; otherwise it can
            # be decoded as-is if the default locale is latin-1.
            env['LC_ALL'] = 'C'
            stdout = subprocess.check_output(
                [sys.executable, "-c", script],
                env=env)
            stdout = stdout.rstrip(b'\n\r')
            self.assertEqual(stdout.decode('ascii'), ascii(value))

            # test bytes
            keyb = key.encode("ascii", "surrogateescape")
            valueb = value.encode("ascii", "surrogateescape")
            script = "import os; print(ascii(os.getenvb(%s)))" % repr(keyb)
            envb = Dict[Any, Any](os.environ.copy().items())
            envb[keyb] = valueb
            stdout = subprocess.check_output(
                [sys.executable, "-c", script],
                env=envb)
            stdout = stdout.rstrip(b'\n\r')
            self.assertEqual(stdout.decode('ascii'), ascii(valueb))

    def test_bytes_program(self) -> None:
        abs_program = os.fsencode(sys.executable)
        path, programs = os.path.split(sys.executable)
        program = os.fsencode(programs)

        # absolute bytes path
        exitcode = subprocess.call([abs_program, "-c", "pass"])
        self.assertEqual(exitcode, 0)

        # bytes program, unicode PATH
        env = os.environ.copy()
        env["PATH"] = path
        exitcode = subprocess.call([program, "-c", "pass"], env=env)
        self.assertEqual(exitcode, 0)

        # bytes program, bytes PATH
        envb = os.environb.copy()
        envb[b"PATH"] = os.fsencode(path)
        exitcode = subprocess.call([program, "-c", "pass"], env=envb)
        self.assertEqual(exitcode, 0)

    def test_pipe_cloexec(self) -> None:
        sleeper = support.findfile("input_reader.py", subdir="subprocessdata")
        fd_status = support.findfile("fd_status.py", subdir="subprocessdata")

        p1 = subprocess.Popen([sys.executable, sleeper],
                              stdin=subprocess.PIPE, stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE, close_fds=False)

        self.addCleanup(p1.communicate, b'')

        p2 = subprocess.Popen([sys.executable, fd_status],
                              stdout=subprocess.PIPE, close_fds=False)

        output, error = p2.communicate()
        result_fds = set(map(int, output.split(b',')))
        unwanted_fds = set([p1.stdin.fileno(), p1.stdout.fileno(),
                            p1.stderr.fileno()])

        self.assertFalse(result_fds & unwanted_fds,
                         "Expected no fds from %r to be open in child, "
                         "found %r" %
                              (unwanted_fds, result_fds & unwanted_fds))

    def test_pipe_cloexec_real_tools(self) -> None:
        qcat = support.findfile("qcat.py", subdir="subprocessdata")
        qgrep = support.findfile("qgrep.py", subdir="subprocessdata")

        subdata = b'zxcvbn'
        data = subdata * 4 + b'\n'

        p1 = subprocess.Popen([sys.executable, qcat],
                              stdin=subprocess.PIPE, stdout=subprocess.PIPE,
                              close_fds=False)

        p2 = subprocess.Popen([sys.executable, qgrep, subdata],
                              stdin=p1.stdout, stdout=subprocess.PIPE,
                              close_fds=False)

        self.addCleanup(p1.wait)
        self.addCleanup(p2.wait)
        def kill_p1() -> None:
            #try:
            p1.terminate()
            #except ProcessLookupError:
            #    pass
        def kill_p2() -> None:
            #try:
            p2.terminate()
            #except ProcessLookupError:
            #    pass
        self.addCleanup(kill_p1)
        self.addCleanup(kill_p2)

        p1.stdin.write(data)
        p1.stdin.close()

        readfiles, ignored1, ignored2 = select.select([p2.stdout], [], [], 10)

        self.assertTrue(readfiles, "The child hung")
        self.assertEqual(p2.stdout.read(), data)

        p1.stdout.close()
        p2.stdout.close()

    def test_close_fds(self) -> None:
        fd_status = support.findfile("fd_status.py", subdir="subprocessdata")

        fds = os.pipe()
        self.addCleanup(os.close, fds[0])
        self.addCleanup(os.close, fds[1])

        open_fds = set([fds[0], fds[1]])
        # add a bunch more fds
        for _ in range(9):
            fd = os.open("/dev/null", os.O_RDONLY)
            self.addCleanup(os.close, fd)
            open_fds.add(fd)

        p = subprocess.Popen([sys.executable, fd_status],
                             stdout=subprocess.PIPE, close_fds=False)
        output, ignored = p.communicate()
        remaining_fds = set(map(int, output.split(b',')))

        self.assertEqual(remaining_fds & open_fds, open_fds,
                         "Some fds were closed")

        p = subprocess.Popen([sys.executable, fd_status],
                             stdout=subprocess.PIPE, close_fds=True)
        output, ignored = p.communicate()
        remaining_fds = set(map(int, output.split(b',')))

        self.assertFalse(remaining_fds & open_fds,
                         "Some fds were left open")
        self.assertIn(1, remaining_fds, "Subprocess failed")

        # Keep some of the fd's we opened open in the subprocess.
        # This tests _posixsubprocess.c's proper handling of fds_to_keep.
        fds_to_keep = set(open_fds.pop() for _ in range(8))
        p = subprocess.Popen([sys.executable, fd_status],
                             stdout=subprocess.PIPE, close_fds=True,
                             pass_fds=())
        output, ignored = p.communicate()
        remaining_fds = set(map(int, output.split(b',')))

        self.assertFalse(remaining_fds & fds_to_keep & open_fds,
                         "Some fds not in pass_fds were left open")
        self.assertIn(1, remaining_fds, "Subprocess failed")

    # Mac OS X Tiger (10.4) has a kernel bug: sometimes, the file
    # descriptor of a pipe closed in the parent process is valid in the
    # child process according to fstat(), but the mode of the file
    # descriptor is invalid, and read or write raise an error.
    @support.requires_mac_ver(10, 5)
    def test_pass_fds(self) -> None:
        fd_status = support.findfile("fd_status.py", subdir="subprocessdata")

        open_fds = Set[int]()

        for x in range(5):
            fds = os.pipe()
            self.addCleanup(os.close, fds[0])
            self.addCleanup(os.close, fds[1])
            open_fds.update([fds[0], fds[1]])

        for fd in open_fds:
            p = subprocess.Popen([sys.executable, fd_status],
                                 stdout=subprocess.PIPE, close_fds=True,
                                 pass_fds=(fd, ))
            output, ignored = p.communicate()

            remaining_fds = set(map(int, output.split(b',')))
            to_be_closed = open_fds - {fd}

            self.assertIn(fd, remaining_fds, "fd to be passed not passed")
            self.assertFalse(remaining_fds & to_be_closed,
                             "fd to be closed passed")

            # pass_fds overrides close_fds with a warning.
            with self.assertWarns(RuntimeWarning) as context:
                self.assertFalse(subprocess.call(
                        [sys.executable, "-c", "import sys; sys.exit(0)"],
                        close_fds=False, pass_fds=(fd, )))
            self.assertIn('overriding close_fds', str(context.warning))

    def test_stdout_stdin_are_single_inout_fd(self) -> None:
        with io.open(os.devnull, "r+") as inout:
            p = subprocess.Popen([sys.executable, "-c", "import sys; sys.exit(0)"],
                                 stdout=inout, stdin=inout)
            p.wait()

    def test_stdout_stderr_are_single_inout_fd(self) -> None:
        with io.open(os.devnull, "r+") as inout:
            p = subprocess.Popen([sys.executable, "-c", "import sys; sys.exit(0)"],
                                 stdout=inout, stderr=inout)
            p.wait()

    def test_stderr_stdin_are_single_inout_fd(self) -> None:
        with io.open(os.devnull, "r+") as inout:
            p = subprocess.Popen([sys.executable, "-c", "import sys; sys.exit(0)"],
                                 stderr=inout, stdin=inout)
            p.wait()

    def test_wait_when_sigchild_ignored(self) -> None:
        # NOTE: sigchild_ignore.py may not be an effective test on all OSes.
        sigchild_ignore = support.findfile("sigchild_ignore.py",
                                           subdir="subprocessdata")
        p = subprocess.Popen([sys.executable, sigchild_ignore],
                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        stdout, stderr = p.communicate()
        self.assertEqual(0, p.returncode, "sigchild_ignore.py exited"
                         " non-zero with this error:\n%s" %
                         stderr.decode('utf8'))

    def test_select_unbuffered(self) -> None:
        # Issue #11459: bufsize=0 should really set the pipes as
        # unbuffered (and therefore let select() work properly).
        select = support.import_module("select")
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys;'
                              'sys.stdout.write("apple")'],
                             stdout=subprocess.PIPE,
                             bufsize=0)
        f = p.stdout
        self.addCleanup(f.close)
        try:
            self.assertEqual(f.read(4), b"appl")
            self.assertIn(f, select.select([f], [], [], 0.0)[0])
        finally:
            p.wait()

    def test_zombie_fast_process_del(self) -> None:
        # Issue #12650: on Unix, if Popen.__del__() was called before the
        # process exited, it wouldn't be added to subprocess._active, and would
        # remain a zombie.
        # spawn a Popen, and delete its reference before it exits
        p = subprocess.Popen([sys.executable, "-c",
                              'import sys, time;'
                              'time.sleep(0.2)'],
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)
        self.addCleanup(p.stdout.close)
        self.addCleanup(p.stderr.close)
        ident = id(p)
        pid = p.pid
        del p
        # check that p is in the active processes list
        self.assertIn(ident, [id(o) for o in subprocess._active])

    def test_leak_fast_process_del_killed(self) -> None:
        # Issue #12650: on Unix, if Popen.__del__() was called before the
        # process exited, and the process got killed by a signal, it would never
        # be removed from subprocess._active, which triggered a FD and memory
        # leak.
        # spawn a Popen, delete its reference and kill it
        p = subprocess.Popen([sys.executable, "-c",
                              'import time;'
                              'time.sleep(3)'],
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)
        self.addCleanup(p.stdout.close)
        self.addCleanup(p.stderr.close)
        ident = id(p)
        pid = p.pid
        del p
        os.kill(pid, signal.SIGKILL)
        # check that p is in the active processes list
        self.assertIn(ident, [id(o) for o in subprocess._active])

        # let some time for the process to exit, and create a new Popen: this
        # should trigger the wait() of p
        time.sleep(0.2)
        with self.assertRaises(EnvironmentError) as c:
            with subprocess.Popen(['nonexisting_i_hope'],
                                  stdout=subprocess.PIPE,
                                  stderr=subprocess.PIPE) as proc:
                pass
        # p should have been wait()ed on, and removed from the _active list
        self.assertRaises(OSError, os.waitpid, pid, 0)
        self.assertNotIn(ident, [id(o) for o in subprocess._active])


@unittest.skipUnless(mswindows, "Windows specific tests")
class Win32ProcessTestCase(BaseTestCase):

    def test_startupinfo(self) -> None:
        # startupinfo argument
        # We uses hardcoded constants, because we do not want to
        # depend on win32all.
        STARTF_USESHOWWINDOW = 1
        SW_MAXIMIZE = 3
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags = STARTF_USESHOWWINDOW
        startupinfo.wShowWindow = SW_MAXIMIZE
        # Since Python is a console process, it won't be affected
        # by wShowWindow, but the argument should be silently
        # ignored
        subprocess.call([sys.executable, "-c", "import sys; sys.exit(0)"],
                        startupinfo=startupinfo)

    def test_creationflags(self) -> None:
        # creationflags argument
        CREATE_NEW_CONSOLE = 16
        sys.stderr.write("    a DOS box should flash briefly ...\n")
        subprocess.call(sys.executable +
                        ' -c "import time; time.sleep(0.25)"',
                        creationflags=CREATE_NEW_CONSOLE)

    def test_invalid_args(self) -> None:
        # invalid arguments should raise ValueError
        self.assertRaises(ValueError, subprocess.call,
                          [sys.executable, "-c",
                           "import sys; sys.exit(47)"],
                          preexec_fn=lambda: 1)
        self.assertRaises(ValueError, subprocess.call,
                          [sys.executable, "-c",
                           "import sys; sys.exit(47)"],
                          stdout=subprocess.PIPE,
                          close_fds=True)

    def test_close_fds(self) -> None:
        # close file descriptors
        rc = subprocess.call([sys.executable, "-c",
                              "import sys; sys.exit(47)"],
                              close_fds=True)
        self.assertEqual(rc, 47)

    def test_shell_sequence(self) -> None:
        # Run command through the shell (sequence)
        newenv = os.environ.copy()
        newenv["FRUIT"] = "physalis"
        p = subprocess.Popen(["set"], shell=1,
                             stdout=subprocess.PIPE,
                             env=newenv)
        self.addCleanup(p.stdout.close)
        self.assertIn(b"physalis", p.stdout.read())

    def test_shell_string(self) -> None:
        # Run command through the shell (string)
        newenv = os.environ.copy()
        newenv["FRUIT"] = "physalis"
        p = subprocess.Popen("set", shell=1,
                             stdout=subprocess.PIPE,
                             env=newenv)
        self.addCleanup(p.stdout.close)
        self.assertIn(b"physalis", p.stdout.read())

    def test_call_string(self) -> None:
        # call() function with string argument on Windows
        rc = subprocess.call(sys.executable +
                             ' -c "import sys; sys.exit(47)"')
        self.assertEqual(rc, 47)

    def _kill_process(self, method: str, *args: Any) -> None:
        # Some win32 buildbot raises EOFError if stdin is inherited
        p = subprocess.Popen([sys.executable, "-c", """if 1:
                             import sys, time
                             sys.stdout.write('x\\n')
                             sys.stdout.flush()
                             time.sleep(30)
                             """],
                             stdin=subprocess.PIPE,
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)
        self.addCleanup(p.stdout.close)
        self.addCleanup(p.stderr.close)
        self.addCleanup(p.stdin.close)
        # Wait for the interpreter to be completely initialized before
        # sending any signal.
        p.stdout.read(1)
        getattr(p, method)(*args)
        _, stderr = p.communicate()
        self.assertStderrEqual(stderr, b'')
        returncode = p.wait()
        self.assertNotEqual(returncode, 0)

    def test_send_signal(self) -> None:
        self._kill_process('send_signal', signal.SIGTERM)

    def test_kill(self) -> None:
        self._kill_process('kill')

    def test_terminate(self) -> None:
        self._kill_process('terminate')


# The module says:
#   "NB This only works (and is only relevant) for UNIX."
#
# Actually, getoutput should work on any platform with an os.popen, but
# I'll take the comment as given, and skip this suite.
@unittest.skipUnless(os.name == 'posix', "only relevant for UNIX")
class CommandTests(unittest.TestCase):
    def test_getoutput(self) -> None:
        self.assertEqual(subprocess.getoutput('echo xyzzy'), 'xyzzy')
        self.assertEqual(subprocess.getstatusoutput('echo xyzzy'),
                         (0, 'xyzzy'))

        # we use mkdtemp in the next line to create an empty directory
        # under our exclusive control; from that, we can invent a pathname
        # that we _know_ won't exist.  This is guaranteed to fail.
        dir = None # type: str
        try:
            dir = tempfile.mkdtemp()
            name = os.path.join(dir, "foo")

            status, output = subprocess.getstatusoutput('cat ' + name)
            self.assertNotEqual(status, 0)
        finally:
            if dir is not None:
                os.rmdir(dir)


@unittest.skipUnless(getattr(subprocess, '_has_poll', False),
                     "poll system call not supported")
class ProcessTestCaseNoPoll(ProcessTestCase):
    def setUp(self) -> None:
        subprocess._has_poll = False
        ProcessTestCase.setUp(self)

    def tearDown(self) -> None:
        subprocess._has_poll = True
        ProcessTestCase.tearDown(self)


#@unittest.skipUnless(getattr(subprocess, '_posixsubprocess', False),
#                     "_posixsubprocess extension module not found.")
#class ProcessTestCasePOSIXPurePython(ProcessTestCase, POSIXProcessTestCase):
#    @classmethod
#    def setUpClass(cls):
#        global subprocess
#        assert subprocess._posixsubprocess
#        # Reimport subprocess while forcing _posixsubprocess to not exist.
#        with support.check_warnings(('.*_posixsubprocess .* not being used.*',
#                                     RuntimeWarning)):
#            subprocess = support.import_fresh_module(
#                    'subprocess', blocked=['_posixsubprocess'])
#        assert not subprocess._posixsubprocess
#
#    @classmethod
#    def tearDownClass(cls):
#        global subprocess
#        # Reimport subprocess as it should be, restoring order to the universe#.
#        subprocess = support.import_fresh_module('subprocess')
#        assert subprocess._posixsubprocess


class HelperFunctionTests(unittest.TestCase):
    @unittest.skipIf(mswindows, "errno and EINTR make no sense on windows")
    def test_eintr_retry_call(self) -> None:
        record_calls = List[Any]()
        def fake_os_func(*args: Any) -> tuple:
            record_calls.append(args)
            if len(record_calls) == 2:
                raise OSError(errno.EINTR, "fake interrupted system call")
            return tuple(reversed(args))

        self.assertEqual((999, 256),
                         subprocess._eintr_retry_call(fake_os_func, 256, 999))
        self.assertEqual([(256, 999)], record_calls)
        # This time there will be an EINTR so it will loop once.
        self.assertEqual((666,),
                         subprocess._eintr_retry_call(fake_os_func, 666))
        self.assertEqual([(256, 999), (666,), (666,)], record_calls)


@unittest.skipUnless(mswindows, "Windows-specific tests")
class CommandsWithSpaces (BaseTestCase):

    def setUp(self) -> None:
        super().setUp()
        f, fname = mkstemp(".py", "te st")
        self.fname = fname.lower ()
        os.write(f, b"import sys;"
                    b"sys.stdout.write('%d %s' % (len(sys.argv), [a.lower () for a in sys.argv]))"
        )
        os.close(f)

    def tearDown(self) -> None:
        os.remove(self.fname)
        super().tearDown()

    def with_spaces(self, *args: Any, **kwargs: Any) -> None:
        kwargs['stdout'] = subprocess.PIPE
        p = subprocess.Popen(*args, **kwargs)
        self.addCleanup(p.stdout.close)
        self.assertEqual(
          p.stdout.read ().decode("mbcs"),
          "2 [%r, 'ab cd']" % self.fname
        )

    def test_shell_string_with_spaces(self) -> None:
        # call() function with string argument with spaces on Windows
        self.with_spaces('"%s" "%s" "%s"' % (sys.executable, self.fname,
                                             "ab cd"), shell=1)

    def test_shell_sequence_with_spaces(self) -> None:
        # call() function with sequence argument with spaces on Windows
        self.with_spaces([sys.executable, self.fname, "ab cd"], shell=1)

    def test_noshell_string_with_spaces(self) -> None:
        # call() function with string argument with spaces on Windows
        self.with_spaces('"%s" "%s" "%s"' % (sys.executable, self.fname,
                             "ab cd"))

    def test_noshell_sequence_with_spaces(self) -> None:
        # call() function with sequence argument with spaces on Windows
        self.with_spaces([sys.executable, self.fname, "ab cd"])


class ContextManagerTests(BaseTestCase):

    def test_pipe(self) -> None:
        with subprocess.Popen([sys.executable, "-c",
                               "import sys;"
                               "sys.stdout.write('stdout');"
                               "sys.stderr.write('stderr');"],
                              stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE) as proc:
            self.assertEqual(proc.stdout.read(), b"stdout")
            self.assertStderrEqual(proc.stderr.read(), b"stderr")

        self.assertTrue(proc.stdout.closed)
        self.assertTrue(proc.stderr.closed)

    def test_returncode(self) -> None:
        with subprocess.Popen([sys.executable, "-c",
                               "import sys; sys.exit(100)"]) as proc:
            pass
        # __exit__ calls wait(), so the returncode should be set
        self.assertEqual(proc.returncode, 100)

    def test_communicate_stdin(self) -> None:
        with subprocess.Popen([sys.executable, "-c",
                              "import sys;"
                              "sys.exit(sys.stdin.read() == 'context')"],
                             stdin=subprocess.PIPE) as proc:
            proc.communicate(b"context")
            self.assertEqual(proc.returncode, 1)

    def test_invalid_args(self) -> None:
        with self.assertRaises(EnvironmentError) as c:
            with subprocess.Popen(['nonexisting_i_hope'],
                                  stdout=subprocess.PIPE,
                                  stderr=subprocess.PIPE) as proc:
                pass

            if c.exception.errno != errno.ENOENT:  # ignore "no such file"
                raise c.exception


def test_main():
    unit_tests = (ProcessTestCase,
                  POSIXProcessTestCase,
                  Win32ProcessTestCase,
                  #ProcessTestCasePOSIXPurePython,
                  CommandTests,
                  ProcessTestCaseNoPoll,
                  HelperFunctionTests,
                  CommandsWithSpaces,
                  ContextManagerTests,
                  )

    support.run_unittest(*unit_tests)
    support.reap_children()

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_tempfile
# tempfile.py unit tests.
import tempfile
import os
import signal
import sys
import re
import warnings

import unittest
from test import support

from typing import Any, AnyStr, List, Dict, IO


if hasattr(os, 'stat'):
    import stat
    has_stat = 1
else:
    has_stat = 0

has_textmode = (tempfile._text_openflags != tempfile._bin_openflags)
has_spawnl = hasattr(os, 'spawnl')

# TEST_FILES may need to be tweaked for systems depending on the maximum
# number of files that can be opened at one time (see ulimit -n)
if sys.platform in ('openbsd3', 'openbsd4'):
    TEST_FILES = 48
else:
    TEST_FILES = 100

# This is organized as one test for each chunk of code in tempfile.py,
# in order of their appearance in the file.  Testing which requires
# threads is not done here.

# Common functionality.
class TC(unittest.TestCase):

    str_check = re.compile(r"[a-zA-Z0-9_-]{6}$")

    def setUp(self) -> None:
        self._warnings_manager = support.check_warnings()
        self._warnings_manager.__enter__()
        warnings.filterwarnings("ignore", category=RuntimeWarning,
                                message="mktemp", module=__name__)

    def tearDown(self) -> None:
        self._warnings_manager.__exit__(None, None, None)


    def failOnException(self, what: str, ei: tuple = None) -> None:
        if ei is None:
            ei = sys.exc_info()
        self.fail("%s raised %s: %s" % (what, ei[0], ei[1]))

    def nameCheck(self, name: str, dir: str, pre: str, suf: str) -> None:
        (ndir, nbase) = os.path.split(name)
        npre  = nbase[:len(pre)]
        nsuf  = nbase[len(nbase)-len(suf):]

        # check for equality of the absolute paths!
        self.assertEqual(os.path.abspath(ndir), os.path.abspath(dir),
                         "file '%s' not in directory '%s'" % (name, dir))
        self.assertEqual(npre, pre,
                         "file '%s' does not begin with '%s'" % (nbase, pre))
        self.assertEqual(nsuf, suf,
                         "file '%s' does not end with '%s'" % (nbase, suf))

        nbase = nbase[len(pre):len(nbase)-len(suf)]
        self.assertTrue(self.str_check.match(nbase),
                     "random string '%s' does not match /^[a-zA-Z0-9_-]{6}$/"
                     % nbase)

test_classes = [] # type: List[type]

class test_exports(TC):
    def test_exports(self) -> None:
        # There are no surprising symbols in the tempfile module
        dict = tempfile.__dict__

        expected = {
            "NamedTemporaryFile" : 1,
            "TemporaryFile" : 1,
            "mkstemp" : 1,
            "mkdtemp" : 1,
            "mktemp" : 1,
            "TMP_MAX" : 1,
            "gettempprefix" : 1,
            "gettempdir" : 1,
            "tempdir" : 1,
            "template" : 1,
            "SpooledTemporaryFile" : 1,
            "TemporaryDirectory" : 1,
        }

        unexp = List[str]()
        for key in dict:
            if key[0] != '_' and key not in expected:
                unexp.append(key)
        self.assertTrue(len(unexp) == 0,
                        "unexpected keys: %s" % unexp)

test_classes.append(test_exports)


class test__RandomNameSequence(TC):
    """Test the internal iterator object _RandomNameSequence."""

    def setUp(self) -> None:
        self.r = tempfile._RandomNameSequence()
        super().setUp()

    def test_get_six_char_str(self) -> None:
        # _RandomNameSequence returns a six-character string
        s = next(self.r)
        self.nameCheck(s, '', '', '')

    def test_many(self) -> None:
        # _RandomNameSequence returns no duplicate strings (stochastic)

        dict = Dict[str, int]()
        r = self.r
        for i in range(TEST_FILES):
            s = next(r)
            self.nameCheck(s, '', '', '')
            self.assertNotIn(s, dict)
            dict[s] = 1

    def supports_iter(self) -> None:
        # _RandomNameSequence supports the iterator protocol

        i = 0
        r = self.r
        try:
            for s in r:
                i += 1
                if i == 20:
                    break
        except:
            self.failOnException("iteration")

    @unittest.skipUnless(hasattr(os, 'fork'),
        "os.fork is required for this test")
    def test_process_awareness(self) -> None:
        # ensure that the random source differs between
        # child and parent.
        read_fd, write_fd = os.pipe()
        pid = None # type: int
        try:
            pid = os.fork()
            if not pid:
                os.close(read_fd)
                os.write(write_fd, next(self.r).encode("ascii"))
                os.close(write_fd)
                # bypass the normal exit handlers- leave those to
                # the parent.
                os._exit(0)
            parent_value = next(self.r)
            child_value = os.read(read_fd, len(parent_value)).decode("ascii")
        finally:
            if pid:
                # best effort to ensure the process can't bleed out
                # via any bugs above
                try:
                    os.kill(pid, signal.SIGKILL)
                except EnvironmentError:
                    pass
            os.close(read_fd)
            os.close(write_fd)
        self.assertNotEqual(child_value, parent_value)


test_classes.append(test__RandomNameSequence)


class test__candidate_tempdir_list(TC):
    """Test the internal function _candidate_tempdir_list."""

    def test_nonempty_list(self) -> None:
        # _candidate_tempdir_list returns a nonempty list of strings

        cand = tempfile._candidate_tempdir_list()

        self.assertFalse(len(cand) == 0)
        for c in cand:
            self.assertIsInstance(c, str)

    def test_wanted_dirs(self) -> None:
        # _candidate_tempdir_list contains the expected directories

        # Make sure the interesting environment variables are all set.
        with support.EnvironmentVarGuard() as env:
            for envname in 'TMPDIR', 'TEMP', 'TMP':
                dirname = os.getenv(envname)
                if not dirname:
                    env[envname] = os.path.abspath(envname)

            cand = tempfile._candidate_tempdir_list()

            for envname in 'TMPDIR', 'TEMP', 'TMP':
                dirname = os.getenv(envname)
                if not dirname: raise ValueError
                self.assertIn(dirname, cand)

            try:
                dirname = os.getcwd()
            except (AttributeError, os.error):
                dirname = os.curdir

            self.assertIn(dirname, cand)

            # Not practical to try to verify the presence of OS-specific
            # paths in this list.

test_classes.append(test__candidate_tempdir_list)


# We test _get_default_tempdir by testing gettempdir.


class test__get_candidate_names(TC):
    """Test the internal function _get_candidate_names."""

    def test_retval(self) -> None:
        # _get_candidate_names returns a _RandomNameSequence object
        obj = tempfile._get_candidate_names()
        self.assertIsInstance(obj, tempfile._RandomNameSequence)

    def test_same_thing(self) -> None:
        # _get_candidate_names always returns the same object
        a = tempfile._get_candidate_names()
        b = tempfile._get_candidate_names()

        self.assertTrue(a is b)

test_classes.append(test__get_candidate_names)


class test__mkstemp_inner(TC):
    """Test the internal function _mkstemp_inner."""

    class mkstemped:
        _bflags = tempfile._bin_openflags
        _tflags = tempfile._text_openflags

        def __init__(self, dir: str, pre: str, suf: str, bin: int) -> None:
            if bin: flags = self._bflags
            else:   flags = self._tflags

            (self.fd, self.name) = tempfile._mkstemp_inner(dir, pre, suf, flags)
        
            self._close = os.close
            self._unlink = os.unlink

        def write(self, str: bytes) -> None:
            os.write(self.fd, str)

        def __del__(self) -> None:
            self._close(self.fd)
            self._unlink(self.name)

    def do_create(self, dir: str = None, pre: str = "", suf: str= "",
                  bin: int = 1) -> mkstemped:
        if dir is None:
            dir = tempfile.gettempdir()
        try:
            file = test__mkstemp_inner.mkstemped(dir, pre, suf, bin) # see #259
        except:
            self.failOnException("_mkstemp_inner")

        self.nameCheck(file.name, dir, pre, suf)
        return file

    def test_basic(self) -> None:
        # _mkstemp_inner can create files
        self.do_create().write(b"blat")
        self.do_create(pre="a").write(b"blat")
        self.do_create(suf="b").write(b"blat")
        self.do_create(pre="a", suf="b").write(b"blat")
        self.do_create(pre="aa", suf=".txt").write(b"blat")

    def test_basic_many(self) -> None:
        # _mkstemp_inner can create many files (stochastic)
        extant = List[Any](range(TEST_FILES))
        for i in extant:
            extant[i] = self.do_create(pre="aa")

    def test_choose_directory(self) -> None:
        # _mkstemp_inner can create files in a user-selected directory
        dir = tempfile.mkdtemp()
        try:
            self.do_create(dir=dir).write(b"blat")
        finally:
            os.rmdir(dir)

    def test_file_mode(self) -> None:
        # _mkstemp_inner creates files with the proper mode
        if not has_stat:
            return            # ugh, can't use SkipTest.

        file = self.do_create()
        mode = stat.S_IMODE(os.stat(file.name).st_mode)
        expected = 0o600
        if sys.platform in ('win32', 'os2emx'):
            # There's no distinction among 'user', 'group' and 'world';
            # replicate the 'user' bits.
            user = expected >> 6
            expected = user * (1 + 8 + 64)
        self.assertEqual(mode, expected)

    def test_noinherit(self) -> None:
        # _mkstemp_inner file handles are not inherited by child processes
        if not has_spawnl:
            return            # ugh, can't use SkipTest.

        if support.verbose:
            v="v"
        else:
            v="q"

        file = self.do_create()
        fd = "%d" % file.fd

        try:
            me = __file__ # type: str
        except NameError:
            me = sys.argv[0]

        # We have to exec something, so that FD_CLOEXEC will take
        # effect.  The core of this test is therefore in
        # tf_inherit_check.py, which see.
        tester = os.path.join(os.path.dirname(os.path.abspath(me)),
                              "tf_inherit_check.py")

        # On Windows a spawn* /path/ with embedded spaces shouldn't be quoted,
        # but an arg with embedded spaces should be decorated with double
        # quotes on each end
        if sys.platform in ('win32',):
            decorated = '"%s"' % sys.executable
            tester = '"%s"' % tester
        else:
            decorated = sys.executable

        retval = os.spawnl(os.P_WAIT, sys.executable, decorated, tester, v, fd)
        self.assertFalse(retval < 0,
                    "child process caught fatal signal %d" % -retval)
        self.assertFalse(retval > 0, "child process reports failure %d"%retval)

    def test_textmode(self) -> None:
        # _mkstemp_inner can create files in text mode
        if not has_textmode:
            return            # ugh, can't use SkipTest.

        # A text file is truncated at the first Ctrl+Z byte
        f = self.do_create(bin=0)
        f.write(b"blat\x1a")
        f.write(b"extra\n")
        os.lseek(f.fd, 0, os.SEEK_SET)
        self.assertEqual(os.read(f.fd, 20), b"blat")

test_classes.append(test__mkstemp_inner)


class test_gettempprefix(TC):
    """Test gettempprefix()."""

    def test_sane_template(self) -> None:
        # gettempprefix returns a nonempty prefix string
        p = tempfile.gettempprefix()

        self.assertIsInstance(p, str)
        self.assertTrue(len(p) > 0)

    def test_usable_template(self) -> None:
        # gettempprefix returns a usable prefix string

        # Create a temp directory, avoiding use of the prefix.
        # Then attempt to create a file whose name is
        # prefix + 'xxxxxx.xxx' in that directory.
        p = tempfile.gettempprefix() + "xxxxxx.xxx"
        d = tempfile.mkdtemp(prefix="")
        try:
            p = os.path.join(d, p)
            try:
                fd = os.open(p, os.O_RDWR | os.O_CREAT)
            except:
                self.failOnException("os.open")
            os.close(fd)
            os.unlink(p)
        finally:
            os.rmdir(d)

test_classes.append(test_gettempprefix)


class test_gettempdir(TC):
    """Test gettempdir()."""

    def test_directory_exists(self) -> None:
        # gettempdir returns a directory which exists

        dir = tempfile.gettempdir()
        self.assertTrue(os.path.isabs(dir) or dir == os.curdir,
                     "%s is not an absolute path" % dir)
        self.assertTrue(os.path.isdir(dir),
                     "%s is not a directory" % dir)

    def test_directory_writable(self) -> None:
        # gettempdir returns a directory writable by the user

        # sneaky: just instantiate a NamedTemporaryFile, which
        # defaults to writing into the directory returned by
        # gettempdir.
        try:
            file = tempfile.NamedTemporaryFile()
            file.write(b"blat")
            file.close()
        except:
            self.failOnException("create file in %s" % tempfile.gettempdir())

    def test_same_thing(self) -> None:
        # gettempdir always returns the same object
        a = tempfile.gettempdir()
        b = tempfile.gettempdir()

        self.assertTrue(a is b)

test_classes.append(test_gettempdir)


class test_mkstemp(TC):
    """Test mkstemp()."""

    def do_create(self, dir: str = None, pre: str = "", suf: str = "") -> None:
        if dir is None:
            dir = tempfile.gettempdir()
        try:
            (fd, name) = tempfile.mkstemp(dir=dir, prefix=pre, suffix=suf)
            (ndir, nbase) = os.path.split(name)
            adir = os.path.abspath(dir)
            self.assertEqual(adir, ndir,
                "Directory '%s' incorrectly returned as '%s'" % (adir, ndir))
        except:
            self.failOnException("mkstemp")

        try:
            self.nameCheck(name, dir, pre, suf)
        finally:
            os.close(fd)
            os.unlink(name)

    def test_basic(self) -> None:
        # mkstemp can create files
        self.do_create()
        self.do_create(pre="a")
        self.do_create(suf="b")
        self.do_create(pre="a", suf="b")
        self.do_create(pre="aa", suf=".txt")
        self.do_create(dir=".")

    def test_choose_directory(self) -> None:
        # mkstemp can create directories in a user-selected directory
        dir = tempfile.mkdtemp()
        try:
            self.do_create(dir=dir)
        finally:
            os.rmdir(dir)

test_classes.append(test_mkstemp)


class test_mkdtemp(TC):
    """Test mkdtemp()."""

    def do_create(self, dir: str = None, pre: str = "", suf: str = "") -> str:
        if dir is None:
            dir = tempfile.gettempdir()
        try:
            name = tempfile.mkdtemp(dir=dir, prefix=pre, suffix=suf)
        except:
            self.failOnException("mkdtemp")

        try:
            self.nameCheck(name, dir, pre, suf)
            return name
        except:
            os.rmdir(name)
            raise

    def test_basic(self) -> None:
        # mkdtemp can create directories
        os.rmdir(self.do_create())
        os.rmdir(self.do_create(pre="a"))
        os.rmdir(self.do_create(suf="b"))
        os.rmdir(self.do_create(pre="a", suf="b"))
        os.rmdir(self.do_create(pre="aa", suf=".txt"))

    def test_basic_many(self) -> None:
        # mkdtemp can create many directories (stochastic)
        extant = List[Any](range(TEST_FILES))
        try:
            for i in extant:
                extant[i] = self.do_create(pre="aa")
        finally:
            for i in extant:
                if(isinstance(i, str)):
                    os.rmdir(i)

    def test_choose_directory(self) -> None:
        # mkdtemp can create directories in a user-selected directory
        dir = tempfile.mkdtemp()
        try:
            os.rmdir(self.do_create(dir=dir))
        finally:
            os.rmdir(dir)

    def test_mode(self) -> None:
        # mkdtemp creates directories with the proper mode
        if not has_stat:
            return            # ugh, can't use SkipTest.

        dir = self.do_create()
        try:
            mode = stat.S_IMODE(os.stat(dir).st_mode)
            mode &= 0o777 # Mask off sticky bits inherited from /tmp
            expected = 0o700
            if sys.platform in ('win32', 'os2emx'):
                # There's no distinction among 'user', 'group' and 'world';
                # replicate the 'user' bits.
                user = expected >> 6
                expected = user * (1 + 8 + 64)
            self.assertEqual(mode, expected)
        finally:
            os.rmdir(dir)

test_classes.append(test_mkdtemp)


class test_mktemp(TC):
    """Test mktemp()."""

    # For safety, all use of mktemp must occur in a private directory.
    # We must also suppress the RuntimeWarning it generates.
    def setUp(self) -> None:
        self.dir = tempfile.mkdtemp()
        super().setUp()

    def tearDown(self) -> None:
        if self.dir:
            os.rmdir(self.dir)
            self.dir = None
        super().tearDown()

    class mktemped:
        def _unlink(self, path: str) -> None:
            os.unlink(path)
        
        _bflags = tempfile._bin_openflags

        def __init__(self, dir: str, pre: str, suf: str) -> None:
            self.name = tempfile.mktemp(dir=dir, prefix=pre, suffix=suf)
            # Create the file.  This will raise an exception if it's
            # mysteriously appeared in the meanwhile.
            os.close(os.open(self.name, self._bflags, 0o600))

        def __del__(self) -> None:
            self._unlink(self.name)

    def do_create(self, pre: str = "", suf: str = "") -> mktemped:
        try:
            file = test_mktemp.mktemped(self.dir, pre, suf) # see #259
        except:
            self.failOnException("mktemp")

        self.nameCheck(file.name, self.dir, pre, suf)
        return file

    def test_basic(self) -> None:
        # mktemp can choose usable file names
        self.do_create()
        self.do_create(pre="a")
        self.do_create(suf="b")
        self.do_create(pre="a", suf="b")
        self.do_create(pre="aa", suf=".txt")

    def test_many(self) -> None:
        # mktemp can choose many usable file names (stochastic)
        extant = List[Any](range(TEST_FILES))
        for i in extant:
            extant[i] = self.do_create(pre="aa")

##     def test_warning(self):
##         # mktemp issues a warning when used
##         warnings.filterwarnings("error",
##                                 category=RuntimeWarning,
##                                 message="mktemp")
##         self.assertRaises(RuntimeWarning,
##                           tempfile.mktemp, dir=self.dir)

test_classes.append(test_mktemp)


# We test _TemporaryFileWrapper by testing NamedTemporaryFile.


class test_NamedTemporaryFile(TC):
    """Test NamedTemporaryFile()."""

    def do_create(self, dir: str = None, pre: str = "", suf: str = "",
                  delete: bool = True) -> IO[Any]:
        if dir is None:
            dir = tempfile.gettempdir()
        try:
            file = tempfile.NamedTemporaryFile(dir=dir, prefix=pre, suffix=suf,
                                               delete=delete)
        except:
            self.failOnException("NamedTemporaryFile")

        self.nameCheck(file.name, dir, pre, suf)
        return file


    def test_basic(self) -> None:
        # NamedTemporaryFile can create files
        self.do_create()
        self.do_create(pre="a")
        self.do_create(suf="b")
        self.do_create(pre="a", suf="b")
        self.do_create(pre="aa", suf=".txt")

    def test_creates_named(self) -> None:
        # NamedTemporaryFile creates files with names
        f = tempfile.NamedTemporaryFile()
        self.assertTrue(os.path.exists(f.name),
                        "NamedTemporaryFile %s does not exist" % f.name)

    def test_del_on_close(self) -> None:
        # A NamedTemporaryFile is deleted when closed
        dir = tempfile.mkdtemp()
        try:
            f = tempfile.NamedTemporaryFile(dir=dir)
            f.write(b'blat')
            f.close()
            self.assertFalse(os.path.exists(f.name),
                        "NamedTemporaryFile %s exists after close" % f.name)
        finally:
            os.rmdir(dir)

    def test_dis_del_on_close(self) -> None:
        # Tests that delete-on-close can be disabled
        dir = tempfile.mkdtemp()
        tmp = None # type: str
        try:
            f = tempfile.NamedTemporaryFile(dir=dir, delete=False)
            tmp = f.name
            f.write(b'blat')
            f.close()
            self.assertTrue(os.path.exists(f.name),
                        "NamedTemporaryFile %s missing after close" % f.name)
        finally:
            if tmp is not None:
                os.unlink(tmp)
            os.rmdir(dir)

    def test_multiple_close(self) -> None:
        # A NamedTemporaryFile can be closed many times without error
        f = tempfile.NamedTemporaryFile()
        f.write(b'abc\n')
        f.close()
        try:
            f.close()
            f.close()
        except:
            self.failOnException("close")

    def test_context_manager(self) -> None:
        # A NamedTemporaryFile can be used as a context manager
        with tempfile.NamedTemporaryFile() as f:
            self.assertTrue(os.path.exists(f.name))
        self.assertFalse(os.path.exists(f.name))
        def use_closed():
            with f:
                pass
        self.assertRaises(ValueError, use_closed)

    # How to test the mode and bufsize parameters?

test_classes.append(test_NamedTemporaryFile)

class test_SpooledTemporaryFile(TC):
    """Test SpooledTemporaryFile()."""

    def do_create(self, max_size: int = 0, dir: str = None, pre: str = "",
                  suf: str = "") -> tempfile.SpooledTemporaryFile:
        if dir is None:
            dir = tempfile.gettempdir()
        try:
            file = tempfile.SpooledTemporaryFile(max_size=max_size, dir=dir, prefix=pre, suffix=suf)
        except:
            self.failOnException("SpooledTemporaryFile")

        return file


    def test_basic(self) -> None:
        # SpooledTemporaryFile can create files
        f = self.do_create()
        self.assertFalse(f._rolled)
        f = self.do_create(max_size=100, pre="a", suf=".txt")
        self.assertFalse(f._rolled)

    def test_del_on_close(self) -> None:
        # A SpooledTemporaryFile is deleted when closed
        dir = tempfile.mkdtemp()
        try:
            f = tempfile.SpooledTemporaryFile(max_size=10, dir=dir)
            self.assertFalse(f._rolled)
            f.write(b'blat ' * 5)
            self.assertTrue(f._rolled)
            filename = f.name
            f.close()
            self.assertFalse(isinstance(filename, str) and os.path.exists(filename),
                        "SpooledTemporaryFile %s exists after close" % filename)
        finally:
            os.rmdir(dir)

    def test_rewrite_small(self) -> None:
        # A SpooledTemporaryFile can be written to multiple within the max_size
        f = self.do_create(max_size=30)
        self.assertFalse(f._rolled)
        for i in range(5):
            f.seek(0, 0)
            f.write(b'x' * 20)
        self.assertFalse(f._rolled)

    def test_write_sequential(self) -> None:
        # A SpooledTemporaryFile should hold exactly max_size bytes, and roll
        # over afterward
        f = self.do_create(max_size=30)
        self.assertFalse(f._rolled)
        f.write(b'x' * 20)
        self.assertFalse(f._rolled)
        f.write(b'x' * 10)
        self.assertFalse(f._rolled)
        f.write(b'x')
        self.assertTrue(f._rolled)

    def test_writelines(self) -> None:
        # Verify writelines with a SpooledTemporaryFile
        f = self.do_create()
        f.writelines([b'x', b'y', b'z'])
        f.seek(0)
        buf = f.read()
        self.assertEqual(buf, b'xyz')

    def test_writelines_sequential(self) -> None:
        # A SpooledTemporaryFile should hold exactly max_size bytes, and roll
        # over afterward
        f = self.do_create(max_size=35)
        f.writelines([b'x' * 20, b'x' * 10, b'x' * 5])
        self.assertFalse(f._rolled)
        f.write(b'x')
        self.assertTrue(f._rolled)

    def test_sparse(self) -> None:
        # A SpooledTemporaryFile that is written late in the file will extend
        # when that occurs
        f = self.do_create(max_size=30)
        self.assertFalse(f._rolled)
        f.seek(100, 0)
        self.assertFalse(f._rolled)
        f.write(b'x')
        self.assertTrue(f._rolled)

    def test_fileno(self) -> None:
        # A SpooledTemporaryFile should roll over to a real file on fileno()
        f = self.do_create(max_size=30)
        self.assertFalse(f._rolled)
        self.assertTrue(f.fileno() > 0)
        self.assertTrue(f._rolled)

    def test_multiple_close_before_rollover(self) -> None:
        # A SpooledTemporaryFile can be closed many times without error
        f = tempfile.SpooledTemporaryFile()
        f.write(b'abc\n')
        self.assertFalse(f._rolled)
        f.close()
        try:
            f.close()
            f.close()
        except:
            self.failOnException("close")

    def test_multiple_close_after_rollover(self) -> None:
        # A SpooledTemporaryFile can be closed many times without error
        f = tempfile.SpooledTemporaryFile(max_size=1)
        f.write(b'abc\n')
        self.assertTrue(f._rolled)
        f.close()
        try:
            f.close()
            f.close()
        except:
            self.failOnException("close")

    def test_bound_methods(self) -> None:
        # It should be OK to steal a bound method from a SpooledTemporaryFile
        # and use it independently; when the file rolls over, those bound
        # methods should continue to function
        f = self.do_create(max_size=30)
        read = f.read
        write = f.write
        seek = f.seek

        write(b"a" * 35)
        write(b"b" * 35)
        seek(0, 0)
        self.assertEqual(read(70), b'a'*35 + b'b'*35)

    def test_text_mode(self) -> None:
        # Creating a SpooledTemporaryFile with a text mode should produce
        # a file object reading and writing (Unicode) text strings.
        f = tempfile.SpooledTemporaryFile(mode='w+', max_size=10)
        f.write("abc\n")
        f.seek(0)
        self.assertEqual(f.read(), "abc\n")
        f.write("def\n")
        f.seek(0)
        self.assertEqual(f.read(), "abc\ndef\n")
        f.write("xyzzy\n")
        f.seek(0)
        self.assertEqual(f.read(), "abc\ndef\nxyzzy\n")
        # Check that Ctrl+Z doesn't truncate the file
        f.write("foo\x1abar\n")
        f.seek(0)
        self.assertEqual(f.read(), "abc\ndef\nxyzzy\nfoo\x1abar\n")

    def test_text_newline_and_encoding(self) -> None:
        f = tempfile.SpooledTemporaryFile(mode='w+', max_size=10,
                                          newline='', encoding='utf-8')
        f.write("\u039B\r\n")
        f.seek(0)
        self.assertEqual(f.read(), "\u039B\r\n")
        self.assertFalse(f._rolled)

        f.write("\u039B" * 20 + "\r\n")
        f.seek(0)
        self.assertEqual(f.read(), "\u039B\r\n" + ("\u039B" * 20) + "\r\n")
        self.assertTrue(f._rolled)

    def test_context_manager_before_rollover(self) -> None:
        # A SpooledTemporaryFile can be used as a context manager
        with tempfile.SpooledTemporaryFile(max_size=1) as f:
            self.assertFalse(f._rolled)
            self.assertFalse(f.closed)
        self.assertTrue(f.closed)
        def use_closed():
            with f:
                pass
        self.assertRaises(ValueError, use_closed)

    def test_context_manager_during_rollover(self) -> None:
        # A SpooledTemporaryFile can be used as a context manager
        with tempfile.SpooledTemporaryFile(max_size=1) as f:
            self.assertFalse(f._rolled)
            f.write(b'abc\n')
            f.flush()
            self.assertTrue(f._rolled)
            self.assertFalse(f.closed)
        self.assertTrue(f.closed)
        def use_closed():
            with f:
                pass
        self.assertRaises(ValueError, use_closed)

    def test_context_manager_after_rollover(self) -> None:
        # A SpooledTemporaryFile can be used as a context manager
        f = tempfile.SpooledTemporaryFile(max_size=1)
        f.write(b'abc\n')
        f.flush()
        self.assertTrue(f._rolled)
        with f:
            self.assertFalse(f.closed)
        self.assertTrue(f.closed)
        def use_closed():
            with f:
                pass
        self.assertRaises(ValueError, use_closed)


test_classes.append(test_SpooledTemporaryFile)


class test_TemporaryFile(TC):
    """Test TemporaryFile()."""

    def test_basic(self) -> None:
        # TemporaryFile can create files
        # No point in testing the name params - the file has no name.
        try:
            tempfile.TemporaryFile()
        except:
            self.failOnException("TemporaryFile")

    def test_has_no_name(self) -> None:
        # TemporaryFile creates files with no names (on this system)
        dir = tempfile.mkdtemp()
        f = tempfile.TemporaryFile(dir=dir)
        f.write(b'blat')

        # Sneaky: because this file has no name, it should not prevent
        # us from removing the directory it was created in.
        try:
            os.rmdir(dir)
        except:
            ei = sys.exc_info()
            # cleanup
            f.close()
            os.rmdir(dir)
            self.failOnException("rmdir", ei)

    def test_multiple_close(self) -> None:
        # A TemporaryFile can be closed many times without error
        f = tempfile.TemporaryFile()
        f.write(b'abc\n')
        f.close()
        try:
            f.close()
            f.close()
        except:
            self.failOnException("close")

    # How to test the mode and bufsize parameters?
    def test_mode_and_encoding(self) -> None:

        def roundtrip(input: AnyStr, *args: Any, **kwargs: Any) -> None:
            with tempfile.TemporaryFile(*args, **kwargs) as fileobj:
                fileobj.write(input)
                fileobj.seek(0)
                self.assertEqual(input, fileobj.read())

        roundtrip(b"1234", "w+b")
        roundtrip("abdc\n", "w+")
        roundtrip("\u039B", "w+", encoding="utf-16")
        roundtrip("foo\r\n", "w+", newline="")


if tempfile.NamedTemporaryFile is not tempfile.TemporaryFile:
    test_classes.append(test_TemporaryFile)


# Helper for test_del_on_shutdown
class NulledModules:
    def __init__(self, *modules: Any) -> None:
        self.refs = [mod.__dict__ for mod in modules]
        self.contents = [ref.copy() for ref in self.refs]

    def __enter__(self) -> None:
        for d in self.refs:
            for key in d:
                d[key] = None

    def __exit__(self, *exc_info: Any) -> None:
        for d, c in zip(self.refs, self.contents):
            d.clear()
            d.update(c)

class test_TemporaryDirectory(TC):
    """Test TemporaryDirectory()."""

    def do_create(self, dir: str = None, pre: str = "", suf: str = "",
                  recurse: int = 1) -> tempfile.TemporaryDirectory:
        if dir is None:
            dir = tempfile.gettempdir()
        try:
            tmp = tempfile.TemporaryDirectory(dir=dir, prefix=pre, suffix=suf)
        except:
            self.failOnException("TemporaryDirectory")
        self.nameCheck(tmp.name, dir, pre, suf)
        # Create a subdirectory and some files
        if recurse:
            self.do_create(tmp.name, pre, suf, recurse-1)
        with open(os.path.join(tmp.name, "test.txt"), "wb") as f:
            f.write(b"Hello world!")
        return tmp

    def test_mkdtemp_failure(self) -> None:
        # Check no additional exception if mkdtemp fails
        # Previously would raise AttributeError instead
        # (noted as part of Issue #10188)
        with tempfile.TemporaryDirectory() as nonexistent:
            pass
        with self.assertRaises(os.error):
            tempfile.TemporaryDirectory(dir=nonexistent)

    def test_explicit_cleanup(self) -> None:
        # A TemporaryDirectory is deleted when cleaned up
        dir = tempfile.mkdtemp()
        try:
            d = self.do_create(dir=dir)
            self.assertTrue(os.path.exists(d.name),
                            "TemporaryDirectory %s does not exist" % d.name)
            d.cleanup()
            self.assertFalse(os.path.exists(d.name),
                        "TemporaryDirectory %s exists after cleanup" % d.name)
        finally:
            os.rmdir(dir)

    @support.skip_unless_symlink
    def test_cleanup_with_symlink_to_a_directory(self) -> None:
        # cleanup() should not follow symlinks to directories (issue #12464)
        d1 = self.do_create()
        d2 = self.do_create()

        # Symlink d1/foo -> d2
        os.symlink(d2.name, os.path.join(d1.name, "foo"))

        # This call to cleanup() should not follow the "foo" symlink
        d1.cleanup()

        self.assertFalse(os.path.exists(d1.name),
                         "TemporaryDirectory %s exists after cleanup" % d1.name)
        self.assertTrue(os.path.exists(d2.name),
                        "Directory pointed to by a symlink was deleted")
        self.assertEqual(os.listdir(d2.name), ['test.txt'],
                         "Contents of the directory pointed to by a symlink "
                         "were deleted")
        d2.cleanup()

    @support.cpython_only
    def test_del_on_collection(self) -> None:
        # A TemporaryDirectory is deleted when garbage collected
        dir = tempfile.mkdtemp()
        try:
            d = self.do_create(dir=dir)
            name = d.name
            del d # Rely on refcounting to invoke __del__
            self.assertFalse(os.path.exists(name),
                        "TemporaryDirectory %s exists after __del__" % name)
        finally:
            os.rmdir(dir)

    @unittest.expectedFailure # See issue #10188
    def test_del_on_shutdown(self) -> None:
        # A TemporaryDirectory may be cleaned up during shutdown
        # Make sure it works with the relevant modules nulled out
        with self.do_create() as dir:
            d = self.do_create(dir=dir)
            # Mimic the nulling out of modules that
            # occurs during system shutdown
            modules = [os, os.path]
            if has_stat:
                modules.append(stat)
            # Currently broken, so suppress the warning
            # that is otherwise emitted on stdout
            with support.captured_stderr() as err:
                with NulledModules(*modules):
                    d.cleanup()
            # Currently broken, so stop spurious exception by
            # indicating the object has already been closed
            d._closed = True
            # And this assert will fail, as expected by the
            # unittest decorator...
            self.assertFalse(os.path.exists(d.name),
                        "TemporaryDirectory %s exists after cleanup" % d.name)

    def test_warnings_on_cleanup(self) -> None:
        # Two kinds of warning on shutdown
        #   Issue 10888: may write to stderr if modules are nulled out
        #   ResourceWarning will be triggered by __del__
        with self.do_create() as dir:
            if os.sep != '\\':
                # Embed a backslash in order to make sure string escaping
                # in the displayed error message is dealt with correctly
                suffix = '\\check_backslash_handling'
            else:
                suffix = ''
            d = self.do_create(dir=dir, suf=suffix)

            #Check for the Issue 10888 message
            modules = [os, os.path]
            if has_stat:
                modules.append(stat)
            with support.captured_stderr() as err:
                with NulledModules(*modules):
                    d.cleanup()
            message = err.getvalue().replace('\\\\', '\\')
            self.assertIn("while cleaning up",  message)
            self.assertIn(d.name,  message)

            # Check for the resource warning
            with support.check_warnings(('Implicitly', ResourceWarning), quiet=False):
                warnings.filterwarnings("always", category=ResourceWarning)
                d.__del__()
            self.assertFalse(os.path.exists(d.name),
                        "TemporaryDirectory %s exists after __del__" % d.name)

    def test_multiple_close(self) -> None:
        # Can be cleaned-up many times without error
        d = self.do_create()
        d.cleanup()
        try:
            d.cleanup()
            d.cleanup()
        except:
            self.failOnException("cleanup")

    def test_context_manager(self) -> None:
        # Can be used as a context manager
        d = self.do_create()
        with d as name:
            self.assertTrue(os.path.exists(name))
            self.assertEqual(name, d.name)
        self.assertFalse(os.path.exists(name))


test_classes.append(test_TemporaryDirectory)

def test_main() -> None:
    support.run_unittest(*test_classes)

if __name__ == "__main__":
    test_main()

########NEW FILE########
__FILENAME__ = test_textwrap
#
# Test suite for the textwrap module.
#
# Original tests written by Greg Ward <gward@python.net>.
# Converted to PyUnit by Peter Hansen <peter@engcorp.com>.
# Currently maintained by Greg Ward.
#
# $Id$
#

import unittest
from test import support

from typing import Any, List, Sequence, Undefined

from textwrap import TextWrapper, wrap, fill, dedent


class BaseTestCase(unittest.TestCase):
    '''Parent class with utility methods for textwrap tests.'''

    wrapper = Undefined(TextWrapper)

    def show(self, textin: Sequence[str]) -> str:
        if isinstance(textin, list):
            results = List[str]()
            for i in range(len(textin)):
                results.append("  %d: %r" % (i, textin[i]))
            result = '\n'.join(results)
        elif isinstance(textin, str):
            result = "  %s\n" % repr(textin)
        return result


    def check(self, result: Sequence[str], expect: Sequence[str]) -> None:
        self.assertEqual(result, expect,
            'expected:\n%s\nbut got:\n%s' % (
                self.show(expect), self.show(result)))

    def check_wrap(self, text: str, width: int, expect: Sequence[str],
                   **kwargs: Any) -> None:
        result = wrap(text, width, **kwargs)
        self.check(result, expect)

    def check_split(self, text: str, expect: Sequence[str]) -> None:
        result = self.wrapper._split(text)
        self.assertEqual(result, expect,
                         "\nexpected %r\n"
                         "but got  %r" % (expect, result))


class WrapTestCase(BaseTestCase):

    def setUp(self) -> None:
        self.wrapper = TextWrapper(width=45)

    def test_simple(self) -> None:
        # Simple case: just words, spaces, and a bit of punctuation

        text = "Hello there, how are you this fine day?  I'm glad to hear it!"

        self.check_wrap(text, 12,
                        ["Hello there,",
                         "how are you",
                         "this fine",
                         "day?  I'm",
                         "glad to hear",
                         "it!"])
        self.check_wrap(text, 42,
                        ["Hello there, how are you this fine day?",
                         "I'm glad to hear it!"])
        self.check_wrap(text, 80, [text])


    def test_whitespace(self) -> None:
        # Whitespace munging and end-of-sentence detection

        text = """\
This is a paragraph that already has
line breaks.  But some of its lines are much longer than the others,
so it needs to be wrapped.
Some lines are \ttabbed too.
What a mess!
"""

        expect = ["This is a paragraph that already has line",
                  "breaks.  But some of its lines are much",
                  "longer than the others, so it needs to be",
                  "wrapped.  Some lines are  tabbed too.  What a",
                  "mess!"]

        wrapper = TextWrapper(45, fix_sentence_endings=True)
        result = wrapper.wrap(text)
        self.check(result, expect)

        results = wrapper.fill(text)
        self.check(results, '\n'.join(expect))

    def test_fix_sentence_endings(self) -> None:
        wrapper = TextWrapper(60, fix_sentence_endings=True)

        # SF #847346: ensure that fix_sentence_endings=True does the
        # right thing even on input short enough that it doesn't need to
        # be wrapped.
        text = "A short line. Note the single space."
        expect = ["A short line.  Note the single space."]
        self.check(wrapper.wrap(text), expect)

        # Test some of the hairy end cases that _fix_sentence_endings()
        # is supposed to handle (the easy stuff is tested in
        # test_whitespace() above).
        text = "Well, Doctor? What do you think?"
        expect = ["Well, Doctor?  What do you think?"]
        self.check(wrapper.wrap(text), expect)

        text = "Well, Doctor?\nWhat do you think?"
        self.check(wrapper.wrap(text), expect)

        text = 'I say, chaps! Anyone for "tennis?"\nHmmph!'
        expect = ['I say, chaps!  Anyone for "tennis?"  Hmmph!']
        self.check(wrapper.wrap(text), expect)

        wrapper.width = 20
        expect = ['I say, chaps!', 'Anyone for "tennis?"', 'Hmmph!']
        self.check(wrapper.wrap(text), expect)

        text = 'And she said, "Go to hell!"\nCan you believe that?'
        expect = ['And she said, "Go to',
                  'hell!"  Can you',
                  'believe that?']
        self.check(wrapper.wrap(text), expect)

        wrapper.width = 60
        expect = ['And she said, "Go to hell!"  Can you believe that?']
        self.check(wrapper.wrap(text), expect)

        text = 'File stdio.h is nice.'
        expect = ['File stdio.h is nice.']
        self.check(wrapper.wrap(text), expect)

    def test_wrap_short(self) -> None:
        # Wrapping to make short lines longer

        text = "This is a\nshort paragraph."

        self.check_wrap(text, 20, ["This is a short",
                                   "paragraph."])
        self.check_wrap(text, 40, ["This is a short paragraph."])


    def test_wrap_short_1line(self) -> None:
        # Test endcases

        text = "This is a short line."

        self.check_wrap(text, 30, ["This is a short line."])
        self.check_wrap(text, 30, ["(1) This is a short line."],
                        initial_indent="(1) ")


    def test_hyphenated(self) -> None:
        # Test breaking hyphenated words

        text = ("this-is-a-useful-feature-for-"
                "reformatting-posts-from-tim-peters'ly")

        self.check_wrap(text, 40,
                        ["this-is-a-useful-feature-for-",
                         "reformatting-posts-from-tim-peters'ly"])
        self.check_wrap(text, 41,
                        ["this-is-a-useful-feature-for-",
                         "reformatting-posts-from-tim-peters'ly"])
        self.check_wrap(text, 42,
                        ["this-is-a-useful-feature-for-reformatting-",
                         "posts-from-tim-peters'ly"])

    def test_hyphenated_numbers(self) -> None:
        # Test that hyphenated numbers (eg. dates) are not broken like words.
        text = ("Python 1.0.0 was released on 1994-01-26.  Python 1.0.1 was\n"
                "released on 1994-02-15.")

        self.check_wrap(text, 30, ['Python 1.0.0 was released on',
                                   '1994-01-26.  Python 1.0.1 was',
                                   'released on 1994-02-15.'])
        self.check_wrap(text, 40, ['Python 1.0.0 was released on 1994-01-26.',
                                   'Python 1.0.1 was released on 1994-02-15.'])

        text = "I do all my shopping at 7-11."
        self.check_wrap(text, 25, ["I do all my shopping at",
                                   "7-11."])
        self.check_wrap(text, 27, ["I do all my shopping at",
                                   "7-11."])
        self.check_wrap(text, 29, ["I do all my shopping at 7-11."])

    def test_em_dash(self) -> None:
        # Test text with em-dashes
        text = "Em-dashes should be written -- thus."
        self.check_wrap(text, 25,
                        ["Em-dashes should be",
                         "written -- thus."])

        # Probe the boundaries of the properly written em-dash,
        # ie. " -- ".
        self.check_wrap(text, 29,
                        ["Em-dashes should be written",
                         "-- thus."])
        expect = ["Em-dashes should be written --",
                  "thus."]
        self.check_wrap(text, 30, expect)
        self.check_wrap(text, 35, expect)
        self.check_wrap(text, 36,
                        ["Em-dashes should be written -- thus."])

        # The improperly written em-dash is handled too, because
        # it's adjacent to non-whitespace on both sides.
        text = "You can also do--this or even---this."
        expect = ["You can also do",
                  "--this or even",
                  "---this."]
        self.check_wrap(text, 15, expect)
        self.check_wrap(text, 16, expect)
        expect = ["You can also do--",
                  "this or even---",
                  "this."]
        self.check_wrap(text, 17, expect)
        self.check_wrap(text, 19, expect)
        expect = ["You can also do--this or even",
                  "---this."]
        self.check_wrap(text, 29, expect)
        self.check_wrap(text, 31, expect)
        expect = ["You can also do--this or even---",
                  "this."]
        self.check_wrap(text, 32, expect)
        self.check_wrap(text, 35, expect)

        # All of the above behaviour could be deduced by probing the
        # _split() method.
        text = "Here's an -- em-dash and--here's another---and another!"
        expect = ["Here's", " ", "an", " ", "--", " ", "em-", "dash", " ",
                  "and", "--", "here's", " ", "another", "---",
                  "and", " ", "another!"]
        self.check_split(text, expect)

        text = "and then--bam!--he was gone"
        expect = ["and", " ", "then", "--", "bam!", "--",
                  "he", " ", "was", " ", "gone"]
        self.check_split(text, expect)


    def test_unix_options (self) -> None:
        # Test that Unix-style command-line options are wrapped correctly.
        # Both Optik (OptionParser) and Docutils rely on this behaviour!

        text = "You should use the -n option, or --dry-run in its long form."
        self.check_wrap(text, 20,
                        ["You should use the",
                         "-n option, or --dry-",
                         "run in its long",
                         "form."])
        self.check_wrap(text, 21,
                        ["You should use the -n",
                         "option, or --dry-run",
                         "in its long form."])
        expect = ["You should use the -n option, or",
                  "--dry-run in its long form."]
        self.check_wrap(text, 32, expect)
        self.check_wrap(text, 34, expect)
        self.check_wrap(text, 35, expect)
        self.check_wrap(text, 38, expect)
        expect = ["You should use the -n option, or --dry-",
                  "run in its long form."]
        self.check_wrap(text, 39, expect)
        self.check_wrap(text, 41, expect)
        expect = ["You should use the -n option, or --dry-run",
                  "in its long form."]
        self.check_wrap(text, 42, expect)

        # Again, all of the above can be deduced from _split().
        text = "the -n option, or --dry-run or --dryrun"
        expect = ["the", " ", "-n", " ", "option,", " ", "or", " ",
                  "--dry-", "run", " ", "or", " ", "--dryrun"]
        self.check_split(text, expect)

    def test_funky_hyphens (self) -> None:
        # Screwy edge cases cooked up by David Goodger.  All reported
        # in SF bug #596434.
        self.check_split("what the--hey!", ["what", " ", "the", "--", "hey!"])
        self.check_split("what the--", ["what", " ", "the--"])
        self.check_split("what the--.", ["what", " ", "the--."])
        self.check_split("--text--.", ["--text--."])

        # When I first read bug #596434, this is what I thought David
        # was talking about.  I was wrong; these have always worked
        # fine.  The real problem is tested in test_funky_parens()
        # below...
        self.check_split("--option", ["--option"])
        self.check_split("--option-opt", ["--option-", "opt"])
        self.check_split("foo --option-opt bar",
                         ["foo", " ", "--option-", "opt", " ", "bar"])

    def test_punct_hyphens(self) -> None:
        # Oh bother, SF #965425 found another problem with hyphens --
        # hyphenated words in single quotes weren't handled correctly.
        # In fact, the bug is that *any* punctuation around a hyphenated
        # word was handled incorrectly, except for a leading "--", which
        # was special-cased for Optik and Docutils.  So test a variety
        # of styles of punctuation around a hyphenated word.
        # (Actually this is based on an Optik bug report, #813077).
        self.check_split("the 'wibble-wobble' widget",
                         ['the', ' ', "'wibble-", "wobble'", ' ', 'widget'])
        self.check_split('the "wibble-wobble" widget',
                         ['the', ' ', '"wibble-', 'wobble"', ' ', 'widget'])
        self.check_split("the (wibble-wobble) widget",
                         ['the', ' ', "(wibble-", "wobble)", ' ', 'widget'])
        self.check_split("the ['wibble-wobble'] widget",
                         ['the', ' ', "['wibble-", "wobble']", ' ', 'widget'])

    def test_funky_parens (self) -> None:
        # Second part of SF bug #596434: long option strings inside
        # parentheses.
        self.check_split("foo (--option) bar",
                         ["foo", " ", "(--option)", " ", "bar"])

        # Related stuff -- make sure parens work in simpler contexts.
        self.check_split("foo (bar) baz",
                         ["foo", " ", "(bar)", " ", "baz"])
        self.check_split("blah (ding dong), wubba",
                         ["blah", " ", "(ding", " ", "dong),",
                          " ", "wubba"])

    def test_initial_whitespace(self) -> None:
        # SF bug #622849 reported inconsistent handling of leading
        # whitespace; let's test that a bit, shall we?
        text = " This is a sentence with leading whitespace."
        self.check_wrap(text, 50,
                        [" This is a sentence with leading whitespace."])
        self.check_wrap(text, 30,
                        [" This is a sentence with", "leading whitespace."])

    def test_no_drop_whitespace(self) -> None:
        # SF patch #1581073
        text = " This is a    sentence with     much whitespace."
        self.check_wrap(text, 10,
                        [" This is a", "    ", "sentence ",
                         "with     ", "much white", "space."],
                        drop_whitespace=False)

    def test_split(self) -> None:
        # Ensure that the standard _split() method works as advertised
        # in the comments

        text = "Hello there -- you goof-ball, use the -b option!"

        result = self.wrapper._split(text)
        self.check(result,
             ["Hello", " ", "there", " ", "--", " ", "you", " ", "goof-",
              "ball,", " ", "use", " ", "the", " ", "-b", " ",  "option!"])

    def test_break_on_hyphens(self) -> None:
        # Ensure that the break_on_hyphens attributes work
        text = "yaba daba-doo"
        self.check_wrap(text, 10, ["yaba daba-", "doo"],
                        break_on_hyphens=True)
        self.check_wrap(text, 10, ["yaba", "daba-doo"],
                        break_on_hyphens=False)

    def test_bad_width(self) -> None:
        # Ensure that width <= 0 is caught.
        text = "Whatever, it doesn't matter."
        self.assertRaises(ValueError, wrap, text, 0)
        self.assertRaises(ValueError, wrap, text, -1)

    def test_no_split_at_umlaut(self) -> None:
        text = "Die Empf\xe4nger-Auswahl"
        self.check_wrap(text, 13, ["Die", "Empf\xe4nger-", "Auswahl"])

    def test_umlaut_followed_by_dash(self) -> None:
        text = "aa \xe4\xe4-\xe4\xe4"
        self.check_wrap(text, 7, ["aa \xe4\xe4-", "\xe4\xe4"])


class LongWordTestCase (BaseTestCase):
    def setUp(self) -> None:
        self.wrapper = TextWrapper()
        self.text = '''\
Did you say "supercalifragilisticexpialidocious?"
How *do* you spell that odd word, anyways?
'''

    def test_break_long(self) -> None:
        # Wrap text with long words and lots of punctuation

        self.check_wrap(self.text, 30,
                        ['Did you say "supercalifragilis',
                         'ticexpialidocious?" How *do*',
                         'you spell that odd word,',
                         'anyways?'])
        self.check_wrap(self.text, 50,
                        ['Did you say "supercalifragilisticexpialidocious?"',
                         'How *do* you spell that odd word, anyways?'])

        # SF bug 797650.  Prevent an infinite loop by making sure that at
        # least one character gets split off on every pass.
        self.check_wrap('-'*10+'hello', 10,
                        ['----------',
                         '               h',
                         '               e',
                         '               l',
                         '               l',
                         '               o'],
                        subsequent_indent = ' '*15)

        # bug 1146.  Prevent a long word to be wrongly wrapped when the
        # preceding word is exactly one character shorter than the width
        self.check_wrap(self.text, 12,
                        ['Did you say ',
                         '"supercalifr',
                         'agilisticexp',
                         'ialidocious?',
                         '" How *do*',
                         'you spell',
                         'that odd',
                         'word,',
                         'anyways?'])

    def test_nobreak_long(self) -> None:
        # Test with break_long_words disabled
        self.wrapper.break_long_words = False
        self.wrapper.width = 30
        expect = ['Did you say',
                  '"supercalifragilisticexpialidocious?"',
                  'How *do* you spell that odd',
                  'word, anyways?'
                  ]
        result = self.wrapper.wrap(self.text)
        self.check(result, expect)

        # Same thing with kwargs passed to standalone wrap() function.
        result = wrap(self.text, width=30, break_long_words=0)
        self.check(result, expect)


class IndentTestCases(BaseTestCase):

    # called before each test method
    def setUp(self) -> None:
        self.text = '''\
This paragraph will be filled, first without any indentation,
and then with some (including a hanging indent).'''


    def test_fill(self) -> None:
        # Test the fill() method

        expect = '''\
This paragraph will be filled, first
without any indentation, and then with
some (including a hanging indent).'''

        result = fill(self.text, 40)
        self.check(result, expect)


    def test_initial_indent(self) -> None:
        # Test initial_indent parameter

        expect = ["     This paragraph will be filled,",
                  "first without any indentation, and then",
                  "with some (including a hanging indent)."]
        result = wrap(self.text, 40, initial_indent="     ")
        self.check(result, expect)

        expects = "\n".join(expect)
        results = fill(self.text, 40, initial_indent="     ")
        self.check(results, expects)


    def test_subsequent_indent(self) -> None:
        # Test subsequent_indent parameter

        expect = '''\
  * This paragraph will be filled, first
    without any indentation, and then
    with some (including a hanging
    indent).'''

        result = fill(self.text, 40,
                      initial_indent="  * ", subsequent_indent="    ")
        self.check(result, expect)


# Despite the similar names, DedentTestCase is *not* the inverse
# of IndentTestCase!
class DedentTestCase(unittest.TestCase):

    def assertUnchanged(self, text: str) -> None:
        """assert that dedent() has no effect on 'text'"""
        self.assertEqual(text, dedent(text))

    def test_dedent_nomargin(self) -> None:
        # No lines indented.
        text = "Hello there.\nHow are you?\nOh good, I'm glad."
        self.assertUnchanged(text)

        # Similar, with a blank line.
        text = "Hello there.\n\nBoo!"
        self.assertUnchanged(text)

        # Some lines indented, but overall margin is still zero.
        text = "Hello there.\n  This is indented."
        self.assertUnchanged(text)

        # Again, add a blank line.
        text = "Hello there.\n\n  Boo!\n"
        self.assertUnchanged(text)

    def test_dedent_even(self) -> None:
        # All lines indented by two spaces.
        text = "  Hello there.\n  How are ya?\n  Oh good."
        expect = "Hello there.\nHow are ya?\nOh good."
        self.assertEqual(expect, dedent(text))

        # Same, with blank lines.
        text = "  Hello there.\n\n  How are ya?\n  Oh good.\n"
        expect = "Hello there.\n\nHow are ya?\nOh good.\n"
        self.assertEqual(expect, dedent(text))

        # Now indent one of the blank lines.
        text = "  Hello there.\n  \n  How are ya?\n  Oh good.\n"
        expect = "Hello there.\n\nHow are ya?\nOh good.\n"
        self.assertEqual(expect, dedent(text))

    def test_dedent_uneven(self) -> None:
        # Lines indented unevenly.
        text = '''\
        def foo():
            while 1:
                return foo
        '''
        expect = '''\
def foo():
    while 1:
        return foo
'''
        self.assertEqual(expect, dedent(text))

        # Uneven indentation with a blank line.
        text = "  Foo\n    Bar\n\n   Baz\n"
        expect = "Foo\n  Bar\n\n Baz\n"
        self.assertEqual(expect, dedent(text))

        # Uneven indentation with a whitespace-only line.
        text = "  Foo\n    Bar\n \n   Baz\n"
        expect = "Foo\n  Bar\n\n Baz\n"
        self.assertEqual(expect, dedent(text))

    # dedent() should not mangle internal tabs
    def test_dedent_preserve_internal_tabs(self) -> None:
        text = "  hello\tthere\n  how are\tyou?"
        expect = "hello\tthere\nhow are\tyou?"
        self.assertEqual(expect, dedent(text))

        # make sure that it preserves tabs when it's not making any
        # changes at all
        self.assertEqual(expect, dedent(expect))

    # dedent() should not mangle tabs in the margin (i.e.
    # tabs and spaces both count as margin, but are *not*
    # considered equivalent)
    def test_dedent_preserve_margin_tabs(self) -> None:
        text = "  hello there\n\thow are you?"
        self.assertUnchanged(text)

        # same effect even if we have 8 spaces
        text = "        hello there\n\thow are you?"
        self.assertUnchanged(text)

        # dedent() only removes whitespace that can be uniformly removed!
        text = "\thello there\n\thow are you?"
        expect = "hello there\nhow are you?"
        self.assertEqual(expect, dedent(text))

        text = "  \thello there\n  \thow are you?"
        self.assertEqual(expect, dedent(text))

        text = "  \t  hello there\n  \t  how are you?"
        self.assertEqual(expect, dedent(text))

        text = "  \thello there\n  \t  how are you?"
        expect = "hello there\n  how are you?"
        self.assertEqual(expect, dedent(text))


def test_main() -> None:
    support.run_unittest(WrapTestCase,
                              LongWordTestCase,
                              IndentTestCases,
                              DedentTestCase)

if __name__ == '__main__':
    test_main()

########NEW FILE########
__FILENAME__ = tf_inherit_check
# Helper script for test_tempfile.py.  argv[2] is the number of a file
# descriptor which should _not_ be open.  Check this by attempting to
# write to it -- if we succeed, something is wrong.

import sys
import os

verbose = (sys.argv[1] == 'v')
try:
    fd = int(sys.argv[2])

    try:
        os.write(fd, b"blat")
    except os.error:
        # Success -- could not write to fd.
        sys.exit(0)
    else:
        if verbose:
            sys.stderr.write("fd %d is open in child" % fd)
        sys.exit(1)

except Exception:
    if verbose:
        raise
    sys.exit(1)

########NEW FILE########
__FILENAME__ = textwrap
"""Text wrapping and filling.
"""

# Copyright (C) 1999-2001 Gregory P. Ward.
# Copyright (C) 2002, 2003 Python Software Foundation.
# Written by Greg Ward <gward@python.net>

import string, re

from typing import Dict, List, Any

__all__ = ['TextWrapper', 'wrap', 'fill', 'dedent']

# Hardcode the recognized whitespace characters to the US-ASCII
# whitespace characters.  The main reason for doing this is that in
# ISO-8859-1, 0xa0 is non-breaking whitespace, so in certain locales
# that character winds up in string.whitespace.  Respecting
# string.whitespace in those cases would 1) make textwrap treat 0xa0 the
# same as any other whitespace char, which is clearly wrong (it's a
# *non-breaking* space), 2) possibly cause problems with Unicode,
# since 0xa0 is not in range(128).
_whitespace = '\t\n\x0b\x0c\r '

class TextWrapper:
    """
    Object for wrapping/filling text.  The public interface consists of
    the wrap() and fill() methods; the other methods are just there for
    subclasses to override in order to tweak the default behaviour.
    If you want to completely replace the main wrapping algorithm,
    you'll probably have to override _wrap_chunks().

    Several instance attributes control various aspects of wrapping:
      width (default: 70)
        the maximum width of wrapped lines (unless break_long_words
        is false)
      initial_indent (default: "")
        string that will be prepended to the first line of wrapped
        output.  Counts towards the line's width.
      subsequent_indent (default: "")
        string that will be prepended to all lines save the first
        of wrapped output; also counts towards each line's width.
      expand_tabs (default: true)
        Expand tabs in input text to spaces before further processing.
        Each tab will become 1 .. 8 spaces, depending on its position in
        its line.  If false, each tab is treated as a single character.
      replace_whitespace (default: true)
        Replace all whitespace characters in the input text by spaces
        after tab expansion.  Note that if expand_tabs is false and
        replace_whitespace is true, every tab will be converted to a
        single space!
      fix_sentence_endings (default: false)
        Ensure that sentence-ending punctuation is always followed
        by two spaces.  Off by default because the algorithm is
        (unavoidably) imperfect.
      break_long_words (default: true)
        Break words longer than 'width'.  If false, those words will not
        be broken, and some lines might be longer than 'width'.
      break_on_hyphens (default: true)
        Allow breaking hyphenated words. If true, wrapping will occur
        preferably on whitespaces and right after hyphens part of
        compound words.
      drop_whitespace (default: true)
        Drop leading and trailing whitespace from lines.
    """

    unicode_whitespace_trans = Dict[int, int]()
    uspace = ord(' ')
    for x in _whitespace:
        unicode_whitespace_trans[ord(x)] = uspace

    # This funky little regex is just the trick for splitting
    # text up into word-wrappable chunks.  E.g.
    #   "Hello there -- you goof-ball, use the -b option!"
    # splits into
    #   Hello/ /there/ /--/ /you/ /goof-/ball,/ /use/ /the/ /-b/ /option!
    # (after stripping out empty strings).
    wordsep_re = re.compile(
        r'(\s+|'                                  # any whitespace
        r'[^\s\w]*\w+[^0-9\W]-(?=\w+[^0-9\W])|'   # hyphenated words
        r'(?<=[\w\!\"\'\&\.\,\?])-{2,}(?=\w))')   # em-dash

    # This less funky little regex just split on recognized spaces. E.g.
    #   "Hello there -- you goof-ball, use the -b option!"
    # splits into
    #   Hello/ /there/ /--/ /you/ /goof-ball,/ /use/ /the/ /-b/ /option!/
    wordsep_simple_re = re.compile(r'(\s+)')

    # XXX this is not locale- or charset-aware -- string.lowercase
    # is US-ASCII only (and therefore English-only)
    sentence_end_re = re.compile(r'[a-z]'             # lowercase letter
                                 r'[\.\!\?]'          # sentence-ending punct.
                                 r'[\"\']?'           # optional end-of-quote
                                 r'\Z')               # end of chunk


    def __init__(self,
                 width: int = 70,
                 initial_indent: str = "",
                 subsequent_indent: str = "",
                 expand_tabs: bool = True,
                 replace_whitespace: bool = True,
                 fix_sentence_endings: bool = False,
                 break_long_words: bool = True,
                 drop_whitespace: bool = True,
                 break_on_hyphens: bool = True) -> None:
        self.width = width
        self.initial_indent = initial_indent
        self.subsequent_indent = subsequent_indent
        self.expand_tabs = expand_tabs
        self.replace_whitespace = replace_whitespace
        self.fix_sentence_endings = fix_sentence_endings
        self.break_long_words = break_long_words
        self.drop_whitespace = drop_whitespace
        self.break_on_hyphens = break_on_hyphens


    # -- Private methods -----------------------------------------------
    # (possibly useful for subclasses to override)

    def _munge_whitespace(self, text: str) -> str:
        """_munge_whitespace(text : string) -> string

        Munge whitespace in text: expand tabs and convert all other
        whitespace characters to spaces.  Eg. " foo\tbar\n\nbaz"
        becomes " foo    bar  baz".
        """
        if self.expand_tabs:
            text = text.expandtabs()
        if self.replace_whitespace:
            text = text.translate(self.unicode_whitespace_trans)
        return text


    def _split(self, text: str) -> List[str]:
        """_split(text : string) -> [string]

        Split the text to wrap into indivisible chunks.  Chunks are
        not quite the same as words; see _wrap_chunks() for full
        details.  As an example, the text
          Look, goof-ball -- use the -b option!
        breaks into the following chunks:
          'Look,', ' ', 'goof-', 'ball', ' ', '--', ' ',
          'use', ' ', 'the', ' ', '-b', ' ', 'option!'
        if break_on_hyphens is True, or in:
          'Look,', ' ', 'goof-ball', ' ', '--', ' ',
          'use', ' ', 'the', ' ', '-b', ' ', option!'
        otherwise.
        """
        if self.break_on_hyphens is True:
            chunks = self.wordsep_re.split(text)
        else:
            chunks = self.wordsep_simple_re.split(text)
        chunks = [c for c in chunks if c]
        return chunks

    def _fix_sentence_endings(self, chunks: List[str]) -> None:
        """_fix_sentence_endings(chunks : [string])

        Correct for sentence endings buried in 'chunks'.  Eg. when the
        original text contains "... foo.\nBar ...", munge_whitespace()
        and split() will convert that to [..., "foo.", " ", "Bar", ...]
        which has one too few spaces; this method simply changes the one
        space to two.
        """
        i = 0
        patsearch = self.sentence_end_re.search
        while i < len(chunks)-1:
            if chunks[i+1] == " " and patsearch(chunks[i]):
                chunks[i+1] = "  "
                i += 2
            else:
                i += 1

    def _handle_long_word(self, reversed_chunks: List[str],
                          cur_line: List[str], cur_len: int,
                          width: int) -> None:
        """_handle_long_word(chunks : [string],
                             cur_line : [string],
                             cur_len : int, width : int)

        Handle a chunk of text (most likely a word, not whitespace) that
        is too long to fit in any line.
        """
        # Figure out when indent is larger than the specified width, and make
        # sure at least one character is stripped off on every pass
        if width < 1:
            space_left = 1
        else:
            space_left = width - cur_len

        # If we're allowed to break long words, then do so: put as much
        # of the next chunk onto the current line as will fit.
        if self.break_long_words:
            cur_line.append(reversed_chunks[-1][:space_left])
            reversed_chunks[-1] = reversed_chunks[-1][space_left:]

        # Otherwise, we have to preserve the long word intact.  Only add
        # it to the current line if there's nothing already there --
        # that minimizes how much we violate the width constraint.
        elif not cur_line:
            cur_line.append(reversed_chunks.pop())

        # If we're not allowed to break long words, and there's already
        # text on the current line, do nothing.  Next time through the
        # main loop of _wrap_chunks(), we'll wind up here again, but
        # cur_len will be zero, so the next line will be entirely
        # devoted to the long word that we can't handle right now.

    def _wrap_chunks(self, chunks: List[str]) -> List[str]:
        """_wrap_chunks(chunks : [string]) -> [string]

        Wrap a sequence of text chunks and return a list of lines of
        length 'self.width' or less.  (If 'break_long_words' is false,
        some lines may be longer than this.)  Chunks correspond roughly
        to words and the whitespace between them: each chunk is
        indivisible (modulo 'break_long_words'), but a line break can
        come between any two chunks.  Chunks should not have internal
        whitespace; ie. a chunk is either all whitespace or a "word".
        Whitespace chunks will be removed from the beginning and end of
        lines, but apart from that whitespace is preserved.
        """
        lines = List[str]()
        if self.width <= 0:
            raise ValueError("invalid width %r (must be > 0)" % self.width)

        # Arrange in reverse order so items can be efficiently popped
        # from a stack of chucks.
        chunks.reverse()

        while chunks:

            # Start the list of chunks that will make up the current line.
            # cur_len is just the length of all the chunks in cur_line.
            cur_line = List[str]()
            cur_len = 0

            # Figure out which static string will prefix this line.
            if lines:
                indent = self.subsequent_indent
            else:
                indent = self.initial_indent

            # Maximum width for this line.
            width = self.width - len(indent)

            # First chunk on line is whitespace -- drop it, unless this
            # is the very beginning of the text (ie. no lines started yet).
            if self.drop_whitespace and chunks[-1].strip() == '' and lines:
                del chunks[-1]

            while chunks:
                l = len(chunks[-1])

                # Can at least squeeze this chunk onto the current line.
                if cur_len + l <= width:
                    cur_line.append(chunks.pop())
                    cur_len += l

                # Nope, this line is full.
                else:
                    break

            # The current line is full, and the next chunk is too big to
            # fit on *any* line (not just this one).
            if chunks and len(chunks[-1]) > width:
                self._handle_long_word(chunks, cur_line, cur_len, width)

            # If the last chunk on this line is all whitespace, drop it.
            if self.drop_whitespace and cur_line and cur_line[-1].strip() == '':
                del cur_line[-1]

            # Convert current line back to a string and store it in list
            # of all lines (return value).
            if cur_line:
                lines.append(indent + ''.join(cur_line))

        return lines


    # -- Public interface ----------------------------------------------

    def wrap(self, text: str) -> List[str]:
        """wrap(text : string) -> [string]

        Reformat the single paragraph in 'text' so it fits in lines of
        no more than 'self.width' columns, and return a list of wrapped
        lines.  Tabs in 'text' are expanded with string.expandtabs(),
        and all other whitespace characters (including newline) are
        converted to space.
        """
        text = self._munge_whitespace(text)
        chunks = self._split(text)
        if self.fix_sentence_endings:
            self._fix_sentence_endings(chunks)
        return self._wrap_chunks(chunks)

    def fill(self, text: str) -> str:
        """fill(text : string) -> string

        Reformat the single paragraph in 'text' to fit in lines of no
        more than 'self.width' columns, and return a new string
        containing the entire wrapped paragraph.
        """
        return "\n".join(self.wrap(text))


# -- Convenience interface ---------------------------------------------

def wrap(text: str, width: int = 70, **kwargs: Any) -> List[str]:
    """Wrap a single paragraph of text, returning a list of wrapped lines.

    Reformat the single paragraph in 'text' so it fits in lines of no
    more than 'width' columns, and return a list of wrapped lines.  By
    default, tabs in 'text' are expanded with string.expandtabs(), and
    all other whitespace characters (including newline) are converted to
    space.  See TextWrapper class for available keyword args to customize
    wrapping behaviour.
    """
    w = TextWrapper(width=width, **kwargs)
    return w.wrap(text)

def fill(text: str, width: int = 70, **kwargs: Any) -> str:
    """Fill a single paragraph of text, returning a new string.

    Reformat the single paragraph in 'text' to fit in lines of no more
    than 'width' columns, and return a new string containing the entire
    wrapped paragraph.  As with wrap(), tabs are expanded and other
    whitespace characters converted to space.  See TextWrapper class for
    available keyword args to customize wrapping behaviour.
    """
    w = TextWrapper(width=width, **kwargs)
    return w.fill(text)


# -- Loosely related functionality -------------------------------------

_whitespace_only_re = re.compile('^[ \t]+$', re.MULTILINE)
_leading_whitespace_re = re.compile('(^[ \t]*)(?:[^ \t\n])', re.MULTILINE)

def dedent(text: str) -> str:
    """Remove any common leading whitespace from every line in `text`.

    This can be used to make triple-quoted strings line up with the left
    edge of the display, while still presenting them in the source code
    in indented form.

    Note that tabs and spaces are both treated as whitespace, but they
    are not equal: the lines "  hello" and "\thello" are
    considered to have no common leading whitespace.  (This behaviour is
    new in Python 2.5; older versions of this module incorrectly
    expanded tabs before searching for common leading whitespace.)
    """
    # Look for the longest leading string of spaces and tabs common to
    # all lines.
    margin = None # type: str
    text = _whitespace_only_re.sub('', text)
    indents = _leading_whitespace_re.findall(text)
    for indent in indents:
        if margin is None:
            margin = indent

        # Current line more deeply indented than previous winner:
        # no change (previous winner is still on top).
        elif indent.startswith(margin):
            pass

        # Current line consistent with and no deeper than previous winner:
        # it's the new winner.
        elif margin.startswith(indent):
            margin = indent

        # Current line and previous winner have no common whitespace:
        # there is no margin.
        else:
            margin = ""
            break

    # sanity check (testing/debugging only)
    if 0 and margin:
        for line in text.split("\n"):
            assert not line or line.startswith(margin), \
                   "line = %r, margin = %r" % (line, margin)

    if margin:
        text = re.sub(r'(?m)^' + margin, '', text)
    return text

if __name__ == "__main__":
    #print dedent("\tfoo\n\tbar")
    #print dedent("  \thello there\n  \t  how are you?")
    print(dedent("Hello there.\n  This is indented."))

########NEW FILE########
__FILENAME__ = test_typing
from __future__ import with_statement
from abc import abstractmethod, ABCMeta
import unittest

from typing import (
    List, Dict, Set, Tuple, Pattern, BytesPattern, Match, BytesMatch, Any,
    Function, Generic, AbstractGeneric, Protocol, Sized, Iterable, Iterator,
    Sequence, AbstractSet, Mapping, BinaryIO, TextIO, SupportsInt, SupportsFloat,
    SupportsAbs, Reversible, Undefined, cast, forwardref, overload, typevar
)


class TestTyping(unittest.TestCase):
    def test_List(self):
        self.assertIs(List[int], list)
        self.assertIs(List[unicode], list)
        
    def test_Dict(self):
        self.assertIs(Dict[int, unicode], dict)
        self.assertIs(Dict[unicode, int], dict)
        
    def test_Set(self):
        self.assertIs(Set[int], set)
        self.assertIs(Set[unicode], set)
        
    def test_Tuple(self):
        self.assertIs(Tuple[int], tuple)
        self.assertIs(Tuple[unicode, int], tuple)
        self.assertIs(Tuple[unicode, int, bool], tuple)

    def test_Pattern(self):
        import re
        self.assertIs(type(re.compile(u'')), Pattern)
        self.assertIs(type(re.compile('')), BytesPattern)
        # Note that actually Pattern is the same as BytesPattern, which is
        # a bit awkward.

    def test_Match(self):
        import re
        self.assertIs(type(re.match(u'', u'')), Match)
        self.assertIs(type(re.match('', '')), BytesMatch)
        # Note that actually Match is the same as BytesMatch, which is
        # a bit awkward.
        
    def test_Any(self):
        o = object()
        self.assertIs(Any(o), o)
        s = u'x'
        self.assertIs(Any(s), s)

    def test_Function(self):
        # Just check that we can call Function. Don't care about return value.
        Function[[], int]
        Function[[int], None]
        Function[[int, unicode], bool]

    def test_cast(self):
        o = object()
        # cast performs no runtime checks!
        self.assertIs(cast(int, o), o)
        s = u'x'
        self.assertIs(cast(unicode, s), s)
        self.assertIs(cast(u'xyz', s), s)
        # cast does not check type validity; anything goes.
        self.assertIs(cast(o, s), s)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_simple_overload(self):
        @overload
        def f(x): return x + u'string'
        @overload
        def f(x): return x + 1
        
        self.assertEqual(f(u'x'), u'xstring')
        self.assertEqual(f(1), 2)
        
        @overload
        def g(x): return u'integer'
        @overload
        def g(x): return u'string'
        
        self.assertEqual(g(u'x'), u'string')
        self.assertEqual(g(1), u'integer')

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_overload_with_three_variants(self):
        @overload
        def f(x): return u'string'
        @overload
        def f(x): return u'integer'
        @overload
        def f(x): return u'floating'
        
        self.assertEqual(f(u'x'), u'string')
        self.assertEqual(f(1), u'integer')
        self.assertEqual(f(1.0), u'floating')

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_overload_with_two_args(self):
        @overload
        def f(x, y): return (1, x, y)
        @overload
        def f(x, y): return (2, x, y)

        self.assertEqual(f(u'x', u'y'), (1, u'x', u'y'))
        self.assertEqual(f(u'z', 3), (2, u'z', 3))
        
        @overload
        def g(x, y): return 1
        @overload
        def g(x, y): return 2

        self.assertEqual(g(u'x', u'y'), 1)
        self.assertEqual(g(u'x', 1), 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_global_overload(self):
        self.assertEqual(global_overload(u'x'), u's')
        self.assertEqual(global_overload(1), u'i')

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_partial_overload_annotation(self):
        @overload
        def f(x, y): return 1
        @overload
        def f(x, y): return 2

        self.assertEqual(f(u'x', object()), 1)
        self.assertEqual(f(object(), 1), 2)
        
    @overload
    def method_overload(self, x):
        return u's'
    
    @overload
    def method_overload(self, x):
        return u'i'

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_method_overload(self):
        self.assertEqual(self.method_overload(u'x'), u's')
        self.assertEqual(self.method_overload(1), u'i')

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_overload_with_any_type(self):
        @overload
        def f(x, y): return 1
        @overload
        def f(x, y): return 2

        self.assertEqual(f((), 0), 1)
        self.assertEqual(f((), ()), 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_overload_with_type_alias(self):
        @overload
        def f(x): return 1
        @overload
        def f(x): return 2
        @overload
        def f(x): return 3
        @overload
        def f(x): return 4

        self.assertEqual(f([]), 1)
        self.assertEqual(f({}), 2)
        self.assertEqual(f(()), 3)
        self.assertEqual(f((1, u'x')), 3)
        self.assertEqual(f(1), 4)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_call_overload_with_invalid_arg_count(self):
        @overload
        def f(x): return 1
        @overload
        def f(x): return 2

        msg1 = ur'f\(\) takes exactly 1 argument \(%d given\)'
        msg2 = ur'f\(\) takes exactly 1 positional argument \(%d given\)'
        
        with self.assertRaisesRegex(TypeError, msg1 % 0):
            f()
        with self.assertRaisesRegex(TypeError, msg2 % 2):
            f(1, 2)
        with self.assertRaisesRegex(TypeError, msg2 % 3):
            f(u'x', u'y', u'z')

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_overload_with_variable_argument_counts(self):
        @overload
        def f(): return None
        @overload
        def f(x): return x

        self.assertEqual(f(), None)
        self.assertEqual(f(1), 1)
        
        @overload
        def g(x): return x + 1
        @overload
        def g(): return None

        self.assertEqual(g(), None)
        self.assertEqual(g(1), 2)
        
        msg = ur'g\(\) takes no arguments \(2 given\)'
        with self.assertRaisesRegex(TypeError, msg):
            g(1, 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_overload_dispatch_order(self):
        class A(object): pass
        class B(A): pass
        class C(B): pass

        @overload
        def f(x): return u'B'
        @overload
        def f(x): return u'A'

        self.assertEqual(f(B()), u'B')
        self.assertEqual(f(A()), u'A')

        @overload
        def g(x): return u'C'
        @overload
        def g(x): return u'B'
        @overload
        def g(x): return u'A'

        self.assertEqual(g(C()), u'C')
        self.assertEqual(g(B()), u'B')
        self.assertEqual(g(A()), u'A')

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_name_of_overloaded_function(self):
        @overload
        def f(x): return 1
        @overload
        def f(x): return 2

        self.assertEqual(f.__name__, u'f')

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_overloaded_function_as_str(self):
        @overload
        def f(x): return 1
        @overload
        def f(x): return 2

        self.assertRegex(unicode(f), u'^<function f at.*>$')

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_overload_with_default_arg_values(self):
        @overload
        def f(x=u'x'): return x + u'!'
        @overload
        def f(y): return y + 1

        self.assertEqual(f(), u'x!')
        self.assertEqual(f(u'y'), u'y!')
        self.assertEqual(f(3), 4)
        
        @overload
        def g(a, x=u'x', y=u'z'): return 1
        @overload
        def g(a, x=1): return 2

        self.assertEqual(g(1), 1)
        self.assertEqual(g(u'x'), 2)
        self.assertEqual(g(1, u'XX'), 1)
        self.assertEqual(g(1, 2), 2)
        self.assertEqual(g(1, u'XX', u'YY'), 1)
        
        with self.assertRaises(TypeError):
            g(1, u'x', 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_no_matching_overload(self):
        @overload
        def f(x): return 1
        @overload
        def f(x): return 2

        # Fall back to the last overload variant if no annotation matches.
        self.assertEqual(f(()), 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_function_type_dispatch_in_overload(self):
        @overload
        def f(x): return 1
        @overload
        def f(x): return 2

        self.assertEqual(f(ord), 1)
        self.assertEqual(f(unicode.find), 1)
        self.assertEqual(f(u'x'.find), 1)
        self.assertEqual(f(unicode), 1)
        self.assertEqual(f(TestTyping), 1)
        self.assertEqual(f(self.test_function_type_dispatch_in_overload), 1)
        self.assertEqual(f(self.assertEqual), 1)
        self.assertEqual(f(TestTyping.assertEqual), 1)

        class A(object):
            def __call__(self): pass
            
        self.assertEqual(f(A()), 1)
        
        self.assertEqual(f(1), 2)
        self.assertEqual(f(object()), 2)

    def test_typevar(self):
        t = typevar(u't')
        self.assertEqual(t.name, u't')

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_typevar_in_overload(self):
        t = typevar(u't')
        
        @overload
        def f(x, y): return 1
        @overload
        def f(x, y): return 2
        
        self.assertEqual(f((), u'x'), 1)
        self.assertEqual(f((), 1.1), 2)

    def test_simple_generic_class(self):
        t = typevar(u't')

        class C(Generic[t]):
            pass

        self.assertIs(C[int], C)
        self.assertIsInstance(C(), C)
        self.assertIsInstance(C[int](), C)

    def test_generic_class_with_two_typeargs(self):
        t = typevar(u't')
        u = typevar(u'u')

        class C(Generic[t, u]):
            pass

        self.assertIs(C[int, unicode], C)
        self.assertIsInstance(C(), C)
        self.assertIsInstance(C[int, unicode](), C)

    def test_abstract_generic_class(self):
        t = typevar(u't')
        class C(AbstractGeneric[t]):
            pass
        class D(object):
            pass
        self.assertIs(C[int], C)
        self.assertNotIsInstance(D(), C)
        C.register(D)
        self.assertIsInstance(D(), C)

    def test_sequence(self):
        self.assertIs(Sequence[int], Sequence)
        
        self.assertIsInstance([], Sequence)
        self.assertIsInstance((), Sequence)
        self.assertIsInstance(u'', Sequence)
        self.assertIsInstance('', Sequence)
        self.assertIsInstance(xrange(5), Sequence)
        self.assertNotIsInstance({}, Sequence)

    def test_abstract_set(self):
        self.assertIs(AbstractSet[int], AbstractSet)
        
        self.assertIsInstance(set(), AbstractSet)
        self.assertIsInstance(frozenset(), AbstractSet)

    def test_mapping(self):
        self.assertIs(Mapping[int, unicode], Mapping)
        self.assertIsInstance({}, Mapping)

    def test_io_types(self):
        self.assertIsInstance(BinaryIO, type)
        self.assertIsInstance(TextIO, type)

    def test_supports_int(self):
        self.assertIsInstance(1, SupportsInt)
        self.assertIsInstance(1.1, SupportsInt)
        self.assertNotIsInstance(u'', SupportsInt)
        self.assertNotIsInstance('', SupportsInt)
        self.assertNotIsInstance((), SupportsInt)

    def test_supports_float(self):
        self.assertIsInstance(1.1, SupportsFloat)
        self.assertIsInstance(1, SupportsFloat)
        self.assertNotIsInstance(u'', SupportsFloat)
        self.assertNotIsInstance('', SupportsFloat)
        self.assertNotIsInstance((), SupportsFloat)

    def test_supports_abs(self):
        self.assertIsInstance(1.1, SupportsAbs)
        self.assertIsInstance(1, SupportsAbs)
        self.assertNotIsInstance(u'', SupportsAbs)
        self.assertNotIsInstance((), SupportsAbs)

    def test_reversible(self):
        self.assertIsInstance([], Reversible)
        self.assertIsInstance(xrange(1), Reversible)
        self.assertNotIsInstance((), Reversible)
        self.assertNotIsInstance(u'', Reversible)

    def test_simple_protocol(self):
        class P(Protocol):
            def f(self): pass

        class A(object):
            # Conforms to P
            def f(self): pass
            def g(self): pass

        class B(object):
            # Does not conform to P
            def g(self): pass

        self.assertIsInstance(A(), P)
        self.assertNotIsInstance(B(), P)
        
        self.assertTrue(issubclass(A, P))
        self.assertFalse(issubclass(B, P))
        self.assertTrue(issubclass(P, Protocol))
        self.assertTrue(issubclass(Protocol, Protocol))
        self.assertTrue(issubclass(A, Protocol))

    def test_issubclass_of_protocol(self):
        class A(object): pass
        self.assertTrue(issubclass(A, Protocol))

    def test_protocol_with_two_attrs(self):
        class P(Protocol):
            def __int__(self): pass
            x = 0

        class A(object):
            # Conforms to P; attribute values don't need to be similar
            __int__ = 0
            def x(self): pass
            def f(self): pass # Extra method

        class B(object):
            # Does not conform to P
            __int__ = 0
        class C(object):
            # Does not conform to P
            x = 0

        self.assertIsInstance(A(), P)
        self.assertNotIsInstance(B(), P)
        self.assertNotIsInstance(C(), P)

    def test_protocol_inheritance(self):
        class P(Protocol):
            def f(self): pass
        class PP(P, Protocol):
            def g(self): pass

        class A(object):
            # Conforms to P but not PP
            def f(self): pass
        class B(object):
            # Conforms to P and PP
            def f(self): pass
            def g(self): pass
        class C(object):
            # Conforms to neither P nor PP
            def g(self): pass

        self.assertIsInstance(A(), P)
        self.assertIsInstance(B(), P)
        self.assertIsInstance(B(), PP)
        self.assertNotIsInstance(A(), PP)
        self.assertNotIsInstance(C(), PP)

    def test_builtin_class_and_protocol(self):
        class P(Protocol):
            def __add__(self): pass

        self.assertIsInstance(u'', P)
        self.assertIsInstance([], P)
        self.assertIsInstance(1, P)
        self.assertNotIsInstance({}, P)
        
        self.assertTrue(issubclass(unicode, P))
        self.assertFalse(issubclass(dict, P))

    def test_generic_protocol(self):
        t = typevar(u't')
        class P(Protocol[t]):
            x = 1
        class A(object):
            x = 2
        self.assertIsInstance(A(), P)

    def test_indexing_in_protocol(self):
        class P(Protocol):
            def __getitem__(self): pass
        class A(object):
            def __getitem__(self): pass
        class B(object):
            pass
        self.assertIsInstance(A(), P)
        self.assertNotIsInstance(B(), P)

    def test_sized(self):
        self.assertIsInstance([], Sized)
        self.assertIsInstance((), Sized)
        self.assertIsInstance(u'', Sized)
        self.assertIsInstance('', Sized)
        self.assertIsInstance({}, Sized)
        self.assertIsInstance(set(), Sized)
        self.assertIsInstance(xrange(5), Sized)
        self.assertNotIsInstance(1, Sized)

        class A(object):
            def __len__(self): pass

        self.assertIsInstance(A(), Sized)

    def test_iterable(self):
        self.assertIsInstance([], Iterable)
        class A(object):
            def __iter__(self): pass
            def g(self): pass
        self.assertIsInstance(A(), Iterable)
        self.assertNotIsInstance(1, Iterable)

    def test_iterator(self):
        self.assertIsInstance(iter(u''), Iterator)
        self.assertIsInstance(iter([]), Iterator)
        self.assertIsInstance(iter({}), Iterator)        
        self.assertNotIsInstance([], Iterator)
        
        class A(object):
            def __iter__(self): pass
            def next(self): pass
        self.assertIsInstance(A(), Iterator)
        
        class B(object):
            def __iter__(self): pass
        self.assertNotIsInstance(B(), Iterator)
        
        class C(object):
            def next(self): pass
        self.assertNotIsInstance(C(), Iterator)

    def test_class_inheritance_and_protocols(self):
        class A(object):
            def __iter__(self): pass
        class B(A):
            def next(self): pass
        self.assertIsInstance(B(), Iterator)
        self.assertNotIsInstance(A(), Iterator)

    def test_class_multiple_inheritance_and_protocols(self):
        class A(object):
            def __iter__(self): pass
        class B(object):
            def next(self): pass
        class C(A, B): pass
        self.assertIsInstance(C(), Iterator)
        self.assertNotIsInstance(A(), Iterator)
        self.assertNotIsInstance(B(), Iterator)

    def test_multiple_protocol_inheritance(self):
        class P(Protocol):
            x = 1
        class P2(Protocol):
            y = 1
        class P3(P, P2, Protocol): pass

        class A(object):
            x = 1
            y = 1
        class B(object):
            x = 1
        class C(object):
            y = 1

        self.assertIsInstance(A(), P3)
        self.assertNotIsInstance(B(), P3)
        self.assertNotIsInstance(C(), P3)

    def test_protocol_docstrings(self):
        class P(Protocol):
            u"""blah"""
            def f(self): pass
        class A(object):
            def f(self): pass
        self.assertIsInstance(A(), P)

    def test_forward_ref_in_annotation(self):
        A = forwardref(u'A')
        def f(a):
            return a
        self.assertEqual(A.name, u'A')
        class A(object): pass

    def test_string_literal_in_annotation(self):
        def f(a):
            return a + u'x'
        def f(a):
            return list(a)

    def test_undefined(self):
        self.assertEqual(unicode(Undefined), u'<typing.Undefined>')
        with self.assertRaises(AttributeError):
            Undefined.x = 1
        with self.assertRaises(AttributeError):
            Undefined.x
        with self.assertRaises(TypeError):
            if Undefined == 0: pass
        with self.assertRaises(TypeError):
            if Undefined != 0: pass
        with self.assertRaises(TypeError):
            hash(Undefined)
        with self.assertRaises(TypeError):
            if Undefined: pass
        with self.assertRaises(TypeError):
            if not Undefined: pass

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_simple_string_literal_in_overload(self):
        @overload
        def f(a): return u's'
        @overload
        def f(a): return u'i'
        
        self.assertEqual(f(u''), u's')
        self.assertEqual(f(2), u'i')

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_module_ref_string_literal_in_overload(self):
        @overload
        def f(a): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f(Dummy()), 1)
        self.assertEqual(f(2), 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_module_ref_string_literal_in_overload(self):
        @overload
        def f(a): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f(Dummy()), 1)
        self.assertEqual(f(2), 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_local_ref_string_literal_in_overload(self):
        @overload
        def f(a): return 1
        @overload
        def f(a): return 2
        
        class C(object): pass
        self.assertEqual(f(C()), 1)
        self.assertEqual(f(2), 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_any_string_literal_in_overload(self):
        @overload
        def f(a): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f(object()), 1)
        self.assertEqual(f(None), 1)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_generic_type_string_literal_in_overload(self):
        @overload
        def f(a): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f([]), 1)
        self.assertEqual(f(()), 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_tuple_type_string_literal_in_overload(self):
        @overload
        def f(a): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f(()), 1)
        self.assertEqual(f([]), 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_function_type_string_literal_in_overload(self):
        @overload
        def f(a): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f(ord), 1)
        self.assertEqual(f([]), 2)

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_forward_ref_in_overload(self):
        A = forwardref(u'A')

        @overload
        def f(a): return 1
        @overload
        def f(a): return 2

        class A(object): pass

        self.assertEqual(f(A()), 1)
        self.assertEqual(f(object()), 2)

    def test_construct_class_with_abstract_method(self):
        t = typevar(u't')
        
        class A(AbstractGeneric[t]):
            @abstractmethod
            def f(self): pass

        class B(A):
            def f(self): pass

        with self.assertRaises(TypeError):
            A()
        B()

    def test_protocol_with_abstract_method(self):
        class A(Protocol):
            @abstractmethod
            def f(self): pass
            
        with self.assertRaises(TypeError):
            A() # No implementation for abstract method.

    def test_protocol_inheritance(self):
        class A(Protocol):
            def f(self): return 1
        class B(A): pass
        
        self.assertEqual(B().f(), 1)

        class C(A): pass
        # B is not a protocol since it doesn't explicitly subclass Protocol.
        self.assertNotIsInstance(C(), B)

    def test_protocol_inheritance_with_abstract_method(self):
        class A(Protocol):
            @abstractmethod
            def f(self): pass
        class B(A):
            pass
        
        with self.assertRaises(TypeError):
            B() # No implementation for abstract method.
        class C(A):
            def f(self): pass
        C()

    @unittest.skip("overloads not supported in 2.7 yet")
    def test_overloaded_abstract_method(self):
        class A():
            __metaclass__ = ABCMeta
            @abstractmethod
            @overload
            def f(self, x): pass
            @abstractmethod
            @overload
            def f(self, x): pass

        with self.assertRaises(TypeError):
            A()
            
        class B():
            __metaclass__ = ABCMeta
            @overload
            @abstractmethod
            def f(self, x): pass
            
            @overload
            @abstractmethod
            def f(self, x): pass

        with self.assertRaises(TypeError):
            B()

        class C(B):
            @overload
            def f(self, x):
                return 1
            
            @overload
            def f(self, x):
                return u'x'

        self.assertEqual(C().f(2), 1)
        self.assertEqual(C().f(None), u'x')


@overload
def global_overload(x):
    return u's'

@overload
def global_overload(x):
    return u'i'


class Dummy(object):
    u"""Dummy class defined in module scope"""


if __name__ == u'__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = typing
u"""Static type checking helpers"""

from abc import ABCMeta, abstractmethod
import inspect
import sys
import re


__all__ = [
    # Type system related
    'AbstractGeneric',
    'AbstractGenericMeta',
    'Any',
    'BytesMatch',
    'BytesPattern',
    'Dict',
    'Generic',
    'GenericMeta',
    'List',
    'Match',
    'Pattern',
    'Protocol',
    'Set',
    'Tuple',
    'Undefined',
    'cast',
    'forwardref',
    'overload',
    'typevar',
    # Protocols and abstract base classes
    'Container',
    'Iterable',
    'Iterator',
    'Sequence',
    'Sized',
    'AbstractSet',
    'Mapping',
    'BinaryIO',
    'TextIO',
]


class GenericMeta(type):
    """Metaclass for generic classes that support indexing by types."""
    
    def __getitem__(self, args):
        # Just ignore args; they are for compile-time checks only.
        return self


class Generic(object):
    __metaclass__ = GenericMeta
    """Base class for generic classes."""


class AbstractGenericMeta(ABCMeta):
    """Metaclass for abstract generic classes that support type indexing.

    This is used for both protocols and ordinary abstract classes.
    """
    
    def __new__(mcls, name, bases, namespace):
        cls = ABCMeta.__new__(mcls, name, bases, namespace)
        # 'Protocol' must be an explicit base class in order for a class to
        # be a protocol.
        cls._is_protocol = name == u'Protocol' or Protocol in bases
        return cls
    
    def __getitem__(self, args):
        # Just ignore args; they are for compile-time checks only.
        return self


class Protocol(object):
    __metaclass__ = AbstractGenericMeta
    """Base class for protocol classes."""

    @classmethod
    def __subclasshook__(cls, c):
        if not cls._is_protocol:
            # No structural checks since this isn't a protocol.
            return NotImplemented
        
        if cls is Protocol:
            # Every class is a subclass of the empty protocol.
            return True

        # Find all attributes defined in the protocol.
        attrs = cls._get_protocol_attrs()

        for attr in attrs:
            if not any(attr in d.__dict__ for d in c.__mro__):
                return NotImplemented
        return True

    @classmethod
    def _get_protocol_attrs(cls):
        # Get all Protocol base classes.
        protocol_bases = []
        for c in cls.__mro__:
            if getattr(c, '_is_protocol', False) and c.__name__ != 'Protocol':
                protocol_bases.append(c)
        
        # Get attributes included in protocol.
        attrs = set()
        for base in protocol_bases:
            for attr in base.__dict__.keys():
                # Include attributes not defined in any non-protocol bases.
                for c in cls.__mro__:
                    if (c is not base and attr in c.__dict__ and
                            not getattr(c, '_is_protocol', False)):
                        break
                else:
                    if (not attr.startswith(u'_abc_') and
                        attr != '__abstractmethods__' and
                        attr != '_is_protocol' and
                        attr != '__dict__' and
                        attr != '_get_protocol_attrs' and
                        attr != '__module__'):
                        attrs.add(attr)
        
        return attrs


class AbstractGeneric(object):
    __metaclass__ = AbstractGenericMeta
    """Base class for abstract generic classes."""


class TypeAlias(object):
    """Class for defining generic aliases for library types."""
    
    def __init__(self, target_type):
        self.target_type = target_type
    
    def __getitem__(self, typeargs):
        return self.target_type


# Define aliases for built-in types that support indexing.
List = TypeAlias(list)
Dict = TypeAlias(dict)
Set = TypeAlias(set)
Tuple = TypeAlias(tuple)
Function = TypeAlias(callable)

# Give names to some built-in types.
Pattern = type(re.compile(u''))
BytesPattern = Pattern # TODO Pattern and BytesPattern shouldn't be the same!
Match = type(re.match(u'', u''))
BytesMatch = Match # TODO See above.


class typevar(object):
    def __init__(self, name):
        self.name = name


class forwardref(object):
    def __init__(self, name):
        self.name = name


def Any(x):
    """The Any type; can also be used to cast a value to type Any."""
    return x


def cast(type, object):
    """Cast a value to a type.

    This only affects static checking; simply return object at runtime.
    """
    return object


def overload(func):
    """Function decorator for defining overloaded functions."""
    frame = sys._getframe(1)
    locals = frame.f_locals
    # See if there is a previous overload variant available.  Also verify
    # that the existing function really is overloaded: otherwise, replace
    # the definition.  The latter is actually important if we want to reload
    # a library module such as genericpath with a custom one that uses
    # overloading in the implementation.
    if func.__name__ in locals and hasattr(locals[func.__name__], 'dispatch'):
        orig_func = locals[func.__name__]
        
        def wrapper(*args, **kwargs):
            ret, ok = orig_func.dispatch(*args, **kwargs)
            if ok:
                return ret
            return func(*args, **kwargs)
        wrapper.isoverload = True
        wrapper.dispatch = make_dispatcher(func, orig_func.dispatch)
        wrapper.next = orig_func
        wrapper.__name__ = func.__name__
        if hasattr(func, '__isabstractmethod__'):
            # Note that we can't reliably check that abstractmethod is
            # used consistently across overload variants, so we let a
            # static checker do it.
            wrapper.__isabstractmethod__ = func.__isabstractmethod__
        return wrapper
    else:
        # Return the initial overload variant.
        func.isoverload = True
        func.dispatch = make_dispatcher(func)
        func.next = None
        return func


def is_erased_type(t):
    return t is Any or isinstance(t, typevar)


def make_dispatcher(func, previous=None):
    """Create argument dispatcher for an overloaded function.

    Also handle chaining of multiple overload variants.
    """
    (args, varargs, varkw, defaults) = inspect.getargspec(func)
    
    argtypes = []
    for arg in args:
        ann = None # annotations.get(arg)
        if isinstance(ann, forwardref):
            ann = ann.name
        if is_erased_type(ann):
            ann = None
        elif isinstance(ann, unicode):
            # The annotation is a string => evaluate it lazily when the
            # overloaded function is first called.
            frame = sys._getframe(2)
            t = [None]
            ann_str = ann
            def check(x):
                if not t[0]:
                    # Evaluate string in the context of the overload caller.
                    t[0] = eval(ann_str, frame.f_globals, frame.f_locals)
                    if is_erased_type(t[0]):
                        # Anything goes.
                        t[0] = object
                if isinstance(t[0], type):
                    return isinstance(x, t[0])
                else:
                    return t[0](x)
            ann = check
        argtypes.append(ann)

    maxargs = len(argtypes)
    minargs = maxargs
    if defaults:
        minargs = len(argtypes) - len(defaults)
    
    def dispatch(*args, **kwargs):
        if previous:
            ret, ok = previous(*args, **kwargs)
            if ok:
                return ret, ok

        nargs = len(args)
        if nargs < minargs or nargs > maxargs:
            # Invalid argument count.
            return None, False
        
        for i in xrange(nargs):
            argtype = argtypes[i]
            if argtype:
                if isinstance(argtype, type):
                    if not isinstance(args[i], argtype):
                        break
                else:
                    if not argtype(args[i]):
                        break
        else:
            return func(*args, **kwargs), True
        return None, False
    return dispatch


class Undefined(object):
    """Class that represents an undefined value with a specified type.

    At runtime the name Undefined is bound to an instance of this
    class.  The intent is that any operation on an Undefined object
    raises an exception, including use in a boolean context.  Some
    operations cannot be disallowed: Undefined can be used as an
    operand of 'is', and it can be assigned to variables and stored in
    containers.

    'Undefined' makes it possible to declare the static type of a
    variable even if there is no useful default value to initialize it
    with:

      from typing import Undefined
      x = Undefined(int)
      y = Undefined # type: int

    The latter form can be used if efficiency is of utmost importance,
    since it saves a call operation and potentially additional
    operations needed to evaluate a type expression.  Undefined(x)
    just evaluates to Undefined, ignoring the argument value.
    """
    
    def __repr__(self):
        return '<typing.Undefined>'

    def __setattr__(self, attr, value):
        raise AttributeError("'Undefined' object has no attribute '%s'" % attr)

    def __eq__(self, other):
        raise TypeError("'Undefined' object cannot be compared")

    def __ne__(self, other):
        raise TypeError("'Undefined' object cannot be compared")

    def __call__(self, type):
        return self

    def __nonzero__(self):
        raise TypeError("'Undefined' object is not valid as a boolean")

    def __hash__(self):
        raise TypeError("'Undefined' object is not hashable")


Undefined = Undefined()


# Abstract classes


T = typevar('T')
KT = typevar('KT')
VT = typevar('VT')


class SupportsInt(Protocol):
    @abstractmethod
    def __int__(self): pass


class SupportsFloat(Protocol):
    @abstractmethod
    def __float__(self): pass


class SupportsAbs(Protocol[T]):
    @abstractmethod
    def __abs__(self): pass


class Reversible(Protocol[T]):
    @abstractmethod
    def __reversed__(self): pass


class Sized(Protocol):
    @abstractmethod
    def __len__(self): pass


class Container(Protocol[T]):
    @abstractmethod
    def __contains__(self, x): pass


class Iterable(Protocol[T]):
    @abstractmethod
    def __iter__(self): pass


class Iterator(Iterable[T], Protocol[T]):
    @abstractmethod
    def next(self): pass


class Sequence(Sized, Iterable[T], Container[T], AbstractGeneric[T]):
    @abstractmethod
    def __getitem__(self, i): pass
    
    @abstractmethod
    def __getitem__(self, s): pass
    
    @abstractmethod
    def __reversed__(self, s): pass
    
    @abstractmethod
    def index(self, x): pass
    
    @abstractmethod
    def count(self, x): pass


for t in list, tuple, unicode, str, xrange:
    Sequence.register(t)


class AbstractSet(Sized, Iterable[T], AbstractGeneric[T]):
    @abstractmethod
    def __contains__(self, x): pass
    @abstractmethod
    def __and__(self, s): pass
    @abstractmethod
    def __or__(self, s): pass
    @abstractmethod
    def __sub__(self, s): pass
    @abstractmethod
    def __xor__(self, s): pass
    @abstractmethod
    def isdisjoint(self, s): pass


for t in set, frozenset, type({}.keys()), type({}.items()):
    AbstractSet.register(t)


class Mapping(Sized, Iterable[KT], AbstractGeneric[KT, VT]):
    @abstractmethod
    def __getitem__(self, k): pass
    @abstractmethod
    def __setitem__(self, k, v): pass
    @abstractmethod
    def __delitem__(self, v): pass
    @abstractmethod
    def __contains__(self, o): pass

    @abstractmethod
    def clear(self): pass
    @abstractmethod
    def copy(self): pass
    @abstractmethod
    def get(self, k): pass
    @abstractmethod
    def get(self, k, default): pass
    @abstractmethod
    def pop(self, k): pass
    @abstractmethod
    def pop(self, k, default): pass
    @abstractmethod
    def popitem(self): pass
    @abstractmethod
    def setdefault(self, k): pass
    @abstractmethod
    def setdefault(self, k, default): pass
    
    @abstractmethod
    def update(self, m): pass
    @abstractmethod
    def update(self, m): pass
    
    @abstractmethod
    def keys(self): pass
    @abstractmethod
    def values(self): pass
    @abstractmethod
    def items(self): pass


# TODO Consider more types: os.environ, etc. However, these add dependencies.
Mapping.register(dict)


# Note that the BinaryIO and TextIO classes must be in sync with typing module stubs.


class BinaryIO(object):
    __metaclass__ = ABCMeta
    @abstractmethod
    def close(self): pass
    @abstractmethod
    def closed(self): pass
    @abstractmethod
    def fileno(self): pass
    @abstractmethod
    def flush(self): pass
    @abstractmethod
    def isatty(self): pass
    @abstractmethod
    def read(self, n = -1): pass
    @abstractmethod
    def readable(self): pass
    @abstractmethod
    def readline(self, limit = -1): pass
    @abstractmethod
    def readlines(self, hint = -1): pass
    @abstractmethod
    def seek(self, offset, whence = 0): pass
    @abstractmethod
    def seekable(self): pass
    @abstractmethod
    def tell(self): pass
    @abstractmethod
    def truncate(self, size = None): pass
    @abstractmethod
    def writable(self): pass
    @overload
    @abstractmethod
    def write(self, s): pass
    @overload
    @abstractmethod
    def write(self, s): pass
    @abstractmethod
    def writelines(self, lines): pass

    @abstractmethod
    def __enter__(self): pass
    @abstractmethod
    def __exit__(self, type, value, traceback): pass


class TextIO(object):
    __metaclass__ = ABCMeta
    @abstractmethod
    def close(self): pass
    @abstractmethod
    def closed(self): pass
    @abstractmethod
    def fileno(self): pass
    @abstractmethod
    def flush(self): pass
    @abstractmethod
    def isatty(self): pass
    @abstractmethod
    def read(self, n = -1): pass
    @abstractmethod
    def readable(self): pass
    @abstractmethod
    def readline(self, limit = -1): pass
    @abstractmethod
    def readlines(self, hint = -1): pass
    @abstractmethod
    def seek(self, offset, whence = 0): pass
    @abstractmethod
    def seekable(self): pass
    @abstractmethod
    def tell(self): pass
    @abstractmethod
    def truncate(self, size = None): pass
    @abstractmethod
    def writable(self): pass
    @abstractmethod
    def write(self, s): pass
    @abstractmethod
    def writelines(self, lines): pass

    @abstractmethod
    def __enter__(self): pass
    @abstractmethod
    def __exit__(self, type, value, traceback): pass


# TODO Register TextIO/BinaryIO as the base class of file-like types.


del t

########NEW FILE########
__FILENAME__ = test_typing
from abc import abstractmethod, ABCMeta
import unittest

from typing import (
    List, Dict, Set, Tuple, Pattern, Match, Any, Function, Generic,
    AbstractGeneric, Protocol, Sized, Iterable, Iterator, Sequence,
    AbstractSet, Mapping, BinaryIO, TextIO, SupportsInt, SupportsFloat,
    SupportsAbs, SupportsRound, Reversible, Undefined, AnyStr, builtinclass,
    cast, disjointclass, ducktype, forwardref, overload, typevar
)


class TestTyping(unittest.TestCase):
    def test_List(self):
        self.assertIs(List[int], list)
        self.assertIs(List[str], list)
        
    def test_Dict(self):
        self.assertIs(Dict[int, str], dict)
        self.assertIs(Dict[str, int], dict)
        
    def test_Set(self):
        self.assertIs(Set[int], set)
        self.assertIs(Set[str], set)
        
    def test_Tuple(self):
        self.assertIs(Tuple[int], tuple)
        self.assertIs(Tuple[str, int], tuple)
        self.assertIs(Tuple[str, int, bool], tuple)

    def test_Pattern(self):
        import re
        self.assertIs(type(re.compile('')), Pattern.target_type)
        self.assertIs(type(re.compile(b'')), Pattern.target_type)

    def test_Match(self):
        import re
        self.assertIs(type(re.match('', '')), Match.target_type)
        self.assertIs(type(re.match(b'', b'')), Match.target_type)
        
    def test_Any(self):
        o = object()
        self.assertIs(Any(o), o)
        s = 'x'
        self.assertIs(Any(s), s)

    def test_Function(self):
        # Just check that we can call Function. Don't care about return value.
        Function[[], int]
        Function[[int], None]
        Function[[int, str], bool]

    def test_cast(self):
        o = object()
        # cast performs no runtime checks!
        self.assertIs(cast(int, o), o)
        s = 'x'
        self.assertIs(cast(str, s), s)
        self.assertIs(cast('xyz', s), s)
        # cast does not check type validity; anything goes.
        self.assertIs(cast(o, s), s)

    def test_simple_overload(self):
        @overload
        def f(x:str) -> str: return x + 'string'
        @overload
        def f(x:int) -> str: return x + 1
        
        self.assertEqual(f('x'), 'xstring')
        self.assertEqual(f(1), 2)
        
        @overload
        def g(x:int) -> str: return 'integer'
        @overload
        def g(x:str) -> str: return 'string'
        
        self.assertEqual(g('x'), 'string')
        self.assertEqual(g(1), 'integer')

    def test_overload_with_three_variants(self):
        @overload
        def f(x:str) -> str: return 'string'
        @overload
        def f(x:int) -> str: return 'integer'
        @overload
        def f(x:float) -> str: return 'floating'
        
        self.assertEqual(f('x'), 'string')
        self.assertEqual(f(1), 'integer')
        self.assertEqual(f(1.0), 'floating')

    def test_overload_with_two_args(self):
        @overload
        def f(x:str, y:str) -> int: return (1, x, y)
        @overload
        def f(x:str, y:int) -> int: return (2, x, y)

        self.assertEqual(f('x', 'y'), (1, 'x', 'y'))
        self.assertEqual(f('z', 3), (2, 'z', 3))
        
        @overload
        def g(x:str, y:str) -> int: return 1
        @overload
        def g(x:int, y:str) -> int: return 2

        self.assertEqual(g('x', 'y'), 1)
        self.assertEqual(g('x', 1), 2)

    def test_global_overload(self):
        self.assertEqual(global_overload('x'), 's')
        self.assertEqual(global_overload(1), 'i')

    def test_partial_overload_annotation(self):
        @overload
        def f(x:str, y): return 1
        @overload
        def f(x, y:int): return 2

        self.assertEqual(f('x', object()), 1)
        self.assertEqual(f(object(), 1), 2)
        
    @overload
    def method_overload(self, x:str) -> str:
        return 's'
    
    @overload
    def method_overload(self, x:int) -> str:
        return 'i'

    def test_method_overload(self):
        self.assertEqual(self.method_overload('x'), 's')
        self.assertEqual(self.method_overload(1), 'i')

    def test_overload_with_any_type(self):
        @overload
        def f(x:Any, y:int): return 1
        @overload
        def f(x:Any, y:Any): return 2

        self.assertEqual(f((), 0), 1)
        self.assertEqual(f((), ()), 2)

    def test_overload_with_type_alias(self):
        @overload
        def f(x:List[int]): return 1
        @overload
        def f(x:Dict[int, str]): return 2
        @overload
        def f(x:Tuple[int, str]): return 3
        @overload
        def f(x): return 4

        self.assertEqual(f([]), 1)
        self.assertEqual(f({}), 2)
        self.assertEqual(f(()), 3)
        self.assertEqual(f((1, 'x')), 3)
        self.assertEqual(f(1), 4)

    def test_call_overload_with_invalid_arg_count(self):
        @overload
        def f(x:int): return 1
        @overload
        def f(x:Any): return 2

        msg1 = r'f\(\) takes exactly 1 argument \(%d given\)'
        msg2 = r'f\(\) takes exactly 1 positional argument \(%d given\)'
        
        with self.assertRaisesRegex(TypeError, msg1 % 0):
            f()
        with self.assertRaisesRegex(TypeError, msg2 % 2):
            f(1, 2)
        with self.assertRaisesRegex(TypeError, msg2 % 3):
            f('x', 'y', 'z')

    def test_overload_with_variable_argument_counts(self):
        @overload
        def f(): return None
        @overload
        def f(x): return x

        self.assertEqual(f(), None)
        self.assertEqual(f(1), 1)
        
        @overload
        def g(x): return x + 1
        @overload
        def g(): return None

        self.assertEqual(g(), None)
        self.assertEqual(g(1), 2)
        
        msg = r'g\(\) takes no arguments \(2 given\)'
        with self.assertRaisesRegex(TypeError, msg):
            g(1, 2)

    def test_overload_dispatch_order(self):
        class A: pass
        class B(A): pass
        class C(B): pass

        @overload
        def f(x:B): return 'B'
        @overload
        def f(x:A): return 'A'

        self.assertEqual(f(B()), 'B')
        self.assertEqual(f(A()), 'A')

        @overload
        def g(x:C): return 'C'
        @overload
        def g(x:B): return 'B'
        @overload
        def g(x:A): return 'A'

        self.assertEqual(g(C()), 'C')
        self.assertEqual(g(B()), 'B')
        self.assertEqual(g(A()), 'A')

    def test_name_of_overloaded_function(self):
        @overload
        def f(x:str): return 1
        @overload
        def f(x): return 2

        self.assertEqual(f.__name__, 'f')

    def test_overloaded_function_as_str(self):
        @overload
        def f(x:str): return 1
        @overload
        def f(x): return 2

        self.assertRegex(str(f), '^<function f at.*>$')

    def test_overload_with_default_arg_values(self):
        @overload
        def f(x:str='x'): return x + '!'
        @overload
        def f(y): return y + 1

        self.assertEqual(f(), 'x!')
        self.assertEqual(f('y'), 'y!')
        self.assertEqual(f(3), 4)
        
        @overload
        def g(a:int, x:str='x', y:str='z'): return 1
        @overload
        def g(a, x=1): return 2

        self.assertEqual(g(1), 1)
        self.assertEqual(g('x'), 2)
        self.assertEqual(g(1, 'XX'), 1)
        self.assertEqual(g(1, 2), 2)
        self.assertEqual(g(1, 'XX', 'YY'), 1)
        
        with self.assertRaises(TypeError):
            g(1, 'x', 2)

    def test_no_matching_overload(self):
        @overload
        def f(x:str): return 1
        @overload
        def f(x:int): return 2

        # Fall back to the last overload variant if no annotation matches.
        self.assertEqual(f(()), 2)

    def test_function_type_dispatch_in_overload(self):
        @overload
        def f(x:Function[[], str]): return 1
        @overload
        def f(x): return 2

        self.assertEqual(f(ord), 1)
        self.assertEqual(f(str.find), 1)
        self.assertEqual(f('x'.find), 1)
        self.assertEqual(f(str), 1)
        self.assertEqual(f(TestTyping), 1)
        self.assertEqual(f(self.test_function_type_dispatch_in_overload), 1)
        self.assertEqual(f(self.assertEqual), 1)
        self.assertEqual(f(TestTyping.assertEqual), 1)

        class A:
            def __call__(self): pass
            
        self.assertEqual(f(A()), 1)
        
        self.assertEqual(f(1), 2)
        self.assertEqual(f(object()), 2)

    def test_typevar(self):
        t = typevar('t')
        self.assertEqual(t.name, 't')
        self.assertIsNone(t.values)

    def test_typevar_values(self):
        t = typevar('t', values=(int, str))
        self.assertEqual(t.name, 't')
        self.assertEqual(t.values, (int, str))

    def test_predefined_typevars(self):
        self.assertEqual(AnyStr.name, 'AnyStr')
        self.assertEqual(AnyStr.values, (str, bytes))

    def test_typevar_in_overload(self):
        t = typevar('t')
        
        @overload
        def f(x:t, y:str): return 1
        @overload
        def f(x, y): return 2
        
        self.assertEqual(f((), 'x'), 1)
        self.assertEqual(f((), 1.1), 2)

    def test_simple_generic_class(self):
        t = typevar('t')

        class C(Generic[t]):
            pass

        self.assertIs(C[int], C)
        self.assertIsInstance(C(), C)
        self.assertIsInstance(C[int](), C)

    def test_generic_class_with_two_typeargs(self):
        t = typevar('t')
        u = typevar('u')

        class C(Generic[t, u]):
            pass

        self.assertIs(C[int, str], C)
        self.assertIsInstance(C(), C)
        self.assertIsInstance(C[int, str](), C)

    def test_abstract_generic_class(self):
        t = typevar('t')
        class C(AbstractGeneric[t]):
            pass
        class D:
            pass
        self.assertIs(C[int], C)
        self.assertNotIsInstance(D(), C)
        C.register(D)
        self.assertIsInstance(D(), C)

    def test_sequence(self):
        self.assertIs(Sequence[int], Sequence)
        
        self.assertIsInstance([], Sequence)
        self.assertIsInstance((), Sequence)
        self.assertIsInstance('', Sequence)
        self.assertIsInstance(b'', Sequence)
        self.assertIsInstance(range(5), Sequence)
        self.assertNotIsInstance({}, Sequence)

    def test_abstract_set(self):
        self.assertIs(AbstractSet[int], AbstractSet)
        
        self.assertIsInstance(set(), AbstractSet)
        self.assertIsInstance(frozenset(), AbstractSet)
        self.assertIsInstance({}.keys(), AbstractSet)
        self.assertIsInstance({}.items(), AbstractSet)
        # This is consistent with collections.Set.
        self.assertNotIsInstance({}.values(), AbstractSet)

    def test_mapping(self):
        self.assertIs(Mapping[int, str], Mapping)
        self.assertIsInstance({}, Mapping)

    def test_io_types(self):
        self.assertIsInstance(BinaryIO, type)
        self.assertIsInstance(TextIO, type)

    def test_supports_int(self):
        self.assertIsInstance(1, SupportsInt)
        self.assertIsInstance(1.1, SupportsInt)
        self.assertNotIsInstance('', SupportsInt)
        self.assertNotIsInstance(b'', SupportsInt)
        self.assertNotIsInstance((), SupportsInt)

    def test_supports_float(self):
        self.assertIsInstance(1.1, SupportsFloat)
        self.assertIsInstance(1, SupportsFloat)
        self.assertNotIsInstance('', SupportsFloat)
        self.assertNotIsInstance(b'', SupportsFloat)
        self.assertNotIsInstance((), SupportsFloat)

    def test_supports_abs(self):
        self.assertIsInstance(1.1, SupportsAbs)
        self.assertIsInstance(1, SupportsAbs)
        self.assertNotIsInstance('', SupportsAbs)
        self.assertNotIsInstance((), SupportsAbs)

    def test_supports_round(self):
        self.assertIsInstance(1.1, SupportsRound)
        self.assertIsInstance(1, SupportsRound)
        self.assertNotIsInstance('', SupportsRound)
        self.assertNotIsInstance((), SupportsRound)

    def test_reversible(self):
        self.assertIsInstance([], Reversible)
        self.assertIsInstance(range(1), Reversible)
        self.assertNotIsInstance((), Reversible)
        self.assertNotIsInstance('', Reversible)

    def test_simple_protocol(self):
        class P(Protocol):
            def f(self): pass

        class A:
            # Conforms to P
            def f(self): pass
            def g(self): pass

        class B:
            # Does not conform to P
            def g(self): pass

        self.assertIsInstance(A(), P)
        self.assertNotIsInstance(B(), P)
        
        self.assertTrue(issubclass(A, P))
        self.assertFalse(issubclass(B, P))
        self.assertTrue(issubclass(P, Protocol))
        self.assertTrue(issubclass(Protocol, Protocol))
        self.assertTrue(issubclass(A, Protocol))

    def test_issubclass_of_protocol(self):
        class A: pass
        self.assertTrue(issubclass(A, Protocol))

    def test_protocol_with_two_attrs(self):
        class P(Protocol):
            def __int__(self): pass
            x = 0

        class A:
            # Conforms to P; attribute values don't need to be similar
            __int__ = 0
            def x(self): pass
            def f(self): pass # Extra method

        class B:
            # Does not conform to P
            __int__ = 0
        class C:
            # Does not conform to P
            x = 0

        self.assertIsInstance(A(), P)
        self.assertNotIsInstance(B(), P)
        self.assertNotIsInstance(C(), P)

    def test_protocol_inheritance(self):
        class P(Protocol):
            def f(self): pass
        class PP(P, Protocol):
            def g(self): pass

        class A:
            # Conforms to P but not PP
            def f(self): pass
        class B:
            # Conforms to P and PP
            def f(self): pass
            def g(self): pass
        class C:
            # Conforms to neither P nor PP
            def g(self): pass

        self.assertIsInstance(A(), P)
        self.assertIsInstance(B(), P)
        self.assertIsInstance(B(), PP)
        self.assertNotIsInstance(A(), PP)
        self.assertNotIsInstance(C(), PP)

    def test_builtin_class_and_protocol(self):
        class P(Protocol):
            def __add__(self): pass

        self.assertIsInstance('', P)
        self.assertIsInstance([], P)
        self.assertIsInstance(1, P)
        self.assertNotIsInstance({}, P)
        
        self.assertTrue(issubclass(str, P))
        self.assertFalse(issubclass(dict, P))

    def test_generic_protocol(self):
        t = typevar('t')
        class P(Protocol[t]):
            x = 1
        class A:
            x = 2
        self.assertIsInstance(A(), P)

    def test_indexing_in_protocol(self):
        class P(Protocol):
            def __getitem__(self): pass
        class A:
            def __getitem__(self): pass
        class B:
            pass
        self.assertIsInstance(A(), P)
        self.assertNotIsInstance(B(), P)

    def test_sized(self):
        self.assertIsInstance([], Sized)
        self.assertIsInstance((), Sized)
        self.assertIsInstance('', Sized)
        self.assertIsInstance(b'', Sized)
        self.assertIsInstance({}, Sized)
        self.assertIsInstance(set(), Sized)
        self.assertIsInstance(range(5), Sized)
        self.assertNotIsInstance(1, Sized)

        class A:
            def __len__(self): pass

        self.assertIsInstance(A(), Sized)

    def test_iterable(self):
        self.assertIsInstance([], Iterable)
        class A:
            def __iter__(self): pass
            def g(self): pass
        self.assertIsInstance(A(), Iterable)
        self.assertNotIsInstance(1, Iterable)

    def test_iterator(self):
        self.assertIsInstance(iter(''), Iterator)
        self.assertIsInstance(iter([]), Iterator)
        self.assertIsInstance(iter({}), Iterator)        
        self.assertNotIsInstance([], Iterator)
        
        class A:
            def __iter__(self): pass
            def __next__(self): pass
        self.assertIsInstance(A(), Iterator)
        
        class B:
            def __iter__(self): pass
        self.assertNotIsInstance(B(), Iterator)
        
        class C:
            def __next__(self): pass
        self.assertNotIsInstance(C(), Iterator)

    def test_class_inheritance_and_protocols(self):
        class A:
            def __iter__(self): pass
        class B(A):
            def __next__(self): pass
        self.assertIsInstance(B(), Iterator)
        self.assertNotIsInstance(A(), Iterator)

    def test_class_multiple_inheritance_and_protocols(self):
        class A:
            def __iter__(self): pass
        class B:
            def __next__(self): pass
        class C(A, B): pass
        self.assertIsInstance(C(), Iterator)
        self.assertNotIsInstance(A(), Iterator)
        self.assertNotIsInstance(B(), Iterator)

    def test_multiple_protocol_inheritance(self):
        class P(Protocol):
            x = 1
        class P2(Protocol):
            y = 1
        class P3(P, P2, Protocol): pass

        class A:
            x = 1
            y = 1
        class B:
            x = 1
        class C:
            y = 1

        self.assertIsInstance(A(), P3)
        self.assertNotIsInstance(B(), P3)
        self.assertNotIsInstance(C(), P3)

    def test_protocol_docstrings(self):
        class P(Protocol):
            """blah"""
            def f(self): pass
        class A:
            def f(self): pass
        self.assertIsInstance(A(), P)

    def test_forward_ref_in_annotation(self):
        A = forwardref('A')
        def f(a:A) -> A:
            return a
        self.assertEqual(A.name, 'A')
        class A: pass

    def test_string_literal_in_annotation(self):
        def f(a:'str') -> 'str':
            return a + 'x'
        def f(a:'Iterable[int]') -> 'List[int]':
            return list(a)

    def test_undefined(self):
        self.assertEqual(str(Undefined), '<typing.Undefined>')
        with self.assertRaises(AttributeError):
            Undefined.x = 1
        with self.assertRaises(AttributeError):
            Undefined.x
        with self.assertRaises(TypeError):
            if Undefined == 0: pass
        with self.assertRaises(TypeError):
            if Undefined != 0: pass
        with self.assertRaises(TypeError):
            hash(Undefined)
        with self.assertRaises(TypeError):
            if Undefined: pass
        with self.assertRaises(TypeError):
            if not Undefined: pass

    def test_simple_string_literal_in_overload(self):
        @overload
        def f(a:'str') -> str: return 's'
        @overload
        def f(a:'int') -> str: return 'i'
        
        self.assertEqual(f(''), 's')
        self.assertEqual(f(2), 'i')

    def test_module_ref_string_literal_in_overload(self):
        @overload
        def f(a:'Dummy'): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f(Dummy()), 1)
        self.assertEqual(f(2), 2)

    def test_module_ref_string_literal_in_overload(self):
        @overload
        def f(a:'Dummy'): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f(Dummy()), 1)
        self.assertEqual(f(2), 2)

    def test_local_ref_string_literal_in_overload(self):
        @overload
        def f(a:'C'): return 1
        @overload
        def f(a): return 2
        
        class C: pass
        self.assertEqual(f(C()), 1)
        self.assertEqual(f(2), 2)

    def test_any_string_literal_in_overload(self):
        @overload
        def f(a:'Any'): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f(object()), 1)
        self.assertEqual(f(None), 1)

    def test_generic_type_string_literal_in_overload(self):
        @overload
        def f(a:'List[int]'): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f([]), 1)
        self.assertEqual(f(()), 2)

    def test_tuple_type_string_literal_in_overload(self):
        @overload
        def f(a:'Tuple[int]'): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f(()), 1)
        self.assertEqual(f([]), 2)

    def test_function_type_string_literal_in_overload(self):
        @overload
        def f(a:'Function[[], int]'): return 1
        @overload
        def f(a): return 2
        
        self.assertEqual(f(ord), 1)
        self.assertEqual(f([]), 2)

    def test_forward_ref_in_overload(self):
        A = forwardref('A')

        @overload
        def f(a:A): return 1
        @overload
        def f(a): return 2

        class A: pass

        self.assertEqual(f(A()), 1)
        self.assertEqual(f(object()), 2)

    def test_construct_class_with_abstract_method(self):
        t = typevar('t')
        
        class A(AbstractGeneric[t]):
            @abstractmethod
            def f(self): pass

        class B(A):
            def f(self): pass

        with self.assertRaises(TypeError):
            A()
        B()

    def test_protocol_with_abstract_method(self):
        class A(Protocol):
            @abstractmethod
            def f(self): pass
            
        with self.assertRaises(TypeError):
            A() # No implementation for abstract method.

    def test_protocol_inheritance(self):
        class A(Protocol):
            def f(self): return 1
        class B(A): pass
        
        self.assertEqual(B().f(), 1)

        class C(A): pass
        # B is not a protocol since it doesn't explicitly subclass Protocol.
        self.assertNotIsInstance(C(), B)

    def test_protocol_inheritance_with_abstract_method(self):
        class A(Protocol):
            @abstractmethod
            def f(self): pass
        class B(A):
            pass
        
        with self.assertRaises(TypeError):
            B() # No implementation for abstract method.
        class C(A):
            def f(self): pass
        C()

    def test_overloaded_abstract_method(self):
        class A(metaclass=ABCMeta):
            @abstractmethod
            @overload
            def f(self, x:int): pass
            @abstractmethod
            @overload
            def f(self, x): pass

        with self.assertRaises(TypeError):
            A()
            
        class B(metaclass=ABCMeta):
            @overload
            @abstractmethod
            def f(self, x:int) -> int: pass
            
            @overload
            @abstractmethod
            def f(self, x) ->None: pass

        with self.assertRaises(TypeError):
            B()

        class C(B):
            @overload
            def f(self, x:int) -> int:
                return 1
            
            @overload
            def f(self, x):
                return 'x'

        self.assertEqual(C().f(2), 1)
        self.assertEqual(C().f(None), 'x')

    def test_builtinclass(self):
        class A: pass
        self.assertIs(builtinclass(int), int)
        self.assertIs(builtinclass(A), A)

    def test_ducktype(self):
        class A: pass
        self.assertIs(ducktype(str)(A), A)

    def test_disjointclass(self):
        class A: pass
        self.assertIs(disjointclass(str)(A), A)
        self.assertIs(disjointclass('str')(A), A)


@overload
def global_overload(x:str) -> str:
    return 's'

@overload
def global_overload(x:int) -> str:
    return 'i'


class Dummy:
    """Dummy class defined in module scope"""


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = typing
"""Static type checking helpers"""

from abc import ABCMeta, abstractmethod, abstractproperty
import inspect
import sys
import re


__all__ = [
    # Type system related
    'AbstractGeneric',
    'AbstractGenericMeta',
    'Any',
    'Dict',
    'Generic',
    'GenericMeta',
    'IO',
    'List',
    'Match',
    'Pattern',
    'Protocol',
    'Set',
    'Tuple',
    'Undefined',
    'cast',
    'forwardref',
    'overload',
    'typevar',
    # Protocols and abstract base classes
    'Container',
    'Iterable',
    'Iterator',
    'Sequence',
    'Sized',
    'AbstractSet',
    'Mapping',
    'BinaryIO',
    'TextIO',
]


def builtinclass(cls):
    """Mark a class as a built-in/extension class for type checking."""
    return cls


def ducktype(type):
    """Return a duck type declaration decorator.

    The decorator only affects type checking.
    """
    def decorator(cls):
        return cls
    return decorator


def disjointclass(type):
    """Return a disjoint class declaration decorator.

    The decorator only affects type checking.
    """
    def decorator(cls):
        return cls
    return decorator


class GenericMeta(type):
    """Metaclass for generic classes that support indexing by types."""
    
    def __getitem__(self, args):
        # Just ignore args; they are for compile-time checks only.
        return self


class Generic(metaclass=GenericMeta):
    """Base class for generic classes."""


class AbstractGenericMeta(ABCMeta):
    """Metaclass for abstract generic classes that support type indexing.

    This is used for both protocols and ordinary abstract classes.
    """
    
    def __new__(mcls, name, bases, namespace):
        cls = super().__new__(mcls, name, bases, namespace)
        # 'Protocol' must be an explicit base class in order for a class to
        # be a protocol.
        cls._is_protocol = name == 'Protocol' or Protocol in bases
        return cls
    
    def __getitem__(self, args):
        # Just ignore args; they are for compile-time checks only.
        return self


class Protocol(metaclass=AbstractGenericMeta):
    """Base class for protocol classes."""

    @classmethod
    def __subclasshook__(cls, c):
        if not cls._is_protocol:
            # No structural checks since this isn't a protocol.
            return NotImplemented
        
        if cls is Protocol:
            # Every class is a subclass of the empty protocol.
            return True

        # Find all attributes defined in the protocol.
        attrs = cls._get_protocol_attrs()

        for attr in attrs:
            if not any(attr in d.__dict__ for d in c.__mro__):
                return NotImplemented
        return True

    @classmethod
    def _get_protocol_attrs(cls):
        # Get all Protocol base classes.
        protocol_bases = []
        for c in cls.__mro__:
            if getattr(c, '_is_protocol', False) and c.__name__ != 'Protocol':
                protocol_bases.append(c)
        
        # Get attributes included in protocol.
        attrs = set()
        for base in protocol_bases:
            for attr in base.__dict__.keys():
                # Include attributes not defined in any non-protocol bases.
                for c in cls.__mro__:
                    if (c is not base and attr in c.__dict__ and
                            not getattr(c, '_is_protocol', False)):
                        break
                else:
                    if (not attr.startswith('_abc_') and
                        attr != '__abstractmethods__' and
                        attr != '_is_protocol' and
                        attr != '__dict__' and
                        attr != '_get_protocol_attrs' and
                        attr != '__module__'):
                        attrs.add(attr)
        
        return attrs


class AbstractGeneric(metaclass=AbstractGenericMeta):
    """Base class for abstract generic classes."""


class TypeAlias:
    """Class for defining generic aliases for library types."""
    
    def __init__(self, target_type):
        self.target_type = target_type
    
    def __getitem__(self, typeargs):
        return self.target_type


Traceback = object() # TODO proper type object


# Define aliases for built-in types that support indexing.
List = TypeAlias(list)
Dict = TypeAlias(dict)
Set = TypeAlias(set)
Tuple = TypeAlias(tuple)
Function = TypeAlias(callable)
Pattern = TypeAlias(type(re.compile('')))
Match = TypeAlias(type(re.match('', '')))


class typevar:
    def __init__(self, name, *, values=None):
        self.name = name
        self.values = values


# Predefined type variables.
AnyStr = typevar('AnyStr', values=(str, bytes))


class forwardref:
    def __init__(self, name):
        self.name = name


def Any(x):
    """The Any type; can also be used to cast a value to type Any."""
    return x


def cast(type, object):
    """Cast a value to a type.

    This only affects static checking; simply return object at runtime.
    """
    return object


def overload(func):
    """Function decorator for defining overloaded functions."""
    frame = sys._getframe(1)
    locals = frame.f_locals
    # See if there is a previous overload variant available.  Also verify
    # that the existing function really is overloaded: otherwise, replace
    # the definition.  The latter is actually important if we want to reload
    # a library module such as genericpath with a custom one that uses
    # overloading in the implementation.
    if func.__name__ in locals and hasattr(locals[func.__name__], 'dispatch'):
        orig_func = locals[func.__name__]
        
        def wrapper(*args, **kwargs):
            ret, ok = orig_func.dispatch(*args, **kwargs)
            if ok:
                return ret
            return func(*args, **kwargs)
        wrapper.isoverload = True
        wrapper.dispatch = make_dispatcher(func, orig_func.dispatch)
        wrapper.next = orig_func
        wrapper.__name__ = func.__name__
        if hasattr(func, '__isabstractmethod__'):
            # Note that we can't reliably check that abstractmethod is
            # used consistently across overload variants, so we let a
            # static checker do it.
            wrapper.__isabstractmethod__ = func.__isabstractmethod__
        return wrapper
    else:
        # Return the initial overload variant.
        func.isoverload = True
        func.dispatch = make_dispatcher(func)
        func.next = None
        return func


def is_erased_type(t):
    return t is Any or isinstance(t, typevar)


def make_dispatcher(func, previous=None):
    """Create argument dispatcher for an overloaded function.

    Also handle chaining of multiple overload variants.
    """
    (args, varargs, varkw, defaults,
     kwonlyargs, kwonlydefaults, annotations) = inspect.getfullargspec(func)
    
    argtypes = []
    for arg in args:
        ann = annotations.get(arg)
        if isinstance(ann, forwardref):
            ann = ann.name
        if is_erased_type(ann):
            ann = None
        elif isinstance(ann, str):
            # The annotation is a string => evaluate it lazily when the
            # overloaded function is first called.
            frame = sys._getframe(2)
            t = [None]
            ann_str = ann
            def check(x):
                if not t[0]:
                    # Evaluate string in the context of the overload caller.
                    t[0] = eval(ann_str, frame.f_globals, frame.f_locals)
                    if is_erased_type(t[0]):
                        # Anything goes.
                        t[0] = object
                if isinstance(t[0], type):
                    return isinstance(x, t[0])
                else:
                    return t[0](x)
            ann = check
        argtypes.append(ann)

    maxargs = len(argtypes)
    minargs = maxargs
    if defaults:
        minargs = len(argtypes) - len(defaults)
    
    def dispatch(*args, **kwargs):
        if previous:
            ret, ok = previous(*args, **kwargs)
            if ok:
                return ret, ok

        nargs = len(args)
        if nargs < minargs or nargs > maxargs:
            # Invalid argument count.
            return None, False
        
        for i in range(nargs):
            argtype = argtypes[i]
            if argtype:
                if isinstance(argtype, type):
                    if not isinstance(args[i], argtype):
                        break
                else:
                    if not argtype(args[i]):
                        break
        else:
            return func(*args, **kwargs), True
        return None, False
    return dispatch


class Undefined:
    """Class that represents an undefined value with a specified type.

    At runtime the name Undefined is bound to an instance of this
    class.  The intent is that any operation on an Undefined object
    raises an exception, including use in a boolean context.  Some
    operations cannot be disallowed: Undefined can be used as an
    operand of 'is', and it can be assigned to variables and stored in
    containers.

    'Undefined' makes it possible to declare the static type of a
    variable even if there is no useful default value to initialize it
    with:

      from typing import Undefined
      x = Undefined(int)
      y = Undefined # type: int

    The latter form can be used if efficiency is of utmost importance,
    since it saves a call operation and potentially additional
    operations needed to evaluate a type expression.  Undefined(x)
    just evaluates to Undefined, ignoring the argument value.
    """
    
    def __repr__(self):
        return '<typing.Undefined>'

    def __setattr__(self, attr, value):
        raise AttributeError("'Undefined' object has no attribute '%s'" % attr)

    def __eq__(self, other):
        raise TypeError("'Undefined' object cannot be compared")

    def __call__(self, type):
        return self

    def __bool__(self):
        raise TypeError("'Undefined' object is not valid as a boolean")


Undefined = Undefined()


# Abstract classes


T = typevar('T')
KT = typevar('KT')
VT = typevar('VT')


class SupportsInt(Protocol):
    @abstractmethod
    def __int__(self) -> int: pass


class SupportsFloat(Protocol):
    @abstractmethod
    def __float__(self) -> float: pass


class SupportsAbs(Protocol[T]):
    @abstractmethod
    def __abs__(self) -> T: pass


class SupportsRound(Protocol[T]):
    @abstractmethod
    def __round__(self, ndigits: int = 0) -> T: pass


class Reversible(Protocol[T]):
    @abstractmethod
    def __reversed__(self) -> 'Iterator[T]': pass


class Sized(Protocol):
    @abstractmethod
    def __len__(self) -> int: pass


class Container(Protocol[T]):
    @abstractmethod
    def __contains__(self, x) -> bool: pass


class Iterable(Protocol[T]):
    @abstractmethod
    def __iter__(self) -> 'Iterator[T]': pass


class Iterator(Iterable[T], Protocol[T]):
    @abstractmethod
    def __next__(self) -> T: pass


class Sequence(Sized, Iterable[T], Container[T], AbstractGeneric[T]):
    @abstractmethod
    @overload
    def __getitem__(self, i: int) -> T: pass
    
    @abstractmethod
    @overload
    def __getitem__(self, s: slice) -> 'Sequence[T]': pass
    
    @abstractmethod
    def __reversed__(self, s: slice) -> Iterator[T]: pass
    
    @abstractmethod
    def index(self, x) -> int: pass
    
    @abstractmethod
    def count(self, x) -> int: pass


for t in list, tuple, str, bytes, range:
    Sequence.register(t)


class AbstractSet(Sized, Iterable[T], AbstractGeneric[T]):
    @abstractmethod
    def __contains__(self, x: object) -> bool: pass
    @abstractmethod
    def __and__(self, s: 'AbstractSet[T]') -> 'AbstractSet[T]': pass
    @abstractmethod
    def __or__(self, s: 'AbstractSet[T]') -> 'AbstractSet[T]': pass
    @abstractmethod
    def __sub__(self, s: 'AbstractSet[T]') -> 'AbstractSet[T]': pass
    @abstractmethod
    def __xor__(self, s: 'AbstractSet[T]') -> 'AbstractSet[T]': pass
    @abstractmethod
    def isdisjoint(self, s: 'AbstractSet[T]') -> bool: pass


for t in set, frozenset, type({}.keys()), type({}.items()):
    AbstractSet.register(t)


class Mapping(Sized, Iterable[KT], AbstractGeneric[KT, VT]):
    @abstractmethod
    def __getitem__(self, k: KT) -> VT: pass
    @abstractmethod
    def __setitem__(self, k: KT, v: VT) -> None: pass
    @abstractmethod
    def __delitem__(self, v: KT) -> None: pass
    @abstractmethod
    def __contains__(self, o: object) -> bool: pass

    @abstractmethod
    def clear(self) -> None: pass
    @abstractmethod
    def copy(self) -> 'Mapping[KT, VT]': pass
    @overload
    @abstractmethod
    def get(self, k: KT) -> VT: pass
    @overload
    @abstractmethod
    def get(self, k: KT, default: VT) -> VT: pass
    @overload
    @abstractmethod
    def pop(self, k: KT) -> VT: pass
    @overload
    @abstractmethod
    def pop(self, k: KT, default: VT) -> VT: pass
    @abstractmethod
    def popitem(self) -> Tuple[KT, VT]: pass
    @overload
    @abstractmethod
    def setdefault(self, k: KT) -> VT: pass
    @overload
    @abstractmethod
    def setdefault(self, k: KT, default: VT) -> VT: pass
    
    @overload
    @abstractmethod
    def update(self, m: 'Mapping[KT, VT]') -> None: pass
    @overload
    @abstractmethod
    def update(self, m: Iterable[Tuple[KT, VT]]) -> None: pass
    
    @abstractmethod
    def keys(self) -> AbstractSet[KT]: pass
    @abstractmethod
    def values(self) -> AbstractSet[VT]: pass
    @abstractmethod
    def items(self) -> AbstractSet[Tuple[KT, VT]]: pass


# TODO Consider more types: os.environ, etc. However, these add dependencies.
Mapping.register(dict)


# Note that the BinaryIO and TextIO classes must be in sync with typing module
# stubs.


class IO(AbstractGeneric[AnyStr]):
    @abstractproperty
    def mode(self) -> str: pass
    @abstractproperty
    def name(self) -> str: pass
    @abstractmethod
    def close(self) -> None: pass
    @abstractmethod
    def closed(self) -> bool: pass
    @abstractmethod
    def fileno(self) -> int: pass
    @abstractmethod
    def flush(self) -> None: pass
    @abstractmethod
    def isatty(self) -> bool: pass
    @abstractmethod
    def read(self, n: int = -1) -> AnyStr: pass
    @abstractmethod
    def readable(self) -> bool: pass
    @abstractmethod
    def readline(self, limit: int = -1) -> AnyStr: pass
    @abstractmethod
    def readlines(self, hint: int = -1) -> List[AnyStr]: pass
    @abstractmethod
    def seek(self, offset: int, whence: int = 0) -> int: pass
    @abstractmethod
    def seekable(self) -> bool: pass
    @abstractmethod
    def tell(self) -> int: pass
    @abstractmethod
    def truncate(self, size: int = None) -> int: pass
    @abstractmethod
    def writable(self) -> bool: pass
    @abstractmethod
    def write(self, s: AnyStr) -> int: pass
    @abstractmethod
    def writelines(self, lines: List[AnyStr]) -> None: pass

    @abstractmethod
    def __enter__(self) -> 'IO[AnyStr]': pass
    @abstractmethod
    def __exit__(self, type, value, traceback) -> None: pass


class BinaryIO(IO[bytes]):
    @overload
    @abstractmethod
    def write(self, s: bytes) -> int: pass
    @overload
    @abstractmethod
    def write(self, s: bytearray) -> int: pass

    @abstractmethod
    def __enter__(self) -> 'BinaryIO': pass


class TextIO(IO[str]):
    @abstractproperty
    def buffer(self) -> BinaryIO: pass
    @abstractproperty
    def encoding(self) -> str: pass
    @abstractproperty
    def errors(self) -> str: pass
    @abstractproperty
    def line_buffering(self) -> bool: pass
    @abstractproperty
    def newlines(self) -> Any: pass
    @abstractmethod
    def __enter__(self) -> 'TextIO': pass


# TODO Register IO/TextIO/BinaryIO as the base class of file-like types.


del t

########NEW FILE########
__FILENAME__ = build
"""Facilities to build mypy programs and modules they depend on.

Parse, analyze and translate the source files of a program in the correct
order (based on file dependencies), and collect the results.

This module only directs a build, which is performed in multiple passes per
file.  The individual passes are implemented in separate modules.

The function build() is the main interface to this module.
"""

import os
import os.path
import shlex
import subprocess
import sys
from os.path import dirname, basename

from typing import Undefined, Dict, List, Tuple, cast, Set

from mypy.types import Type
from mypy.nodes import MypyFile, Node, Import, ImportFrom, ImportAll
from mypy.nodes import SymbolTableNode, MODULE_REF
from mypy.semanal import SemanticAnalyzer, FirstPass, ThirdPass
from mypy.checker import TypeChecker
from mypy.errors import Errors, CompileError
from mypy.icode import FuncIcode
from mypy import cgen
from mypy import icode
from mypy import parse
from mypy import transform


debug = False


# Build targets (for selecting compiler passes)
SEMANTIC_ANALYSIS = 0   # Semantic analysis only
TYPE_CHECK = 1          # Type check
TRANSFORM = 3           # Type check and transform for runtime type checking
ICODE = 4               # All TRANSFORM passes + generate icode
C = 5                   # All ICODE passes + generate C and compile it


# Build flags
COMPILE_ONLY = 'compile-only'   # Compile only to C, do not generate binary
VERBOSE = 'verbose'             # More verbose messages (for troubleshooting)
MODULE = 'module'               # Build/run module as a script
TEST_BUILTINS = 'test-builtins' # Use stub builtins to speed up tests


# State ids. These describe the states a source file / module can be in a
# build.

# We aren't processing this source file yet (no associated state object).
UNSEEN_STATE = 0
# The source file has a state object, but we haven't done anything with it yet.
UNPROCESSED_STATE = 1
# We've parsed the source file.
PARSED_STATE = 2
# We've done the first two passes of semantic analysis.
PARTIAL_SEMANTIC_ANALYSIS_STATE = 3
# We've semantically analyzed the source file.
SEMANTICALLY_ANALYSED_STATE = 4
# We've type checked the source file (and all its dependencies).
TYPE_CHECKED_STATE = 5


final_state = TYPE_CHECKED_STATE


def earlier_state(s: int, t: int) -> bool:
    return s < t


class BuildResult:
    """The result of a successful build.

    Attributes:
      files:  Dictionary from module name to related AST node.
      types:  Dictionary from parse tree node to its inferred type.
      icode:  Dictionary from function name to related Icode.
      binary_path: Path of generated binary file (for the C back end,
                   None otherwise)
    """

    def __init__(self, files: Dict[str, MypyFile],
                 types: Dict[Node, Type],
                 icode: Dict[str, FuncIcode],
                 binary_path: str) -> None:
        self.files = files
        self.types = types
        self.icode = icode
        self.binary_path = binary_path


def build(program_path: str,
          target: int,
          module: str = None,
          program_text: str = None,
          alt_lib_path: str = None,
          bin_dir: str = None,
          output_dir: str = None,
          pyversion: int = 3,
          flags: List[str] = None) -> BuildResult:
    """Build a mypy program.

    A single call to build performs parsing, semantic analysis and optionally
    type checking and other build passes for the program *and* all imported
    modules, recursively.

    Return BuildResult if successful; otherwise raise CompileError.
    
    Arguments:
      program_path: the path to the main source file (if module argument is
        given, this can be None => will be looked up)
      target: select passes to perform (a build target constant, e.g. C)
    Optional arguments:
      module: name of the initial module; __main__ by default
      program_text: the main source file contents; if omitted, read from file
      alt_lib_dir: an additional directory for looking up library modules
        (takes precedence over other directories)
      bin_dir: directory containing the mypy script, used for finding data
        directories; if omitted, use '.' as the data directory
      output_dir: directory where the output (Python) is stored
      pyversion: Python version (2 for 2.x or 3 for 3.x)
      flags: list of build options (e.g. COMPILE_ONLY)
    """
    flags = flags or []
    module = module or '__main__'

    data_dir = default_data_dir(bin_dir)
    
    # Determine the default module search path.
    lib_path = default_lib_path(data_dir, target, pyversion)
    
    if TEST_BUILTINS in flags:
        # Use stub builtins (to speed up test cases and to make them easier to
        # debug).
        lib_path.insert(0, os.path.join('mypy', 'test', 'data', 'lib-stub'))
    elif program_path:
        # Include directory of the program file in the module search path.
        lib_path.insert(
            0, remove_cwd_prefix_from_path(dirname(program_path)))
    else:
        # Building/running a module.
        lib_path.insert(0, os.getcwd())
    
    # If provided, insert the caller-supplied extra module path to the
    # beginning (highest priority) of the search path.
    if alt_lib_path:
        lib_path.insert(0, alt_lib_path)
    
    # Construct a build manager object that performs all the stages of the
    # build in the correct order.
    #
    # Ignore current directory prefix in error messages.
    manager = BuildManager(data_dir, lib_path, target, output_dir,
                           pyversion=pyversion, flags=flags,
                           ignore_prefix=os.getcwd())

    program_path = program_path or lookup_program(module, lib_path)
    if program_text is None:
        program_text = read_program(program_path)
    
    # Construct information that describes the initial file. __main__ is the
    # implicit module id and the import context is empty initially ([]).
    info = StateInfo(program_path, module, [], manager)
    # Perform the build by sending the file as new file (UnprocessedFile is the
    # initial state of all files) to the manager. The manager will process the
    # file and all dependant modules recursively.
    return manager.process(UnprocessedFile(info, program_text))


def default_data_dir(bin_dir: str) -> str:
    if not bin_dir:
        # Default to current directory.
        return ''
    base = os.path.basename(bin_dir)
    dir = os.path.dirname(bin_dir)
    if (sys.platform == 'win32' and base.lower() == 'scripts'
            and not os.path.isdir(os.path.join(dir, 'stubs'))):
        # Installed, on Windows.
        return os.path.join(dir, 'Lib', 'mypy')
    elif base == 'scripts':
        # Assume that we have a repo check out or unpacked source tarball.
        return os.path.dirname(bin_dir)
    elif base == 'bin':
        # Installed to somewhere (can be under /usr/local or anywhere).
        return os.path.join(dir, 'lib', 'mypy')
    elif base == 'python3':
        # Assume we installed python3 with brew on os x
        return os.path.join(os.path.dirname(dir), 'lib', 'mypy')
    else:
        # Don't know where to find the data files!
        raise RuntimeError("Broken installation: can't determine base dir")


def default_lib_path(data_dir: str, target: int, pyversion: int) -> List[str]:
    """Return default standard library search paths."""
    # IDEA: Make this more portable.
    path = List[str]()
    
    # Add MYPYPATH environment variable to library path, if defined.
    path_env = os.getenv('MYPYPATH')
    if path_env is not None:
        path[:0] = path_env.split(os.pathsep)

    if target in [ICODE, C]:
        # Add C back end library directory.
        path.append(os.path.join(data_dir, 'lib'))
    else:
        # Add library stubs directory. By convention, they are stored in the
        # stubs/x.y directory of the mypy installation.
        version_dir = '3.2'
        if pyversion < 3:
            version_dir = '2.7'
        path.append(os.path.join(data_dir, 'stubs', version_dir))
        path.append(os.path.join(data_dir, 'stubs-auto', version_dir))
    
    # Add fallback path that can be used if we have a broken installation.
    if sys.platform != 'win32':
        path.append('/usr/local/lib/mypy')
    
    return path


def lookup_program(module: str, lib_path: List[str]) -> str:
    path = find_module(module, lib_path)
    if path:
        return path
    else:
        raise CompileError([
            "mypy: can't find module '{}'".format(module)])


def read_program(path: str) -> str:
    try:
        f = open(path)
        text = f.read()
        f.close()
    except IOError as ioerr:
        raise CompileError([
            "mypy: can't read file '{}': {}".format(path, ioerr.strerror)])
    return text


class BuildManager:
    """This is the central class for building a mypy program.

    It coordinates parsing, import processing, semantic analysis and
    type checking. It manages state objects that actually perform the
    build steps.

    Attributes:
      data_dir:        Mypy data directory (contains stubs)
      target:          Build target; selects which passes to perform
      lib_path:        Library path for looking up modules
      semantic_analyzer:
                       Semantic analyzer, pass 2
      semantic_analyzer_pass3:
                       Semantic analyzer, pass 3
      type_checker:    Type checker
      errors:          Used for reporting all errors
      output_dir:      Store output files here (Python)
      pyversion:       Python version (2 or 3)
      flags:           Build options
      states:          States of all individual files that are being
                       processed. Each file in a build is always represented
                       by a single state object (after it has been encountered
                       for the first time). This is the only place where
                       states are stored.
      module_files:    Map from module name to source file path. There is a
                       1:1 mapping between modules and source files.
      icode:           Generated icode (when compiling via C)
      binary_path:     Path of the generated binary (or None)
      module_deps:     Cache for module dependencies (direct or indirect).
                       Item (m, n) indicates whether m depends on n (directly
                       or indirectly).
      missing_modules: Set of modules that could not be imported encountered so far

    TODO Refactor code related to transformation, icode generation etc. to
         external objects.  This module should not directly depend on them.
    """
    
    def __init__(self, data_dir: str,
                 lib_path: List[str],
                 target: int,
                 output_dir: str,
                 pyversion: int,
                 flags: List[str],
                 ignore_prefix: str) -> None:
        self.data_dir = data_dir
        self.errors = Errors()
        self.errors.set_ignore_prefix(ignore_prefix)
        self.lib_path = lib_path
        self.target = target
        self.output_dir = output_dir
        self.pyversion = pyversion
        self.flags = flags
        self.semantic_analyzer = SemanticAnalyzer(lib_path, self.errors)
        self.semantic_analyzer_pass3 = ThirdPass(self.errors)
        self.type_checker = TypeChecker(self.errors,
                                        self.semantic_analyzer.modules,
                                        self.pyversion)
        self.states = List[State]()
        self.module_files = Dict[str, str]()
        self.icode = Dict[str, FuncIcode]()
        self.binary_path = None # type: str
        self.module_deps = Dict[Tuple[str, str], bool]()
        self.missing_modules = Set[str]()
    
    def process(self, initial_state: 'UnprocessedFile') -> BuildResult:
        """Perform a build.

        The argument is a state that represents the main program
        file. This method should only be called once per a build
        manager object.  The return values are identical to the return
        values of the build function.
        """
        self.states.append(initial_state)
        
        # Process states in a loop until all files (states) have been
        # semantically analyzed or type checked (depending on target).
        #
        # We type check all files before the rest of the passes so that we can
        # report errors and fail as quickly as possible.
        while True:
            # Find the next state that has all its dependencies met.
            next = self.next_available_state()
            if not next:
                trace('done')
                break
            
            # Potentially output some debug information.
            trace('next {} ({})'.format(next.path, next.state()))
            
            # Set the import context for reporting error messages correctly.
            self.errors.set_import_context(next.import_context)
            # Process the state. The process method is reponsible for adding a
            # new state object representing the new state of the file.
            next.process()
        
            # Raise exception if the build failed. The build can fail for
            # various reasons, such as parse error, semantic analysis error,
            # etc.
            if self.errors.is_blockers():
                self.errors.raise_error()
        
        # If there were no errors, all files should have been fully processed.
        for s in self.states:
            assert s.state() == final_state, (
                '{} still unprocessed in state {}'.format(s.path, s.state()))

        if self.errors.is_errors():
            self.errors.raise_error()
        
        # Collect a list of all files.
        trees = List[MypyFile]()
        for state in self.states:
            trees.append((cast('ParsedFile', state)).tree)

        # Perform any additional passes after type checking for all the files.
        self.final_passes(trees, self.type_checker.type_map)
        
        return BuildResult(self.semantic_analyzer.modules,
                           self.type_checker.type_map,
                           self.icode, self.binary_path)
    
    def next_available_state(self) -> 'State':
        """Find a ready state (one that has all its dependencies met)."""
        i = len(self.states) - 1
        while i >= 0:
            if self.states[i].is_ready():
                num_incomplete = self.states[i].num_incomplete_deps()
                if num_incomplete == 0:
                    # This is perfect; no need to look for the best match.
                    return self.states[i]
            i -= 1
        return None
    
    def has_module(self, name: str) -> bool:
        """Have we seen a module yet?"""
        return name in self.module_files
    
    def file_state(self, path: str) -> int:
        """Return the state of a source file.

        In particular, return UNSEEN_STATE if the file has no associated
        state.

        This function does not consider any dependencies.
        """
        for s in self.states:
            if s.path == path:
                return s.state()
        return UNSEEN_STATE
    
    def module_state(self, name: str) -> int:
        """Return the state of a module.

        In particular, return UNSEEN_STATE if the file has no associated
        state.

        This considers also module dependencies.
        """
        if not self.has_module(name):
            return UNSEEN_STATE
        state = final_state
        fs = self.file_state(self.module_files[name])
        if earlier_state(fs, state):
            state = fs
        return state

    def is_dep(self, m1: str, m2: str, done: Set[str] = None) -> bool:
        """Does m1 import m2 directly or indirectly?"""
        # Have we computed this previously?
        dep = self.module_deps.get((m1, m2))
        if dep is not None:
            return dep
        
        if not done:
            done = set([m1])
            
        # m1 depends on m2 iff one of the deps of m1 depends on m2.
        st = self.lookup_state(m1)
        for m in st.dependencies:
            if m in done:
                continue
            done.add(m)
            # Cache this dependency.
            self.module_deps[m1, m] = True
            # Search recursively.
            if m == m2 or self.is_dep(m, m2, done):
                # Yes! Mark it in the cache.
                self.module_deps[m1, m2] = True
                return True
        # No dependency. Mark it in the cache.
        self.module_deps[m1, m2] = False
        return False

    def lookup_state(self, module: str) -> 'State':
        for state in self.states:
            if state.id == module:
                return state
        raise RuntimeError('%s not found' % str)
    
    def all_imported_modules_in_file(self,
                                     file: MypyFile) -> List[Tuple[str, int]]:
        """Find all import statements in a file.

        Return list of tuples (module id, import line number) for all modules
        imported in file.
        """
        res = List[Tuple[str, int]]()
        for imp in file.imports:
            if isinstance(imp, Import):
                for id, _ in imp.ids:
                    res.append((id, imp.line))
            elif isinstance(imp, ImportFrom):
                res.append((imp.id, imp.line))
                # Also add any imported names that are submodules.
                for name, __ in imp.names:
                    sub_id = imp.id + '.' + name
                    if self.is_module(sub_id):
                        res.append((sub_id, imp.line))
            elif isinstance(imp, ImportAll):
                res.append((imp.id, imp.line))
        return res
    
    def is_module(self, id: str) -> bool:
        """Is there a file in the file system corresponding to module id?"""
        return find_module(id, self.lib_path) is not None

    def final_passes(self, files: List[MypyFile],
                     types: Dict[Node, Type]) -> None:
        """Perform the code generation passes for type checked files."""
        if self.target == TRANSFORM:
            self.transform(files)
        elif self.target == ICODE:
            self.transform(files)
            self.generate_icode(files, types)
        elif self.target == C:
            self.transform(files)
            self.generate_icode(files, types)
            self.generate_c_and_compile(files)
        elif self.target in [SEMANTIC_ANALYSIS, TYPE_CHECK]:
            pass # Nothing to do.
        else:
            raise RuntimeError('Unsupported target %d' % self.target)

    def get_python_out_path(self, f: MypyFile) -> str:
        if f.fullname() == '__main__':
            return os.path.join(self.output_dir, basename(f.path))
        else:
            components = f.fullname().split('.')
            if os.path.basename(f.path) == '__init__.py':
                components.append('__init__.py')
            else:
                components[-1] += '.py'
            return os.path.join(self.output_dir, *components)

    def transform(self, files: List[MypyFile]) -> None:
        for f in files:
            if f.fullname() == 'typing':
                # The typing module is special and is currently not
                # transformed.
                continue
            # Transform parse tree and produce pretty-printed output.
            v = transform.DyncheckTransformVisitor(
                self.type_checker.type_map,
                self.semantic_analyzer.modules,
                is_pretty=True)
            f.accept(v)

    def generate_icode(self, files: List[MypyFile],
                       types: Dict[Node, Type]) -> None:
        builder = icode.IcodeBuilder(types)
        for f in files:
            # TODO remove ugly builtins hack
            if not f.path.endswith('/builtins.py'):
                f.accept(builder)
        self.icode = builder.generated

    def generate_c_and_compile(self, files: List[MypyFile]) -> None:
        gen = cgen.CGenerator()
        
        for fn, icode in self.icode.items():
            gen.generate_function('M' + fn, icode)

        program_name = os.path.splitext(basename(files[0].path))[0]
        c_file = '%s.c' % program_name

        # Write C file.
        self.log('writing %s' % c_file)
        out = open(c_file, 'w')
        out.writelines(gen.output())
        out.close()

        if COMPILE_ONLY not in self.flags:
            # Generate binary file.
            data_dir = self.data_dir
            vm_dir = os.path.join(data_dir, 'vm')
            cc = os.getenv('CC', 'gcc')
            cflags = shlex.split(os.getenv('CFLAGS', '-O2'))
            cmdline = [cc] + cflags +['-I%s' % vm_dir,
                                      '-o%s' % program_name,
                                      c_file,
                                      os.path.join(vm_dir, 'runtime.c')]
            self.log(' '.join(cmdline))
            status = subprocess.call(cmdline)
            # TODO check status
            self.log('removing %s' % c_file)
            os.remove(c_file)
            self.binary_path = os.path.join('.', program_name)

    def log(self, message: str) -> None:
        if VERBOSE in self.flags:
            print('LOG: %s' % message)


def remove_cwd_prefix_from_path(p: str) -> str:
    """Remove current working directory prefix from p, if present.

    If the result would be empty, return '.' instead.
    """
    cur = os.getcwd()
    # Add separator to the end of the path, unless one is already present.
    if basename(cur) != '':
        cur += os.sep
    # Remove current directory prefix from the path, if present.
    if p.startswith(cur):
        p = p[len(cur):]
    # Avoid returning an empty path; replace that with '.'.
    if p == '':
        p = '.'
    return p


def is_stub(path: str) -> bool:
    """Does path refer to a stubs file?

    Currently check if there is a 'stubs' directory component somewhere
    in the path.
    """
    # TODO more precise check
    dirname, basename = os.path.split(path)
    if basename == '':
        return False
    else:
        stubnames = ['stubs', 'stubs-auto']
        return (basename in stubnames) or is_stub(dirname)


class StateInfo:
    """Description of a source file that is being built."""
    
    def __init__(self, path: str, id: str,
                 import_context: List[Tuple[str, int]],
                 manager: BuildManager) -> None:
        """Initialize state information.

        Arguments:
          path:    Path to the file
          id:      Module id, such as 'os.path' or '__main__' (for the main
                   program file)
          import_context:
                   The import trail that caused this module to be
                   imported (path, line) tuples
          manager: The manager that manages this build
        """
        self.path = path
        self.id = id
        self.import_context = import_context
        self.manager = manager


class State:
    """Abstract base class for build states.

    There is always at most one state per source file.
    """

    # The StateInfo attributes are duplicated here for convenience.
    path = Undefined(str)
    id = Undefined(str)
    import_context = Undefined(List[Tuple[str, int]])
    manager = Undefined(BuildManager)
    # Modules that this file directly depends on (in no particular order).
    dependencies = Undefined(List[str])
    
    def __init__(self, info: StateInfo) -> None:
        self.path = info.path
        self.id = info.id
        self.import_context = info.import_context
        self.manager = info.manager
        self.dependencies = []
    
    def info(self) -> StateInfo:
        return StateInfo(self.path, self.id, self.import_context, self.manager)
    
    def process(self) -> None:
        raise RuntimeError('Not implemented')
    
    def is_ready(self) -> bool:
        """Return True if all dependencies are at least in the same state
        as this object (but not in the initial state).
        """
        for module in self.dependencies:
            state = self.manager.module_state(module)
            if earlier_state(state,
                             self.state()) or state == UNPROCESSED_STATE:
                return False
        return True

    def num_incomplete_deps(self) -> int:
        """Return the number of dependencies that are ready but incomplete."""
        return 0 # Does not matter in this state
    
    def state(self) -> int:
        raise RuntimeError('Not implemented')
    
    def switch_state(self, state_object: 'State') -> None:
        """Called by state objects to replace the state of the file.

        Also notify the manager.
        """
        for i in range(len(self.manager.states)):
            if self.manager.states[i].path == state_object.path:
                self.manager.states[i] = state_object
                return 
        raise RuntimeError('State for {} not found'.format(state_object.path))
    
    def errors(self) -> Errors:
        return self.manager.errors
    
    def semantic_analyzer(self) -> SemanticAnalyzer:
        return self.manager.semantic_analyzer
    
    def semantic_analyzer_pass3(self) -> ThirdPass:
        return self.manager.semantic_analyzer_pass3
    
    def type_checker(self) -> TypeChecker:
        return self.manager.type_checker
    
    def fail(self, path: str, line: int, msg: str, blocker: bool = True) -> None:
        """Report an error in the build (e.g. if could not find a module)."""
        self.errors().set_file(path)
        self.errors().report(line, msg, blocker=blocker)


class UnprocessedFile(State):
    def __init__(self, info: StateInfo, program_text: str) -> None:
        super().__init__(info)
        self.program_text = program_text
        trace('waiting {}'.format(info.path))
        
        # Add surrounding package(s) as dependencies.
        for p in super_packages(self.id):
            if not self.import_module(p):
                # Could not find a module. Typically the reason is a misspelled
                # module name, or the module has not been installed.
                self.fail(self.path, 1, "No module named '{}'".format(p))
            self.dependencies.append(p)
    
    def process(self) -> None:
        """Parse the file, store global names and advance to the next state."""
        tree = self.parse(self.program_text, self.path)

        # Store the parsed module in the shared module symbol table.
        self.manager.semantic_analyzer.modules[self.id] = tree
        
        if '.' in self.id:
            # Include module in the symbol table of the enclosing package.
            c = self.id.split('.')
            p = '.'.join(c[:-1])
            sem_anal = self.manager.semantic_analyzer
            sem_anal.modules[p].names[c[-1]] = SymbolTableNode(
                MODULE_REF, tree, p)
        
        if self.id != 'builtins':
            # The builtins module is imported implicitly in every program (it
            # contains definitions of int, print etc.).
            trace('import builtins')
            if not self.import_module('builtins'):
                self.fail(self.path, 1, 'Could not find builtins')

        # Add all directly imported modules to be processed (however they are
        # not processed yet, just waiting to be processed).
        for id, line in self.manager.all_imported_modules_in_file(tree):
            self.errors().push_import_context(self.path, line)
            try:
                res = self.import_module(id)
            finally:
                self.errors().pop_import_context()
            if not res:
                self.fail(self.path, line, "No module named '{}'".format(id), blocker=False)
                self.manager.missing_modules.add(id)

        # Do the first pass of semantic analysis: add top-level definitions in
        # the file to the symbol table.
        first = FirstPass(self.semantic_analyzer())
        first.analyze(tree, self.path, self.id)
        # Initialize module symbol table, which was populated by the semantic
        # analyzer.
        tree.names = self.semantic_analyzer().globals

        # Replace this state object with a parsed state in BuildManager.
        self.switch_state(ParsedFile(self.info(), tree))
    
    def import_module(self, id: str) -> bool:
        """Schedule a module to be processed.

        Add an unprocessed state object corresponding to the module to the
        manager, or do nothing if the module already has a state object.
        """
        if self.manager.has_module(id):
            # Do nothing:f already being compiled.
            return True
        
        path, text = read_module_source_from_file(id, self.manager.lib_path)
        if text is not None:
            info = StateInfo(path, id, self.errors().import_context(),
                             self.manager)
            self.manager.states.append(UnprocessedFile(info, text))
            self.manager.module_files[id] = path
            return True
        else:
            return False
    
    def parse(self, source_text: str, fnam: str) -> MypyFile:
        """Parse the source of a file with the given name.

        Raise CompileError if there is a parse error.
        """
        num_errs = self.errors().num_messages()
        tree = parse.parse(source_text, fnam, self.errors(),
                           pyversion=self.manager.pyversion)
        tree._fullname = self.id
        if self.errors().num_messages() != num_errs:
            self.errors().raise_error()
        return tree
    
    def state(self) -> int:
        return UNPROCESSED_STATE


class ParsedFile(State):
    tree = Undefined(MypyFile)
    
    def __init__(self, info: StateInfo, tree: MypyFile) -> None:
        super().__init__(info)
        self.tree = tree

        # Build a list all directly imported moules (dependencies).
        imp = List[str]()
        for id, line in self.manager.all_imported_modules_in_file(tree):
            # Omit missing modules, as otherwise we could not type check
            # programs with missing modules.
            if not id in self.manager.missing_modules:
                imp.append(id)
        if self.id != 'builtins':
            imp.append('builtins')
        
        if imp != []:
            trace('{} dependencies: {}'.format(info.path, imp))

        # Record the dependencies. Note that the dependencies list also
        # contains any superpackages and we must preserve them (e.g. os for
        # os.path).
        self.dependencies.extend(imp)
    
    def process(self) -> None:
        """Semantically analyze file and advance to the next state."""
        self.semantic_analyzer().visit_file(self.tree, self.tree.path)
        self.switch_state(PartiallySemanticallyAnalyzedFile(self.info(),
                                                            self.tree))
        
    def num_incomplete_deps(self) -> int:        
        """Return the number of dependencies that are incomplete.

        Here complete means that their state is *later* than this module.
        Cyclic dependencies are omitted to break cycles forcibly (and somewhat
        arbitrarily).
        """
        incomplete = 0
        for module in self.dependencies:
            state = self.manager.module_state(module)
            if (not earlier_state(self.state(), state) and
                    not self.manager.is_dep(module, self.id)):
                incomplete += 1
        return incomplete
    
    def state(self) -> int:
        return PARSED_STATE


class PartiallySemanticallyAnalyzedFile(ParsedFile):
    def process(self) -> None:
        """Perform final pass of semantic analysis and advance state."""
        self.semantic_analyzer_pass3().visit_file(self.tree, self.tree.path)
        if 'dump-type-stats' in self.manager.flags:
            analyze_types(self.tree, self.tree.path)
        self.switch_state(SemanticallyAnalyzedFile(self.info(), self.tree))

    def state(self) -> int:
        return PARTIAL_SEMANTIC_ANALYSIS_STATE


class SemanticallyAnalyzedFile(ParsedFile):
    def process(self) -> None:
        """Type check file and advance to the next state."""
        if self.manager.target >= TYPE_CHECK:
            self.type_checker().visit_file(self.tree, self.tree.path)
            if 'dump-infer-stats' in self.manager.flags:
                analyze_types(self.tree, self.tree.path, inferred=True,
                              typemap=self.manager.type_checker.type_map)
        
        # FIX remove from active state list to speed up processing
        
        self.switch_state(TypeCheckedFile(self.info(), self.tree))
    
    def state(self) -> int:
        return SEMANTICALLY_ANALYSED_STATE


class TypeCheckedFile(SemanticallyAnalyzedFile):
    def process(self) -> None:
        """Finished, so cannot process."""
        raise RuntimeError('Cannot process TypeCheckedFile')
    
    def is_ready(self) -> bool:
        """Finished, so cannot ever become ready."""
        return False
    
    def state(self) -> int:
        return TYPE_CHECKED_STATE


def trace(s):
    if debug:
        print(s)


def read_module_source_from_file(id: str,
                                 lib_path: List[str]) -> Tuple[str, str]:
    """Find and read the source file of a module.

    Return a pair (path, file contents). Return (None, None) if the module
    could not be found or read.

    Arguments:
      id:       module name, a string of form 'foo' or 'foo.bar'
      lib_path: library search path
    """
    path = find_module(id, lib_path)
    if path is not None:
        text = ''
        try:
            f = open(path)
            try:
                text = f.read()
            finally:
                f.close()
        except IOError:
            return None, None
        return path, text
    else:
        return None, None


def find_module(id: str, lib_path: List[str]) -> str:
    """Return the path of the module source file, or None if not found."""
    for pathitem in lib_path:
        comp = id.split('.')
        path = os.path.join(pathitem, os.sep.join(comp[:-1]), comp[-1] + '.py')
        text = ''
        if not os.path.isfile(path):
            path = os.path.join(pathitem, os.sep.join(comp), '__init__.py')
        if os.path.isfile(path) and verify_module(id, path):
            return path
    return None


def verify_module(id: str, path: str) -> bool:
    """Check that all packages containing id have a __init__ file."""
    if path.endswith('__init__.py'):
        path = dirname(path)
    for i in range(id.count('.')):
        path = dirname(path)
        if not os.path.isfile(os.path.join(path, '__init__.py')):
            return False
    return True


def super_packages(id: str) -> List[str]:
    """Return the surrounding packages of a module, e.g. ['os'] for os.path."""
    c = id.split('.')
    res = [] # type: List[str]
    for i in range(1, len(c)):
        res.append('.'.join(c[:i]))
    return res


def make_parent_dirs(path: str) -> None:
    parent = os.path.dirname(path)
    try:
        os.makedirs(parent)
    except OSError:
        pass


def analyze_types(tree, path, inferred=False, typemap=None):
    from os.path import basename
    if basename(path) in ('abc.py', 'typing.py', 'builtins.py'):
        return
    print(path)
    v = MyVisitor(inferred, typemap)
    tree.accept(v)
    print('  ** precision **')
    print('  precise  ', v.num_precise)
    print('  imprecise', v.num_imprecise)
    print('  any      ', v.num_any)
    print('  ** kinds **')
    print('  simple   ', v.num_simple)
    print('  generic  ', v.num_generic)
    print('  function ', v.num_function)
    print('  tuple    ', v.num_tuple)
    print('  typevar  ', v.num_typevar)
    print('  complex  ', v.num_complex)
    print('  any      ', v.num_any)


from mypy.traverser import TraverserVisitor
from mypy.types import (
    AnyType, Instance, FunctionLike, TupleType, Void, TypeVar
)
from mypy import nodes


class MyVisitor(TraverserVisitor):
    def __init__(self, inferred, typemap=None):
        self.inferred = inferred
        self.typemap = typemap
        
        self.num_precise = 0
        self.num_imprecise = 0
        self.num_any = 0

        self.num_simple = 0
        self.num_generic = 0
        self.num_tuple = 0
        self.num_function = 0
        self.num_typevar = 0
        self.num_complex = 0

        self.line = -1
        
        TraverserVisitor.__init__(self)
    
    def visit_func_def(self, o):
        self.line = o.line
        if len(o.expanded) > 1:
            for defn in o.expanded:
                self.visit_func_def(defn)
        else:
            if o.type:
                sig = o.type
                arg_types = sig.arg_types
                if (sig.arg_names and sig.arg_names[0] == 'self' and
                    not self.inferred):
                    arg_types = arg_types[1:]
                for arg in arg_types:
                    self.type(arg)
                self.type(sig.ret_type)
            super().visit_func_def(o)

    def visit_type_application(self, o):
        self.line = o.line
        for t in o.types:
            self.type(t)
        super().visit_type_application(o)

    def visit_assignment_stmt(self, o):
        self.line = o.line
        if (isinstance(o.rvalue, nodes.CallExpr) and
            isinstance(o.rvalue.analyzed, nodes.TypeVarExpr)):
            # Type variable definition -- not a real assignment.
            return
        if o.type:
            self.type(o.type)
        elif self.inferred:
            for lvalue in o.lvalues:
                if isinstance(lvalue, nodes.ParenExpr):
                    lvalue = lvalue.expr
                if isinstance(lvalue, (nodes.TupleExpr, nodes.ListExpr)):
                    items = lvalue.items
                else:
                    items = [lvalue]
                for item in items:
                    if hasattr(item, 'is_def') and item.is_def:
                        t = self.typemap.get(item)
                        if t:
                            self.type(t)
                        else:
                            print('  !! No inferred type on line', self.line)
        super().visit_assignment_stmt(o)

    def type(self, t):
        if isinstance(t, AnyType):
            print('  !! Any type around line', self.line)
            self.num_any += 1
        elif is_imprecise(t):
            print('  !! Imprecise type around line', self.line)
            self.num_imprecise += 1
        else:
            self.num_precise += 1

        if isinstance(t, Instance):
            if t.args:
                if any(is_complex(arg) for arg in t.args):
                    self.num_complex += 1
                else:
                    self.num_generic += 1
            else:
                self.num_simple += 1
        elif isinstance(t, Void):
            self.num_simple += 1
        elif isinstance(t, FunctionLike):
            self.num_function += 1
        elif isinstance(t, TupleType):
            if any(is_complex(item) for item in t.items):
                self.num_complex += 1
            else:
                self.num_tuple += 1
        elif isinstance(t, TypeVar):
            self.num_typevar += 1


def is_imprecise(t):
    return t.accept(HasAnyQuery())

from mypy.types import TypeQuery, ANY_TYPE_STRATEGY

class HasAnyQuery(TypeQuery):
    def __init__(self):
        super().__init__(False, ANY_TYPE_STRATEGY)

    def visit_any(self, t):
        return True

    def visit_instance(self, t):
        if t.type.fullname() == 'builtins.tuple':
            return True
        else:
            return super().visit_instance(t)


def is_generic(t):
    return isinstance(t, Instance) and t.args


def is_complex(t):
    return is_generic(t) or isinstance(t, (FunctionLike, TupleType,
                                           TypeVar))

########NEW FILE########
__FILENAME__ = cgen
"""Generate C code from icode."""

import os

from typing import Undefined, List, Dict, overload

from mypy import errors
from mypy import icode
from mypy.icode import (
    BasicBlock, SetRI, SetRR, SetRNone, IfOp, BinOp, Goto, Return, Opcode,
    CallDirect, CallMethod, FuncIcode, UnaryOp, SetGR, SetRG, Construct,
    SetAttr, GetAttr, IfR
)
from mypy.nodes import TypeInfo, FuncBase
from mypy import transform


INDENT = 4


# Operator flags
OVERFLOW_CHECK_3_ARGS = 1
SHR_OPERAND = 2
CLEAR_LSB = 4


MAIN_FRAGMENT = '''
int main(int argc, char **argv) {
    MValue stack[1024];
    MEnv env;
    env.frame = stack;
    env.stack_top = stack + 1024 - 16; // Reserve 16 entries for arguments
    M__init(&env);
    return 0;
}
'''


class CGenerator:
    """Translate icode to C."""
    
    func = Undefined(FuncIcode)

    def __init__(self) -> None:
        self.prolog = ['#include "mypy.h"\n']
        self.types = [] # type: List[str]
        self.out = [] # type: List[str]
        self.indent = 0
        self.frame_size = 0
        self.global_vars = {} # type: Dict[str, int]
        self.classes = {} # type: Dict[TypeInfo, ClassRepresentation]
        # Count temp labels.
        self.num_labels = 0

    def output(self) -> List[str]:
        result = self.prolog[:]
        result.append('MValue Mglobals[%d];' % max(len(self.global_vars), 1))
        result.append('\n')
        result.extend(self.types)
        result.extend(self.out)
        result.append(MAIN_FRAGMENT)
        return result
    
    def generate_function(self, name: str, func: FuncIcode) -> None:
        # Initialize function-specific state information.
        self.func = func
        self.num_labels = 0
        self.frame_size = func.num_registers

        # Simplistic name mangling.
        name = name.replace('.', '_')
        name = name.replace('$', '_')
        
        # Add function definition and opening brace.
        header = 'MValue %s(MEnv *e)' % name
        self.emit(header)
        self.emit('{')

        # Add function declaration.
        self.emit_prolog('%s;\n' % header)

        # Generate code that updates and checks the stack pointer.
        self.emit('MValue t;')
        self.emit('MValue *frame = e->frame;')
        self.emit('e->frame = frame + %d;' % self.frame_size)
        self.emit('if (e->frame >= e->stack_top)')
        self.emit('    abort();') # Dummy handler; should raise an exception

        # Geneate code that initializes the stack frame. The gc must not see
        # uninitialized values.
        for i in range(func.num_args, self.frame_size):
            if func.register_types[i] == icode.INT:
                self.emit('frame[%d] = 0;' % i)
            else:
                self.emit('frame[%d] = MNone;' % i)

        # Translate function body, one basic block at a time.
        for b in func.blocks:
            self.emit('%s:' % label(b.label))
            for op in b.ops:
                self.opcode(op)

        self.emit('}')

    int_conditionals = {
        '==': 'MShortEq',
        '!=': 'MShortNe',
        '<': 'MShortLt',
        '<=': 'MShortLe',
        '>': 'MShortGt',
        '>=': 'MShortGe'
    }

    int_arithmetic = {
        '+': ('+', 'MIsAddOverflow', 'MIntAdd', OVERFLOW_CHECK_3_ARGS),
        '-': ('-', 'MIsSubOverflow', 'MIntSub', OVERFLOW_CHECK_3_ARGS),
        '*': ('*', 'MIsPotentialMulOverflow', 'MIntMul', SHR_OPERAND),
        '//': ('/', 'MIsPotentialFloorDivOverflow', 'MIntFloorDiv',
               SHR_OPERAND | CLEAR_LSB),
        '%': ('%', 'MIsPotentialModOverflow', 'MIntMod', 0),
        '&': ('&', None, 'MIntAnd', 0),
        '|': ('|', None, 'MIntAnd', 0),
        '^': ('^', None, 'MIntAnd', 0),
        '<<': ('<<', 'MIsShlOverflow', 'MIntShl', SHR_OPERAND),
        '>>': ('>>', 'MIsShrOverflow', 'MIntShr', SHR_OPERAND | CLEAR_LSB)
    }

    @overload
    def opcode(self, opcode: SetRI) -> None:
        self.emit('%s = %d;' % (reg(opcode.target), 2 * opcode.intval))

    @overload
    def opcode(self, opcode: SetRR) -> None:
        self.emit('%s = %s;' % (reg(opcode.target), reg(opcode.source)))

    @overload
    def opcode(self, opcode: SetRNone) -> None:
        self.emit('%s = MNone;' % reg(opcode.target))

    @overload
    def opcode(self, opcode: SetGR) -> None:
        self.emit('%s = %s;' % (self.globalvar(opcode.target),
                                reg(opcode.source)))

    @overload
    def opcode(self, opcode: SetRG) -> None:
        self.emit('%s = %s;' % (reg(opcode.target),
                                self.globalvar(opcode.source)))

    @overload
    def opcode(self, opcode: IfOp) -> None:
        left = operand(opcode.left, opcode.left_kind)
        right = operand(opcode.right, opcode.right_kind)
        op = self.int_conditionals[opcode.op]
        self.emit('if (%s(%s, %s))' % (op, left, right))
        self.emit('    goto %s;' % (label(opcode.true_block.label)))
        self.emit('else')
        self.emit('    goto %s;' % (label(opcode.false_block.label)))

    @overload
    def opcode(self, opcode: IfR) -> None:
        op = '!='
        if opcode.negated:
            op = '=='
        self.emit('if (%s %s MNone)' % (reg(opcode.value), op))
        self.emit('    goto %s;' % (label(opcode.true_block.label)))
        self.emit('else')
        self.emit('    goto %s;' % (label(opcode.false_block.label)))

    @overload
    def opcode(self, opcode: BinOp) -> None:
        target = reg(opcode.target)
        left = operand(opcode.left, opcode.left_kind)
        right = operand(opcode.right, opcode.right_kind)
        op, overflow, opfn, flags = self.int_arithmetic[opcode.op]
        if flags & SHR_OPERAND:
            operation = '%s %s (%s >> 1)' % (left, op, right)
        else:
            operation = '%s %s %s' % (left, op, right)
        if flags & CLEAR_LSB:
            operation = '(%s) & ~1' % operation
        if flags & OVERFLOW_CHECK_3_ARGS:
            # Overflow check needs third argument (operation result).
            label = self.label()
            self.emit('if (MIsShort(%s) && MIsShort(%s)) {' % (left, right))
            self.emit(  't = %s;' % operation)
            self.emit(  'if (%s(t, %s, %s))' % (overflow, left, right))
            self.emit(  '    goto %s;' % label)
            self.emit('} else {')
            self.emit('%s:' % label)
            self.emit(  't = %s(e, %s, %s);' % (opfn, left, right))
            self.emit_error_check('t')
            self.emit('}')
            self.emit('%s = t;' % target)
        elif overflow:
            # Overflow check needs only 2 operands.
            self.emit('if (MIsShort(%s) && MIsShort(%s) && !%s(%s, %s))' %
                      (left, right, overflow, left, right))
            self.emit('    %s = %s;' % (target, operation))
            self.emit('else {')
            self.emit(  '%s = %s(e, %s, %s);' % (target, opfn, left, right))
            self.emit_error_check(target)
            self.emit('}')
        else:
            # No overflow check needed.
            self.emit('if (MIsShort(%s) && MIsShort(%s))' % (left, right))
            self.emit('    %s = %s;' % (target, operation))
            self.emit('else {')
            self.emit(  '%s = %s(e, %s, %s);' % (target, opfn, left, right))
            self.emit_error_check(target)
            self.emit('}')

    @overload
    def opcode(self, opcode: UnaryOp) -> None:
        target = reg(opcode.target)
        operand = reg(opcode.operand)
        if opcode.op == '-':
            self.emit('if (MIsShort(%s) && %s != M_SHORT_MIN)' % (
                operand, operand))
            self.emit('    %s = -%s;' % (target, operand))
            self.emit('else {')
            self.emit('    %s = MIntUnaryMinus(e, %s);' % (target, operand))
            self.emit_error_check(target)
            self.emit('}')
        elif opcode.op == '~':
            self.emit('if (MIsShort(%s))' % operand)
            self.emit('    %s = ~%s & ~1;' % (target, operand))
            self.emit('else {')
            self.emit('    %s = MIntInvert(e, %s);' % (target, operand))
            self.emit_error_check(target)
            self.emit('}')
        else:
            raise NotImplementedError('UnaryOp %s' % opcode.op)

    @overload
    def opcode(self, opcode: Goto) -> None:
        self.emit('goto %s;' % label(opcode.next_block.label))

    @overload
    def opcode(self, opcode: Return) -> None:
        self.emit_return(reg(opcode.retval))

    @overload
    def opcode(self, opcode: CallDirect) -> None:
        for i, arg in enumerate(opcode.args):
            self.emit('%s = %s;' % (reg(self.frame_size + i), reg(arg)))
        self.direct_call(opcode.target, opcode.func)

    @overload
    def opcode(self, opcode: CallMethod) -> None:
        recv = reg(opcode.object)
        self.emit('%s = %s;' % (reg(self.frame_size), recv))
        for i, arg in enumerate(opcode.args):
            self.emit('%s = %s;' % (reg(self.frame_size + 1 + i), reg(arg)))
        target = reg(opcode.target)
        self.get_class_representation(opcode.type)
        rep = self.classes[opcode.type]
        method = opcode.method.replace('$', '_') # Simple name mangling.
        if opcode.static:
            self.direct_call(opcode.target, '%s_%s' % (opcode.type.name(),
                                                       method))
        else:
            vtable_index = rep.vtable_index[method]
            self.emit('t = MInvokeVirtual(e, %s, %d);' % (recv, vtable_index))
            self.emit('if (t == MError)')
            self.emit('    return MError;')
            self.emit('%s = t;' % reg(opcode.target))

    @overload
    def opcode(self, opcode: Construct) -> None:
        rep = self.get_class_representation(opcode.type)
        self.emit('t = MAlloc(e, sizeof(MInstanceHeader) + '
                  '%d * sizeof(MValue));' % len(rep.slotmap))
        self.emit('MInitInstance(t, &%s);' % rep.cname)
        self.emit('%s = t;' % reg(opcode.target))

    @overload
    def opcode(self, opcode: SetAttr) -> None:
        rep = self.get_class_representation(opcode.type)
        slot = rep.slotmap[opcode.attr]
        self.emit('MSetSlot(%s, %d, %s);' % (reg(opcode.object),
                                             slot, reg(opcode.source)))

    @overload
    def opcode(self, opcode: GetAttr) -> None:
        rep = self.get_class_representation(opcode.type)
        slot = rep.slotmap[opcode.attr]
        self.emit('%s = MGetSlot(%s, %d);' % (reg(opcode.target),
                                              reg(opcode.object), slot))

    @overload
    def opcode(self, opcode: Opcode) -> None:
        """Default case."""
        raise NotImplementedError(type(opcode))

    #
    # Helpers
    #

    def get_class_representation(self, cls: TypeInfo) -> 'ClassRepresentation':
        rep = self.classes.get(cls)
        if not rep:
            rep = self.generate_class(cls)
        return rep

    def generate_class(self, cls: TypeInfo) -> 'ClassRepresentation':
        if cls.bases:
            baserep = self.get_class_representation(cls.bases[0].type)
        else:
            baserep = None
        rep = ClassRepresentation(cls, baserep)
        self.classes[cls] = rep

        # Emit vtable.
        vtable = 'MVT_%s' % cls.name()
        self.emit_types('MFunction %s[] = {' % vtable)
        for m in rep.vtable_methods:
            defining_class = rep.defining_class[m]
            self.emit_types('    M%s_%s,' % (defining_class, m))
        self.emit_types('}; /* %s */' % vtable)

        # Emit type runtime info.
        self.emit_types('MTypeRepr %s = {' % rep.cname)
        self.emit_types('    %s,' % vtable)
        self.emit_types('    0,')
        self.emit_types('    "%s"' % cls.fullname())
        self.emit_types('};\n')
        
        return rep

    def direct_call(self, target: int, funcname: str) -> None:
        self.emit('t = M%s(e);' % funcname)
        self.emit('if (t == MError)')
        self.emit('    return MError;')
        self.emit('%s = t;' % reg(target))

    def emit(self, s: str) -> None:
        if '}' in s:
            self.indent -= INDENT
        indent = self.indent
        if s.endswith(':'):
            indent -= INDENT
        self.out.append(' ' * indent + s + '\n')
        if '{' in s:
            self.indent += INDENT

    def emit_return(self, retval: str) -> None:
        self.emit('e->frame = frame;')
        self.emit('return %s;' % retval)

    def emit_error_check(self, value: str) -> None:
        self.emit('if (%s == MError) {' % value)
        self.emit_return('MError')
        self.emit('}')

    def emit_prolog(self, s: str) -> None:
        self.prolog.append(s + '\n')

    def emit_types(self, s: str) -> None:
        self.types.append(s + '\n')

    def label(self) -> str:
        n = self.num_labels
        self.num_labels = n + 1
        return 'T%d' % n

    def globalvar(self, name: str) -> str:
        num = self.global_vars.get(name, -1)
        if num < 0:
            num = len(self.global_vars)
            self.global_vars[name] = num
        return 'Mglobals[%d]' % num


def reg(n: int) -> str:
    return 'frame[%d]' % n


def label(n: int) -> str:
    return 'L%d' % n


def operand(n: int, kind: int) -> str:
    if kind == icode.INT_KIND:
        return str(n * 2)
    else:
        return reg(n)


class ClassRepresentation:
    """Description of the runtime representation of a mypy class."""
    # TODO add methods
    # TODO add base class

    cname = ''
    fullname = ''
    
    slotmap = Undefined(Dict[str, int])
    
    # Map method name to/from vtable index
    vtable_index = Undefined(Dict[str, int])
    
    defining_class = Undefined(Dict[str, str])
    
    vtable_methods = Undefined(List[str])

    def __init__(self, type: TypeInfo, base: 'ClassRepresentation') -> None:
        self.cname = 'MR_%s' % type.name()
        self.fullname = type.fullname()
        self.slotmap = {}
        self.vtable_index = {}
        self.defining_class = {}
        self.vtable_methods = []
        if base:
            self.inherit_from_base(base)
        for m in sorted(type.names):
            if isinstance(type.names[m].node, FuncBase):
                self.add_method(m, type)
            else:
                self.slotmap[m] = len(self.slotmap)
                self.add_method('_' + m, type)    # Getter TODO refactor
                self.add_method('set_' + m, type) # Setter # TODO refactor

    def add_method(self, method: str, defining_class: TypeInfo) -> None:
        self.defining_class[method] = defining_class.name()
        if method not in self.vtable_index:
            self.vtable_index[method] = len(self.vtable_methods)
            self.vtable_methods.append(method)

    def inherit_from_base(self, base: 'ClassRepresentation') -> None:
        # TODO use dict.update
        for k, v in base.vtable_index.items():
            self.vtable_index[k] = v
        self.vtable_methods.extend(base.vtable_methods)
        for k, v in base.slotmap.items():
            self.slotmap[k] = v
        for k, n in base.defining_class.items():
            self.defining_class[k] = n

########NEW FILE########
__FILENAME__ = checker
"""Mypy type checker."""

import itertools
            
from typing import Undefined, Dict, List, cast, overload, Tuple

from mypy.errors import Errors
from mypy.nodes import (
    SymbolTable, Node, MypyFile, VarDef, LDEF, Var,
    OverloadedFuncDef, FuncDef, FuncItem, FuncBase, TypeInfo,
    ClassDef, GDEF, Block, AssignmentStmt, NameExpr, MemberExpr, IndexExpr,
    TupleExpr, ListExpr, ParenExpr, ExpressionStmt, ReturnStmt, IfStmt,
    WhileStmt, OperatorAssignmentStmt, YieldStmt, WithStmt, AssertStmt,
    RaiseStmt, TryStmt, ForStmt, DelStmt, CallExpr, IntExpr, StrExpr,
    BytesExpr, UnicodeExpr, FloatExpr, OpExpr, UnaryExpr, CastExpr, SuperExpr,
    TypeApplication, DictExpr, SliceExpr, FuncExpr, TempNode, SymbolTableNode,
    Context, ListComprehension, ConditionalExpr, GeneratorExpr,
    Decorator, SetExpr, PassStmt, TypeVarExpr, UndefinedExpr, PrintStmt
)
from mypy.nodes import function_type, method_type
from mypy import nodes
from mypy.types import (
    Type, AnyType, Callable, Void, FunctionLike, Overloaded, TupleType,
    Instance, NoneTyp, UnboundType, ErrorType, TypeTranslator, BasicTypes,
    strip_type
)
from mypy.sametypes import is_same_type
from mypy.messages import MessageBuilder
import mypy.checkexpr
from mypy import messages
from mypy.subtypes import (
    is_subtype, is_equivalent, map_instance_to_supertype, is_proper_subtype,
    is_more_precise
)
from mypy.semanal import self_type, set_callable_name, refers_to_fullname
from mypy.erasetype import erase_typevars
from mypy.expandtype import expand_type_by_instance, expand_type
from mypy.visitor import NodeVisitor
from mypy.join import join_types
from mypy.treetransform import TransformVisitor


# Kinds of isinstance checks.
ISINSTANCE_OVERLAPPING = 0
ISINSTANCE_ALWAYS_TRUE = 1
ISINSTANCE_ALWAYS_FALSE = 2


class ConditionalTypeBinder:
    """Keep track of conditional types of variables."""

    def __init__(self) -> None:
        self.types = Dict[Var, List[Type]]()

    def push(self, var: Var, type: Type) -> None:
        self.types.setdefault(var, []).append(type)
        
    def pop(self, var: Var) -> None:
        self.types[var].pop()
        
    def get(self, var: Var) -> Type:
        values = self.types.get(var)
        if values:
            return values[-1]
        else:
            return var.type


class TypeChecker(NodeVisitor[Type]):
    """Mypy type checker.

    Type check mypy source files that have been semantically analysed.
    """

    # Target Python major version
    pyversion = 3
    # Error message reporting
    errors = Undefined(Errors)
    # SymbolNode table for the whole program
    symtable = Undefined(SymbolTable)
    # Utility for generating messages
    msg = Undefined(MessageBuilder)
    # Types of type checked nodes
    type_map = Undefined(Dict[Node, Type])

    # Helper for managing conditional types
    binder = Undefined(ConditionalTypeBinder)
    # Helper for type checking expressions
    expr_checker = Undefined('mypy.checkexpr.ExpressionChecker')
    
    # Stack of function return types
    return_types = Undefined(List[Type])
    # Type context for type inference
    type_context = Undefined(List[Type])
    # Flags; true for dynamically typed functions
    dynamic_funcs = Undefined(List[bool])
    # Stack of functions being type checked
    function_stack = Undefined(List[FuncItem])
    
    globals = Undefined(SymbolTable)
    locals = Undefined(SymbolTable)
    modules = Undefined(Dict[str, MypyFile])
    
    def __init__(self, errors: Errors, modules: Dict[str, MypyFile],
                 pyversion: int = 3) -> None:
        """Construct a type checker.

        Use errors to report type check errors. Assume symtable has been
        populated by the semantic analyzer.
        """
        self.expr_checker
        self.errors = errors
        self.modules = modules
        self.pyversion = pyversion
        self.msg = MessageBuilder(errors)
        self.type_map = {}
        self.binder = ConditionalTypeBinder()
        self.expr_checker = mypy.checkexpr.ExpressionChecker(self, self.msg)
        self.return_types = []
        self.type_context = []
        self.dynamic_funcs = []
        self.function_stack = []
    
    def visit_file(self, file_node: MypyFile, path: str) -> None:  
        """Type check a mypy file with the given path."""
        self.errors.set_file(path)
        self.globals = file_node.names
        self.locals = None
        
        for d in file_node.defs:
            self.accept(d)
    
    def accept(self, node: Node, type_context: Type = None) -> Type:
        """Type check a node in the given type context."""
        self.type_context.append(type_context)
        typ = node.accept(self)
        self.type_context.pop()
        self.store_type(node, typ)
        if self.is_dynamic_function():
            return AnyType()
        else:
            return typ
    
    #
    # Definitions
    #
    
    def visit_var_def(self, defn: VarDef) -> Type:
        """Type check a variable definition.

        It can be of any kind: local, member or global.
        """
        # Type check initializer.
        if defn.init:
            # There is an initializer.
            if defn.items[0].type:
                # Explicit types.
                if len(defn.items) == 1:
                    self.check_single_assignment(defn.items[0].type, None,
                                                 defn.init, defn.init)
                else:
                    # Multiple assignment.
                    lvt = List[Type]()
                    for v in defn.items:
                        lvt.append(v.type)
                    self.check_multi_assignment(
                        lvt, [None] * len(lvt),
                        defn.init, defn.init)
            else:
                init_type = self.accept(defn.init)
                if defn.kind == LDEF and not defn.is_top_level:
                    # Infer local variable type if there is an initializer
                    # except if the definition is at the top level (outside a
                    # function).
                    self.infer_local_variable_type(defn.items, init_type, defn)
        else:
            # No initializer
            if (defn.kind == LDEF and not defn.items[0].type and
                    not defn.is_top_level and not self.is_dynamic_function()):
                self.fail(messages.NEED_ANNOTATION_FOR_VAR, defn)
    
    def infer_local_variable_type(self, x, y, z):
        # TODO
        raise RuntimeError('Not implemented')
    
    def visit_overloaded_func_def(self, defn: OverloadedFuncDef) -> Type:
        num_abstract = 0
        for fdef in defn.items:
            self.check_func_item(fdef.func, name=fdef.func.name())
            if fdef.func.is_abstract:
                num_abstract += 1
        if num_abstract not in (0, len(defn.items)):
            self.fail(messages.INCONSISTENT_ABSTRACT_OVERLOAD, defn)
        if defn.info:
            self.check_method_override(defn)
            self.check_inplace_operator_method(defn)
        self.check_overlapping_overloads(defn)

    def check_overlapping_overloads(self, defn: OverloadedFuncDef) -> None:
        for i, item in enumerate(defn.items):
            for j, item2 in enumerate(defn.items[i + 1:]):
                # TODO overloads involving decorators
                sig1 = function_type(item.func)
                sig2 = function_type(item2.func)
                if is_unsafe_overlapping_signatures(sig1, sig2):
                    self.msg.overloaded_signatures_overlap(i + 1, j + 2,
                                                           item.func)
    
    def visit_func_def(self, defn: FuncDef) -> Type:
        """Type check a function definition."""
        self.check_func_item(defn, name=defn.name())
        if defn.info:
            self.check_method_override(defn)
            self.check_inplace_operator_method(defn)
        if defn.original_def:
            if not is_same_type(function_type(defn),
                                function_type(defn.original_def)):
                self.msg.incompatible_conditional_function_def(defn)
    
    def check_func_item(self, defn: FuncItem,
                        type_override: Callable = None,
                        name: str = None) -> Type:
        """Type check a function.

        If type_override is provided, use it as the function type.
        """
        # We may be checking a function definition or an anonymous function. In
        # the first case, set up another reference with the precise type.
        fdef = None # type: FuncDef
        if isinstance(defn, FuncDef):
            fdef = defn

        self.function_stack.append(defn)
        self.dynamic_funcs.append(defn.type is None and not type_override)
        
        if fdef:
            self.errors.push_function(fdef.name())
        
        typ = function_type(defn)
        if type_override:
            typ = type_override
        if isinstance(typ, Callable):
            self.check_func_def(defn, typ, name)
        else:
            raise RuntimeError('Not supported')
        
        if fdef:
            self.errors.pop_function()
        
        self.dynamic_funcs.pop()
        self.function_stack.pop()
    
    def check_func_def(self, defn: FuncItem, typ: Callable, name: str) -> None:
        """Type check a function definition."""
        # Expand type variables with value restrictions to ordinary types.
        for item, typ in self.expand_typevars(defn, typ):
            defn.expanded.append(item)
            
            # We may be checking a function definition or an anonymous
            # function. In the first case, set up another reference with the
            # precise type.
            if isinstance(item, FuncDef):
                fdef = item
            else:
                fdef = None

            self.enter()

            if fdef:
                # Check if __init__ has an invalid, non-None return type.
                if (fdef.info and fdef.name() == '__init__' and
                        not isinstance(typ.ret_type, Void) and
                        not self.dynamic_funcs[-1]):
                    self.fail(messages.INIT_MUST_NOT_HAVE_RETURN_TYPE,
                              item.type)

            if name in nodes.reverse_op_method_set:
                self.check_reverse_op_method(item, typ, name)

            # Push return type.
            self.return_types.append(typ.ret_type)

            # Store argument types.
            nargs = len(item.args)
            for i in range(len(typ.arg_types)):
                arg_type = typ.arg_types[i]
                if typ.arg_kinds[i] == nodes.ARG_STAR:
                    arg_type = self.named_generic_type('builtins.list',
                                                       [arg_type])
                elif typ.arg_kinds[i] == nodes.ARG_STAR2:
                    arg_type = self.named_generic_type('builtins.dict',
                                                       [self.str_type(),
                                                        arg_type])
                item.args[i].type = arg_type

            # Type check initialization expressions.
            for j in range(len(item.init)):
                if item.init[j]:
                    self.accept(item.init[j])

            # Type check body.
            self.accept(item.body)

            self.return_types.pop()

            self.leave()

    def check_reverse_op_method(self, defn: FuncItem, typ: Callable,
                                method: str) -> None:
        """Check a reverse operator method such as __radd__."""
        
        # If the argument of a reverse operator method such as __radd__
        # does not define the corresponding non-reverse method such as __add__
        # the return type of __radd__ may not reliably represent the value of
        # the corresponding operation even in a fully statically typed program.
        #
        # This example illustrates the issue:
        #
        #   class A: pass
        #   class B:
        #       def __radd__(self, x: A) -> int: # Note that A does not define
        #           return 1                     # __add__!
        #   class C(A):
        #       def __add__(self, x: Any) -> str: return 'x'
        #   a = Undefined(A)
        #   a = C()
        #   a + B()  # Result would be 'x', even though static type seems to
        #            # be int!

        if method in ('__eq__', '__ne__'):
            # These are defined for all objects => can't cause trouble.
            return 
        
        # With 'Any' or 'object' return type we are happy, since any possible
        # return value is valid.
        ret_type = typ.ret_type
        if isinstance(ret_type, AnyType):
            return
        if isinstance(ret_type, Instance):
            if ret_type.type.fullname() == 'builtins.object':
                return
        # Plausibly the method could have too few arguments, which would result
        # in an error elsewhere.
        if len(typ.arg_types) <= 2:
            # TODO check self argument kind
            
            # Check for the issue described above.
            arg_type = typ.arg_types[1]
            other_method = nodes.normal_from_reverse_op[method]
            fail = False
            if isinstance(arg_type, Instance):
                if not arg_type.type.has_readable_member(other_method):
                    fail = True
            elif isinstance(arg_type, AnyType):
                self.msg.reverse_operator_method_with_any_arg_must_return_any(
                    method, defn)
                return
            else:
                fail = True
            if fail:
                self.msg.invalid_reverse_operator_signature(
                    method, other_method, defn)
                return

            typ2 = self.expr_checker.analyse_external_member_access(
                other_method, arg_type, defn)
            self.check_overlapping_op_methods(
                typ, method, defn.info,
                typ2, other_method, cast(Instance, arg_type),
                defn)

    def check_overlapping_op_methods(self,
                                     reverse_type: Callable,
                                     reverse_name: str,
                                     reverse_class: TypeInfo,
                                     forward_type: Type,
                                     forward_name: str,
                                     forward_base: Instance,
                                     context: Context) -> None:
        """Check for overlapping method and reverse method signatures.

        Assume reverse method has valid argument count and kinds.
        """

        # Reverse operator method that overlaps unsafely with the
        # forward operator method can result in type unsafety. This is
        # similar to overlapping overload variants.
        #
        # This example illustrates the issue:
        #
        #   class X: pass
        #   class A:
        #       def __add__(self, x: X) -> int:
        #           if isinstance(x, X):
        #               return 1
        #           return NotImplemented
        #   class B:
        #       def __radd__(self, x: A) -> str: return 'x'
        #   class C(X, B): pass
        #   b = Undefined(B)
        #   b = C()
        #   A() + b # Result is 1, even though static type seems to be str!
        #
        # The reason for the problem is that B and X are overlapping
        # types, and the return types are different. Also, if the type
        # of x in __radd__ would not be A, the methods could be
        # non-overlapping.

        if isinstance(forward_type, Callable):
            # TODO check argument kinds
            if len(forward_type.arg_types) < 1:
                # Not a valid operator method -- can't succeed anyway.
                return

            # Construct normalized function signatures corresponding to the
            # operator methods. The first argument is the left operand and the
            # second operatnd is the right argument -- we switch the order of
            # the arguments of the reverse method.
            forward_tweaked = Callable([forward_base,
                                        forward_type.arg_types[0]],
                                       [nodes.ARG_POS] * 2,
                                       [None] * 2,
                                       forward_type.ret_type,
                                       is_type_obj=False,
                                       name=forward_type.name)            
            reverse_args = reverse_type.arg_types
            reverse_tweaked = Callable([reverse_args[1], reverse_args[0]],
                                       [nodes.ARG_POS] * 2,
                                       [None] * 2,
                                       reverse_type.ret_type,
                                       is_type_obj=False,
                                       name=reverse_type.name)
            
            if is_unsafe_overlapping_signatures(forward_tweaked,
                                                reverse_tweaked):
                self.msg.operator_method_signatures_overlap(
                    reverse_class.name(), reverse_name,
                    forward_base.type.name(), forward_name, context)
        elif isinstance(forward_type, Overloaded):
            for item in forward_type.items():
                self.check_overlapping_op_methods(
                    reverse_type, reverse_name, reverse_class,
                    item, forward_name, forward_base, context)
        else:
            # TODO what about this?
            assert False, 'Forward operator method type is not Callable'

    def check_inplace_operator_method(self, defn: FuncBase) -> None:
        """Check an inplace operator method such as __iadd__.

        They cannot arbitrarily overlap with __add__.
        """
        method = defn.name()
        if method not in nodes.inplace_operator_methods:
            return
        typ = method_type(defn)
        cls = defn.info
        other_method = '__' + method[3:]
        if cls.has_readable_member(other_method):
            instance = self_type(cls)
            typ2 = self.expr_checker.analyse_external_member_access(
                other_method, instance, defn)
            fail = False
            if isinstance(typ2, FunctionLike):
                if not is_more_general_arg_prefix(typ, typ2):
                    fail = True
            else:
                # TODO overloads
                fail = True
            if fail:
                self.msg.signatures_incompatible(method, other_method, defn)

    def expand_typevars(self, defn: FuncItem,
                        typ: Callable) -> List[Tuple[FuncItem, Callable]]:
        # TODO use generator
        subst = List[List[Tuple[int, Type]]]()
        tvars = typ.variables or []
        tvars = tvars[:]
        if defn.info:
            # Class type variables
            tvars += defn.info.defn.type_vars or []
        for tvar in tvars:
            if tvar.values:
                subst.append([(tvar.id, value)
                              for value in tvar.values])
        if subst:
            result = List[Tuple[FuncItem, Callable]]()
            for substitutions in itertools.product(*subst):
                mapping = dict(substitutions)
                expanded = cast(Callable, expand_type(typ, mapping))
                result.append((expand_func(defn, mapping), expanded))
            return result
        else:
            return [(defn, typ)]
    
    def check_method_override(self, defn: FuncBase) -> None:
        """Check if function definition is compatible with base classes."""
        # Check against definitions in base classes.
        for base in defn.info.mro[1:]:
            self.check_method_or_accessor_override_for_base(defn, base)
    
    def check_method_or_accessor_override_for_base(self, defn: FuncBase,
                                                   base: TypeInfo) -> None:
        """Check if method definition is compatible with a base class."""
        if base:
            name = defn.name()
            if name != '__init__':
                # Check method override (__init__ is special).
                self.check_method_override_for_base_with_name(defn, name, base)
                if name in nodes.inplace_operator_methods:
                    # Figure out the name of the corresponding operator method.
                    method = '__' + name[3:]
                    # An inplace overator method such as __iadd__ might not be
                    # always introduced safely if a base class defined __add__.
                    # TODO can't come up with an example where this is
                    #      necessary; now it's "just in case"
                    self.check_method_override_for_base_with_name(defn, method,
                                                                  base)

    def check_method_override_for_base_with_name(
            self, defn: FuncBase, name: str, base: TypeInfo) -> None:
        base_attr = base.names.get(name)
        if base_attr:
            # The name of the method is defined in the base class.

            # Construct the type of the overriding method.
            typ = method_type(defn)
            # Map the overridden method type to subtype context so that
            # it can be checked for compatibility.
            original_type = base_attr.type
            if original_type is None and isinstance(base_attr.node,
                                                    FuncDef):
                original_type = function_type(cast(FuncDef,
                                                   base_attr.node))
            if isinstance(original_type, FunctionLike):
                original = map_type_from_supertype(
                    method_type(original_type),
                    defn.info, base)
                # Check that the types are compatible.
                # TODO overloaded signatures
                self.check_override(cast(FunctionLike, typ),
                                    cast(FunctionLike, original),
                                    defn.name(),
                                    name,
                                    base.name(),
                                    defn)
            else:
                assert original_type is not None
                self.msg.signature_incompatible_with_supertype(
                    defn.name(), name, base.name(), defn)
    
    def check_override(self, override: FunctionLike, original: FunctionLike,
                       name: str, name_in_super: str, supertype: str,
                       node: Context) -> None:
        """Check a method override with given signatures.

        Arguments:
          override:  The signature of the overriding method.
          original:  The signature of the original supertype method.
          name:      The name of the subtype. This and the next argument are
                     only used for generating error messages.
          supertype: The name of the supertype.
        """
        if (isinstance(override, Overloaded) or
                isinstance(original, Overloaded) or
                len(cast(Callable, override).arg_types) !=
                    len(cast(Callable, original).arg_types) or
                cast(Callable, override).min_args !=
                    cast(Callable, original).min_args):
            # Use boolean variable to clarify code.
            fail = False
            if not is_subtype(override, original):
                fail = True
            elif (not isinstance(original, Overloaded) and
                  isinstance(override, Overloaded) and
                  name in nodes.reverse_op_methods.keys()):
                # Operator method overrides cannot introduce overloading, as
                # this could be unsafe with reverse operator methods.
                fail = True
            if fail:
                self.msg.signature_incompatible_with_supertype(
                    name, name_in_super, supertype, node)
            return
        else:
            # Give more detailed messages for the common case of both
            # signatures having the same number of arguments and no
            # overloads.
            
            coverride = cast(Callable, override)
            coriginal = cast(Callable, original)
            
            for i in range(len(coverride.arg_types)):
                if not is_equivalent(coriginal.arg_types[i],
                                     coverride.arg_types[i]):
                    self.msg.argument_incompatible_with_supertype(
                        i + 1, name, name_in_super, supertype, node)
            
            if not is_subtype(coverride.ret_type, coriginal.ret_type):
                self.msg.return_type_incompatible_with_supertype(
                    name, name_in_super, supertype, node)
    
    def visit_class_def(self, defn: ClassDef) -> Type:
        """Type check a class definition."""
        typ = defn.info
        self.errors.push_type(defn.name)
        self.accept(defn.defs)
        self.check_multiple_inheritance(typ)
        self.errors.pop_type()

    def check_multiple_inheritance(self, typ: TypeInfo) -> None:
        """Check for multiple inheritance related errors."""

        if len(typ.bases) <= 1:
            # No multiple inheritance.
            return
        # Verify that inherited attributes are compatible.
        mro = typ.mro[1:]
        for i, base in enumerate(mro):
            for name in base.names:
                for base2 in mro[i + 1:]:
                    if name in base2.names:
                        self.check_compatibility(name, base, base2, typ)
        # Verify that base class layouts are compatible.
        builtin_bases = [nearest_builtin_ancestor(base.type)
                         for base in typ.bases]
        for base1 in builtin_bases:
            for base2 in builtin_bases:
                if not (base1 in base2.mro or base2 in base1.mro):
                    self.fail(messages.INSTANCE_LAYOUT_CONFLICT, typ)
        # Verify that no disjointclass constraints are violated.
        for base in typ.mro:
            for disjoint in base.disjointclass_decls:
                if disjoint in typ.mro:
                    self.msg.disjointness_violation(base, disjoint, typ)

    def check_compatibility(self, name: str, base1: TypeInfo,
                            base2: TypeInfo, ctx: Context) -> None:
        if name == '__init__':
            # __init__ can be incompatible -- it's a special case.
            return
        first = base1[name]
        second = base2[name]
        first_type = first.type
        second_type = second.type
        if (isinstance(first_type, FunctionLike) and
                isinstance(second_type, FunctionLike)):
            # Method override
            first_sig = method_type(cast(FunctionLike, first_type))
            second_sig = method_type(cast(FunctionLike, second_type))
            # TODO Can we relax the equivalency requirement?
            ok = is_equivalent(first_sig, second_sig)
        else:
            ok = is_equivalent(first_type, second_type)
        if not ok:
            self.msg.base_class_definitions_incompatible(name, base1, base2,
                                                         ctx)
    
    #
    # Statements
    #
    
    def visit_block(self, b: Block) -> Type:
        for s in b.body:
            self.accept(s)
    
    def visit_assignment_stmt(self, s: AssignmentStmt) -> Type:
        """Type check an assignment statement.

        Handle all kinds of assignment statements (simple, indexed, multiple).
        """
        self.check_assignments(self.expand_lvalues(s.lvalues[-1]), s.rvalue)
        if len(s.lvalues) > 1:
            # Chained assignment (e.g. x = y = ...).
            # Make sure that rvalue type will not be reinferred.
            rvalue = self.temp_node(self.type_map[s.rvalue], s)
            for lv in s.lvalues[:-1]:
                self.check_assignments(self.expand_lvalues(lv), rvalue)

    def check_assignments(self, lvalues: List[Node],
                          rvalue: Node) -> None:        
        # Collect lvalue types. Index lvalues require special consideration,
        # since we cannot typecheck them until we know the rvalue type.
        # For each lvalue, one of lvalue_types[i] or index_lvalues[i] is not
        # None.
        lvalue_types = [] # type: List[Type]       # Each may be None
        index_lvalues = [] # type: List[IndexExpr] # Each may be None
        inferred = [] # type: List[Var]
        is_inferred = False
        
        for lv in lvalues:
            if self.is_definition(lv):
                is_inferred = True
                if isinstance(lv, NameExpr):
                    inferred.append(cast(Var, lv.node))
                else:
                    m = cast(MemberExpr, lv)
                    self.accept(m.expr)
                    inferred.append(m.def_var)
                lvalue_types.append(None)
                index_lvalues.append(None)
            elif isinstance(lv, IndexExpr):
                lvalue_types.append(None)
                index_lvalues.append(lv)
                inferred.append(None)
            elif isinstance(lv, MemberExpr):
                lvalue_types.append(
                    self.expr_checker.analyse_ordinary_member_access(lv,
                                                                     True))
                self.store_type(lv, lvalue_types[-1])
                index_lvalues.append(None)
                inferred.append(None)
            else:
                lvalue_types.append(self.accept(lv))
                index_lvalues.append(None)
                inferred.append(None)
        
        if len(lvalues) == 1:
            # Single lvalue.
            self.check_single_assignment(lvalue_types[0],
                                         index_lvalues[0], rvalue, rvalue)
        else:
            self.check_multi_assignment(lvalue_types, index_lvalues,
                                        rvalue, rvalue)
        if is_inferred:
            self.infer_variable_type(inferred, lvalues, self.accept(rvalue),
                                     rvalue)
    
    def is_definition(self, s: Node) -> bool:
        if isinstance(s, NameExpr):
            if s.is_def:
                return True
            # If the node type is not defined, this must the first assignment
            # that we process => this is a definition, even though the semantic
            # analyzer did not recognize this as such. This can arise in code
            # that uses isinstance checks, if type checking of the primary
            # definition is skipped due to an always False type check.
            node = s.node
            if isinstance(node, Var):
                return node.type is None
        elif isinstance(s, MemberExpr):
            return s.is_def
        return False
    
    def expand_lvalues(self, n: Node) -> List[Node]:
        if isinstance(n, TupleExpr):
            return self.expr_checker.unwrap_list(n.items)
        elif isinstance(n, ListExpr):
            return self.expr_checker.unwrap_list(n.items)
        elif isinstance(n, ParenExpr):
            return self.expand_lvalues(n.expr)
        else:
            return [n]
    
    def infer_variable_type(self, names: List[Var], lvalues: List[Node],
                            init_type: Type, context: Context) -> None:
        """Infer the type of initialized variables from initializer type."""
        if isinstance(init_type, Void):
            self.check_not_void(init_type, context)
        elif not self.is_valid_inferred_type(init_type):
            # We cannot use the type of the initialization expression for type
            # inference (it's not specific enough).
            self.fail(messages.NEED_ANNOTATION_FOR_VAR, context)
        else:
            # Infer type of the target.
            
            # Make the type more general (strip away function names etc.).
            init_type = strip_type(init_type)
            
            if len(names) > 1:
                if isinstance(init_type, TupleType):
                    # Initializer with a tuple type.
                    if len(init_type.items) == len(names):
                        for i in range(len(names)):
                            self.set_inferred_type(names[i], lvalues[i],
                                                   init_type.items[i])
                    else:
                        self.msg.incompatible_value_count_in_assignment(
                            len(names), len(init_type.items), context)
                elif (isinstance(init_type, Instance) and
                      is_subtype(init_type,
                                 self.named_generic_type('typing.Iterable',
                                                         [AnyType()]))):
                    # Initializer with an iterable type.
                    item_type = self.iterable_item_type(cast(Instance,
                                                             init_type))
                    for i in range(len(names)):
                        self.set_inferred_type(names[i], lvalues[i], item_type)
                elif isinstance(init_type, AnyType):
                    for i in range(len(names)):
                        self.set_inferred_type(names[i], lvalues[i], AnyType())
                else:
                    self.fail(messages.INCOMPATIBLE_TYPES_IN_ASSIGNMENT,
                              context)
            else:
                for v in names:
                    self.set_inferred_type(v, lvalues[0], init_type)

    def set_inferred_type(self, var: Var, lvalue: Node, type: Type) -> None:
        """Store inferred variable type.

        Store the type to both the variable node and the expression node that
        refers to the variable (lvalue). If var is None, do nothing.
        """
        if var:
            var.type = type
            self.store_type(lvalue, type)
    
    def is_valid_inferred_type(self, typ: Type) -> bool:
        """Is an inferred type invalid?

        Examples include the None type or a type with a None component.
        """
        if is_same_type(typ, NoneTyp()):
            return False
        elif isinstance(typ, Instance):
            for arg in typ.args:
                if not self.is_valid_inferred_type(arg):
                    return False
        elif isinstance(typ, TupleType):
            for item in typ.items:
                if not self.is_valid_inferred_type(item):
                    return False
        return True
    
    def check_multi_assignment(self, lvalue_types: List[Type],
                               index_lvalues: List[IndexExpr],
                               rvalue: Node,
                               context: Context,
                               msg: str = None) -> None:
        if not msg:
            msg = messages.INCOMPATIBLE_TYPES_IN_ASSIGNMENT
        # First handle case where rvalue is of form Undefined, ...
        rvalue_type = get_undefined_tuple(rvalue)
        undefined_rvalue = True
        if not rvalue_type:
            # Infer the type of an ordinary rvalue expression.
            rvalue_type = self.accept(rvalue) # TODO maybe elsewhere; redundant
            undefined_rvalue = False
        # Try to expand rvalue to lvalue(s).
        if isinstance(rvalue_type, AnyType):
            pass
        elif isinstance(rvalue_type, TupleType):
            # Rvalue with tuple type.
            items = [] # type: List[Type]
            for i in range(len(lvalue_types)):
                if lvalue_types[i]:
                    items.append(lvalue_types[i])
                elif i < len(rvalue_type.items):
                    # TODO Figure out more precise type context, probably
                    #      based on the type signature of the _set method.
                    items.append(rvalue_type.items[i])
            if not undefined_rvalue:
                # Infer rvalue again, now in the correct type context.
                rvalue_type = cast(TupleType, self.accept(rvalue,
                                                          TupleType(items)))
            if len(rvalue_type.items) != len(lvalue_types):
                self.msg.incompatible_value_count_in_assignment(
                    len(lvalue_types), len(rvalue_type.items), context)
            else:
                # The number of values is compatible. Check their types.
                for j in range(len(lvalue_types)):
                    self.check_single_assignment(
                        lvalue_types[j], index_lvalues[j],
                        self.temp_node(rvalue_type.items[j]), context, msg)
        elif (is_subtype(rvalue_type,
                         self.named_generic_type('typing.Iterable',
                                                 [AnyType()])) and
              isinstance(rvalue_type, Instance)):
            # Rvalue is iterable.
            item_type = self.iterable_item_type(cast(Instance, rvalue_type))
            for k in range(len(lvalue_types)):
                self.check_single_assignment(lvalue_types[k],
                                             index_lvalues[k],
                                             self.temp_node(item_type),
                                             context, msg)
        else:
            self.fail(msg, context)

    def check_single_assignment(self,
            lvalue_type: Type, index_lvalue: IndexExpr,
            rvalue: Node, context: Context,
            msg: str = messages.INCOMPATIBLE_TYPES_IN_ASSIGNMENT) -> None:
        """Type check an assignment.

        If lvalue_type is None, the index_lvalue argument must be the
        index expr for indexed assignment (__setitem__).
        Otherwise, lvalue_type is used as the type of the lvalue.
        """
        if lvalue_type:
            if refers_to_fullname(rvalue, 'typing.Undefined'):
                # The rvalue is just 'Undefined'; this is always valid.
                # Infer the type of 'Undefined' from the lvalue type.
                self.store_type(rvalue, lvalue_type)
                return
            rvalue_type = self.accept(rvalue, lvalue_type)
            self.check_subtype(rvalue_type, lvalue_type, context, msg)
        elif index_lvalue:
            self.check_indexed_assignment(index_lvalue, rvalue, context)
    
    def check_indexed_assignment(self, lvalue: IndexExpr,
                                 rvalue: Node, context: Context) -> None:
        """Type check indexed assignment base[index] = rvalue.

        The lvalue argument is the base[index] expression.
        """
        basetype = self.accept(lvalue.base)
        method_type = self.expr_checker.analyse_external_member_access(
            '__setitem__', basetype, context)
        lvalue.method_type = method_type
        self.expr_checker.check_call(method_type, [lvalue.index, rvalue],
                                     [nodes.ARG_POS, nodes.ARG_POS],
                                     context)
    
    def visit_expression_stmt(self, s: ExpressionStmt) -> Type:
        self.accept(s.expr)
    
    def visit_return_stmt(self, s: ReturnStmt) -> Type:
        """Type check a return statement."""
        if self.is_within_function():
            if s.expr:
                # Return with a value.
                typ = self.accept(s.expr, self.return_types[-1])
                # Returning a value of type Any is always fine.
                if not isinstance(typ, AnyType):
                    if isinstance(self.return_types[-1], Void):
                        self.fail(messages.NO_RETURN_VALUE_EXPECTED, s)
                    else:
                        self.check_subtype(
                            typ, self.return_types[-1], s,
                            messages.INCOMPATIBLE_RETURN_VALUE_TYPE)
            else:
                # Return without a value. It's valid in a generator function.
                if not self.function_stack[-1].is_generator:
                    if (not isinstance(self.return_types[-1], Void) and
                        not self.is_dynamic_function()):
                        self.fail(messages.RETURN_VALUE_EXPECTED, s)
    
    def visit_yield_stmt(self, s: YieldStmt) -> Type:
        return_type = self.return_types[-1]
        if isinstance(return_type, Instance):
            if return_type.type.fullname() != 'typing.Iterator':
                self.fail(messages.INVALID_RETURN_TYPE_FOR_YIELD, s)
                return None
            expected_item_type = return_type.args[0]
        elif isinstance(return_type, AnyType):
            expected_item_type = AnyType()
        else:
            self.fail(messages.INVALID_RETURN_TYPE_FOR_YIELD, s)
            return None
        actual_item_type = self.accept(s.expr, expected_item_type)
        self.check_subtype(actual_item_type, expected_item_type, s)
    
    def visit_if_stmt(self, s: IfStmt) -> Type:
        """Type check an if statement."""
        for e, b in zip(s.expr, s.body):
            t = self.accept(e)
            self.check_not_void(t, e)
            var, type, kind = find_isinstance_check(e, self.type_map)
            if kind != ISINSTANCE_ALWAYS_FALSE:
                # Only type check body if the if condition can be true.
                if var:
                    self.binder.push(var, type)
                self.accept(b)
                if var:
                    self.binder.pop(var)
            if kind == ISINSTANCE_ALWAYS_TRUE:
                # The condition is always true => remaining elif/else blocks
                # can never be reached.
                break
        else:
            if s.else_body:
                self.accept(s.else_body)
    
    def visit_while_stmt(self, s: WhileStmt) -> Type:
        """Type check a while statement."""
        t = self.accept(s.expr)
        self.check_not_void(t, s)
        self.accept(s.body)
        if s.else_body:
            self.accept(s.else_body)
    
    def visit_operator_assignment_stmt(self,
                                       s: OperatorAssignmentStmt) -> Type:
        """Type check an operator assignment statement, e.g. x += 1."""
        lvalue_type = self.accept(s.lvalue)
        method = infer_operator_assignment_method(lvalue_type, s.op)
        rvalue_type, method_type = self.expr_checker.check_op(
            method, lvalue_type, s.rvalue, s)
        
        if isinstance(s.lvalue, IndexExpr):
            lv = cast(IndexExpr, s.lvalue)
            self.check_single_assignment(None, lv, s.rvalue, s.rvalue)
        else:
            if not is_subtype(rvalue_type, lvalue_type):
                self.msg.incompatible_operator_assignment(s.op, s)
    
    def visit_assert_stmt(self, s: AssertStmt) -> Type:
        self.accept(s.expr)
    
    def visit_raise_stmt(self, s: RaiseStmt) -> Type:
        """Type check a raise statement."""
        if s.expr:
            typ = self.accept(s.expr)
            if isinstance(typ, FunctionLike):
                if typ.is_type_obj():
                    # Cases like "raise ExceptionClass".
                    typeinfo = typ.type_object()
                    base = self.lookup_typeinfo('builtins.BaseException')
                    if base in typeinfo.mro:
                        # Good!
                        return None
                    # Else fall back to the check below (which will fail).
            self.check_subtype(typ,
                               self.named_type('builtins.BaseException'), s,
                               messages.INVALID_EXCEPTION)
    
    def visit_try_stmt(self, s: TryStmt) -> Type:
        """Type check a try statement."""
        self.accept(s.body)
        for i in range(len(s.handlers)):
            if s.types[i]:
                t = self.exception_type(s.types[i])
                if s.vars[i]:
                    self.check_assignments([s.vars[i]],
                                           self.temp_node(t, s.vars[i]))
            self.accept(s.handlers[i])
        if s.finally_body:
            self.accept(s.finally_body)
        if s.else_body:
            self.accept(s.else_body)
    
    def exception_type(self, n: Node) -> Type:
        if isinstance(n, ParenExpr):
            # Multiple exception types (...).
            unwrapped = self.expr_checker.unwrap(n)
            if isinstance(unwrapped, TupleExpr):
                t = None # type: Type
                for item in unwrapped.items:
                    tt = self.exception_type(item)
                    if t:
                        t = join_types(t, tt, self.basic_types())
                    else:
                        t = tt
                return t
        else:
            # A single exception type; should evaluate to a type object type.
            type = self.accept(n)
            return self.check_exception_type(type, n)
        self.fail('Unsupported exception', n)
        return AnyType()

    @overload
    def check_exception_type(self, type: FunctionLike,
                             context: Context) -> Type:
        item = type.items()[0]
        ret = item.ret_type
        if (is_subtype(ret, self.named_type('builtins.BaseException'))
                and item.is_type_obj()):
            return ret
        else:
            self.fail(messages.INVALID_EXCEPTION_TYPE, context)
            return AnyType()        

    @overload
    def check_exception_type(self, type: AnyType, context: Context) -> Type:
        return AnyType()

    @overload
    def check_exception_type(self, type: Type, context: Context) -> Type:
        self.fail(messages.INVALID_EXCEPTION_TYPE, context)
        return AnyType()

    def visit_for_stmt(self, s: ForStmt) -> Type:
        """Type check a for statement."""
        item_type = self.analyse_iterable_item_type(s.expr)
        self.analyse_index_variables(s.index, s.is_annotated(), item_type, s)
        self.accept(s.body)

    def analyse_iterable_item_type(self, expr: Node) -> Type:
        """Analyse iterable expression and return iterator item type."""
        iterable = self.accept(expr)
        
        self.check_not_void(iterable, expr)
        if isinstance(iterable, TupleType):
            joined = NoneTyp() # type: Type
            for item in iterable.items:
                joined = join_types(joined, item, self.basic_types())
            if isinstance(joined, ErrorType):
                self.fail(messages.CANNOT_INFER_ITEM_TYPE, expr)
                return AnyType()
            return joined
        else:
            # Non-tuple iterable.
            self.check_subtype(iterable,
                               self.named_generic_type('typing.Iterable',
                                                       [AnyType()]),
                               expr, messages.ITERABLE_EXPECTED)

            echk = self.expr_checker
            method = echk.analyse_external_member_access('__iter__', iterable,
                                                         expr)
            iterator = echk.check_call(method, [], [], expr)[0]
            if self.pyversion >= 3:
                nextmethod = '__next__'
            else:
                nextmethod = 'next'
            method = echk.analyse_external_member_access(nextmethod, iterator,
                                                         expr)
            return echk.check_call(method, [], [], expr)[0]

    def analyse_index_variables(self, index: List[NameExpr],
                                is_annotated: bool,
                                item_type: Type, context: Context) -> None:
        """Type check or infer for loop or list comprehension index vars."""
        if not is_annotated:
            # Create a temporary copy of variables with Node item type.
            # TODO this is ugly
            node_index = [] # type: List[Node]
            for i in index:
                node_index.append(i)
            self.check_assignments(node_index,
                                   self.temp_node(item_type, context))
        elif len(index) == 1:
            v = cast(Var, index[0].node)
            if v.type:
                self.check_single_assignment(v.type, None,
                                           self.temp_node(item_type), context,
                                           messages.INCOMPATIBLE_TYPES_IN_FOR)
        else:
            t = [] # type: List[Type]
            for ii in index:
                v = cast(Var, ii.node)
                if v.type:
                    t.append(v.type)
                else:
                    t.append(AnyType())
            self.check_multi_assignment(t, [None] * len(index),
                                        self.temp_node(item_type), context,
                                        messages.INCOMPATIBLE_TYPES_IN_FOR)
    
    def visit_del_stmt(self, s: DelStmt) -> Type:
        if isinstance(s.expr, IndexExpr):
            e = cast(IndexExpr, s.expr)  # Cast
            m = MemberExpr(e.base, '__delitem__')
            m.line = s.line
            c = CallExpr(m, [e.index], [nodes.ARG_POS], [None])
            c.line = s.line
            return c.accept(self)
        else:
            s.expr.accept(self)
            return None
    
    def visit_decorator(self, e: Decorator) -> Type:
        e.func.accept(self)
        sig = function_type(e.func) # type: Type
        # Process decorators from the inside out.
        for i in range(len(e.decorators)):
            n = len(e.decorators) - 1 - i
            dec = self.accept(e.decorators[n])
            temp = self.temp_node(sig)
            sig, t2 = self.expr_checker.check_call(dec, [temp],
                                                   [nodes.ARG_POS], e)
        sig = set_callable_name(sig, e.func)
        e.var.type = sig
        e.var.is_ready = True

    def visit_with_stmt(self, s: WithStmt) -> Type:
        echk = self.expr_checker
        for expr, name in zip(s.expr, s.name):
            ctx = self.accept(expr)
            enter = echk.analyse_external_member_access('__enter__', ctx, expr)
            obj = echk.check_call(enter, [], [], expr)[0]
            if name:
                self.check_assignments([name], self.temp_node(obj, expr))
            exit = echk.analyse_external_member_access('__exit__', ctx, expr)
            arg = self.temp_node(AnyType(), expr)
            echk.check_call(exit, [arg] * 3, [nodes.ARG_POS] * 3, expr)
        self.accept(s.body)

    def visit_print_stmt(self, s: PrintStmt) -> Type:
        for arg in s.args:
            self.accept(arg)            
    
    #
    # Expressions
    #
    
    def visit_name_expr(self, e: NameExpr) -> Type:
        return self.expr_checker.visit_name_expr(e)
    
    def visit_paren_expr(self, e: ParenExpr) -> Type:
        return self.expr_checker.visit_paren_expr(e)
    
    def visit_call_expr(self, e: CallExpr) -> Type:
        return self.expr_checker.visit_call_expr(e)
    
    def visit_member_expr(self, e: MemberExpr) -> Type:
        return self.expr_checker.visit_member_expr(e)
    
    def visit_int_expr(self, e: IntExpr) -> Type:
        return self.expr_checker.visit_int_expr(e)
    
    def visit_str_expr(self, e: StrExpr) -> Type:
        return self.expr_checker.visit_str_expr(e)
    
    def visit_bytes_expr(self, e: BytesExpr) -> Type:
        return self.expr_checker.visit_bytes_expr(e)
    
    def visit_unicode_expr(self, e: UnicodeExpr) -> Type:
        return self.expr_checker.visit_unicode_expr(e)
    
    def visit_float_expr(self, e: FloatExpr) -> Type:
        return self.expr_checker.visit_float_expr(e)
    
    def visit_op_expr(self, e: OpExpr) -> Type:
        return self.expr_checker.visit_op_expr(e)
    
    def visit_unary_expr(self, e: UnaryExpr) -> Type:
        return self.expr_checker.visit_unary_expr(e)
    
    def visit_index_expr(self, e: IndexExpr) -> Type:
        return self.expr_checker.visit_index_expr(e)
    
    def visit_cast_expr(self, e: CastExpr) -> Type:
        return self.expr_checker.visit_cast_expr(e)
    
    def visit_super_expr(self, e: SuperExpr) -> Type:
        return self.expr_checker.visit_super_expr(e)
    
    def visit_type_application(self, e: TypeApplication) -> Type:
        return self.expr_checker.visit_type_application(e)

    def visit_type_var_expr(self, e: TypeVarExpr) -> Type:
        # TODO Perhaps return a special type used for type variables only?
        return AnyType()
    
    def visit_list_expr(self, e: ListExpr) -> Type:
        return self.expr_checker.visit_list_expr(e)
    
    def visit_set_expr(self, e: SetExpr) -> Type:
        return self.expr_checker.visit_set_expr(e)
    
    def visit_tuple_expr(self, e: TupleExpr) -> Type:
        return self.expr_checker.visit_tuple_expr(e)
    
    def visit_dict_expr(self, e: DictExpr) -> Type:
        return self.expr_checker.visit_dict_expr(e)
    
    def visit_slice_expr(self, e: SliceExpr) -> Type:
        return self.expr_checker.visit_slice_expr(e)
    
    def visit_func_expr(self, e: FuncExpr) -> Type:
        return self.expr_checker.visit_func_expr(e)
    
    def visit_list_comprehension(self, e: ListComprehension) -> Type:
        return self.expr_checker.visit_list_comprehension(e)

    def visit_generator_expr(self, e: GeneratorExpr) -> Type:
        return self.expr_checker.visit_generator_expr(e)

    def visit_undefined_expr(self, e: UndefinedExpr) -> Type:
        return self.expr_checker.visit_undefined_expr(e)

    def visit_temp_node(self, e: TempNode) -> Type:
        return e.type

    def visit_conditional_expr(self, e: ConditionalExpr) -> Type:
        return self.expr_checker.visit_conditional_expr(e)
    
    #
    # Helpers
    #
    
    def check_subtype(self, subtype: Type, supertype: Type, context: Context,
                       msg: str = messages.INCOMPATIBLE_TYPES) -> None:
        """Generate an error if the subtype is not compatible with
        supertype."""
        if not is_subtype(subtype, supertype):
            if isinstance(subtype, Void):
                self.msg.does_not_return_value(subtype, context)
            else:
                self.fail(msg, context)
    
    def named_type(self, name: str) -> Instance:
        """Return an instance type with type given by the name and no
        type arguments. For example, named_type('builtins.object')
        produces the object type.
        """
        # Assume that the name refers to a type.
        sym = self.lookup_qualified(name)
        return Instance(cast(TypeInfo, sym.node), [])
    
    def named_type_if_exists(self, name: str) -> Type:
        """Return named instance type, or UnboundType if the type was
        not defined.
        
        This is used to simplify test cases by avoiding the need to
        define basic types not needed in specific test cases (tuple
        etc.).
        """
        try:
            # Assume that the name refers to a type.
            sym = self.lookup_qualified(name)
            return Instance(cast(TypeInfo, sym.node), [])
        except KeyError:
            return UnboundType(name)
    
    def named_generic_type(self, name: str, args: List[Type]) -> Instance:
        """Return an instance with the given name and type arguments.

        Assume that the number of arguments is correct.  Assume that
        the name refers to a compatible generic type.
        """
        return Instance(self.lookup_typeinfo(name), args)

    def lookup_typeinfo(self, fullname: str) -> TypeInfo:
        # Assume that the name refers to a class.
        sym = self.lookup_qualified(fullname)
        return cast(TypeInfo, sym.node)
    
    def type_type(self) -> Instance:
        """Return instance type 'type'."""
        return self.named_type('builtins.type')
    
    def object_type(self) -> Instance:
        """Return instance type 'object'."""
        return self.named_type('builtins.object')
    
    def bool_type(self) -> Instance:
        """Return instance type 'bool'."""
        return self.named_type('builtins.bool')
    
    def str_type(self) -> Instance:
        """Return instance type 'str'."""
        return self.named_type('builtins.str')
    
    def tuple_type(self) -> Type:
        """Return instance type 'tuple'."""
        # We need the tuple for analysing member access. We want to be able to
        # do this even if tuple type is not available (useful in test cases),
        # so we return an unbound type if there is no tuple type.
        return self.named_type_if_exists('builtins.tuple')
    
    def check_type_equivalency(self, t1: Type, t2: Type, node: Context,
                               msg: str = messages.INCOMPATIBLE_TYPES) -> None:
        """Generate an error if the types are not equivalent. The
        dynamic type is equivalent with all types.
        """
        if not is_equivalent(t1, t2):
            self.fail(msg, node)
    
    def store_type(self, node: Node, typ: Type) -> None:
        """Store the type of a node in the type map."""
        self.type_map[node] = typ
    
    def is_dynamic_function(self) -> bool:
        return len(self.dynamic_funcs) > 0 and self.dynamic_funcs[-1]
    
    def lookup(self, name: str, kind: int) -> SymbolTableNode:
        """Look up a definition from the symbol table with the given name.
        TODO remove kind argument
        """
        if self.locals is not None and name in self.locals:
            return self.locals[name]
        elif name in self.globals:
            return self.globals[name]
        else:
            b = self.globals.get('__builtins__', None)
            if b:
                table = cast(MypyFile, b.node).names
                if name in table:
                    return table[name]
            raise KeyError('Failed lookup: {}'.format(name))
    
    def lookup_qualified(self, name: str) -> SymbolTableNode:
        if '.' not in name:
            return self.lookup(name, GDEF) # FIX kind
        else:
            parts = name.split('.')
            n = self.modules[parts[0]]
            for i in range(1, len(parts) - 1):
                n = cast(MypyFile, ((n.names.get(parts[i], None).node)))
            return n.names[parts[-1]]
    
    def enter(self) -> None:
        self.locals = SymbolTable()
    
    def leave(self) -> None:
        self.locals = None
    
    def basic_types(self) -> BasicTypes:
        """Return a BasicTypes instance that contains primitive types that are
        needed for certain type operations (joins, for example).
        """
        return BasicTypes(self.object_type(), self.type_type(),
                          self.named_type_if_exists('builtins.tuple'),
                          self.named_type_if_exists('builtins.function'))
    
    def is_within_function(self) -> bool:
        """Are we currently type checking within a function?

        I.e. not at class body or at the top level.
        """
        return self.return_types != []
    
    def check_not_void(self, typ: Type, context: Context) -> None:
        """Generate an error if the type is Void."""
        if isinstance(typ, Void):
            self.msg.does_not_return_value(typ, context)
    
    def temp_node(self, t: Type, context: Context = None) -> Node:
        """Create a temporary node with the given, fixed type."""
        temp = TempNode(t)
        if context:
            temp.set_line(context.get_line())
        return temp
    
    def fail(self, msg: str, context: Context) -> None:
        """Produce an error message."""
        self.msg.fail(msg, context)

    def iterable_item_type(self, instance: Instance) -> Type:
        iterable = map_instance_to_supertype(
            instance,
            self.lookup_typeinfo('typing.Iterable'))
        return iterable.args[0]


def map_type_from_supertype(typ: Type, sub_info: TypeInfo,
                            super_info: TypeInfo) -> Type:
    """Map type variables in a type defined in a supertype context to be valid
    in the subtype context. Assume that the result is unique; if more than
    one type is possible, return one of the alternatives.
    
    For example, assume
    
      class D(Generic[S]) ...
      class C(D[E[T]], Generic[T]) ...
    
    Now S in the context of D would be mapped to E[T] in the context of C.
    """
    # Create the type of self in subtype, of form t[a1, ...].
    inst_type = self_type(sub_info)
    # Map the type of self to supertype. This gets us a description of the
    # supertype type variables in terms of subtype variables, i.e. t[t1, ...]
    # so that any type variables in tN are to be interpreted in subtype
    # context.
    inst_type = map_instance_to_supertype(inst_type, super_info)
    # Finally expand the type variables in type with those in the previously
    # constructed type. Note that both type and inst_type may have type
    # variables, but in type they are interpreterd in supertype context while
    # in inst_type they are interpreted in subtype context. This works even if
    # the names of type variables in supertype and subtype overlap.
    return expand_type_by_instance(typ, inst_type)


def get_undefined_tuple(rvalue: Node) -> Type:
    """Get tuple type corresponding to a tuple of Undefined values.

    The type is Tuple[Any, ...]. If rvalue is not of the right form, return
    None.
    """
    if isinstance(rvalue, TupleExpr):
        for item in rvalue.items:
            if not refers_to_fullname(item, 'typing.Undefined'):
                break
        else:
            return TupleType([AnyType()] * len(rvalue.items))
    return None


def find_isinstance_check(node: Node,
                          type_map: Dict[Node, Type]) -> Tuple[Var, Type, int]:
    """Check if node is an isinstance(variable, type) check.

    If successful, return tuple (variable, target-type, kind); otherwise,
    return (None, AnyType, -1).

    When successful, the kind takes one of these values:

      ISINSTANCE_OVERLAPPING: The type of variable and the target type are
          partially overlapping => the test result can be True or False.
      ISINSTANCE_ALWAYS_TRUE: The target type at least as general as the
          variable type => the test is always True.
      ISINSTANCE_ALWAYS_FALSE: The target type and the variable type are not
          overlapping => the test is always False.
    """
    if isinstance(node, CallExpr):
        if refers_to_fullname(node.callee, 'builtins.isinstance'):
            expr = node.args[0]
            if isinstance(expr, NameExpr):
                type = get_isinstance_type(node.args[1], type_map)
                if type and isinstance(expr.node, Var):
                    var = cast(Var, expr.node)
                    kind = ISINSTANCE_OVERLAPPING
                    if var.type:
                        if is_proper_subtype(var.type, type):
                            kind = ISINSTANCE_ALWAYS_TRUE
                        elif not is_overlapping_types(var.type, type):
                            kind = ISINSTANCE_ALWAYS_FALSE
                    return cast(Var, expr.node), type, kind
    # Not a supported isinstance check
    return None, AnyType(), -1


def get_isinstance_type(node: Node, type_map: Dict[Node, Type]) -> Type:
    type = type_map[node]
    if isinstance(type, FunctionLike):
        if type.is_type_obj():
            # Type variables may be present -- erase them, which is the best
            # we can do (outside disallowing them here).
            return erase_typevars(type.items()[0].ret_type)
    return None


def is_overlapping_types(t: Type, s: Type) -> bool:
    """Can a value of type t be a value of type s, or vice versa?"""
    if isinstance(t, Instance):
        if isinstance(s, Instance):
            # If the classes are explicitly declared as disjoint, they can't
            # overlap.
            if t.type in s.type.disjoint_classes:
                return False
            
            # Built-in classes in the mro affect whether two types can be
            # overlapping.
            # TODO Find the most distant ancestor with the same memory layout,
            #      since multiple inheritance seems possible if the memory
            #      layout is the same.
            tbuiltin = nearest_builtin_ancestor(t.type)
            sbuiltin = nearest_builtin_ancestor(s.type)
            
            # If one is a base class of other, the types overlap, unless there
            # is an explicit disjointclass constraint.
            if tbuiltin in sbuiltin.mro or sbuiltin in tbuiltin.mro:
                return True
            return tbuiltin == sbuiltin
    # We conservatively assume that non-instance types can overlap any other
    # types.    
    return True


def nearest_builtin_ancestor(type: TypeInfo) -> TypeInfo:
    for base in type.mro:
        if base.defn.is_builtinclass:
            return base
    else:
        assert False, 'No built-in ancestor found for {}'.format(type.name())


def expand_node(defn: Node, map: Dict[int, Type]) -> Node:
    visitor = TypeTransformVisitor(map)
    return defn.accept(visitor)


def expand_func(defn: FuncItem, map: Dict[int, Type]) -> FuncItem:
    return cast(FuncItem, expand_node(defn, map))


class TypeTransformVisitor(TransformVisitor):
    def __init__(self, map: Dict[int, Type]) -> None:
        super().__init__()
        self.map = map
    
    def type(self, type: Type) -> Type:
        return expand_type(type, self.map)


def is_unsafe_overlapping_signatures(signature: Type, other: Type) -> bool:
    """Check if two signatures may be unsafely overlapping.

    Two signatures s and t are overlapping if both can be valid for the same
    statically typed values and the return types are incompatible.

    Assume calls are first checked against 'signature', then against 'other'.
    Thus if 'signature' is more general than 'other', there is no unsafe
    overlapping.

    TODO If argument types vary covariantly, the return type may vary
         covariantly as well.
    """
    if isinstance(signature, Callable):
        if isinstance(other, Callable):
            # TODO varargs
            # TODO keyword args
            # TODO erasure
            # TODO allow to vary covariantly
            # Check if the argument counts are overlapping.
            min_args = max(signature.min_args, other.min_args)
            max_args = min(len(signature.arg_types), len(other.arg_types))
            if min_args > max_args:
                # Argument counts are not overlapping.
                return False
            # Signatures are overlapping iff if they are overlapping for the
            # smallest common argument count.
            for i in range(min_args):
                t1 = signature.arg_types[i]
                t2 = other.arg_types[i]
                if not is_overlapping_types(t1, t2):
                    return False
            # All arguments types for the smallest common argument count are
            # overlapping => the signature is overlapping. The overlapping is
            # safe if the return types are identical.
            if is_same_type(signature.ret_type, other.ret_type):
                return False
            # If the first signature has more general argument types, the
            # latter will never be called 
            if is_more_general_arg_prefix(signature, other):
                return False
            return not is_more_precise_signature(signature, other)            
    return True


def is_more_general_arg_prefix(t: FunctionLike, s: FunctionLike) -> bool:
    """Does t have wider arguments than s?"""
    # TODO should an overload with additional items be allowed to be more
    #      general than one with fewer items (or just one item)?
    # TODO check argument kinds
    if isinstance(t, Callable):
        if isinstance(s, Callable):
            return all(is_proper_subtype(args, argt)
                       for argt, args in zip(t.arg_types, s.arg_types))
    elif isinstance(t, FunctionLike):
        if isinstance(s, FunctionLike):
            if len(t.items()) == len(s.items()):
                return all(is_same_arg_prefix(items, itemt)
                           for items, itemt in zip(t.items(), s.items()))
    return False


def is_same_arg_prefix(t: Callable, s: Callable) -> bool:
    # TODO check argument kinds
    return all(is_same_type(argt, args)
               for argt, args in zip(t.arg_types, s.arg_types))


def is_more_precise_signature(t: Callable, s: Callable) -> bool:
    """Is t more precise than s?

    A signature t is more precise than s if all argument types and the return
    type of t are more precise than the corresponding types in s.

    Assume that the argument kinds and names are compatible, and that the
    argument counts are overlapping.
    """
    # TODO generic function types
    # Only consider the common prefix of argument types.
    for argt, args in zip(t.arg_types, s.arg_types):
        if not is_more_precise(argt, args):
            return False
    return is_more_precise(t.ret_type, s.ret_type)


def infer_operator_assignment_method(type: Type, operator: str) -> str:
    """Return the method used for operator assignment for given value type.

    For example, if operator is '+', return '__iadd__' or '__add__' depending
    on which method is supported by the type.
    """
    method = nodes.op_methods[operator]
    if isinstance(type, Instance):
        if operator in nodes.ops_with_inplace_method:
            inplace = '__i' + method[2:]
            if type.type.has_readable_member(inplace):
                method = inplace
    return method

########NEW FILE########
__FILENAME__ = checkexpr
"""Expression type checker. This file is conceptually part of TypeChecker."""

from typing import Undefined, cast, List, Tuple, Dict, Function

from mypy.types import (
    Type, AnyType, Callable, Overloaded, NoneTyp, Void, TypeVarDef,
    TupleType, Instance, TypeVar, TypeTranslator, ErasedType, FunctionLike
)
from mypy.nodes import (
    NameExpr, RefExpr, Var, FuncDef, OverloadedFuncDef, TypeInfo, CallExpr,
    Node, MemberExpr, IntExpr, StrExpr, BytesExpr, UnicodeExpr, FloatExpr,
    OpExpr, UnaryExpr, IndexExpr, CastExpr, TypeApplication, ListExpr,
    TupleExpr, DictExpr, FuncExpr, SuperExpr, ParenExpr, SliceExpr, Context,
    ListComprehension, GeneratorExpr, SetExpr, MypyFile, Decorator,
    UndefinedExpr, ConditionalExpr, TempNode
)
from mypy.nodes import function_type, method_type
from mypy import nodes
import mypy.checker
from mypy import types
from mypy.sametypes import is_same_type
from mypy.replacetvars import replace_func_type_vars, replace_type_vars
from mypy.messages import MessageBuilder
from mypy import messages
from mypy.infer import infer_type_arguments, infer_function_type_arguments
from mypy import join
from mypy.expandtype import expand_type, expand_caller_var_args
from mypy.subtypes import is_subtype
from mypy import erasetype
from mypy.checkmember import analyse_member_access, type_object_type
from mypy.semanal import self_type
from mypy.constraints import get_actual_type


class ExpressionChecker:
    """Expression type checker.

    This clas works closely together with checker.TypeChecker.
    """
    
    # Some services are provided by a TypeChecker instance.
    chk = Undefined('mypy.checker.TypeChecker')
    # This is shared with TypeChecker, but stored also here for convenience.
    msg = Undefined(MessageBuilder)
    
    def __init__(self,
                  chk: 'mypy.checker.TypeChecker',
                  msg: MessageBuilder) -> None:
        """Construct an expression type checker."""
        self.chk = chk
        self.msg = msg
    
    def visit_name_expr(self, e: NameExpr) -> Type:
        """Type check a name expression.

        It can be of any kind: local, member or global.
        """
        return self.analyse_ref_expr(e)
    
    def analyse_ref_expr(self, e: RefExpr) -> Type:
        result = Undefined(Type)
        node = e.node
        if isinstance(node, Var):
            # Variable reference.
            result = self.analyse_var_ref(node, e)
        elif isinstance(node, FuncDef):
            # Reference to a global function.
            result = function_type(node)
        elif isinstance(node, OverloadedFuncDef):
            result = node.type
        elif isinstance(node, TypeInfo):
            # Reference to a type object.
            result = type_object_type(node, self.chk.type_type)
        elif isinstance(node, MypyFile):
            # Reference to a module object.
            result = self.chk.named_type('builtins.module')
        elif isinstance(node, Decorator):
            result = self.analyse_var_ref(node.var, e)
        else:
            # Unknown reference; use any type implicitly to avoid
            # generating extra type errors.
            result = AnyType()
        return result

    def analyse_var_ref(self, var: Var, context: Context) -> Type:
        if not var.type:
            if not var.is_ready:
                self.msg.cannot_determine_type(var.name(), context)
            # Implicit 'Any' type.
            return AnyType()
        else:
            # Look up local type of variable with type (inferred or explicit).
            return self.chk.binder.get(var)
    
    def visit_call_expr(self, e: CallExpr) -> Type:
        """Type check a call expression."""
        if e.analyzed:
            # It's really a special form that only looks like a call.
            return self.accept(e.analyzed)
        self.accept(e.callee)
        # Access callee type directly, since accept may return the Any type
        # even if the type is known (in a dynamically typed function). This
        # way we get a more precise callee in dynamically typed functions.
        callee_type = self.chk.type_map[e.callee]
        return self.check_call_expr_with_callee_type(callee_type, e)
    
    def check_call_expr_with_callee_type(self, callee_type: Type,
                                         e: CallExpr) -> Type:
        """Type check call expression.

        The given callee type overrides the type of the callee
        expression.
        """
        return self.check_call(callee_type, e.args, e.arg_kinds, e,
                               e.arg_names, callable_node=e.callee)[0]
    
    def check_call(self, callee: Type, args: List[Node],
                   arg_kinds: List[int], context: Context,
                   arg_names: List[str] = None,
                   callable_node: Node = None,
                   arg_messages: MessageBuilder = None) -> Tuple[Type, Type]:
        """Type check a call.

        Also infer type arguments if the callee is a generic function.

        Return (result type, inferred callee type).

        Arguments:
          callee: type of the called value
          args: actual argument expressions
          arg_kinds: contains nodes.ARG_* constant for each argument in args
            describing whether the argument is positional, *arg, etc.
          arg_names: names of arguments (optional)
          callable_node: associate the inferred callable type to this node,
            if specified
          arg_messages: TODO
        """
        arg_messages = arg_messages or self.msg
        is_var_arg = nodes.ARG_STAR in arg_kinds
        if isinstance(callee, Callable):
            if callee.is_type_obj():
                t = callee.type_object()
            if callee.is_type_obj() and callee.type_object().is_abstract:
                type = callee.type_object()
                self.msg.cannot_instantiate_abstract_class(
                    callee.type_object().name(), type.abstract_attributes,
                    context)
            
            formal_to_actual = map_actuals_to_formals(
                arg_kinds, arg_names,
                callee.arg_kinds, callee.arg_names,
                lambda i: self.accept(args[i]))
            
            if callee.is_generic():
                callee = self.infer_function_type_arguments_using_context(
                    callee, context)
                callee = self.infer_function_type_arguments(
                    callee, args, arg_kinds, formal_to_actual, context)
            
            arg_types = self.infer_arg_types_in_context2(
                callee, args, arg_kinds, formal_to_actual)

            self.check_argument_count(callee, arg_types, arg_kinds,
                                      arg_names, formal_to_actual, context)
            
            self.check_argument_types(arg_types, arg_kinds, callee,
                                      formal_to_actual, context,
                                      messages=arg_messages)
            if callable_node:
                # Store the inferred callable type.
                self.chk.store_type(callable_node, callee)
            return callee.ret_type, callee
        elif isinstance(callee, Overloaded):
            # Type check arguments in empty context. They will be checked again
            # later in a context derived from the signature; these types are
            # only used to pick a signature variant.
            self.msg.disable_errors()
            arg_types = self.infer_arg_types_in_context(None, args)
            self.msg.enable_errors()
            
            target = self.overload_call_target(arg_types, is_var_arg,
                                               callee, context,
                                               messages=arg_messages)
            return self.check_call(target, args, arg_kinds, context, arg_names,
                                   arg_messages=arg_messages)
        elif isinstance(callee, AnyType) or self.chk.is_dynamic_function():
            self.infer_arg_types_in_context(None, args)
            return AnyType(), AnyType()
        else:
            return self.msg.not_callable(callee, context), AnyType()
    
    def infer_arg_types_in_context(self, callee: Callable,
                                   args: List[Node]) -> List[Type]:
        """Infer argument expression types using a callable type as context.

        For example, if callee argument 2 has type List[int], infer the
        argument expression with List[int] type context.
        """
        # TODO Always called with callee as None, i.e. empty context.
        res = [] # type: List[Type]
        
        fixed = len(args)
        if callee:
            fixed = min(fixed, callee.max_fixed_args())
        
        for i in range(fixed):
            arg = args[i] # FIX refactor
            ctx = None # type: Type
            if callee and i < len(callee.arg_types):
                ctx = callee.arg_types[i]
            res.append(self.accept(arg, ctx))
        
        for j in range(fixed, len(args)):
            if callee and callee.is_var_arg:
                res.append(self.accept(args[j], callee.arg_types[-1]))
            else:
                res.append(self.accept(args[j]))
        
        return res
    
    def infer_arg_types_in_context2(
            self, callee: Callable, args: List[Node], arg_kinds: List[int],
            formal_to_actual: List[List[int]]) -> List[Type]:
        """Infer argument expression types using a callable type as context.

        For example, if callee argument 2 has type List[int], infer the
        argument exprsession with List[int] type context.

        Returns the inferred types of *actual arguments*.
        """
        res = [None] * len(args) # type: List[Type]

        for i, actuals in enumerate(formal_to_actual):
            for ai in actuals:
                if arg_kinds[ai] != nodes.ARG_STAR:
                    res[ai] = self.accept(args[ai], callee.arg_types[i])

        # Fill in the rest of the argument types.
        for i, t in enumerate(res):
            if not t:
                res[i] = self.accept(args[i])
        return res
    
    def infer_function_type_arguments_using_context(
            self, callable: Callable, error_context: Context) -> Callable:
        """Unify callable return type to type context to infer type vars.

        For example, if the return type is set[t] where 't' is a type variable
        of callable, and if the context is set[int], return callable modified
        by substituting 't' with 'int'.
        """
        ctx = self.chk.type_context[-1]
        if not ctx:
            return callable
        # The return type may have references to function type variables that
        # we are inferring right now. We must consider them as indeterminate
        # and they are not potential results; thus we replace them with the
        # None type. On the other hand, class type variables are valid results.
        erased_ctx = replace_func_type_vars(ctx, ErasedType())
        args = infer_type_arguments(callable.type_var_ids(), callable.ret_type,
                                    erased_ctx, self.chk.basic_types())
        # Only substite non-None and non-erased types.
        new_args = [] # type: List[Type]
        for arg in args:
            if isinstance(arg, NoneTyp) or has_erased_component(arg):
                new_args.append(None)
            else:
                new_args.append(arg)
        return cast(Callable, self.apply_generic_arguments(callable, new_args,
                                                           error_context))
    
    def infer_function_type_arguments(self, callee_type: Callable,
                                      args: List[Node],
                                      arg_kinds: List[int],
                                      formal_to_actual: List[List[int]],
                                      context: Context) -> Callable:
        """Infer the type arguments for a generic callee type.

        Infer based on the types of arguments.

        Return a derived callable type that has the arguments applied (and
        stored as implicit type arguments).
        """
        if not self.chk.is_dynamic_function():
            # Disable type errors during type inference. There may be errors
            # due to partial available context information at this time, but
            # these errors can be safely ignored as the arguments will be
            # inferred again later.
            self.msg.disable_errors()
            
            arg_types = self.infer_arg_types_in_context2(
                callee_type, args, arg_kinds, formal_to_actual)
        
            self.msg.enable_errors()

            arg_pass_nums = self.get_arg_infer_passes(
                callee_type.arg_types, formal_to_actual, len(args))

            pass1_args = [] # type: List[Type]
            for i, arg in enumerate(arg_types):
                if arg_pass_nums[i] > 1:
                    pass1_args.append(None)
                else:
                    pass1_args.append(arg)
            
            inferred_args = infer_function_type_arguments(
                callee_type, pass1_args, arg_kinds, formal_to_actual,
                self.chk.basic_types()) # type: List[Type]

            if 2 in arg_pass_nums:
                # Second pass of type inference.
                (callee_type,
                 inferred_args) = self.infer_function_type_arguments_pass2(
                    callee_type, args, arg_kinds, formal_to_actual,
                    inferred_args, context)
        else:
            # In dynamically typed functions use implicit 'Any' types for
            # type variables.
            inferred_args = [AnyType()] * len(callee_type.variables)
        return self.apply_inferred_arguments(callee_type, inferred_args,
                                             context)

    def infer_function_type_arguments_pass2(
                             self, callee_type: Callable,
                             args: List[Node],
                             arg_kinds: List[int],
                             formal_to_actual: List[List[int]],
                             inferred_args: List[Type],
                             context: Context) -> Tuple[Callable, List[Type]]:
        """Perform second pass of generic function type argument inference.

        The second pass is needed for arguments with types such as func<s(t)>,
        where both s and t are type variables, when the actual argument is a
        lambda with inferred types.  The idea is to infer the type variable t
        in the first pass (based on the types of other arguments).  This lets
        us infer the argument and return type of the lambda expression and
        thus also the type variable s in this second pass.

        Return (the callee with type vars applied, inferred actual arg types).
        """
        # None or erased types in inferred types mean that there was not enough
        # information to infer the argument. Replace them with None values so
        # that they are not applied yet below.
        for i, arg in enumerate(inferred_args):
            if isinstance(arg, NoneTyp) or isinstance(arg, ErasedType):
                inferred_args[i] = None

        callee_type = cast(Callable, self.apply_generic_arguments(
            callee_type, inferred_args, context))
        arg_types = self.infer_arg_types_in_context2(
            callee_type, args, arg_kinds, formal_to_actual)

        inferred_args = infer_function_type_arguments(
            callee_type, arg_types, arg_kinds, formal_to_actual,
            self.chk.basic_types())

        return callee_type, inferred_args

    def get_arg_infer_passes(self, arg_types: List[Type],
                             formal_to_actual: List[List[int]],
                             num_actuals: int) -> List[int]:
        """Return pass numbers for args for two-pass argument type inference.

        For each actual, the pass number is either 1 (first pass) or 2 (second
        pass).

        Two-pass argument type inference primarily lets us infer types of
        lambdas more effectively.
        """
        res = [1] * num_actuals
        for i, arg in enumerate(arg_types):
            if arg.accept(ArgInferSecondPassQuery()):
                for j in formal_to_actual[i]:
                    res[j] = 2
        return res
    
    def apply_inferred_arguments(self, callee_type: Callable,
                                 inferred_args: List[Type],
                                 context: Context) -> Callable:
        """Apply inferred values of type arguments to a generic function.

        Inferred_args contains the values of function type arguments.
        """
        # Report error if some of the variables could not be solved. In that
        # case assume that all variables have type Any to avoid extra
        # bogus error messages.
        for i, inferred_type in enumerate(inferred_args):
            if not inferred_type:
                # Could not infer a non-trivial type for a type variable.
                self.msg.could_not_infer_type_arguments(
                    callee_type, i + 1, context)
                inferred_args = [AnyType()] * len(inferred_args)
        # Apply the inferred types to the function type. In this case the
        # return type must be Callable, since we give the right number of type
        # arguments.
        return cast(Callable, self.apply_generic_arguments(callee_type,
                                                      inferred_args, context))

    def check_argument_count(self, callee: Callable, actual_types: List[Type],
                             actual_kinds: List[int],  actual_names: List[str],
                             formal_to_actual: List[List[int]],
                             context: Context) -> None:
        """Check that the number of arguments to a function are valid.

        Also check that there are no duplicate values for arguments.
        """
        formal_kinds = callee.arg_kinds

        # Collect list of all actual arguments matched to formal arguments.
        all_actuals = [] # type: List[int]
        for actuals in formal_to_actual:
            all_actuals.extend(actuals)

        is_error = False # Keep track of errors to avoid duplicate errors.
        for i, kind in enumerate(actual_kinds):
            if i not in all_actuals and (
                    kind != nodes.ARG_STAR or
                    not is_empty_tuple(actual_types[i])):
                # Extra actual: not matched by a formal argument.
                if kind != nodes.ARG_NAMED:
                    self.msg.too_many_arguments(callee, context)
                else:
                    self.msg.unexpected_keyword_argument(
                        callee, actual_names[i], context)
                    is_error = True
            elif kind == nodes.ARG_STAR and (
                    nodes.ARG_STAR not in formal_kinds):
                actual_type = actual_types[i]
                if isinstance(actual_type, TupleType):
                    if all_actuals.count(i) < len(actual_type.items):
                        # Too many tuple items as some did not match.
                        self.msg.too_many_arguments(callee, context)
                # *args can be applied even if the function takes a fixed
                # number of positional arguments. This may succeed at runtime.

        for i, kind in enumerate(formal_kinds):
            if kind == nodes.ARG_POS and (not formal_to_actual[i] and
                                          not is_error):
                # No actual for a mandatory positional formal.
                self.msg.too_few_arguments(callee, context)
            elif kind in [nodes.ARG_POS, nodes.ARG_OPT,
                          nodes.ARG_NAMED] and is_duplicate_mapping(
                                                    formal_to_actual[i],
                                                    actual_kinds):
                self.msg.duplicate_argument_value(callee, i, context)
            elif (kind == nodes.ARG_NAMED and formal_to_actual[i] and
                  actual_kinds[formal_to_actual[i][0]] != nodes.ARG_NAMED):
                # Positional argument when expecting a keyword argument.
                self.msg.too_many_positional_arguments(callee, context)
    
    def check_argument_types(self, arg_types: List[Type], arg_kinds: List[int],
                             callee: Callable,
                             formal_to_actual: List[List[int]],
                             context: Context,
                             messages: MessageBuilder = None) -> None:
        """Check argument types against a callable type.

        Report errors if the argument types are not compatible.
        """
        messages = messages or self.msg
        # Keep track of consumed tuple *arg items.
        tuple_counter = [0]
        for i, actuals in enumerate(formal_to_actual):
            for actual in actuals:
                arg_type = arg_types[actual]
                # Check that a *arg is valid as varargs.
                if (arg_kinds[actual] == nodes.ARG_STAR and
                        not self.is_valid_var_arg(arg_type)):
                    messages.invalid_var_arg(arg_type, context)
                if (arg_kinds[actual] == nodes.ARG_STAR2 and
                        not self.is_valid_keyword_var_arg(arg_type)):
                    messages.invalid_keyword_var_arg(arg_type, context)
                # Get the type of an inidividual actual argument (for *args
                # and **args this is the item type, not the collection type).
                actual_type = get_actual_type(arg_type, arg_kinds[actual],
                                              tuple_counter)
                self.check_arg(actual_type, arg_type,
                               callee.arg_types[i],
                               actual + 1, callee, context, messages)
                
                # There may be some remaining tuple varargs items that haven't
                # been checked yet. Handle them.
                if (callee.arg_kinds[i] == nodes.ARG_STAR and
                        arg_kinds[actual] == nodes.ARG_STAR and
                        isinstance(arg_types[actual], TupleType)):
                    tuplet = cast(TupleType, arg_types[actual])
                    while tuple_counter[0] < len(tuplet.items):
                        actual_type = get_actual_type(arg_type,
                                                      arg_kinds[actual],
                                                      tuple_counter)
                        self.check_arg(actual_type, arg_type,
                                       callee.arg_types[i],
                                       actual + 1, callee, context, messages)
    
    def check_arg(self, caller_type: Type, original_caller_type: Type,
                  callee_type: Type, n: int, callee: Callable,
                  context: Context, messages: MessageBuilder) -> None:
        """Check the type of a single argument in a call."""
        if isinstance(caller_type, Void):
            messages.does_not_return_value(caller_type, context)
        elif not is_subtype(caller_type, callee_type):
            messages.incompatible_argument(n, callee, original_caller_type,
                                           context)
    
    def overload_call_target(self, arg_types: List[Type], is_var_arg: bool,
                             overload: Overloaded, context: Context,
                             messages: MessageBuilder = None) -> Type:
        """Infer the correct overload item to call with given argument types.

        The return value may be Callable or AnyType (if an unique item
        could not be determined). If is_var_arg is True, the caller
        uses varargs.
        """
        messages = messages or self.msg
        # TODO also consider argument names and kinds
        # TODO for overlapping signatures we should try to get a more precise
        #      result than 'Any'
        match = [] # type: List[Callable]
        for typ in overload.items():
            if self.matches_signature_erased(arg_types, is_var_arg, typ):
                if (match and not is_same_type(match[-1].ret_type,
                                               typ.ret_type) and
                    not mypy.checker.is_more_precise_signature(
                            match[-1], typ)):
                    # Ambiguous return type. Either the function overload is
                    # overlapping (which results in an error elsewhere) or the
                    # caller has provided some Any argument types; in
                    # either case can only infer the type to be Any, as it is
                    # not an error to use Any types in calls.
                    #
                    # Overlapping overload items are fine if the items are
                    # covariant in both argument types and return types with
                    # respect to type precision.
                    return AnyType()
                else:
                    match.append(typ)
        if not match:
            messages.no_variant_matches_arguments(overload, context)
            return AnyType()
        else:
            if len(match) == 1:
                return match[0]
            else:
                # More than one signature matches. Pick the first *non-erased*
                # matching signature, or default to the first one if none
                # match.
                for m in match:
                    if self.match_signature_types(arg_types, is_var_arg, m):
                        return m
                return match[0]
    
    def matches_signature_erased(self, arg_types: List[Type], is_var_arg: bool,
                                 callee: Callable) -> bool:
        """Determine whether arguments could match the signature at runtime.

        If is_var_arg is True, the caller uses varargs. This is used for
        overload resolution.
        """
        if not is_valid_argc(len(arg_types), False, callee):
            return False
        
        if is_var_arg:
            if not self.is_valid_var_arg(arg_types[-1]):
                return False
            arg_types, rest = expand_caller_var_args(arg_types,
                                                     callee.max_fixed_args())

        # Fixed function arguments.
        func_fixed = callee.max_fixed_args()
        for i in range(min(len(arg_types), func_fixed)):
            if not is_subtype(self.erase(arg_types[i]),
                              self.erase(
                                  callee.arg_types[i])):
                return False
        # Function varargs.
        if callee.is_var_arg:
            for i in range(func_fixed, len(arg_types)):
                if not is_subtype(self.erase(arg_types[i]),
                                  self.erase(callee.arg_types[func_fixed])):
                    return False
        return True
    
    def match_signature_types(self, arg_types: List[Type], is_var_arg: bool,
                              callee: Callable) -> bool:
        """Determine whether arguments types match the signature.

        If is_var_arg is True, the caller uses varargs. Assume that argument
        counts are compatible.
        """
        if is_var_arg:
            arg_types, rest = expand_caller_var_args(arg_types,
                                                     callee.max_fixed_args())

        # Fixed function arguments.
        func_fixed = callee.max_fixed_args()
        for i in range(min(len(arg_types), func_fixed)):
            if not is_subtype(arg_types[i], callee.arg_types[i]):
                return False
        # Function varargs.
        if callee.is_var_arg:
            for i in range(func_fixed, len(arg_types)):
                if not is_subtype(arg_types[i],
                                  callee.arg_types[func_fixed]):
                    return False
        return True
    
    def apply_generic_arguments(self, callable: Callable, types: List[Type],
                                context: Context) -> Type:
        """Apply generic type arguments to a callable type.

        For example, applying [int] to 'def [T] (T) -> T' results in
        'def [-1:int] (int) -> int'. Here '[-1:int]' is an implicit bound type
        variable.
        
        Note that each type can be None; in this case, it will not be applied.
        """
        tvars = callable.variables
        if len(tvars) != len(types):
            self.msg.incompatible_type_application(len(tvars), len(types),
                                                   context)
            return AnyType()
        
        # Check that inferred type variable values are compatible with allowed
        # values.  Also, promote subtype values to allowed values.
        types = types[:]
        for i, type in enumerate(types):
            values = callable.variables[i].values
            if values and type:
                if isinstance(type, AnyType):
                    continue
                for value in values:
                    if is_subtype(type, value):
                        types[i] = value
                        break
                else:
                    self.msg.incompatible_typevar_value(
                        callable, i + 1, type, context)

        # Create a map from type variable id to target type.
        id_to_type = {} # type: Dict[int, Type]
        for i, tv in enumerate(tvars):
            if types[i]:
                id_to_type[tv.id] = types[i]

        # Apply arguments to argument types.
        arg_types = [expand_type(at, id_to_type) for at in callable.arg_types]
        
        bound_vars = [(tv.id, id_to_type[tv.id])
                      for tv in tvars
                      if tv.id in id_to_type]

        # The callable may retain some type vars if only some were applied.
        remaining_tvars = [tv for tv in tvars if tv.id not in id_to_type]
        
        return Callable(arg_types,
                        callable.arg_kinds,
                        callable.arg_names,
                        expand_type(callable.ret_type, id_to_type),
                        callable.is_type_obj(),
                        callable.name,
                        remaining_tvars,
                        callable.bound_vars + bound_vars,
                        callable.line, callable.repr)
    
    def apply_generic_arguments2(self, overload: Overloaded, types: List[Type],
                                context: Context) -> Type:
        items = [] # type: List[Callable]
        for item in overload.items():
            applied = self.apply_generic_arguments(item, types, context)
            if isinstance(applied, Callable):
                items.append(applied)
            else:
                # There was an error.
                return AnyType()
        return Overloaded(items)
    
    def visit_member_expr(self, e: MemberExpr) -> Type:
        """Visit member expression (of form e.id)."""
        return self.analyse_ordinary_member_access(e, False)
    
    def analyse_ordinary_member_access(self, e: MemberExpr,
                                       is_lvalue: bool) -> Type:
        """Analyse member expression or member lvalue."""
        if e.kind is not None:
            # This is a reference to a module attribute.
            return self.analyse_ref_expr(e)
        else:
            # This is a reference to a non-module attribute.
            return analyse_member_access(e.name, self.accept(e.expr), e,
                                         is_lvalue, False,
                                         self.chk.basic_types(), self.msg)
    
    def analyse_external_member_access(self, member: str, base_type: Type,
                                       context: Context) -> Type:
        """Analyse member access that is external, i.e. it cannot
        refer to private definitions. Return the result type.
        """
        # TODO remove; no private definitions in mypy
        return analyse_member_access(member, base_type, context, False, False,
                                     self.chk.basic_types(), self.msg)
    
    def visit_int_expr(self, e: IntExpr) -> Type:
        """Type check an integer literal (trivial)."""
        return self.named_type('builtins.int')
    
    def visit_str_expr(self, e: StrExpr) -> Type:
        """Type check a string literal (trivial)."""
        return self.named_type('builtins.str')
    
    def visit_bytes_expr(self, e: BytesExpr) -> Type:
        """Type check a bytes literal (trivial)."""
        return self.named_type('builtins.bytes')
    
    def visit_unicode_expr(self, e: UnicodeExpr) -> Type:
        """Type check a unicode literal (trivial)."""
        return self.named_type('builtins.unicode')
    
    def visit_float_expr(self, e: FloatExpr) -> Type:
        """Type check a float literal (trivial)."""
        return self.named_type('builtins.float')
    
    def visit_op_expr(self, e: OpExpr) -> Type:
        """Type check a binary operator expression."""
        if e.op == 'and' or e.op == 'or':
            return self.check_boolean_op(e, e)
        if e.op == '*' and isinstance(e.left, ListExpr):
            # Expressions of form [...] * e get special type inference.
            return self.check_list_multiply(e)
        left_type = self.accept(e.left)
        right_type = self.accept(e.right) # TODO only evaluate if needed
        if e.op == 'in' or e.op == 'not in':
            result, method_type = self.check_op('__contains__', right_type,
                                                e.left, e)
            e.method_type = method_type
            if e.op == 'in':
                return result
            else:
                return self.chk.bool_type()
        elif e.op in nodes.op_methods:
            method = self.get_operator_method(e.op)
            result, method_type = self.check_op(method, left_type, e.right, e,
                                                allow_reverse=True)
            e.method_type = method_type
            return result
        elif e.op == 'is' or e.op == 'is not':
            return self.chk.bool_type()
        else:
            raise RuntimeError('Unknown operator {}'.format(e.op))

    def get_operator_method(self, op: str) -> str:
        if op == '/' and self.chk.pyversion == 2:
            # TODO also check for "from __future__ import division"
            return '__div__'
        else:
            return nodes.op_methods[op]
    
    def check_op(self, method: str, base_type: Type, arg: Node,
                 context: Context,
                 allow_reverse: bool = False) -> Tuple[Type, Type]:
        """Type check a binary operation which maps to a method call.

        Return tuple (result type, inferred operator method type).
        """
        # Use a local error storage for errors related to invalid argument
        # type (but NOT other errors). This error may need to be suppressed
        # for operators which support __rX methods.
        local_errors = self.msg.copy()
        if not allow_reverse or self.has_member(base_type, method):
            method_type = self.analyse_external_member_access(
                method, base_type, context)
            result = self.check_call(method_type, [arg], [nodes.ARG_POS],
                                     context, arg_messages=local_errors)
            if allow_reverse:
                arg_type = self.chk.type_map[arg]
                if isinstance(arg_type, AnyType):
                    # If the right operand has type Any, we can't make any
                    # conjectures about the type of the result, since the
                    # operand could have a __r method that returns anything.
                    result = AnyType(), result[1]
            success = not local_errors.is_errors()
        else:
            result = AnyType(), AnyType()
            success = False
        if success or not allow_reverse or isinstance(base_type, AnyType):
            # We were able to call the normal variant of the operator method,
            # or there was some problem not related to argument type
            # validity, or the operator has no __rX method. In any case, we
            # don't need to consider the __rX method.
            self.msg.add_errors(local_errors)
            return result
        else:
            # Calling the operator method was unsuccessful. Try the __rX
            # method of the other operand instead.
            rmethod = self.get_reverse_op_method(method)
            arg_type = self.accept(arg)
            if self.has_member(arg_type, rmethod):
                method_type = self.analyse_external_member_access(
                    rmethod, arg_type, context)
                temp = TempNode(base_type)
                return self.check_call(method_type, [temp], [nodes.ARG_POS],
                                       context)
            else:
                # No __rX method either. Do deferred type checking to produce
                # error message that we may have missed previously.
                # TODO Fix type checking an expression more than once.
                method_type = self.analyse_external_member_access(
                    method, base_type, context)
                return self.check_call(method_type, [arg], [nodes.ARG_POS],
                                       context)

    def get_reverse_op_method(self, method: str) -> str:
        if method == '__div__' and self.chk.pyversion == 2:
            return '__rdiv__'
        else:
            return nodes.reverse_op_methods[method]
    
    def check_boolean_op(self, e: OpExpr, context: Context) -> Type:
        """Type check a boolean operation ('and' or 'or')."""

        # A boolean operation can evaluate to either of the operands.
        
        # We use the current type context to guide the type inference of of
        # the left operand. We also use the left operand type to guide the type
        # inference of the right operand so that expressions such as
        # '[1] or []' are inferred correctly.
        ctx = self.chk.type_context[-1]
        left_type = self.accept(e.left, ctx)
        right_type = self.accept(e.right, left_type)
        
        self.check_not_void(left_type, context)
        self.check_not_void(right_type, context)

        return join.join_types(left_type, right_type,
                               self.chk.basic_types())

    def check_list_multiply(self, e: OpExpr) -> Type:
        """Type check an expression of form '[...] * e'.

        Type inference is special-cased for this common construct.
        """
        right_type = self.accept(e.right)
        if is_subtype(right_type, self.chk.named_type('builtins.int')):
            # Special case: [...] * <int value>. Use the type context of the
            # OpExpr, since the multiplication does not affect the type.
            left_type = self.accept(e.left, context=self.chk.type_context[-1])
        else:
            left_type = self.accept(e.left)
        result, method_type = self.check_op('__mul__', left_type, e.right, e)
        e.method_type = method_type
        return result
    
    def visit_unary_expr(self, e: UnaryExpr) -> Type:
        """Type check an unary operation ('not', '-' or '~')."""
        operand_type = self.accept(e.expr)
        op = e.op
        if op == 'not':
            self.check_not_void(operand_type, e)
            result = self.chk.bool_type() # type: Type
        elif op == '-':
            method_type = self.analyse_external_member_access('__neg__',
                                                              operand_type, e)
            result, method_type = self.check_call(method_type, [], [], e)
            e.method_type = method_type
        elif op == '~':
            method_type = self.analyse_external_member_access('__invert__',
                                                              operand_type, e)
            result, method_type = self.check_call(method_type, [], [], e)
            e.method_type = method_type
        return result
    
    def visit_index_expr(self, e: IndexExpr) -> Type:
        """Type check an index expression (base[index]).

        It may also represent type application.
        """
        if e.analyzed:
            # It's actually a type application.
            return self.accept(e.analyzed)
        left_type = self.accept(e.base)
        if isinstance(left_type, TupleType):
            # Special case for tuples. They support indexing only by integer
            # literals.
            index = self.unwrap(e.index)
            ok = False
            if isinstance(index, IntExpr):
                n = index.value
                ok = True
            elif isinstance(index, UnaryExpr):
                if index.op == '-':
                    operand = index.expr
                    if isinstance(operand, IntExpr):
                        n = len(left_type.items) - operand.value
                        ok = True
            if ok:
                if n >= 0 and n < len(left_type.items):
                    return left_type.items[n]
                else:
                    self.chk.fail(messages.TUPLE_INDEX_OUT_OF_RANGE, e)
                    return AnyType()
            else:
                self.chk.fail(messages.TUPLE_INDEX_MUST_BE_AN_INT_LITERAL, e)
                return AnyType()
        else:
            result, method_type = self.check_op('__getitem__', left_type,
                                                e.index, e)
            e.method_type = method_type
            return result

    def visit_cast_expr(self, expr: CastExpr) -> Type:
        """Type check a cast expression."""
        source_type = self.accept(expr.expr)
        target_type = expr.type
        if not self.is_valid_cast(source_type, target_type):
            self.msg.invalid_cast(target_type, source_type, expr)
        return target_type
    
    def is_valid_cast(self, source_type: Type, target_type: Type) -> bool:
        """Is a cast from source_type to target_type meaningful?"""
        return (isinstance(target_type, AnyType) or
                (not isinstance(source_type, Void) and
                 not isinstance(target_type, Void)))
    
    def visit_type_application(self, tapp: TypeApplication) -> Type:
        """Type check a type application (expr[type, ...])."""
        expr_type = self.accept(tapp.expr)
        if isinstance(expr_type, Callable):
            new_type = self.apply_generic_arguments(expr_type,
                                                    tapp.types, tapp)
        elif isinstance(expr_type, Overloaded):
            overload = expr_type
            # Only target items with the right number of generic type args.
            items = [c for c in overload.items()
                     if len(c.variables) == len(tapp.types)]
            new_type = self.apply_generic_arguments2(Overloaded(items),
                                                     tapp.types, tapp)
        else:
            self.chk.fail(messages.INVALID_TYPE_APPLICATION_TARGET_TYPE, tapp)
            new_type = AnyType()
        self.chk.type_map[tapp.expr] = new_type
        return new_type
    
    def visit_list_expr(self, e: ListExpr) -> Type:
        """Type check a list expression [...]."""
        return self.check_list_or_set_expr(e.items, 'builtins.list', '<list>',
                                           e)

    def visit_set_expr(self, e: SetExpr) -> Type:
        return self.check_list_or_set_expr(e.items, 'builtins.set', '<set>', e)

    def check_list_or_set_expr(self, items: List[Node], fullname: str,
                               tag: str, context: Context) -> Type:
        # Translate into type checking a generic function call.
        tv = TypeVar('T', -1, [])
        constructor = Callable([tv],
                               [nodes.ARG_STAR],
                               [None],
                               self.chk.named_generic_type(fullname,
                                                           [tv]),
                               False,
                               tag,
                               [TypeVarDef('T', -1, None)])
        return self.check_call(constructor,
                               items,
                               [nodes.ARG_POS] * len(items), context)[0]
    
    def visit_tuple_expr(self, e: TupleExpr) -> Type:    
        """Type check a tuple expression."""
        ctx = None # type: TupleType
        # Try to determine type context for type inference.
        if isinstance(self.chk.type_context[-1], TupleType):
            t = cast(TupleType, self.chk.type_context[-1])
            if len(t.items) == len(e.items):
                ctx = t
        # Infer item types.
        items = [] # type: List[Type]
        for i in range(len(e.items)):
            item = e.items[i]
            tt = Undefined # type: Type
            if not ctx:
                tt = self.accept(item)
            else:
                tt = self.accept(item, ctx.items[i])
            self.check_not_void(tt, e)
            items.append(tt)
        return TupleType(items)
    
    def visit_dict_expr(self, e: DictExpr) -> Type:
        # Translate into type checking a generic function call.
        tv1 = TypeVar('KT', -1, [])
        tv2 = TypeVar('VT', -2, [])
        constructor = Undefined(Callable)
        # The callable type represents a function like this:
        #
        #   def <unnamed>(*v: Tuple[kt, vt]) -> Dict[kt, vt]: ...
        constructor = Callable([TupleType([tv1, tv2])],
                               [nodes.ARG_STAR],
                               [None],
                               self.chk.named_generic_type('builtins.dict',
                                                           [tv1, tv2]),
                               False,
                               '<list>',
                               [TypeVarDef('KT', -1, None),
                                TypeVarDef('VT', -2, None)])
        # Synthesize function arguments.
        args = List[Node]()
        for key, value in e.items:
            args.append(TupleExpr([key, value]))
        return self.check_call(constructor,
                               args,
                               [nodes.ARG_POS] * len(args), e)[0]
    
    def visit_func_expr(self, e: FuncExpr) -> Type:
        """Type check lambda expression."""
        inferred_type = self.infer_lambda_type_using_context(e)
        if not inferred_type:
            # No useful type context.
            ret_type = e.expr().accept(self.chk)
            if not e.args:
                # Form 'lambda: e'; just use the inferred return type.
                return Callable([], [], [], ret_type, is_type_obj=False)
            else:
                # TODO: Consider reporting an error. However, this is fine if
                # we are just doing the first pass in contextual type
                # inference.
                return AnyType()
        else:
            # Type context available.
            self.chk.check_func_item(e, type_override=inferred_type)
            ret_type = self.chk.type_map[e.expr()]
            return replace_callable_return_type(inferred_type, ret_type)

    def infer_lambda_type_using_context(self, e: FuncExpr) -> Callable:
        """Try to infer lambda expression type using context.

        Return None if could not infer type.
        """
        # TODO also accept 'Any' context
        ctx = self.chk.type_context[-1]
        if not ctx or not isinstance(ctx, Callable):
            return None
        
        # The context may have function type variables in it. We replace them
        # since these are the type variables we are ultimately trying to infer;
        # they must be considered as indeterminate. We use ErasedType since it
        # does not affect type inference results (it is for purposes like this
        # only).
        ctx = replace_func_type_vars(ctx, ErasedType())
        
        callable_ctx = cast(Callable, ctx)
        
        if callable_ctx.arg_kinds != e.arg_kinds:
            # Incompatible context; cannot use it to infer types.
            self.chk.fail(messages.CANNOT_INFER_LAMBDA_TYPE, e)
            return None
        
        return callable_ctx
    
    def visit_super_expr(self, e: SuperExpr) -> Type:
        """Type check a super expression (non-lvalue)."""
        t = self.analyse_super(e, False)
        return t
    
    def analyse_super(self, e: SuperExpr, is_lvalue: bool) -> Type:
        """Type check a super expression."""
        if e.info and e.info.bases:
            # TODO fix multiple inheritance etc
            return analyse_member_access(e.name, self_type(e.info), e,
                                         is_lvalue, True,
                                         self.chk.basic_types(), self.msg,
                                         e.info.mro[1])
        else:
            # Invalid super. This has been reported by the semantic analyser.
            return AnyType()
    
    def visit_paren_expr(self, e: ParenExpr) -> Type:
        """Type check a parenthesised expression."""
        return self.accept(e.expr, self.chk.type_context[-1])
    
    def visit_slice_expr(self, e: SliceExpr) -> Type:
        for index in [e.begin_index, e.end_index, e.stride]:
            if index:
                t = self.accept(index)
                self.chk.check_subtype(t, self.named_type('builtins.int'),
                                       index, messages.INVALID_SLICE_INDEX)
        return self.named_type('builtins.slice')

    def visit_list_comprehension(self, e: ListComprehension) -> Type:
        return self.check_generator_or_comprehension(
            e.generator, 'builtins.list', '<list-comprehension>')

    def visit_generator_expr(self, e: GeneratorExpr) -> Type:
        return self.check_generator_or_comprehension(e, 'typing.Iterator',
                                                     '<generator>')
    
    def check_generator_or_comprehension(self, gen: GeneratorExpr,
                                         type_name: str,
                                         id_for_messages: str) -> Type:
        """Type check a generator expression or a list comprehension."""
        
        item_type = self.chk.analyse_iterable_item_type(gen.right_expr)
        self.chk.analyse_index_variables(gen.index, False, item_type, gen)

        if gen.condition:
            self.accept(gen.condition)
        
        # Infer the type of the list comprehension by using a synthetic generic
        # callable type.
        tv = TypeVar('T', -1, [])
        constructor = Callable([tv],
                               [nodes.ARG_POS],
                               [None],
                               self.chk.named_generic_type(type_name, [tv]),
                               False,
                               id_for_messages,
                               [TypeVarDef('T', -1, None)])
        return self.check_call(constructor,
                               [gen.left_expr], [nodes.ARG_POS], gen)[0]

    def visit_undefined_expr(self, e: UndefinedExpr) -> Type:
        return e.type

    def visit_conditional_expr(self, e: ConditionalExpr) -> Type:
        cond_type = self.accept(e.cond)
        self.check_not_void(cond_type, e)
        if_type = self.accept(e.if_expr)
        else_type = self.accept(e.else_expr, context=if_type)
        return join.join_types(if_type, else_type, self.chk.basic_types())
    
    #
    # Helpers
    #
    
    def accept(self, node: Node, context: Type = None) -> Type:
        """Type check a node. Alias for TypeChecker.accept."""
        return self.chk.accept(node, context)
    
    def check_not_void(self, typ: Type, context: Context) -> None:
        """Generate an error if type is Void."""
        self.chk.check_not_void(typ, context)
    
    def is_boolean(self, typ: Type) -> bool:
        """Is type compatible with bool?"""
        return is_subtype(typ, self.chk.bool_type())
    
    def named_type(self, name: str) -> Instance:
        """Return an instance type with type given by the name and no type
        arguments. Alias for TypeChecker.named_type.
        """
        return self.chk.named_type(name)
    
    def is_valid_var_arg(self, typ: Type) -> bool:
        """Is a type valid as a *args argument?"""
        return (isinstance(typ, TupleType) or
                is_subtype(typ, self.chk.named_generic_type('typing.Iterable',
                                                            [AnyType()])) or
                isinstance(typ, AnyType))
    
    def is_valid_keyword_var_arg(self, typ: Type) -> bool:    
        """Is a type valid as a **kwargs argument?"""
        return is_subtype(typ, self.chk.named_generic_type(
            'builtins.dict', [self.named_type('builtins.str'), AnyType()]))
    
    def has_non_method(self, typ: Type, member: str) -> bool:
        """Does type have a member variable / property with the given name?"""
        if isinstance(typ, Instance):
            return (not typ.type.has_method(member) and
                    typ.type.has_readable_member(member))
        else:
            return False
    
    def has_member(self, typ: Type, member: str) -> bool:
        """Does type have member with the given name?"""
        # TODO TupleType => also consider tuple attributes
        if isinstance(typ, Instance):
            return typ.type.has_readable_member(member)
        elif isinstance(typ, AnyType):
            return True
        else:
            return False
    
    def unwrap(self, e: Node) -> Node:
        """Unwrap parentheses from an expression node."""
        if isinstance(e, ParenExpr):
            return self.unwrap(e.expr)
        else:
            return e
    
    def unwrap_list(self, a: List[Node]) -> List[Node]:
        """Unwrap parentheses from a list of expression nodes."""
        r = List[Node]()
        for n in a:
            r.append(self.unwrap(n))
        return r

    def erase(self, type: Type) -> Type:
        """Replace type variable types in type with Any."""
        return erasetype.erase_type(type, self.chk.basic_types())


def is_valid_argc(nargs: int, is_var_arg: bool, callable: Callable) -> bool:
    """Return a boolean indicating whether a call expression has a
    (potentially) compatible number of arguments for calling a function.
    Varargs at caller are not checked.
    """
    if is_var_arg:
        if callable.is_var_arg:
            return True
        else:
            return nargs - 1 <= callable.max_fixed_args()
    elif callable.is_var_arg:
        return nargs >= callable.min_args
    else:
        # Neither has varargs.
        return nargs <= len(callable.arg_types) and nargs >= callable.min_args


def map_actuals_to_formals(caller_kinds: List[int],
                           caller_names: List[str],
                           callee_kinds: List[int],
                           callee_names: List[str],
                           caller_arg_type: Function[[int],
                                                     Type]) -> List[List[int]]:
    """Calculate mapping between actual (caller) args and formals.

    The result contains a list of caller argument indexes mapping to each
    callee argument index, indexed by callee index.

    The caller_arg_type argument should evaluate to the type of the actual
    argument type with the given index.
    """
    ncallee = len(callee_kinds)
    map = [None] * ncallee # type: List[List[int]]
    for i in range(ncallee):
        map[i] = []
    j = 0
    for i, kind in enumerate(caller_kinds):
        if kind == nodes.ARG_POS:
            if j < ncallee:
                if callee_kinds[j] in [nodes.ARG_POS, nodes.ARG_OPT,
                                       nodes.ARG_NAMED]:
                    map[j].append(i)
                    j += 1
                elif callee_kinds[j] == nodes.ARG_STAR:
                    map[j].append(i)
        elif kind == nodes.ARG_STAR:
            # We need to to know the actual type to map varargs.
            argt = caller_arg_type(i)
            if isinstance(argt, TupleType):
                # A tuple actual maps to a fixed number of formals.
                for k in range(len(argt.items)):
                    if j < ncallee:
                        if callee_kinds[j] != nodes.ARG_STAR2:
                            map[j].append(i)
                        else:
                            raise NotImplementedError()
                        j += 1
            else:
                # Assume that it is an iterable (if it isn't, there will be
                # an error later).
                while j < ncallee:
                    if callee_kinds[j] in (nodes.ARG_NAMED, nodes.ARG_STAR2):
                        break
                    else:
                        map[j].append(i)
                    j += 1
        elif kind == nodes.ARG_NAMED:
            name = caller_names[i]
            if name in callee_names:
                map[callee_names.index(name)].append(i)
            elif nodes.ARG_STAR2 in callee_kinds:
                map[callee_kinds.index(nodes.ARG_STAR2)].append(i)
        else:
            assert kind == nodes.ARG_STAR2
            for j in range(ncallee):
                # TODO tuple varargs complicate this
                no_certain_match = (
                    not map[j] or caller_kinds[map[j][0]] == nodes.ARG_STAR)
                if ((callee_names[j] and no_certain_match)
                        or callee_kinds[j] == nodes.ARG_STAR2):
                    map[j].append(i)
    return map


def is_empty_tuple(t: Type) -> bool:
    return isinstance(t, TupleType) and not cast(TupleType, t).items


def is_duplicate_mapping(mapping: List[int], actual_kinds: List[int]) -> bool:
    # Multiple actuals can map to the same formal only if they both come from
    # varargs (*args and **kwargs); in this case at runtime it is possible that
    # there are no duplicates. We need to allow this, as the convention
    # f(..., *args, **kwargs) is common enough.
    return len(mapping) > 1 and not (
        len(mapping) == 2 and
        actual_kinds[mapping[0]] == nodes.ARG_STAR and
        actual_kinds[mapping[1]] == nodes.ARG_STAR2)


def replace_callable_return_type(c: Callable, new_ret_type: Type) -> Callable:
    """Return a copy of a callable type with a different return type."""
    return Callable(c.arg_types,
                    c.arg_kinds,
                    c.arg_names,
                    new_ret_type,
                    c.is_type_obj(),
                    c.name,
                    c.variables,
                    c.bound_vars,
                    c.line)


class ArgInferSecondPassQuery(types.TypeQuery):
    """Query whether an argument type should be inferred in the second pass.

    The result is True if the type has a type variable in a callable return
    type anywhere. For example, the result for Function[[], T] is True if t is
    a type variable.
    """    
    def __init__(self) -> None:
        super().__init__(False, types.ANY_TYPE_STRATEGY)

    def visit_callable(self, t: Callable) -> bool:
        return self.query_types(t.arg_types) or t.accept(HasTypeVarQuery())


class HasTypeVarQuery(types.TypeQuery):
    """Visitor for querying whether a type has a type variable component."""
    def __init__(self) -> None:
        super().__init__(False, types.ANY_TYPE_STRATEGY)

    def visit_type_var(self, t: TypeVar) -> bool:
        return True


def has_erased_component(t: Type) -> bool:
    return t is not None and t.accept(HasErasedComponentsQuery())


class HasErasedComponentsQuery(types.TypeQuery):
    """Visitor for querying whether a type has an erased component."""
    def __init__(self) -> None:
        super().__init__(False, types.ANY_TYPE_STRATEGY)

    def visit_erased_type(self, t: ErasedType) -> bool:
        return True

########NEW FILE########
__FILENAME__ = checkmember
"""Type checking of attribute access"""

from typing import cast, Function, List

from mypy.types import (
    Type, Instance, AnyType, TupleType, Callable, FunctionLike, TypeVarDef,
    Overloaded, TypeVar, TypeTranslator, BasicTypes
)
from mypy.nodes import TypeInfo, FuncBase, Var, FuncDef, SymbolNode, Context
from mypy.nodes import ARG_POS, function_type, Decorator
from mypy.messages import MessageBuilder
from mypy.subtypes import map_instance_to_supertype
from mypy.expandtype import expand_type_by_instance
from mypy.nodes import method_type
from mypy.semanal import self_type
from mypy import messages
from mypy import subtypes


def analyse_member_access(name: str, typ: Type, node: Context, is_lvalue: bool,
                          is_super: bool, basic_types: BasicTypes,
                          msg: MessageBuilder, override_info: TypeInfo = None,
                          report_type: Type = None) -> Type:
    """Analyse attribute access.

    This is a general operation that supports various different variations:
    
      1. lvalue or non-lvalue access (i.e. setter or getter access)
      2. supertype access (when using super(); is_super == True and
         override_info should refer to the supertype)
    """
    report_type = report_type or typ
    if isinstance(typ, Instance):
        if name == '__init__' and not is_super:
            # Accessing __init__ in statically typed code would compromise
            # type safety unless used via super().
            msg.fail(messages.CANNOT_ACCESS_INIT, node)
            return AnyType()
        
        # The base object has an instance type.
        
        info = typ.type
        if override_info:
            info = override_info
        
        # Look up the member. First look up the method dictionary.
        method = info.get_method(name)
        if method:
            if is_lvalue:
                msg.fail(messages.CANNOT_ASSIGN_TO_METHOD, node)
            typ = map_instance_to_supertype(typ, method.info)
            return expand_type_by_instance(method_type(method), typ)
        else:
            # Not a method.
            return analyse_member_var_access(name, typ, info, node,
                                             is_lvalue, is_super, msg,
                                             report_type=report_type)
    elif isinstance(typ, AnyType):
        # The base object has dynamic type.
        return AnyType()
    elif isinstance(typ, TupleType):
        # Actually look up from the 'tuple' type.
        return analyse_member_access(name, basic_types.tuple, node, is_lvalue,
                                     is_super, basic_types, msg)
    elif (isinstance(typ, FunctionLike) and
              cast(FunctionLike, typ).is_type_obj()):
        # Class attribute.
        # TODO super?
        sig = cast(FunctionLike, typ)
        itype = cast(Instance, sig.items()[0].ret_type)
        result = analyse_class_attribute_access(itype, name, node, is_lvalue,
                                                msg)
        if result:
            return result
        # Look up from the 'type' type.
        return analyse_member_access(name, basic_types.type_type, node,
                                     is_lvalue, is_super, basic_types, msg,
                                     report_type=report_type)
    elif isinstance(typ, FunctionLike):
        # Look up from the 'function' type.
        return analyse_member_access(name, basic_types.function, node,
                                     is_lvalue, is_super, basic_types, msg,
                                     report_type=report_type)
    return msg.has_no_attr(report_type, name, node)


def analyse_member_var_access(name: str, itype: Instance, info: TypeInfo,
                              node: Context, is_lvalue: bool, is_super: bool,
                              msg: MessageBuilder,
                              report_type: Type = None) -> Type:
    """Analyse attribute access that does not target a method.

    This is logically part of analyse_member_access and the arguments are
    similar.
    """
    # It was not a method. Try looking up a variable.
    v = lookup_member_var_or_accessor(info, name, is_lvalue)

    vv = v
    if isinstance(vv, Decorator):
        # The associated Var node of a decorator contains the type.
        v = vv.var
    
    if isinstance(v, Var):
        # Found a member variable.
        var = v
        itype = map_instance_to_supertype(itype, var.info)
        if var.type:
            t = expand_type_by_instance(var.type, itype)
            if (var.is_initialized_in_class and isinstance(t, FunctionLike)
                    and not var.is_staticmethod):
                # Class-level function object becomes a bound method.
                functype = cast(FunctionLike, t)
                check_method_type(functype, itype, node, msg)
                signature = method_type(functype)
                if var.is_property:
                    if is_lvalue:
                        msg.read_only_property(name, info, node)
                    # A property cannot have an overloaded type => the cast
                    # is fine.
                    return cast(Callable, signature).ret_type
                else:
                    return signature
            return t
        else:
            if not var.is_ready:
                msg.cannot_determine_type(var.name(), node)
            # Implicit 'Any' type.
            return AnyType()
    elif isinstance(v, FuncDef):
        assert False, "Did not expect a function"
    
    # Could not find the member.
    if is_super:
        msg.undefined_in_superclass(name, node)
        return AnyType()
    else:
        return msg.has_no_attr(report_type or itype, name, node)


def lookup_member_var_or_accessor(info: TypeInfo, name: str,
                                  is_lvalue: bool) -> SymbolNode:
    """Find the attribute/accessor node that refers to a member of a type."""
    # TODO handle lvalues
    node = info.get(name)
    if node:
        return node.node
    else:
        return None


def check_method_type(functype: FunctionLike, itype: Instance,
                      context: Context, msg: MessageBuilder) -> None:
    for item in functype.items():
        if not item.arg_types or item.arg_kinds[0] != ARG_POS:
            # No positional first (self) argument.
            msg.invalid_method_type(item, context)
        else:
            # Check that self argument has type 'Any' or valid instance type.
            selfarg = item.arg_types[0]
            if not subtypes.is_equivalent(selfarg, itype):
                msg.invalid_method_type(item, context)


def analyse_class_attribute_access(itype: Instance, name: str,
                                   context: Context, is_lvalue: bool,
                                   msg: MessageBuilder) -> Type:
    node = itype.type.get(name)
    if node:
        if is_lvalue and isinstance(node.node, FuncDef):
            msg.fail(messages.CANNOT_ASSIGN_TO_METHOD, context)
        if is_lvalue and isinstance(node.node, TypeInfo):
            msg.fail(messages.CANNOT_ASSIGN_TO_TYPE, context)
        t = node.type
        if t:
            return add_class_tvars(t, itype.type)
        elif isinstance(node.node, TypeInfo):
            # TODO add second argument
            return type_object_type(cast(TypeInfo, node.node), None)
        else:
            return function_type(cast(FuncBase, node.node))
    else:
        return None


def add_class_tvars(t: Type, info: TypeInfo) -> Type:
    if isinstance(t, Callable):
        vars = [TypeVarDef(n, i + 1, None)
                for i, n in enumerate(info.type_vars)]
        return Callable(t.arg_types,
                        t.arg_kinds,
                        t.arg_names,
                        t.ret_type,
                        t.is_type_obj(),
                        t.name,
                        vars + t.variables,
                        t.bound_vars,
                        t.line, None)
    elif isinstance(t, Overloaded):
        return Overloaded([cast(Callable, add_class_tvars(i, info))
                           for i in t.items()])
    return t


def type_object_type(info: TypeInfo, type_type: Function[[], Type]) -> Type:
    """Return the type of a type object.

    For a generic type G with type variables T and S the type is of form

      def [T, S](...) -> G[T, S],

    where ... are argument types for the __init__ method.
    """
    init_method = info.get_method('__init__')
    if not init_method:
        # Must be an invalid class definition.
        return AnyType()
    else:
        # Construct callable type based on signature of __init__. Adjust
        # return type and insert type arguments.
        init_type = method_type(init_method)
        if isinstance(init_type, Callable):
            return class_callable(init_type, info)
        else:
            # Overloaded __init__.
            items = [] # type: List[Callable]
            for it in cast(Overloaded, init_type).items():
                items.append(class_callable(it, info))
            return Overloaded(items)
    

def class_callable(init_type: Callable, info: TypeInfo) -> Callable:
    """Create a type object type based on the signature of __init__."""
    variables = [] # type: List[TypeVarDef]
    for i, tvar in enumerate(info.defn.type_vars):
        variables.append(TypeVarDef(tvar.name, i + 1, tvar.values))

    initvars = init_type.variables
    variables.extend(initvars)

    c = Callable(init_type.arg_types,
                 init_type.arg_kinds,
                 init_type.arg_names,
                 self_type(info),
                 True,
                 None,
                 variables).with_name('"{}"'.format(info.name()))
    return convert_class_tvars_to_func_tvars(c, len(initvars))


def convert_class_tvars_to_func_tvars(callable: Callable,
                                      num_func_tvars: int) -> Callable:
    return cast(Callable, callable.accept(TvarTranslator(num_func_tvars)))


class TvarTranslator(TypeTranslator):
    def __init__(self, num_func_tvars: int) -> None:
        super().__init__()
        self.num_func_tvars = num_func_tvars
    
    def visit_type_var(self, t: TypeVar) -> Type:
        if t.id < 0:
            return t
        else:
            return TypeVar(t.name, -t.id - self.num_func_tvars, t.values)
    
    def translate_variables(self,
                            variables: List[TypeVarDef]) -> List[TypeVarDef]:
        if not variables:
            return variables
        items = [] # type: List[TypeVarDef]
        for v in variables:
            if v.id > 0:
                items.append(TypeVarDef(v.name, -v.id - self.num_func_tvars,
                                        v.values))
            else:
                items.append(v)
        return items

########NEW FILE########
__FILENAME__ = coerce
from typing import cast

from mypy.nodes import Node, TypeInfo, CoerceExpr, JavaCast
from mypy.types import (
    Type, Instance, Void, NoneTyp, AnyType
)
from mypy.sametypes import is_same_type
from mypy.subtypes import is_proper_subtype
from mypy.rttypevars import translate_runtime_type_vars_in_context


def coerce(expr: Node, target_type: Type, source_type: Type, context: TypeInfo,
           is_wrapper_class: bool = False, is_java: bool = False) -> Node:
    """Build an expression that coerces expr from source_type to target_type.

    Return bare expr if the coercion is trivial (always a no-op).
    """
    if is_trivial_coercion(target_type, source_type, is_java):
        res = expr
    else:
        # Translate type variables to expressions that fetch the value of a
        # runtime type variable.
        target = translate_runtime_type_vars_in_context(target_type, context,
                                                        is_java)
        source = translate_runtime_type_vars_in_context(source_type, context,
                                                        is_java)
        res = CoerceExpr(expr, target, source, is_wrapper_class)
    
    if is_java and ((isinstance(source_type, Instance) and
                     (cast(Instance, source_type)).erased)
                    or (isinstance(res, CoerceExpr) and
                        isinstance(target_type, Instance))):
        res = JavaCast(res, target_type)
    
    return res                  


def is_trivial_coercion(target_type: Type, source_type: Type,
                        is_java: bool) -> bool:
    """Is an implicit coercion from source_type to target_type a no-op?

    Note that we omit coercions of form any <= C, unless C is a primitive that
    may have a special representation.
    """
    # FIX: Replace type vars in source type with any?
    if isinstance(source_type, Void) or is_same_type(target_type, source_type):
        return True
    
    # Coercions from a primitive type to any other type are non-trivial, since
    # we may have to change the representation.
    if not is_java and is_special_primitive(source_type):
        return False
    
    return (is_proper_subtype(source_type, target_type)
            or isinstance(source_type, NoneTyp)
            or isinstance(target_type, AnyType))


def is_special_primitive(type: Type) -> bool:
    """Is type a primitive with a special runtime representation?

    There needs to be explicit corcions to/from special primitive types. For
    example, floats need to boxed/unboxed. The special primitive types include
    int, float and bool.
    """
    return (isinstance(type, Instance)
            and (cast(Instance, type)).type.fullname() in ['builtins.int',
                                                     'builtins.float',
                                                     'builtins.bool'])

########NEW FILE########
__FILENAME__ = compilemapd
from typing import Undefined, List, Tuple, cast

from nodes import TypeInfo
from types import Instance, Type, TypeVar, AnyType


class MapPremise: pass


class MapExpr: pass


class AssertClass(MapPremise):
    i = Undefined(MapExpr)
    c = Undefined(TypeInfo)
    
    def __init__(self, i: MapExpr, c: TypeInfo) -> None:
        self.i = i
        self.c = c
    
    def __str__(self):
        return str(self.i) + ' = ' + self.c.name + '[...]'


class AssertDyn(MapPremise):
    i = Undefined(MapExpr)
    
    def __init__(self, i: MapExpr) -> None:
        self.i = i
    
    def __str__(self):
        return str(self.i) + ' = Any'


class AssertEq(MapPremise):
    i1 = Undefined(MapExpr)
    i2 = Undefined(MapExpr)
    
    def __init__(self, i1: MapExpr, i2: MapExpr) -> None:
        self.i1 = i1
        self.i2 = i2
    
    def __str__(self):
        return str(self.i1) + ' = ' + str(self.i2)


class TypeVarRef(MapExpr):
    n = 0
    
    def __init__(self, n: int) -> None:
        self.n = n
    
    def __str__(self):
        return str(self.n)


class TypeArgRef(MapExpr):
    base = Undefined(MapExpr)
    n = 0
    
    def __init__(self, base: MapExpr, n: int) -> None:
        self.base = base
        self.n = n
    
    def __str__(self):
        return str(self.base) + '.' + str(self.n)


class DefaultArg(MapExpr):
    def __str__(self):
        return 'd'


def compile_subclass_mapping(num_subtype_type_vars: int,
                             super_type: Instance) -> Tuple[List[MapPremise],
                                                            List[MapExpr]]:
    """Compile mapping from superclass to subclass type variables.

    Args:
      num_subtype_type_vars: number of type variables in subclass
      super_type:         definition of supertype; this may contain type
                          variable references
    """
    
    # TODO describe what's going on
    
    premises = find_eq_premises(super_type, None)
    exprs = [] # type: List[MapExpr]
    
    for i in range(1, num_subtype_type_vars + 1):
        paths = find_all_paths(i, super_type, None)
        if len(paths) == 0:
            exprs.append(DefaultArg())
        else:
            exprs.append(paths[0])
            if len(paths) > 1:
                # Multiple paths; make sure they are all the same.
                for j in range(1, len(paths)):
                    premises.append(AssertEq(paths[0], paths[j]))
    
    return premises, exprs  


def find_all_paths(tv: int, typ: Type, expr: MapExpr) -> List[MapExpr]:
    if isinstance(typ, TypeVar) and (cast(TypeVar, typ)).id == tv:
        return [expr]
    elif isinstance(typ, Instance) and (cast(Instance, typ)).args != []:
        inst = cast(Instance, typ)
        res = [] # type: List[MapExpr]
        for i in range(len(inst.args)):
            e = Undefined # type: MapExpr
            if not expr:
                e = TypeVarRef(i + 1)
            else:
                e = TypeArgRef(expr, i + 1)
            res += find_all_paths(tv, inst.args[i], e)
        return res
    else:
        return []


def find_eq_premises(typ: Type, expr: MapExpr) -> List[MapPremise]:
    if isinstance(typ, Instance):
        inst = cast(Instance, typ)
        res = [] # type: List[MapPremise]
        if expr:
            res.append(AssertClass(expr, inst.type))
        for i in range(len(inst.args)):
            e = Undefined # type: MapExpr
            if not expr:
                e = TypeVarRef(i + 1)
            else:
                e = TypeArgRef(expr, i + 1)
            res += find_eq_premises(inst.args[i], e)
        return res
    elif isinstance(typ, AnyType):
        return [AssertDyn(expr)]
    else:
        return []

########NEW FILE########
__FILENAME__ = compileslotmap
from typing import List, Tuple

from mypy.types import Type
from mypy.nodes import TypeInfo
from mypy.semanal import self_type
from mypy.subtypes import map_instance_to_supertype
from mypy.maptypevar import num_slots, get_tvar_access_path


def compile_slot_mapping(typ: TypeInfo) -> List[Type]:
    """Return types that represent values of type variable slots of a type.

    The returned types are in terms of type variables of the type.
    
    For example, assume these definitions:
    
      class D(Generic[S]): ...
      class C(D[E[S]], Generic[T, S]): ...
    
    Now slot mappings for C is [E[S], T] (S and T refer to type variables of
    C).
    """
    exprs = [] # type: List[Type]
    
    for slot in range(num_slots(typ)):
        # Figure out the superclass which defines the slot; also figure out
        # the tvar index that maps to the slot.
        origin, tv = find_slot_origin(typ, slot)
        
        # Map self type to the superclass -> extract tvar with target index
        # (only contains subclass tvars?? PROBABLY NOT).
        selftype = self_type(typ)
        selftype = map_instance_to_supertype(selftype, origin)
        tvar = selftype.args[tv - 1]
        
        # tvar is the representation of the slot in terms of type arguments.
        exprs.append(tvar)
    
    return exprs


def find_slot_origin(info: TypeInfo, slot: int) -> Tuple[TypeInfo, int]:
    """Determine class and type variable index that directly maps to the slot.

    The result defines which class in inheritance hierarchy of info introduced
    the slot. All subclasses inherit this slot. The result TypeInfo always
    refers to one of the base classes of info (or info itself).

    Examples:
      - In 'class C(Generic[T]): ...', the slot 0 in C is mapped to
        type var 1 (T) in C.
      - In 'class D(C[U], Generic[S, U]): ...', the slot 0 in D is mapped
        to type var 1 (T) in C; the slot 1 of D is mapped to type variable 1
        of D.
    """
    base = info.bases[0].type
    super_slots = num_slots(base)
    if slot < super_slots:
        # A superclass introduced the slot.
        return find_slot_origin(base, slot)
    else:
        # This class introduced the slot. Figure out which type variable maps
        # to the slot.
        for tv in range(1, len(info.type_vars) + 1):
            if get_tvar_access_path(info, tv)[0] - 1 == slot:
                return (info, tv)
        
        raise RuntimeError('Could not map slot')

########NEW FILE########
__FILENAME__ = constraints
"""Type inference constraints."""

from typing import List, cast, Undefined

from mypy.types import (
    Callable, Type, TypeVisitor, UnboundType, AnyType, Void, NoneTyp, TypeVar,
    Instance, TupleType, Overloaded, ErasedType
)
from mypy.expandtype import expand_caller_var_args
from mypy.subtypes import map_instance_to_supertype
from mypy import nodes


SUBTYPE_OF = 0
SUPERTYPE_OF = 1


class Constraint:
    """A representation of a type constraint.

    It can be either T <: type or T :> type (T is a type variable).
    """
    
    type_var = 0   # Type variable id
    op = 0         # SUBTYPE_OF or SUPERTYPE_OF
    
    target = Undefined(Type)
    
    def __repr__(self) -> str:
        op_str = '<:'
        if self.op == SUPERTYPE_OF:
            op_str = ':>'
        return '{} {} {}'.format(self.type_var, op_str, self.target)
    
    def __init__(self, type_var: int, op: int, target: Type) -> None:
        self.type_var = type_var
        self.op = op
        self.target = target


def infer_constraints_for_callable(
                 callee: Callable, arg_types: List[Type], arg_kinds: List[int],
                 formal_to_actual: List[List[int]]) -> List[Constraint]:
    """Infer type variable constraints for a callable and actual arguments.
    
    Return a list of constraints.
    """
    
    constraints = [] # type: List[Constraint]
    tuple_counter = [0]
    
    for i, actuals in enumerate(formal_to_actual):
        for actual in actuals:
            actual_type = get_actual_type(arg_types[actual], arg_kinds[actual],
                                          tuple_counter)
            c = infer_constraints(callee.arg_types[i], actual_type,
                                  SUPERTYPE_OF)
            constraints.extend(c)

    return constraints


def get_actual_type(arg_type: Type, kind: int,
                    tuple_counter: List[int]) -> Type:
    """Return the type of an actual argument with the given kind.

    If the argument is a *arg, return the individual argument item.
    """
    
    if kind == nodes.ARG_STAR:
        if isinstance(arg_type, Instance):
            if arg_type.type.fullname() == 'builtins.list':
                # List *arg.
                return arg_type.args[0]
            elif arg_type.args:
                # TODO try to map type arguments to Iterable
                return arg_type.args[0]
            else:
                return AnyType()
        elif isinstance(arg_type, TupleType):
            # Get the next tuple item of a tuple *arg.
            tuplet = cast(TupleType, arg_type)
            tuple_counter[0] += 1
            return tuplet.items[tuple_counter[0] - 1]
        else:
            return AnyType()
    elif kind == nodes.ARG_STAR2:
        if isinstance(arg_type, Instance) and (
                (cast(Instance, arg_type)).type.fullname() == 'builtins.dict'):
            # Dict **arg. TODO more general (Mapping)
            return (cast(Instance, arg_type)).args[1]
        else:
            return AnyType()
    else:
        # No translation for other kinds.
        return arg_type


def infer_constraints(template: Type, actual: Type,
                      direction: int) -> List[Constraint]:
    """Infer type constraints.

    Match a template type, which may contain type variable references,
    recursively against a type which does not contain (the same) type
    variable references. The result is a list of type constrains of
    form 'T is a supertype/subtype of x', where T is a type variable
    present in the the template and x is a type without reference to
    type variables present in the template.
    
    Assume T and S are type variables. Now the following results can be
    calculated (read as '(template, actual) --> result'):
    
      (T, X)            -->  T :> X
      (X[T], X[Y])      -->  T <: Y and T :> Y
      ((T, T), (X, Y))  -->  T :> X and T :> Y
      ((T, S), (X, Y))  -->  T :> X and S :> Y
      (X[T], Any)       -->  T <: Any and T :> Any
    
    The constraints are represented as Constraint objects.
    """
    
    return template.accept(ConstraintBuilderVisitor(actual, direction))


class ConstraintBuilderVisitor(TypeVisitor[List[Constraint]]):
    """Visitor class for inferring type constraints."""

    # The type that is compared against a template
    actual = Undefined(Type)
    
    def __init__(self, actual: Type, direction: int) -> None:
        # Direction must be SUBTYPE_OF or SUPERTYPE_OF.
        self.actual = actual
        self.direction = direction
    
    # Trivial leaf types
    
    def visit_unbound_type(self, template: UnboundType) -> List[Constraint]:
        return []
    
    def visit_any(self, template: AnyType) -> List[Constraint]:
        return []
    
    def visit_void(self, template: Void) -> List[Constraint]:
        return []
    
    def visit_none_type(self, template: NoneTyp) -> List[Constraint]:
        return []

    def visit_erased_type(self, template: ErasedType) -> List[Constraint]:
        return []
    
    # Non-trivial leaf type
    
    def visit_type_var(self, template: TypeVar) -> List[Constraint]:
        return [Constraint(template.id, SUPERTYPE_OF, self.actual)]
    
    # Non-leaf types
    
    def visit_instance(self, template: Instance) -> List[Constraint]:
        actual = self.actual
        if isinstance(actual, Instance):
            res = [] # type: List[Constraint]
            instance = cast(Instance, actual)
            if (self.direction == SUBTYPE_OF and
                    template.type.has_base(instance.type.fullname())):
                mapped = map_instance_to_supertype(template, instance.type)
                for i in range(len(instance.args)):
                    # The constraints for generic type parameters are
                    # invariant. Include the default constraint and its
                    # negation to achieve the effect.
                    cb = infer_constraints(mapped.args[i], instance.args[i],
                                           self.direction)
                    res.extend(cb)
                    res.extend(negate_constraints(cb))
                return res
            elif (self.direction == SUPERTYPE_OF and
                    instance.type.has_base(template.type.fullname())):
                mapped = map_instance_to_supertype(instance, template.type)
                for j in range(len(template.args)):
                    # The constraints for generic type parameters are
                    # invariant.
                    cb = infer_constraints(template.args[j], mapped.args[j],
                                           self.direction)
                    res.extend(cb)
                    res.extend(negate_constraints(cb))
                return res
        if isinstance(actual, AnyType):
            # IDEA: Include both ways, i.e. add negation as well?
            return self.infer_against_any(template.args)
        else:
            return []
    
    def visit_callable(self, template: Callable) -> List[Constraint]:
        if isinstance(self.actual, Callable):
            cactual = cast(Callable, self.actual)
            # FIX verify argument counts
            # FIX what if one of the functions is generic
            res = [] # type: List[Constraint]
            for i in range(len(template.arg_types)):
                # Negate constraints due function argument type contravariance.
                res.extend(negate_constraints(infer_constraints(
                    template.arg_types[i], cactual.arg_types[i],
                    self.direction)))
            res.extend(infer_constraints(template.ret_type, cactual.ret_type,
                                         self.direction))
            return res
        elif isinstance(self.actual, AnyType):
            # FIX what if generic
            res = self.infer_against_any(template.arg_types)
            res.extend(infer_constraints(template.ret_type, AnyType(),
                                         self.direction))
            return res
        elif isinstance(self.actual, Overloaded):
            return self.infer_against_overloaded(cast(Overloaded, self.actual),
                                                 template)
        else:
            return []

    def infer_against_overloaded(self, overloaded: Overloaded,
                                 template: Callable) -> List[Constraint]:
        # Create constraints by matching an overloaded type against a template.
        # This is tricky to do in general. We cheat by only matching against
        # the first overload item, and by only matching the return type. This
        # seems to work somewhat well, but we should really use a more
        # reliable technique.
        item = overloaded.items()[0]
        return infer_constraints(template.ret_type, item.ret_type,
                                 self.direction)
    
    def visit_tuple_type(self, template: TupleType) -> List[Constraint]:
        actual = self.actual
        if (isinstance(actual, TupleType) and
                len((cast(TupleType, actual)).items) == len(template.items)):
            res = [] # type: List[Constraint]
            for i in range(len(template.items)):
                res.extend(infer_constraints(template.items[i],
                                             cast(TupleType, actual).items[i],
                                             self.direction))
            return res
        elif isinstance(actual, AnyType):
            return self.infer_against_any(template.items)
        else:
            return []
    
    def infer_against_any(self, types: List[Type]) -> List[Constraint]:
        res = [] # type: List[Constraint]
        for t in types:
            res.extend(infer_constraints(t, AnyType(), self.direction))
        return res


def negate_constraints(constraints: List[Constraint]) -> List[Constraint]:
    res = [] # type: List[Constraint]
    for c in constraints:
        res.append(Constraint(c.type_var, neg_op(c.op), c.target))
    return res


def neg_op(op: int) -> int:
    """Map SubtypeOf to SupertypeOf and vice versa."""
    
    if op == SUBTYPE_OF:
        return SUPERTYPE_OF
    elif op == SUPERTYPE_OF:
        return SUBTYPE_OF
    else:
        raise ValueError('Invalid operator {}'.format(op))

########NEW FILE########
__FILENAME__ = erasetype
import typing

from mypy.types import (
    Type, TypeVisitor, UnboundType, ErrorType, AnyType, Void, NoneTyp,
    Instance, TypeVar, Callable, TupleType, Overloaded, ErasedType,
    TypeTranslator, BasicTypes, TypeList
)


def erase_type(typ: Type, basic: BasicTypes) -> Type:
    """Erase any type variables from a type.

    Also replace tuple types with the corresponding concrete types. Replace
    callable types with empty callable types.
    
    Examples:
      A -> A
      B[X] -> B[Any]
      Tuple[A, B] -> tuple
      Function[...] -> Function[[], None]
    """
    
    return typ.accept(EraseTypeVisitor(basic))


class EraseTypeVisitor(TypeVisitor[Type]):
    def __init__(self, basic: BasicTypes) -> None:
        self.basic = basic
    
    def visit_unbound_type(self, t: UnboundType) -> Type:
        assert False, 'Not supported'
    
    def visit_error_type(self, t: ErrorType) -> Type:
        return t
    
    def visit_type_list(self, t: TypeList) -> Type:
        assert False, 'Not supported'
    
    def visit_any(self, t: AnyType) -> Type:
        return t
    
    def visit_void(self, t: Void) -> Type:
        return t
    
    def visit_none_type(self, t: NoneTyp) -> Type:
        return t
    
    def visit_erased_type(self, t: ErasedType) -> Type:
        # Should not get here.
        raise RuntimeError()
    
    def visit_instance(self, t: Instance) -> Type:
        return Instance(t.type, [AnyType()] * len(t.args), t.line,
                        t.repr)
    
    def visit_type_var(self, t: TypeVar) -> Type:
        return AnyType()
    
    def visit_callable(self, t: Callable) -> Type:
        # We must preserve the type object flag for overload resolution to
        # work.
        return Callable([], [], [], Void(), t.is_type_obj())

    def visit_overloaded(self, t: Overloaded) -> Type:
        return t.items()[0].accept(self)
    
    def visit_tuple_type(self, t: TupleType) -> Type:
        return self.basic.tuple


def erase_generic_types(t: Type) -> Type:
    """Remove generic type arguments and type variables from a type.

    Replace all types A[...] with simply A, and all type variables
    with 'Any'.
    """
    
    if t:
        return t.accept(GenericTypeEraser())
    else:
        return None


class GenericTypeEraser(TypeTranslator):
    """Implementation of type erasure"""
    
    # FIX: What about generic function types?
    
    def visit_type_var(self, t: TypeVar) -> Type:
        return AnyType()
    
    def visit_instance(self, t: Instance) -> Type:
        return Instance(t.type, [], t.line)


def erase_typevars(t: Type) -> Type:
    """Replace all type variables in a type with any."""    
    return t.accept(TypeVarEraser())


class TypeVarEraser(TypeTranslator):
    """Implementation of type erasure"""
    
    def visit_type_var(self, t: TypeVar) -> Type:
        return AnyType()

########NEW FILE########
__FILENAME__ = errors
import os
import os.path

from typing import Undefined, Tuple, List, typevar, Sequence, Any, Function


T = typevar('T')


class ErrorInfo:
    """Representation of a single error message."""
    
    # Description of a sequence of imports that refer to the source file
    # related to this error. Each item is a (path, line number) tuple.
    import_ctx = Undefined(List[Tuple[str, int]])
    
    # The source file that was the source of this error.
    file = ''
    
    # The name of the type in which this error is located at.
    type = ''     # Unqualified, may be None
    
    # The name of the function or member in which this error is located at.
    function_or_member = ''     # Unqualified, may be None
    
    # The line number related to this error within file.
    line = 0     # -1 if unknown
    
    # The error message.
    message = ''

    # If True, we should halt build after the file that generated this error.
    blocker = True
    
    def __init__(self, import_ctx: List[Tuple[str, int]], file: str, typ: str,
                 function_or_member: str, line: int, message: str, blocker: bool) -> None:
        self.import_ctx = import_ctx
        self.file = file
        self.type = typ
        self.function_or_member = function_or_member
        self.line = line
        self.message = message
        self.blocker = blocker


class Errors:
    """Container for compile errors.

    This class generates and keeps tracks of compile errors and the
    current error context (nested imports).
    """
    
    # List of generated error messages.
    error_info = Undefined(List[ErrorInfo])
    
    # Current error context.
    # Import context, as a list of (path, line) pairs.
    import_ctx = Undefined(List[Tuple[str, int]])
    
    # Path name prefix that is removed from all paths, if set.
    ignore_prefix = None # type: str

    # Path to current file.
    file = None # type: str
    
    # Stack of short names of currents types (or None).
    type_name = Undefined(List[str])
    
    # Stack of short names of current functions or members (or None).
    function_or_member = Undefined(List[str])
    
    def __init__(self) -> None:
        self.error_info = []
        self.import_ctx = []
        self.type_name = [None]
        self.function_or_member = [None]

    def copy(self) -> 'Errors':
        new = Errors()
        new.file = self.file
        new.import_ctx = self.import_ctx[:]
        new.type_name = self.type_name[:]
        new.function_or_member = self.function_or_member[:]
        return new
    
    def set_ignore_prefix(self, prefix: str) -> None:
        """Set path prefix that will be removed from all paths."""
        prefix = os.path.normpath(prefix)
        # Add separator to the end, if not given.
        if os.path.basename(prefix) != '':
            prefix += os.sep
        self.ignore_prefix = prefix
    
    def set_file(self, file: str) -> None:
        """Set the path of the current file."""
        file = os.path.normpath(file)
        self.file = remove_path_prefix(file, self.ignore_prefix)
    
    def push_function(self, name: str) -> None:
        """Set the current function or member short name (it can be None)."""
        self.function_or_member.append(name)

    def pop_function(self) -> None:
        self.function_or_member.pop()
    
    def push_type(self, name: str) -> None:
        """Set the short name of the current type (it can be None)."""
        self.type_name.append(name)

    def pop_type(self) -> None:
        self.type_name.pop()
    
    def push_import_context(self, path: str, line: int) -> None:
        """Add a (file, line) tuple to the import context."""
        self.import_ctx.append((os.path.normpath(path), line))
    
    def pop_import_context(self) -> None:
        """Remove the topmost item from the import context."""
        self.import_ctx.pop()
    
    def import_context(self) -> List[Tuple[str, int]]:
        """Return a copy of the import context."""
        return self.import_ctx[:]
    
    def set_import_context(self, ctx: List[Tuple[str, int]]) -> None:
        """Replace the entire import context with a new value."""
        self.import_ctx = ctx[:]
    
    def report(self, line: int, message: str, blocker: bool = True) -> None:
        """Report message at the given line using the current error context."""
        type = self.type_name[-1]
        if len(self.function_or_member) > 2:
            type = None # Omit type context if nested function
        info = ErrorInfo(self.import_context(), self.file, type,
                         self.function_or_member[-1], line, message,
                         blocker)
        self.error_info.append(info)
    
    def num_messages(self) -> int:
        """Return the number of generated messages."""
        return len(self.error_info)
    
    def is_errors(self) -> bool:
        """Are there any generated errors?"""
        return bool(self.error_info)

    def is_blockers(self) -> bool:
        """Are the any errors that are blockers?"""
        return any(err for err in self.error_info if err.blocker)
    
    def raise_error(self) -> None:
        """Raise a CompileError with the generated messages.

        Render the messages suitable for displaying.
        """
        raise CompileError(self.messages())
    
    def messages(self) -> List[str]:
        """Return a string list that represents the error messages.

        Use a form suitable for displaying to the user.
        """
        a = [] # type: List[str]
        errors = self.render_messages(self.sort_messages(self.error_info))
        errors = self.remove_duplicates(errors)
        for file, line, message in errors:
            s = ''
            if file is not None:
                if line is not None and line >= 0:
                    s = '{}, line {}: {}'.format(file, line, message)
                else:
                    s = '{}: {}'.format(file, message)
            else:
                s = message
            a.append(s)
        return a
    
    def render_messages(self, errors: List[ErrorInfo]) -> List[Tuple[str, int,
                                                                     str]]:
        """Translate the messages into a sequence of tuples.

        Each tuple is of form (path, line, message.  The rendered
        sequence includes information about error contexts. The path
        item may be None. If the line item is negative, the line
        number is not defined for the tuple.
        """
        result = [] # type: List[Tuple[str, int, str]] # (path, line, message)
        
        prev_import_context = [] # type: List[Tuple[str, int]]
        prev_function_or_member = None # type: str
        prev_type = None # type: str
        
        for e in errors:
            # Report module import context, if different from previous message.
            if e.import_ctx != prev_import_context:
                last = len(e.import_ctx) - 1
                i = last
                while i >= 0:
                    path, line = e.import_ctx[i]
                    fmt = 'In module imported in {}, line {}'
                    if i < last:
                        fmt = '                   in {}, line {}'
                    if i > 0:
                        fmt += ','
                    else:
                        fmt += ':'
                    # Remove prefix to ignore from path (if present) to
                    # simplify path.
                    path = remove_path_prefix(path, self.ignore_prefix)
                    result.append((None, -1, fmt.format(path, line)))
                    i -= 1
            
            # Report context within a source file.
            if (e.function_or_member != prev_function_or_member or
                    e.type != prev_type):
                if e.function_or_member is None:
                    if e.type is None:
                        result.append((e.file, -1, 'At top level:'))
                    else:
                        result.append((e.file, -1, 'In class "{}":'.format(
                            e.type)))
                else:
                    if e.type is None:
                        result.append((e.file, -1,
                                       'In function "{}":'.format(
                                           e.function_or_member)))
                    else:
                        result.append((e.file, -1,
                                       'In member "{}" of class "{}":'.format(
                                           e.function_or_member, e.type)))
            elif e.type != prev_type:
                if e.type is None:
                    result.append((e.file, -1, 'At top level:'))
                else:
                    result.append((e.file, -1,
                                   'In class "{}":'.format(e.type)))
            
            result.append((e.file, e.line, e.message))
            
            prev_import_context = e.import_ctx
            prev_function_or_member = e.function_or_member
            prev_type = e.type
        
        return result
    
    def sort_messages(self, errors: List[ErrorInfo]) -> List[ErrorInfo]:
        """Sort an array of error messages locally by line number.
        
        I.e., sort a run of consecutive messages with the same file
        context by line number, but otherwise retain the general
        ordering of the messages.
        """
        result = [] # type: List[ErrorInfo]
        i = 0
        while i < len(errors):
            i0 = i
            # Find neighbouring errors with the same context and file.
            while (i + 1 < len(errors) and
                       errors[i + 1].import_ctx == errors[i].import_ctx and
                       errors[i + 1].file == errors[i].file):
                i += 1
            i += 1
            
            # Sort the errors specific to a file according to line number.
            a = stable_sort(errors[i0:i], lambda x: x.line)
            result.extend(a)
        return result
    
    def remove_duplicates(self, errors: List[Tuple[str, int, str]]
                          ) -> List[Tuple[str, int, str]]:
        """Remove duplicates from a sorted error list."""
        res = [] # type: List[Tuple[str, int, str]]
        i = 0
        while i < len(errors):
            dup = False
            j = i - 1
            while (j >= 0 and errors[j][0] == errors[i][0] and
                       errors[j][1] == errors[i][1]):
                if errors[j] == errors[i]:
                    dup = True
                    break
                j -= 1
            if not dup:
                res.append(errors[i])
            i += 1
        return res


class CompileError(Exception):
    """Exception raised when there is a compile error.

    It can be a parse, semantic analysis, type check or other
    compilation-related error.
    """
    
    messages = Undefined(List[str])
    
    def __init__(self, messages: List[str]) -> None:
        super().__init__()
        self.messages = messages


def stable_sort(a: Sequence[T], key: Function[[T], Any]) -> List[T]:
    """Perform a stable sort of a sequence.

    If the original sequence has a[n] == a[n+m] (when comparing using
    the comparison function f), in the sorted sequence item a[n] will
    be at an earlier index than a[n + m].
    """
    # TODO use sorted with key (need support for keyword arguments)
    l = List[Tuple[Any, int, T]]()
    for i, x in enumerate(a):
        l.append((key(x), i, x))
    result = List[T]()
    for k, j, y in sorted(l):
        result.append(y)        
    return result


def remove_path_prefix(path: str, prefix: str) -> str:
    """If path starts with prefix, return copy of path with the prefix removed.
    Otherwise, return path. If path is None, return None.
    """
    if prefix is not None and path.startswith(prefix):
        return path[len(prefix):]
    else:
        return path

########NEW FILE########
__FILENAME__ = expandtype
from typing import Dict, Tuple, List, cast, Undefined

from mypy.types import (
    Type, Instance, Callable, TypeVisitor, UnboundType, ErrorType, AnyType,
    Void, NoneTyp, TypeVar, Overloaded, TupleType, ErasedType, TypeList
)


def expand_type(typ: Type, map: Dict[int, Type]) -> Type:
    """Substitute any type variable references in a type with given values."""
    
    return typ.accept(ExpandTypeVisitor(map))


def expand_type_by_instance(typ: Type, instance: Instance) -> Type:
    """Substitute type variables in type using values from an Instance."""
    
    if instance.args == []:
        return typ
    else:
        variables = {} # type: Dict[int, Type]
        for i in range(len(instance.args)):
            variables[i + 1] = instance.args[i]
        typ = expand_type(typ, variables)
        if isinstance(typ, Callable):
            bounds = [] # type: List[Tuple[int, Type]]
            for j in range(len(instance.args)):
                bounds.append((j + 1, instance.args[j]))
            typ = update_callable_implicit_bounds(cast(Callable, typ), bounds)
        else:
            pass
        return typ


class ExpandTypeVisitor(TypeVisitor[Type]):
    """Visitor that substitutes type variables with values."""
    
    variables = Undefined(Dict[int, Type]) # typevar id -> value
    
    def __init__(self, variables: Dict[int, Type]) -> None:
        self.variables = variables
    
    def visit_unbound_type(self, t: UnboundType) -> Type:
        return t
    
    def visit_error_type(self, t: ErrorType) -> Type:
        return t
    
    def visit_type_list(self, t: TypeList) -> Type:
        assert False, 'Not supported'
    
    def visit_any(self, t: AnyType) -> Type:
        return t
    
    def visit_void(self, t: Void) -> Type:
        return t
    
    def visit_none_type(self, t: NoneTyp) -> Type:
        return t
    
    def visit_erased_type(self, t: ErasedType) -> Type:
        # Should not get here.
        raise RuntimeError()
    
    def visit_instance(self, t: Instance) -> Type:
        args = self.expand_types(t.args)
        return Instance(t.type, args, t.line, t.repr)
    
    def visit_type_var(self, t: TypeVar) -> Type:
        repl = self.variables.get(t.id, t)
        if isinstance(repl, Instance):
            inst = cast(Instance, repl)
            # Return copy of instance with type erasure flag on.
            return Instance(inst.type, inst.args, inst.line, inst.repr, True)
        else:
            return repl
    
    def visit_callable(self, t: Callable) -> Type:
        return Callable(self.expand_types(t.arg_types),
                        t.arg_kinds,
                        t.arg_names,
                        t.ret_type.accept(self),
                        t.is_type_obj(),
                        t.name,
                        t.variables,
                        self.expand_bound_vars(t.bound_vars), t.line, t.repr)
    
    def visit_overloaded(self, t: Overloaded) -> Type:
        items = [] # type: List[Callable]
        for item in t.items():
            items.append(cast(Callable, item.accept(self)))
        return Overloaded(items)
    
    def visit_tuple_type(self, t: TupleType) -> Type:
        return TupleType(self.expand_types(t.items), t.line, t.repr)
    
    def expand_types(self, types: List[Type]) -> List[Type]:
        a = [] # type: List[Type]
        for t in types:
            a.append(t.accept(self))
        return a
    
    def expand_bound_vars(
            self, types: List[Tuple[int, Type]]) -> List[Tuple[int, Type]]:
        a = [] # type: List[Tuple[int, Type]]
        for id, t in types:
            a.append((id, t.accept(self)))
        return a


def update_callable_implicit_bounds(
        t: Callable, arg_types: List[Tuple[int, Type]]) -> Callable:
    # FIX what if there are existing bounds?
    return Callable(t.arg_types,
                    t.arg_kinds,
                    t.arg_names,
                    t.ret_type,
                    t.is_type_obj(),
                    t.name,
                    t.variables,
                    arg_types, t.line, t.repr)


def expand_caller_var_args(arg_types: List[Type],
                           fixed_argc: int) -> Tuple[List[Type], Type]:
    """Expand the caller argument types in a varargs call.

    Fixedargc is the maximum number of fixed arguments that the target
    function accepts.
    
    Return (fixed argument types, type of the rest of the arguments). Return
    (None, None) if the last (vararg) argument had an invalid type. If the
    vararg argument was not an array (nor dynamic), the last item in the
    returned tuple is None.
    """
    
    if isinstance(arg_types[-1], TupleType):
        return arg_types[:-1] + (cast(TupleType, arg_types[-1])).items, None
    else:
        item_type = Undefined # type: Type
        if isinstance(arg_types[-1], AnyType):
            item_type = AnyType()
        elif isinstance(arg_types[-1], Instance) and (
                cast(Instance, arg_types[-1]).type.fullname() ==
                    'builtins.list'):
            # List.
            item_type = (cast(Instance, arg_types[-1])).args[0]
        else:
            return None, None
        
        if len(arg_types) > fixed_argc:
            return arg_types[:-1], item_type
        else:
            return (arg_types[:-1] +
                    [item_type] * (fixed_argc - len(arg_types) + 1), item_type)

########NEW FILE########
__FILENAME__ = icode
"""icode: Register-based intermediate representation of mypy programs."""

from typing import List, Undefined, Dict, Tuple, cast, overload

from mypy.types import AnyType, Instance, Type, Callable, FunctionLike
from mypy.nodes import (
    FuncDef, IntExpr, MypyFile, ReturnStmt, NameExpr, WhileStmt,
    AssignmentStmt, Node, Var, OpExpr, Block, CallExpr, IfStmt, ParenExpr,
    UnaryExpr, ExpressionStmt, CoerceExpr, ClassDef, MemberExpr, TypeInfo,
    VarDef, SuperExpr, IndexExpr, UndefinedExpr
)
from mypy import nodes
from mypy.visitor import NodeVisitor
from mypy.subtypes import is_named_instance


# Operand kinds
REG_KIND = 0 # Register
INT_KIND = 1 # Integer literal


class FuncIcode:
    """Icode and related information for a function."""

    def __init__(self, num_args: int, blocks: 'List[BasicBlock]',
                  register_types: List[int]) -> None:
        self.num_args = num_args
        self.blocks = blocks
        self.num_registers = len(register_types)
        self.register_types = register_types


class BasicBlock:
    """An icode basic block.

    Only the last instruction exits the block. Exceptions are not considered
    as exits.
    """
    def __init__(self, label: int) -> None:
        self.ops = List[Opcode]()
        self.label = label


class Opcode:
    """Abstract base class for all icode opcodes."""
    def is_exit(self) -> bool:
        """Does this opcode exit the block?"""
        return False


class SetRR(Opcode):
    """Assign register to register (rN = rN)."""
    def __init__(self, target: int, source: int) -> None:
        self.target = target
        self.source = source

    def __str__(self) -> str:
        return 'r%d = r%d' % (self.target, self.source)


class SetRI(Opcode):
    """Assign integer literal to register (rN = N)."""
    def __init__(self, target: int, intval: int) -> None:
        self.target = target
        self.intval = intval

    def __str__(self) -> str:
        return 'r%d = %d' % (self.target, self.intval)


class SetRNone(Opcode):
    """Assign None to register (rN = None)."""
    def __init__(self, target: int) -> None:
        self.target = target

    def __str__(self) -> str:
        return 'r%d = None' % self.target


class SetGR(Opcode):
    """Assign register to global (g = rN)."""
    def __init__(self, target: str, source: int) -> None:
        self.target = target
        self.source = source

    def __str__(self) -> str:
        return '%s = r%d' % (self.target, self.source)


class SetRG(Opcode):
    """Assign global to register (rN = g)."""
    def __init__(self, target: int, source: str) -> None:
        self.target = target
        self.source = source

    def __str__(self) -> str:
        return 'r%d = %s' % (self.target, self.source)


class GetAttr(Opcode):
    """Look up an attribute directly (rN = rN.x [C])."""
    def __init__(self, target: int, object: int, attr: str,
                 type: TypeInfo) -> None:
        self.target = target
        self.object = object
        self.attr = attr
        self.type = type

    def __str__(self) -> str:
        return 'r%d = r%d.%s [%s]' % (self.target, self.object, self.attr,
                                      self.type.name())


class SetAttr(Opcode):
    """Assign to an attribute directly (rN.x = rN [C])."""
    def __init__(self, object: int, attr: str, source: int,
                 type: TypeInfo) -> None:
        self.object = object
        self.attr = attr
        self.source = source
        self.type = type

    def __str__(self) -> str:
        return 'r%d.%s = r%d [%s]' % (self.object, self.attr, self.source,
                                      self.type.name())


class CallDirect(Opcode):
    """Call directly a global function (rN = g(rN, ...))."""
    def __init__(self, target: int, func: str, args: List[int]) -> None:
        self.target = target
        self.func = func
        self.args = args

    def __str__(self) -> str:
        args = ', '.join(['r%d' % arg for arg in self.args])
        return 'r%d = %s(%s)' % (self.target, self.func, args)


class CallMethod(Opcode):
    """Call a method (rN = rN.m(rN, ...) [C]).

    Attributes:
      target: lvalue for the result (register)
      object: receiver (register)
      method: method name
      type: vtable to use
      args: arguments (registers)
      static: resolve method statically (be default, at runtime)
    """
    def __init__(self, target: int, object: int, method: str, type: TypeInfo,
                 args: List[int], static: bool = False) -> None:
        self.target = target
        self.object = object
        self.method = method
        self.type = type
        self.args = args
        self.static = static

    def __str__(self) -> str:
        args = ', '.join(['r%d' % arg for arg in self.args])
        cls = self.type.name()
        if self.static:
            cls = 'static ' + cls
        return 'r%d = r%d.%s(%s) [%s]' % (self.target, self.object,
                                          self.method, args, cls)


class Construct(Opcode):
    """Construct an uninitialized class instance (rN = <construct C>)."""
    def __init__(self, target: int, type: TypeInfo) -> None:
        self.target = target
        self.type = type

    def __str__(self) -> str:
        return 'r%d = <construct %s>' % (self.target, self.type.name())


class Return(Opcode):
    """Return from function (return rN)."""
    def __init__(self, retval: int) -> None:
        self.retval = retval
        
    def is_exit(self) -> bool:
        return True

    def __str__(self) -> str:
        return 'return r%d' % self.retval


class Branch(Opcode):
    """Abstract base class for branch opcode."""  
    true_block = Undefined # type: BasicBlock
    false_block = Undefined # type: BasicBlock
        
    def is_exit(self) -> bool:
        return True

    def invert(self) -> None:
        pass


class IfOp(Branch):
    inversion = {'==': '!=', '!=': '==',
                 '<': '>=', '<=': '>', '>': '<=', '>=': '<'}
    
    """Conditional operator branch (e.g. if r0 < r1 goto L2 else goto L3)."""
    def __init__(self,
                 left: int, left_kind: int,
                 right: int, right_kind: int,
                 op: str, true_block: BasicBlock,
                 false_block: BasicBlock) -> None:
        self.left = left
        self.left_kind = left_kind
        self.right = right
        self.right_kind = right_kind
        self.op = op
        self.true_block = true_block
        self.false_block = false_block

    def invert(self) -> None:
        self.true_block, self.false_block = self.false_block, self.true_block
        self.op = self.inversion[self.op]

    def __str__(self) -> str:
        return 'if %s %s %s goto L%d else goto L%d' % (
            operand(self.left, self.left_kind), self.op,
            operand(self.right, self.right_kind),
            self.true_block.label, self.false_block.label)


class IfR(Branch):
    """Conditional value branch (if rN goto LN else goto LN). """
    negated = False
    
    def __init__(self, value: int,
                 true_block: BasicBlock, false_block: BasicBlock) -> None:
        self.value = value
        self.true_block = true_block
        self.false_block = false_block
        self.negated = False

    def invert(self) -> None:
        # This is tricky; not sure if this works all the time.
        # This was implemented by trial and error and testing indicates that
        # it *seems* to work.
        self.negated = not self.negated
        self.true_block, self.false_block = self.false_block, self.true_block

    def __str__(self) -> str:
        prefix = ''
        if self.negated:
            prefix = 'not '
        return 'if %sr%d goto L%d else goto L%d' % (
            prefix, self.value, self.true_block.label, self.false_block.label)


class Goto(Opcode):
    """Unconditional jump (goto LN)."""
    def __init__(self, next_block: BasicBlock) -> None:
        self.next_block = next_block
        
    def is_exit(self) -> bool:
        return True

    def __str__(self) -> str:
        return 'goto L%d' % self.next_block.label


class BinOp(Opcode):
    """Primitive binary operation (e.g. r0 = r1 + r2 [int])."""
    def __init__(self, target: int,
                 left: int, left_kind: int,
                 right: int, right_kind: int,
                 op: str) -> None:
        self.target = target
        self.left = left
        self.left_kind = left_kind
        self.right = right
        self.right_kind = right_kind
        self.op = op

    def __str__(self) -> str:
        return 'r%d = %s %s %s [int]' % (self.target,
                                         operand(self.left, self.left_kind),
                                         self.op,
                                         operand(self.right, self.right_kind))


class UnaryOp(Opcode):
    """Primitive unary operation (e.g. r0 = -r1 [int])."""
    def __init__(self, target: int, operand: int, op: str) -> None:
        self.target = target
        self.operand = operand
        self.op = op

    def __str__(self) -> str:
        return 'r%d = %sr%d [int]' % (self.target, self.op, self.operand)


# Types of registers
INT = 0 # int, initialized to 0
REF = 1 # Arbitrary reference, initialized to None


class IcodeBuilder(NodeVisitor[int]):
    """Generate icode from a parse tree."""

    generated = Undefined(Dict[str, FuncIcode])
    
    # List of generated blocks in the current scope
    blocks = Undefined(List[BasicBlock])
    # Current basic block
    current = Undefined(BasicBlock)
    # Number of registers allocated in the current scope
    num_registers = 0
    # Map local variable to allocated register
    lvar_regs = Undefined(Dict[Node, int])
    # Stack of expression target registers (-1 => create new register)
    targets = Undefined(List[int])
    # Storage type for each register (REG_* values)
    register_types = Undefined(List[int])

    # Stack of inactive scopes
    scopes = Undefined(List[Tuple[List[BasicBlock], int, Dict[Node, int]]])

    def __init__(self, types: Dict[Node, Type]) -> None:
        self.generated = {}
        self.scopes = []
        self.targets = []
        self.types = types

    def visit_mypy_file(self, mfile: MypyFile) -> int:
        if mfile.fullname() in ('typing', 'abc'):
            # These module are special; their contents are currently all
            # built-in primitives.
            return -1
        
        self.enter()
        
        # Initialize non-int global variables.
        for name in sorted(mfile.names):
            node = mfile.names[name].node
            if (isinstance(node, Var) and
                    name not in nodes.implicit_module_attrs):
                v = cast(Var, node)
                if (not is_named_instance(v.type, 'builtins.int')
                        and v.fullname() != 'typing.Undefined'):
                    tmp = self.alloc_register()
                    self.add(SetRNone(tmp))
                    self.add(SetGR(v.fullname(), tmp))
        
        for d in mfile.defs:
            d.accept(self)
        self.add_implicit_return()
        self.generated['__init'] = FuncIcode(0, self.blocks,
                                             self.register_types)
        # TODO leave?
        return -1

    def visit_func_def(self, fdef: FuncDef) -> int:
        if fdef.name().endswith('*'):
            # Wrapper functions are not supported yet.
            return -1
        
        self.enter()

        for arg in fdef.args:
            self.add_local(arg)
        fdef.body.accept(self)
        self.add_implicit_return(cast(Callable, fdef.type))

        if fdef.info:
            name = '%s.%s' % (fdef.info.name(), fdef.name())
        else:
            name = fdef.name()
        
        self.generated[name] = FuncIcode(len(fdef.args), self.blocks,
                                         self.register_types)

        self.leave()
        
        return -1

    def add_implicit_return(self, sig: FunctionLike = None) -> None:
        if not self.current.ops or not isinstance(self.current.ops[-1],
                                                  Return):
            r = self.alloc_register()
            if sig and is_named_instance((cast(Callable, sig)).ret_type,
                                         'builtins.int'):
                self.add(SetRI(r, 0))
            else:
                self.add(SetRNone(r))
            self.add(Return(r))

    def visit_class_def(self, tdef: ClassDef) -> int:
        # TODO assignments in the body
        # TODO multiple inheritance
        tdef.defs.accept(self)

        # Generate icode for the function that constructs an instance.
        self.make_class_constructor(tdef)
        
        return -1

    def make_class_constructor(self, tdef: ClassDef) -> None:
        # Do we have a non-empty __init__?
        init = cast(FuncDef, tdef.info.get_method('__init__'))
        init_argc = len(init.args) - 1
        if init.info.fullname() == 'builtins.object':
            init = None
        
        self.enter()
        if init:
            args = [] # type: List[int]
            for arg in init.args[1:]:
                args.append(self.add_local(arg))
        target = self.alloc_register()
        self.add(Construct(target, tdef.info))
        # Inititalize data attributes to default values.
        for name, node in sorted(tdef.info.names.items()):
            if isinstance(node.node, Var):
                var = cast(Var, node.node)
                temp = self.alloc_register()
                vtype = var.type
                if is_named_instance(vtype, 'builtins.int'):
                    self.add(SetRI(temp, 0))
                else:
                    self.add(SetRNone(temp))
                self.add(SetAttr(target, name, temp, tdef.info))
        if init:
            self.add(CallMethod(self.alloc_register(), target, '__init__',
                                init.info, args, static=True))
        self.add(Return(target))
        self.generated[tdef.name] = FuncIcode(init_argc, self.blocks,
                                              self.register_types)
        self.leave()

    #
    # Statements
    #

    def visit_block(self, b: Block) -> int:
        for stmt in b.body:
            stmt.accept(self)
        return -1

    def visit_var_def(self, d: VarDef) -> int:
        assert len(d.items) == 1
        var = d.items[0]
        if d.kind == nodes.LDEF:
            reg = self.add_local(var)
            if d.init:
                self.accept(d.init, reg)
        elif d.kind == nodes.GDEF and d.init:
            init = self.accept(d.init)
            self.add(SetGR(var.fullname(), init))
        return -1

    def visit_expression_stmt(self, s: ExpressionStmt) -> int:
        self.accept(s.expr)
        return -1

    def visit_return_stmt(self, s: ReturnStmt) -> int:
        retval = self.accept(s.expr)
        self.add(Return(retval))
        return -1

    def visit_assignment_stmt(self, s: AssignmentStmt) -> int:
        assert len(s.lvalues) == 1
        lvalue = s.lvalues[0]

        undefined_rvalue = is_undefined_initializer(s.rvalue)

        if isinstance(lvalue, NameExpr):
            name = cast(NameExpr, lvalue)
            if name.kind == nodes.LDEF:
                if name.is_def or s.type:
                    reg = self.add_local(cast(Var, name.node))
                else:
                    reg = self.lvar_regs[name.node]
                if not undefined_rvalue:
                    self.accept(s.rvalue, reg)
            elif name.kind == nodes.GDEF:
                assert isinstance(name.node, Var)
                if not undefined_rvalue:
                    var = cast(Var, name.node)
                    rvalue = self.accept(s.rvalue)
                    self.add(SetGR(var.fullname(), rvalue))
            elif name.kind == nodes.MDEF and undefined_rvalue:
                # Attribute initializers not supported yet.
                pass
            else:
                raise NotImplementedError()
        elif isinstance(lvalue, MemberExpr):
            member = cast(MemberExpr, lvalue)
            obj = self.accept(member.expr)
            obj_type = self.types[member.expr]
            assert isinstance(obj_type, Instance) # TODO more flexible
            typeinfo = (cast(Instance, obj_type)).type
            source = self.accept(s.rvalue)
            if member.direct:
                self.add(SetAttr(obj, member.name, source, typeinfo))
            else:
                temp = self.alloc_register()
                # TODO do not hard code set$ prefix
                self.add(CallMethod(temp, obj, 'set$' + member.name, typeinfo,
                                    [source]))
        elif isinstance(lvalue, IndexExpr):
            indexexpr = cast(IndexExpr, lvalue)
            obj_type = self.types[indexexpr.base]
            assert isinstance(obj_type, Instance) # TODO more flexible
            typeinfo = (cast(Instance, obj_type)).type
            base = self.accept(indexexpr.base)
            index = self.accept(indexexpr.index)
            value = self.accept(s.rvalue)
            temp = self.alloc_register()
            self.add(CallMethod(temp, base, '__setitem__', typeinfo,
                                [index, value]))
        else:
            raise RuntimeError()

    def visit_while_stmt(self, s: WhileStmt) -> int:
        # Split block so that we get a handle to the top of the loop.
        top = self.new_block()
        branches = self.process_conditional(s.expr)
        body = self.new_block()
        # Bind "true" branches to the body block.
        self.set_branches(branches, True, body)
        s.body.accept(self)
        # Add branch to the top at the end of the body.
        self.add(Goto(top))
        next = self.new_block()
        # Bind "false" branches to the new block.
        self.set_branches(branches, False, next)
        return -1

    def visit_if_stmt(self, s: IfStmt) -> int:
        # If condition + body.
        branches = self.process_conditional(s.expr[0])
        if_body = self.new_block()
        self.set_branches(branches, True, if_body)
        s.body[0].accept(self)
        if s.else_body:
            # Else block.
            goto = Goto(None)
            self.add(goto)
            else_body = self.new_block()
            self.set_branches(branches, False, else_body)
            s.else_body.accept(self)
            next = self.new_block()
            goto.next_block = next
        else:
            # No else block.
            next = self.new_block()
            self.set_branches(branches, False, next)
        return -1

    #
    # Expressions (values)
    #

    def visit_int_expr(self, e: IntExpr) -> int:
        r = self.target_register()
        self.add(SetRI(r, e.value))
        return r

    def visit_name_expr(self, e: NameExpr) -> int:
        # TODO other names than locals
        if e.kind == nodes.LDEF:
            target = self.targets[-1]
            source = self.lvar_regs[e.node]
            if target < 0:
                return source
            else:
                self.add(SetRR(target, source))
                return target
        elif e.kind == nodes.GDEF:
            target = self.target_register()
            assert isinstance(e.node, Var) # TODO more flexible
            var = cast(Var, e.node)
            if var.fullname() == 'builtins.None':
                self.add(SetRNone(target)) # Special opcode for None
            else:
                self.add(SetRG(target, var.fullname()))
            return target
        else:
            raise NotImplementedError('unsupported kind %d' % e.kind)

    def visit_member_expr(self, e: MemberExpr) -> int:
        obj = self.accept(e.expr)
        obj_type = self.types[e.expr]
        assert isinstance(obj_type, Instance) # TODO more flexible
        typeinfo = (cast(Instance, obj_type)).type
        target = self.target_register()
        if e.direct:
            self.add(GetAttr(target, obj, e.name, typeinfo))
        else:
            # TODO do not hard code '$' + ...
            self.add(CallMethod(target, obj, '$' + e.name, typeinfo, []))
        return target

    def visit_op_expr(self, e: OpExpr) -> int:
        # TODO arbitrary operand types
        left_type = self.types[e.left]
        right_type = self.types[e.right]
        if (is_named_instance(left_type, 'builtins.int') and
                is_named_instance(right_type, 'builtins.int')):
            # Primitive operation
            left, left_kind = self.get_operand(e.left)
            right, right_kind = self.get_operand(e.right)
            target = self.target_register()
            self.add(BinOp(target, left, left_kind, right, right_kind, e.op))
        else:
            # Generate method call
            inst = cast(Instance, left_type)
            left = self.accept(e.left)
            right = self.accept(e.right)
            target = self.target_register()
            method = nodes.op_methods[e.op]
            if e.op == 'in':
                left, right = right, left
                inst = cast(Instance, right_type)
            self.add(CallMethod(target, left, method, inst.type, [right]))
        return target

    def get_operand(self, n: Node) -> Tuple[int, int]:
        if isinstance(n, IntExpr):
            return (cast(IntExpr, n)).value, INT_KIND
        else:
            return self.accept(n), REG_KIND

    def visit_unary_expr(self, e: UnaryExpr) -> int:
        operand_type = self.types[e.expr]
        operand = self.accept(e.expr)
        target = self.target_register()
        if is_named_instance(operand_type, 'builtins.int'):
            self.add(UnaryOp(target, operand, e.op))
        else:
            if e.op == '-':
                method = '__neg__'
            elif e.op == '~':
                method = '__invert__'
            else:
                raise NotImplementedError()
            inst = cast(Instance, operand_type) # TODO more flexible
            self.add(CallMethod(target, operand, method, inst.type, []))
        return target

    def visit_call_expr(self, e: CallExpr) -> int:
        args = [] # type: List[int]
        for arg in e.args:
            args.append(self.accept(arg))
        if isinstance(e.callee, NameExpr):
            name = cast(NameExpr, e.callee)
            target = self.target_register()
            self.add(CallDirect(target, name.name, args))
        elif isinstance(e.callee, MemberExpr):
            member = cast(MemberExpr, e.callee)
            receiver = self.accept(member.expr)
            target = self.target_register()
            receiver_type = self.types[member.expr]
            assert isinstance(receiver_type, Instance) # TODO more flexible
            typeinfo = (cast(Instance, receiver_type)).type
            self.add(CallMethod(target, receiver, member.name, typeinfo, args))
        elif isinstance(e.callee, SuperExpr):
            superexpr = cast(SuperExpr, e.callee)
            target = self.target_register()
            self.add(CallMethod(target, 0,
                                superexpr.name,
                                superexpr.info.bases[0].type,
                                args, static=True))
        else:
            raise NotImplementedError('call target %s' % type(e.callee))
        return target

    def visit_paren_expr(self, e: ParenExpr) -> int:
        return e.expr.accept(self)

    def visit_coerce_expr(self, e: CoerceExpr) -> int:
        if (is_named_instance(e.source_type, 'builtins.int') and
            isinstance(e.target_type, AnyType)):
            # This is a no-op currently.
            # TODO perhaps should do boxing in some cases...
            return e.expr.accept(self)
        else:
            # Non-trivial coercions not supported yet.
            raise NotImplementedError()

    def visit_index_expr(self, e: IndexExpr) -> int:
        # Generate method call
        basetype = cast(Instance, self.types[e.base])
        base = self.accept(e.base)
        index = self.accept(e.index)
        target = self.target_register()
        self.add(CallMethod(target, base, '__getitem__', basetype.type,
                            [index]))
        return target

    #
    # Conditional expressions
    #

    @overload
    def process_conditional(self, e: OpExpr) -> List[Branch]:
        # Return branches that need to be bound. The true and false parts
        # are always tweaked to be correctly.
        if e.op in ['==', '!=', '<', '<=', '>', '>=']:
            # TODO check that operand types are as expected
            left, left_kind = self.get_operand(e.left)
            right, right_kind = self.get_operand(e.right)
            branch = IfOp(left, left_kind, right, right_kind, e.op, None, None)
            self.add(branch)
            return [branch]
        elif e.op == 'and':
            # Short circuit 'and'.
            # TODO non-bool operands
            lbranches = self.process_conditional(e.left)
            new = self.new_block()
            self.set_branches(lbranches, True, new)
            rbraches = self.process_conditional(e.right)
            return lbranches + rbraches
        elif e.op == 'or':
            # Short circuit 'or'.
            # TODO non-bool operands
            lbranches = self.process_conditional(e.left)
            new = self.new_block()
            self.set_branches(lbranches, False, new)
            rbraches = self.process_conditional(e.right)
            return lbranches + rbraches
        else:
            raise NotImplementedError()

    @overload
    def process_conditional(self, e: UnaryExpr) -> List[Branch]:
        if e.op == 'not':
            branches = self.process_conditional(e.expr)
            for b in branches:
                b.invert()
            return branches
        else:
            raise NotImplementedError()

    @overload
    def process_conditional(self, e: ParenExpr) -> List[Branch]:
        return self.process_conditional(e.expr)

    @overload
    def process_conditional(self, e: Node) -> List[Branch]:
        """Catch-all variant for value expressions.

        Generate opcode of form 'if rN goto ...'.
        """
        value = self.accept(e)
        branch = IfR(value, None, None)
        self.add(branch)
        return [branch]

    #
    # Helpers
    #

    def enter(self) -> None:
        """Enter a new scope.

        Each function and the file top level is a separate scope.
        """
        self.scopes.append((self.blocks, self.num_registers, self.lvar_regs))
        self.blocks = []
        self.num_registers = 0
        self.register_types= []
        self.lvar_regs = {}
        self.current = None
        self.new_block()

    def leave(self) -> None:
        """Leave a scope."""
        self.blocks, self.num_registers, self.lvar_regs = self.scopes.pop()
        self.current = self.blocks[-1]

    def new_block(self) -> BasicBlock:
        new = BasicBlock(len(self.blocks))
        self.blocks.append(new)
        if self.current:
            if self.current.ops and not self.current.ops[-1].is_exit():
                self.add(Goto(new))
        self.current = new
        return new

    def add(self, op: Opcode) -> None:
        self.current.ops.append(op)

    def accept(self, n: Node, target: int = -1) -> int:
        self.targets.append(target)
        actual = n.accept(self)
        self.targets.pop()
        return actual

    def alloc_register(self, type: int = REF) -> int:
        # Temps are always set before access, so type does not matter for them.
        n = self.num_registers
        self.num_registers += 1
        self.register_types.append(type)
        return n

    def target_register(self) -> int:
        if self.targets[-1] < 0:
            return self.alloc_register()
        else:
            return self.targets[-1]

    def add_local(self, node: Var) -> int:
        type = REF
        if is_named_instance(node.type, 'builtins.int'):
            type = INT
        reg = self.alloc_register(type)
        self.lvar_regs[node] = reg
        return reg
    
    def set_branches(self, branches: List[Branch], condition: bool,
                     target: BasicBlock) -> None:
        """Set branch targets for the given condition (True or False).

        If the target has already been set for a branch, skip the branch.
        """
        for b in branches:
            if condition:
                if not b.true_block:
                    b.true_block = target
            else:
                if not b.false_block:
                    b.false_block = target


def render(func):
    res = []
    for b in func.blocks:
        if res:
            res.append('L%d:' % b.label)
        res.extend(['    ' + str(op) for op in b.ops])

    return filter_out_trivial_gotos(res)


def filter_out_trivial_gotos(disasm: List[str]) -> List[str]:
    """Filter out gotos to the next opcode (they are no-ops)."""
    res = [] # type: List[str]
    for i, s in enumerate(disasm):
        if s.startswith('    goto '):
            label = s.split()[1]
            if i + 1 < len(disasm) and disasm[i+1].startswith('%s:' % label):
                # Omit goto
                continue
        res.append(s)
    return res


def operand(n: int, kind: int) -> str:
    if kind == INT_KIND:
        return str(n)
    else:
        return 'r%d' % n


def is_undefined_initializer(node: Node) -> bool:
    return ((isinstance(node, CallExpr) and
             isinstance((cast(CallExpr, node)).analyzed, UndefinedExpr)) or
            (isinstance(node, NameExpr)
             and (cast(NameExpr, node)).fullname == 'typing.Undefined'))

########NEW FILE########
__FILENAME__ = infer
"""Utilities for type argument inference."""

from typing import List

from mypy.constraints import infer_constraints, infer_constraints_for_callable
from mypy.types import Type, Callable, BasicTypes
from mypy.solve import solve_constraints
from mypy.constraints import SUBTYPE_OF


def infer_function_type_arguments(callee_type: Callable,
                                  arg_types: List[Type],
                                  arg_kinds: List[int],
                                  formal_to_actual: List[List[int]],
                                  basic: BasicTypes) -> List[Type]:
    """Infer the type arguments of a generic function.

    Return an array of lower bound types for the type variables -1 (at
    index 0), -2 (at index 1), etc. A lower bound is None if a value
    could not be inferred.

    Arguments:
      callee_type: the target generic function
      arg_types: argument types at the call site
      arg_kinds: nodes.ARG_* values for arg_types
      formal_to_actual: mapping from formal to actual variable indices
      basic: references to basic types which are needed during inference
    """
    # Infer constraints.
    constraints = infer_constraints_for_callable(
        callee_type, arg_types, arg_kinds, formal_to_actual)
    
    # Solve constraints.
    type_vars = callee_type.type_var_ids()
    return solve_constraints(type_vars, constraints, basic)


def infer_type_arguments(type_var_ids: List[int],
                         template: Type, actual: Type,
                         basic: BasicTypes) -> List[Type]:
    # Like infer_function_type_arguments, but only match a single type
    # against a generic type.
    constraints = infer_constraints(template, actual, SUBTYPE_OF)
    return solve_constraints(type_var_ids, constraints, basic)

########NEW FILE########
__FILENAME__ = join
"""Calculation of the least upper bound types (joins)."""

from typing import cast, List

from mypy.types import (
    Type, AnyType, NoneTyp, Void, TypeVisitor, Instance, UnboundType,
    ErrorType, TypeVar, Callable, TupleType, ErasedType, BasicTypes, TypeList
)
from mypy.subtypes import is_subtype, is_equivalent, map_instance_to_supertype


def join_types(s: Type, t: Type, basic: BasicTypes) -> Type:
    """Return the least upper bound of s and t.

    For example, the join of 'int' and 'object' is 'object'.

    If the join does not exist, return an ErrorType instance.
    """
    
    if isinstance(s, AnyType):
        return s
    
    if isinstance(s, NoneTyp) and not isinstance(t, Void):
        return t

    if isinstance(s, ErasedType):
        return t

    # Use a visitor to handle non-trivial cases.
    return t.accept(TypeJoinVisitor(s, basic))


class TypeJoinVisitor(TypeVisitor[Type]):
    """Implementation of the least upper bound algorithm."""
    
    def __init__(self, s: Type, basic: BasicTypes) -> None:
        self.s = s
        self.basic = basic
        self.object = basic.object
    
    def visit_unbound_type(self, t: UnboundType) -> Type:
        if isinstance(self.s, Void) or isinstance(self.s, ErrorType):
            return ErrorType()
        else:
            return AnyType()
    
    def visit_error_type(self, t: ErrorType) -> Type:
        return t
    
    def visit_type_list(self, t: TypeList) -> Type:
        assert False, 'Not supported'
    
    def visit_any(self, t: AnyType) -> Type:
        return t
    
    def visit_void(self, t: Void) -> Type:
        if isinstance(self.s, Void):
            return t
        else:
            return ErrorType()
    
    def visit_none_type(self, t: NoneTyp) -> Type:
        if not isinstance(self.s, Void):
            return self.s
        else:
            return self.default(self.s)
    
    def visit_erased_type(self, t: ErasedType) -> Type:
        return self.s
    
    def visit_type_var(self, t: TypeVar) -> Type:
        if isinstance(self.s, TypeVar) and (cast(TypeVar, self.s)).id == t.id:
            return self.s
        else:
            return self.default(self.s)
    
    def visit_instance(self, t: Instance) -> Type:
        if isinstance(self.s, Instance):
            return join_instances(t, cast(Instance, self.s), self.basic)
        elif t.type == self.basic.type_type.type and is_subtype(self.s, t):
            return t
        else:
            return self.default(self.s)
    
    def visit_callable(self, t: Callable) -> Type:
        if isinstance(self.s, Callable) and is_similar_callables(
                                                    t, cast(Callable, self.s)):
            return combine_similar_callables(t, cast(Callable, self.s),
                                             self.basic)
        elif t.is_type_obj() and is_subtype(self.s, self.basic.type_type):
            return self.basic.type_type
        elif (isinstance(self.s, Instance) and
                  cast(Instance, self.s).type == self.basic.type_type.type and
                  t.is_type_obj()):
            return self.basic.type_type
        else:
            return self.default(self.s)
    
    def visit_tuple_type(self, t: TupleType) -> Type:
        if (isinstance(self.s, TupleType) and
                cast(TupleType, self.s).length() == t.length()):
            items = [] # type: List[Type]
            for i in range(t.length()):
                items.append(self.join(t.items[i],
                                       (cast(TupleType, self.s)).items[i]))
            return TupleType(items)
        else:
            return self.default(self.s)
    
    def join(self, s: Type, t: Type) -> Type:
        return join_types(s, t, self.basic)
    
    def default(self, typ: Type) -> Type:
        if isinstance(typ, UnboundType):
            return AnyType()
        elif isinstance(typ, Void) or isinstance(typ, ErrorType):
            return ErrorType()
        else:
            return self.object


def join_instances(t: Instance, s: Instance, basic: BasicTypes) -> Type:
    """Calculate the join of two instance types.

    If allow_interfaces is True, also consider interface-type results for
    non-interface types.
    
    Return ErrorType if the result is ambiguous.
    """
    
    if t.type == s.type:
        # Simplest case: join two types with the same base type (but
        # potentially different arguments).
        if is_subtype(t, s):
            # Compatible; combine type arguments.
            args = [] # type: List[Type]
            for i in range(len(t.args)):
                args.append(join_types(t.args[i], s.args[i], basic))
            return Instance(t.type, args)
        else:
            # Incompatible; return trivial result object.
            return basic.object
    elif t.type.bases and is_subtype(t, s):
        return join_instances_via_supertype(t, s, basic)
    else:
        # Now t is not a subtype of s, and t != s. Now s could be a subtype
        # of t; alternatively, we need to find a common supertype. This works
        # in of the both cases.
        return join_instances_via_supertype(s, t, basic)


def join_instances_via_supertype(t: Instance, s: Instance,
                                 basic: BasicTypes) -> Type:
    # Give preference to joins via duck typing relationship, so that
    # join(int, float) == float, for example.
    if t.type.ducktype and is_subtype(t.type.ducktype, s):
        return join_types(t.type.ducktype, s, basic)
    elif s.type.ducktype and is_subtype(s.type.ducktype, t):
        return join_types(t, s.type.ducktype, basic)
    res = s
    mapped = map_instance_to_supertype(t, t.type.bases[0].type)
    join = join_instances(mapped, res, basic)
    # If the join failed, fail. This is a defensive measure (this might
    # never happen).
    if isinstance(join, ErrorType):
        return join
    # Now the result must be an Instance, so the cast below cannot fail.
    res = cast(Instance, join)
    return res


def is_similar_callables(t: Callable, s: Callable) -> bool:
    """Return True if t and s are equivalent and have identical numbers of
    arguments, default arguments and varargs.
    """
    
    return (len(t.arg_types) == len(s.arg_types) and t.min_args == s.min_args
            and t.is_var_arg == s.is_var_arg and is_equivalent(t, s))


def combine_similar_callables(t: Callable, s: Callable,
                              basic: BasicTypes) -> Callable:
    arg_types = [] # type: List[Type]
    for i in range(len(t.arg_types)):
        arg_types.append(join_types(t.arg_types[i], s.arg_types[i], basic))
    # TODO kinds and argument names
    return Callable(arg_types,
                    t.arg_kinds,
                    t.arg_names,
                    join_types(t.ret_type, s.ret_type, basic),
                    t.is_type_obj() and s.is_type_obj(),
                    None,
                    t.variables)
    return s

########NEW FILE########
__FILENAME__ = lex
"""Lexical analyzer for mypy.

Translate a string that represents a file or a compilation unit to a list of
tokens.

This module can be run as a script (lex.py FILE).
"""

import re

from mypy.util import short_type
from typing import List, Undefined, Function, Dict, Any, Match, Pattern


class Token:
    """Base class for all tokens."""
    
    def __init__(self, string: str, pre: str = '') -> None:
        """Initialize a token.
        
        Arguments:
          string: Token string in program text
          pre:    Space, comments etc. before token
        """
        
        self.string = string
        self.pre = pre
        self.line = 0
    
    def __repr__(self) -> str:
        """The representation is of form 'Keyword(  if)'."""
        t = short_type(self)
        return t + '(' + self.fix(self.pre) + self.fix(self.string) + ')'
    
    def rep(self) -> str:
        return self.pre + self.string
    
    def fix(self, s: str) -> str:
        """Replace common non-printable chars with escape sequences.

        Do not use repr() since we don't want do duplicate backslashes.
        """
        return s.replace('\n', '\\n').replace('\t', '\\t').replace('\r', '\\r')


# Token classes


class Break(Token):
    """Statement break (line break or semicolon)"""


class Indent(Token):
    """Increase block indent level."""


class Dedent(Token):
    """Decrease block indent level."""


class Eof(Token):
    """End of file"""


class Keyword(Token):
    """Reserved word (other than keyword operators; they use Op).

    Examples: if, class, while, def.
    """


class Name(Token):
    """An alphanumeric identifier"""


class IntLit(Token):
    """Integer literal"""


class StrLit(Token):
    """String literal"""
    
    def parsed(self) -> str:
        """Return the parsed contents of the literal."""
        return _parse_str_literal(self.string)


class BytesLit(Token):
    """Bytes literal"""
    
    def parsed(self) -> str:
        """Return the parsed contents of the literal."""
        return _parse_str_literal(self.string)


class UnicodeLit(Token):
    """Unicode literal (Python 2.x)"""
    
    def parsed(self) -> str:
        """Return the parsed contents of the literal."""
        return _parse_str_literal(self.string)


class FloatLit(Token):
    """Float literal"""


class Punct(Token):
    """Punctuator (e.g. comma, '(' or '=')"""


class Colon(Token):
    pass


class Op(Token):
    """Operator (e.g. '+' or 'in')"""


class Bom(Token):
    """Byte order mark (at the start of a file)"""


class LexError(Token):
    """Lexer error token"""
    
    def __init__(self, string: str, type: int) -> None:
        """Initialize token.

        The type argument is one of the error types below.
        """
        super().__init__(string)
        self.type = type


# Lexer error types
NUMERIC_LITERAL_ERROR = 0
UNTERMINATED_STRING_LITERAL = 1
INVALID_CHARACTER = 2
NON_ASCII_CHARACTER_IN_COMMENT = 3
NON_ASCII_CHARACTER_IN_STRING = 4
INVALID_UTF8_SEQUENCE = 5
INVALID_BACKSLASH = 6
INVALID_DEDENT = 7

# Encoding contexts
STR_CONTEXT = 1
COMMENT_CONTEXT = 2


def lex(string: str, first_line: int = 1) -> List[Token]:
    """Analyze string and return an array of token objects.

    The last token is always Eof.
    """
    l = Lexer()
    l.lex(string, first_line)
    return l.tok


# Reserved words (not including operators)
keywords = set([
    'as', 'assert', 'break', 'class', 'continue', 'def', 'del', 'elif',
    'else', 'except', 'finally', 'from', 'for', 'global', 'if', 'import',
    'lambda', 'pass', 'raise', 'return', 'try', 'while', 'with',
    'yield'])

# Alphabetical operators (reserved words)
alpha_operators = set(['in', 'is', 'not', 'and', 'or'])

# String literal prefixes
str_prefixes = set(['r', 'b', 'br', 'u', 'ur'])  

# List of regular expressions that match non-alphabetical operators
operators = [re.compile('[-+*/<>.%&|^~]'),
             re.compile('==|!=|<=|>=|\\*\\*|//|<<|>>')]

# List of regular expressions that match punctuator tokens
punctuators = [re.compile('[=,()@]'),
               re.compile('\\['),
               re.compile(']'),
               re.compile('([-+*/%&|^]|\\*\\*|//|<<|>>)=')]


# Source file encodings
DEFAULT_ENCODING = 0
ASCII_ENCODING = 1
LATIN1_ENCODING = 2
UTF8_ENCODING = 3


# Map single-character string escape sequences to corresponding characters.
escape_map = {'a': '\x07',
              'b': '\x08',
              'f': '\x0c',
              'n': '\x0a',
              'r': '\x0d',
              't': '\x09',
              'v': '\x0b',
              '"': '"',
              "'": "'"}


# Matches the optional prefix of a string literal, e.g. the 'r' in r"foo".
str_prefix_re = re.compile('[rRbBuU]*')

# Matches an escape sequence in a string, e.g. \n or \x4F.
escape_re = re.compile(
    "\\\\([abfnrtv'\"]|x[0-9a-fA-F]{2}|u[0-9a-fA-F]{4}|[0-7]{1,3})")


def _parse_str_literal(string: str) -> str:
    """Translate escape sequences in str literal to the corresponding chars.

    For example, \t is translated to the tab character (ascii 9).

    Return the translated contents of the literal.  Also handle raw and
    triple-quoted string literals.
    """
    
    prefix = str_prefix_re.match(string).group(0).lower()
    s = string[len(prefix):]
    if s.startswith("'''") or s.startswith('"""'):
        return s[3:-3]
    elif 'r' in prefix:
        return s[1:-1].replace('\\' + s[0], s[0])
    else:
        return escape_re.sub(lambda m: escape_repl(m, prefix), s[1:-1])


def escape_repl(m: Match[str], prefix: str) -> str:
    """Translate a string escape sequence, e.g. \t -> the tab character.

    Assume that the Match object is from escape_re.
    """
    
    seq = m.group(1)
    if len(seq) == 1 and seq in escape_map:
        # Single-character escape sequence, e.g. \n.
        return escape_map[seq]
    elif seq.startswith('x'):
        # Hexadecimal sequence \xNN.
        return chr(int(seq[1:], 16))
    elif seq.startswith('u'):
        # Unicode sequence \uNNNN.
        if 'b' not in prefix:
            return chr(int(seq[1:], 16))
        else:
            return '\\' + seq
    else:
        # Octal sequence.
        ord = int(seq, 8)
        if 'b' in prefix:
            # Make sure code is no larger than 255 for bytes literals.
            ord = ord % 256
        return chr(ord)


class Lexer:
    """Lexical analyzer."""
    
    i = 0      # Current string index (into s)
    s = ''     # The string being analyzed
    line = 0   # Current line number
    pre_whitespace = ''     # Whitespace and comments before the next token
    enc = DEFAULT_ENCODING  # Encoding TODO implement properly

    # Generated tokens
    tok = Undefined(List[Token])
    
    # Table from byte character value to lexer method. E.g. entry at ord('0')
    # contains the method lex_number().
    map = Undefined(List[Function[[], None]])

    # Indent levels of currently open blocks, in spaces.
    indents = Undefined(List[int])
    
    # Open ('s, ['s and {'s without matching closing bracket; used for ignoring
    # newlines within parentheses/brackets.
    open_brackets = Undefined(List[str])
    
    def __init__(self) -> None:
        self.map = [self.unknown_character] * 256
        self.tok = []
        self.indents = [0]
        self.open_brackets = []
        # Fill in the map from valid character codes to relevant lexer methods.
        for seq, method in [('ABCDEFGHIJKLMNOPQRSTUVWXYZ', self.lex_name),
                            ('abcdefghijklmnopqrstuvwxyz_', self.lex_name),
                            ('0123456789', self.lex_number),
                            ('.', self.lex_number_or_dot),
                            (' ' + '\t' + '\x0c', self.lex_space),
                            ('"', self.lex_str_double),
                            ("'", self.lex_str_single),
                            ('\r' + '\n', self.lex_break),
                            (';', self.lex_semicolon),
                            (':', self.lex_colon),
                            ('#', self.lex_comment),
                            ('\\', self.lex_backslash),
                            ('([{', self.lex_open_bracket),
                            (')]}', self.lex_close_bracket),
                            ('-+*/<>%&|^~=!,@', self.lex_misc)]:
            for c in seq:
                self.map[ord(c)] = method
    
    def lex(self, s: str, first_line: int) -> None:
        """Lexically analyze a string, storing the tokens at the tok list."""
        self.s = s
        self.i = 0
        self.line = first_line

        if s.startswith('\xef\xbb\xbf'):
            self.add_token(Bom(s[0:3]))
            
        # Parse initial indent; otherwise first-line indent would not generate
        # an error.
        self.lex_indent()

        # Make a local copy of map as a simple optimization.
        map = self.map
        
        # Lex the file. Repeatedly call the lexer method for the current char.
        while self.i < len(s):
            # Get the character code of the next character to lex.
            c = ord(s[self.i])
            # Dispatch to the relevant lexer method. This will consume some
            # characters in the text, add a token to self.tok and increment
            # self.i.
            map[c]()
        
        # Append a break if there is no statement/block terminator at the end
        # of input.
        if len(self.tok) > 0 and (not isinstance(self.tok[-1], Break) and
                                  not isinstance(self.tok[-1], Dedent)):
            self.add_token(Break(''))

        # Attack any dangling comments/whitespace to a final Break token.
        if self.tok and isinstance(self.tok[-1], Break):
            self.tok[-1].string += self.pre_whitespace
            self.pre_whitespace = ''

        # Close remaining open blocks with Dedent tokens.
        self.lex_indent()
        
        self.add_token(Eof(''))
    
    def lex_number_or_dot(self) -> None:
        """Analyse a token starting with a dot.

        It can be the member access operator or a float literal such as '.123'.
        """
        if self.is_at_number():
            self.lex_number()
        else:
            self.lex_misc()
    
    number_exp = re.compile(r'[0-9]|\.[0-9]')
    
    def is_at_number(self) -> bool:
        """Is the current location at a numeric literal?"""
        return self.match(self.number_exp) != ''
    
    # Regexps used by lex_number

    # Decimal/hex/octal literal
    number_exp1 = re.compile('0[xXoO][0-9a-fA-F]+|[0-9]+')
    # Float literal, e.g. '1.23' or '12e+34'
    number_exp2 = re.compile(
        r'[0-9]*\.[0-9]*([eE][-+]?[0-9]+)?|[0-9]+[eE][-+]?[0-9]+')
    # These characters must not appear after a number literal.
    name_char_exp = re.compile('[a-zA-Z0-9_]')
    
    def lex_number(self) -> None:
        """Analyse an int or float literal.

        Assume that the current location points to one of them.
        """
        s1 = self.match(self.number_exp1)
        s2 = self.match(self.number_exp2)
        
        maxlen = max(len(s1), len(s2))
        if self.name_char_exp.match(
                    self.s[self.i + maxlen:self.i + maxlen + 1]) is not None:
            # Error: alphanumeric character after number literal.
            s3 = self.match(re.compile('[0-9][0-9a-zA-Z_]*'))
            maxlen = max(maxlen, len(s3))
            self.add_token(LexError(' ' * maxlen, NUMERIC_LITERAL_ERROR))
        elif len(s1) > len(s2):
            # Integer literal.
            self.add_token(IntLit(s1))
        else:
            # Float literal.
            self.add_token(FloatLit(s2))
    
    name_exp = re.compile('[a-zA-Z_][a-zA-Z0-9_]*')
    
    def lex_name(self) -> None:
        """Analyse a name.

        A name can be an identifier, a keyword or an alphabetical operator.
        Also deal with prefixed string literals such as r'...'.
        """
        s = self.match(self.name_exp)
        if s in keywords:
            self.add_token(Keyword(s))
        elif s in alpha_operators:
            self.add_token(Op(s))
        elif s in str_prefixes and self.match(re.compile('[a-z]+[\'"]')) != '':
            self.lex_prefixed_str(s)
        else:
            self.add_token(Name(s))
    
    # Regexps representing components of string literals

    # Initial part of a single-quoted literal, e.g. b'foo' or b'foo\\\n
    str_exp_single = re.compile(
        r"[a-z]*'([^'\\\r\n]|\\[^\r\n])*('|\\(\n|\r\n?))")
    # Non-initial part of a multiline single-quoted literal, e.g. foo'
    str_exp_single_multi = re.compile(
        r"([^'\\\r\n]|\\[^\r\n])*('|\\(\n|\r\n?))")
    # Initial part of a single-quoted raw literal, e.g. r'foo' or r'foo\\\n
    str_exp_raw_single = re.compile(
        r"[a-z]*'([^'\r\n\\]|\\'|\\[^\n\r])*('|\\(\n|\r\n?))")
    # Non-initial part of a raw multiline single-quoted literal, e.g. foo'
    str_exp_raw_single_multi = re.compile(
        r"([^'\r\n]|'')*('|\\(\n|\r\n?))")

    # Start of a ''' literal, e.g. b'''
    str_exp_single3 = re.compile("[a-z]*'''")
    # End of a ''' literal, e.g. foo'''
    str_exp_single3end = re.compile(r"[^\n\r]*?'''")

    # The following are similar to above (but use double quotes).
    
    str_exp_double = re.compile(
        r'[a-z]*"([^"\\\r\n]|\\[^\r\n])*("|\\(\n|\r\n?))')
    str_exp_double_multi = re.compile(
        r'([^"\\\r\n]|\\[^\r\n])*("|\\(\n|\r\n?))')  
    str_exp_raw_double = re.compile(
        r'[a-z]*"([^"\r\n\\]|\\"|\\[^\n\r])*("|\\(\n|\r\n?))')
    str_exp_raw_double_multi = re.compile(
        r'([^"\r\n]|"")*("|\\(\n|\r\n?))')
    
    str_exp_double3 = re.compile('[a-z]*"""')
    str_exp_double3end = re.compile(r'[^\n\r]*?"""')
    
    def lex_str_single(self) -> None:
        """Analyse single-quoted string literal"""
        self.lex_str(self.str_exp_single, self.str_exp_single_multi,
                     self.str_exp_single3, self.str_exp_single3end)
    
    def lex_str_double(self) -> None:
        """Analyse double-quoted string literal"""
        self.lex_str(self.str_exp_double, self.str_exp_double_multi,
                     self.str_exp_double3, self.str_exp_double3end)
    
    def lex_prefixed_str(self, prefix: str) -> None:
        """Analyse a string literal with a prefix, such as r'...'."""
        s = self.match(re.compile('[a-z]+[\'"]'))
        if s.endswith("'"):
            re1 = self.str_exp_single
            re2 = self.str_exp_single_multi
            if 'r' in prefix:
                re1 = self.str_exp_raw_single
                re2 = self.str_exp_raw_single_multi
            self.lex_str(re1, re2, self.str_exp_single3,
                         self.str_exp_single3end, prefix)
        else:
            re1 = self.str_exp_double
            re2 = self.str_exp_double_multi
            if 'r' in prefix:
                re1 = self.str_exp_raw_double
                re2 = self.str_exp_raw_double_multi
            self.lex_str(re1, re2, self.str_exp_double3,
                         self.str_exp_double3end, prefix)
    
    def lex_str(self, regex: Pattern[str], re2: Pattern[str],
                re3: Pattern[str], re3end: Pattern[str],
                prefix: str = '') -> None:
        """Analyse a string literal described by regexps.

        Assume that the current location is at the beginning of the
        literal. The arguments re3 and re3end describe the
        corresponding triple-quoted literals.
        """
        s3 = self.match(re3)
        if s3 != '':
            # Triple-quoted string literal.
            self.lex_triple_quoted_str(re3end, prefix)
        else:
            # Single or double quoted string literal.
            s = self.match(regex)
            if s != '':
                if s.endswith('\n') or s.endswith('\r'):
                    self.lex_multiline_string_literal(re2, s)
                else:
                    self.verify_encoding(s, STR_CONTEXT)
                    if 'b' in prefix:
                        self.add_token(BytesLit(s))
                    elif 'u' in prefix:
                        self.add_token(UnicodeLit(s))
                    else:
                        self.add_token(StrLit(s))
            else:
                # Unterminated string literal.
                s = self.match(re.compile('[^\\n\\r]*'))
                self.add_token(LexError(s, UNTERMINATED_STRING_LITERAL))
    
    def lex_triple_quoted_str(self, re3end: Pattern[str], prefix: str) -> None:
        line = self.line
        ss = self.s[self.i:self.i + len(prefix) + 3]
        self.i += len(prefix) + 3
        while True:
            m = re3end.match(self.s, self.i)
            if m is not None:
                break
            m = re.match('[^\\n\\r]*(\\n|\\r\\n?)', self.s[self.i:])
            if m is None:
                self.add_special_token(
                    LexError(ss, UNTERMINATED_STRING_LITERAL), line, 0)
                return 
            s = m.group(0)
            ss += s
            self.line += 1
            self.i += len(s)
        lit = Undefined # type: Token
        if 'b' in prefix:
            lit = BytesLit(ss + m.group(0))
        elif 'u' in prefix:
            lit = UnicodeLit(ss + m.group(0))
        else:
            lit = StrLit(ss + m.group(0))
        self.add_special_token(lit, line, len(m.group(0)))
    
    def lex_multiline_string_literal(self, re_end: Pattern[str],
                                     prefix: str) -> None:
        """Analyze multiline single/double-quoted string literal.

        Use explicit \ for line continuation.
        """
        line = self.line
        self.i += len(prefix)
        ss = prefix
        while True:
            m = self.match(re_end)
            if m == '':
                self.add_special_token(
                    LexError(ss, UNTERMINATED_STRING_LITERAL), line, 0)
                return 
            ss += m
            self.line += 1
            self.i += len(m)        
            if not m.endswith('\n') and not m.endswith('\r'): break
        self.add_special_token(StrLit(ss), line, 0) # TODO bytes
    
    comment_exp = re.compile(r'#[^\n\r]*')
    
    def lex_comment(self) -> None:
        """Analyze a comment."""
        s = self.match(self.comment_exp)
        self.verify_encoding(s, COMMENT_CONTEXT)
        self.add_pre_whitespace(s)
    
    backslash_exp = re.compile(r'\\(\n|\r\n?)')
    
    def lex_backslash(self) -> None:
        s = self.match(self.backslash_exp)
        if s != '':
            self.add_pre_whitespace(s)
            self.line += 1
        else:
            self.add_token(LexError('\\', INVALID_BACKSLASH))
    
    space_exp = re.compile(r'[ \t\x0c]*')
    indent_exp = re.compile(r'[ \t]*[#\n\r]?')
    
    def lex_space(self) -> None:
        """Analyze a run of whitespace characters (within a line, not indents).

        Only store them in self.pre_whitespace.
        """
        s = self.match(self.space_exp)
        self.add_pre_whitespace(s)
    
    comment_or_newline = '#' + '\n' + '\r' # type: str
    
    def lex_indent(self) -> None:
        """Analyze whitespace chars at the beginning of a line (indents)."""
        s = self.match(self.indent_exp)
        if s != '' and s[-1] in self.comment_or_newline:
            # Empty line (whitespace only or comment only).
            self.add_pre_whitespace(s[:-1])
            if s[-1] == '#':
                self.lex_comment()
            else:
                self.lex_break()
            self.lex_indent()
            return 
        indent = self.calc_indent(s)
        if indent == self.indents[-1]:
            # No change in indent: just whitespace.
            self.add_pre_whitespace(s)
        elif indent > self.indents[-1]:
            # An increased indent (new block).
            self.indents.append(indent)
            self.add_token(Indent(s))
        else:
            # Decreased indent (end of one or more blocks).
            pre = self.pre_whitespace
            self.pre_whitespace = ''
            while indent < self.indents[-1]:
                self.add_token(Dedent(''))
                self.indents.pop()
            self.pre_whitespace = pre
            self.add_pre_whitespace(s)            
            if indent != self.indents[-1]:
                # Error: indent level does not match a previous indent level.
                self.add_token(LexError('', INVALID_DEDENT))
    
    def calc_indent(self, s: str) -> int:
        indent = 0
        for ch in s:
            if ch == ' ':
                indent += 1
            else:
                # Tab: 8 spaces (rounded to a multiple of 8).
                indent += 8 - indent % 8
        return indent
    
    break_exp = re.compile(r'\r\n|\r|\n|;')
    
    def lex_break(self) -> None:
        """Analyse a line break."""
        s = self.match(self.break_exp)
        if self.tok and isinstance(self.tok[-1], Break):
            self.tok[-1].string += self.pre_whitespace + s
            self.i += len(s)
            self.line += 1
            self.pre_whitespace = ''
        elif self.ignore_break():
            self.add_pre_whitespace(s)
            self.line += 1
        else:
            self.add_token(Break(s))
            self.line += 1
            self.lex_indent()
    
    def lex_semicolon(self) -> None:
        self.add_token(Break(';'))
    
    def lex_colon(self) -> None:
        self.add_token(Colon(':'))
    
    open_bracket_exp = re.compile('[[({]')
    
    def lex_open_bracket(self) -> None:
        s = self.match(self.open_bracket_exp)
        self.open_brackets.append(s)
        self.add_token(Punct(s))
    
    close_bracket_exp = re.compile('[])}]')
    
    open_bracket = {')': '(', ']': '[', '}': '{'}
    
    def lex_close_bracket(self) -> None:
        s = self.match(self.close_bracket_exp)
        if (self.open_brackets != []
                and self.open_bracket[s] == self.open_brackets[-1]):
            self.open_brackets.pop()
        self.add_token(Punct(s))
    
    def lex_misc(self) -> None:
        """Analyze a non-alphabetical operator or a punctuator."""
        s = ''
        t = None # type: Any
        for re_list, type in [(operators, Op), (punctuators, Punct)]:
            for re in re_list:
                s2 = self.match(re)
                if len(s2) > len(s):
                    t = type
                    s = s2
        if s == '':
            # Could not match any token; report an invalid character. This is
            # reached at least if the current character is '!' not followed by
            # '='.
            self.add_token(LexError(self.s[self.i], INVALID_CHARACTER))
        else:
            self.add_token(t(s))
    
    def unknown_character(self) -> None:
        """Report an unknown character as a lexical analysis error."""
        self.add_token(LexError(self.s[self.i], INVALID_CHARACTER))
    
    # Utility methods
    
    def match(self, pattern: Pattern[str]) -> str:
        """Try to match a regular expression at current location.

        If the argument regexp is matched at the current location,
        return the matched string; otherwise return the empty string.
        """
        m = pattern.match(self.s, self.i)
        if m is not None:
            return m.group(0)
        else:
            return ''
    
    def add_pre_whitespace(self, s: str) -> None:
        """Record whitespace and comments before the next token.
        
        The accumulated whitespace/comments will be stored in the next token
        and then it will be cleared.

        This is needed for pretty-printing the original source code while
        preserving comments, indentation, whitespace etc.
        """
        self.pre_whitespace += s
        self.i += len(s)
    
    def add_token(self, tok: Token) -> None:
        """Store a token.

        Update its line number and record preceding whitespace
        characters and comments.
        """
        if (tok.string == '' and not isinstance(tok, Eof)
                and not isinstance(tok, Break)
                and not isinstance(tok, LexError)
                and not isinstance(tok, Dedent)):
            raise ValueError('Empty token')
        tok.pre = self.pre_whitespace
        tok.line = self.line
        self.tok.append(tok)
        self.i += len(tok.string)
        self.pre_whitespace = ''
    
    def add_special_token(self, tok: Token, line: int, skip: int) -> None:
        """Like add_token, but caller sets the number of chars to skip."""
        if (tok.string == '' and not isinstance(tok, Eof)
                and not isinstance(tok, Break)
                and not isinstance(tok, LexError)
                and not isinstance(tok, Dedent)):
            raise ValueError('Empty token')
        tok.pre = self.pre_whitespace
        tok.line = line
        self.tok.append(tok)
        self.i += skip
        self.pre_whitespace = ''
    
    def ignore_break(self) -> bool:
        """If the next token is a break, can we ignore it?"""
        if len(self.open_brackets) > 0 or len(self.tok) == 0:
            # Ignore break after open ( [ or { or at the beginning of file.
            return True
        else:
            # Ignore break after another break or dedent.
            t = self.tok[-1]
            return isinstance(t, Break) or isinstance(t, Dedent)
    
    def verify_encoding(self, string: str, context: int) -> None:
        """Verify that token is encoded correctly (using the file encoding)."""
        codec = None # type: str
        if self.enc == ASCII_ENCODING:
            codec = 'ascii'
        elif self.enc in [UTF8_ENCODING, DEFAULT_ENCODING]:
            codec = 'utf8'
        if codec is not None:
            try:
                pass # FIX string.decode(codec)
            except UnicodeDecodeError:
                type = INVALID_UTF8_SEQUENCE
                if self.enc == ASCII_ENCODING:
                    if context == STR_CONTEXT:
                        type = NON_ASCII_CHARACTER_IN_STRING
                    else:
                        type = NON_ASCII_CHARACTER_IN_COMMENT
                self.add_token(LexError('', type))


if __name__ == '__main__':
    # Lexically analyze a file and dump the tokens to stdout.
    import sys
    if len(sys.argv) != 2:
        print('Usage: lex.py FILE')
        sys.exit(2)
    fnam = sys.argv[1]
    s = open(fnam).read()
    for t in lex(s):
        print(t)

########NEW FILE########
__FILENAME__ = maptypevar
from typing import Any, List, cast

from mypy.types import RuntimeTypeVar, OBJECT_VAR, Instance, Type, TypeVar
from mypy.nodes import TypeInfo, Node, MemberExpr, IndexExpr, IntExpr
from mypy.transutil import self_expr, tvar_slot_name


def get_tvar_access_expression(typ: TypeInfo, tvindex: int, alt: Any,
                               is_java: Any) -> RuntimeTypeVar:
    """Return a type expression that maps from runtime type variable slots
    to the type variable in the given class with the given index.
    
    For example, assuming class A(Generic[T, S]): ... and
    class B(A[X, Y[U]], Generic[U]): ...:
    
      get_tvar_access_expression(<B>, 1) ==
        RuntimeTypeVar(<self.__tv2.args[0]>)  (with <...> represented as nodes)
    """
    # First get the description of how to get from supertype type variables to
    # a subtype type variable.
    mapping = get_tvar_access_path(typ, tvindex)
    
    # The type checker should have noticed if there is no mapping. Be defensive
    # and make sure there is one.
    if mapping is None:
        raise RuntimeError('Could not find a typevar mapping')
    
    # Build the expression for getting at the subtype type variable
    # progressively.
    
    # First read the value of a supertype runtime type variable slot.
    s = self_expr() # type: Node
    if alt == OBJECT_VAR:
        o = '__o'
        if is_java:
            o = '__o_{}'.format(typ.name)
        s = MemberExpr(s, o)
    expr = MemberExpr(s, tvar_slot_name(mapping[0] - 1, alt)) # type: Node
    
    # Then, optionally look into arguments based on the description.
    for i in mapping[1:]:
        expr = MemberExpr(expr, 'args')
        expr = IndexExpr(expr, IntExpr(i - 1))
    
    # Than add a final wrapper so that we have a valid type.
    return RuntimeTypeVar(expr)


def get_tvar_access_path(typ: TypeInfo, tvindex: int) -> List[int]:
    """Determine how to calculate the value of a type variable of a type.
    
    The description is based on operations on type variable slot values
    embedded in an instance. The type variable and slot indexing is 1-based.
    
     - If tvar slot x maps directly to tvar tvindex in the type, return [x].
     - If argument y of slot x maps to tvar tvindex, return [x, y]. For
       argument z of argument y of x return [x, y, z], etc.
     - If there is no relation, return None.
    
    For example, assume these definitions:
    
      class A(Generic[S, U]): ...
      class B(A[X, Y[T]], Generic[T]): ...
    
    Now we can query the access path to type variable 1 (T) of B:
    
      get_tvar_access_path(<B>, 1) == [2, 1] (slot 2, lookup type argument 1).
    """
    if not typ.bases:
        return None
    
    # Check argument range.
    if tvindex < 1 or tvindex > len(typ.type_vars):
        raise RuntimeError('{} does not have tvar #{}'.format(typ.name,
                                                              tvindex))
    
    # Figure out the superclass instance type.
    base = typ.bases[0]
    
    # Go through all the supertype tvars to find a match.
    mapping = None # type: List[int]
    for i in range(len(base.args)):
        mapping = find_tvar_mapping(base.args[i], tvindex)
        if mapping is not None:
            if base.type.bases[0]:
                return get_tvar_access_path(base.type, i + 1) + mapping
            else:
                return [i + 1] + mapping
    
    # The type variable was introduced in this type.
    return [tvar_slot_index(typ, tvindex)]


def find_tvar_mapping(t: Type, index: int) -> List[int]:
    """Recursively search for a type variable instance (with given index)
    within the type t, which represents a supertype definition. Return the
    path to the first found instance.
    
     - If t is a bare type variable with correct index, return [] as the path.
     - If type variable is within instance arguments, return the indexing
       operations required to get it.
     - If no result could be found, return None.
    
    Examples:
      find_tvar_mapping(T`1, 1) == []
      find_tvar_mapping(A<X, Y, T`1>, 1) == [2]
      find_tvar_mapping(A<B<X, T`2>, T`1>, 2) == [0, 1]
      find_tvar_mapping(A<T`2>, T`1) == None               (no T`1 within t)
      find_tvar_mapping(A<T`1, T`1>, T`1) == [0]           (first match)
    """
    if isinstance(t, Instance) and (cast(Instance, t)).args != []:
        inst = cast(Instance, t)
        for argi in range(len(inst.args)):
            mapping = find_tvar_mapping(inst.args[argi], index)
            if mapping is not None:
                return get_tvar_access_path(inst.type, argi + 1) + mapping
        return None
    elif isinstance(t, TypeVar) and (cast(TypeVar, t)).id == index:
        return []
    else:
        return None


def tvar_slot_index(typ: TypeInfo, tvindex: int) -> int:
    """If the specified type variable was introduced as a new variable in type,
    return the slot index (1 = first type varible slot) of the type variable.
    """
    base_slots = num_slots(typ.bases[0].type)
    
    for i in range(1, tvindex):
        if get_tvar_access_path(typ, i)[0] > base_slots:
            base_slots += 1
    
    return base_slots + 1  


def num_slots(typ: TypeInfo) -> int:
    """Return the number of type variable slots used by a type.

    If type is None, the result is 0.
    """
    if not typ or not typ.bases:
        return 0
    slots = num_slots(typ.bases[0].type)
    ntv = len(typ.type_vars)
    for i in range(ntv):
        n = get_tvar_access_path(typ, i + 1)[0]
        slots = max(slots, n)
    return slots

########NEW FILE########
__FILENAME__ = meet
from typing import cast, List

from mypy.join import is_similar_callables, combine_similar_callables
from mypy.types import (
    Type, AnyType, TypeVisitor, UnboundType, Void, ErrorType, NoneTyp, TypeVar,
    Instance, Callable, TupleType, ErasedType, BasicTypes, TypeList
)
from mypy.sametypes import is_same_type
from mypy.subtypes import is_subtype


# TODO Describe this module.


def meet_types(s: Type, t: Type, basic: BasicTypes) -> Type:
    if isinstance(s, AnyType) or isinstance(s, ErasedType):
        return s
    
    return t.accept(TypeMeetVisitor(s, basic))


class TypeMeetVisitor(TypeVisitor[Type]):
    def __init__(self, s: Type, basic: BasicTypes) -> None:
        self.s = s
        self.basic = basic
    
    def visit_unbound_type(self, t: UnboundType) -> Type:
        if isinstance(self.s, Void) or isinstance(self.s, ErrorType):
            return ErrorType()
        elif isinstance(self.s, NoneTyp):
            return self.s
        else:
            return AnyType()
    
    def visit_error_type(self, t: ErrorType) -> Type:
        return t
    
    def visit_type_list(self, t: TypeList) -> Type:
        assert False, 'Not supported'
    
    def visit_any(self, t: AnyType) -> Type:
        return t
    
    def visit_void(self, t: Void) -> Type:
        if isinstance(self.s, Void):
            return t
        else:
            return ErrorType()
    
    def visit_none_type(self, t: NoneTyp) -> Type:
        if not isinstance(self.s, Void) and not isinstance(self.s, ErrorType):
            return t
        else:
            return ErrorType()

    def visit_erased_type(self, t: ErasedType) -> Type:
        return self.s
    
    def visit_type_var(self, t: TypeVar) -> Type:
        if isinstance(self.s, TypeVar) and (cast(TypeVar, self.s)).id == t.id:
            return self.s
        else:
            return self.default(self.s)
    
    def visit_instance(self, t: Instance) -> Type:
        if isinstance(self.s, Instance):
            si = cast(Instance, self.s)
            if t.type == si.type:
                if is_subtype(t, self.s):
                    # Combine type arguments. We could have used join below
                    # equivalently.
                    args = [] # type: List[Type]
                    for i in range(len(t.args)):
                        args.append(self.meet(t.args[i], si.args[i]))
                    return Instance(t.type, args)
                else:
                    return NoneTyp()
            else:
                if is_subtype(t, self.s):
                    return t
                elif is_subtype(self.s, t):
                    # See also above comment.
                    return self.s
                else:
                    return NoneTyp()
        else:
            return self.default(self.s)
    
    def visit_callable(self, t: Callable) -> Type:
        if isinstance(self.s, Callable) and is_similar_callables(
                                                   t, cast(Callable, self.s)):
            return combine_similar_callables(t, cast(Callable, self.s),
                                             self.basic)
        else:
            return self.default(self.s)
    
    def visit_tuple_type(self, t: TupleType) -> Type:
        if isinstance(self.s, TupleType) and (
                             cast(TupleType, self.s).length() == t.length()):
            items = [] # type: List[Type]
            for i in range(t.length()):
                items.append(self.meet(t.items[i],
                                       (cast(TupleType, self.s)).items[i]))
            return TupleType(items)
        else:
            return self.default(self.s)
    
    def visit_intersection(self, t):
        # TODO Obsolete; target overload types instead?
        # Only support very rudimentary meets between intersection types.
        if is_same_type(self.s, t):
            return self.s
        else:
            return self.default(self.s)
    
    def meet(self, s, t):
        return meet_types(s, t, self.basic)
    
    def default(self, typ):
        if isinstance(typ, UnboundType):
            return AnyType()
        elif isinstance(typ, Void) or isinstance(typ, ErrorType):
            return ErrorType()
        else:
            return NoneTyp()

########NEW FILE########
__FILENAME__ = messages
"""Facilities and constants for generating error messages during type checking.

The type checker itself does not deal with message string literals to
improve code clarity and to simplify localization (in the future)."""

import re

from typing import Undefined, cast, List, Any, Sequence, Iterable

from mypy.errors import Errors
from mypy.types import (
    Type, Callable, Instance, TypeVar, TupleType, Void, NoneTyp, AnyType,
    Overloaded, FunctionLike
)
from mypy.nodes import (
    TypeInfo, Context, op_methods, FuncDef, reverse_type_aliases
)


# Constants that represent simple type checker error message, i.e. messages
# that do not have any parameters.

NO_RETURN_VALUE_EXPECTED = 'No return value expected'
INCOMPATIBLE_RETURN_VALUE_TYPE = 'Incompatible return value type'
RETURN_VALUE_EXPECTED = 'Return value expected'
BOOLEAN_VALUE_EXPECTED = 'Boolean value expected'
BOOLEAN_EXPECTED_FOR_IF = 'Boolean value expected for if condition'
BOOLEAN_EXPECTED_FOR_WHILE = 'Boolean value expected for while condition'
BOOLEAN_EXPECTED_FOR_UNTIL = 'Boolean value expected for until condition'
BOOLEAN_EXPECTED_FOR_NOT = 'Boolean value expected for not operand'
INVALID_EXCEPTION = 'Exception must be derived from BaseException'
INVALID_EXCEPTION_TYPE = 'Exception type must be derived from BaseException'
INVALID_RETURN_TYPE_FOR_YIELD = \
                         'Iterator function return type expected for "yield"'
INCOMPATIBLE_TYPES = 'Incompatible types'
INCOMPATIBLE_TYPES_IN_ASSIGNMENT = 'Incompatible types in assignment'
INIT_MUST_NOT_HAVE_RETURN_TYPE = 'Cannot define return type for "__init__"'
GETTER_TYPE_INCOMPATIBLE_WITH_SETTER = \
                                     'Type of getter incompatible with setter'
TUPLE_INDEX_MUST_BE_AN_INT_LITERAL = 'Tuple index must an integer literal'
TUPLE_INDEX_OUT_OF_RANGE = 'Tuple index out of range'
TYPE_CONSTANT_EXPECTED = 'Type "Constant" or initializer expected'
INCOMPATIBLE_PAIR_ITEM_TYPE = 'Incompatible Pair item type'
INVALID_TYPE_APPLICATION_TARGET_TYPE = 'Invalid type application target type'
INCOMPATIBLE_TUPLE_ITEM_TYPE = 'Incompatible tuple item type'
INCOMPATIBLE_KEY_TYPE = 'Incompatible dictionary key type'
INCOMPATIBLE_VALUE_TYPE = 'Incompatible dictionary value type'
NEED_ANNOTATION_FOR_VAR = 'Need type annotation for variable'
ITERABLE_EXPECTED = 'Iterable expected'
INCOMPATIBLE_TYPES_IN_FOR = 'Incompatible types in for statement'
INCOMPATIBLE_ARRAY_VAR_ARGS = 'Incompatible variable arguments in call'
INVALID_SLICE_INDEX = 'Slice index must be an integer or None'
CANNOT_INFER_LAMBDA_TYPE = 'Cannot infer type of lambda'
CANNOT_INFER_ITEM_TYPE = 'Cannot infer iterable item type'
CANNOT_ACCESS_INIT = 'Cannot access "__init__" directly'
CANNOT_ASSIGN_TO_METHOD = 'Cannot assign to a method'
CANNOT_ASSIGN_TO_TYPE = 'Cannot assign to a type'
INCONSISTENT_ABSTRACT_OVERLOAD = \
              'Overloaded method has both abstract and non-abstract variants'
INSTANCE_LAYOUT_CONFLICT = 'Instance layout conflict in multiple inheritance'


class MessageBuilder:
    """Helper class for reporting type checker error messages with parameters.
    
    The methods of this class need to be provided with the context within a
    file; the errors member manages the wider context.
    
    IDEA: Support a 'verbose mode' that includes full information about types
          in error messages and that may otherwise produce more detailed error
          messages.
    """
    
    # Report errors using this instance. It knows about the current file and
    # import context.
    errors = Undefined(Errors)
    
    # Number of times errors have been disabled.
    disable_count = 0
    
    def __init__(self, errors: Errors) -> None:
        self.errors = errors
        self.disable_count = 0

    #
    # Helpers
    #

    def copy(self) -> 'MessageBuilder':
        return MessageBuilder(self.errors.copy())

    def add_errors(self, messages: 'MessageBuilder') -> None:
        """Add errors in messages to this builder."""
        self.errors.error_info.extend(messages.errors.error_info)

    def disable_errors(self) -> None:
        self.disable_count += 1

    def enable_errors(self) -> None:
        self.disable_count -= 1

    def is_errors(self) -> bool:
        return self.errors.is_errors()
    
    def fail(self, msg: str, context: Context) -> None:
        """Report an error message (unless disabled)."""
        if self.disable_count <= 0:
            self.errors.report(context.get_line(), msg.strip())
    
    def format(self, typ: Type) -> str:
        """Convert a type to a relatively short string that is
        suitable for error messages. Mostly behave like format_simple
        below, but never return an empty string.
        """
        s = self.format_simple(typ)
        if s != '':
            # If format_simple returns a non-trivial result, use that.
            return s
        elif isinstance(typ, FunctionLike):
            func = cast(FunctionLike, typ)
            if func.is_type_obj():
                # The type of a type object type can be derived from the
                # return type (this always works).
                itype = cast(Instance, func.items()[0].ret_type)
                return self.format(itype)                
            else:
                # Use a simple representation for function types; proper
                # function types may result in long and difficult-to-read
                # error messages.
                return 'function'
        else:
            # Default case; we simply have to return something meaningful here.
            return 'object'
    
    def format_simple(self, typ: Type) -> str:
        """Convert simple types to string that is suitable for error messages.
        
        Return "" for complex types. Try to keep the length of the result
        relatively short to avoid overly long error messages.
        
        Examples:
          builtins.int -> 'int'
          Any type -> 'Any'
          void -> None
          function type -> "" (empty string)
        """
        if isinstance(typ, Instance):
            itype = cast(Instance, typ)
            # Get the short name of the type.
            base_str = itype.type.name()
            if itype.args == []:
                # No type arguments. Place the type name in quotes to avoid
                # potential for confusion: otherwise, the type name could be
                # interpreted as a normal word.
                return '"{}"'.format(base_str)
            elif itype.type.fullname() in reverse_type_aliases:
                alias = reverse_type_aliases[itype.type.fullname()]
                alias = alias.split('.')[-1]
                items = [strip_quotes(self.format(arg)) for arg in itype.args]
                return '{}[{}]'.format(alias, ', '.join(items))
            else:
                # There are type arguments. Convert the arguments to strings
                # (using format() instead of format_simple() to avoid empty
                # strings). If the result is too long, replace arguments
                # with [...].
                a = [] # type: List[str]
                for arg in itype.args:
                    a.append(strip_quotes(self.format(arg)))
                s = ', '.join(a)
                if len((base_str + s)) < 25:
                    return '{}[{}]'.format(base_str, s)
                else:
                    return '{}[...]'.format(base_str)
        elif isinstance(typ, TypeVar):
            # This is similar to non-generic instance types.
            return '"{}"'.format((cast(TypeVar, typ)).name)
        elif isinstance(typ, TupleType):
            items = []
            for t in (cast(TupleType, typ)).items:
                items.append(strip_quotes(self.format(t)))
            s = '"Tuple[{}]"'.format(', '.join(items))
            if len(s) < 30:
                return s
            else:
                return 'tuple'
        elif isinstance(typ, Void):
            return 'None'
        elif isinstance(typ, NoneTyp):
            return 'None'
        elif isinstance(typ, AnyType):
            return '"Any"'
        elif typ is None:
            raise RuntimeError('Type is None')
        else:
            # No simple representation for this type that would convey very
            # useful information. No need to mention the type explicitly in a
            # message.
            return ''

    #
    # Specific operations
    #
    
    # The following operations are for genering specific error messages. They
    # get some information as arguments, and they build an error message based
    # on them.
    
    def has_no_attr(self, typ: Type, member: str, context: Context) -> Type:
        """Report a missing or non-accessible member.

        The type argument is the base type. If member corresponds to
        an operator, use the corresponding operator name in the
        messages. Return type Any.
        """
        if (isinstance(typ, Instance) and
                (cast(Instance, typ)).type.has_readable_member(member)):
            self.fail('Member "{}" is not assignable'.format(member), context)
        elif isinstance(typ, Void):
            self.check_void(typ, context)
        elif member == '__contains__':
            self.fail('Unsupported right operand type for in ({})'.format(
                self.format(typ)), context)
        elif member in op_methods.values():
            # Access to a binary operator member (e.g. _add). This case does
            # not handle indexing operations.
            for op, method in op_methods.items():
                if method == member:
                    self.unsupported_left_operand(op, typ, context)
                    break
        elif member == '__neg__':
            self.fail('Unsupported operand type for unary - ({})'.format(
                self.format(typ)), context)
        elif member == '__invert__':
            self.fail('Unsupported operand type for ~ ({})'.format(
                self.format(typ)), context)
        elif member == '__getitem__':
            # Indexed get.
            self.fail('Value of type {} is not indexable'.format(
                self.format(typ)), context)
        elif member == '__setitem__':
            # Indexed set.
            self.fail('Unsupported target for indexed assignment', context)
        else:
            # The non-special case: a missing ordinary attribute.
            self.fail('{} has no attribute "{}"'.format(self.format(typ),
                                                        member), context)
        return AnyType()
    
    def unsupported_operand_types(self, op: str, left_type: Any,
                                  right_type: Any, context: Context) -> None:
        """Report unsupported operand types for a binary operation.
        
        Types can be Type objects or strings.
        """
        if isinstance(left_type, Void) or isinstance(right_type, Void):
            self.check_void(left_type, context)
            self.check_void(right_type, context)
            return 
        
        left_str = ''
        if isinstance(left_type, str):
            left_str = left_type
        else:
            left_str = self.format(left_type)
        
        right_str = ''
        if isinstance(right_type, str):
            right_str = right_type
        else:
            right_str = self.format(right_type)
        
        msg = 'Unsupported operand types for {} ({} and {})'.format(
                                                    op, left_str, right_str)
        self.fail(msg, context)
    
    def unsupported_left_operand(self, op: str, typ: Type,
                                 context: Context) -> None:
        if not self.check_void(typ, context):
            self.fail('Unsupported left operand type for {} ({})'.format(
                op, self.format(typ)), context)
    
    def type_expected_as_right_operand_of_is(self, context: Context) -> None:
        self.fail('Type expected as right operand of "is"', context)
    
    def not_callable(self, typ: Type, context: Context) -> Type:
        self.fail('{} not callable'.format(self.format(typ)), context)
        return AnyType()
    
    def incompatible_argument(self, n: int, callee: Callable, arg_type: Type,
                              context: Context) -> None:
        """Report an error about an incompatible argument type.

        The argument type is arg_type, argument number is n and the
        callee type is 'callee'. If the callee represents a method
        that corresponds to an operator, use the corresponding
        operator name in the messages.
        """
        target = ''
        if callee.name:
            name = callee.name
            base = extract_type(name)
            
            for op, method in op_methods.items():
                for variant in method, '__r' + method[2:]:
                    if name.startswith('"{}" of'.format(variant)):
                        if op == 'in' or variant != method:
                            # Reversed order of base/argument.
                            self.unsupported_operand_types(op, arg_type, base,
                                                           context)
                        else:
                            self.unsupported_operand_types(op, base, arg_type,
                                                           context)
                        return 
            
            if name.startswith('"__getitem__" of'):
                self.invalid_index_type(arg_type, base, context)
                return 
            
            if name.startswith('"__setitem__" of'):
                if n == 1:
                    self.invalid_index_type(arg_type, base, context)
                else:
                    self.fail(INCOMPATIBLE_TYPES_IN_ASSIGNMENT, context)
                return 
            
            target = 'to {} '.format(name)
        
        msg = ''
        if callee.name == '<list>':
            name = callee.name[1:-1]
            msg = '{} item {} has incompatible type {}'.format(
                name[0].upper() + name[1:], n, self.format_simple(arg_type))
        elif callee.name == '<list-comprehension>':
            msg = 'List comprehension has incompatible type List[{}]'.format(
                                  strip_quotes(self.format(arg_type)))
        elif callee.name == '<generator>':
            msg = 'Generator has incompatible item type {}'.format(
                                              self.format_simple(arg_type))
        else:
            msg = 'Argument {} {}has incompatible type {}'.format(
                n, target, self.format_simple(arg_type))
        self.fail(msg, context)
    
    def invalid_index_type(self, index_type: Type, base_str: str,
                           context: Context) -> None:
        self.fail('Invalid index type {} for {}'.format(
            self.format(index_type), base_str), context)
    
    def invalid_argument_count(self, callee: Callable, num_args: int,
                               context: Context) -> None:
        if num_args < len(callee.arg_types):
            self.too_few_arguments(callee, context)
        else:
            self.too_many_arguments(callee, context)
    
    def too_few_arguments(self, callee: Callable, context: Context) -> None:
        msg = 'Too few arguments'
        if callee.name:
            msg += ' for {}'.format(callee.name)
        self.fail(msg, context)
    
    def too_many_arguments(self, callee: Callable, context: Context) -> None:
        msg = 'Too many arguments'
        if callee.name:
            msg += ' for {}'.format(callee.name)
        self.fail(msg, context)
    
    def too_many_positional_arguments(self, callee: Callable,
                                      context: Context) -> None:
        msg = 'Too many positional arguments'
        if callee.name:
            msg += ' for {}'.format(callee.name)
        self.fail(msg, context)

    def unexpected_keyword_argument(self, callee: Callable, name: str,
                                    context: Context) -> None:
        msg = 'Unexpected keyword argument "{}"'.format(name)
        if callee.name:
            msg += ' for {}'.format(callee.name)
        self.fail(msg, context)            

    def duplicate_argument_value(self, callee: Callable, index: int,
                                 context: Context) -> None:
        self.fail('{} gets multiple values for keyword argument "{}"'.
                  format(capitalize(callable_name(callee)),
                         callee.arg_names[index]), context)
    
    def does_not_return_value(self, void_type: Type, context: Context) -> None:
        """Report an error about a void type in a non-void context.

        The first argument must be a void type. If the void type has a
        source in it, report it in the error message. This allows
        giving messages such as 'Foo does not return a value'.
        """
        if (cast(Void, void_type)).source is None:
            self.fail('Function does not return a value', context)
        else:
            self.fail('{} does not return a value'.format(
                capitalize((cast(Void, void_type)).source)), context)
    
    def no_variant_matches_arguments(self, overload: Overloaded,
                                      context: Context) -> None:
        if overload.name():
            self.fail('No overload variant of {} matches argument types'
                      .format(overload.name()), context)
        else:
            self.fail('No overload variant matches argument types', context)
    
    def function_variants_overlap(self, n1: int, n2: int,
                                  context: Context) -> None:
        self.fail('Function signature variants {} and {} overlap'.format(
            n1 + 1, n2 + 1), context)
    
    def invalid_cast(self, target_type: Type, source_type: Type,
                      context: Context) -> None:
        if not self.check_void(source_type, context):
            self.fail('Cannot cast from {} to {}'.format(
                self.format(source_type), self.format(target_type)), context)
    
    def incompatible_operator_assignment(self, op: str,
                                         context: Context) -> None:
        self.fail('Result type of {} incompatible in assignment'.format(op),
                  context)
    
    def incompatible_value_count_in_assignment(self, lvalue_count: int,
                                               rvalue_count: int,
                                               context: Context) -> None:
        if rvalue_count < lvalue_count:
            self.fail('Need {} values to assign'.format(lvalue_count), context)
        elif rvalue_count > lvalue_count:
            self.fail('Too many values to assign', context)
    
    def type_incompatible_with_supertype(self, name: str, supertype: TypeInfo,
                                          context: Context) -> None:
        self.fail('Type of "{}" incompatible with supertype "{}"'.format(
            name, supertype.name), context)
    
    def signature_incompatible_with_supertype(
            self, name: str, name_in_super: str, supertype: str,
            context: Context) -> None:
        target = self.override_target(name, name_in_super, supertype)
        self.fail('Signature of "{}" incompatible with {}'.format(
            name, target), context)
    
    def argument_incompatible_with_supertype(
            self, arg_num: int, name: str, name_in_supertype: str,
            supertype: str, context: Context) -> None:
        target = self.override_target(name, name_in_supertype, supertype)
        self.fail('Argument {} of "{}" incompatible with {}'
                  .format(arg_num, name, target), context)
    
    def return_type_incompatible_with_supertype(
            self, name: str, name_in_supertype: str, supertype: str,
            context: Context) -> None:
        target = self.override_target(name, name_in_supertype, supertype)
        self.fail('Return type of "{}" incompatible with {}'
                  .format(name, target), context)

    def override_target(self, name: str, name_in_super: str,
                        supertype: str) -> str:
        target = 'supertype "{}"'.format(supertype)
        if name_in_super != name:
            target = '"{}" of {}'.format(name_in_super, target)
        return target        
    
    def boolean_return_value_expected(self, method: str,
                                      context: Context) -> None:
        self.fail('Boolean return value expected for method "{}"'.format(
            method), context)
    
    def incompatible_type_application(self, expected_arg_count: int,
                                      actual_arg_count: int,
                                      context: Context) -> None:
        if expected_arg_count == 0:
            self.fail('Type application targets a non-generic function',
                      context)
        elif actual_arg_count > expected_arg_count:
            self.fail('Type application has too many types ({} expected)'
                      .format(expected_arg_count), context)
        else:
            self.fail('Type application has too few types ({} expected)'
                      .format(expected_arg_count), context)
    
    def incompatible_array_item_type(self, typ: Type, index: int,
                                     context: Context) -> None:
        self.fail('Array item {} has incompatible type {}'.format(
            index, self.format(typ)), context)
    
    def could_not_infer_type_arguments(self, callee_type: Callable, n: int,
                                       context: Context) -> None:
        if callee_type.name and n > 0:
            self.fail('Cannot infer type argument {} of {}'.format(
                n, callee_type.name), context)
        else:
            self.fail('Cannot infer function type argument', context)
    
    def invalid_var_arg(self, typ: Type, context: Context) -> None:
        self.fail('List or tuple expected as variable arguments', context)
    
    def invalid_keyword_var_arg(self, typ: Type, context: Context) -> None:
        if isinstance(typ, Instance) and (
                (cast(Instance, typ)).type.fullname() == 'builtins.dict'):
            self.fail('Keywords must be strings', context)
        else:
            self.fail('Argument after ** must be a dictionary',
                      context)
    
    def incomplete_type_var_match(self, member: str, context: Context) -> None:
        self.fail('"{}" has incomplete match to supertype type variable'
                  .format(member), context)
    
    def not_implemented(self, msg: str, context: Context) -> Type:
        self.fail('Feature not implemented yet ({})'.format(msg), context)
        return AnyType()
    
    def undefined_in_superclass(self, member: str, context: Context) -> None:
        self.fail('"{}" undefined in superclass'.format(member), context)
    
    def check_void(self, typ: Type, context: Context) -> bool:
        """If type is void, report an error such as '.. does not
        return a value' and return True. Otherwise, return False.
        """
        if isinstance(typ, Void):
            self.does_not_return_value(typ, context)
            return True
        else:
            return False

    def cannot_determine_type(self, name: str, context: Context) -> None:
        self.fail("Cannot determine type of '%s'" % name, context)

    def invalid_method_type(self, sig: Callable, context: Context) -> None:
        self.fail('Invalid method type', context)

    def incompatible_conditional_function_def(self, defn: FuncDef) -> None:
        self.fail('All conditional function variants must have identical '
                  'signatures', defn)

    def cannot_instantiate_abstract_class(self, class_name: str,
                                          abstract_attributes: List[str],
                                          context: Context) -> None:
        attrs = format_string_list("'%s'" % a for a in abstract_attributes[:5])
        self.fail("Cannot instantiate abstract class '%s' with abstract "
                  "method%s %s" % (class_name, plural_s(abstract_attributes),
                                   attrs),
                  context)

    def base_class_definitions_incompatible(self, name: str, base1: TypeInfo,
                                            base2: TypeInfo,
                                            context: Context) -> None:
        self.fail('Definition of "{}" in base class "{}" is incompatible '
                  'with definition in base class "{}"'.format(
                      name, base1.name(), base2.name()), context)

    def read_only_property(self, name: str, type: TypeInfo,
                           context: Context) -> None:
        self.fail('Property "{}" defined in "{}" is read-only'.format(
            name, type.name()), context)

    def incompatible_typevar_value(self, callee: Callable, index: int,
                                   type: Type, context: Context) -> None:
        self.fail('Type argument {} of {} has incompatible value {}'.format(
            index, callable_name(callee), self.format(type)), context)

    def disjointness_violation(self, cls: TypeInfo, disjoint: TypeInfo,
                               context: Context) -> None:
        self.fail('disjointclass constraint of class {} disallows {} as a '
                  'base class'.format(cls.name(), disjoint.name()), context)

    def overloaded_signatures_overlap(self, index1: int, index2: int,
                                      context: Context) -> None:
        self.fail('Overloaded function signatures {} and {} overlap with '
                  'incompatible return types'.format(index1, index2), context)

    def invalid_reverse_operator_signature(self, reverse: str, other: str,
                                           context: Context) -> None:
        self.fail('"Any" return type expected since argument to {} does not '
                  'support {}'.format(reverse, other), context)

    def reverse_operator_method_with_any_arg_must_return_any(
            self, method: str, context: Context) -> None:
        self.fail('"Any" return type expected since argument to {} has type '
                  '"Any"'.format(method), context)

    def operator_method_signatures_overlap(
            self, reverse_class: str, reverse_method: str, forward_class: str,
            forward_method: str, context: Context) -> None:
        self.fail('Signatures of "{}" of "{}" and "{}" of "{}" are unsafely '
                  'overlapping'.format(reverse_method, reverse_class,
                                       forward_method, forward_class), context)

    def signatures_incompatible(self, method: str, other_method: str,
                                context: Context) -> None:
        self.fail('Signatures of "{}" and "{}" are incompatible'.format(
            method, other_method), context)


def capitalize(s: str) -> str:
    """Capitalize the first character of a string."""
    if s == '':
        return ''
    else:
        return s[0].upper() + s[1:]


def extract_type(name: str) -> str:
    """If the argument is the name of a method (of form C.m), return
    the type portion in quotes (e.g. "y"). Otherwise, return the string
    unmodified.
    """
    name = re.sub('^"[a-zA-Z0-9_]+" of ', '', name)
    return name


def strip_quotes(s: str) -> str:
    """Strip a double quote at the beginning and end of the string, if any."""
    s = re.sub('^"', '', s)
    s = re.sub('"$', '', s)
    return s


def plural_s(s: Sequence[Any]) -> str:
    if len(s) > 1:
        return 's'
    else:
        return ''


def format_string_list(s: Iterable[str]) -> str:
    l = list(s)
    assert len(l) > 0
    if len(l) == 1:
        return l[0]
    else:
        return '%s and %s' % (', '.join(l[:-1]), l[-1])


def callable_name(type: Callable) -> str:
    if type.name:
        return type.name
    else:
        return 'function'

########NEW FILE########
__FILENAME__ = myunit
import sys
import re
import time
import traceback

from typing import List, Tuple, Any, Function, overload, Undefined


# TODO remove global state
is_verbose = False
is_quiet = False
patterns = List[str]()
times = List[Tuple[float, str]]()


class AssertionFailure(Exception):
    """Exception used to signal skipped test cases."""
    def __init__(self, s: str = None) -> None:
        if s:
            super().__init__(s)
        else:
            super().__init__()


class SkipTestCaseException(Exception): pass


def assert_true(b: bool, msg: str = None) -> None:
    if not b:
        raise AssertionFailure(msg)


def assert_false(b: bool, msg: str = None) -> None:
    if b:
        raise AssertionFailure(msg)


def assert_equal(a: object, b: object, fmt: str = '{} != {}') -> None:
    if a != b:
        raise AssertionFailure(fmt.format(repr(a), repr(b)))


def assert_not_equal(a: object, b: object, fmt: str = '{} == {}') -> None:
    if a == b:
        raise AssertionFailure(fmt.format(repr(a), repr(b)))


def assert_raises(typ: type, *rest: Any) -> None:
    """Usage: assert_raises(exception class[, message], function[, args])
    
    Call function with the given arguments and expect an exception of the given
    type.
    
    TODO use overloads for better type checking
    """
    # Parse arguments.
    msg = None # type: str
    if isinstance(rest[0], str) or rest[0] is None:
        msg = rest[0]
        rest = rest[1:]
    f = rest[0]
    args = [] # type: List[Any]
    if len(rest) > 1:
        args = rest[1]
        assert len(rest) <= 2
    
    # Perform call and verify the exception.
    try:
        f(*args)
    except Exception as e:
        assert_type(typ, e)
        if msg:
            assert_equal(e.args[0], msg, 'Invalid message {}, expected {}')
    else:
        raise AssertionFailure('No exception raised')


def assert_type(typ: type, value: object) -> None:
    if type(value) != typ:
        raise AssertionFailure('Invalid type {}, expected {}'.format(
            typename(type(value)), typename(typ)))


def fail() -> None:
    raise AssertionFailure()


class TestCase:
    def __init__(self, name: str, suite: 'Suite' = None,
                 func: Function[[], None] = None) -> None:
        self.func = func
        self.name = name
        self.suite = suite
    
    def run(self) -> None:
        if self.func:
            self.func()
    
    def set_up(self) -> None:
        if self.suite:
            self.suite.set_up()
    
    def tear_down(self) -> None:
        if self.suite:
            self.suite.tear_down()


class Suite:
    def __init__(self) -> None:
        self.prefix = typename(type(self)) + '.'
        # Each test case is either a TestCase object or (str, function).
        self._test_cases = [] # type: List[Any]
        self.init()
    
    def set_up(self) -> None:
        pass
    
    def tear_down(self) -> None:
        pass
    
    def init(self) -> None:
        for m in dir(self):
            if m.startswith('test'):
                t = getattr(self, m)
                if isinstance(t, Suite):
                    self.add_test((m + '.', t))
                else:
                    self.add_test(TestCase(m, self, getattr(self, m)))
    
    @overload
    def add_test(self, test: TestCase) -> None:
        self._test_cases.append(test)
    
    @overload
    def add_test(self, test: Tuple[str, Function[[], None]]) -> None:
        self._test_cases.append(test)
    
    @overload
    def add_test(self, test: Tuple[str, 'Suite']) -> None:
        self._test_cases.append(test)
    
    def cases(self) -> List[Any]:
        return self._test_cases[:]
    
    def skip(self) -> None:
        raise SkipTestCaseException()


def run_test(t: Suite, args: List[str] = None) -> None:
    global patterns, is_verbose, is_quiet
    if not args:
        args = []
    is_verbose = False
    is_quiet = False
    patterns = []
    i = 0
    while i < len(args):
        a = args[i]
        if a == '-v':
            is_verbose = True
        elif a == '-q':
            is_quiet = True
        elif len(a) > 0 and a[0] != '-':
            patterns.append(a)
        else:
            raise ValueError('Invalid arguments')
        i += 1
    if len(patterns) == 0:
        patterns.append('*')
    
    num_total, num_fail, num_skip = run_test_recursive(t, 0, 0, 0, '', 0)
    
    skip_msg = ''
    if num_skip > 0:
        skip_msg = ', {} skipped'.format(num_skip)
    
    if num_fail == 0:
        if not is_quiet:
            print('%d test cases run%s, all passed.' % (num_total, skip_msg))
            print('*** OK ***')
    else:
        sys.stderr.write('%d/%d test cases failed%s.\n' % (num_fail,
                                                           num_total,
                                                           skip_msg))
        sys.stderr.write('*** FAILURE ***\n')


def run_test_recursive(test: Any, num_total: int, num_fail: int, num_skip: int,
                       prefix: str, depth: int) -> Tuple[int, int, int]:
    """The first argument may be TestCase, Suite or (str, Suite)."""
    if isinstance(test, TestCase):
        name = prefix + test.name
        for pattern in patterns:
            if match_pattern(name, pattern):
                match = True
                break
        else:
            match = False
        if match:
            is_fail, is_skip = run_single_test(name, test)
            if is_fail: num_fail += 1
            if is_skip: num_skip += 1
            num_total += 1
    else:
        suite = Undefined # type: Suite
        suite_prefix = ''
        if isinstance(test, list) or isinstance(test, tuple):
            suite = test[1]
            suite_prefix = test[0]
        else:
            suite = test
            suite_prefix = test.prefix
        
        for stest in suite.cases():
            new_prefix = prefix
            if depth > 0:
                new_prefix = prefix + suite_prefix
            num_total, num_fail, num_skip = run_test_recursive(
                stest, num_total, num_fail, num_skip, new_prefix, depth + 1)
    return num_total, num_fail, num_skip


def run_single_test(name: str, test: Any) -> Tuple[bool, bool]:
    if is_verbose:
        sys.stderr.write(name)
        sys.stderr.flush()

    time0 = time.time()
    test.set_up() # FIX: check exceptions
    try:
        test.run()
    except Exception:
        exc_type, exc_value, exc_traceback = sys.exc_info()
    else:
        exc_traceback = None
    test.tear_down() # FIX: check exceptions
    times.append((time.time() - time0, name))

    if exc_traceback:
        if isinstance(exc_value, SkipTestCaseException):
            if is_verbose:
                sys.stderr.write(' (skipped)\n')
            return False, True
        else:
            handle_failure(name, exc_type, exc_value, exc_traceback)
            return True, False
    elif is_verbose:
        sys.stderr.write('\n')
        
    return False, False


def handle_failure(name, exc_type, exc_value, exc_traceback) -> None:
    # Report failed test case.
    if is_verbose:
        sys.stderr.write('\n\n')
    msg = ''
    if exc_value.args and exc_value.args[0]:
        msg = ': ' + str(exc_value)
    else:
        msg = ''
    sys.stderr.write('Traceback (most recent call last):\n')
    tb = traceback.format_tb(exc_traceback)
    tb = clean_traceback(tb)
    for s in tb:
        sys.stderr.write(s)
    exception = typename(exc_type)
    sys.stderr.write('{}{}\n\n'.format(exception, msg))
    sys.stderr.write('{} failed\n\n'.format(name))


def typename(t: type) -> str:
    if '.' in str(t):
        return str(t).split('.')[-1].rstrip("'>")
    else:
        return str(t)[8:-2]


def match_pattern(s: str, p: str) -> bool:
    if len(p) == 0:
        return len(s) == 0
    elif p[0] == '*':
        if len(p) == 1:
            return True
        else:
            for i in range(len(s) + 1):
                if match_pattern(s[i:], p[1:]):
                    return True
            return False
    elif len(s) == 0:
        return False
    else:
        return s[0] == p[0] and match_pattern(s[1:], p[1:])


def clean_traceback(tb: List[str]) -> List[str]:
    # Remove clutter from the traceback.
    start = 0
    for i, s in enumerate(tb):
        if '\n    test.run()\n' in s or '\n    self.func()\n' in s:
            start = i + 1
    tb = tb[start:]
    for f in ['assert_equal', 'assert_not_equal', 'assert_type',
              'assert_raises', 'assert_true']:
        if tb != [] and ', in {}\n'.format(f) in tb[-1]:
            tb = tb[:-1]
    return tb

########NEW FILE########
__FILENAME__ = noderepr
"""Classes for storing the lexical token information of nodes.

This is used for outputting the original source code represented by the nodes
(including original formatting and comments).

Each node representation usually only contains tokens directly associated
with that node (terminals). All members are Tokens or lists of Tokens,
unless explicitly mentioned otherwise.

If a representation has a Break token, the member name is br.
"""

from typing import Any, List, Tuple, Undefined

from mypy.lex import Token


class MypyFileRepr:
    def __init__(self, eof):
        self.eof = eof


class ImportRepr:
    def __init__(self, import_tok: Any, components: List[List[Token]],
                 as_names: List[Tuple[Token, Token]], commas: List[Token],
                 br: Any) -> None:
        self.import_tok = import_tok
        self.components = components
        self.as_names = as_names
        self.commas = commas
        self.br = br


class ImportFromRepr:
    def __init__(self,
                 from_tok: Any,
                 components: List[Token],
                 import_tok: Any,
                 lparen: Any,
                 names: List[Tuple[List[Token], Token]],
                 rparen: Any, br: Any) -> None:
        # Notes:
        # - lparen and rparen may be empty
        # - in each names tuple, the first item contains tokens for
        #   'name [as name]' and the second item is a comma or empty.
        self.from_tok = from_tok
        self.components = components
        self.import_tok = import_tok
        self.lparen = lparen
        self.names = names
        self.rparen = rparen
        self.br = br


class FuncRepr:
    def __init__(self, def_tok: Any, name: Any, args: 'FuncArgsRepr') -> None:
        # Note: name may be empty.
        self.def_tok = def_tok
        self.name = name
        self.args = args


class FuncArgsRepr:
    """Representation of a set of function arguments."""
    def __init__(self, lseparator: Any, rseparator: Any, arg_names: Any,
                 commas: Any, assigns: Any, asterisk: Any) -> None:
        # Lseparator and rseparator are '(' and ')', respectively.
        self.lseparator = lseparator
        self.rseparator = rseparator
        self.arg_names = arg_names
        self.commas = commas
        self.assigns = assigns
        self.asterisk = asterisk


class VarRepr:
    def __init__(self, name: Any, comma: Any) -> None:
        # Note_ comma may be empty.
        self.name = name
        self.comma = comma


class TypeDefRepr:
    def __init__(self, class_tok: Any, name: Any, lparen: Any, commas: Any,
                 rparen: Any) -> None:
        self.class_tok = class_tok
        self.name = name
        self.lparen = lparen
        self.commas = commas
        self.rparen = rparen


class VarDefRepr:
    def __init__(self, assign: Any, br: Any) -> None:
        # Note: assign may be empty.
        self.assign = assign
        self.br = br


class DecoratorRepr:
    def __init__(self, ats: Any, brs: Any) -> None:
        self.ats = ats
        self.brs = brs


class BlockRepr:
    def __init__(self, colon: Any, br: Any, indent: Any, dedent: Any) -> None:
        self.colon = colon
        self.br = br
        self.indent = indent
        self.dedent = dedent


class GlobalDeclRepr:
    def __init__(self, global_tok: Any, names: List[Token],
                 commas: List[Token], br: Any) -> None:
        self.global_tok = global_tok
        self.names = names
        self.commas = commas
        self.br = br


class ExpressionStmtRepr:
    def __init__(self, br: Any) -> None:
        self.br = br


class AssignmentStmtRepr:
    def __init__(self, assigns: List[Token], br: Any) -> None:
        self.assigns = assigns
        self.br = br


class OperatorAssignmentStmtRepr:
    def __init__(self, assign: Any, br: Any) -> None:
        self.assign = assign
        self.br = br


class WhileStmtRepr:
    def __init__(self, while_tok: Any, else_tok: Any) -> None:
        self.while_tok = while_tok
        self.else_tok = else_tok


class ForStmtRepr:
    def __init__(self, for_tok: Any, commas: Any, in_tok: Any,
                 else_tok: Any) -> None:
        self.for_tok = for_tok
        self.commas = commas
        self.in_tok = in_tok
        self.else_tok = else_tok


class SimpleStmtRepr:
    """Representation for break, continue, pass, return and assert."""
    def __init__(self, keyword: Any, br: Any) -> None:
        self.keyword = keyword
        self.br = br


class IfStmtRepr:
    def __init__(self, if_tok: Any, elif_toks: Any, else_tok: Any) -> None:
        # Note: else_tok may be empty.
        self.if_tok = if_tok
        self.elif_toks = elif_toks
        self.else_tok = else_tok


class RaiseStmtRepr:
    def __init__(self, raise_tok: Any, from_tok: Any, br: Any) -> None:
        self.raise_tok = raise_tok
        self.from_tok = from_tok
        self.br = br


class TryStmtRepr:
    def __init__(self, try_tok: Any, except_toks: Any, name_toks: Any,
                 as_toks: Any, else_tok: Any, finally_tok: Any) -> None:
        self.try_tok = try_tok
        self.except_toks = except_toks
        self.name_toks = name_toks
        self.as_toks = as_toks
        self.else_tok = else_tok
        self.finally_tok = finally_tok


class WithStmtRepr:
    def __init__(self, with_tok: Any, as_toks: Any, commas: Any) -> None:
        self.with_tok = with_tok
        self.as_toks = as_toks
        self.commas = commas


class IntExprRepr:
    def __init__(self, int: Any) -> None:
        self.int = int


class StrExprRepr:
    def __init__(self, string: List[Token]) -> None:
        self.string = string


class FloatExprRepr:
    def __init__(self, float: Any) -> None:
        self.float = float


class ParenExprRepr:
    def __init__(self, lparen: Any, rparen: Any) -> None:
        self.lparen = lparen
        self.rparen = rparen


class NameExprRepr:
    def __init__(self, id: Any) -> None:
        self.id = id


class MemberExprRepr:
    def __init__(self, dot: Any, name: Any) -> None:
        self.dot = dot
        self.name = name


class CallExprRepr:
    def __init__(self, lparen: Any, commas: List[Token], star: Any, star2: Any,
                 keywords: List[List[Token]], rparen: Any) -> None:
        # Asterisk may be empty.
        self.lparen = lparen
        self.commas = commas
        self.star = star
        self.star2 = star2
        self.keywords = keywords
        self.rparen = rparen


class IndexExprRepr:
    def __init__(self, lbracket: Any, rbracket: Any) -> None:
        self.lbracket = lbracket
        self.rbracket = rbracket


class SliceExprRepr:
    def __init__(self, colon: Any, colon2: Any) -> None:
        self.colon = colon
        self.colon2 = colon2


class UnaryExprRepr:
    def __init__(self, op: Any) -> None:
        self.op = op


class OpExprRepr:
    def __init__(self, op: Any, op2: Any) -> None:
        # Note: op2 may be empty; it is used for "is not" and "not in".
        self.op = op
        self.op2 = op2


class CastExprRepr:
    def __init__(self, lparen: Any, rparen: Any) -> None:
        self.lparen = lparen
        self.rparen = rparen


class FuncExprRepr:
    def __init__(self, lambda_tok: Any, colon: Any, args: Any) -> None:
        self.lambda_tok = lambda_tok
        self.colon = colon
        self.args = args


class SuperExprRepr:
    def __init__(self, super_tok: Any, lparen: Any, rparen: Any, dot: Any,
                 name: Any) -> None:
        self.super_tok = super_tok
        self.lparen = lparen
        self.rparen = rparen
        self.dot = dot
        self.name = name


class ListSetExprRepr:
    # [...] or {...}
    def __init__(self, lbracket: Any, commas: List[Token], rbracket: Any,
                 langle: Any, rangle: Any) -> None:
        self.lbracket = lbracket
        self.commas = commas
        self.rbracket = rbracket
        self.langle = langle
        self.rangle = rangle


class TupleExprRepr:
    def __init__(self, lparen: Any, commas: List[Token], rparen: Any) -> None:
        # Note: lparen and rparen may be empty.
        self.lparen = lparen
        self.commas = commas
        self.rparen = rparen


class DictExprRepr:
    def __init__(self, lbrace: Any, colons: List[Token], commas: List[Token],
                 rbrace: Any, langle: Any, type_comma: Any,
                 rangle: Any) -> None:
        self.lbrace = lbrace
        self.colons = colons
        self.commas = commas
        self.rbrace = rbrace
        self.langle = langle
        self.type_comma = type_comma
        self.rangle = rangle


class TypeApplicationRepr:
    def __init__(self, langle: Any, commas: Any, rangle: Any) -> None:
        self.langle = langle
        self.commas = commas
        self.rangle = rangle


class GeneratorExprRepr:
    def __init__(self, for_tok: Any, commas: Any, in_tok: Any,
                 if_tok: Any) -> None:
        self.for_tok = for_tok
        self.commas = commas
        self.in_tok = in_tok
        self.if_tok = if_tok


class ListComprehensionRepr:
    def __init__(self, lbracket: Any, rbracket: Any) -> None:
        self.lbracket = lbracket
        self.rbracket = rbracket

########NEW FILE########
__FILENAME__ = nodes
"""Abstract syntax tree node classes (i.e. parse tree)."""

import re
from abc import abstractmethod, ABCMeta

from typing import (
    Any, overload, typevar, Undefined, List, Tuple, cast, Set, Dict
)

from mypy.lex import Token
import mypy.strconv
from mypy.visitor import NodeVisitor
from mypy.util import dump_tagged, short_type


class Context(metaclass=ABCMeta):
    """Base type for objects that are valid as error message locations."""
    #@abstractmethod
    def get_line(self) -> int: pass


import mypy.types


T = typevar('T')


# Variable kind constants
# TODO rename to use more descriptive names

LDEF = 0 # type: int
GDEF = 1 # type: int
MDEF = 2 # type: int
MODULE_REF = 3 # type: int
# Type variable declared using typevar(...) has kind UNBOUND_TVAR. It's not
# valid as a type. A type variable is valid as a type (kind TVAR) within 
# (1) a generic class that uses the type variable as a type argument or
# (2) a generic function that refers to the type variable in its signature.
UNBOUND_TVAR = 4 # type: 'int'
TVAR = 5 # type: int


node_kinds = {
    LDEF: 'Ldef',
    GDEF: 'Gdef',
    MDEF: 'Mdef',
    MODULE_REF: 'ModuleRef',
    UNBOUND_TVAR: 'UnboundTvar',
    TVAR: 'Tvar',
}


implicit_module_attrs = ['__name__', '__doc__', '__file__']


type_aliases = {
    'typing.List': '__builtins__.list',
    'typing.Dict': '__builtins__.dict',
    'typing.Set': '__builtins__.set',
}

reverse_type_aliases = dict((name.replace('__builtins__', 'builtins'), alias)
                            for alias, name in type_aliases.items())


class Node(Context):
    """Common base class for all non-type parse tree nodes."""
    
    line = -1
    # Textual representation
    repr = None # type: Any
    
    def __str__(self) -> str:
        return self.accept(mypy.strconv.StrConv())
    
    @overload
    def set_line(self, tok: Token) -> 'Node':
        self.line = tok.line
        return self
    
    @overload
    def set_line(self, line: int) -> 'Node':
        self.line = line
        return self

    def get_line(self) -> int:
        # TODO this should be just 'line'
        return self.line
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        raise RuntimeError('Not implemented')


class SymbolNode(Node):
    # Nodes that can be stored in a symbol table.
    
    # TODO do not use methods for these
    
    @abstractmethod
    def name(self) -> str: pass

    @abstractmethod
    def fullname(self) -> str: pass


class MypyFile(SymbolNode):
    """The abstract syntax tree of a single source file."""
    
    _name = None     # type: str    # Module name ('__main__' for initial file)
    _fullname = None # type: str    # Qualified module name
    path = ''        # Path to the file (None if not known)
    defs = Undefined # type: List[Node]  # Global definitions and statements
    is_bom = False   # Is there a UTF-8 BOM at the start?
    names = Undefined('SymbolTable')
    imports = Undefined(List[Node])    # All import nodes within the file
    
    def __init__(self, defs: List[Node], imports: List[Node],
                 is_bom: bool = False) -> None:
        self.defs = defs
        self.line = 1  # Dummy line number
        self.imports = imports
        self.is_bom = is_bom

    def name(self) -> str:
        return self._name

    def fullname(self) -> str:
        return self._fullname
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_mypy_file(self)


class Import(Node):
    """import m [as n]"""
    
    ids = Undefined(List[Tuple[str, str]])     # (module id, as id)
    
    def __init__(self, ids: List[Tuple[str, str]]) -> None:
        self.ids = ids
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_import(self)


class ImportFrom(Node):
    """from m import x, ..."""
    
    names = Undefined(List[Tuple[str, str]]) # Tuples (name, as name)
    
    def __init__(self, id: str, names: List[Tuple[str, str]]) -> None:
        self.id = id
        self.names = names
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_import_from(self)


class ImportAll(Node):
    """from m import *"""
    
    def __init__(self, id: str) -> None:
        self.id = id
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_import_all(self)


class FuncBase(SymbolNode):
    """Abstract base class for function-like nodes"""
    
    # Type signature (Callable or Overloaded)
    type = None # type: mypy.types.Type
    # If method, reference to TypeInfo
    info = None # type: TypeInfo

    @abstractmethod
    def name(self) -> str: pass
    
    def fullname(self) -> str:
        return self.name()
    
    def is_method(self) -> bool:
        return bool(self.info)


class OverloadedFuncDef(FuncBase):
    """A logical node representing all the variants of an overloaded function.

    This node has no explicit representation in the source program.
    Overloaded variants must be consecutive in the source file.
    """
    
    items = Undefined(List['Decorator'])
    _fullname = None # type: str
    
    def __init__(self, items: List['Decorator']) -> None:
        self.items = items
        self.set_line(items[0].line)
    
    def name(self) -> str:
        return self.items[1].func.name()

    def fullname(self) -> str:
        return self._fullname
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_overloaded_func_def(self)


class FuncItem(FuncBase):
    args = Undefined(List['Var'])    # Argument names
    arg_kinds = Undefined(List[int]) # Kinds of arguments (ARG_*)
    
    # Initialization expessions for fixed args; None if no initialiser
    init = Undefined(List['AssignmentStmt'])
    min_args = 0           # Minimum number of arguments
    max_pos = 0            # Maximum number of positional arguments, -1 if
                           # no explicit limit (*args not included)
    body = Undefined('Block')
    is_implicit = False    # Implicit dynamic types?
    is_overload = False    # Is this an overload variant of function with
                           # more than one overload variant?
    is_generator = False   # Contains a yield statement?
    expanded = Undefined(List['FuncItem'])  # Variants of function with type
                                            # variables with values expanded
    
    def __init__(self, args: List['Var'], arg_kinds: List[int],
                 init: List[Node], body: 'Block',
                 typ: 'mypy.types.Type' = None) -> None:
        self.args = args
        self.arg_kinds = arg_kinds
        self.max_pos = arg_kinds.count(ARG_POS) + arg_kinds.count(ARG_OPT)
        self.body = body
        self.type = typ
        self.expanded = []
        
        i2 = List[AssignmentStmt]()
        self.min_args = 0
        for i in range(len(init)):
            if init[i] is not None:
                rvalue = init[i]
                lvalue = NameExpr(args[i].name()).set_line(rvalue.line)
                assign = AssignmentStmt([lvalue], rvalue)
                assign.set_line(rvalue.line)
                i2.append(assign)
            else:
                i2.append(None)
                if i < self.max_fixed_argc():
                    self.min_args = i + 1
        self.init = i2
    
    def max_fixed_argc(self) -> int:
        return self.max_pos
    
    @overload
    def set_line(self, tok: Token) -> Node:
        super().set_line(tok)
        for n in self.args:
            n.line = self.line
        return self
    
    @overload
    def set_line(self, tok: int) -> Node:
        super().set_line(tok)
        for n in self.args:
            n.line = self.line
        return self
    
    def init_expressions(self) -> List[Node]:
        res = List[Node]()
        for i in self.init:
            if i is not None:
                res.append(i.rvalue)
            else:
                res.append(None)
        return res


class FuncDef(FuncItem):
    """Function definition.

    This is a non-lambda function defined using 'def'. 
    """
    
    _fullname = None # type: str       # Name with module prefix
    is_decorated = False
    is_conditional = False             # Defined conditionally (within block)?
    is_abstract = False
    is_static = False
    is_property = False
    original_def = None # type: FuncDef  # Original conditional definition
    
    def __init__(self,
                 name: str,              # Function name
                 args: List['Var'],      # Argument names
                 arg_kinds: List[int],   # Arguments kinds (nodes.ARG_*)
                 init: List[Node],       # Initializers (each may be None)
                 body: 'Block',
                 typ: 'mypy.types.Type' = None) -> None:
        super().__init__(args, arg_kinds, init, body, typ)
        self._name = name

    def name(self) -> str:
        return self._name
    
    def fullname(self) -> str:
        return self._fullname

    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_func_def(self)
    
    def is_constructor(self) -> bool:
        return self.info is not None and self._name == '__init__'

    def get_name(self) -> str:
        """TODO merge with name()"""
        return self._name


class Decorator(SymbolNode):
    """A decorated function.

    A single Decorator object can include any number of function decorators.
    """
    
    func = Undefined(FuncDef)          # Decorated function
    decorators = Undefined(List[Node]) # Decorators, at least one
    var = Undefined('Var')             # Represents the decorated function obj
    is_overload = False
    
    def __init__(self, func: FuncDef, decorators: List[Node],
                 var: 'Var') -> None:
        self.func = func
        self.decorators = decorators
        self.var = var
        self.is_overload = False

    def name(self) -> str:
        return self.func.name()

    def fullname(self) -> str:
        return self.func.fullname()

    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_decorator(self)


class Var(SymbolNode):
    """A variable.

    It can refer to global/local variable or a data attribute.
    """
    
    _name = None     # type: str   # Name without module prefix
    _fullname = None # type: str   # Name with module prefix
    info = Undefined('TypeInfo')   # Defining class (for member variables)
    type = None # type: mypy.types.Type # Declared or inferred type, or None
    is_self = False  # Is this the first argument to an ordinary method
                     # (usually "self")?
    is_ready = False # If inferred, is the inferred type available?
    # Is this initialized explicitly to a non-None value in class body?
    is_initialized_in_class = False
    is_staticmethod = False
    is_property = False
    
    def __init__(self, name: str, type: 'mypy.types.Type' = None) -> None:
        self._name = name
        self.type = type
        self.is_self = False
        self.is_ready = True
        self.is_initialized_in_class = False

    def name(self) -> str:
        return self._name

    def fullname(self) -> str:
        return self._fullname
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_var(self)


class ClassDef(Node):
    """Class definition"""
    
    name = Undefined(str)         # Name of the class without module prefix
    fullname = None # type: str   # Fully qualified name of the class
    defs = Undefined('Block')
    type_vars = Undefined(List['mypy.types.TypeVarDef'])
    # Base classes (Instance or UnboundType).
    base_types = Undefined(List['mypy.types.Type'])
    info = None # type: TypeInfo  # Related TypeInfo
    metaclass = ''
    decorators = Undefined(List[Node])
    # Built-in/extension class? (single implementation inheritance only)
    is_builtinclass = False
    
    def __init__(self, name: str, defs: 'Block',
                 type_vars: List['mypy.types.TypeVarDef'] = None,
                 base_types: List['mypy.types.Type'] = None,
                 metaclass: str = None) -> None:
        if not base_types:
            base_types = []
        self.name = name
        self.defs = defs
        self.type_vars = type_vars or []
        self.base_types = base_types
        self.metaclass = metaclass
        self.decorators = []
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_class_def(self)
    
    def is_generic(self) -> bool:
        return self.info.is_generic()


class VarDef(Node):
    """Variable definition with explicit types"""
    
    items = Undefined(List[Var])
    kind = None # type: int          # LDEF/GDEF/MDEF/...
    init = Undefined(Node)           # Expression or None
    is_top_level = False # Is the definition at the top level (not within
                         # a function or a type)?
    
    def __init__(self, items: List[Var], is_top_level: bool,
                 init: Node = None) -> None:
        self.items = items
        self.is_top_level = is_top_level
        self.init = init
    
    def info(self) -> 'TypeInfo':
        return self.items[0].info
    
    @overload
    def set_line(self, tok: Token) -> Node:
        super().set_line(tok)
        for n in self.items:
            n.line = self.line
        return self
    
    @overload
    def set_line(self, tok: int) -> Node:
        super().set_line(tok)
        for n in self.items:
            n.line = self.line
        return self
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_var_def(self)


class GlobalDecl(Node):
    """Declaration global x, y, ..."""
    
    names = Undefined(List[str])
    
    def __init__(self, names: List[str]) -> None:
        self.names = names
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_global_decl(self)


class Block(Node):
    body = Undefined(List[Node])
    
    def __init__(self, body: List[Node]) -> None:
        self.body = body
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_block(self)


# Statements


class ExpressionStmt(Node):
    """An expression as a statament, such as print(s)."""
    expr = Undefined(Node)
    
    def __init__(self, expr: Node) -> None:
        self.expr = expr
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_expression_stmt(self)


class AssignmentStmt(Node):
    """Assignment statement

    The same node class is used for single assignment, multiple assignment
    (e.g. x, y = z) and chained assignment (e.g. x = y = z), assignments
    that define new names, and assignments with explicit types (# type).

    An lvalue can be NameExpr, TupleExpr, ListExpr, MemberExpr, IndexExpr or
    ParenExpr.
    """
    
    lvalues = Undefined(List[Node])
    rvalue = Undefined(Node)
    type = None # type: mypy.types.Type # Declared type in a comment,
                                        # may be None.
    
    def __init__(self, lvalues: List[Node], rvalue: Node,
                 type: 'mypy.types.Type' = None) -> None:
        self.lvalues = lvalues
        self.rvalue = rvalue
        self.type = type
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_assignment_stmt(self)


class OperatorAssignmentStmt(Node):
    """Operator assignment statement such as x += 1"""
    
    op = ''
    lvalue = Undefined(Node)
    rvalue = Undefined(Node)
    
    def __init__(self, op: str, lvalue: Node, rvalue: Node) -> None:
        self.op = op
        self.lvalue = lvalue
        self.rvalue = rvalue
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_operator_assignment_stmt(self)


class WhileStmt(Node):
    expr = Undefined(Node)
    body = Undefined(Block)
    else_body = Undefined(Block)
    
    def __init__(self, expr: Node, body: Block, else_body: Block) -> None:
        self.expr = expr
        self.body = body
        self.else_body = else_body
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_while_stmt(self)


class ForStmt(Node):
    # Index variables
    index = Undefined(List['NameExpr'])
    # Index variable types (each may be None)
    types = Undefined(List['mypy.types.Type'])
    # Expression to iterate
    expr = Undefined(Node)
    body = Undefined(Block)
    else_body = Undefined(Block)
    
    def __init__(self, index: List['NameExpr'], expr: Node, body: Block,
                 else_body: Block,
                 types: List['mypy.types.Type'] = None) -> None:
        self.index = index
        self.expr = expr
        self.body = body
        self.else_body = else_body
        self.types = types
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_for_stmt(self)
    
    def is_annotated(self) -> bool:
        ann = False
        for t in self.types:
            if t is not None:
                ann = True
        return ann


class ReturnStmt(Node):
    expr = Undefined(Node)   # Expression or None
    
    def __init__(self, expr: Node) -> None:
        self.expr = expr
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_return_stmt(self)


class AssertStmt(Node):
    expr = Undefined(Node)
    
    def __init__(self, expr: Node) -> None:
        self.expr = expr
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_assert_stmt(self)


class YieldStmt(Node):
    expr = Undefined(Node)
    
    def __init__(self, expr: Node) -> None:
        self.expr = expr
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_yield_stmt(self)


class DelStmt(Node):
    expr = Undefined(Node)
    
    def __init__(self, expr: Node) -> None:
        self.expr = expr
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_del_stmt(self)


class BreakStmt(Node):
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_break_stmt(self)


class ContinueStmt(Node):
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_continue_stmt(self)


class PassStmt(Node):
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_pass_stmt(self)


class IfStmt(Node):
    expr = Undefined(List[Node])
    body = Undefined(List[Block])
    else_body = Undefined(Block)
    
    def __init__(self, expr: List[Node], body: List[Block],
                 else_body: Block) -> None:
        self.expr = expr
        self.body = body
        self.else_body = else_body
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_if_stmt(self)


class RaiseStmt(Node):
    expr = Undefined(Node)
    from_expr = Undefined(Node)
    
    def __init__(self, expr: Node, from_expr: Node = None) -> None:
        self.expr = expr
        self.from_expr = from_expr
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_raise_stmt(self)


class TryStmt(Node):
    body = Undefined(Block)                # Try body
    types = Undefined(List[Node])          # Except type expressions
    vars = Undefined(List['NameExpr'])     # Except variable names
    handlers = Undefined(List[Block])      # Except bodies
    else_body = Undefined(Block)
    finally_body = Undefined(Block)
    
    def __init__(self, body: Block, vars: List['NameExpr'], types: List[Node],
                 handlers: List[Block], else_body: Block,
                 finally_body: Block) -> None:
        self.body = body
        self.vars = vars
        self.types = types
        self.handlers = handlers
        self.else_body = else_body
        self.finally_body = finally_body
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_try_stmt(self)


class WithStmt(Node):
    expr = Undefined(List[Node])
    name = Undefined(List['NameExpr'])
    body = Undefined(Block)
    
    def __init__(self, expr: List[Node], name: List['NameExpr'],
                 body: Block) -> None:
        self.expr = expr
        self.name = name
        self.body = body
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_with_stmt(self)


class PrintStmt(Node):
    """Python 2 print statement"""
    
    args = Undefined(List[Node])
    newline = False

    def __init__(self, args: List[Node], newline: bool) -> None:
        self.args = args
        self.newline = newline
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_print_stmt(self)


# Expressions


class IntExpr(Node):
    """Integer literal"""
    
    value = 0
    
    def __init__(self, value: int) -> None:
        self.value = value
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_int_expr(self)


class StrExpr(Node):
    """String literal"""
    
    value = ''
    
    def __init__(self, value: str) -> None:
        self.value = value
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_str_expr(self)


class BytesExpr(Node):
    """Bytes literal"""
    
    value = '' # TODO use bytes
    
    def __init__(self, value: str) -> None:
        self.value = value
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_bytes_expr(self)


class UnicodeExpr(Node):
    """Unicode literal (Python 2.x)"""
    
    value = '' # TODO use bytes
    
    def __init__(self, value: str) -> None:
        self.value = value
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_unicode_expr(self)


class FloatExpr(Node):
    """Float literal"""
    
    value = 0.0
    
    def __init__(self, value: float) -> None:
        self.value = value
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_float_expr(self)


class ParenExpr(Node):
    """Parenthesised expression"""
    
    expr = Undefined(Node)
    
    def __init__(self, expr: Node) -> None:
        self.expr = expr
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_paren_expr(self)


class RefExpr(Node):
    """Abstract base class for name-like constructs"""
    
    kind = None # type: int      # LDEF/GDEF/MDEF/... (None if not available)
    node = Undefined(Node)       # Var, FuncDef or TypeInfo that describes this
    fullname = None # type: str  # Fully qualified name (or name if not global)
    
    # Does this define a new name with inferred type?
    #
    # For members, after semantic analysis, this does not take base
    # classes into consideration at all; the type checker deals with these.
    is_def = False


class NameExpr(RefExpr):
    """Name expression

    This refers to a local name, global name or a module.
    """
    
    name = None # type: str      # Name referred to (may be qualified)
    info = Undefined('TypeInfo') # TypeInfo of class surrounding expression
                                 # (may be None)
    
    def __init__(self, name: str) -> None:
        self.name = name
    
    def type_node(self):
        return cast('TypeInfo', self.node)
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_name_expr(self)


class MemberExpr(RefExpr):
    """Member access expression x.y"""
    
    expr = Undefined(Node)
    name = None # type: str
    # The variable node related to a definition.
    def_var = None # type: Var
    # Is this direct assignment to a data member (bypassing accessors)?
    direct = False
    
    def __init__(self, expr: Node, name: str, direct: bool = False) -> None:
        self.expr = expr
        self.name = name
        self.direct = direct
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_member_expr(self)


# Kinds of arguments

# Positional argument
ARG_POS = 0 # type: int
# Positional, optional argument (functions only, not calls)
ARG_OPT = 1 # type: int
# *arg argument
ARG_STAR = 2 # type: int
# Keyword argument x=y in call, or keyword-only function arg
ARG_NAMED = 3 # type: int
# **arg argument
ARG_STAR2 = 4 # type: int


class CallExpr(Node):
    """Call expression.

    This can also represent several special forms that are syntactically calls
    such as cast(...) and Undefined(...).
    """
    
    callee = Undefined(Node)
    args = Undefined(List[Node])
    arg_kinds = Undefined(List[int]) # ARG_ constants
    arg_names = Undefined(List[str]) # Each name can be None if not a keyword
                                     # argument.
    analyzed = Undefined(Node)       # If not None, the node that represents
                                     # the meaning of the CallExpr. For
                                     # cast(...) this is a CastExpr.
    
    def __init__(self, callee: Node, args: List[Node], arg_kinds: List[int],
                 arg_names: List[str] = None, analyzed: Node = None) -> None:
        if not arg_names:
            arg_names = [None] * len(args)
        self.callee = callee
        self.args = args
        self.arg_kinds = arg_kinds
        self.arg_names = arg_names
        self.analyzed = analyzed
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_call_expr(self)


class IndexExpr(Node):
    """Index expression x[y].

    Also wraps type application as a special form.
    """
    
    base = Undefined(Node)
    index = Undefined(Node)
    # Inferred __getitem__ method type
    method_type = None # type: mypy.types.Type
    # If not None, this is actually semantically a type application
    # Class[type, ...].
    analyzed = Undefined('TypeApplication')
    
    def __init__(self, base: Node, index: Node) -> None:
        self.base = base
        self.index = index
        self.analyzed = None
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_index_expr(self)


class UnaryExpr(Node):
    """Unary operation"""
    
    op = ''
    expr = Undefined(Node)
    # Inferred operator method type
    method_type = None # type: mypy.types.Type
    
    def __init__(self, op: str, expr: Node) -> None:
        self.op = op
        self.expr = expr
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_unary_expr(self)


# Map from binary operator id to related method name (in Python 3).
op_methods = {
    '+': '__add__',
    '-': '__sub__',
    '*': '__mul__',
    '/': '__truediv__',
    '%': '__mod__',
    '//': '__floordiv__',
    '**': '__pow__',
    '&': '__and__',
    '|': '__or__',
    '^': '__xor__',
    '<<': '__lshift__',
    '>>': '__rshift__',
    '==': '__eq__',
    '!=': '__ne__',
    '<': '__lt__',
    '>=': '__ge__',
    '>': '__gt__',
    '<=': '__le__',
    'in': '__contains__',
}

ops_with_inplace_method = {
    '+', '-', '*', '/', '%', '//', '**', '&', '|', '^', '<<', '>>'}

inplace_operator_methods = set(
    '__i' + op_methods[op][2:] for op in ops_with_inplace_method)

reverse_op_methods = {
    '__add__': '__radd__',
    '__sub__': '__rsub__',
    '__mul__': '__rmul__',
    '__truediv__': '__rtruediv__',
    '__mod__': '__rmod__',
    '__floordiv__': '__rfloordiv__',
    '__pow__': '__rpow__',
    '__and__': '__rand__',
    '__or__': '__ror__',
    '__xor__': '__rxor__',
    '__lshift__': '__rlshift__',
    '__rshift__': '__rrshift__',
    '__eq__': '__eq__',
    '__ne__': '__ne__',
    '__lt__': '__gt__',
    '__ge__': '__le__',
    '__gt__': '__lt__',
    '__le__': '__ge__',
}

normal_from_reverse_op = dict((m, n) for n, m in reverse_op_methods.items())
reverse_op_method_set = set(reverse_op_methods.values())


class OpExpr(Node):
    """Binary operation (other than . or [], which have specific nodes)."""
    
    op = ''
    left = Undefined(Node)
    right = Undefined(Node)
    # Inferred type for the operator method type (when relevant; None for
    # 'is').
    method_type = None # type: mypy.types.Type
    
    def __init__(self, op: str, left: Node, right: Node) -> None:
        self.op = op
        self.left = left
        self.right = right
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_op_expr(self)


class SliceExpr(Node):
    """Slice expression (e.g. 'x:y', 'x:', '::2' or ':').

    This is only valid as index in index expressions.
    """
    
    begin_index = Undefined(Node)  # May be None
    end_index = Undefined(Node)    # May be None
    stride = Undefined(Node)       # May be None
    
    def __init__(self, begin_index: Node, end_index: Node,
                 stride: Node) -> None:
        self.begin_index = begin_index
        self.end_index = end_index
        self.stride = stride
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_slice_expr(self)


class CastExpr(Node):
    """Cast expression cast(type, expr)."""
    
    expr = Undefined(Node)
    type = Undefined('mypy.types.Type')
    
    def __init__(self, expr: Node, typ: 'mypy.types.Type') -> None:
        self.expr = expr
        self.type = typ
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_cast_expr(self)


class SuperExpr(Node):
    """Expression super().name"""
    
    name = ''
    info = Undefined('TypeInfo') # Type that contains this super expression
    
    def __init__(self, name: str) -> None:
        self.name = name
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_super_expr(self)


class FuncExpr(FuncItem):
    """Lambda expression"""

    def name(self) -> str:
        return '<lambda>'
    
    def expr(self) -> Node:
        """Return the expression (the body) of the lambda."""
        ret = cast(ReturnStmt, self.body.body[0])
        return ret.expr
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_func_expr(self)


class ListExpr(Node):
    """List literal expression [...]."""
    
    items = Undefined(List[Node] )
    
    def __init__(self, items: List[Node]) -> None:
        self.items = items
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_list_expr(self)


class DictExpr(Node):
    """Dictionary literal expression {key: value, ...}."""
    
    items = Undefined(List[Tuple[Node, Node]])
    
    def __init__(self, items: List[Tuple[Node, Node]]) -> None:
        self.items = items
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_dict_expr(self)


class TupleExpr(Node):
    """Tuple literal expression (..., ...)"""
    
    items = Undefined(List[Node])
    
    def __init__(self, items: List[Node]) -> None:
        self.items = items
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_tuple_expr(self)


class SetExpr(Node):
    """Set literal expression {value, ...}."""
    
    items = Undefined(List[Node])
    
    def __init__(self, items: List[Node]) -> None:
        self.items = items
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_set_expr(self)


class GeneratorExpr(Node):
    """Generator expression ... for ... in ... [ if ... ]."""
    
    left_expr = Undefined(Node)
    right_expr = Undefined(Node)
    condition = Undefined(Node)   # May be None
    index = Undefined(List[NameExpr])
    types = Undefined(List['mypy.types.Type'])
    
    def __init__(self, left_expr: Node, index: List[NameExpr],
                  types: List['mypy.types.Type'], right_expr: Node,
                 condition: Node) -> None:
        self.left_expr = left_expr
        self.right_expr = right_expr
        self.condition = condition
        self.index = index
        self.types = types
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_generator_expr(self)


class ListComprehension(Node):
    """List comprehension (e.g. [x + 1 for x in a])"""
    
    generator = Undefined(GeneratorExpr)
    
    def __init__(self, generator: GeneratorExpr) -> None:
        self.generator = generator
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_list_comprehension(self)


class ConditionalExpr(Node):
    """Conditional expression (e.g. x if y else z)"""
    
    cond = Undefined(Node)
    if_expr = Undefined(Node)
    else_expr = Undefined(Node)
    
    def __init__(self, cond: Node, if_expr: Node, else_expr: Node) -> None:
        self.cond = cond
        self.if_expr = if_expr
        self.else_expr = else_expr
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_conditional_expr(self)


class UndefinedExpr(Node):
    """Expression Undefined(type), used as an initializer.

    This is used to declare the type of a variable without initializing with
    a proper value. For example:

      x = Undefined(List[int])
    """
    
    def __init__(self, type: 'mypy.types.Type') -> None:
        self.type = type

    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_undefined_expr(self)


class TypeApplication(Node):
    """Type application expr[type, ...]"""
    
    expr = Undefined(Node)
    types = Undefined(List['mypy.types.Type'])
    
    def __init__(self, expr: Node, types: List['mypy.types.Type']) -> None:
        self.expr = expr
        self.types = types
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_type_application(self)


class TypeVarExpr(SymbolNode):
    """Type variable expression typevar(...)."""

    _name = ''
    _fullname = ''
    # Value restriction: only types in the list are valid as values. If the
    # list is empty, there is no restriction.
    values = Undefined(List['mypy.types.Type'])

    def __init__(self, name: str, fullname: str,
                 values: List['mypy.types.Type']) -> None:
        self._name = name
        self._fullname = fullname
        self.values = values

    def name(self) -> str:
        return self._name

    def fullname(self) -> str:
        return self._fullname
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_type_var_expr(self)


class DucktypeExpr(Node):
    """Ducktype class decorator expression ducktype(...)."""

    type = Undefined('mypy.types.Type')

    def __init__(self, type: 'mypy.types.Type') -> None:
        self.type = type

    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_ducktype_expr(self)


class DisjointclassExpr(Node):
    """Disjoint class class decorator expression disjointclass(cls)."""

    cls = Undefined(RefExpr)

    def __init__(self, cls: RefExpr) -> None:
        self.cls = cls

    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_disjointclass_expr(self)


class CoerceExpr(Node):
    """Implicit coercion expression.

    This is used only when compiling/transforming.  These are inserted
    after type checking.
    """
    
    expr = Undefined(Node)
    target_type = Undefined('mypy.types.Type')
    source_type = Undefined('mypy.types.Type')
    is_wrapper_class = False
    
    def __init__(self, expr: Node, target_type: 'mypy.types.Type',
                 source_type: 'mypy.types.Type',
                 is_wrapper_class: bool) -> None:
        self.expr = expr
        self.target_type = target_type
        self.source_type = source_type
        self.is_wrapper_class = is_wrapper_class
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_coerce_expr(self)


class JavaCast(Node):
    # TODO obsolete; remove
    expr = Undefined(Node)
    target = Undefined('mypy.types.Type')    
    
    def __init__(self, expr: Node, target: 'mypy.types.Type') -> None:
        self.expr = expr
        self.target = target
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_java_cast(self)


class TypeExpr(Node):
    """Expression that evaluates to a runtime representation of a type.

    This is used only for runtime type checking. This node is always generated
    only after type checking.
    """
    
    type = Undefined('mypy.types.Type')    
    
    def __init__(self, typ: 'mypy.types.Type') -> None:
        self.type = typ
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_type_expr(self)


class TempNode(Node):
    """Temporary dummy node used during type checking.

    This node is not present in the original program; it is just an artifact
    of the type checker implementation. It only represents an opaque node with
    some fixed type.
    """
    
    type = Undefined('mypy.types.Type')
    
    def __init__(self, typ: 'mypy.types.Type') -> None:
        self.type = typ
    
    def accept(self, visitor: NodeVisitor[T]) -> T:
        return visitor.visit_temp_node(self)


class TypeInfo(SymbolNode):
    """Class representing the type structure of a single class.

    The corresponding ClassDef instance represents the parse tree of
    the class.
    """
    
    _fullname = None # type: str      # Fully qualified name
    defn = Undefined(ClassDef)        # Corresponding ClassDef
    # Method Resolution Order: the order of looking up attributes. The first
    # value always to refers to self.
    mro = Undefined(List['TypeInfo'])
    subtypes = Undefined(Set['TypeInfo']) # Direct subclasses
    names = Undefined('SymbolTable')      # Names defined directly in this type
    is_abstract = False       # Does the class have any abstract attributes?
    abstract_attributes = Undefined(List[str])
    # All classes in this build unit that are disjoint with this class.
    disjoint_classes = Undefined(List['TypeInfo'])
    # Targets of disjointclass declarations present in this class only (for
    # generating error messages).
    disjointclass_decls = Undefined(List['TypeInfo'])
    
    # Information related to type annotations.
    
    # Generic type variable names
    type_vars = Undefined(List[str])
    
    # Direct base classes.
    bases = Undefined(List['mypy.types.Instance'])

    # Duck type compatibility (ducktype decorator)
    ducktype = None # type: mypy.types.Type
    
    def __init__(self, names: 'SymbolTable', defn: ClassDef) -> None:
        """Initialize a TypeInfo."""
        self.names = names
        self.defn = defn
        self.subtypes = set()
        self.mro = []
        self.type_vars = []
        self.bases = []
        self._fullname = defn.fullname
        self.is_abstract = False
        self.abstract_attributes = []
        self.disjoint_classes = []
        self.disjointclass_decls = []
        if defn.type_vars:
            for vd in defn.type_vars:
                self.type_vars.append(vd.name)
    
    def name(self) -> str:
        """Short name."""
        return self.defn.name

    def fullname(self) -> str:
        return self._fullname
    
    def is_generic(self) -> bool:
        """Is the type generic (i.e. does it have type variables)?"""
        return self.type_vars is not None and len(self.type_vars) > 0
    
    def get(self, name: str) -> 'SymbolTableNode':
        for cls in self.mro:
            n = cls.names.get(name)
            if n:
                return n
        return None

    def __getitem__(self, name: str) -> 'SymbolTableNode':
        n = self.get(name)
        if n:
            return n
        else:
            raise KeyError(name)

    def __repr__(self) -> str:
        return '<TypeInfo %s>' % self.fullname()
        
    
    # IDEA: Refactor the has* methods to be more consistent and document
    #       them.
    
    def has_readable_member(self, name: str) -> bool:
        return self.get(name) is not None
    
    def has_writable_member(self, name: str) -> bool:
        return self.has_var(name)
    
    def has_var(self, name: str) -> bool:
        return self.get_var(name) is not None
    
    def has_method(self, name: str) -> bool:
        return self.get_method(name) is not None
    
    def get_var(self, name: str) -> Var:
        for cls in self.mro:
            if name in cls.names:
                node = cls.names[name].node
                if isinstance(node, Var):
                    return cast(Var, node)
                else:
                    return None
        return None
    
    def get_var_or_getter(self, name: str) -> SymbolNode:
        # TODO getter
        return self.get_var(name)
    
    def get_var_or_setter(self, name: str) -> SymbolNode:
        # TODO setter
        return self.get_var(name)
    
    def get_method(self, name: str) -> FuncBase:
        for cls in self.mro:
            if name in cls.names:
                node = cls.names[name].node
                if isinstance(node, FuncBase):
                    return node
                else:
                    return None
        return None

    def calculate_mro(self) -> None:
        """Calculate and set mro (method resolution order).

        Raise MroError if cannot determine mro.
        """
        self.mro = linearize_hierarchy(self)
    
    def has_base(self, fullname: str) -> bool:
        """Return True if type has a base type with the specified name.

        This can be either via extension or via implementation.
        """
        for cls in self.mro:
            if cls.fullname() == fullname:
                return True
        return False
    
    def all_subtypes(self) -> 'Set[TypeInfo]':
        """Return TypeInfos of all subtypes, including this type, as a set."""
        subtypes = set([self])
        for subt in self.subtypes:
            for t in subt.all_subtypes():
                subtypes.add(t)
        return subtypes
    
    def all_base_classes(self) -> 'List[TypeInfo]':
        """Return a list of base classes, including indirect bases."""
        assert False
    
    def direct_base_classes(self) -> 'List[TypeInfo]':
        """Return a direct base classes.

        Omit base classes of other base classes.
        """
        return [base.type for base in self.bases]
    
    def __str__(self) -> str:
        """Return a string representation of the type.

        This includes the most important information about the type.
        """
        base = None # type: str
        if self.bases:
            base = 'Bases({})'.format(', '.join(str(base)
                                                for base in self.bases))
        return dump_tagged(['Name({})'.format(self.fullname()),
                            base,
                            ('Names', sorted(self.names.keys()))],
                           'TypeInfo')


class SymbolTableNode:
    # LDEF/GDEF/MDEF/UNBOUND_TVAR/TVAR/...
    kind = None # type: int
    # AST node of definition (FuncDef/Var/TypeInfo/Decorator/TypeVarExpr,
    # or None for a bound type variable).
    node = Undefined(SymbolNode)
    # Type variable id (for bound type variables only)
    tvar_id = 0
    # Module id (e.g. "foo.bar") or None
    mod_id = ''
    # If None, fall back to type of node    
    type_override = Undefined('mypy.types.Type')
    
    def __init__(self, kind: int, node: SymbolNode, mod_id: str = None,
                 typ: 'mypy.types.Type' = None, tvar_id: int = 0) -> None:
        self.kind = kind
        self.node = node
        self.type_override = typ
        self.mod_id = mod_id
        self.tvar_id = tvar_id

    @property
    def fullname(self) -> str:
        if self.node is not None:
            return self.node.fullname()
        else:
            return None

    @property
    def type(self) -> 'mypy.types.Type':
        # IDEA: Get rid of the Any type.
        node = self.node # type: Any
        if self.type_override is not None:
            return self.type_override
        elif ((isinstance(node, Var) or isinstance(node, FuncDef))
              and node.type is not None):
            return node.type
        elif isinstance(node, Decorator):
            return (cast(Decorator, node)).var.type
        else:
            return None
    
    def __str__(self) -> str:
        s = '{}/{}'.format(node_kinds[self.kind], short_type(self.node))
        if self.mod_id is not None:
            s += ' ({})'.format(self.mod_id)
        # Include declared type of variables and functions.
        if self.type is not None:
            s += ' : {}'.format(self.type)
        return s


class SymbolTable(Dict[str, SymbolTableNode]):
    def __str__(self) -> str:
        a = List[str]()
        for key, value in self.items():
            # Filter out the implicit import of builtins.
            if isinstance(value, SymbolTableNode):
                if (value.fullname != 'builtins' and
                        value.fullname.split('.')[-1] not in
                            implicit_module_attrs):
                    a.append('  ' + str(key) + ' : ' + str(value))
            else:
                a.append('  <invalid item>')
        a = sorted(a)
        a.insert(0, 'SymbolTable(')
        a[-1] += ')'
        return '\n'.join(a)


def clean_up(s: str) -> str:
    # TODO remove
    return re.sub('.*::', '', s)
        

def function_type(func: FuncBase) -> 'mypy.types.FunctionLike':
    if func.type:
        return cast(mypy.types.FunctionLike, func.type)
    else:
        # Implicit type signature with dynamic types.
        # Overloaded functions always have a signature, so func must be an
        # ordinary function.
        fdef = cast(FuncDef, func)        
        name = func.name()
        if name:
            name = '"{}"'.format(name)
        names = [] # type: List[str]
        for arg in fdef.args:
            names.append(arg.name())
        return mypy.types.Callable([mypy.types.AnyType()] * len(fdef.args),
            fdef.arg_kinds,
            names,
            mypy.types.AnyType(),
            False,
            name)


@overload
def method_type(func: FuncBase) -> 'mypy.types.FunctionLike':
    """Return the signature of a method (omit self)."""
    return method_type(function_type(func))

@overload
def method_type(sig: 'mypy.types.FunctionLike') -> 'mypy.types.FunctionLike':
    if isinstance(sig, mypy.types.Callable):
        csig = cast(mypy.types.Callable, sig)
        return method_callable(csig)
    else:
        osig = cast(mypy.types.Overloaded, sig)
        items = List[mypy.types.Callable]()
        for c in osig.items():
            items.append(method_callable(c))
        return mypy.types.Overloaded(items)


def method_callable(c: 'mypy.types.Callable') -> 'mypy.types.Callable':
    return mypy.types.Callable(c.arg_types[1:],
                           c.arg_kinds[1:],
                           c.arg_names[1:],
                           c.ret_type,
                           c.is_type_obj(),
                           c.name,
                           c.variables,
                           c.bound_vars)


class MroError(Exception):
    """Raised if a consistent mro cannot be determined for a class."""


def linearize_hierarchy(info: TypeInfo) -> List[TypeInfo]:
    # TODO describe
    if info.mro:
        return info.mro
    bases = info.direct_base_classes()
    return [info] + merge([linearize_hierarchy(base) for base in bases] +
                          [bases])


def merge(seqs: List[List[TypeInfo]]) -> List[TypeInfo]:
    seqs = [s[:] for s in seqs]
    result = List[TypeInfo]()
    while True:
        seqs = [s for s in seqs if s]
        if not seqs:
            return result
        for seq in seqs:
            head = seq[0]
            if not [s for s in seqs if head in s[1:]]:
                break
        else:
            raise MroError()
        result.append(head)
        for s in seqs:
            if s[0] == head:
                del s[0]

########NEW FILE########
__FILENAME__ = opgen
"""Alore code generation for runtime type operations.

TODO This is mostly obsolete, but this is kept anyway, since some of the
     code or at least some ideas can probably be reused.
"""

from typing import List, cast

from nodes import MypyFile, ClassDef, TypeInfo
from types import Instance, TypeVar, BOUND_VAR, Type
import transform
from maptypevar import num_slots, get_tvar_access_path
from compileslotmap import compile_slot_mapping
from transutil import dynamic_suffix, tvar_slot_name


def generate_runtime_support(f: MypyFile) -> str:
    return generate_slot_map(f) + '\n' + generate_type_map(f)


# Type-to-slot mapping


def generate_slot_map(f: MypyFile) -> str:
    map = [] # type: List[str]
    ops = [] # type: List[str]
    map.append('def __InitSlotMap()')
    map.append('  __SlotMap = std::Map(')
    for d in f.defs:
        if isinstance(d, ClassDef):
            td = cast(ClassDef, d)
            if td.info:
                add_slot_map_data(map, ops, td.info)
    map.append('  )')
    map.append('end')
    return '\n'.join(map) + '\n' + '\n'.join(ops)


def add_slot_map_data(map: List[str], ops: List[str], typ: TypeInfo) -> None:
    base = typ
    while base:
        add_slot_map_support_for_type_pair(map, ops, base, typ)
        base = base.base


def add_slot_map_support_for_type_pair(map: List[str], ops: List[str],
                                       base: TypeInfo, typ: TypeInfo) -> None:
    op = '__{}TypeTo{}Slots'.format(base.name(), typ.name())
    map.append('    ({}, {}) : {},'.format(base.name(), typ.name(), op))
    if typ.is_generic():
        map.append('    ({}, {}) : {},'.format(base.name(), typ.name() +
                                               dynamic_suffix(False),
                                               op))
    generate_slot_map_op(ops, op, base, typ)


def generate_slot_map_op(ops: List[str], op: str, base: TypeInfo,
                         typ: TypeInfo) -> None:
    ops.append('def {}(t)'.format(op))
    nslots = num_slots(typ)
    slots = compile_slot_mapping(base)
    a = [] # type: List[str]
    for t in slots:
        a.append(transform_type_to_runtime_repr(t))
    for i in range(len(slots), nslots):
        a.append('__Dyn')
    ops.append('  return [' + ', '.join(a) + ']')
    ops.append('end')


def transform_type_to_runtime_repr(t: Type) -> str:
    if isinstance(t, Instance):
        inst = cast(Instance, t)
        if inst.args == []:
            return inst.type.name()
        else:
            args = [] # type: List[str]
            for a in inst.args:
                args.append(transform_type_to_runtime_repr(a))
            return '__Gen({}, [{}])'.format(inst.type.name(), ', '.join(args))
    elif isinstance(t, TypeVar):
        tv = cast(TypeVar, t)
        return 't.args[{}]'.format(tv.id - 1)
    else:
        raise TypeError('{} not supported'.format(t))


# Slot-to-type mapping


def generate_type_map(f: MypyFile) -> str:
    map = [] # type: List[str]
    ops = [] # type: List[str]
    map.append('def __InitTypeMap()')
    for alt, suffix in [(None, ''), (BOUND_VAR, 'B')]:
        map.append('  __TypeMap{} = std::Map('.format(suffix))
        for d in f.defs:
            if isinstance(d, ClassDef):
                td = cast(ClassDef, d)
                if td.info is not None:
                    add_type_map_support_for_type(map, ops, td.info, alt,
                                                  suffix)
        map.append('  )')
    map.append('end')
    return '\n'.join(map) + '\n' + '\n'.join(ops)


def add_type_map_support_for_type(map: List[str], ops: List[str],
                                  typ: TypeInfo, alt, suffix: str) -> None:
    op = '__{}ValueToType{}'.format(typ.name(), suffix)
    map.append('    {} : {},'.format(typ.name(), op))
    if typ.is_generic():
        map.append('    {} : {},'.format(typ.name() + dynamic_suffix(False),
                                         op))
    generate_type_map_op(ops, op, typ, alt)


def generate_type_map_op(ops: List[str], op: str, typ, alt) -> None:
    ops.append('def {}(v)'.format(op))
    a = [] # type: List[str]
    for i in range(len(typ.type_vars)):
        p = get_tvar_access_path(typ, i + 1)
        expr = 'v.' + tvar_slot_name(p[0] - 1, alt)
        for j in p[1:]:
            expr += '.args[{}]'.format(j - 1)
        a.append(expr)
    ops.append('  return [{}]'.format(', '.join(a)))
    ops.append('end')

########NEW FILE########
__FILENAME__ = output
"""Parse tree pretty printer."""

import re

import typing

from mypy import nodes
from mypy.visitor import NodeVisitor
from mypy.typerepr import CommonTypeRepr


class OutputVisitor(NodeVisitor):
    """Parse tree Node visitor that outputs the original, formatted
    source code.  You can implement custom transformations by
    subclassing this class.
    """
    def __init__(self):
        super().__init__()
        self.result = []  # strings
        self.line_number = 1
        # If True, omit the next character if it is a space
        self.omit_next_space = False
        # Number of spaces of indent right now
        self.indent = 0
        # Number of spaces of extra indent to add when encountering a line
        # break
        self.extra_indent = 0
        self.block_depth = 0
    
    def output(self):
        """Return a string representation of the output."""
        return ''.join(self.result)
    
    def visit_mypy_file(self, o):
        self.nodes(o.defs)
        self.token(o.repr.eof)
    
    def visit_import(self, o):
        r = o.repr
        self.token(r.import_tok)
        for i in range(len(r.components)):
            self.tokens(r.components[i])
            if r.as_names[i]:
                self.tokens(r.as_names[i])
            if i < len(r.commas):
                self.token(r.commas[i])
        self.token(r.br)
    
    def visit_import_from(self, o):
        self.output_import_from_or_all(o)
    
    def visit_import_all(self, o):
        self.output_import_from_or_all(o)
    
    def output_import_from_or_all(self, o):
        r = o.repr
        self.token(r.from_tok)
        self.tokens(r.components)
        self.token(r.import_tok)
        self.token(r.lparen)
        for misc, comma in r.names:
            self.tokens(misc)
            self.token(comma)
        self.token(r.rparen)
        self.token(r.br)
    
    def visit_class_def(self, o):
        r = o.repr
        self.tokens([r.class_tok, r.name])
        self.type_vars(o.type_vars)
        self.token(r.lparen)
        for i in range(len(o.base_types)):
            if o.base_types[i].repr:
                self.type(o.base_types[i])
            if i < len(r.commas):
                self.token(r.commas[i])
        self.token(r.rparen)
        self.node(o.defs)
    
    def type_vars(self, v):
        # IDEA: Combine this with type_vars in TypeOutputVisitor.
        if v and v.repr:
            r = v.repr
            self.token(r.langle)
            for i in range(len(v.items)):
                d = v.items[i]
                self.token(d.repr.name)
                self.token(d.repr.is_tok)
                if d.bound:
                    self.type(d.bound)
                if i < len(r.commas):
                    self.token(r.commas[i])
            self.token(r.rangle)
    
    def visit_func_def(self, o):
        r = o.repr
        
        if r.def_tok:
            self.token(r.def_tok)
        else:
            self.type(o.type.items()[0].ret_type)
        
        self.token(r.name)
        
        self.function_header(o, r.args, o.arg_kinds)
        
        self.node(o.body)
    
    def visit_overloaded_func_def(self, o):
        for f in o.items:
            f.accept(self)
    
    def function_header(self, o, arg_repr, arg_kinds, pre_args_func=None,
                        erase_type=False, strip_space_before_first_arg=False):
        r = o.repr
        
        t = None
        if o.type and not erase_type:
            t = o.type
        
        init = o.init
        
        if t:
            self.type_vars(t.variables)
        
        self.token(arg_repr.lseparator)
        if pre_args_func:
            pre_args_func()
        asterisk = 0
        for i in range(len(arg_repr.arg_names)):
            if t:
                if t.arg_types[i].repr:
                    self.type(t.arg_types[i])
            if arg_kinds[i] in [nodes.ARG_STAR, nodes.ARG_STAR2]:
                self.token(arg_repr.asterisk[asterisk])
                asterisk += 1
            if not erase_type:
                self.token(arg_repr.arg_names[i])
            else:
                n = arg_repr.arg_names[i].rep()
                if i == 0 and strip_space_before_first_arg:
                    # Remove spaces before the first argument name. Generally
                    # spaces are only present after a type, and if we erase the
                    # type, we should also erase also the spaces.
                    n = re.sub(' +([a-zA-Z0-9_]+)$', '\\1', n)
                self.string(n)
            if i < len(arg_repr.assigns):
                self.token(arg_repr.assigns[i])
            if init and i < len(init) and init[i]:
                self.node(init[i].rvalue)
            if i < len(arg_repr.commas):
                self.token(arg_repr.commas[i])
        self.token(arg_repr.rseparator)
    
    def visit_var_def(self, o):
        r = o.repr
        if r:
            for v in o.items:
                self.type(v.type)
                self.node(v)
            self.token(r.assign)
            self.node(o.init)
            self.token(r.br)
    
    def visit_var(self, o):
        r = o.repr
        self.token(r.name)
        self.token(r.comma)
    
    def visit_decorator(self, o):
        for at, br, dec in zip(o.repr.ats, o.repr.brs, o.decorators):
            self.token(at)
            self.node(dec)
            self.token(br)
        self.node(o.func)
    
    # Statements
    
    def visit_block(self, o):
        r = o.repr
        self.tokens([r.colon, r.br, r.indent])
        self.block_depth += 1
        old_indent = self.indent
        self.indent = len(r.indent.string)
        self.nodes(o.body)
        self.token(r.dedent)
        self.indent = old_indent
        self.block_depth -= 1
    
    def visit_global_decl(self, o):
        r = o.repr
        self.token(r.global_tok)
        for i in range(len(r.names)):
            self.token(r.names[i])
            if i < len(r.commas):
                self.token(r.commas[i])
        self.token(r.br)
    
    def visit_expression_stmt(self, o):
        self.node(o.expr)
        self.token(o.repr.br)
    
    def visit_assignment_stmt(self, o):
        r = o.repr
        i = 0
        for lv in o.lvalues:
            self.node(lv)
            self.token(r.assigns[i])
            i += 1
        self.node(o.rvalue)
        self.token(r.br)
    
    def visit_operator_assignment_stmt(self, o):
        r = o.repr
        self.node(o.lvalue)
        self.token(r.assign)
        self.node(o.rvalue)
        self.token(r.br)
    
    def visit_return_stmt(self, o):
        self.simple_stmt(o, o.expr)
    
    def visit_assert_stmt(self, o):
        self.simple_stmt(o, o.expr)
    
    def visit_yield_stmt(self, o):
        self.simple_stmt(o, o.expr)
    
    def visit_del_stmt(self, o):
        self.simple_stmt(o, o.expr)
    
    def visit_break_stmt(self, o):
        self.simple_stmt(o)
    
    def visit_continue_stmt(self, o):
        self.simple_stmt(o)
    
    def visit_pass_stmt(self, o):
        self.simple_stmt(o)
    
    def simple_stmt(self, o, expr=None):
        self.token(o.repr.keyword)
        self.node(expr)
        self.token(o.repr.br)
    
    def visit_raise_stmt(self, o):
        self.token(o.repr.raise_tok)
        self.node(o.expr)
        if o.from_expr:
            self.token(o.repr.from_tok)
            self.node(o.from_expr)
        self.token(o.repr.br)
    
    def visit_while_stmt(self, o):
        self.token(o.repr.while_tok)
        self.node(o.expr)
        self.node(o.body)
        if o.else_body:
            self.token(o.repr.else_tok)
            self.node(o.else_body)
    
    def visit_for_stmt(self, o):
        r = o.repr
        self.token(r.for_tok)
        for i in range(len(o.index)):
            self.type(o.types[i])
            self.node(o.index[i])
            self.token(r.commas[i])
        self.token(r.in_tok)
        self.node(o.expr)
        
        self.node(o.body)
        if o.else_body:
            self.token(r.else_tok)
            self.node(o.else_body)
    
    def visit_if_stmt(self, o):
        r = o.repr
        self.token(r.if_tok)
        self.node(o.expr[0])
        self.node(o.body[0])
        for i in range(1, len(o.expr)):
            self.token(r.elif_toks[i - 1])
            self.node(o.expr[i])
            self.node(o.body[i])
        self.token(r.else_tok)
        if o.else_body:
            self.node(o.else_body)
    
    def visit_try_stmt(self, o):
        r = o.repr
        self.token(r.try_tok)
        self.node(o.body)
        for i in range(len(o.types)):
            self.token(r.except_toks[i])
            self.node(o.types[i])
            self.token(r.as_toks[i])
            self.node(o.vars[i])
            self.node(o.handlers[i])
        if o.else_body:
            self.token(r.else_tok)
            self.node(o.else_body)
        if o.finally_body:
            self.token(r.finally_tok)
            self.node(o.finally_body)
    
    def visit_with_stmt(self, o):
        self.token(o.repr.with_tok)
        for i in range(len(o.expr)):
            self.node(o.expr[i])
            self.token(o.repr.as_toks[i])
            self.node(o.name[i])
            if i < len(o.repr.commas):
                self.token(o.repr.commas[i])
        self.node(o.body)
    
    # Expressions
    
    def visit_int_expr(self, o):
        self.token(o.repr.int)
    
    def visit_str_expr(self, o):
        self.tokens(o.repr.string)
    
    def visit_bytes_expr(self, o):
        self.tokens(o.repr.string)
    
    def visit_float_expr(self, o):
        self.token(o.repr.float)
    
    def visit_paren_expr(self, o):
        self.token(o.repr.lparen)
        self.node(o.expr)
        self.token(o.repr.rparen)
    
    def visit_name_expr(self, o):
        # Supertype references may not have a representation.
        if o.repr:
            self.token(o.repr.id)
    
    def visit_member_expr(self, o):
        self.node(o.expr)
        self.token(o.repr.dot)
        self.token(o.repr.name)
    
    def visit_index_expr(self, o):
        self.node(o.base)
        self.token(o.repr.lbracket)
        self.node(o.index)
        self.token(o.repr.rbracket)
    
    def visit_slice_expr(self, o):
        self.node(o.begin_index)
        self.token(o.repr.colon)
        self.node(o.end_index)
        self.token(o.repr.colon2)
        self.node(o.stride)    
    
    def visit_call_expr(self, o):
        r = o.repr
        self.node(o.callee)
        self.token(r.lparen)
        nargs = len(o.args)
        nkeyword = 0
        for i in range(nargs):
            if o.arg_kinds[i] == nodes.ARG_STAR:
                self.token(r.star)
            elif o.arg_kinds[i] == nodes.ARG_STAR2:
                self.token(r.star2)
            elif o.arg_kinds[i] == nodes.ARG_NAMED:
                self.tokens(r.keywords[nkeyword])
                nkeyword += 1
            self.node(o.args[i])
            if i < len(r.commas):
                self.token(r.commas[i])
        self.token(r.rparen)
    
    def visit_op_expr(self, o):
        self.node(o.left)
        self.tokens([o.repr.op, o.repr.op2])
        self.node(o.right)
    
    def visit_cast_expr(self, o):
        self.token(o.repr.lparen)
        self.type(o.type)
        self.token(o.repr.rparen)
        self.node(o.expr)
    
    def visit_super_expr(self, o):
        r = o.repr
        self.tokens([r.super_tok, r.lparen, r.rparen, r.dot, r.name])
    
    def visit_unary_expr(self, o):
        self.token(o.repr.op)
        self.node(o.expr)
    
    def visit_list_expr(self, o):
        r = o.repr
        self.token(r.lbracket)
        self.comma_list(o.items, r.commas)
        self.token(r.rbracket)
    
    def visit_set_expr(self, o):
        self.visit_list_expr(o)
    
    def visit_tuple_expr(self, o):
        r = o.repr
        self.token(r.lparen)
        self.comma_list(o.items, r.commas)
        self.token(r.rparen)
    
    def visit_dict_expr(self, o):
        r = o.repr
        self.token(r.lbrace)
        i = 0
        for k, v in o.items:
            self.node(k)
            self.token(r.colons[i])
            self.node(v)
            if i < len(r.commas):
                self.token(r.commas[i])
            i += 1
        self.token(r.rbrace)
    
    def visit_func_expr(self, o):
        r = o.repr
        self.token(r.lambda_tok)
        self.function_header(o, r.args, o.arg_kinds)
        self.token(r.colon)
        self.node(o.body.body[0].expr)
    
    def visit_type_application(self, o):
        self.node(o.expr)
        self.token(o.repr.langle)
        self.type_list(o.types, o.repr.commas)
        self.token(o.repr.rangle)

    def visit_generator_expr(self, o):
        r = o.repr
        self.node(o.left_expr)
        self.token(r.for_tok)
        for i in range(len(o.index)):
            self.node(o.types[i])
            self.node(o.index[i])
            self.token(r.commas[i])
        self.token(r.in_tok)
        self.node(o.right_expr)
        if o.condition:
            self.token(r.if_tok)
            self.node(o.condition)

    def visit_list_comprehension(self, o):
        self.token(o.repr.lbracket)
        self.node(o.generator)
        self.token(o.repr.rbracket)
    
    # Helpers
    
    def line(self):
        return self.line_number
    
    def string(self, s):
        """Output a string."""
        if self.omit_next_space:
            if s.startswith(' '):
                s = s[1:]
            self.omit_next_space = False
        self.line_number += s.count('\n')
        if s != '':
            s = s.replace('\n', '\n' + ' ' * self.extra_indent)
            self.result.append(s)
    
    def token(self, t):
        """Output a token."""
        self.string(t.rep())
    
    def tokens(self, a):
        """Output an array of tokens."""
        for t in a:
            self.token(t)
    
    def node(self, n):
        """Output a node."""
        if n: n.accept(self)
    
    def nodes(self, a):
        """Output an array of nodes."""
        for n in a:
            self.node(n)
    
    def comma_list(self, items, commas):
        for i in range(len(items)):
            self.node(items[i])
            if i < len(commas):
                self.token(commas[i])
    
    def type_list(self, items, commas):
        for i in range(len(items)):
            self.type(items[i])
            if i < len(commas):
                self.token(commas[i])
    
    def type(self, t):
        """Output a type."""
        if t:
            v = TypeOutputVisitor()
            t.accept(v)
            self.string(v.output())
    
    def last_output_char(self):
        if self.result and self.result[-1]:
            return self.result[-1][-1]
        else:
            return ''



class TypeOutputVisitor:
    """Type visitor that outputs source code."""
    def __init__(self):
        self.result = []  # strings
    
    def output(self):
        """Return a string representation of the output."""
        return ''.join(self.result)
    
    def visit_unbound_type(self, t):
        self.visit_instance(t)
    
    def visit_any(self, t):
        if t.repr:
            self.token(t.repr.any_tok)
    
    def visit_void(self, t):
        if t.repr:
            self.token(t.repr.void)
    
    def visit_instance(self, t):
        r = t.repr
        if isinstance(r, CommonTypeRepr):
            self.tokens(r.components)
            self.token(r.langle)
            self.comma_list(t.args, r.commas)
            self.token(r.rangle)
        else:
            # List type t[].
            assert len(t.args) == 1
            self.comma_list(t.args, [])
            self.tokens([r.lbracket, r.rbracket])
    
    def visit_type_var(self, t):
        self.token(t.repr.name)
    
    def visit_tuple_type(self, t):
        r = t.repr
        self.tokens(r.components)
        self.token(r.langle)
        self.comma_list(t.items, r.commas)
        self.token(r.rangle)
    
    def visit_callable(self, t):
        r = t.repr
        self.tokens([r.func, r.langle])
        t.ret_type.accept(self)
        self.token(r.lparen)
        self.comma_list(t.arg_types, r.commas)
        self.tokens([r.rparen, r.rangle])
    
    def type_vars(self, v):
        if v and v.repr:
            r = v.repr
            self.token(r.langle)
            for i in range(len(v.items)):
                d = v.items[i]
                self.token(d.repr.name)
                self.token(d.repr.is_tok)
                if d.bound:
                    self.type(d.bound)
                if i < len(r.commas):
                    self.token(r.commas[i])
            self.token(r.rangle)
    
    # Helpers
    
    def string(self, s):
        """Output a string."""
        self.result.append(s)
    
    def token(self, t):
        """Output a token."""
        self.result.append(t.rep())
    
    def tokens(self, a):
        """Output an array of tokens."""
        for t in a:
            self.token(t)
    
    def type(self, n):
        """Output a type."""
        if n: n.accept(self)
    
    def comma_list(self, items, commas):
        for i in range(len(items)):
            self.type(items[i])
            if i < len(commas):
                self.token(commas[i])

########NEW FILE########
__FILENAME__ = parse
"""Mypy parser.

Constructs a parse tree (abstract syntax tree) based on a string
representing a source file. Performs only minimal semantic checks.
"""

import re

from typing import Undefined, List, Tuple, Any, Set, cast

from mypy import lex
from mypy.lex import (
    Token, Eof, Bom, Break, Name, Colon, Dedent, IntLit, StrLit, BytesLit,
    UnicodeLit, FloatLit, Op, Indent, Keyword, Punct, LexError
)
import mypy.types
from mypy.nodes import (
    MypyFile, Import, Node, ImportAll, ImportFrom, FuncDef, OverloadedFuncDef,
    ClassDef, Decorator, Block, Var, VarDef, OperatorAssignmentStmt,
    ExpressionStmt, AssignmentStmt, ReturnStmt, RaiseStmt, AssertStmt,
    YieldStmt, DelStmt, BreakStmt, ContinueStmt, PassStmt, GlobalDecl,
    WhileStmt, ForStmt, IfStmt, TryStmt, WithStmt, CastExpr, ParenExpr,
    TupleExpr, GeneratorExpr, ListComprehension, ListExpr, ConditionalExpr,
    DictExpr, SetExpr, NameExpr, IntExpr, StrExpr, BytesExpr, UnicodeExpr,
    FloatExpr, CallExpr, SuperExpr, MemberExpr, IndexExpr, SliceExpr, OpExpr,
    UnaryExpr, FuncExpr, TypeApplication, PrintStmt
)
from mypy import nodes
from mypy import noderepr
from mypy.errors import Errors, CompileError
from mypy.types import Void, Type, Callable, AnyType, UnboundType
from mypy.parsetype import (
    parse_type, parse_types, parse_signature, TypeParseError
)


precedence = {
    '**': 16,
    '-u': 15, '+u': 15, '~': 15,   # unary operators (-, + and ~)
    '<cast>': 14,
    '*': 13, '/': 13, '//': 13, '%': 13,
    '+': 12, '-': 12,
    '>>': 11, '<<': 11,
    '&': 10,
    '^': 9,
    '|': 8,
    '==': 7, '!=': 7, '<': 7, '>': 7, '<=': 7, '>=': 7, 'is': 7, 'in': 7,
    'not': 6,
    'and': 5,
    'or': 4,
    '<if>': 3, # conditional expression
    '<for>': 2, # list comprehension
    ',': 1}


op_assign = set([
    '+=', '-=', '*=', '/=', '//=', '%=', '**=', '|=', '&=', '^=', '>>=',
    '<<='])


none = Token('') # Empty token


def parse(s: str, fnam: str = None, errors: Errors = None,
          pyversion: int = 3) -> MypyFile:
    """Parse a source file, without doing any semantic analysis.

    Return the parse tree. If errors is not provided, raise ParseError
    on failure. Otherwise, use the errors object to report parse errors.

    The pyversion argument determines the Python syntax variant (2 for 2.x and
    3 for 3.x).
    """
    parser = Parser(fnam, errors, pyversion)
    tree = parser.parse(s)
    tree.path = fnam
    return tree


class Parser:
    tok = Undefined(List[Token])
    ind = 0
    errors = Undefined(Errors)
    raise_on_error = False
    
    # Are we currently parsing the body of a class definition?
    is_class_body = False
    # All import nodes encountered so far in this parse unit.
    imports = Undefined(List[Node])
    
    def __init__(self, fnam: str, errors: Errors, pyversion: int) -> None:
        self.raise_on_error = errors is None
        self.pyversion = pyversion
        if errors is not None:
            self.errors = errors
        else:
            self.errors = Errors()
        if fnam is not None:
            self.errors.set_file(fnam)
        else:
            self.errors.set_file('<input>')
    
    def parse(self, s: str) -> MypyFile:
        self.tok = lex.lex(s)
        self.ind = 0
        self.imports = []
        file = self.parse_file()
        if self.raise_on_error and self.errors.is_errors():
            self.errors.raise_error()
        return file
    
    def parse_file(self) -> MypyFile:
        """Parse a mypy source file."""
        is_bom = self.parse_bom()
        defs = self.parse_defs()
        eof = self.expect_type(Eof)
        node = MypyFile(defs, self.imports, is_bom)
        self.set_repr(node, noderepr.MypyFileRepr(eof))
        return node
    
    # Parse the initial part
    
    def parse_bom(self) -> bool:
        """Parse the optional byte order mark at the beginning of a file."""
        if isinstance(self.current(), Bom):
            self.expect_type(Bom)
            if isinstance(self.current(), Break):
                self.expect_break()
            return True
        else:
            return False
    
    def parse_import(self) -> Import:
        import_tok = self.expect('import')
        ids = List[Tuple[str, str]]()
        id_toks = List[List[Token]]()
        commas = List[Token]()
        as_names = List[Tuple[Token, Token]]()
        while True:
            id, components = self.parse_qualified_name()
            id_toks.append(components)
            as_id = id
            if self.current_str() == 'as':
                as_tok = self.expect('as')
                name_tok = self.expect_type(Name)
                as_id = name_tok.string
                as_names.append((as_tok, name_tok))
            else:
                as_names.append(None)
            ids.append((id, as_id))
            if self.current_str() != ',':
                break
            commas.append(self.expect(','))
        br = self.expect_break()
        node = Import(ids)
        self.imports.append(node)
        self.set_repr(node, noderepr.ImportRepr(import_tok, id_toks, as_names,
                                                commas, br))
        return node
    
    def parse_import_from(self) -> Node:
        from_tok = self.expect('from')
        name, components = self.parse_qualified_name()
        import_tok = self.expect('import')
        name_toks = List[Tuple[List[Token], Token]]()
        lparen = none
        rparen = none
        node = Undefined(Node)
        if self.current_str() == '*':
            name_toks.append(([self.skip()], none))
            node = ImportAll(name)
        else:
            is_paren = self.current_str() == '('
            if is_paren:
                lparen = self.expect('(')
            targets = List[Tuple[str, str]]()
            while True:
                id, as_id, toks = self.parse_import_name()
                targets.append((id, as_id))
                if self.current_str() != ',':
                    name_toks.append((toks, none))
                    break
                name_toks.append((toks, self.expect(',')))
                if is_paren and self.current_str() == ')':
                    break
            if is_paren:
                rparen = self.expect(')')
            node = ImportFrom(name, targets)
        br = self.expect_break()
        self.imports.append(node)
        self.set_repr(node, noderepr.ImportFromRepr(
            from_tok, components,import_tok, lparen, name_toks, rparen, br))
        return node
    
    def parse_import_name(self) -> Tuple[str, str, List[Token]]:
        tok = self.expect_type(Name)
        name = tok.string
        tokens = [tok]
        if self.current_str() == 'as':
            tokens.append(self.skip())
            as_name = self.expect_type(Name)
            tokens.append(as_name)
            return name, as_name.string, tokens
        else:
            return name, name, tokens
    
    def parse_qualified_name(self) -> Tuple[str, List[Token]]:
        """Parse a name with an optional module qualifier.

        Return a tuple with the name as a string and a token array
        containing all the components of the name.
        """
        components = List[Token]()
        tok = self.expect_type(Name)
        n = tok.string
        components.append(tok)
        while self.current_str() == '.':
            components.append(self.expect('.'))
            tok = self.expect_type(Name)
            n += '.' + tok.string
            components.append(tok)
        return n, components
    
    # Parsing global definitions
    
    def parse_defs(self) -> List[Node]:
        defs = List[Node]()
        while not self.eof():
            try:
                defn = self.parse_statement()
                if defn is not None:
                    if not self.try_combine_overloads(defn, defs):
                        defs.append(defn)
            except ParseError:
                pass
        return defs
    
    def parse_class_def(self) -> ClassDef:
        old_is_class_body = self.is_class_body
        self.is_class_body = True
        
        type_tok = self.expect('class')
        lparen = none
        rparen = none
        metaclass = None # type: str
        
        try:
            commas, base_types = List[Token](), List[Type]()
            try:
                name_tok = self.expect_type(Name)
                name = name_tok.string
                
                self.errors.push_type(name)
                
                if self.current_str() == '(':
                    lparen = self.skip()
                    while True:
                        if self.current_str() == 'metaclass':
                            metaclass = self.parse_metaclass()
                            break
                        base_types.append(self.parse_super_type())
                        if self.current_str() != ',':
                            break
                        commas.append(self.skip())
                    rparen = self.expect(')')
            except ParseError:
                pass
            
            defs, _ = self.parse_block()
            
            node = ClassDef(name, defs, None, base_types, metaclass=metaclass)
            self.set_repr(node, noderepr.TypeDefRepr(type_tok, name_tok,
                                                     lparen, commas, rparen))
            return node
        finally:
            self.errors.pop_type()
            self.is_class_body = old_is_class_body
    
    def parse_super_type(self) -> Type:
        if (isinstance(self.current(), Name) and self.current_str() != 'void'):
            return self.parse_type()
        else:
            self.parse_error()

    def parse_metaclass(self) -> str:
        self.expect('metaclass')
        self.expect('=')
        return self.parse_qualified_name()[0]
    
    def parse_decorated_function_or_class(self) -> Node:
        ats = List[Token]()
        brs = List[Token]()
        decorators = List[Node]()
        while self.current_str() == '@':
            ats.append(self.expect('@'))
            decorators.append(self.parse_expression())
            brs.append(self.expect_break())
        if self.current_str() != 'class':
            func = self.parse_function()
            func.is_decorated = True
            var = Var(func.name())
            # Types of decorated functions must always be inferred.
            var.is_ready = False
            var.set_line(decorators[0].line)
            node = Decorator(func, decorators, var)
            self.set_repr(node, noderepr.DecoratorRepr(ats, brs))
            return node
        else:
            cls = self.parse_class_def()
            cls.decorators = decorators
            return cls
    
    def parse_function(self) -> FuncDef:
        def_tok = self.expect('def')
        is_method = self.is_class_body
        self.is_class_body = False
        try:
            (name, args, init, kinds,
             typ, is_error, toks) = self.parse_function_header()
            
            body, comment_type = self.parse_block(allow_type=True)
            if comment_type:
                # The function has a # type: ... signature.
                if typ:
                    self.errors.report(
                        def_tok.line, 'Function has duplicate type signatures')
                sig = cast(Callable, comment_type)
                if is_method:
                    self.check_argument_kinds(kinds,
                                              [nodes.ARG_POS] + sig.arg_kinds,
                                              def_tok.line)
                    # Add implicit 'self' argument to signature.
                    typ = Callable(List[Type]([AnyType()]) + sig.arg_types,
                                   kinds,
                                   [arg.name() for arg in args],
                                   sig.ret_type,
                                   False)
                else:
                    self.check_argument_kinds(kinds, sig.arg_kinds,
                                              def_tok.line)
                    typ = Callable(sig.arg_types,
                                   kinds,
                                   [arg.name() for arg in args],
                                   sig.ret_type,
                                   False)
            
            # If there was a serious error, we really cannot build a parse tree
            # node.
            if is_error:
                return None
            
            node = FuncDef(name, args, kinds, init, body, typ)
            name_tok, arg_reprs = toks
            node.set_line(name_tok)
            self.set_repr(node, noderepr.FuncRepr(def_tok, name_tok,
                                                  arg_reprs))
            return node
        finally:
            self.errors.pop_function()
            self.is_class_body = is_method

    def check_argument_kinds(self, funckinds: List[int], sigkinds: List[int],
                             line: int) -> None:
        """Check that * and ** arguments are consistent.

        Arguments:
          funckinds: kinds of arguments in function definition
          sigkinds:  kinds of arguments in signature (after # type:)
        """
        for kind, token in [(nodes.ARG_STAR, '*'),
                            (nodes.ARG_STAR2, '**')]:
            if ((kind in funckinds and
                 sigkinds[funckinds.index(kind)] != kind) or
                (funckinds.count(kind) != sigkinds.count(kind))):
                self.fail(
                    "Inconsistent use of '{}' in function "
                    "signature".format(token), line)
    
    def parse_function_header(self) -> Tuple[str, List[Var], List[Node],
                                             List[int], Type, bool,
                                             Tuple[Token, Any]]:
        """Parse function header (a name followed by arguments)

        Returns a 7-tuple with the following items:
          name
          arguments
          initializers
          kinds
          signature (annotation)
          error flag (True if error)
          (name token, representation of arguments)
        """        
        name_tok = none
        
        try:
            name_tok = self.expect_type(Name)
            name = name_tok.string
            
            self.errors.push_function(name)
            
            (args, init, kinds, typ, arg_repr) = self.parse_args()
        except ParseError:
            if not isinstance(self.current(), Break):
                self.ind -= 1 # Kludge: go back to the Break token
            # Resynchronise parsing by going back over :, if present.
            if isinstance(self.tok[self.ind - 1], Colon):
                self.ind -= 1
            return (name, [], [], [], None, True, (name_tok, None))
        
        return (name, args, init, kinds, typ, False, (name_tok, arg_repr))
    
    def parse_args(self) -> Tuple[List[Var], List[Node], List[int], Type,
                                  noderepr.FuncArgsRepr]:
        """Parse a function signature (...) [-> t]."""
        lparen = self.expect('(')
        
        # Parse the argument list (everything within '(' and ')').
        (args, init, kinds,
         has_inits, arg_names,
         commas, asterisk,
         assigns, arg_types) = self.parse_arg_list()
        
        rparen = self.expect(')')

        if self.current_str() == '-':
            self.skip()
            self.expect('>')
            ret_type = self.parse_type()
        else:
            ret_type = None

        self.verify_argument_kinds(kinds, lparen.line)
        
        names = [] # type: List[str]
        for arg in args:
            names.append(arg.name())
        
        annotation = self.build_func_annotation(
            ret_type, arg_types, kinds, names, lparen.line)
        
        return (args, init, kinds, annotation,
                noderepr.FuncArgsRepr(lparen, rparen, arg_names, commas,
                                      assigns, asterisk))
    
    def build_func_annotation(self, ret_type: Type, arg_types: List[Type],
                              kinds: List[int], names: List[str], 
                              line: int, is_default_ret: bool = False) -> Type:
        # Are there any type annotations?
        if ((ret_type and not is_default_ret)
                or arg_types != [None] * len(arg_types)):
            # Yes. Construct a type for the function signature.
            return self.construct_function_type(arg_types, kinds, names,
                                                ret_type, line)
        else:
            return None
    
    def parse_arg_list(
        self, allow_signature: bool = True) -> Tuple[List[Var], List[Node],
                                                     List[int], bool,
                                                     List[Token], List[Token],
                                                     List[Token], List[Token],
                                                     List[Type]]:
        """Parse function definition argument list.

        This includes everything between '(' and ')').

        Return a 9-tuple with these items:
          arguments, initializers, kinds, has inits, arg name tokens,
          comma tokens, asterisk tokens, assignment tokens, argument types
        """
        args = []  # type: List[Var]
        kinds = [] # type: List[int]
        names = [] # type: List[str]
        init = []  # type: List[Node]
        has_inits = False
        arg_types = [] # type: List[Type]        
        
        arg_names = [] # type: List[Token]
        commas = []    # type: List[Token]
        asterisk = []  # type: List[Token]
        assigns = []   # type: List[Token]
        
        require_named = False
        
        if self.current_str() != ')' and self.current_str() != ':':
            while self.current_str() != ')':
                if self.current_str() == '*' and self.peek().string == ',':
                    self.expect('*')
                    require_named = True
                elif self.current_str() in ['*', '**']:
                    asterisk.append(self.skip())
                    isdict = asterisk[-1].string == '**'
                    name = self.expect_type(Name)
                    arg_names.append(name)
                    names.append(name.string)
                    var_arg = Var(name.string)
                    self.set_repr(var_arg, noderepr.VarRepr(name, none))
                    args.append(var_arg)
                    init.append(None)
                    assigns.append(none)
                    if isdict:
                        kinds.append(nodes.ARG_STAR2)
                    else:
                        kinds.append(nodes.ARG_STAR)
                    arg_types.append(self.parse_arg_type(allow_signature))
                    require_named = True
                else:
                    name = self.expect_type(Name)
                    arg_names.append(name)
                    args.append(Var(name.string))
                    arg_types.append(self.parse_arg_type(allow_signature))
                    
                    if self.current_str() == '=':
                        assigns.append(self.expect('='))
                        init.append(self.parse_expression(precedence[',']))
                        has_inits = True
                        if require_named:
                            kinds.append(nodes.ARG_NAMED)
                        else:
                            kinds.append(nodes.ARG_OPT)
                    else:
                        if require_named:
                            self.parse_error()
                        init.append(None)
                        assigns.append(none)
                        kinds.append(nodes.ARG_POS)
                        
                if self.current().string != ',':
                    break
                commas.append(self.expect(','))
        
        return (args, init, kinds, has_inits, arg_names, commas, asterisk,
                assigns, arg_types)

    def parse_arg_type(self, allow_signature: bool) -> Type:
        if self.current_str() == ':' and allow_signature:
            self.skip()
            return self.parse_type()
        else:
            return None

    def verify_argument_kinds(self, kinds: List[int], line: int) -> None:
        found = Set[int]()
        for i, kind in enumerate(kinds):
            if kind == nodes.ARG_POS and found & set([nodes.ARG_OPT,
                                                      nodes.ARG_STAR,
                                                      nodes.ARG_STAR2]):
                self.fail('Invalid argument list', line)
            elif kind == nodes.ARG_STAR and nodes.ARG_STAR in found:
                self.fail('Invalid argument list', line)
            elif kind == nodes.ARG_STAR2 and i != len(kinds) - 1:
                self.fail('Invalid argument list', line)
            found.add(kind)
    
    def construct_function_type(self, arg_types: List[Type], kinds: List[int],
                                names: List[str], ret_type: Type,
                                line: int) -> Callable:
        # Complete the type annotation by replacing omitted types with 'Any'.
        arg_types = arg_types[:]
        for i in range(len(arg_types)):
            if arg_types[i] is None:
                arg_types[i] = AnyType()
        if ret_type is None:
            ret_type = AnyType()
        return Callable(arg_types, kinds, names, ret_type, False, None,
                        None, [], line, None)
    
    # Parsing statements
    
    def parse_block(self, allow_type: bool = False) -> Tuple[Block, Type]:
        colon = self.expect(':')
        if not isinstance(self.current(), Break):
            # Block immediately after ':'.
            node = Block([self.parse_statement()]).set_line(colon)
            self.set_repr(node, noderepr.BlockRepr(colon, none, none, none))
            return cast(Block, node), None
        else:
            # Indented block.
            br = self.expect_break()
            type = self.parse_type_comment(br, signature=True)
            indent = self.expect_indent()
            stmt = [] # type: List[Node]
            while (not isinstance(self.current(), Dedent) and
                   not isinstance(self.current(), Eof)):
                try:
                    s = self.parse_statement()
                    if s is not None:
                        if not self.try_combine_overloads(s, stmt):
                            stmt.append(s)
                except ParseError:
                    pass
            dedent = none
            if isinstance(self.current(), Dedent):
                dedent = self.skip()
            node = Block(stmt).set_line(colon) 
            self.set_repr(node, noderepr.BlockRepr(colon, br, indent, dedent))
            return cast(Block, node), type

    def try_combine_overloads(self, s: Node, stmt: List[Node]) -> bool:
        if isinstance(s, Decorator) and stmt:
            fdef = cast(Decorator, s)
            n = fdef.func.name()
            if (isinstance(stmt[-1], Decorator) and
                    (cast(Decorator, stmt[-1])).func.name() == n):
                stmt[-1] = OverloadedFuncDef([cast(Decorator, stmt[-1]), fdef])
                return True
            elif (isinstance(stmt[-1], OverloadedFuncDef) and
                      (cast(OverloadedFuncDef, stmt[-1])).name() == n):
                (cast(OverloadedFuncDef, stmt[-1])).items.append(fdef)
                return True
        return False
    
    def parse_statement(self) -> Node:
        stmt = Undefined # type: Node
        t = self.current()
        ts = self.current_str()
        if ts == 'if':
            stmt = self.parse_if_stmt()
        elif ts == 'def':
            stmt = self.parse_function()
        elif ts == 'while':
            stmt = self.parse_while_stmt()
        elif ts == 'return':
            stmt = self.parse_return_stmt()
        elif ts == 'for':
            stmt = self.parse_for_stmt()
        elif ts == 'try':
            stmt = self.parse_try_stmt()
        elif ts == 'break':
            stmt = self.parse_break_stmt()
        elif ts == 'continue':
            stmt = self.parse_continue_stmt()
        elif ts == 'pass':
            stmt = self.parse_pass_stmt()
        elif ts == 'raise':
            stmt = self.parse_raise_stmt()
        elif ts == 'import':
            stmt = self.parse_import()
        elif ts == 'from':
            stmt = self.parse_import_from()
        elif ts == 'class':
            stmt = self.parse_class_def()
        elif ts == 'global':
            stmt = self.parse_global_decl()
        elif ts == 'assert':
            stmt = self.parse_assert_stmt()
        elif ts == 'yield':
            stmt = self.parse_yield_stmt()
        elif ts == 'del':
            stmt = self.parse_del_stmt()
        elif ts == 'with':
            stmt = self.parse_with_stmt()
        elif ts == '@':
            stmt = self.parse_decorated_function_or_class()
        elif ts == 'print' and self.pyversion == 2:
            stmt = self.parse_print_stmt()
        else:
            stmt = self.parse_expression_or_assignment()
        if stmt is not None:
            stmt.set_line(t)
        return stmt
    
    def parse_expression_or_assignment(self) -> Node:
        e = self.parse_expression()
        if self.current_str() == '=':
            return self.parse_assignment(e)
        elif self.current_str() in op_assign:
            # Operator assignment statement.
            op = self.current_str()[:-1]
            assign = self.skip()
            r = self.parse_expression()
            br = self.expect_break()
            node = OperatorAssignmentStmt(op, e, r)
            self.set_repr(node,
                          noderepr.OperatorAssignmentStmtRepr(assign, br))
            return node
        else:
            # Expression statement.
            br = self.expect_break()
            expr = ExpressionStmt(e)
            self.set_repr(expr, noderepr.ExpressionStmtRepr(br))
            return expr
    
    def parse_assignment(self, lv: Any) -> Node:
        """Parse an assignment statement.

        Assume that lvalue has been parsed already, and the current token is =.
        Also parse an optional '# type:' comment.
        """
        assigns = [self.expect('=')]
        lvalues = [lv]
        
        e = self.parse_expression()
        while self.current_str() == '=':
            lvalues.append(e)
            assigns.append(self.skip())
            e = self.parse_expression()
        br = self.expect_break()

        type = self.parse_type_comment(br, signature=False)
        assignment = AssignmentStmt(lvalues, e, type)
        self.set_repr(assignment, noderepr.AssignmentStmtRepr(assigns, br))
        return assignment
    
    def parse_return_stmt(self) -> ReturnStmt:
        return_tok = self.expect('return')
        expr = None # type: Node
        if not isinstance(self.current(), Break):
            expr = self.parse_expression()
        br = self.expect_break()
        node = ReturnStmt(expr)
        self.set_repr(node, noderepr.SimpleStmtRepr(return_tok, br))
        return node
    
    def parse_raise_stmt(self) -> RaiseStmt:
        raise_tok = self.expect('raise')
        expr = None # type: Node
        from_expr = None # type: Node
        from_tok = none
        if not isinstance(self.current(), Break):
            expr = self.parse_expression()
            if self.current_str() == 'from':
                from_tok = self.expect('from')
                from_expr = self.parse_expression()
        br = self.expect_break()
        node = RaiseStmt(expr, from_expr)
        self.set_repr(node, noderepr.RaiseStmtRepr(raise_tok, from_tok, br))
        return node
    
    def parse_assert_stmt(self) -> AssertStmt:
        assert_tok = self.expect('assert')
        expr = self.parse_expression()
        br = self.expect_break()
        node = AssertStmt(expr)
        self.set_repr(node, noderepr.SimpleStmtRepr(assert_tok, br))
        return node
    
    def parse_yield_stmt(self) -> YieldStmt:
        yield_tok = self.expect('yield')
        expr = None # type: Node
        if not isinstance(self.current(), Break):
            expr = self.parse_expression()
        br = self.expect_break()
        node = YieldStmt(expr)
        self.set_repr(node, noderepr.SimpleStmtRepr(yield_tok, br))
        return node
    
    def parse_del_stmt(self) -> DelStmt:
        del_tok = self.expect('del')
        expr = self.parse_expression()
        br = self.expect_break()
        node = DelStmt(expr)
        self.set_repr(node, noderepr.SimpleStmtRepr(del_tok, br))
        return node
    
    def parse_break_stmt(self) -> BreakStmt:
        break_tok = self.expect('break')
        br = self.expect_break()
        node = BreakStmt()
        self.set_repr(node, noderepr.SimpleStmtRepr(break_tok, br))
        return node
    
    def parse_continue_stmt(self) -> ContinueStmt:
        continue_tok = self.expect('continue')
        br = self.expect_break()
        node = ContinueStmt()
        self.set_repr(node, noderepr.SimpleStmtRepr(continue_tok, br))
        return node
    
    def parse_pass_stmt(self) -> PassStmt:
        pass_tok = self.expect('pass')
        br = self.expect_break()
        node = PassStmt()
        self.set_repr(node, noderepr.SimpleStmtRepr(pass_tok, br))
        return node
    
    def parse_global_decl(self) -> GlobalDecl:
        global_tok = self.expect('global')
        names = List[str]()
        name_toks = List[Token]()
        commas = List[Token]()
        while True:
            n = self.expect_type(Name)
            names.append(n.string)
            name_toks.append(n)
            if self.current_str() != ',':
                break
            commas.append(self.skip())
        br = self.expect_break()
        node = GlobalDecl(names)
        self.set_repr(node, noderepr.GlobalDeclRepr(global_tok, name_toks,
                                                    commas, br))
        return node
    
    def parse_while_stmt(self) -> WhileStmt:
        is_error = False
        while_tok = self.expect('while')
        try:
            expr = self.parse_expression()
        except ParseError:
            is_error = True
        body, _ = self.parse_block()
        if self.current_str() == 'else':
            else_tok = self.expect('else')
            else_body, _ = self.parse_block()
        else:
            else_body = None
            else_tok = none
        if is_error is not None:
            node = WhileStmt(expr, body, else_body)
            self.set_repr(node, noderepr.WhileStmtRepr(while_tok, else_tok))
            return node
        else:
            return None
    
    def parse_for_stmt(self) -> ForStmt:
        for_tok = self.expect('for')
        index, types, commas = self.parse_for_index_variables()
        in_tok = self.expect('in')
        expr = self.parse_expression()
        
        body, _ = self.parse_block()
        
        if self.current_str() == 'else':
            else_tok = self.expect('else')
            else_body, _ = self.parse_block()
        else:
            else_body = None
            else_tok = none
        
        node = ForStmt(index, expr, body, else_body, types)
        self.set_repr(node, noderepr.ForStmtRepr(for_tok, commas, in_tok,
                                                 else_tok))
        return node
    
    def parse_for_index_variables(self) -> Tuple[List[NameExpr], List[Type],
                                                 List[Token]]:
        # Parse index variables of a 'for' statement.
        index = List[NameExpr]()
        types = List[Type]()
        commas = List[Token]()
        
        is_paren = self.current_str() == '('
        if is_paren:
            self.skip()
        
        while True:
            v = self.parse_name_expr()
            index.append(v)
            types.append(None)
            if self.current_str() != ',':
                commas.append(none)
                break
            commas.append(self.skip())
        
        if is_paren:
            self.expect(')')
        
        return index, types, commas
    
    def parse_if_stmt(self) -> IfStmt:
        is_error = False
        
        if_tok = self.expect('if')
        expr = List[Node]()
        try:
            expr.append(self.parse_expression())
        except ParseError:
            is_error = True
        
        body = [self.parse_block()[0]]
        
        elif_toks = List[Token]()
        while self.current_str() == 'elif':
            elif_toks.append(self.expect('elif'))
            try:
                expr.append(self.parse_expression())
            except ParseError:
                is_error = True
            body.append(self.parse_block()[0])
        
        if self.current_str() == 'else':
            else_tok = self.expect('else')
            else_body, _ = self.parse_block()
        else:
            else_tok = none
            else_body = None
        
        if not is_error:
            node = IfStmt(expr, body, else_body)
            self.set_repr(node, noderepr.IfStmtRepr(if_tok, elif_toks,
                                                    else_tok))
            return node
        else:
            return None
    
    def parse_try_stmt(self) -> Node:
        try_tok = self.expect('try')
        body, _ = self.parse_block()
        is_error = False
        vars = List[NameExpr]()
        types = List[Node]()
        handlers = List[Block]()
        except_toks, name_toks, as_toks, except_brs = (List[Token](),
                                                       List[Token](),
                                                       List[Token](),
                                                       List[Token]())
        while self.current_str() == 'except':
            except_toks.append(self.expect('except'))
            if not isinstance(self.current(), Colon):
                try:
                    t = self.current()
                    types.append(self.parse_expression().set_line(t))
                    if self.current_str() == 'as':
                        as_toks.append(self.expect('as'))
                        vars.append(self.parse_name_expr())
                    else:
                        name_toks.append(none)
                        vars.append(None)
                        as_toks.append(none)
                except ParseError:
                    is_error = True
            else:
                types.append(None)
                vars.append(None)
                as_toks.append(none)
            handlers.append(self.parse_block()[0])
        if not is_error:
            if self.current_str() == 'else':
                else_tok = self.skip()
                else_body, _ = self.parse_block()
            else:
                else_tok = none
                else_body = None
            if self.current_str() == 'finally':
                finally_tok = self.expect('finally')
                finally_body, _ = self.parse_block()
            else:
                finally_tok = none
                finally_body = None
            node = TryStmt(body, vars, types, handlers, else_body,
                           finally_body)
            self.set_repr(node, noderepr.TryStmtRepr(try_tok, except_toks,
                                                     name_toks, as_toks,
                                                     else_tok, finally_tok))
            return node
        else:
            return None
    
    def parse_with_stmt(self) -> WithStmt:
        with_tok = self.expect('with')
        as_toks = List[Token]()
        commas = List[Token]()
        expr = List[Node]()
        name = List[NameExpr]()
        while True:
            e = self.parse_expression(precedence[','])
            if self.current_str() == 'as':
                as_toks.append(self.expect('as'))
                n = self.parse_name_expr()
            else:
                as_toks.append(none)
                n = None
            expr.append(e)
            name.append(n)
            if self.current_str() != ',':
                break
            commas.append(self.expect(','))
        body, _ = self.parse_block()
        node = WithStmt(expr, name, body)
        self.set_repr(node, noderepr.WithStmtRepr(with_tok, as_toks, commas))
        return node

    def parse_print_stmt(self) -> PrintStmt:
        self.expect('print')
        args = List[Node]()
        while not isinstance(self.current(), Break):
            args.append(self.parse_expression(precedence[',']))
            if self.current_str() == ',':
                comma = True
                self.skip()
            else:
                comma = False
                break
        self.expect_break()
        return PrintStmt(args, newline=not comma)
    
    # Parsing expressions
    
    def parse_expression(self, prec: int = 0) -> Node:
        """Parse a subexpression within a specific precedence context."""
        expr = Undefined # type: Node
        t = self.current() # Remember token for setting the line number.
        
        # Parse a "value" expression or unary operator expression and store
        # that in expr.
        s = self.current_str()
        if s == '(':
            # Parerenthesised expression or cast.
            expr = self.parse_parentheses()
        elif s == '[':
            expr = self.parse_list_expr()
        elif s in ['-', '+', 'not', '~']:
            # Unary operation.
            expr = self.parse_unary_expr()
        elif s == 'lambda':
            expr = self.parse_lambda_expr()
        elif s == '{':
            expr = self.parse_dict_or_set_expr()
        else:
            if isinstance(self.current(), Name):
                # Name expression.
                expr = self.parse_name_expr()
            elif isinstance(self.current(), IntLit):
                expr = self.parse_int_expr()
            elif isinstance(self.current(), StrLit):
                expr = self.parse_str_expr()
            elif isinstance(self.current(), BytesLit):
                expr = self.parse_bytes_literal()
            elif isinstance(self.current(), UnicodeLit):
                expr = self.parse_unicode_literal()
            elif isinstance(self.current(), FloatLit):
                expr = self.parse_float_expr()
            else:
                # Invalid expression.
                self.parse_error()
        
        # Set the line of the expression node, if not specified. This
        # simplifies recording the line number as not every node type needs to
        # deal with it separately.
        if expr.line < 0:
            expr.set_line(t)
        
        # Parse operations that require a left argument (stored in expr).
        while True:
            t = self.current()
            s = self.current_str()
            if s == '(':
                # Call expression.
                expr = self.parse_call_expr(expr)
            elif s == '.':
                # Member access expression.
                expr = self.parse_member_expr(expr)
            elif s == '[':
                # Indexing expression.
                expr = self.parse_index_expr(expr)
            elif s == ',':
                # The comma operator is used to build tuples. Comma also
                # separates array items and function arguments, but in this
                # case the precedence is too low to build a tuple.
                if precedence[','] > prec:
                    expr = self.parse_tuple_expr(expr)
                else:
                    break
            elif s == 'for':
                if precedence['<for>'] > prec:
                    # List comprehension or generator expression. Parse as
                    # generator expression; it will be converted to list
                    # comprehension if needed elsewhere.
                    expr = self.parse_generator_expr(expr)
                else:
                    break                              
            elif s == 'if':
                # Conditional expression.
                if precedence['<if>'] > prec:
                    expr = self.parse_conditional_expr(expr)
                else:
                    break
            else:
                # Binary operation or a special case.
                if isinstance(self.current(), Op):
                    op = self.current_str()
                    op_prec = precedence[op]
                    if op == 'not':
                        # Either "not in" or an error.
                        op_prec = precedence['in']
                    if op_prec > prec:
                        expr = self.parse_bin_op_expr(expr, op_prec)
                    else:
                        # The operation cannot be associated with the
                        # current left operand due to the precedence
                        # context; let the caller handle it.
                        break
                else:
                    # Not an operation that accepts a left argument; let the
                    # caller handle the rest.
                    break
            
            # Set the line of the expression node, if not specified. This
            # simplifies recording the line number as not every node type
            # needs to deal with it separately.
            if expr.line < 0:
                expr.set_line(t)
        
        return expr
    
    def parse_parentheses(self) -> Node:
        lparen = self.skip()
        if self.current_str() == ')':
            # Empty tuple ().
            expr = self.parse_empty_tuple_expr(lparen) # type: Node
        else:
            # Parenthesised expression.
            expr = self.parse_expression(0)
            rparen = self.expect(')')
            expr = ParenExpr(expr)
            self.set_repr(expr, noderepr.ParenExprRepr(lparen, rparen))
        return expr
    
    def parse_empty_tuple_expr(self, lparen: Any) -> TupleExpr:
        rparen = self.expect(')')
        node = TupleExpr([])
        self.set_repr(node, noderepr.TupleExprRepr(lparen, [], rparen))
        return node
    
    def parse_list_expr(self) -> Node:
        """Parse list literal or list comprehension."""
        items = List[Node]()
        lbracket = self.expect('[')
        commas = List[Token]()
        while self.current_str() != ']' and not self.eol():
            items.append(self.parse_expression(precedence['<for>']))
            if self.current_str() != ',':
                break
            commas.append(self.expect(','))
        if self.current_str() == 'for' and len(items) == 1:
            items[0] = self.parse_generator_expr(items[0])            
        rbracket = self.expect(']')
        if len(items) == 1 and isinstance(items[0], GeneratorExpr):
             list_comp = ListComprehension(cast(GeneratorExpr, items[0]))
             self.set_repr(list_comp, noderepr.ListComprehensionRepr(lbracket,
                                                                     rbracket))
             return list_comp
        else:
            expr = ListExpr(items)
            self.set_repr(expr, noderepr.ListSetExprRepr(lbracket, commas,
                                                         rbracket, none, none))
            return expr
    
    def parse_generator_expr(self, left_expr: Node) -> GeneratorExpr:
        for_tok = self.expect('for')
        index, types, commas = self.parse_for_index_variables()
        in_tok = self.expect('in')
        right_expr = self.parse_expression_list()
        if self.current_str() == 'if':
            if_tok = self.skip()
            cond = self.parse_expression()
        else:
            if_tok = none
            cond = None
        gen = GeneratorExpr(left_expr, index, types, right_expr, cond)
        gen.set_line(for_tok)
        self.set_repr(gen, noderepr.GeneratorExprRepr(for_tok, commas, in_tok,
                                                      if_tok))
        return gen
    
    def parse_expression_list(self) -> Node:
        prec = precedence['<if>']
        expr = self.parse_expression(prec)
        if self.current_str() != ',':
            return expr
        else:
            t = self.current()
            return self.parse_tuple_expr(expr, prec).set_line(t)
    
    def parse_conditional_expr(self, left_expr: Node) -> ConditionalExpr:
        self.expect('if')
        cond = self.parse_expression(precedence['<if>'])
        self.expect('else')
        else_expr = self.parse_expression(precedence['<if>'])
        return ConditionalExpr(cond, left_expr, else_expr)
    
    def parse_dict_or_set_expr(self) -> Node:
        items = List[Tuple[Node, Node]]()
        lbrace = self.expect('{')
        colons = List[Token]()
        commas = List[Token]()
        while self.current_str() != '}' and not self.eol():
            key = self.parse_expression(precedence[','])
            if self.current_str() in [',', '}'] and items == []:
                return self.parse_set_expr(key, lbrace)
            elif self.current_str() != ':':
                self.parse_error()
            colons.append(self.expect(':'))
            value = self.parse_expression(precedence[','])
            items.append((key, value))
            if self.current_str() != ',':
                break
            commas.append(self.expect(','))
        rbrace = self.expect('}')
        node = DictExpr(items)
        self.set_repr(node, noderepr.DictExprRepr(lbrace, colons, commas,
                                                  rbrace, none, none, none))
        return node
    
    def parse_set_expr(self, first: Node, lbrace: Token) -> SetExpr:
        items = [first]
        commas = List[Token]()
        while self.current_str() != '}' and not self.eol():
            commas.append(self.expect(','))
            if self.current_str() == '}':
                break
            items.append(self.parse_expression(precedence[',']))
        rbrace = self.expect('}')
        expr = SetExpr(items)
        self.set_repr(expr, noderepr.ListSetExprRepr(lbrace, commas,
                                                     rbrace, none, none))
        return expr
    
    def parse_tuple_expr(self, expr: Node,
                         prec: int = precedence[',']) -> TupleExpr:
        items = [expr]
        commas = List[Token]()
        while True:
            commas.append(self.expect(','))
            if (self.current_str() in [')', ']', '='] or
                    isinstance(self.current(), Break)):
                break
            items.append(self.parse_expression(prec))
            if self.current_str() != ',': break
        node = TupleExpr(items)
        self.set_repr(node, noderepr.TupleExprRepr(none, commas, none))
        return node
    
    def parse_name_expr(self) -> NameExpr:
        tok = self.expect_type(Name)
        node = NameExpr(tok.string)
        node.set_line(tok)
        self.set_repr(node, noderepr.NameExprRepr(tok))
        return node
    
    def parse_int_expr(self) -> IntExpr:
        tok = self.expect_type(IntLit)
        s = tok.string
        v = 0
        if len(s) > 2 and s[1] in 'xX':
            v = int(s[2:], 16)
        elif len(s) > 2 and s[1] in 'oO':
            v = int(s[2:], 8)
        else:
            v = int(s)
        node = IntExpr(v)
        self.set_repr(node, noderepr.IntExprRepr(tok))
        return node
    
    def parse_str_expr(self) -> StrExpr:
        # XXX \uxxxx literals
        tok = [self.expect_type(StrLit)]
        value = (cast(StrLit, tok[0])).parsed()
        while isinstance(self.current(), StrLit):
            t = cast(StrLit, self.skip())
            tok.append(t)
            value += t.parsed()
        node = StrExpr(value)
        self.set_repr(node, noderepr.StrExprRepr(tok))
        return node
    
    def parse_bytes_literal(self) -> Node:
        # XXX \uxxxx literals
        tok = [self.expect_type(BytesLit)]
        value = (cast(BytesLit, tok[0])).parsed()
        while isinstance(self.current(), BytesLit):
            t = cast(BytesLit, self.skip())
            tok.append(t)
            value += t.parsed()
        if self.pyversion >= 3:
            node = BytesExpr(value) # type: Node
        else:
            node = StrExpr(value)
        self.set_repr(node, noderepr.StrExprRepr(tok))
        return node
    
    def parse_unicode_literal(self) -> Node:
        # XXX \uxxxx literals
        tok = [self.expect_type(UnicodeLit)]
        value = (cast(UnicodeLit, tok[0])).parsed()
        while isinstance(self.current(), UnicodeLit):
            t = cast(UnicodeLit, self.skip())
            tok.append(t)
            value += t.parsed()
        if self.pyversion >= 3:
            # Python 3.3 supports u'...' as an alias of '...'.
            node = StrExpr(value) # type: Node
        else:
            node = UnicodeExpr(value)
        self.set_repr(node, noderepr.StrExprRepr(tok))
        return node
    
    def parse_float_expr(self) -> FloatExpr:
        tok = self.expect_type(FloatLit)
        node = FloatExpr(float(tok.string))
        self.set_repr(node, noderepr.FloatExprRepr(tok))
        return node
    
    def parse_call_expr(self, callee: Any) -> CallExpr:
        lparen = self.expect('(')
        (args, kinds, names,
         commas, star, star2, assigns) = self.parse_arg_expr()
        rparen = self.expect(')')
        node = CallExpr(callee, args, kinds, names)
        self.set_repr(node, noderepr.CallExprRepr(lparen, commas, star, star2,
                                                  assigns, rparen))
        return node
    
    def parse_arg_expr(self) -> Tuple[List[Node], List[int], List[str],
                                      List[Token], Token, Token,
                                      List[List[Token]]]:
        """Parse arguments in a call expression (within '(' and ')').

        Return a tuple with these items:
          argument expressions
          argument kinds
          argument names (for named arguments; None for ordinary args)
          comma tokens
          * token (if any)
          ** token (if any)
          (assignment, name) tokens
        """        
        args = []  # type: List[Node]
        kinds = [] # type: List[int]
        names = [] # type: List[str]
        star = none
        star2 = none
        commas = []   # type: List[Token]
        keywords = [] # type: List[List[Token]]
        var_arg = False
        dict_arg = False
        named_args = False
        while self.current_str() != ')' and not self.eol() and not dict_arg:
            if isinstance(self.current(), Name) and self.peek().string == '=':
                # Named argument
                name = self.expect_type(Name)
                assign = self.expect('=')
                kinds.append(nodes.ARG_NAMED)
                names.append(name.string)
                keywords.append([name, assign])
                named_args = True
            elif (self.current_str() == '*' and not var_arg and not dict_arg
                    and not named_args):
                # *args
                var_arg = True
                star = self.expect('*')
                kinds.append(nodes.ARG_STAR)
                names.append(None)
            elif self.current_str() == '**':
                # **kwargs
                star2 = self.expect('**')
                dict_arg = True
                kinds.append(nodes.ARG_STAR2)
                names.append(None)
            elif not var_arg and not named_args:
                # Ordinary argument
                kinds.append(nodes.ARG_POS)
                names.append(None)
            else:
                self.parse_error()
            args.append(self.parse_expression(precedence[',']))
            if self.current_str() != ',':
                break
            commas.append(self.expect(','))
        return args, kinds, names, commas, star, star2, keywords
    
    def parse_member_expr(self, expr: Any) -> Node:
        dot = self.expect('.')
        name = self.expect_type(Name)
        node = Undefined(Node)
        if (isinstance(expr, CallExpr) and isinstance(expr.callee, NameExpr)
                and expr.callee.name == 'super'):
            # super() expression
            node = SuperExpr(name.string)
            self.set_repr(node,
                          noderepr.SuperExprRepr(expr.callee.repr.id,
                                                 expr.repr.lparen,
                                                 expr.repr.rparen, dot, name))
        else:
            node = MemberExpr(expr, name.string)
            self.set_repr(node, noderepr.MemberExprRepr(dot, name))
        return node
    
    def parse_index_expr(self, base: Any) -> IndexExpr:
        lbracket = self.expect('[')
        if self.current_str() != ':':
            index = self.parse_expression(0)
        else:
            index = None
        if self.current_str() == ':':
            # Slice.
            colon = self.expect(':')
            if self.current_str() != ']' and self.current_str() != ':':
                end_index = self.parse_expression(0)
            else:
                end_index = None
            colon2 = none
            stride = None # type: Node
            if self.current_str() == ':':
                colon2 = self.expect(':')
                if self.current_str() != ']':
                    stride = self.parse_expression()
            index = SliceExpr(index, end_index, stride).set_line(colon.line)
            self.set_repr(index, noderepr.SliceExprRepr(colon, colon2))
        rbracket = self.expect(']')
        node = IndexExpr(base, index)
        self.set_repr(node, noderepr.IndexExprRepr(lbracket, rbracket))
        return node
    
    def parse_bin_op_expr(self, left: Node, prec: int) -> OpExpr:
        op = self.expect_type(Op)
        op2 = none
        op_str = op.string
        if op_str == 'not':
            if self.current_str() == 'in':
                op_str = 'not in'
                op2 = self.skip()
            else:
                self.parse_error()
        elif op_str == 'is' and self.current_str() == 'not':
            op_str = 'is not'
            op2 = self.skip()
        elif op_str == '~':
            self.ind -= 1
            self.parse_error()
        right = self.parse_expression(prec)
        node = OpExpr(op_str, left, right)
        self.set_repr(node, noderepr.OpExprRepr(op, op2))
        return node
    
    def parse_unary_expr(self) -> UnaryExpr:
        op_tok = self.skip()
        op = op_tok.string
        if op == '-' or op == '+':
            prec = precedence['-u']
        else:
            prec = precedence[op]
        expr = self.parse_expression(prec)
        node = UnaryExpr(op, expr)
        self.set_repr(node, noderepr.UnaryExprRepr(op_tok))
        return node
    
    def parse_lambda_expr(self) -> FuncExpr:
        is_error = False
        lambda_tok = self.expect('lambda')
        
        (args, init, kinds, has_inits,
         arg_names, commas, asterisk,
         assigns, arg_types) = self.parse_arg_list(allow_signature=False)

        names = List[str]()
        for arg in args:
            names.append(arg.name())

        # Use 'object' as the placeholder return type; it will be inferred
        # later. We can't use 'Any' since it could make type inference results
        # less precise.
        ret_type = UnboundType('__builtins__.object')
        typ = self.build_func_annotation(ret_type, arg_types, kinds, names,
                                         lambda_tok.line, is_default_ret=True)
        
        colon = self.expect(':')
        
        expr = self.parse_expression(precedence[','])
        
        body = Block([ReturnStmt(expr).set_line(lambda_tok)])
        body.set_line(colon)
        
        node = FuncExpr(args, kinds, init, body, typ)
        self.set_repr(node,
                      noderepr.FuncExprRepr(
                          lambda_tok, colon,
                          noderepr.FuncArgsRepr(none, none, arg_names, commas,
                                                assigns, asterisk)))
        return node
    
    # Helper methods
    
    def skip(self) -> Token:
        self.ind += 1
        return self.tok[self.ind - 1]
    
    def expect(self, string: str) -> Token:
        if self.current_str() == string:
            self.ind += 1
            return self.tok[self.ind - 1]
        else:
            self.parse_error()
    
    def expect_indent(self) -> Token:
        if isinstance(self.current(), Indent):
            return self.expect_type(Indent)
        else:
            self.fail('Expected an indented block', self.current().line)
            return none
    
    def fail(self, msg: str, line: int) -> None:
        self.errors.report(line, msg)
    
    def expect_type(self, typ: type) -> Token:
        if isinstance(self.current(), typ):
            self.ind += 1
            return self.tok[self.ind - 1]
        else:
            self.parse_error()
    
    def expect_colon_and_break(self) -> Tuple[Token, Token]:
        return self.expect_type(Colon), self.expect_type(Break)
    
    def expect_break(self) -> Token:
        return self.expect_type(Break)
    
    def expect_end(self) -> Tuple[Token, Token]:
        return self.expect('end'), self.expect_type(Break)
    
    def current(self) -> Token:
        return self.tok[self.ind]
    
    def current_str(self) -> str:
        return self.current().string
    
    def peek(self) -> Token:
        return self.tok[self.ind + 1]
    
    def parse_error(self) -> None:
        self.parse_error_at(self.current())
        raise ParseError()
    
    def parse_error_at(self, tok: Token, skip: bool = True) -> None:
        msg = ''
        if isinstance(tok, LexError):
            msg = token_repr(tok)
            msg = msg[0].upper() + msg[1:]
        elif isinstance(tok, Indent) or isinstance(tok, Dedent):
            msg = 'Inconsistent indentation'
        else:
            msg = 'Parse error before {}'.format(token_repr(tok))
        
        self.errors.report(tok.line, msg)
        
        if skip:
            self.skip_until_next_line()
    
    def skip_until_break(self) -> None:
        n = 0
        while (not isinstance(self.current(), Break)
               and not isinstance(self.current(), Eof)):
            self.skip()
            n += 1
        if isinstance(self.tok[self.ind - 1], Colon) and n > 1:
            self.ind -= 1
    
    def skip_until_next_line(self) -> None:
        self.skip_until_break()
        if isinstance(self.current(), Break):
            self.skip()
    
    def eol(self) -> bool:
        return isinstance(self.current(), Break) or self.eof()
    
    def eof(self) -> bool:
        return isinstance(self.current(), Eof)
    
    # Type annotation related functionality
    
    def parse_type(self) -> Type:
        line = self.current().line
        try:
            typ, self.ind = parse_type(self.tok, self.ind)
        except TypeParseError as e:
            self.parse_error_at(e.token)
            raise ParseError()
        return typ

    annotation_prefix_re = re.compile(r'#\s*type:')

    def parse_type_comment(self, token: Token, signature: bool) -> Type:
        """Parse a '# type: ...' annotation.

        Return None if no annotation found. If signature is True, expect
        a type signature of form (...) -> t.
        """
        whitespace_or_comments = token.rep().strip()
        if self.annotation_prefix_re.match(whitespace_or_comments):
            type_as_str = whitespace_or_comments.split(':', 1)[1].strip()
            tokens = lex.lex(type_as_str, token.line)
            if len(tokens) < 2:
                # Empty annotation (only Eof token)
                self.errors.report(token.line, 'Empty type annotation')
                return None
            try:
                if not signature:
                    type, index = parse_types(tokens, 0)
                else:
                    type, index = parse_signature(tokens)
            except TypeParseError as e:
                self.parse_error_at(e.token, skip=False)
                return None
            if index < len(tokens) - 2:
                self.parse_error_at(tokens[index], skip=False)
                return None
            return type
        else:
            return None                          
    
    # Representation management
    
    def set_repr(self, node: Node, repr: Any) -> None:
        node.repr = repr
    
    def repr(self, node: Node) -> Any:
        return node.repr
    
    def paren_repr(self, e: Node) -> Tuple[List[Token], List[Token]]:
        """If e is a ParenExpr, return an array of left-paren tokens
        (more that one if nested parens) and an array of corresponding
        right-paren tokens.  Otherwise, return [], [].
        """
        if isinstance(e, ParenExpr):
            lp, rp = self.paren_repr(e.expr)
            lp.insert(0, self.repr(e).lparen)
            rp.append(self.repr(e).rparen)
            return lp, rp
        else:
            return [], []


class ParseError(Exception): pass


def token_repr(tok: Token) -> str:
    """Return a representation of a token for use in parse error messages."""
    if isinstance(tok, Break):
        return 'end of line'
    elif isinstance(tok, Eof):
        return 'end of file'
    elif isinstance(tok, Keyword) or isinstance(tok, Name):
        return '"{}"'.format(tok.string)
    elif isinstance(tok, IntLit) or isinstance(tok, FloatLit):
        return 'numeric literal'
    elif isinstance(tok, StrLit):
        return 'string literal'
    elif (isinstance(tok, Punct) or isinstance(tok, Op)
          or isinstance(tok, Colon)):
        return tok.string
    elif isinstance(tok, Bom):
        return 'byte order mark'
    elif isinstance(tok, Indent):
        return 'indent'
    elif isinstance(tok, Dedent):
        return 'dedent'
    else:
        if isinstance(tok, LexError):
            t = tok.type
            if t == lex.NUMERIC_LITERAL_ERROR:
                return 'invalid numeric literal'
            elif t == lex.UNTERMINATED_STRING_LITERAL:
                return 'unterminated string literal'
            elif t == lex.INVALID_CHARACTER:
                msg = 'unrecognized character'
                if ord(tok.string) in range(33, 127):
                    msg += ' ' + tok.string
                return msg
            elif t == lex.INVALID_UTF8_SEQUENCE:
                return 'invalid UTF-8 sequence'
            elif t == lex.NON_ASCII_CHARACTER_IN_COMMENT:
                return 'non-ASCII character in comment'
            elif t == lex.NON_ASCII_CHARACTER_IN_STRING:
                return 'non-ASCII character in string'
            elif t == lex.INVALID_DEDENT:
                return 'inconsistent indentation'
        raise ValueError('Unknown token {}'.format(repr(tok)))


def unwrap_parens(node: Node) -> Node:
    """Unwrap any outer parentheses in node.

    If the node is a parenthesised expression, recursively find the first
    non-parenthesised subexpression and return that. Otherwise, return node.
    """
    if isinstance(node, ParenExpr):
        return unwrap_parens(node.expr)
    else:
        return node


if __name__ == '__main__':
    # Parse a file and dump the AST (or display errors).
    import sys
    if len(sys.argv) != 2:
        print('Usage: parse.py FILE')
        sys.exit(2)
    fnam = sys.argv[1]
    s = open(fnam).read()
    errors = Errors()
    try:
        tree = parse(s, fnam)
        print(tree)
    except CompileError as e:
        for msg in e.messages:
            print(msg)

########NEW FILE########
__FILENAME__ = parsetype
"""Type parser"""

from typing import List, Tuple, cast

from mypy.types import (
    Type, UnboundType, TupleType, TypeList, AnyType, Callable
)
from mypy.typerepr import CommonTypeRepr, ListTypeRepr
from mypy.lex import Token, Name, StrLit, Break, lex
from mypy import nodes


none = Token('') # Empty token


class TypeParseError(Exception):
    def __init__(self, token: Token, index: int) -> None:
        super().__init__()
        self.token = token
        self.index = index


def parse_type(tok: List[Token], index: int) -> Tuple[Type, int]:
    """Parse a type.

    Return (type, index after type).
    """
    
    p = TypeParser(tok, index)
    return p.parse_type(), p.index()


def parse_types(tok: List[Token], index: int) -> Tuple[Type, int]:
    """Parse one or more types separated by commas (optional parentheses).

    Return (type, index after type).    
    """
    
    p = TypeParser(tok, index)
    return p.parse_types(), p.index()


class TypeParser:
    def __init__(self, tok: List[Token], ind: int) -> None:
        self.tok = tok
        self.ind = ind
    
    def index(self) -> int:
        return self.ind
    
    def parse_type(self) -> Type:
        """Parse a type."""
        t = self.current_token()
        if isinstance(t, Name):
            return self.parse_named_type()
        elif t.string == '[':
            return self.parse_type_list()
        elif isinstance(t, StrLit):
            # Type escaped as string literal.
            typestr = t.parsed()
            line = t.line
            self.skip()
            try:
                result = parse_str_as_type(typestr, line)
            except TypeParseError as e:
                raise TypeParseError(e.token, self.ind)
            return result
        else:
            self.parse_error()

    def parse_types(self) -> Type:
        parens = False
        if self.current_token_str() == '(':
            self.skip()
            parens = True
        type = self.parse_type()
        if self.current_token_str() == ',':
            items = [type]
            while self.current_token_str() == ',':
                self.skip()
                items.append(self.parse_type())
            type = TupleType(items)
        if parens:
            self.expect(')')
        return type

    def parse_type_list(self) -> TypeList:
        """Parse type list [t, ...]."""
        lbracket = self.expect('[')
        commas = [] # type: List[Token]
        items = [] # type: List[Type]
        while self.current_token_str() != ']':
            t = self.parse_type()
            items.append(t)
            if self.current_token_str() != ',':
                break
            commas.append(self.skip())
        rbracket = self.expect(']')
        return TypeList(items, line=lbracket.line)
    
    def parse_named_type(self) -> Type:
        line = self.current_token().line
        name = ''
        components = [] # type: List[Token]
        
        components.append(self.expect_type(Name))
        name += components[-1].string
        
        while self.current_token_str() == '.':
            components.append(self.skip())
            t = self.expect_type(Name)
            components.append(t)
            name += '.' + t.string
        
        langle, rangle = none, none
        commas = [] # type: List[Token]
        args = [] # type: List[Type]
        if self.current_token_str() == '[':
            lbracket = self.skip()
            
            while True:
                typ = self.parse_type()
                args.append(typ)
                if self.current_token_str() != ',':
                    break
                commas.append(self.skip())
            
            rbracket = self.expect(']')
        
        typ = UnboundType(name, args, line, CommonTypeRepr(components,
                                                           langle,
                                                           commas, rangle))
        return typ
    
    # Helpers
    
    def skip(self) -> Token:
        self.ind += 1
        return self.tok[self.ind - 1]
    
    def expect(self, string: str) -> Token:
        if self.tok[self.ind].string == string:
            self.ind += 1
            return self.tok[self.ind - 1]
        else:
            self.parse_error()
    
    def expect_type(self, typ: type) -> Token:
        if isinstance(self.current_token(), typ):
            self.ind += 1
            return self.tok[self.ind - 1]
        else:
            self.parse_error()
    
    def current_token(self) -> Token:
        return self.tok[self.ind]
    
    def current_token_str(self) -> str:
        return self.current_token().string
    
    def parse_error(self) -> None:
        raise TypeParseError(self.tok[self.ind], self.ind)


def parse_str_as_type(typestr: str, line: int) -> Type:
    """Parse a type represented as a string.

    Raise TypeParseError on parse error.
    """
    
    typestr = typestr.strip()
    tokens = lex(typestr, line)
    result, i = parse_type(tokens, 0)
    if i < len(tokens) - 2:
        raise TypeParseError(tokens[i], i)
    return result


def parse_signature(tokens: List[Token]) -> Tuple[Callable, int]:
    """Parse signature of form (...) -> ...

    Return tuple (signature type, token index).
    """
    i = 0
    if tokens[i].string != '(':
        raise TypeParseError(tokens[i], i)
    i += 1
    arg_types = List[Type]()
    arg_kinds = List[int]()
    while tokens[i].string != ')':
        if tokens[i].string == '*':
            arg_kinds.append(nodes.ARG_STAR)
            i += 1
        elif tokens[i].string == '**':
            arg_kinds.append(nodes.ARG_STAR2)
            i += 1
        else:
            arg_kinds.append(nodes.ARG_POS)
        arg, i = parse_type(tokens, i)
        arg_types.append(arg)
        next = tokens[i].string
        if next not in ',)':
            raise TypeParseError(tokens[i], i)
        if next == ',':
            i += 1            
    i += 1
    if tokens[i].string != '-' or tokens[i + 1].string != '>':
        raise TypeParseError(tokens[i], i)
    i += 2
    ret_type, i = parse_type(tokens, i)
    return Callable(arg_types,
                    arg_kinds,
                    [None] * len(arg_types),
                    ret_type, False), i

########NEW FILE########
__FILENAME__ = pprinter
from typing import List, cast

from mypy.output import TypeOutputVisitor
from mypy.nodes import (
    Node, VarDef, ClassDef, FuncDef, MypyFile, CoerceExpr, TypeExpr, CallExpr,
    TypeVarExpr
)
from mypy.visitor import NodeVisitor
from mypy.types import Void, TypeVisitor, Callable, Instance, Type, UnboundType
from mypy.maptypevar import num_slots
from mypy.transutil import tvar_arg_name
from mypy import coerce
from mypy import nodes


class PrettyPrintVisitor(NodeVisitor):
    """Convert transformed parse trees into formatted source code.

    Use automatic formatting (i.e. omit original formatting).
    """

    def __init__(self) -> None:
        super().__init__()
        self.result = [] # type: List[str]
        self.indent = 0

    def output(self) -> str:
        return ''.join(self.result)
    
    #
    # Definitions
    #

    def visit_mypy_file(self, file: MypyFile) -> None:
        for d in file.defs:
            d.accept(self)
    
    def visit_class_def(self, tdef: ClassDef) -> None:
        self.string('class ')
        self.string(tdef.name)
        if tdef.base_types:
            b = [] # type: List[str]
            for bt in tdef.base_types:
                if not bt:
                    continue
                elif isinstance(bt, UnboundType):
                    b.append(bt.name)
                elif (cast(Instance, bt)).type.fullname() != 'builtins.object':
                    typestr = bt.accept(TypeErasedPrettyPrintVisitor())
                    b.append(typestr)
            if b:
                self.string('({})'.format(', '.join(b)))
        self.string(':\n')
        for d in tdef.defs.body:
            d.accept(self)
        self.dedent()
    
    def visit_func_def(self, fdef: FuncDef) -> None:
        # FIX varargs, default args, keyword args etc.
        ftyp = cast(Callable, fdef.type)
        self.string('def ')
        self.string(fdef.name())
        self.string('(')
        for i in range(len(fdef.args)):
            a = fdef.args[i]
            self.string(a.name())
            if i < len(ftyp.arg_types):
                self.string(': ')
                self.type(ftyp.arg_types[i])
            else:
                self.string('xxx ')
            if i < len(fdef.args) - 1:
                self.string(', ')
        self.string(') -> ')
        self.type(ftyp.ret_type)
        fdef.body.accept(self)
    
    def visit_var_def(self, vdef: VarDef) -> None:
        if vdef.items[0].name() not in nodes.implicit_module_attrs:
            self.string(vdef.items[0].name())
            self.string(': ')
            self.type(vdef.items[0].type)
            if vdef.init:
                self.string(' = ')
                self.node(vdef.init)
            self.string('\n')
    
    #
    # Statements
    #

    def visit_block(self, b):
        self.string(':\n')
        for s in b.body:
            s.accept(self)
        self.dedent()

    def visit_pass_stmt(self, o):
        self.string('pass\n')
    
    def visit_return_stmt(self, o):
        self.string('return ')
        if o.expr:
            self.node(o.expr)
        self.string('\n')
    
    def visit_expression_stmt(self, o):
        self.node(o.expr)
        self.string('\n')
    
    def visit_assignment_stmt(self, o):
        if isinstance(o.rvalue, CallExpr) and isinstance(o.rvalue.analyzed,
                                                         TypeVarExpr):
            # Skip type variable definition 'x = typevar(...)'.
            return
        self.node(o.lvalues[0]) # FIX multiple lvalues
        if o.type:
            self.string(': ')
            self.type(o.type)
        self.string(' = ')
        self.node(o.rvalue)
        self.string('\n')

    def visit_if_stmt(self, o):
        self.string('if ')
        self.node(o.expr[0])
        self.node(o.body[0])
        for e, b in zip(o.expr[1:], o.body[1:]):
            self.string('elif ')
            self.node(e)
            self.node(b)
        if o.else_body:
            self.string('else')
            self.node(o.else_body)

    def visit_while_stmt(self, o):
        self.string('while ')
        self.node(o.expr)
        self.node(o.body)
        if o.else_body:
            self.string('else')
            self.node(o.else_body)
    
    #
    # Expressions
    #
    
    def visit_call_expr(self, o):
        if o.analyzed:
            o.analyzed.accept(self)
            return
        self.node(o.callee)
        self.string('(')
        self.omit_next_space = True
        for i in range(len(o.args)):
            self.node(o.args[i])
            if i < len(o.args) - 1:
                self.string(', ')
        self.string(')')
    
    def visit_member_expr(self, o):
        self.node(o.expr)
        self.string('.' + o.name)
        if o.direct:
            self.string('!')
    
    def visit_name_expr(self, o):
        self.string(o.name)
    
    def visit_coerce_expr(self, o: CoerceExpr) -> None:
        self.string('{')
        self.full_type(o.target_type)
        if coerce.is_special_primitive(o.source_type):
            self.string(' <= ')
            self.type(o.source_type)
        self.string(' ')
        self.node(o.expr)
        self.string('}')
    
    def visit_type_expr(self, o: TypeExpr) -> None:
        # Type expressions are only generated during transformation, so we must
        # use automatic formatting.
        self.string('<')
        self.full_type(o.type)
        self.string('>')
    
    def visit_index_expr(self, o):
        if o.analyzed:
            o.analyzed.accept(self)
            return
        self.node(o.base)
        self.string('[')
        self.node(o.index)
        self.string(']')

    def visit_int_expr(self, o):
        self.string(str(o.value))
    
    def visit_str_expr(self, o):
        self.string(repr(o.value))

    def visit_op_expr(self, o):
        self.node(o.left)
        self.string(' %s ' % o.op)
        self.node(o.right)

    def visit_unary_expr(self, o):
        self.string(o.op)
        if o.op == 'not':
            self.string(' ')
        self.node(o.expr)

    def visit_paren_expr(self, o):
        self.string('(')
        self.node(o.expr)
        self.string(')')
    
    def visit_super_expr(self, o):
        self.string('super().')
        self.string(o.name)

    def visit_cast_expr(self, o):
        self.string('cast(')
        self.type(o.type)
        self.string(', ')
        self.node(o.expr)
        self.string(')')

    def visit_type_application(self, o):
        # Type arguments are erased in transformation.
        self.node(o.expr)

    def visit_undefined_expr(self, o):
        # Omit declared type as redundant.
        self.string('Undefined')
    
    #
    # Helpers
    #

    def string(self, s: str) -> None:
        if not s:
            return
        if self.last_output_char() == '\n':
            self.result.append(' ' * self.indent)
        self.result.append(s)
        if s.endswith(':\n'):
            self.indent += 4

    def dedent(self) -> None:
        self.indent -= 4

    def node(self, n: Node) -> None:
        n.accept(self)

    def last_output_char(self) -> str:
        if self.result:
            return self.result[-1][-1]
        return ''
    
    def type(self, t):
        """Pretty-print a type with erased type arguments."""
        if t:
            v = TypeErasedPrettyPrintVisitor()
            self.string(t.accept(v))
    
    def full_type(self, t):
        """Pretty-print a type, includingn type arguments."""
        if t:
            v = TypePrettyPrintVisitor()
            self.string(t.accept(v))


class TypeErasedPrettyPrintVisitor(TypeVisitor[str]):
    """Pretty-print types.

    Omit type variables (e.g. C instead of C[int]).

    Note that the translation does not preserve all information about the
    types, but this is fine since this is only used in test case output.
    """
    
    def visit_any(self, t):
        return 'Any'
    
    def visit_void(self, t):
        return 'None'
    
    def visit_instance(self, t):
        return t.type.name()
    
    def visit_type_var(self, t):
        return 'Any*'
    
    def visit_runtime_type_var(self, t):
        v = PrettyPrintVisitor()
        t.node.accept(v)
        return v.output()


class TypePrettyPrintVisitor(TypeVisitor[str]):
    """Pretty-print types.

    Include type variables.
    
    Note that the translation does not preserve all information about the
    types, but this is fine since this is only used in test case output.
    """
    
    def visit_any(self, t):
        return 'Any'
    
    def visit_void(self, t):
        return 'None'
    
    def visit_instance(self, t):
        s = t.type.name()
        if t.args:
            argstr = ', '.join([a.accept(self) for a in t.args])
            s += '[%s]' % argstr
        return s
    
    def visit_type_var(self, t):
        return 'Any*'
    
    def visit_runtime_type_var(self, t):
        v = PrettyPrintVisitor()
        t.node.accept(v)
        return v.output()

########NEW FILE########
__FILENAME__ = replacetvars
"""Type operations"""

import typing

from mypy.lex import Token
from mypy.types import Type, AnyType, NoneTyp, TypeTranslator, TypeVar
from mypy.typerepr import AnyRepr


def replace_type_vars(typ: Type, func_tvars: bool = True) -> Type:
    """Replace type variable references in a type with the Any type. If
    func_tvars is false, only replace instance type variables.
    """
    return typ.accept(ReplaceTypeVarsVisitor(func_tvars))


class ReplaceTypeVarsVisitor(TypeTranslator):
    # Only override type variable handling; otherwise perform an indentity
    # transformation.
    
    func_tvars = False
    
    def __init__(self, func_tvars: bool) -> None:
        self.func_tvars = func_tvars
    
    def visit_type_var(self, t: TypeVar) -> Type:
        if t.id > 0 or self.func_tvars:
            if t.repr is not None:
                # Give a representation for the dynamic type.
                tok = Token('Any')
                tok.pre = t.repr.name.pre
                return AnyType(t.line, AnyRepr(tok))
            else:
                return AnyType()
        else:
            return t


def replace_func_type_vars(typ: Type, target_type: Type) -> Type:
    """Replace function type variables in a type with the target type."""
    return typ.accept(ReplaceFuncTypeVarsVisitor(target_type))


class ReplaceFuncTypeVarsVisitor(TypeTranslator):
    def __init__(self, target_type: Type) -> None:
        self.target_type = target_type
    
    def visit_type_var(self, t: TypeVar) -> Type:
        if t.id < 0:
            return self.target_type
        else:
            return t

########NEW FILE########
__FILENAME__ = rttypevars
"""Translation of type variables to runtime type variable expressions.

Source-level type variables are mapped to references to type variable slots
in instancse or local variables that contain the runtime values of type
variables.
"""

from typing import Any

from mypy.types import Type, TypeTranslator, TypeVar, RuntimeTypeVar
from mypy.nodes import NameExpr, TypeInfo
from mypy.transutil import tvar_arg_name
from mypy.maptypevar import get_tvar_access_expression


def translate_runtime_type_vars_locally(typ: Type) -> Type:
    """Replace type variable references in a type with runtime type variables.

    The type variable references refer to runtime local variables (__tv* etc.),
    i.e. this assumes a generic class constructor context.
    """
    return typ.accept(TranslateRuntimeTypeVarsLocallyVisitor())


class TranslateRuntimeTypeVarsLocallyVisitor(TypeTranslator):
    """Reuse most of the implementation by inheriting TypeTranslator."""
    def visit_type_var(self, t: TypeVar) -> Type:
        # FIX function type variables
        return RuntimeTypeVar(NameExpr(tvar_arg_name(t.id)))


def translate_runtime_type_vars_in_context(typ: Type, context: TypeInfo,
                                           is_java: Any) -> Type:
    """Replace type variable types within a type with runtime type variables.

    Perform the translation in the context of the given type.
    
    For example, assuming class A(Generic[T, S]) ... and
    class B(A[X, Y[U]], Generic[U]) ...:
    
      TranslateRuntimeTypeVarsInContext(C[U`1], <B>) ==
        C[RuntimeTypeVar(<self.__tv2.args[0]>)]  (<...> uses node repr.)
    """
    return typ.accept(ContextualRuntimeTypeVarTranslator(context, is_java))


class ContextualRuntimeTypeVarTranslator(TypeTranslator):
    """Reuse most of the implementation by inheriting TypeTranslator."""
    def __init__(self, context, is_java):
        self.context = context
        self.is_java = is_java
    
    def visit_type_var(self, t: TypeVar) -> Type:
        if t.id < 0:
            # Generic function type variable; always in a local variable.
            return RuntimeTypeVar(NameExpr(tvar_arg_name(t.id)))
        else:
            # Instance type variables are stored in the instance.
            return get_tvar_access_expression(self.context, t.id,
                                              t.is_wrapper_var, self.is_java)

########NEW FILE########
__FILENAME__ = sametypes
from typing import List, cast

from mypy.types import (
    Type, UnboundType, ErrorType, AnyType, NoneTyp, Void, TupleType, Callable,
    TypeVar, Instance, TypeVisitor, ErasedType, TypeList
)


def is_same_type(left: Type, right: Type) -> bool:
    """Is 'left' the same type as 'right'?"""
    
    if isinstance(right, UnboundType):
        # Make unbound types same as anything else to reduce the number of
        # generated spurious error messages.
        return True
    else:
        return left.accept(SameTypeVisitor(right))


def is_same_types(a1: List[Type], a2: List[Type]) -> bool:
    if len(a1) != len(a2):
        return False
    for i in range(len(a1)):
        if not is_same_type(a1[i], a2[i]):
            return False
    return True


class SameTypeVisitor(TypeVisitor[bool]):
    """Visitor for checking whether two types are the 'same' type."""
    
    def __init__(self, right: Type) -> None:
        self.right = right
    
    # visit_x(left) means: is left (which is an instance of X) the same type as
    # right?
    
    def visit_unbound_type(self, left: UnboundType) -> bool:
        return True
    
    def visit_error_type(self, left: ErrorType) -> bool:
        return False
    
    def visit_type_list(self, t: TypeList) -> bool:
        assert False, 'Not supported'
    
    def visit_any(self, left: AnyType) -> bool:
        return isinstance(self.right, AnyType)
    
    def visit_void(self, left: Void) -> bool:
        return isinstance(self.right, Void)
    
    def visit_none_type(self, left: NoneTyp) -> bool:
        return isinstance(self.right, NoneTyp)
    
    def visit_erased_type(self, left: ErasedType) -> bool:
        # Should not get here.
        raise RuntimeError()
    
    def visit_instance(self, left: Instance) -> bool:
        return (isinstance(self.right, Instance) and
                left.type == (cast(Instance, self.right)).type and
                is_same_types(left.args, (cast(Instance, self.right)).args))
    
    def visit_type_var(self, left: TypeVar) -> bool:
        return (isinstance(self.right, TypeVar) and
                left.id == (cast(TypeVar, self.right)).id and
                left.is_wrapper_var ==
                    cast(TypeVar, self.right).is_wrapper_var)
    
    def visit_callable(self, left: Callable) -> bool:
        # FIX generics
        if isinstance(self.right, Callable):
            cright = cast(Callable, self.right)
            return (is_same_type(left.ret_type, cright.ret_type) and
                    is_same_types(left.arg_types, cright.arg_types)  and
                    left.arg_names == cright.arg_names and
                    left.arg_kinds == cright.arg_kinds and
                    left.is_type_obj() == cright.is_type_obj())
        else:
            return False
    
    def visit_tuple_type(self, left: TupleType) -> bool:
        if isinstance(self.right, TupleType):
            return is_same_types(left.items, cast(TupleType, self.right).items)
        else:
            return False

########NEW FILE########
__FILENAME__ = semanal
"""The semantic analyzer.

Bind names to definitions and do various other simple consistency
checks. For example, consider this program:

  x = 1
  y = x

Here semantic analysis would detect that the assignment 'x = 1'
defines a new variable, the type of which is to be inferred (in a
later pass; type inference or type checking is not part of semantic
analysis).  Also, it would bind both references to 'x' to the same
module-level variable node.  The second assignment would also be
analyzed, and the type of 'y' marked as being inferred.

Semantic analysis is the first analysis pass after parsing, and it is
subdivided into three passes:

 * FirstPass looks up externally visible names defined in a module but
   ignores imports and local definitions.  It helps enable (some)
   cyclic references between modules, such as module 'a' that imports
   module 'b' and used names defined in b *and* vice versa.  The first
   pass can be performed before dependent modules have been processed.
 
 * SemanticAnalyzer is the second pass.  It does the bulk of the work.
   It assumes that dependent modules have been semantically analyzed,
   up to the second pass, unless there is a import cycle.
 
 * ThirdPass checks that type argument counts are valid; for example,
   it will reject Dict[int].  We don't do this in the second pass,
   since we infer the type argument counts of classes during this
   pass, and it is possible to refer to classes defined later in a
   file, which would not have the type argument count set yet.

Semantic analysis of types is implemented in module mypy.typeanal.

TODO: Check if the third pass slows down type checking significantly.
  We could probably get rid of it -- for example, we could collect all
  analyzed types in a collection and check them without having to
  traverse the entire AST.
"""

from typing import (
    Undefined, List, Dict, Set, Tuple, cast, Any, overload, typevar
)

from mypy.nodes import (
    MypyFile, TypeInfo, Node, AssignmentStmt, FuncDef, OverloadedFuncDef,
    ClassDef, VarDef, Var, GDEF, MODULE_REF, FuncItem, Import,
    ImportFrom, ImportAll, Block, LDEF, NameExpr, MemberExpr,
    IndexExpr, ParenExpr, TupleExpr, ListExpr, ExpressionStmt, ReturnStmt,
    RaiseStmt, YieldStmt, AssertStmt, OperatorAssignmentStmt, WhileStmt,
    ForStmt, BreakStmt, ContinueStmt, IfStmt, TryStmt, WithStmt, DelStmt,
    GlobalDecl, SuperExpr, DictExpr, CallExpr, RefExpr, OpExpr, UnaryExpr,
    SliceExpr, CastExpr, TypeApplication, Context, SymbolTable,
    SymbolTableNode, TVAR, UNBOUND_TVAR, ListComprehension, GeneratorExpr,
    FuncExpr, MDEF, FuncBase, Decorator, SetExpr, UndefinedExpr, TypeVarExpr,
    StrExpr, PrintStmt, ConditionalExpr, DucktypeExpr, DisjointclassExpr,
    ARG_POS, ARG_NAMED, MroError, type_aliases
)
from mypy.visitor import NodeVisitor
from mypy.traverser import TraverserVisitor
from mypy.errors import Errors
from mypy.types import (
    NoneTyp, Callable, Overloaded, Instance, Type, TypeVar, AnyType,
    FunctionLike, UnboundType, TypeList, ErrorType, TypeVarDef,
    replace_self_type, TupleType
)
from mypy.nodes import function_type, implicit_module_attrs
from mypy.typeanal import TypeAnalyser, TypeAnalyserPass3
from mypy.parsetype import parse_str_as_type, TypeParseError


T = typevar('T')


class TypeTranslationError(Exception):
    """Exception raised when an expression is not valid as a type."""


class SemanticAnalyzer(NodeVisitor):
    """Semantically analyze parsed mypy files.

    The analyzer binds names and does various consistency checks for a
    parse tree. Note that type checking is performed as a separate
    pass.

    This is the second phase of semantic analysis.
    """
    
    # Library search paths
    lib_path = Undefined(List[str])
    # Module name space
    modules = Undefined(Dict[str, MypyFile])
    # Global name space for current module
    globals = Undefined(SymbolTable)
    # Names declared using "global" (separate set for each scope)
    global_decls = Undefined(List[Set[str]])
    # Local names of function scopes; None for non-function scopes.
    locals = Undefined(List[SymbolTable])
    # Nested block depths of scopes
    block_depth = Undefined(List[int])
    # TypeInfo of directly enclosing class (or None)
    type = Undefined(TypeInfo)
    # Stack of outer classes (the second tuple item contains tvars).
    type_stack = Undefined(List[Tuple[TypeInfo, List[SymbolTableNode]]])
    # Stack of functions being analyzed
    function_stack = Undefined(List[FuncItem])

    loop_depth = 0         # Depth of breakable loops
    cur_mod_id = ''        # Current module id (or None) (phase 2)
    imports = Undefined(Set[str])  # Imported modules (during phase 2 analysis)
    errors = Undefined(Errors)     # Keep track of generated errors
    
    def __init__(self, lib_path: List[str], errors: Errors) -> None:
        """Construct semantic analyzer.

        Use lib_path to search for modules, and report analysis errors
        using the Errors instance.
        """
        self.locals = [None]
        self.imports = set()
        self.type = None
        self.type_stack = []
        self.function_stack = []
        self.block_depth = [0]
        self.loop_depth = 0
        self.lib_path = lib_path
        self.errors = errors
        self.modules = {}
    
    def visit_file(self, file_node: MypyFile, fnam: str) -> None:
        self.errors.set_file(fnam)
        self.globals = file_node.names
        self.cur_mod_id = file_node.fullname()
        
        if 'builtins' in self.modules:
            self.globals['__builtins__'] = SymbolTableNode(
                MODULE_REF, self.modules['builtins'], self.cur_mod_id)
        
        defs = file_node.defs
        for d in defs:
            d.accept(self)

        if self.cur_mod_id == 'builtins':
            remove_imported_names_from_symtable(self.globals, 'builtins')
    
    def visit_func_def(self, defn: FuncDef) -> None:
        self.errors.push_function(defn.name())
        self.update_function_type_variables(defn)
        self.errors.pop_function()
        
        if self.is_class_scope():
            # Method definition
            defn.is_conditional = self.block_depth[-1] > 0
            defn.info = self.type
            if not defn.is_decorated:
                if not defn.is_overload:
                    if defn.name() in self.type.names:
                        n = self.type.names[defn.name()].node
                        if self.is_conditional_func(n, defn):
                            defn.original_def = cast(FuncDef, n)
                        else:
                            self.name_already_defined(defn.name(), defn)
                    self.type.names[defn.name()] = SymbolTableNode(MDEF, defn)
            if not defn.is_static:
                if not defn.args:
                    self.fail('Method must have at least one argument', defn)
                elif defn.type:
                    sig = cast(FunctionLike, defn.type)
                    defn.type = replace_implicit_self_type(
                        sig, self_type(self.type))

        if self.is_func_scope() and (not defn.is_decorated and
                                     not defn.is_overload):
            self.add_local_func(defn, defn)
            defn._fullname = defn.name()
        
        self.errors.push_function(defn.name())
        self.analyse_function(defn)
        self.errors.pop_function()

    def is_conditional_func(self, n: Node, defn: FuncDef) -> bool:
        return (isinstance(n, FuncDef) and cast(FuncDef, n).is_conditional and
                defn.is_conditional)

    def update_function_type_variables(self, defn: FuncDef) -> None:
        """Make any type variables in the signature of defn explicit.

        Update the signature of defn to contain type variable definitions
        if defn is generic.
        """
        if defn.type:
            functype = cast(Callable, defn.type)
            typevars = self.infer_type_variables(functype)
            # Do not define a new type variable if already defined in scope.
            typevars = [(tvar, values) for tvar, values in typevars
                        if not self.is_defined_type_var(tvar, defn)]
            if typevars:
                defs = [TypeVarDef(tvar[0], -i - 1, tvar[1])
                        for i, tvar in enumerate(typevars)]
                functype.variables = defs

    def infer_type_variables(self,
                             type: Callable) -> List[Tuple[str, List[Type]]]:
        """Return list of unique type variables referred to in a callable."""
        names = List[str]()
        values = List[List[Type]]()
        for arg in type.arg_types + [type.ret_type]:
            for tvar, vals in self.find_type_variables_in_type(arg):
                if tvar not in names:
                    names.append(tvar)
                    values.append(vals)
        return list(zip(names, values))

    def find_type_variables_in_type(
            self, type: Type) -> List[Tuple[str, List[Type]]]:
        """Return a list of all unique type variable references in type."""
        result = List[Tuple[str, List[Type]]]()
        if isinstance(type, UnboundType):
            name = type.name
            node = self.lookup_qualified(name, type)
            if node and node.kind == UNBOUND_TVAR:
                result.append((name, cast(TypeVarExpr, node.node).values))
            for arg in type.args:
                result.extend(self.find_type_variables_in_type(arg))
        elif isinstance(type, TypeList):
            for item in type.items:
                result.extend(self.find_type_variables_in_type(item))
        elif isinstance(type, AnyType):
            pass
        else:
            assert False, 'Unsupported type %s' % type
        return result

    def is_defined_type_var(self, tvar: str, context: Node) -> bool:
        return self.lookup_qualified(tvar, context).kind == TVAR
    
    def visit_overloaded_func_def(self, defn: OverloadedFuncDef) -> None:
        t = List[Callable]()
        for item in defn.items:
            # TODO support decorated overloaded functions properly
            item.is_overload = True
            item.func.is_overload = True
            item.accept(self)
            t.append(cast(Callable, function_type(item.func)))
            if not [dec for dec in item.decorators
                    if refers_to_fullname(dec, 'typing.overload')]:
                self.fail("'overload' decorator expected", item)
                
        defn.type = Overloaded(t)
        defn.type.line = defn.line
        
        if self.is_class_scope():
            self.type.names[defn.name()] = SymbolTableNode(MDEF, defn,
                                                           typ=defn.type)
            defn.info = self.type
        elif self.is_func_scope():
            self.add_local_func(defn, defn)
    
    def analyse_function(self, defn: FuncItem) -> None:
        is_method = self.is_class_scope()
        tvarnodes = self.add_func_type_variables_to_symbol_table(defn)
        if defn.type:
            # Signature must be analyzed in the surrounding scope so that
            # class-level imported names and type variables are in scope.
            defn.type = self.anal_type(defn.type)
            self.check_function_signature(defn)
            if isinstance(defn, FuncDef):
                defn.info = self.type
                defn.type = set_callable_name(defn.type, defn)
        self.function_stack.append(defn)
        self.enter()
        for init in defn.init:
            if init:
                init.rvalue.accept(self)
        for v in defn.args:
            self.add_local(v, defn)
        for init_ in defn.init:
            if init_:
                init_.lvalues[0].accept(self)
        
        # The first argument of a method is like 'self', though the name could
        # be different.
        if is_method and defn.args:
            defn.args[0].is_self = True
        
        defn.body.accept(self)
        disable_typevars(tvarnodes)
        self.leave()
        self.function_stack.pop()
    
    def add_func_type_variables_to_symbol_table(
            self, defn: FuncItem) -> List[SymbolTableNode]:
        nodes = List[SymbolTableNode]()
        if defn.type:
            tt = defn.type
            names = self.type_var_names()
            items = cast(Callable, tt).variables
            for i, item in enumerate(items):
                name = item.name
                if name in names:
                    self.name_already_defined(name, defn)
                node = self.add_type_var(name, -i - 1, defn)
                nodes.append(node)
                names.add(name)
        return nodes
    
    def type_var_names(self) -> Set[str]:
        if not self.type:
            return set()
        else:
            return set(self.type.type_vars)
    
    def add_type_var(self, fullname: str, id: int,
                     context: Context) -> SymbolTableNode:
        node = self.lookup_qualified(fullname, context)
        node.kind = TVAR
        node.tvar_id = id
        return node

    def check_function_signature(self, fdef: FuncItem) -> None:
        sig = cast(Callable, fdef.type)
        if len(sig.arg_types) < len(fdef.args):
            self.fail('Type signature has too few arguments', fdef)
        elif len(sig.arg_types) > len(fdef.args):
            self.fail('Type signature has too many arguments', fdef)
    
    def visit_class_def(self, defn: ClassDef) -> None:
        self.clean_up_bases_and_infer_type_variables(defn)
        self.setup_class_def_analysis(defn)
        self.analyze_base_classes(defn)
        self.analyze_metaclass(defn)

        for decorator in defn.decorators:
            self.analyze_class_decorator(defn, decorator)

        # Analyze class body.
        defn.defs.accept(self)

        self.calculate_abstract_status(defn.info)
        self.setup_ducktyping(defn)
        
        # Restore analyzer state.
        self.block_depth.pop()
        self.locals.pop()
        self.type, tvarnodes = self.type_stack.pop()
        disable_typevars(tvarnodes)
        if self.type_stack:
            # Enable type variables of the enclosing class again.
            enable_typevars(self.type_stack[-1][1])

    def analyze_class_decorator(self, defn: ClassDef, decorator: Node) -> None:
        decorator.accept(self)
        if refers_to_fullname(decorator, 'typing.builtinclass'):
            defn.is_builtinclass = True
    
    def calculate_abstract_status(self, typ: TypeInfo) -> None:
        """Calculate abstract status of a class.

        Set is_abstract of the type to True if the type has an unimplemented
        abstract attribute.  Also compute a list of abstract attributes.
        """
        concrete = Set[str]()
        abstract = List[str]()
        for base in typ.mro:
            for name, symnode in base.names.items():
                node = symnode.node
                if isinstance(node, OverloadedFuncDef):
                    # Unwrap an overloaded function definition. We can just
                    # check arbitrarily the first overload item. If the
                    # different items have a different abstract status, there
                    # should be an error reported elsewhere.
                    func = node.items[0] # type: Node
                else:
                    func = node
                if isinstance(func, Decorator):
                    fdef = func.func
                    if fdef.is_abstract and name not in concrete:
                        typ.is_abstract = True
                        abstract.append(name)
                concrete.add(name)
        typ.abstract_attributes = sorted(abstract)

    def setup_ducktyping(self, defn: ClassDef) -> None:
        for decorator in defn.decorators:
            if isinstance(decorator, CallExpr):
                analyzed = decorator.analyzed
                if isinstance(analyzed, DucktypeExpr):
                    defn.info.ducktype = analyzed.type
                elif isinstance(analyzed, DisjointclassExpr):
                    node = analyzed.cls.node
                    if isinstance(node, TypeInfo):
                        defn.info.disjoint_classes.append(node)
                        defn.info.disjointclass_decls.append(node)
                        node.disjoint_classes.append(defn.info)
                    else:
                        self.fail('Argument 1 to disjointclass does not refer '
                                  'to a class', analyzed)

    def clean_up_bases_and_infer_type_variables(self, defn: ClassDef) -> None:
        """Remove extra base classes such as Generic and infer type vars.

        For example, consider this class:

        . class Foo(Bar, Generic[t]): ...
          
        Now we will remove Generic[t] from bases of Foo and infer that the
        type variable 't' is a type argument of Foo.
        """
        removed = List[int]()
        type_vars = List[TypeVarDef]()
        for i, base in enumerate(defn.base_types):
            tvars = self.analyze_typevar_declaration(base)
            if tvars is not None:
                if type_vars:
                    self.fail('Duplicate Generic or AbstractGeneric in bases',
                              defn)
                removed.append(i)
                for j, tvar in enumerate(tvars):
                    name, values = tvar
                    type_vars.append(TypeVarDef(name, j + 1, values))
        if type_vars:
            defn.type_vars = type_vars
            if defn.info:
                defn.info.type_vars = [tv.name for tv in type_vars]
        for i in reversed(removed):
            del defn.base_types[i]

    def analyze_typevar_declaration(self, t: Type) -> List[Tuple[str,
                                                                 List[Type]]]:
        if not isinstance(t, UnboundType):
            return None
        unbound = cast(UnboundType, t)
        sym = self.lookup_qualified(unbound.name, unbound)
        if sym is None:
            return None
        if sym.node.fullname() in ('typing.Generic',
                                   'typing.AbstractGeneric'):
            tvars = List[Tuple[str, List[Type]]]()
            for arg in unbound.args:
                tvar = self.analyze_unbound_tvar(arg)
                if tvar:
                    tvars.append(tvar)
                else:
                    self.fail('Free type variable expected in %s[...]' %
                              sym.node.name(), t)
            return tvars
        return None

    def analyze_unbound_tvar(self, t: Type) -> Tuple[str, List[Type]]:
        if not isinstance(t, UnboundType):
            return None
        unbound = cast(UnboundType, t)
        sym = self.lookup_qualified(unbound.name, unbound)
        if sym is not None and sym.kind == UNBOUND_TVAR:
            return unbound.name, cast(TypeVarExpr, sym.node).values[:]
        return None

    def setup_class_def_analysis(self, defn: ClassDef) -> None:
        """Prepare for the analysis of a class definition."""
        if not defn.info:
            defn.info = TypeInfo(SymbolTable(), defn)
            defn.info._fullname = defn.info.name()
        if self.is_func_scope() or self.type:
            kind = MDEF
            if self.is_func_scope():
                kind = LDEF
            self.add_symbol(defn.name, SymbolTableNode(kind, defn.info), defn)
        if self.type_stack:
            # Disable type variables of the enclosing class.
            disable_typevars(self.type_stack[-1][1])
        tvarnodes = self.add_class_type_variables_to_symbol_table(defn.info)
        # Remember previous active class and type vars of *this* class.
        self.type_stack.append((self.type, tvarnodes))
        self.locals.append(None) # Add class scope
        self.block_depth.append(-1) # The class body increments this to 0
        self.type = defn.info

    def analyze_base_classes(self, defn: ClassDef) -> None:
        """Analyze and set up base classes."""        
        bases = List[Instance]()
        for i in range(len(defn.base_types)):
            base = self.anal_type(defn.base_types[i])
            if isinstance(base, Instance):
                defn.base_types[i] = base
                bases.append(base)
        # Add 'object' as implicit base if there is no other base class.
        if (not bases and defn.fullname != 'builtins.object'):
            obj = self.object_type()
            defn.base_types.insert(0, obj)
            bases.append(obj)
        defn.info.bases = bases
        if not self.verify_base_classes(defn):
            return
        try:
            defn.info.calculate_mro()
        except MroError:
            self.fail("Cannot determine consistent method resolution order "
                      '(MRO) for "%s"' % defn.name, defn)
        else:
            # If there are cyclic imports, we may be missing 'object' in
            # the MRO. Fix MRO if needed.
            if defn.info.mro[-1].fullname() != 'builtins.object':
                defn.info.mro.append(self.object_type().type)

    def verify_base_classes(self, defn: ClassDef) -> bool:
        base_classes = List[str]()
        info = defn.info
        for base in info.bases:
            baseinfo = base.type
            if self.is_base_class(info, baseinfo):
                self.fail('Cycle in inheritance hierarchy', defn)
                # Clear bases to forcefully get rid of the cycle.
                info.bases = []
            if baseinfo.fullname() == 'builtins.bool':
                self.fail("'%s' is not a valid base class" %
                          baseinfo.name(), defn)
                return False
        dup = find_duplicate(info.direct_base_classes())
        if dup:
            self.fail('Duplicate base class "%s"' % dup.name(), defn)
            return False
        return True

    def is_base_class(self, t: TypeInfo, s: TypeInfo) -> bool:
        """Determine if t is a base class of s (but do not use mro)."""
        # Search the base class graph for t, starting from s.
        worklist = [s]
        visited = {s}
        while worklist:
            nxt = worklist.pop()
            if nxt == t:
                return True
            for base in nxt.bases:
                if base.type not in visited:
                    worklist.append(base.type)
                    visited.add(base.type)
        return False

    def analyze_metaclass(self, defn: ClassDef) -> None:
        if defn.metaclass:
            sym = self.lookup_qualified(defn.metaclass, defn)
            if sym is not None and not isinstance(sym.node, TypeInfo):
                self.fail("Invalid metaclass '%s'" % defn.metaclass, defn)

    def object_type(self) -> Instance:
        return self.named_type('__builtins__.object')

    def named_type(self, qualified_name: str) -> Instance:
        sym = self.lookup_qualified(qualified_name, None)
        return Instance(cast(TypeInfo, sym.node), [])
    
    def is_instance_type(self, t: Type) -> bool:
        return isinstance(t, Instance)
    
    def add_class_type_variables_to_symbol_table(
            self, info: TypeInfo) -> List[SymbolTableNode]:
        vars = info.type_vars
        nodes = List[SymbolTableNode]()
        if vars:
            for i in range(len(vars)):
                node = self.add_type_var(vars[i], i + 1, info)
                nodes.append(node)
        return nodes
    
    def visit_import(self, i: Import) -> None:
        for id, as_id in i.ids:
            if as_id != id:
                self.add_module_symbol(id, as_id, i)
            else:
                base = id.split('.')[0]
                self.add_module_symbol(base, base, i)

    def add_module_symbol(self, id: str, as_id: str, context: Context) -> None:
        if id in self.modules:
            m = self.modules[id]
            self.add_symbol(as_id, SymbolTableNode(MODULE_REF, m, self.cur_mod_id), context)
        else:
            self.add_unknown_symbol(as_id, context)
    
    def visit_import_from(self, i: ImportFrom) -> None:
        if i.id in self.modules:
            m = self.modules[i.id]
            for id, as_id in i.names:
                node = m.names.get(id, None)
                if node:
                    node = self.normalize_type_alias(node, i)
                    if not node:
                        return
                    self.add_symbol(as_id, SymbolTableNode(node.kind, node.node,
                                                           self.cur_mod_id), i)
                else:
                    self.fail("Module has no attribute '{}'".format(id), i)
        else:
            for id, as_id in i.names:
                self.add_unknown_symbol(as_id, i)

    def normalize_type_alias(self, node: SymbolTableNode,
                                         ctx: Context) -> SymbolTableNode:
        if node.fullname in type_aliases:
            # Node refers to an aliased type such as typing.List; normalize.
            node = self.lookup_qualified(type_aliases[node.fullname], ctx)
        return node
    
    def visit_import_all(self, i: ImportAll) -> None:
        if i.id in self.modules:
            m = self.modules[i.id]
            for name, node in m.names.items():
                if not name.startswith('_'):
                    self.add_symbol(name, SymbolTableNode(node.kind, node.node,
                                                          self.cur_mod_id), i)
        else:
            # Don't add any dummy symbols for 'from x import *' if 'x' is unknown.
            pass

    def add_unknown_symbol(self, name: str, context: Context) -> None:
        var = Var(name)
        var._fullname = self.qualified_name(name)
        var.is_ready = True
        var.type = AnyType()
        self.add_symbol(name, SymbolTableNode(GDEF, var, self.cur_mod_id), context)
    
    #
    # Statements
    #
    
    def visit_block(self, b: Block) -> None:
        self.block_depth[-1] += 1
        for s in b.body:
            s.accept(self)
        self.block_depth[-1] -= 1
    
    def visit_block_maybe(self, b: Block) -> None:
        if b:
            self.visit_block(b)
    
    def visit_var_def(self, defn: VarDef) -> None:
        for i in range(len(defn.items)):
            defn.items[i].type = self.anal_type(defn.items[i].type)
        
        for v in defn.items:
            if self.is_func_scope():
                defn.kind = LDEF
                self.add_local(v, defn)
            elif self.type:
                v.info = self.type
                v.is_initialized_in_class = defn.init is not None
                self.type.names[v.name()] = SymbolTableNode(MDEF, v,
                                                            typ=v.type)
            elif v.name not in self.globals:
                defn.kind = GDEF
                self.add_var(v, defn)
        
        if defn.init:
            defn.init.accept(self)
    
    def anal_type(self, t: Type) -> Type:
        if t:
            a = TypeAnalyser(self.lookup_qualified, self.fail)
            return t.accept(a)
        else:
            return None
    
    def visit_assignment_stmt(self, s: AssignmentStmt) -> None:
        for lval in s.lvalues:
            self.analyse_lvalue(lval, explicit_type=s.type is not None)
        s.rvalue.accept(self)
        if s.type:
            s.type = self.anal_type(s.type)
        else:
            s.type = self.infer_type_from_undefined(s.rvalue)
        if s.type:
            # Store type into nodes.
            for lvalue in s.lvalues:
                self.store_declared_types(lvalue, s.type)
        self.process_typevar_declaration(s)
    
    def analyse_lvalue(self, lval: Node, nested: bool = False,
                       add_global: bool = False,
                       explicit_type: bool = False) -> None:
        """Analyze an lvalue or assignment target.

        Only if add_global is True, add name to globals table. If nested
        is true, the lvalue is within a tuple or list lvalue expression.
        """
        if isinstance(lval, NameExpr):
            nested_global = (not self.is_func_scope() and
                             self.block_depth[-1] > 0 and
                             not self.type)
            if (add_global or nested_global) and lval.name not in self.globals:
                # Define new global name.
                v = Var(lval.name)
                v._fullname = self.qualified_name(lval.name)
                v.is_ready = False # Type not inferred yet
                lval.node = v
                lval.is_def = True
                lval.kind = GDEF
                lval.fullname = v._fullname
                self.globals[lval.name] = SymbolTableNode(GDEF, v,
                                                          self.cur_mod_id)
            elif isinstance(lval.node, Var) and lval.is_def:
                # Since the is_def flag is set, this must have been analyzed
                # already in the first pass and added to the symbol table.
                v = cast(Var, lval.node)
                assert v.name() in self.globals
            elif (self.is_func_scope() and lval.name not in self.locals[-1] and
                  lval.name not in self.global_decls[-1]):
                # Define new local name.
                v = Var(lval.name)
                lval.node = v
                lval.is_def = True
                lval.kind = LDEF
                lval.fullname = lval.name
                self.add_local(v, lval)
            elif not self.is_func_scope() and (self.type and
                                            lval.name not in self.type.names):
                # Define a new attribute within class body.
                v = Var(lval.name)
                v.info = self.type
                v.is_initialized_in_class = True
                lval.node = v
                lval.is_def = True
                lval.kind = MDEF
                lval.fullname = lval.name
                self.type.names[lval.name] = SymbolTableNode(MDEF, v)
            else:
                # Bind to an existing name.
                if explicit_type:
                    self.name_already_defined(lval.name, lval)
                lval.accept(self)
                self.check_lvalue_validity(lval.node, lval)
        elif isinstance(lval, MemberExpr):
            if not add_global:
                self.analyse_member_lvalue(lval)
            if explicit_type and not self.is_self_member_ref(lval):
                self.fail('Type cannot be declared in assignment to non-self '
                          'attribute', lval)
        elif isinstance(lval, IndexExpr):
            if explicit_type:
                self.fail('Unexpected type declaration', lval)
            if not add_global:
                lval.accept(self)
        elif isinstance(lval, ParenExpr):
            self.analyse_lvalue(lval.expr, nested, add_global, explicit_type)
        elif (isinstance(lval, TupleExpr) or
              isinstance(lval, ListExpr)) and not nested:
            items = (Any(lval)).items
            for i in items:
                self.analyse_lvalue(i, nested=True, add_global=add_global,
                                    explicit_type = explicit_type)
        else:
            self.fail('Invalid assignment target', lval)
    
    def analyse_member_lvalue(self, lval: MemberExpr) -> None:
        lval.accept(self)
        if (self.is_self_member_ref(lval) and
                self.type.get(lval.name) is None):
            # Implicit attribute definition in __init__.
            lval.is_def = True
            v = Var(lval.name)
            v.info = self.type
            v.is_ready = False
            lval.def_var = v
            lval.node = v
            self.type.names[lval.name] = SymbolTableNode(MDEF, v)
        self.check_lvalue_validity(lval.node, lval)

    def is_self_member_ref(self, memberexpr: MemberExpr) -> bool:
        """Does memberexpr to refer to an attribute of self?"""
        if not isinstance(memberexpr.expr, NameExpr):
            return False
        node = (cast(NameExpr, memberexpr.expr)).node
        return isinstance(node, Var) and (cast(Var, node)).is_self

    def check_lvalue_validity(self, node: Node, ctx: Context) -> None:
        if isinstance(node, (FuncDef, TypeInfo, TypeVarExpr)):
            self.fail('Invalid assignment target', ctx)

    def infer_type_from_undefined(self, rvalue: Node) -> Type:
        if isinstance(rvalue, CallExpr):
            if isinstance(rvalue.analyzed, UndefinedExpr):
                undef = cast(UndefinedExpr, rvalue.analyzed)
                return undef.type
        return None

    def store_declared_types(self, lvalue: Node, typ: Type) -> None:
        if isinstance(lvalue, RefExpr):
            lvalue.is_def = False
            if isinstance(lvalue.node, Var):
                var = cast(Var, lvalue.node)
                var.type = typ
                var.is_ready = True
            # If node is not a variable, we'll catch it elsewhere.
        elif isinstance(lvalue, TupleExpr):
            if isinstance(typ, TupleType):
                if len(lvalue.items) != len(typ.items):
                    self.fail('Incompatible number of tuple items', lvalue)
                    return
                for item, itemtype in zip(lvalue.items, typ.items):
                    self.store_declared_types(item, itemtype)
            else:
                self.fail('Tuple type expected for multiple variables',
                          lvalue) 
        elif isinstance(lvalue, ParenExpr):
            self.store_declared_types(lvalue.expr, typ)
        else:
            raise RuntimeError('Internal error (%s)' % type(lvalue))

    def process_typevar_declaration(self, s: AssignmentStmt) -> None:
        """Check if s declares a typevar; it yes, store it in symbol table."""
        if len(s.lvalues) != 1 or not isinstance(s.lvalues[0], NameExpr):
            return
        if not isinstance(s.rvalue, CallExpr):
            return
        call = cast(CallExpr, s.rvalue)
        if not isinstance(call.callee, RefExpr):
            return
        callee = cast(RefExpr, call.callee)
        if callee.fullname != 'typing.typevar':
            return
        # TODO Share code with check_argument_count in checkexpr.py?
        if len(call.args) < 1:
            self.fail("Too few arguments for typevar()", s)
            return
        if len(call.args) > 2:
            self.fail("Too many arguments for typevar()", s)
            return
        if call.arg_kinds not in ([ARG_POS], [ARG_POS, ARG_NAMED]):
            self.fail("Unexpected arguments to typevar()", s)
            return
        if not isinstance(call.args[0], StrExpr):
            self.fail("typevar() expects a string literal argument", s)
            return
        lvalue = cast(NameExpr, s.lvalues[0])
        name = lvalue.name
        if cast(StrExpr, call.args[0]).value != name:
            self.fail("Unexpected typevar() argument value", s)
            return
        if not lvalue.is_def:
            if s.type:
                self.fail("Cannot declare the type of a type variable", s)
            else:
                self.fail("Cannot redefine '%s' as a type variable" % name, s)
            return
        if len(call.args) == 2:
            # Analyze values=(...) argument.
            if call.arg_names[1] != 'values':
                self.fail("Unexpected keyword argument '{}' to typevar()".
                          format(call.arg_names[1]), s)
                return
            if isinstance(call.args[1], ParenExpr):
                expr = cast(ParenExpr, call.args[1]).expr
                if isinstance(expr, TupleExpr):
                    values = self.analyze_types(expr.items)
                else:
                    self.fail('The values argument must be a tuple literal', s)
                    return
            else:                  
                self.fail('The values argument must be in parentheses (...)',
                          s)
                return
        else:
            values = []
        # Yes, it's a valid type variable definition!
        node = self.lookup(name, s)
        node.kind = UNBOUND_TVAR
        typevar = TypeVarExpr(name, node.fullname, values)
        typevar.line = call.line
        call.analyzed = typevar
        node.node = typevar

    def analyze_types(self, items: List[Node]) -> List[Type]:
        result = List[Type]()
        for node in items:
            try:
                result.append(self.anal_type(expr_to_unanalyzed_type(node)))
            except TypeTranslationError:
                self.fail('Type expected', node)
                result.append(AnyType())
        return result

    def visit_decorator(self, dec: Decorator) -> None:
        if not dec.is_overload:
            if self.is_func_scope():
                self.add_symbol(dec.var.name(), SymbolTableNode(LDEF, dec),
                                dec)
            elif self.type:
                dec.var.info = self.type
                dec.var.is_initialized_in_class = True
                self.add_symbol(dec.var.name(), SymbolTableNode(MDEF, dec),
                                dec)
        for d in dec.decorators:
            d.accept(self)
        removed = List[int]()
        for i, d in enumerate(dec.decorators):
            if refers_to_fullname(d, 'abc.abstractmethod'):
                removed.append(i)
                dec.func.is_abstract = True
                self.check_decorated_function_is_method('abstractmethod', dec)
            elif refers_to_fullname(d, 'builtins.staticmethod'):
                removed.append(i)
                dec.func.is_static = True
                dec.var.is_staticmethod = True
                self.check_decorated_function_is_method('staticmethod', dec)
            elif refers_to_fullname(d, 'builtins.property'):
                removed.append(i)
                dec.func.is_property = True
                dec.var.is_property = True
                if dec.is_overload:
                    self.fail('A property cannot be overloaded', dec)
                self.check_decorated_function_is_method('property', dec)
                if len(dec.func.args) > 1:
                    self.fail('Too many arguments', dec.func)
        for i in reversed(removed):
            del dec.decorators[i]
        dec.func.accept(self)
        if not dec.decorators and not dec.var.is_property:
            # No non-special decorators left. We can trivially infer the type
            # of the function here.
            dec.var.type = dec.func.type

    def check_decorated_function_is_method(self, decorator: str,
                                           context: Context) -> None:
        if not self.type or self.is_func_scope():
            self.fail("'%s' used with a non-method" % decorator, context)
    
    def visit_expression_stmt(self, s: ExpressionStmt) -> None:
        s.expr.accept(self)
    
    def visit_return_stmt(self, s: ReturnStmt) -> None:
        if not self.is_func_scope():
            self.fail("'return' outside function", s)
        if s.expr:
            s.expr.accept(self)
    
    def visit_raise_stmt(self, s: RaiseStmt) -> None:
        if s.expr:
            s.expr.accept(self)
    
    def visit_yield_stmt(self, s: YieldStmt) -> None:
        if not self.is_func_scope():
            self.fail("'yield' outside function", s)
        else:
            self.function_stack[-1].is_generator = True
        if s.expr:
            s.expr.accept(self)
    
    def visit_assert_stmt(self, s: AssertStmt) -> None:
        if s.expr:
            s.expr.accept(self)
    
    def visit_operator_assignment_stmt(self,
                                       s: OperatorAssignmentStmt) -> None:
        s.lvalue.accept(self)
        s.rvalue.accept(self)
    
    def visit_while_stmt(self, s: WhileStmt) -> None:
        s.expr.accept(self)
        self.loop_depth += 1
        s.body.accept(self)
        self.loop_depth -= 1
        self.visit_block_maybe(s.else_body)
    
    def visit_for_stmt(self, s: ForStmt) -> None:
        s.expr.accept(self)
        
        # Bind index variables and check if they define new names.
        for n in s.index:
            self.analyse_lvalue(n)
        
        # Analyze index variable types.
        for i in range(len(s.types)):
            t = s.types[i]
            if t:
                s.types[i] = self.anal_type(t)
                v = cast(Var, s.index[i].node)
                # TODO check if redefinition
                v.type = s.types[i]
        
        # Report error if only some of the loop variables have annotations.
        if s.types != [None] * len(s.types) and None in s.types:
            self.fail('Cannot mix unannotated and annotated loop variables', s)
            
        self.loop_depth += 1
        self.visit_block(s.body)
        self.loop_depth -= 1
        
        self.visit_block_maybe(s.else_body)
    
    def visit_break_stmt(self, s: BreakStmt) -> None:
        if self.loop_depth == 0:
            self.fail("'break' outside loop", s)
    
    def visit_continue_stmt(self, s: ContinueStmt) -> None:
        if self.loop_depth == 0:
            self.fail("'continue' outside loop", s)
    
    def visit_if_stmt(self, s: IfStmt) -> None:
        for i in range(len(s.expr)):
            s.expr[i].accept(self)
            self.visit_block(s.body[i])
        self.visit_block_maybe(s.else_body)
    
    def visit_try_stmt(self, s: TryStmt) -> None:
        self.analyze_try_stmt(s, self)

    def analyze_try_stmt(self, s: TryStmt, visitor: NodeVisitor,
                          add_global: bool = False) -> None:
        s.body.accept(visitor)
        for type, var, handler in zip(s.types, s.vars, s.handlers):
            if type:
                type.accept(visitor)
            if var:
                self.analyse_lvalue(var, add_global=add_global)
            handler.accept(visitor)
        if s.else_body:
            s.else_body.accept(visitor)
        if s.finally_body:
            s.finally_body.accept(visitor)
    
    def visit_with_stmt(self, s: WithStmt) -> None:
        for e in s.expr:
            e.accept(self)
        for n in s.name:
            if n:
                self.analyse_lvalue(n)
        self.visit_block(s.body)
    
    def visit_del_stmt(self, s: DelStmt) -> None:
        s.expr.accept(self)
        if not isinstance(s.expr, (IndexExpr, NameExpr, MemberExpr)):
            self.fail('Invalid delete target', s)
    
    def visit_global_decl(self, g: GlobalDecl) -> None:
        for n in g.names:
            self.global_decls[-1].add(n)

    def visit_print_stmt(self, s: PrintStmt) -> None:
        for arg in s.args:
            arg.accept(self)
    
    #
    # Expressions
    #
    
    def visit_name_expr(self, expr: NameExpr) -> None:
        n = self.lookup(expr.name, expr)
        if n:
            if n.kind == TVAR:
                self.fail("'{}' is a type variable and only valid in type "
                          "context".format(expr.name), expr)
            else:
                expr.kind = n.kind
                expr.node = (cast(Node, n.node))
                expr.fullname = n.fullname
    
    def visit_super_expr(self, expr: SuperExpr) -> None:
        if not self.type:
            self.fail('"super" used outside class', expr)
            return 
        expr.info = self.type
    
    def visit_tuple_expr(self, expr: TupleExpr) -> None:
        for item in expr.items:
            item.accept(self)
    
    def visit_list_expr(self, expr: ListExpr) -> None:
        for item in expr.items:
            item.accept(self)
    
    def visit_set_expr(self, expr: SetExpr) -> None:
        for item in expr.items:
            item.accept(self)
    
    def visit_dict_expr(self, expr: DictExpr) -> None:
        for key, value in expr.items:
            key.accept(self)
            value.accept(self)
    
    def visit_paren_expr(self, expr: ParenExpr) -> None:
        expr.expr.accept(self)
    
    def visit_call_expr(self, expr: CallExpr) -> None:
        """Analyze a call expression.

        Some call expressions are recognized as special forms, including
        cast(...), Undefined(...) and Any(...).
        """
        expr.callee.accept(self)
        if refers_to_fullname(expr.callee, 'typing.cast'):
            # Special form cast(...).
            if not self.check_fixed_args(expr, 2, 'cast'):
                return
            # Translate first argument to an unanalyzed type.
            try:
                target = expr_to_unanalyzed_type(expr.args[0])
            except TypeTranslationError:
                self.fail('Cast target is not a type', expr)
                return
            # Pigguback CastExpr object to the CallExpr object; it takes
            # precedence over the CallExpr semantics.
            expr.analyzed = CastExpr(expr.args[1], target)
            expr.analyzed.line = expr.line
            expr.analyzed.accept(self)
        elif refers_to_fullname(expr.callee, 'typing.Any'):
            # Special form Any(...).
            if not self.check_fixed_args(expr, 1, 'Any'):
                return            
            expr.analyzed = CastExpr(expr.args[0], AnyType())
            expr.analyzed.line = expr.line
            expr.analyzed.accept(self)
        elif refers_to_fullname(expr.callee, 'typing.Undefined'):
            # Special form Undefined(...).
            if not self.check_fixed_args(expr, 1, 'Undefined'):
                return
            try:
                type = expr_to_unanalyzed_type(expr.args[0])
            except TypeTranslationError:
                self.fail('Argument to Undefined is not a type', expr)
                return
            expr.analyzed = UndefinedExpr(type)
            expr.analyzed.line = expr.line
            expr.analyzed.accept(self)
        elif refers_to_fullname(expr.callee, 'typing.ducktype'):
            # Special form ducktype(...).
            if not self.check_fixed_args(expr, 1, 'ducktype'):
                return
            # Translate first argument to an unanalyzed type.
            try:
                target = expr_to_unanalyzed_type(expr.args[0])
            except TypeTranslationError:
                self.fail('Argument 1 to ducktype is not a type', expr)
                return
            expr.analyzed = DucktypeExpr(target)
            expr.analyzed.line = expr.line
            expr.analyzed.accept(self)
        elif refers_to_fullname(expr.callee, 'typing.disjointclass'):
            # Special form disjointclass(...).
            if not self.check_fixed_args(expr, 1, 'disjointclass'):
                return
            arg = expr.args[0]
            if isinstance(arg, RefExpr):
                expr.analyzed = DisjointclassExpr(arg)
                expr.analyzed.line = expr.line
                expr.analyzed.accept(self)
            else:
                self.fail('Argument 1 to disjointclass is not a class', expr)
        else:
            # Normal call expression.
            for a in expr.args:
                a.accept(self)

    def check_fixed_args(self, expr: CallExpr, numargs: int,
                         name: str) -> bool:
        """Verify that expr has specified number of positional args.

        Return True if the arguments are valid.
        """
        s = 's'
        if numargs == 1:
            s = ''
        if len(expr.args) != numargs:
            self.fail("'%s' expects %d argument%s" % (name, numargs, s),
                      expr)
            return False
        if expr.arg_kinds != [ARG_POS] * numargs:
            self.fail("'%s' must be called with %s positional argument%s" %
                      (name, numargs, s), expr)
            return False
        return True
    
    def visit_member_expr(self, expr: MemberExpr) -> None:
        base = expr.expr
        base.accept(self)
        # Bind references to module attributes.
        if isinstance(base, RefExpr) and cast(RefExpr,
                                              base).kind == MODULE_REF:
            names = (cast(MypyFile, (cast(RefExpr, base)).node)).names
            n = names.get(expr.name, None)
            if n:
                n = self.normalize_type_alias(n, expr)
                if not n:
                    return
                expr.kind = n.kind
                expr.fullname = n.fullname
                expr.node = n.node
    
    def visit_op_expr(self, expr: OpExpr) -> None:
        expr.left.accept(self)
        expr.right.accept(self)
    
    def visit_unary_expr(self, expr: UnaryExpr) -> None:
        expr.expr.accept(self)
    
    def visit_index_expr(self, expr: IndexExpr) -> None:
        expr.base.accept(self)
        if refers_to_class_or_function(expr.base):
            # Special form -- type application.
            # Translate index to an unanalyzed type.
            types = List[Type]()
            if isinstance(expr.index, TupleExpr):
                items = (cast(TupleExpr, expr.index)).items
            else:
                items = [expr.index]
            for item in items:
                try:
                    typearg = expr_to_unanalyzed_type(item)
                except TypeTranslationError:
                    self.fail('Type expected within [...]', expr)
                    return
                typearg = self.anal_type(typearg)
                types.append(typearg)
            expr.analyzed = TypeApplication(expr.base, types)
            expr.analyzed.line = expr.line
        else:
            expr.index.accept(self)

    def visit_slice_expr(self, expr: SliceExpr) -> None:
        if expr.begin_index:
            expr.begin_index.accept(self)
        if expr.end_index:
            expr.end_index.accept(self)
        if expr.stride:
            expr.stride.accept(self)
    
    def visit_cast_expr(self, expr: CastExpr) -> None:
        expr.expr.accept(self)
        expr.type = self.anal_type(expr.type)

    def visit_undefined_expr(self, expr: UndefinedExpr) -> None:
        expr.type = self.anal_type(expr.type)
    
    def visit_type_application(self, expr: TypeApplication) -> None:
        expr.expr.accept(self)
        for i in range(len(expr.types)):
            expr.types[i] = self.anal_type(expr.types[i])

    def visit_list_comprehension(self, expr: ListComprehension) -> None:
        expr.generator.accept(self)

    def visit_generator_expr(self, expr: GeneratorExpr) -> None:
        self.enter()
        expr.right_expr.accept(self)
        # Bind index variables.
        for n in expr.index:
            self.analyse_lvalue(n)
        if expr.condition:
            expr.condition.accept(self)

        # TODO analyze variable types (see visit_for_stmt)

        expr.left_expr.accept(self)
        self.leave()

    def visit_func_expr(self, expr: FuncExpr) -> None:
        self.analyse_function(expr)

    def visit_conditional_expr(self, expr: ConditionalExpr) -> None:
        expr.if_expr.accept(self)
        expr.cond.accept(self)
        expr.else_expr.accept(self)

    def visit_ducktype_expr(self, expr: DucktypeExpr) -> None:
        expr.type = self.anal_type(expr.type)

    def visit_disjointclass_expr(self, expr: DisjointclassExpr) -> None:
        expr.cls.accept(self)
    
    #
    # Helpers
    #
    
    def lookup(self, name: str, ctx: Context) -> SymbolTableNode:
        """Look up an unqualified name in all active namespaces."""
        # 1. Name declared using 'global x' takes precedence
        if name in self.global_decls[-1]:
            if name in self.globals:
                return self.globals[name]
            else:
                self.name_not_defined(name, ctx)
                return None
        # 2. Class attributes (if within class definition)
        if self.is_class_scope() and name in self.type.names:
            return self.type[name]
        # 3. Local (function) scopes
        for table in reversed(self.locals):
            if table is not None and name in table:
                return table[name]
        # 4. Current file global scope
        if name in self.globals:
            return self.globals[name]
        # 5. Builtins
        b = self.globals.get('__builtins__', None)
        if b:
            table = (cast(MypyFile, b.node)).names
            if name in table:
                return table[name]
        # Give up.
        self.name_not_defined(name, ctx)
        return None
    
    def lookup_qualified(self, name: str, ctx: Context) -> SymbolTableNode:
        if '.' not in name:
            return self.lookup(name, ctx)
        else:
            parts = name.split('.')
            n = self.lookup(parts[0], ctx) # type: SymbolTableNode
            if n:
                for i in range(1, len(parts)):
                    if isinstance(n.node, TypeInfo):
                        n = (cast(TypeInfo, n.node)).get(parts[i])
                    elif isinstance(n.node, MypyFile):
                        n = (cast(MypyFile, n.node)).names.get(parts[i], None)
                    if not n:
                        self.name_not_defined(name, ctx)
                if n:
                    n = self.normalize_type_alias(n, ctx)
            return n
    
    def qualified_name(self, n: str) -> str:
        return self.cur_mod_id + '.' + n
    
    def enter(self) -> None:
        self.locals.append(SymbolTable())
        self.global_decls.append(set())
    
    def leave(self) -> None:
        self.locals.pop()
        self.global_decls.pop()

    def is_func_scope(self) -> bool:
        return self.locals[-1] is not None

    def is_class_scope(self) -> bool:
        return self.type is not None and not self.is_func_scope()

    def add_symbol(self, name: str, node: SymbolTableNode,
                   context: Context) -> None:
        if self.is_func_scope():
            if name in self.locals[-1]:
                # Flag redefinition unless this is a reimport of a module.
                if not (node.kind == MODULE_REF and
                        self.locals[-1][name].node == node.node):
                    self.name_already_defined(name, context)
            self.locals[-1][name] = node
        elif self.type:
            self.type.names[name] = node
        else:
            if name in self.globals and (not isinstance(node.node, MypyFile) or
                                         self.globals[name].node != node.node):
                # Modules can be imported multiple times to support import
                # of multiple submodules of a package (e.g. a.x and a.y).
                self.name_already_defined(name, context)
            self.globals[name] = node
    
    def add_var(self, v: Var, ctx: Context) -> None:
        if self.is_func_scope():
            self.add_local(v, ctx)
        else:
            self.globals[v.name()] = SymbolTableNode(GDEF, v, self.cur_mod_id)
            v._fullname = self.qualified_name(v.name())
    
    def add_local(self, v: Var, ctx: Context) -> None:
        if v.name() in self.locals[-1]:
            self.name_already_defined(v.name(), ctx)
        v._fullname = v.name()
        self.locals[-1][v.name()] = SymbolTableNode(LDEF, v)

    def add_local_func(self, defn: FuncBase, ctx: Context) -> None:
        # TODO combine with above
        if defn.name() in self.locals[-1]:
            self.name_already_defined(defn.name(), ctx)
        self.locals[-1][defn.name()] = SymbolTableNode(LDEF, defn)
    
    def check_no_global(self, n: str, ctx: Context,
                        is_func: bool = False) -> None:
        if n in self.globals:
            if is_func and isinstance(self.globals[n].node, FuncDef):
                self.fail(("Name '{}' already defined (overload variants "
                           "must be next to each other)").format(n), ctx)
            else:
                self.name_already_defined(n, ctx)
    
    def name_not_defined(self, name: str, ctx: Context) -> None:
        self.fail("Name '{}' is not defined".format(name), ctx)
    
    def name_already_defined(self, name: str, ctx: Context) -> None:
        self.fail("Name '{}' already defined".format(name), ctx)
    
    def fail(self, msg: str, ctx: Context) -> None:
        self.errors.report(ctx.get_line(), msg)


class FirstPass(NodeVisitor):
    """First phase of semantic analysis"""
    
    def __init__(self, sem: SemanticAnalyzer) -> None:
        self.sem = sem

    def analyze(self, file: MypyFile, fnam: str, mod_id: str) -> None:
        """Perform the first analysis pass.

        Resolve the full names of definitions not nested within functions and
        construct type info structures, but do not resolve inter-definition
        references such as base classes.

        Also add implicit definitions such as __name__.
        """
        sem = self.sem
        sem.cur_mod_id = mod_id
        sem.errors.set_file(fnam)
        sem.globals = SymbolTable()
        sem.global_decls = [set()]
        sem.block_depth = [0]

        defs = file.defs
    
        # Add implicit definitions of module '__name__' etc.
        for n in implicit_module_attrs:
            name_def = VarDef([Var(n, AnyType())], True)
            defs.insert(0, name_def)
        
        for d in defs:
            d.accept(self)
        
        # Add implicit definition of 'None' to builtins, as we cannot define a
        # variable with a None type explicitly.
        if mod_id == 'builtins':
            none_def = VarDef([Var('None', NoneTyp())], True)
            defs.append(none_def)
            none_def.accept(self)

    def visit_block(self, b: Block) -> None:
        self.sem.block_depth[-1] += 1
        for node in b.body:
            node.accept(self)
        self.sem.block_depth[-1] -= 1
    
    def visit_assignment_stmt(self, s: AssignmentStmt) -> None:
        for lval in s.lvalues:
            self.sem.analyse_lvalue(lval, add_global=True,
                                    explicit_type=s.type is not None)
    
    def visit_func_def(self, d: FuncDef) -> None:
        sem = self.sem
        d.is_conditional = sem.block_depth[-1] > 0
        if d.name() in sem.globals:
            n = sem.globals[d.name()].node
            if sem.is_conditional_func(n, d):
                # Conditional function definition -- multiple defs are ok.
                d.original_def = cast(FuncDef, n)
            else:
                sem.check_no_global(d.name(), d, True)
        d._fullname = sem.qualified_name(d.name())
        sem.globals[d.name()] = SymbolTableNode(GDEF, d, sem.cur_mod_id)
    
    def visit_overloaded_func_def(self, d: OverloadedFuncDef) -> None:
        self.sem.check_no_global(d.name(), d)
        d._fullname = self.sem.qualified_name(d.name())
        self.sem.globals[d.name()] = SymbolTableNode(GDEF, d,
                                                     self.sem.cur_mod_id)
    
    def visit_class_def(self, d: ClassDef) -> None:
        self.sem.check_no_global(d.name, d)
        d.fullname = self.sem.qualified_name(d.name)
        info = TypeInfo(SymbolTable(), d)
        info.set_line(d.line)
        d.info = info
        self.sem.globals[d.name] = SymbolTableNode(GDEF, info,
                                                   self.sem.cur_mod_id)
    
    def visit_var_def(self, d: VarDef) -> None:
        for v in d.items:
            self.sem.check_no_global(v.name(), d)
            v._fullname = self.sem.qualified_name(v.name())
            self.sem.globals[v.name()] = SymbolTableNode(GDEF, v,
                                                         self.sem.cur_mod_id)

    def visit_for_stmt(self, s: ForStmt) -> None:
        for n in s.index:
            self.sem.analyse_lvalue(n, add_global=True)

    def visit_with_stmt(self, s: WithStmt) -> None:
        for n in s.name:
            if n:
                self.sem.analyse_lvalue(n, add_global=True)

    def visit_decorator(self, d: Decorator) -> None:
        d.var._fullname = self.sem.qualified_name(d.var.name())
        self.sem.add_symbol(d.var.name(), SymbolTableNode(GDEF, d.var), d)

    def visit_if_stmt(self, s: IfStmt) -> None:
        for node in s.body:
            node.accept(self)
        if s.else_body:
            s.else_body.accept(self)

    def visit_try_stmt(self, s: TryStmt) -> None:
        self.sem.analyze_try_stmt(s, self, add_global=True)


class ThirdPass(TraverserVisitor[None]):
    """The third and final pass of semantic analysis.

    Check type argument counts and values of generic types. Also update
    TypeInfo disjointclass information.
    """
    
    def __init__(self, errors: Errors) -> None:
        self.errors = errors
    
    def visit_file(self, file_node: MypyFile, fnam: str) -> None:
        self.errors.set_file(fnam)
        file_node.accept(self)
        
    def visit_func_def(self, fdef: FuncDef) -> None:
        self.errors.push_function(fdef.name())
        self.analyze(fdef.type)
        super().visit_func_def(fdef)
        self.errors.pop_function()

    def visit_class_def(self, tdef: ClassDef) -> None:
        for type in tdef.info.bases:
            self.analyze(type)
        info = tdef.info
        # Collect declared disjoint classes from all base classes.
        for base in info.mro:
            for disjoint in base.disjoint_classes:
                if disjoint not in info.disjoint_classes:
                    info.disjoint_classes.append(disjoint)
                    for subtype in disjoint.all_subtypes():
                        if info not in subtype.disjoint_classes:
                            subtype.disjoint_classes.append(info)
        super().visit_class_def(tdef)

    def visit_assignment_stmt(self, s: AssignmentStmt) -> None:
        self.analyze(s.type)
        super().visit_assignment_stmt(s)

    def visit_undefined_expr(self, e: UndefinedExpr) -> None:
        self.analyze(e.type)

    def visit_cast_expr(self, e: CastExpr) -> None:
        self.analyze(e.type)
        super().visit_cast_expr(e)

    def visit_type_application(self, e: TypeApplication) -> None:
        for type in e.types:
            self.analyze(type)
        super().visit_type_application(e)

    def analyze(self, type: Type) -> None:
        if type:
            analyzer = TypeAnalyserPass3(self.fail)
            type.accept(analyzer)
    
    def fail(self, msg: str, ctx: Context) -> None:
        self.errors.report(ctx.get_line(), msg)


def self_type(typ: TypeInfo) -> Instance:
    """For a non-generic type, return instance type representing the type.
    For a generic G type with parameters T1, .., Tn, return G[T1, ..., Tn].
    """
    tv = List[Type]()
    for i in range(len(typ.type_vars)):
        tv.append(TypeVar(typ.type_vars[i], i + 1,
                          typ.defn.type_vars[i].values))
    return Instance(typ, tv)


@overload
def replace_implicit_self_type(sig: Callable, new: Type) -> Callable:
    # We can detect implicit self type by it having no representation.
    if not sig.arg_types[0].repr:
        return replace_self_type(sig, new)
    else:
        return sig

@overload
def replace_implicit_self_type(sig: FunctionLike, new: Type) -> FunctionLike:
    osig = cast(Overloaded, sig)
    return Overloaded([replace_implicit_self_type(i, new)
                       for i in osig.items()])


def set_callable_name(sig: Type, fdef: FuncDef) -> Type:
    if isinstance(sig, FunctionLike):
        if fdef.info:
            return sig.with_name(
                '"{}" of "{}"'.format(fdef.name(), fdef.info.name()))
        else:
            return sig.with_name('"{}"'.format(fdef.name()))
    else:
        return sig


def refers_to_fullname(node: Node, fullname: str) -> bool:
    """Is node a name or member expression with the given full name?"""
    return isinstance(node,
                      RefExpr) and cast(RefExpr, node).fullname == fullname


def refers_to_class_or_function(node: Node) -> bool:
    """Does semantically analyzed node refer to a class?"""
    return (isinstance(node, RefExpr) and
            isinstance(cast(RefExpr, node).node, (TypeInfo, FuncDef,
                                                  OverloadedFuncDef)))


def expr_to_unanalyzed_type(expr: Node) -> Type:
    """Translate an expression to the corresonding type.

    The result is not semantically analyzed. It can be UnboundType or ListType.
    Raise TypeTranslationError if the expression cannot represent a type.
    """
    if isinstance(expr, NameExpr):
        name = expr.name
        return UnboundType(name, line=expr.line)
    elif isinstance(expr, MemberExpr):
        fullname = get_member_expr_fullname(expr)
        if fullname:
            return UnboundType(fullname, line=expr.line)
        else:
            raise TypeTranslationError()
    elif isinstance(expr, IndexExpr):
        base = expr_to_unanalyzed_type(expr.base)
        if isinstance(base, UnboundType):
            if base.args:
                raise TypeTranslationError()
            if isinstance(expr.index, TupleExpr):
                args = cast(TupleExpr, expr.index).items
            else:
                args = [expr.index]
            base.args = [expr_to_unanalyzed_type(arg) for arg in args]
            return base
        else:
            raise TypeTranslationError()
    elif isinstance(expr, ListExpr):
        return TypeList([expr_to_unanalyzed_type(t) for t in expr.items],
                        line=expr.line)
    elif isinstance(expr, StrExpr):
        # Parse string literal type.
        try:
            result = parse_str_as_type(expr.value, expr.line)
        except TypeParseError:
            raise TypeTranslationError()
        return result
    else:
        raise TypeTranslationError()


def get_member_expr_fullname(expr: MemberExpr) -> str:
    """Return the qualified name represention of a member expression.

    Return a string of form foo.bar, foo.bar.baz, or similar, or None if the
    argument cannot be represented in this form.
    """
    if isinstance(expr.expr, NameExpr):
        initial = cast(NameExpr, expr.expr).name
    elif isinstance(expr.expr, MemberExpr):
        initial = get_member_expr_fullname(cast(MemberExpr, expr.expr))
    else:
        return None
    return '{}.{}'.format(initial, expr.name)


def find_duplicate(list: List[T]) -> T:
    """If the list has duplicates, return one of the duplicates.

    Otherwise, return None.
    """
    for i in range(1, len(list)):
        if list[i] in list[:i]:
            return list[i]
    return None


def disable_typevars(nodes: List[SymbolTableNode]) -> None:
    for node in nodes:
        assert node.kind in (TVAR, UNBOUND_TVAR)
        node.kind = UNBOUND_TVAR


def enable_typevars(nodes: List[SymbolTableNode]) -> None:
    for node in nodes:
        assert node.kind in (TVAR, UNBOUND_TVAR)
        node.kind = TVAR


def remove_imported_names_from_symtable(names: SymbolTable,
                                        module: str) -> None:
    """Remove all imported names from the symbol table of a module."""
    removed = List[str]()
    for name, node in names.items():
        fullname = node.node.fullname()
        prefix = fullname[:fullname.rfind('.')]
        if prefix != module:
            removed.append(name)
    for name in removed:
        del names[name]

########NEW FILE########
__FILENAME__ = solve
"""Type inference constraint solving"""

from typing import List, Dict

from mypy.types import Type, Void, NoneTyp, AnyType, ErrorType, BasicTypes
from mypy.constraints import Constraint, SUPERTYPE_OF
from mypy.join import join_types
from mypy.meet import meet_types
from mypy.subtypes import is_subtype


def solve_constraints(vars: List[int], constraints: List[Constraint],
                      basic: BasicTypes) -> List[Type]:
    """Solve type constraints.

    Return lower bound for each type variable or None if the variable could
    not be solved.
    """
    # Collect a list of constraints for each type variable.
    cmap = Dict[int, List[Constraint]]()
    for con in constraints:
        a = cmap.get(con.type_var, [])
        a.append(con)
        cmap[con.type_var] = a
    
    res = [] # type: List[Type]

    # Solve each type variable separately.
    for tvar in vars:
        bottom = None # type: Type
        top = None # type: Type
        
        # Process each contraint separely, and calculate the lower and upper
        # bounds based on constraints. Note that we assume that the contraint
        # targets do not have contraint references.
        for c in cmap.get(tvar, []):
            if c.op == SUPERTYPE_OF:
                if bottom is None:
                    bottom = c.target
                else:
                    bottom = join_types(bottom, c.target, basic)
            else:
                if top is None:
                    top = c.target
                else:
                    top = meet_types(top, c.target, basic)
        
        if top is None:
            if isinstance(bottom, Void):
                top = Void()
            else:
                top = basic.object
        
        if bottom is None:
            if isinstance(top, Void):
                bottom = Void()
            else:
                bottom = NoneTyp()
        
        if isinstance(top, AnyType) or isinstance(bottom, AnyType):
            top = AnyType()
            bottom = AnyType()
        
        # Pick the most specific type if it satisfies the constraints.
        if (not top or not bottom or is_subtype(bottom, top)) and (
                not isinstance(top, ErrorType) and
                not isinstance(bottom, ErrorType)):
            res.append(bottom)
        else:
            res.append(None)
    
    return res

########NEW FILE########
__FILENAME__ = strconv
"""Conversion of parse tree nodes to strings."""

import re
import os

import typing

from mypy.util import dump_tagged, short_type
import mypy.nodes
from mypy.visitor import NodeVisitor


class StrConv(NodeVisitor[str]):
    """Visitor for converting a Node to a human-readable string.
    
    For example, an MypyFile node from program '1' is converted into
    something like this:
    
      MypyFile:1(
        fnam
        ExpressionStmt:1(
          IntExpr(1)))
    """
    def dump(self, nodes, obj):
        """Convert a list of items to a multiline pretty-printed string.

        The tag is produced from the type name of obj and its line
        number. See mypy.util.dump_tagged for a description of the nodes
        argument.
        """
        return dump_tagged(nodes, short_type(obj) + ':' + str(obj.line))
    
    def func_helper(self, o):
        """Return a list in a format suitable for dump() that represents the
        arguments and the body of a function. The caller can then decorate the
        array with information specific to methods, global functions or
        anonymous functions.
        """
        args = []
        init = []
        extra = []
        for i, kind in enumerate(o.arg_kinds):
            if kind == mypy.nodes.ARG_POS:
                args.append(o.args[i])
            elif kind in (mypy.nodes.ARG_OPT, mypy.nodes.ARG_NAMED):
                args.append(o.args[i])
                init.append(o.init[i])
            elif kind == mypy.nodes.ARG_STAR:
                extra.append(('VarArg', [o.args[i]]))
            elif kind == mypy.nodes.ARG_STAR2:
                extra.append(('DictVarArg', [o.args[i]]))
        a = []
        if args:
            a.append(('Args', args))
        if o.type:
            a.append(o.type)
        if init:
            a.append(('Init', init))
        if o.is_generator:
            a.append('Generator')
        a.extend(extra)
        a.append(o.body)
        return a                    
    
    # Top-level structures
    
    def visit_mypy_file(self, o):
        # Skip implicit definitions.
        defs = o.defs
        while (defs and isinstance(defs[0], mypy.nodes.VarDef) and
                not defs[0].repr):
            defs = defs[1:]
        a = [defs]
        if o.is_bom:
            a.insert(0, 'BOM')
        # Omit path to special file with name "main". This is used to simplify
        # test case descriptions; the file "main" is used by default in many
        # test cases.
        if o.path is not None and o.path != 'main':
            # Insert path. Normalize directory separators to / to unify test
            # case# output in all platforms.
            a.insert(0, o.path.replace(os.sep, '/'))
        return self.dump(a, o)
    
    def visit_import(self, o):
        a = []
        for id, as_id in o.ids:
            a.append('{} : {}'.format(id, as_id))
        return 'Import:{}({})'.format(o.line, ', '.join(a))
    
    def visit_import_from(self, o):
        a = []
        for name, as_name in o.names:
            a.append('{} : {}'.format(name, as_name))
        return 'ImportFrom:{}({}, [{}])'.format(o.line, o.id, ', '.join(a))
    
    def visit_import_all(self, o):
        return 'ImportAll:{}({})'.format(o.line, o.id)
    
    # Definitions
    
    def visit_func_def(self, o):
        a = self.func_helper(o)
        a.insert(0, o.name())
        if mypy.nodes.ARG_NAMED in o.arg_kinds:
            a.insert(1, 'MaxPos({})'.format(o.max_pos))
        if o.is_abstract:
            a.insert(-1, 'Abstract')
        if o.is_static:
            a.insert(-1, 'Static')
        if o.is_property:
            a.insert(-1, 'Property')
        return self.dump(a, o)
    
    def visit_overloaded_func_def(self, o):
        a = o.items[:]
        if o.type:
            a.insert(0, o.type)
        return self.dump(a, o)
    
    def visit_class_def(self, o):
        a = [o.name, o.defs.body]
        # Display base types unless they are implicitly just builtins.object
        # (in this case there is no representation).
        if len(o.base_types) > 1 or (len(o.base_types) == 1
                                     and o.base_types[0].repr):
            a.insert(1, ('BaseType', o.base_types))
        if o.type_vars:
            a.insert(1, ('TypeVars', o.type_vars))
        if o.metaclass:
            a.insert(1, 'Metaclass({})'.format(o.metaclass))
        if o.decorators:
            a.insert(1, ('Decorators', o.decorators))
        if o.is_builtinclass:
            a.insert(1, 'Builtinclass')
        if o.info and o.info.ducktype:
            a.insert(1, 'Ducktype({})'.format(o.info.ducktype))
        if o.info and o.info.disjoint_classes:
            a.insert(1, ('Disjointclasses', [info.fullname() for
                                             info in o.info.disjoint_classes]))
        return self.dump(a, o)
    
    def visit_var_def(self, o):
        a = []
        for n in o.items:
            a.append('Var({})'.format(n.name()))
            a.append('Type({})'.format(n.type))
        if o.init:
            a.append(o.init)
        return self.dump(a, o)
    
    def visit_var(self, o):
        l = ''
        # Add :nil line number tag if no line number is specified to remain
        # compatible with old test case descriptions that assume this.
        if o.line < 0:
            l = ':nil'
        return 'Var' + l + '(' + o.name() + ')'
    
    def visit_global_decl(self, o):
        return self.dump([o.names], o)
    
    def visit_decorator(self, o):
        return self.dump([o.var, o.decorators, o.func], o)
    
    def visit_annotation(self, o):
        return 'Type:{}({})'.format(o.line, o.type)
    
    # Statements
    
    def visit_block(self, o):
        return self.dump(o.body, o)
    
    def visit_expression_stmt(self, o):
        return self.dump([o.expr], o)
    
    def visit_assignment_stmt(self, o):
        if len(o.lvalues) > 1:
            a = [('Lvalues', o.lvalues)]
        else:
            a = [o.lvalues[0]]
        a.append(o.rvalue)
        if o.type:
            a.append(o.type)
        return self.dump(a, o)
    
    def visit_operator_assignment_stmt(self, o):
        return self.dump([o.op, o.lvalue, o.rvalue], o)
    
    def visit_while_stmt(self, o):
        a = [o.expr, o.body]
        if o.else_body:
            a.append(('Else', o.else_body.body))
        return self.dump(a, o)
    
    def visit_for_stmt(self, o):
        a = [o.index]
        if o.types != [None] * len(o.types):
            a += o.types
        a.extend([o.expr, o.body])
        if o.else_body:
            a.append(('Else', o.else_body.body))
        return self.dump(a, o)
    
    def visit_return_stmt(self, o):
        return self.dump([o.expr], o)
    
    def visit_if_stmt(self, o):
        a = []
        for i in range(len(o.expr)):
            a.append(('If', [o.expr[i]]))
            a.append(('Then', o.body[i].body))
        
        if not o.else_body:
            return self.dump(a, o)
        else:
            return self.dump([a, ('Else', o.else_body.body)], o)
    
    def visit_break_stmt(self, o):
        return self.dump([], o)
    
    def visit_continue_stmt(self, o):
        return self.dump([], o)
    
    def visit_pass_stmt(self, o):
        return self.dump([], o)
    
    def visit_raise_stmt(self, o):
        return self.dump([o.expr, o.from_expr], o)
    
    def visit_assert_stmt(self, o):
        return self.dump([o.expr], o)
    
    def visit_yield_stmt(self, o):
        return self.dump([o.expr], o)
    
    def visit_del_stmt(self, o):
        return self.dump([o.expr], o)
    
    def visit_try_stmt(self, o):
        a = [o.body]
        
        for i in range(len(o.vars)):
            a.append(o.types[i])
            if o.vars[i]:
                a.append(o.vars[i])
            a.append(o.handlers[i])
        
        if o.else_body:
            a.append(('Else', o.else_body.body))
        if o.finally_body:
            a.append(('Finally', o.finally_body.body))
        
        return self.dump(a, o)
    
    def visit_with_stmt(self, o):
        a = []
        for i in range(len(o.expr)):
            a.append(('Expr', [o.expr[i]]))
            if o.name[i]:
                a.append(('Name', [o.name[i]]))
        return self.dump(a + [o.body], o)

    def visit_print_stmt(self, o):
        a = o.args[:]
        if o.newline:
            a.append('Newline')
        return self.dump(a, o)
    
    # Expressions
    
    # Simple expressions
    
    def visit_int_expr(self, o):
        return 'IntExpr({})'.format(o.value)
    
    def visit_str_expr(self, o):
        return 'StrExpr({})'.format(self.str_repr(o.value))
    
    def visit_bytes_expr(self, o):
        return 'BytesExpr({})'.format(self.str_repr(o.value))
    
    def visit_unicode_expr(self, o):
        return 'UnicodeExpr({})'.format(self.str_repr(o.value))
    
    def str_repr(self, s):
        s = re.sub(r'\\u[0-9a-fA-F]{4}', lambda m: '\\' + m.group(0), s)
        return re.sub('[^\\x20-\\x7e]',
                      lambda m: r'\u%.4x' % ord(m.group(0)), s)
    
    def visit_float_expr(self, o):
        return 'FloatExpr({})'.format(o.value)
    
    def visit_paren_expr(self, o):
        return self.dump([o.expr], o)
    
    def visit_name_expr(self, o):
        return (short_type(o) + '(' + self.pretty_name(o.name, o.kind,
                                                       o.fullname, o.is_def)
                + ')')
    
    def pretty_name(self, name, kind, fullname, is_def):
        n = name
        if is_def:
            n += '*'
        if kind == mypy.nodes.GDEF or (fullname != name and
                                       fullname is not None):
            # Append fully qualified name for global references.
            n += ' [{}]'.format(fullname)
        elif kind == mypy.nodes.LDEF:
            # Add tag to signify a local reference.
            n += ' [l]'
        elif kind == mypy.nodes.MDEF:
            # Add tag to signify a member reference.
            n += ' [m]'
        return n
    
    def visit_member_expr(self, o):
        return self.dump([o.expr, self.pretty_name(o.name, o.kind, o.fullname,
                                                   o.is_def)], o)
    
    def visit_call_expr(self, o):
        if o.analyzed:
            return o.analyzed.accept(self)
        args = []
        extra = []
        for i, kind in enumerate(o.arg_kinds):
            if kind in [mypy.nodes.ARG_POS, mypy.nodes.ARG_STAR]:
                args.append(o.args[i])
                if kind == mypy.nodes.ARG_STAR:
                    extra.append('VarArg')
            elif kind == mypy.nodes.ARG_NAMED:
                extra.append(('KwArgs', [o.arg_names[i], o.args[i]]))
            elif kind == mypy.nodes.ARG_STAR2:
                extra.append(('DictVarArg', [o.args[i]]))
            else:
                raise RuntimeError('unknown kind %d' % kind)

        return self.dump([o.callee, ('Args', args)] + extra, o)
    
    def visit_op_expr(self, o):
        return self.dump([o.op, o.left, o.right], o)
    
    def visit_cast_expr(self, o):
        return self.dump([o.expr, o.type], o)
    
    def visit_unary_expr(self, o):
        return self.dump([o.op, o.expr], o)
    
    def visit_list_expr(self, o):
        return self.dump(o.items, o)
    
    def visit_dict_expr(self, o):
        return self.dump([[k, v] for k, v in o.items], o)
    
    def visit_set_expr(self, o):
        return self.dump(o.items, o)
    
    def visit_tuple_expr(self, o):
        return self.dump(o.items, o)
    
    def visit_index_expr(self, o):
        if o.analyzed:
            return o.analyzed.accept(self)
        return self.dump([o.base, o.index], o)
    
    def visit_super_expr(self, o):
        return self.dump([o.name], o)

    def visit_undefined_expr(self, o):
        return 'UndefinedExpr:{}({})'.format(o.line, o.type)
    
    def visit_type_application(self, o):
        return self.dump([o.expr, ('Types', o.types)], o)

    def visit_type_var_expr(self, o):
        if o.values:
            return self.dump([('Values', o.values)], o)
        else:
            return 'TypeVarExpr:{}()'.format(o.line)

    def visit_ducktype_expr(self, o):
        return 'DucktypeExpr:{}({})'.format(o.line, o.type)

    def visit_disjointclass_expr(self, o):
        return 'DisjointclassExpr:{}({})'.format(o.line, o.cls.fullname)
    
    def visit_func_expr(self, o):
        a = self.func_helper(o)
        return self.dump(a, o)
    
    def visit_generator_expr(self, o):
        # FIX types
        return self.dump([o.left_expr, o.index, o.right_expr, o.condition], o)
    
    def visit_list_comprehension(self, o):
        return self.dump([o.generator], o)
    
    def visit_conditional_expr(self, o):
        return self.dump([('Condition', [o.cond]), o.if_expr, o.else_expr], o)
    
    def visit_slice_expr(self, o):
        a = [o.begin_index, o.end_index, o.stride]
        if not a[0]:
            a[0] = '<empty>'
        if not a[1]:
            a[1] = '<empty>'
        return self.dump(a, o)
    
    def visit_coerce_expr(self, o):
        return self.dump([o.expr, ('Types', [o.target_type, o.source_type])],
                         o)
    
    def visit_type_expr(self, o):
        return self.dump([str(o.type)], o)
    
    def visit_filter_node(self, o):
        # These are for convenience. These node types are not defined in the
        # parser module.
        pass

########NEW FILE########
__FILENAME__ = subtypes
from typing import cast, List, Dict

from mypy.types import (
    Type, AnyType, UnboundType, TypeVisitor, ErrorType, Void, NoneTyp,
    Instance, TypeVar, Callable, TupleType, Overloaded, ErasedType, TypeList
)
from mypy import sametypes
from mypy.nodes import TypeInfo
from mypy.expandtype import expand_type


def is_subtype(left: Type, right: Type) -> bool:
    """Is 'left' subtype of 'right'?

    Also consider Any to be a subtype of any type, and vice versa. This
    recursively applies to components of composite types (List[int] is subtype
    of List[Any], for example).
    """
    if (isinstance(right, AnyType) or isinstance(right, UnboundType)
            or isinstance(right, ErasedType)):
        return True
    else:
        return left.accept(SubtypeVisitor(right))


def is_equivalent(a: Type, b: Type) -> bool:
    return is_subtype(a, b) and is_subtype(b, a)


class SubtypeVisitor(TypeVisitor[bool]):
    def __init__(self, right: Type) -> None:
        self.right = right
    
    # visit_x(left) means: is left (which is an instance of X) a subtype of
    # right?
    
    def visit_unbound_type(self, left: UnboundType) -> bool:
        return True
    
    def visit_error_type(self, left: ErrorType) -> bool:
        return False
    
    def visit_type_list(self, t: TypeList) -> bool:
        assert False, 'Not supported'
    
    def visit_any(self, left: AnyType) -> bool:
        return True
    
    def visit_void(self, left: Void) -> bool:
        return isinstance(self.right, Void)
    
    def visit_none_type(self, left: NoneTyp) -> bool:
        return not isinstance(self.right, Void)
    
    def visit_erased_type(self, left: ErasedType) -> bool:
        return True
    
    def visit_instance(self, left: Instance) -> bool:
        right = self.right
        if isinstance(right, Instance):
            if left.type.ducktype and is_subtype(left.type.ducktype,
                                                 self.right):
                return True
            rname = right.type.fullname()
            if not left.type.has_base(rname) and rname != 'builtins.object':
                return False
            
            # Map left type to corresponding right instances.
            t = map_instance_to_supertype(left, right.type)
            result = True
            for i in range(len(right.args)):
                if not is_equivalent(t.args[i], right.args[i]):
                    result = False
                    break
            return result
        else:
            return False
    
    def visit_type_var(self, left: TypeVar) -> bool:
        right = self.right
        if isinstance(right, TypeVar):
            return (left.name == right.name and
                    left.is_wrapper_var == right.is_wrapper_var)
        else:
            return is_named_instance(self.right, 'builtins.object')
    
    def visit_callable(self, left: Callable) -> bool:
        right = self.right
        if isinstance(right, Callable):
            return is_callable_subtype(left, right)
        elif isinstance(right, Overloaded):
            return all(is_subtype(left, item) for item in right.items())
        elif is_named_instance(right, 'builtins.object'):
            return True
        elif (is_named_instance(right, 'builtins.type') and
                  left.is_type_obj()):
            return True
        else:
            return False
    
    def visit_tuple_type(self, left: TupleType) -> bool:
        right = self.right
        if isinstance(right, Instance) and (
                is_named_instance(right, 'builtins.object') or
                is_named_instance(right, 'builtins.tuple')):
            return True
        elif isinstance(right, TupleType):
            if len(left.items) != len(right.items):
                return False
            for i in range(len(left.items)):
                if not is_subtype(left.items[i], right.items[i]):
                    return False
            return True
        else:
            return False
    
    def visit_overloaded(self, left: Overloaded) -> bool:
        right = self.right
        if is_named_instance(right, 'builtins.object'):
            return True
        elif isinstance(right, Callable) or is_named_instance(
                                                 right, 'builtins.type'):
            for item in left.items():
                if is_subtype(item, right):
                    return True
            return False
        elif isinstance(right, Overloaded):
            # TODO: this may be too restrictive
            if len(left.items()) != len(right.items()):
                return False
            for i in range(len(left.items())):
                if not is_subtype(left.items()[i], right.items()[i]):
                    return False
            return True
        elif isinstance(right, UnboundType):
            return True
        else:
            return False


def is_callable_subtype(left: Callable, right: Callable) -> bool:
    # TODO support named arguments, **args etc.
    
    # Subtyping is not currently supported for generic functions.
    if left.variables or right.variables:
        return False
    
    # Non-type cannot be a subtype of type.
    if right.is_type_obj() and not left.is_type_obj():
        return False
    
    # Check return types.
    if not is_subtype(left.ret_type, right.ret_type):
        return False
    
    if len(left.arg_types) < len(right.arg_types):
        return False
    if left.min_args > right.min_args:
        return False
    for i in range(len(right.arg_types)):
        if not is_subtype(right.arg_types[i], left.arg_types[i]):
            return False
    
    if right.is_var_arg and not left.is_var_arg:
        return False
    
    if (left.is_var_arg and not right.is_var_arg and
            len(left.arg_types) <= len(right.arg_types)):
        return False
    
    return True


def map_instance_to_supertype(instance: Instance,
                              supertype: TypeInfo) -> Instance:
    """Map an Instance type, including the type arguments, to compatible
    Instance of a specific supertype.
    
    Assume that supertype is a supertype of instance.type.
    """
    if instance.type == supertype:
        return instance
    
    # Strip type variables away if the supertype has none.
    if not supertype.type_vars:
        return Instance(supertype, [])
    
    return map_instance_to_supertypes(instance, supertype)[0]


def map_instance_to_direct_supertype(instance: Instance,
                                     supertype: TypeInfo) -> Instance:
    typ = instance.type
    
    for base in typ.bases:
        if base.type == supertype:
            map = type_var_map(typ, instance.args)
            return cast(Instance, expand_type(base, map))
    
    # Relationship with the supertype not specified explicitly. Use AnyType
    # type arguments implicitly.
    # TODO Should this be an error instead?
    return Instance(supertype, [AnyType()] * len(supertype.type_vars))


def type_var_map(typ: TypeInfo, args: List[Type]) -> Dict[int, Type]:
    if not args:
        return None
    else:
        tvars = {} # type: Dict[int, Type]
        for i in range(len(args)):
            tvars[i + 1] = args[i]
        return tvars


def map_instance_to_supertypes(instance: Instance,
                               supertype: TypeInfo) -> List[Instance]:
    # FIX: Currently we should only have one supertype per interface, so no
    #      need to return an array
    result = [] # type: List[Instance]
    for path in class_derivation_paths(instance.type, supertype):
        types = [instance]
        for sup in path:
            a = [] # type: List[Instance]
            for t in types:
                a.extend(map_instance_to_direct_supertypes(t, sup))
            types = a
        result.extend(types)
    return result


def class_derivation_paths(typ: TypeInfo,
                           supertype: TypeInfo) -> List[List[TypeInfo]]:
    """Return an array of non-empty paths of direct base classes from
    type to supertype.  Return [] if no such path could be found.
    
      InterfaceImplementationPaths(A, B) == [[B]] if A inherits B
      InterfaceImplementationPaths(A, C) == [[B, C]] if A inherits B and
                                                        B inherits C
    """
    # FIX: Currently we might only ever have a single path, so this could be
    #      simplified
    result = [] # type: List[List[TypeInfo]]

    for base in typ.bases:
        if base.type == supertype:
            result.append([base.type])
        else:
            # Try constructing a longer path via the base class.
            for path in class_derivation_paths(base.type, supertype):
                result.append([base.type] + path)

    return result


def map_instance_to_direct_supertypes(instance: Instance,
                                      supertype: TypeInfo) -> List[Instance]:
    # FIX: There should only be one supertypes, always.
    typ = instance.type
    result = [] # type: List[Instance]
    
    for b in typ.bases:
        if b.type == supertype:
            map = type_var_map(typ, instance.args)
            result.append(cast(Instance, expand_type(b, map)))
    
    if result:
        return result
    else:
        # Relationship with the supertype not specified explicitly. Use dynamic
        # type arguments implicitly.
        return [Instance(supertype, [AnyType()] * len(supertype.type_vars))]


def is_named_instance(t: Type, fullname: str) -> bool:
    return (isinstance(t, Instance) and
            cast(Instance, t).type.fullname() == fullname)


def is_proper_subtype(t: Type, s: Type) -> bool:
    """Check if t is a proper subtype of s?

    For proper subtypes, there's no need to rely on compatibility due to
    Any types. Any instance type t is also a proper subtype of t.
    """
    # FIX tuple types
    if isinstance(t, Instance):
        if isinstance(s, Instance):
            if not t.type.has_base(s.type.fullname()):
                return False
            t = map_instance_to_supertype(t, s.type)
            return all(sametypes.is_same_type(x, y)
                       for x, y in zip(t.args, s.args))
        return False
    else:
        return sametypes.is_same_type(t, s)


def is_more_precise(t: Type, s: Type) -> bool:
    """Check if t is a more precise type than s.

    A t is a proper subtype of s, t is also more precise than s. Also, if
    s is Any, t is more precise than s for any t. Finally, if t is the same
    type as s, t is more precise than s.
    """
    # TODO Should List[int] be more precise than List[Any]?
    if isinstance(s, AnyType):
        return True
    if isinstance(s, Instance):
        return is_proper_subtype(t, s)
    return sametypes.is_same_type(t, s)

########NEW FILE########
__FILENAME__ = config
import os
import os.path

import typing


PREFIX = ''

# Location of test data files such as test case descriptions.
test_data_prefix = os.path.join(PREFIX, 'mypy', 'test', 'data')

assert os.path.isdir(test_data_prefix), \
        'Test data prefix ({}) not set correctly'.format(test_data_prefix)

# Temp directory used for the temp files created when running test cases.
test_temp_dir = os.path.join(PREFIX, 'tmp')

if not os.path.isdir(test_temp_dir):
    os.mkdir(test_temp_dir)

assert os.path.isdir(test_temp_dir), \
        'Test temp dir ({}) not set correctly'.format(test_temp_dir)

########NEW FILE########
__FILENAME__ = bool
# builtins stub used in boolean-related test cases.

from typing import builtinclass

@builtinclass
class object:
    def __init__(self) -> None: pass

class type: pass

class bool: pass

class int: pass

########NEW FILE########
__FILENAME__ = dict
# Builtins stub used in dictionary-related test cases.

from typing import typevar, Generic, Iterable, Iterator

T = typevar('T')
S = typevar('S')

class object:
    def __init__(self) -> None: pass

class type: pass

class dict(Generic[T, S]): pass
class int: pass # for convenience
class str: pass # for keyword argument key type
class list(Iterable[T], Generic[T]): # needed by some test cases
    def __iter__(self) -> Iterator[T]: pass
    def __mul__(self, x: int) -> list[T]: pass

########NEW FILE########
__FILENAME__ = exception

class object:
    def __init__(self): pass

class type: pass

class BaseException: pass

########NEW FILE########
__FILENAME__ = for
# builtins stub used in for statement test cases

from typing import typevar, Generic, Iterable, Iterator
from abc import abstractmethod, ABCMeta

t = typevar('t')

class object:
    def __init__(self) -> None: pass
    
class type: pass
class bool: pass
class int: pass # for convenience
class str: pass # for convenience

class list(Iterable[t], Generic[t]):
    def __iter__(self) -> Iterator[t]: pass

class tuple: pass

########NEW FILE########
__FILENAME__ = function
from typing import builtinclass

@builtinclass
class object:
    def __init__(self): pass

class type: pass
class function: pass

########NEW FILE########
__FILENAME__ = icodegen
# These builtins stubs are used implicitly in parse-tree to icode generation
# test cases (testicodegen.py and test/data/icode-basic.test).

from typing import typevar, Generic, builtinclass

t = typevar('t')

@builtinclass
class object:
    def __init__(self) -> None: pass

class type: pass
class str: pass

# Primitive types are special in generated code.

class int:
    def __add__(self, n: int) -> int: pass
    def __sub__(self, n: int) -> int: pass
    def __mul__(self, n: int) -> int: pass
    def __neg__(self) -> int: pass
    def __eq__(self, n: int) -> bool: pass
    def __ne__(self, n: int) -> bool: pass
    def __lt__(self, n: int) -> bool: pass
    def __gt__(self, n: int) -> bool: pass
    def __le__(self, n: int) -> bool: pass
    def __ge__(self, n: int) -> bool: pass

class float: pass
class bool: pass

class list(Generic[t]): pass

def print(*object) -> None: pass

########NEW FILE########
__FILENAME__ = isinstance
from typing import builtinclass

@builtinclass
class object:
    def __init__(self) -> None: pass

@builtinclass
class type:
    def __init__(self, x) -> None: pass

def isinstance(x: object, t: type) -> bool: pass

@builtinclass
class int: pass
@builtinclass
class bool(int): pass
@builtinclass
class str: pass

########NEW FILE########
__FILENAME__ = list
# Builtins stub used in list-related test cases.

from typing import typevar, Generic, builtinclass, Iterable, Iterator

T = typevar('T')

@builtinclass
class object:
    def __init__(self): pass

class type: pass

class list(Iterable[T], Generic[T]):
    def __iter__(self) -> Iterator[T]: pass
    def __mul__(self, x: int) -> list[T]: pass

class tuple: pass

class int: pass
class str: pass

########NEW FILE########
__FILENAME__ = module
class object:
    def __init__(self) -> None: pass
class module: pass
class type: pass

########NEW FILE########
__FILENAME__ = ops
from typing import Undefined, builtinclass

# This is an extension of transform builtins with additional operations.

@builtinclass
class object:
    def __init__(self) -> None: pass
    def __eq__(self, o: 'object') -> 'bool': pass
    def __ne__(self, o: 'object') -> 'bool': pass

class type: pass

class bool: pass

class str:
    def __init__(self, x: 'int') -> None: pass
    def __add__(self, x: 'str') -> 'str': pass

class int:
    def __add__(self, x: 'int') -> 'int': pass
    def __sub__(self, x: 'int') -> 'int': pass
    def __mul__(self, x: 'int') -> 'int': pass
    def __mod__(self, x: 'int') -> 'int': pass
    def __floordiv__(self, x: 'int') -> 'int': pass
    def __neg__(self) -> 'int': pass
    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    def __lt__(self, x: 'int') -> bool: pass
    def __le__(self, x: 'int') -> bool: pass
    def __gt__(self, x: 'int') -> bool: pass
    def __ge__(self, x: 'int') -> bool: pass

class float: pass

class BaseException: pass

True = Undefined(bool)
False = Undefined(bool)

def __print(a1=None, a2=None, a3=None, a4=None): pass

########NEW FILE########
__FILENAME__ = primitives
# builtins stub with non-generic primitive types

class object:
    def __init__(self) -> None: pass

class int: pass
class str: pass
class float: pass
class bool: pass
class bytes: pass

########NEW FILE########
__FILENAME__ = property
import typing

class object:
    def __init__(self) -> None: pass

class type:
    def __init__(self, x) -> None: pass

property = object() # Dummy definition.

class int: pass
class str: pass
class bytes: pass

########NEW FILE########
__FILENAME__ = python2
class object:
    def __init__(self) -> None: pass

class type:
    def __init__(self, x) -> None: pass

class int: pass
class str: pass
class unicode: pass

# Definition of None is implicit

########NEW FILE########
__FILENAME__ = set
# Builtins stub used in set-related test cases.

from typing import typevar, Generic

T = typevar('T')

class object:
    def __init__(self) -> None: pass

class type: pass

class int: pass
class str: pass

class set(Generic[T]): pass

########NEW FILE########
__FILENAME__ = slice
# Builtins stub used in slicing test cases.

class object:
    def __init__(self): pass

class type: pass

class int: pass

class slice: pass

########NEW FILE########
__FILENAME__ = staticmethod
import typing

class object:
    def __init__(self) -> None: pass

class type:
    def __init__(self, x) -> None: pass

staticmethod = object() # Dummy definition.

class int:
    @staticmethod
    def from_bytes(bytes: bytes, byteorder: str) -> int: pass

class str: pass
class bytes: pass

########NEW FILE########
__FILENAME__ = transform
# Builtins stubs used implicitly in program transformation test cases.

class object:
    def __init__(self) -> None: pass

class type: pass

# str is handy for debugging; allows outputting messages.
class str: pass

# Primitive types int/float have special coercion behaviour (they may have
# a different representation from ordinary values).

class int: pass

class float: pass


# The functions below are special functions used in test cases; their
# implementations are actually in the __dynchk module, but they are defined
# here so that the semantic analyser and the type checker are happy without
# having to analyse the entire __dynchk module all the time.
#
# The transformation implementation has special case handling for these
# functions; it's a bit ugly but it works for now.

def __print(a1=None, a2=None, a3=None, a4=None):
    # Do not use *args since this would require list and break many test
    # cases.
    pass

########NEW FILE########
__FILENAME__ = tuple
# Builtins stub used in tuple-related test cases.

from typing import Iterable

class object:
    def __init__(self): pass

class type: pass

# Current tuple types get special treatment in the type checker, thus there
# is no need for type arguments here.
class tuple: pass

# We need int for indexing tuples.
class int: pass
class str: pass # For convenience

########NEW FILE########
__FILENAME__ = abc
class ABCMeta: pass
abstractmethod = object()

########NEW FILE########
__FILENAME__ = builtins
from typing import builtinclass

@builtinclass
class object:
    def __init__(self) -> None: pass

@builtinclass
class type:
    def __init__(self, x) -> None: pass

# These are provided here for convenience.
@builtinclass
class int: pass
@builtinclass
class str: pass

# Definition of None is implicit


########NEW FILE########
__FILENAME__ = typing
# Stub for typing module. Many of the definitions have special handling in
# the type checker, so they can just be initialized to anything.

from abc import abstractmethod

cast = object()
overload = object()
Undefined = object()
Any = object()
typevar = object()
Generic = object()
AbstractGeneric = object()
Tuple = object()
Function = object()
builtinclass = object()
ducktype = object()
disjointclass = object()

# Type aliases.
List = object()
Dict = object()
Set = object()

T = typevar('T')

class Iterable(AbstractGeneric[T]):
    @abstractmethod
    def __iter__(self) -> 'Iterator[T]': pass

class Iterator(Iterable[T], AbstractGeneric[T]):
    @abstractmethod
    def __next__(self) -> T: pass

########NEW FILE########
__FILENAME__ = data
"""Utilities for processing .test files containing test case descriptions."""

import os.path
import os
import re
from os import remove, rmdir

from typing import Function, List, Tuple, Undefined

from mypy.myunit import TestCase, SkipTestCaseException


def parse_test_cases(
            path: str,
            perform: Function[['DataDrivenTestCase'], None],
            base_path: str = '.',
            optional_out: bool = False,
            include_path: str = None) -> List['DataDrivenTestCase']:
    """Parse a file with test case descriptions.

    Return an array of test cases.
    """
    
    if not include_path:
        include_path = os.path.dirname(path)
    l = open(path).readlines()
    for i in range(len(l)):
        l[i] = l[i].rstrip('\n')
    p = parse_test_data(l, path)
    out = [] # type: List[DataDrivenTestCase]
    
    # Process the parsed items. Each item has a header of form [id args],
    # optionally followed by lines of text.
    i = 0
    while i < len(p):
        ok = False
        i0 = i
        if p[i].id == 'case':
            i += 1
            
            files = [] # type: List[Tuple[str, str]] # path and contents
            while i < len(p) and p[i].id not in ['out', 'case']:
                if p[i].id == 'file':
                    # Record an extra file needed for the test case.
                    files.append((os.path.join(base_path, p[i].arg),
                                  '\n'.join(p[i].data)))
                elif p[i].id == 'builtins':
                    # Use a custom source file for the std module.
                    mpath = os.path.join(os.path.dirname(path), p[i].arg)
                    f = open(mpath)
                    files.append((os.path.join(base_path, 'builtins.py'),
                                  f.read()))
                    f.close()
                else:
                    raise ValueError(
                        'Invalid section header {} in {} at line {}'.format(
                            p[i].id, path, p[i].line))
                i += 1
            
            tcout = [] # type: List[str]
            if i < len(p) and p[i].id == 'out':
                tcout = p[i].data
                ok = True
                i += 1
            elif optional_out:
                ok = True
            
            if ok:
                input = expand_includes(p[i0].data, include_path)
                expand_errors(input, tcout, 'main')
                tc = DataDrivenTestCase(p[i0].arg, input, tcout, path,
                                        p[i0].line, perform, files)
                out.append(tc)
        if not ok:
            raise ValueError(
                '{}, line {}: Error in test case description'.format(
                    path, p[i0].line))
    
    return out


class DataDrivenTestCase(TestCase):
    input = Undefined(List[str])
    output = Undefined(List[str])
    
    file = ''
    line = 0
    
    perform = Undefined(Function[['DataDrivenTestCase'], None])

    # (file path, file content) tuples 
    files = Undefined(List[Tuple[str, str]] )
    
    clean_up = Undefined(List[Tuple[bool, str]])
    
    def __init__(self, name, input, output, file, line, perform, files):
        super().__init__(name)
        self.input = input
        self.output = output
        self.file = file
        self.line = line
        self.perform = perform
        self.files = files
    
    def set_up(self) -> None:
        super().set_up()
        self.clean_up = []
        for path, content in self.files:
            dir = os.path.dirname(path)
            for d in self.add_dirs(dir):
                self.clean_up.append((True, d))
            f = open(path, 'w')
            f.write(content)
            f.close()
            self.clean_up.append((False, path))
    
    def add_dirs(self, dir: str) -> List[str]:
        """Add all subdirectories required to create dir.

        Return an array of the created directories in the order of creation.
        """
        if dir == '' or os.path.isdir(dir):
            return []
        else:
            dirs = self.add_dirs(os.path.dirname(dir)) + [dir]
            os.mkdir(dir)
            return dirs
    
    def run(self):
        if self.name.endswith('-skip'):
            raise SkipTestCaseException()
        else:
            self.perform(self)
    
    def tear_down(self) -> None:
        for is_dir, path in reversed(self.clean_up):
            if is_dir:
                rmdir(path)
            else:
                remove(path)
        super().tear_down()


class TestItem:
    """Parsed test caseitem.

    An item is of the form
      [id arg]
      .. data ..
    """
    
    id = ''
    arg = ''
    
    # Text data, array of 8-bit strings    
    data = Undefined(List[str])
    
    file = ''
    line = 0 # Line number in file
    
    def __init__(self, id: str, arg: str, data: List[str], file: str,
                 line: int) -> None:
        self.id = id
        self.arg = arg
        self.data = data
        self.file = file
        self.line = line


def parse_test_data(l: List[str], fnam: str) -> List[TestItem]:
    """Parse a list of lines that represent a sequence of test items."""
    
    ret = [] # type: List[TestItem]
    data = [] # type: List[str]
    
    id = None # type: str
    arg = None # type: str
    
    i = 0
    i0 = 0
    while i < len(l):
        s = l[i].strip()
        
        if l[i].startswith('[') and s.endswith(']') and not s.startswith('[['):
            if id:
                data = collapse_line_continuation(data)
                data = strip_list(data)
                ret.append(TestItem(id, arg, strip_list(data), fnam, i0 + 1))
            i0 = i
            id = s[1:-1]
            arg = None
            if ' ' in id:
                arg = id[id.index(' ') + 1:]
                id = id[:id.index(' ')]
            data = []
        elif l[i].startswith('[['):
            data.append(l[i][1:])
        elif not l[i].startswith('--'):
            data.append(l[i])
        elif l[i].startswith('----'):
            data.append(l[i][2:])
        i += 1
    
    # Process the last item.
    if id:
        data = collapse_line_continuation(data)
        data = strip_list(data)
        ret.append(TestItem(id, arg, data, fnam, i + 1))
    
    return ret


def strip_list(l: List[str]) -> List[str]:
    """Return a stripped copy of l.

    Strip whitespace at the end of all lines, and strip all empty
    lines from the end of the array.
    """
    
    r = [] # type: List[str]
    for s in l:
        # Strip spaces at end of line
        r.append(re.sub(r'\s+$', '', s))
    
    while len(r) > 0 and r[-1] == '':
        r.pop()
    
    return r


def collapse_line_continuation(l: List[str]) -> List[str]:
    r = [] # type: List[str]
    cont = False
    for s in l:
        ss = re.sub(r'\\$', '', s)
        if cont:
            r[-1] += re.sub('^ +', '', ss)
        else:
            r.append(ss)
        cont = s.endswith('\\')
    return r


def expand_includes(a: List[str], base_path: str) -> List[str]:
    """Expand @includes within a list of lines.

    Replace all lies starting with @include with the contents of the
    file name following the prefix. Look for the files in base_path.
    """
    
    res = [] # type: List[str]
    for s in a:
        if s.startswith('@include '):
            fn = s.split(' ', 1)[1].strip()
            f = open(os.path.join(base_path, fn))
            res.extend(f.readlines())
            f.close()
        else:
            res.append(s)
    return res


def expand_errors(input, output, fnam):
    """Transform comments such as '# E: message' in input.

    The result is lines like 'fnam, line N: message'.
    """
    
    for i in range(len(input)):
        m = re.search('# E: (.*)$', input[i])
        if m:
            output.append('{}, line {}: {}'.format(fnam, i + 1, m.group(1)))

########NEW FILE########
__FILENAME__ = helpers
import sys
import re
import os

from typing import List

from mypy.myunit import AssertionFailure
from mypy.test import config


# AssertStringArraysEqual displays special line alignment helper messages if
# the first different line has at least this many characters,
MIN_LINE_LENGTH_FOR_ALIGNMENT = 5


def assert_string_arrays_equal(expected: List[str], actual: List[str],
                               msg: str) -> None:
    """Assert that two string arrays are equal.

    Display any differences in a human-readable form.
    """
    
    actual = clean_up(actual)
    
    if actual != expected:
        num_skip_start = num_skipped_prefix_lines(expected, actual)
        num_skip_end = num_skipped_suffix_lines(expected, actual)
        
        sys.stderr.write('Expected:\n')
        
        # If omit some lines at the beginning, indicate it by displaying a line
        # with '...'.
        if num_skip_start > 0:
            sys.stderr.write('  ...\n')
        
        # Keep track of the first different line.
        first_diff = -1
        
        # Display only this many first characers of identical lines.
        width = 75
        
        for i in range(num_skip_start, len(expected) - num_skip_end):
            if i >= len(actual) or expected[i] != actual[i]:
                if first_diff < 0:
                    first_diff = i
                sys.stderr.write('  {:<45} (diff)'.format(expected[i]))
            else:
                e = expected[i]
                sys.stderr.write('  ' + e[:width])
                if len(e) > width:
                    sys.stderr.write('...')
            sys.stderr.write('\n')
        if num_skip_end > 0:
            sys.stderr.write('  ...\n')
        
        sys.stderr.write('Actual:\n')
        
        if num_skip_start > 0:
            sys.stderr.write('  ...\n')
        
        for j in range(num_skip_start, len(actual) - num_skip_end):
            if j >= len(expected) or expected[j] != actual[j]:
                sys.stderr.write('  {:<45} (diff)'.format(actual[j]))
            else:
                a = actual[j]
                sys.stderr.write('  ' + a[:width])
                if len(a) > width:
                    sys.stderr.write('...')
            sys.stderr.write('\n')
        if actual == []:
            sys.stderr.write('  (empty)\n')
        if num_skip_end > 0:
            sys.stderr.write('  ...\n')
        
        sys.stderr.write('\n')
        
        if first_diff >= 0 and first_diff < len(actual) and (
                len(expected[first_diff]) >= MIN_LINE_LENGTH_FOR_ALIGNMENT
                or len(actual[first_diff]) >= MIN_LINE_LENGTH_FOR_ALIGNMENT):
            # Display message that helps visualize the differences between two
            # long lines.
            show_align_message(expected[first_diff], actual[first_diff])
        
        raise AssertionFailure(msg)


def show_align_message(s1: str, s2: str) -> None:
    """Align s1 and s2 so that the their first difference is highlighted.

    For example, if s1 is 'foobar' and s2 is 'fobar', display the
    following lines:
    
      E: foobar
      A: fobar
           ^
    
    If s1 and s2 are long, only display a fragment of the strings around the
    first difference. If s1 is very short, do nothing.
    """
    
    # Seeing what went wrong is trivial even without alignment if the expected
    # string is very short. In this case do nothing to simplify output.
    if len(s1) < 4:
        return 
    
    maxw = 72 # Maximum number of characters shown
    
    sys.stderr.write('Alignment of first line difference:\n')
    
    trunc = False
    while s1[:30] == s2[:30]:
        s1 = s1[10:]
        s2 = s2[10:]
        trunc = True
    
    if trunc:
        s1 = '...' + s1
        s2 = '...' + s2
    
    max_len = max(len(s1), len(s2))
    extra = ''
    if max_len > maxw:
        extra = '...'
    
    # Write a chunk of both lines, aligned.
    sys.stderr.write('  E: {}{}\n'.format(s1[:maxw], extra))
    sys.stderr.write('  A: {}{}\n'.format(s2[:maxw], extra))
    # Write an indicator character under the different columns.
    sys.stderr.write('     ')
    for j in range(min(maxw, max(len(s1), len(s2)))):
        if s1[j:j + 1] != s2[j:j + 1]:
            sys.stderr.write('^') # Difference
            break
        else:
            sys.stderr.write(' ') # Equal
    sys.stderr.write('\n')


def assert_string_arrays_equal_wildcards(expected: List[str],
                                         actual: List[str],
                                         msg: str) -> None:
    # Like above, but let a line with only '...' in expected match any number
    # of lines in actual.
    actual = clean_up(actual)
    
    while actual != [] and actual[-1] == '':
        actual = actual[:-1]
    
    # Expand "..." wildcards away.
    expected = match_array(expected, actual)
    assert_string_arrays_equal(expected, actual, msg)


def clean_up(a):
    """Remove common directory prefix from all strings in a.

    This uses a naive string replace; it seems to work well enough. Also
    remove trailing carriage returns.
    """
    res = []
    for s in a:
        prefix = config.PREFIX + os.sep
        ss = s
        for p in prefix, prefix.replace(os.sep, '/'):
            if p != '/' and p != '//' and p != '\\' and p != '\\\\':
                ss = ss.replace(p, '')
        # Ignore spaces at end of line.
        ss = re.sub(' +$', '', ss)
        res.append(re.sub('\\r$', '', ss))
    return res


def match_array(pattern: List[str], target: List[str]) -> List[str]:
    """Expand '...' wildcards in pattern by matching against target."""
    
    res = [] # type: List[str]
    i = 0
    j = 0
    
    while i < len(pattern):
        if pattern[i] == '...':
            # Wildcard in pattern.
            if i + 1 == len(pattern):
                # Wildcard at end of pattern; match the rest of target.
                res.extend(target[j:])
                # Finished.
                break
            else:
                # Must find the instance of the next pattern line in target.
                jj = j
                while jj < len(target):
                    if target[jj] == pattern[i + 1]:
                        break
                    jj += 1
                if jj == len(target):
                    # No match. Get out.
                    res.extend(pattern[i:])
                    break
                res.extend(target[j:jj])
                i += 1
                j = jj
        elif (j < len(target) and (pattern[i] == target[j]
                                   or (i + 1 < len(pattern)
                                       and j + 1 < len(target)
                                       and pattern[i + 1] == target[j + 1]))):
            # In sync; advance one line. The above condition keeps sync also if
            # only a single line is different, but loses it if two consecutive
            # lines fail to match.
            res.append(pattern[i])
            i += 1
            j += 1
        else:
            # Out of sync. Get out.
            res.extend(pattern[i:])
            break
    return res


def num_skipped_prefix_lines(a1: List[str], a2: List[str]) -> int:
    num_eq = 0
    while num_eq < min(len(a1), len(a2)) and a1[num_eq] == a2[num_eq]:
        num_eq += 1
    return max(0, num_eq - 4)


def num_skipped_suffix_lines(a1: List[str], a2: List[str]) -> int:
    num_eq = 0
    while (num_eq < min(len(a1), len(a2))
           and a1[-num_eq - 1] == a2[-num_eq - 1]):
        num_eq += 1
    return max(0, num_eq - 4)


def testfile_pyversion(path: str) -> int:
    if path.endswith('python2.test'):
        return 2
    else:
        return 3

########NEW FILE########
__FILENAME__ = testcgen
"""Test cases for compiling mypy programs to C and running them.

The compilation to C uses the full C builtins (lib/builtins.py).
    
Note: These test cases are not included in the main test suite yet.
"""

import os.path
import re
import subprocess
import sys

from mypy import build
from mypy import errors
from mypy.myunit import Suite, run_test
from mypy.test.config import test_data_prefix, test_temp_dir
from mypy.test.data import parse_test_cases
from mypy.test.helpers import assert_string_arrays_equal
from mypy.test.helpers import assert_string_arrays_equal_wildcards
import typing


class CGenCompileSuite(Suite):
    """Test cases that compile to C and perform checks on the C code."""

    files = ['cgen-codeoutput.test']

    def cases(self):
        c = []
        for f in self.files:
            c += parse_test_cases(os.path.join(test_data_prefix, f),
                                  test_cgen_compile, test_temp_dir, True)
        return c


def test_cgen_compile(testcase):
    # Build the program.
    text = '\n'.join(testcase.input)
    try:
        build.build('_program.py',
                    target=build.C,
                    program_text=text, 
                    alt_lib_path='lib',
                    flags=[build.COMPILE_ONLY, build.TEST_BUILTINS])
        outfile = '_program.c'
        f = open(outfile)
        out = [s.rstrip('\n\r') for s in f.readlines()]
        f.close()
        os.remove(outfile)
    except errors.CompileError as e:
        out = e.messages
    # Verify output.
    assert_string_arrays_equal_wildcards(testcase.output, out,
                               'Invalid output ({}, line {})'.format(
                                   testcase.file, testcase.line))


class CGenRunSuite(Suite):
    """Test cases that compile a program to C and run it.

    The output (stdout) of the program is compared to expected output.
    """

    # Test case descriptions
    files = ['cgen-basic.test',
             'cgen-intops.test',
             'cgen-classes.test']

    def cases(self):
        c = []
        for f in self.files:
            c += parse_test_cases(os.path.join(test_data_prefix, f),
                                  test_cgen, test_temp_dir, True)
        return c


def test_cgen(testcase):
    # Build the program.
    text = '\n'.join(testcase.input)
    program = '_program.py'
    try:
        build.build(program,
                    target=build.C,
                    program_text=text,
                    flags=[build.TEST_BUILTINS],
                    alt_lib_path='lib')
        # Run the program.
        outfile = './_program'
        outb = subprocess.check_output([outfile], stderr=subprocess.STDOUT)
        # Split output into lines.
        out = [s.rstrip('\n\r') for s in str(outb, 'utf8').splitlines()]
        # Remove temp file.
        os.remove(outfile)
    except errors.CompileError as e:
        out = e.messages
    # Include line-end comments in the expected output.
    # Note: # characters in string literals can confuse this.
    for s in testcase.input:
        m = re.search(' #(?! type:)(.*)', s)
        if m:
            testcase.output.append(m.group(1).strip())
    # Verify output.
    assert_string_arrays_equal(testcase.output, out,
                               'Invalid output ({}, line {})'.format(
                                   testcase.file, testcase.line))


class CGenSuite(Suite):
    def __init__(self):
        self.test_compile = CGenCompileSuite()
        self.test_run = CGenRunSuite()
        super().__init__()


if __name__ == '__main__':
    run_test(CGenSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testcheck
"""Type checker test cases"""

import os.path

import typing

from mypy import build
from mypy.myunit import Suite, run_test
from mypy.test.config import test_temp_dir, test_data_prefix
from mypy.test.data import parse_test_cases
from mypy.test.helpers import assert_string_arrays_equal, testfile_pyversion
from mypy.test.testsemanal import normalize_error_messages
from mypy.errors import CompileError


# List of files that contain test case descriptions.
files = [
    'check-basic.test',
    'check-classes.test',
    'check-expressions.test',
    'check-statements.test',
    'check-generics.test',
    'check-tuples.test',
    'check-dynamic-typing.test',
    'check-functions.test',
    'check-inference.test',
    'check-inference-context.test',
    'check-varargs.test',
    'check-kwargs.test',
    'check-overloading.test',
    'check-type-checks.test',
    'check-abstract.test',
    'check-multiple-inheritance.test',
    'check-super.test',
    'check-modules.test',
    'check-generic-subtyping.test',
    'check-typevar-values.test',
    'check-python2.test',
    'check-unsupported.test',
]


class TypeCheckSuite(Suite):
    def cases(self):
        c = []
        for f in files:
            c += parse_test_cases(os.path.join(test_data_prefix, f),
                                  self.run_test, test_temp_dir, True)
        return c
    
    def run_test(self, testcase):
        a = []
        try:
            src = '\n'.join(testcase.input)
            build.build('main',
                        target=build.TYPE_CHECK,
                        program_text=src,
                        pyversion=testfile_pyversion(testcase.file),
                        flags=[build.TEST_BUILTINS],
                        alt_lib_path=test_temp_dir)
        except CompileError as e:
            a = normalize_error_messages(e.messages)
        assert_string_arrays_equal(
            testcase.output, a,
            'Invalid type checker output ({}, line {})'.format(
                testcase.file, testcase.line))


if __name__ == '__main__':
    import sys
    run_test(TypeCheckSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testdyncheck
"""Test case runner for runtime type checking transform."""

import os
import os.path
import shutil

import typing

from mypy import build
from mypy.myunit import Suite, run_test
from mypy.test.helpers import assert_string_arrays_equal_wildcards
from mypy.test.data import parse_test_cases
from mypy.test.config import test_data_prefix, test_temp_dir
from mypy.test.testoutput import remove_prefix
from mypy.transform import DyncheckTransformVisitor
from mypy.pprinter import PrettyPrintVisitor
from mypy.errors import CompileError


# The builtins stub used during transformation in test cases.
TRANSFORM_BUILTINS = 'fixtures/transform.py'


class DyncheckTransformSuite(Suite):
    test_case_files = ['dyncheck-trans-basic.test',
                       'dyncheck-trans-generics.test',
                       'dyncheck-trans-generic-inheritance.test']
    
    def cases(self):
        c = []
        for f in self.test_case_files:
            c += parse_test_cases(
                os.path.join(test_data_prefix, f),
                builtins_wrapper(test_transform,
                                 os.path.join(test_data_prefix,
                                              TRANSFORM_BUILTINS)),
                test_temp_dir, True)
        return c


def test_transform(testcase):
    """Perform a runtime checking transformation test case."""
    expected = remove_comment_lines(testcase.output)
    try:
        # Construct input as a single single.
        src = '\n'.join(testcase.input)
        # Parse and type check the input program. Perform transform manually
        # so that we can skip some files.
        result = build.build(program_path='main',
                             target=build.TRANSFORM,
                             program_text=src,
                             flags=[build.TEST_BUILTINS],
                             alt_lib_path=test_temp_dir)
        a = []
        first = True
        # Transform each file separately.
        for fnam in sorted(result.files.keys()):
            f = result.files[fnam]
            # Skip the builtins module and files with '_skip.' in the path.
            if (not f.path.endswith('/builtins.py') and
                not f.path.endswith('/typing.py') and
                not f.path.endswith('/abc.py') and '_skip.' not in f.path):
                if not first:
                    # Display path for files other than the first.
                    a.append('{}:'.format(remove_prefix(f.path,
                                                        test_temp_dir)))
                
                # Pretty print the transformed tree.
                v2 = PrettyPrintVisitor()
                f.accept(v2)
                s = v2.output()
                if s != '':
                    a += s.split('\n')
            first = False
    except CompileError as e:
        a = e.messages
    assert_string_arrays_equal_wildcards(
        expected, a,
        'Invalid source code output ({}, line {})'.format(testcase.file,
                                                          testcase.line))


def remove_comment_lines(a):
    """Return a copy of array with comments removed.

    Lines starting with '--' (but not with '---') are removed.
    """
    r = []
    for s in a:
        if s.strip().startswith('--') and not s.strip().startswith('---'):
            pass
        else:
            r.append(s)
    return r


def builtins_wrapper(func, path):
    """Decorate a function that implements a data-driven test case to copy an
    alternative builtins module implementation in place before performing the
    test case. Clean up after executing the test case.
    """
    return lambda testcase: perform_test(func, path, testcase)


def perform_test(func, path, testcase):
    for path, _ in testcase.files:
        if os.path.basename(path) == 'builtins.py':
            default_builtins = False
            break
    else:
        # Use default builtins.
        builtins = os.path.join(test_temp_dir, 'builtins.py')
        shutil.copyfile(path, builtins)
        default_builtins = True

    # Actually peform the test case.
    func(testcase)
    
    if default_builtins:
        # Clean up.
        os.remove(builtins)


if __name__ == '__main__':
    import sys
    run_test(DyncheckTransformSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testicodegen
"""Test cases for icode generation."""

import os.path
import re

import typing

from mypy import build
from mypy import icode
from mypy.myunit import Suite, run_test
from mypy.test.helpers import assert_string_arrays_equal_wildcards
from mypy.test.data import parse_test_cases
from mypy.test.config import test_data_prefix, test_temp_dir
from mypy.test.testoutput import remove_prefix
from mypy.test.testdyncheck import builtins_wrapper, remove_comment_lines
from mypy.transform import DyncheckTransformVisitor
from mypy.errors import CompileError


# The builtins stub used during icode generation test cases.
ICODE_GEN_BUILTINS = 'fixtures/icodegen.py'


class IcodeGenerationSuite(Suite):
    test_case_files = ['icode-basic.test',
                       'icode-classes.test']
    
    def cases(self):
        c = []
        for f in self.test_case_files:
            c += parse_test_cases(
                os.path.join(test_data_prefix, f),
                builtins_wrapper(test_transform,
                                 os.path.join(test_data_prefix,
                                              ICODE_GEN_BUILTINS)),
                test_temp_dir, True)
        return c


def test_transform(testcase):
    """Perform a runtime checking transformation test case."""
    
    expected = remove_comment_lines(testcase.output)

    func_names = get_func_names(expected)

    try:
        # Construct input as a single single.
        src = '\n'.join(testcase.input)
        # Parse and type check the input program.
        result = build.build(program_path='main',
                             target=build.ICODE,
                             program_text=src,
                             flags=[build.TEST_BUILTINS],
                             alt_lib_path=test_temp_dir)
        a = []
        for fn in func_names:
            a.append('def {}:'.format(fn))
            try:
                funccode = result.icode[fn]
            except KeyError:
                raise RuntimeError('no icode for %s (%s)' % (
                    fn, list(result.icode.keys())))
            code = icode.render(funccode)
            a.extend(code)
    except CompileError as e:
        a = e.messages
    assert_string_arrays_equal_wildcards(
        expected, a,
        'Invalid source code output ({}, line {})'.format(testcase.file,
                                                          testcase.line))


def get_func_names(expected):
    res = []
    for s in expected:
        m = re.match(r'def ([_a-zA-Z0-9.*$]+):', s)
        if m:
            res.append(m.group(1))
    if not res:
        raise RuntimeError('No function name in test case output')
    return res


if __name__ == '__main__':
    import sys
    run_test(IcodeGenerationSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testinfer
"""Test cases for type inference helper functions."""

import typing

from mypy.myunit import Suite, assert_equal, assert_true, run_test
from mypy.checkexpr import map_actuals_to_formals
from mypy.nodes import ARG_POS, ARG_OPT, ARG_STAR, ARG_STAR2, ARG_NAMED
from mypy.types import AnyType, TupleType


class MapActualsToFormalsSuite(Suite):
    """Test cases for checkexpr.map_actuals_to_formals."""
    
    def test_basic(self):
        self.assert_map([], [], [])

    def test_positional_only(self):
        self.assert_map([ARG_POS],
                        [ARG_POS],
                        [[0]])
        self.assert_map([ARG_POS, ARG_POS],
                        [ARG_POS, ARG_POS],
                        [[0], [1]])

    def test_optional(self):
        self.assert_map([],
                        [ARG_OPT],
                        [[]])
        self.assert_map([ARG_POS],
                        [ARG_OPT],
                        [[0]])
        self.assert_map([ARG_POS],
                        [ARG_OPT, ARG_OPT],
                        [[0], []])

    def test_callee_star(self):
        self.assert_map([],
                        [ARG_STAR],
                        [[]])
        self.assert_map([ARG_POS],
                        [ARG_STAR],
                        [[0]])
        self.assert_map([ARG_POS, ARG_POS],
                        [ARG_STAR],
                        [[0, 1]])

    def test_caller_star(self):
        self.assert_map([ARG_STAR],
                        [ARG_STAR],
                        [[0]])
        self.assert_map([ARG_POS, ARG_STAR],
                        [ARG_STAR],
                        [[0, 1]])
        self.assert_map([ARG_STAR],
                        [ARG_POS, ARG_STAR],
                        [[0], [0]])
        self.assert_map([ARG_STAR],
                        [ARG_OPT, ARG_STAR],
                        [[0], [0]])

    def test_too_many_caller_args(self):
        self.assert_map([ARG_POS],
                        [],
                        [])
        self.assert_map([ARG_STAR],
                        [],
                        [])
        self.assert_map([ARG_STAR],
                        [ARG_POS],
                        [[0]])

    def test_tuple_star(self):
        self.assert_vararg_map(
            [ARG_STAR],
            [ARG_POS],
            [[0]],
            TupleType([AnyType()]))
        self.assert_vararg_map(
            [ARG_STAR],
            [ARG_POS, ARG_POS],
            [[0], [0]],
            TupleType([AnyType(), AnyType()]))
        self.assert_vararg_map(
            [ARG_STAR],
            [ARG_POS, ARG_OPT, ARG_OPT],
            [[0], [0], []],
            TupleType([AnyType(), AnyType()]))

    def test_named_args(self):
        self.assert_map(
            ['x'],
            [(ARG_POS, 'x')],
            [[0]])
        self.assert_map(
            ['y', 'x'],
            [(ARG_POS, 'x'), (ARG_POS, 'y')],
            [[1], [0]])

    def test_some_named_args(self):
        self.assert_map(
            ['y'],
            [(ARG_OPT, 'x'), (ARG_OPT, 'y'), (ARG_OPT, 'z')],
            [[], [0], []])

    def test_missing_named_arg(self):
        self.assert_map(
            ['y'],
            [(ARG_OPT, 'x')],
            [[]])

    def test_duplicate_named_arg(self):
        self.assert_map(
            ['x', 'x'],
            [(ARG_OPT, 'x')],
            [[0, 1]])

    def test_varargs_and_bare_asterisk(self):
        self.assert_map(
            [ARG_STAR],
            [ARG_STAR, (ARG_NAMED, 'x')],
            [[0], []])
        self.assert_map(
            [ARG_STAR, 'x'],
            [ARG_STAR, (ARG_NAMED, 'x')],
            [[0], [1]])

    def test_keyword_varargs(self):
        self.assert_map(
            ['x'],
            [ARG_STAR2],
            [[0]])
        self.assert_map(
            ['x', ARG_STAR2],
            [ARG_STAR2],
            [[0, 1]])
        self.assert_map(
            ['x', ARG_STAR2],
            [(ARG_POS, 'x'), ARG_STAR2],
            [[0], [1]])
        self.assert_map(
            [ARG_POS, ARG_STAR2],
            [(ARG_POS, 'x'), ARG_STAR2],
            [[0], [1]])

    def test_both_kinds_of_varargs(self):
        self.assert_map(
            [ARG_STAR, ARG_STAR2],
            [(ARG_POS, 'x'), (ARG_POS, 'y')],
            [[0, 1], [0, 1]])

    def test_special_cases(self):
        self.assert_map([ARG_STAR],
                        [ARG_STAR, ARG_STAR2],
                        [[0], []])
        self.assert_map([ARG_STAR, ARG_STAR2],
                        [ARG_STAR, ARG_STAR2],
                        [[0], [1]])

    def assert_map(self, caller_kinds, callee_kinds, expected):
        caller_kinds, caller_names = expand_caller_kinds(caller_kinds)
        callee_kinds, callee_names = expand_callee_kinds(callee_kinds)
        result = map_actuals_to_formals(
            caller_kinds,
            caller_names,
            callee_kinds,
            callee_names,
            lambda i: AnyType())
        assert_equal(result, expected)

    def assert_vararg_map(self, caller_kinds, callee_kinds, expected,
                           vararg_type):
        result = map_actuals_to_formals(
            caller_kinds,
            [],
            callee_kinds,
            [],
            lambda i: vararg_type)
        assert_equal(result, expected)


def expand_caller_kinds(kinds_or_names):
    kinds = []
    names = []
    for k in kinds_or_names:
        if isinstance(k, str):
            kinds.append(ARG_NAMED)
            names.append(k)
        else:
            kinds.append(k)
            names.append(None)
    return kinds, names


def expand_callee_kinds(kinds_and_names):
    kinds = []
    names = []
    for v in kinds_and_names:
        if isinstance(v, tuple):
            kinds.append(v[0])
            names.append(v[1])
        else:
            kinds.append(v)
            names.append(None)
    return kinds, names


if __name__ == '__main__':
    import sys
    run_test(MapActualsToFormalsSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testlex
"""Lexical analyzer test cases"""

import typing

from mypy.myunit import Suite, assert_equal
from mypy.lex import lex


class LexerSuite(Suite):
    def test_empty(self):
        self.assert_lex('', 'Eof()')
    
    def test_keywords(self):
        self.assert_lex(
            'if else elif def return pass',
            'Keyword(if) Keyword( else) Keyword( elif) Keyword( def) '
            'Keyword( return) Keyword( pass) Break() Eof()')
        
        self.assert_lex(
            'from import as class global',
            'Keyword(from) Keyword( import) Keyword( as) Keyword( class) '
            'Keyword( global) ...')
    
    def test_identifiers(self):
        self.assert_lex(
            'i x FooBar FOO_BAR __x var',
            'Name(i) Name( x) Name( FooBar) Name( FOO_BAR) Name( __x) '
            'Name( var) Break() Eof()')
        
        self.assert_lex(
            'any interface void',
            'Name(any) Name( interface) Name( void) Break() Eof()')
    
    def test_int_literals(self):
        self.assert_lex(
            '0 1 0987654321 10002000300040005000600070008000',
            'IntLit(0) IntLit( 1) IntLit( 0987654321) '
            'IntLit( 10002000300040005000600070008000) Break() Eof()')
    
    def test_hex_int_literals(self):
        self.assert_lex('0x0 0xabcedf0189 0xAFe 0X2',
                        'IntLit(0x0) IntLit( 0xabcedf0189) IntLit( 0xAFe) '
                        'IntLit( 0X2) ...')
    
    def test_oct_int_literals(self):
        self.assert_lex('0o0 0o127 0O1',
                        'IntLit(0o0) IntLit( 0o127) IntLit( 0O1) ...')
    
    def test_float_literals(self):
        self.assert_lex('1.2 .1 1.',
                        'FloatLit(1.2) FloatLit( .1) FloatLit( 1.) ...')
        
        self.assert_lex(
            '1e2 1.2e+3 1.3e-12',
            'FloatLit(1e2) FloatLit( 1.2e+3) FloatLit( 1.3e-12) ...')
        
        self.assert_lex('1.e2', 'FloatLit(1.e2) ...')
    
    def test_comments(self):
        self.assert_lex('# foo "" bar' + '\n' + 'x #x',
                        'Name(# foo "" bar\\nx) Break( #x) Eof()')
    
    def test_empty_lines(self):
        self.assert_lex(r'\n1', r'IntLit(\n1) ...')
        self.assert_lex(r'\n\n1', r'IntLit(\n\n1) ...')
        self.assert_lex(r'1\n\n2', r'IntLit(1) Break(\n\n) IntLit(2) ...')
    
    def test_line_breaks(self):
        self.assert_lex('1\\r2', 'IntLit(1) Break(\\r) IntLit(2) ...')
        self.assert_lex('1\\r\\n2', 'IntLit(1) Break(\\r\\n) IntLit(2) ...')
    
    def test_operators(self):
        self.assert_lex('- + < > == != <= >= .',
                        'Op(-) Op( +) Op( <) Op( >) Op( ==) Op( !=) Op( <=) '
                        'Op( >=) Op( .) ...')
        
        self.assert_lex('* / % // **',
                        'Op(*) Op( /) Op( %) Op( //) Op( **) ...')
        
        self.assert_lex('& | ^ ~ << >>',
                        'Op(&) Op( |) Op( ^) Op( ~) Op( <<) Op( >>) ...')
        
        self.assert_lex('in is and or not',
                        'Op(in) Op( is) Op( and) Op( or) Op( not) ...')
    
    def test_punctuators(self):
        self.assert_lex(': = ,', 'Colon(:) Punct( =) Punct( ,) ...')
        
        self.assert_lex(
            '+= -= *= %= //=',
            'Punct(+=) Punct( -=) Punct( *=) Punct( %=) Punct( //=) ...')
        self.assert_lex('**=', 'Punct(**=) ...')
        self.assert_lex(
            '&= |= ^= <<= >>=',
            'Punct(&=) Punct( |=) Punct( ^=) Punct( <<=) Punct( >>=) ...')
    
    def test_basic_indentation(self):
        self.assert_lex(
            'y' + '\n' + '  x',
            'Name(y) Break(\\n) Indent(  ) Name(x) Break() Dedent() Eof()')
        
        self.assert_lex(
            'y' + '\n' + '  x' + '\n' + 'z',
            'Name(y) Break(\\n) Indent(  ) Name(x) Break(\\n) Dedent() '
            'Name(z) Break() Eof()')
    
    def test_multiple_indent_levels(self):
        self.assert_lex('y' + '\n' +
                        '  x' + '\n' +
                        '  y' + '\n' +
                        '    z',
                        'Name(y) Break(\\n) ' +
                        'Indent(  ) Name(x) Break(\\n) ' +
                        'Name(  y) Break(\\n) ' +
                        'Indent(    ) Name(z) Break() ' +
                        'Dedent() Dedent() Eof()')
        
        self.assert_lex('y' + '\n' +
                        '  x' + '\n' +
                        '    z' + '\n' +
                        '  y',
                        'Name(y) Break(\\n) ' +
                        'Indent(  ) Name(x) Break(\\n) ' +
                        'Indent(    ) Name(z) Break(\\n) ' +
                        'Dedent() Name(  y) Break() ' +
                        'Dedent() Eof()')
    
    def test_tab_indent(self):
        self.assert_lex('y' + '\n' +
                        '\t' + 'x' + '\n' +
                        '        y' + '\n' +
                        ' ' + '\t' + 'z',
                        'Name(y) Break(\\n) ' +
                        'Indent(\\t) Name(x) Break(\\n) ' +
                        'Name(        y) Break(\\n) ' +
                        'Name( \\tz) Break() ' +
                        'Dedent() Eof()')
    
    def test_comment_after_dedent(self):
        self.assert_lex('y\n'
                        '  x\n'
                        '# Foo\n'
                        'z',
                        r'Name(y) Break(\n) Indent(  ) Name(x) '
                        r'Break(\n# Foo\n) '
                        r'Dedent() Name(z) Break() Eof()')
    
    def test_parens(self):
        self.assert_lex('( x )', 'Punct(() Name( x) Punct( )) Break() Eof()')
        self.assert_lex(
            '( x' + '\n' + '  y )',
            'Punct(() Name( x) Name(\\n  y) Punct( )) Break() Eof()')
        
        self.assert_lex('()' + '\n' + ' y',
                        'Punct(() Punct()) Break(\\n) Indent( ) Name(y) '
                        'Break() Dedent() Eof()')
        
        # [ ... ] and { ... }.
        self.assert_lex(
            '[ x' + '\n' + '  y ]',
            'Punct([) Name( x) Name(\\n  y) Punct( ]) Break() Eof()')
        self.assert_lex(
            '{ x' + '\n' + '  y }',
            'Punct({) Name( x) Name(\\n  y) Punct( }) Break() Eof()')
        
        # Nested brackets.
        self.assert_lex(
            '({}' + '\n' + ' y)',
            'Punct(() Punct({) Punct(}) Name(\\n y) Punct()) Break() Eof()')
    
    def test_brackets_and_line_breaks(self):
        # This used to fail.
        self.assert_lex('{}' + '\n' + '1',
                        'Punct({) Punct(}) Break(\\n) IntLit(1) Break() Eof()')
    
    def test_str_literals(self):
        self.assert_lex("'' 'foo_bar'",
                        "StrLit('') StrLit( 'foo_bar') Break() Eof()")
        self.assert_lex('"" "foo_bar"',
                        'StrLit("") StrLit( "foo_bar") Break() Eof()')
        
        self.assert_lex('"\\"" 1', 'StrLit("\\"") IntLit( 1) Break() Eof()')
        self.assert_lex("'\\'' 1", "StrLit('\\'') IntLit( 1) Break() Eof()")
        
        self.assert_lex('"\\\\" 1', 'StrLit("\\\\") IntLit( 1) Break() Eof()')
        self.assert_lex("'\\\\' 1", "StrLit('\\\\') IntLit( 1) Break() Eof()")
    
    def test_triple_quoted_string_literals(self):
        # Single-line
        
        self.assert_lex("''''''", "StrLit('''''') ...")
        self.assert_lex("1 '''x''y'''1",
                        "IntLit(1) StrLit( '''x''y''') IntLit(1) ...")
        
        self.assert_lex('""""""', 'StrLit("""""") ...')
        self.assert_lex('"""x""y"""', 'StrLit("""x""y""") ...')
        
        # Multiple-line
        
        self.assert_lex("'''" + '\n' + "'''", "StrLit('''\\n''') ...")
        self.assert_lex("'''x''" + '\n' + "''x'''",
                        "StrLit('''x''\\n''x''') ...")
        self.assert_lex("'''''" + '\n' + "'''''",
                        "StrLit('''''\\n''') StrLit('') ...")
        self.assert_lex("'''x" + '\n' + 'xyz' + '\n' + "''x'''",
                        "StrLit('''x\\nxyz\\n''x''') ...")
        
        self.assert_lex('"""x' + '\n' + 'y"""', 'StrLit("""x\\ny""") ...')

    def test_unicode_literals(self):
        self.assert_lex("u'' u'foo'",
                        "UnicodeLit(u'') UnicodeLit( u'foo') ...")
        self.assert_lex('u"" u"foo"',
                        'UnicodeLit(u"") UnicodeLit( u"foo") ...')
        self.assert_lex('ur"" ur"foo"',
                        'UnicodeLit(ur"") UnicodeLit( ur"foo") ...')
        self.assert_lex('u"""foo\n"""',
                        r'UnicodeLit(u"""foo\n""") ...')
    
    def test_semicolons(self):
        self.assert_lex('a;b', 'Name(a) Break(;) Name(b) ...')
        self.assert_lex('a;', 'Name(a) Break(;) Eof()')
        
        self.assert_lex(';a', 'Break(;) Name(a) ...')
        self.assert_lex('a;;b', 'Name(a) Break(;) Break(;) Name(b) ...')
    
    def test_raw_string(self):
        self.assert_lex("r'' r'foo bar'",
                        "StrLit(r'') StrLit( r'foo bar') ...")
        self.assert_lex('r"" r"foo bar"',
                        'StrLit(r"") StrLit( r"foo bar") ...')
        
        self.assert_lex("r'\\x\\''", "StrLit(r'\\x\\'') ...")
        self.assert_lex('r"\\x\\""', 'StrLit(r"\\x\\"") ...')
        
        self.assert_lex("r'\\\\' ''", "StrLit(r'\\\\') StrLit( '') ...")
        self.assert_lex('r"\\\\" ""', 'StrLit(r"\\\\") StrLit( "") ...')
        
        self.assert_lex("r'''" + '\n' + "x'''", "StrLit(r'''\\nx''') ...")
    
    def test_bytes(self):
        self.assert_lex("b'\\'' b'foo bar'",
                        "BytesLit(b'\\'') BytesLit( b'foo bar') ...")
        self.assert_lex('b"\\"" b"foo bar"',
                        'BytesLit(b"\\"") BytesLit( b"foo bar") ...')
        
        self.assert_lex("b'''" + '\n' + " x'''", "BytesLit(b'''\\n x''') ...")
    
    def test_raw_bytes(self):
        self.assert_lex("br'x\\x\\''", "BytesLit(br'x\\x\\'') ...")
        self.assert_lex('br"x\\y\\""', 'BytesLit(br"x\\y\\"") ...')
        
        self.assert_lex('br"""' + '\n' + 'x"""', 'BytesLit(br"""\\nx""") ...')
    
    def test_backslash(self):
        self.assert_lex('a\\' + '\n' + ' b', 'Name(a) Name(\\\\n b) ...')    
        self.assert_lex(
            'a = \\' + '\n' + ' 1' + '\n' + '=',
            'Name(a) Punct( =) IntLit( \\\\n 1) Break(\\n) Punct(=) ...')
    
    def test_backslash_in_string(self):
        self.assert_lex("'foo\\" + '\n' + "bar'", "StrLit('foo\\\\nbar') ...")
        self.assert_lex("'foo\\" + '\n' + ' zar\\' + '\n' + "  bar'",
                        "StrLit('foo\\\\n zar\\\\n  bar') ...")
        
        self.assert_lex('"foo\\' + '\n' + 'bar"', 'StrLit("foo\\\\nbar") ...')
    
    def test_backslash_in_raw_string(self):
        self.assert_lex("r'a\\" + '\n' + "b\\'1",
                        "StrLit(r'a\\\\nb\\') IntLit(1) ...")
        self.assert_lex("r'a\\" + '\n' + '-\\' + '\n' + "b\\'1",
                        "StrLit(r'a\\\\n-\\\\nb\\') IntLit(1) ...")
        self.assert_lex('r"a\\' + '\n' + 'b\\"1',
                        'StrLit(r"a\\\\nb\\") IntLit(1) ...')
        self.assert_lex('r"a\\' + '\n' + '-\\' + '\n' + 'b\\"1',
                        'StrLit(r"a\\\\n-\\\\nb\\") IntLit(1) ...')
    
    def test_final_dedent(self):
        self.assert_lex(
          '1' + '\n' + ' 1' + '\n',
          'IntLit(1) Break(\\n) Indent( ) IntLit(1) Break(\\n) Dedent() Eof()')
    
    def test_empty_line(self):
        self.assert_lex('1' + '\n' + ' 1' + '\n' + '\n',
                        r'IntLit(1) Break(\n) Indent( ) IntLit(1) '
                        r'Break(\n\n) Dedent() Eof()')
    
    def test_comments_and_indents(self):
        self.assert_lex('1' + '\n' + ' #x' + '\n' + ' y',
                        r'IntLit(1) Break(\n #x\n) Indent( ) Name(y) '
                        r'Break() Dedent() Eof()')
        self.assert_lex('1' + '\n' + '#x' + '\n' + ' y',
                        r'IntLit(1) Break(\n#x\n) Indent( ) Name(y) '
                        r'Break() Dedent() Eof()')
    
    def test_form_feed(self):
        self.assert_lex('\x0c' + '\n' + 'x', 'Name(\x0c\\nx) ...')

    def test_comment_after_linebreak(self):
        self.assert_lex('1\n# foo\n2',
                        'IntLit(1) Break(\\n# foo\\n) IntLit(2) ...')
        self.assert_lex('1\n# foo',
                        'IntLit(1) Break(\\n# foo) Eof()')
    
    def test_line_numbers(self):
        self.assert_line('a\\nb', [1, 1, 2, 2, 2])
        
        self.assert_line('(\\nb)', [1, 2, 2]) # Note: omit break and eof tokens
        
        self.assert_line('a\\n b', [1, 1,     # a, break
                                    2, 2, 2,  # indent, b, break
                                    2, 2])    # dedent, break
        self.assert_line('a\\n b\\nc', [1, 1,       # a, break
                                        2, 2, 2,    # indent, b, break
                                        3, 3])      # dedent, c
        
        self.assert_line('a\\rb', [1, 1, 2])
        self.assert_line('a\\r\\nb', [1, 1, 2])
        
        self.assert_line('"""x""" 1', [1, 1])
        self.assert_line('"""x\\ny""" 1', [1, 2])
        self.assert_line('"""x\\r\\ny""" 1', [1, 2])
        self.assert_line('"""x\\ry""" 1', [1, 2])
        self.assert_line('"""x\\n\\ny""" 1', [1, 3])
        self.assert_line('\\n"""x\\ny""" 1', [2, 3])
        
        self.assert_line('"x" 1', [1, 1])
        self.assert_line('"\\\\n" 1', [1, 2])
        self.assert_line('"\\\\nx\\\\n" 1', [1, 3])
        
        self.assert_line('r"x" 1', [1, 1])
        self.assert_line('r"\\\\n" 1', [1, 2])
        self.assert_line('r"\\\\nx\\\\n" 1', [1, 3])
    
    def test_backslash_line(self):
        self.assert_line('a\\\\n 1\\n=', [1, 2, 2, 3])
    
    def test_invalid_parens(self):
        self.assert_lex('([\\n )\\n1',
                        'Punct(() Punct([) Punct(\\n )) IntLit(\\n1) ...')
        self.assert_lex('])', 'Punct(]) Punct()) ...')
        self.assert_lex('(]\\n )', 'Punct(() Punct(]) Punct(\\n )) ...')
        self.assert_lex('(\\n ])', 'Punct(() Punct(\\n ]) Punct()) ...')
    
    def test_invalid_indent(self):
        self.assert_lex('x\\n  y\\n z',
                        'Name(x) Break(\\n) Indent(  ) Name(y) ' +
                        'Break(\\n) Dedent() LexError( ) Name(z) ...')
    
    def test_invalid_backslash(self):
        self.assert_lex('\\ \\nx', 'LexError(\\) Break( \\n) Name(x) ...')
        self.assert_lex('\\ \\nx', 'LexError(\\) Break( \\n) Name(x) ...')
    
    def test_non_terminated_string_literal(self):
        self.assert_lex("'", 'LexError(\') ...')
        self.assert_lex("'\\na", 'LexError(\') Break(\\n) Name(a) ...')
        
        self.assert_lex('"', 'LexError(") ...')
        self.assert_lex('"\\na', 'LexError(") Break(\\n) Name(a) ...')
        
        self.assert_lex("r'", 'LexError(r\') ...')
        self.assert_lex('r"', 'LexError(r") ...')
        
        self.assert_lex('"""', 'LexError(""") ...')
        self.assert_lex('"""\\n', 'LexError("""\\n) ...')
        
        self.assert_lex("'''", "LexError(''') ...")
        self.assert_lex("'''\\n", "LexError('''\\n) ...")
        
        self.assert_lex("'\\", 'LexError(\'\\) ...')
        self.assert_lex("'\\\\n", 'LexError(\'\\\\n) ...')
        self.assert_lex("r'\\", 'LexError(r\'\\) ...')
        self.assert_lex("r'\\\\n", 'LexError(r\'\\\\n) ...')
    
    def test_invalid_hex_int_literals(self):
        self.assert_lex('0x', 'LexError(  ) ...')
        self.assert_lex('0xax', 'LexError(    ) ...')
    
    # TODO
    #   invalid escape sequences in string literals etc.
    
    def assert_lex(self, src, lexed):
        src = src.replace('\\n', '\n')
        src = src.replace('\\r', '\r')
        
        if lexed.endswith(' ...'):
            lexed = lexed[:-3] + 'Break() Eof()'
        
        l = lex(src)
        r = []
        for t in l:
            r.append(str(t))
        act = ' '.join(r)
        if act != lexed:
            print('Actual:  ', act)
            print('Expected:', lexed)
        assert_equal(act, lexed)
    
    def assert_line(self, s, a):
        s = s.replace('\\n', '\n')
        s = s.replace('\\r', '\r')
        
        tt = lex(s)
        r = []
        for t in tt:
            r.append(t.line)
        if len(r) == len(a) + 2:
            a = a[:]
            a.append(a[-1])
            a.append(a[-1])
        assert_equal(r, a)

########NEW FILE########
__FILENAME__ = testopgen
"""Test Alore type operation generation (OBSOLETE)."""

import os.path

import typing

from build import build
from myunit import Suite, run_test
from config import test_data_prefix, test_temp_dir
from helpers import assert_string_arrays_equal_wildcards
from data import parse_test_cases
from testoutput import remove_prefix
from testtransform import (
    remove_comment_lines, builtins_wrapper, TRANSFORM_BUILTINS
)
from transform import DyncheckTransformVisitor
from opgen import generate_runtime_support
from errors import CompileError


class DyncheckOpGenSuite(Suite):
    test_case_files = ['dyncheck-opgen.test']
    
    def cases(self):
        c = []
        for f in self.test_case_files:
            c += parse_test_cases(
                os.path.join(test_data_prefix, f),
                builtins_wrapper(test_op_gen,
                                 os.path.join(test_data_prefix,
                                              TRANSFORM_BUILTINS)),
                test_temp_dir, True)
        return c


def test_op_gen(testcase):
    """Perform a type operation support data and code genereation test case."""
    expected = remove_comment_lines(testcase.output)
    try:
        src = '\n'.join(testcase.input)
        # Parse and type check the input program.
        trees, symtable, infos, types = build(src, 'main', False,
                                              test_temp_dir, True)
        a = []
        first = True
        # Transform each file separately.
        for t in trees:
            # Skip the builtins module and files with '_skip.' in the path.
            if not t.path.endswith('/builtins.py') and '_skip.' not in t.path:
                if not first:
                    # Display path for files other than the first.
                    a.append('{}:'.format(
                        remove_prefix(t.path, test_temp_dir)))
                
                # Transform parse tree and produce the code for operations.
                # Note that currently we generate this for each file
                # separately; this needs to be fixed eventually.
                v = DyncheckTransformVisitor(types, symtable, True)
                t.accept(v)
                s = generate_runtime_support(t)
                if s != '':
                    a += s.split('\n')
            first = False
    except CompileError as e:
        a = e.messages
    assert_string_arrays_equal_wildcards(
        expected, a,
        'Invalid source code output ({}, line {})'.format(testcase.file,
                                                          testcase.line))

    
if __name__ == '__main__':
    import sys
    run_test(DyncheckOpGenSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testoutput
"""Tests for parse tree pretty printing that preserves formatting

Test case descriptions are in file test/data/output.test.
"""

import os.path
import re

from typing import Undefined, Any

from mypy import build
from mypy.myunit import Suite, run_test
from mypy.test.helpers import assert_string_arrays_equal
from mypy.test.data import parse_test_cases
from mypy.test.config import test_data_prefix, test_temp_dir
from mypy.parse import parse
from mypy.output import OutputVisitor
from mypy.errors import CompileError


# Files which contain test case descriptions.
output_files = ['output.test']


class OutputSuite(Suite):
    def cases(self):
        c = []
        for f in output_files:
            c += parse_test_cases(os.path.join(test_data_prefix, f),
                                  test_output, test_temp_dir, True)
        return c


def test_output(testcase):
    """Perform an identity source code transformation test case."""
    expected = testcase.output
    if expected == []:
        expected = testcase.input
    try:
        src = '\n'.join(testcase.input)
        # Parse and semantically analyze the source program.
        
        # Test case names with a special suffix get semantically analyzed. This
        # lets us test that semantic analysis does not break source code pretty
        # printing.
        if testcase.name.endswith('_SemanticAnalyzer'):
            result = build.build('main',
                                 target=build.SEMANTIC_ANALYSIS,
                                 program_text=src,
                                 flags=[build.TEST_BUILTINS],
                                 alt_lib_path=test_temp_dir)
            files = result.files
        else:
            files = {'main': parse(src, 'main')}
        a = []
        first = True
        
        # Produce an output containing the pretty-printed forms (with original
        # formatting) of all the relevant source files.
        for fnam in sorted(files.keys()):
            f = files[fnam]
            # Omit the builtins and files marked for omission.
            if (not f.path.endswith(os.sep + 'builtins.py') and
                    '-skip.' not in f.path):
                # Add file name + colon for files other than the first.
                if not first:
                    a.append('{}:'.format(fix_path(remove_prefix(
                        f.path, test_temp_dir))))
                
                v = OutputVisitor()
                f.accept(v)
                s = v.output()
                if s != '':
                    a += s.split('\n')
            first = False
    except CompileError as e:
        a = e.messages
    assert_string_arrays_equal(
        expected, a, 'Invalid source code output ({}, line {})'.format(
            testcase.file, testcase.line))


def remove_prefix(path, prefix):
    regexp = '^' + prefix.replace('\\', '\\\\')
    np = re.sub(regexp, '', path)
    if np.startswith(os.sep):
        np = np[1:]
    return np


def fix_path(path):
    return path.replace('\\', '/')


if __name__ == '__main__':
    import sys
    run_test(OutputSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testparse
"""Tests for the mypy parser

Test case descriptions are in files test/data/parse[-errors].test."""

import os.path

import typing

from mypy.myunit import Suite, AssertionFailure, run_test
from mypy.test.helpers import assert_string_arrays_equal
from mypy.test.data import parse_test_cases
from mypy.test import config
from mypy.parse import parse
from mypy.errors import CompileError


class ParserSuite(Suite):
    parse_files = ['parse.test',
                   'parse-python2.test']

    def cases(self):
        # The test case descriptions are stored in data files.
        c = []
        for f in self.parse_files:
            c += parse_test_cases(
                os.path.join(config.test_data_prefix, f), test_parser)
        return c


def test_parser(testcase):
    """Perform a single parser test case.

    The argument contains the description of the test case.
    """
    
    pyversion = 3
    if testcase.file.endswith('python2.test'):
        pyversion = 2
    
    try:
        n = parse('\n'.join(testcase.input), pyversion=pyversion)
        a = str(n).split('\n')
    except CompileError as e:
        a = e.messages
    assert_string_arrays_equal(testcase.output, a,
                               'Invalid parser output ({}, line {})'.format(
                                   testcase.file, testcase.line))


# The file name shown in test case output. This is displayed in error
# messages, and must match the file name in the test case descriptions.
INPUT_FILE_NAME = 'file'


class ParseErrorSuite(Suite):
    def cases(self):
        # Test case descriptions are in an external file.
        return parse_test_cases(os.path.join(config.test_data_prefix,
                                             'parse-errors.test'),
                                test_parse_error)


def test_parse_error(testcase):
    try:
        # Compile temporary file.
        parse('\n'.join(testcase.input), INPUT_FILE_NAME)
        raise AssertionFailure('No errors reported')
    except CompileError as e:
        # Verify that there was a compile error and that the error messages
        # are equivalent.
        assert_string_arrays_equal(
            testcase.output, e.messages,
            'Invalid compiler output ({}, line {})'.format(testcase.file,
                                                           testcase.line))


class CombinedParserSuite(Suite):
    def __init__(self):
        self.test_parse = ParserSuite()
        self.test_parse_errors = ParseErrorSuite()
        super().__init__()


if __name__ == '__main__':
    import sys
    run_test(CombinedParserSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testpythoneval
"""Test cases for running mypy programs using a Python interpreter.

Each test case type checks a program then runs it using Python. The
output (stdout) of the program is compared to expected output. Type checking
uses full builtins and other stubs.

Note: Currently Python interpreter and mypy implementation paths are hard coded
      (see python_path and mypy_path below).

Note: These test cases are *not* included in the main test suite, as running
      this suite is slow and it would slow down the main suite too much. The
      slowness is due to translating the mypy implementation in each test case.
"""

import os
import os.path
import subprocess
import sys

import typing

from mypy.myunit import Suite, run_test
from mypy.test.config import test_data_prefix, test_temp_dir
from mypy.test.data import parse_test_cases
from mypy.test.helpers import assert_string_arrays_equal


# Files which contain test case descriptions.
python_eval_files = ['pythoneval.test']

# Path to Python 3 interpreter
python3_path = 'python3'
# Path to Python 2 interpreter
python2_path = 'python'


class PythonEvaluationSuite(Suite):
    def cases(self):
        c = []
        for f in python_eval_files:
            c += parse_test_cases(os.path.join(test_data_prefix, f),
                                  test_python_evaluation, test_temp_dir, True)
        return c


def test_python_evaluation(testcase):
    # Write the program to a file.
    program = '_program.py'
    outfile = '_program.out'
    f = open(program, 'w')
    for s in testcase.input:
        f.write('{}\n'.format(s))
    f.close()
    # Use Python 2 interpreter if running a Python 2 test case.
    if testcase.name.lower().endswith('python2'):
        args = ['--py2', python2_path]
    else:
        args = []
    # Set up module path.
    typing_path = os.path.join(os.getcwd(), 'lib-typing', '3.2')
    assert os.path.isdir(typing_path)
    os.environ['PYTHONPATH'] = os.pathsep.join([typing_path, '.'])
    os.environ['MYPYPATH'] = '.'
    # Run the program.
    process = subprocess.Popen([python3_path,
                                os.path.join('scripts', 'mypy')] +
                               args +
                               [program],
                               stdout=subprocess.PIPE,
                               stderr=subprocess.STDOUT)
    outb = process.stdout.read()
    # Split output into lines.
    out = [s.rstrip('\n\r') for s in str(outb, 'utf8').splitlines()]
    # Remove temp file.
    os.remove(program)
    assert_string_arrays_equal(testcase.output, out,
                               'Invalid output ({}, line {})'.format(
                                   testcase.file, testcase.line))


if __name__ == '__main__':
    run_test(PythonEvaluationSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testsemanal
"""Semantic analyzer test cases"""

import os.path

from typing import Dict, List

from mypy import build
from mypy.myunit import Suite, run_test
from mypy.test.helpers import assert_string_arrays_equal, testfile_pyversion
from mypy.test.data import parse_test_cases
from mypy.test.config import test_data_prefix, test_temp_dir
from mypy.errors import CompileError
from mypy.nodes import TypeInfo


# Semantic analyser test cases: dump parse tree

# Semantic analysis test case description files.
semanal_files = ['semanal-basic.test',
                 'semanal-expressions.test',
                 'semanal-classes.test',
                 'semanal-types.test',
                 'semanal-modules.test',
                 'semanal-statements.test',
                 'semanal-abstractclasses.test',
                 'semanal-python2.test']


class SemAnalSuite(Suite):
    def cases(self):
        c = []
        for f in semanal_files:
            c += parse_test_cases(os.path.join(test_data_prefix, f),
                                  test_semanal, test_temp_dir)
        return c


def test_semanal(testcase):
    """Perform a semantic analysis test case.

    The testcase argument contains a description of the test case
    (inputs and output).
    """
    
    try:
        src = '\n'.join(testcase.input)
        result = build.build('main',
                             target=build.SEMANTIC_ANALYSIS,
                             program_text=src,
                             pyversion=testfile_pyversion(testcase.file),
                             flags=[build.TEST_BUILTINS],
                             alt_lib_path=test_temp_dir)
        a = []
        # Include string representations of the source files in the actual
        # output.
        for fnam in sorted(result.files.keys()):
            f = result.files[fnam]
            # Omit the builtins module and files with a special marker in the
            # path.
            # TODO the test is not reliable
            if (not f.path.endswith((os.sep + 'builtins.py',
                                     'typing.py',
                                     'abc.py'))
                    and not os.path.basename(f.path).startswith('_')
                    and not os.path.splitext(
                        os.path.basename(f.path))[0].endswith('_')):
                a += str(f).split('\n')
    except CompileError as e:
        a = e.messages
    assert_string_arrays_equal(
        testcase.output, a,
        'Invalid semantic analyzer output ({}, line {})'.format(testcase.file,
                                                                testcase.line))

# Semantic analyser error test cases

# Paths to files containing test case descriptions.
semanal_error_files = ['semanal-errors.test']


class SemAnalErrorSuite(Suite):
    def cases(self):
        # Read test cases from test case description files.
        c = []
        for f in semanal_error_files:
            c += parse_test_cases(os.path.join(test_data_prefix, f),
                                  test_semanal_error, test_temp_dir)
        return c
    

def test_semanal_error(testcase):
    """Perform a test case."""
    
    try:
        src = '\n'.join(testcase.input)
        build.build('main',
                    target=build.SEMANTIC_ANALYSIS,
                    program_text=src,
                    flags=[build.TEST_BUILTINS],
                    alt_lib_path=test_temp_dir)
        raise AssertionError('No errors reported in {}, line {}'.format(
            testcase.file, testcase.line))
    except CompileError as e:
        # Verify that there was a compile error and that the error messages
        # are equivalent.
        assert_string_arrays_equal(
            testcase.output, normalize_error_messages(e.messages),
            'Invalid compiler output ({}, line {})'.format(testcase.file,
                                                           testcase.line))


def normalize_error_messages(messages):
    """Translate an array of error messages to use / as path separator."""
    
    a = []
    for m in messages:
        a.append(m.replace(os.sep, '/'))
    return a


# SymbolNode table export test cases

# Test case descriptions
semanal_symtable_files = ['semanal-symtable.test']

    
class SemAnalSymtableSuite(Suite):
    def cases(self):
        c = []
        for f in semanal_symtable_files:
            c += parse_test_cases(os.path.join(test_data_prefix, f),
                                  self.run_test, test_temp_dir)
        return c
    
    def run_test(self, testcase):
        """Perform a test case."""
        try:
            # Build test case input.
            src = '\n'.join(testcase.input)
            result = build.build('main',
                                 target=build.SEMANTIC_ANALYSIS,
                                 program_text=src,
                                 flags=[build.TEST_BUILTINS],
                                 alt_lib_path=test_temp_dir)
            # The output is the symbol table converted into a string.
            a = []      
            for f in sorted(result.files.keys()):
                if f not in ('builtins', 'typing', 'abc'):
                    a.append('{}:'.format(f))
                    for s in str(result.files[f].names).split('\n'):
                        a.append('  ' + s)
        except CompileError as e:
            a = e.messages
        assert_string_arrays_equal(
            testcase.output, a,
            'Invalid semantic analyzer output ({}, line {})'.format(
                testcase.file, testcase.line))


# Type info export test cases

semanal_typeinfo_files = ['semanal-typeinfo.test']

    
class SemAnalTypeInfoSuite(Suite):
    def cases(self):
        """Test case descriptions"""
        c = []
        for f in semanal_typeinfo_files:
            c += parse_test_cases(os.path.join(test_data_prefix, f),
                                  self.run_test, test_temp_dir)
        return c
    
    def run_test(self, testcase):
        """Perform a test case."""
        try:
            # Build test case input.
            src = '\n'.join(testcase.input)
            result = build.build('main',
                                 target=build.SEMANTIC_ANALYSIS,
                                 program_text=src,
                                 flags=[build.TEST_BUILTINS],
                                 alt_lib_path=test_temp_dir)
            
            # Collect all TypeInfos in top-level modules.
            typeinfos = TypeInfoMap()
            for f in result.files.values():
                for n in f.names.values():
                    if isinstance(n.node, TypeInfo):
                        typeinfos[n.fullname] = n.node
            
            # The output is the symbol table converted into a string.
            a = str(typeinfos).split('\n')
        except CompileError as e:
            a = e.messages
        assert_string_arrays_equal(
            testcase.output, a,
            'Invalid semantic analyzer output ({}, line {})'.format(
                testcase.file, testcase.line))


class TypeInfoMap(Dict[str, TypeInfo]):
    def __str__(self) -> str:
        a = ['TypeInfoMap('] # type: List[str]
        for x, y in sorted(self.items()):
            if isinstance(x, str) and (not x.startswith('builtins.') and
                                       not x.startswith('typing.') and
                                       not x.startswith('abc.')):
                ti = ('\n' + '  ').join(str(y).split('\n'))
                a.append('  {} : {}'.format(x, ti))
        a[-1] += ')'
        return '\n'.join(a)


class CombinedSemAnalSuite(Suite):
    def __init__(self):
        self.test_semanal = SemAnalSuite()
        self.test_semanal_errors = SemAnalErrorSuite()
        self.test_semanal_symtable = SemAnalSymtableSuite()
        self.test_semanal_typeinfos = SemAnalTypeInfoSuite()
        super().__init__()


if __name__ == '__main__':
    import sys
    run_test(CombinedSemAnalSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testsolve
"""Test cases for the constraint solver used in type inference."""

import typing

from mypy.myunit import Suite, assert_equal, run_test
from mypy.constraints import SUPERTYPE_OF, SUBTYPE_OF, Constraint
from mypy.solve import solve_constraints
from mypy.typefixture import TypeFixture


class SolveSuite(Suite):
    def __init__(self):
        super().__init__()
        self.fx = TypeFixture()
    
    def test_empty_input(self):
        self.assert_solve([], [], [])
    
    def test_simple_supertype_constraints(self):
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.a)],
                          [(self.fx.a, self.fx.o)])
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.a),
                           self.supc(self.fx.t, self.fx.b)],
                          [(self.fx.a, self.fx.o)])
    
    def test_simple_subtype_constraints(self):
        self.assert_solve(['T'],
                          [self.subc(self.fx.t, self.fx.a)],
                          [(self.fx.nonet, self.fx.a)])
        self.assert_solve(['T'],
                          [self.subc(self.fx.t, self.fx.a),
                           self.subc(self.fx.t, self.fx.b)],
                          [(self.fx.nonet, self.fx.b)])
    
    def test_both_kinds_of_constraints(self):
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.b),
                           self.subc(self.fx.t, self.fx.a)],
                          [(self.fx.b, self.fx.a)])
    
    def test_unsatisfiable_constraints(self):
        # The constraints are impossible to satisfy.
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.a),
                           self.subc(self.fx.t, self.fx.b)],
                          [None])
    
    def test_exactly_specified_result(self):
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.b),
                           self.subc(self.fx.t, self.fx.b)],
                          [(self.fx.b, self.fx.b)])
    
    def test_multiple_variables(self):
        self.assert_solve(['T', 'S'],
                          [self.supc(self.fx.t, self.fx.b),
                           self.supc(self.fx.s, self.fx.c),
                           self.subc(self.fx.t, self.fx.a)],
                          [(self.fx.b, self.fx.a), (self.fx.c, self.fx.o)])
    
    def test_no_constraints_for_var(self):
        self.assert_solve(['T'],
                          [],
                          [(self.fx.nonet, self.fx.o)])
        self.assert_solve(['T', 'S'],
                          [],
                          [(self.fx.nonet, self.fx.o),
                           (self.fx.nonet, self.fx.o)])
        self.assert_solve(['T', 'S'],
                          [self.supc(self.fx.s, self.fx.a)],
                          [(self.fx.nonet, self.fx.o), (self.fx.a, self.fx.o)])
    
    def test_void_constraints(self):
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.void)],
                          [(self.fx.void, self.fx.void)])
        self.assert_solve(['T'],
                          [self.subc(self.fx.t, self.fx.void)],
                          [(self.fx.void, self.fx.void)])
        
        # Both bounds void.
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.void),
                           self.subc(self.fx.t, self.fx.void)],
                          [(self.fx.void, self.fx.void)])
        
        # Cannot infer any type.
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.a),
                           self.supc(self.fx.t, self.fx.void)],
                          [None])
        self.assert_solve(['T'],
                          [self.subc(self.fx.t, self.fx.a),
                           self.subc(self.fx.t, self.fx.void)],
                          [None])
    
    def test_simple_constraints_with_dynamic_type(self):
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.anyt)],
                          [(self.fx.anyt, self.fx.anyt)])
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.anyt),
                           self.supc(self.fx.t, self.fx.anyt)],
                          [(self.fx.anyt, self.fx.anyt)])
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.anyt),
                           self.supc(self.fx.t, self.fx.a)],
                          [(self.fx.anyt, self.fx.anyt)])
        
        self.assert_solve(['T'],
                          [self.subc(self.fx.t, self.fx.anyt)],
                          [(self.fx.anyt, self.fx.anyt)])
        self.assert_solve(['T'],
                          [self.subc(self.fx.t, self.fx.anyt),
                           self.subc(self.fx.t, self.fx.anyt)],
                          [(self.fx.anyt, self.fx.anyt)])
        self.assert_solve(['T'],
                          [self.subc(self.fx.t, self.fx.anyt),
                           self.subc(self.fx.t, self.fx.a)],
                          [(self.fx.anyt, self.fx.anyt)])
    
    def test_both_normal_and_any_types_in_results(self):
        # If one of the bounds is any, we promote the other bound to
        # any as well, since otherwise the type range does not make sense.
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.a),
                           self.subc(self.fx.t, self.fx.anyt)],
                          [(self.fx.anyt, self.fx.anyt)])
        
        self.assert_solve(['T'],
                          [self.supc(self.fx.t, self.fx.anyt),
                           self.subc(self.fx.t, self.fx.a)],
                          [(self.fx.anyt, self.fx.anyt)])
    
    def assert_solve(self, vars, constraints, results):
        res = []
        for r in results:
            if isinstance(r, tuple):
                res.append(r[0])
            else:
                res.append(r)
        actual = solve_constraints(vars, constraints, self.fx.basic)
        assert_equal(str(actual), str(res))
    
    def supc(self, type_var, bound):
        return Constraint(type_var.name, SUPERTYPE_OF, bound)
    
    def subc(self, type_var, bound):
        return Constraint(type_var.name, SUBTYPE_OF, bound)


if __name__ == '__main__':
    import sys
    run_test(SolveSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testsubtypes
import typing

from mypy.myunit import Suite, assert_true, run_test
from mypy.subtypes import is_subtype
from mypy.typefixture import TypeFixture, InterfaceTypeFixture


class SubtypingSuite(Suite):
    def set_up(self):
        self.fx = TypeFixture()
    
    def test_trivial_cases(self):
        for simple in self.fx.void, self.fx.a, self.fx.o, self.fx.b:
            self.assert_subtype(simple, simple)
    
    def test_instance_subtyping(self):
        self.assert_proper_subtype(self.fx.a, self.fx.o)
        self.assert_proper_subtype(self.fx.b, self.fx.o)
        self.assert_proper_subtype(self.fx.b, self.fx.a)
        
        self.assert_not_subtype(self.fx.a, self.fx.d)
        self.assert_not_subtype(self.fx.b, self.fx.c)
    
    def test_simple_generic_instance_subtyping(self):
        self.assert_subtype(self.fx.ga, self.fx.ga)
        self.assert_subtype(self.fx.hab, self.fx.hab)
        
        self.assert_not_subtype(self.fx.ga, self.fx.g2a)
        self.assert_not_subtype(self.fx.ga, self.fx.gb)
        self.assert_not_subtype(self.fx.gb, self.fx.ga)
    
    def test_generic_subtyping_with_inheritance(self):
        self.assert_subtype(self.fx.gsab, self.fx.gb)
        self.assert_not_subtype(self.fx.gsab, self.fx.ga)
    
    def test_interface_subtyping(self):
        self.assert_subtype(self.fx.e, self.fx.f)
        self.assert_equivalent(self.fx.f, self.fx.f)
        self.assert_not_subtype(self.fx.a, self.fx.f)
    
    def test_generic_interface_subtyping(self):
        # TODO make this work
        self.skip()
        
        fx2 = InterfaceTypeFixture()
        
        self.assert_subtype(fx2.m1, fx2.gfa)
        self.assert_not_subtype(fx2.m1, fx2.gfb)
        
        self.assert_equivalent(fx2.gfa, fx2.gfa)
    
    def test_basic_callable_subtyping(self):
        self.assert_proper_subtype(self.fx.callable(self.fx.o, self.fx.d),
                                   self.fx.callable(self.fx.a, self.fx.d))
        self.assert_proper_subtype(self.fx.callable(self.fx.d, self.fx.b),
                                   self.fx.callable(self.fx.d, self.fx.a))
        
        self.assert_unrelated(self.fx.callable(self.fx.a, self.fx.a),
                              self.fx.callable(self.fx.a, self.fx.void))
        
        self.assert_unrelated(
            self.fx.callable(self.fx.a, self.fx.a, self.fx.a),
            self.fx.callable(self.fx.a, self.fx.a))
    
    def test_default_arg_callable_subtyping(self):
        self.assert_proper_subtype(
            self.fx.callable_default(1, self.fx.a, self.fx.d, self.fx.a),
            self.fx.callable(self.fx.a, self.fx.d, self.fx.a))
        
        self.assert_proper_subtype(
            self.fx.callable_default(1, self.fx.a, self.fx.d, self.fx.a),
            self.fx.callable(self.fx.a, self.fx.a))
        
        self.assert_proper_subtype(
            self.fx.callable_default(0, self.fx.a, self.fx.d, self.fx.a),
            self.fx.callable_default(1, self.fx.a, self.fx.d, self.fx.a))
        
        self.assert_unrelated(
            self.fx.callable_default(1, self.fx.a, self.fx.d, self.fx.a),
            self.fx.callable(self.fx.d, self.fx.d, self.fx.a))
        
        self.assert_unrelated(
            self.fx.callable_default(0, self.fx.a, self.fx.d, self.fx.a),
            self.fx.callable_default(1, self.fx.a, self.fx.a, self.fx.a))
        
        self.assert_unrelated(
            self.fx.callable_default(1, self.fx.a, self.fx.a),
            self.fx.callable(self.fx.a, self.fx.a, self.fx.a))
    
    def test_var_arg_callable_subtyping(self):
        self.assert_proper_subtype(
            self.fx.callable_var_arg(0, self.fx.a, self.fx.a),
            self.fx.callable_var_arg(0, self.fx.b, self.fx.a))
        
        self.assert_unrelated(
            self.fx.callable_var_arg(0, self.fx.a, self.fx.a),
            self.fx.callable(self.fx.a, self.fx.a))
        
        self.assert_proper_subtype(
            self.fx.callable_var_arg(0, self.fx.a, self.fx.a),
            self.fx.callable(self.fx.a))
        
        self.assert_proper_subtype(
            self.fx.callable_var_arg(1, self.fx.a, self.fx.d, self.fx.a),
            self.fx.callable(self.fx.a, self.fx.a))
        
        self.assert_proper_subtype(
            self.fx.callable_var_arg(0, self.fx.a, self.fx.d, self.fx.a),
            self.fx.callable(self.fx.a, self.fx.a))
    
    def test_type_callable_subtyping(self):
        self.assert_proper_subtype(
            self.fx.callable_type(self.fx.d, self.fx.a), self.fx.type_type)
        
        self.assert_proper_subtype(
            self.fx.callable_type(self.fx.d, self.fx.b),
            self.fx.callable(self.fx.d, self.fx.a))
        
        self.assert_proper_subtype(self.fx.callable_type(self.fx.a, self.fx.b),
                                   self.fx.callable(self.fx.a, self.fx.b))
    
    # IDEA: Maybe add these test cases (they are tested pretty well in type
    #       checker tests already):
    #  * more interface subtyping test cases
    #  * more generic interface subtyping test cases
    #  * type variables
    #  * tuple types
    #  * void type
    #  * None type
    #  * any type
    #  * generic function types
    
    def assert_subtype(self, s, t):
        assert_true(is_subtype(s, t), '{} not subtype of {}'.format(s, t))
    
    def assert_not_subtype(self, s, t):
        assert_true(not is_subtype(s, t), '{} subtype of {}'.format(s, t))
    
    def assert_proper_subtype(self, s, t):
        self.assert_subtype(s, t)
        self.assert_not_subtype(t, s)
    
    def assert_equivalent(self, s, t):
        self.assert_subtype(s, t)
        self.assert_subtype(t, s)
    
    def assert_unrelated(self, s, t):
        self.assert_not_subtype(s, t)
        self.assert_not_subtype(t, s)


if __name__ == '__main__':
    import sys
    run_test(SubtypingSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testtransform
"""Identity AST transform test cases"""

import os.path

from typing import Dict, List

from mypy import build
from mypy.myunit import Suite, run_test
from mypy.test.helpers import assert_string_arrays_equal, testfile_pyversion
from mypy.test.data import parse_test_cases
from mypy.test.config import test_data_prefix, test_temp_dir
from mypy.errors import CompileError
from mypy.nodes import TypeInfo
from mypy.treetransform import TransformVisitor


class TransformSuite(Suite):
    # Reuse semantic analysis test cases.
    transform_files = ['semanal-basic.test',
                       'semanal-expressions.test',
                       'semanal-classes.test',
                       'semanal-types.test',
                       'semanal-modules.test',
                       'semanal-statements.test',
                       'semanal-abstractclasses.test',
                       'semanal-python2.test']

    def cases(self):
        c = []
        for f in self.transform_files:
            c += parse_test_cases(os.path.join(test_data_prefix, f),
                                  test_transform, test_temp_dir)
        return c


def test_transform(testcase):
    """Perform an identity transform test case."""
    
    try:
        src = '\n'.join(testcase.input)
        result = build.build('main',
                             target=build.SEMANTIC_ANALYSIS,
                             program_text=src,
                             pyversion=testfile_pyversion(testcase.file),
                             flags=[build.TEST_BUILTINS],
                             alt_lib_path=test_temp_dir)
        a = []
        # Include string representations of the source files in the actual
        # output.
        for fnam in sorted(result.files.keys()):
            f = result.files[fnam]

            # Omit the builtins module and files with a special marker in the
            # path.
            # TODO the test is not reliable
            if (not f.path.endswith((os.sep + 'builtins.py',
                                     'typing.py',
                                     'abc.py'))
                    and not os.path.basename(f.path).startswith('_')
                    and not os.path.splitext(
                        os.path.basename(f.path))[0].endswith('_')):
                t = TestTransformVisitor()
                f = t.node(f)
                a += str(f).split('\n')
    except CompileError as e:
        a = e.messages
    assert_string_arrays_equal(
        testcase.output, a,
        'Invalid semantic analyzer output ({}, line {})'.format(testcase.file,
                                                                testcase.line))


class TestTransformVisitor(TransformVisitor):
    def type(self, type):
        assert type is not None
        return type


if __name__ == '__main__':
    import sys
    run_test(TransformSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testtypegen
"""Test cases for the type checker: exporting inferred types"""

import os.path
import re

import typing

from mypy import build
from mypy.myunit import Suite, run_test
from mypy.test import config
from mypy.test.data import parse_test_cases
from mypy.test.helpers import assert_string_arrays_equal
from mypy.util import short_type
from mypy.nodes import NameExpr, TypeVarExpr, CallExpr
from mypy.traverser import TraverserVisitor
from mypy.errors import CompileError


class TypeExportSuite(Suite):
    # List of files that contain test case descriptions.
    files = ['typexport-basic.test']
    
    def cases(self):
        c = []
        for f in self.files:
            c += parse_test_cases(os.path.join(config.test_data_prefix, f),
                                  self.run_test, config.test_temp_dir)
        return c
    
    def run_test(self, testcase):
        a = []
        try:
            line = testcase.input[0]
            mask = ''
            if line.startswith('##'):
                mask = '(' + line[2:].strip() + ')$'
            
            src = '\n'.join(testcase.input)
            result = build.build(program_path='main',
                                 target=build.TYPE_CHECK,
                                 program_text=src,
                                 flags=[build.TEST_BUILTINS],
                                 alt_lib_path=config.test_temp_dir)
            map = result.types
            nodes = map.keys()

            # Ignore NameExpr nodes of variables with explicit (trivial) types
            # to simplify output. Also ignore 'Undefined' nodes.
            searcher = VariableDefinitionNodeSearcher()
            for file in result.files.values():
                file.accept(searcher)
            ignored = searcher.nodes

            # Filter nodes that should be included in the output.
            keys = []
            for node in nodes:
                if node.line is not None and node.line != -1 and map[node]:
                    if ignore_node(node) or node in ignored:
                        continue
                    if (re.match(mask, short_type(node))
                            or (isinstance(node, NameExpr)
                                and re.match(mask, node.name))):
                        # Include node in output.
                        keys.append(node)
                        
            for key in sorted(keys,
                              key=lambda n: (n.line, short_type(n),
                                             str(n) + str(map[n]))):
                ts = str(map[key]).replace('*', '') # Remove erased tags
                ts = ts.replace('__main__.', '')
                a.append('{}({}) : {}'.format(short_type(key), key.line, ts))
        except CompileError as e:
            a = e.messages
        assert_string_arrays_equal(
            testcase.output, a,
            'Invalid type checker output ({}, line {})'.format(testcase.file,
                                                               testcase.line))


class VariableDefinitionNodeSearcher(TraverserVisitor):
    def __init__(self):
        self.nodes = set()
    
    def visit_assignment_stmt(self, s):
        if s.type or ignore_node(s.rvalue):
            for lvalue in s.lvalues:
                if isinstance(lvalue, NameExpr):
                    self.nodes.add(lvalue)
            if (isinstance(s.rvalue, NameExpr)
                    and s.rvalue.fullname == 'typing.Undefined'):
                self.nodes.add(s.rvalue)


def ignore_node(node):
    """Return True if node is to be omitted from test case output."""
    
    # We want to get rid of object() expressions in the typing module stub
    # and also typevar(...) expressions. Since detecting whether a node comes
    # from the typing module is not easy, we just to strip them all away.
    if isinstance(node, TypeVarExpr):
        return True
    if isinstance(node, NameExpr) and node.fullname == 'builtins.object':
        return True
    if isinstance(node, CallExpr) and (ignore_node(node.callee) or
                                       node.analyzed):
        return True
    
    return False


if __name__ == '__main__':
    import sys
    run_test(TypeExportSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = testtypes
"""Test cases for mypy types and type operations."""

from typing import List

from mypy.myunit import (
    Suite, assert_equal, assert_true, assert_false, run_test
)
from mypy.erasetype import erase_type
from mypy.expandtype import expand_type
from mypy.join import join_types
from mypy.meet import meet_types
from mypy.types import (
    UnboundType, AnyType, Void, Callable, TupleType, TypeVarDef, Type,
    Instance, NoneTyp, ErrorType
)
from mypy.nodes import ARG_POS, ARG_OPT, ARG_STAR
from mypy.replacetvars import replace_type_vars
from mypy.subtypes import is_subtype, is_more_precise, is_proper_subtype
from mypy.typefixture import TypeFixture, InterfaceTypeFixture


class TypesSuite(Suite):
    def __init__(self):
        super().__init__()
        self.x = UnboundType('X')  # Helpers
        self.y = UnboundType('Y')
    
    def test_any(self):
        assert_equal(str(AnyType()), 'Any')
    
    def test_simple_unbound_type(self):
        u = UnboundType('Foo')
        assert_equal(str(u), 'Foo?')
    
    def test_generic_unbound_type(self):
        u = UnboundType('Foo', [UnboundType('T'), AnyType()])
        assert_equal(str(u), 'Foo?[T?, Any]')
    
    def test_void_type(self):
        assert_equal(str(Void(None)), 'void')
    
    def test_callable_type(self):
        c = Callable([self.x, self.y],
                     [ARG_POS, ARG_POS],
                     [None, None],
                     AnyType(), False)
        assert_equal(str(c), 'def (X?, Y?) -> Any')
        
        c2 = Callable([], [], [], Void(None), False)
        assert_equal(str(c2), 'def ()')
    
    def test_callable_type_with_default_args(self):
        c = Callable([self.x, self.y], [ARG_POS, ARG_OPT], [None, None],
                     AnyType(), False)
        assert_equal(str(c), 'def (X?, Y? =) -> Any')
        
        c2 = Callable([self.x, self.y], [ARG_OPT, ARG_OPT], [None, None],
                      AnyType(), False)
        assert_equal(str(c2), 'def (X? =, Y? =) -> Any')
    
    def test_callable_type_with_var_args(self):
        c = Callable([self.x], [ARG_STAR], [None], AnyType(), False)
        assert_equal(str(c), 'def (*X?) -> Any')
        
        c2 = Callable([self.x, self.y], [ARG_POS, ARG_STAR],
                      [None, None], AnyType(), False)
        assert_equal(str(c2), 'def (X?, *Y?) -> Any')
        
        c3 = Callable([self.x, self.y], [ARG_OPT, ARG_STAR], [None, None],
                      AnyType(), False)
        assert_equal(str(c3), 'def (X? =, *Y?) -> Any')
    
    def test_tuple_type(self):
        assert_equal(str(TupleType([])), 'Tuple[]')
        assert_equal(str(TupleType([self.x])), 'Tuple[X?]')
        assert_equal(str(TupleType([self.x, AnyType()])), 'Tuple[X?, Any]')
    
    def test_type_variable_binding(self):
        assert_equal(str(TypeVarDef('X', 1, None)), 'X')
        assert_equal(str(TypeVarDef('X', 1, [self.x, self.y])),
                     'X in (X?, Y?)')
    
    def test_generic_function_type(self):
        c = Callable([self.x, self.y], [ARG_POS, ARG_POS], [None, None],
                     self.y, False, None,
                     [TypeVarDef('X', -1, None)])
        assert_equal(str(c), 'def [X] (X?, Y?) -> Y?')
        
        v = [TypeVarDef('Y', -1, None), TypeVarDef('X', -2, None)]
        c2 = Callable([], [], [], Void(None), False, None, v)
        assert_equal(str(c2), 'def [Y, X] ()')


class TypeOpsSuite(Suite):
    def set_up(self):
        self.fx = TypeFixture()
    
    # expand_type
    
    def test_trivial_expand(self):
        for t in (self.fx.a, self.fx.o, self.fx.t, self.fx.void, self.fx.nonet,
                  self.tuple(self.fx.a),
                  self.callable([], self.fx.a, self.fx.a), self.fx.anyt):
            self.assert_expand(t, [], t)
            self.assert_expand(t, [], t)
            self.assert_expand(t, [], t)
    
    def test_expand_naked_type_var(self):
        self.assert_expand(self.fx.t, [(1, self.fx.a)], self.fx.a)
        self.assert_expand(self.fx.t, [(2, self.fx.a)], self.fx.t)
    
    def test_expand_basic_generic_types(self):
        self.assert_expand(self.fx.gt, [(1, self.fx.a)], self.fx.ga)
    
    # IDEA: Add test cases for
    #   tuple types
    #   callable types
    #   multiple arguments
    
    def assert_expand(self, orig, map_items, result):
        lower_bounds = {}
        
        for id, t in map_items:
            lower_bounds[id] = t
        
        exp = expand_type(orig, lower_bounds)
        # Remove erased tags (asterisks).
        assert_equal(str(exp).replace('*', ''), str(result))
    
    # replace_type_vars
    
    def test_trivial_replace(self):
        for t in (self.fx.a, self.fx.o, self.fx.void, self.fx.nonet,
                  self.tuple(self.fx.a),
                  self.callable([], self.fx.a, self.fx.a), self.fx.anyt,
                  self.fx.err):
            self.assert_replace(t, t)
    
    def test_replace_type_var(self):
        self.assert_replace(self.fx.t, self.fx.anyt)
    
    def test_replace_generic_instance(self):
        self.assert_replace(self.fx.ga, self.fx.ga)
        self.assert_replace(self.fx.gt, self.fx.gdyn)
    
    def assert_replace(self, orig, result):
        assert_equal(str(replace_type_vars(orig)), str(result))
    
    # erase_type
    
    def test_trivial_erase(self):
        for t in (self.fx.a, self.fx.o, self.fx.void, self.fx.nonet,
                  self.fx.anyt, self.fx.err):
            self.assert_erase(t, t)
    
    def test_erase_with_type_variable(self):
        self.assert_erase(self.fx.t, self.fx.anyt)
    
    def test_erase_with_generic_type(self):
        self.assert_erase(self.fx.ga, self.fx.gdyn)
        self.assert_erase(self.fx.hab,
                          Instance(self.fx.hi, [self.fx.anyt, self.fx.anyt]))
    
    def test_erase_with_tuple_type(self):
        self.assert_erase(self.tuple(self.fx.a), self.fx.std_tuple)
    
    def test_erase_with_function_type(self):
        self.assert_erase(self.fx.callable(self.fx.a, self.fx.b),
                          self.fx.callable_type(self.fx.void))
    
    def test_erase_with_type_object(self):
        self.assert_erase(self.fx.callable_type(self.fx.a, self.fx.b),
                          self.fx.callable_type(self.fx.void))
    
    def assert_erase(self, orig, result):
        assert_equal(str(erase_type(orig, self.fx.basic)), str(result))

    # is_more_precise

    def test_is_more_precise(self):
        fx = self.fx
        assert_true(is_more_precise(fx.b, fx.a))
        assert_true(is_more_precise(fx.b, fx.b))
        assert_true(is_more_precise(fx.b, fx.b))
        assert_true(is_more_precise(fx.b, fx.anyt))
        assert_true(is_more_precise(self.tuple(fx.b, fx.a),
                                    self.tuple(fx.b, fx.a)))
        
        assert_false(is_more_precise(fx.a, fx.b))
        assert_false(is_more_precise(fx.anyt, fx.b))
        assert_false(is_more_precise(self.tuple(fx.b, fx.b),
                                     self.tuple(fx.b, fx.a)))

    # is_proper_subtype

    def test_is_proper_subtype(self):
        fx = self.fx
        
        assert_true(is_proper_subtype(fx.a, fx.a))
        assert_true(is_proper_subtype(fx.b, fx.a))
        assert_true(is_proper_subtype(fx.b, fx.o))
        assert_true(is_proper_subtype(fx.b, fx.o))
        
        assert_false(is_proper_subtype(fx.a, fx.b))
        assert_false(is_proper_subtype(fx.o, fx.b))
        
        assert_true(is_proper_subtype(fx.anyt, fx.anyt))
        assert_false(is_proper_subtype(fx.a, fx.anyt))
        assert_false(is_proper_subtype(fx.anyt, fx.a))
        
        assert_true(is_proper_subtype(fx.ga, fx.ga))
        assert_true(is_proper_subtype(fx.gdyn, fx.gdyn))
        assert_true(is_proper_subtype(fx.gsab, fx.gb))
        assert_false(is_proper_subtype(fx.gsab, fx.ga))
        assert_false(is_proper_subtype(fx.gb, fx.ga))
        assert_false(is_proper_subtype(fx.ga, fx.gdyn))
        assert_false(is_proper_subtype(fx.gdyn, fx.ga))

        assert_true(is_proper_subtype(fx.t, fx.t))
        assert_false(is_proper_subtype(fx.t, fx.s))
    
    # Helpers
    
    def tuple(self, *a):
        return TupleType(a)
    
    def callable(self, vars, *a) -> Callable:
        """callable(args, a1, ..., an, r) constructs a callable with
        argument types a1, ... an and return type r and type arguments
        vars.
        """
        tv = [] # type: List[TypeVarDef]
        n = -1
        for v in vars:
            tv.append(TypeVarDef(v, n, None))
            n -= 1
        return Callable(a[:-1],
                        [ARG_POS] * (len(a) - 1),
                        [None] * (len(a) - 1),
                        a[-1],
                        False,
                        None,
                        tv)


class JoinSuite(Suite):
    def set_up(self):
        self.fx = TypeFixture()
    
    def test_trivial_cases(self):
        for simple in self.fx.void, self.fx.a, self.fx.o, self.fx.b:
            self.assert_join(simple, simple, simple)
    
    def test_class_subtyping(self):
        self.assert_join(self.fx.a, self.fx.o, self.fx.o)
        self.assert_join(self.fx.b, self.fx.o, self.fx.o)
        self.assert_join(self.fx.a, self.fx.d, self.fx.o)
        self.assert_join(self.fx.b, self.fx.c, self.fx.a)
        self.assert_join(self.fx.b, self.fx.d, self.fx.o)
    
    def test_tuples(self):
        self.assert_join(self.tuple(), self.tuple(), self.tuple())
        self.assert_join(self.tuple(self.fx.a),
                         self.tuple(self.fx.a),
                         self.tuple(self.fx.a))
        self.assert_join(self.tuple(self.fx.b, self.fx.c),
                         self.tuple(self.fx.a, self.fx.d),
                         self.tuple(self.fx.a, self.fx.o))
        
        self.assert_join(self.tuple(self.fx.a, self.fx.a),
                         self.fx.std_tuple,
                         self.fx.o)
        self.assert_join(self.tuple(self.fx.a),
                         self.tuple(self.fx.a, self.fx.a),
                         self.fx.o)
    
    def test_function_types(self):
        self.assert_join(self.callable(self.fx.a, self.fx.b),
                         self.callable(self.fx.a, self.fx.b),
                         self.callable(self.fx.a, self.fx.b))
        
        self.assert_join(self.callable(self.fx.a, self.fx.b),
                         self.callable(self.fx.b, self.fx.b),
                         self.fx.o)
        self.assert_join(self.callable(self.fx.a, self.fx.b),
                         self.callable(self.fx.a, self.fx.a),
                         self.fx.o)
    
    def test_type_vars(self):
        self.assert_join(self.fx.t, self.fx.t, self.fx.t)
        self.assert_join(self.fx.s, self.fx.s, self.fx.s)
        self.assert_join(self.fx.t, self.fx.s, self.fx.o)
    
    def test_void(self):
        self.assert_join(self.fx.void, self.fx.void, self.fx.void)
        self.assert_join(self.fx.void, self.fx.anyt, self.fx.anyt)
        
        # Join of any other type against void results in ErrorType, since there
        # is no other meaningful result.
        for t in [self.fx.a, self.fx.o, NoneTyp(), UnboundType('x'),
                  self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b)]:
            self.assert_join(t, self.fx.void, self.fx.err)
    
    def test_none(self):
        # Any type t joined with None results in t.
        for t in [NoneTyp(), self.fx.a, self.fx.o, UnboundType('x'),
                  self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b), self.fx.anyt]:
            self.assert_join(t, NoneTyp(), t)
    
    def test_unbound_type(self):
        self.assert_join(UnboundType('x'), UnboundType('x'), self.fx.anyt)
        self.assert_join(UnboundType('x'), UnboundType('y'), self.fx.anyt)
        
        # Any type t joined with an unbound type results in dynamic. Unbound
        # type means that there is an error somewhere in the program, so this
        # does not affect type safety (whatever the result).
        for t in [self.fx.a, self.fx.o, self.fx.ga, self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b)]:
            self.assert_join(t, UnboundType('X'), self.fx.anyt)
    
    def test_any_type(self):
        # Join against 'Any' type always results in 'Any'.
        for t in [self.fx.anyt, self.fx.a, self.fx.o, NoneTyp(),
                  UnboundType('x'), self.fx.void, self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b)]:
            self.assert_join(t, self.fx.anyt, self.fx.anyt)
    
    def test_other_mixed_types(self):
        # In general, joining unrelated types produces object.
        for t1 in [self.fx.a, self.fx.t, self.tuple(),
                   self.callable(self.fx.a, self.fx.b)]:
            for t2 in [self.fx.a, self.fx.t, self.tuple(),
                       self.callable(self.fx.a, self.fx.b)]:
                if str(t1) != str(t2):
                    self.assert_join(t1, t2, self.fx.o)
    
    def test_error_type(self):
        self.assert_join(self.fx.err, self.fx.anyt, self.fx.anyt)
        
        # Meet against any type except dynamic results in ErrorType.
        for t in [self.fx.a, self.fx.o, NoneTyp(), UnboundType('x'),
                  self.fx.void, self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b)]:
            self.assert_join(t, self.fx.err, self.fx.err)
    
    def test_simple_generics(self):
        self.assert_join(self.fx.ga, self.fx.ga, self.fx.ga)
        self.assert_join(self.fx.ga, self.fx.gb, self.fx.o)
        self.assert_join(self.fx.ga, self.fx.g2a, self.fx.o)
        
        self.assert_join(self.fx.ga, self.fx.nonet, self.fx.ga)
        self.assert_join(self.fx.ga, self.fx.anyt, self.fx.anyt)
        
        for t in [self.fx.a, self.fx.o, self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b)]:
            self.assert_join(t, self.fx.ga, self.fx.o)
    
    def test_generics_with_multiple_args(self):
        self.assert_join(self.fx.hab, self.fx.hab, self.fx.hab)
        self.assert_join(self.fx.hab, self.fx.haa, self.fx.o)
        self.assert_join(self.fx.hab, self.fx.hbb, self.fx.o)
    
    def test_generics_with_inheritance(self):
        self.assert_join(self.fx.gsab, self.fx.gb, self.fx.gb)
        self.assert_join(self.fx.gsba, self.fx.gb, self.fx.o)
    
    def test_generics_with_inheritance_and_shared_supertype(self):
        self.assert_join(self.fx.gsba, self.fx.gs2a, self.fx.ga)
        self.assert_join(self.fx.gsab, self.fx.gs2a, self.fx.o)
    
    def test_generic_types_and_any(self):
        self.assert_join(self.fx.gdyn, self.fx.ga, self.fx.gdyn)
    
    def test_callables_with_any(self):
        self.assert_join(self.callable(self.fx.a, self.fx.a, self.fx.anyt,
                                       self.fx.a),
                         self.callable(self.fx.a, self.fx.anyt, self.fx.a,
                                       self.fx.anyt),
                         self.callable(self.fx.a, self.fx.anyt, self.fx.anyt,
                                       self.fx.anyt))
    
    def test_join_interface_types(self):
        self.skip() # FIX
        self.assert_join(self.fx.f, self.fx.f, self.fx.f)
        self.assert_join(self.fx.f, self.fx.f2, self.fx.o)
        self.assert_join(self.fx.f, self.fx.f3, self.fx.f)
    
    def test_join_interface_and_class_types(self):
        self.skip() # FIX
        
        self.assert_join(self.fx.o, self.fx.f, self.fx.o)
        self.assert_join(self.fx.a, self.fx.f, self.fx.o)
        
        self.assert_join(self.fx.e, self.fx.f, self.fx.f)
    
    def test_join_class_types_with_interface_result(self):
        self.skip() # FIX
        # Unique result
        self.assert_join(self.fx.e, self.fx.e2, self.fx.f)
        
        # Ambiguous result
        self.assert_join(self.fx.e2, self.fx.e3, self.fx.err)
    
    def test_generic_interfaces(self):
        self.skip() # FIX
        
        fx = InterfaceTypeFixture()
        
        self.assert_join(fx.gfa, fx.gfa, fx.gfa)
        self.assert_join(fx.gfa, fx.gfb, fx.o)
        
        self.assert_join(fx.m1, fx.gfa, fx.gfa)
        
        self.assert_join(fx.m1, fx.gfb, fx.o)
    
    def test_simple_type_objects(self):
        t1 = self.type_callable(self.fx.a, self.fx.a)
        t2 = self.type_callable(self.fx.b, self.fx.b)
        
        self.assert_join(t1, t1, t1)
        assert_true(join_types(t1, t1, self.fx.basic).is_type_obj())
        
        self.assert_join(t1, t2, self.fx.type_type)
        self.assert_join(t1, self.fx.type_type, self.fx.type_type)
        self.assert_join(self.fx.type_type, self.fx.type_type,
                         self.fx.type_type)
    
    # There are additional test cases in check-inference.test.
    
    # FIX interfaces with different paths
    
    # FIX generic interfaces + inheritance
    # FIX generic interfaces + ranges
    
    # FIX function types + varargs and default args
    
    def assert_join(self, s, t, join):
        self.assert_simple_join(s, t, join)
        self.assert_simple_join(t, s, join)
    
    def assert_simple_join(self, s, t, join):
        result = join_types(s, t, self.fx.basic)
        actual = str(result)
        expected = str(join)
        assert_equal(actual, expected,
                     'join({}, {}) == {{}} ({{}} expected)'.format(s, t))
        if not isinstance(s, ErrorType) and not isinstance(result, ErrorType):
            assert_true(is_subtype(s, result),
                        '{} not subtype of {}'.format(s, result))
        if not isinstance(t, ErrorType) and not isinstance(result, ErrorType):
            assert_true(is_subtype(t, result),
                        '{} not subtype of {}'.format(t, result))
    
    def tuple(self, *a):
        return TupleType(a)
    
    def callable(self, *a):
        """callable(a1, ..., an, r) constructs a callable with argument types
        a1, ... an and return type r.
        """
        n = len(a) - 1
        return Callable(a[:-1], [ARG_POS] * n, [None] * n,
                        a[-1], False)
    
    def type_callable(self, *a):
        """type_callable(a1, ..., an, r) constructs a callable with
        argument types a1, ... an and return type r, and which
        represents a type.
        """
        n = len(a) - 1
        return Callable(a[:-1], [ARG_POS] * n, [None] * n,
                        a[-1], True)


class MeetSuite(Suite):
    def set_up(self):
        self.fx = TypeFixture()
    
    def test_trivial_cases(self):
        for simple in self.fx.void, self.fx.a, self.fx.o, self.fx.b:
            self.assert_meet(simple, simple, simple)
    
    def test_class_subtyping(self):
        self.assert_meet(self.fx.a, self.fx.o, self.fx.a)
        self.assert_meet(self.fx.a, self.fx.b, self.fx.b)
        self.assert_meet(self.fx.b, self.fx.o, self.fx.b)
        self.assert_meet(self.fx.a, self.fx.d, NoneTyp())
        self.assert_meet(self.fx.b, self.fx.c, NoneTyp())
    
    def test_tuples(self):
        self.assert_meet(self.tuple(), self.tuple(), self.tuple())
        self.assert_meet(self.tuple(self.fx.a),
                         self.tuple(self.fx.a),
                         self.tuple(self.fx.a))
        self.assert_meet(self.tuple(self.fx.b, self.fx.c),
                         self.tuple(self.fx.a, self.fx.d),
                         self.tuple(self.fx.b, NoneTyp()))
        
        self.assert_meet(self.tuple(self.fx.a, self.fx.a),
                         self.fx.std_tuple,
                         NoneTyp())
        self.assert_meet(self.tuple(self.fx.a),
                         self.tuple(self.fx.a, self.fx.a),
                         NoneTyp())
    
    def test_function_types(self):
        self.assert_meet(self.callable(self.fx.a, self.fx.b),
                         self.callable(self.fx.a, self.fx.b),
                         self.callable(self.fx.a, self.fx.b))
        
        self.assert_meet(self.callable(self.fx.a, self.fx.b),
                         self.callable(self.fx.b, self.fx.b),
                         NoneTyp())
        self.assert_meet(self.callable(self.fx.a, self.fx.b),
                         self.callable(self.fx.a, self.fx.a),
                         NoneTyp())
    
    def test_type_vars(self):
        self.assert_meet(self.fx.t, self.fx.t, self.fx.t)
        self.assert_meet(self.fx.s, self.fx.s, self.fx.s)
        self.assert_meet(self.fx.t, self.fx.s, NoneTyp())
    
    def test_void(self):
        self.assert_meet(self.fx.void, self.fx.void, self.fx.void)
        self.assert_meet(self.fx.void, self.fx.anyt, self.fx.anyt)
        
        # Meet of any other type against void results in ErrorType, since there
        # is no meaningful valid result.
        for t in [self.fx.a, self.fx.o, UnboundType('x'), NoneTyp(),
                  self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b)]:
            self.assert_meet(t, self.fx.void, self.fx.err)
    
    def test_none(self):
        self.assert_meet(NoneTyp(), NoneTyp(), NoneTyp())
        
        self.assert_meet(NoneTyp(), self.fx.anyt, self.fx.anyt)
        self.assert_meet(NoneTyp(), self.fx.void, self.fx.err)
        
        # Any type t joined with None results in None, unless t is any or
        # void.
        for t in [self.fx.a, self.fx.o, UnboundType('x'), self.fx.t,
                  self.tuple(), self.callable(self.fx.a, self.fx.b)]:
            self.assert_meet(t, NoneTyp(), NoneTyp())
    
    def test_unbound_type(self):
        self.assert_meet(UnboundType('x'), UnboundType('x'), self.fx.anyt)
        self.assert_meet(UnboundType('x'), UnboundType('y'), self.fx.anyt)
        
        self.assert_meet(UnboundType('x'), self.fx.void, self.fx.err)
        
        # The meet of any type t with an unbound type results in dynamic
        # (except for void). Unbound type means that there is an error
        # somewhere in the program, so this does not affect type safety.
        for t in [self.fx.anyt, self.fx.a, self.fx.o, self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b)]:
            self.assert_meet(t, UnboundType('X'), self.fx.anyt)
    
    def test_dynamic_type(self):
        # Meet against dynamic type always results in dynamic.
        for t in [self.fx.anyt, self.fx.a, self.fx.o, NoneTyp(),
                  UnboundType('x'), self.fx.void, self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b)]:
            self.assert_meet(t, self.fx.anyt, self.fx.anyt)
    
    def test_error_type(self):
        self.assert_meet(self.fx.err, self.fx.anyt, self.fx.anyt)
        
        # Meet against any type except dynamic results in ErrorType.
        for t in [self.fx.a, self.fx.o, NoneTyp(), UnboundType('x'),
                  self.fx.void, self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b)]:
            self.assert_meet(t, self.fx.err, self.fx.err)
    
    def test_simple_generics(self):
        self.assert_meet(self.fx.ga, self.fx.ga, self.fx.ga)
        self.assert_meet(self.fx.ga, self.fx.o, self.fx.ga)
        self.assert_meet(self.fx.ga, self.fx.gb, self.fx.nonet)
        self.assert_meet(self.fx.ga, self.fx.g2a, self.fx.nonet)
        
        self.assert_meet(self.fx.ga, self.fx.nonet, self.fx.nonet)
        self.assert_meet(self.fx.ga, self.fx.anyt, self.fx.anyt)
        
        for t in [self.fx.a, self.fx.t, self.tuple(),
                  self.callable(self.fx.a, self.fx.b)]:
            self.assert_meet(t, self.fx.ga, self.fx.nonet)
    
    def test_generics_with_multiple_args(self):
        self.assert_meet(self.fx.hab, self.fx.hab, self.fx.hab)
        self.assert_meet(self.fx.hab, self.fx.haa, self.fx.nonet)
        self.assert_meet(self.fx.hab, self.fx.hbb, self.fx.nonet)
    
    def test_generics_with_inheritance(self):
        self.assert_meet(self.fx.gsab, self.fx.gb, self.fx.gsab)
        self.assert_meet(self.fx.gsba, self.fx.gb, self.fx.nonet)
    
    def test_generics_with_inheritance_and_shared_supertype(self):
        self.assert_meet(self.fx.gsba, self.fx.gs2a, self.fx.nonet)
        self.assert_meet(self.fx.gsab, self.fx.gs2a, self.fx.nonet)
    
    def test_generic_types_and_dynamic(self):
        self.assert_meet(self.fx.gdyn, self.fx.ga, self.fx.gdyn)
    
    def test_callables_with_dynamic(self):
        self.assert_meet(self.callable(self.fx.a, self.fx.a, self.fx.anyt,
                                       self.fx.a),
                         self.callable(self.fx.a, self.fx.anyt, self.fx.a,
                                       self.fx.anyt),
                         self.callable(self.fx.a, self.fx.anyt, self.fx.anyt,
                                       self.fx.anyt))
    
    def test_meet_interface_types(self):
        self.assert_meet(self.fx.f, self.fx.f, self.fx.f)
        self.assert_meet(self.fx.f, self.fx.f2, self.fx.nonet)
        self.assert_meet(self.fx.f, self.fx.f3, self.fx.f3)
    
    def test_join_interface_and_class_types(self):
        self.assert_meet(self.fx.o, self.fx.f, self.fx.f)
        self.assert_meet(self.fx.a, self.fx.f, self.fx.nonet)
        
        self.assert_meet(self.fx.e, self.fx.f, self.fx.e)
    
    def test_join_class_types_with_shared_interfaces(self):
        # These have nothing special with respect to meets, unlike joins. These
        # are for completeness only.
        self.assert_meet(self.fx.e, self.fx.e2, self.fx.nonet)
        self.assert_meet(self.fx.e2, self.fx.e3, self.fx.nonet)
    
    def test_meet_with_generic_interfaces(self):
        # TODO fix
        self.skip()
        
        fx = InterfaceTypeFixture()
        self.assert_meet(fx.gfa, fx.m1, fx.m1)
        self.assert_meet(fx.gfa, fx.gfa, fx.gfa)
        self.assert_meet(fx.gfb, fx.m1, fx.nonet)
    
    # FIX generic interfaces + ranges
    
    def assert_meet(self, s, t, meet):
        self.assert_simple_meet(s, t, meet)
        self.assert_simple_meet(t, s, meet)
    
    def assert_simple_meet(self, s, t, meet):
        result = meet_types(s, t, self.fx.basic)
        actual = str(result)
        expected = str(meet)
        assert_equal(actual, expected,
                     'meet({}, {}) == {{}} ({{}} expected)'.format(s, t))
        if not isinstance(s, ErrorType) and not isinstance(result, ErrorType):
            assert_true(is_subtype(result, s),
                        '{} not subtype of {}'.format(result, s))
        if not isinstance(t, ErrorType) and not isinstance(result, ErrorType):
            assert_true(is_subtype(result, t),
                        '{} not subtype of {}'.format(result, t))
    
    def tuple(self, *a):
        return TupleType(a)
    
    def callable(self, *a):
        """callable(a1, ..., an, r) constructs a callable with argument types
        a1, ... an and return type r.
        """
        n = len(a) - 1
        return Callable(a[:-1],
                        [ARG_POS] * n, [None] * n,
                        a[-1], False)


class CombinedTypesSuite(Suite):
    def __init__(self):
        self.test_types = TypesSuite()
        self.test_type_ops = TypeOpsSuite()
        self.test_join = JoinSuite()
        self.test_meet = MeetSuite()
        super().__init__()


if __name__ == '__main__':
    import sys
    run_test(CombinedTypesSuite(), sys.argv[1:])

########NEW FILE########
__FILENAME__ = transform
"""Transform program to include explicit coercions and wrappers.

The transform performs these main changes:

 - add explicit coercions to/from any (or more generally, between different
   levels of typing precision)
 - add wrapper methods and functions for calling statically typed functions
   in dynamically typed code
 - add wrapper methods for overrides with a different signature
 - add generic wrapper classes for coercions between generic types (e.g.
   from List[Any] to List[str])
"""

from typing import Undefined, Dict, List, Tuple, cast

from mypy.nodes import (
    Node, MypyFile, TypeInfo, ClassDef, VarDef, FuncDef, Var,
    ReturnStmt, AssignmentStmt, IfStmt, WhileStmt, MemberExpr, NameExpr, MDEF,
    CallExpr, SuperExpr, TypeExpr, CastExpr, OpExpr, CoerceExpr, GDEF,
    SymbolTableNode, IndexExpr, function_type
)
from mypy.traverser import TraverserVisitor
from mypy.types import Type, AnyType, Callable, TypeVarDef, Instance
from mypy.lex import Token
from mypy.transformtype import TypeTransformer
from mypy.transutil import (
    prepend_arg_type, is_simple_override, tvar_arg_name, dynamic_suffix,
    add_arg_type_after_self
)
from mypy.coerce import coerce
from mypy.rttypevars import translate_runtime_type_vars_in_context


class DyncheckTransformVisitor(TraverserVisitor):
    """Translate a parse tree to use runtime representation of generics.

    Translate generic type variables to ordinary variables and all make
    all non-trivial coercions explicit. Also generate generic wrapper classes
    for coercions between generic types and wrapper methods for overrides
    and for more efficient access from dynamically typed code.
    
    This visitor modifies the parse tree in-place.
    """

    type_map = Undefined(Dict[Node, Type])
    modules = Undefined(Dict[str, MypyFile])
    is_pretty = False
    type_tf = Undefined(TypeTransformer)
    
    # Stack of function return types
    return_types = Undefined(List[Type])
    # Stack of dynamically typed function flags
    dynamic_funcs = Undefined(List[bool])
    
    # Associate a Node with its start end line numbers.
    line_map = Undefined(Dict[Node, Tuple[int, int]])
    
    is_java = False
    
    # The current type context (or None if not within a type).
    _type_context = None # type: TypeInfo
    
    def type_context(self) -> TypeInfo:
        return self._type_context
    
    def __init__(self, type_map: Dict[Node, Type],
                 modules: Dict[str, MypyFile], is_pretty: bool,
                 is_java: bool = False) -> None:
        self.type_tf = TypeTransformer(self)
        self.return_types = []
        self.dynamic_funcs = [False]
        self.line_map = {}
        self.type_map = type_map
        self.modules = modules
        self.is_pretty = is_pretty
        self.is_java = is_java
    
    #
    # Transform definitions
    #
    
    def visit_mypy_file(self, o: MypyFile) -> None:
        """Transform an file."""
        res = [] # type: List[Node]
        for d in o.defs:
            if isinstance(d, ClassDef):
                self._type_context = d.info
                res.extend(self.type_tf.transform_class_def(d))
                self._type_context = None
            else:
                d.accept(self)
                res.append(d)
        o.defs = res
    
    def visit_var_def(self, o: VarDef) -> None:
        """Transform a variable definition in-place.

        This is not suitable for member variable definitions; they are
        transformed in TypeTransformer.
        """
        super().visit_var_def(o)
        
        if o.init is not None:
            if o.items[0].type:
                t = o.items[0].type
            else:
                t = AnyType()
            o.init = self.coerce(o.init, t, self.get_type(o.init),
                                 self.type_context())
    
    def visit_func_def(self, fdef: FuncDef) -> None:
        """Transform a global function definition in-place.

        This is not suitable for methods; they are transformed in
        FuncTransformer.
        """
        self.prepend_generic_function_tvar_args(fdef)
        self.transform_function_body(fdef)
    
    def transform_function_body(self, fdef: FuncDef) -> None:
        """Transform the body of a function."""
        self.dynamic_funcs.append(fdef.is_implicit)
        # FIX overloads
        self.return_types.append(cast(Callable, function_type(fdef)).ret_type)
        super().visit_func_def(fdef)
        self.return_types.pop()
        self.dynamic_funcs.pop()
    
    def prepend_generic_function_tvar_args(self, fdef: FuncDef) -> None:
        """Add implicit function type variable arguments if fdef is generic."""
        sig = cast(Callable, function_type(fdef))
        tvars = sig.variables
        if not fdef.type:
            fdef.type = sig
        
        tv = [] # type: List[Var]
        ntvars = len(tvars)
        if fdef.is_method():
            # For methods, add type variable arguments after the self arg.
            for n in range(ntvars):
                tv.append(Var(tvar_arg_name(-1 - n)))
                fdef.type = add_arg_type_after_self(cast(Callable, fdef.type),
                                                    AnyType())
            fdef.args = [fdef.args[0]] + tv + fdef.args[1:]
        else:
            # For ordinary functions, prepend type variable arguments.
            for n in range(ntvars):
                tv.append(Var(tvar_arg_name(-1 - n)))
                fdef.type = prepend_arg_type(cast(Callable, fdef.type),
                                             AnyType())
            fdef.args = tv + fdef.args
        fdef.init = List[AssignmentStmt]([None]) * ntvars + fdef.init
    
    #
    # Transform statements
    #    
    
    def transform_block(self, block: List[Node]) -> None:
        for stmt in block:
            stmt.accept(self)
    
    def visit_return_stmt(self, s: ReturnStmt) -> None:
        super().visit_return_stmt(s)
        s.expr = self.coerce(s.expr, self.return_types[-1],
                             self.get_type(s.expr), self.type_context())
    
    def visit_assignment_stmt(self, s: AssignmentStmt) -> None:
        super().visit_assignment_stmt(s)
        if isinstance(s.lvalues[0], IndexExpr):
            index = cast(IndexExpr, s.lvalues[0])
            method_type = index.method_type
            if self.dynamic_funcs[-1] or isinstance(method_type, AnyType):
                lvalue_type = AnyType() # type: Type
            else:
                method_callable = cast(Callable, method_type)
                # TODO arg_types[1] may not be reliable
                lvalue_type = method_callable.arg_types[1]
        else:
            lvalue_type = self.get_type(s.lvalues[0])
            
        s.rvalue = self.coerce2(s.rvalue, lvalue_type, self.get_type(s.rvalue),
                                self.type_context())
    
    #
    # Transform expressions
    #
    
    def visit_member_expr(self, e: MemberExpr) -> None:
        super().visit_member_expr(e)
        
        typ = self.get_type(e.expr)
        
        if self.dynamic_funcs[-1]:
            e.expr = self.coerce_to_dynamic(e.expr, typ, self.type_context())
            typ = AnyType()
        
        if isinstance(typ, Instance):
            # Reference to a statically-typed method variant with the suffix
            # derived from the base object type.
            suffix = self.get_member_reference_suffix(e.name, typ.type)
        else:
            # Reference to a dynamically-typed method variant.
            suffix = self.dynamic_suffix()
        e.name += suffix
    
    def visit_name_expr(self, e: NameExpr) -> None:
        super().visit_name_expr(e)
        if e.kind == MDEF and isinstance(e.node, FuncDef):
            # Translate reference to a method.
            suffix = self.get_member_reference_suffix(e.name, e.info)
            e.name += suffix
            # Update representation to have the correct name.
            prefix = e.repr.components[0].pre
    
    def get_member_reference_suffix(self, name: str, info: TypeInfo) -> str:
        if info.has_method(name):
            fdef = cast(FuncDef, info.get_method(name))
            return self.type_suffix(fdef)
        else:
            return ''
    
    def visit_call_expr(self, e: CallExpr) -> None:
        if e.analyzed:
            # This is not an ordinary call.
            e.analyzed.accept(self)
            return
        
        super().visit_call_expr(e)
        
        # Do no coercions if this is a call to debugging facilities.
        if self.is_debugging_call_expr(e):
            return

        # Get the type of the callable (type variables in the context of the
        # enclosing class).
        ctype = self.get_type(e.callee)

        # Add coercions for the arguments.
        for i in range(len(e.args)):
            arg_type = AnyType() # type: Type
            if isinstance(ctype, Callable):
                arg_type = ctype.arg_types[i]
            e.args[i] = self.coerce2(e.args[i], arg_type,
                                     self.get_type(e.args[i]),
                                     self.type_context())
        
        # Prepend type argument values to the call as needed.
        if isinstance(ctype, Callable) and cast(Callable,
                                                ctype).bound_vars != []:
            bound_vars = (cast(Callable, ctype)).bound_vars

            # If this is a constructor call (target is the constructor
            # of a generic type or superclass __init__), include also
            # instance type variables.  Otherwise filter them away --
            # include only generic function type variables.
            if (not (cast(Callable, ctype)).is_type_obj() and
                    not (isinstance(e.callee, SuperExpr) and
                         (cast(SuperExpr, e.callee)).name == '__init__')):
                # Filter instance type variables; only include function tvars.
                bound_vars = [(id, t) for id, t in bound_vars if id < 0]
            
            args = [] # type: List[Node]
            for i in range(len(bound_vars)):
                # Compile type variables to runtime type variable expressions.
                tv = translate_runtime_type_vars_in_context(
                    bound_vars[i][1],
                    self.type_context(),
                    self.is_java)
                args.append(TypeExpr(tv))
            e.args = args + e.args
    
    def is_debugging_call_expr(self, e):
        return isinstance(e.callee, NameExpr) and e.callee.name in ['__print']
    
    def visit_cast_expr(self, e: CastExpr) -> None:
        super().visit_cast_expr(e)
        if isinstance(self.get_type(e), AnyType):
            e.expr = self.coerce(e.expr, AnyType(), self.get_type(e.expr),
                                 self.type_context())
    
    def visit_op_expr(self, e: OpExpr) -> None:
        super().visit_op_expr(e)
        if e.op in ['and', 'or']:
            target = self.get_type(e)
            e.left = self.coerce(e.left, target,
                                 self.get_type(e.left), self.type_context())
            e.right = self.coerce(e.right, target,
                                  self.get_type(e.right), self.type_context())
        else:
            method_type = e.method_type
            if self.dynamic_funcs[-1] or isinstance(method_type, AnyType):
                e.left = self.coerce_to_dynamic(e.left, self.get_type(e.left),
                                                self.type_context())
                e.right = self.coerce(e.right, AnyType(),
                                      self.get_type(e.right),
                                      self.type_context())
            elif method_type:
                method_callable = cast(Callable, method_type)
                operand = e.right
                # For 'in', the order of operands is reversed.
                if e.op == 'in':
                    operand = e.left
                # TODO arg_types[0] may not be reliable
                operand = self.coerce(operand, method_callable.arg_types[0],
                                      self.get_type(operand),
                                      self.type_context())
                if e.op == 'in':
                    e.left = operand
                else:
                    e.right = operand

    def visit_index_expr(self, e: IndexExpr) -> None:
        if e.analyzed:
            # Actually a type application, not indexing.
            e.analyzed.accept(self)
            return
        super().visit_index_expr(e)
        method_type = e.method_type
        if self.dynamic_funcs[-1] or isinstance(method_type, AnyType):
            e.base = self.coerce_to_dynamic(e.base, self.get_type(e.base),
                                            self.type_context())
            e.index = self.coerce_to_dynamic(e.index, self.get_type(e.index),
                                             self.type_context())
        else:
            method_callable = cast(Callable, method_type)
            e.index = self.coerce(e.index, method_callable.arg_types[0],
                                  self.get_type(e.index), self.type_context())
    
    #
    # Helpers
    #    
    
    def get_type(self, node: Node) -> Type:
        """Return the type of a node as reported by the type checker."""
        return self.type_map[node]
    
    def set_type(self, node: Node, typ: Type) -> None:
        self.type_map[node] = typ
    
    def type_suffix(self, fdef: FuncDef, info: TypeInfo = None) -> str:
        """Return the suffix for a mangled name.

        This includes an optional type suffix for a function or method.
        """
        if not info:
            info = fdef.info
        # If info is None, we have a global function => no suffix. Also if the
        # method is not an override, we need no suffix.
        if not info or (not info.bases or
                        not info.bases[0].type.has_method(fdef.name())):
            return ''
        elif is_simple_override(fdef, info):
            return self.type_suffix(fdef, info.bases[0].type)
        elif self.is_pretty:
            return '`' + info.name()
        else:
            return '__' + info.name()
    
    def dynamic_suffix(self) -> str:
        """Return the suffix of the dynamic wrapper of a method or class."""
        return dynamic_suffix(self.is_pretty)
    
    def wrapper_class_suffix(self) -> str:
        """Return the suffix of a generic wrapper class."""
        return '**'
    
    def coerce(self, expr: Node, target_type: Type, source_type: Type,
               context: TypeInfo, is_wrapper_class: bool = False) -> Node:
        return coerce(expr, target_type, source_type, context,
                      is_wrapper_class, self.is_java)
    
    def coerce2(self, expr: Node, target_type: Type, source_type: Type,
                context: TypeInfo, is_wrapper_class: bool = False) -> Node:
        """Create coercion from source_type to target_type.

        Also include middle coercion do 'Any' if transforming a dynamically
        typed function.
        """
        if self.dynamic_funcs[-1]:
            return self.coerce(self.coerce(expr, AnyType(), source_type,
                                           context, is_wrapper_class),
                               target_type, AnyType(), context,
                               is_wrapper_class)
        else:
            return self.coerce(expr, target_type, source_type, context,
                               is_wrapper_class)
    
    def coerce_to_dynamic(self, expr: Node, source_type: Type,
                          context: TypeInfo) -> Node:
        if isinstance(source_type, AnyType):
            return expr
        source_type = translate_runtime_type_vars_in_context(
            source_type, context, self.is_java)
        return CoerceExpr(expr, AnyType(), source_type, False)
    
    def add_line_mapping(self, orig_node: Node, new_node: Node) -> None:
        """Add a line mapping for a wrapper.

        The node new_node has logically the same line numbers as
        orig_node. The nodes should be FuncDef/ClassDef nodes.
        """
        if orig_node.repr:
            start_line = orig_node.line
            end_line = start_line # TODO use real end line
            self.line_map[new_node] = (start_line, end_line)
    
    def named_type(self, name: str) -> Instance:
        # TODO combine with checker
        # Assume that the name refers to a type.
        sym = self.lookup(name, GDEF)
        return Instance(cast(TypeInfo, sym.node), [])
    
    def lookup(self, fullname: str, kind: int) -> SymbolTableNode:
        # TODO combine with checker
        # TODO remove kind argument
        parts = fullname.split('.')
        n = self.modules[parts[0]]
        for i in range(1, len(parts) - 1):
            n = cast(MypyFile, ((n.names.get(parts[i], None).node)))
        return n.names[parts[-1]]
    
    def object_member_name(self) -> str:
        if self.is_java:
            return '__o_{}'.format(self.type_context().name())
        else:
            return '__o'

########NEW FILE########
__FILENAME__ = transformfunc
"""Transform functions for runtime type checking."""

from typing import Undefined, List, Tuple, cast

from mypy.nodes import (
    FuncDef, Var, Node, Block, TypeInfo, NameExpr, MemberExpr,
    CallExpr, ReturnStmt, ExpressionStmt, TypeExpr, function_type, VarDef
)
from mypy import nodes
from mypy.checker import map_type_from_supertype
from mypy.types import Callable, AnyType, Void, RuntimeTypeVar, Type
from mypy.replacetvars import replace_type_vars
import mypy.transform
from mypy.transutil import (
    is_simple_override, tvar_arg_name, self_expr, dynamic_sig, is_generic,
    add_arg_type_after_self, translate_type_vars_to_bound_vars,
    translate_function_type_vars_to_dynamic, replace_ret_type,
    translate_type_vars_to_wrapper_vars,
    translate_type_vars_to_wrapped_object_vars
)
from mypy.erasetype import erase_generic_types


# TODO
#  - overloads
#  - generate semantic analysis info during transform (e.g.
#    transformMethodImplementation, Var constructors, NameExpr)


class FuncTransformer:
    """Transform methods for runtime type checking.
    
    This is used by DyncheckTransformVisitor and TypeTransformer is logically
    forms a single unit with these classes.
    """
    
    # Used for common transformation operations.
    tf = Undefined('mypy.transform.DyncheckTransformVisitor')
    
    def __init__(self, tf: 'mypy.transform.DyncheckTransformVisitor') -> None:
        self.tf = tf
    
    def transform_method(self, fdef: FuncDef) -> List[FuncDef]:
        """Transform a method.

        The result is one or more methods.
        """
        # Transform the body of the method.
        self.tf.transform_function_body(fdef)
        
        res = Undefined # type: List[FuncDef]
        
        if fdef.is_constructor():
            # The method is a constructor. Constructors are transformed to one
            # method.
            res = [self.transform_method_implementation(fdef, fdef.name())]
        else:
            # Normal methods are transformed to 1-3 variants. The
            # first is the main implementation of the method, and the
            # second is the dynamically-typed wrapper. The third
            # variant is for method overrides, and represents the
            # overridden supertype method.
            
            res = [self.transform_method_implementation(
                fdef, fdef.name() + self.tf.type_suffix(fdef))]
            
            if fdef.info.bases and fdef.info.mro[1].has_method(fdef.name()):
                # Override.
                # TODO do not assume single inheritance
                
                # Is is an override with a different signature? For
                # trivial overrides we can inherit wrappers.
                if not is_simple_override(fdef, fdef.info):
                    # Create a wrapper for overridden superclass method.
                    res.append(self.override_method_wrapper(fdef))
                    # Create a dynamically-typed method wrapper.
                    res.append(self.dynamic_method_wrapper(fdef))
            else:
                # Not an override.
                
                # Create a dynamically-typed method wrapper.
                res.append(self.dynamic_method_wrapper(fdef))
        
        return res
    
    def transform_method_implementation(self, fdef: FuncDef,
                                        name: str) -> FuncDef:
        """Transform the implementation of a method (i.e. unwrapped)."""
        args = fdef.args
        arg_kinds = fdef.arg_kinds
        
        typ = function_type(fdef) # type: Type
        init = fdef.init_expressions()
        
        if fdef.name() == '__init__' and is_generic(fdef):
            args, arg_kinds, init, typ = self.add_constructor_tvar_args(
                fdef, typ, args, arg_kinds, init)
        
        fdef2 = FuncDef(name, args, arg_kinds, init, fdef.body, typ)
        fdef2.info = fdef.info
        
        self.tf.prepend_generic_function_tvar_args(fdef2)
        
        return fdef2
    
    def add_constructor_tvar_args(
            self, fdef: FuncDef, typ: Type,
            args: List[Var], arg_kinds: List[int], 
            init: List[Node]) -> Tuple[List[Var], List[int], List[Node], Type]:
        """Add type variable arguments for __init__ of a generic type.

        Return tuple (new args, new kinds, new inits).
        """
        tv = [] # type: List[Var]
        ntvars = len(fdef.info.type_vars)
        for n in range(ntvars):
            tv.append(Var(tvar_arg_name(n + 1)))
            typ = add_arg_type_after_self(cast(Callable, typ), AnyType())
        args = [args[0]] + tv + args[1:]
        arg_kinds = [arg_kinds[0]] + [nodes.ARG_POS] * ntvars + arg_kinds[1:]
        init = List[Node]([None]) * ntvars + init
        return (args, arg_kinds, init, typ)
    
    def override_method_wrapper(self, fdef: FuncDef) -> FuncDef:
        """Construct a method wrapper for an overridden method."""
        orig_fdef = fdef.info.mro[1].get_method(fdef.name())
        return self.method_wrapper(cast(FuncDef, orig_fdef), fdef, False,
                                   False)
    
    def dynamic_method_wrapper(self, fdef: FuncDef) -> FuncDef:
        """Construct a dynamically typed method wrapper."""
        return self.method_wrapper(fdef, fdef, True, False)
    
    def generic_method_wrappers(self, fdef: FuncDef) -> List[Node]:
        """Construct wrapper class methods for a method of a generic class."""
        return [self.generic_static_method_wrapper(fdef),
                self.generic_dynamic_method_wrapper(fdef)]
    
    def generic_static_method_wrapper(self, fdef: FuncDef) -> FuncDef:
        """Construct statically typed wrapper class method."""
        return self.method_wrapper(fdef, fdef, False, True)
    
    def generic_dynamic_method_wrapper(self, fdef: FuncDef) -> FuncDef:
        """Construct dynamically-typed wrapper class method."""
        return self.method_wrapper(fdef, fdef, True, True)
    
    def method_wrapper(self, act_as_func_def: FuncDef,
                       target_func_def: FuncDef, is_dynamic: bool,
                       is_wrapper_class: bool) -> FuncDef:
        """Construct a method wrapper.

        It acts as a specific method (with the same signature), coerces
        arguments, calls the target method and finally coerces the return
        value.
        """
        is_override = act_as_func_def.info != target_func_def.info
        
        # Determine suffixes.
        target_suffix = self.tf.type_suffix(target_func_def)
        wrapper_suffix = self.get_wrapper_suffix(act_as_func_def, is_dynamic)
        
        # Determine function signatures.
        target_sig = self.get_target_sig(act_as_func_def, target_func_def,
                                         is_dynamic, is_wrapper_class)
        wrapper_sig = self.get_wrapper_sig(act_as_func_def, is_dynamic)
        call_sig = self.get_call_sig(act_as_func_def, target_func_def.info,
                                     is_dynamic, is_wrapper_class, is_override)
        
        if is_wrapper_class:
            bound_sig = cast(Callable,
                             translate_type_vars_to_bound_vars(target_sig))
        else:
            bound_sig = None
        
        call_stmt = self.call_wrapper(act_as_func_def, is_dynamic,
                                      is_wrapper_class, target_sig, call_sig,
                                      target_suffix, bound_sig)
        
        wrapper_args = self.get_wrapper_args(act_as_func_def, is_dynamic)    
        wrapper_func_def = FuncDef(act_as_func_def.name() + wrapper_suffix,
                                   wrapper_args,
                                   act_as_func_def.arg_kinds,
                                   [None] * len(wrapper_args),
                                   Block([call_stmt]),
                                   wrapper_sig)
        
        self.tf.add_line_mapping(target_func_def, wrapper_func_def)
        
        if is_wrapper_class and not is_dynamic:
            self.tf.prepend_generic_function_tvar_args(wrapper_func_def)
        
        return wrapper_func_def
    
    def get_target_sig(self, act_as_func_def: FuncDef,
                       target_func_def: FuncDef,
                       is_dynamic: bool, is_wrapper_class: bool) -> Callable:
        """Return the target method signature for a method wrapper."""
        sig = cast(Callable, function_type(target_func_def))
        if is_wrapper_class:
            if sig.is_generic() and is_dynamic:
                sig = cast(Callable,
                           translate_function_type_vars_to_dynamic(sig))
            return cast(Callable,
                        translate_type_vars_to_wrapped_object_vars(sig))
        elif is_dynamic:
            if sig.is_generic():
                return cast(Callable,
                            translate_function_type_vars_to_dynamic(sig))
            else:
                return sig
        else:
            return sig
    
    def get_wrapper_sig(self, act_as_func_def: FuncDef,
                        is_dynamic: bool) -> Callable:
        """Return the signature of the wrapper method.

        The wrapper method signature has an additional type variable
        argument (with type 'Any'), and all type variables have been
        erased.
        """
        sig = cast(Callable, function_type(act_as_func_def))
        if is_dynamic:
            return dynamic_sig(sig)
        elif is_generic(act_as_func_def):
            return cast(Callable, erase_generic_types(sig)) # FIX REFACTOR?
        else:
            return sig
    
    def get_call_sig(self, act_as_func_def: FuncDef,
                     current_class: TypeInfo, is_dynamic: bool,
                     is_wrapper_class: bool, is_override: bool) -> Callable:
        """Return the source signature in a wrapped call.
        
        It has type variables replaced with 'Any', but as an
        exception, type variables are intact in the return type in
        generic wrapper classes. The exception allows omitting an
        extra return value coercion, as the target return type and the
        source return type will be the same.
        """
        sig = cast(Callable, function_type(act_as_func_def))
        if is_dynamic:
            return dynamic_sig(sig)
        elif is_generic(act_as_func_def):
            call_sig = sig
            # If this is an override wrapper, keep type variables
            # intact. Otherwise replace them with dynamic to get
            # desired coercions that check argument types.
            if not is_override or is_wrapper_class:
                call_sig = (cast(Callable, replace_type_vars(call_sig, False)))
            else:
                call_sig = cast(Callable, map_type_from_supertype(
                    call_sig, current_class, act_as_func_def.info))
            if is_wrapper_class:
                # Replace return type with the original return within
                # wrapper classes to get rid of an unnecessary
                # coercion. There will still be a coercion due to the
                # extra coercion generated for generic wrapper
                # classes. However, function generic type variables
                # still need to be replaced, as the wrapper does not
                # affect them.
                ret = sig.ret_type
                if is_dynamic:
                    ret = translate_function_type_vars_to_dynamic(ret)
                call_sig = replace_ret_type(
                    call_sig, translate_type_vars_to_wrapper_vars(ret))
            return call_sig
        else:
            return sig
    
    def get_wrapper_args(self, act_as_func_def: FuncDef,
                         is_dynamic: bool) -> List[Var]:
        """Return the formal arguments of a wrapper method.

        These may include the type variable argument.
        """
        args = [] # type: List[Var]
        for a in act_as_func_def.args:
            args.append(Var(a.name()))
        return args
    
    def call_wrapper(self, fdef: FuncDef, is_dynamic: bool,
                     is_wrapper_class: bool, target_ann: Callable,
                     cur_ann: Callable, target_suffix: str,
                     bound_sig: Callable) -> Node:
        """Return the body of wrapper method.

        The body contains only a call to the wrapped method and a
        return statement (if the call returns a value). Arguments are coerced
        to the target signature.
        """        
        args = self.call_args(fdef.args, target_ann, cur_ann, is_dynamic,
                              is_wrapper_class, bound_sig,
                              ismethod=fdef.is_method())
        selfarg = args[0]
        args = args[1:]
        
        member = fdef.name() + target_suffix
        if not is_wrapper_class:
            callee = MemberExpr(selfarg, member)
        else:
            callee = MemberExpr(
                MemberExpr(self_expr(), self.tf.object_member_name()), member)
        
        call = CallExpr(callee,
                        args,
                        [nodes.ARG_POS] * len(args),
                        [None] * len(args)) # type: Node
        if bound_sig:
            call = self.tf.coerce(call, bound_sig.ret_type,
                                  target_ann.ret_type, self.tf.type_context(),
                                  is_wrapper_class)
            call = self.tf.coerce(call, cur_ann.ret_type, bound_sig.ret_type,
                                  self.tf.type_context(), is_wrapper_class)
        else:
            call = self.tf.coerce(call, cur_ann.ret_type, target_ann.ret_type,
                                  self.tf.type_context(), is_wrapper_class)
        if not isinstance(target_ann.ret_type, Void):
            return ReturnStmt(call)
        else:
            return ExpressionStmt(call)
    
    def call_args(self, vars: List[Var], target_ann: Callable,
                  cur_ann: Callable, is_dynamic: bool, is_wrapper_class: bool,
                  bound_sig: Callable = None,
                  ismethod: bool = False) -> List[Node]:
        """Construct the arguments of a wrapper call expression.

        Insert coercions as needed.
        """
        args = [] # type: List[Node]
        # Add ordinary arguments, including self (for methods).
        for i in range(len(vars)):
            a = vars[i]
            name = NameExpr(a.name())
            if bound_sig is None:
                args.append(self.tf.coerce(name, target_ann.arg_types[i],
                                           cur_ann.arg_types[i],
                                           self.tf.type_context(),
                                           is_wrapper_class))
            else:
                c = self.tf.coerce(name, bound_sig.arg_types[i],
                                   cur_ann.arg_types[i],
                                   self.tf.type_context(), is_wrapper_class)
                args.append(self.tf.coerce(c, target_ann.arg_types[i],
                                           bound_sig.arg_types[i],
                                           self.tf.type_context(),
                                           is_wrapper_class))
        # Add type variable arguments for a generic function.
        for i in range(len(target_ann.variables)):
            # Non-dynamic wrapper method in a wrapper class passes
            # generic function type arguments to the target function;
            # otherwise use dynamic types.
            index = i
            if ismethod:
                index += 1
            if is_wrapper_class and not is_dynamic:
                args.insert(index,
                    TypeExpr(RuntimeTypeVar(NameExpr(tvar_arg_name(-i - 1)))))
            else:
                args.insert(index, TypeExpr(AnyType()))
        return args
    
    def get_wrapper_suffix(self, func_def: FuncDef, is_dynamic: bool) -> str:
        if is_dynamic:
            return self.tf.dynamic_suffix()
        else:
            return self.tf.type_suffix(func_def)

########NEW FILE########
__FILENAME__ = transformtype
"""Transform classes for runtime type checking."""

from typing import Undefined, List, Set, Any, cast, Tuple, Dict

from mypy.nodes import (
    ClassDef, Node, FuncDef, VarDef, Block, Var, ExpressionStmt,
    TypeInfo, SuperExpr, NameExpr, CallExpr, MDEF, MemberExpr, ReturnStmt,
    AssignmentStmt, TypeExpr, PassStmt, SymbolTableNode
)
from mypy import nodes
from mypy.semanal import self_type
from mypy.types import (
    Callable, Instance, Type, AnyType, BOUND_VAR, Void, RuntimeTypeVar,
    UnboundType
)
from mypy.checkmember import analyse_member_access
from mypy.checkexpr import type_object_type
from mypy.subtypes import map_instance_to_supertype
import mypy.transform
from mypy.transformfunc import FuncTransformer
from mypy.transutil import (
    self_expr, tvar_slot_name, tvar_arg_name, prepend_arg_type
)
from mypy.rttypevars import translate_runtime_type_vars_locally
from mypy.compileslotmap import find_slot_origin
from mypy.coerce import coerce
from mypy.maptypevar import num_slots, get_tvar_access_path
from mypy import erasetype


class TypeTransformer:
    """Class for transforming type definitions for runtime type checking.

    Transform a type definition by modifying it in-place.

    The following transformations are performed:

      * Represent generic type variables explicitly as attributes.
      * Create generic wrapper classes used by coercions to different type
        args.
      * Create wrapper methods needed when overriding methods with different
        signatures.
      * Create wrapper methods for calling methods in dynamically typed code.
        These perform the necessary coercions for arguments and return values
        to/from 'Any'.
    
    This is used by DyncheckTransformVisitor and is logically aggregated within
    that class.
    """
    
    # Used for common transformation operations.
    tf = Undefined('mypy.transform.DyncheckTransformVisitor')
    # Used for transforming methods.
    func_tf = Undefined(FuncTransformer)
    
    def __init__(self, tf: 'mypy.transform.DyncheckTransformVisitor') -> None:
        self.tf = tf
        self.func_tf = FuncTransformer(tf)
    
    def transform_class_def(self, tdef: ClassDef) -> List[Node]:        
        """Transform a type definition.

        The result may be one or two definitions.  The first is the
        transformation of the original ClassDef. The second is a
        wrapper type, which is generated for generic types only.
        """
        defs = [] # type: List[Node]
        
        if tdef.info.type_vars:
            # This is a generic type. Insert type variable slots in
            # the class definition for new type variables, i.e. type
            # variables not mapped to superclass type variables.
            defs.extend(self.make_tvar_representation(tdef.info))
        
        # Iterate over definitions and transform each of them.
        vars = set() # type: Set[Var]
        for d in tdef.defs.body:
            if isinstance(d, FuncDef):
                # Implicit cast from FuncDef[] to Node[] is safe below.
                defs.extend(Any(self.func_tf.transform_method(d)))
            elif isinstance(d, VarDef):
                defs.extend(self.transform_var_def(d))
                for n in d.items:
                    vars.add(n)
            elif isinstance(d, AssignmentStmt):
                self.transform_assignment(d)
                defs.append(d)

        # Add accessors for implicitly defined attributes.
        for node in tdef.info.names.values():
            if isinstance(node.node, Var):
                v = cast(Var, node.node)
                if v.info == tdef.info and v not in vars:
                    defs.extend(self.make_accessors(v))
        
        # For generic classes, add an implicit __init__ wrapper.
        defs.extend(self.make_init_wrapper(tdef))
        
        if tdef.is_generic() or (tdef.info.bases and
                                 tdef.info.mro[1].is_generic()):
            self.make_instance_tvar_initializer(
                cast(FuncDef, tdef.info.get_method('__init__')))

        if not defs:
            defs.append(PassStmt())

        if tdef.is_generic():
            gen_wrapper = self.generic_class_wrapper(tdef)

        tdef.defs = Block(defs)

        dyn_wrapper = self.make_type_object_wrapper(tdef)
        
        if not tdef.is_generic():
            return [tdef, dyn_wrapper]
        else:
            return [tdef, dyn_wrapper, gen_wrapper]
    
    def make_init_wrapper(self, tdef: ClassDef) -> List[Node]:
        """Make and return an implicit __init__ if class needs it.
        
        Otherwise, return an empty list. We include an implicit
        __init__ if the class is generic or if it extends a generic class
        and if it does not define __init__.
        
        The __init__ of a generic class requires one or more extra type
        variable arguments. The inherited __init__ may not accept these.

        For example, assume these definitions:
        
        . class A(Generic[T]): pass
        . class B(A[int]): pass
        
        The constructor for B will be (equivalent to)
        
        . def __init__(self: B) -> None:
        .     self.__tv = <int>
        .     super().__init__(<int>)
        """
        
        # FIX overloading, default args / varargs, keyword args

        info = tdef.info
        
        if '__init__' not in info.names and (
                tdef.is_generic() or (info.bases and
                                      info.mro[1].is_generic())):
            # Generic class with no explicit __init__ method
            # (i.e. __init__ inherited from superclass). Generate a
            # wrapper that initializes type variable slots and calls
            # the superclass __init__ method.

            base = info.mro[1]
            selftype = self_type(info)    
            callee_type = cast(Callable, analyse_member_access(
                '__init__', selftype, None, False, True, None, None,
                base))
            
            # Now the callee type may contain the type variables of a
            # grandparent as bound type variables, but we want the
            # type variables of the parent class. Explicitly set the
            # bound type variables.
            callee_type = self.fix_bound_init_tvars(callee_type,
                map_instance_to_supertype(selftype, base))
            
            super_init = cast(FuncDef, base.get_method('__init__'))
            
            # Build argument list.
            args = [Var('self')]
            for i in range(1, len(super_init.args)):
                args.append(Var(super_init.args[i].name()))
                args[-1].type = callee_type.arg_types[i - 1]

            selft = self_type(self.tf.type_context())
            callee_type = prepend_arg_type(callee_type, selft)
            
            creat = FuncDef('__init__', args,
                            super_init.arg_kinds, [None] * len(args),
                            Block([]))
            creat.info = tdef.info
            creat.type = callee_type
            creat.is_implicit = False
            tdef.info.names['__init__'] = SymbolTableNode(MDEF, creat,
                                                          typ=creat.type)
            
            # Insert a call to superclass constructor. If the
            # superclass is object, the constructor does nothing =>
            # omit the call.
            if base.fullname() != 'builtins.object':
                creat.body.body.append(
                    self.make_superclass_constructor_call(tdef.info,
                                                          callee_type))
            
            # Implicit cast from FuncDef[] to Node[] is safe below.
            return Any(self.func_tf.transform_method(creat))
        else:
            return []
    
    def fix_bound_init_tvars(self, callable: Callable,
                             typ: Instance) -> Callable:
        """Replace bound type vars of callable with args from instance type."""
        a = [] # type: List[Tuple[int, Type]]
        for i in range(len(typ.args)):
            a.append((i + 1, typ.args[i]))
        return Callable(callable.arg_types, callable.arg_kinds,
                        callable.arg_names, callable.ret_type,
                        callable.is_type_obj(), callable.name,
                        callable.variables, a)
    
    def make_superclass_constructor_call(
            self, info: TypeInfo, callee_type: Callable) -> ExpressionStmt:
        """Construct a statement that calls the superclass constructor.

        In particular, it passes any type variables arguments as needed.
        """
        callee = SuperExpr('__init__')
        callee.info = info
        
        # We do not handle generic constructors. Either pass runtime
        # type variables from the current scope or perhaps require
        # explicit constructor in this case.
        
        selftype = self_type(info)    
        
        # FIX overloading
        # FIX default args / varargs
        
        # Map self type to the superclass context.
        base = info.mro[1]
        selftype = map_instance_to_supertype(selftype, base)
        
        super_init = cast(FuncDef, base.get_method('__init__'))
        
        # Add constructor arguments.
        args = [] # type: List[Node]
        for n in range(1, callee_type.min_args):            
            args.append(NameExpr(super_init.args[n].name()))
            self.tf.set_type(args[-1], callee_type.arg_types[n])

        # Store callee type after stripping away the 'self' type.
        self.tf.set_type(callee, nodes.method_callable(callee_type))
        
        call = CallExpr(callee, args, [nodes.ARG_POS] * len(args))
        return ExpressionStmt(call)
    
    def transform_var_def(self, o: VarDef) -> List[Node]:
        """Transform a member variable definition.

        The result may be one or more definitions.
        """
        res = [o] # type: List[Node]
        
        self.tf.visit_var_def(o)
        
        # Add $x and set$x accessor wrappers for data attributes. These let
        # derived classes redefine a data attribute as a property.
        for n in o.items:
            res.extend(self.make_accessors(n))
        
        return res
    
    def transform_assignment(self, o: AssignmentStmt) -> None:
        """Transform an assignment statement in class body."""
        self.tf.visit_assignment_stmt(o)

    def make_accessors(self, n: Var) -> List[Node]:
        if n.type:
            t = n.type
        else:
            t = AnyType()
        return [self.make_getter_wrapper(n.name(), t),
                self.make_setter_wrapper(n.name(), t),
                self.make_dynamic_getter_wrapper(n.name(), t),
                self.make_dynamic_setter_wrapper(n.name(), t)]
    
    def make_getter_wrapper(self, name: str, typ: Type) -> FuncDef:
        """Create a getter wrapper for a data attribute.

        The getter will be of this form:
        
        . def $name*(self: C) -> type:
        .     return self.name!
        """
        scope = self.make_scope()
        selft = self.self_type()
        selfv = scope.add('self', selft)
        
        member_expr = MemberExpr(scope.name_expr('self'), name, direct=True)
        ret = ReturnStmt(member_expr)

        wrapper_name = '$' + name
        sig = Callable([selft], [nodes.ARG_POS], [None], typ, False)
        fdef = FuncDef(wrapper_name,
                       [selfv],
                       [nodes.ARG_POS],
                       [None],
                       Block([ret]), sig)
        fdef.info = self.tf.type_context()
        return fdef
    
    def make_dynamic_getter_wrapper(self, name: str, typ: Type) -> FuncDef:
        """Create a dynamically-typed getter wrapper for a data attribute.

        The getter will be of this form:
        
        . def $name*(self: C) -> Any:
        .     return {Any <= typ self.name!}
        """
        scope = self.make_scope()
        selft = self.self_type()
        selfv = scope.add('self', selft)
        
        member_expr = MemberExpr(scope.name_expr('self'), name, direct=True)
        coerce_expr = coerce(member_expr, AnyType(), typ,
                             self.tf.type_context())
        ret = ReturnStmt(coerce_expr)

        wrapper_name = '$' + name + self.tf.dynamic_suffix()
        sig = Callable([selft], [nodes.ARG_POS], [None], AnyType(), False)
        return FuncDef(wrapper_name,
                       [selfv],
                       [nodes.ARG_POS],
                       [None],
                       Block([ret]), sig)
    
    def make_setter_wrapper(self, name: str, typ: Type) -> FuncDef:
        """Create a setter wrapper for a data attribute.

        The setter will be of this form:
        
        . def set$name(self: C, name: typ) -> None:
        .     self.name! = name
        """
        scope = self.make_scope()
        selft = self.self_type()
        selfv = scope.add('self', selft)
        namev = scope.add(name, typ)
        
        lvalue = MemberExpr(scope.name_expr('self'), name, direct=True)
        rvalue = scope.name_expr(name)
        ret = AssignmentStmt([lvalue], rvalue)

        wrapper_name = 'set$' + name
        sig = Callable([selft, typ],
                       [nodes.ARG_POS, nodes.ARG_POS],
                       [None, None],
                       Void(), False)
        fdef = FuncDef(wrapper_name,
                       [selfv, namev],
                       [nodes.ARG_POS, nodes.ARG_POS],
                       [None, None],
                       Block([ret]), sig)
        fdef.info = self.tf.type_context()
        return fdef
    
    def make_dynamic_setter_wrapper(self, name: str, typ: Type) -> FuncDef:
        """Create a dynamically-typed setter wrapper for a data attribute.

        The setter will be of this form:
        
        . def set$name*(self: C, name; Any) -> None:
        .     self.name! = {typ name}
        """
        lvalue = MemberExpr(self_expr(), name, direct=True)
        name_expr = NameExpr(name)
        rvalue = coerce(name_expr, typ, AnyType(), self.tf.type_context())
        ret = AssignmentStmt([lvalue], rvalue)

        wrapper_name = 'set$' + name + self.tf.dynamic_suffix()
        selft = self_type(self.tf.type_context())            
        sig = Callable([selft, AnyType()],
                       [nodes.ARG_POS, nodes.ARG_POS],
                       [None, None],
                       Void(), False)
        return FuncDef(wrapper_name,
                       [Var('self'), Var(name)],
                       [nodes.ARG_POS, nodes.ARG_POS],
                       [None, None],
                       Block([ret]), sig)
    
    def generic_accessor_wrappers(self, s: AssignmentStmt) -> List[Node]:
        """Construct wrapper class methods for attribute accessors."""
        res = [] # type: List[Node]
        assert len(s.lvalues) == 1
        assert isinstance(s.lvalues[0], NameExpr)
        assert s.type is not None
        name = cast(NameExpr, s.lvalues[0])
        for fd in [self.make_getter_wrapper(name.name, s.type),
                   self.make_setter_wrapper(name.name, s.type)]:
            res.extend(self.func_tf.generic_method_wrappers(fd))
        return res
    
    def generic_class_wrapper(self, tdef: ClassDef) -> ClassDef:
        """Construct a wrapper class for a generic type."""
        # FIX semanal meta-info for nodes + TypeInfo
        
        defs = [] # type: List[Node]
        
        # Does the type have a superclass, other than builtins.object?
        base = tdef.info.mro[1]
        has_proper_superclass = base.fullname() != 'builtins.object'
        
        if not has_proper_superclass or self.tf.is_java:
            # Generate member variables for wrapper object.
            defs.extend(self.make_generic_wrapper_member_vars(tdef))
        
        for alt in [False, BOUND_VAR]:
            defs.extend(self.make_tvar_representation(tdef.info, alt))
        
        # Generate constructor.
        defs.append(self.make_generic_wrapper_init(tdef.info))
        
        # Generate method wrappers.
        for d in tdef.defs.body:
            if isinstance(d, FuncDef):
                if not d.is_constructor():
                    defs.extend(self.func_tf.generic_method_wrappers(d))
            elif isinstance(d, AssignmentStmt):
                defs.extend(self.generic_accessor_wrappers(d))
            elif not isinstance(d, PassStmt):
                raise RuntimeError(
                    'Definition {} at line {} not supported'.format(
                        type(d), d.line))
        
        base_type = self.tf.named_type('builtins.object') # type: Type
        # Inherit superclass wrapper if there is one.
        if has_proper_superclass:
            base = self.find_generic_base_class(tdef.info)
            if base:
                # TODO bind the type somewhere
                base_type = UnboundType(base.defn.name +
                                        self.tf.wrapper_class_suffix())
        
        # Build the type definition.
        wrapper = ClassDef(tdef.name + self.tf.wrapper_class_suffix(),
                          Block(defs),
                          None,
                          [base_type])
        # FIX fullname
        
        self.tf.add_line_mapping(tdef, wrapper)
        
        return wrapper
    
    def find_generic_base_class(self, info: TypeInfo) -> TypeInfo:
        base = info.mro[1]
        while True:
            if base.type_vars != []:
                return base
            if len(base.mro) <= 1:
                return None
            base = base.mro[1]
    
    def make_generic_wrapper_member_vars(self, tdef: ClassDef) -> List[Node]:
        """Generate member variable definition for wrapped object (__o).
        
        This is added to a generic wrapper class.
        """
        # The type is 'Any' since it should behave covariantly in subclasses.
        return [VarDef([Var(self.object_member_name(tdef.info),
                            AnyType())], False, None)]
    
    def object_member_name(self, info: TypeInfo) -> str:
        if self.tf.is_java:
            return '__o_{}'.format(info.name)
        else:
            return '__o'
    
    def make_generic_wrapper_init(self, info: TypeInfo) -> FuncDef:
        """Build constructor of a generic wrapper class."""
        nslots = num_slots(info)
        
        cdefs = [] # type: List[Node]
        
        # Build superclass constructor call.
        base = info.mro[1]
        if base.fullname() != 'builtins.object' and self.tf.is_java:
            s = SuperExpr('__init__')
            cargs = [NameExpr('__o')] # type: List[Node]
            for n in range(num_slots(base)):
                cargs.append(NameExpr(tvar_arg_name(n + 1)))
            for n in range(num_slots(base)):
                cargs.append(NameExpr(tvar_arg_name(n + 1, BOUND_VAR)))
            c = CallExpr(s, cargs, [nodes.ARG_POS] * len(cargs))
            cdefs.append(ExpressionStmt(c))
        
        # Create initialization of the wrapped object.
        cdefs.append(AssignmentStmt([MemberExpr(
                                         self_expr(),
                                         self.object_member_name(info),
                                         direct=True)],
                                    NameExpr('__o')))
        
        # Build constructor arguments.
        args = [Var('self'), Var('__o')]
        init = [None, None] # type: List[Node]
        
        for alt in [False, BOUND_VAR]:
            for n in range(nslots):
                args.append(Var(tvar_arg_name(n + 1, alt)))
                init.append(None)

        nargs = nslots * 2 + 2
        fdef = FuncDef('__init__',
                       args,
                       [nodes.ARG_POS] * nargs,
                       init,
                       Block(cdefs),
                       Callable( [AnyType()] * nargs,
                                [nodes.ARG_POS] * nargs, [None] * nargs,
                                Void(),
                                is_type_obj=False))
        fdef.info = info
        
        self.make_wrapper_slot_initializer(fdef)
        
        return fdef
    
    def make_tvar_representation(self, info: TypeInfo,
                                 is_alt: Any = False) -> List[Node]:
        """Return type variable slot member definitions.

        There are of form '__tv*: Any'. Only include new slots defined in the
        type.
        """
        defs = [] # type: List[Node]
        base_slots = num_slots(info.mro[1])
        for n in range(len(info.type_vars)):
            # Only include a type variable if it introduces a new slot.
            slot = get_tvar_access_path(info, n + 1)[0] - 1
            if slot >= base_slots:
                defs.append(VarDef([Var(tvar_slot_name(slot, is_alt),
                                        AnyType())], False, None))
        return defs
    
    def make_instance_tvar_initializer(self, creat: FuncDef) -> None:
        """Add type variable member initialization code to a constructor.

        Modify the constructor body directly.
        """
        for n in range(num_slots(creat.info)):
            rvalue = self.make_tvar_init_expression(creat.info, n)
            init = AssignmentStmt([MemberExpr(self_expr(),
                                              tvar_slot_name(n),
                                              direct=True)],
                                  rvalue)
            self.tf.set_type(init.lvalues[0], AnyType())
            self.tf.set_type(init.rvalue, AnyType())
            creat.body.body.insert(n, init)
    
    def make_wrapper_slot_initializer(self, creat: FuncDef) -> None:
        """Add type variable member initializations to a wrapper constructor.

        The function must be a constructor of a generic wrapper class. Modify
        the constructor body directly.
        """
        for alt in [BOUND_VAR, False]:
            for n in range(num_slots(creat.info)):
                rvalue = TypeExpr(
                    RuntimeTypeVar(NameExpr(tvar_slot_name(n, alt))))
                init = AssignmentStmt(
                    [MemberExpr(self_expr(),
                                tvar_slot_name(n, alt), direct=True)],
                    rvalue)
                self.tf.set_type(init.lvalues[0], AnyType())
                self.tf.set_type(init.rvalue, AnyType())
                creat.body.body.insert(n, init)
    
    def make_tvar_init_expression(self, info: TypeInfo, slot: int) -> TypeExpr:
        """Return the initializer for the given slot in the given type.
        
        This is the type expression that initializes the given slot
        using the type arguments given to the constructor.
        
        Examples:
          - In 'class C(Generic[T]) ...', the initializer for the slot 0 is
            TypeExpr(RuntimeTypeVar(NameExpr('__tv'))).
          - In 'class D(C[int]) ...', the initializer for the slot 0 is
            TypeExpr(<int instance>).
        """
        # Figure out the superclass which defines the slot; also figure out
        # the tvar index that maps to the slot.
        origin, tv = find_slot_origin(info, slot)
        
        # Map self type to the superclass -> extract tvar with target index
        # (only contains subclass tvars?? PROBABLY NOT).
        selftype = self_type(info)
        selftype = map_instance_to_supertype(selftype, origin)
        tvar = selftype.args[tv - 1]
        
        # Map tvar to an expression; refer to local vars instead of member
        # vars always.
        tvar = translate_runtime_type_vars_locally(tvar)
        
        # Build the rvalue (initializer) expression
        return TypeExpr(tvar)

    def make_type_object_wrapper(self, tdef: ClassDef) -> FuncDef:
        """Construct dynamically typed wrapper function for a class.

        It simple calls the type object and returns the result.
        """
        
        # TODO keyword args, default args and varargs
        # TODO overloads

        type_sig = cast(Callable, type_object_type(tdef.info, None))
        type_sig = cast(Callable, erasetype.erase_typevars(type_sig))
        
        init = cast(FuncDef, tdef.info.get_method('__init__'))
        arg_kinds = type_sig.arg_kinds

        # The wrapper function has a dynamically typed signature.
        wrapper_sig = Callable( [AnyType()] * len(arg_kinds),
                               arg_kinds, [None] * len(arg_kinds),
                               AnyType(), False)
        
        n = NameExpr(tdef.name) # TODO full name
        args = self.func_tf.call_args(
            init.args[1:],
            type_sig,
            wrapper_sig,
            True, False)
        call = CallExpr(n, args, arg_kinds)
        ret = ReturnStmt(call)
        

        fdef = FuncDef(tdef.name + self.tf.dynamic_suffix(),
                       init.args[1:],
                       arg_kinds, [None] * len(arg_kinds),
                       Block([ret]))
        
        fdef.type = wrapper_sig
        return fdef

    def self_type(self) -> Instance:
        return self_type(self.tf.type_context())

    def make_scope(self) -> 'Scope':
        return Scope(self.tf.type_map)
        

class Scope:
    """Maintain a temporary local scope during transformation."""
    def __init__(self, type_map: Dict[Node, Type]) -> None:
        self.names = {} # type: Dict[str, Var]
        self.type_map = type_map

    def add(self, name: str, type: Type) -> Var:
        v = Var(name)
        v.type = type
        self.names[name] = v
        return v

    def name_expr(self, name: str) -> NameExpr:
        nexpr = NameExpr(name)
        nexpr.kind = nodes.LDEF
        node = self.names[name]
        nexpr.node = node
        self.type_map[nexpr] = node.type
        return nexpr

########NEW FILE########
__FILENAME__ = transutil
from typing import cast, Any, List

from mypy.types import (
    Callable, Type, AnyType, TypeTranslator, TypeVar, BOUND_VAR, OBJECT_VAR,
    replace_self_type
) 
from mypy.nodes import FuncDef, TypeInfo, NameExpr, LDEF
from mypy import nodes
from mypy.noderepr import FuncRepr, FuncArgsRepr, CallExprRepr
from mypy.lex import Token
from mypy.nodes import function_type
from mypy.sametypes import is_same_type
from mypy.parse import none


def prepend_arg_type(t: Callable, arg_type: Type) -> Callable:
    """Prepend an argument with the given type to a callable type."""
    return Callable([arg_type] + t.arg_types,
                    [nodes.ARG_POS] + t.arg_kinds,
                    List[str]([None]) + t.arg_names,
                    t.ret_type,
                    t.is_type_obj(),
                    t.name,
                    t.variables,
                    t.bound_vars,
                    t.line, None)


def add_arg_type_after_self(t: Callable, arg_type: Type) -> Callable:
    """Add an argument with the given type to a callable type after 'self'."""
    return Callable([t.arg_types[0], arg_type] + t.arg_types[1:],
                    [t.arg_kinds[0], nodes.ARG_POS] + t.arg_kinds[1:],
                    [t.arg_names[0], None] + t.arg_names[1:],
                    t.ret_type,
                    t.is_type_obj(),
                    t.name,
                    t.variables,
                    t.bound_vars,
                    t.line, None)


def replace_ret_type(t: Callable, ret_type: Type) -> Callable:
    """Return a copy of a callable type with a different return type."""
    return Callable(t.arg_types,
                    t.arg_kinds,
                    t.arg_names,
                    ret_type,
                    t.is_type_obj(),
                    t.name,
                    t.variables,
                    t.bound_vars,
                    t.line, None)


def dynamic_sig(sig: Callable) -> Callable:
    """Translate callable type to type erased (dynamically-typed) callable.

    Preserve the number and kinds of arguments.
    """
    return Callable( [AnyType()] * len(sig.arg_types),
                    sig.arg_kinds,
                    sig.arg_names,
                    AnyType(),
                    sig.is_type_obj())


def translate_type_vars_to_wrapper_vars(typ: Type) -> Type:
    """Translate any instance type variables in a type into wrapper tvars.
    
    (Wrapper tvars are type variables that refer to values stored in a generic
    class wrapper).
    """
    return typ.accept(TranslateTypeVarsToWrapperVarsVisitor())


class TranslateTypeVarsToWrapperVarsVisitor(TypeTranslator):
    """Visitor that implements TranslateTypeVarsToWrapperVarsVisitor."""
    def visit_type_var(self, t: TypeVar) -> Type:
        if t.id > 0:
            return TypeVar(t.name, t.id, t.values, True, t.line, t.repr)
        else:
            return t


def translate_type_vars_to_bound_vars(typ: Type) -> Type:
    return typ.accept(TranslateTypeVarsToBoundVarsVisitor())


class TranslateTypeVarsToBoundVarsVisitor(TypeTranslator):
    def visit_type_var(self, t: TypeVar) -> Type:
        if t.id > 0:
            return TypeVar(t.name, t.id, t.values, BOUND_VAR, t.line, t.repr)
        else:
            return t


def translate_type_vars_to_wrapped_object_vars(typ: Type) -> Type:
    return typ.accept(TranslateTypeVarsToWrappedObjectVarsVisitor())


class TranslateTypeVarsToWrappedObjectVarsVisitor(TypeTranslator):
    def visit_type_var(self, t: TypeVar) -> Type:
        if t.id > 0:
            return TypeVar(t.name, t.id, t.values, OBJECT_VAR, t.line, t.repr)
        else:
            return t


def translate_function_type_vars_to_dynamic(typ: Type) -> Type:
    """Translate any function type variables in a type into type 'Any'."""
    return typ.accept(TranslateFunctionTypeVarsToDynamicVisitor())


class TranslateFunctionTypeVarsToDynamicVisitor(TypeTranslator):
    """Visitor that implements TranslateTypeVarsToWrapperVarsVisitor."""
    def visit_type_var(self, t: TypeVar) -> Type:
        if t.id < 0:
            return AnyType()
        else:
            return t


def is_generic(fdef: FuncDef) -> bool:
    """Is a function a method of a generic type?

    (Note that this may return False even if the function itself is generic.)
    """
    return fdef.info is not None and fdef.info.type_vars != []


def is_simple_override(fdef: FuncDef, info: TypeInfo) -> bool:
    """Is function an override with the same type precision as the original?
    
    Compare to the original method in the superclass of info.
    """
    # If this is not an override, this can't be a simple override either.
    # Generic inheritance is not currently supported, since we need to map
    # type variables between types; in the future this restriction can be
    # lifted.
    if len(info.mro) <= 1:
        return False
    base = info.mro[1]
    if base.type_vars != []:
        return False
    orig = base.get_method(fdef.name())
    # Ignore the first argument (self) when determining type sameness.
    # TODO overloads
    newtype = cast(Callable, function_type(fdef))
    newtype = replace_self_type(newtype, AnyType())
    origtype = cast(Callable, function_type(orig))
    origtype = replace_self_type(origtype, AnyType())
    return is_same_type(newtype, origtype)


def tvar_slot_name(n: int, is_alt: Any = False) -> str:
    """Return the name of the member that holds the runtime value of the given
    type variable slot.
    """
    if is_alt != BOUND_VAR:
        if n == 0:
            return '__tv'
        else:
            return '__tv{}'.format(n + 1)
    else:
        # Greatest lower bound
        if n == 0:
            return '__btv'
        else:
            return '__btv{}'.format(n + 1)


def tvar_arg_name(n: int, is_alt: Any = False) -> str:
    """Return the name of the implicit function/constructor argument that
    contains the runtime value of a type variable. n is 1, 2, ... for instance
    type variables and -1, -2, ... for function type variables.
    """
    if is_alt != BOUND_VAR:
        if n > 0:
            # Equivalent to slot name.
            return tvar_slot_name(n - 1)
        elif n == -1:
            return '__ftv'
        else:
            return '__ftv{}'.format(-n)
    else:
        if n > 0:
            # Equivalent to slot name.
            return tvar_slot_name(n - 1, BOUND_VAR)
        elif n == -1:
            return '__bftv' # FIX do we need this?
        else:
            return '__bftv{}'.format(-n) # FIX do we need this?


def dynamic_suffix(is_pretty: bool) -> str:
    """Return the suffix of the dynamic wrapper of a method or class."""
    if is_pretty:
        return '*'
    else:
        return '___dyn'


def self_expr() -> NameExpr:
    n = NameExpr('self')
    n.kind = LDEF
    return n

########NEW FILE########
__FILENAME__ = traverser
"""Generic node traverser visitor"""

from typing import typevar, Generic

from mypy.visitor import NodeVisitor
from mypy.nodes import (
    Block, MypyFile, VarDef, FuncItem, CallExpr, ClassDef, Decorator, FuncDef,
    ExpressionStmt, AssignmentStmt, OperatorAssignmentStmt, WhileStmt,
    ForStmt, ReturnStmt, AssertStmt, YieldStmt, DelStmt, IfStmt, RaiseStmt,
    TryStmt, WithStmt, ParenExpr, MemberExpr, OpExpr, SliceExpr, CastExpr,
    UnaryExpr, ListExpr, TupleExpr, DictExpr, SetExpr, IndexExpr,
    GeneratorExpr, ListComprehension, ConditionalExpr, TypeApplication,
    FuncExpr, OverloadedFuncDef
)


T = typevar('T')


class TraverserVisitor(NodeVisitor[T], Generic[T]):
    """A parse tree visitor that traverses the parse tree during visiting.

    It does not peform any actions outside the travelsal. Subclasses
    should override visit methods to perform actions during
    travelsal. Calling the superclass method allows reusing the
    travelsal implementation.
    """

    # Visit methods
    
    def visit_mypy_file(self, o: MypyFile) -> T:
        for d in o.defs:
            d.accept(self)

    def visit_block(self, block: Block) -> T:
        for s in block.body:
            s.accept(self)
    
    def visit_func(self, o: FuncItem) -> T:
        for i in o.init:
            if i is not None:
                i.accept(self)
        for v in o.args:
            self.visit_var(v)
        o.body.accept(self)
    
    def visit_func_def(self, o: FuncDef) -> T:
        self.visit_func(o)

    def visit_overloaded_func_def(self, o: OverloadedFuncDef) -> T:
        for item in o.items:
            item.accept(self)
    
    def visit_class_def(self, o: ClassDef) -> T:
        o.defs.accept(self)
    
    def visit_decorator(self, o: Decorator) -> T:
        o.func.accept(self)
        o.var.accept(self)
        for decorator in o.decorators:
            decorator.accept(self)
    
    def visit_var_def(self, o: VarDef) -> T:
        if o.init is not None:
            o.init.accept(self)
        for v in o.items:
            self.visit_var(v)
    
    def visit_expression_stmt(self, o: ExpressionStmt) -> T:
        o.expr.accept(self)
    
    def visit_assignment_stmt(self, o: AssignmentStmt) -> T:
        o.rvalue.accept(self)
        for l in o.lvalues:
            l.accept(self)
    
    def visit_operator_assignment_stmt(self, o: OperatorAssignmentStmt) -> T:
        o.rvalue.accept(self)
        o.lvalue.accept(self)
    
    def visit_while_stmt(self, o: WhileStmt) -> T:
        o.expr.accept(self)
        o.body.accept(self)
        if o.else_body:
            o.else_body.accept(self)
    
    def visit_for_stmt(self, o: ForStmt) -> T:
        for ind in o.index:
            ind.accept(self)
        o.expr.accept(self)
        o.body.accept(self)
        if o.else_body:
            o.else_body.accept(self)
    
    def visit_return_stmt(self, o: ReturnStmt) -> T:
        if o.expr is not None:
            o.expr.accept(self)
    
    def visit_assert_stmt(self, o: AssertStmt) -> T:
        if o.expr is not None:
            o.expr.accept(self)
    
    def visit_yield_stmt(self, o: YieldStmt) -> T:
        if o.expr is not None:
            o.expr.accept(self)
    
    def visit_del_stmt(self, o: DelStmt) -> T:
        if o.expr is not None:
            o.expr.accept(self)
    
    def visit_if_stmt(self, o: IfStmt) -> T:
        for e in o.expr:
            e.accept(self)
        for b in o.body:
            b.accept(self)
        if o.else_body:
            o.else_body.accept(self)
    
    def visit_raise_stmt(self, o: RaiseStmt) -> T:
        if o.expr is not None:
            o.expr.accept(self)
        if o.from_expr is not None:
            o.from_expr.accept(self)
    
    def visit_try_stmt(self, o: TryStmt) -> T:
        o.body.accept(self)
        for i in range(len(o.types)):
            if o.types[i]:
                o.types[i].accept(self)
            o.handlers[i].accept(self)
        if o.else_body is not None:
            o.else_body.accept(self)
        if o.finally_body is not None:
            o.finally_body.accept(self)
    
    def visit_with_stmt(self, o: WithStmt) -> T:
        for i in range(len(o.expr)):
            o.expr[i].accept(self)
            if o.name[i] is not None:
                o.name[i].accept(self)
        o.body.accept(self)
    
    def visit_paren_expr(self, o: ParenExpr) -> T:
        o.expr.accept(self)
    
    def visit_member_expr(self, o: MemberExpr) -> T:
        o.expr.accept(self)
    
    def visit_call_expr(self, o: CallExpr) -> T:
        for a in o.args:
            a.accept(self)
        o.callee.accept(self)
        if o.analyzed:
            o.analyzed.accept(self)
    
    def visit_op_expr(self, o: OpExpr) -> T:
        o.left.accept(self)
        o.right.accept(self)
    
    def visit_slice_expr(self, o: SliceExpr) -> T:
        if o.begin_index is not None:
            o.begin_index.accept(self)
        if o.end_index is not None:
            o.end_index.accept(self)
        if o.stride is not None:
            o.stride.accept(self)
    
    def visit_cast_expr(self, o: CastExpr) -> T:
        o.expr.accept(self)
    
    def visit_unary_expr(self, o: UnaryExpr) -> T:
        o.expr.accept(self)
    
    def visit_list_expr(self, o: ListExpr) -> T:
        for item in o.items:
            item.accept(self)
    
    def visit_tuple_expr(self, o: TupleExpr) -> T:
        for item in o.items:
            item.accept(self)
    
    def visit_dict_expr(self, o: DictExpr) -> T:
        for k, v in o.items:
            k.accept(self)
            v.accept(self)
    
    def visit_set_expr(self, o: SetExpr) -> T:
        for item in o.items:
            item.accept(self)
    
    def visit_index_expr(self, o: IndexExpr) -> T:
        o.base.accept(self)
        o.index.accept(self)
        if o.analyzed:
            o.analyzed.accept(self)
    
    def visit_generator_expr(self, o: GeneratorExpr) -> T:
        o.left_expr.accept(self)
        o.right_expr.accept(self)
        if o.condition is not None:
            o.condition.accept(self)
        for index in o.index:
            index.accept(self)
    
    def visit_list_comprehension(self, o: ListComprehension) -> T:
        o.generator.accept(self)
    
    def visit_conditional_expr(self, o: ConditionalExpr) -> T:
        o.cond.accept(self)
        o.if_expr.accept(self)
        o.else_expr.accept(self)
    
    def visit_type_application(self, o: TypeApplication) -> T:
        o.expr.accept(self)
    
    def visit_func_expr(self, o: FuncExpr) -> T:
        self.visit_func(o)

########NEW FILE########
__FILENAME__ = treetransform
"""Base visitor that implements an identity AST transform.

Subclass TransformVisitor to perform non-trivial transformations.
"""

from typing import List, Dict

from mypy.nodes import (
    MypyFile, Import, Node, ImportAll, ImportFrom, FuncItem, FuncDef,
    OverloadedFuncDef, ClassDef, Decorator, Block, Var, VarDef,
    OperatorAssignmentStmt, ExpressionStmt, AssignmentStmt, ReturnStmt,
    RaiseStmt, AssertStmt, YieldStmt, DelStmt, BreakStmt, ContinueStmt,
    PassStmt, GlobalDecl, WhileStmt, ForStmt, IfStmt, TryStmt, WithStmt,
    CastExpr, ParenExpr, TupleExpr, GeneratorExpr, ListComprehension, ListExpr,
    ConditionalExpr, DictExpr, SetExpr, NameExpr, IntExpr, StrExpr, BytesExpr,
    UnicodeExpr, FloatExpr, CallExpr, SuperExpr, MemberExpr, IndexExpr,
    SliceExpr, OpExpr, UnaryExpr, FuncExpr, TypeApplication, PrintStmt,
    SymbolTable, RefExpr, UndefinedExpr, TypeVarExpr, DucktypeExpr,
    DisjointclassExpr, CoerceExpr, TypeExpr, JavaCast, TempNode
)
from mypy.types import Type
from mypy.visitor import NodeVisitor


class TransformVisitor(NodeVisitor[Node]):
    """Transform a semantically analyzed AST (or subtree) to an identical copy.

    Use the node() method to transform an AST node.

    Subclass to perform a non-identity transform.

    Notes:

     * Do not duplicate TypeInfo nodes. This would generally not be desirable.
     * Only update some name binding cross-references, but only those that
       refer to Var nodes, not those targeting ClassDef, TypeInfo or FuncDef
       nodes.
     * Types are not transformed, but you can override type() to also perform
       type transformation.

    TODO nested classes and functions have not been tested well enough
    """

    def __init__(self) -> None:
        # There may be multiple references to a Var node. Keep track of
        # Var translations using a dictionary.
        self.var_map = Dict[Var, Var]()
    
    def visit_mypy_file(self, node: MypyFile) -> Node:
        # NOTE: The 'names' and 'imports' instance variables will be empty!
        new = MypyFile(self.nodes(node.defs), [], node.is_bom)
        new._name = node._name
        new._fullname = node._fullname
        new.path = node.path
        new.names = SymbolTable()
        return new
    
    def visit_import(self, node: Import) -> Node:
        return Import(node.ids[:])
    
    def visit_import_from(self, node: ImportFrom) -> Node:
        return ImportFrom(node.id, node.names[:])
    
    def visit_import_all(self, node: ImportAll) -> Node:
        return ImportAll(node.id)
    
    def visit_func_def(self, node: FuncDef) -> FuncDef:
        # Note that a FuncDef must be transformed to a FuncDef.
        new = FuncDef(node.name(),
                      [self.visit_var(var) for var in node.args],
                      node.arg_kinds[:],
                      [None] * len(node.init),
                      self.block(node.body),
                      self.optional_type(node.type))

        self.copy_function_attributes(new, node)
        
        new._fullname = node._fullname
        new.is_decorated = node.is_decorated
        new.is_conditional = node.is_conditional
        new.is_abstract = node.is_abstract
        new.is_static = node.is_static
        new.is_property = node.is_property
        new.original_def = node.original_def
        return new
    
    def visit_func_expr(self, node: FuncExpr) -> Node:
        new = FuncExpr([self.visit_var(var) for var in node.args],
                       node.arg_kinds[:],
                       [None] * len(node.init),
                       self.block(node.body),
                       self.optional_type(node.type))
        self.copy_function_attributes(new, node)
        return new

    def copy_function_attributes(self, new: FuncItem,
                                 original: FuncItem) -> None:
        new.info = original.info
        new.min_args = original.min_args
        new.max_pos = original.max_pos
        new.is_implicit = original.is_implicit
        new.is_overload = original.is_overload
        new.is_generator = original.is_generator
        new.init = self.duplicate_inits(original.init)

    def duplicate_inits(self,
                        inits: List[AssignmentStmt]) -> List[AssignmentStmt]:
        result = List[AssignmentStmt]()
        for init in inits:
            if init:
                result.append(self.duplicate_assignment(init))
            else:
                result.append(None)
        return result
    
    def visit_overloaded_func_def(self, node: OverloadedFuncDef) -> Node:
        items = [self.visit_decorator(decorator)
                 for decorator in node.items]
        for newitem, olditem in zip(items, node.items):
            newitem.line = olditem.line
        new = OverloadedFuncDef(items)
        new._fullname = node._fullname
        new.type = self.type(node.type)
        new.info = node.info
        return new
    
    def visit_class_def(self, node: ClassDef) -> Node:
        new = ClassDef(node.name,
                      self.block(node.defs),
                      node.type_vars,
                      self.types(node.base_types),
                      node.metaclass)
        new.fullname = node.fullname
        new.info = node.info
        new.decorators = [decorator.accept(self)
                          for decorator in node.decorators]
        new.is_builtinclass = node.is_builtinclass
        return new
    
    def visit_var_def(self, node: VarDef) -> Node:
        new = VarDef([self.visit_var(var) for var in node.items],
                     node.is_top_level,
                     self.optional_node(node.init))
        new.kind = node.kind
        return new
    
    def visit_global_decl(self, node: GlobalDecl) -> Node:
        return GlobalDecl(node.names[:])
    
    def visit_block(self, node: Block) -> Block:
        return Block(self.nodes(node.body))
    
    def visit_decorator(self, node: Decorator) -> Decorator:
        # Note that a Decorator must be transformed to a Decorator.
        func = self.visit_func_def(node.func)
        func.line = node.func.line
        new = Decorator(func, self.nodes(node.decorators),
                        self.visit_var(node.var))
        new.is_overload = node.is_overload
        return new
    
    def visit_var(self, node: Var) -> Var:
        # Note that a Var must be transformed to a Var.
        if node in self.var_map:
            return self.var_map[node]
        new = Var(node.name(), self.optional_type(node.type))
        new.line = node.line
        new._fullname = node._fullname
        new.info = node.info
        new.is_self = node.is_self
        new.is_ready = node.is_ready
        new.is_initialized_in_class = node.is_initialized_in_class
        new.is_staticmethod = node.is_staticmethod
        new.is_property = node.is_property
        new.set_line(node.line)
        self.var_map[node] = new
        return new
    
    def visit_expression_stmt(self, node: ExpressionStmt) -> Node:
        return ExpressionStmt(self.node(node.expr))
    
    def visit_assignment_stmt(self, node: AssignmentStmt) -> Node:
        return self.duplicate_assignment(node)
    
    def duplicate_assignment(self, node: AssignmentStmt) -> AssignmentStmt:
        new = AssignmentStmt(self.nodes(node.lvalues),
                             self.node(node.rvalue),
                             self.optional_type(node.type))
        new.line = node.line
        return new
    
    def visit_operator_assignment_stmt(self,
                                       node: OperatorAssignmentStmt) -> Node:
        return OperatorAssignmentStmt(node.op,
                                      self.node(node.lvalue),
                                      self.node(node.rvalue))
    
    def visit_while_stmt(self, node: WhileStmt) -> Node:
        return WhileStmt(self.node(node.expr),
                         self.block(node.body),
                         self.optional_block(node.else_body))
    
    def visit_for_stmt(self, node: ForStmt) -> Node:
        return ForStmt(self.names(node.index),
                       self.node(node.expr),
                       self.block(node.body),
                       self.optional_block(node.else_body),
                       self.optional_types(node.types))
    
    def visit_return_stmt(self, node: ReturnStmt) -> Node:
        return ReturnStmt(self.optional_node(node.expr))
    
    def visit_assert_stmt(self, node: AssertStmt) -> Node:
        return AssertStmt(self.node(node.expr))
    
    def visit_yield_stmt(self, node: YieldStmt) -> Node:
        return YieldStmt(self.node(node.expr))
    
    def visit_del_stmt(self, node: DelStmt) -> Node:
        return DelStmt(self.node(node.expr))
    
    def visit_if_stmt(self, node: IfStmt) -> Node:
        return IfStmt(self.nodes(node.expr),
                      self.blocks(node.body),
                      self.optional_block(node.else_body))
    
    def visit_break_stmt(self, node: BreakStmt) -> Node:
        return BreakStmt()
    
    def visit_continue_stmt(self, node: ContinueStmt) -> Node:
        return ContinueStmt()
    
    def visit_pass_stmt(self, node: PassStmt) -> Node:
        return PassStmt()
    
    def visit_raise_stmt(self, node: RaiseStmt) -> Node:
        return RaiseStmt(self.optional_node(node.expr),
                         self.optional_node(node.from_expr))
    
    def visit_try_stmt(self, node: TryStmt) -> Node:
        return TryStmt(self.block(node.body),
                       self.optional_names(node.vars),
                       self.optional_nodes(node.types),
                       self.blocks(node.handlers),
                       self.optional_block(node.else_body),
                       self.optional_block(node.finally_body))
    
    def visit_with_stmt(self, node: WithStmt) -> Node:
        return WithStmt(self.nodes(node.expr),
                        self.optional_names(node.name),
                        self.block(node.body))
    
    def visit_print_stmt(self, node: PrintStmt) -> Node:
        return PrintStmt(self.nodes(node.args),
                         node.newline)
    
    def visit_int_expr(self, node: IntExpr) -> Node:
        return IntExpr(node.value)
    
    def visit_str_expr(self, node: StrExpr) -> Node:
        return StrExpr(node.value)
    
    def visit_bytes_expr(self, node: BytesExpr) -> Node:
        return BytesExpr(node.value)
    
    def visit_unicode_expr(self, node: UnicodeExpr) -> Node:
        return UnicodeExpr(node.value)
    
    def visit_float_expr(self, node: FloatExpr) -> Node:
        return FloatExpr(node.value)
    
    def visit_paren_expr(self, node: ParenExpr) -> Node:
        return ParenExpr(self.node(node.expr))
    
    def visit_name_expr(self, node: NameExpr) -> Node:
        return self.duplicate_name(node)

    def duplicate_name(self, node: NameExpr) -> NameExpr:
        # This method is used when the transform result must be a NameExpr.
        # visit_name_expr() is used when there is no such restriction.
        new = NameExpr(node.name)
        new.info = node.info
        self.copy_ref(new, node)
        return new
    
    def visit_member_expr(self, node: MemberExpr) -> Node:
        member = MemberExpr(self.node(node.expr),
                            node.name)
        if node.def_var:
            member.def_var = self.visit_var(node.def_var)
        self.copy_ref(member, node)
        return member

    def copy_ref(self, new: RefExpr, original: RefExpr) -> None:
        new.kind = original.kind
        new.fullname = original.fullname
        target = original.node
        if isinstance(target, Var):
            target = self.visit_var(target)
        new.node = target
        new.is_def = original.is_def        
    
    def visit_call_expr(self, node: CallExpr) -> Node:
        return CallExpr(self.node(node.callee),
                        self.nodes(node.args),
                        node.arg_kinds[:],
                        node.arg_names[:],
                        self.optional_node(node.analyzed))
    
    def visit_op_expr(self, node: OpExpr) -> Node:
        new = OpExpr(node.op, self.node(node.left), self.node(node.right))
        new.method_type = self.optional_type(node.method_type)
        return new
    
    def visit_cast_expr(self, node: CastExpr) -> Node:
        return CastExpr(self.node(node.expr),
                        self.type(node.type))
    
    def visit_super_expr(self, node: SuperExpr) -> Node:
        new = SuperExpr(node.name)
        new.info = node.info
        return new
    
    def visit_unary_expr(self, node: UnaryExpr) -> Node:
        new = UnaryExpr(node.op, self.node(node.expr))
        new.method_type = self.optional_type(node.method_type)
        return new
    
    def visit_list_expr(self, node: ListExpr) -> Node:
        return ListExpr(self.nodes(node.items))
    
    def visit_dict_expr(self, node: DictExpr) -> Node:
        return DictExpr([(self.node(key), self.node(value))
                         for key, value in node.items])
    
    def visit_tuple_expr(self, node: TupleExpr) -> Node:
        return TupleExpr(self.nodes(node.items))
    
    def visit_set_expr(self, node: SetExpr) -> Node:
        return SetExpr(self.nodes(node.items))
    
    def visit_index_expr(self, node: IndexExpr) -> Node:
        new = IndexExpr(self.node(node.base), self.node(node.index))
        if node.method_type:
            new.method_type = self.type(node.method_type)
        if node.analyzed:
            new.analyzed = self.visit_type_application(node.analyzed)
            new.analyzed.set_line(node.analyzed.line)
        return new
    
    def visit_undefined_expr(self, node: UndefinedExpr) -> Node:
        return UndefinedExpr(self.type(node.type))
    
    def visit_type_application(self, node: TypeApplication) -> TypeApplication:
        return TypeApplication(self.node(node.expr),
                               self.types(node.types))
    
    def visit_list_comprehension(self, node: ListComprehension) -> Node:
        generator = self.duplicate_generator(node.generator)
        generator.set_line(node.generator.line)
        return ListComprehension(generator)
    
    def visit_generator_expr(self, node: GeneratorExpr) -> Node:
        return self.duplicate_generator(node)

    def duplicate_generator(self, node: GeneratorExpr) -> GeneratorExpr:
        return GeneratorExpr(self.node(node.left_expr),
                             self.names(node.index),
                             self.optional_types(node.types),
                             self.node(node.right_expr),
                             self.optional_node(node.condition))
    
    def visit_slice_expr(self, node: SliceExpr) -> Node:
        return SliceExpr(self.optional_node(node.begin_index),
                         self.optional_node(node.end_index),
                         self.optional_node(node.stride))
    
    def visit_conditional_expr(self, node: ConditionalExpr) -> Node:
        return ConditionalExpr(self.node(node.cond),
                               self.node(node.if_expr),
                               self.node(node.else_expr))
    
    def visit_type_var_expr(self, node: TypeVarExpr) -> Node:
        return TypeVarExpr(node.name(), node.fullname(),
                           self.types(node.values))

    def visit_ducktype_expr(self, node: DucktypeExpr) -> Node:
        return DucktypeExpr(node.type)

    def visit_disjointclass_expr(self, node: DisjointclassExpr) -> Node:
        return DisjointclassExpr(node.cls)
    
    def visit_coerce_expr(self, node: CoerceExpr) -> Node:
        raise RuntimeError('Not supported')
    
    def visit_type_expr(self, node: TypeExpr) -> Node:
        raise RuntimeError('Not supported')
    
    def visit_java_cast(self, node: JavaCast) -> Node:
        raise RuntimeError('Not supported')
    
    def visit_temp_node(self, node: TempNode) -> Node:
        return TempNode(self.type(node.type))

    def node(self, node: Node) -> Node:
        new = node.accept(self)
        new.set_line(node.line)
        return new        

    # Helpers
    #
    # All the node helpers also propagate line numbers.

    def optional_node(self, node: Node) -> Node:
        if node:
            return self.node(node)
        else:
            return None

    def block(self, block: Block) -> Block:
        new = self.visit_block(block)
        new.line = block.line
        return new

    def optional_block(self, block: Block) -> Block:
        if block:
            return self.block(block)
        else:
            return None

    def nodes(self, nodes: List[Node]) -> List[Node]:
        return [self.node(node) for node in nodes]

    def optional_nodes(self, nodes: List[Node]) -> List[Node]:
        return [self.optional_node(node) for node in nodes]

    def blocks(self, blocks: List[Block]) -> List[Block]:
        return [self.block(block) for block in blocks]

    def names(self, names: List[NameExpr]) -> List[NameExpr]:
        return [self.duplicate_name(name) for name in names]

    def optional_names(self, names: List[NameExpr]) -> List[NameExpr]:
        result = List[NameExpr]()
        for name in names:
            if name:
                result.append(self.duplicate_name(name))
            else:
                result.append(None)
        return result
    
    def type(self, type: Type) -> Type:
        # Override this method to transform types.
        return type

    def optional_type(self, type: Type) -> Type:
        if type:
            return self.type(type)
        else:
            return None

    def types(self, types: List[Type]) -> List[Type]:
        return [self.type(type) for type in types]

    def optional_types(self, types: List[Type]) -> List[Type]:
        return [self.optional_type(type) for type in types]

########NEW FILE########
__FILENAME__ = typeanal
"""Semantic analysis of types"""

from typing import Undefined, Function, cast, List, Tuple

from mypy.types import (
    Type, UnboundType, TypeVar, TupleType, Instance, AnyType, Callable,
    Void, NoneTyp, TypeList, TypeVarDef, TypeVisitor
)
from mypy.typerepr import TypeVarRepr
from mypy.nodes import (
    GDEF, TypeInfo, Context, SymbolTableNode, TVAR, TypeVarExpr
)
from mypy.sametypes import is_same_type
from mypy import nodes


class TypeAnalyser(TypeVisitor[Type]):
    """Semantic analyzer for types (semantic analysis pass 2)."""

    def __init__(self, lookup_func: Function[[str, Context], SymbolTableNode],
                 fail_func: Function[[str, Context], None]) -> None:
        self.lookup = lookup_func
        self.fail = fail_func
    
    def visit_unbound_type(self, t: UnboundType) -> Type:
        sym = self.lookup(t.name, t)
        if sym is not None:
            if sym.kind == TVAR:
                if len(t.args) > 0:
                    self.fail('Type variable "{}" used with arguments'.format(
                        t.name), t)
                if t.repr:
                    rep = TypeVarRepr(t.repr.components[0])
                else:
                    rep = None
                values = cast(TypeVarExpr, sym.node).values
                return TypeVar(t.name, sym.tvar_id, values, False, t.line, rep)
            elif sym.node.fullname() == 'builtins.None':
                return Void()
            elif sym.node.fullname() == 'typing.Any':
                return AnyType()
            elif sym.node.fullname() == 'typing.Tuple':
                return TupleType(self.anal_array(t.args))
            elif sym.node.fullname() == 'typing.Function':
                return self.analyze_function_type(t)
            elif not isinstance(sym.node, TypeInfo):
                name = sym.fullname
                if name is None:
                    name = sym.node.name()
                self.fail('Invalid type "{}"'.format(name), t)
                return t
            info = cast(TypeInfo, sym.node)
            if len(t.args) > 0 and info.fullname() == 'builtins.tuple':
                return TupleType(self.anal_array(t.args), t.line, t.repr)
            else:
                # Analyze arguments and construct Instance type. The
                # number of type arguments and their values are
                # checked only later, since we do not always know the
                # valid count at this point. Thus we may construct an
                # Instance with an invalid number of type arguments.
                return Instance(info, self.anal_array(t.args), t.line, t.repr)
        else:
            return t
    
    def visit_any(self, t: AnyType) -> Type:
        return t
    
    def visit_void(self, t: Void) -> Type:
        return t
    
    def visit_none_type(self, t: NoneTyp) -> Type:
        return t

    def visit_type_list(self, t: TypeList) -> Type:
        self.fail('Invalid type', t)
    
    def visit_instance(self, t: Instance) -> Type:
        return t
    
    def visit_type_var(self, t: TypeVar) -> Type:
        raise RuntimeError('TypeVar is already analysed')
    
    def visit_callable(self, t: Callable) -> Type:
        res = Callable(self.anal_array(t.arg_types),
                       t.arg_kinds,
                       t.arg_names,
                       t.ret_type.accept(self),
                       t.is_type_obj(),
                       t.name,
                       self.anal_var_defs(t.variables),
                       self.anal_bound_vars(t.bound_vars), t.line, t.repr)
        
        return res
    
    def visit_tuple_type(self, t: TupleType) -> Type:
        return TupleType(self.anal_array(t.items), t.line, t.repr)

    def analyze_function_type(self, t: UnboundType) -> Type:
        if len(t.args) != 2:
            self.fail('Invalid function type', t)
        if not isinstance(t.args[0], TypeList):
            self.fail('Invalid function type', t)
            return AnyType()
        args = (cast(TypeList, t.args[0])).items
        return Callable(self.anal_array(args),
                        [nodes.ARG_POS] * len(args), [None] * len(args),
                        ret_type=t.args[1].accept(self),
                        is_type_obj=False)
    
    def anal_array(self, a: List[Type]) -> List[Type]:
        res = List[Type]()
        for t in a:
            res.append(t.accept(self))
        return res
    
    def anal_bound_vars(self,
                        a: List[Tuple[int, Type]]) -> List[Tuple[int, Type]]:
        res = List[Tuple[int, Type]]()
        for id, t in a:
            res.append((id, t.accept(self)))
        return res
    
    def anal_var_defs(self, var_defs: List[TypeVarDef]) -> List[TypeVarDef]:
        a = List[TypeVarDef]()
        for vd in var_defs:
            a.append(TypeVarDef(vd.name, vd.id, self.anal_array(vd.values),
                                vd.line, vd.repr))
        return a


class TypeAnalyserPass3(TypeVisitor[None]):
    """Analyze type argument counts and values of generic types.

    This is semantic analysis pass 3 for types.

    Perform these operations:

     * Report error for invalid type argument counts, such as List[x, y].
     * Make implicit Any type argumenents explicit my modifying types
       in-place. For example, modify Foo into Foo[Any] if Foo expects a single
       type argument.
     * If a type variable has a value restriction, ensure that the value is
       valid. For example, reject IO[int] if the type argument must be str
       or bytes.

    We can't do this earlier than the third pass, since type argument counts
    are only determined in pass 2, and we have to support forward references
    to types.
    """

    def __init__(self, fail_func: Function[[str, Context], None]) -> None:
        self.fail = fail_func
    
    def visit_instance(self, t: Instance) -> None:
        info = t.type
        # Check type argument count.
        if len(t.args) != len(info.type_vars):
            if len(t.args) == 0:
                # Insert implicit 'Any' type arguments.
                t.args = [AnyType()] * len(info.type_vars)
                return
            # Invalid number of type parameters.
            n = len(info.type_vars)
            s = '{} type arguments'.format(n)
            if n == 0:
                s = 'no type arguments'
            elif n == 1:
                s = '1 type argument'
            act = str(len(t.args))
            if act == '0':
                act = 'none'
            self.fail('"{}" expects {}, but {} given'.format(
                info.name(), s, act), t)
        elif info.defn.type_vars:
            # Check type argument values.
            for arg, typevar in zip(t.args, info.defn.type_vars):
                if typevar.values:
                    if isinstance(arg, TypeVar):
                        arg_values = arg.values
                        if not arg_values:
                            self.fail('Type variable "{}" not valid as type '
                                      'argument value for "{}"'.format(
                                          arg.name, info.name()), t)
                            continue
                    else:
                        arg_values = [arg]
                    self.check_type_var_values(info, arg_values,
                                               typevar.values, t)
        for arg in t.args:
            arg.accept(self)

    def check_type_var_values(self, type: TypeInfo, actuals: List[Type],
                              valids: List[Type], context: Context) -> None:
        for actual in actuals:
            if (not isinstance(actual, AnyType) and
                not any(is_same_type(actual, value) for value in valids)):
                self.fail('Invalid type argument value for "{}"'.format(
                    type.name()), context)

    def visit_callable(self, t: Callable) -> None:
        t.ret_type.accept(self)
        for arg_type in t.arg_types:
            arg_type.accept(self)
    
    def visit_tuple_type(self, t: TupleType) -> None:
        for item in t.items:
            item.accept(self)

    # Other kinds of type are trivial, since they are atomic (or invalid).

    def visit_unbound_type(self, t: UnboundType) -> None:
        pass
    
    def visit_any(self, t: AnyType) -> None:
        pass
    
    def visit_void(self, t: Void) -> None:
        pass
    
    def visit_none_type(self, t: NoneTyp) -> None:
        pass

    def visit_type_list(self, t: TypeList) -> None:
        self.fail('Invalid type', t)
    
    def visit_type_var(self, t: TypeVar) -> None:
        pass

########NEW FILE########
__FILENAME__ = typefixture
"""Fixture used in type-related test cases.

It contains class TypeInfos and Type objects.
"""

from typing import List

from mypy.types import (
    TypeVar, AnyType, Void, ErrorType, NoneTyp, Instance, Callable, TypeVarDef,
    BasicTypes
)
from mypy.nodes import (
    TypeInfo, ClassDef, Block, ARG_POS, ARG_OPT, ARG_STAR, SymbolTable
)


class TypeFixture:
    """Helper class that is used as a fixture in type-related unit tests.

    The members are initialized to contain various type-related values.
    """
    
    def __init__(self):
        # Type variables

        self.t = TypeVar('T', 1, [])    # T`1 (type variable)
        self.tf = TypeVar('T', -1, [])  # T`-1 (type variable)
        self.tf2 = TypeVar('T', -2, []) # T`-2 (type variable)
        self.s = TypeVar('S', 2, [])    # S`2 (type variable)
        self.s1 = TypeVar('S', 1, [])   # S`1 (type variable)
        self.sf = TypeVar('S', -2, [])  # S`-2 (type variable)
        self.sf1 = TypeVar('S', -1, []) # S`-1 (type variable)

        # Simple types

        self.anyt = AnyType()
        self.void = Void()
        self.err = ErrorType()
        self.nonet = NoneTyp()

        # Abstract class TypeInfos

        # class F
        self.fi = make_type_info('F', is_abstract=True)

        # class F2
        self.f2i = make_type_info('F2', is_abstract=True)

        # class F3(F)
        self.f3i = make_type_info('F3', is_abstract=True, mro=[self.fi])

        # Class TypeInfos

        self.oi = make_type_info('builtins.object')         # class object
        self.std_tuplei = make_type_info('builtins.tuple')  # class tuple
        self.type_typei = make_type_info('builtins.type')   # class type
        self.std_functioni = make_type_info('std::Function') # Function TODO
        self.ai = make_type_info('A', mro=[self.oi])        # class A
        self.bi = make_type_info('B', mro=[self.ai, self.oi]) # class B(A)
        self.ci = make_type_info('C', mro=[self.ai, self.oi]) # class C(A)
        self.di = make_type_info('D', mro=[self.oi])        # class D

        # class E(F)
        self.ei = make_type_info('E', mro=[self.fi, self.oi])

        # class E2(F2, F)
        self.e2i = make_type_info('E2', mro=[self.f2i, self.fi, self.oi])

        # class E3(F, F2)
        self.e3i = make_type_info('E3', mro=[self.fi, self.f2i, self.oi])

        # Generic class TypeInfos

        # G[T]
        self.gi = make_type_info('G', mro=[self.oi], typevars=['T'])
        # G2[T]
        self.g2i = make_type_info('G2', mro=[self.oi], typevars=['T'])
        # H[S, T]
        self.hi = make_type_info('H', mro=[self.oi], typevars=['S', 'T'])
        # GS[T, S] <: G[S]
        self.gsi = make_type_info('GS', mro=[self.gi, self.oi],
                                  typevars=['T', 'S'],
                                  bases=[Instance(self.gi, [self.s])])
        # GS2[S] <: G[S]
        self.gs2i = make_type_info('GS2', mro=[self.gi, self.oi],
                                   typevars=['S'],
                                   bases=[Instance(self.gi, [self.s1])])
        # list[T]
        self.std_listi = make_type_info('builtins.list', mro=[self.oi],
                                        typevars=['T'])

        # Instance types

        self.o = Instance(self.oi, [])                       # object
        self.std_tuple = Instance(self.std_tuplei, [])       # tuple
        self.type_type = Instance(self.type_typei, [])         # type
        self.std_function = Instance(self.std_functioni, []) # function TODO
        self.a = Instance(self.ai, [])          # A
        self.b = Instance(self.bi, [])          # B
        self.c = Instance(self.ci, [])          # C
        self.d = Instance(self.di, [])          # D

        self.e = Instance(self.ei, [])          # E
        self.e2 = Instance(self.e2i, [])        # E2
        self.e3 = Instance(self.e3i, [])        # E3

        self.f = Instance(self.fi, [])          # F
        self.f2 = Instance(self.f2i, [])        # F2
        self.f3 = Instance(self.f3i, [])        # F3

        # Generic instance types

        self.ga = Instance(self.gi, [self.a])        # G[A]
        self.gb = Instance(self.gi, [self.b])        # G[B]
        self.go = Instance(self.gi, [self.o])        # G[object]
        self.gt = Instance(self.gi, [self.t])        # G[T`1]
        self.gtf = Instance(self.gi, [self.tf])      # G[T`-1]
        self.gtf2 = Instance(self.gi, [self.tf2])    # G[T`-2]
        self.gs = Instance(self.gi, [self.s])        # G[S]
        self.gdyn = Instance(self.gi, [self.anyt])    # G[Any]

        self.g2a = Instance(self.g2i, [self.a])      # G2[A]

        self.gsab = Instance(self.gsi, [self.a, self.b])  # GS[A, B]
        self.gsba = Instance(self.gsi, [self.b, self.a])  # GS[B, A]

        self.gs2a = Instance(self.gs2i, [self.a])    # GS2[A]

        self.hab = Instance(self.hi, [self.a, self.b])    # H[A, B]
        self.haa = Instance(self.hi, [self.a, self.a])    # H[A, A]
        self.hbb = Instance(self.hi, [self.b, self.b])    # H[B, B]
        self.hts = Instance(self.hi, [self.t, self.s])    # H[T, S]

        self.lsta = Instance(self.std_listi, [self.a])  # List[A]
        self.lstb = Instance(self.std_listi, [self.b])  # List[B]

        # Basic types
        self.basic = BasicTypes(self.o, self.type_type, self.std_tuple,
                                self.std_function)
    
    # Helper methods
    
    def callable(self, *a):
        """callable(a1, ..., an, r) constructs a callable with argument types
        a1, ... an and return type r.
        """
        return Callable(a[:-1], [ARG_POS] * (len(a) - 1),
                        [None] * (len(a) - 1), a[-1], False)
    
    def callable_type(self, *a):
        """callable_type(a1, ..., an, r) constructs a callable with
        argument types a1, ... an and return type r, and which
        represents a type.
        """
        return Callable(a[:-1], [ARG_POS] * (len(a) - 1),
                        [None] * (len(a) - 1), a[-1], True)
    
    def callable_default(self, min_args, *a):
        """callable_default(min_args, a1, ..., an, r) constructs a
        callable with argument types a1, ... an and return type r,
        with min_args mandatory fixed arguments.
        """
        n = len(a) - 1
        return Callable(a[:-1],
                        [ARG_POS] * min_args + [ARG_OPT] * (n - min_args),
                        [None]  * n,
                        a[-1], False)
    
    def callable_var_arg(self, min_args, *a):
        """callable_var_arg(min_args, a1, ..., an, r) constructs a callable
        with argument types a1, ... *an and return type r.
        """
        n = len(a) - 1
        return Callable(a[:-1],
                        [ARG_POS] * min_args +
                        [ARG_OPT] * (n - 1 - min_args) +
                        [ARG_STAR], [None] * n,
                        a[-1], False)


class InterfaceTypeFixture(TypeFixture):
    """Extension of TypeFixture that contains additional generic
    interface types."""
    
    def __init__(self):
        super().__init__()
        # GF[T]
        self.gfi = make_type_info('GF', typevars=['T'], is_abstract=True)
    
        # M1 <: GF[A]
        self.m1i = make_type_info('M1',
                                  is_abstract=True,
                                  mro=[self.gfi, self.oi],
                                  bases=[Instance(self.gfi, [self.a])])

        self.gfa = Instance(self.gfi, [self.a]) # GF[A]
        self.gfb = Instance(self.gfi, [self.b]) # GF[B]

        self.m1 = Instance(self.m1i, []) # M1


def make_type_info(name: str,
                   is_abstract: bool = False,
                   mro: List[TypeInfo] = None,
                   bases: List[Instance] = None,
                   typevars: List[str] = None) -> TypeInfo:
    """Make a TypeInfo suitable for use in unit tests."""
    
    class_def = ClassDef(name, Block([]), None, [])
    class_def.fullname = name
    
    if typevars:
        v = [] # type: List[TypeVarDef]
        id = 1
        for n in typevars:
            v.append(TypeVarDef(n, id, None))
            id += 1
        class_def.type_vars = v
    
    info = TypeInfo(SymbolTable(), class_def)
    if mro is None:
        mro = []
    info.mro = [info] + mro
    if bases is None:
        if mro:
            # By default, assume that there is a single non-generic base.
            bases = [Instance(mro[0], [])]
        else:
            bases = []
    info.bases = bases
    
    return info

########NEW FILE########
__FILENAME__ = typerepr
"""Representation classes for Type subclasses and TypeVars.

These are used for source-source transformation that preserves original
formatting and comments.
"""

from typing import List, Any

from mypy.lex import Token


class CommonTypeRepr:
    """Representation of UnboundType, Instance and Callable."""
    def __init__(self, components: List[Token],  langle, commas: List[Token],
                  rangle: Any) -> None:
        # Note: langle and rangle may be empty.
        self.components = components
        self.langle = langle
        self.commas = commas
        self.rangle = rangle


class ListTypeRepr:
    """Representation of list type t[]."""
    def __init__(self, lbracket, rbracket) -> None:
        self.lbracket = lbracket
        self.rbracket = rbracket


class AnyRepr:
    """Representation of Any."""
    def __init__(self, any_tok: Any) -> None:
        self.any_tok = any_tok


class VoidRepr:
    """Representation of the 'None' type."""
    def __init__(self, void: Any) -> None:
        self.void = void


class CallableRepr:
    """Representation of Callable."""
    def __init__(self, func: Any, langle: Any, lparen: Any, commas: Any,
                  rparen: Any, rangle: Any) -> None:
        self.func = func
        self.langle = langle
        self.lparen = lparen
        self.commas = commas
        self.rparen = rparen
        self.rangle = rangle


class TypeVarRepr:
    """Representation of TypeVar."""
    def __init__(self, name: Any) -> None:
        self.name = name


class TypeVarsRepr:
    """Representation of TypeVars."""
    def __init__(self, langle: Any, commas: List[Token], rangle: Any) -> None:
        self.langle = langle
        self.commas = commas
        self.rangle = rangle


class TypeVarDefRepr:
    """Representation of TypeVarDef."""
    def __init__(self, name: Any, is_tok: Any) -> None:
        # TODO remove is_tok
        self.name = name
        self.is_tok = is_tok

########NEW FILE########
__FILENAME__ = types
"""Classes for representing mypy types."""

from abc import abstractmethod
from typing import Undefined, Any, typevar, List, Tuple, cast, Generic

import mypy.nodes


T = typevar('T')


class Type(mypy.nodes.Context):
    """Abstract base class for all types."""
    
    line = 0
    repr = Undefined(Any)
    
    def __init__(self, line: int = -1, repr=None) -> None:
        self.line = line
        self.repr = repr

    def get_line(self) -> int:
        return self.line
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        raise RuntimeError('Not implemented')
    
    def __repr__(self) -> str:
        return self.accept(TypeStrVisitor())


class TypeVarDef(mypy.nodes.Context):
    """Definition of a single type variable."""
    
    name = ''
    id = 0
    values = Undefined(List[Type])
    line = 0
    repr = Undefined(Any)
    
    def __init__(self, name: str, id: int, values: List[Type], line: int = -1,
                 repr: Any = None) -> None:
        self.name = name
        self.id = id
        self.values = values
        self.line = line
        self.repr = repr

    def get_line(self) -> int:
        return self.line
    
    def __repr__(self) -> str:
        if self.values:
            return '{} in {}'.format(self.name, tuple(self.values))
        else:
            return self.name


class UnboundType(Type):
    """Instance type that has not been bound during semantic analysis."""
    
    name = ''
    args = Undefined(List[Type])
    
    def __init__(self, name: str, args: List[Type] = None, line: int = -1,
                 repr: Any = None) -> None:
        if not args:
            args = []
        self.name = name
        self.args = args
        super().__init__(line, repr)
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_unbound_type(self)


class ErrorType(Type):
    """The error type is used as the result of failed type operations."""
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_error_type(self)


class TypeList(Type):
    """A list of types [...].

    This is only used for the arguments of a Function type, i.e. for
    [arg, ...] in Function[[arg, ...], ret].
    """

    items = Undefined(List[Type])

    def __init__(self, items: List[Type], line: int = -1,
                 repr: Any = None) -> None:
        super().__init__(line, repr)
        self.items = items
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_type_list(self)


class AnyType(Type):
    """The type 'Any'."""
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_any(self)


class Void(Type):
    """The return type 'None'.

    This can only be used as the return type in a callable type and as
    the result type of calling such callable.
    """
    
    source = ''   # May be None; function that generated this value
    
    def __init__(self, source: str = None, line: int = -1,
                 repr: Any = None) -> None:
        self.source = source
        super().__init__(line, repr)
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_void(self)
    
    def with_source(self, source: str) -> 'Void':
        return Void(source, self.line, self.repr)


class NoneTyp(Type):
    """The type of 'None'.

    This is only used internally during type inference.  Programs
    cannot declare a variable of this type, and the type checker
    refuses to infer this type for a variable. However, subexpressions
    often have this type. Note that this is not used as the result
    type when calling a function with a void type, even though
    semantically such a function returns a None value; the void type
    is used instead so that we can report an error if the caller tries
    to do anything with the return value.
    """
    
    def __init__(self, line: int = -1, repr=None) -> None:
        super().__init__(line, repr)
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_none_type(self)


class ErasedType(Type):
    """Placeholder for an erased type.

    This is used during type inference. This has the special property that
    it is ignored during type inference.
    """
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_erased_type(self)


class Instance(Type):
    """An instance type of form C[T1, ..., Tn].

    The list of type variables may be empty.
    """
    
    type = Undefined(mypy.nodes.TypeInfo)
    args = Undefined(List[Type])
    erased = False      # True if result of type variable substitution
    
    def __init__(self, typ: mypy.nodes.TypeInfo, args: List[Type],
                 line: int = -1, repr: Any = None,
                 erased: Any = False) -> None:
        self.type = typ
        self.args = args
        self.erased = erased
        super().__init__(line, repr)
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_instance(self)


BOUND_VAR = 2
OBJECT_VAR = 3


class TypeVar(Type):
    """A type variable type.

    This refers to either a class type variable (id > 0) or a function
    type variable (id < 0).
    """
    
    name = '' # Name of the type variable (for messages and debugging)
    id = 0    # 1, 2, ... for type-related, -1, ... for function-related
    values = Undefined(List[Type])  # Value restriction
    
    # True if refers to the value of the type variable stored in a generic
    # instance wrapper. This is only relevant for generic class wrappers. If
    # False (default), this refers to the type variable value(s) given as the
    # implicit type variable argument.
    #
    # Can also be BoundVar/ObjectVar TODO better representation
    is_wrapper_var = Undefined(Any)
    
    def __init__(self, name: str, id: int, values: List[Type],
                 is_wrapper_var: Any = False, line: int = -1,
                 repr: Any = None) -> None:
        self.name = name
        self.id = id
        self.values = values
        self.is_wrapper_var = is_wrapper_var
        super().__init__(line, repr)
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_type_var(self)


class FunctionLike(Type):
    """Abstract base class for function types."""

    @abstractmethod
    def is_type_obj(self) -> bool: pass

    @abstractmethod
    def type_object(self) -> mypy.nodes.TypeInfo: pass

    @abstractmethod
    def items(self) -> List['Callable']: pass

    @abstractmethod
    def with_name(self, name: str) -> Type: pass


class Callable(FunctionLike):
    """Type of a non-overloaded callable object (function)."""
    
    arg_types = Undefined(List[Type]) # Types of function arguments
    arg_kinds = Undefined(List[int])  # mypy.nodes.ARG_ constants
    arg_names = Undefined(List[str])  # None if not a keyword argument
    min_args = 0               # Minimum number of arguments
    is_var_arg = False         # Is it a varargs function?
    ret_type = Undefined(Type) # Return value type
    name = ''                  # Name (may be None; for error messages)
    # Type variables for a generic function
    variables = Undefined(List[TypeVarDef])
    
    # Implicit bound values of type variables. These can be either for
    # class type variables or for generic function type variables.
    # For example, the method 'append' of List[int] has implicit value
    # 'int' for the list type variable; the explicit method type is
    # just 'def append(int) -> None', without any type variable. Implicit
    # values are needed for runtime type checking, but they do not
    # affect static type checking.
    #
    # All class type arguments must be stored first, ordered by id,
    # and function type arguments must be stored next, again ordered by id
    # (absolute value this time).
    #
    # Stored as tuples (id, type).
    bound_vars = Undefined(List[Tuple[int, Type]])
    
    _is_type_obj = False # Does this represent a type object?
    
    def __init__(self, arg_types: List[Type],
                 arg_kinds: List[int],
                 arg_names: List[str],
                 ret_type: Type,
                 is_type_obj: bool,
                 name: str = None, variables: List[TypeVarDef] = None,
                 bound_vars: List[Tuple[int, Type]] = None,
                 line: int = -1, repr: Any = None) -> None:
        if variables is None:
            variables = []
        if not bound_vars:
            bound_vars = []
        self.arg_types = arg_types
        self.arg_kinds = arg_kinds
        self.arg_names = arg_names
        self.min_args = arg_kinds.count(mypy.nodes.ARG_POS)
        self.is_var_arg = mypy.nodes.ARG_STAR in arg_kinds
        self.ret_type = ret_type
        self._is_type_obj = is_type_obj
        assert not name or '<bound method' not in name
        self.name = name
        self.variables = variables
        self.bound_vars = bound_vars
        super().__init__(line, repr)
    
    def is_type_obj(self) -> bool:
        return self._is_type_obj

    def type_object(self) -> mypy.nodes.TypeInfo:
        assert self._is_type_obj
        return (cast(Instance, self.ret_type)).type
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_callable(self)
    
    def with_name(self, name: str) -> 'Callable':
        """Return a copy of this type with the specified name."""
        ret = self.ret_type
        if isinstance(ret, Void):
            ret = ret.with_source(name)
        return Callable(self.arg_types,
                        self.arg_kinds,
                        self.arg_names,
                        ret,
                        self.is_type_obj(),
                        name,
                        self.variables,
                        self.bound_vars,
                        self.line, self.repr)
    
    def max_fixed_args(self) -> int:
        n = len(self.arg_types)
        if self.is_var_arg:
            n -= 1
        return n
    
    def items(self) -> List['Callable']:
        return [self]
    
    def is_generic(self) -> bool:
        return bool(self.variables)
    
    def type_var_ids(self) -> List[int]:
        a = List[int]()
        for tv in self.variables:
            a.append(tv.id)
        return a


class Overloaded(FunctionLike):
    """Overloaded function type T1, ... Tn, where each Ti is Callable.
    
    The variant to call is chosen based on runtime argument types; the first
    matching signature is the target.
    """
    
    _items = Undefined(List[Callable]) # Must not be empty
    
    def __init__(self, items: List[Callable]) -> None:
        self._items = items
        super().__init__(items[0].line, None)
    
    def items(self) -> List[Callable]:
        return self._items
    
    def name(self) -> str:
        return self._items[0].name
    
    def is_type_obj(self) -> bool:
        # All the items must have the same type object status, so it's
        # sufficient to query only (any) one of them.
        return self._items[0].is_type_obj()

    def type_object(self) -> mypy.nodes.TypeInfo:
        # All the items must have the same type object, so it's sufficient to
        # query only (any) one of them.
        return self._items[0].type_object()
    
    def with_name(self, name: str) -> 'Overloaded':
        ni = List[Callable]()
        for it in self._items:
            ni.append(it.with_name(name))
        return Overloaded(ni)
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_overloaded(self)


class TupleType(Type):
    """The tuple type Tuple[T1, ..., Tn] (at least one type argument)."""
    
    items = Undefined(List[Type])
    
    def __init__(self, items: List[Type], line: int = -1,
                 repr: Any = None) -> None:
        self.items = items
        super().__init__(line, repr)
    
    def length(self) -> int:
        return len(self.items)
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_tuple_type(self)


class RuntimeTypeVar(Type):
    """Reference to a runtime variable with the value of a type variable.

    The reference can must be a expression node, but only some node
    types are properly supported (NameExpr, MemberExpr and IndexExpr
    mainly).
    """
    
    node = Undefined(mypy.nodes.Node)
    
    def __init__(self, node: mypy.nodes.Node) -> None:
        self.node = node
        super().__init__(-1, None)
    
    def accept(self, visitor: 'TypeVisitor[T]') -> T:
        return visitor.visit_runtime_type_var(self)


#
# Visitor-related classes
#


class TypeVisitor(Generic[T]):
    """Visitor class for types (Type subclasses).

    The parameter T is the return type of the visit methods.
    """
    
    def visit_unbound_type(self, t: UnboundType) -> T:
        pass

    def visit_type_list(self, t: TypeList) -> T:
        pass
    
    def visit_error_type(self, t: ErrorType) -> T:
        pass
    
    def visit_any(self, t: AnyType) -> T:
        pass
    
    def visit_void(self, t: Void) -> T:
        pass
    
    def visit_none_type(self, t: NoneTyp) -> T:
        pass
    
    def visit_erased_type(self, t: ErasedType) -> T:
        pass
    
    def visit_type_var(self, t: TypeVar) -> T:
        pass
    
    def visit_instance(self, t: Instance) -> T:
        pass
    
    def visit_callable(self, t: Callable) -> T:
        pass
    
    def visit_overloaded(self, t: Overloaded) -> T:
        pass
    
    def visit_tuple_type(self, t: TupleType) -> T:
        pass
    
    def visit_runtime_type_var(self, t: RuntimeTypeVar) -> T:
        pass


class TypeTranslator(TypeVisitor[Type]):
    """Identity type transformation.

    Subclass this and override some methods to implement a non-trivial
    transformation.
    """
    
    def visit_unbound_type(self, t: UnboundType) -> Type:
        return t

    def visit_type_list(self, t: TypeList) -> Type:
        return t
    
    def visit_error_type(self, t: ErrorType) -> Type:
        return t
    
    def visit_any(self, t: AnyType) -> Type:
        return t
    
    def visit_void(self, t: Void) -> Type:
        return t
    
    def visit_none_type(self, t: NoneTyp) -> Type:
        return t
    
    def visit_erased_type(self, t: ErasedType) -> Type:
        return t
    
    def visit_instance(self, t: Instance) -> Type:
        return Instance(t.type, self.translate_types(t.args), t.line, t.repr)
    
    def visit_type_var(self, t: TypeVar) -> Type:
        return t
    
    def visit_callable(self, t: Callable) -> Type:
        return Callable(self.translate_types(t.arg_types),
                        t.arg_kinds,
                        t.arg_names,
                        t.ret_type.accept(self),
                        t.is_type_obj(),
                        t.name,
                        self.translate_variables(t.variables),
                        self.translate_bound_vars(t.bound_vars),
                        t.line, t.repr)
    
    def visit_tuple_type(self, t: TupleType) -> Type:
        return TupleType(self.translate_types(t.items), t.line, t.repr)
    
    def translate_types(self, types: List[Type]) -> List[Type]:
        return [t.accept(self) for t in types]
    
    def translate_bound_vars(
            self, types: List[Tuple[int, Type]]) -> List[Tuple[int, Type]]:
        return [(id, t.accept(self)) for id, t in types]

    def translate_variables(self,
                            variables: List[TypeVarDef]) -> List[TypeVarDef]:
        return variables


class TypeStrVisitor(TypeVisitor[str]):
    """Visitor for pretty-printing types into strings.

    Do not preserve original formatting.
    
    Notes:
     - Include implicit bound type variables of callables.
     - Represent unbound types as Foo? or Foo?[...].
     - Represent the NoneTyp type as None.
    """
    
    def visit_unbound_type(self, t):
        s = t.name + '?'
        if t.args != []:
            s += '[{}]'.format(self.list_str(t.args))
        return s

    def visit_type_list(self, t):
        return '<TypeList {}>'.format(self.list_str(t.items))
    
    def visit_error_type(self, t):
        return '<ERROR>'
    
    def visit_any(self, t):
        return 'Any'
    
    def visit_void(self, t):
        return 'void'
    
    def visit_none_type(self, t):
        # Include quotes to make this distinct from the None value.
        return "'None'"
    
    def visit_erased_type(self, t):
        return "<Erased>"
    
    def visit_instance(self, t):
        s = t.type.fullname()
        if t.erased:
            s += '*'
        if t.args != []:
            s += '[{}]'.format(self.list_str(t.args))
        return s
    
    def visit_type_var(self, t):
        if t.name is None:
            # Anonymous type variable type (only numeric id).
            return '`{}'.format(t.id)
        else:
            # Named type variable type.
            s = '{}`{}'.format(t.name, t.id)
            if t.is_wrapper_var == BOUND_VAR:
                s += '!B'
            elif t.is_wrapper_var == True:
                s += '!W'
            elif t.is_wrapper_var == OBJECT_VAR:
                s += '!O'
            return s
    
    def visit_callable(self, t):
        s = ''
        bare_asterisk = False
        for i in range(len(t.arg_types)):
            if s != '':
                s += ', '
            if t.arg_kinds[i] == mypy.nodes.ARG_NAMED and not bare_asterisk:
                s += '*, '
                bare_asterisk = True
            if t.arg_kinds[i] == mypy.nodes.ARG_STAR:
                s += '*'
            if t.arg_kinds[i] == mypy.nodes.ARG_STAR2:
                s += '**'
            if t.arg_names[i]:
                s += t.arg_names[i] + ': '
            s += str(t.arg_types[i])
            if t.arg_kinds[i] == mypy.nodes.ARG_OPT:
                s += ' ='
        
        s = '({})'.format(s)
        
        if not isinstance(t.ret_type, Void):
            s += ' -> {}'.format(t.ret_type)
        
        if t.variables:
            s = '{} {}'.format(t.variables, s)
        
        if t.bound_vars != []:
            # Include implicit bound type variables.
            a = []
            for i, bt in t.bound_vars:
                a.append('{}:{}'.format(i, bt))
            s = '[{}] {}'.format(', '.join(a), s)
        
        return 'def {}'.format(s)
    
    def visit_overloaded(self, t):
        a = []
        for i in t.items():
            a.append(i.accept(self))
        return 'Overload({})'.format(', '.join(a))
    
    def visit_tuple_type(self, t):
        s = self.list_str(t.items)
        return 'Tuple[{}]'.format(s)
    
    def visit_runtime_type_var(self, t):
        return '<RuntimeTypeVar>'
    
    def list_str(self, a):
        """Convert items of an array to strings (pretty-print types)
        and join the results with commas.
        """
        res = []
        for t in a:
            if isinstance(t, Type):
                res.append(t.accept(self))
            else:
                res.append(str(t))
        return ', '.join(res)


# These constants define the method used by TypeQuery to combine multiple
# query results, e.g. for tuple types. The strategy is not used for empty
# result lists; in that case the default value takes precedence.
ANY_TYPE_STRATEGY = 0   # Return True if any of the results are True.
ALL_TYPES_STRATEGY = 1  # Return True if all of the results are True.


class TypeQuery(TypeVisitor[bool]):
    """Visitor for performing simple boolean queries of types.

    This class allows defining the default value for leafs to simplify the
    implementation of many queries.
    """
    
    default = False  # Default result
    strategy = 0     # Strategy for combining multiple values
    
    def __init__(self, default: bool, strategy: int) -> None:
        """Construct a query visitor.

        Use the given default result and strategy for combining
        multiple results. The strategy must be either
        ANY_TYPE_STRATEGY or ALL_TYPES_STRATEGY.
        """
        self.default = default
        self.strategy = strategy
    
    def visit_unbound_type(self, t: UnboundType) -> bool:
        return self.default

    def visit_type_list(self, t: TypeList) -> bool:
        return self.default
    
    def visit_error_type(self, t: ErrorType) -> bool:
        return self.default
    
    def visit_any(self, t: AnyType) -> bool:
        return self.default
    
    def visit_void(self, t: Void) -> bool:
        return self.default
    
    def visit_none_type(self, t: NoneTyp) -> bool:
        return self.default
    
    def visit_erased_type(self, t: ErasedType) -> bool:
        return self.default
    
    def visit_type_var(self, t: TypeVar) -> bool:
        return self.default
    
    def visit_instance(self, t: Instance) -> bool:
        return self.query_types(t.args)
    
    def visit_callable(self, t: Callable) -> bool:
        # FIX generics
        return self.query_types(t.arg_types + [t.ret_type])
    
    def visit_tuple_type(self, t: TupleType) -> bool:
        return self.query_types(t.items)
    
    def visit_runtime_type_var(self, t: RuntimeTypeVar) -> bool:
        return self.default
    
    def query_types(self, types: List[Type]) -> bool:
        """Perform a query for a list of types.

        Use the strategy constant to combine the results.
        """
        if not types:
            # Use default result for empty list.
            return self.default
        if self.strategy == ANY_TYPE_STRATEGY:
            # Return True if at least one component is true.
            res = False
            for t in types:
                res = res or t.accept(self)
                if res:
                    break
            return res
        else:
            # Return True if all components are true.
            res = True
            for t in types:
                res = res and t.accept(self)
                if not res:
                    break
            return res


class BasicTypes:
    """Collection of Instance types of basic types (object, type, etc.)."""
    
    def __init__(self, object: Instance, type_type: Instance, tuple: Type,
                  function: Type) -> None:
        self.object = object
        self.type_type = type_type
        self.tuple = tuple
        self.function = function


def strip_type(typ: Type) -> Type:
    """Make a copy of type without 'debugging info' (function name)."""
    
    if isinstance(typ, Callable):
        return Callable(typ.arg_types,
                        typ.arg_kinds,
                        typ.arg_names,
                        typ.ret_type,
                        typ.is_type_obj(),
                        None,
                        typ.variables)
    elif isinstance(typ, Overloaded):
        return Overloaded([cast(Callable, strip_type(item))
                           for item in typ.items()])
    else:
        return typ


def replace_self_type(t: Callable, self_type: Type) -> Callable:
    """Return a copy of a callable type with a different self argument type.

    Assume that the callable is the signature of a method.
    """
    return Callable([self_type] + t.arg_types[1:],
                    t.arg_kinds,
                    t.arg_names,
                    t.ret_type,
                    t.is_type_obj(),
                    t.name,
                    t.variables,
                    t.bound_vars,
                    t.line, None)

########NEW FILE########
__FILENAME__ = util
"""Utility functions."""

from typing import typevar, List, Any


T = typevar('T')


def short_type(obj: object) -> str:
    """Return the last component of the type name of an object.

    If obj is None, return 'nil'. For example, if obj is 1, return 'int'.
    """
    if obj is None:
        return 'nil'
    t = str(type(obj))
    return t.split('.')[-1].rstrip("'>")


def indent(s: str, n: int) -> str:
    """Indent all the lines in s (separated by Newlines) by n spaces."""
    s = ' ' * n + s
    s = s.replace('\n', '\n' + ' ' * n)
    return s


def array_repr(a: List[T]) -> List[str]:
    """Return the items of an array converted to strings using Repr."""
    aa = [] # type: List[str]
    for x in a:
        aa.append(repr(x))
    return aa


def dump_tagged(nodes: List[Any], tag: str) -> str:
    """Convert an array into a pretty-printed multiline string representation.
    
    The format is
      tag(
        item1..
        itemN)
    Individual items are formatted like this:
     - arrays are flattened
     - pairs (str : array) are converted recursively, so that str is the tag
     - other items are converted to strings and indented
    """
    a = [] # type: List[str]
    if tag:
        a.append(tag + '(')
    for n in nodes:
        if isinstance(n, list):
            if n:
                a.append(dump_tagged(n, None))
        elif isinstance(n, tuple):
            s = dump_tagged(n[1], n[0])
            a.append(indent(s, 2))
        elif n:
            a.append(indent(str(n), 2))
    if tag:
        a[-1] += ')'
    return '\n'.join(a)

########NEW FILE########
__FILENAME__ = visitor
"""Generic abstract syntax tree node visitor"""

from typing import typevar, Generic

import mypy.nodes


T = typevar('T')


class NodeVisitor(Generic[T]):
    """Empty base class for parse tree node visitors.

    The T type argument specifies the return type of the visit
    methods. As all methods defined here return None by default,
    subclasses do not always need to override all the methods.

    TODO make the default return value explicit
    """
    
    # Module structure
    
    def visit_mypy_file(self, o: 'mypy.nodes.MypyFile') -> T:
        pass
    
    def visit_import(self, o: 'mypy.nodes.Import') -> T:
        pass
    def visit_import_from(self, o: 'mypy.nodes.ImportFrom') -> T:
        pass
    def visit_import_all(self, o: 'mypy.nodes.ImportAll') -> T:
        pass
    
    # Definitions
    
    def visit_func_def(self, o: 'mypy.nodes.FuncDef') -> T:
        pass
    def visit_overloaded_func_def(self,
                                  o: 'mypy.nodes.OverloadedFuncDef') -> T:
        pass
    def visit_class_def(self, o: 'mypy.nodes.ClassDef') -> T:
        pass
    def visit_var_def(self, o: 'mypy.nodes.VarDef') -> T:
        pass
    def visit_global_decl(self, o: 'mypy.nodes.GlobalDecl') -> T:
        pass
    def visit_decorator(self, o: 'mypy.nodes.Decorator') -> T:
        pass
    
    def visit_var(self, o: 'mypy.nodes.Var') -> T:
        pass
    
    # Statements
    
    def visit_block(self, o: 'mypy.nodes.Block') -> T:
        pass
    
    def visit_expression_stmt(self, o: 'mypy.nodes.ExpressionStmt') -> T:
        pass
    def visit_assignment_stmt(self, o: 'mypy.nodes.AssignmentStmt') -> T:
        pass
    def visit_operator_assignment_stmt(self,
                                 o: 'mypy.nodes.OperatorAssignmentStmt') -> T:
        pass
    def visit_while_stmt(self, o: 'mypy.nodes.WhileStmt') -> T:
        pass
    def visit_for_stmt(self, o: 'mypy.nodes.ForStmt') -> T:
        pass
    def visit_return_stmt(self, o: 'mypy.nodes.ReturnStmt') -> T:
        pass
    def visit_assert_stmt(self, o: 'mypy.nodes.AssertStmt') -> T:
        pass
    def visit_yield_stmt(self, o: 'mypy.nodes.YieldStmt') -> T:
        pass
    def visit_del_stmt(self, o: 'mypy.nodes.DelStmt') -> T:
        pass
    def visit_if_stmt(self, o: 'mypy.nodes.IfStmt') -> T:
        pass
    def visit_break_stmt(self, o: 'mypy.nodes.BreakStmt') -> T:
        pass
    def visit_continue_stmt(self, o: 'mypy.nodes.ContinueStmt') -> T:
        pass
    def visit_pass_stmt(self, o: 'mypy.nodes.PassStmt') -> T:
        pass
    def visit_raise_stmt(self, o: 'mypy.nodes.RaiseStmt') -> T:
        pass
    def visit_try_stmt(self, o: 'mypy.nodes.TryStmt') -> T:
        pass
    def visit_with_stmt(self, o: 'mypy.nodes.WithStmt') -> T:
        pass
    def visit_print_stmt(self, o: 'mypy.nodes.PrintStmt') -> T:
        pass
    
    # Expressions
    
    def visit_int_expr(self, o: 'mypy.nodes.IntExpr') -> T:
        pass
    def visit_str_expr(self, o: 'mypy.nodes.StrExpr') -> T:
        pass
    def visit_bytes_expr(self, o: 'mypy.nodes.BytesExpr') -> T:
        pass
    def visit_unicode_expr(self, o: 'mypy.nodes.UnicodeExpr') -> T:
        pass
    def visit_float_expr(self, o: 'mypy.nodes.FloatExpr') -> T:
        pass
    def visit_paren_expr(self, o: 'mypy.nodes.ParenExpr') -> T:
        pass
    def visit_name_expr(self, o: 'mypy.nodes.NameExpr') -> T:
        pass
    def visit_member_expr(self, o: 'mypy.nodes.MemberExpr') -> T:
        pass
    def visit_call_expr(self, o: 'mypy.nodes.CallExpr') -> T:
        pass
    def visit_op_expr(self, o: 'mypy.nodes.OpExpr') -> T:
        pass
    def visit_cast_expr(self, o: 'mypy.nodes.CastExpr') -> T:
        pass
    def visit_super_expr(self, o: 'mypy.nodes.SuperExpr') -> T:
        pass
    def visit_unary_expr(self, o: 'mypy.nodes.UnaryExpr') -> T:
        pass
    def visit_list_expr(self, o: 'mypy.nodes.ListExpr') -> T:
        pass
    def visit_dict_expr(self, o: 'mypy.nodes.DictExpr') -> T:
        pass
    def visit_tuple_expr(self, o: 'mypy.nodes.TupleExpr') -> T:
        pass
    def visit_set_expr(self, o: 'mypy.nodes.SetExpr') -> T:
        pass
    def visit_index_expr(self, o: 'mypy.nodes.IndexExpr') -> T:
        pass
    def visit_undefined_expr(self, o: 'mypy.nodes.UndefinedExpr') -> T:
        pass
    def visit_type_application(self, o: 'mypy.nodes.TypeApplication') -> T:
        pass
    def visit_func_expr(self, o: 'mypy.nodes.FuncExpr') -> T:
        pass
    def visit_list_comprehension(self, o: 'mypy.nodes.ListComprehension') -> T:
        pass
    def visit_generator_expr(self, o: 'mypy.nodes.GeneratorExpr') -> T:
        pass
    def visit_slice_expr(self, o: 'mypy.nodes.SliceExpr') -> T:
        pass
    def visit_conditional_expr(self, o: 'mypy.nodes.ConditionalExpr') -> T:
        pass
    def visit_type_var_expr(self, o: 'mypy.nodes.TypeVarExpr') -> T:
        pass
    def visit_ducktype_expr(self, o: 'mypy.nodes.DucktypeExpr') -> T:
        pass
    def visit_disjointclass_expr(self, o: 'mypy.nodes.DisjointclassExpr') -> T:
        pass
    
    def visit_coerce_expr(self, o: 'mypy.nodes.CoerceExpr') -> T:
        pass
    def visit_type_expr(self, o: 'mypy.nodes.TypeExpr') -> T:
        pass
    def visit_java_cast(self, o: 'mypy.nodes.JavaCast') -> T:
        pass
    
    def visit_temp_node(self, o: 'mypy.nodes.TempNode') -> T:
        pass

########NEW FILE########
__FILENAME__ = bottles
import typing

REFRAIN = '''
%d bottles of beer on the wall,
%d bottles of beer,
take one down, pass it around,
%d bottles of beer on the wall!
'''
bottles_of_beer = 99
while bottles_of_beer > 1:
    print(REFRAIN % (bottles_of_beer, bottles_of_beer,
        bottles_of_beer - 1))
    bottles_of_beer -= 1

########NEW FILE########
__FILENAME__ = class
import typing

class BankAccount(object):
    def __init__(self, initial_balance: int = 0) -> None:
        self.balance = initial_balance
    def deposit(self, amount: int) -> None:
        self.balance += amount
    def withdraw(self, amount: int) -> None:
        self.balance -= amount
    def overdrawn(self) -> bool:
        return self.balance < 0
my_account = BankAccount(15)
my_account.withdraw(5)
print(my_account.balance)
########NEW FILE########
__FILENAME__ = cmdline
# This program adds up integers in the command line
import sys
import typing
try:
    total = sum(int(arg) for arg in sys.argv[1:])
    print('sum =', total)
except ValueError:
    print('Please supply integer arguments')
########NEW FILE########
__FILENAME__ = dict
import typing
prices = {'apple': 0.40, 'banana': 0.50}
my_purchase = {
    'apple': 1,
    'banana': 6}
grocery_bill = sum(prices[fruit] * my_purchase[fruit]
                   for fruit in my_purchase)
print('I owe the grocer $%.2f' % grocery_bill)

########NEW FILE########
__FILENAME__ = fib
import typing
parents, babies = (1, 1)
while babies < 100:
    print('This generation has {0} babies'.format(babies))
    parents, babies = (babies, parents + babies)

########NEW FILE########
__FILENAME__ = files
# indent your Python code to put into an email
import glob
import typing
# glob supports Unix style pathname extensions
python_files = glob.glob('*.py')
for file_name in sorted(python_files):
    print('    ------' + file_name)

    f = open(file_name)
    for line in f:
        print('    ' + line.rstrip())
    f.close()

    print()
########NEW FILE########
__FILENAME__ = for
import typing
friends = ['john', 'pat', 'gary', 'michael']
for i, name in enumerate(friends):
    print("iteration {iteration} is {name}".format(iteration=i, name=name))

########NEW FILE########
__FILENAME__ = generators
# Prime number sieve with generators

import itertools
from typing import Iterator

def iter_primes() -> Iterator[int]:
     # an iterator of all numbers between 2 and +infinity
     numbers = itertools.count(2)

     # generate primes forever
     while True:
         # get the first number from the iterator (always a prime)
         prime = next(numbers)
         yield prime

         # this code iteratively builds up a chain of
         # filters...slightly tricky, but ponder it a bit
         numbers = filter(prime.__rmod__, numbers)

for p in iter_primes():
    if p > 1000:
        break
    print(p)
########NEW FILE########
__FILENAME__ = greet
import typing

def greet(name: str) -> None:
    print('Hello', name)
greet('Jack')
greet('Jill')
greet('Bob')

########NEW FILE########
__FILENAME__ = guess
# "Guess the Number" Game (edited) from http://inventwithpython.com

import random
import typing

guesses_made = 0

name = input('Hello! What is your name?\n')

number = random.randint(1, 20)
print('Well, {0}, I am thinking of a number between 1 and 20.'.format(name))

while guesses_made < 6:

    guess = int(input('Take a guess: '))

    guesses_made += 1

    if guess < number:
        print('Your guess is too low.')

    if guess > number:
        print('Your guess is too high.')

    if guess == number:
        break

if guess == number:
    print('Good job, {0}! You guessed my number in {1} guesses!'.format(
                                                          name, guesses_made))
else:
    print('Nope. The number I was thinking of was {0}'.format(number))

########NEW FILE########
__FILENAME__ = hello
import typing
print('Hello, world')

########NEW FILE########
__FILENAME__ = input
import typing
name = input('What is your name?\n')
print('Hi, %s.' % name)

########NEW FILE########
__FILENAME__ = itertool
from itertools import groupby
import typing
lines = '''
This is the
first paragraph.

This is the second.
'''.splitlines()
# Use itertools.groupby and bool to return groups of
# consecutive lines that either have content or don't.
for has_chars, frags in groupby(lines, bool):
    if has_chars:
        print(' '.join(frags))
# PRINTS:
# This is the first paragraph.
# This is the second.

########NEW FILE########
__FILENAME__ = regexp
import typing
import re
for test_string in ['555-1212', 'ILL-EGAL']:
    if re.match(r'^\d{3}-\d{4}$', test_string):
        print(test_string, 'is a valid US local phone number')
    else:
        print(test_string, 'rejected')

########NEW FILE########
__FILENAME__ = abc
# Stubs for abc.

# Thesee definitions have special processing in type checker.
class ABCMeta: pass
abstractmethod = object()

########NEW FILE########
__FILENAME__ = builtins
"""Stubs for builtins (Python 2.7)"""

from typing import (
    Undefined, typevar, AbstractGeneric, Iterator, Iterable, overload,
    Sequence, Mapping, Tuple, List, Any, Dict, Function, Generic, Set,
    AbstractSet, Sized, Reversible, SupportsInt, SupportsFloat, SupportsAbs,
    SupportsRound, TextIO, builtinclass, ducktype
)
from abc import abstractmethod, ABCMeta


T = typevar('T')
KT = typevar('KT')
VT = typevar('VT')
S = typevar('S')
T1 = typevar('T1')
T2 = typevar('T2')
T3 = typevar('T3')
T4 = typevar('T4')


staticmethod = object() # Only valid as a decorator.


@builtinclass
class object:
    __doc__ = ''
    __class__ = Undefined # type: type
    
    def __init__(self) -> None: pass
    
    def __eq__(self, o: object) -> bool: pass
    def __ne__(self, o: object) -> bool: pass
    
    def __str__(self) -> str: pass
    def __repr__(self) -> str: pass

    def __hash__(self) -> int: pass


# Classes


@builtinclass
class type:
    __name__ = ''
    __module__ = ''
    __dict__ = Undefined # type: Dict[str, Any]
    
    def __init__(self, o: object) -> None: pass


@builtinclass
@ducktype(float)
class int(SupportsInt, SupportsFloat):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, x: SupportsInt) -> None: pass
    @overload
    def __init__(self, x: str, base: int = 10) -> None: pass
    @overload
    def __init__(self, x: unicode, base: int = 10) -> None: pass
    @overload
    def __init__(self, x: bytearray, base: int = 10) -> None: pass

    def bit_length(self) -> int: pass

    # TODO all __r* methods
    
    def __add__(self, x: int) -> int: pass
    def __sub__(self, x: int) -> int: pass
    def __mul__(self, x: int) -> int: pass
    def __floordiv__(self, x: int) -> int: pass
    def __div__(self, x: int) -> int: pass
    def __truediv__(self, x: int) -> float: pass    
    def __mod__(self, x: int) -> int: pass
    
    def __radd__(self, x: int) -> int: pass
    def __rsub__(self, x: int) -> int: pass
    def __rmul__(self, x: int) -> int: pass
    def __rfloordiv__(self, x: int) -> int: pass
    def __rdiv__(self, x: int) -> int: pass
    def __rtruediv__(self, x: int) -> float: pass
    def __rmod__(self, x: int) -> int: pass

    # Return type can be int or float, depending on the value of x.
    def __pow__(self, x: int) -> Any: pass
    def __rpow__(self, x: int) -> Any: pass

    def __and__(self, n: int) -> int: pass
    def __or__(self, n: int) -> int: pass
    def __xor__(self, n: int) -> int: pass
    def __lshift__(self, n: int) -> int: pass
    def __rshift__(self, n: int) -> int: pass

    def __rand__(self, n: int) -> int: pass
    def __ror__(self, n: int) -> int: pass
    def __rxor__(self, n: int) -> int: pass
    def __rlshift__(self, n: int) -> int: pass
    def __rrshift__(self, n: int) -> int: pass

    def __neg__(self) -> int: pass
    def __invert__(self) -> int: pass

    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    def __lt__(self, x: int) -> bool: pass
    def __le__(self, x: int) -> bool: pass
    def __gt__(self, x: int) -> bool: pass
    def __ge__(self, x: int) -> bool: pass

    # Conversions

    def __str__(self) -> str: pass
    def __float__(self) -> float: pass
    def __int__(self) -> int: return self
    
    def __hash__(self) -> int: pass

    
@builtinclass
class float(SupportsFloat, SupportsInt):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, x: SupportsFloat) -> None: pass
    @overload
    def __init__(self, x: str) -> None: pass
    @overload
    def __init__(self, x: unicode) -> None: pass
    @overload
    def __init__(self, x: bytearray) -> None: pass

    # Operators
    
    def __add__(self, x: float) -> float: pass
    def __sub__(self, x: float) -> float: pass
    def __mul__(self, x: float) -> float: pass
    def __floordiv__(self, x: float) -> float: pass
    def __div__(self, x: float) -> float: pass
    def __truediv__(self, x: float) -> float: pass
    def __mod__(self, x: float) -> float: pass
    def __pow__(self, x: float) -> float: pass
    
    def __radd__(self, x: float) -> float: pass
    def __rsub__(self, x: float) -> float: pass
    def __rmul__(self, x: float) -> float: pass
    def __rfloordiv__(self, x: float) -> float: pass
    def __rdiv__(self, x: float) -> float: pass
    def __rtruediv__(self, x: float) -> float: pass
    def __rmod__(self, x: float) -> float: pass
    def __rpow__(self, x: float) -> float: pass
    
    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    def __lt__(self, x: float) -> bool: pass
    def __le__(self, x: float) -> bool: pass
    def __gt__(self, x: float) -> bool: pass
    def __ge__(self, x: float) -> bool: pass
    def __neg__(self) -> float: pass

    def __str__(self) -> str: pass
    def __int__(self) -> int: pass
    def __float__(self) -> float: return self
    def __hash__(self) -> int: pass


@builtinclass
class complex:
    # TODO this is just a placeholder; add more members
    def __init__(self, re: float, im: float = 0.0) -> None: pass


@builtinclass
class unicode(Sequence[unicode]):
    # TODO maketrans
    
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, o: object) -> None: pass
    @overload
    def __init__(self, o: str, encoding: str = None,
                 errors: str = 'strict') -> None: pass
    @overload
    def __init__(self, o: bytearray, encoding: str = None,
                 errors: str = 'strict') -> None: pass

    def capitalize(self) -> unicode: pass
    def center(self, width: int, fillchar: unicode = u' ') -> unicode: pass
    def count(self, x: unicode) -> int: pass
    def decode(self, encoding: str = 'utf-8',
               errors: str = 'strict') -> unicode: pass
    def encode(self, encoding: str = 'utf-8',
               errors: str = 'strict') -> str: pass
    # TODO tuple suffix; None value for int
    def endswith(self, suffix: unicode, start: int = 0,
                 end: int = None) -> bool: pass
    def expandtabs(self, tabsize: int = 8) -> str: pass
    
    @overload
    def find(self, sub: unicode, start: int = 0) -> int: pass
    @overload
    def find(self, sub: unicode, start: int, end: int) -> int: pass
    
    def format(self, *args: Any, **kwargs: Any) -> unicode: pass
    def format_map(self, map: Mapping[unicode, Any]) -> unicode: pass
    
    @overload
    def index(self, sub: unicode, start: int = 0) -> int: pass
    @overload
    def index(self, sub: unicode, start: int, end: int) -> int: pass
    
    def isalnum(self) -> bool: pass
    def isalpha(self) -> bool: pass
    def isdecimal(self) -> bool: pass
    def isdigit(self) -> bool: pass
    def isidentifier(self) -> bool: pass
    def islower(self) -> bool: pass
    def isnumeric(self) -> bool: pass
    def isprintable(self) -> bool: pass
    def isspace(self) -> bool: pass
    def istitle(self) -> bool: pass
    def isupper(self) -> bool: pass
    def join(self, iterable: Iterable[unicode]) -> unicode: pass
    def ljust(self, width: int, fillchar: unicode = u' ') -> unicode: pass
    def lower(self) -> unicode: pass
    def lstrip(self, chars: unicode = None) -> unicode: pass
    def partition(self, sep: unicode) -> Tuple[unicode, unicode, unicode]: pass
    def replace(self, old: unicode, new: unicode,
                count: int = -1) -> unicode: pass
    
    @overload
    def rfind(self, sub: unicode, start: int = 0) -> int: pass
    @overload
    def rfind(self, sub: unicode, start: int, end: int) -> int: pass
    @overload
    def rindex(self, sub: unicode, start: int = 0) -> int: pass
    @overload
    def rindex(self, sub: unicode, start: int, end: int) -> int: pass
    
    def rjust(self, width: int, fillchar: unicode = u' ') -> unicode: pass
    def rpartition(self, sep: unicode) -> Tuple[unicode, unicode,
                                                unicode]: pass
    def rsplit(self, sep: unicode = None,
               maxsplit: int = -1) -> List[unicode]: pass
    def rstrip(self, chars: unicode = None) -> unicode: pass
    def split(self, sep: unicode = None,
              maxsplit: int = -1) -> List[unicode]: pass
    def splitlines(self, keepends: bool = False) -> List[unicode]: pass
    # TODO tuple prefix; None value for int
    def startswith(self, prefix: unicode, start: int = 0,
                   end: int = None) -> bool: pass
    def strip(self, chars: unicode = None) -> unicode: pass
    def swapcase(self) -> unicode: pass
    def title(self) -> unicode: pass
    def translate(self, table: Dict[int, Any]) -> unicode: pass
    def upper(self) -> unicode: pass
    def zfill(self, width: int) -> unicode: pass
    
    @overload
    def __getitem__(self, i: int) -> unicode: pass
    @overload
    def __getitem__(self, s: slice) -> unicode: pass

    def __getslice__(self, start: int, stop: int) -> unicode: pass

    def __add__(self, s: unicode) -> unicode: pass
    def __mul__(self, n: int) -> str: pass
    def __mod__(self, *args: Any) -> unicode: pass
    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    def __lt__(self, x: unicode) -> bool: pass
    def __le__(self, x: unicode) -> bool: pass
    def __gt__(self, x: unicode) -> bool: pass
    def __ge__(self, x: unicode) -> bool: pass
    
    def __len__(self) -> int: pass
    def __contains__(self, s: object) -> bool: pass
    def __iter__(self) -> Iterator[unicode]: pass
    def __str__(self) -> str: pass
    def __repr__(self) -> str: pass
    def __int__(self) -> int: pass
    def __float__(self) -> float: pass
    def __hash__(self) -> int: pass
    

@builtinclass
class str(Sequence[str]):
    # TODO fromhex
    # TODO maketrans
    
    def __init__(self, object: object) -> None: pass

    def capitalize(self) -> str: pass
    
    @overload
    def center(self, width: int, fillchar: str = None) -> str: pass
    @overload
    def center(self, width: int, fillchar: bytearray = None) -> str: pass
    @overload
    def count(self, x: str) -> int: pass
    @overload
    def count(self, x: bytearray) -> int: pass
    def decode(self, encoding: str = 'utf-8',
               errors: str = 'strict') -> unicode: pass
    def encode(self, encoding: str = 'utf-8',
               errors: str = 'strict') -> str: pass
    @overload
    def endswith(self, suffix: str) -> bool: pass
    @overload
    def endswith(self, suffix: bytearray) -> bool: pass
    def expandtabs(self, tabsize: int = 8) -> str: pass
    @overload
    def find(self, sub: str, start: int = 0) -> int: pass
    @overload
    def find(self, sub: str, start: int, end: int) -> int: pass
    @overload
    def find(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def find(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def index(self, sub: str, start: int = 0) -> int: pass
    @overload
    def index(self, sub: str, start: int, end: int) -> int: pass
    @overload
    def index(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def index(self, sub: bytearray, start: int, end: int) -> int: pass
    def isalnum(self) -> bool: pass
    def isalpha(self) -> bool: pass
    def isdigit(self) -> bool: pass
    def islower(self) -> bool: pass
    def isspace(self) -> bool: pass
    def istitle(self) -> bool: pass
    def isupper(self) -> bool: pass
    @overload
    def join(self, iterable: Iterable[str]) -> str: pass
    @overload
    def join(self, iterable: Iterable[bytearray]) -> str: pass
    @overload
    def ljust(self, width: int, fillchar: str = None) -> str: pass
    @overload
    def ljust(self, width: int, fillchar: bytearray = None) -> str: pass
    def lower(self) -> str: pass
    @overload
    def lstrip(self, chars: str = None) -> str: pass
    @overload
    def lstrip(self, chars: bytearray = None) -> str: pass
    @overload
    def partition(self, sep: str) -> Tuple[str, str, str]: pass
    @overload
    def partition(self, sep: bytearray) -> Tuple[str, str, str]: pass
    @overload
    def replace(self, old: str, new: str, count: int = -1) -> str: pass
    @overload
    def replace(self, old: bytearray, new: bytearray,
                count: int = -1) -> str: pass
    @overload
    def rfind(self, sub: str, start: int = 0) -> int: pass
    @overload
    def rfind(self, sub: str, start: int, end: int) -> int: pass
    @overload
    def rfind(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def rfind(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def rindex(self, sub: str, start: int = 0) -> int: pass
    @overload
    def rindex(self, sub: str, start: int, end: int) -> int: pass
    @overload
    def rindex(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def rindex(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def rjust(self, width: int, fillchar: str = None) -> str: pass
    @overload
    def rjust(self, width: int, fillchar: bytearray = None) -> str: pass
    @overload
    def rpartition(self, sep: str) -> Tuple[str, str, str]: pass
    @overload
    def rpartition(self, sep: bytearray) -> Tuple[str, str, str]: pass
    @overload
    def rsplit(self, sep: str = None,
               maxsplit: int = -1) -> List[str]: pass
    @overload
    def rsplit(self, sep: bytearray = None,
               maxsplit: int = -1) -> List[str]: pass
    @overload
    def rstrip(self, chars: str = None) -> str: pass
    @overload
    def rstrip(self, chars: bytearray = None) -> str: pass
    @overload
    def split(self, sep: str = None, maxsplit: int = -1) -> List[str]: pass
    @overload
    def split(self, sep: bytearray = None,
              maxsplit: int = -1) -> List[str]: pass
    def splitlines(self, keepends: bool = False) -> List[str]: pass
    @overload
    def startswith(self, prefix: str) -> bool: pass
    @overload
    def startswith(self, prefix: bytearray) -> bool: pass
    @overload
    def strip(self, chars: str = None) -> str: pass
    @overload
    def strip(self, chars: bytearray = None) -> str: pass
    def swapcase(self) -> str: pass
    def title(self) -> str: pass
    @overload
    def translate(self, table: str) -> str: pass
    @overload
    def translate(self, table: bytearray) -> str: pass
    def upper(self) -> str: pass
    def zfill(self, width: int) -> str: pass
    
    def __len__(self) -> int: pass
    def __iter__(self) -> Iterator[str]: pass
    def __str__(self) -> str: pass
    def __repr__(self) -> str: pass
    def __int__(self) -> int: pass
    def __float__(self) -> float: pass
    def __hash__(self) -> int: pass
    
    @overload
    def __getitem__(self, i: int) -> str: pass
    @overload
    def __getitem__(self, s: slice) -> str: pass

    def __getslice__(self, start: int, stop: int) -> str: pass
    
    @overload
    def __add__(self, s: str) -> str: pass    
    @overload
    def __add__(self, s: bytearray) -> str: pass
    
    def __mul__(self, n: int) -> str: pass
    def __rmul__(self, n: int) -> str: pass
    def __contains__(self, o: object) -> bool: pass    
    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    def __lt__(self, x: str) -> bool: pass
    def __le__(self, x: str) -> bool: pass
    def __gt__(self, x: str) -> bool: pass
    def __ge__(self, x: str) -> bool: pass


@builtinclass
class bytearray(Sequence[int]):
    # TODO fromhex
    # TODO maketrans
    
    @overload
    def __init__(self, ints: Iterable[int]) -> None: pass
    @overload
    def __init__(self, string: str, encoding: str,
                 errors: str = 'strict') -> None: pass
    @overload
    def __init__(self, string: unicode, encoding: str,
                 errors: str = 'strict') -> None: pass
    @overload
    def __init__(self, length: int) -> None: pass
    @overload
    def __init__(self) -> None: pass

    def capitalize(self) -> bytearray: pass
    @overload
    def center(self, width: int, fillchar: str = None) -> bytearray: pass
    @overload
    def center(self, width: int, fillchar: bytearray = None) -> bytearray: pass
    @overload
    def count(self, x: str) -> int: pass
    @overload
    def count(self, x: bytearray) -> int: pass
    def decode(self, encoding: str = 'utf-8',
               errors: str = 'strict') -> str: pass
    @overload
    def endswith(self, suffix: str) -> bool: pass
    @overload
    def endswith(self, suffix: bytearray) -> bool: pass
    def expandtabs(self, tabsize: int = 8) -> bytearray: pass
    @overload
    def find(self, sub: str, start: int = 0) -> int: pass
    @overload
    def find(self, sub: str, start: int, end: int) -> int: pass
    @overload
    def find(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def find(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def index(self, sub: str, start: int = 0) -> int: pass
    @overload
    def index(self, sub: str, start: int, end: int) -> int: pass
    @overload
    def index(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def index(self, sub: bytearray, start: int, end: int) -> int: pass
    def isalnum(self) -> bool: pass
    def isalpha(self) -> bool: pass
    def isdigit(self) -> bool: pass
    def islower(self) -> bool: pass
    def isspace(self) -> bool: pass
    def istitle(self) -> bool: pass
    def isupper(self) -> bool: pass
    @overload
    def join(self, iterable: Iterable[str]) -> bytearray: pass
    @overload
    def join(self, iterable: Iterable[bytearray]) -> bytearray: pass
    @overload
    def ljust(self, width: int, fillchar: str = None) -> bytearray: pass
    @overload
    def ljust(self, width: int, fillchar: bytearray = None) -> bytearray: pass
    def lower(self) -> bytearray: pass
    @overload
    def lstrip(self, chars: str = None) -> bytearray: pass
    @overload
    def lstrip(self, chars: bytearray = None) -> bytearray: pass
    @overload
    def partition(self, sep: str) -> Tuple[bytearray, bytearray,
                                             bytearray]: pass
    @overload
    def partition(self, sep: bytearray) -> Tuple[bytearray, bytearray,
                                                 bytearray]: pass
    @overload
    def replace(self, old: str, new: str,
                count: int = -1) -> bytearray: pass
    @overload
    def replace(self, old: bytearray, new: bytearray,
                count: int = -1) -> bytearray: pass
    @overload
    def rfind(self, sub: str, start: int = 0) -> int: pass
    @overload
    def rfind(self, sub: str, start: int, end: int) -> int: pass
    @overload
    def rfind(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def rfind(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def rindex(self, sub: str, start: int = 0) -> int: pass
    @overload
    def rindex(self, sub: str, start: int, end: int) -> int: pass
    @overload
    def rindex(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def rindex(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def rjust(self, width: int, fillchar: str = None) -> bytearray: pass
    @overload
    def rjust(self, width: int, fillchar: bytearray = None) -> bytearray: pass
    @overload
    def rpartition(self, sep: str) -> Tuple[bytearray, bytearray,
                                              bytearray]: pass
    @overload
    def rpartition(self, sep: bytearray) -> Tuple[bytearray, bytearray,
                                                  bytearray]:pass
    @overload
    def rsplit(self, sep: str = None,
               maxsplit: int = -1) -> List[bytearray]: pass
    @overload
    def rsplit(self, sep: bytearray = None,
               maxsplit: int = -1) -> List[bytearray]: pass
    @overload
    def rstrip(self, chars: str = None) -> bytearray: pass
    @overload
    def rstrip(self, chars: bytearray = None) -> bytearray: pass
    @overload
    def split(self, sep: str = None,
              maxsplit: int = -1) -> List[bytearray]: pass
    @overload
    def split(self, sep: bytearray = None,
              maxsplit: int = -1) -> List[bytearray]: pass
    def splitlines(self, keepends: bool = False) -> List[bytearray]: pass
    @overload
    def startswith(self, prefix: str) -> bool: pass
    @overload
    def startswith(self, prefix: bytearray) -> bool: pass
    @overload
    def strip(self, chars: str = None) -> bytearray: pass
    @overload
    def strip(self, chars: bytearray = None) -> bytearray: pass
    def swapcase(self) -> bytearray: pass
    def title(self) -> bytearray: pass
    @overload
    def translate(self, table: str) -> bytearray: pass
    @overload
    def translate(self, table: bytearray) -> bytearray: pass
    def upper(self) -> bytearray: pass
    def zfill(self, width: int) -> bytearray: pass
    
    def __len__(self) -> int: pass
    def __iter__(self) -> Iterator[int]: pass
    def __str__(self) -> str: pass
    def __repr__(self) -> str: pass
    def __int__(self) -> int: pass
    def __float__(self) -> float: pass
    def __hash__(self) -> int: pass
    
    @overload
    def __getitem__(self, i: int) -> int: pass
    @overload
    def __getitem__(self, s: slice) -> bytearray: pass

    def __getslice__(self, start: int, stop: int) -> bytearray: pass
    
    @overload
    def __setitem__(self, i: int, x: int) -> None: pass
    @overload
    def __setitem__(self, s: slice, x: Sequence[int]) -> None: pass

    def __setslice__(self, start: int, stop: int,
                     x: Sequence[int]) -> None: pass
    
    @overload
    def __delitem__(self, i: int) -> None: pass
    @overload
    def __delitem__(self, s: slice) -> None: pass
    
    def __delslice__(self, start: int, stop: int) -> None: pass
    
    @overload
    def __add__(self, s: str) -> bytearray: pass    
    @overload
    def __add__(self, s: bytearray) -> bytearray: pass
    
    def __mul__(self, n: int) -> bytearray: pass
    def __contains__(self, o: object) -> bool: pass    
    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    # TODO more general types for operands
    def __lt__(self, x: bytearray) -> bool: pass
    def __le__(self, x: bytearray) -> bool: pass
    def __gt__(self, x: bytearray) -> bool: pass
    def __ge__(self, x: bytearray) -> bool: pass


@builtinclass
class bool(int, SupportsInt, SupportsFloat):
    def __init__(self, o: object = False) -> None: pass


@builtinclass
class slice:
    start = 0
    step = 0
    stop = 0
    def __init__(self, start: int, stop: int, step: int) -> None: pass


@builtinclass
class tuple(Sized):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[Any]) -> None: pass
    
    def __len__(self) -> int: pass
    def __contains__(self, x: object) -> bool: pass
    def __lt__(self, x: tuple) -> bool: pass
    def __le__(self, x: tuple) -> bool: pass
    def __gt__(self, x: tuple) -> bool: pass
    def __ge__(self, x: tuple) -> bool: pass


@builtinclass
class function:
    # TODO name of the class (corresponds to Python 'function' class)
    __name__ = ''
    __module__ = ''


@builtinclass
class list(Sequence[T], Reversible[T], AbstractGeneric[T]):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[T]) -> None: pass
    
    def append(self, object: T) -> None: pass
    def extend(self, iterable: Iterable[T]) -> None: pass
    def pop(self) -> T: pass
    def index(self, object: T) -> int: pass
    def count(self, object: T) -> int: pass
    def insert(self, index: int, object: T) -> None: pass
    def remove(self, object: T) -> None: pass
    def reverse(self) -> None: pass
    def sort(self, *, key: Function[[T], Any] = None,
             reverse: bool = False) -> None: pass
    
    def __len__(self) -> int: pass
    def __iter__(self) -> Iterator[T]: pass
    def __str__(self) -> str: pass
    def __hash__(self) -> int: pass
    
    @overload
    def __getitem__(self, i: int) -> T: pass
    @overload
    def __getitem__(self, s: slice) -> List[T]: pass
    
    def __getslice__(self, start: int, stop: int) -> List[T]: pass
    
    @overload
    def __setitem__(self, i: int, o: T) -> None: pass
    @overload
    def __setitem__(self, s: slice, o: Sequence[T]) -> None: pass
    
    def __setslice__(self, start: int, stop: int, o: Sequence[T]) -> None: pass
    
    @overload
    def __delitem__(self, i: int) -> None: pass
    @overload
    def __delitem__(self, s: slice) -> None: pass

    def __delslice(self, start: int, stop: int) -> None: pass
    
    def __add__(self, x: List[T]) -> List[T]: pass
    def __mul__(self, n: int) -> List[T]: pass
    def __rmul__(self, n: int) -> List[T]: pass
    def __contains__(self, o: object) -> bool: pass
    def __reversed__(self) -> Iterator[T]: pass


@builtinclass
class dict(Mapping[KT, VT], Generic[KT, VT]):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, map: Mapping[KT, VT]) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[Tuple[KT, VT]]) -> None: pass
    # TODO __init__ keyword args
    
    def __len__(self) -> int: pass
    def __getitem__(self, k: KT) -> VT: pass
    def __setitem__(self, k: KT, v: VT) -> None: pass
    def __delitem__(self, v: KT) -> None: pass
    def __contains__(self, o: object) -> bool: pass
    def __iter__(self) -> Iterator[KT]: pass
    def __str__(self) -> str: pass

    def has_key(self, k: KT) -> bool: pass
    
    def clear(self) -> None: pass
    def copy(self) -> Dict[KT, VT]: pass
    
    @overload
    def get(self, k: KT) -> VT: pass
    @overload
    def get(self, k: KT, default: VT) -> VT: pass
    @overload
    def pop(self, k: KT) -> VT: pass
    @overload
    def pop(self, k: KT, default: VT) -> VT: pass
    def popitem(self) -> Tuple[KT, VT]: pass
    @overload
    def setdefault(self, k: KT) -> VT: pass
    @overload
    def setdefault(self, k: KT, default: VT) -> VT: pass
    
    @overload
    def update(self, m: Mapping[KT, VT]) -> None: pass
    @overload
    def update(self, m: Iterable[Tuple[KT, VT]]) -> None: pass

    def keys(self) -> List[KT]: pass
    def values(self) -> List[VT]: pass
    def items(self) -> List[Tuple[KT, VT]]: pass
    def iterkeys(self) -> Iterator[KT]: pass
    def itervalues(self) -> Iterator[VT]: pass
    def iteritems(self) -> Iterator[Tuple[KT, VT]]: pass


@builtinclass
class set(AbstractSet[T], Generic[T]):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[T]) -> None: pass
    
    def add(self, element: T) -> None: pass
    def remove(self, element: T) -> None: pass
    def copy(self) -> AbstractSet[T]: pass
    def isdisjoint(self, s: AbstractSet[T]) -> bool: pass
    
    def __len__(self) -> int: pass
    def __contains__(self, o: object) -> bool: pass
    def __iter__(self) -> Iterator[T]: pass    
    def __str__(self) -> str: pass
    def __and__(self, s: AbstractSet[T]) -> AbstractSet[T]: pass
    def __or__(self, s: AbstractSet[T]) -> AbstractSet[T]: pass
    def __sub__(self, s: AbstractSet[T]) -> AbstractSet[T]: pass
    def __xor__(self, s: AbstractSet[T]) -> AbstractSet[T]: pass
    # TODO more set operations


@builtinclass
class frozenset(AbstractSet[T], Generic[T]):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[T]) -> None: pass

    def isdisjoint(self, s: AbstractSet[T]) -> bool: pass
    
    def __len__(self) -> int: pass
    def __contains__(self, o: object) -> bool: pass
    def __iter__(self) -> Iterator[T]: pass    
    def __str__(self) -> str: pass
    def __and__(self, s: AbstractSet[T]) -> frozenset[T]: pass
    def __or__(self, s: AbstractSet[T]) -> frozenset[T]: pass
    def __sub__(self, s: AbstractSet[T]) -> frozenset[T]: pass
    def __xor__(self, s: AbstractSet[T]) -> frozenset[T]: pass
    # TODO more set operations


@builtinclass
class enumerate(Iterator[Tuple[int, T]], Generic[T]):
    def __init__(self, iterable: Iterable[T], start: int = 0) -> None: pass
    def __iter__(self) -> Iterator[Tuple[int, T]]: pass
    def next(self) -> Tuple[int, T]: pass
    # TODO __getattribute__


@builtinclass
class xrange(Sized, Iterable[int], Reversible[int]):
    @overload
    def __init__(self, stop: int) -> None: pass
    @overload
    def __init__(self, start: int, stop: int, step: int = 1) -> None: pass
    
    def __len__(self) -> int: pass
    def __iter__(self) -> Iterator[int]: pass
    def __getitem__(self, i: int) -> int: pass
    def __reversed__(self) -> Iterator[int]: pass


@builtinclass
class module:
    __name__ = ''
    __file__ = ''
    __dict__ = Undefined # type: Dict[str, Any]


True = Undefined # type: bool
False = Undefined # type: bool
__debug__ = False


long = int
bytes = str


class _NotImplementedType: pass # TODO name of the class
NotImplemented = Undefined # type: _NotImplementedType


@overload
def abs(n: int) -> int: pass
@overload
def abs(n: float) -> float: pass
@overload
def abs(n: SupportsAbs[T]) -> T: pass

def all(i: Iterable) -> bool: pass
def any(i: Iterable) -> bool: pass
def callable(o: object) -> bool: pass
def chr(code: int) -> str: pass
def delattr(o: Any, name: str) -> None: pass
def dir(o: object = None) -> List[str]: pass

@overload
def divmod(a: int, b: int) -> Tuple[int, int]: pass
@overload
def divmod(a: float, b: float) -> Tuple[float, float]: pass

def filter(function: Function[[T], Any],
           iterable: Iterable[T]) -> List[T]: pass
def format(o: object, format_spec: str = '') -> str: pass
def getattr(o: Any, name: str, default: Any = None) -> Any: pass
def hasattr(o: Any, name: str) -> bool: pass
def hash(o: object) -> int: pass
# TODO __index__
def hex(i: int) -> str: pass
def id(o: object) -> int: pass
def input(prompt: str = None) -> Any: pass

@overload
def iter(iterable: Iterable[T]) -> Iterator[T]: pass
@overload
def iter(function: Function[[], T], sentinel: T) -> Iterator[T]: pass

@overload
def isinstance(o: object, t: type) -> bool: pass
@overload
def isinstance(o: object, t: tuple) -> bool: pass

def issubclass(cls: type, classinfo: type) -> bool: pass
# TODO perhaps support this
#def issubclass(type cld, classinfo: Sequence[type]) -> bool: pass
def len(o: Sized) -> int: pass

# TODO more than two iterables
@overload
def map(func: Function[[T1], S], iter1: Iterable[T1]) -> List[S]: pass
@overload
def map(func: Function[[T1, T2], S],
        iter1: Iterable[T1],
        iter2: Iterable[T2]) -> List[S]: pass

# TODO keyword argument key
@overload
def max(iterable: Iterable[T]) -> T: pass
@overload
def max(arg1: T, arg2: T, *args: T) -> T: pass

# TODO memoryview

@overload
def min(iterable: Iterable[T]) -> T: pass
@overload
def min(arg1: T, arg2: T, *args: T) -> T: pass

@overload
def next(i: Iterator[T]) -> T: pass
@overload
def next(i: Iterator[T], default: T) -> T: pass

# TODO __index__
def oct(i: int) -> str: pass

# TODO return type
@overload
def open(file: str, mode: str = 'r', buffering: int = -1, encoding: str = None,
         errors: str = None, newline: str = None,
         closefd: bool = True) -> Any: pass
@overload
def open(file: unicode, mode: str = 'r', buffering: int = -1,
         encoding: str = None, errors: str = None, newline: str = None,
         closefd: bool = True) -> Any: pass
@overload
def open(file: int, mode: str = 'r', buffering: int = -1, encoding: str = None,
         errors: str = None, newline: str = None,
         closefd: bool = True) -> Any: pass

@overload
def ord(c: str) -> int: pass
@overload
def ord(c: unicode) -> int: pass
@overload
def ord(c: bytearray) -> int: pass

# The return type can be int or float, depending on the value of y.
@overload
def pow(x: int, y: int) -> Any: pass
@overload
def pow(x: int, y: int, z: int) -> Any: pass
@overload
def pow(x: float, y: float) -> float: pass
@overload
def pow(x: float, y: float, z: float) -> float: pass

# TODO property

def range(x: int, y: int = 0, step: int = 1) -> List[int]: pass
def raw_input(prompt: str = None) -> str: pass

@overload
def reversed(object: Reversible[T]) -> Iterator[T]: pass
@overload
def reversed(object: Sequence[T]) -> Iterator[T]: pass

def repr(o: object) -> str: pass

# Always return a float if ndigits is present.
@overload
def round(number: float) -> int: pass
@overload
def round(number: float, ndigits: int) -> float: pass
@overload
def round(number: SupportsRound[T]) -> T: pass
@overload
def round(number: SupportsRound[T], ndigits: int) -> T: pass

def setattr(object: Any, name: str, value: Any) -> None: pass
def sorted(iterable: Iterable[T], *,
           cmp: Function[[T, T], int] = None,
           key: Function[[T], Any] = None,
           reverse: bool = False) -> List[T]: pass
def sum(iterable: Iterable[T], start: T = None) -> T: pass

# TODO more than four iterables
@overload
def zip(iter1: Iterable[T1]) -> List[Tuple[T1]]: pass
@overload
def zip(iter1: Iterable[T1],
        iter2: Iterable[T2]) -> List[Tuple[T1, T2]]: pass
@overload
def zip(iter1: Iterable[T1], iter2: Iterable[T2],
        iter3: Iterable[T3]) -> List[Tuple[T1, T2, T3]]: pass
@overload
def zip(iter1: Iterable[T1], iter2: Iterable[T2], iter3: Iterable[T3],
        iter4: Iterable[T4]) -> List[Tuple[T1, T2, T3, T4]]: pass

def __import__(name: str,
               globals: Dict[str, Any] = {},
               locals: Dict[str, Any] = {},
               fromlist: List[str] = [], level: int = -1) -> Any: pass


# Exceptions


@builtinclass
class BaseException:
    args = Undefined # type: Any
    def __init__(self, *args: Any) -> None: pass
    def with_traceback(self, tb: Any) -> BaseException: pass

class GeneratorExit(BaseException): pass
class KeyboardInterrupt(BaseException): pass
class SystemExit(BaseException): pass

class Exception(BaseException): pass
class StopIteration(Exception): pass
class StandardError(Exception): pass

class ArithmeticError(StandardError): pass
@builtinclass
class EnvironmentError(StandardError):
    errno = 0
    strerror = ''
    filename = '' # TODO can this be unicode?
class LookupError(StandardError): pass
class RuntimeError(StandardError): pass
class ValueError(StandardError): pass

class AssertionError(StandardError): pass
class AttributeError(StandardError): pass
class EOFError(StandardError): pass
class FloatingPointError(ArithmeticError): pass
class IOError(EnvironmentError): pass
class ImportError(StandardError): pass
class IndexError(LookupError): pass
class KeyError(LookupError): pass
class MemoryError(StandardError): pass
class NameError(StandardError): pass
class NotImplementedError(RuntimeError): pass
class OSError(EnvironmentError): pass
class OverflowError(ArithmeticError): pass
class ReferenceError(StandardError): pass
class SyntaxError(StandardError): pass
class IndentationError(SyntaxError): pass
class TabError(IndentationError): pass
class SystemError(StandardError): pass
class TypeError(StandardError): pass
class UnboundLocalError(NameError): pass
class UnicodeError(ValueError): pass
class UnicodeDecodeError(UnicodeError): pass
class UnicodeEncodeError(UnicodeError): pass
class UnicodeTranslateError(UnicodeError): pass
class ZeroDivisionError(ArithmeticError): pass

class Warning(Exception): pass
class UserWarning(Warning): pass
class DeprecationWarning(Warning): pass
class SyntaxWarning(Warning): pass
class RuntimeWarning(Warning): pass
class FutureWarning(Warning): pass
class PendingDeprecationWarning(Warning): pass
class ImportWarning(Warning): pass
class UnicodeWarning(Warning): pass
class BytesWarning(Warning): pass
class ResourceWarning(Warning): pass

# TODO Windows-only
class WindowsError(OSError): pass

# TODO: VMSError

########NEW FILE########
__FILENAME__ = re
# Stubs for re
# Ron Murawski <ron@horizonchess.com>
# 'bytes' support added by Jukka Lehtosalo

# based on: http://docs.python.org/2.7/library/re.html

from typing import (
    Undefined, List, Iterator, overload, Function, Tuple, Sequence, Dict
)

# ----- re variables and constants -----
A = 0
ASCII = 0
DEBUG = 0
I = 0
IGNORECASE = 0
L = 0
LOCALE = 0
M = 0
MULTILINE = 0
S = 0
DOTALL = 0
X = 0
VERBOSE = 0

class error(Exception): pass

class Match:
    pos = 0
    endpos = 0
    lastindex = 0
    lastgroup = ''
    string = ''
    
    # The regular expression object whose match() or search() method produced
    # this match instance.
    re = Undefined('Pattern')
    
    def expand(self, template: str) -> str: pass
    
    @overload
    def group(self, group1: int = 0) -> str: pass
    @overload
    def group(self, group1: str) -> str: pass
    @overload
    def group(self, group1: int, group2: int,
              *groups: int) -> Sequence[str]: pass
    @overload
    def group(self, group1: str, group2: str,
              *groups: str) -> Sequence[str]: pass
    
    def groups(self, default: str = None) -> Sequence[str]: pass
    def groupdict(self, default: str = None) -> Dict[str, str]: pass
    def start(self, group: int = 0) -> int: pass
    def end(self, group: int = 0) -> int: pass
    def span(self, group: int = 0) -> Tuple[int, int]: pass

class UnicodeMatch:
    pos = 0
    endpos = 0
    lastindex = 0
    lastgroup = u''
    string = u''
    
    # The regular expression object whose match() or search() method produced
    # this match instance.
    re = Undefined('UnicodePattern')
    
    def expand(self, template: unicode) -> unicode: pass
    
    @overload
    def group(self, group1: int = 0) -> unicode: pass
    @overload
    def group(self, group1: unicode) -> unicode: pass
    @overload
    def group(self, group1: int, group2: int,
              *groups: int) -> Sequence[unicode]: pass
    @overload
    def group(self, group1: unicode, group2: unicode,
              *groups: unicode) -> Sequence[unicode]: pass
    
    def groups(self, default: unicode = None) -> Sequence[unicode]: pass
    def groupdict(self, default: unicode = None) -> Dict[unicode,
                                                         unicode]: pass
    def start(self, group: int = 0) -> int: pass
    def end(self, group: int = 0) -> int: pass
    def span(self, group: int = 0) -> Tuple[int, int]: pass

# ----- re classes -----
class Pattern:
    flags = 0
    groupindex = 0
    groups = 0
    pattern = ''

    def search(self, string: str, pos: int = 0,
               endpos: int = -1) -> Match: pass
    def match(self, string: str, pos: int = 0, endpos: int = -1) -> Match: pass
    def split(self, string: str, maxsplit: int = 0) -> List[str]: pass
    def findall(self, string: str, pos: int = 0,
                endpos: int = -1) -> List[str]: pass
    def finditer(self, string: str, pos: int = 0,
                 endpos: int = -1) -> Iterator[Match]: pass
    
    @overload
    def sub(self, repl: str, string: str, count: int = 0) -> str: pass
    @overload
    def sub(self, repl: Function[[Match], str], string: str,
            count: int = 0) -> str: pass
    
    @overload
    def subn(self, repl: str, string: str, count: int = 0) -> Tuple[str,
                                                                    int]: pass
    @overload
    def subn(self, repl: Function[[Match], str], string: str,
             count: int = 0) -> Tuple[str, int]: pass

class UnicodePattern:
    flags = 0
    groupindex = 0
    groups = 0
    pattern = u''

    def search(self, string: unicode, pos: int = 0,
               endpos: int = -1) -> UnicodeMatch: pass
    def match(self, string: unicode, pos: int = 0,
              endpos: int = -1) -> UnicodeMatch: pass
    def split(self, string: unicode, maxsplit: int = 0) -> List[unicode]: pass
    def findall(self, string: unicode, pos: int = 0,
                endpos: int = -1) -> List[unicode]: pass
    def finditer(self, string: unicode, pos: int = 0,
                 endpos: int = -1) -> Iterator[UnicodeMatch]: pass
    
    @overload
    def sub(self, repl: unicode, string: unicode,
            count: int = 0) -> unicode: pass
    @overload
    def sub(self, repl: Function[[UnicodeMatch], unicode], string: unicode,
            count: int = 0) -> unicode: pass
    
    @overload
    def subn(self, repl: unicode, string: unicode,
             count: int = 0) -> Tuple[unicode, int]: pass
    @overload
    def subn(self, repl: Function[[UnicodeMatch], unicode], string: unicode,
             count: int = 0) -> Tuple[unicode, int]: pass

@overload
def compile(pattern: str, flags: int = 0) -> Pattern: pass
@overload
def compile(pattern: unicode, flags: int = 0) -> UnicodePattern: pass

@overload
def search(pattern: str, string: str, flags: int = 0) -> Match: pass
@overload
def search(pattern: unicode, string: unicode,
           flags: int = 0) -> UnicodeMatch: pass

@overload
def match(pattern: str, string: str, flags: int = 0) -> Match: pass
@overload
def match(pattern: unicode, string: unicode,
          flags: int = 0) -> UnicodeMatch: pass

@overload
def split(pattern: str, string: str, maxsplit: int = 0,
          flags: int = 0) -> List[str]: pass
@overload
def split(pattern: unicode, string: unicode, maxsplit: int = 0,
          flags: int = 0) -> List[unicode]: pass

@overload
def findall(pattern: str, string: str, flags: int = 0) -> List[str]: pass
@overload
def findall(pattern: unicode, string: unicode,
            flags: int = 0) -> List[unicode]: pass

# Return an iterator yielding match objects over all non-overlapping matches 
# for the RE pattern in string. The string is scanned left-to-right, and 
# matches are returned in the order found. Empty matches are included in the 
# result unless they touch the beginning of another match.
@overload
def finditer(pattern: str, string: str,
             flags: int = 0) -> Iterator[Match]: pass
@overload
def finditer(pattern: unicode, string: unicode,
             flags: int = 0) -> Iterator[UnicodeMatch]: pass

@overload
def sub(pattern: str, repl: str, string: str, count: int = 0,
        flags: int = 0) -> str: pass
@overload
def sub(pattern: str, repl: Function[[Match], str], string: str,
        count: int = 0, flags: int = 0) -> str: pass
@overload
def sub(pattern: unicode, repl: unicode, string: unicode, count: int = 0,
        flags: int = 0) -> unicode: pass
@overload
def sub(pattern: unicode, repl: Function[[UnicodeMatch], unicode],
        string: unicode, count: int = 0, flags: int = 0) -> unicode: pass

@overload
def subn(pattern: str, repl: str, string: str, count: int = 0,
         flags: int = 0) -> Tuple[str, int]: pass
@overload
def subn(pattern: str, repl: Function[[Match], str], string: str, 
         count: int = 0, flags: int = 0) -> Tuple[str, int]: pass
@overload
def subn(pattern: unicode, repl: unicode, string: unicode, count: int = 0, 
         flags: int = 0) -> Tuple[unicode, int]: pass
@overload
def subn(pattern: unicode, repl: Function[[UnicodeMatch], unicode],
         string: unicode, count: int = 0, flags: int = 0) -> Tuple[unicode,
                                                                   int]: pass

@overload
def escape(string: str) -> str: pass
@overload
def escape(string: unicode) -> unicode: pass

def purge() -> None: pass

########NEW FILE########
__FILENAME__ = sys
# Stubs for sys
# Ron Murawski <ron@horizonchess.com>

# based on http://docs.python.org/2.7/library/sys.html

# Partially adapted to Python 2.7 by Jukka Lehtosalo.

from typing import (
    Undefined, List, Sequence, Any, Dict, Tuple, BinaryIO, overload
)

# ----- sys variables -----
abiflags = ''
argv = Undefined(List[str])
byteorder = ''
builtin_module_names = Undefined(Sequence[str]) # actually a tuple of strings
copyright = ''
#dllhandle = 0  # Windows only
dont_write_bytecode = False
__displayhook__ = Undefined(Any) # contains the original value of displayhook
__excepthook__ = Undefined(Any)  # contains the original value of excepthook
exec_prefix = ''
executable = ''
float_repr_style = ''
hexversion = 0  # this is a 32-bit int
last_type = Undefined(Any)
last_value = Undefined(Any)
last_traceback = Undefined(Any)
maxsize = 0
maxunicode = 0
meta_path = Undefined(List[Any])
modules = Undefined(Dict[str, Any])
path = Undefined(List[str])
path_hooks = Undefined(List[Any]) # TODO precise type; function, path to finder
path_importer_cache = Undefined(Dict[str, Any]) # TODO precise type
platform = ''
prefix = ''
ps1 = ''
ps2 = ''
stdin = Undefined(BinaryIO)
stdout = Undefined(BinaryIO)
stderr = Undefined(BinaryIO)
__stdin__ = Undefined(BinaryIO)
__stdout__ = Undefined(BinaryIO)
__stderr__ = Undefined(BinaryIO)
subversion = Undefined(Tuple[str, str, str])
tracebacklimit = 0
version = ''
api_version = 0 
warnoptions = Undefined(Any)
#  Each entry is a tuple of the form (action, message, category, module,
#    lineno)
#winver = ''  # Windows only
_xoptions = Undefined(Dict[Any, Any])

flags = Undefined(_flags)
class _flags:
    debug = 0
    division_warning = 0
    inspect = 0
    interactive = 0
    optimize = 0
    dont_write_bytecode = 0
    no_user_site = 0
    no_site = 0
    ignore_environment = 0
    verbose = 0
    bytes_warning = 0
    quiet = 0
    hash_randomization = 0

float_info = Undefined(_float_info)
class _float_info:
    epsilon = 0.0   # DBL_EPSILON
    dig = 0         # DBL_DIG
    mant_dig = 0    # DBL_MANT_DIG
    max = 0.0       # DBL_MAX
    max_exp = 0     # DBL_MAX_EXP
    max_10_exp = 0  # DBL_MAX_10_EXP
    min = 0.0       # DBL_MIN
    min_exp = 0     # DBL_MIN_EXP
    min_10_exp = 0  # DBL_MIN_10_EXP
    radix = 0       # FLT_RADIX
    rounds = 0      # FLT_ROUNDS

hash_info = Undefined(_hash_info)
class _hash_info:
    width = 0    # width in bits used for hash values
    modulus = 0  # prime modulus P used for numeric hash scheme
    inf = 0      # hash value returned for a positive infinity
    nan = 0      # hash value returned for a nan
    imag = 0     # multiplier used for the imaginary part of a complex number

int_info = Undefined(_int_info)
class _int_info:
    bits_per_digit = 0  # number of bits held in each digit. Python integers 
                        # are stored internally in 
                        # base 2**int_info.bits_per_digit
    sizeof_digit = 0    # size in bytes of C type used to represent a digit

version_info = Undefined(_version_info)
class _version_info:
    major = 0
    minor = 0
    micro = 0
    releaselevel = ''
    serial = 0


# ----- sys function stubs -----
def call_tracing(fn: Any, args: Any) -> object: pass
def _clear_type_cache() -> None: pass
def _current_frames() -> Dict[int, Any]: pass
def displayhook(value: int) -> None: pass  # value might be None
def excepthook(type_: type, value: BaseException, traceback: Any) -> None:
    # TODO traceback type
    pass
def exc_info() -> Tuple[type, Any, Any]: pass # see above
def exit(arg: int = 0) -> None: pass  # arg might be None
def getcheckinterval() -> int: pass  # deprecated
def getdefaultencoding() -> str: pass
#def getdlopenflags() -> int: pass  # Unix only
def getfilesystemencoding() -> str: pass  # cannot return None
#def getrefcount(object) -> int: pass  # no ref counts in MyPy!
def getrecursionlimit() -> int: pass

@overload
def getsizeof(obj: object) -> int: pass
@overload
def getsizeof(obj: object, default: int) -> int: pass

def getswitchinterval() -> float: pass

@overload
def _getframe() -> Any: pass
@overload
def _getframe(depth: int) -> Any: pass

def getprofile() -> Any: pass # TODO return type
def gettrace() -> Any: pass # TODO return
def getwindowsversion() -> Any: pass  # Windows only, TODO return type
def intern(string: str) -> str: pass
def setcheckinterval(interval: int) -> None: pass  # deprecated
#def setdlopenflags(n: int) -> None: pass  # Linux only
def setprofile(profilefunc: Any) -> None: pass # TODO type
def setrecursionlimit(limit: int) -> None: pass
def setswitchinterval(interval: float) -> None: pass
def settrace(tracefunc: Any) -> None: pass # TODO type
# Trace functions should have three arguments: frame, event, and arg. frame 
# is the current stack frame. event is a string: 'call', 'line', 'return', 
# 'exception', 'c_call', 'c_return', or 'c_exception'. arg depends on the 
# event type.
def settscdump(on_flag: bool) -> None: pass

########NEW FILE########
__FILENAME__ = typing
"""Stubs for typing"""

from abc import abstractmethod, ABCMeta


# Definitions of special type checking related constructs.  Their definition
# are not used, so their value does not matter.

cast = object()
overload = object()
Undefined = object()
Any = object()
typevar = object()
Generic = object()
AbstractGeneric = object()
Tuple = object()
Function = object()
builtinclass = object()
ducktype = object()
disjointclass = object()

# Type aliases.
List = object()
Dict = object()
Set = object()

# Defines aliases for built-in types.
# Note that here 're' refers to the stub!  The Python 're' module does not
# define Pattern, etc.  At runtime, the string and bytes variants actually
# point to the same type, which means that they can't be used for overloading
# reliably.
from re import Pattern, UnicodePattern, Match, UnicodeMatch


# Abstract base classes.

T = typevar('T')
KT = typevar('KT')
VT = typevar('VT')


# TODO Container etc.

class SupportsInt(metaclass=ABCMeta):
    @abstractmethod
    def __int__(self) -> int: pass
    
class SupportsFloat(metaclass=ABCMeta):
    @abstractmethod
    def __float__(self) -> float: pass

@disjointclass(int)
@disjointclass(float)
class SupportsAbs(AbstractGeneric[T]):
    @abstractmethod
    def __abs__(self) -> T: pass

@disjointclass(int)
@disjointclass(float)
class SupportsRound(AbstractGeneric[T]):
    @abstractmethod
    def __round__(self, ndigits: int = 0) -> T: pass

class Reversible(AbstractGeneric[T]):
    @abstractmethod
    def __reversed__(self) -> Iterator[T]: pass

class Sized(metaclass=ABCMeta):
    @abstractmethod
    def __len__(self) -> int: pass

class Iterable(AbstractGeneric[T]):
    @abstractmethod
    def __iter__(self) -> Iterator[T]: pass

class Iterator(Iterable[T], AbstractGeneric[T]):
    @abstractmethod
    def next(self) -> T: pass

class Sequence(Sized, Iterable[T], AbstractGeneric[T]):
    @abstractmethod
    def __contains__(self, x: object) -> bool: pass
    @overload
    @abstractmethod
    def __getitem__(self, i: int) -> T: pass
    @overload
    @abstractmethod
    def __getitem__(self, s: slice) -> Sequence[T]: pass
    
class AbstractSet(Sized, Iterable[T], AbstractGeneric[T]):
    @abstractmethod
    def __contains__(self, x: object) -> bool: pass
    # TODO __le__, __lt__, __gt__, __ge__
    @abstractmethod
    def __and__(self, s: AbstractSet[T]) -> AbstractSet[T]: pass
    @abstractmethod
    def __or__(self, s: AbstractSet[T]) -> AbstractSet[T]: pass
    @abstractmethod
    def __sub__(self, s: AbstractSet[T]) -> AbstractSet[T]: pass
    @abstractmethod
    def __xor__(self, s: AbstractSet[T]) -> AbstractSet[T]: pass
    # TODO argument can be any container?
    @abstractmethod
    def isdisjoint(self, s: AbstractSet[T]) -> bool: pass

class Mapping(Sized, Iterable[KT], AbstractGeneric[KT, VT]):
    @abstractmethod
    def __getitem__(self, k: KT) -> VT: pass
    @abstractmethod
    def __setitem__(self, k: KT, v: VT) -> None: pass
    @abstractmethod
    def __delitem__(self, v: KT) -> None: pass
    @abstractmethod
    def __contains__(self, o: object) -> bool: pass

    @abstractmethod
    def clear(self) -> None: pass
    @abstractmethod
    def copy(self) -> Mapping[KT, VT]: pass
    @overload
    @abstractmethod
    def get(self, k: KT) -> VT: pass
    @overload
    @abstractmethod
    def get(self, k: KT, default: VT) -> VT: pass
    @overload
    @abstractmethod
    def pop(self, k: KT) -> VT: pass
    @overload
    @abstractmethod
    def pop(self, k: KT, default: VT) -> VT: pass
    @abstractmethod
    def popitem(self) -> Tuple[KT, VT]: pass
    @overload
    @abstractmethod
    def setdefault(self, k: KT) -> VT: pass
    @overload
    @abstractmethod
    def setdefault(self, k: KT, default: VT) -> VT: pass
    
    # TODO keyword arguments
    @overload
    @abstractmethod
    def update(self, m: Mapping[KT, VT]) -> None: pass
    @overload
    @abstractmethod
    def update(self, m: Iterable[Tuple[KT, VT]]) -> None: pass
    
    @abstractmethod
    def keys(self) -> list[KT]: pass
    @abstractmethod
    def values(self) -> list[VT]: pass
    @abstractmethod
    def items(self) -> list[Tuple[KT, VT]]: pass
    @abstractmethod
    def iterkeys(self) -> Iterator[KT]: pass
    @abstractmethod
    def itervalues(self) -> Iterator[VT]: pass
    @abstractmethod
    def iteritems(self) -> Iterator[Tuple[KT, VT]]: pass

class BinaryIO(metaclass=ABCMeta):    
    # TODO iteration
    # TODO mode
    # TODO name
    # TODO detach
    # TODO readinto
    # TODO read1?
    # TODO peek?
    @abstractmethod
    def close(self) -> None: pass
    @abstractmethod
    def closed(self) -> bool: pass
    @abstractmethod
    def fileno(self) -> int: pass
    @abstractmethod
    def flush(self) -> None: pass
    @abstractmethod
    def isatty(self) -> bool: pass
    # TODO what if n is None?
    @abstractmethod
    def read(self, n: int = -1) -> str: pass
    @abstractmethod
    def readable(self) -> bool: pass
    @abstractmethod
    def readline(self, limit: int = -1) -> str: pass
    @abstractmethod
    def readlines(self, hint: int = -1) -> list[str]: pass
    @abstractmethod
    def seek(self, offset: int, whence: int = 0) -> int: pass
    @abstractmethod
    def seekable(self) -> bool: pass
    @abstractmethod
    def tell(self) -> int: pass
    # TODO None should not be compatible with int
    @abstractmethod
    def truncate(self, size: int = None) -> int: pass
    @abstractmethod
    def writable(self) -> bool: pass
    # TODO buffer objects
    @overload
    @abstractmethod
    def write(self, s: str) -> int: pass
    @overload
    @abstractmethod
    def write(self, s: bytearray) -> int: pass
    @abstractmethod
    def writelines(self, lines: list[str]) -> None: pass

    @abstractmethod
    def __enter__(self) -> BinaryIO: pass
    @abstractmethod
    def __exit__(self, type, value, traceback) -> None: pass

class TextIO(metaclass=ABCMeta):
    # TODO iteration
    # TODO buffer?
    # TODO str encoding
    # TODO str errors
    # TODO line_buffering
    # TODO mode
    # TODO name
    # TODO any newlines
    # TODO detach(self)
    @abstractmethod
    def close(self) -> None: pass
    @abstractmethod
    def closed(self) -> bool: pass
    @abstractmethod
    def fileno(self) -> int: pass
    @abstractmethod
    def flush(self) -> None: pass
    @abstractmethod
    def isatty(self) -> bool: pass
    # TODO what if n is None?
    @abstractmethod
    def read(self, n: int = -1) -> unicode: pass
    @abstractmethod
    def readable(self) -> bool: pass
    @abstractmethod
    def readline(self, limit: int = -1) -> unicode: pass
    @abstractmethod
    def readlines(self, hint: int = -1) -> list[unicode]: pass
    @abstractmethod
    def seek(self, offset: int, whence: int = 0) -> int: pass
    @abstractmethod
    def seekable(self) -> bool: pass
    @abstractmethod
    def tell(self) -> int: pass
    # TODO is None compatible with int?
    @abstractmethod
    def truncate(self, size: int = None) -> int: pass
    @abstractmethod
    def writable(self) -> bool: pass
    # TODO buffer objects
    @abstractmethod
    def write(self, s: unicode) -> int: pass
    @abstractmethod
    def writelines(self, lines: list[unicode]) -> None: pass

    @abstractmethod
    def __enter__(self) -> TextIO: pass
    @abstractmethod
    def __exit__(self, type, value, traceback) -> None: pass

########NEW FILE########
__FILENAME__ = abc
# Stubs for abc.

# Thesee definitions have special processing in type checker.
class ABCMeta: pass
abstractmethod = object()

########NEW FILE########
__FILENAME__ = array
# Stubs for array

# Based on http://docs.python.org/3.2/library/array.html

from typing import Any, Iterable, Tuple, List, Iterator, BinaryIO, overload

typecodes = ''

class array:
    def __init__(self, typecode: str,
                 initializer: Iterable[Any] = None) -> None:
        typecode = ''
        itemsize = 0

    def append(self, x: Any) -> None: pass
    def buffer_info(self) -> Tuple[int, int]: pass
    def byteswap(self) -> None: pass
    def count(self, x: Any) -> int: pass
    def extend(self, iterable: Iterable[Any]) -> None: pass
    def frombytes(self, s: bytes) -> None: pass
    def fromfile(self, f: BinaryIO, n: int) -> None: pass
    def fromlist(self, list: List[Any]) -> None: pass
    def fromstring(self, s: bytes) -> None: pass
    def fromunicode(self, s: str) -> None: pass
    def index(self, x: Any) -> int: pass
    def insert(self, i: int, x: Any) -> None: pass
    def pop(self, i: int = -1) -> Any: pass
    def remove(self, x: Any) -> None: pass
    def reverse(self) -> None: pass
    def tobytes(self) -> bytes: pass
    def tofile(self, f: BinaryIO) -> None: pass
    def tolist(self) -> List[Any]: pass
    def tostring(self) -> bytes: pass
    def tounicode(self) -> str: pass
    
    def __len__(self) -> int: pass
    def __iter__(self) -> Iterator[Any]: pass
    def __str__(self) -> str: pass
    def __hash__(self) -> int: pass
    
    @overload
    def __getitem__(self, i: int) -> Any: pass
    @overload
    def __getitem__(self, s: slice) -> 'array': pass
    
    def __setitem__(self, i: int, o: Any) -> None: pass
    def __delitem__(self, i: int) -> None: pass
    def __add__(self, x: 'array') -> 'array': pass
    def __mul__(self, n: int) -> 'array': pass
    def __contains__(self, o: object) -> bool: pass

########NEW FILE########
__FILENAME__ = atexit
from typing import typevar, Any

FT = typevar('FT')

def register(func: FT, *args: Any, **kargs: Any) -> FT: pass

########NEW FILE########
__FILENAME__ = base64
# Stubs for base64

# Based on http://docs.python.org/3.2/library/base64.html

from typing import IO

def b64encode(s: bytes, altchars: bytes = None) -> bytes: pass
def b64decode(s: bytes, altchars: bytes = None,
              validate: bool = False) -> bytes: pass
def standard_b64encode(s: bytes) -> bytes: pass
def standard_b64decode(s: bytes) -> bytes: pass
def urlsafe_b64encode(s: bytes) -> bytes: pass
def urlsafe_b64decode(s: bytes) -> bytes: pass
def b32encode(s: bytes) -> bytes: pass
def b32decode(s: bytes, casefold: bool = False,
              map01: bytes = None) -> bytes: pass
def b16encode(s: bytes) -> bytes: pass
def b16decode(s: bytes, casefold: bool = False) -> bytes: pass

def decode(input: IO[bytes], output: IO[bytes]) -> None: pass
def decodebytes(s: bytes) -> bytes: pass
def decodestring(s: bytes) -> bytes: pass
def encode(input: IO[bytes], output: IO[bytes]) -> None: pass
def encodebytes(s: bytes) -> bytes: pass
def encodestring(s: bytes) -> bytes: pass

########NEW FILE########
__FILENAME__ = binascii
# Stubs for binascii

# Based on http://docs.python.org/3.2/library/binascii.html

import typing

def a2b_uu(string: bytes) -> bytes: pass
def b2a_uu(data: bytes) -> bytes: pass
def a2b_base64(string: bytes) -> bytes: pass
def b2a_base64(data: bytes) -> bytes: pass
def a2b_qp(string: bytes, header: bool = False) -> bytes: pass
def b2a_qp(data: bytes, quotetabs: bool = False, istext: bool = True,
             header: bool = False) -> bytes: pass
def a2b_hqx(string: bytes) -> bytes: pass
def rledecode_hqx(data: bytes) -> bytes: pass
def rlecode_hqx(data: bytes) -> bytes: pass
def b2a_hqx(data: bytes) -> bytes: pass
def crc_hqx(data: bytes, crc: int) -> int: pass
def crc32(data: bytes, crc: int = None) -> int: pass
def b2a_hex(data: bytes) -> bytes: pass
def hexlify(data: bytes) -> bytes: pass
def a2b_hex(hexstr: bytes) -> bytes: pass
def unhexlify(hexlify: bytes) -> bytes: pass

class Error(Exception): pass
class Incomplete(Exception): pass

########NEW FILE########
__FILENAME__ = builtins
"""Stubs for builtins"""

from typing import (
    Undefined, typevar, AbstractGeneric, Iterator, Iterable, overload,
    Sequence, Mapping, Tuple, List, Any, Dict, Function, Generic, Set,
    AbstractSet, Sized, Reversible, SupportsInt, SupportsFloat, SupportsAbs,
    SupportsRound, IO, builtinclass, ducktype
)
from abc import abstractmethod, ABCMeta

# Note that names imported above are not automatically made visible via the
# implicit builtins import.

T = typevar('T')
KT = typevar('KT')
VT = typevar('VT')
S = typevar('S')
T1 = typevar('T1')
T2 = typevar('T2')
T3 = typevar('T3')
T4 = typevar('T4')


staticmethod = object() # Only valid as a decorator.
property = object()


@builtinclass
class object:
    __doc__ = ''
    __class__ = Undefined # type: type
    
    def __init__(self) -> None: pass
    
    def __eq__(self, o: object) -> bool: pass
    def __ne__(self, o: object) -> bool: pass
    
    def __str__(self) -> str: pass
    def __repr__(self) -> str: pass

    def __hash__(self) -> int: pass


# Classes


@builtinclass
class type:
    __name__ = ''
    __module__ = ''
    __dict__ = Undefined # type: Dict[str, Any]
    
    def __init__(self, o: object) -> None: pass


@builtinclass
@ducktype(float)
class int(SupportsInt, SupportsFloat):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, x: SupportsInt) -> None: pass
    @overload
    def __init__(self, x: str) -> None: pass
    @overload
    def __init__(self, x: bytes) -> None: pass
    @overload
    def __init__(self, x: bytearray) -> None: pass
    @overload
    def __init__(self, string: str, base: int) -> None: pass
    @overload
    def __init__(self, string: bytes, base: int) -> None: pass
    @overload
    def __init__(self, string: bytearray, base: int) -> None: pass

    def bit_length(self) -> int: pass
    def to_bytes(self, length: int, byteorder: str, *,
                 signed: bool = False) -> bytes: pass

    # TODO actually classmethod
    # TODO buffer object argument
    @staticmethod
    def from_bytes(bytes: Sequence[int], byteorder: str, *,
                   signed: bool = False) -> int: pass

    def __add__(self, x: int) -> int: pass
    def __sub__(self, x: int) -> int: pass
    def __mul__(self, x: int) -> int: pass
    def __floordiv__(self, x: int) -> int: pass
    def __truediv__(self, x: int) -> float: pass
    def __mod__(self, x: int) -> int: pass
    
    def __radd__(self, x: int) -> int: pass
    def __rsub__(self, x: int) -> int: pass
    def __rmul__(self, x: int) -> int: pass
    def __rfloordiv__(self, x: int) -> int: pass
    def __rtruediv__(self, x: int) -> float: pass
    def __rmod__(self, x: int) -> int: pass
    
    # Return type can be int or float, depending on the value of x.
    def __pow__(self, x: int) -> Any: pass
    def __rpow__(self, x: int) -> Any: pass

    def __and__(self, n: int) -> int: pass
    def __or__(self, n: int) -> int: pass
    def __xor__(self, n: int) -> int: pass
    def __lshift__(self, n: int) -> int: pass
    def __rshift__(self, n: int) -> int: pass

    def __rand__(self, n: int) -> int: pass
    def __ror__(self, n: int) -> int: pass
    def __rxor__(self, n: int) -> int: pass
    def __rlshift__(self, n: int) -> int: pass
    def __rrshift__(self, n: int) -> int: pass

    def __neg__(self) -> int: pass
    def __invert__(self) -> int: pass

    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    def __lt__(self, x: int) -> bool: pass
    def __le__(self, x: int) -> bool: pass
    def __gt__(self, x: int) -> bool: pass
    def __ge__(self, x: int) -> bool: pass

    # Conversions

    def __str__(self) -> str: pass
    def __float__(self) -> float: pass
    def __int__(self) -> int: return self
    
    def __hash__(self) -> int: pass

    
@builtinclass
@ducktype(complex)
class float(SupportsFloat, SupportsInt):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, x: SupportsFloat) -> None: pass
    @overload
    def __init__(self, x: str) -> None: pass
    @overload
    def __init__(self, x: bytes) -> None: pass
    @overload
    def __init__(self, x: bytearray) -> None: pass

    def as_integer_ratio(self) -> Tuple[int, int]: pass
    def hex(self) -> str: pass
    def is_integer(self) -> bool: pass

    # TODO actually classmethod
    @staticmethod
    def fromhex(s: str) -> float: pass

    # Operators
    
    def __add__(self, x: float) -> float: pass
    def __sub__(self, x: float) -> float: pass
    def __mul__(self, x: float) -> float: pass
    def __floordiv__(self, x: float) -> float: pass
    def __truediv__(self, x: float) -> float: pass
    def __mod__(self, x: float) -> float: pass
    def __pow__(self, x: float) -> float: pass
    
    def __radd__(self, x: float) -> float: pass
    def __rsub__(self, x: float) -> float: pass
    def __rmul__(self, x: float) -> float: pass
    def __rfloordiv__(self, x: float) -> float: pass
    def __rtruediv__(self, x: float) -> float: pass
    def __rmod__(self, x: float) -> float: pass
    def __rpow__(self, x: float) -> float: pass
    
    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    def __lt__(self, x: float) -> bool: pass
    def __le__(self, x: float) -> bool: pass
    def __gt__(self, x: float) -> bool: pass
    def __ge__(self, x: float) -> bool: pass
    def __neg__(self) -> float: pass

    def __str__(self) -> str: pass
    def __int__(self) -> int: pass
    def __float__(self) -> float: return self
    def __hash__(self) -> int: pass


@builtinclass
class complex:
    # TODO this is just a placeholder; add more members
    def __init__(self, re: float, im: float = 0.0) -> None: pass


@builtinclass
class str(Sequence[str]):
    # TODO maketrans
    
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, o: object) -> None: pass
    @overload
    def __init__(self, o: bytes, encoding: str = None,
                 errors: str = 'strict') -> None: pass
    @overload
    def __init__(self, o: bytearray, encoding: str = None,
                 errors: str = 'strict') -> None: pass

    def capitalize(self) -> str: pass
    def center(self, width: int, fillchar: str = ' ') -> str: pass
    def count(self, x: str) -> int: pass
    def encode(self, encoding: str = 'utf-8',
               errors: str = 'strict') -> bytes: pass
    # TODO tuple suffix; None value for int
    def endswith(self, suffix: str, start: int = 0,
                 end: int = None) -> bool: pass
    def expandtabs(self, tabsize: int = 8) -> str: pass
    
    @overload
    def find(self, sub: str, start: int = 0) -> int: pass
    @overload
    def find(self, sub: str, start: int, end: int) -> int: pass
    
    def format(self, *args: Any, **kwargs: Any) -> str: pass
    def format_map(self, map: Mapping[str, Any]) -> str: pass
    
    @overload
    def index(self, sub: str, start: int = 0) -> int: pass
    @overload
    def index(self, sub: str, start: int, end: int) -> int: pass
    
    def isalnum(self) -> bool: pass
    def isalpha(self) -> bool: pass
    def isdecimal(self) -> bool: pass
    def isdigit(self) -> bool: pass
    def isidentifier(self) -> bool: pass
    def islower(self) -> bool: pass
    def isnumeric(self) -> bool: pass
    def isprintable(self) -> bool: pass
    def isspace(self) -> bool: pass
    def istitle(self) -> bool: pass
    def isupper(self) -> bool: pass
    def join(self, iterable: Iterable[str]) -> str: pass
    def ljust(self, width: int, fillchar: str = ' ') -> str: pass
    def lower(self) -> str: pass
    def lstrip(self, chars: str = None) -> str: pass
    def partition(self, sep: str) -> Tuple[str, str, str]: pass
    def replace(self, old: str, new: str, count: int = -1) -> str: pass
    
    @overload
    def rfind(self, sub: str, start: int = 0) -> int: pass
    @overload
    def rfind(self, sub: str, start: int, end: int) -> int: pass
    @overload
    def rindex(self, sub: str, start: int = 0) -> int: pass
    @overload
    def rindex(self, sub: str, start: int, end: int) -> int: pass
    
    def rjust(self, width: int, fillchar: str = ' ') -> str: pass
    def rpartition(self, sep: str) -> Tuple[str, str, str]: pass
    def rsplit(self, sep: str = None, maxsplit: int = -1) -> List[str]: pass
    def rstrip(self, chars: str = None) -> str: pass
    def split(self, sep: str = None, maxsplit: int = -1) -> List[str]: pass
    def splitlines(self, keepends: bool = False) -> List[str]: pass
    # TODO tuple prefix; None value for int
    def startswith(self, prefix: str, start: int = 0,
                   end: int = None) -> bool: pass
    def strip(self, chars: str = None) -> str: pass
    def swapcase(self) -> str: pass
    def title(self) -> str: pass
    def translate(self, table: Dict[int, Any]) -> str: pass
    def upper(self) -> str: pass
    def zfill(self, width: int) -> str: pass
    
    @overload
    def __getitem__(self, i: int) -> str: pass
    @overload
    def __getitem__(self, s: slice) -> str: pass

    def __add__(self, s: str) -> str: pass
    def __mul__(self, n: int) -> str: pass
    def __rmul__(self, n: int) -> str: pass
    def __mod__(self, *args: Any) -> str: pass
    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    def __lt__(self, x: str) -> bool: pass
    def __le__(self, x: str) -> bool: pass
    def __gt__(self, x: str) -> bool: pass
    def __ge__(self, x: str) -> bool: pass
    
    def __len__(self) -> int: pass
    def __contains__(self, s: object) -> bool: pass
    def __iter__(self) -> Iterator[str]: pass
    def __str__(self) -> str: return self
    def __repr__(self) -> str: pass
    def __int__(self) -> int: pass
    def __float__(self) -> float: pass
    def __hash__(self) -> int: pass
    

@builtinclass
class bytes(Sequence[int]):
    # TODO fromhex
    # TODO maketrans
    
    @overload
    def __init__(self, ints: Iterable[int]) -> None: pass
    @overload
    def __init__(self, string: str, encoding: str,
                 errors: str = 'strict') -> None: pass
    @overload
    def __init__(self, length: int) -> None: pass
    @overload
    def __init__(self) -> None: pass

    def capitalize(self) -> bytes: pass
    
    @overload
    def center(self, width: int, fillchar: bytes = None) -> bytes: pass
    @overload
    def center(self, width: int, fillchar: bytearray = None) -> bytes: pass
    @overload
    def count(self, x: bytes) -> int: pass
    @overload
    def count(self, x: bytearray) -> int: pass
    def decode(self, encoding: str = 'utf-8',
               errors: str = 'strict') -> str: pass
    @overload
    def endswith(self, suffix: bytes) -> bool: pass
    @overload
    def endswith(self, suffix: bytearray) -> bool: pass
    def expandtabs(self, tabsize: int = 8) -> bytes: pass
    @overload
    def find(self, sub: bytes, start: int = 0) -> int: pass
    @overload
    def find(self, sub: bytes, start: int, end: int) -> int: pass
    @overload
    def find(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def find(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def index(self, sub: bytes, start: int = 0) -> int: pass
    @overload
    def index(self, sub: bytes, start: int, end: int) -> int: pass
    @overload
    def index(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def index(self, sub: bytearray, start: int, end: int) -> int: pass
    def isalnum(self) -> bool: pass
    def isalpha(self) -> bool: pass
    def isdigit(self) -> bool: pass
    def islower(self) -> bool: pass
    def isspace(self) -> bool: pass
    def istitle(self) -> bool: pass
    def isupper(self) -> bool: pass
    @overload
    def join(self, iterable: Iterable[bytes]) -> bytes: pass
    @overload
    def join(self, iterable: Iterable[bytearray]) -> bytes: pass
    @overload
    def ljust(self, width: int, fillchar: bytes = None) -> bytes: pass
    @overload
    def ljust(self, width: int, fillchar: bytearray = None) -> bytes: pass
    def lower(self) -> bytes: pass
    @overload
    def lstrip(self, chars: bytes = None) -> bytes: pass
    @overload
    def lstrip(self, chars: bytearray = None) -> bytes: pass
    @overload
    def partition(self, sep: bytes) -> Tuple[bytes, bytes, bytes]: pass
    @overload
    def partition(self, sep: bytearray) -> Tuple[bytes, bytes, bytes]: pass
    @overload
    def replace(self, old: bytes, new: bytes, count: int = -1) -> bytes: pass
    @overload
    def replace(self, old: bytearray, new: bytearray,
                count: int = -1) -> bytes: pass
    @overload
    def rfind(self, sub: bytes, start: int = 0) -> int: pass
    @overload
    def rfind(self, sub: bytes, start: int, end: int) -> int: pass
    @overload
    def rfind(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def rfind(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def rindex(self, sub: bytes, start: int = 0) -> int: pass
    @overload
    def rindex(self, sub: bytes, start: int, end: int) -> int: pass
    @overload
    def rindex(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def rindex(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def rjust(self, width: int, fillchar: bytes = None) -> bytes: pass
    @overload
    def rjust(self, width: int, fillchar: bytearray = None) -> bytes: pass
    @overload
    def rpartition(self, sep: bytes) -> Tuple[bytes, bytes, bytes]: pass
    @overload
    def rpartition(self, sep: bytearray) -> Tuple[bytes, bytes, bytes]: pass
    @overload
    def rsplit(self, sep: bytes = None,
               maxsplit: int = -1) -> List[bytes]: pass
    @overload
    def rsplit(self, sep: bytearray = None,
               maxsplit: int = -1) -> List[bytes]: pass
    @overload
    def rstrip(self, chars: bytes = None) -> bytes: pass
    @overload
    def rstrip(self, chars: bytearray = None) -> bytes: pass
    @overload
    def split(self, sep: bytes = None, maxsplit: int = -1) -> List[bytes]: pass
    @overload
    def split(self, sep: bytearray = None,
              maxsplit: int = -1) -> List[bytes]: pass
    def splitlines(self, keepends: bool = False) -> List[bytes]: pass
    @overload
    def startswith(self, prefix: bytes) -> bool: pass
    @overload
    def startswith(self, prefix: bytearray) -> bool: pass
    @overload
    def strip(self, chars: bytes = None) -> bytes: pass
    @overload
    def strip(self, chars: bytearray = None) -> bytes: pass
    def swapcase(self) -> bytes: pass
    def title(self) -> bytes: pass
    @overload
    def translate(self, table: bytes) -> bytes: pass
    @overload
    def translate(self, table: bytearray) -> bytes: pass
    def upper(self) -> bytes: pass
    def zfill(self, width: int) -> bytes: pass
    
    def __len__(self) -> int: pass
    def __iter__(self) -> Iterator[int]: pass
    def __str__(self) -> str: pass
    def __repr__(self) -> str: pass
    def __int__(self) -> int: pass
    def __float__(self) -> float: pass
    def __hash__(self) -> int: pass
    
    @overload
    def __getitem__(self, i: int) -> int: pass
    @overload
    def __getitem__(self, s: slice) -> bytes: pass
    @overload
    def __add__(self, s: bytes) -> bytes: pass    
    @overload
    def __add__(self, s: bytearray) -> bytes: pass
    
    def __mul__(self, n: int) -> bytes: pass
    def __rmul__(self, n: int) -> bytes: pass
    def __contains__(self, o: object) -> bool: pass    
    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    def __lt__(self, x: bytes) -> bool: pass
    def __le__(self, x: bytes) -> bool: pass
    def __gt__(self, x: bytes) -> bool: pass
    def __ge__(self, x: bytes) -> bool: pass


@builtinclass
class bytearray(Sequence[int]):
    # TODO fromhex
    # TODO maketrans
    
    @overload
    def __init__(self, ints: Iterable[int]) -> None: pass
    @overload
    def __init__(self, string: str, encoding: str,
                 errors: str = 'strict') -> None: pass
    @overload
    def __init__(self, length: int) -> None: pass
    @overload
    def __init__(self) -> None: pass

    def capitalize(self) -> bytearray: pass
    @overload
    def center(self, width: int, fillchar: bytes = None) -> bytearray: pass
    @overload
    def center(self, width: int, fillchar: bytearray = None) -> bytearray: pass
    @overload
    def count(self, x: bytes) -> int: pass
    @overload
    def count(self, x: bytearray) -> int: pass
    def decode(self, encoding: str = 'utf-8',
               errors: str = 'strict') -> str: pass
    @overload
    def endswith(self, suffix: bytes) -> bool: pass
    @overload
    def endswith(self, suffix: bytearray) -> bool: pass
    def expandtabs(self, tabsize: int = 8) -> bytearray: pass
    @overload
    def find(self, sub: bytes, start: int = 0) -> int: pass
    @overload
    def find(self, sub: bytes, start: int, end: int) -> int: pass
    @overload
    def find(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def find(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def index(self, sub: bytes, start: int = 0) -> int: pass
    @overload
    def index(self, sub: bytes, start: int, end: int) -> int: pass
    @overload
    def index(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def index(self, sub: bytearray, start: int, end: int) -> int: pass
    def isalnum(self) -> bool: pass
    def isalpha(self) -> bool: pass
    def isdigit(self) -> bool: pass
    def islower(self) -> bool: pass
    def isspace(self) -> bool: pass
    def istitle(self) -> bool: pass
    def isupper(self) -> bool: pass
    @overload
    def join(self, iterable: Iterable[bytes]) -> bytearray: pass
    @overload
    def join(self, iterable: Iterable[bytearray]) -> bytearray: pass
    @overload
    def ljust(self, width: int, fillchar: bytes = None) -> bytearray: pass
    @overload
    def ljust(self, width: int, fillchar: bytearray = None) -> bytearray: pass
    def lower(self) -> bytearray: pass
    @overload
    def lstrip(self, chars: bytes = None) -> bytearray: pass
    @overload
    def lstrip(self, chars: bytearray = None) -> bytearray: pass
    @overload
    def partition(self, sep: bytes) -> Tuple[bytearray, bytearray,
                                             bytearray]: pass
    @overload
    def partition(self, sep: bytearray) -> Tuple[bytearray, bytearray,
                                                 bytearray]: pass
    @overload
    def replace(self, old: bytes, new: bytes,
                count: int = -1) -> bytearray: pass
    @overload
    def replace(self, old: bytearray, new: bytearray,
                count: int = -1) -> bytearray: pass
    @overload
    def rfind(self, sub: bytes, start: int = 0) -> int: pass
    @overload
    def rfind(self, sub: bytes, start: int, end: int) -> int: pass
    @overload
    def rfind(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def rfind(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def rindex(self, sub: bytes, start: int = 0) -> int: pass
    @overload
    def rindex(self, sub: bytes, start: int, end: int) -> int: pass
    @overload
    def rindex(self, sub: bytearray, start: int = 0) -> int: pass
    @overload
    def rindex(self, sub: bytearray, start: int, end: int) -> int: pass
    @overload
    def rjust(self, width: int, fillchar: bytes = None) -> bytearray: pass
    @overload
    def rjust(self, width: int, fillchar: bytearray = None) -> bytearray: pass
    @overload
    def rpartition(self, sep: bytes) -> Tuple[bytearray, bytearray,
                                              bytearray]: pass
    @overload
    def rpartition(self, sep: bytearray) -> Tuple[bytearray, bytearray,
                                                  bytearray]:pass
    @overload
    def rsplit(self, sep: bytes = None,
               maxsplit: int = -1) -> List[bytearray]: pass
    @overload
    def rsplit(self, sep: bytearray = None,
               maxsplit: int = -1) -> List[bytearray]: pass
    @overload
    def rstrip(self, chars: bytes = None) -> bytearray: pass
    @overload
    def rstrip(self, chars: bytearray = None) -> bytearray: pass
    @overload
    def split(self, sep: bytes = None,
              maxsplit: int = -1) -> List[bytearray]: pass
    @overload
    def split(self, sep: bytearray = None,
              maxsplit: int = -1) -> List[bytearray]: pass
    def splitlines(self, keepends: bool = False) -> List[bytearray]: pass
    @overload
    def startswith(self, prefix: bytes) -> bool: pass
    @overload
    def startswith(self, prefix: bytearray) -> bool: pass
    @overload
    def strip(self, chars: bytes = None) -> bytearray: pass
    @overload
    def strip(self, chars: bytearray = None) -> bytearray: pass
    def swapcase(self) -> bytearray: pass
    def title(self) -> bytearray: pass
    @overload
    def translate(self, table: bytes) -> bytearray: pass
    @overload
    def translate(self, table: bytearray) -> bytearray: pass
    def upper(self) -> bytearray: pass
    def zfill(self, width: int) -> bytearray: pass
    
    def __len__(self) -> int: pass
    def __iter__(self) -> Iterator[int]: pass
    def __str__(self) -> str: pass
    def __repr__(self) -> str: pass
    def __int__(self) -> int: pass
    def __float__(self) -> float: pass
    def __hash__(self) -> int: pass
    
    @overload
    def __getitem__(self, i: int) -> int: pass
    @overload
    def __getitem__(self, s: slice) -> bytearray: pass
    @overload
    def __setitem__(self, i: int, x: int) -> None: pass
    @overload
    def __setitem__(self, s: slice, x: Sequence[int]) -> None: pass
    @overload
    def __delitem__(self, i: int) -> None: pass
    @overload
    def __delitem__(self, s: slice) -> None: pass
    
    @overload
    def __add__(self, s: bytes) -> bytearray: pass    
    @overload
    def __add__(self, s: bytearray) -> bytearray: pass
    @overload
    def __iadd__(self, s: bytes) -> bytearray: pass    
    @overload
    def __iadd__(self, s: bytearray) -> bytearray: pass
    
    def __mul__(self, n: int) -> bytearray: pass
    def __rmul__(self, n: int) -> bytearray: pass
    def __imul__(self, n: int) -> bytearray: pass
    def __contains__(self, o: object) -> bool: pass
    def __eq__(self, x: object) -> bool: pass
    def __ne__(self, x: object) -> bool: pass
    @overload
    def __lt__(self, x: bytearray) -> bool: pass
    @overload
    def __lt__(self, x: bytes) -> bool: pass
    @overload
    def __le__(self, x: bytearray) -> bool: pass
    @overload
    def __le__(self, x: bytes) -> bool: pass
    @overload
    def __gt__(self, x: bytearray) -> bool: pass
    @overload
    def __gt__(self, x: bytes) -> bool: pass
    @overload
    def __ge__(self, x: bytearray) -> bool: pass
    @overload
    def __ge__(self, x: bytes) -> bool: pass


@builtinclass
class bool(int, SupportsInt, SupportsFloat):
    def __init__(self, o: object = False) -> None: pass


@builtinclass
class slice:
    start = 0
    step = 0
    stop = 0
    def __init__(self, start: int, stop: int, step: int) -> None: pass


@builtinclass
class tuple(Iterable[Any], Sized):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[Any]) -> None: pass
    @overload
    def __init__(self, iterable: tuple) -> None: pass
    
    def __len__(self) -> int: pass
    def __contains__(self, x: object) -> bool: pass
    
    @overload
    def __getitem__(self, x: int) -> Any: pass
    @overload
    def __getitem__(self, x: slice) -> tuple: pass
    
    def __iter__(self) -> Iterator[Any]: pass
    def __lt__(self, x: tuple) -> bool: pass
    def __le__(self, x: tuple) -> bool: pass
    def __gt__(self, x: tuple) -> bool: pass
    def __ge__(self, x: tuple) -> bool: pass


@builtinclass
class function:
    # TODO not defined in builtins!
    __name__ = ''
    __module__ = ''
    __code__ = Undefined(Any)


@builtinclass
class list(Sequence[T], Reversible[T], AbstractGeneric[T]):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[T]) -> None: pass
    
    def append(self, object: T) -> None: pass
    def extend(self, iterable: Iterable[T]) -> None: pass
    def pop(self) -> T: pass
    def index(self, object: T) -> int: pass
    def count(self, object: T) -> int: pass
    def insert(self, index: int, object: T) -> None: pass
    def remove(self, object: T) -> None: pass
    def reverse(self) -> None: pass
    def sort(self, *, key: Function[[T], Any] = None,
             reverse: bool = False) -> None: pass
    
    def __len__(self) -> int: pass
    def __iter__(self) -> Iterator[T]: pass
    def __str__(self) -> str: pass
    def __hash__(self) -> int: pass
    
    @overload
    def __getitem__(self, i: int) -> T: pass
    @overload
    def __getitem__(self, s: slice) -> List[T]: pass    
    @overload
    def __setitem__(self, i: int, o: T) -> None: pass
    @overload
    def __setitem__(self, s: slice, o: Sequence[T]) -> None: pass
    @overload
    def __delitem__(self, i: int) -> None: pass
    @overload
    def __delitem__(self, s: slice) -> None: pass
    
    def __add__(self, x: List[T]) -> List[T]: pass
    def __iadd__(self, x: Iterable[T]) -> List[T]: pass
    def __mul__(self, n: int) -> List[T]: pass
    def __rmul__(self, n: int) -> List[T]: pass
    def __imul__(self, n: int) -> List[T]: pass
    def __contains__(self, o: object) -> bool: pass
    def __reversed__(self) -> Iterator[T]: pass


@builtinclass
class dict(Mapping[KT, VT], Generic[KT, VT]):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, map: Mapping[KT, VT]) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[Tuple[KT, VT]]) -> None: pass
    # TODO __init__ keyword args
    
    def __len__(self) -> int: pass
    def __getitem__(self, k: KT) -> VT: pass
    def __setitem__(self, k: KT, v: VT) -> None: pass
    def __delitem__(self, v: KT) -> None: pass
    def __contains__(self, o: object) -> bool: pass
    def __iter__(self) -> Iterator[KT]: pass
    def __str__(self) -> str: pass
    
    def clear(self) -> None: pass
    def copy(self) -> Dict[KT, VT]: pass
    
    @overload
    def get(self, k: KT) -> VT: pass
    @overload
    def get(self, k: KT, default: VT) -> VT: pass
    @overload
    def pop(self, k: KT) -> VT: pass
    @overload
    def pop(self, k: KT, default: VT) -> VT: pass
    def popitem(self) -> Tuple[KT, VT]: pass
    @overload
    def setdefault(self, k: KT) -> VT: pass
    @overload
    def setdefault(self, k: KT, default: VT) -> VT: pass
    
    @overload
    def update(self, m: Mapping[KT, VT]) -> None: pass
    @overload
    def update(self, m: Iterable[Tuple[KT, VT]]) -> None: pass

    def keys(self) -> Set[KT]: pass
    def values(self) -> Set[VT]: pass
    def items(self) -> Set[Tuple[KT, VT]]: pass

    # TODO actually a class method
    @staticmethod
    @overload
    def fromkeys(seq: Sequence[T]) -> Dict[T, Any]: pass
    @staticmethod
    @overload
    def fromkeys(seq: Sequence[T], value: S) -> Dict[T, S]: pass


@builtinclass
class set(AbstractSet[T], Generic[T]):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[T]) -> None: pass
    
    def add(self, element: T) -> None: pass
    def clear(self) -> None: pass
    def copy(self) -> set[T]: pass
    def difference(self, s: Iterable[Any]) -> set[T]: pass
    def difference_update(self, s: Iterable[Any]) -> None: pass
    def discard(self, element: T) -> None: pass
    def intersection(self, s: Iterable[Any]) -> set[T]: pass
    def intersection_update(self, s: Iterable[Any]) -> None: pass
    def isdisjoint(self, s: AbstractSet[Any]) -> bool: pass
    def issubset(self, s: AbstractSet[Any]) -> bool: pass
    def issuperset(self, s: AbstractSet[Any]) -> bool: pass
    def pop(self) -> T: pass
    def remove(self, element: T) -> None: pass
    def symmetric_difference(self, s: Iterable[T]) -> set[T]: pass
    def symmetric_difference_update(self, s: Iterable[T]) -> None: pass
    def union(self, s: Iterable[T]) -> set[T]: pass
    def update(self, s: Iterable[T]) -> None: pass
    
    def __len__(self) -> int: pass
    def __contains__(self, o: object) -> bool: pass
    def __iter__(self) -> Iterator[T]: pass    
    def __str__(self) -> str: pass
    def __and__(self, s: AbstractSet[Any]) -> set[T]: pass
    def __iand__(self, s: AbstractSet[Any]) -> set[T]: pass
    def __or__(self, s: AbstractSet[T]) -> set[T]: pass
    def __ior__(self, s: AbstractSet[T]) -> set[T]: pass
    def __sub__(self, s: AbstractSet[Any]) -> set[T]: pass
    def __isub__(self, s: AbstractSet[Any]) -> set[T]: pass
    def __xor__(self, s: AbstractSet[T]) -> set[T]: pass
    def __ixor__(self, s: AbstractSet[T]) -> set[T]: pass
    def __le__(self, s: AbstractSet[Any]) -> bool: pass
    def __lt__(self, s: AbstractSet[Any]) -> bool: pass
    def __ge__(self, s: AbstractSet[Any]) -> bool: pass
    def __gt__(self, s: AbstractSet[Any]) -> bool: pass
    
    # TODO more set operations


@builtinclass
class frozenset(AbstractSet[T], Generic[T]):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[T]) -> None: pass

    def copy(self) -> frozenset[T]: pass
    def difference(self, s: AbstractSet[Any]) -> frozenset[T]: pass
    def intersection(self, s: AbstractSet[Any]) -> frozenset[T]: pass
    def isdisjoint(self, s: AbstractSet[T]) -> bool: pass
    def issubset(self, s: AbstractSet[Any]) -> bool: pass
    def issuperset(self, s: AbstractSet[Any]) -> bool: pass
    def symmetric_difference(self, s: AbstractSet[T]) -> frozenset[T]: pass
    def union(self, s: AbstractSet[T]) -> frozenset[T]: pass
    
    def __len__(self) -> int: pass
    def __contains__(self, o: object) -> bool: pass
    def __iter__(self) -> Iterator[T]: pass    
    def __str__(self) -> str: pass
    def __and__(self, s: AbstractSet[T]) -> frozenset[T]: pass
    def __or__(self, s: AbstractSet[T]) -> frozenset[T]: pass
    def __sub__(self, s: AbstractSet[T]) -> frozenset[T]: pass
    def __xor__(self, s: AbstractSet[T]) -> frozenset[T]: pass
    def __le__(self, s: AbstractSet[Any]) -> bool: pass
    def __lt__(self, s: AbstractSet[Any]) -> bool: pass
    def __ge__(self, s: AbstractSet[Any]) -> bool: pass
    def __gt__(self, s: AbstractSet[Any]) -> bool: pass


@builtinclass
class enumerate(Iterator[Tuple[int, T]], Generic[T]):
    def __init__(self, iterable: Iterable[T], start: int = 0) -> None: pass
    def __iter__(self) -> Iterator[Tuple[int, T]]: pass
    def __next__(self) -> Tuple[int, T]: pass
    # TODO __getattribute__


@builtinclass
class range(Sequence[int], Reversible[int]):
    @overload
    def __init__(self, stop: int) -> None: pass
    @overload
    def __init__(self, start: int, stop: int, step: int = 1) -> None: pass
    
    def count(self, value: int) -> int: pass
    def index(self, value: int, start: int = 0, stop: int = None) -> int: pass
    
    def __len__(self) -> int: pass
    def __contains__(self, o: object) -> bool: pass
    def __iter__(self) -> Iterator[int]: pass
    @overload
    def __getitem__(self, i: int) -> int: pass
    @overload
    def __getitem__(self, s: slice) -> range: pass
    def __repr__(self) -> str: pass
    def __reversed__(self) -> Iterator[int]: pass


@builtinclass
class module:
    # TODO not defined in builtins!
    __name__ = ''
    __file__ = ''
    __dict__ = Undefined # type: Dict[str, Any]


True = Undefined # type: bool
False = Undefined # type: bool
__debug__ = False


NotImplemented = Undefined # type: Any


@overload
def abs(n: int) -> int: pass
@overload
def abs(n: float) -> float: pass
@overload
def abs(n: SupportsAbs[T]) -> T: pass

def all(i: Iterable) -> bool: pass
def any(i: Iterable) -> bool: pass
def ascii(o: object) -> str: pass
def callable(o: object) -> bool: pass
def chr(code: int) -> str: pass
def delattr(o: Any, name: str) -> None: pass
def dir(o: object = None) -> List[str]: pass

_N = typevar('_N', values=(int, float))
def divmod(a: _N, b: _N) -> Tuple[_N, _N]: pass

# TODO code object as source
def eval(source: str, globals: Dict[str, Any] = None,
         locals: Mapping[str, Any] = None) -> Any: pass

def filter(function: Function[[T], Any],
           iterable: Iterable[T]) -> Iterator[T]: pass
def format(o: object, format_spec: str = '') -> str: pass
def getattr(o: Any, name: str, default: Any = None) -> Any: pass
def globals() -> Dict[str, Any]: pass
def hasattr(o: Any, name: str) -> bool: pass
def hash(o: object) -> int: pass
# TODO __index__
def hex(i: int) -> str: pass
def id(o: object) -> int: pass
def input(prompt: str = None) -> str: pass

@overload
def iter(iterable: Iterable[T]) -> Iterator[T]: pass
@overload
def iter(function: Function[[], T], sentinel: T) -> Iterator[T]: pass

@overload
def isinstance(o: object, t: type) -> bool: pass
@overload
def isinstance(o: object, t: tuple) -> bool: pass

def issubclass(cls: type, classinfo: type) -> bool: pass
# TODO perhaps support this
#def issubclass(type cld, classinfo: Sequence[type]) -> bool: pass
def len(o: Sized) -> int: pass
def locals() -> Dict[str, Any]: pass

# TODO more than two iterables
@overload
def map(func: Function[[T1], S], iter1: Iterable[T1]) -> Iterator[S]: pass
@overload
def map(func: Function[[T1, T2], S],
        iter1: Iterable[T1],
        iter2: Iterable[T2]) -> Iterator[S]: pass

# TODO keyword argument key
@overload
def max(iterable: Iterable[T]) -> T: pass
@overload
def max(arg1: T, arg2: T, *args: T) -> T: pass

# TODO memoryview

@overload
def min(iterable: Iterable[T]) -> T: pass
@overload
def min(arg1: T, arg2: T, *args: T) -> T: pass

@overload
def next(i: Iterator[T]) -> T: pass
@overload
def next(i: Iterator[T], default: T) -> T: pass

# TODO __index__
def oct(i: int) -> str: pass

@overload
def open(file: str, mode: str = 'r', buffering: int = -1, encoding: str = None,
         errors: str = None, newline: str = None,
         closefd: bool = True) -> IO[Any]: pass
@overload
def open(file: bytes, mode: str = 'r', buffering: int = -1,
         encoding: str = None, errors: str = None, newline: str = None,
         closefd: bool = True) -> IO[Any]: pass
@overload
def open(file: int, mode: str = 'r', buffering: int = -1, encoding: str = None,
         errors: str = None, newline: str = None,
         closefd: bool = True) -> IO[Any]: pass

@overload
def ord(c: str) -> int: pass
@overload
def ord(c: bytes) -> int: pass
@overload
def ord(c: bytearray) -> int: pass

def print(*values: Any, *, sep: str = ' ', end: str = '\n',
           file: IO[str] = None) -> None: pass

# The return type can be int or float, depending on the value of y.
@overload
def pow(x: int, y: int) -> Any: pass
@overload
def pow(x: int, y: int, z: int) -> Any: pass
@overload
def pow(x: float, y: float) -> float: pass
@overload
def pow(x: float, y: float, z: float) -> float: pass

@overload
def reversed(object: Reversible[T]) -> Iterator[T]: pass
@overload
def reversed(object: Sequence[T]) -> Iterator[T]: pass

def repr(o: object) -> str: pass

# Always return a float if ndigits is present.
@overload
def round(number: float) -> int: pass
@overload
def round(number: float, ndigits: int) -> float: pass
@overload
def round(number: SupportsRound[T]) -> T: pass
@overload
def round(number: SupportsRound[T], ndigits: int) -> T: pass

def setattr(object: Any, name: str, value: Any) -> None: pass
def sorted(iterable: Iterable[T], *, key: Function[[T], Any] = None,
           reverse: bool = False) -> List[T]: pass
def sum(iterable: Iterable[T], start: T = None) -> T: pass

# TODO more than four iterables
@overload
def zip(iter1: Iterable[T1]) -> Iterator[Tuple[T1]]: pass
@overload
def zip(iter1: Iterable[T1],
        iter2: Iterable[T2]) -> Iterator[Tuple[T1, T2]]: pass
@overload
def zip(iter1: Iterable[T1], iter2: Iterable[T2],
        iter3: Iterable[T3]) -> Iterator[Tuple[T1, T2, T3]]: pass
@overload
def zip(iter1: Iterable[T1], iter2: Iterable[T2], iter3: Iterable[T3],
        iter4: Iterable[T4]) -> Iterator[Tuple[T1, T2, T3, T4]]: pass

def __import__(name: str,
               globals: Dict[str, Any] = {},
               locals: Dict[str, Any] = {},
               fromlist: List[str] = [], level: int = -1) -> Any: pass


# Exceptions


@builtinclass
class BaseException:
    args = Undefined # type: Any
    def __init__(self, *args: Any) -> None: pass
    def with_traceback(self, tb: Any) -> BaseException: pass

class GeneratorExit(BaseException): pass
class KeyboardInterrupt(BaseException): pass
@builtinclass
class SystemExit(BaseException):
    code = 0

# Base classes
class Exception(BaseException): pass
class ArithmeticError(Exception): pass
@builtinclass
class EnvironmentError(Exception):
    errno = 0
    strerror = ''
    filename = '' # TODO can this be bytes?
class LookupError(Exception): pass
class RuntimeError(Exception): pass
class ValueError(Exception): pass

class AssertionError(Exception): pass
class AttributeError(Exception): pass
class EOFError(Exception): pass
class FloatingPointError(ArithmeticError): pass
class IOError(EnvironmentError): pass
class ImportError(Exception): pass
class IndexError(LookupError): pass
class KeyError(LookupError): pass
class MemoryError(Exception): pass
class NameError(Exception): pass
class NotImplementedError(RuntimeError): pass
class OSError(EnvironmentError): pass
class OverflowError(ArithmeticError): pass
class ReferenceError(Exception): pass
class StopIteration(Exception): pass
class SyntaxError(Exception): pass
class IndentationError(SyntaxError): pass
class TabError(IndentationError): pass
class SystemError(Exception): pass
class TypeError(Exception): pass
class UnboundLocalError(NameError): pass
class UnicodeError(ValueError): pass
class UnicodeDecodeError(UnicodeError): pass
class UnicodeEncodeError(UnicodeError): pass
class UnicodeTranslateError(UnicodeError): pass
class ZeroDivisionError(ArithmeticError): pass

class Warning(Exception): pass
class UserWarning(Warning): pass
class DeprecationWarning(Warning): pass
class SyntaxWarning(Warning): pass
class RuntimeWarning(Warning): pass
class FutureWarning(Warning): pass
class PendingDeprecationWarning(Warning): pass
class ImportWarning(Warning): pass
class UnicodeWarning(Warning): pass
class BytesWarning(Warning): pass
class ResourceWarning(Warning): pass

# TODO Windows-only
class WindowsError(OSError): pass

# TODO: VMSError

########NEW FILE########
__FILENAME__ = bz2

########NEW FILE########
__FILENAME__ = calendar
# Stubs for calendar

# NOTE: These are incomplete!

from typing import overload, Tuple

# TODO actually, any number of items larger than 5 is fine
@overload
def timegm(t: Tuple[int, int, int, int, int, int]) -> int: pass
@overload
def timegm(t: Tuple[int, int, int, int, int, int, int]) -> int: pass
@overload
def timegm(t: Tuple[int, int, int, int, int, int, int, int]) -> int: pass
@overload
def timegm(t: Tuple[int, int, int, int, int, int, int, int, int]) -> int: pass

########NEW FILE########
__FILENAME__ = codecs
from typing import Any
def lookup(encoding: str) -> Any: pass
BOM_UTF8 = b''

########NEW FILE########
__FILENAME__ = collections
# Stubs for collections

# Based on http://docs.python.org/3.2/library/collections.html

# TODO namedtuple (requires language changes)
# TODO UserDict
# TODO UserList
# TODO UserString
# TODO more abstract base classes (interfaces in mypy)

from typing import (
    typevar, Iterable, AbstractGeneric, Iterator, Dict, Generic, overload,
    Mapping, List, Tuple, Undefined, Function, Set, Sequence, Sized
)

T = typevar('T')
KT = typevar('KT')
VT = typevar('VT')


class deque(Sized, Iterable[T], AbstractGeneric[T]):
    # TODO int with None default
    maxlen = 0 # TODO readonly
    def __init__(self, iterable: Iterable[T] = None,
                 maxlen: int = None) -> None: pass
    def append(self, x: T) -> None: pass
    def appendleft(self, x: T) -> None: pass
    def clear(self) -> None: pass
    def count(self, x: T) -> int: pass
    def extend(self, iterable: Iterable[T]) -> None: pass
    def extendleft(self, iterable: Iterable[T]) -> None: pass
    def pop(self) -> T: pass
    def popleft(self) -> T: pass
    def remove(self, value: T) -> None: pass
    def reverse(self) -> None: pass
    def rotate(self, n: int) -> None: pass
    
    def __len__(self) -> int: pass
    def __iter__(self) -> Iterator[T]: pass
    def __str__(self) -> str: pass
    def __hash__(self) -> int: pass
    
    def __getitem__(self, i: int) -> T: pass
    def __setitem__(self, i: int, x: T) -> None: pass
    def __contains__(self, o: T) -> bool: pass

    # TODO __reversed__

    
class Counter(Dict[T, int], Generic[T]):
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, Mapping: Mapping[T, int]) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[T]) -> None: pass
    # TODO keyword arguments
    
    def elements(self) -> Iterator[T]: pass
    
    @overload
    def most_common(self) -> List[T]: pass
    @overload
    def most_common(self, n: int) -> List[T]: pass
    
    @overload
    def subtract(self, Mapping: Mapping[T, int]) -> None: pass
    @overload
    def subtract(self, iterable: Iterable[T]) -> None: pass
    
    # TODO update


class OrderedDict(Dict[KT, VT], Generic[KT, VT]):
    def popitem(self, last: bool = True) -> Tuple[KT, VT]: pass
    def move_to_end(self, key: KT, last: bool = True) -> None: pass


class defaultdict(Dict[KT, VT], Generic[KT, VT]):
    default_factory = Undefined(Function[[], VT])
    
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, map: Mapping[KT, VT]) -> None: pass
    @overload
    def __init__(self, iterable: Iterable[Tuple[KT, VT]]) -> None: pass
    @overload
    def __init__(self, default_factory: Function[[], VT]) -> None: pass
    @overload
    def __init__(self, default_factory: Function[[], VT],
                 map: Mapping[KT, VT]) -> None: pass
    @overload
    def __init__(self, default_factory: Function[[], VT],
                 iterable: Iterable[Tuple[KT, VT]]) -> None: pass
    # TODO __init__ keyword args
    
    def __missing__(self, key: KT) -> VT: pass
    # TODO __reversed__

########NEW FILE########
__FILENAME__ = contextlib
# Stubs for contextlib

# NOTE: These are incomplete!

from typing import Any

# TODO more precise type?
def contextmanager(func: Any) -> Any: pass

########NEW FILE########
__FILENAME__ = copy
# Stubs for copy

# NOTE: These are incomplete!

from typing import typevar

T = typevar('T')

def deepcopy(x: T) -> T: pass

########NEW FILE########
__FILENAME__ = errors
import typing

class DistutilsError(Exception): pass
class DistutilsExecError(DistutilsError): pass

########NEW FILE########
__FILENAME__ = spawn
from typing import List

# In Python, arguments have integer default values
def spawn(cmd: List[str], search_path: bool = True, verbose: bool = False,
           dry_run: bool = False) -> None: pass
def find_executable(executable: str, path: str = None) -> str: pass

########NEW FILE########
__FILENAME__ = doctest
# Stubs for doctest

# NOTE: These are incomplete!

from typing import Any, Tuple

# TODO arguments missing
def testmod(module: Any = None, *, name: str = None, globs: Any = None,
            verbose: bool = None) -> Tuple[int, int]: pass

########NEW FILE########
__FILENAME__ = errno
# Stubs for errno

# Based on http://docs.python.org/3.2/library/errno.html

from typing import Undefined, Dict

errorcode = Undefined(Dict[int, str])

# TODO some of the names below are platform specific

EPERM = 0
ENOENT = 0
ESRCH = 0
EINTR = 0
EIO = 0
ENXIO = 0
E2BIG = 0
ENOEXEC = 0
EBADF = 0
ECHILD = 0
EAGAIN = 0
ENOMEM = 0
EACCES = 0
EFAULT = 0
ENOTBLK = 0
EBUSY = 0
EEXIST = 0
EXDEV = 0
ENODEV = 0
ENOTDIR = 0
EISDIR = 0
EINVAL = 0
ENFILE = 0
EMFILE = 0
ENOTTY = 0
ETXTBSY = 0
EFBIG = 0
ENOSPC = 0
ESPIPE = 0
EROFS = 0
EMLINK = 0
EPIPE = 0
EDOM = 0
ERANGE = 0
EDEADLK = 0
ENAMETOOLONG = 0
ENOLCK = 0
ENOSYS = 0
ENOTEMPTY = 0
ELOOP = 0
EWOULDBLOCK = 0
ENOMSG = 0
EIDRM = 0
ECHRNG = 0
EL2NSYNC = 0
EL3HLT = 0
EL3RST = 0
ELNRNG = 0
EUNATCH = 0
ENOCSI = 0
EL2HLT = 0
EBADE = 0
EBADR = 0
EXFULL = 0
ENOANO = 0
EBADRQC = 0
EBADSLT = 0
EDEADLOCK = 0
EBFONT = 0
ENOSTR = 0
ENODATA = 0
ETIME = 0
ENOSR = 0
ENONET = 0
ENOPKG = 0
EREMOTE = 0
ENOLINK = 0
EADV = 0
ESRMNT = 0
ECOMM = 0
EPROTO = 0
EMULTIHOP = 0
EDOTDOT = 0
EBADMSG = 0
EOVERFLOW = 0
ENOTUNIQ = 0
EBADFD = 0
EREMCHG = 0
ELIBACC = 0
ELIBBAD = 0
ELIBSCN = 0
ELIBMAX = 0
ELIBEXEC = 0
EILSEQ = 0
ERESTART = 0
ESTRPIPE = 0
EUSERS = 0
ENOTSOCK = 0
EDESTADDRREQ = 0
EMSGSIZE = 0
EPROTOTYPE = 0
ENOPROTOOPT = 0
EPROTONOSUPPORT = 0
ESOCKTNOSUPPORT = 0
EOPNOTSUPP = 0
EPFNOSUPPORT = 0
EAFNOSUPPORT = 0
EADDRINUSE = 0
EADDRNOTAVAIL = 0
ENETDOWN = 0
ENETUNREACH = 0
ENETRESET = 0
ECONNABORTED = 0
ECONNRESET = 0
ENOBUFS = 0
EISCONN = 0
ENOTCONN = 0
ESHUTDOWN = 0
ETOOMANYREFS = 0
ETIMEDOUT = 0
ECONNREFUSED = 0
EHOSTDOWN = 0
EHOSTUNREACH = 0
EALREADY = 0
EINPROGRESS = 0
ESTALE = 0
EUCLEAN = 0
ENOTNAM = 0
ENAVAIL = 0
EISNAM = 0
EREMOTEIO = 0
EDQUOT = 0

########NEW FILE########
__FILENAME__ = fcntl
# Stubs for fcntl

# NOTE: These are incomplete!

import typing

FD_CLOEXEC = 0
F_GETFD = 0
F_SETFD = 0

def fcntl(fd: int, op: int, arg: int = 0) -> int: pass

########NEW FILE########
__FILENAME__ = fnmatch
# Stubs for fnmatch

# Based on http://docs.python.org/3.2/library/fnmatch.html and
# python-lib/fnmatch.py

from typing import overload, Iterable, List

@overload
def fnmatch(name: str, pat: str) -> bool: pass
@overload
def fnmatch(name: bytes, pat: bytes) -> bool: pass

@overload
def fnmatchcase(name: str, pat: str) -> bool: pass
@overload
def fnmatchcase(name: bytes, pat: bytes) -> bool: pass

@overload
def filter(names: Iterable[str], pat: str) -> List[str]: pass
@overload
def filter(names: Iterable[bytes], pat: bytes) -> List[bytes]: pass
def translate(pat: str) -> str: pass

########NEW FILE########
__FILENAME__ = functools
# Stubs for functools

# NOTE: These are incomplete!

from typing import Function, Any

# TODO implement as class; more precise typing
# TODO cache_info and __wrapped__ attributes
# TODO None valid as value for maxsize
def lru_cache(maxsize: int = 100) -> Function[[Any], Any]: pass

# TODO more precise typing?
def wraps(func: Any) -> Any: pass

########NEW FILE########
__FILENAME__ = gc
# Stubs for gc

# NOTE: These are incomplete!

import typing

def collect(generation: int = -1) -> int: pass
def disable() -> None: pass
def enable() -> None: pass
def isenabled() -> bool: pass

########NEW FILE########
__FILENAME__ = getopt
# Stubs for getopt

# Based on http://docs.python.org/3.2/library/getopt.html

from typing import List, Tuple

def getopt(args: List[str], shortopts: str,
           longopts: List[str]) -> Tuple[List[Tuple[str, str]],
                                         List[str]]: pass

def gnu_getopt(args: List[str], shortopts: str,
               longopts: List[str]) -> Tuple[List[Tuple[str, str]],
                                             List[str]]: pass

class GetoptError(Exception):
    msg = ''
    opt = ''

error = GetoptError

########NEW FILE########
__FILENAME__ = glob
# Stubs for glob

# Based on http://docs.python.org/3.2/library/glob.html

from typing import overload, List, Iterator

@overload
def glob(pathname: str) -> List[str]: pass
@overload
def glob(pathname: bytes) -> List[bytes]: pass
@overload
def iglob(pathname: str) -> Iterator[str]: pass
@overload
def iglob(pathname: bytes) -> Iterator[bytes]: pass

########NEW FILE########
__FILENAME__ = grp
from typing import List, Undefined

# TODO group database entry object type

class struct_group:
    gr_name = ''
    gr_passwd = ''
    gr_gid = 0
    gr_mem = Undefined(List[str])

def getgrgid(gid: int) -> struct_group: pass
def getgrnam(name: str) -> struct_group: pass
def getgrall() -> List[struct_group]: pass

########NEW FILE########
__FILENAME__ = hashlib
# Stubs for hashlib

# NOTE: These are incomplete!

from abc import abstractmethod, ABCMeta
import typing

class Hash(metaclass=ABCMeta):
    @abstractmethod
    def update(self, arg: bytes) -> None: pass
    @abstractmethod
    def digest(self) -> bytes: pass
    @abstractmethod
    def hexdigest(self) -> str: pass
    @abstractmethod
    def copy(self) -> 'Hash': pass

def md5(arg: bytes = None) -> Hash: pass
def sha1(arg: bytes = None) -> Hash: pass
def sha224(arg: bytes = None) -> Hash: pass
def sha256(arg: bytes = None) -> Hash: pass
def sha384(arg: bytes = None) -> Hash: pass
def sha512(arg: bytes = None) -> Hash: pass

def new(name: str, data: bytes = None) -> Hash: pass

########NEW FILE########
__FILENAME__ = heapq
# Stubs for heapq

# Based on http://docs.python.org/3.2/library/heapq.html

from typing import typevar, List, Iterable, Any, Function

T = typevar('T')

def heappush(heap: List[T], item: T) -> None: pass
def heappop(heap: List[T]) -> T: pass
def heappushpop(heap: List[T], item: T) -> T: pass
def heapify(x: List[T]) -> None: pass
def heapreplace(heap: List[T], item: T) -> T: pass
def merge(*iterables: Iterable[T]) -> Iterable[T]: pass
def nlargest(n: int, iterable: Iterable[T],
             key: Function[[T], Any] = None) -> List[T]: pass
def nsmallest(n: int, iterable: Iterable[T],
              key: Function[[T], Any] = None) -> List[T]: pass

########NEW FILE########
__FILENAME__ = imp
# Stubs for imp

# NOTE: These are incomplete!

from typing import typevar

T = typevar('T')

def cache_from_source(path: str, debug_override: bool = None) -> str: pass
def reload(module: T) -> T: pass # TODO imprecise signature

########NEW FILE########
__FILENAME__ = importlib
# Stubs for importlib

# NOTE: These are incomplete!

from typing import Any

# TODO more precise type?
def import_module(name: str, package: str = None) -> Any: pass

########NEW FILE########
__FILENAME__ = io
# Stubs for io

# Based on http://docs.python.org/3.2/library/io.html

# Only a subset of functionality is included (see below).
# TODO IOBase
# TODO RawIOBase
# TODO BufferedIOBase
# TODO FileIO
# TODO BufferedReader
# TODO BufferedWriter
# TODO BufferedRandom
# TODO BufferedRWPair
# TODO TextIOBase
# TODO IncrementalNewlineDecoder

DEFAULT_BUFFER_SIZE = 0

from builtins import open
from typing import List, BinaryIO, TextIO, IO, overload, Iterator, Iterable

class BytesIO(BinaryIO):
    def __init__(self, initial_bytes: bytes = b'') -> None: pass
    # TODO getbuffer
    # TODO see comments in BinaryIO for missing functionality
    def close(self) -> None: pass
    def closed(self) -> bool: pass
    def fileno(self) -> int: pass
    def flush(self) -> None: pass
    def isatty(self) -> bool: pass
    def read(self, n: int = -1) -> bytes: pass
    def readable(self) -> bool: pass
    def readline(self, limit: int = -1) -> bytes: pass
    def readlines(self, hint: int = -1) -> List[bytes]: pass
    def seek(self, offset: int, whence: int = 0) -> int: pass
    def seekable(self) -> bool: pass
    def tell(self) -> int: pass
    def truncate(self, size: int = None) -> int: pass
    def writable(self) -> bool: pass
    @overload
    def write(self, s: bytes) -> int: pass
    @overload
    def write(self, s: bytearray) -> int: pass
    def writelines(self, lines: Iterable[bytes]) -> None: pass
    def getvalue(self) -> bytes: pass
    def read1(self) -> str: pass

    def __iter__(self) -> Iterator[bytes]: pass
    def __enter__(self) -> 'BytesIO': pass
    def __exit__(self, type, value, traceback) -> bool: pass

class StringIO(TextIO):
    def __init__(self, initial_value: str = '',
                 newline: str = None) -> None: pass
    # TODO see comments in BinaryIO for missing functionality
    def close(self) -> None: pass
    def closed(self) -> bool: pass
    def fileno(self) -> int: pass
    def flush(self) -> None: pass
    def isatty(self) -> bool: pass
    def read(self, n: int = -1) -> str: pass
    def readable(self) -> bool: pass
    def readline(self, limit: int = -1) -> str: pass
    def readlines(self, hint: int = -1) -> List[str]: pass
    def seek(self, offset: int, whence: int = 0) -> int: pass
    def seekable(self) -> bool: pass
    def tell(self) -> int: pass
    def truncate(self, size: int = None) -> int: pass
    def writable(self) -> bool: pass
    def write(self, s: str) -> int: pass
    def writelines(self, lines: Iterable[str]) -> None: pass
    def getvalue(self) -> str: pass

    def __iter__(self) -> Iterator[str]: pass
    def __enter__(self) -> 'StringIO': pass
    def __exit__(self, type, value, traceback) -> bool: pass
    
class TextIOWrapper(TextIO):
    # write_through is undocumented but used by subprocess
    def __init__(self, buffer: IO[bytes], encoding: str = None,
                 errors: str = None, newline: str = None,
                 line_buffering: bool = False,
                 write_through: bool = True) -> None: pass
    # TODO see comments in BinaryIO for missing functionality
    def close(self) -> None: pass
    def closed(self) -> bool: pass
    def fileno(self) -> int: pass
    def flush(self) -> None: pass
    def isatty(self) -> bool: pass
    def read(self, n: int = -1) -> str: pass
    def readable(self) -> bool: pass
    def readline(self, limit: int = -1) -> str: pass
    def readlines(self, hint: int = -1) -> List[str]: pass
    def seek(self, offset: int, whence: int = 0) -> int: pass
    def seekable(self) -> bool: pass
    def tell(self) -> int: pass
    def truncate(self, size: int = None) -> int: pass
    def writable(self) -> bool: pass
    def write(self, s: str) -> int: pass
    def writelines(self, lines: Iterable[str]) -> None: pass
    def getvalue(self) -> str: pass

    def __iter__(self) -> Iterator[str]: pass
    def __enter__(self) -> StringIO: pass
    def __exit__(self, type, value, traceback) -> bool: pass

########NEW FILE########
__FILENAME__ = itertools
# Stubs for itertools

# Based on http://docs.python.org/3.2/library/itertools.html

from typing import Iterator, typevar, Iterable, overload, Any, Function, Tuple

T = typevar('T')
S = typevar('S')

def count(start: int = 0,
          step: int = 1) -> Iterator[int]: pass # more general types?
def cycle(iterable: Iterable[T]) -> Iterator[T]: pass

@overload
def repeat(object: T) -> Iterator[T]: pass
@overload
def repeat(object: T, times: int) -> Iterator[T]: pass

def accumulate(iterable: Iterable[T]) -> Iterator[T]: pass
def chain(*iterables: Iterable[T]) -> Iterator[T]: pass
# TODO chain.from_Iterable
def compress(data: Iterable[T], selectors: Iterable[Any]) -> Iterator[T]: pass
def dropwhile(predicate: Function[[T], Any],
              iterable: Iterable[T]) -> Iterator[T]: pass
def filterfalse(predicate: Function[[T], Any],
                iterable: Iterable[T]) -> Iterator[T]: pass

@overload
def groupby(iterable: Iterable[T]) -> Iterator[Tuple[T, Iterator[T]]]: pass
@overload
def groupby(iterable: Iterable[T],
            key: Function[[T], S]) -> Iterator[Tuple[S, Iterator[T]]]: pass

@overload
def islice(iterable: Iterable[T], stop: int) -> Iterator[T]: pass
@overload
def islice(iterable: Iterable[T], start: int, stop: int,
           step: int = 1) -> Iterator[T]: pass

def starmap(func: Any, iterable: Iterable[Any]) -> Iterator[Any]: pass
def takewhile(predicate: Function[[T], Any],
              iterable: Iterable[T]) -> Iterator[T]: pass
def tee(iterable: Iterable[Any], n: int = 2) -> Iterator[Any]: pass
def zip_longest(*p: Iterable[Any]) -> Iterator[Any]: pass # TODO fillvalue

def product(*p: Iterable[Any]) -> Iterator[Any]: pass # TODO repeat
# TODO int with None default
def permutations(iterable: Iterable[Any], r: int = None) -> Iterator[Any]: pass
def combinations(iterable: Iterable[Any], r: int) -> Iterable[Any]: pass
def combinations_with_replacement(iterable: Iterable[Any],
                                  r: int) -> Iterable[Any]: pass

########NEW FILE########
__FILENAME__ = locale
# Stubs for locale

# NOTE: These are incomplete!

from typing import overload, Iterable

@overload
def setlocale(category: int, locale: str = None) -> str: pass
@overload
def setlocale(category: int, locale: Iterable[str]) -> str: pass

########NEW FILE########
__FILENAME__ = handlers
# Stubs for logging.handlers

# NOTE: These are incomplete!

from typing import Any

class BufferingHandler:
    def __init__(self, capacity: int) -> None: pass
    def emit(self, record: Any) -> None: pass
    def flush(self) -> None: pass
    def shouldFlush(self, record: Any) -> bool: pass

########NEW FILE########
__FILENAME__ = math
# Stubs for math
# Ron Murawski <ron@horizonchess.com>

# based on: http://docs.python.org/3.2/library/math.html

from typing import overload, Tuple, Iterable

# ----- variables and constants -----
e = 0.0
pi = 0.0

# ----- functions -----
def ceil(x: float) -> int: pass
def copysign(x: float, y: float) -> float: pass
def fabs(x: float) -> float: pass
def factorial(x: int) -> int: pass
def floor(x: float) -> int: pass
def fmod(x: float, y: float) -> float: pass
def frexp(x: float) -> Tuple[float, int]: pass
def fsum(iterable: Iterable) -> float: pass
def isfinite(x: float) -> bool: pass
def isinf(x: float) -> bool: pass
def isnan(x: float) -> bool: pass
def ldexp(x: float, i: int) -> float: pass
def modf(x: float) -> Tuple[float, float]: pass
def trunc(x: float) -> float: pass
def exp(x: float) -> float: pass
def expm1(x: float) -> float: pass
def log(x: float, base: float = e) -> float: pass
def log1p(x: float) -> float: pass
def log10(x: float) -> float: pass
def pow(x: float, y: float) -> float: pass
def sqrt(x: float) -> float: pass
def acos(x: float) -> float: pass
def asin(x: float) -> float: pass
def atan(x: float) -> float: pass
def atan2(y: float, x: float) -> float: pass
def cos(x: float) -> float: pass
def hypot(x: float, y: float) -> float: pass
def sin(x: float) -> float: pass
def tan(x: float) -> float: pass
def degrees(x: float) -> float: pass
def radians(x: float) -> float: pass
def acosh(x: float) -> float: pass
def asinh(x: float) -> float: pass
def atanh(x: float) -> float: pass
def cosh(x: float) -> float: pass
def sinh(x: float) -> float: pass
def tanh(x: float) -> float: pass
def erf(x: object) -> float: pass
def erfc(x: object) -> float: pass
def gamma(x: object) -> float: pass
def lgamma(x: object) -> float: pass

########NEW FILE########
__FILENAME__ = msvcrt
# Stubs for msvcrt

# NOTE: These are incomplete!

from typing import overload, BinaryIO, TextIO

def get_osfhandle(file: int) -> int: pass
def open_osfhandle(handle: int, flags: int) -> int: pass

########NEW FILE########
__FILENAME__ = operator
# Stubs for operator

# NOTE: These are incomplete!

from typing import Any

def add(a: Any, b: Any) -> Any: pass

########NEW FILE########
__FILENAME__ = path
# Stubs for os.path
# Ron Murawski <ron@horizonchess.com>

# based on http://docs.python.org/3.2/library/os.path.html

from typing import overload, List, Any, AnyStr, Tuple, BinaryIO, TextIO

# ----- os.path variables -----
supports_unicode_filenames = False
# aliases (also in os)
curdir = ''
pardir = ''
sep = ''
altsep = ''
extsep = ''
pathsep = ''
defpath = ''
devnull = ''

# ----- os.path function stubs -----
@overload
def abspath(path: str) -> str: pass
@overload
def abspath(path: bytes) -> bytes: pass
@overload
def basename(path: str) -> str: pass
@overload
def basename(path: bytes) -> bytes: pass
# NOTE: Empty List[bytes] results in '' (str) => fall back to Any return type.
def commonprefix(list: List[AnyStr]) -> Any: pass
@overload
def dirname(path: str) -> str: pass
@overload
def dirname(path: bytes) -> bytes: pass
@overload
def exists(path: str) -> bool: pass
@overload
def exists(path: bytes) -> bool: pass
@overload
def lexists(path: str) -> bool: pass
@overload
def lexists(path: bytes) -> bool: pass
@overload
def expanduser(path: str) -> str: pass
@overload
def expanduser(path: bytes) -> bytes: pass
@overload
def expandvars(path: str) -> str: pass
@overload
def expandvars(path: bytes) -> bytes: pass

# These return float if os.stat_float_times() == True
@overload
def getatime(path: str) -> Any: pass
@overload
def getatime(path: bytes) -> Any: pass
@overload
def getmtime(path: str) -> Any: pass
@overload
def getmtime(path: bytes) -> Any: pass
@overload
def getctime(path: str) -> Any: pass
@overload
def getctime(path: bytes) -> Any: pass

@overload
def getsize(path: str) -> int: pass
@overload
def getsize(path: bytes) -> int: pass
@overload
def isabs(path: str) -> bool: pass
@overload
def isabs(path: bytes) -> bool: pass
@overload
def isfile(path: str) -> bool: pass
@overload
def isfile(path: bytes) -> bool: pass
@overload
def isdir(path: str) -> bool: pass
@overload
def isdir(path: bytes) -> bool: pass
@overload
def islink(path: str) -> bool: pass
@overload
def islink(path: bytes) -> bool: pass
@overload
def ismount(path: str) -> bool: pass
@overload
def ismount(path: bytes) -> bool: pass
@overload
def join(path: str, *paths: str) -> str: pass
@overload
def join(path: bytes, *paths: bytes) -> bytes: pass
@overload
def normcase(path: str) -> str: pass
@overload
def normcase(path: bytes) -> bytes: pass
@overload
def normpath(path: str) -> str: pass
@overload
def normpath(path: bytes) -> bytes: pass
@overload
def realpath(path: str) -> str: pass
@overload
def realpath(path: bytes) -> bytes: pass
@overload
def relpath(path: str, start: str = None) -> str: pass
@overload
def relpath(path: bytes, start: bytes = None) -> bytes: pass
@overload
def samefile(path1: str, path2: str) -> bool: pass
@overload
def samefile(path1: bytes, path2: bytes) -> bool: pass
def sameopenfile(fp1: int, fp2: int) -> bool: pass
#def samestat(stat1: stat_result,
#             stat2: stat_result) -> bool: pass  # Unix only
@overload
def split(path: str) -> Tuple[str, str]: pass
@overload
def split(path: bytes) -> Tuple[bytes, bytes]: pass
@overload
def splitdrive(path: str) -> Tuple[str, str]: pass
@overload
def splitdrive(path: bytes) -> Tuple[bytes, bytes]: pass
@overload
def splitext(path: str) -> Tuple[str, str]: pass
@overload
def splitext(path: bytes) -> Tuple[bytes, bytes]: pass
#def splitunc(path: str) -> Tuple[str, str]: pass  # Windows only, deprecated

########NEW FILE########
__FILENAME__ = pickle
# Stubs for pickle

# NOTE: These are incomplete!

from typing import Any, IO

def dumps(obj: Any, protocol: int = None, *,
          fix_imports: bool = True) -> bytes: pass
def loads(p: bytes, *, fix_imports: bool = True,
          encoding: str = 'ASCII', errors: str = 'strict') -> Any: pass
def load(file: IO[bytes], *, fix_imports: bool = True, encoding: str = 'ASCII',
         errors: str = 'strict') -> Any: pass

########NEW FILE########
__FILENAME__ = platform
# Stubs for platform

# NOTE: These are incomplete!

from typing import Tuple

def mac_ver(release: str = '',
            version_info: Tuple[str, str, str] = ('', '', ''),
            machine: str = '') -> Tuple[str, Tuple[str, str, str], str]: pass

########NEW FILE########
__FILENAME__ = posix
# Stubs for posix

# NOTE: These are incomplete!

import typing
from os import stat_result


########NEW FILE########
__FILENAME__ = posixpath
# Stubs for os.path
# Ron Murawski <ron@horizonchess.com>

# based on http://docs.python.org/3.2/library/os.path.html

from typing import Any, List, Tuple, IO, overload

# ----- os.path variables -----
supports_unicode_filenames = False

# ----- os.path function stubs -----
def abspath(path: str) -> str: pass
def basename(path) -> str: pass
def commonprefix(list: List[str]) -> str: pass
def dirname(path: str) -> str: pass
def exists(path: str) -> bool: pass
def lexists(path: str) -> bool: pass
def expanduser(path: str) -> str: pass
def expandvars(path: str) -> str: pass
def getatime(path: str) -> int:
    pass # return float if os.stat_float_times() returns True
def getmtime(path: str) -> int:
    pass # return float if os.stat_float_times() returns True
def getctime(path: str) -> int:
    pass # return float if os.stat_float_times() returns True
def getsize(path: str) -> int: pass
def isabs(path: str) -> bool: pass
def isfile(path: str) -> bool: pass
def isdir(path: str) -> bool: pass
def islink(path: str) -> bool: pass
def ismount(path: str) -> bool: pass
def join(path: str, *paths: str) -> str: pass
def normcase(path: str) -> str: pass
def normpath(path: str) -> str: pass
def realpath(path: str) -> str: pass
def relpath(path: str, start: str = None) -> str: pass
def samefile(path1: str, path2: str) -> bool: pass

def sameopenfile(fp1: IO[Any], fp2: IO[Any]) -> bool: pass

#def samestat(stat1: stat_result, stat2: stat_result) -> bool:
#    pass  # Unix only
def split(path: str) -> Tuple[str, str]: pass
def splitdrive(path: str) -> Tuple[str, str]: pass
def splitext(path: str) -> Tuple[str, str]: pass
#def splitunc(path: str) -> Tuple[str, str] : pass  # Windows only, deprecated

########NEW FILE########
__FILENAME__ = pprint
# Stubs for pprint

# Based on http://docs.python.org/3.2/library/pprint.html

from typing import Any, Dict, Tuple, TextIO

def pformat(o: object, indent: int = 1, width: int = 80,
            depth: int = None) -> str: pass
def pprint(o: object, stream: TextIO = None, indent: int = 1, width: int = 80,
           depth: int = None) -> None: pass
def isreadable(o: object) -> bool: pass
def isrecursive(o: object) -> bool: pass
def saferepr(o: object) -> str: pass

class PrettyPrinter:
    def __init__(self, indent: int = 1, width: int = 80, depth: int = None,
                 stream: TextIO = None) -> None: pass
    def pformat(self, o: object) -> str: pass
    def pprint(self, o: object) -> None: pass
    def isreadable(self, o: object) -> bool: pass
    def isrecursive(self, o: object) -> bool: pass
    def format(self, o: object, context: Dict[int, Any], maxlevels: int,
               level: int) -> Tuple[str, bool, bool]: pass

########NEW FILE########
__FILENAME__ = pwd
# Stubs for pwd

# NOTE: These are incomplete!

import typing

class struct_passwd:
    # TODO use namedtuple
    pw_name = ''
    pw_passwd = ''
    pw_uid = 0
    pw_gid = 0
    pw_gecos = ''
    pw_dir = ''
    pw_shell = ''

def getpwuid(uid: int) -> struct_passwd: pass
def getpwnam(name: str) -> struct_passwd: pass

########NEW FILE########
__FILENAME__ = random
# Stubs for random
# Ron Murawski <ron@horizonchess.com>
# Updated by Jukka Lehtosalo

# based on http://docs.python.org/3.2/library/random.html

# ----- random classes -----

import _random
from typing import (
    Any, overload, typevar, Sequence, List, Function, AbstractSet
)

t = typevar('t')

class Random(_random.Random):
    def __init__(self, x: Any = None) -> None: pass
    def seed(self, a: Any = None, version: int = 2) -> None: pass
    def getstate(self) -> tuple: pass
    def setstate(self, state: tuple) -> None: pass
    def getrandbits(self, k: int) -> int: pass
    
    @overload
    def randrange(self, stop: int) -> int: pass
    @overload
    def randrange(self, start: int, stop: int, step: int = 1) -> int: pass
    
    def randint(self, a: int, b: int) -> int: pass
    def choice(self, seq: Sequence[t]) -> t: pass
    
    @overload
    def shuffle(self, x: List[Any]) -> None: pass
    @overload
    def shuffle(self, x: List[Any], random: Function[[], float]) -> None: pass
    
    @overload
    def sample(self, population: Sequence[t], k: int) -> List[t]: pass
    @overload
    def sample(self, population: AbstractSet[t], k: int) -> List[t]: pass
    
    def random(self) -> float: pass
    def uniform(self, a: float, b: float) -> float: pass
    def triangular(self, low: float = 0.0, high: float = 1.0,
                     mode: float = None) -> float: pass
    def betavariate(self, alpha: float, beta: float) -> float: pass
    def expovariate(self, lambd: float) -> float: pass
    def gammavariate(self, alpha: float, beta: float) -> float: pass
    def gauss(self, mu: float, sigma: float) -> float: pass
    def lognormvariate(self, mu: float, sigma: float) -> float: pass
    def normalvariate(self, mu: float, sigma: float) -> float: pass
    def vonmisesvariate(self, mu: float, kappa: float) -> float: pass
    def paretovariate(self, alpha: float) -> float: pass
    def weibullvariate(self, alpha: float, beta: float) -> float: pass

# SystemRandom is not implemented for all OS's; good on Windows & Linux
class SystemRandom:
    def __init__(self, randseed: object = None) -> None: pass
    def random(self) -> float: pass
    def getrandbits(self, k: int) -> int: pass
    def seed(self, arg: object) -> None: pass

# ----- random function stubs -----
def seed(a: Any = None, version: int = 2) -> None: pass
def getstate() -> object: pass
def setstate(state: object) -> None: pass
def getrandbits(k: int) -> int: pass

@overload
def randrange(stop: int) -> int: pass
@overload
def randrange(start: int, stop: int, step: int = 1) -> int: pass

def randint(a: int, b: int) -> int: pass
def choice(seq: Sequence[t]) -> t: pass

@overload
def shuffle(x: List[Any]) -> None: pass
@overload
def shuffle(x: List[Any], random: Function[[], float]) -> None: pass

@overload
def sample(population: Sequence[t], k: int) -> List[t]: pass
@overload
def sample(population: AbstractSet[t], k: int) -> List[t]: pass

def random() -> float: pass
def uniform(a: float, b: float) -> float: pass
def triangular(low: float = 0.0, high: float = 1.0,
               mode: float = None) -> float: pass
def betavariate(alpha: float, beta: float) -> float: pass
def expovariate(lambd: float) -> float: pass
def gammavariate(alpha: float, beta: float) -> float: pass
def gauss(mu: float, sigma: float) -> float: pass
def lognormvariate(mu: float, sigma: float) -> float: pass
def normalvariate(mu: float, sigma: float) -> float: pass
def vonmisesvariate(mu: float, kappa: float) -> float: pass
def paretovariate(alpha: float) -> float: pass
def weibullvariate(alpha: float, beta: float) -> float: pass

########NEW FILE########
__FILENAME__ = re
# Stubs for re
# Ron Murawski <ron@horizonchess.com>
# 'bytes' support added by Jukka Lehtosalo

# based on: http://docs.python.org/3.2/library/re.html
# and http://hg.python.org/cpython/file/618ea5612e83/Lib/re.py

from typing import (
    Undefined, List, Iterator, overload, Function, Tuple, Sequence, Dict,
    Generic, AnyStr, Match, Pattern
)

# ----- re variables and constants -----
A = 0
ASCII = 0
DEBUG = 0
I = 0
IGNORECASE = 0
L = 0
LOCALE = 0
M = 0
MULTILINE = 0
S = 0
DOTALL = 0
X = 0
VERBOSE = 0
U = 0
UNICODE = 0

class error(Exception): pass

def compile(pattern: AnyStr, flags: int = 0) -> Pattern[AnyStr]: pass
def search(pattern: AnyStr, string: AnyStr,
           flags: int = 0) -> Match[AnyStr]: pass
def match(pattern: AnyStr, string: AnyStr,
          flags: int = 0) -> Match[AnyStr]: pass
def split(pattern: AnyStr, string: AnyStr, maxsplit: int = 0,
          flags: int = 0) -> List[AnyStr]: pass
def findall(pattern: AnyStr, string: AnyStr,
            flags: int = 0) -> List[AnyStr]: pass

# Return an iterator yielding match objects over all non-overlapping matches 
# for the RE pattern in string. The string is scanned left-to-right, and 
# matches are returned in the order found. Empty matches are included in the 
# result unless they touch the beginning of another match.
def finditer(pattern: AnyStr, string: AnyStr,
             flags: int = 0) -> Iterator[Match[AnyStr]]: pass

@overload
def sub(pattern: AnyStr, repl: AnyStr, string: AnyStr, count: int = 0,
        flags: int = 0) -> AnyStr: pass
@overload
def sub(pattern: AnyStr, repl: Function[[Match[AnyStr]], AnyStr],
        string: AnyStr, count: int = 0, flags: int = 0) -> AnyStr: pass

@overload
def subn(pattern: AnyStr, repl: AnyStr, string: AnyStr, count: int = 0,
         flags: int = 0) -> Tuple[AnyStr, int]: pass
@overload
def subn(pattern: AnyStr, repl: Function[[Match[AnyStr]], AnyStr],
         string: AnyStr, count: int = 0,
         flags: int = 0) -> Tuple[AnyStr, int]: pass

def escape(string: AnyStr) -> AnyStr: pass

def purge() -> None: pass

########NEW FILE########
__FILENAME__ = resource
# Stubs for resource

# NOTE: These are incomplete!

from typing import Tuple

RLIMIT_CORE = 0

def getrlimit(resource: int) -> Tuple[int, int]: pass
def setrlimit(resource: int, limits: Tuple[int, int]) -> None: pass

# NOTE: This is an alias of OSError in Python 3.3.
class error(Exception): pass

########NEW FILE########
__FILENAME__ = select
# Stubs for select

# NOTE: These are incomplete!

from typing import Any, Tuple, List, Sequence

class error(Exception): pass

POLLIN = 0
POLLPRI = 0
POLLOUT = 0
POLLERR = 0
POLLHUP = 0
POLLNVAL = 0

class poll:
    def __init__(self) -> None: pass
    def register(self, fd: Any,
                 eventmask: int = POLLIN|POLLPRI|POLLOUT) -> None: pass
    def modify(self, fd: Any, eventmask: int) -> None: pass
    def unregister(self, fd: Any) -> None: pass
    def poll(self, timeout: int = None) -> List[Tuple[int, int]]: pass

def select(rlist: Sequence, wlist: Sequence, xlist: Sequence,
           timeout: float = None) -> Tuple[List[int],
                                           List[int],
                                           List[int]]: pass

########NEW FILE########
__FILENAME__ = shlex
# Stubs for shlex

# Based on http://docs.python.org/3.2/library/shlex.html

from typing import List, Undefined, Tuple, Any, TextIO

def split(s: str, comments: bool = False,
          posix: bool = True) -> List[str]: pass

class shlex:
    commenters = ''
    wordchars = ''
    whitespace = ''
    escape = ''
    quotes = ''
    escapedquotes = ''
    whitespace_split = ''
    infile = ''
    instream = Undefined(TextIO)
    source = ''
    debug = 0
    lineno = 0
    token = ''
    eof = ''
    
    def __init__(self, instream=None, infile=None,
                 posix: bool = False) -> None: pass
    def get_token(self) -> str: pass
    def push_token(self, tok: str) -> None: pass
    def read_token(self) -> str: pass
    def sourcehook(self, filename: str) -> Tuple[str, TextIO]: pass
    # TODO argument types
    def push_source(self, newstream: Any, newfile: Any = None) -> None: pass
    def pop_source(self) -> None: pass
    def error_leader(self, infile: str = None,
                     lineno: int = None) -> None: pass

########NEW FILE########
__FILENAME__ = shutil
# Stubs for shutil

# Based on http://docs.python.org/3.2/library/shutil.html

# 'bytes' paths are not properly supported: they don't work with all functions,
# sometimes they only work partially (broken exception messages), and the test
# cases don't use them.

from typing import (
    overload, List, Iterable, Function, Any, Tuple, Sequence, IO, AnyStr
)

def copyfileobj(fsrc: IO[AnyStr], fdst: IO[AnyStr],
                length: int = None) -> None: pass

def copyfile(src: str, dst: str) -> None: pass
def copymode(src: str, dst: str) -> None: pass
def copystat(src: str, dst: str) -> None: pass
def copy(src: str, dst: str) -> None: pass
def copy2(src: str, dst: str) -> None: pass
def ignore_patterns(*patterns: str) -> Function[[str, List[str]],
                                                Iterable[str]]: pass
def copytree(src: str, dst: str, symlinks: bool = False,
             ignore: Function[[str, List[str]], Iterable[str]] = None,
             copy_function: Function[[str, str], None] = copy2,
             ignore_dangling_symlinks: bool = False) -> None: pass
def rmtree(path: str, ignore_errors: bool = False,
           onerror: Function[[Any, str, Any], None] = None) -> None: pass
def move(src: str, dst: str) -> None: pass

class Error(Exception): pass

def make_archive(base_name: str, format: str, root_dir: str = None,
                 base_dir: str = None, verbose: bool = False,
                 dry_run: bool = False, owner: str = None, group: str = None,
                 logger: Any = None) -> str: pass
def get_archive_formats() -> List[Tuple[str, str]]: pass
def register_archive_format(name: str, function: Any,
                            extra_args: Sequence[Tuple[str, Any]] = None,
                            description: str = None) -> None: pass
def unregister_archive_format(name: str) -> None: pass
def unpack_archive(filename: str, extract_dir: str = None,
                   format: str = None) -> None: pass
def register_unpack_format(name: str, extensions: List[str], function: Any,
                           extra_args: Sequence[Tuple[str, Any]] = None,
                           description: str = None) -> None: pass
def unregister_unpack_format(name: str) -> None: pass
def get_unpack_formats() -> List[Tuple[str, List[str], str]]: pass

########NEW FILE########
__FILENAME__ = signal
# Stubs for signal

# Based on http://docs.python.org/3.2/library/signal.html

from typing import Any, overload, Function

SIG_DFL = 0
SIG_IGN = 0

# TODO more SIG* constants (these should be platform specific?)
SIGHUP = 0
SIGINT = 0
SIGQUIT = 0
SIGABRT = 0
SIGKILL = 0
SIGALRM = 0
SIGTERM = 0

SIGUSR1 = 0
SIGUSR2 = 0
SIGCONT = 0
SIGSTOP = 0

SIGPOLL = 0
SIGVTALRM = 0

CTRL_C_EVENT = 0 # Windows
CTRL_BREAK_EVENT = 0 # Windows

NSIG = 0
ITIMER_REAL = 0
ITIMER_VIRTUAL = 0
ITIMER_PROF = 0

class ItimerError(IOError): pass

def alarm(time: int) -> int: pass # Unix
def getsignal(signalnum: int) -> Any: pass
def pause() -> None: pass # Unix
#def setitimer(which: int, seconds: float,
#              internval: float = None) -> Tuple[float, float]: pass # Unix
#def getitimer(int which): pass # Unix
def set_wakeup_fd(fd: int) -> None: pass
def siginterrupt(signalnum: int, flag: bool) -> None: pass

@overload
def signal(signalnum: int, handler: int) -> Any: pass
@overload
def signal(signalnum: int,
           handler: Function[[int, Any], None]) -> Any:
    pass # TODO frame object type

########NEW FILE########
__FILENAME__ = socket
# Stubs for socket
# Ron Murawski <ron@horizonchess.com>

# based on: http://docs.python.org/3.2/library/socket.html
# see: http://hg.python.org/cpython/file/3d0686d90f55/Lib/socket.py
# see: http://nullege.com/codes/search/socket

from typing import Undefined, Any, Tuple, overload, List

# ----- variables and constants -----

AF_UNIX = 0
AF_INET = 0
AF_INET6 = 0
SOCK_STREAM = 0
SOCK_DGRAM = 0
SOCK_RAW = 0
SOCK_RDM = 0
SOCK_SEQPACKET = 0
SOCK_CLOEXEC = 0
SOCK_NONBLOCK = 0
SOMAXCONN = 0
has_ipv6 = False
_GLOBAL_DEFAULT_TIMEOUT = 0.0
SocketType = Undefined(Any)
SocketIO = Undefined(Any)


# the following constants are included with Python 3.2.3 (Ubuntu)
# some of the constants may be Linux-only
# all Windows/Mac-specific constants are absent
AF_APPLETALK = 0
AF_ASH = 0
AF_ATMPVC = 0
AF_ATMSVC = 0
AF_AX25 = 0
AF_BLUETOOTH = 0
AF_BRIDGE = 0
AF_DECnet = 0
AF_ECONET = 0
AF_IPX = 0
AF_IRDA = 0
AF_KEY = 0
AF_LLC = 0
AF_NETBEUI = 0
AF_NETLINK = 0
AF_NETROM = 0
AF_PACKET = 0
AF_PPPOX = 0
AF_ROSE = 0
AF_ROUTE = 0
AF_SECURITY = 0
AF_SNA = 0
AF_TIPC = 0
AF_UNSPEC = 0
AF_WANPIPE = 0
AF_X25 = 0
AI_ADDRCONFIG = 0
AI_ALL = 0
AI_CANONNAME = 0
AI_NUMERICHOST = 0
AI_NUMERICSERV = 0
AI_PASSIVE = 0
AI_V4MAPPED = 0
BDADDR_ANY = 0
BDADDR_LOCAL = 0
BTPROTO_HCI = 0
BTPROTO_L2CAP = 0
BTPROTO_RFCOMM = 0
BTPROTO_SCO = 0
CAPI = 0
EAGAIN = 0
EAI_ADDRFAMILY = 0
EAI_AGAIN = 0
EAI_BADFLAGS = 0
EAI_FAIL = 0
EAI_FAMILY = 0
EAI_MEMORY = 0
EAI_NODATA = 0
EAI_NONAME = 0
EAI_OVERFLOW = 0
EAI_SERVICE = 0
EAI_SOCKTYPE = 0
EAI_SYSTEM = 0
EBADF = 0
EINTR = 0
EWOULDBLOCK = 0
HCI_DATA_DIR = 0
HCI_FILTER = 0
HCI_TIME_STAMP = 0
INADDR_ALLHOSTS_GROUP = 0
INADDR_ANY = 0
INADDR_BROADCAST = 0
INADDR_LOOPBACK = 0
INADDR_MAX_LOCAL_GROUP = 0
INADDR_NONE = 0
INADDR_UNSPEC_GROUP = 0
IPPORT_RESERVED = 0
IPPORT_USERRESERVED = 0
IPPROTO_AH = 0
IPPROTO_DSTOPTS = 0
IPPROTO_EGP = 0
IPPROTO_ESP = 0
IPPROTO_FRAGMENT = 0
IPPROTO_GRE = 0
IPPROTO_HOPOPTS = 0
IPPROTO_ICMP = 0
IPPROTO_ICMPV6 = 0
IPPROTO_IDP = 0
IPPROTO_IGMP = 0
IPPROTO_IP = 0
IPPROTO_IPIP = 0
IPPROTO_IPV6 = 0
IPPROTO_NONE = 0
IPPROTO_PIM = 0
IPPROTO_PUP = 0
IPPROTO_RAW = 0
IPPROTO_ROUTING = 0
IPPROTO_RSVP = 0
IPPROTO_TCP = 0
IPPROTO_TP = 0
IPPROTO_UDP = 0
IPV6_CHECKSUM = 0
IPV6_DSTOPTS = 0
IPV6_HOPLIMIT = 0
IPV6_HOPOPTS = 0
IPV6_JOIN_GROUP = 0
IPV6_LEAVE_GROUP = 0
IPV6_MULTICAST_HOPS = 0
IPV6_MULTICAST_IF = 0
IPV6_MULTICAST_LOOP = 0
IPV6_NEXTHOP = 0
IPV6_PKTINFO = 0
IPV6_RECVDSTOPTS = 0
IPV6_RECVHOPLIMIT = 0
IPV6_RECVHOPOPTS = 0
IPV6_RECVPKTINFO = 0
IPV6_RECVRTHDR = 0
IPV6_RECVTCLASS = 0
IPV6_RTHDR = 0
IPV6_RTHDRDSTOPTS = 0
IPV6_RTHDR_TYPE_0 = 0
IPV6_TCLASS = 0
IPV6_UNICAST_HOPS = 0
IPV6_V6ONLY = 0
IP_ADD_MEMBERSHIP = 0
IP_DEFAULT_MULTICAST_LOOP = 0
IP_DEFAULT_MULTICAST_TTL = 0
IP_DROP_MEMBERSHIP = 0
IP_HDRINCL = 0
IP_MAX_MEMBERSHIPS = 0
IP_MULTICAST_IF = 0
IP_MULTICAST_LOOP = 0
IP_MULTICAST_TTL = 0
IP_OPTIONS = 0
IP_RECVOPTS = 0
IP_RECVRETOPTS = 0
IP_RETOPTS = 0
IP_TOS = 0
IP_TTL = 0
MSG_CTRUNC = 0
MSG_DONTROUTE = 0
MSG_DONTWAIT = 0
MSG_EOR = 0
MSG_OOB = 0
MSG_PEEK = 0
MSG_TRUNC = 0
MSG_WAITALL = 0
NETLINK_DNRTMSG = 0
NETLINK_FIREWALL = 0
NETLINK_IP6_FW = 0
NETLINK_NFLOG = 0
NETLINK_ROUTE = 0
NETLINK_USERSOCK = 0
NETLINK_XFRM = 0
NI_DGRAM = 0
NI_MAXHOST = 0
NI_MAXSERV = 0
NI_NAMEREQD = 0
NI_NOFQDN = 0
NI_NUMERICHOST = 0
NI_NUMERICSERV = 0
PACKET_BROADCAST = 0
PACKET_FASTROUTE = 0
PACKET_HOST = 0
PACKET_LOOPBACK = 0
PACKET_MULTICAST = 0
PACKET_OTHERHOST = 0
PACKET_OUTGOING = 0
PF_PACKET = 0
SHUT_RD = 0
SHUT_RDWR = 0
SHUT_WR = 0
SOL_HCI = 0
SOL_IP = 0
SOL_SOCKET = 0
SOL_TCP = 0
SOL_TIPC = 0
SOL_UDP = 0
SO_ACCEPTCONN = 0
SO_BROADCAST = 0
SO_DEBUG = 0
SO_DONTROUTE = 0
SO_ERROR = 0
SO_KEEPALIVE = 0
SO_LINGER = 0
SO_OOBINLINE = 0
SO_RCVBUF = 0
SO_RCVLOWAT = 0
SO_RCVTIMEO = 0
SO_REUSEADDR = 0
SO_SNDBUF = 0
SO_SNDLOWAT = 0
SO_SNDTIMEO = 0
SO_TYPE = 0
TCP_CORK = 0
TCP_DEFER_ACCEPT = 0
TCP_INFO = 0
TCP_KEEPCNT = 0
TCP_KEEPIDLE = 0
TCP_KEEPINTVL = 0
TCP_LINGER2 = 0
TCP_MAXSEG = 0
TCP_NODELAY = 0
TCP_QUICKACK = 0
TCP_SYNCNT = 0
TCP_WINDOW_CLAMP = 0
TIPC_ADDR_ID = 0
TIPC_ADDR_NAME = 0
TIPC_ADDR_NAMESEQ = 0
TIPC_CFG_SRV = 0
TIPC_CLUSTER_SCOPE = 0
TIPC_CONN_TIMEOUT = 0
TIPC_CRITICAL_IMPORTANCE = 0
TIPC_DEST_DROPPABLE = 0
TIPC_HIGH_IMPORTANCE = 0
TIPC_IMPORTANCE = 0
TIPC_LOW_IMPORTANCE = 0
TIPC_MEDIUM_IMPORTANCE = 0
TIPC_NODE_SCOPE = 0
TIPC_PUBLISHED = 0
TIPC_SRC_DROPPABLE = 0
TIPC_SUBSCR_TIMEOUT = 0
TIPC_SUB_CANCEL = 0
TIPC_SUB_PORTS = 0
TIPC_SUB_SERVICE = 0
TIPC_TOP_SRV = 0
TIPC_WAIT_FOREVER = 0
TIPC_WITHDRAWN = 0
TIPC_ZONE_SCOPE = 0


# ----- exceptions -----
class error(IOError):
    pass

class herror(error):
    def __init__(self, herror: int, string: str) -> None: pass

class gaierror(error):
    def __init__(self, error: int, string: str) -> None: pass

class timeout(error):
    pass


# Addresses can be either tuples of varying lengths (AF_INET, AF_INET6,
# AF_NETLINK, AF_TIPC) or strings (AF_UNIX).

# TODO AF_PACKET and AF_BLUETOOTH address objects


# ----- classes -----
class socket:
    family = 0
    type = 0
    proto = 0
    
    def __init__(self, family: int = AF_INET, type: int = SOCK_STREAM,
                 proto: int = 0, fileno: int = None) -> None: pass
    
    # --- methods ---
    # second tuple item is an address
    def accept(self) -> Tuple['socket', Any]: pass
    
    @overload
    def bind(self, address: tuple) -> None: pass
    @overload
    def bind(self, address: str) -> None: pass
    
    def close(self) -> None: pass
    
    @overload
    def connect(self, address: tuple) -> None: pass
    @overload
    def connect(self, address: str) -> None: pass
    
    @overload
    def connect_ex(self, address: tuple) -> int: pass
    @overload
    def connect_ex(self, address: str) -> int: pass
    
    def detach(self) -> int: pass
    def fileno(self) -> int: pass
    
    # return value is an address
    def getpeername(self) -> Any: pass
    def getsockname(self) -> Any: pass
    
    @overload
    def getsockopt(self, level: int, optname: str) -> bytes: pass
    @overload
    def getsockopt(self, level: int, optname: str, buflen: int) -> bytes: pass
    
    def gettimeout(self) -> float: pass
    def ioctl(self, control: object,
              option: Tuple[int, int, int]) -> None: pass
    def listen(self, backlog: int) -> None: pass
    # TODO the return value may be BinaryIO or TextIO, depending on mode
    def makefile(self, mode: str = 'r', buffering: int = None, 
                 encoding: str = None, errors: str = None,
                 newline: str = None) -> Any: 
        pass
    def recv(self, bufsize: int, flags: int = 0) -> bytes: pass
    
    # return type is an address
    def recvfrom(self, bufsize: int, flags: int = 0) -> Any: pass
    def recvfrom_into(self, buffer: bytes, nbytes: int,
                      flags: int = 0) -> Any: pass
    def recv_into(self, buffer: bytes, nbytes: int,
                  flags: int = 0) -> Any: pass
    def send(self, data: bytes, flags=0) -> int: pass
    def sendall(self, data: bytes, flags=0) -> Any:
        pass # return type: None on success
    
    @overload
    def sendto(self, data: bytes, address: tuple, flags: int = 0) -> int: pass
    @overload
    def sendto(self, data: bytes, address: str, flags: int = 0) -> int: pass
    
    def setblocking(self, flag: bool) -> None: pass
    # TODO None valid for the value argument
    def settimeout(self, value: float) -> None: pass
    
    @overload
    def setsockopt(self, level: int, optname: str, value: int) -> None: pass
    @overload
    def setsockopt(self, level: int, optname: str, value: bytes) -> None: pass
    
    def shutdown(self, how: int) -> None: pass
    

# ----- functions -----
def create_connection(address: Tuple[str, int], 
                      timeout: float = _GLOBAL_DEFAULT_TIMEOUT,
                      source_address: Tuple[str, int] = None) -> socket: pass

# the 5th tuple item is an address
def getaddrinfo(
        host: str, port: int, family: int = 0, type: int = 0, proto: int = 0,
        flags: int = 0) -> List[Tuple[int, int, int, str, tuple]]:
    pass

def getfqdn(name: str = '') -> str: pass
def gethostbyname(hostname: str) -> str: pass
def gethostbyname_ex(hostname: str) -> Tuple[str, List[str], List[str]]: pass
def gethostname() -> str: pass
def gethostbyaddr(ip_address: str) -> Tuple[str, List[str], List[str]]: pass
def getnameinfo(sockaddr: tuple, flags: int) -> Tuple[str, int]: pass
def getprotobyname(protocolname: str) -> int: pass
def getservbyname(servicename: str, protocolname: str = None) -> int: pass
def getservbyport(port: int, protocolname: str = None) -> str: pass
def socketpair(family: int = AF_INET,
               type: int = SOCK_STREAM,
               proto: int = 0) -> Tuple[socket, socket]: pass
def fromfd(fd: int, family: int, type: int, proto: int = 0) -> socket: pass
def ntohl(x: int) -> int: pass  # param & ret val are 32-bit ints
def ntohs(x: int) -> int: pass  # param & ret val are 16-bit ints
def htonl(x: int) -> int: pass  # param & ret val are 32-bit ints
def htons(x: int) -> int: pass  # param & ret val are 16-bit ints
def inet_aton(ip_string: str) -> bytes: pass  # ret val 4 bytes in length
def inet_ntoa(packed_ip: bytes) -> str: pass
def inet_pton(address_family: int, ip_string: str) -> bytes: pass
def inet_ntop(address_family: int, packed_ip: bytes) -> str: pass
# TODO the timeout may be None
def getdefaulttimeout() -> float: pass
def setdefaulttimeout(timeout: float) -> None: pass

########NEW FILE########
__FILENAME__ = stat
# Stubs for stat

# Based on http://docs.python.org/3.2/library/stat.html

import typing

def S_ISDIR(mode: int) -> bool: pass
def S_ISCHR(mode: int) -> bool: pass
def S_ISBLK(mode: int) -> bool: pass
def S_ISREG(mode: int) -> bool: pass
def S_ISFIFO(mode: int) -> bool: pass
def S_ISLNK(mode: int) -> bool: pass
def S_ISSOCK(mode: int) -> bool: pass

def S_IMODE(mode: int) -> int: pass
def S_IFMT(mode) -> int: pass

ST_MODE = 0
ST_INO = 0
ST_DEV = 0
ST_NLINK = 0
ST_UID = 0
ST_GID = 0
ST_SIZE = 0
ST_ATIME = 0
ST_MTIME = 0
ST_CTIME = 0

S_IFSOCK = 0
S_IFLNK = 0
S_IFREG = 0
S_IFBLK = 0
S_IFDIR = 0
S_IFCHR = 0
S_IFIFO = 0
S_ISUID = 0
S_ISGID = 0
S_ISVTX = 0

S_IRWXU = 0
S_IRUSR = 0
S_IWUSR = 0
S_IXUSR = 0

S_IRWXG = 0
S_IRGRP = 0
S_IWGRP = 0
S_IXGRP = 0

S_IRWXO = 0
S_IROTH = 0
S_IWOTH = 0
S_IXOTH = 0

S_ENFMT = 0
S_IREAD = 0
S_IWRITE = 0
S_IEXEC = 0

UF_NODUMP = 0
UF_IMMUTABLE = 0
UF_APPEND = 0
UF_OPAQUE = 0
UF_NOUNLINK = 0
#int UF_COMPRESSED # OS X 10.6+ only
#int UF_HIDDEN     # OX X 10.5+ only
SF_ARCHIVED = 0
SF_IMMUTABLE = 0
SF_APPEND = 0
SF_NOUNLINK = 0
SF_SNAPSHOT = 0

########NEW FILE########
__FILENAME__ = string
# Stubs for string

# Based on http://docs.python.org/3.2/library/string.html

from typing import Mapping

ascii_letters = ''
ascii_lowercase = ''
ascii_uppercase = ''
digits = ''
hexdigits = ''
octdigits = ''
punctuation = ''
printable = ''
whitespace = ''

def capwords(s: str, sep: str = None) -> str: pass

class Template:
    template = ''
    
    def __init__(self, template: str) -> None: pass
    def substitute(self, mapping: Mapping[str, str], **kwds: str) -> str: pass
    def safe_substitute(self, mapping: Mapping[str, str],
                        **kwds: str) -> str: pass

# TODO Formatter

########NEW FILE########
__FILENAME__ = struct
# Stubs for struct

# Based on http://docs.python.org/3.2/library/struct.html

from typing import overload, Any, Undefined

class error(Exception): pass

@overload
def pack(fmt: str, *v: Any) -> bytes: pass
@overload
def pack(fmt: bytes, *v: Any) -> bytes: pass

@overload
def pack_into(fmt: str, buffer: Any, offset: int, *v: Any) -> None: pass
# TODO buffer type
@overload
def pack_into(fmt: bytes, buffer: Any, offset: int, *v: Any) -> None: pass

# TODO return type should be tuple
# TODO buffer type
@overload
def unpack(fmt: str, buffer: Any) -> Any: pass
@overload
def unpack(fmt: bytes, buffer: Any) -> Any: pass

@overload
def unpack_from(fmt: str, buffer: Any) -> Any: pass
@overload
def unpack_from(fmt: bytes, buffer: Any, offset: int = 0) -> Any: pass

@overload
def calcsize(fmt: str) -> int: pass
@overload
def calcsize(fmt: bytes) -> int: pass

class Struct:
    format = b''
    size = 0
    
    @overload
    def __init__(self, format: str) -> None: pass
    @overload
    def __init__(self, format: bytes) -> None: pass

    def pack(self, *v: Any) -> bytes: pass
    # TODO buffer type
    def pack_into(self, buffer: Any, offset: int, *v: Any) -> None: pass
    # TOTO return type should be tuple
    # TODO buffer type
    def unpack(self, buffer: Any) -> Any: pass
    def unpack_from(self, buffer: Any, offset: int = 0) -> Any: pass

########NEW FILE########
__FILENAME__ = subprocess
# Stubs for subprocess

# Based on http://docs.python.org/3.2/library/subprocess.html

from typing import Sequence, Any, Mapping, Undefined, Function, Tuple, IO

# TODO force keyword arguments
# TODO more keyword arguments
def call(args: Sequence[str], *, stdin: Any = None, stdout: Any = None,
         stderr: Any = None, shell: bool = False,
         env: Mapping[str, str] = None) -> int: pass
def check_call(args: Sequence[str], *, stdin: Any = None, stdout: Any = None,
               stderr: Any = None, shell: bool = False,
               env: Mapping[str, str] = None) -> int: pass
# Return str/bytes
def check_output(args: Sequence[str], *, stdin: Any = None, stderr: Any = None,
                 shell: bool = False, universal_newlines: bool = False,
                 env: Mapping[str, str] = None) -> Any: pass

# TODO types
PIPE = Undefined(Any)
STDOUT = Undefined(Any)

class CalledProcessError(Exception):
    returncode = 0
    cmd = ''
    output = b'' # May be None

class Popen:
    stdin = Undefined(IO[Any])
    stdout = Undefined(IO[Any])
    stderr = Undefined(IO[Any])
    pid = 0
    returncode = 0
    
    def __init__(self,
                  args: Sequence[str],
                  bufsize: int = 0,
                  executable: str = None,
                  stdin: Any = None,
                  stdout: Any = None,
                  stderr: Any = None,
                  preexec_fn: Function[[], Any] = None,
                  close_fds: bool = True,
                  shell: bool = False,
                  cwd: str = None,
                  env: Mapping[str, str] = None,
                  universal_newlines: bool = False,
                  startupinfo: Any = None,
                  creationflags: int = 0,
                  restore_signals: bool = True,
                  start_new_session: bool = False,
                  pass_fds: Any = ()) -> None: pass
    
    def poll(self) -> int: pass
    def wait(self) -> int: pass
    # Return str/bytes
    def communicate(self, input=None) -> Tuple[Any, Any]: pass
    def send_signal(self, signal: int) -> None: pass
    def terminatate(self) -> None: pass
    def kill(self) -> None: pass
    def __enter__(self) -> 'Popen': pass
    def __exit__(self, type, value, traceback) -> bool: pass

def getstatusoutput(cmd: str) -> Tuple[int, str]: pass
def getoutput(cmd: str) -> str: pass

# Windows-only: STARTUPINFO etc.

########NEW FILE########
__FILENAME__ = sys
# Stubs for sys
# Ron Murawski <ron@horizonchess.com>

# based on http://docs.python.org/3.2/library/sys.html

from typing import (
    Undefined, List, Sequence, Any, Dict, Tuple, TextIO, overload, Traceback
)

# ----- sys variables -----
abiflags = ''
argv = Undefined(List[str])
byteorder = ''
builtin_module_names = Undefined(Sequence[str]) # actually a tuple of strings
copyright = ''
#dllhandle = 0  # Windows only
dont_write_bytecode = False
__displayhook__ = Undefined(Any) # contains the original value of displayhook
__excepthook__ = Undefined(Any)  # contains the original value of excepthook
exec_prefix = ''
executable = ''
float_repr_style = ''
hexversion = 0  # this is a 32-bit int
last_type = Undefined(Any)
last_value = Undefined(Any)
last_traceback = Undefined(Any)
maxsize = 0
maxunicode = 0
meta_path = Undefined(List[Any])
modules = Undefined(Dict[str, Any])
path = Undefined(List[str])
path_hooks = Undefined(List[Any]) # TODO precise type; function, path to finder
path_importer_cache = Undefined(Dict[str, Any]) # TODO precise type
platform = ''
prefix = ''
ps1 = ''
ps2 = ''
stdin = Undefined(TextIO)
stdout = Undefined(TextIO)
stderr = Undefined(TextIO)
__stdin__ = Undefined(TextIO)
__stdout__ = Undefined(TextIO)
__stderr__ = Undefined(TextIO)
# deprecated and removed in Python 3.3:
subversion = Undefined(Tuple[str, str, str])
tracebacklimit = 0
version = ''
api_version = 0 
warnoptions = Undefined(Any)
#  Each entry is a tuple of the form (action, message, category, module,
#    lineno)
#winver = ''  # Windows only
_xoptions = Undefined(Dict[Any, Any])

flags = Undefined(_flags)
class _flags:
    debug = 0
    division_warning = 0
    inspect = 0
    interactive = 0
    optimize = 0
    dont_write_bytecode = 0
    no_user_site = 0
    no_site = 0
    ignore_environment = 0
    verbose = 0
    bytes_warning = 0
    quiet = 0
    hash_randomization = 0

float_info = Undefined(_float_info)
class _float_info:
    epsilon = 0.0   # DBL_EPSILON
    dig = 0         # DBL_DIG
    mant_dig = 0    # DBL_MANT_DIG
    max = 0.0       # DBL_MAX
    max_exp = 0     # DBL_MAX_EXP
    max_10_exp = 0  # DBL_MAX_10_EXP
    min = 0.0       # DBL_MIN
    min_exp = 0     # DBL_MIN_EXP
    min_10_exp = 0  # DBL_MIN_10_EXP
    radix = 0       # FLT_RADIX
    rounds = 0      # FLT_ROUNDS

hash_info = Undefined(_hash_info)
class _hash_info:
    width = 0    # width in bits used for hash values
    modulus = 0  # prime modulus P used for numeric hash scheme
    inf = 0      # hash value returned for a positive infinity
    nan = 0      # hash value returned for a nan
    imag = 0     # multiplier used for the imaginary part of a complex number

int_info = Undefined(_int_info)
class _int_info:
    bits_per_digit = 0  # number of bits held in each digit. Python integers 
                        # are stored internally in 
                        # base 2**int_info.bits_per_digit
    sizeof_digit = 0    # size in bytes of C type used to represent a digit

version_info = Undefined(_version_info)
class _version_info:
    major = 0
    minor = 0
    micro = 0
    releaselevel = ''
    serial = 0


# ----- sys function stubs -----
def call_tracing(fn: Any, args: Any) -> object: pass
def _clear_type_cache() -> None: pass
def _current_frames() -> Dict[int, Any]: pass
def displayhook(value: int) -> None: pass  # value might be None
def excepthook(type_: type, value: BaseException,
               traceback: Traceback) -> None: pass
def exc_info() -> Tuple[type, BaseException, Traceback]: pass
def exit(arg: int = 0) -> None: pass  # arg might be None
def getcheckinterval() -> int: pass  # deprecated
def getdefaultencoding() -> str: pass
def getdlopenflags() -> int: pass  # Unix only
def getfilesystemencoding() -> str: pass  # cannot return None
def getrefcount(object) -> int: pass
def getrecursionlimit() -> int: pass

@overload
def getsizeof(obj: object) -> int: pass
@overload
def getsizeof(obj: object, default: int) -> int: pass

def getswitchinterval() -> float: pass

@overload
def _getframe() -> Any: pass
@overload
def _getframe(depth: int) -> Any: pass

def getprofile() -> Any: pass # TODO return type
def gettrace() -> Any: pass # TODO return
def getwindowsversion() -> Any: pass  # Windows only, TODO return type
def intern(string: str) -> str: pass
def setcheckinterval(interval: int) -> None: pass  # deprecated
#def setdlopenflags(n: int) -> None: pass  # Linux only
def setprofile(profilefunc: Any) -> None: pass # TODO type
def setrecursionlimit(limit: int) -> None: pass
def setswitchinterval(interval: float) -> None: pass
def settrace(tracefunc: Any) -> None: pass # TODO type
# Trace functions should have three arguments: frame, event, and arg. frame 
# is the current stack frame. event is a string: 'call', 'line', 'return', 
# 'exception', 'c_call', 'c_return', or 'c_exception'. arg depends on the 
# event type.
def settscdump(on_flag: bool) -> None: pass

def gettotalrefcount() -> int: pass # Debug builds only

########NEW FILE########
__FILENAME__ = sysconfig
# Stubs for sysconfig

# NOTE: These are incomplete!

import typing

def get_config_var(name: str) -> str: pass
def is_python_build() -> bool: pass

########NEW FILE########
__FILENAME__ = tarfile
# TODO these are incomplete

from typing import Any, List, overload, Function

class TarError(Exception): pass

class TarInfo:
    name = ''
    size = 0
    uid = 0
    gid = 0

class TarFile:
    def getmember(self, name: str) -> TarInfo: pass
    def getmembers(self) -> List[TarInfo]: pass
    def getnames(self) -> List[str]: pass
    def extractall(self, path: str = ".",
                   members: List[TarInfo] = None) -> None: pass
    
    @overload
    def extract(self, member: str, path: str = "",
                set_attrs: bool = True) -> None: pass
    @overload
    def extract(self, member: TarInfo, path: str = "",
                set_attrs: bool = True) -> None: pass
    
    def add(self, name: str, arcname: str = None, recursive: bool = True,
            exclude: Function[[str], bool] = None, *,
            filter: 'Function[[TarFile], TarFile]' = None) -> None: pass
    def close(self) -> None: pass

def open(name: str, mode: str = 'r', fileobj: Any = None, bufsize: int = 10240,
         **kwargs) -> TarFile: pass

########NEW FILE########
__FILENAME__ = tempfile
# Stubs for tempfile
# Ron Murawski <ron@horizonchess.com>

# based on http://docs.python.org/3.3/library/tempfile.html

from typing import Tuple, BinaryIO

# global variables
tempdir = ''
template = ''

# TODO text files

# function stubs 
def TemporaryFile(
            mode: str = 'w+b', buffering: int = None, encoding: str = None, 
            newline: str = None, suffix: str = '', prefix: str = 'tmp',
            dir: str = None) -> BinaryIO:
    pass
def NamedTemporaryFile(
            mode: str = 'w+b', buffering: int = None, encoding: str = None, 
            newline: str = None, suffix: str = '', prefix: str = 'tmp',
            dir: str = None, delete=True) -> BinaryIO: 
    pass
def SpooledTemporaryFile(
            max_size: int = 0, mode: str = 'w+b', buffering: int = None, 
            encoding: str = None, newline: str = None, suffix: str = '', 
            prefix: str = 'tmp', dir: str = None) -> BinaryIO: 
    pass

class TemporaryDirectory:
    name = ''    
    def __init__(self, suffix: str = '', prefix: str = 'tmp',
                 dir: str = None) -> None: pass
    def cleanup(self) -> None: pass
    def __enter__(self) -> str: pass
    def __exit__(self, type, value, traceback) -> bool: pass
    
def mkstemp(suffix: str = '', prefix: str = 'tmp', dir: str = None,
            text: bool = False) -> Tuple[int, str]: pass
def mkdtemp(suffix: str = '', prefix: str = 'tmp',
            dir: str = None) -> str: pass
def mktemp(suffix: str = '', prefix: str = 'tmp', dir: str = None) -> str: pass
def gettempdir() -> str: pass
def gettempprefix() -> str: pass

########NEW FILE########
__FILENAME__ = threading
# Stubs for threading

# NOTE: These are incomplete!

from typing import Any, Dict

class Thread:
    name = ''
    ident = 0
    daemon = False
    
    def __init__(self, group: Any = None, target: Any = None, args: Any = (),
                 kwargs: Dict[Any, Any] = None,
                 verbose: Any = None) -> None: pass
    def start(self) -> None: pass
    def run(self) -> None: pass
    # TODO None value for float
    def join(self, timeout: float = None) -> None: pass
    def is_alive(self) -> bool: pass

    # Legacy methods
    def getName(self) -> str: pass
    def setName(self, name: str) -> None: pass
    def isDaemon(self) -> bool: pass
    def setDaemon(self, daemon: bool) -> None: pass

class Event:
    def is_set(self) -> bool: pass
    def set(self) -> None: pass
    def clear(self) -> None: pass
    # TODO can it return None?
    # TOOD None value for float
    def wait(self, timeout: float = None) -> bool: pass

class RLock:
    # TODO may return None
    def acquire(self, blocking: bool = True,
                timeout: float = -1.0) -> bool: pass
    def release(self) -> None: pass
    def __enter__(self) -> bool: pass
    def __exit__(self, type, value, traceback) -> bool: pass

########NEW FILE########
__FILENAME__ = time
# Stubs for time
# Ron Murawski <ron@horizonchess.com>

# based on: http://docs.python.org/3.2/library/time.html#module-time
# see: http://nullege.com/codes/search?cq=time

from typing import Undefined, Tuple, overload

# ----- variables and constants -----
accept2dyear = False
altzone = 0
daylight = 0
timezone = 0
tzname = Undefined(Tuple[str, str])


# ----- classes/methods -----
class struct_time:
    # this is supposed to be a namedtuple object 
    # namedtuple is not yet implemented (see file: mypy/stubs/collections.py)
    # see: http://docs.python.org/3.2/library/time.html#time.struct_time
    # see: http://nullege.com/codes/search/time.struct_time
    # TODO: namedtuple() object problem
    #namedtuple __init__(self, int, int, int, int, int, int, int, int, int):
    #    pass
    tm_year = 0
    tm_mon = 0
    tm_mday = 0
    tm_hour = 0
    tm_min = 0
    tm_sec = 0
    tm_wday = 0
    tm_yday = 0
    tm_isdst = 0


# ----- functions -----
@overload
def asctime() -> str: pass  # return current time
@overload
def asctime(t: struct_time) -> str: pass
@overload
def asctime(t: Tuple[int, int, int, int, int, int, int, int, int]) -> str: pass

def clock() -> float: pass

@overload
def ctime() -> str: pass  # return current time
@overload
def ctime(secs: float) -> str: pass

@overload
def gmtime() -> struct_time: pass  # return current time
@overload
def gmtime(secs: float) -> struct_time: pass

@overload
def localtime() -> struct_time: pass  # return current time
@overload
def localtime(secs: float) -> struct_time: pass

@overload
def mktime(t: struct_time) -> float: pass
@overload
def mktime(t: Tuple[int, int, int, int, int,
                    int, int, int, int]) -> float: pass

@overload
def sleep(secs: int) -> None: pass
@overload
def sleep(secs: float) -> None: pass

@overload
def strftime(format: str) -> str: pass  # return current time
@overload
def strftime(format: str, t: struct_time) -> str: pass
@overload
def strftime(format: str, t: Tuple[int, int, int, int, int,
                                   int, int, int, int]) -> str: pass

def strptime(string: str,
             format: str = "%a %b %d %H:%M:%S %Y") -> struct_time: pass
def time() -> float: pass
def tzset() -> None: pass  # Unix only

########NEW FILE########
__FILENAME__ = traceback
# Stubs for traceback

import typing

# TODO signatures
def format_tb(traceback): pass
def print_ecx(limit=None, file=None, chain=True): pass

# TODO add more

########NEW FILE########
__FILENAME__ = types
# Stubs for types

# TODO this is work in progress

from typing import Any

class ModuleType:
    def __init__(self, name: str, doc: Any) -> None: pass

class MethodType: pass
class BuiltinMethodType: pass

########NEW FILE########
__FILENAME__ = typing
"""Stubs for typing"""

from abc import abstractmethod, ABCMeta


# Definitions of special type checking related constructs.  Their definition
# are not used, so their value does not matter.

cast = object()
overload = object()
Undefined = object()
Any = object()
typevar = object()
Generic = object()
AbstractGeneric = object()
Tuple = object()
Function = object()
builtinclass = object()
ducktype = object()
disjointclass = object()

# Type aliases.
List = object()
Dict = object()
Set = object()

# Predefined type variables.
AnyStr = typevar('AnyStr', values=(str, bytes))


# Abstract base classes.

T = typevar('T')
KT = typevar('KT')
VT = typevar('VT')


# TODO Container etc.

class SupportsInt(metaclass=ABCMeta):
    @abstractmethod
    def __int__(self) -> int: pass
    
class SupportsFloat(metaclass=ABCMeta):
    @abstractmethod
    def __float__(self) -> float: pass

@disjointclass(int)
@disjointclass(float)
class SupportsAbs(AbstractGeneric[T]):
    @abstractmethod
    def __abs__(self) -> T: pass

@disjointclass(int)
@disjointclass(float)
class SupportsRound(AbstractGeneric[T]):
    @abstractmethod
    def __round__(self, ndigits: int = 0) -> T: pass

class Reversible(AbstractGeneric[T]):
    @abstractmethod
    def __reversed__(self) -> Iterator[T]: pass

class Sized(metaclass=ABCMeta):
    @abstractmethod
    def __len__(self) -> int: pass

class Iterable(AbstractGeneric[T]):
    @abstractmethod
    def __iter__(self) -> Iterator[T]: pass

class Iterator(Iterable[T], AbstractGeneric[T]):
    @abstractmethod
    def __next__(self) -> T: pass

class Sequence(Iterable[T], Sized, AbstractGeneric[T]):
    @abstractmethod
    def __contains__(self, x: object) -> bool: pass
    @overload
    @abstractmethod
    def __getitem__(self, i: int) -> T: pass
    @overload
    @abstractmethod
    def __getitem__(self, s: slice) -> Sequence[T]: pass
    
class AbstractSet(Iterable[T], Sized, AbstractGeneric[T]):
    @abstractmethod
    def __contains__(self, x: object) -> bool: pass
    @abstractmethod
    def __le__(self, s: AbstractSet[Any]) -> bool: pass
    @abstractmethod
    def __lt__(self, s: AbstractSet[Any]) -> bool: pass
    @abstractmethod
    def __gt__(self, s: AbstractSet[Any]) -> bool: pass
    @abstractmethod
    def __ge__(self, s: AbstractSet[Any]) -> bool: pass
    @abstractmethod
    def __and__(self, s: AbstractSet[Any]) -> AbstractSet[T]: pass
    # In order to support covariance, T should not be used within an argument
    # type. We need union types to properly model this.
    @abstractmethod
    def __or__(self, s: AbstractSet[T]) -> AbstractSet[T]: pass
    @abstractmethod
    def __sub__(self, s: AbstractSet[Any]) -> AbstractSet[T]: pass
    @abstractmethod
    def __xor__(self, s: AbstractSet[T]) -> AbstractSet[T]: pass
    # TODO argument can be any container?
    @abstractmethod
    def isdisjoint(self, s: AbstractSet[Any]) -> bool: pass

class Mapping(Iterable[KT], Sized, AbstractGeneric[KT, VT]):
    @abstractmethod
    def __getitem__(self, k: KT) -> VT: pass
    @abstractmethod
    def __setitem__(self, k: KT, v: VT) -> None: pass
    @abstractmethod
    def __delitem__(self, v: KT) -> None: pass
    @abstractmethod
    def __contains__(self, o: object) -> bool: pass

    @abstractmethod
    def clear(self) -> None: pass
    @abstractmethod
    def copy(self) -> Mapping[KT, VT]: pass
    @overload
    @abstractmethod
    def get(self, k: KT) -> VT: pass
    @overload
    @abstractmethod
    def get(self, k: KT, default: VT) -> VT: pass
    @overload
    @abstractmethod
    def pop(self, k: KT) -> VT: pass
    @overload
    @abstractmethod
    def pop(self, k: KT, default: VT) -> VT: pass
    @abstractmethod
    def popitem(self) -> Tuple[KT, VT]: pass
    @overload
    @abstractmethod
    def setdefault(self, k: KT) -> VT: pass
    @overload
    @abstractmethod
    def setdefault(self, k: KT, default: VT) -> VT: pass
    
    # TODO keyword arguments
    @overload
    @abstractmethod
    def update(self, m: Mapping[KT, VT]) -> None: pass
    @overload
    @abstractmethod
    def update(self, m: Iterable[Tuple[KT, VT]]) -> None: pass
    
    # TODO use views for the return values instead
    @abstractmethod
    def keys(self) -> AbstractSet[KT]: pass
    @abstractmethod
    def values(self) -> AbstractSet[VT]: pass
    @abstractmethod
    def items(self) -> AbstractSet[Tuple[KT, VT]]: pass

class IO(Iterable[AnyStr], AbstractGeneric[AnyStr]):
    # TODO detach
    # TODO use abstract properties
    @property
    def mode(self) -> str: pass
    @property
    def name(self) -> str: pass
    @abstractmethod
    def close(self) -> None: pass
    @abstractmethod
    def closed(self) -> bool: pass
    @abstractmethod
    def fileno(self) -> int: pass
    @abstractmethod
    def flush(self) -> None: pass
    @abstractmethod
    def isatty(self) -> bool: pass
    # TODO what if n is None?
    @abstractmethod
    def read(self, n: int = -1) -> AnyStr: pass
    @abstractmethod
    def readable(self) -> bool: pass
    @abstractmethod
    def readline(self, limit: int = -1) -> AnyStr: pass
    @abstractmethod
    def readlines(self, hint: int = -1) -> list[AnyStr]: pass
    @abstractmethod
    def seek(self, offset: int, whence: int = 0) -> int: pass
    @abstractmethod
    def seekable(self) -> bool: pass
    @abstractmethod
    def tell(self) -> int: pass
    # TODO None should not be compatible with int
    @abstractmethod
    def truncate(self, size: int = None) -> int: pass
    @abstractmethod
    def writable(self) -> bool: pass
    # TODO buffer objects
    @abstractmethod
    def write(self, s: AnyStr) -> int: pass
    @abstractmethod
    def writelines(self, lines: Iterable[AnyStr]) -> None: pass

    @abstractmethod
    def __iter__(self) -> Iterator[AnyStr]: pass
    @abstractmethod
    def __enter__(self) -> 'IO[AnyStr]': pass
    @abstractmethod
    def __exit__(self, type, value, traceback) -> bool: pass

class BinaryIO(IO[bytes]):    
    # TODO readinto
    # TODO read1?
    # TODO peek?
    @overload
    @abstractmethod
    def write(self, s: bytes) -> int: pass
    @overload
    @abstractmethod
    def write(self, s: bytearray) -> int: pass

    @abstractmethod
    def __enter__(self) -> BinaryIO: pass

class TextIO(IO[str]):
    # TODO use abstractproperty
    @property
    def buffer(self) -> BinaryIO: pass
    @property
    def encoding(self) -> str: pass
    @property
    def errors(self) -> str: pass
    @property
    def line_buffering(self) -> bool: pass
    @property
    def newlines(self) -> Any: pass # None, str or tuple
    @abstractmethod
    def __enter__(self) -> TextIO: pass

class Match(Generic[AnyStr]):
    pos = 0
    endpos = 0
    lastindex = 0
    lastgroup = Undefined(AnyStr)
    string = Undefined(AnyStr)
    
    # The regular expression object whose match() or search() method produced
    # this match instance.
    re = Undefined('Pattern[AnyStr]')
    
    def expand(self, template: AnyStr) -> AnyStr: pass
    
    @overload
    def group(self, group1: int = 0) -> AnyStr: pass
    @overload
    def group(self, group1: str) -> AnyStr: pass
    @overload
    def group(self, group1: int, group2: int,
              *groups: int) -> Sequence[AnyStr]: pass
    @overload
    def group(self, group1: str, group2: str,
              *groups: str) -> Sequence[AnyStr]: pass
    
    def groups(self, default: AnyStr = None) -> Sequence[AnyStr]: pass
    def groupdict(self, default: AnyStr = None) -> dict[str, AnyStr]: pass
    def start(self, group: int = 0) -> int: pass
    def end(self, group: int = 0) -> int: pass
    def span(self, group: int = 0) -> Tuple[int, int]: pass

class Pattern(Generic[AnyStr]):
    flags = 0
    groupindex = 0
    groups = 0
    pattern = Undefined(AnyStr)

    def search(self, string: AnyStr, pos: int = 0,
               endpos: int = -1) -> Match[AnyStr]: pass
    def match(self, string: AnyStr, pos: int = 0,
              endpos: int = -1) -> Match[AnyStr]: pass
    def split(self, string: AnyStr, maxsplit: int = 0) -> list[AnyStr]: pass
    def findall(self, string: AnyStr, pos: int = 0,
                endpos: int = -1) -> list[AnyStr]: pass
    def finditer(self, string: AnyStr, pos: int = 0,
                 endpos: int = -1) -> Iterator[Match[AnyStr]]: pass
    
    @overload
    def sub(self, repl: AnyStr, string: AnyStr,
            count: int = 0) -> AnyStr: pass
    @overload
    def sub(self, repl: Function[[Match[AnyStr]], AnyStr], string: AnyStr,
            count: int = 0) -> AnyStr: pass
    
    @overload
    def subn(self, repl: AnyStr, string: AnyStr,
             count: int = 0) -> Tuple[AnyStr, int]: pass
    @overload
    def subn(self, repl: Function[[Match[AnyStr]], AnyStr], string: AnyStr,
             count: int = 0) -> Tuple[AnyStr, int]: pass

class Traceback: pass

########NEW FILE########
__FILENAME__ = unicodedata
# Stubs for unicodedata

# NOTE: These are incomplete!

import typing

def normalize(form: str, unistr: str) -> str: pass

########NEW FILE########
__FILENAME__ = unittest
# Stubs for unittest

# Based on http://docs.python.org/3.0/library/unittest.html

# NOTE: These stubs are based on the 3.0 version API, since later versions
#       would require featurs not supported currently by mypy.

# Only a subset of functionality is included.

from typing import (
    Any, Function, Iterable, Undefined, Tuple, List, TextIO, Sequence,
    overload, typevar, Pattern
)
from abc import abstractmethod, ABCMeta

FT = typevar('FT')

class Testable(metaclass=ABCMeta):
    @abstractmethod
    def run(self, result: 'TestResult') -> None: pass
    @abstractmethod
    def debug(self) -> None: pass
    @abstractmethod
    def countTestCases(self) -> int: pass

# TODO ABC for test runners?

class TestResult:
    errors = Undefined(List[Tuple[Testable, str]])
    failures = Undefined(List[Tuple[Testable, str]])
    testsRun = 0
    shouldStop = False
    
    def wasSuccessful(self) -> bool: pass
    def stop(self) -> None: pass
    def startTest(self, test: Testable) -> None: pass
    def stopTest(self, test: Testable) -> None: pass
    def addError(self, test: Testable,
                  err: Tuple[type, Any, Any]) -> None: pass # TODO
    def addFailure(self, test: Testable,
                    err: Tuple[type, Any, Any]) -> None: pass # TODO
    def addSuccess(self, test: Testable) -> None: pass

class _AssertRaisesBaseContext:
    expected = Undefined(Any)
    failureException = Undefined(type)
    obj_name = ''
    expected_regex = Undefined(Pattern[str])
    
class _AssertRaisesContext(_AssertRaisesBaseContext):
    exception = Undefined(Any) # TODO precise type
    def __enter__(self) -> _AssertRaisesContext: pass
    def __exit__(self, exc_type, exc_value, tb) -> bool: pass
    
class _AssertWarnsContext(_AssertRaisesBaseContext):
    warning = Undefined(Any) # TODO precise type
    filename = ''
    lineno = 0
    def __enter__(self) -> _AssertWarnsContext: pass
    def __exit__(self, exc_type, exc_value, tb) -> bool: pass

class TestCase(Testable):
    def __init__(self, methodName: str = 'runTest') -> None: pass
    # TODO failureException
    def setUp(self) -> None: pass
    def tearDown(self) -> None: pass
    def run(self, result: TestResult = None) -> None: pass
    def debug(self) -> None: pass
    def assert_(self, expr: Any, msg: object = None) -> None: pass
    def failUnless(self, expr: Any, msg: object = None) -> None: pass
    def assertTrue(self, expr: Any, msg: object = None) -> None: pass
    def assertEqual(self, first: Any, second: Any,
                    msg: object = None) -> None: pass
    def failUnlessEqual(self, first: Any, second: Any,
                        msg: object = None) -> None: pass
    def assertNotEqual(self, first: Any, second: Any,
                       msg: object = None) -> None: pass
    def assertSequenceEqual(self, first: Sequence[Any], second: Sequence[Any],
                            msg: object = None,
                            seq_type: type = None) -> None: pass
    def failIfEqual(self, first: Any, second: Any,
                    msg: object = None) -> None: pass
    def assertAlmostEqual(self, first: float, second: float, places: int = 7,
                          msg: object = None,
                          delta: float = None) -> None: pass
    def failUnlessAlmostEqual(self, first: float, second: float,
                              places: int = 7,
                              msg: object = None) -> None: pass
    def assertNotAlmostEqual(self, first: float, second: float,
                             places: int = 7, msg: object = None,
                             delta: float = None) -> None: pass
    def failIfAlmostEqual(self, first: float, second: float, places: int = 7,
                          msg: object = None) -> None: pass
    def assertGreater(self, first: Any, second: Any,
                      msg: object = None) -> None: pass
    def assertGreaterEqual(self, first: Any, second: Any,
                      msg: object = None) -> None: pass
    def assertLess(self, first: Any, second: Any,
                   msg: object = None) -> None: pass
    def assertLessEqual(self, first: Any, second: Any,
                        msg: object = None) -> None: pass
    # TODO: If callableObj is None, the return value is None.
    def assertRaises(self, excClass: type, callableObj: Any = None,
                     *args: Any, **kwargs: Any) -> _AssertRaisesContext: pass
    def failIf(self, expr: Any, msg: object = None) -> None: pass
    def assertFalse(self, expr: Any, msg: object = None) -> None: pass
    def assertIs(self, first: object, second: object,
                 msg: object = None) -> None: pass
    def assertIsNot(self, first: object, second: object,
                    msg: object = None) -> None: pass
    def assertIsNone(self, expr: Any, msg: object = None) -> None: pass
    def assertIsNotNone(self, expr: Any, msg: object = None) -> None: pass
    def assertIn(self, first: T, second: Iterable[T],
                 msg: object = None) -> None: pass
    def assertNotIn(self, first: T, second: Iterable[T],
                    msg: object = None) -> None: pass
    def assertIsInstance(self, obj: Any, cls: type,
                         msg: object = None) -> None: pass
    def assertNotIsInstance(self, obj: Any, cls: type,
                            msg: object = None) -> None: pass
    def assertWarns(self, expected_warning: type, callable_obj: Any = None,
                    *args: Any, **kwargs: Any) -> _AssertWarnsContext: pass
    def fail(self, msg: object = None) -> None: pass
    def countTestCases(self) -> int: pass
    def defaultTestResult(self) -> TestResult: pass
    def id(self) -> str: pass
    def shortDescription(self) -> str: pass # May return None
    def addCleanup(function: Any, *args: Any, **kwargs: Any) -> None: pass
    def skipTest(self, reason: Any) -> None: pass

class FunctionTestCase(Testable):
    def __init__(self, testFunc: Function[[], None],
                 setUp: Function[[], None] = None,
                 tearDown: Function[[], None] = None,
                 description: str = None) -> None: pass
    def run(self, result: TestResult) -> None: pass
    def debug(self) -> None: pass
    def countTestCases(self) -> int: pass

class TestSuite(Testable):
    def __init__(self, tests: Iterable[Testable] = None) -> None: pass
    def addTest(self, test: Testable) -> None: pass
    def addTests(self, tests: Iterable[Testable]) -> None: pass
    def run(self, result: TestResult) -> None: pass
    def debug(self) -> None: pass
    def countTestCases(self) -> int: pass

# TODO TestLoader
# TODO defaultTestLoader

class TextTestRunner:
    def __init__(self, stream: TextIO = None, descriptions: bool = True,
                 verbosity: int = 1, failfast: bool = False) -> None: pass

class SkipTest(Exception):
    pass

# TODO precise types
def skipUnless(condition: Any, reason: str) -> Any: pass
def skipIf(condition: Any, reason: str) -> Any: pass
def expectedFailure(func: FT) -> FT: pass
def skip(reason: str) -> Any: pass

def main(module: str = '__main__', defaultTest: str = None,
         argv: List[str] = None, testRunner: Any = None,
         testLoader: Any = None) -> None: pass # TODO types

########NEW FILE########
__FILENAME__ = parse
# Stubs for urllib.parse

# NOTE: These are incomplete!

########NEW FILE########
__FILENAME__ = request
# Stubs for urllib.request

# NOTE: These are incomplete!

########NEW FILE########
__FILENAME__ = warnings
# Stubs for warnings

# Based on http://docs.python.org/3.2/library/warnings.html

from typing import overload, Any, List, TextIO

@overload
def warn(message: str, category: type = None,
         stacklevel: int = 1) -> None: pass
@overload
def warn(message: Warning, category: type = None,
         stacklevel: int = 1) -> None: pass

@overload
def warn_explicit(message: str, category: type, filename: str, lineno: int,
                  module: str = None, registry: Any = None,
                  module_globals: Any = None) -> None: pass
@overload
def warn_explicit(message: Warning, category: type, filename: str, lineno: int,
                  module: str = None, registry: Any = None,
                  module_globals: Any = None) -> None: pass

# logging modifies showwarning => make it a variable.
def _showwarning(message: str, category: type, filename: str, lineno: int,
                 file: TextIO = None, line: str = None) -> None: pass
showwarning = _showwarning

def formatwarning(message: str, category: type, filename: str, lineno: int,
                  line: str = None) -> None: pass
def filterwarnings(action: str, message: str = '', category: type = Warning,
                   module: str = '', lineno: int = 0,
                   append: bool = False) -> None: pass
def simplefilter(action: str, category: type = Warning, lineno: int = 0,
                 append: bool = False) -> None: pass
def resetwarnings() -> None: pass

class catch_warnings:
    # TODO record and module must be keyword arguments!
    # TODO type of module?
    def __init__(self, record: bool = False, module: Any = None) -> None: pass
    def __enter__(self) -> List[Any]: pass
    def __exit__(self, type, value, traceback) -> bool: pass

########NEW FILE########
__FILENAME__ = weakref
# Stubs for weakref

# NOTE: These are incomplete!

from typing import (
    typevar, Generic, Any, Function, overload, Mapping, Iterator, Dict, Tuple,
    Iterable
)

T = typevar('T')
KT = typevar('KT')
VT = typevar('VT')

class ReferenceType(Generic[T]):
    # TODO members
    pass

def ref(o: T, callback: Function[[ReferenceType[T]],
                                 Any] = None) -> ReferenceType[T]: pass

# TODO callback
def proxy(object: T) -> T: pass

class WeakValueDictionary(Generic[KT, VT]):
    # TODO tuple iterable argument?
    @overload
    def __init__(self) -> None: pass
    @overload
    def __init__(self, map: Mapping[KT, VT]) -> None: pass
    
    def __len__(self) -> int: pass    
    def __getitem__(self, k: KT) -> VT: pass
    def __setitem__(self, k: KT, v: VT) -> None: pass
    def __delitem__(self, v: KT) -> None: pass
    def __contains__(self, o: object) -> bool: pass
    def __iter__(self) -> Iterator[KT]: pass
    def __str__(self) -> str: pass
    
    def clear(self) -> None: pass
    def copy(self) -> Dict[KT, VT]: pass
    
    @overload
    def get(self, k: KT) -> VT: pass
    @overload
    def get(self, k: KT, default: VT) -> VT: pass
    
    @overload
    def pop(self, k: KT) -> VT: pass
    @overload
    def pop(self, k: KT, default: VT) -> VT: pass
    
    def popitem(self) -> Tuple[KT, VT]: pass
    
    @overload
    def setdefault(self, k: KT) -> VT: pass
    @overload
    def setdefault(self, k: KT, default: VT) -> VT: pass
    
    @overload
    def update(self, m: Mapping[KT, VT]) -> None: pass
    @overload
    def update(self, m: Iterable[Tuple[KT, VT]]) -> None: pass
    
    # NOTE: incompatible with Mapping
    def keys(self) -> Iterator[KT]: pass
    def values(self) -> Iterator[VT]: pass
    def items(self) -> Iterator[Tuple[KT, VT]]: pass

    # TODO return type
    def valuerefs(self) -> Iterable[Any]: pass

########NEW FILE########
__FILENAME__ = zipfile
# TODO these are incomplete

from typing import overload, List, Undefined, Tuple, BinaryIO

ZIP_STORED = 0
ZIP_DEFLATED = 0

@overload
def is_zipfile(filename: str) -> bool: pass
@overload
def is_zipfile(filename: BinaryIO) -> bool: pass

class ZipInfo:
    filename = ''
    date_time = Undefined(Tuple[int, int, int, int, int, int])
    compressed_size = 0
    file_size = 0

class ZipFile:
    @overload
    def __init__(self, file: str, mode: str = 'r',
                 compression: int = ZIP_STORED,
                 allowZip64: bool = False) -> None: pass
    @overload
    def __init__(self, file: BinaryIO, mode: str = 'r',
                  compression: int = ZIP_STORED,
                 allowZip64: bool = False) -> None: pass
    
    def close(self) -> None: pass
    def getinfo(name: str) -> ZipInfo: pass
    def infolist(self) -> List[ZipInfo]: pass
    def namelist(self) -> List[str]: pass
    
    @overload
    def read(self, name: str, pwd: str = None) -> bytes: pass
    @overload
    def read(self, name: ZipInfo, pwd: str = None) -> bytes: pass
    
    def write(self, filename: str, arcname: str = None,
              compress_type: int = None) -> None: pass
    
    def __enter__(self) -> 'ZipFile': pass
    def __exit__(self, type, value, traceback) -> bool: pass

########NEW FILE########
__FILENAME__ = zlib
# Stubs for zlib

# Based on http://docs.python.org/3.2/library/zlib.html

# TODO this stub file is an empty placeholder

########NEW FILE########
__FILENAME__ = _dummy_thread
# Stubs for _dummy_thread

# NOTE: These are incomplete!

from typing import Undefined, Any

class LockType:
    def acquire(self) -> None: pass
    def release(self) -> None: pass

def allocate_lock() -> LockType: pass

########NEW FILE########
__FILENAME__ = _posixsubprocess
# Stubs for _posixsubprocess

# NOTE: These are incomplete!

from typing import Tuple, Sequence

def cloexec_pipe() -> Tuple[int, int]: pass
def fork_exec(args: Sequence[str],
              executable_list, close_fds, fds_to_keep, cwd: str, env_list,
              p2cread: int, p2cwrite: int, c2pred: int, c2pwrite: int,
              errread: int, errwrite: int, errpipe_read: int,
              errpipe_write: int, restore_signals, start_new_session,
              preexec_fn) -> int: pass

########NEW FILE########
__FILENAME__ = _random
# Stubs for _random

# NOTE: These are incomplete!

from typing import Any

class Random:
    def seed(self, x: Any = None) -> None: pass
    def getstate(self) -> tuple: pass
    def setstate(self, state: tuple) -> None: pass
    def random(self) -> float: pass
    def getrandbits(self, k: int) -> int: pass

########NEW FILE########
__FILENAME__ = _subprocess
# Stubs for _subprocess

# NOTE: These are incomplete!

from typing import Mapping, Any, Tuple

CREATE_NEW_CONSOLE = 0
CREATE_NEW_PROCESS_GROUP = 0
STD_INPUT_HANDLE = 0
STD_OUTPUT_HANDLE = 0
STD_ERROR_HANDLE = 0
SW_HIDE = 0
STARTF_USESTDHANDLES = 0
STARTF_USESHOWWINDOW = 0
INFINITE = 0
DUPLICATE_SAME_ACCESS = 0
WAIT_OBJECT_0 = 0

# TODO not exported by the Python module
class Handle:
    def Close(self) -> None: pass

def GetVersion() -> int: pass
def GetExitCodeProcess(handle: Handle) -> int: pass
def WaitForSingleObject(handle: Handle, timeout: int) -> int: pass
def CreateProcess(executable: str, cmd_line: str,
                  proc_attrs, thread_attrs,
                  inherit: int, flags: int,
                  env_mapping: Mapping[str, str],
                  curdir: str,
                  startupinfo: Any) -> Tuple[Any, Handle, int, int]: pass
def GetModuleFileName(module: int) -> str: pass
def GetCurrentProcess() -> Handle: pass
def DuplicateHandle(source_proc: Handle, source: Handle, target_proc: Handle,
                    target: Any, access: int, inherit: int) -> int: pass
def CreatePipe(pipe_attrs, size: int) -> Tuple[Handle, Handle]: pass
def GetStdHandle(arg: int) -> int: pass
def TerminateProcess(handle: Handle, exit_code: int) -> None: pass

########NEW FILE########
__FILENAME__ = _thread
# Stubs for _thread

# NOTE: These are incomplete!

from typing import Undefined, Any

def _count() -> int: pass
_dangling = Undefined(Any)

class LockType:
    def acquire(self) -> None: pass
    def release(self) -> None: pass

def allocate_lock() -> LockType: pass

########NEW FILE########
__FILENAME__ = tests
import sys

import typing

from mypy.myunit import Suite, run_test
from mypy.test import testtypes
from mypy.test import testsubtypes
from mypy.test import testsolve
from mypy.test import testinfer
from mypy.test import testlex
from mypy.test import testparse
from mypy.test import testsemanal
from mypy.test import testtransform
from mypy.test import testcheck
from mypy.test import testtypegen
from mypy.test import testoutput
from mypy.test import testdyncheck
from mypy.test import testicodegen


class AllSuite(Suite):
    def __init__(self):
        self.test_types = testtypes.TypesSuite()
        self.test_typeops = testtypes.TypeOpsSuite()
        self.test_join = testtypes.JoinSuite()
        self.test_meet = testtypes.MeetSuite()
        self.test_subtypes = testsubtypes.SubtypingSuite()
        self.test_solve = testsolve.SolveSuite()
        self.test_infer = testinfer.MapActualsToFormalsSuite()
        self.test_lex = testlex.LexerSuite()
        self.test_parse = testparse.ParserSuite()
        self.test_parse_errors = testparse.ParseErrorSuite()
        self.test_semanal = testsemanal.SemAnalSuite()
        self.test_semanal_errors = testsemanal.SemAnalErrorSuite()
        self.test_semanal_symtable = testsemanal.SemAnalSymtableSuite()
        self.test_semanal_typeinfos = testsemanal.SemAnalTypeInfoSuite()
        self.test_transform = testtransform.TransformSuite()
        self.test_check = testcheck.TypeCheckSuite()
        self.test_typegen = testtypegen.TypeExportSuite()
        self.test_output = testoutput.OutputSuite()
        self.test_dyncheck = testdyncheck.DyncheckTransformSuite()
        self.test_icodegen = testicodegen.IcodeGenerationSuite()
        super().__init__()


if __name__ == '__main__':
    run_test(AllSuite(), sys.argv[1:])

########NEW FILE########
