__FILENAME__ = debug
#!/usr/bin/env python
# -*- coding:  utf-8 -*-
"""
human_curl.debug
~~~~~~~~~~~~~~~~~~~~~~~~~~

Debuggging tests for human_curl

:copyright: (c) 2011 by Alexandr Lispython (alex@obout.ru).
:license: BSD, see LICENSE for more details.
"""

import logging
from .tests import *


logger = logging.getLogger("human_curl")
logger.setLevel(logging.DEBUG)

# Add the log message handler to the logger
# LOG_FILENAME = os.path.join(os.path.dirname(__file__), "debug.log")
# handler = logging.handlers.FileHandler(LOG_FILENAME)
handler = logging.StreamHandler()

formatter = logging.Formatter("%(levelname)s %(asctime)s %(module)s [%(lineno)d] %(process)d %(thread)d | %(message)s ")

handler.setFormatter(formatter)

logger.addHandler(handler)

########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# human_curl documentation build configuration file, created by
# sphinx-quickstart on Thu Sep  1 01:41:40 2011.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.doctest', 'sphinx.ext.coverage', 'sphinx.ext.viewcode']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'human_curl'
copyright = u'2011, Alexandr Lispython (alex@obout.ru)'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.0.1'
# The full version, including alpha/beta/rc tags.
release = '0.0.1'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'human_curldoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'human_curl.tex', u'human\\_curl Documentation',
   u'Alexandr Lispython (alex@obout.ru)', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'human_curl', u'human_curl Documentation',
     [u'Alexandr Lispython (alex@obout.ru)'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'human_curl', u'human_curl Documentation', u'Alexandr Lispython (alex@obout.ru)',
   'human_curl', 'One line description of project.', 'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = async
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

from urlparse import urljoin

from human_curl import async, Response, async_client

HTTP_TEST_URL = "http://h.wrttn.me"
def build_url(*parts):
    return urljoin(HTTP_TEST_URL, "/".join(parts))

urls = [build_url("get?test_key=%s" % str(x)) for x in xrange(10)]

rs = [async_client.get(url) for url in urls]
async_client.start()

print(async_client.responses)

########NEW FILE########
__FILENAME__ = async1
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

from urlparse import urljoin
from datetime import datetime

from human_curl.async import AsyncClient
from human_curl.utils import stdout_debug

def success_callback(response, **kwargs):
    """This function call when response successed
    """
    print("success callback")
    print(response, response.request)
    print(response.headers)
    print(response.content)
    print(kwargs)

def fail_callback(request, opener, **kwargs):
    """Collect errors
    """
    print("fail callback")
    print(request, opener)
    print(kwargs)


# In kwargs we can pass default arguments
# Add pre and post callback call hooks
async_client = AsyncClient(success_callback=success_callback,
                           fail_callback=fail_callback)

results = []
fails = []

async_client.get('http://h.wrttn.me/get')
async_client.get('http://httpbin.org/get',
                 success_callback=success_callback, fail_callback=fail_callback)

async_client.start()

########NEW FILE########
__FILENAME__ = async2
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

from urlparse import urljoin
from datetime import datetime

from human_curl.async import AsyncClient
from human_curl.utils import stdout_debug

def success_callback(response, **kwargs):
    """This function call when response successed
    """
    print("success callback")
    print(response, response.request)
    print(response.headers)
    print(response.content)
    print(kwargs)

def fail_callback(request, opener, **kwargs):
    """Collect errors
    """
    print("fail callback")
    print(request, opener)
    print(kwargs)


# In kwargs we can pass default arguments
# Add pre and post callback call hooks
async_client = AsyncClient(success_callback=success_callback,
                           fail_callback=fail_callback)

results = []
fails = []

async_client.get('http://h.wrttn.me/get')
async_client.get('http://httpbin.org/get',
                 success_callback=success_callback, fail_callback=fail_callback)

async_client.start()

########NEW FILE########
__FILENAME__ = async_contextmanager
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

from urlparse import urljoin
from datetime import datetime

from human_curl.async import AsyncClient
from human_curl.utils import stdout_debug

def success_callback(response, **kwargs):
    """This function call when response successed
    """
    print("success callback")
    print(response, response.request)
    print(response.headers)
    print(response.content)
    print(kwargs)

def fail_callback(request, opener, **kwargs):
    """Collect errors
    """
    print("fail callback")
    print(request, opener)
    print(kwargs)


# In kwargs we can pass default arguments
# Add pre and post callback call hooks
with AsyncClient(success_callback=success_callback,
                 fail_callback=fail_callback) as async_client:

    async_client.get('http://h.wrttn.me/get')
    async_client.get('http://httpbin.org/get',
                     success_callback=success_callback, fail_callback=fail_callback)
    # async client start when exit

########NEW FILE########
__FILENAME__ = auth
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

import human_curl as hurl
from human_curl.auth import BasicAuth, DigestAuth, OAuth

def stdout_debug(debug_type, debug_msg):
    """Print messages
    """
    debug_types = ('I', '<', '>', '<', '>')
    if debug_type == 0:
        print('%s' % debug_msg.strip())
    elif debug_type in (1, 2):
        for line in debug_msg.splitlines():
            print('%s %s' % (debug_types[debug_type], line))
    elif debug_type == 4:
        print('%s %r' % (debug_types[debug_type], debug_msg))


r1 = hurl.get("https://h.wrttn.me/basic-auth/username/password",
              debug=stdout_debug, allow_redirects=False,
              auth=("username", "password"))
print(r1)

r2 = hurl.get("https://h.wrttn.me/basic-auth/username/password",
              debug=stdout_debug, auth=("username", "password"))
print(r2)

r3 = hurl.get("https://h.wrttn.me/basic-auth/username/password",
              debug=stdout_debug, allow_redirects=False,
              auth=BasicAuth("username", "password"))

print(r3)



r4 = hurl.get("http://127.0.0.1:5000/digest-auth/auth/username/password",
             debug=stdout_debug, allow_redirects=False,
             auth=DigestAuth("username", "password"))
print(r4)



########NEW FILE########
__FILENAME__ = bench
#!/usr/bin/env python
# -*- coding:  utf-8 -*-
import time
import human_curl
import requests
import json
import uuid
from pprint import pprint
from contextlib import contextmanager

@contextmanager
def timer(func):
    print("Start test %s" % func)
    t = time.time()
    yield
    print("Total time %s for %s --------------- "% (str(time.time()-t), func))


# TEST REDIRECTS
with timer("human_curl"):
    r = human_curl.get('http://httpbin.org/redirect/7', allow_redirects=True,
                       max_redirects=10)
    print(r)
    print(len(r.history))


with timer("python-requests"):
    r = requests.get('http://httpbin.org/redirect/7', allow_redirects=True)
    print(r)
    print(len(r.history))


files =  {
    #('first_file', open("/tmp/testfile1.txt.gz")),
    'first_file': open("/tmp/testfile2.txt"),
    'second_file': open("/tmp/testfile3.txt"),
    }

#FILES UPLOADING
with timer("human_curl"):
    try:
        r = human_curl.post('http://h.wrttn.me/post', allow_redirects=True, files=files,
                            max_redirects=10)
        print(r)
        #print(json.loads(r.content))
    except Exception, e:
        print(e)

with timer("python-requests"):
    try:
        r = requests.post('http://h.wrttn.me/post', allow_redirects=True, files=files)
        print(r)
        #print(json.loads(r.response))
    except Exception, e:
        print(e)

custom_headers = (
    ('Test-Header', 'fwkjenwkljbnfkjqnewfrjven3lrf'),
    ('Another-Header', 'ifenwqnfe;wnfqfjlweqnnlf')
    )

with timer("human_curl"):
    r = human_curl.get("http://h.wrttn.me/headers",
                        headers=custom_headers)
    print(r)
    print(json.loads(r.content))

custom_vars = {
    uuid.uuid4().hex: uuid.uuid4().hex,
    uuid.uuid4().hex: uuid.uuid4().hex,
    uuid.uuid4().hex: uuid.uuid4().hex,
    }

with timer('human_curl'):
    r =  human_curl.post("http://h.wrttn.me/post",
                        data = custom_vars, debug=True)
    print(r)
    print(json.loads(r.content))


########NEW FILE########
__FILENAME__ = cookies
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

import human_curl as hurl

def stdout_debug(debug_type, debug_msg):
    """Print messages
    """
    debug_types = ('I', '<', '>', '<', '>')
    if debug_type == 0:
        print('%s' % debug_msg.strip())
    elif debug_type in (1, 2):
        for line in debug_msg.splitlines():
            print('%s %s' % (debug_types[debug_type], line))
    elif debug_type == 4:
        print('%s %r' % (debug_types[debug_type], debug_msg))


r1 = hurl.get("http://www.google.com",
              debug=stdout_debug, allow_redirects=True)

print(r1.cookiesjar)
r2 = hurl.get("http://h.wrttn.me/cookies/set/llllll/adkbhahjsbhjwbf",
              debug=stdout_debug, cookies=r1.cookiesjar)
assert r1.cookiesjar == r2.cookiesjar
print(r2.cookiesjar)
print(r2.content)
r3 = hurl.get("http://h.wrttn.me/cookies/set/222222/adkbhahjsbhjwbf",
              debug=stdout_debug, cookies=r1.cookiesjar)


print(r3.cookiesjar)
print(r3.content)


########NEW FILE########
__FILENAME__ = multi_get
#http://rarestblog.com/py/multi_get.py.txt

import cStringIO
import sys

try:
    import pycurl2 as pycurl
except ImportError:
    import pycurl

import re
def removewww(a):
    return a.replace('www.','')

def domain_from_url(url):
    if re.findall(r'^[a-z]+://', url):
        try: return re.findall('^[a-z]+://(www[0-9-]+\.)?([a-z0-9+\.-]+)', url.strip())[0][1].lower()
        except: return ''#repr(sys.exc_info())
    else:
        domain,_,_ = url.partition('/')
        return domain

def short_domain_from_url(url):
    try:
        parts=domain_from_url(url).split('.')
        return removewww('.'.join(parts[-2:] if parts[-2] not in ('co','net','org','com','blogspot','wordpress') else parts[-3:]))
    except:
        return ''

def reduce_by_domain(urls):
    out = []
    on = {}
    for k in urls:
        if short_domain_from_url(k) not in on:
            on[short_domain_from_url(k)] = 1
            out.append(k)
    return out

def multi_get(wf, urls, debug = 0, num_conn = 100, timeout = 5,
              ua = None, ref = None, percentile = 100, cf = None, follow = 1, ref_dict = None):
    if ua is None:
        ua = 'multi_get'
    queue = []

    wf_keys = dict.fromkeys(wf.keys(),1)

    for url in dict.fromkeys(urls).keys():
        url = url.strip()
        if len(url)>250:
            wf[url]='---'
            continue
        if not url or url[0] == "#" or url in wf_keys:
            continue
        filename = "[%03d]" % (len(queue) + 1)
        queue.append((url, filename))


    if not queue:
        return

    num_urls = len(queue)
    num_conn = min(num_conn, num_urls)
    assert 1 <= num_conn <= 10000, "invalid number of concurrent connections"
    if debug:
        print "PycURL %s (compiled against 0x%x)" % (pycurl.version, pycurl.COMPILE_LIBCURL_VERSION_NUM)

    if debug:
        print "----- Getting", num_urls, "URLs using", num_conn, "connections -----"

    m = pycurl.CurlMulti()
    m.handles = []
    for i in range(num_conn):
        c = pycurl.Curl()
        c.fp = None
        if follow:
            c.setopt(pycurl.FOLLOWLOCATION, 1)
            c.setopt(pycurl.MAXREDIRS, 5)
        c.setopt(pycurl.CONNECTTIMEOUT, timeout)
        c.setopt(pycurl.TIMEOUT, timeout)
        c.setopt(pycurl.NOSIGNAL, 1)
        c.setopt(pycurl.USERAGENT, ua)
        if cf:
            c.setopt(pycurl.COOKIEFILE, cf)
            c.setopt(pycurl.COOKIEJAR, cf)

        if ref: c.setopt(pycurl.REFERER, ref)
        m.handles.append(c)

    from UserString import MutableString

    freelist = m.handles[:]
    num_processed = 0
    bailout = 0
    while num_processed < num_urls:
        if bailout: break
        while queue and freelist:
            url, filename = queue.pop(0)
            if '.pdf' not in url:
                c = freelist.pop()
                if type(url)==type(u''):
                    url=url.encode('utf8', 'replace')
                c.setopt(pycurl.URL, url)
                c.res = cStringIO.StringIO()
                c.setopt(pycurl.WRITEFUNCTION, c.res.write)
                if ref_dict is not None:
                    if ref_dict.get(url, ''):
                        c.setopt(pycurl.REFERER, ref_dict.get(url, ''))

                m.add_handle(c)
                c.filename = filename
                c.url = url
            else:
                wf[url]='---'
                num_urls -= 1
        while 1:
            ret, num_handles = m.perform()
            if ret != pycurl.E_CALL_MULTI_PERFORM:
                break
        while 1:
            num_q, ok_list, err_list = m.info_read()
            for c in ok_list:
                c.fp = None
                m.remove_handle(c)


                text = c.res.getvalue()
                if len(text)>100000: text = ''

                wf[c.url]=text

                try:
                    if debug: print "[ ok] %5s %40s" % (c.filename, c.url[:40])
                except:
                    pass

                freelist.append(c)
            for c, errno, errmsg in err_list:
                c.fp = None
                m.remove_handle(c)
                if debug: print "[err] %5s %40s" % (c.filename, c.url[:40])
                wf[c.url]='---'
                freelist.append(c)
            num_processed = num_processed + len(ok_list) + len(err_list)
            if num_urls:
                if float(num_processed)/num_urls*100 > percentile:
                    bailout = 1
                    break
            if num_q == 0:
                break
        m.select(1.0)

    m.close()

if __name__ == '__main__':
    import time, urllib, cjson

    urls = []
    for query in range(10):
        yql_query = "select * from search.web(%d) where query=\"%s\"" % (100, query)
        url = 'http://query.yahooapis.com/v1/public/yql?q=%s&format=json' % urllib.urlencode({'':yql_query})[1:]
        try:
            url_read = urllib.urlopen(url).read()
            urls += list([i['url'] for i in cjson.decode(url_read)['query']['results']['result']])
        except: pass

    print urls
    urls = reduce_by_domain(urls)
    print "%d URLs" % len(urls)

    res = {}
    import time
    tt = time.time()
    multi_get(res, urls, num_conn = 300, percentile = 80)
    print len(urls)/(time.time()-tt), 'urls per second'

########NEW FILE########
__FILENAME__ = oauth
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

import human_curl as hurl
from human_curl.auth import BasicAuth, DigestAuth, OAuthManager, OAuthConsumer, OAuthToken

def stdout_debug(debug_type, debug_msg):
    """Print messages
    """
    debug_types = ('I', '<', '>', '<', '>')
    if debug_type == 0:
        print('%s' % debug_msg.strip())
    elif debug_type in (1, 2):
        for line in debug_msg.splitlines():
            print('%s %s' % (debug_types[debug_type], line))
    elif debug_type == 4:
        print('%s %r' % (debug_types[debug_type], debug_msg))


CONSUMER_KEY = ""
CONSUMER_SECRET = ""

REQUEST_TOKEN_URL = "https://api.twitter.com/oauth/request_token"
AUTHORIZE_URL = "https://api.twitter.com/oauth/authorize"
ACCESS_TOKEN_URL = "https://api.twitter.com/oauth/access_token"
CALLBACK_URL = "http://h.wrttn.me/request_callback"

ACCESS_TOKEN = ""
ACCESS_TOKEN_SECRET = ""


PROTECTED_RESOURCE = "https://api.twitter.com/1/statuses/home_timeline.json?count=5"

consumer = OAuthConsumer(CONSUMER_KEY, CONSUMER_SECRET)
token = OAuthToken(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)

oauth = OAuthManager(consumer, token)

r = hurl.get(PROTECTED_RESOURCE,
              debug=stdout_debug,
             allow_redirects=False,
             auth=oauth)
print(r)
print(r.content)


########NEW FILE########
__FILENAME__ = oauth2
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

import human_curl as hurl
from human_curl.auth import *

def stdout_debug(debug_type, debug_msg):
    """Print messages
    """
    debug_types = ('I', '<', '>', '<', '>')
    if debug_type == 0:
        print('%s' % debug_msg.strip())
    elif debug_type in (1, 2):
        for line in debug_msg.splitlines():
            print('%s %s' % (debug_types[debug_type], line))
    elif debug_type == 4:
        print('%s %r' % (debug_types[debug_type], debug_msg))


request_token_url = "http://oauth-sandbox.sevengoslings.net/request_token"
authorize_url = "http://oauth-sandbox.sevengoslings.net/authorize"
access_token_url = "http://oauth-sandbox.sevengoslings.net/access_token"
protected_resource = "http://oauth-sandbox.sevengoslings.net/two_legged"


consumer_key = "be4b2eab12130803"
consumer_secret = "a2e0e39b27d08ee2f50c4d3ec06f"


r = hurl.Request("GET", protected_resource,
            debug=stdout_debug
            )

consumer = OAuthConsumer(consumer_key, consumer_secret)

oauth_manager = OAuthManager(consumer, request_token_url=request_token_url,
                             authorize_url=authorize_url,
                             access_token_url=access_token_url,
                             signature_method=SignatureMethod_PLAINTEXT)

oauth_manager.setup_request(r)
oauth_manager.request_token()

print(oauth_manager._tmp_token_key, oauth_manager._tmp_token_secret)
print(oauth_manager.confirm_url)

# oauth_manager.verify(pin)

#oauth_manager.access_request()

########NEW FILE########
__FILENAME__ = proxy
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

import human_curl as hurl

r = hurl.get("http://nntime.com/proxy-country/China-63.htm", debug=hurl.utils.stdout_debug,
             proxy = ('socks4', ("69.59.140.30", 1080 )))


print(r)
print(r.headers)

########NEW FILE########
__FILENAME__ = usage
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

########NEW FILE########
__FILENAME__ = async
"""
human_curl.async
~~~~~~~~~~~~~~~~

Async module

:copyright: (c) 2011 - 2012 by Alexandr Lispython (alex@obout.ru).
:license: BSD, see LICENSE for more details.
"""

from logging import getLogger
from types import FunctionType

try:
    import pycurl2 as pycurl
except ImportError:
    import pycurl

# Lib imports
from . import get_version
from .core import Request
from .exceptions import InterfaceError, CurlError


__all__ = ("AsyncClient", "map", "async_client", "get", "head", "post", "put", "options", "delete")

logger = getLogger('human_curl.async')

DEFAULT_MAX_OPENERS = 1000
DEFAULT_SLEEP_TIMEOUT = 2.0
DEFAULT_INFO_READ_RETRIES_MAX = 10


class AsyncClient(object):
    """Client to create async requests

    .. versionadded:: 0.0.5

    """

    def __init__(self, size=DEFAULT_MAX_OPENERS,
                 success_callback=None, fail_callback=None,
                 process_func=None,
                 sleep_timeout=DEFAULT_SLEEP_TIMEOUT,
                 info_read_retries_max=DEFAULT_INFO_READ_RETRIES_MAX, **kwargs):
        """Create `AsyncClient`

        :param size: openers count
        :param success_callback: default success cullback function
        :param fail_callback: default fail callback function
        :param sleep_timeout: sleep in perform
        :param \*\*kwargs: global request parameters
        """

        self.success_callback = success_callback
        self.fail_callback = fail_callback

        self._remaining = 0
        self._openers_pool = None
        self._num_conn = size
        self._data_queue = []
        self._num_urls = 0
        self._sleep_timeout = sleep_timeout
        self.num_processed = 0
        self._process_func = process_func
        self._free_openers = []
        self.responses = []
        self._default_user_agent = None
        self._default_params = kwargs
        self._finished = False


    @property
    def user_agent(self):
        """Setup user agent
        """
        if not self._default_user_agent:
            self._default_user_agent = "Mozilla/5.0 (compatible; human_curl.async; {0}; +http://h.wrttn.me/human_curl)".format(get_version())
        return self._default_user_agent


    def add_handler(self, **params):
        """Add request params to data queue

        :param \*\*kwargs: Optional arguments that passed to `Request`.
        """

        # Check callback functions
        if ('success_callback' not in params and not self.success_callback) or \
           ('fail_callback' not in params and not self.fail_callback):
            raise InterfaceError("You must specify success_calback or fail_callback")

        self._data_queue.append(params)
        self._remaining += 1
        self._num_urls = self._remaining

    @property
    def connections_count(self):
        """Calculace and return number of connections

        :return: number of connections
        """
        return min(self._num_conn, self._remaining)

    def build_pool(self):
        """Make openers pool

        :return: returns a new :class:`pycurl.MultiCUrl` object.
        """
        self._openers_pool = pycurl.CurlMulti()
        self._openers_pool.handles = []

        # Get calculated connections count
        num_openers = self.connections_count

        for i in xrange(num_openers):
            self._openers_pool.handles.append(self.get_opener())

        logger.info("Created {0} openers".format(num_openers))
        return self._openers_pool

    @staticmethod
    def get_opener():
        """Make `pycurl.Curl` objcet

        :return opener: :class:`pycurl.Curl` object
        """
        opener = pycurl.Curl()
        opener.fp = None
        opener.setopt(pycurl.NOSIGNAL, 1)
        opener.dirty = False
        return opener

    def perform_pool(self):
        """Perform openers in pool
        """
        while True:
            ret, num_handles = self._openers_pool.perform()
            if ret != pycurl.E_CALL_MULTI_PERFORM:
                break

    def start(self, process_func=None):
        """Start workers poll

        :param process_func: function to call in process
        """

        if process_func and isinstance(process_func, FunctionType):
            self._process_func = process_func
        elif process_func:
            raise InterfaceError("process_func must be function")

        if not self._openers_pool:
            self._openers_pool = self.build_pool()

        self._free_openers = self._openers_pool.handles[:]

        while self._remaining:

            self.process_raw_data()
            self.perform_pool()
            self.process_pending_requests()

            logger.info("Processed {0} from {1} items".format(
                self.num_processed, self._num_urls))

            # Sleep timeout
            self._openers_pool.select(self._sleep_timeout)

        self.cleanup_pool()

    def configure_opener(self, opener, data):
        """Make and configure `Request` from data

        :param opener: :class:`pycurl.Curl` instance
        :param data: `Request` params as dict
        """
        opener = self.reset_opener(opener)

        if 'user_agent' not in data:
            data['user_agent'] = self.user_agent

        mixed_data = self._default_params
        mixed_data.update(data)
        data = mixed_data

        request = Request(**data)
        request.build_opener(request.url, opener)

        # Reset opener settings to defaults
        opener.request = request
        opener.success_callback = data.pop('success_callback', None) or \
                                  self.success_callback
        opener.fail_callback = data.get('fail_callback', None) or \
                               self.fail_callback
        return opener

    def reset_opener(self, opener):
        """Reset opener settings to defaults

        :param opener: :class:`pycurl.Curl` object
        """
        opener.success_callback = None
        opener.fail_callback = None
        opener.request = None

        if getattr(opener, "dirty", False) is True:
            # After appling this method curl raise error
            # Unable to fetch curl handle from curl object
            opener.reset()

        # Maybe need delete cookies?
        return opener

    def make_response(self, opener):
        """Make response from successed request

        :param opener: :class:`pycurl.Curl` object
        :return response: :class:`Response` object
        """
        response = opener.request.make_response()
        return response

    def process_raw_data(self):
        """Load data from queue, make request instance and add handler
        """

        while self._data_queue and self._free_openers:
            request_data = self._data_queue.pop()
            opener = self._free_openers.pop()

            # Create request object
            self.configure_opener(opener, request_data)

            # Add configured opener to handles pool
            self._openers_pool.add_handle(opener)

    def process_pending_requests(self):
        """Process any requests that were completed by the last
        call to multi.socket_action.
        """
        while True:
            try:
                num_queued, success_list, error_list = self._openers_pool.info_read()
            except Exception, e:
                logger.warn(e)
                raise CurlError(e[0], e[1])

            for opener in success_list:
                opener.fp = None
                self._openers_pool.remove_handle(opener)

                # Make `Response` object from opener
                response = self.make_response(opener)
                opener.success_callback(response=response,
                                        async_client=self, opener=opener)
                ## FIXME: after pycurl.MultiCurl reset error
                ## opener.dirty = True
                self._free_openers.append(opener)

            for opener, errno, errmsg in error_list:
                opener.fp = None
                self._openers_pool.remove_handle(opener)

                opener.fail_callback(errno=errno, errmsg=errmsg,
                                     async_client=self, opener=opener,
                                     request=opener.request)
                ## FIXME: after pycurl.MultiCurl reset error
                ## opener.dirty = True
                self._free_openers.append(opener)


            success_len = len(success_list)
            error_len = len(error_list)

            self.num_processed = self.num_processed + success_len + error_len
            self._remaining -= success_len + error_len

            if self._process_func:
                self._process_func(num_processed=self.num_processed, remaining=self._remaining,
                                  num_urls=self._num_urls, success_len=success_len,
                                  error_len=error_len)

            if num_queued == 0:
                break

    def cleanup_pool(self):
        """Close all fp, clean objects

        :param openers_pool:
        """
        if not self._openers_pool:
            return None

        for opener in self._openers_pool.handles:
            if opener.fp is not None:
                opener.fp.close()
                opener.fp = None
            opener.close()

        self._openers_pool.close()

    def method(self, method, **kwargs):
        """Added request params to data_queue

        :param method: request method
        :return self: :class:`AsyncClient` object
        """
        if 'url' not in kwargs:
            raise InterfaceError("You need specify url param")

        self.add_handler(method=method, **kwargs)

        # Return self to make chain calls
        return self

    def get(self, url, **kwargs):
        return self.method("get", url=url, **kwargs)

    def post(self, url, data='', **kwargs):
        return self.method("post", url=url, data=data, **kwargs)

    def head(self, url, **kwargs):
        return self.method("head", url=url, **kwargs)

    def options(self, url, **kwargs):
        return self.method("options", url=url, **kwargs)

    def put(self, url, **kwargs):
        return self.method("put", url=url, **kwargs)

    def delete(self, url, **kwargs):
        return self.method("delete", url=url, **kwargs)

    def __del__(self):
        """ Close deascriptors after object delete
        """
        self.cleanup_pool()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        logger.debug((exc_type, exc_value, traceback))
        self.start()


def default_success_callback(response, async_client, opener, **kwargs):
    """Default callback for collect `Response` objects

    :param response: :class:`Response` object
    :param async_client: :class:`AsyncClient` object
    :param opener: :class:`pycurl.Curl` object
    """

    async_client.responses.append(response)

def default_fail_callback(request, errno, errmsg, async_client, opener):
    """Default callback for collect fails

    :param request: :class:`Request` object
    :param errno: error number code
    :param errmsg: error message
    :param async_client: :class:`AsyncClient` object
    :param opener: :class:`pycurl.Curl` object
    """

async_client = AsyncClient(success_callback=default_success_callback,
                           fail_callback=default_fail_callback)


def map(requests):
    """
    :param requests: iterate methods
    """
    if not requests:
        return []
    requests = [request for request in requests]
    async_client.start()
    return async_client.responses


# Make aliases
get = async_client.get
put = async_client.put
post = async_client.post
delete = async_client.delete
head = async_client.head
options = async_client.options

########NEW FILE########
__FILENAME__ = auth
#!/usr/bin/env python
# -*- coding:  utf-8 -*-

"""
human_curl.auth
~~~~~~~~~~~~~~~

Authentication module for human curl

:copyright: (c) 2011 - 2012 by Alexandr Lispython (alex@obout.ru).
:license: BSD, see LICENSE for more details.
"""
import binascii
import hmac
from types import StringTypes, ListType

try:
    import pycurl2 as pycurl
except ImportError:
    import pycurl

from urllib import urlencode

import methods as hurl
from .exceptions import InterfaceError
from .utils import *


try:
    from hashlib import sha1
    sha = sha1
except ImportError:
    # hashlib was added in Python 2.5
    import sha


class AuthManager(object):
    """Auth manager base class
    """

    def __init__(self):
        self._parent_request = None
        self._debug = None

    def setup(self, curl_opener):
        raise NotImplementedError

    def setup_request(self, request):
        """Setup parent request for current auth manager
        """
        self._parent_request = request
        if hasattr(request, '_debug_curl'):
            self._debug = request._debug_curl


class BasicAuth(AuthManager):
    """Basic Auth manager

    HTTP Basic authentication
    """

    def __init__(self, username=None, password=None, *args, **kwargs):
        super(BasicAuth, self).__init__(*args, **kwargs)
        if not username or not password:
            raise InterfaceError("Basic auth required username and password")

        self._username = username
        self._password = password

    def setup(self, curl_opener):
        """Setup BasicAuth for opener
        """
        curl_opener.setopt(pycurl.HTTPAUTH, pycurl.HTTPAUTH_BASIC)
        curl_opener.setopt(pycurl.USERPWD, "%s:%s" % (self._username, self._password))


class DigestAuth(BasicAuth):
    """Digest auth manager

    HTTP Digest authentication manager
    full support of qop == auth and part of qop == auth-int
    auth-int don't create HA1 with entity body
    """

    def __init__(self, username=None, password=None, *args, **kwargs):
        super(DigestAuth, self).__init__(username, password, *args, **kwargs)

    def setup(self, curl_opener):
        """Setup auth method for curl opener
        """
        curl_opener.setopt(pycurl.HTTPAUTH, pycurl.HTTPAUTH_DIGEST)
        curl_opener.setopt(pycurl.USERPWD, "%s:%s" % (self._username,
                                                      self._password))


DEFAULT_OAUTH_VERSION = '1.0' #OAUHT 2.0


class SignatureMethod(object):
    """A way of signing requests.

    The OAuth protocol lets consumers and service providers pick a way to sign
    requests. This interface shows the methods expected by the other `oauth`
    modules for signing requests. Subclass it and implement its methods to
    provide a new way to sign requests.
    """

    def signing_base(self, request, consumer_secret, token_secret):
        """Calculates the string that needs to be signed.

        This method returns a 2-tuple containing the starting key for the
        signing and the message to be signed. The latter may be used in error
        messages to help clients debug their software.

        """
        raise NotImplementedError

    def sign(self, request, consumer_secret, token_secret):
        """Returns the signature for the given request, based on the consumer
        and token_secret also provided.

        You should use your implementation of `signing_base()` to build the
        message to sign. Otherwise it may be less useful for debugging.

        """
        raise NotImplementedError

    def check(self, request, consumer_secret, token_secret, signature):
        """Returns whether the given signature is the correct signature for
        the given consumer and token signing the given request."""
        built = self.sign(request, consumer_secret, token_secret)
        return built == signature


class SignatureMethod_HMAC_SHA1(SignatureMethod):
    name = 'HMAC-SHA1'

    def signing_base(self, request, consumer_secret, token_secret=None):
        if not request.get('normalized_url') or request.get('method') is None:
            raise ValueError("Base URL for request is not set.")

        sig = (
            url_escape(request['method']),
            url_escape(request['normalized_url']),
            url_escape(request['normalized_parameters']),
        )

        key = '%s&' % url_escape(consumer_secret)
        if token_secret:
            key += url_escape(token_secret)

        raw = '&'.join(sig)
        return key, raw

    def sign(self, request, consumer_secret, token_secret=None):
        """Builds the base signature string.
        """
        key, raw = self.signing_base(request, consumer_secret, token_secret)

        hashed = hmac.new(key, raw, sha)

        # Calculate the digest base 64.
        return binascii.b2a_base64(hashed.digest())[:-1]


class SignatureMethod_PLAINTEXT(SignatureMethod):
    """OAuth PLAINTEXT signature

    oauth_signature is set to the concatenated encoded values
    of the Consumer Secret and Token Secret, separated by a ‘&’ character
    (ASCII code 38), even if either secret is empty. The result MUST be encoded again.
    """

    name = 'PLAINTEXT'

    def signing_base(self, request, consumer_secret, token_secret):
        """Concatenates the consumer key and secret with the token's secret.
        """

        sig = '%s&' % url_escape(consumer_secret)
        if token_secret:
            sig = sig + url_escape(token_secret)
        return sig, sig

    def sign(self, request, consumer_secret, token_secret):
        key, raw = self.signing_base(request, consumer_secret, token_secret)
        return url_escape(raw)


class OAuthAuthorization(Authorization):
    """OAuth authorization header value
    """

    REQUIRED_FIELDS = ('oauth_consumer', 'oauth_nonce', 'oauth_signature', 'oauth_signature_method',
                       'oauth_timestamp')

    def __init__(self, data=None):
        super(OAuthAuthorization, self).__init__('OAuth', data)

    oauth_consumer = property(lambda x: x.get('oauth_consumer'), doc='''
    ''')
    oauth_token = property(lambda x: x.get('oauth_token'), doc='''
    ''')
    oauth_signature_method = property(lambda x: x.get('oauth_signature_method'), doc='''
    ''')

    oauth_signature = property(lambda x: x.get('oauth_signature'), doc='''
    ''')
    oauth_timestamp = property(lambda x: x.get('oauth_timestamp'), doc='''
    ''')

    oauth_nonce = property(lambda x: x.get('oauth_nonce'), doc='''
    ''')
    oauth_version = property(lambda x: x.get('oauth_version'), doc='''
    ''')


class OAuthToken(object):
    """OAuth token wrapper

    Request Token:
    Used by the Consumer to ask the User to authorize access
    to the Protected Resources. The User-authorized Request Token is exchanged
    for an Access Token, MUST only be used once, and MUST NOT
    be used for any other purpose. It is RECOMMENDED that Request Tokens
    have a limited lifetime.

    Access Token:
    Used by the Consumer to access the Protected Resources
    on behalf of the User. Access Tokens MAY limit access to certain
    Protected Resources, and MAY have a limited lifetime.
    Service Providers SHOULD allow Users to revoke Access Tokens.
    Only the Access Token SHALL be used to access the Protect Resources.
    """

    def __init__(self, key, secret):
        self._key = key
        self._secret = secret
        self._callback = None
        self._callback_confirmed = None
        self._verifier = None

        if self._key and self._secret:
            # ready for request to protected resources
            self._state = 7
        else:
            self._state = 1

    @property
    def state(self):
        return self._state


class OAuthConsumer(object):
    """Registered application that uses OAuth to access the
    Service Provider on behalf of the User.

    """

    def __init__(self, key, secret):
        # A value used by the Consumer to identify itself to the Service Provider.
        self._key = key
        # A secret used by the Consumer to establish ownership of the Consumer Key.
        self._secret = secret

        if key is None or secret is None:
            raise ValueError("Key and secret must be set.")


class OAuthManager(AuthManager):
    """Auth manager for OAuth
    """

    SIGNATURES_METHODS = {
        # 'RSA-SHA1': SignatureMethod_RSA_SHA1
        'HMAC-SHA1': SignatureMethod_HMAC_SHA1,
        'PLAINTEXT': SignatureMethod_PLAINTEXT}

    def __init__(self, consumer, token=None, request_token_url=None,
                 authorize_url=None, access_token_url=None, signature_method=None,
                 version=DEFAULT_OAUTH_VERSION):

        if isinstance(consumer, OAuthConsumer):
            self._consumer = consumer
        else:
            self._consumer = OAuthConsumer(*consumer)

        if isinstance(token, OAuthToken):
            self._token = token
        elif token is None:
            self._token = None
        else:
            self._token = OAuthToken(*token)


        if isinstance(signature_method, SignatureMethod):
            self._signature_method = signature_method
        elif signature_method is None:
            self._signature_method = SignatureMethod_PLAINTEXT()
        elif isinstance(signature_method, StringTypes):
            if signature_method.upper() in self.SIGNATURES_METHODS.keys():
                self._signature_method = self.SIGNATURES_METHODS[signature_method.upper()]()
            else:
                raise RuntimeError('Unknown signature method')
        elif issubclass(signature_method, SignatureMethod):
            self._signature_method = signature_method()
        else:
            raise RuntimeError('Unknown signature method')


        # if consumer key, secret specified and tokens secret, key
        # 3 if tmp_token and tmp_token_secret is given
        # 5 if verifier
        # 7 if token_key and token_secret
        self._state = self._token.state if self._token else 1
        self._realm = None

        self._verifier = None

        # oauth challenge urls
        self._request_token_url = request_token_url
        self._authorize_url = authorize_url
        self._access_token_url = access_token_url

        self._version = version
        if self._state == 1 and (not self._request_token_url or
                                 not self._authorize_url or
                                 not self._access_token_url):
            raise RuntimeError('Challenge urls required if state is 1')

        self._parent_request = None
        self._debug = None

        self._tmp_token_key = None
        self._tmp_token_secret = None

    @property
    def state(self):
        return self._state

    def verify(self, verifier):
        """Verify access request
        """
        self._verifier = verifier
        self._state = 5

    def auth_header(self, realm=None):
        params = {
            'oauth_consumer_key': self._consumer._key,
            'oauth_timestamp': generate_timestamp(),
            'oauth_signature_method': self._signature_method.name,
            'oauth_nonce': generate_nonce(),
            'oauth_version': str(self._version),
            'oauth_token': self._token._key,
            'realm': realm or normalize_url(self._parent_request._build_url())
            }

        params['oauth_signature'] = self._signature_method.sign({
            'method': self._parent_request._method.upper(),
            'normalized_url': normalize_url(self._parent_request._build_url()),
            'normalized_parameters': normalize_parameters(self._parent_request._build_url())},
                                                                self._consumer._secret, self._token._secret)
        return Authorization('OAuth', params)


    def access_request(self):
        """Create request to access token endpoint
        """
        params = {
            'oauth_verifier': self._verifier,
            'oauth_token': self._tmp_token_key,
            'oauth_consumer_key': self._consumer._key,
            'oauth_timestamp': generate_timestamp(),
            'oauth_signature_method': self._signature_method.name,
            'oauth_nonce': generate_nonce(),
            'oauth_version': str(self._version),
            'realm': normalize_url(self._access_token_url)}

        params['oauth_signature'] = self._signature_method.sign({
            'method': 'POST',
            'normalized_url': normalize_url(self._access_token_url),
            'normalized_parameters': normalize_parameters(self._access_token_url)
            }, self._consumer._secret, self._tmp_token_secret)

        r = hurl.post(self._access_token_url,
                      data=urlencode(params), debug = self._debug)

        ## r = hurl.post(self._access_token_url,
        ##               headers={"Authorization": str(OAuthAuthorization(params))},
        ##               debug=self._debug)

        if r.status_code in (200, 201):
            tokens = parse_qs(r.content)
            self._token = OAuthToken(tokens['oauth_token'][0], tokens['oauth_token_secret'][0])
            self._state = 7

    def request_token(self):
        """Send request to request_token endpoint
        """

        params = {
            'oauth_consumer_key': self._consumer._key,
            'oauth_timestamp': generate_timestamp(),
            'oauth_signature_method': self._signature_method.name,
            'oauth_nonce': generate_nonce(),
            'oauth_version': str(self._version),
            'realm': normalize_url(self._request_token_url)}

        params['oauth_signature'] = self._signature_method.sign({
            'method': 'POST',
            'normalized_url': normalize_url(self._request_token_url),
            'normalized_parameters': normalize_parameters(self._request_token_url)},
                                                                self._consumer._secret, None)

        r = hurl.post(self._request_token_url,
                      data=urlencode(params), debug=self._debug)

        ## r = hurl.post(self._request_token_url,
        ##             headers={"Authorization": str(OAuthAuthorization(params))},
        ##             debug=self._debug)

        if r.status_code in (200, 201):
            tokens = parse_qs(r.content)
            self._tmp_token_key = tokens['oauth_token'][0]
            self._tmp_token_secret = tokens['oauth_token_secret'][0]
            self._state = 3 # oauth_token and oauth_secret is given

    @property
    def confirm_url(self):
        return "%s?oauth_token=%s" % (self._authorize_url, self._tmp_token_key)

    def setup(self, curl_opener):
        if self._state == 7:
            if isinstance(self._parent_request._headers, ListType):
                self._parent_request._headers.append(('Authorization', str(self.auth_header())))
            else:
                self._parent_request._headers = data_wrapper({'Authorization': str(self.auth_header())})
            ## curl_opener.setopt(pycurl.HTTPHEADER, ["%s: %s" % (capwords(f, "-"), v) for f, v
            ##                                   in CaseInsensitiveDict(self._parent_request._headers).iteritems()])
            #curl_opener.setopt(pycurl.HEADER, {'Authorization': str(self.auth_header())})
        else:
            raise AuthError('OAuth require token_key and token_secret')

########NEW FILE########
__FILENAME__ = compat
"""
human_curl.compat
~~~~~~~~~~~~~~~~~

Compatibility module

:copyright: (c) 2012 by Alexandr Lispython (alex@obout.ru).
:license: BSD, see LICENSE for more details.
"""


try:
    import simplejson as json
except ImportError:
    import json

########NEW FILE########
__FILENAME__ = core
#!/usr/bin/env python
# -*- coding:  utf-8 -*-
"""
human_curl.core
~~~~~~~~~~~~~~~

Heart of human_curl library


:copyright: Copyright 2011 - 2012 by Alexandr Lispython (alex@obout.ru).
:license: BSD, see LICENSE for more details.
"""

import time
from os.path import exists as file_exists
from logging import getLogger
from re import compile as re_compile
from string import capwords
from urllib import urlencode, quote_plus
from cookielib import CookieJar
from itertools import chain
from urlparse import urlparse, urljoin, urlunparse, parse_qsl
from types import (StringTypes, TupleType, DictType, NoneType,
                   ListType, FunctionType)

try:
    import pycurl2 as pycurl
except ImportError:
    import pycurl
from . import get_version
from .compat import json
from .auth import AuthManager, BasicAuth
from .exceptions import (InvalidMethod, CurlError, InterfaceError)
from .utils import (decode_gzip, CaseInsensitiveDict, to_cookiejar,
                    morsel_to_cookie, data_wrapper, make_curl_post_files,
                    to_unicode, logger_debug, urlnoencode)


from StringIO import StringIO

try:
    import platform
    if platform.system().lower() != 'windows':
        import signal
        from threading import current_thread
        if current_thread().name == 'MainThread':
            signal.signal(signal.SIGPIPE, signal.SIG_IGN)
except ImportError:
    pass


__all__ = ("Request", "Response", "HTTPError", "InvalidMethod", "CurlError", "CURL_INFO_MAP")

logger = getLogger("human_curl.core")

# DEFAULTS
DEFAULT_TIME_OUT = 15.0
STATUSES_WITH_LOCATION = (301, 302, 303, 305, 307)
PYCURL_VERSION_INFO = pycurl.version_info()
HTTP_GENERAL_RESPONSE_HEADER = re_compile(r"(?P<version>HTTP\/.*?)\s+(?P<code>\d{3})\s+(?P<message>.*)")

try:
    CURL_VERSION = PYCURL_VERSION_INFO[1]
except IndexError, e:
    CURL_VERSION = ""
    logger.warn("Unknown pycURL / cURL version")


PROXIES_TYPES_MAP = {
    'socks5': pycurl.PROXYTYPE_SOCKS5,
    'socks4': pycurl.PROXYTYPE_SOCKS4,
    'http': pycurl.PROXYTYPE_HTTP,
    'https': pycurl.PROXYTYPE_HTTP}


# FULL LIST OF GETINFO OPTIONS
CURL_INFO_MAP = {
    # timers
    # An overview of the six time values available from curl_easy_getinfo()
    # perform() --> NAMELOOKUP --> CONNECT --> APPCONNECT
    # --> PRETRANSFER --> STARTTRANSFER --> TOTAL --> REDIRECT
    "TOTAL_TIME": pycurl.TOTAL_TIME,
    "NAMELOOKUP_TIME": pycurl.NAMELOOKUP_TIME,
    "CONNECT_TIME": pycurl.CONNECT_TIME,
    "APPCONNECT_TIME": pycurl.APPCONNECT_TIME,
    "PRETRANSFER_TIME": pycurl.PRETRANSFER_TIME,
    "STARTTRANSFER_TIME": pycurl.STARTTRANSFER_TIME,
    "REDIRECT_TIME": pycurl.REDIRECT_TIME,
    "HTTP_CODE": pycurl.HTTP_CODE,
    "REDIRECT_COUNT": pycurl.REDIRECT_COUNT,
    "REDIRECT_URL": pycurl.REDIRECT_URL,
    "SIZE_UPLOAD": pycurl.SIZE_UPLOAD,
    "SIZE_DOWNLOAD": pycurl.SIZE_DOWNLOAD,
    "SPEED_DOWNLOAD": pycurl.SPEED_DOWNLOAD,
    "SPEED_UPLOAD": pycurl.SPEED_UPLOAD,
    "HEADER_SIZE": pycurl.HEADER_SIZE,
    "REQUEST_SIZE": pycurl.REQUEST_SIZE,
    "SSL_VERIFYRESULT": pycurl.SSL_VERIFYRESULT,
    "SSL_ENGINES": pycurl.SSL_ENGINES,
    "CONTENT_LENGTH_DOWNLOAD": pycurl.CONTENT_LENGTH_DOWNLOAD,
    "CONTENT_LENGTH_UPLOAD": pycurl.CONTENT_LENGTH_UPLOAD,
    "CONTENT_TYPE": pycurl.CONTENT_TYPE,

    "HTTPAUTH_AVAIL": pycurl.HTTPAUTH_AVAIL,
    "PROXYAUTH_AVAIL": pycurl.PROXYAUTH_AVAIL,
    "OS_ERRNO": pycurl.OS_ERRNO,
    "NUM_CONNECTS": pycurl.NUM_CONNECTS,
    "PRIMARY_IP": pycurl.PRIMARY_IP,
    "CURLINFO_LASTSOCKET": pycurl.LASTSOCKET,
    "EFFECTIVE_URL": pycurl.EFFECTIVE_URL,
    "INFO_COOKIELIST": pycurl.INFO_COOKIELIST,
    "RESPONSE_CODE": pycurl.RESPONSE_CODE,
    "HTTP_CONNECTCODE": pycurl.HTTP_CONNECTCODE,
    # "FILETIME": pycurl.FILETIME
    # "PRIVATE": pycurl.PRIVATE, # (Added in 7.10.3)
    # "CERTINFO": pycurl.CERTINFO,
    # "PRIMARY_PORT": pycurl.PRIMARY_PORT,
    }


def get_code_by_name(name):
    """Returns proxy type code
    """
    return PROXIES_TYPES_MAP[name]


class Request(object):
    r"""A single HTTP / HTTPS requests

    Usage:

    >>> request = Request("GET", "http://google.com")
    >>> print(repr(request))
    <Request: GET [ http://google.com ]>
    >>> request.send()
    >>> response = requests.response
    """

    SUPPORTED_METHODS = ("GET", "HEAD", "POST", "DELETE", "PUT", "OPTIONS")

    def __init__(self, method, url, params=None, data=None, headers=None, cookies=None,
                 files=None, timeout=None, connection_timeout=None, allow_redirects=False,
                 max_redirects=5, proxy=None, auth=None, network_interface=None, use_gzip=None,
                 validate_cert=False, ca_certs=None, cert=None, debug=False, user_agent=None,
                 ip_v6=False, options=None, netrc=False, netrc_file=None, encode_query=None, **kwargs):
        """A single HTTP / HTTPS request

        Arguments:
        - `url`: (string) resource url
        - `method`: (string) one of `self.SUPPORTED_METHODS`
        - `data`: (dict, duple, string) data to send as Content-Disposition form-data
        - `params`: (dict, tuple) of GET params (?param1=value1&param2=value2)
        - `headers`: (dict, tuple) of request headers
        - `cookies`: (dict, tuple or CookieJar) of cookies
        - `files`: (dict, tuple or list) of files
           Example:
               (('field_file_name', '/path/to/file.txt'),
               ('field_file_name', open('/path/to/file.txt')),
               ('multiple_files_field', (open("/path/to/file.1.txt"), open("/path/to/file.1.txt"))),
               ('multiple_files_field', ("/path/to/file.1.txt", "/path/to/file.1.txt")))
        - `timeout`: (float) connection time out
        - `connection_timeout`: (float)
        - `allow_redirects`: (bool) follow redirects parametr
        - `proxy`: (dict, tuple or list) of proxies
           Examples:
               ('http', ('127.0.0.1', 9050))
               ('http', ('127.0.0.1', 9050, ('username', 'password')))
        - `auth`: (dict, tuple or list) for resource base auth
        - `network_interface`: (str) Pepform an operation using a specified interface.
           You can enter interface name, IP address or host name.
        - `use_gzip`: (bool) accept gzipped data
        - `validate_cert`: (bool) validate server certificate
        - `ca_certs`: tells curl to use the specified certificate file to verify the peer.
        - `cert`: (string) tells curl to use the specified certificate file
           when getting a file with HTTPS.
        - `debug`: (bool) use for `pycurl.DEBUGFUNCTION`
        - `user_agent`: (string) user agent
        - `ip_v6`: (bool) use ipv6 protocol
        - `options`: (tuple, list) low level pycurl options using
        """
        self._url = url
        if not method or not isinstance(method, StringTypes):
            raise InterfaceError("method argument must be string")

        if method.upper() not in self.SUPPORTED_METHODS:
            raise InvalidMethod("cURL do not support %s method" % method.upper())

        self._method = method.upper()

        self._user_agent = user_agent

        self._headers = data_wrapper(headers)

        if files is not None:
            self._files = make_curl_post_files(files)
        else:
            self._files = None

        self._params = data_wrapper(params)

        # String, dict, tuple, list
        if isinstance(data, (StringTypes, NoneType)):
            self._data = data
        else:
            self._data = data_wrapper(data)

        if isinstance(cookies, CookieJar):
            self._cookies = cookies
        elif isinstance(cookies, (TupleType, DictType)):
            self._cookies = to_cookiejar(cookies)
        else:
            self._cookies = None

        if isinstance(proxy, NoneType):
            self._proxy = proxy
        elif isinstance(proxy, TupleType):
            if len(proxy) != 2 or not isinstance(proxy[1], TupleType):
                raise InterfaceError('Proxy must be a tuple object')
            else:
                self._proxy = proxy

        if not isinstance(network_interface, (StringTypes, NoneType)):
            raise InterfaceError("Network interface argument must be string or None")

        self._network_interface = network_interface

        if isinstance(auth, AuthManager):
            self._auth = auth
        elif isinstance(auth, TupleType):
            self._auth = BasicAuth(*auth)
        elif auth is None:
            self._auth = None
        else:
            raise ValueError("auth must be list, tuple or dict, not %s" % type(auth))

        # follow by location header field
        self._allow_redirects = allow_redirects
        self._max_redirects = max_redirects

        self._timeout = int(timeout or DEFAULT_TIME_OUT)
        self._connection_timeout = connection_timeout

        self._use_gzip = use_gzip

        # Certificates
        self._validate_cert = validate_cert
        self._ca_certs = ca_certs
        self._cert = cert
        self._start_time = time.time()
        self._debug_curl = debug
        self._ip_v6 = ip_v6

        self.response = None

        if options is None:
            self._options = None
        elif isinstance(options, (ListType, TupleType)):
            self._options = data_wrapper(options)
        else:
            raise InterfaceError("options must be None, ListType or TupleType")

        self._curl = None

        self.body_output = StringIO()
        self.headers_output = StringIO()

        self._netrc = netrc
        self._netrc_file = None

        self._encode_query = encode_query

    def __repr__(self, ):
        # TODO: collect `Request` settings into representation string
        return "<%s: %s [ %s ]>" % (self.__class__.__name__, self._method, self._url)

    @property
    def user_agent(self):
        if not self._user_agent:
            self._user_agent = "Mozilla/5.0 (compatible; human_curl; {0}; +http://h.wrttn.me/human_curl)".format(get_version())
        return self._user_agent

    @property
    def url(self):
        if not self._url:
            self._url = self._build_url()
        return self._url

    def _build_url(self):
        """Build resource url

        Parsing ``self._url``, add ``self._params`` to query string if need

        :return self._url: resource url
        """
        scheme, netloc, path, params, query, fragment = urlparse(self._url)

        # IDN domains support
        netloc = to_unicode(netloc).encode('idna')

        if not netloc:
            raise ValueError("Invalid url")
        elif not scheme:
            scheme = "http"

        tmp = []
        if self._params is not None:
            for param, value in self._params:
                if isinstance(value, TupleType):
                    for i in value:
                        tmp.append((param, i))
                elif isinstance(value, StringTypes):
                    tmp.append((param, value))

        if tmp:
            tmp = parse_qsl(query) + tmp
        else:
            tmp = parse_qsl(query)

        if self._encode_query:
            query = urlencode(tmp)
        else:
            query = urlnoencode(tmp)

        del tmp

        self._url = urlunparse([scheme, netloc, path, params, query, fragment])

        return self._url

    def send(self):
        """Send request to self._url resource

        :return: `Response` object
        """

        try:
            opener = self.build_opener(self._build_url())
            opener.perform()
            # if close before getinfo, raises pycurl.error can't invote getinfo()
            # opener.close()
        except pycurl.error, e:
            raise CurlError(e[0], e[1])
        else:
            self.response = self.make_response()

        return self.response

    def make_response(self):
        """Make response from finished opener

        :return response: :class:`Response` object
        """
        response = Response(url=self._url, curl_opener=self._opener,
                            body_output=self.body_output,
                            headers_output=self.headers_output, request=self,
                            cookies=self._cookies)
        try:
            response.parse_cookies()
        except Exception, e:
            logger.error(e, exc_info=True)
        return response

    def setup_writers(self, opener, headers_writer, body_writer):
        """Setup headers and body writers

        :param opener: :class:`pycurl.Curl` object
        :param headers_writer: `StringIO` object
        :param body_writer: `StringIO` object
        """
        # Body and header writers
        opener.setopt(pycurl.HEADERFUNCTION, headers_writer)
        opener.setopt(pycurl.WRITEFUNCTION, body_writer)

    def setup_netrc(self, opener):
        """Setup netrc file

        :paramt opener: :class:`pycurl.Curl` object
        """
        if self._netrc:
            opener.setopt(pycurl.NETRC, 1)

        if self._netrc_file and file_exists(self._netrc_file):
            opener.setopt(pycurl.NETRC_FILE, self._netrc_file)


    @staticmethod
    def clean_opener(opener):
        """Reset opener options

        :param opener: :class:`pycurl.Curl` object
        :return opener: clean :`pycurl.Curl` object
        """
        opener.reset()
        return opener


    def build_opener(self, url, opener=None):
        """Compile pycurl.Curl instance

        Compile `pycurl.Curl` instance with given instance settings
        and return `pycurl.Curl` configured instance, StringIO instances
        of body_output and headers_output

        :param url: resource url
        :return: an ``(opener, body_output, headers_output)`` tuple.
        """
        # http://curl.haxx.se/mail/curlpython-2005-06/0004.html
        # http://curl.haxx.se/mail/lib-2010-03/0114.html

        opener = opener or pycurl.Curl()

        if getattr(opener, "dirty", True):
            opener = self.clean_opener(opener)

        logger.debug("Open url: %s" % url)
        opener.setopt(pycurl.URL, url)
        opener.setopt(pycurl.NOSIGNAL, 1)


        if isinstance(self._auth, AuthManager):
            self._auth.setup_request(self)
            self._auth.setup(opener)
        elif self._netrc:
            self.setup_netrc(opener)
        else:
            opener.unsetopt(pycurl.USERPWD)

        if self._headers:
            logger.debug("Setup custom headers %s" %
                         "\r\n".join(["%s: %s" % (f, v) for f, v
                                      in CaseInsensitiveDict(self._headers).iteritems()]))
            opener.setopt(pycurl.HTTPHEADER, ["%s: %s" % (capwords(f, "-"), v) for f, v
                                              in CaseInsensitiveDict(self._headers).iteritems()])

        # Option -L  Follow  "Location: "  hints
        if self._allow_redirects is True:
            logger.debug("Allow redirects")
            opener.setopt(pycurl.FOLLOWLOCATION, self._allow_redirects)
            if self._max_redirects:
                opener.setopt(pycurl.MAXREDIRS, self._max_redirects)

        # Set timeout for a retrieving an object
        if self._timeout is not None:
            logger.debug("Set timeout: %s" % self._timeout)
            opener.setopt(pycurl.TIMEOUT, self._timeout)
        if self._connection_timeout is not None:
            logger.debug("Set connect timeout: %s" % self._timeout)
            opener.setopt(pycurl.CONNECTTIMEOUT, self._connection_timeout)

        # Setup debug output write function
        if isinstance(self._debug_curl, FunctionType):
            logger.debug("Setup %s as debug function" % self._debug_curl.__name__)
            opener.setopt(pycurl.VERBOSE, 1)
            opener.setopt(pycurl.DEBUGFUNCTION, self._debug_curl)
        elif self._debug_curl is True:
            opener.setopt(pycurl.VERBOSE, 1)
            opener.setopt(pycurl.DEBUGFUNCTION, logger_debug)
        else:
            opener.setopt(pycurl.VERBOSE, 0)

        # Send allow gzip encoding header
        if self._use_gzip is not None:
            logger.debug("Use gzip")
            opener.setopt(pycurl.ENCODING, "gzip,deflate")

        # Specify network interface (ip address) for query
        if self._network_interface is not None:
            logger.debug("Use custom network interface %s" % self._network_interface)
            opener.setopt(pycurl.INTERFACE, self._network_interface)

        # Setup proxy for request
        if self._proxy is not None:
            logger.debug("Use proxies %s - %s" % self._proxy)
            if len(self._proxy) > 2:
                proxy_type, proxy_addr, proxy_auth = self._proxy
            else:
                proxy_type, proxy_addr = self._proxy
                proxy_auth = None

            opener.setopt(pycurl.PROXY, proxy_addr[0])
            opener.setopt(pycurl.PROXYPORT, proxy_addr[1])
            opener.setopt(pycurl.PROXYTYPE, get_code_by_name(proxy_type))

            if proxy_type.upper() in ("CONNECT", "SSL", "HTTPS"):
                # if CONNECT proxy, need use HTTPPROXYTINNEL
                opener.setopt(pycurl.HTTPPROXYTUNNEL, 1)
            if proxy_auth:
                if len(proxy_auth) == 2:
                    opener.setopt(pycurl.PROXYUSERPWD, "%s:%s" % proxy_auth)
                else:
                    raise InterfaceError("Proxy auth data must be tuple")

        logger.debug("Setup user agent %s" % self.user_agent)
        opener.setopt(pycurl.USERAGENT, self.user_agent)

        if self._validate_cert not in (None, False):
            logger.debug("Validate certificate")
            # Verify that we've got the right site; harmless on a non-SSL connect.
            opener.setopt(pycurl.SSL_VERIFYPEER, 1)
            opener.setopt(pycurl.SSL_VERIFYHOST, 2)
        else:
            opener.setopt(pycurl.SSL_VERIFYPEER, 0)
            opener.setopt(pycurl.SSL_VERIFYHOST, 0)

        if self._ca_certs is not None:
            logger.debug("Use ca cert %s" % self._ca_certs)
            if file_exists(self._ca_certs):
                opener.setopt(pycurl.CAINFO, self._ca_certs)

        ## (HTTPS) Tells curl to use the specified certificate file when getting a
        ## file with HTTPS. The certificate must be in PEM format.
        ## If the optional password isn't specified, it will be queried for on the terminal.
        ## Note that this certificate is the private key and the private certificate concatenated!
        ## If this option is used several times, the last one will be used.
        if self._cert:
            opener.setopt(pycurl.SSLCERT, self._cert)

        if self._ip_v6:
            opener.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_WHATEVER)
        else:
            opener.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_V4)

        # opener.setopt(c.NOPROGRESS, 0)
        # opener.setopt(c.PROGRESSFUNCTION, self._progress_callback)

        # Add cookies from self._cookies
        if self._cookies is not None:
            chunks = []
            for cookie in self._cookies:
                name, value = cookie.name, cookie.value
                ## if isinstance(name, unicode):
                ##     name = name.encode("utf-8")
                ## if isinstance(value, unicode):
                ##     value = value.encode("utf-8")
                name = quote_plus(name)
                value = quote_plus(value)
                chunks.append('%s=%s;' % (name, value))
            if chunks:
                opener.setopt(pycurl.COOKIE, ''.join(chunks))
        else:
            # set empty cookie to activate cURL cookies
            opener.setopt(pycurl.COOKIELIST, '')

        curl_options = {
            "GET": pycurl.HTTPGET,
            "POST": pycurl.POST,
            # "PUT": pycurl.UPLOAD,
            "PUT": pycurl.PUT,
            "HEAD": pycurl.NOBODY}

        logger.debug("Use method %s for request" % self._method)
        if self._method in curl_options.values():
            opener.setopt(curl_options[self._method], True)
        elif self._method in self.SUPPORTED_METHODS:
            opener.setopt(pycurl.CUSTOMREQUEST, self._method)
        else:
            raise InvalidMethod("cURL request do not support %s" %
                                self._method)

        # Responses without body
        if self._method in ("OPTIONS", "HEAD", "DELETE"):
            opener.setopt(pycurl.NOBODY, True)

        if self._method in ("POST", "PUT"):
            if self._files is not None:
                post_params = self._files
                if isinstance(self._data, (TupleType, ListType, DictType)):
                    post_params.extend(data_wrapper(self._data))
                opener.setopt(opener.HTTPPOST, post_params)
            else:
                if isinstance(self._data, StringTypes):
                    logger.debug(("self._data is string"))
                    logger.debug(("self._data", self._data))
                    request_buffer = StringIO(self._data)

                    # raw data for body request
                    opener.setopt(pycurl.READFUNCTION, request_buffer.read)
                    def ioctl(cmd):
                        logger.debug(("cmd", cmd))
                        if cmd == pycurl.IOCMD_RESTARTREAD:
                            request_buffer.seek(0)

                    opener.setopt(pycurl.IOCTLFUNCTION, ioctl)
                    if self._method == "PUT":
                        opener.setopt(pycurl.PUT, True)
                        opener.setopt(pycurl.INFILESIZE, len(self._data))
                    else:
                        opener.setopt(pycurl.POST, True)
                        opener.setopt(pycurl.POSTFIELDSIZE, len(self._data))
                elif isinstance(self._data, (TupleType, ListType, DictType)):
                    # use multipart/form-data;
                    opener.setopt(opener.HTTPPOST, data_wrapper(self._data))

                    # use postfields to send vars as application/x-www-form-urlencoded
                    # opener.setopt(pycurl.POSTFIELDS, encoded_data)

        if isinstance(self._options, (TupleType, ListType)):
            for key, value in self._options:
                opener.setopt(key, value)


        self.body_output = StringIO()
        self.headers_output = StringIO()

        self.setup_writers(opener, self.headers_output.write, self.body_output.write)

        self._opener = opener

        return opener


class Response(object):
    """Response object
    """

    def __init__(self, url, curl_opener, body_output, headers_output,
                 request=None, cookies=None):
        """
        Arguments:
        :param url: resource url
        :param curl_opener: :class:`pycurl.Curl` object
        :param body_output: :StringIO instance
        :param headers_output: :StringIO instance
        :param request: :class:`Request` instance
        :param cookies_jar: :class:`CookieJar` instance
        """

        # Requested url
        self._request_url = url
        self._url = None

        # Request object
        self._request = request

        # Response headers
        self._headers = None

        # Cookies dictionary
        self._cookies = None
        if isinstance(cookies, CookieJar):
            self._cookies_jar = cookies
        elif isinstance(cookies, (TupleType, DictType)):
            self._cookies_jar = to_cookiejar(cookies)
        else:
            self._cookies_jar = None

        # Seconds from request start to finish
        self.request_time = None
        self._curl_opener = curl_opener

        # StringIO object for response body
        self._body_otput = body_output
        # StringIO object for response headers
        self._headers_output = headers_output

        # :Response status code
        self._status_code = None

        # Unziped end decoded response body
        self._content = None

        # Redirects history
        self._history = []

        # list of parsed headers blocks
        self._headers_history = []

        # get data from curl_opener.getinfo before curl_opener.close()
        self._response_info = dict()
        self._get_curl_info()

        # not good call methods in __init__
        # it's really very BAD
        # DO NOT UNCOMMENT
        # self._parse_headers_raw()


    def __repr__(self):
        return "<%s: %s >" % (self.__class__.__name__, self.status_code)

    def _get_curl_info(self):
        """Extract info from `self._curl_opener` with getinfo()

        """
        for field, value in CURL_INFO_MAP.iteritems():
            try:
                field_data = self._curl_opener.getinfo(value)
            except Exception, e:
                logger.warn(e)
                continue
            else:
                self._response_info[field] = field_data
        self._url = self._response_info.get("EFFECTIVE_URL")
        return self._response_info

    @property
    def request(self):
        return self._request

    @property
    def url(self):
        if not self._url:
            self._get_curl_info()
        return self._url

    @property
    def status_code(self):
        if not self._status_code:
            self._status_code = int(self._curl_opener.getinfo(pycurl.HTTP_CODE))
        return self._status_code

    @property
    def cookiesjar(self):
        """Returns cookie jar object
        """
        if not self._cookies_jar:
            self._cookies_jar = CookieJar()
            # add cookies from self._cookies
        return self._cookies_jar

    @property
    def content(self):
        """Returns decoded self._content
        """
        import zlib
        if not self._content:
            if 'gzip' in self.headers.get('Content-Encoding', '') and \
                   'zlib' not in pycurl.version:
                try:
                    self._content = decode_gzip(self._body_otput.getvalue())
                except zlib.error:
                    pass
            else:
                self._content = self._body_otput.getvalue()
        return self._content

    @property
    def json(self):
        """Returns the json-encoded content of a response
        """
        try:
            return json.loads(self.content)
        except ValueError:
            return None

    @staticmethod
    def _split_headers_blocks(raw_headers):
        i = 0
        blocks = []
        for item in raw_headers.strip().split("\r\n"):
            if item.startswith("HTTP"):
                blocks.append([item])
                i = len(blocks) - 1
            elif item:
                blocks[i].append(item)
        return blocks

    def _parse_headers_raw(self):
        """Parse response headers and save as instance vars
        """
        def parse_header_block(raw_block):
            r"""Parse headers block

            Arguments:
            - `block`: raw header block

            Returns:
            - `headers_list`:
            """
            block_headers = []
            for header in raw_block:
                if not header:
                    continue
                elif not header.startswith("HTTP"):
                    field, value = map(lambda u: u.strip(), header.split(":", 1))
                    if field.startswith("Location"):
                        # maybe not good
                        if not value.startswith("http"):
                            value = urljoin(self.url, value)
                        self._history.append(value)
                    if value[:1] == value[-1:] == '"':
                        value = value[1:-1] # strip "
                    block_headers.append((field, value.strip()))
                elif header.startswith("HTTP"):
                    # extract version, code, message from first header
                    try:
                        version, code, message = HTTP_GENERAL_RESPONSE_HEADER.findall(header)[0]
                    except Exception, e:
                        logger.warn(e)
                        continue
                    else:
                        block_headers.append((version, code, message))
                else:
                    # raise ValueError("Wrong header field")
                    pass
            return block_headers

        raw_headers = self._headers_output.getvalue()

        for raw_block in self._split_headers_blocks(raw_headers):
            block = parse_header_block(raw_block)
            self._headers_history.append(block)

        last_header = self._headers_history[-1]
        self._headers = CaseInsensitiveDict(last_header[1:])

        if not self._history:
            self._history.append(self.url)


    def parse_cookies(self):
        from Cookie import SimpleCookie, CookieError

        if not self._headers_history:
            self._parse_headers_raw()

        # Get cookies from endpoint
        cookies = []
        for header in chain(*self._headers_history):
            if len(header) > 2:
                continue

            key, value = header[0], header[1]

            if key.lower().startswith("set-cookie"):

                try:
                    cookie = SimpleCookie()
                    cookie.load(value)
                    cookies.extend(cookie.values())

                    # update cookie jar
                    for morsel in cookie.values():
                        if isinstance(self._cookies_jar, CookieJar):
                            self._cookies_jar.set_cookie(morsel_to_cookie(morsel))
                except CookieError, e:
                    logger.warn(e)
        self._cookies = dict([(cookie.key, cookie.value) for cookie in cookies])
        return self._cookies

    @property
    def headers(self):
        """Returns response headers
        """
        if not self._headers:
            self._parse_headers_raw()
        return self._headers

    @property
    def cookies(self):
        """Returns list of BaseCookie object

        All cookies in list are ``Cookie.Morsel`` instance

        :return self._cookies: cookies list
        """
        if not self._cookies:
            self.parse_cookies()
        return self._cookies

    @property
    def history(self):
        """Returns redirects history list

        :return: list of `Response` objects
        """
        if not self._history:
            self._parse_headers_raw()
        return self._history

########NEW FILE########
__FILENAME__ = exceptions
#!/usr/bin/env python
# -*- coding:  utf-8 -*-
"""
human_curl.exceptions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Exceptions module for cURL for Humans

:copyright: Copyright 2011 by Alexandr Lispython (alex@obout.ru).
:license: BSD, see LICENSE for more details.
"""

from httplib import responses

__all__ = ("HTTPError", "InvalidMethod", "CurlError", "InterfaceError")

class HTTPError(Exception):
    """Exception for failed HTTP request

    :param code: HTTP error integer error code, e. g. 404
    :param message: error message string
    """
    def __init__(self, code, message=None):
        self.code = code
        message = message or responses.get(code, "Unknown")
        Exception.__init__(self, "%d: %s" % (self.code, message))

class InvalidMethod(Exception):
    """Exception raise if `Request.__init__()` get unsupported method
    """

class CurlError(Exception):
    """Exception raise when `pycurl.Curl` raise connection errors

    :param code: HTTP error integer error code, e. g. 404
    :param message: error message string
    """
    def __init__(self, code, message=None):
        self.code = code
        message = message or responses.get(code, "Unknown")
        Exception.__init__(self, "%d: %s" % (self.code, message))

class InterfaceError(Exception):
    """Raises when get not allowed parametr type
    or not allowed parameter
    """

class AuthError(Exception):
    """Raised by auth manager
    """

########NEW FILE########
__FILENAME__ = methods
# -*- coding:  utf-8 -*-
"""
human_curl.methods
~~~~~~~~~~~~~~~~~~

HTTP methods functions

:copyright: (c) 2011 by Alexandr Lispython (alex@obout.ru).
:license: BSD, see LICENSE for more details.
"""

from .core import Request
from .utils import dispatch_hook

__all__ = ("get", "put", "head", "delete", "post", "options", "request")


def request(method, url, params=None, data=None, headers=None, cookies=None,
            files=None, timeout=None, allow_redirects=False, max_redirects=5, proxy=None,
            auth=None, network_interface=None, use_gzip=None, validate_cert=False,
            ca_certs=None, cert=None, debug=False, user_agent=None, ip_v6=False,
            hooks=None, options=None, callback=None, return_response=True, encode_query=True, **kwargs):
    """Construct and sends a Request object. Returns :class `Response`.

    Arguments:

    - `url`: (string) resource url
    - `method`: (string) one of `self.SUPPORTED_METHODS`
    - `data`: (dict, duple, string) data to send as Content-Disposition form-data
    - `params`: (dict, tuple) of GET params (?param1=value1&param2=value2)
    - `headers`: (dict, tuple) of request headers
    - `cookies`: (dict, tuple or CookieJar) of cookies
    - `files`: (dict, tuple or list) of files
       Example:
           (('field_file_name', '/path/to/file.txt'),
           ('field_file_name', open('/path/to/file.txt')),
           ('multiple_files_field', (open("/path/to/file.1.txt"), open("/path/to/file.1.txt"))),
           ('multiple_files_field', ("/path/to/file.1.txt", "/path/to/file.1.txt")))
    - `timeout`: (float) connection time out
    - `connection_timeout`: (float)
    - `allow_redirects`: (bool) follow redirects parametr
    - `proxy`: (dict, tuple or list) of proxies
       Examples:
           ('http', ('127.0.0.1', 9050))
           ('http', ('127.0.0.1', 9050, ('username', 'password'))
           TODO: multiple proxies support?
           (('http', ('127.0.0.1', 9050)),
            ('socks', ('127.0.0.1', 9050, ('username', 'password')))
    - `auth`: (dict, tuple or list) for resource base auth
    - `network_interface`: (str) use given interface for request
    - `use_gzip`: (bool) accept gzipped data
    - `validate_cert`: (bool)
    - `ca_certs`:
    - `cert`: (string) use for client-side certificate authentication
    - `debug`: (bool) use for `pycurl.DEBUGFUNCTION`
    - `user_agent`: (string) user agent
    - `ip_v6`: (bool) use ipv6 protocol
    - `options`: (list, tuple) low level curl options

    Returns:
    - `response`: :Response instance
    """
    args = dict(
        method=method, url=url, params=params, data=data, headers=headers, cookies=cookies,
        files=files, timeout=timeout, allow_redirects=allow_redirects, max_redirects=max_redirects, proxy=proxy,
        auth=auth, network_interface=network_interface, use_gzip=use_gzip, validate_cert=validate_cert,
        ca_certs=ca_certs, cert=cert, debug=debug, user_agent=user_agent, ip_v6=ip_v6, options=options,
        callback=callback, encode_query=encode_query, **kwargs)

    # TODO: add hooks
    r = Request(**args)

    # process request before send
    r = dispatch_hook('pre_request', hooks, r)

    if not return_response:
        return r
    r.send()

    # process request after send
    r = dispatch_hook('post_request', hooks, r)

    # process response
    r.response = dispatch_hook('response_hook', hooks, r.response)

    return r.response


def get(url, **kwargs):
    """Sends a GET request. Returns :class: `Response` object

    Arguments:
    - `url`: Resource url
    """
    return request("GET", url, **kwargs)


def post(url, data='', **kwargs):
    """Sends a POST request. Returns :class: `Response` object.

    Arguments:
    - `url`: Resource url
    - `data`: vars for send
    """
    return request("POST", url, data=data, **kwargs)


def head(url, **kwargs):
    """Sends a HEAD request. Returns :class: `Response` object.

    Arguments:
    - `url`: Resource url
    """
    return request("HEAD", url, **kwargs)


def put(url, data='', **kwargs):
    """Sends a PUT request. Returns :class: `Response` object.

    Arguments:
    - `url`: Resource url
    - `data`: vars for send
    """
    return request("PUT", url, data=data, **kwargs)


def patch(url, data='', **kwargs):
    """Sends a PATCH request. Returns :class: `Response` object.

    Arguments:
    - `url`: Resource url
    - `data`: update data
    """
    return request("PATCH", url, data=data, **kwargs)


def delete(url, **kwargs):
    """Sends a DELETE request. Returns :class: `Response` object.

    Arguments:
    - `url`: Resource url
    """
    return request("DELETE", url, **kwargs)


def options(url, **kwargs):
    """Sends a OPTIONS request. Returns :class: `Response` object.

    Arguments:
    - `url`: Resource url
    """
    return request("OPTIONS", url, **kwargs)

########NEW FILE########
__FILENAME__ = utils
#!/usr/bin/env python
# -*- coding:  utf-8 -*-
"""
human_curl.utils
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Utils module of cURL for Humans

:copyright: Copyright 2012 by Alexandr Lispython (alex@obout.ru).
:license: BSD, see LICENSE for more details.
"""

import zlib
import time
import urllib
import urlparse
try:
    import pycurl2 as pycurl
except ImportError:
    import pycurl
import random
from urllib2 import parse_http_list
from logging import getLogger
from Cookie import Morsel
from string import capwords
from os.path import exists as file_exists
from cookielib import CookieJar, Cookie
from types import ListType, DictType, TupleType, FileType, StringTypes

try:
    bytes
except Exception:
    bytes = str

try:
    from urlparse import parse_qs
    parse_qs # placate pyflakes
except ImportError:
    # fall back for Python 2.5
    from cgi import parse_qs

from .exceptions import InterfaceError

__all__ = ('decode_gzip', 'CaseInsensitiveDict', 'from_cookiejar', 'to_cookiejar',
           'morsel_to_cookie', 'data_wrapper', 'make_curl_post_files', 'url_escape',
           'utf8', 'to_unicode', 'parse_authenticate_header', 'parse_authorization_header',
           'WWWAuthenticate', 'Authorization', 'parse_dict_header', 'generate_nonce',
           'generate_timestamp', 'generate_verifier', 'normalize_url', 'normalize_parameters',
           'parse_qs', 'stdout_debug', 'dispatch_hook', 'curry')

logger = getLogger("human_curl.core")

def url_escape(value):
    """Returns a valid URL-encoded version of the given value."""
    """Escape a URL including any /."""
    return urllib.quote(value.encode('utf-8'), safe='~')
#    return quote_plus(utf8(value))

_UTF8_TYPES = (bytes, type(None))
def utf8(value):
    """Converts a string argument to a byte string.

    If the argument is already a byte string or None, it is returned unchanged.
    Otherwise it must be a unicode string and is encoded as utf8.
    """
    if isinstance(value, _UTF8_TYPES):
        return value
    assert isinstance(value, unicode)
    return to_unicode(value).encode("utf-8")

_TO_UNICODE_TYPES = (unicode, type(None))
def to_unicode(value):
    """Converts a string argument to a unicode string.

    If the argument is already a unicode string or None, it is returned
    unchanged.  Otherwise it must be a byte string and is decoded as utf8.
    """
    if isinstance(value, _TO_UNICODE_TYPES):
        return value
    assert isinstance(value, bytes)
    return value.decode("utf-8")


def decode_gzip(content):
    """Return gzip-decoded string.

    Arguments:
    - `content`: bytestring to gzip-decode.
    """

    return zlib.decompress(content, 16 + zlib.MAX_WBITS)


class CaseInsensitiveDict(dict):
    """Case-insensitive Dictionary

    For example, `headers['content-encoding']` will return the
    value of a `'Content-Encoding'` response header.
    """

    def __init__(self, *args, **kwargs):
        tmp_d = dict(*args, **kwargs)
        super(CaseInsensitiveDict, self).__init__([(k.lower(), v) for k, v in tmp_d.iteritems()])

    def __setitem__(self, key, value):
        super(CaseInsensitiveDict, self).__setitem__(key.lower(), value)

    def __delitem__(self, key):
        super(CaseInsensitiveDict, self).__delitem__(key.lower())

    def __contains__(self, key):
        return key.lower() in self

    def __getitem__(self, key):
        return super(CaseInsensitiveDict, self).__getitem__(key.lower())

    def has_key(self, key):
        return super(CaseInsensitiveDict, self).has_key(key.lower())

    def iteritems(self):
        return ((capwords(k, '-'), v) for k, v in super(CaseInsensitiveDict, self).iteritems())


def from_cookiejar(cookiejar):
    """Extract cookies dict from cookiejar

    Attributes:
    - `cookiejar`: cookielib.CookieJar instance

    Returns:
    - `cookies`: (dict) dictionary of cookies
    """
    cookies = {}

    # for cookie in cookiejar:
    #    cookies[cookie.name] = cookie.value

    for domain, d_cookies in cookiejar._cookies.iteritems():
        for path, p_cookies in d_cookies.iteritems():
            for cookie in p_cookies.values():
                cookies[cookie.name] = cookie.value
    return cookies


def to_cookiejar(cookies):
    """Build CookieJar object from dict, list or tuple

    Attributes:
    - `cookies`: (dict, list or tuple)

    Returns:
    - `cookiejar`: `CookieJar` instance
    """
    if isinstance(cookies, CookieJar):
        return cookies

    tmp_cookies = []
    if isinstance(cookies, (TupleType, ListType)):
        tmp_cookies = cookies
    elif isinstance(cookies, DictType):
        tmp_cookies = [(k, v) for k, v in cookies.iteritems()]
    else:
        raise ValueError("Unsupported argument")

    cookie_jar = CookieJar()
    for k, v in tmp_cookies:
        cookie = Cookie(
            version=0,
            name=k,
            value=v,
            port=None,
            port_specified=False,
            domain='',
            domain_specified=False,
            domain_initial_dot=False,
            path='/',
            path_specified=True,
            secure=False,
            expires=None,
            discard=True,
            comment=None,
            comment_url=None,
            rest={'HttpOnly': None},
            rfc2109=False)
        cookie_jar.set_cookie(cookie)

    return cookie_jar


def morsel_to_cookie(morsel):
    """Convert Morsel object to cookielib.Cookie

    Argument:
    - `morsel`: `Cookie.Morsel` instance

    Returns:
    - `cookie`: `cookielib.Cookie` instance
    """
    if not isinstance(morsel, Morsel):
        raise ValueError("morsel mus be Morsel instance")

    # Cookies thinks an int expires x seconds in future,
    # cookielib thinks it is x seconds from epoch,
    # so doing the conversion to string for Cookies
    # fmt = '%a, %d %b %Y %H:%M:%S GMT'
    # sc[name]['expires'] = time.strftime(fmt,
    # time.gmtime(cookie.expires))

    # Morsel keys
    attrs = ('expires', 'path', 'comment', 'domain', 'secure', 'version', 'httponly')
    time_template = "%a, %d-%b-%Y %H:%M:%S GMT"

    tmp = dict(version=0,
               name=None,
               value=None,
               port=None,
               port_specified=False,
               domain='',
               domain_specified=False,
               domain_initial_dot=False,
               path='/',
               path_specified=True,
               secure=False,
               expires=None,
               discard=True,
               comment=None,
               comment_url=None,
               rest={'HttpOnly': None},
               rfc2109=False)

    for attr in attrs:
        try:
            if 'httponly' == attr:
                tmp['rest'] = {'HttpOnly': morsel[attr]}
            elif attr == 'expires':
                # TODO: parse date?
                tmp[attr] = time.mktime(time.strptime(morsel.get(attr), time_template))
                #tmp[attr] = None
            else:
                tmp[attr] = morsel.get(attr, None)
        except (IndexError, Exception), e:
            pass

    tmp['name'] = morsel.key
    tmp['value'] = morsel.value

    try:
        tmp['version'] = int(tmp['version'])
    except ValueError, e:
        tmp['version'] = 1

    cookie = Cookie(**tmp)
    return cookie


def helper(d):
    tmp = []
    for k, v in d:
        if isinstance(v, (TupleType, ListType)):
            for v2 in v:
                tmp.append((k, v2))
        else:
            tmp.append((k, v))
    return tmp


#TODO: use custom MultiValue dict
def data_wrapper(data):
    """Convert data to list and returns
    """
    if isinstance(data, DictType):
        return helper(data.iteritems())
    elif isinstance(data, (TupleType, ListType)):
        return helper(data)
    elif data is None:
        return data
    else:
        raise ValueError("%s argument must be list, tuple or dict, not %s " %
                         ("data_wrapper", type(data)))


def make_curl_post_files(data):
    """Convert parameters dict, list or tuple to cURL style tuple
    """
    if isinstance(data, (TupleType, ListType)):
        iterator = data
    elif isinstance(data, DictType):
        iterator = data.iteritems()
    else:
        raise ValueError("%s argument must be list, tuple or dict, not %s" %
                         ("make_curl_post_files", type(data)))

    def checker(name):
        if file_exists(str(name)):
            return (pycurl.FORM_FILE, str(name))
        else:
            raise RuntimeError("File %s doesn't exist" % v)

    result = []
    for k, v in iterator:
        if isinstance(v, TupleType):
            for k2 in v:
                if isinstance(k2, FileType):
                    result.append((k, checker(k2.name)))
                elif isinstance(k2, StringTypes):
                    result.append((k, checker(k2)))
                else:
                    raise RuntimeError("File %s doesn't exist" % v)
        elif isinstance(v, FileType):
            result.append((k, checker(str(v.name))))
        elif isinstance(v, StringTypes):
            result.append((k, checker(str(v))))
        else:
            raise InterfaceError("Not allowed file value")

    return result



def parse_dict_header(value):
    """Parse key=value pairs from value list
    """
    result = {}
    for item in parse_http_list(value):
        if "=" not in item:
            result[item] = None
            continue
        name, value = item.split('=', 1)
        if value[:1] == value[-1:] == '"':
            value = urllib.unquote(value[1:-1]) # strip " and unquote
        result[name] = value
    return result


def generate_timestamp():
    """Get seconds since epoch (UTC)."""
    return int(time.time())


def generate_nonce(length=8):
    """Generate pseudorandom number."""
    return ''.join([str(random.randint(0, 9)) for i in range(length)])


def generate_verifier(length=8):
    """Generate pseudorandom number."""
    return ''.join([str(random.randint(0, 9)) for i in range(length)])

def parse_authenticate_header(header):
    """Parse WWW-Authenticate response header

    WWW-Authenticate: Digest
                 realm="testrealm@host.com",
                 qop="auth,auth-int",
                 nonce="dcd98b7102dd2f0e8b11d0f600bfb0c093",
                 opaque="5ccc069c403ebaf9f0171e9517f40e41"
    """
    if not header:
        return
    try:
        auth_type, auth_info = header.split(None, 1)
        auth_type = auth_type.lower()
    except ValueError, e:
        print(e)
        return
    return WWWAuthenticate(auth_type, parse_dict_header(auth_info))


def parse_authorization_header(header):
    """Parse authorization header and build Authorization object
    """
    if not header:
        return
    try:
        auth_type, auth_info = header.split(None, 1) # separate auth type and values
        auth_type = auth_type.lower()
    except ValueError, e:
        print(e)
        return

    if auth_type == 'basic':
        try:
            username, password = auth_info.decode('base64').split(':', 1)
        except Exception, e:
            return
        return Authorization('basic', {'username': username,
                                       'password': password})
    elif auth_type == 'digest':
        auth_map = parse_dict_header(auth_info)

        required_map = {
            'auth': ("username", "realm", "nonce", "uri", "response", "opaque"),
            'auth-int': ("realm", "nonce", "uri", "qop", "nc", "cnonce", "response", "opaque")}
        required = required_map.get(auth_map.get('qop', 'auth'))

        for key in required:
            if not key in auth_map:
                return
        return Authorization('digest', auth_map)
    elif auth_type == 'oauth':
        auth_map = parse_dict_header(auth_info)
        return Authorization('oauth', auth_map)
    else:
        raise ValueError("Unknown auth type %s" % auth_type)


class WWWAuthenticate(dict):
    """WWWAuthenticate header object
    """

    AUTH_TYPES = ("Digest", "Basic", "OAuth")

    def __init__(self, auth_type='basic', data=None):
        if auth_type.lower() not in [t.lower() for t in self.AUTH_TYPES]:
            raise RuntimeError("Unsupported auth type: %s" % auth_type)
        dict.__init__(self, data or {})
        self._auth_type = auth_type

    @staticmethod
    def from_string(value):
        """Build Authenticate object from header value

        - `value`: Authorization field value
        """
        return parse_authenticate_header(value)

    def to_header(self):
        """Convert values into WWW-Authenticate header value
        """
        d = dict(self)
        return "%s %s" % (self._auth_type.title(), ", ".join("%s=\"%s\"" % (k, v)
                                                             for k, v in d.iteritems()))


class Authorization(dict):
    """Authorization header object
    """

    AUTH_TYPES = ("Digest", "Basic", "OAuth")

    def __init__(self, auth_type='Basic', data=None):
        if auth_type.lower() not in [t.lower() for t in self.AUTH_TYPES]:
            raise RuntimeError("Unsupported auth type: %s" % auth_type)
        dict.__init__(self, data or {})
        self._auth_type = auth_type

    def __str__(self):
        return self.to_header()

    @staticmethod
    def from_string(value):
        """Build Authorization object from header value

        - `value`: Authorization field value
        """
        return parse_authorization_header(value)

    def to_header(self):
        """Convert values into WWW-Authenticate header value
        """
        d = dict(self)
        return "%s %s" % (self._auth_type, ", ".join("%s=\"%s\"" % (k, v)
                                                             for k, v in sorted(d.iteritems())))


    # Digest auth properties http://tools.ietf.org/html/rfc2069#page-4

    realm = property(lambda x: x.get('realm'), doc="""
    A string to be displayed to users so they know which username and
    password to use.""")

    domain = property(lambda x: x.get('domain'), doc="""domain
    A comma-separated list of URIs, as specified for HTTP/1.0.""")



def normalize_url(url):
    if url is not None:
        scheme, netloc, path, params, query, fragment = urlparse.urlparse(url)

        # Exclude default port numbers.
        if scheme == 'http' and netloc[-3:] == ':80':
            netloc = netloc[:-3]
        elif scheme == 'https' and netloc[-4:] == ':443':
            netloc = netloc[:-4]
        if scheme not in ('http', 'https'):
            raise ValueError("Unsupported URL %s (%s)." % (url, scheme))

        # Normalized URL excludes params, query, and fragment.
        return  urlparse.urlunparse((scheme, netloc, path, None, None, None))
    else:
        return None


def normalize_parameters(url, params=None):
    """Normalize url parameters

    The parameters collected in Section 3.4.1.3 are normalized into a
    single string as follow: http://tools.ietf.org/html/rfc5849#section-3.4.1.3.2
    """
    items = []
    # Include any query string parameters from the provided URL
    query = urlparse.urlparse(url)[4]
    parameters = parse_qs(utf8(query), keep_blank_values=True)
    for k, v in parameters.iteritems():
        parameters[k] = urllib.unquote(v[0])
    url_items = parameters.items()
    url_items = [(utf8(k), utf8(v)) for k, v in url_items if k != 'oauth_signature' ]
    items.extend(url_items)

    if params:
        for key, value in params.iteritems():
            if key == 'oauth_signature':
                continue
            # 1.0a/9.1.1 states that kvp must be sorted by key, then by value,
            # so we unpack sequence values into multiple items for sorting.
            if isinstance(value, basestring):
                items.append((utf8(key), utf8(value)))
            else:
                try:
                    value = list(value)
                except TypeError, e:
                    assert 'is not iterable' in str(e)
                    items.append((utf8(key), utf8(value)))
                else:
                    items.extend((utf8(key), utf8(item)) for item in value)

    items.sort()
    encoded_str = urllib.urlencode(items)
    # Encode signature parameters per Oauth Core 1.0 protocol
    # spec draft 7, section 3.6
    # (http://tools.ietf.org/html/draft-hammer-oauth-07#section-3.6)
    # Spaces must be encoded with "%20" instead of "+"
    return encoded_str.replace('+', '%20').replace('%7E', '~')



def stdout_debug(debug_type, debug_msg):
    """Print messages into stdout

    - `debug_type`: (int) debug output code
    - `debug_msg`: (str) debug message
    """
    debug_types = ('I', '<', '>', '<', '>')
    if debug_type == 0:
        print('%s' % debug_msg.strip())
    elif debug_type in (1, 2):
        for line in debug_msg.splitlines():
            print('%s %s' % (debug_types[debug_type], line))
    elif debug_type == 4:
        print('%s %r' % (debug_types[debug_type], debug_msg))


def logger_debug(debug_type, debug_msg):
    """Handle debug messages

    - `debug_type`: (int) debug output code
    - `debug_msg`: (str) debug message
    """
    debug_types = ('I', '<', '>', '<', '>')
    if debug_type == 0:
        logger.debug('%s', debug_msg.strip())
    elif debug_type in (1, 2):
        for line in debug_msg.splitlines():
            logger.debug('%s %s', debug_types[debug_type], line)
    elif debug_type == 4:
        logger.debug('%s %r', debug_types[debug_type], debug_msg)



def dispatch_hook(key, hooks, data):
    """Dispatch hooks
    """
    hooks = hooks or dict()

    if key in hooks:
        try:
            data = hooks.get(key).__call__(data) or data
        except Exception, e:
            logger.warn(str(e))
    return data


def curry(fn, *cargs, **ckwargs):
    def call_fn(*fargs, **fkwargs):
        d = ckwargs.copy()
        d.update(fkwargs)
        return fn(*(cargs + fargs), **d)
    return call_fn


def urlnoencode(query):
    """Convert a sequence of two-element tuples or dictionary into a URL query string without url-encoding.
    """
    l = []
    arg = "%s=%s"

    if hasattr(query, "items"):
        # mapping objects
        query = query.items()

    for k, v in query:
        l.append(arg % (k, v))

    return "&".join(l)

########NEW FILE########
__FILENAME__ = tests
#!/usr/bin/env python
# -*- coding:  utf-8 -*-
"""
human_curl.tests
~~~~~~~~~~~~~~~~

Unittests for human_curl

:copyright: (c) 2011 - 2012 by Alexandr Lispython (alex@obout.ru).
:license: BSD, see LICENSE for more details.
"""
from __future__ import with_statement

import os
import time
import pycurl2 as pycurl
import cookielib
from Cookie import Morsel
import json
import uuid
from random import randint, choice
from string import ascii_letters, digits
import logging
from urlparse import urljoin
import unittest
import urllib
from types import TupleType, ListType, FunctionType, DictType
from urllib import urlencode

import human_curl as requests
from human_curl import Request, Response
from human_curl import AsyncClient
from human_curl.auth import *
from human_curl.utils import *

from human_curl.exceptions import (CurlError, InterfaceError)

logger = logging.getLogger("human_curl.test")

## async_logger = logging.getLogger("human_curl.async")
## async_logger.setLevel(logging.DEBUG)

## # Add the log message handler to the logger
## # LOG_FILENAME = os.path.join(os.path.dirname(__file__), "debug.log")
## # handler = logging.handlers.FileHandler(LOG_FILENAME)
## handler = logging.StreamHandler()

## formatter = logging.Formatter("%(levelname)s %(asctime)s %(module)s [%(lineno)d] %(process)d %(thread)d | %(message)s ")

## handler.setFormatter(formatter)

## async_logger.addHandler(handler)


TEST_METHODS = (
    ('get', requests.get),
    ('post', requests.post),
    ('head', requests.head),
    ('delete', requests.delete),
    ('put', requests.put),
    ('options', requests.options))

# Use https://github.com/Lispython/httphq
HTTP_TEST_URL = os.environ.get('HTTP_TEST_URL', 'http://h.wrttn.me')
HTTPS_TEST_URL = os.environ.get('HTTPS_TEST_URL', 'https://h.wrttn.me')


print("Use {0} as test server".format(HTTP_TEST_URL))

def build_url(*parts):
    return urljoin(HTTP_TEST_URL, "/".join(parts))

def build_url_secure(*parts):
    return urljoin(HTTPS_TEST_URL, "/".join(parts))

TEST_SERVERS = (build_url, build_url_secure)

def stdout_debug(debug_type, debug_msg):
    """Print messages
    """
    debug_types = ('I', '<', '>', '<', '>')
    if debug_type == 0:
        print('%s' % debug_msg.strip())
    elif debug_type in (1, 2):
        for line in debug_msg.splitlines():
            print('%s %s' % (debug_types[debug_type], line))
    elif debug_type == 4:
        print('%s %r' % (debug_types[debug_type], debug_msg))


def random_string(num=10):
    return ''.join([choice(ascii_letters + digits) for x in xrange(num)])


class BaseTestCase(unittest.TestCase):

    @staticmethod
    def random_string(num=10):
        return random_string(10)

    def random_dict(self, num=10):
        return dict([(self.random_string(10), self.random_string(10))for x in xrange(10)])

    def request_params(self):
        data = self.random_dict(10)
        data['url'] = build_url("get")
        data['method'] = 'get'

        return data


class RequestsTestCase(BaseTestCase):

    def test_build_url(self):
        self.assertEquals(build_url("get"), HTTP_TEST_URL + "/" + "get")
        self.assertEquals(build_url("post"), HTTP_TEST_URL + "/" + "post")
        self.assertEquals(build_url("redirect", "3"), HTTP_TEST_URL + "/" + "redirect" + "/" + "3")

    def tests_invalid_url(self):
        self.assertRaises(ValueError, requests.get, "wefwefwegrer")

    def test_url(self):
        self.assertEquals(requests.get(build_url("get")).url, build_url("get"))

    def test_request(self):
        for method, method_func in TEST_METHODS:
            r = method_func(build_url(method))
            self.assertTrue(isinstance(r, Response))

    def test_HTTP_GET(self):
        r = requests.get(build_url("get"))
        self.assertEquals(r.status_code, 200)

    def test_HTTP_POST(self):
        r = requests.post(build_url("post"))
        self.assertEquals(r.status_code, 201)

    def test_HTTP_HEAD(self):
        r = requests.head(build_url("head"))
        self.assertEquals(r.status_code, 200)

    def test_HTTP_PUT(self):
        r = requests.put(build_url("put"))
        self.assertEquals(r.status_code, 200)
        r2 = requests.put(build_url("put"),
                          data='kcjbwefjhwbcelihbflwkh')
        self.assertEquals(r2.status_code, 200)

    def test_HTTP_DELETE(self):
        r = requests.delete(build_url("delete"))
        self.assertEquals(r.status_code, 200)

    def test_HTTP_OPTIONS(self):
        r = requests.options(build_url("options"))
        self.assertEquals(r.status_code, 200)

    def test_HEADERS(self):
        import string
        headers = (("test-header", "test-header-value"),
                   ("Another-Test-Header", "kjwbrlfjbwekjbf"))

        r = requests.get(build_url("headers"), headers=headers)
        self.assertEquals(r.status_code, 200)

        r_json = json.loads(r.content)
        for field, value in headers:
            self.assertEquals(r_json.get(string.capwords(field, "-")), value)

    def test_PARAMS(self):
        params = {'q': 'test param'}
        r = requests.get(build_url("get""?test=true"), params=params)
        self.assertEquals(r.status_code, 200)
        args = json.loads(r.content)['args']
        self.assertEquals(args['q'][0], params['q'])
        self.assertEquals(args["test"][0], "true")

    def test_POST_DATA(self):
        random_key = "key_" + uuid.uuid4().get_hex()[:10]
        random_value = "value_" + uuid.uuid4().get_hex()
        r = requests.post(build_url('post'),
                          data={random_key: random_value})
        self.assertEquals(r.status_code, 201)

    def test_PUT_DATA(self):
        random_key = "key_" + uuid.uuid4().get_hex()[:10]
        random_value = "value_" + uuid.uuid4().get_hex()
        r = requests.put(build_url('put'),
                          data={random_key: random_value})
        self.assertEquals(r.status_code, 200)

    def test_POST_RAW_DATA(self):
        random_key = "key_" + uuid.uuid4().get_hex()[:10]
        random_value = "value_" + uuid.uuid4().get_hex()
        data = "%s:%s" % (random_key, random_value)
        r = requests.post(build_url('post'),
                          data=data)
        self.assertEquals(r.status_code, 201)
        self.assertTrue(data in r.content)

    def test_PUT_RAW_DATA(self):
        random_key = "key_" + uuid.uuid4().get_hex()[:10]
        random_value = "value_" + uuid.uuid4().get_hex()
        data = "%s:%s" % (random_key, random_value)
        r = requests.put(build_url('put'),
                          data=data)
        self.assertEquals(r.status_code, 200)
        self.assertTrue(data in r.content)

    def test_FILES(self):
        files = {'test_file': open('tests.py'),
                 'test_file2': open('README.rst')}
        r = requests.post(build_url('post'),
                          files=files)
        json_response = json.loads(r.content)
        self.assertEquals(r.status_code, 201)
        for k, v in files.items():
            self.assertTrue(k in json_response['files'].keys())

    def test_POST_DATA_and_FILES(self):
        files = {'test_file': open('tests.py'),
               'test_file2': open('README.rst')}
        random_key1 = "key_" + uuid.uuid4().get_hex()[:10]
        random_value1 = "value_" + uuid.uuid4().get_hex()
        random_key2 = "key_" + uuid.uuid4().get_hex()[:10]
        random_value2 = "value_" + uuid.uuid4().get_hex()
        r = requests.post(build_url('post'),
                          data={random_key1: random_value2,
                                random_key2: random_value2},
                          files=files)

        self.assertEquals(r.status_code, 201)

    def test_PUT_DATA_and_FILES(self):
        files = {'test_file': open('tests.py'),
                 'test_file2': open('README.rst')}
        random_key1 = "key_" + uuid.uuid4().get_hex()[:10]
        random_key2 = "key_" + uuid.uuid4().get_hex()[:10]
        random_value2 = "value_" + uuid.uuid4().get_hex()
        r = requests.put(build_url('put'),
                          data={random_key1: random_value2,
                                random_key2: random_value2},
                          files=files)

        self.assertEquals(r.status_code, 200)

    def test_cookies_jar(self):
        random_key = "key_" + uuid.uuid4().get_hex()[:10]
        random_value = "value_" + uuid.uuid4().get_hex()
        random_key2 = "key_" + uuid.uuid4().get_hex()[:10]
        random_value2 = "value_" + uuid.uuid4().get_hex()

        cookies = ((random_key, random_value),
                   (random_key2, random_value2))

        cookies_jar = cookielib.CookieJar()

        r1 = requests.get(build_url("cookies", "set", random_key, random_value),
                     cookies=cookies_jar, debug=stdout_debug)

        self.assertEquals(r1.cookies[random_key], random_value)
        rtmp = requests.get(build_url("cookies", "set", random_key2, random_value2),
                            cookies=cookies_jar, debug=stdout_debug)

        for cookie in cookies_jar:
            if cookie.name == random_key:
                self.assertEquals(cookie.value, random_value)

        r3 = requests.get(build_url('cookies'), cookies=cookies_jar, debug=stdout_debug)
        json_response = json.loads(r3.content)

        for k, v in cookies:
            self.assertEquals(json_response[k], v)

    def test_send_cookies(self):
        random_key = "key_" + uuid.uuid4().get_hex()[:10]
        random_value = "value_" + uuid.uuid4().get_hex()
        random_key2 = "key_" + uuid.uuid4().get_hex()[:10]
        random_value2 = "value_" + uuid.uuid4().get_hex()

        cookies = ((random_key, random_value),
                   (random_key2, random_value2))

        r = requests.get(build_url('cookies'), cookies=cookies)
        #                          debug=stdout_debug)
        json_response = json.loads(r.content)
        self.assertEquals(json_response[random_key], random_value)


    def test_basic_auth(self):
        username =  uuid.uuid4().get_hex()
        password =  uuid.uuid4().get_hex()
        auth_manager = BasicAuth(username, password)

        r = requests.get(build_url('basic-auth', username, password),
                         auth=auth_manager)
        self.assertEquals(r.status_code, 200)
        json_response = json.loads(r.content)
        self.assertEquals(json_response['password'], password)
        self.assertEquals(json_response['username'], username)
        self.assertEquals(json_response['auth-type'], 'basic')

    def test_digest_auth(self):
        username = uuid.uuid4().get_hex()
        password =  uuid.uuid4().get_hex()
        auth_manager = DigestAuth(username, password)

        r = requests.get(build_url('digest-auth/auth/', username, password),
                         auth=auth_manager, allow_redirects=True)
        self.assertEquals(r.status_code, 200)
        json_response = json.loads(r.content)
        self.assertEquals(json_response['password'], password)
        self.assertEquals(json_response['username'], username)
        self.assertEquals(json_response['auth-type'], 'digest')

    def test_auth_denied(self):
        username = "hacker_username"
        password = "hacker_password"
        http_auth = (username, password)

        r = requests.get(build_url('basic-auth', "username", "password"), auth=http_auth)
        self.assertEquals(r.status_code, 401)

    def test_multivalue_params(self):
        random_key = "key_" + uuid.uuid4().get_hex()[:10]
        random_value1 = "value_" + uuid.uuid4().get_hex()
        random_value2 = "value_" + uuid.uuid4().get_hex()
        r = requests.get(build_url("get"),
                         params={random_key: (random_value1, random_value2)})

        self.assertEquals(build_url("get?%s" %
                                    urlencode(((random_key, random_value1), (random_key, random_value2)))), r.url)

        json_response = json.loads(r.content)
        self.assertTrue(random_value1 in json_response['args'][random_key])
        self.assertTrue(random_value2 in json_response['args'][random_key])

    def test_multivalue_post_data(self):
        random_key = "key_" + uuid.uuid4().get_hex()[:10]
        random_value1 = "value_" + uuid.uuid4().get_hex()
        random_value2 = "value_" + uuid.uuid4().get_hex()
        r = requests.post(build_url("post"),
                         data={random_key: (random_value1, random_value2)})

        json_response = json.loads(r.content)
        self.assertTrue(random_value1 in json_response['args'][random_key])
        self.assertTrue(random_value2 in json_response['args'][random_key])

    def test_redirect(self):
        r = requests.get(build_url("redirect", '3'), allow_redirects=True)
        self.assertEquals(r.status_code, 200)
        self.assertEquals(len(r.history), 3)
        self.assertEquals(r.url, build_url("redirect/end"))
        self.assertEquals(r._request_url, build_url("redirect/3"))
        self.assertRaises(CurlError, requests.get, build_url("redirect", '7'),
                          allow_redirects=True)

    def test_gzip(self):
        r = requests.get(build_url("gzip"), use_gzip=True)

        self.assertEquals(r.headers['Content-Encoding'], 'gzip')

        json_response = json.loads(r.content)
        self.assertEquals(json_response['gzipped'], True)

    def test_response_info(self):
        r = requests.get(build_url("get"))

    def test_unicode_domains(self):
        r = requests.get("http://➡.ws/pep8")
        self.assertEquals(r.url, 'http://xn--hgi.ws/pep8')

    def test_hooks(self):
        def pre_hook(r):
            r.pre_hook = True

        def post_hook(r):
            r.post_hook = True

        def response_hook(r):
            r._status_code = 700
            return r

        r1 = requests.get(build_url("get"), hooks={'pre_request': pre_hook,
                                                   'post_request': post_hook})
        self.assertEquals(r1._request.pre_hook, True)
        self.assertEquals(r1._request.post_hook, True)

        r2 = requests.get(build_url("get"), hooks={'response_hook': response_hook})
        self.assertEquals(r2._status_code, 700)

    def test_json_response(self):
        random_key = "key_" + uuid.uuid4().get_hex()[:10]
        random_value1 = "value_" + uuid.uuid4().get_hex()
        random_value2 = "value_" + uuid.uuid4().get_hex()
        r = requests.get(build_url("get"),
                         params={random_key: (random_value1, random_value2)})

        self.assertEquals(build_url("get?%s" %
                                    urlencode(((random_key, random_value1), (random_key, random_value2)))), r.url)

        json_response = json.loads(r.content)
        self.assertTrue(isinstance(r.json, (dict, DictType)))
        self.assertEquals(json_response, r.json)
        self.assertTrue(random_value1 in r.json['args'][random_key])
        self.assertTrue(random_value2 in r.json['args'][random_key])

    def test_get_encode_query(self):
        params = {'q': 'value with space and @'}
        key, value = 'email', 'user@domain.com'
        response = requests.get(build_url("get""?%s=%s" % (key, value)), params=params)
        self.assertEquals(response.status_code, 200)
        self.assertEqual("{0}/get?email=user%40domain.com&q=value+with+space+and+%40".format(HTTP_TEST_URL), response.request._url)
        args = json.loads(response.content)['args']
        self.assertEquals(args['q'][0], params['q'])
        self.assertEquals(args[key][0], value)

    def test_get_no_encode_query(self):
        params = {'q': 'value with space and @'}
        key, value = 'email', 'user@domain.com'

        # Invalid by HTTP spec
        try:
            response = requests.get(build_url("get""?%s=%s" % (key, value)), params=params, encode_query=False)
        except CurlError, e:
            self.assertEqual(e.code, 52)
        else:
            self.assertEquals(response.status_code, 502)
            self.assertEqual("{0}/get?email=user@domain.com&q=value with space and @".format(HTTP_TEST_URL), response.request._url)


class ResponseTestCase(BaseTestCase):

    def setUp(self):
        pass

    def tearDown(self):
        pass


class RequestTestCase(BaseTestCase):

    def setUp(self):
        pass

    def tearDown(self):
        pass


class UtilsTestCase(BaseTestCase):

    def test_case_insensitive_dict(self):
        test_data = {
            "lower-case-key": uuid.uuid4().hex,
            "UPPER-CASE-KEY": uuid.uuid4().hex,
            "CamelCaseKey": uuid.uuid4().hex}
        cidict = CaseInsensitiveDict(test_data)

        for k, v in test_data.items():
            self.assertTrue(cidict[k], v)

    def test_cookies_from_jar(self):
        test_cookie_jar = cookielib.CookieJar()

        cookies_dict = from_cookiejar(test_cookie_jar)

        for cookie in test_cookie_jar:
            self.assertEquals(cookies_dict[cookie.name], cookie.value)

    def test_jar_from_cookies(self):
        cookies_dict = dict([(uuid.uuid4().hex, uuid.uuid4().hex) for x in xrange(10)])
        cookies_list = [(uuid.uuid4().hex, uuid.uuid4().hex) for x in xrange(10)]

        cookiejar1 = to_cookiejar(cookies_dict)
        cookiejar2 = to_cookiejar(cookies_list)

        for cookie in cookiejar1:
            self.assertEquals(cookie.value, cookies_dict[cookie.name])

        for cookie in cookiejar2:
            for k, v in cookies_list:
                if k == cookie.name:
                    self.assertEquals(cookie.value, v)

    def test_decode_gzip(self):
        from gzip import GzipFile
        try:
            from cString import StringIO
        except ImportError:
            from StringIO import StringIO

        data_for_gzip = Request.__doc__
        tmp_buffer = StringIO()

        gziped_buffer = GzipFile(
            fileobj=tmp_buffer,
            mode="wb",
            compresslevel=7)

        gziped_buffer.write(data_for_gzip)
        gziped_buffer.close()

        gzipped_data = tmp_buffer.getvalue()
        tmp_buffer.close()
        self.assertEquals(data_for_gzip, decode_gzip(gzipped_data))

    def test_morsel_to_cookie(self):
        from time import strftime, localtime
        time_template = "%a, %d-%b-%Y %H:%M:%S GMT"
        m = Morsel()
        m['domain'] = ".yandex"
        m['domain'] = ".yandex.ru"
        m['path'] = "/"
        m['expires'] = "Fri, 27-Aug-2021 17:43:25 GMT"
        m.key = "dj2enbdj3w"
        m.value = "fvjlrwnlkjnf"

        c = morsel_to_cookie(m)
        self.assertEquals(m.key, c.name)
        self.assertEquals(m.value, c.value)
        for x in ('expires', 'path', 'comment', 'domain',
                  'secure', 'version'):
            if x == 'expires':
                self.assertEquals(m[x], strftime(time_template, localtime(getattr(c, x, None))))
            elif x == 'version':
                self.assertTrue(isinstance(getattr(c, x, None), int))
            else:
                self.assertEquals(m[x], getattr(c, x, None))

    def test_data_wrapper(self):
        random_key1 = "key_" + uuid.uuid4().get_hex()[:10]
        random_key2 = "key_" + uuid.uuid4().get_hex()[:10]
        random_key3 = "key_" + uuid.uuid4().get_hex()[:10]
        random_value1 = "value_" + uuid.uuid4().get_hex()
        random_value2 = "value_" + uuid.uuid4().get_hex()
        random_value3 = "value_" + uuid.uuid4().get_hex()

        test_dict = {random_key1: random_value1,
                     random_key2: [random_value1, random_value2],
                     random_key3: (random_value2, random_value3)}
        test_list = ((random_key1, random_value1),
                     (random_key2, [random_value1, random_value2]),
                     (random_key3, (random_value2, random_value3)))

        control_list = ((random_key1, random_value1),
                        (random_key2, random_value1),
                        (random_key2, random_value2),
                        (random_key3, random_value2),
                        (random_key3, random_value3))

        converted_dict = data_wrapper(test_dict)
        for k, v in control_list:
            tmp = []
            for k2, v2 in converted_dict:
                if k2 == k:
                    tmp.append(v2)
            self.assertTrue(v in tmp)

        converted_list = data_wrapper(test_list)
        for k, v in control_list:
            tmp = []
            for k2, v2 in converted_list:
                if k2 == k:
                    tmp.append(v2)
            self.assertTrue(v in tmp)

    def test_curl_post_files(self):
        test_files = (('field_file_name', './README.rst'),
                      ('field_file_name2', open('./setup.py')),
                      ('multiple_files_field', (open("./README.rst"), "./setup.py")))

        curl_files_dict = make_curl_post_files(test_files)

        for k, v in curl_files_dict:
            if isinstance(v, (TupleType, ListType)):
                self.assertTrue(isinstance(v, (TupleType, ListType)))
                self.assertTrue(os.path.exists(v[1]))
                self.assertEquals(v[0], pycurl.FORM_FILE)
            else:
                assert False


class AuthManagersTestCase(BaseTestCase):


    def test_parse_dict_header(self):
        value = '''username="Mufasa",
                 realm="testrealm@host.com",
                 nonce="dcd98b7102dd2f0e8b11d0f600bfb0c093",
                 uri="/dir/index.html",
                 qop=auth,
                 nc=00000001,
                 cnonce="0a4f113b",
                 response="6629fae49393a05397450978507c4ef1",
                 opaque="5ccc069c403ebaf9f0171e9517f40e41"'''

        parsed_header = parse_dict_header(value)
        self.assertEquals(parsed_header['username'], "Mufasa")
        self.assertEquals(parsed_header['realm'], "testrealm@host.com")
        self.assertEquals(parsed_header['nonce'], "dcd98b7102dd2f0e8b11d0f600bfb0c093")
        self.assertEquals(parsed_header['uri'], "/dir/index.html")
        self.assertEquals(parsed_header['qop'], "auth")
        self.assertEquals(parsed_header['nc'], "00000001")


    def test_parse_authorization_header(self):
        test_digest_value = '''Digest username="Mufasa",
        realm="testrealm@host.com",
        nonce="dcd98b7102dd2f0e8b11d0f600bfb0c093",
        uri="/dir/index.html",
        qop=auth,
        nc=00000001,
        cnonce="0a4f113b",
        response="6629fae49393a05397450978507c4ef1",
        opaque="5ccc069c403ebaf9f0171e9517f40e41"'''

        digest_authorization = parse_authorization_header(test_digest_value)

        control_dict = {'username': 'Mufasa',
                        'nonce': 'dcd98b7102dd2f0e8b11d0f600bfb0c093',
                        'realm': 'testrealm@host.com',
                        'qop': 'auth',
                        'cnonce': '0a4f113b',
                        'nc': '00000001',
                        'opaque': '5ccc069c403ebaf9f0171e9517f40e41',
                        'uri': '/dir/index.html',
                        'response': '6629fae49393a05397450978507c4ef1'}

        for k, v in control_dict.iteritems():
            self.assertEquals(digest_authorization[k], v)

        self.assertTrue(isinstance(digest_authorization, Authorization))

        test_oauth_header_value = '''OAuth realm="Photos",
        oauth_consumer_key="dpf43f3p2l4k3l03",
        oauth_signature_method="HMAC-SHA1",
        oauth_timestamp="137131200",
        oauth_nonce="wIjqoS",
        oauth_callback="http%3A%2F%2Fprinter.example.com%2Fready",
        oauth_signature="74KNZJeDHnMBp0EMJ9ZHt%2FXKycU%3D"'''

        oauth_authorization = parse_authorization_header(test_oauth_header_value)

        control_dict = {'realm': 'Photos',
                        'oauth_nonce': 'wIjqoS',
                        'oauth_timestamp': '137131200',
                        'oauth_signature': '74KNZJeDHnMBp0EMJ9ZHt/XKycU=',
                        'oauth_consumer_key': 'dpf43f3p2l4k3l03',
                        'oauth_signature_method': 'HMAC-SHA1',
                        'oauth_callback': 'http://printer.example.com/ready'}


        for k, v in control_dict.iteritems():
            self.assertEquals(oauth_authorization[k], v)

        self.assertTrue(isinstance(digest_authorization, Authorization))


    def test_escape(self):
        self.assertEquals(urllib.unquote(url_escape("http://sp.example.com/")),
                          "http://sp.example.com/")


    def test_parse_authentication_header(self):
        test_digest_authenticate_header = '''Digest
                 realm="testrealm@host.com",
                 qop="auth,auth-int",
                 nonce="dcd98b7102dd2f0e8b11d0f600bfb0c093",
                 opaque="5ccc069c403ebaf9f0171e9517f40e41"'''

        parsed_authentication = parse_authenticate_header(test_digest_authenticate_header)

        control_dict = {'realm': 'testrealm@host.com',
                        'qop': 'auth,auth-int',
                        'nonce': "dcd98b7102dd2f0e8b11d0f600bfb0c093",
                        'opaque': "5ccc069c403ebaf9f0171e9517f40e41"}

        for k, v in control_dict.iteritems():
            self.assertEquals(parsed_authentication[k], v)

        self.assertTrue(isinstance(parsed_authentication, WWWAuthenticate))
        oauth_authentication_header_value = 'OAuth realm="http://sp.example.com/"'

        parsed_oauth_authentication = parse_authenticate_header(oauth_authentication_header_value)

        control_dict = {'realm': 'http://sp.example.com/'}
        for k, v in control_dict.iteritems():
            self.assertEquals(parsed_oauth_authentication[k], v)

        self.assertTrue(isinstance(parsed_oauth_authentication, WWWAuthenticate))


    def test_generate_nonce(self):
        self.assertEquals(len(generate_nonce(8)), 8)

    def test_generate_verifier(self):
        self.assertEquals(len(generate_nonce(8)), 8)

    def test_signature_HMAC_SHA1(self):
        consumer_secret = "consumer_secret"
        url = 'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisco,+CA&oauth_signature_method=HMAC-SHA1'

        #url = u'https://www.google.com/m8/feeds/contacts/default/full/?alt=json&max-contacts=10'


        request = {'method': 'GET',
                   'normalized_url': normalize_url(url),
                   'normalized_parameters': normalize_parameters(url)}

        control_signature = 'W1dE5qAXk/+9bYYCH8P6ieE2F1I='
        control_base_signature_string = 'GET&http%3A%2F%2Fapi.simplegeo.com%2F1.0%2Fplaces%2Faddress.json&address%3D41%2520Decatur%2520St%252C%2520San%2520Francisco%252C%2520CA%26category%3Danimal%26oauth_signature_method%3DHMAC-SHA1%26q%3Dmonkeys'

        method = SignatureMethod_HMAC_SHA1()
        self.assertEquals(method.signing_base(request, consumer_secret, None)[1], control_base_signature_string)
        self.assertEquals(method.sign(request, consumer_secret, None), control_signature)

        consumer_secret = 'kd94hf93k423kf44'
        token_secret = 'pfkkdhi9sl3r4s00'

        url = 'http://photos.example.net/photos?file=vacation.jpg&oauth_consumer_key=dpf43f3p2l4k3l03&oauth_nonce=kllo9940pd9333jh&oauth_signature_method=HMAC-SHA1&oauth_timestamp=1191242096&oauth_token=nnch734d00sl2jdk&oauth_version=1.0&size=original'

        request = {'method': 'GET',
                   'normalized_url': normalize_url(url),
                   'normalized_parameters': normalize_parameters(url)}

        control_signature = 'tR3+Ty81lMeYAr/Fid0kMTYa/WM='
        control_base_signature_string = 'GET&http%3A%2F%2Fphotos.example.net%2Fphotos&file%3Dvacation.jpg%26oauth_consumer_key%3Ddpf43f3p2l4k3l03%26oauth_nonce%3Dkllo9940pd9333jh%26oauth_signature_method%3DHMAC-SHA1%26oauth_timestamp%3D1191242096%26oauth_token%3Dnnch734d00sl2jdk%26oauth_version%3D1.0%26size%3Doriginal'

        method = SignatureMethod_HMAC_SHA1()
        self.assertEquals(method.signing_base(request, consumer_secret, token_secret)[1], control_base_signature_string)
        self.assertEquals(method.sign(request, consumer_secret, token_secret), control_signature)


    def test_signature_PLAIN_TEXT(self):
        url = u'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc\u2766,+CA'

        request = {'method': 'POST',
                   'normalized_url': normalize_url(url),
                   'normalized_parameters': normalize_parameters(url)}

        method = SignatureMethod_PLAINTEXT()

        self.assertEquals(method.sign(request, "djr9rjt0jd78jf88", "jjd999tj88uiths3"), 'djr9rjt0jd78jf88%26jjd999tj88uiths3')
        self.assertEquals(method.sign(request, "djr9rjt0jd78jf88", "jjd99$tj88uiths3"), 'djr9rjt0jd78jf88%26jjd99%2524tj88uiths3')
        self.assertEquals(method.sign(request, "djr9rjt0jd78jf88", None), 'djr9rjt0jd78jf88%26')


    def test_normalize_parameters(self):
        url = u'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc\u2766,+CA'
        parameters = 'address=41%20Decatur%20St%2C%20San%20Francisc%E2%9D%A6%2C%20CA&category=animal&q=monkeys'
        self.assertEquals(parameters, normalize_parameters(url))

        url = u'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc\u2766,+CA'
        self.assertEquals(parameters, normalize_parameters(url))

        url = 'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc\xe2\x9d\xa6,+CA'
        self.assertEquals(parameters, normalize_parameters(url))

        url = 'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc%E2%9D%A6,+CA'
        self.assertEquals(parameters, normalize_parameters(url))

        url = u'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc%E2%9D%A6,+CA'
        self.assertEquals(parameters, normalize_parameters(url))



    def test_normalize_url(self):
        url = u'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc\u2766,+CA'
        control_url = "http://api.simplegeo.com/1.0/places/address.json"

        self.assertEquals(control_url, normalize_url(url))

        url = u'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc\u2766,+CA'
        self.assertEquals(control_url, normalize_url(url))

        url = 'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc\xe2\x9d\xa6,+CA'
        self.assertEquals(control_url, normalize_url(url))

        url = 'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc%E2%9D%A6,+CA'
        self.assertEquals(control_url, normalize_url(url))

        url = u'http://api.simplegeo.com:80/1.0/places/address.json?q=monkeys&category=animal&address=41+Decatur+St,+San+Francisc%E2%9D%A6,+CA'
        self.assertEquals(control_url, normalize_url(url))


    def test_oauth_consumer(self):
        consumer_key = "ljdsfhwjkbnflkjfqkebr"
        consumer_secret = "kjwbefpbnwefgwre"
        consumer = OAuthConsumer(consumer_key, consumer_secret)
        self.assertEquals(consumer_key, consumer._key)
        self.assertEquals(consumer_secret, consumer._secret)
        self.assertTrue(isinstance(consumer, OAuthConsumer))

    def test_oauth_token(self):
        token_key = "lfsjdafjnrbeflbwreferf"
        token_secret = "fjrenlwkjbferlwerjuhiuyg"
        token = OAuthToken(token_key, token_secret)
        self.assertTrue(isinstance(token, OAuthToken))


    def test_oauth_PLAINTEXT(self):
        consumer_key = "be4b2eab12130803"
        consumer_secret = "a2e0e39b27d08ee2f50c4d3ec06f"

        token_key = "lfsjdafjnrbeflbwreferf"
        token_secret = "fjrenlwkjbferlwerjuhiuyg"

        tmp_token_key = "kfwbehlfbqlihrbwf"
        tmp_token_secret = "dlewknfd3jkr4nbfklb5ihrlbfg"

        verifier = ''.join(map(str, [randint(1, 40) for x in xrange(7)]))

        request_token_url = build_url("oauth/1.0/request_token/%s/%s/%s/%s" % \
                             (consumer_key, consumer_secret, tmp_token_key, tmp_token_secret))


        authorize_url = build_url("oauth/1.0/authorize/%s" % verifier)
        access_token_url = build_url("oauth/1.0/access_token/%s/%s/%s/%s/%s/%s/%s" % \
                           (consumer_key, consumer_secret,
                            tmp_token_key, tmp_token_secret,
                            verifier, token_key, token_secret))

        protected_resource = build_url("oauth/1.0/protected_resource/%s/%s" % (consumer_secret, token_secret))

        r = Request("GET", protected_resource,
                    debug=stdout_debug
                    )

        consumer = OAuthConsumer(consumer_key, consumer_secret)

        self.assertRaises(RuntimeError, OAuthManager, consumer)
        oauth_manager = OAuthManager(consumer, request_token_url=request_token_url,
                                     authorize_url=authorize_url,
                                     access_token_url=access_token_url,
                                     signature_method=SignatureMethod_PLAINTEXT)

        self.assertEquals(oauth_manager.state, 1)
        self.assertTrue(isinstance(oauth_manager._signature_method, SignatureMethod))
        oauth_manager.setup_request(r)

        #self.assertEquals(oauth_manager._debug, stdout_debug)

        oauth_manager.request_token()

        self.assertEquals(oauth_manager.state, 3)
        self.assertEquals(oauth_manager._tmp_token_key, tmp_token_key)
        self.assertEquals(oauth_manager._tmp_token_secret, tmp_token_secret)

        self.assertEquals(oauth_manager.confirm_url, "%s?oauth_token=%s" % \
                          (oauth_manager._authorize_url, oauth_manager._tmp_token_key))

        pin = json.loads(requests.get(oauth_manager.confirm_url,
                                           debug=stdout_debug).content)['verifier']
        oauth_manager.verify(pin)


        self.assertEquals(oauth_manager.state, 5)
        self.assertEquals(pin, oauth_manager._verifier)
        self.assertEquals(tmp_token_key, oauth_manager._tmp_token_key)
        self.assertEquals(tmp_token_secret, oauth_manager._tmp_token_secret)

        oauth_manager.access_request()

        self.assertTrue(isinstance(oauth_manager._token, OAuthToken))
        self.assertEquals(oauth_manager._token._key, token_key)
        self.assertEquals(oauth_manager._token._secret, token_secret)
        self.assertEquals(oauth_manager.state, 7)

        ## opener, body_output, headers_output = r.build_opener(r._build_url())
        ## oauth_manager.setup(opener)
        ## opener.perform()
        ## response = Response(url=r._build_url(), curl_opener=opener,
        ##                      body_output=body_output,
        ##                      headers_output=headers_output, request=r,
        ##                      cookies=r._cookies)
        ## self.assertEquals(response.status_code, 200)
        ## self.assertEquals(json.loads(response.content)['success'], True)


    def test_oauth_HMAC_SHA1(self):
        consumer_key = "be4b2eab12130803"
        consumer_secret = "a2e0e39b27d08ee2f50c4d3ec06f"

        token_key = "lfsjdafjnrbeflbwreferf"
        token_secret = "fjrenlwkjbferlwerjuhiuyg"

        tmp_token_key = "kfwbehlfbqlihrbwf"
        tmp_token_secret = "dlewknfd3jkr4nbfklb5ihrlbfg"

        verifier = ''.join(map(str, [randint(1, 40) for x in xrange(7)]))

        request_token_url = build_url("oauth/1.0/request_token/%s/%s/%s/%s" % \
                             (consumer_key, consumer_secret, tmp_token_key, tmp_token_secret))


        authorize_url = build_url("oauth/1.0/authorize/%s" % verifier)
        access_token_url = build_url("oauth/1.0/access_token/%s/%s/%s/%s/%s/%s/%s" % \
                           (consumer_key, consumer_secret,
                            tmp_token_key, tmp_token_secret,
                            verifier, token_key, token_secret))

        protected_resource = build_url("oauth/1.0/protected_resource/%s/%s" % (consumer_secret, token_secret))

        r = Request("GET", protected_resource,
                    debug=stdout_debug,
                    headers = (("Test-header", "test-value"), )
                    )

        consumer = OAuthConsumer(consumer_key, consumer_secret)

        self.assertRaises(RuntimeError, OAuthManager, consumer)
        oauth_manager = OAuthManager(consumer, request_token_url=request_token_url,
                                     authorize_url=authorize_url,
                                     access_token_url=access_token_url,
                                     signature_method=SignatureMethod_HMAC_SHA1)

        self.assertEquals(oauth_manager.state, 1)
        self.assertTrue(isinstance(oauth_manager._signature_method, SignatureMethod))
        oauth_manager.setup_request(r)

#        self.assertEquals(oauth_manager._debug, stdout_debug)

        oauth_manager.request_token()

        self.assertEquals(oauth_manager.state, 3)
        self.assertEquals(oauth_manager._tmp_token_key, tmp_token_key)
        self.assertEquals(oauth_manager._tmp_token_secret, tmp_token_secret)

        self.assertEquals(oauth_manager.confirm_url, "%s?oauth_token=%s" % \
                          (oauth_manager._authorize_url, oauth_manager._tmp_token_key))

        pin = json.loads(requests.get(oauth_manager.confirm_url,
                                           debug=stdout_debug).content)['verifier']
        oauth_manager.verify(pin)


        self.assertEquals(oauth_manager.state, 5)
        self.assertEquals(pin, oauth_manager._verifier)
        self.assertEquals(tmp_token_key, oauth_manager._tmp_token_key)
        self.assertEquals(tmp_token_secret, oauth_manager._tmp_token_secret)

        oauth_manager.access_request()

        self.assertTrue(isinstance(oauth_manager._token, OAuthToken))
        self.assertEquals(oauth_manager._token._key, token_key)
        self.assertEquals(oauth_manager._token._secret, token_secret)
        self.assertEquals(oauth_manager.state, 7)
        ## opener, body_output, headers_output = r.build_opener(r._build_url())
        ## oauth_manager.setup(opener)
        ## opener.perform()
        ## response = Response(url=r._build_url(), curl_opener=opener,
        ##                      body_output=body_output,
        ##                      headers_output=headers_output, request=r,
        ##                      cookies=r._cookies)
        ## self.assertEquals(response.status_code, 200)
        ## self.assertEquals(json.loads(response.content)['success'], True)


    def test_3_legged_oauth(self):
        consumer_key = "be4b2eab12130803"
        consumer_secret = "a2e0e39b27d08ee2f50c4d3ec06f"

        token_key = "lfsjdafjnrbeflbwreferf"
        token_secret = "fjrenlwkjbferlwerjuhiuyg"

        tmp_token_key = "kfwbehlfbqlihrbwf"
        tmp_token_secret = "dlewknfd3jkr4nbfklb5ihrlbfg"

        verifier = ''.join(map(str, [randint(1, 40) for x in xrange(7)]))

        request_token_url = build_url("oauth/1.0/request_token/%s/%s/%s/%s" % \
                             (consumer_key, consumer_secret, tmp_token_key, tmp_token_secret))


        authorize_url = build_url("oauth/1.0/authorize/%s" % verifier)
        access_token_url = build_url("oauth/1.0/access_token/%s/%s/%s/%s/%s/%s/%s" % \
                           (consumer_key, consumer_secret,
                            tmp_token_key, tmp_token_secret,
                            verifier, token_key, token_secret))

        protected_resource = build_url("oauth/1.0/protected_resource/%s/%s" % (consumer_secret, token_secret))


        consumer = OAuthConsumer(consumer_key, consumer_secret)
        token = OAuthToken(token_key, token_secret)

        oauth_manager = OAuthManager(consumer, token=token,
                                     signature_method=SignatureMethod_HMAC_SHA1)

        r = requests.get(protected_resource,
                         debug=stdout_debug,
                         auth=oauth_manager
                         )

        self.assertEquals(oauth_manager.state, 7)
        self.assertTrue(isinstance(oauth_manager._signature_method, SignatureMethod_HMAC_SHA1))

#        self.assertEquals(oauth_manager._debug, stdout_debug)
        self.assertEquals(r.status_code, 200)
        self.assertEquals(json.loads(r.content)['success'], True)



class AsyncTestCase(BaseTestCase):


    def success_callback(self, async_client, opener, response, **kwargs):
        self.assertTrue(isinstance(opener.request, Request))
        self.assertTrue(isinstance(response, Response))
        self.assertTrue(isinstance(async_client, AsyncClient))
        self.assertTrue(async_client._default_user_agent in response.content)

    def fail_callback(self, async_client, opener, errno, errmsg, **kwargs):
        self.assertTrue(isinstance(async_client, AsyncClient))

    def test_AsyncClient_core(self):
        async_client = AsyncClient(size=20)

        self.assertEquals(async_client._num_conn, 20)
        self.assertEquals(async_client._remaining, 0)
        self.assertEquals(async_client.success_callback, None)
        self.assertEquals(async_client.fail_callback, None)
        self.assertEquals(async_client._openers_pool, None)
        self.assertEquals(async_client._data_queue, [])
        self.assertEquals(async_client.connections_count, 0)

        async_client.add_handler(url=build_url("/get"),
                                 method="get",
                                 params={"get1": "get1 value",
                                         "get2": "get2 value"},
                                 success_callback=self.success_callback,
                                 fail_callback=self.fail_callback)
        self.assertEquals(len(async_client._data_queue), 1)
        self.assertTrue(isinstance(async_client._data_queue[0], dict))

        params = self.random_dict(10)

        async_client.get(url=build_url("/get"), params=params,
                         success_callback=self.success_callback,
                         fail_callback=self.fail_callback)
        self.assertTrue(isinstance(async_client._data_queue[1], dict))
        self.assertEquals(async_client._data_queue[1]['params'], params)
        self.assertEquals(async_client.connections_count, 2)

    def test_async_get(self):
        async_client_global = AsyncClient(success_callback=self.success_callback,
                                          fail_callback=self.fail_callback)

        params = self.random_dict(10)
        url = build_url("get")

        self.assertEquals(async_client_global.get(url, params=params), async_client_global)
        self.assertEquals(len(async_client_global._data_queue), 1)

        # Test process_func
        def process_func(num_processed, remaining, num_urls,
                         success_len, error_len):
            print("\nProcess {0} {1} {2} {3} {4}".format(num_processed, remaining, num_urls,
                                                         success_len, error_len))
            self.assertEquals(num_urls, 2)

        def fail_callback(request, errno, errmsg, async_client, opener):
            self.assertTrue(isinstance(request, Request))
            self.assertTrue(isinstance(async_client, AsyncClient))
            self.assertEquals(async_client, async_client_global)
            self.assertEquals(errno, 6)
            self.assertEquals(errmsg, "Couldn't resolve host '{0}'".format(request.url[7:]))
        async_client_global.get("http://fwbefrubfbrfybghbfb4gbyvrv.com", params=params,
                                fail_callback=fail_callback)
        self.assertEquals(len(async_client_global._data_queue), 2)
        async_client_global.start(process_func)

    def test_setup_opener(self):
        async_client = AsyncClient()

        data = self.random_dict(10)
        data['url'] = build_url("get")
        data['method'] = 'get'
        opener = async_client.get_opener()

        self.assertEquals(getattr(opener, 'success_callback', None), None)
        self.assertEquals(getattr(opener, 'fail_callback', None), None)
        self.assertEquals(getattr(opener, 'request', None), None)

        data['success_callback'] = lambda **kwargs: kwargs
        data['fail_callback'] = lambda **kwargs: kwargs

        async_client.configure_opener(opener, data)
        self.assertTrue(isinstance(opener.request, Request))
        self.assertTrue(isinstance(opener.success_callback, FunctionType))
        self.assertTrue(isinstance(opener.fail_callback, FunctionType))


    def test_add_handler(self):
        async_client = AsyncClient()
        data = self.request_params()


        self.assertRaises(InterfaceError, async_client.add_handler, **data)

        data['success_callback'] = lambda **kwargs: kwargs
        data['fail_callback'] = lambda **kwargs: kwargs

        async_client.add_handler(**data)
        self.assertEquals(async_client._data_queue[0], data)
        self.assertEquals(async_client._num_urls, 1)
        self.assertEquals(async_client._remaining, 1)

    def test_get_opener(self):
        async_client = AsyncClient()
        opener = async_client.get_opener()
        self.assertEquals(opener.fp, None)
        self.assertNotEqual(opener, None)


    def test_AsyncClient_contextmanager(self):
        with AsyncClient(success_callback=self.success_callback,
                         fail_callback=self.fail_callback) as async_client_global:

            params = self.random_dict(10)
            url = build_url("get")

            self.assertEquals(async_client_global.get(url, params=params), async_client_global)
            self.assertEquals(len(async_client_global._data_queue), 1)

            # Test process_func
            def process_func(num_processed, remaining, num_urls,
                             success_len, error_len):
                print("\nProcess {0} {1} {2} {3} {4}".format(num_processed, remaining, num_urls,
                                                             success_len, error_len))
                self.assertEquals(num_urls, 2)

            def fail_callback(request, errno, errmsg, async_client, opener):
                self.assertTrue(isinstance(request, Request))
                self.assertTrue(isinstance(async_client, AsyncClient))
                self.assertEquals(async_client, async_client_global)
                self.assertEquals(errno, 6)
                self.assertEquals(errmsg, "Couldn't resolve host '{0}'".format(request.url[7:]))
            async_client_global.get("http://fwbefrubfbrfybghbfb4gbyvrv.com", params=params,
                                    fail_callback=fail_callback)
            self.assertEquals(len(async_client_global._data_queue), 2)


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(RequestsTestCase))
    suite.addTest(unittest.makeSuite(ResponseTestCase))
    suite.addTest(unittest.makeSuite(RequestTestCase))
    suite.addTest(unittest.makeSuite(UtilsTestCase))
    suite.addTest(unittest.makeSuite(AuthManagersTestCase))
    suite.addTest(unittest.makeSuite(AsyncTestCase))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest="suite")

########NEW FILE########
