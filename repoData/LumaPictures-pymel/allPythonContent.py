__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# PyMEL documentation build configuration file, created by
# sphinx-quickstart on Thu Jan 29 22:10:49 2009.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# The contents of this file are pickled, so don't put values in the namespace
# that aren't pickleable (module imports are okay, they're removed automatically).
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# add pymel location so we can get the version
sys.path.append(os.path.abspath(os.path.join('..', '..')))
import pymel
_version = pymel.__version__

# If your extensions are in another directory, add it here. If the directory
# is relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
#sys.path.append(os.path.abspath('.'))

# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.doctest', 'sphinx.ext.autosummary',
              'sphinx.ext.inheritance_diagram', 'sphinx.ext.graphviz']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['../templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'PyMEL'
copyright = u'2009, Chad Dombrova'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = _version.rsplit('.', 1)[0]
# The full version, including alpha/beta/rc tags.
release = _version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
#unused_docs = []

# List of directories, relative to source directory, that shouldn't be searched
# for source files.
exclude_trees = []

# The reST default role (used for this markup: `text`) to use for all documents.
default_role = 'obj'

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
add_module_names = False

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'


# Options for HTML output
# -----------------------

# The style sheet to use for HTML and HTML Help pages. A file of that name
# must exist either in Sphinx' static/ path, or in one of the custom paths
# given in html_static_path.
html_style = 'default.css'

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_use_modindex = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, the reST sources are included in the HTML build as _sources/<name>.
#html_copy_source = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = ''

# Output file base name for HTML help builder.
htmlhelp_basename = 'PyMELdoc'


# Options for LaTeX output
# ------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, document class [howto/manual]).
latex_documents = [
  ('index', 'PyMEL.tex', ur'PyMEL Documentation',
   ur'Chad Dombrova', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_use_modindex = True

#doctest_test_doctest_blocks = 'default'

inheritance_graph_attrs = dict(rankdir="TB", nodesep=0.15, ranksep=0.15)
                            #, size='"6.0, 8.0"',
                            #   fontsize=14, ratio='compress')
inheritance_node_attrs = dict(fontsize=8)

autosummary_generate = True


########NEW FILE########
__FILENAME__ = AETemplates
"""
To create an Attribute Editor template using python, do the following:
 	1. create a subclass of `uitypes.AETemplate`
	2. set its ``_nodeType`` class attribute to the name of the desired node type, or name the class using the
convention ``AE<nodeType>Template``
	3. import the module

AETemplates which do not meet one of the two requirements listed in step 2 will be ignored.  To ensure that your
Template's node type is being detected correctly, use the ``AETemplate.nodeType()`` class method::

    import AETemplates
    AETemplates.AEmib_amb_occlusionTemplate.nodeType()

As a convenience, when pymel is imported it will automatically import the module ``AETemplates``, if it exists,
thereby causing any AETemplates within it or its sub-modules to be registered. Be sure to import pymel
or modules containing your ``AETemplate`` classes before opening the Atrribute Editor for the node types in question.

To check which python templates are loaded::

	from pymel.core.uitypes import AELoader
	print AELoader.loadedTemplates()

The example below demonstrates the simplest case, which is the first. It provides a layout for the mib_amb_occlusion
mental ray shader.
"""

from pymel.core import *

class LocalizedTemplate(ui.AETemplate):
    "automatically apply language localizations to template arguments"
    def _applyLocalization(self, name):
        if name is not None and len(name)>2 and name[0] == 'k' and name[1].isupper():
            return mel.uiRes('m_' + self.__class__.__name__ + '.' + name)
        return name

    def addControl(self, control, label=None, **kwargs):
        label = self._applyLocalization(label)
        ui.AETemplate.addControl(self, control, label=label, **kwargs)

    def beginLayout(self, name, collapse=True):
        name =  self._applyLocalization(name)
        ui.AETemplate.beginLayout(self, name, collapse=collapse)

class MentalRayTemplate(LocalizedTemplate):
    def __init__(self, nodeName):
        LocalizedTemplate.__init__(self,nodeName)
        mel.AEswatchDisplay(nodeName)
        self.beginScrollLayout()
        self.buildBody(nodeName)
        mel.AEmentalrayBaseTemplate(nodeName)
        self.endScrollLayout()

class AEmib_amb_occlusionTemplate(MentalRayTemplate):
    def colorChanged(self, node):
        print "changed", node
    def new(self, attr):
        print "new", attr
        self.samplesCtrl = cmds.attrFieldSliderGrp(attribute=attr, min=0,
            sliderMinValue=2, sliderMaxValue=256,
            step=1.0, sliderStep=1.0, label=self._applyLocalization("kSamples"))
    def replace(self, attr):
        print "replace", attr
        self.samplesCtrl(e=1,attribute=attr)
    def buildBody(self, nodeName):
        print "building", nodeName
        self.beginLayout("kParams",collapse=0)
        self.callCustom(self.new, self.replace, "samples")
        self.addControl("bright", label="kBright", changeCommand=self.colorChanged)
        self.addControl("dark", label="kDark", changeCommand=self.colorChanged)
        self.addControl("spread", label="kSpread", preventOverride=True)
        self.addControl("max_distance", label="kMaxDistance")
        self.addControl("reflective", label="kReflective")
        self.addControl("output_mode", label="kOutputMode")
        self.addControl("occlusion_in_alpha", label="kOcclusionInAlpha")
        self.addControl("falloff", label="kFalloff")
        self.addControl("id_inclexcl", label="If You See This It Worked")
        self.endLayout()
        self.suppress("id_nonself")
        self.dimControl(nodeName, "spread", True)

########NEW FILE########
__FILENAME__ = customClasses
"""
This is an experimental feature!!!  for advanced users only.

Allows a user to create their own subclasses of leaf PyMEL node classes, which
are returned by `PyNode` and all other pymel commands.

.. warning:: If you are not familiar with the classmethod and staticmethod
decorators you should read up on them before using this feature.

        The process is fairly simple:
            1.  Subclass a PyNode class.  Be sure that it is a leaf class,
                meaning that it represents an actual Maya node type and not an
                abstract type higher up in the hierarchy.
            2.  Add an _isVirtual classmethod that accepts two arguments: an
                MObject/MDagPath instance for the current object, and its name.
                It should return True if the current object meets the
                requirements to become the virtual subclass, or else False.
            3.  Add optional _preCreate, _create, and _postCreate methods.  For
                more on these, see below
            4.  Register your subclass by calling
                factories.virtualClasses.register. If the _isVirtual callback
                requires the name of the object, set the keyword argument
                nameRequired to True. The object's name is not always
                immediately available and may take an extra calculation to
                retrieve, so if nameRequired is not set the name argument
                passed to your callback could be None.

        The creation of custom nodes may be customized with the use of
        isVirtual, preCreate, create, and postCreate functions; these are
        functions (or classmethods) which are called before / during / after
        creating the node.

        The isVirtual method is required - it is the callback used on instances
        of the base (ie, 'real') objects to determine whether they should be
        considered an instance of this virtual class. It's input is an MObject
        and an optional name (if nameRequired is set to True). It should return
        True to indicate that the given object is 'of this class', False
        otherwise. PyMEL code should not be used inside the callback, only API
        and maya.cmds. Keep in mind that once your new type is registered, its
        test will be run every time a node of its parent type is returned as a
        PyMEL node class, so be sure to keep your tests simple and fast.

        The preCreate function is called prior to node creation and gives you a
        chance to modify the kwargs dictionary; they are fed the kwargs fed to
        the creation command, and return either 1 or 2 dictionaries; the first
        dictionary is the one actually passed to the creation command; the
        second, if present, is passed to the postCreate command.

        The create method can be used to override the 'default' node creation
        command;  it is given the kwargs given on node creation (possibly
        altered by the preCreate), and must return the string name of the
        created node. (...or any another type of object (such as an MObject),
        as long as the postCreate and class.__init__ support it.)

        The postCreate function is called after creating the new node, and
        gives you a chance to modify it.  The method is passed the PyNode of
        the newly created node, as well as the second dictionary returned from
        the preCreate function as kwargs (if it was returned). You can use
        PyMEL code here, but you should avoid creating any new nodes.

        By default, any method named '_isVirtual', '_preCreateVirtual',
        '_createVirtual', or '_postCreateVirtual' on the class is used; if
        present, these must be classmethods or staticmethods.

        Other methods / functions may be used by passing a string or callable
        to the preCreate / postCreate kwargs.  If a string, then the method
        with that name on the class is used; it should be a classmethod or
        staticmethod present at the time it is registered.

        The value None may also be passed to any of these args (except isVirtual)
        to signal that no function is to be used for these purposes.

        If more than one subclass is registered for a node type, the registered
        callbacks will be run newest to oldest until one returns True. If no
        test returns True, then the standard node class is used. Also, for each
        base node type, if there is already a virtual class registered with the
        same name and module, then it is removed. (This helps alleviate
        registered callbacks from piling up if, for instance, a module is
        reloaded.)

        Overriding methods of PyMEL base classes should be performed with care,
        because certain methods are used internally and altering their results
        may cause PyMEL to error or behave unpredictably.  This is particularly
        true for special methods like __setattr__, __getattr__, __setstate__,
        __getstate__, etc.  Some methods are considered too dangerous to modify,
        and registration will fail if the user defines an override for them;
        this set includes __init__, __new__, and __str__.
"""
# Note - all of this, below the 'warning', is copied from the docstring for
# VirtualClassManger.register - keep it in sync!


import pymel.core as pm
from pymel.internal.factories import virtualClasses

#-------------------------------------------------------------------------------



class CustomJointBase(pm.nt.Joint):
    """ this is an example of how to create your own subdivisions of existing nodes. """

    @classmethod
    def _isVirtual( cls, obj, name ):
        """This is the callback for determining if a Joint should become a "virtual" LegJoint or JawJoint, etc.
        Notice that this method is a classmethod, which means it gets passed the class as "cls" instead of an instance as "self".

        PyMEL code should not be used inside the callback, only API and maya.cmds.
        """
        # obj is either an MObject or an MDagPath, depending on whether this class is a subclass of DependNode or DagNode, respectively.
        # we use MFnDependencyNode below because it works with either and we only need to test attribute existence.
        fn = pm.api.MFnDependencyNode(obj)
        try:
            # NOTE: MFnDependencyNode.hasAttribute fails if the attribute does not exist, so we have to try/except it.
            # the _jointClassID is stored on subclass of CustomJointBase
            return fn.hasAttribute( cls._jointClassID )
        except: pass
        return False

    @classmethod
    def _preCreateVirtual(cls, **kwargs ):
        """
        This class method is called prior to node creation and gives you a
        chance to modify the kwargs dictionary that is passed to the creation
        command.  If it returns two dictionaries, the second is used passed
        as the kwargs to the postCreate method

        this method must be a classmethod or staticmethod
        """
        if 'name' not in kwargs and 'n' not in kwargs:
            # if no name is passed, then use the joint Id as the name.
            kwargs['name'] = cls._jointClassID
        # be sure to return the modified kwarg dictionary

        postKwargs = {}

        if 'rotate' in kwargs:
            postKwargs['rotate'] = kwargs.pop('rotate')
        return kwargs, postKwargs

    @classmethod
    def _postCreateVirtual(cls, newNode, **kwargs ):
        """
        This method is called after creating the new node, and gives you a
        chance to modify it.  The method is passed the PyNode of the newly
        created node, and the second dictionary returned by the preCreate, if
        it returned two items. You can use PyMEL code here, but you should
        avoid creating any new nodes.

        this method must be a classmethod or staticmethod
        """
        # add the identifying attribute. the attribute name will be set on subclasses of this class
        newNode.addAttr( cls._jointClassID )
        rotate = kwargs.get('rotate')
        if rotate is not None:
            newNode.attr('rotate').set(rotate)

class LegJoint(CustomJointBase):
    _jointClassID = 'joint_leg'
    def kick(self):
        print "%s is kicking" % self.name()
        return "kiyaah!"


class JawJoint(CustomJointBase):
    _jointClassID = 'joint_jaw'
    def munch(self):
        print "%s is munching" % self.name()
        return "nom nom nom..."

# we don't need to register CustomJointBase because it's just an abstract class to help us easily make our other virtual nodes
virtualClasses.register( LegJoint, nameRequired=False )
virtualClasses.register( JawJoint, nameRequired=False )

def testJoint():
    # make some regular joints
    pm.nt.Joint()
    pm.nt.Joint()
    # now make some of our custom joints
    LegJoint(name='leftLeg')
    JawJoint(rotate=(90,45,0))

    # now list the joints and see which ones are our special joints
    res = pm.ls(type='joint')
    for x in res:
        if isinstance(x, LegJoint ):
            x.kick()
        elif isinstance(x, JawJoint ):
            x.munch()


#-------------------------------------------------------------------------------

# make sure Mayatomr plugin is loaded or the Mib_amb_occlusion node type might not exist
pm.loadPlugin('Mayatomr')
class Mib_amb_occlusion(pm.nt.Mib_amb_occlusion):
    """This is an example of how to replace a node.  Use this technique with care"""
    def occlude(self):
        print "occluding!"

    @staticmethod
    def _isVirtual(obj, name):
        """
        the callback always returns True, so we always replace the default with our own.
        """
        return True

virtualClasses.register( Mib_amb_occlusion, nameRequired=False )


def testMib():
    n = pm.createNode('mib_amb_occlusion')
    n.occlude()

########NEW FILE########
__FILENAME__ = example1
"""

PyMEL makes python within Maya the way it should be-- readable, concise, and object-oriented. PyMEL integrates the python API with the maya.cmds
module by organizing many of its commands into a class hierarchy, and by customizing them to operate in a more succinct and intuitive way.

======================
Project Goals
======================

    - Create an open-source python module for Maya that is intuitive to MEL users and python users alike
    - Fix bugs and design limitations in Maya's python modues, maya.cmds and maya.mel
    - Keep code concise and readable
    - Add organization through class hierarchy and sub-modules
    - Provide documentation accessible via html and the builtin help() function
    - Make it "just work"

======================
Production Proven
======================

Since its release over a year ago, PyMEL has accumulated an impressive resume in both feature films and games:

    - DreamWorks: *Fung Fu Panda*, *Shrek 4*, *Monsters Vs Aliens*, and *How to Train Your Dragon*
    - Luma Pictures: *Pirates of the Carribean: At World's End*, *Harry Potter 6*, and *Wolverine*
    - ImageMovers Digital: Robert Zemeckis' upcoming *A Christman Carol*
    - 2K Sports: *Major League Baseball 2K8*

Here's what Seth Gibson of Bungie Studios, makers of the hit game *Halo*, has to say:

    "Having done production python code myself for many years, wrapping my head around Maya's native
    implementation took a little bit of time.  With PyMel, I can think and write the python code and
    syntax I'm already used to, which speeds up my development time considerably.  It's also
    going to help our other Technical Artists with their Python learning curve, since PyMEL's syntax
    is consistent with most other python packages.  Kudos to the PyMel team for such a well
    thought out project!"

======================
What's New
======================
----------------------
API Hybridization
----------------------

PyMEL 0.9 is a dramatic leap forward in the evolution of python in Maya.  The node and attribute classes have been rewritten
from the ground up to use the python API as their foundation, increasing the speed and fidelity of PyMEL's object-oriented design.

PyMEL harnesses the API to create a name-independent representation of your object.
This means that the annoying inconsistencies of string comparisons are over: no more worrying about short names versus long names, DAG paths, unique paths,
instance paths...  it's all handled intelligently for you.  And what's more, if *anything* causes the name of your object to change it
will automatically be reflected in your python object.

Below, we make a camera, rename it, and then group and instance it, to demonstrate how the name changes are constantly reflected. Keep in mind
that the changes could have just as easily been performed by the user interacting with objects through the GUI.

    >>> cam, shape = camera()
    >>> print cam
    camera1
    >>> cam.rename('renderCam')
    Transform(u'renderCam')
    >>> print cam
    renderCam
    >>> grp = group(cam)
    >>> instance(grp)
    [Transform(u'group2')]
    >>> print cam
    group1|renderCam
    >>> cam.getInstances()
    [Transform(u'group1|renderCam'), Transform(u'group2|renderCam')]

Comparing attributes is just as easy. It doesn't matter what name you use to access an attribute:

    >>> cam.t == cam.translate
    True
    >>> cam.tx == cam.translate.translateX
    True

PyMEL node classes now include hundreds of new methods derived from the API, but with the same intuitive and unified design as before.
With PyMEL you get the benefits of API speed and versatility without the advanced learning curve.

--------------------
BSD License
--------------------

PyMEL is released under the BSD license, which is as open as open source gets.  Your studio can freely use, contribute to, and
modify this module with no strings attached.


------------------------------
Improved Standalone Support
------------------------------

Unlike the maya module, PyMEL behaves the same in a standalone interpreter as it does in an GUI session.
When pymel detects that it is being imported in a standalone
interpreter it performs these operations:

    #. initializes maya.standalone
    #. parses your Maya.env and adds variables to your environment
    #. sources Autodesk's initialization MEL scripts
    #. sources user preferences
    #. sources userSetup.mel

This makes using Maya in a standalone environment the ideal environment for for batch processes and even rendering.

--------------------------------
Tighter MEL Integration
--------------------------------

Calling MEL from python is still an unfortunate necessity, so PyMEL makes it as easy as possible.  This release builds on PyMEL's already
vastly improved method, which allows you to call a mel procedure as if it was a python function:

.. python::

    values = ['one', 'two', 'three', 'four']

    # default
    maya.mel.eval( 'stringArrayRemoveDuplicates( {"'+'","'.join(values)+'"})')

    # PyMEL
    mel.stringArrayRemoveDuplicates( values )

In the new release, when a MEL script called from PyMEL raises an error, you will get the specific MEL error message in the python
traceback, along with line numbers!

For example, here's a procedure "myScript" with a line that will result in an error:

>>> mel.eval( '''global proc myScript( string $stringArg, float $floatArray[] ){
...     float $donuts = `ls -type camera`;}''')

When we call the procedure via PyMEL, we can quickly determine the problem, because PyMEL gives us the error and the line number:

>>> mel.myScript( 'foo', [] )
Traceback (most recent call last):
    ...
MelConversionError: Error occurred during execution of MEL script: line 2: Cannot convert data of type string[] to type float.

Also, getting and setting MEL global variables is accomplished via a special dictionary-like object, which keeps it simple and
intuitive:

>>> melGlobals['$gMainFileMenu']
mainFileMenu
>>> melGlobals['$gGridDisplayGridLinesDefault'] = 2


==========================
Who is PyMEL for?
==========================

--------------------------
For the Novice
--------------------------

Object-oriented programming, like that provided by PyMEL, is more intuitive to learn because the functionality of an object is directly
associated with the object itself.  For an artist starting to program in Maya, the first question you might ask is "what can I do with this node?"
Using a procedural approach, like that offered by MEL or maya.cmds, you'll have to dig through the hundreds of MEL commands looking for the one that you want.
For a camera node, the ``camera`` MEL command is easy to find, but did you find ``orbit``, ``track``,
``dolly``, and ``tumble``, which also work on cameras?  In PyMEL, all you have to do is type ``help(Camera)`` in the python script editor
to find out all the things a camera node can do, or just look up the Camera class in the PyMEL docs.


--------------------------
For the MEL Scripter
--------------------------

When we say PyMEL is concise and easy to read, we mean it.

MEL:

.. python::

    string $sel[] = `ls -sl`;
    string $shapes[] = `listRelatives -s $sel[0]`;
    string $conn[] = `listConnections -s 1 -d 0 $shapes[0]`;
    setAttr ( $conn[0] + ".radius") 3;

PyMEL

.. python::

    selected()[0].getShape().inputs()[0].radius.set(3)


-----------------------------
For the Technical Director
-----------------------------

For those looking to master python in a production environment, PyMEL is more than a module for Maya scripting,
it is a repository of example python code -- a self-contained pipeline demonstrating
advanced python concepts like function factories, metaclasses, and decorators, as well as essential production practices such as parsing,
pickling, logging, and unit testing.

For those who are already masters of python and who naturally expect more out of a python package, PyMEL is for you, too.  It was written
in for use in production by experiened programmers with a vision for how to add object-oriented design to Maya.


==========================
Powerful Classes
==========================

**Node classes** for every node type

.. python::

    camTrans, cam = camera()  # create a new camera
    cam.setFocalLength(100)
    fov = cam.getHorizontalFieldOfView()
    cam.dolly( -3 )
    cam.track(left=10)
    cam.addBookmark('new')



An **Attribute class** organizes all the attribute commands in one place

.. python::

    s = polySphere()[0]
    if s.visibility.isKeyable() and not s.visibility.isLocked():
        s.visibility.set( True )
        s.visibility.lock()
        print s.visibility.type()


Manipulate **file paths** with ease

.. python::

    #backup all mb files in the current scene's directory
    basedir = sceneName().parent
    backupDir = basedir / "backup" #slash op joins paths
    if not backupDir.exists():
        backupDir.mkdir()
    for file in basedir.files( '*.mb' ):
        print "backing up: ", file.name
        file.copy( backupDir / (file.namebase + ".old") )

Work with shape **components**, perform **vector math**, and easily set object attributes with the results

.. python::

    #select all faces that point up in world space
    s = polySphere()[0]
    for face in s.faces:
        if face.getNormal('world').y > 0.0:
           select( face, add=1)

Manage optionVars as a python dictionary

.. python::

    if 'numbers' not in optionVar:
        optionVar['numbers'] = [1,24,47]
    optionVar['numbers'].append(9)
    numArray = optionVar.pop('numbers')

==========================
Do More with Less Code
==========================

If you've tried working with the default maya.cmds and maya.mel modules, you know that they add a lot of awkward syntax that can slow you down. PyMEL streamlines
this syntax in many ways.

Unlike maya.cmds, PyMEL is safe to import into the main namespace, so you don't have to prefix all your commands:

.. python::

    # default
    cmds.select( cmds.ls() )

    # PyMEL
    select( ls() )

PyMEL provides customized **operators** for succinct scripting:

.. python::

    cam = camera()[0]
    sphere = polySphere()[0]
    sphere | cam  # parent the camera to the sphere

    cam.tx >> cam.ty  # connect operator
    cam.tx // cam.ty  # disconnect operator




==========================
Code Comparison
==========================

--------------------------
maya.cmds
--------------------------

.. python::

    objs = cmds.ls( type= 'transform')
    if objs is not None:                    # returns None when it finds no matches
        for x in objs:
            print mm.eval('longNameOf("%s")' % x)

            # make and break some connections
            cmds.connectAttr(   '%s.sx' % x,  '%s.sy' % x )
            cmds.connectAttr(   '%s.sx' % x,  '%s.sz' % x )
            cmds.disconnectAttr( '%s.sx' % x,  '%s.sy' % x)

            conn = cmds.listConnections( x + ".sx", s=0, d=1, p=1)
            # returns None when it finds no matches
            if conn is not None:
                for inputPlug in conn:
                    cmds.disconnectAttr( x + ".sx", inputPlug )

            # add and set a string array attribute with the history of this transform's shape
            if not mm.eval( 'attributeExists "newAt" "%s"' % x):
                cmds.addAttr(  x, ln='newAt', dataType='stringArray')
            shape = cmds.listRelatives( x, s=1 )
            if shape is not None:
                history = cmds.listHistory( shape[0] )
            else:
                history = []
            args = tuple( ['%s.newAt' % x, len(history)] + history )
            cmds.setAttr( *args ,  type= 'stringArray' )

            # get and set some attributes
            cmds.setAttr ( '%s.rotate' % x, 1,  1, 1 )
            scale = cmds.getAttr ( '%s.scale' % x )
            scale = scale[0] # maya packs the previous result in a list for no apparent reason
            trans = list( cmds.getAttr ( '%s.translate' % x )[0] )  # the tuple must be converted to a list for item assignment
            trans[0] *= scale[0]
            trans[1] *= scale[1]
            trans[2] *= scale[2]
            cmds.setAttr ( '%s.scale' % x, trans[0], trans[1], trans[2] )
            mm.eval('myMelScript("%s",{%s,%s,%s})' % (cmds.nodeType(x), trans[0], trans[1], trans[2]) )

--------------------------
MEL
--------------------------

.. python::

    string $objs[] = `ls -type transform`;
    for ($x in $objs) {
        print (longNameOf($x)); print "\\n";

        // make and break some connections
        connectAttr( $x + ".sx") ($x + ".sy");
        connectAttr( $x + ".sx") ($x + ".sz");
        disconnectAttr( $x + ".sx") ($x + ".sy");
        string $conn[] = `listConnections -s 0 -d 1 -p 1 ($x + ".sx")`;
        for ($inputPlug in $conn)
            disconnectAttr ($x + ".sx") $inputPlug;

        // add and set a string array attribute with the history of this transform's shape
        if ( !`attributeExists "newAt" $x`)
            addAttr -ln newAt -dataType stringArray $x;
        string $shape[] = `listRelatives -s $x`;
        string $history[] = `listHistory $shape[0]`;
        string $elements = "";
        for ($elem in $history)
            $elements += "\"" + $elem + "\" ";
        eval ("setAttr -type stringArray " + $x + ".newAt " + `size $history` + $elements);
        print `getAttr ( $x + ".newAt" )`;

        // get and set some attributes
        setAttr ($x + ".rotate") 1 1 1;
        float $trans[] = `getAttr ($x + ".translate")`;
        float $scale[] = `getAttr ($x + ".scale")`;
        $trans[0] *= $scale[0];
        $trans[1] *= $scale[1];
        $trans[2] *= $scale[2];
        setAttr ($x + ".scale") $trans[0] $trans[1] $trans[2];

        // call some other scripts
        myMelScript( `nodeType $x`, $trans );
    }


--------------------------
PyMEL
--------------------------

.. python::

    from pymel.all import *
    for x in ls( type='transform'):
        print x.longName()                # object oriented design

        # make and break some connections
        x.sx >> x.sy                      # connection operator
        x.sx >> x.sz
        x.sx // x.sy                      # disconnection operator
        x.sx.disconnect()                 # smarter methods -- (automatically disconnects all inputs and outputs when no arg is passed)

        # add and set a string array attribute with the history of this transform's shape
        x.setAttr( 'newAt', x.getShape().history(), force=1 )

        # get and set some attributes
        x.rotate.set( [1,1,1] )
        trans = x.translate.get()
        trans *= x.scale.get()           # vector math
        x.translate.set( trans )         # ability to pass list/vector args
        mel.myMelScript(x.type(), trans) # automatic handling of mel procedures

"""

__test__ = False

#---------------------------------------------------------------------
#        Default Python
#---------------------------------------------------------------------


import maya.mel as mm
import maya.cmds as cmds

mm.eval("""
global proc myMelScript( string $type, float $val[] )
{     print ("the value is:" + $val[0] + " " + $val[1] + " " + $val[2] );
    print "\\n";
}
""")


cmds.file( newFile=1, force=1)
objs = cmds.ls( type= 'transform')
if objs is not None:                    # returns None when it finds no matches
    for x in objs:
        print mm.eval('longNameOf("%s")' % x)

        # make and break some connections
        cmds.connectAttr(   '%s.sx' % x,  '%s.sy' % x )
        cmds.connectAttr(   '%s.sx' % x,  '%s.sz' % x )
        cmds.disconnectAttr( '%s.sx' % x,  '%s.sy' % x)

        conn = cmds.listConnections( x + ".sx", s=0, d=1, p=1)
        # returns None when it finds no matches
        if conn is not None:
            for inputPlug in conn:
                cmds.disconnectAttr( x + ".sx", inputPlug )

        # add and set a string array attribute with the history of this transform's shape
        if not mm.eval( 'attributeExists "newAt" "%s"' % x):
            cmds.addAttr(  x, ln='newAt', dataType='stringArray')
        shape = cmds.listRelatives( x, s=1, f=1 )
        if shape is not None:
            history = cmds.listHistory( shape[0] )
        else:
            history = []
        args = tuple( ['%s.newAt' % x, len(history)] + history )
        cmds.setAttr( *args ,  **{ 'type' : 'stringArray' } )

        # get and set some attributes
        cmds.setAttr ( '%s.rotate' % x, 1,  1, 1 )
        scale = cmds.getAttr ( '%s.scale' % x )
        scale = scale[0] # maya packs the previous result in a list for no apparent reason
        trans = list( cmds.getAttr ( '%s.translate' % x )[0] )  # the tuple must be converted to a list for item assignment
        trans[0] *= scale[0]
        trans[1] *= scale[1]
        trans[2] *= scale[2]
        cmds.setAttr ( '%s.scale' % x, trans[0], trans[1], trans[2] )
        mm.eval('myMelScript("%s",{%s,%s,%s})' % (cmds.nodeType(x), trans[0], trans[1], trans[2]) )



#---------------------------------------------------------------------
#        Default Python
#---------------------------------------------------------------------

import pymel.core as pm
pm.newFile( force=1 )
for x in pm.ls( type='transform'):
    print x.longName()                # object oriented design

    # make and break some connections
    x.sx >> x.sy                      # connection operator
    x.sx >> x.sz
    x.sx // x.sy                      # disconnection operator
    x.sx.disconnect()                 # smarter methods -- (automatically disconnects all inputs and outputs when no arg is passed)

    # add and set a string array attribute with the history of this transform's shape
    if not x.hasAttr('newAt'):
        x.addAttr( 'newAt', dataType='stringArray')
    x.newAt.set( x.getShape().history() )

    # get and set some attributes
    x.rotate.set( [1,1,1] )
    trans = x.translate.get()
    trans *= x.scale.get()           # vector math
    x.translate.set( trans )         # ability to pass list/vector args
    pm.mel.myMelScript(x.type(), trans) # automatic handling of mel procedures
########NEW FILE########
__FILENAME__ = example2
import pymel.core as pm

s = pm.polySphere()[0] # second in list is the history node, if construction history is on
c = pm.polyCube()[0]

print c, s
c.setTranslation( [0,2,0] )
s.setTranslation( [1,-2,0] )

g = pm.group( s, c, n='newGroup' )

print "The children of %s are %s" % (g, g.getChildren())
#print g.getChildren()[0].getShape()
print "difference =", c.translate.get() - s.translate.get()  # basic vector operation

s2 = s.duplicate()[0]

# move the new sphere relatively along the z axis
s2.setTranslation([0,0,-2], relative=1)

# cycle through and move some verts.
# we're moving each verts a relative amount based on its vertex number
num = s2.numVertices()
for i, vert in enumerate(s2.verts):
	pm.move( vert, [ i / float(num), 0, 0 ], r=1)


# save the current scene scene
currScene = pm.saveAs( 'pymel_test_main.ma')

# the parent property gives the parent directory of the current scene.
# the / (slash or divide) operator serves as an os independent way of concatenating paths
# it is a shortut to os.path.join
exportScene = currScene.parent / 'pymel_test_ref.ma'

# if a file already exists where we want to export, delete it first
if exportScene.exists():
	print "removing existing pymel export scene"
	exportScene.remove()

print "exporting new scene:", exportScene
pm.exportSelected( exportScene, f=1 )

# delete the original group
pm.delete(g)

# reference it in a few times
for i in range(1,4):
	ref = pm.createReference( exportScene, namespace=('foo%02d' % i) )
	# offset each newly created reference:
	# first we list all the nodes in the new reference, and get the first in the list.
	# this will be the 'newGroup' node.
	allRefNodes = ref.nodes()
	print "moving" , allRefNodes[0]
	allRefNodes[0].tx.set( 2*i )

# print out some information about our newly created references
allRefs = pm.listReferences()
for r in allRefs:
	print r.namespace, r.refNode, r.withCopyNumber()


# the namespace property of the FileReference class can be used to set the namespace as well as to get it.
allRefs[2].namespace = 'super'


# but if we have to change the namespace of the objects after they have been imported
# there is a different, albeit, more complicated way
ns = allRefs[0].namespace
allRefs[0].importContents()

# heres one way to change the namespace
try:
	pm.namespace( add = 'bar' )
except: pass


for node in pm.ls( ns + ':*', type='transform'):
	newname = node.swapNamespace( 'bar')
	print "renaming %s to %s" % (node, newname)
	node.rename( newname  )




# unload the other one
allRefs[1].unload()







########NEW FILE########
__FILENAME__ = pipeGen
from __future__ import with_statement
import pymel.core as pm

"""
work in progress:

tool for creating procedural pipes

pipes can be moved in a typical hierarchical way by selecting joint handles and moving or rotating.
this will move all pipes below it in the pipe chain.

in addition, by hitting insert or holding the d (pivot) key, only the selected joint will be moved,
preserving the position of all other joints.

to run:
	>>> import pymel.examples.pipeGen as pipeGen
	>>> pipeGen.pipeGenWin()

to create pipes via a script:

	>>> pipeGen.startPipe()
	>>> pipeGen.extendPipe()

"""


ALPHABET = 'ABCDEFGHIJKLMNOP'



def startPipe( basename='pipe',
			pipeRadius = 0.2,
			jointRadius = 0.02,
			subdivAxis = 16,
			subdivJoint = 8,
			jointLength = .8,
			connectorRadius = .1,
			connectorThickness = .2,
			connectorOffset = .001
			):
	print basename
	i=1
	name = basename + str(i)
	while pm.ls( name + '_Jnt0'):
		i += 1
		name = basename + str(i)

	try:
		startPos = pm.selected()[0].getTranslation(ws=1)
	except:
		startPos = [0,0,0]

	pm.select(cl=1)

	rigGrp = pm.group(empty=True, n='%s_RigGrp' % name)
	geoGrp = pm.group(empty=True, n='%s_GeoGrp' % name)

	root = pm.joint( name=name+'_Jnt0')

	trans = pm.group(empty=True, n='%s_Elbow0' % name)
	pm.pointConstraint( root, trans )

	root.scale.lock()

	root.addAttr( 'globalPipeRadius',
			defaultValue=pipeRadius,
			min=.0001 )
	root.globalPipeRadius.showInChannelBox(1)

	root.addAttr( 'globalJointRadius',
		defaultValue=jointRadius  )
	root.globalJointRadius.showInChannelBox(1)

	root.addAttr( 'subdivisionsAxis', at = 'short',
		defaultValue=subdivAxis,
		min=4 )
	root.subdivisionsAxis.showInChannelBox(1)

	root.addAttr( 'subdivisionsJoint', at = 'short',
		defaultValue=subdivJoint )
	root.subdivisionsJoint.showInChannelBox(1)

	root.addAttr( 'globalConnectorRadius',
		defaultValue=connectorRadius )
	root.globalConnectorRadius.showInChannelBox(1)

	root.addAttr( 'globalConnectorThickness',
		defaultValue=connectorThickness )
	root.globalConnectorThickness.showInChannelBox(1)

	root.addAttr( 'globalConnectorOffset',
		min = 0,
		defaultValue=connectorOffset )
	root.globalConnectorOffset.showInChannelBox(1)

	root.radius.showInChannelBox(0)
	root.displayHandle = 1

	root.setParent(rigGrp)
	trans.setParent(rigGrp)

	root.setTranslation( startPos )
	root.select()
	extendPipe(jointLength)


'''
def makeConnectors( parent, name, num):
	# Connectors
	pipe, pipeist = polyCylinder( height = 1, radius=1,
						name = '%s_ConnectorGeo1%s' % (name, num) )
'''


def extendPipe( jointLength=1 ):

	defaultLength = 3.0
	currJnt = ''
	name = ''
	root = ''

	newJnts = []

	for sel in pm.selected():
		sel.select()
		# for now, there's no branching, so we find the deepest joint
		try:
			currJnt = sel
			name = currJnt.split('_')[0]
			root = pm.nt.Joint( '%s_Jnt0' % name )

		except:
			raise "select an object on the pipe that you want to extend"


		# naming
		#----------
		num = int(currJnt.extractNum())

		try:
			twoPrev = int(currJnt.getParent().getParent().extractNum())
		except:
			twoPrev = num-2

		try:
			prev =	int(currJnt.getParent().extractNum())
		except:
			prev = num-1

		curr = num
		new = int(currJnt.nextUniqueName().extractNum())

		print "extending from", currJnt, new

		branchNum = len(currJnt.getChildren())
		#print '%s has %s children' % (currJnt, branchNum)
		if branchNum:
			print "new segment is a branching joint"
			currJnt.addAttr( 'pipeLengthInBtwn%s' % branchNum, min=0 )
			#currJnt.attr( 'pipeLengthInBtwn%s' % branchNum ).showInChannelBox(1)

		#print twoPrev, prev, curr, new

		rigGrp = '%s_RigGrp' % name
		geoGrp = '%s_GeoGrp' % name

		# new skeletal joint
		#---------------------

		if new>1:
			prevJnt = pm.nt.Joint( '%s_Jnt%s' % (name, prev) )
			pos = 2*currJnt.getTranslation(ws=1) - prevJnt.getTranslation(ws=1)
		else:
			prevJnt = None
			pos = currJnt.getTranslation(ws=1) + [0,defaultLength,0]

		newJnt = pm.joint( p=pos, n= '%s_Jnt%s' % (name, new) )
		# re-orient the last created joint, which is considered our current joint
		pm.joint( currJnt, e=1, zeroScaleOrient=1, secondaryAxisOrient='yup', orientJoint='xyz')



		# pymel method: NEEDS FIXING
		#currJnt.setZeroScaleOrient(1)
		#currJnt.setSecondaryAxisOrient('yup') # Flag secondaryAxisOrient can only be used in conjunction with orientJoint flag.
		#currJnt.setOrientJoint('xyz')
		newJnt.scale.lock()

		newJnt.addAttr( 'pipeLength',
			defaultValue=jointLength, min=.0001 )
		newJnt.pipeLength.showInChannelBox(1)

		newJnt.addAttr( 'pipeLengthInBtwn0', min=0 )
		#newJnt.attr( 'pipeLengthInBtwn0' ).showInChannelBox(1)

		newJnt.addAttr( 'pipeLeadIn', dv=0, min=0 )
		newJnt.pipeLeadIn.showInChannelBox(1)

		newJnt.addAttr( 'radiusMultiplier', dv=1, min=0 )
		newJnt.radiusMultiplier.showInChannelBox(1)
		newJnt.displayHandle = 1

		newJnt.radius.showInChannelBox(0)

		# bend hierarchy
		#-----------------

		trans = pm.group( empty=1, n='%s_Elbow%s' % (name, new))
		trans.rotateOrder = 1

		pm.aimConstraint( 	currJnt, trans,
							aimVector = [0, -1, 0],
			 				upVector = [-1, 0, 0]
							)
		pm.pointConstraint( newJnt, trans )

		trans.setParent( rigGrp )

		# keep the end joint oriented along the joint chain so that it can be slid back
		# and forth to change the length of the current pipe segment
		pm.delete( pm.orientConstraint( trans, newJnt ) )

		# Main Pipe
		#------------
		pipe, pipeHist = pm.polyCylinder( height = 1, radius=1,
							name = '%s_Geo%s' % (name, new) )
		pipeHist = pipeHist.rename( '%s_GeoHist%s' % (name, new)  )

		pipe.setPivots( [0, -.5, 0], r=1 )


		root.globalPipeRadius >> pipe.sx
		root.globalPipeRadius >> pipe.sz

		pipeHist.createUVs = 3   # normalize and preserve aspect ratio
		root.subdivisionsAxis >> pipeHist.subdivisionsAxis


		# Pipe Connectors
		#-------------
		pipeConn1, pipeConnHist1 = pm.polyCylinder( height = .1, radius=1,
							name = '%s_Connector1AGeo%s' % (name, new) )
		pipeConnHist1 = pipeConnHist1.rename( '%s_Connector1AHist%s' % (name, new)  )
		pipeConn1.setPivots( [0, -.05, 0], r=1 )
		pipeConn1.setParent( pipe, relative=True )
		pipeConn1.rotate.lock()
		root.subdivisionsAxis >> pipeConnHist1.subdivisionsAxis


		pipeConn2, pipeConnHist2 = pm.polyCylinder( height = .1, radius=1,
							name = '%s_Connector2AGeo%s' % (name, new) )
		pipeConnHist2 = pipeConnHist2.rename( '%s_Connector2AHist%s' % (name, new)  )
		pipeConn2.setPivots( [0, .05, 0], r=1 )
		pipeConn2.setParent( pipe, relative=True )
		pipeConn2.rotate.lock()
		root.subdivisionsAxis >> pipeConnHist2.subdivisionsAxis

		pipeConn1, pipeConnHist1 = pm.polyCylinder( height = .1, radius=1,
							name = '%s_Connector1BGeo%s' % (name, new) )
		pipeConnHist1 = pipeConnHist1.rename( '%s_Connector1BHist%s' % (name, new)  )
		pipeConn1.setPivots( [0, -.05, 0], r=1 )
		pipeConn1.setParent( pipe, relative=True )
		pipeConn1.rotate.lock()
		pipeConn1.visibility = 0
		root.subdivisionsAxis >> pipeConnHist1.subdivisionsAxis


		pipeConn2, pipeConnHist2 = pm.polyCylinder( height = .1, radius=1,
							name = '%s_Connector2BGeo%s' % (name, new) )
		pipeConnHist2 = pipeConnHist2.rename( '%s_Connector2BHist%s' % (name, new)  )
		pipeConn2.setPivots( [0, .05, 0], r=1 )
		pipeConn2.setParent( pipe, relative=True )
		pipeConn2.rotate.lock()
		pipeConn2.visibility = 0
		root.subdivisionsAxis >> pipeConnHist2.subdivisionsAxis


		pipe.setParent( geoGrp )


		#constraints
		pm.pointConstraint( currJnt, pipe )
		aim = pm.aimConstraint( newJnt, pipe )
		aim.offsetZ = -90



		# convert the previous pipe joint into a bendy joint
		if new > 1:
			currElbow = pm.PyNode('%s_Elbow%s' % (name, curr) )
			pipeLoc = pm.spaceLocator( n= '%s_PipeDummy%s' % (name, new) )
			pipeLoc.hide()

			tweak = pm.group(n='%s_ElbowTweak%s' % (name, new))
			tweak.rotateOrder = 2
			#tweak.translate = currElbow.translate.get()
			tweak.setParent( currElbow, r=1 )
			pm.aimConstraint( 	prevJnt, tweak,
							aimVector = [1, 0, 0],
			 				upVector = [0, -1, 0],
							skip=['z', 'x'] )


			# Pipe Joint
			#------------
			pipeJnt, pipeJntHist = pm.polyCylinder( height = 1, radius=1,
								name = '%s_JntGeo%s' % (name, new),
								subdivisionsAxis = 20,
								subdivisionsHeight = 30 )
			pipeJnt.setParent( geoGrp )
			pipeJnt.sy = jointLength
			pipeJnt.visibility = 0
			pipeJntHist = pipeJntHist.rename( '%s_JntGeoHist%s' % (name, new)  )
			pipeJntHist.createUVs = 3   # normalize and preserve aspect ratio

			root.subdivisionsAxis >> pipeJntHist.subdivisionsAxis
			root.subdivisionsJoint >> pipeJntHist.subdivisionsHeight

			# constraints
			pm.parentConstraint( pipeLoc, pipeJnt )
			pipeJnt.translate.lock()
			pipeJnt.rotate.lock()
			#pipeJnt.scale.lock()


			aim = pm.PyNode('%s_Elbow%s_aimConstraint1' % (name, curr))
			aim.setWorldUpType( 2 )
			aim.setWorldUpObject( newJnt )

			bend, bendHandle = pm.nonLinear( '%s_JntGeo%s' % (name, new),
				type='bend' )
			bendHandle = pm.nt.Transform(bendHandle).rename( '%s_BendHandle%s' % (name, new) )
			bendHandle.sx =.5
			bendHandle.hide()

			bend.rename( '%s_Bend%s' % (name, new) )

			pm.parentConstraint( '%s_ElbowTweak%s' % (name, new), bendHandle )

			aim = '%s_ElbowTweak%s_aimConstraint1' % (name, new)
			#aim.worldUpType.set( 1 )
			pm.aimConstraint( aim, e=1, worldUpType='object', worldUpObject=newJnt )

			bendHandle.setParent(rigGrp)

			expr = """
	float $v1[];
	$v1[0] = %(name)s_Elbow%(twoPrev)s.translateX - %(name)s_Elbow%(prev)s.translateX;
	$v1[1] = %(name)s_Elbow%(twoPrev)s.translateY - %(name)s_Elbow%(prev)s.translateY;
	$v1[2] = %(name)s_Elbow%(twoPrev)s.translateZ - %(name)s_Elbow%(prev)s.translateZ;

	float $v2[];
	$v2[0] = %(name)s_Elbow%(curr)s.translateX - %(name)s_Elbow%(prev)s.translateX;
	$v2[1] = %(name)s_Elbow%(curr)s.translateY - %(name)s_Elbow%(prev)s.translateY;
	$v2[2] = %(name)s_Elbow%(curr)s.translateZ - %(name)s_Elbow%(prev)s.translateZ;
	float $mag = sqrt ( $v2[0]*$v2[0] + $v2[1]*$v2[1] + $v2[2]*$v2[2] );
	float $angleData[] = `angleBetween -v1 $v1[0] $v1[1] $v1[2] -v2 $v2[0] $v2[1] $v2[2] `;
	float $angle = $angleData[3];

	if ( !equivalentTol($angle,180.0, 0.1) )
	{
	float $jointDeg = 180 - $angle;
	float $jointRad = -1 * deg_to_rad( $jointDeg );
	%(name)s_Bend%(curr)s.curvature = $jointRad/2;

	%(name)s_ElbowTweak%(curr)s.rotateZ = $jointDeg/2;
	%(name)s_Jnt%(prev)s.pipeLengthInBtwn%(branch)s = %(name)s_Jnt%(prev)s.pipeLength;
	float $pipeLength = %(name)s_Jnt%(prev)s.pipeLengthInBtwn%(branch)s;

	float $centerAngleRad = deg_to_rad(90 -$angle/2);
	float $delta = 0;
	float $pipeLengthRatio = 1;

	if ($centerAngleRad > 0.0) {
		float $radius = .5*%(name)s_Jnt%(prev)s.pipeLengthInBtwn%(branch)s/ $centerAngleRad;
		$delta = $radius - ($radius * cos( $centerAngleRad ));
		$pipeLengthRatio = .5 * $pipeLength / ( $radius * sin( $centerAngleRad ) );
		$pipeLength *= $pipeLengthRatio;
	}
	%(name)s_PipeDummy%(curr)s.translateX = -1*$delta;

	%(name)s_BendHandle%(curr)s.scaleX = .5*%(name)s_Jnt%(prev)s.pipeLengthInBtwn%(branch)s;
	%(name)s_BendHandle%(curr)s.scaleY = %(name)s_BendHandle%(curr)s.scaleX;
	%(name)s_BendHandle%(curr)s.scaleZ = %(name)s_BendHandle%(curr)s.scaleX;

	%(name)s_JntGeo%(curr)s.scaleY = $pipeLength * (1.0+%(name)s_Jnt%(curr)s.pipeLeadIn);
	%(name)s_JntGeo%(curr)s.scaleX = %(name)s_Jnt0.globalPipeRadius + %(name)s_Jnt0.globalJointRadius;
	%(name)s_JntGeo%(curr)s.scaleZ = %(name)s_JntGeo%(curr)s.scaleX;
	%(name)s_JntGeo%(curr)s.visibility = 1;
	%(name)s_Connector1BGeo%(curr)s.visibility=1;
	%(name)s_Connector2BGeo%(curr)s.visibility=1;
	}
	else
	{
	%(name)s_Jnt%(prev)s.pipeLengthInBtwn%(branch)s = 0;
	%(name)s_JntGeo%(curr)s.scaleY = 0;
	%(name)s_JntGeo%(curr)s.visibility = 0;
	%(name)s_Connector1BGeo%(curr)s.visibility=0;
	%(name)s_Connector2BGeo%(curr)s.visibility=0;
	}
	%(name)s_Connector1AGeo%(curr)s.scaleY = %(name)s_Jnt0.globalConnectorThickness * (1/%(name)s_Geo%(curr)s.scaleY);
	%(name)s_Connector2AGeo%(curr)s.scaleY = %(name)s_Connector1AGeo%(curr)s.scaleY;
	%(name)s_Connector1AGeo%(curr)s.translateY = -.5 + %(name)s_Connector1AHist%(curr)s.height/2 + .1*%(name)s_Jnt0.globalConnectorOffset;
	%(name)s_Connector2AGeo%(curr)s.translateY = 0.5 - %(name)s_Connector1AHist%(curr)s.height/2 - .1*%(name)s_Jnt0.globalConnectorOffset;
	%(name)s_Connector1AGeo%(curr)s.scaleX = 1 + %(name)s_Jnt0.globalConnectorRadius;
	%(name)s_Connector1AGeo%(curr)s.scaleZ = 1 + %(name)s_Jnt0.globalConnectorRadius;
	%(name)s_Connector2AGeo%(curr)s.scaleX = 1 + %(name)s_Jnt0.globalConnectorRadius;
	%(name)s_Connector2AGeo%(curr)s.scaleZ = 1 + %(name)s_Jnt0.globalConnectorRadius;

	%(name)s_Connector1BGeo%(curr)s.scaleY = %(name)s_Jnt0.globalConnectorThickness * (1/%(name)s_Geo%(curr)s.scaleY);
	%(name)s_Connector2BGeo%(curr)s.scaleY = %(name)s_Connector1BGeo%(curr)s.scaleY;
	%(name)s_Connector1BGeo%(curr)s.translateY = -.5 + %(name)s_Connector1BHist%(curr)s.height/2 - .1*%(name)s_Jnt0.globalConnectorOffset - .1*%(name)s_Connector1BGeo%(curr)s.scaleY;
	%(name)s_Connector2BGeo%(curr)s.translateY = 0.5 - %(name)s_Connector1BHist%(curr)s.height/2 + .1*%(name)s_Jnt0.globalConnectorOffset + .1*%(name)s_Connector1BGeo%(curr)s.scaleY;
	%(name)s_Connector1BGeo%(curr)s.scaleX = 1 + %(name)s_Jnt0.globalConnectorRadius;
	%(name)s_Connector1BGeo%(curr)s.scaleZ = 1 + %(name)s_Jnt0.globalConnectorRadius;
	%(name)s_Connector2BGeo%(curr)s.scaleX = 1 + %(name)s_Jnt0.globalConnectorRadius;
	%(name)s_Connector2BGeo%(curr)s.scaleZ = 1 + %(name)s_Jnt0.globalConnectorRadius;

	%(name)s_Geo%(curr)s.scaleY = $mag - .5*%(name)s_Jnt%(curr)s.pipeLengthInBtwn0 - .5*%(name)s_Jnt%(prev)s.pipeLengthInBtwn%(branch)s;
	normalize($v2);
	%(name)s_Geo%(curr)s_pointConstraint1.offsetX = .5*%(name)s_Jnt%(prev)s.pipeLengthInBtwn%(branch)s * $v2[0];
	%(name)s_Geo%(curr)s_pointConstraint1.offsetY = .5*%(name)s_Jnt%(prev)s.pipeLengthInBtwn%(branch)s * $v2[1];
	%(name)s_Geo%(curr)s_pointConstraint1.offsetZ = .5*%(name)s_Jnt%(prev)s.pipeLengthInBtwn%(branch)s * $v2[2];
	""" % { 	'twoPrev' : prev,
				'prev' : 	curr,
				'curr'	: 	new,
				'new'	:	new+1,
				'name': 	name,
				'branch':	branchNum

			}
			#print expr
			print 'editing %s_PipeExpr%s' % (name, new)
			#expression( '%s_PipeExpr%s' % (name, curr), e=1, s=expr, ae=1  )
			pm.expression( s=expr, ae=1, n = '%s_PipeExpr%s' % (name, new)  )


		# special case for first joint
		else:
			expr = """
	float $x = %(newJnt)s.tx;
	float $y = %(newJnt)s.ty;
	float $z = %(newJnt)s.tz;
	float $mag = sqrt ( $x*$x + $y*$y + $z*$z );
	%(name)s_Geo%(curr)s.sy = $mag - .5*%(newJnt)s.pipeLengthInBtwn0;

	%(name)s_Connector1AGeo%(curr)s.scaleY = %(name)s_Jnt0.globalConnectorThickness * 1/%(name)s_Geo%(curr)s.scaleY;
	%(name)s_Connector2AGeo%(curr)s.scaleY = %(name)s_Connector1AGeo%(curr)s.scaleY;
	%(name)s_Connector1AGeo%(curr)s.translateY = -.5 + %(name)s_Connector1AHist%(curr)s.height/2 + .1*%(name)s_Jnt0.globalConnectorOffset;
	%(name)s_Connector2AGeo%(curr)s.translateY = 0.5 - %(name)s_Connector1AHist%(curr)s.height/2 - .1*%(name)s_Jnt0.globalConnectorOffset;
	%(name)s_Connector1AGeo%(curr)s.scaleX = 1 + %(name)s_Jnt0.globalConnectorRadius;
	%(name)s_Connector1AGeo%(curr)s.scaleZ = 1 + %(name)s_Jnt0.globalConnectorRadius;
	%(name)s_Connector2AGeo%(curr)s.scaleX = 1 + %(name)s_Jnt0.globalConnectorRadius;
	%(name)s_Connector2AGeo%(curr)s.scaleZ = 1 + %(name)s_Jnt0.globalConnectorRadius;
		""" % { 'newJnt': newJnt,
				'curr'	: 	new,
				'name': 	name
			}
			print 'creating %s_PipeExpr1' % (name)
			pm.expression( s=expr, ae=1, n = '%s_PipeExpr1' % (name))

		'''
		expr = """
	%(pipeJnt)s.scaleX = %(root)s.globalPipeRadius + %(root)s.globalJointRadius;
	%(pipeJnt)s.scaleZ = %(pipeJnt)s.scaleX;
	""" % {	'pipeJnt': pipeJnt,
			'root' : '%s_Jnt0' % (name) }

		print 'creating %s_PipeExpr%s' % (name, new)
		expression( s=expr, ae=1, n = '%s_PipeExpr%s' % (name, new))
		'''

		pipe.translate.lock()
		pipe.rotate.lock()
		#pipe.scale.lock()
		newJnts.append( newJnt )
	pm.select(newJnts)

class pipeGenWin(object):

	def __init__(self):
		try:
			pm.deleteUI( 'PipeGenWin' )
		except: pass

		win = pm.window('PipeGenWin')
		with win:
			with pm.columnLayout():
				with pm.frameLayout( l='Creation', labelVisible=False):
					with pm.columnLayout():
						with pm.rowLayout( nc=3, cw3=[80, 80, 240], cal=([1,'center'], [2,'right'])):
							pm.button( l='Create', w=80, c= lambda *args: self.newPipeCB())
							pm.text( l='Name' )
							self.createGrp = pm.textField( text='pipe', w=90)
						pm.separator(w=400)

						with pm.rowLayout( nc=2, cw2=[80, 320], cal=[1,'center']):
							#text( l='Segments' )
							pm.button( l='Extend', w=80, c = lambda *args: self.extendPipeCB() )
							self.numSegments = pm.intSliderGrp(
								cw3=[80,40,50],
								l='Segments',
								value=1,
								field=1,
								min=1, max=20 )

				with pm.frameLayout( l='Pipe Properties', labelVisible=True):
					with pm.columnLayout():
						self.pipeRadius = pm.floatSliderGrp( l='Radius',
							value=.22,
							field=True,
							precision = 3,
							min=.0001, max=10 )
						self.subdivAxis = pm.intSliderGrp( l='Axis Segments',
							value=16,
							field=True,
							min=3, max=80 )

				with pm.frameLayout( l='Connector Properties', labelVisible=True):
					with pm.columnLayout():
						self.connectorRadius = pm.floatSliderGrp( l='Connector Radius',
							value=.1,
							field=True,
							precision = 3,
							min=0, max=10 )
						self.connectorThickness = pm.floatSliderGrp( l='Connector Height',
							value=.2,
							field=True,
							precision = 3,
							min=.001, max=10 )
						self.connectorOffset = pm.floatSliderGrp( l='Connector Offset',
							value=.001,
							field=True,
							precision = 3,
							min=0, max=4 )

				with pm.frameLayout( l='Joint Properties', labelVisible=True):
					with pm.columnLayout():
						self.jointRadius = pm.floatSliderGrp( l='Radius',
							value=0,
							field=True,
							precision = 3,
							min=0, max=10 )
						self.subdivJoint = pm.intSliderGrp( l='Joint Segments',
							value=8,
							field=True,
							min=1, max=80 )
						self.jointLength = pm.floatSliderGrp( l='Joint Length',
							value=1.2,
							field=True,
							precision = 3,
							min=0.0001, max=10 )


	def newPipeCB(self):

		kwargs={}
		kwargs['pipeRadius'] = self.pipeRadius.getValue()
		kwargs['jointRadius'] = self.jointRadius.getValue()
		kwargs['subdivAxis'] = self.subdivAxis.getValue()
		kwargs['subdivJoint'] = self.subdivJoint.getValue()
		kwargs['jointLength'] = self.jointLength.getValue()
		kwargs['connectorRadius'] = self.connectorRadius.getValue()
		kwargs['connectorThickness'] = self.connectorThickness.getValue()
		kwargs['connectorOffset'] = self.connectorOffset.getValue()
		startPipe( self.createGrp.getText(), **kwargs )

	def extendPipeCB(self):
		kwargs={}
		kwargs['jointLength'] = self.jointLength.getValue()
		for i in range( self.numSegments.getValue() ):
			extendPipe(**kwargs)


"""
TODO

Fixed Joints:
Y-joints
T-joints
Straight joint

Size change Adapter

"""




########NEW FILE########
__FILENAME__ = setVertexColor

import pymel.all as pymel
import pymel.core as pm
from pymel.core.datatypes import *
from time import time
import unittest

def doIt(obj):
    obj.createColorSet('edgeLength')
    colors = []
    for i, vtx in enumerate(obj.vtx):
        #iterate through vertices
        #print vtx, vtx._range, vtx.getIndex(), vtx.getPosition()
        edgs = vtx.connectedEdges()
        totalLen=0
        edgCnt=0
        for edg in edgs:
            edgCnt += 1
            #print edg
            #print "getting length"
            l = edg.getLength()
            #print "length", l
            totalLen += l

        avgLen=totalLen / edgCnt

        currColor = vtx.getColor()
        color = pm.dt.Color.black
        # only set blue if it has not been set before
        if currColor.b<=0.0:
            color.b = avgLen
        color.r = avgLen
        colors.append(color)


    print len(colors)
    obj.setColors( colors )
    obj.updateSurface()

    pm.polyColorPerVertex( obj, e=1, colorDisplayOption=1 )
########NEW FILE########
__FILENAME__ = cachetools
#from pymel.core import factories
#from pymel.all import mayautils
import pprint
import os.path
import re
import copy

import pymel.core as pm
import pymel.internal.factories as factories
#import pymel.internal.mayautils as mayautils
import pymel.internal.startup as startup
import pymel.internal.cmdcache as cmdcache
import pymel.internal.apicache as apicache
import pymel.util as util

def separateExampleCache():
    examples = {}
    succ = fail = 0
    for cmdName, cmdInfo in factories.cmdlist.iteritems():
        try:
            examples[cmdName] = cmdInfo.pop('example')
            succ += 1
        except KeyError:
            fail += 1
            pass
    print "succeeded", succ
    print "failed   ", fail

    mayautils.writeCache( (factories.cmdlist,
                          factories.nodeHierarchy,
                          factories.uiClassList,
                          factories.nodeCommandList,
                          factories.moduleCmds),
                          'mayaCmdsList', 'the list of Maya commands', compressed=False )

    mayautils.writeCache( examples,
                          'mayaCmdsExamples', 'the list of Maya command examples',compressed=False )

def separateApiDocs():
    data = list(mayautils.loadCache('mayaApi',compressed=True))
    apiClassInfo = data[7]
    newApiDocs = {}
    for mfn, mfnInfo in apiClassInfo.iteritems():
        #print mfn, type(mfnInfo)
        if isinstance(mfnInfo, dict):
            #print mfn
            newAllMethodsInfo = {}
            for method, methodInfoList in mfnInfo['methods'].iteritems():
                newMethodInfoList = []
                for i, methodInfo in enumerate(methodInfoList):
                    newMethodInfo = {}
                    if 'doc' in methodInfo:
                        newMethodInfo['doc'] = methodInfo.pop('doc')
                    newArgInfo = {}
                    for arg, argInfo in methodInfo['argInfo'].iteritems():
                        if 'doc' in argInfo:
                            newArgInfo[arg] = {'doc': argInfo.pop('doc')}
                    if newArgInfo:
                        newMethodInfo['argInfo'] = newArgInfo
                    newMethodInfoList.append(newMethodInfo)
                if newMethodInfoList:
                    newAllMethodsInfo[method] = newMethodInfoList
            if newAllMethodsInfo:
                newApiDocs[mfn] = {'methods': newAllMethodsInfo }
        else:
            pass
            #print mfn, type(mfnInfo)
    #pprint.pprint(newApiDocs['MFnTransform'])
    data[7] = apiClassInfo

    mayautils.writeCache( tuple(data),
                          'mayaApi', compressed=True )

    mayautils.writeCache( newApiDocs,
                          'mayaApiDocs',compressed=True )

def upgradeCmdCaches():
    import pymel.internal.cmdcache as cmdcache

    data = list(mayautils.loadCache('mayaCmdsList',compressed=False))
    cmdlist = data[0]
    nodeHierarchy = data[1]
    cmdDocList = {}
    examples = {}
    succ = fail = 0
    for cmdName, cmdInfo in cmdlist.iteritems():

        flags = cmdcache.getCallbackFlags(cmdInfo)
        if flags:
            cmdlist[cmdName]['callbackFlags'] = flags

        try:
            examples[cmdName] = cmdInfo.pop('example')
        except KeyError:
            pass

        newCmdInfo = {}
        if 'description' in cmdInfo:
            newCmdInfo['description'] = cmdInfo.pop('description')
        newFlagInfo = {}
        if 'flags' in cmdInfo:
            for flag, flagInfo in cmdInfo['flags'].iteritems():
                newFlagInfo[flag] = { 'docstring' : flagInfo.pop('docstring') }
            newCmdInfo['flags'] = newFlagInfo

        if newCmdInfo:
            cmdDocList[cmdName] = newCmdInfo

        if 'shortFlags' in cmdInfo:
            d = {}
            #print cmdName
            for flag, flagInfo in cmdInfo['shortFlags'].iteritems():
                if isinstance(flagInfo, dict):
                    d[flag] = flagInfo['longname']
                elif isinstance(flagInfo, basestring):
                    d[flag] = flagInfo
                else:
                    raise TypeError
            cmdInfo['shortFlags'] = d

    hierarchy = [ (x.key, tuple( [y.key for y in x.parents()]), tuple( [y.key for y in x.childs()] ) ) \
                   for x in nodeHierarchy.preorder() ]

    data[0] = cmdlist
    data[1] = hierarchy

    mayautils.writeCache( tuple(data),
                          'mayaCmdsList', 'the list of Maya commands',compressed=True )

    mayautils.writeCache( cmdDocList,
                          'mayaCmdsDocs', 'the Maya command documentation',compressed=True )

    mayautils.writeCache( examples,
                          'mayaCmdsExamples', 'the list of Maya command examples',compressed=True )

#    for cache, useVersion in [ ('mayaApiMelBridge',False), ('mayaApi',True) ]:
#        data = mayautils.loadCache(cache, useVersion=useVersion, compressed=False)
#        mayautils.writeCache(data, cache, useVersion=useVersion, compressed=True)

def addCallbackFlags():
    data = list(mayautils.loadCache('mayaCmdsList',compressed=True))
    cmdlist = data[0]
    succ = 0
    for cmdName, cmdInfo in cmdlist.iteritems():
        flags = factories.getCallbackFlags(cmdInfo)
        if flags:
            cmdlist[cmdName]['callbackFlags'] = flags
            succ += 1

    data[0] = cmdlist
    mayautils.writeCache( tuple(data),
                          'mayaCmdsList', 'the list of Maya commands',compressed=True )

def reduceShortFlags():
    succ = 0
    for cmdName, cmdInfo in factories.cmdlist.iteritems():
        if 'shortFlags' in cmdInfo:
            d = {}
            print cmdName
            for flag, flagInfo in cmdInfo['shortFlags'].iteritems():
                if isinstance(flagInfo, dict):
                    d[flag] = flagInfo['longname']
                elif isinstance(flagInfo, basestring):
                    d[flag] = flagInfo
                else:
                    raise TypeError
            cmdInfo['shortFlags'] = d
            succ += 1
    print "reduced", succ
    mayautils.writeCache( (factories.cmdlist,
                          factories.nodeHierarchy,
                          factories.uiClassList,
                          factories.nodeCommandList,
                          factories.moduleCmds),
                          'mayaCmdsList', 'the list of Maya commands' )

def flattenNodeHier():

    hierarchy = [ (x.key, tuple( [y.key for y in x.parents()]) ) for x in factories.nodeHierarchy.preorder() ]
    factories.nodeHierarchy = hierarchy
    mayautils.writeCache( (factories.cmdlist,
                          factories.nodeHierarchy,
                          factories.uiClassList,
                          factories.nodeCommandList,
                          factories.moduleCmds),
                          'mayaCmdsList', 'the list of Maya commands' )

caches = [ ('mayaCmdsList', True), ('mayaApiMelBridge',False), ('mayaApi',True) ]
def mergeAll():
    data = []
    for cache, useVersion in caches:
        data.append( mayautils.loadCache(cache, useVersion=useVersion))

    mayautils.writeCache( tuple(data), 'mayaAll' )


import time
def mergedTest():
    s1 = time.time()
    for cache, useVersion in caches:
        mayautils.loadCache(cache, useVersion=useVersion)
    print time.time()-s1

    s2 = time.time()
    mayautils.loadCache('mayaAll')
    print time.time() - s2


def compressAll():
    for cache, useVersion in caches + [('mayaCmdsListAll', True), ('mayaCmdsDocs', True) ]:
        compress(cache, useVersion)

def compress(cache, useVersion=True):
    useVersion = dict(caches).get(cache,useVersion)
    data = mayautils.loadCache(cache, useVersion=useVersion, compressed=False)
    mayautils.writeCache(data, cache, useVersion=useVersion, compressed=True)

def decompress():
    caches2 = [ ('mayaCmdsListAll', True), ('mayaApiMelBridge',False), ('mayaApi',True) ]

    num = 3

    s = time.time()
    for i in range(num):
        for cache, useVersion in caches2:
            data = mayautils.loadCache(cache, useVersion=useVersion, compressed=False)
    print "compress=0, docstrings=1:", time.time()-s

    s1 = time.time()
    for i in range(num):
        for cache, useVersion in caches:
            data = mayautils.loadCache(cache, useVersion=useVersion, compressed=False)
    print "compress=0, docstrings=0:", time.time()-s1

    s1 = time.time()
    for i in range(num):
        for cache, useVersion in caches2:
            data = mayautils.loadCache(cache, useVersion=useVersion, compressed=True)
    print "compress=1, docstrings=1:", time.time()-s1

    s1 = time.time()
    for i in range(num):
        for cache, useVersion in caches:
            data = mayautils.loadCache(cache, useVersion=useVersion, compressed=True)
    print "compress=1, docstrings=0:", time.time()-s1

def prepdiff(cache, outputDir='' ):
    pprintCache(cache, True, outputDir)
    pprintCache(cache, False, outputDir)

def pprintCache(cache, compressed, outputDir):
    useVersion = dict(caches).get(cache,True)
    data = mayautils.loadCache(cache, useVersion=useVersion, compressed=compressed)
    fname = os.path.realpath(os.path.join('', cache+ ('_zip.txt' if compressed else '_bin.txt') ) )
    print "writing to", fname
    f = open(fname, 'w')

    pprint.pprint( data, f)
    f.close()

def compareDicts(dict1, dict2, showDiff=True, showOnlys=False, indent=0):
    if isinstance(dict1, (list, tuple)):
        dict1 = dict(enumerate(dict1))
    if isinstance(dict2, (list, tuple)):
        dict2 = dict(enumerate(dict2))
    v1 = set(dict1)
    v2 = set(dict2)
    both = v1 & v2
    only1 = v1 - both
    only2 = v2 - both
    print "\t" * indent, "both:", len(both)
    print "\t" * indent, "only1:", len(only1)
    print "\t" * indent, "only2:", len(only2)

    differences = {}
    for mayaType in both:
        if dict1[mayaType] != dict2[mayaType]:
            differences[mayaType] = (dict1[mayaType], dict2[mayaType])
    print "\t" * indent, "differences:", len(differences)

    #print "\t" * indent, "*" * 60
    if showDiff and differences:
        print "\t" * indent, "different: (%d)" % len(differences)
        for key in sorted(differences):
            print "\t" * indent, key, ':',
            diff1, diff2 = differences[key]
            subDict1 = subDict2 = None
            if type(diff1) == type(diff2) and isinstance(diff1, (dict, list, tuple)):
                print
                compareDicts(diff1, diff2, showDiff=showDiff, showOnlys=showOnlys, indent=indent+1)
            else:
                print diff1, '-', diff2
        #print "\t" * indent, "*" * 60
    if showOnlys:
        if only1:
            print "\t" * indent, "only1: (%d)" % len(only1)
            for x in only1:
                print "\t" * indent, x
            #print "\t" * indent, "*" * 60
        if only2:
            print "\t" * indent, "only2: (%d)" % len(only2)
            for x in only2:
                print "\t" * indent, x
    #print "\t" * indent, "*" * 60
    return both, only1, only2, differences


def compareTrees(tree1, tree2):
    def convertTree(oldTree):
        if isinstance(oldTree, dict):
            return oldTree
        newTree = {}
        for key, parents, children in oldTree:
            newTree[key] = [parents, set(children)]
        return newTree
    tree1 = convertTree(tree1)
    tree2 = convertTree(tree2)
    t1set = set(tree1)
    t2set = set(tree2)
    both = t1set & t2set
    only1 = t1set - both
    only2 = t2set - both
    diff = {}
    for nodeType in both:
        n1 = tree1[nodeType]
        n2 = tree2[nodeType]
        if n1 != n2:
            if n1[0] == n2[0]:
                parentDiff = 'same'
            else:
                parentDiff = (n1[0], n2[0])
            if n1[1] == n2[1]:
                childDiff = 'same'
            else:
                childDiff = (n1[1] - n2[1], n2[1] - n1[1])
        diff[nodeType] = (parentDiff, childDiff)
    return only1, only2, diff

def _getClassEnumDicts(pickleData, parser):
    classInfos = pickleData[-1]
    classEnums = {}; classPyEnums = {}
    for className, classInfo in classInfos.iteritems():
        enums = classInfo.get('enums')
        if enums:
            enums = dict( (enumName, data['values']) for enumName, data in enums.iteritems())
            classEnums[className] = enums
        pyEnums = classInfo.get('pymelEnums')
        if pyEnums:
            classPyEnums[className] = pyEnums
    assert(set(classEnums.keys()) == set(classPyEnums.keys()))
    return classEnums, classPyEnums

def checkEnumConsistency(pickleData, docLocation=None, parser=None):
    '''Check that the pymelEnums and enums have consistent index mappings
    '''
    class NotFound(object):
        def __repr__(self):
            return ':NOTFOUND:'
    notFound = NotFound()

    if parser is None:
        import pymel.internal.parsers as parsers
        import maya.OpenMaya as om
        parser = parsers.ApiDocParser(om, docLocation=docLocation)
    classEnums, classPyEnums = _getClassEnumDicts(pickleData, parser)

    badByEnum = {}

    for className, enums in classEnums.iteritems():
        for enumName, enum in enums.iteritems():
            fullEnumName = "%s.%s" % (className, enumName)
            badThisEnum = {}
            try:
                #print fullEnumName
                #print enum
                pyEnum = classPyEnums[className][enumName]
                #print pyEnum
                enumToPyNames = parser._apiEnumNamesToPymelEnumNames(enum)
                for apiName, val in enum._keys.iteritems():
                    pyName = enumToPyNames[apiName]
                    try:
                        pyIndex = pyEnum.getIndex(pyName)
                    except ValueError:
                        pyIndex = notFound
                    try:
                        apiIndex = enum.getIndex(apiName)
                    except ValueError:
                        apiIndex = notFound
                    if pyIndex != apiIndex:
                        badThisEnum.setdefault('mismatch', []).append(
                                    {'api':(apiName, apiIndex),
                                     'py':(pyName, pyIndex)})
                    if pyIndex is None:
                        badThisEnum.setdefault('badPyIndex', []).append((pyName, pyIndex))
                    if apiIndex is None:
                        badThisEnum.setdefault('badApiIndex', []).append((apiName, apiIndex))

            except Exception:
                import traceback
                badThisEnum['exception'] = traceback.format_exc()
            if badThisEnum:
                badByEnum[fullEnumName] = badThisEnum
    return classEnums, classPyEnums, badByEnum
#    if bad:
#        print
#        print "!" * 80
#        print "Bad results:"
#        print '\n'.join(bad)
#        print "!" * 80
#        raise ValueError("inconsistent pickled enum data")

# made a change to enums in apiClassInfo[apiClassName]['pymelEnums'] such that
# they now have as keys BOTH the api form (kSomeName) and the python form
# (someName) - this method converts over old caches on disk to the new format
def convertPymelEnums(docLocation=None):
    # Compatibility for pre-2012 caches... see note after ApiEnum def in
    # apicache
    import pymel.api
    pymel.api.Enum = apicache.ApiEnum
    apicache.Enum = apicache.ApiEnum

    import pymel.internal.parsers as parsers
    import maya.OpenMaya as om
    parser = parsers.ApiDocParser(om, docLocation=docLocation)

    dummyCache = apicache.ApiCache()
    dummyCache.version = '[0-9.]+'
    cachePattern = pm.Path(dummyCache.path())
    caches = sorted(cachePattern.parent.files(re.compile(cachePattern.name)))
    rawCaches = {}
    badByCache = {}
    enumsByCache = {}
    for cachePath in caches:
        print "checking enum data for: %s" % cachePath
        raw = pm.util.picklezip.load(unicode(cachePath))
        rawCaches[cachePath] = raw
        classEnums, classPyEnums, bad = checkEnumConsistency(raw, parser=parser)
        if bad:
            badByCache[cachePath] = bad
        enumsByCache[cachePath] = {'api':classEnums, 'py':classPyEnums}
    if badByCache:
        pprint.pprint(badByCache)
        print "Do you want to continue converting pymel enums? (y/n)"
        print "(Pymel values will be altered to match the api values)"
        answer = raw_input().lower().strip()
        if not answer or answer[0] != 'y':
            print "aborting cache update"
            return
    fixedKeys = []
    deletedEnums = []
    for cachePath, raw in rawCaches.iteritems():
        print '=' * 60
        print "Fixing: %s" % cachePath
        apiClassInfo = raw[-1]
        apiEnums = enumsByCache[cachePath]['api']
        pyEnums = enumsByCache[cachePath]['py']
        assert(set(apiEnums.keys()) == set(pyEnums.keys()))
        for className, apiEnumsForClass in apiEnums.iteritems():
            pyEnumsForClass = pyEnums[className]
            assert(set(apiEnumsForClass.keys()) == set(pyEnumsForClass.keys()))
            for enumName, apiEnum in apiEnumsForClass.iteritems():
                fullEnumName = '%s.%s' % (className, enumName)
                print fullEnumName

                # first, find any "bad" values - ie, values whose index is None
                # - and delete them
                badKeys = [key for key, index in apiEnum._keys.iteritems()
                           if index is None]
                if badKeys:
                    print "!!!!!!!!"
                    print "fixing bad keys in %s - %s" % (fullEnumName, badKeys)
                    print "!!!!!!!!"
                    assert(None in apiEnum._values)
                    valueDocs =  apiClassInfo[className]['enums'][enumName]['valueDocs']
                    for badKey in badKeys:
                        valueDocs.pop(badKey, None)
                        del apiEnum._keys[badKey]
                    del apiEnum._values[None]

                    if not apiEnum._keys:
                        print "enum empty after removing bad keys - deleting..."
                        del apiClassInfo[className]['enums'][enumName]
                        del apiClassInfo[className]['pymelEnums'][enumName]
                        deletedEnums.append(fullEnumName)
                        continue
                    else:
                        fixedKeys.append(fullEnumName)
                else:
                    assert(None not in apiEnum._values)

                try:
                    pyEnums[className] = parser._apiEnumToPymelEnum(apiEnum)
                except Exception:
                    globals()['rawCaches'] = rawCaches
                    globals()['apiEnum'] = apiEnum
                    raise

    # After making ALL changes, if there were NO errors, write them all out...
    for cachePath, raw in rawCaches.iteritems():
        pm.util.picklezip.dump(raw, unicode(cachePath))

def apiPymelWrapData(keepDocs=False, keepReturnQualifiers=True):
    '''
    Return a dict with info about which api methods were actually wrapped

    Supposed to help detect if changes to the api wraps (or api parsing, etc)
    have affected something that "matters" - ie, a class which is actually
    warpped by pymel, and a method overload that is actually used.

    ***WARNING***
    To work, you will first have to edit factories.py and set _DEBUG_API_WRAPS
    to True
    '''
    # make sure we trigger loading of all dynamic modules, and all their
    # members...
    import pymel.all

    apiClassInfo = factories.apiClassInfo
    usedMethods = {}
    for apiClassName, classMethods in factories._apiMethodWraps.iteritems():
        for methodName, methodWraps in classMethods.iteritems():
            for methodWrapInfo in methodWraps:
                func = methodWrapInfo['funcRef']
                if func is None:
                    continue
                index = methodWrapInfo['index']
                usedClassMethods = usedMethods.setdefault(apiClassName, {})
                methodInfo = apiClassInfo[apiClassName]['methods'][methodName][index]

                # copy the methodInfo, we (might be) modifying it
                methodInfo = copy.deepcopy(methodInfo)
                if not keepDocs:
                    # the docs aren't really necessary for comparing
                    # compatibility... get rid of them..
                    methodInfo.pop('doc', None)
                    for argData in methodInfo.get('argInfo', {}).itervalues():
                        argData.pop('doc', None)
                    methodInfo.get('returnInfo', {}).pop('doc', None)
                if not keepReturnQualifiers:
                    methodInfo.get('returnInfo', {}).pop('qualifiers', None)
                usedClassMethods.setdefault(methodName, {})[index] = methodInfo
    return usedMethods

def findApiWrapRegressions(oldWraps, newWraps):
    '''Given api wrap data from apiPymelWrapData for an old and new version,
    tries to find changes that would cause backwards-compatibility problems /
    regressions.
    '''
    def setClassProblem(className, issue):
        problems[className] = issue

    def getClassProblems(className):
        return problems.setdefault(className, {})

    def setMethodProblem(className, methodName, issue):
        getClassProblems(className)[methodName] = issue

    def getMethodProblems(className, methodName):
        return getClassProblems(className).setdefault(methodName, {})

    def setIndexProblem(className, methodName, index, issue):
        getMethodProblems(className, methodName)[index] = issue

    problems = {}
    for className, oldMethodNames in oldWraps.iteritems():
        if className not in newWraps:
            setClassProblem(className, '!!!Class missing!!!')
            continue
        newMethodNames = newWraps[className]

        for methodName, oldMethodWraps in oldMethodNames.iteritems():
            if methodName not in newMethodNames:
                setMethodProblem(className, methodName, '!!!Method missing!!!')
                continue
            newMethodWraps = newMethodNames[methodName]

            for i, oldWrap in oldMethodWraps.iteritems():
                try:
                    newWrap = newMethodWraps[i]
                except KeyError:
                    setIndexProblem(className, methodName, i, '!!!Overload index missing!!!')
                    continue
                if newWrap == oldWrap:
                    continue
                else:
                    diff = util.compareCascadingDicts(oldWrap, newWrap)
                    setIndexProblem(className, methodName, i, ('Overload differed',
                                                               diff[1:]))
    return problems



########NEW FILE########
__FILENAME__ = docs
import sys
import os
import glob
import shutil
import datetime

from sphinx import main as sphinx_build
from sphinx.ext.autosummary.generate import main as sphinx_autogen

assert 'pymel' not in sys.modules or 'PYMEL_INCLUDE_EXAMPLES' in os.environ, "to generate docs PYMEL_INCLUDE_EXAMPLES env var must be set before pymel is imported"

# remember, the processed command examples are not version specific. you must
# run cmdcache.fixCodeExamples() to bring processed examples in from the raw
# version-specific example caches
os.environ['PYMEL_INCLUDE_EXAMPLES'] = 'True'

pymel_root = os.path.dirname(os.path.dirname(sys.modules[__name__].__file__))
docsdir = os.path.join(pymel_root, 'docs')
stubdir = os.path.join(pymel_root, 'extras', 'completion', 'py')

useStubs = False

if useStubs:
    sys.path.insert(0, stubdir)
    import pymel
    print pymel.__file__
else:
    import pymel
    # make sure dynamic modules are fully loaded
    from pymel.core.uitypes import *
    from pymel.core.nodetypes import *

version = pymel.__version__.rsplit('.',1)[0]
SOURCE = 'source'
BUILD_ROOT = 'build'
BUILD = os.path.join(BUILD_ROOT, version)
sourcedir = os.path.join(docsdir, SOURCE)
gendir = os.path.join(sourcedir, 'generated')
buildrootdir = os.path.join(docsdir, BUILD_ROOT)
builddir = os.path.join(docsdir, BUILD)

from pymel.internal.cmdcache import fixCodeExamples

def generate(clean=True):
    "delete build and generated directories and generate a top-level documentation source file for each module."
    print "generating %s - %s" % (docsdir, datetime.datetime.now())

    if clean:
        clean_build()
        clean_generated()
    os.chdir(sourcedir)

    sphinx_autogen( [''] + '--templates ../templates index.rst'.split() )
    sphinx_autogen( [''] + '--templates ../templates'.split() + glob.glob('generated/pymel.*.rst') )
    print "...done generating %s - %s" % (docsdir, datetime.datetime.now())

def clean_build():
    "delete existing build directory"
    if os.path.exists(buildrootdir):
        print "removing %s - %s" % (buildrootdir, datetime.datetime.now())
        shutil.rmtree(buildrootdir)

def clean_generated():
    "delete existing generated directory"
    if os.path.exists(gendir):
        print "removing %s - %s" % (gendir, datetime.datetime.now())
        shutil.rmtree(gendir)

def find_dot():
    if os.name == 'posix':
        dot_bin = 'dot'
    else:
        dot_bin = 'dot.exe'

    for p in os.environ['PATH'].split(os.pathsep):
        d = os.path.join(p, dot_bin)
        if os.path.exists(d):
            return d
    raise TypeError('cannot find graphiz dot executable in the path')

def build(clean=True, **kwargs):
    print "building %s - %s" % (docsdir, datetime.datetime.now())

    if not os.path.isdir(gendir):
        generate()

    os.chdir( docsdir )
    if clean:
        clean_build()

    #mkdir -p build/html build/doctrees

    #import pymel.internal.cmdcache as cmdcache
    #cmdcache.fixCodeExamples()
    opts = ['']
    opts += '-b html -d build/doctrees'.split()

    # set some defaults
    if 'graphviz_dot' not in kwargs:
        kwargs['graphviz_dot'] = find_dot()

    for key, value in kwargs.iteritems():
        opts.append('-D')
        opts.append( key.strip() + '=' + value.strip() )
    opts.append('-P')
    opts.append(SOURCE)
    opts.append(BUILD)
    sphinx_build(opts)
    print "...done building %s - %s" % (docsdir, datetime.datetime.now())


########NEW FILE########
__FILENAME__ = inheritance
import re
import itertools
from pprint import pprint

import maya.cmds as cmds
import pymel.util as util
import pymel.util.trees as trees
import pymel.api as api
import pymel.internal.cmdcache as cmdcache
import pymel.internal.apicache as apicache
import pymel.internal.factories as factories

#===============================================================================
# maya node type hierarchy info
#===============================================================================

cmds.file(new=1, f=1)
lsTypes = cmds.ls(nodeTypes=1)
num = len(lsTypes)
lsTypes = set(lsTypes)
assert num == len(lsTypes), "The result of ls(nodeTypes=1) contained duplicates"
print num

print 'got ls(nodeTypes=1), confirmed no dupes'

realTypes = lsTypes

try:
    allTypesReal = cmds.allNodeTypes()
except RuntimeError:
    print "Error calling allNodeTypes() !!"
    allTypesReal = None
    realAndAbstract = lsTypes
    abstractTypes = None
else:

    num = len(allTypesReal)
    allTypesReal = set(allTypesReal)
    assert num == len(allTypesReal), "The result of allNodeTypes() contained duplicates"
    print num

    print 'got allNodeTypes(), confirmed no dupes'

    assert lsTypes == allTypesReal, "ls(nodeTypes=1) and allNodeTypes() returned different result"

    print 'confirmed allNodeTypes() == ls(nodeTypes=1)'

    abstractSuffix = ' (abstract)'
    rawRealAndAbstract = cmds.allNodeTypes(includeAbstract=True)
    realAndAbstract = set()
    for x in rawRealAndAbstract:
        if x.endswith(abstractSuffix):
            x = x[:-len(abstractSuffix)]
        assert x not in realAndAbstract
        realAndAbstract.add(x)

    abstractTypes = realAndAbstract - realTypes
    assert len(abstractTypes) + len(realTypes) == len(realAndAbstract)


    print 'got allNodeTypes(includeAbstract=True), separated nodes into real + abstract'
# TODO - make and load a plugin which makes one of every possible plugin node
# type...

# with 2012, we have nodeType(isTypeName), so no longer need to add nodes!
    #print 'about to make nodes...'
    #mobjDict = {}
    #dagMod = api.MDagModifier()
    #dgMod = api.MDGModifier()
    #for nodeType in realTypes:
    #    #print 'making nodeType %s...' % nodeType,
    #    mobjDict[nodeType] = apicache._makeDgModGhostObject(nodeType, dagMod, dgMod)
    #    #print 'success!'
    #dagMod.doIt()
    #dgMod.doIt()
    #
    #print 'made nodes!'
    #
    #nodeDict = {}
    #mfnDag = api.MFnDagNode()
    #mfnDep = api.MFnDependencyNode()
    #nonMelQueryableApiTypes = [api.MFn.kManipContainer, api.MFn.kManip2DContainer,
    #                           api.MFn.kManipulator3D, api.MFn.kManipulator2D,
    #                           api.MFn.kPolyToolFeedbackShape]
    #nonMelQueryableTypes = set()
    #melQueryableTypes = set()
    #dagTypes = set()
    #depTypes = set()
    #for nodeType, mobj in mobjDict.iteritems():
    #    if mfnDag.hasObj(mobj):
    #        dagTypes.add(nodeType)
    #        mfnDag.setObject(mobj)
    #        nodeDict[nodeType] = mfnDag.fullPathName()
    #    else:
    #        depTypes.add(nodeType)
    #        mfnDep.setObject(mobj)
    #        nodeDict[nodeType] = mfnDep.name()
    #    for manipApi in nonMelQueryableApiTypes:
    #        if mobj.hasFn(manipApi):
    #            nonMelQueryableTypes.add(nodeType)
    #            break
    #    else:
    #        melQueryableTypes.add(nodeType)
    #print "num non queryable types:", len(nonMelQueryableTypes)
    #
    ##nodeDict = {}
    ##for nodeType in realTypes:
    ##    result = cmds.createNode(nodeType)
    ##    nodeDict[nodeType] = result
    #
    #assert len(nodeDict) == len(realTypes)
    #assert len(nonMelQueryableTypes) + len(melQueryableTypes) == len(realTypes)
    #assert nonMelQueryableTypes | melQueryableTypes == realTypes

inheritances = {}
badInheritances = {}
goodInheritances = {}
#for nodeType in melQueryableTypes:
for nodeType in realAndAbstract:
    try:
        inheritance = cmds.nodeType( nodeType, inherited=True, isTypeName=True)
    except Exception, e:
        print "error caught:"
        print e
        inheritance = e
    inheritances[nodeType] = inheritance
    if not inheritance or isinstance(inheritance, Exception):
        badInheritances[nodeType] = inheritance
    else:
        goodInheritances[nodeType] = inheritance

if badInheritances:
    print "#" * 60
    print "Warning!!!"
    print "errors in getting inheritance for following node types:"
    for x in badInheritances:
        print "   ", x
    print "#" * 60

#print getApiTypes(mobjDict['polyMoveUVManip'])

discoveredNodes = set()
for nodeType, inheritance in goodInheritances.iteritems():
    assert inheritance[-1] == nodeType
    for x in inheritance:
        if x not in realAndAbstract:
            discoveredNodes.add(x)
if discoveredNodes:
    print "#" * 60
    print "Warning!!!"
    print "%s nodes were not in realAndAbstract" % ', '.join(discoveredNodes)
    print "#" * 60
allKnownNodes = realAndAbstract | discoveredNodes

def compareTrees(tree1, tree2):
    def convertTree(oldTree):
        if isinstance(oldTree, dict):
            return oldTree
        newTree = {}
        for key, parents, children in oldTree:
            newTree[key] = [parents, set(children)]
        return newTree
    tree1 = convertTree(tree1)
    tree2 = convertTree(tree2)
    t1set = set(tree1)
    t2set = set(tree2)
    both = t1set & t2set
    only1 = t1set - both
    only2 = t2set - both
    diff = {}
    for nodeType in both:
        n1 = tree1[nodeType]
        n2 = tree2[nodeType]
        if n1 != n2:
            if n1[0] == n2[0]:
                parentDiff = 'same'
            else:
                parentDiff = (n1[0], n2[0])
            if n1[1] == n2[1]:
                childDiff = 'same'
            else:
                childDiff = (n1[1] - n2[1], n2[1] - n1[1])
        diff[nodeType] = (parentDiff, childDiff)
    return only1, only2, diff

nodeTypeTree = {}
for nodeType in allKnownNodes:
    nodeTypeTree[nodeType] = [ [], set() ]
for nodeType, inheritance in goodInheritances.iteritems():
    assert inheritance[-1] == nodeType
    # len - 1 b/c final item is this nodeType
    for i in xrange(len(inheritance) - 1):
        parent = inheritance[i]
        child = inheritance[i + 1]

        # add the child to the parent
        nodeTypeTree[parent][1].add(child)

        # set the parents for the child
        parents = list(reversed(inheritance[:i+1]))
        if nodeTypeTree[child][0]:
            assert nodeTypeTree[child][0] == parents
        else:
            nodeTypeTree[child][0] = parents

#eliminate manipulators
nonManipTree = {}
manipulators = set()
for name, data in nodeTypeTree.iteritems():
    parents = data[0]
    if parents is not None and ('manip3D' in parents or name == 'manip3D'):
        manipulators.add(name)
    else:
        nonManipTree[name] = data

nonManipNonPlugin = {}
for name, data in nonManipTree.iteritems():
    parents = data[0]
    if parents is not None:
        if (any(x.startswith('TH') for x in parents)
                or name.startswith('TH')):
            continue
    nonManipNonPlugin[name] = data

print "trees equal?"

only1, only2, diff = compareTrees(nonManipNonPlugin, factories.nodeHierarchy)

print
print "-" * 60
print "only1:"
pprint(list(only1))
print "-" * 60
print

print
print "-" * 60
print "only2:"
pprint(list(only2))
print "-" * 60
print

print
print "-" * 60
print "diff:"
#pprint(diff)
print "-" * 60
print

#===============================================================================
# api type hierarchy info
#===============================================================================

def getApiTypes(mobj):
    apiTypes = []
    for apiTypeStr, apiType in factories.apiTypesToApiEnums.iteritems():
        if mobj.hasFn(apiType):
            apiTypes.append(apiTypeStr)
    return apiTypes

mayaToApi = {}
mayaToAllApi = {}
unknownTypes = set()
#toCreate = set(nonManipTree)
toCreate = set(realTypes) - manipulators - set(apicache.ApiCache.CRASH_TYPES)
with apicache._GhostObjMaker(toCreate, manipError=False, multi=True) as typeToObj:
    for mayaType in toCreate:
        obj = typeToObj[mayaType]
        if obj :
            apiType = obj.apiTypeStr()
            mayaToApi[mayaType] = apiType
            mayaToAllApi[mayaType] = getApiTypes(obj)
        else:
            unknownTypes.add(mayaType)

assert mayaToApi.get('containerBase') == 'kContainerBase'

if unknownTypes:
    print "#" * 60
    print "Warning!!!"
    print "could not create the following node types (which SHOULD be createable):"
    for x in sorted(unknownTypes):
        print "   ", x
    print "#" * 60

ac = apicache.ApiCache()
ac._buildApiTypesList()
allApiTypes = set(ac.apiTypesToApiEnums)

#===============================================================================
# First attempt at querying hierarchy info, by finding common types in children,
# and filtering types found in parents
#===============================================================================

#missingApiInfo = set(nonManipTree) - set(mayaToApi)
##missingNonAbstract = missingApiInfo - abstractTypes
#
## To try to find what the apiType for a maya type is, first find all api types
## that are shared by all it's children (it should have children, because if we
## can't create the node type, it should be abstract...
#
#sharedByChildren = {}
#noSharedByChildren = set()
#for missingType in missingApiInfo:
#    common = None
#    for otherType, apiTypes in mayaToAllApi.iteritems():
#        if nodeTypeTree[otherType][0] is None:
#            print 'type %s had None parent' % otherType
#        if missingType in nodeTypeTree[otherType][0]:
#            if common is None:
#                common = set(apiTypes)
#            else:
#                common = common & set(apiTypes)
#    if common:
#        sharedByChildren[missingType] = common
#    else:
#        noSharedByChildren.add(missingType)
#
## these are strange, because every node should at least all have things like
## kBase, kNamedObject, kDependencyNode...
#if noSharedByChildren:
#    print "#" * 60
#    print "Warning!!!"
#    print "could not find any common api types in children of the following node types:"
#    for x in sorted(noSharedByChildren):
#        print "   ", x
#    print "#" * 60
#
## these are api types which are shared by all dependency nodes
#baseApiTypes = set(['kBase', 'kNamedObject', 'kDependencyNode'])
#
#possibilities = {}
## Now, remove api types which are shared by any parents
#for mayaType, possibleApiTypes in sharedByChildren.iteritems():
#    filtered = set(possibleApiTypes)
#    for parent in nodeTypeTree[mayaType][0]:
#        if parent in mayaToApi:
#            filtered -= set([mayaToApi[parent]])
#        elif parent in sharedByChildren:
#            filtered -= sharedByChildren[parent]
#    filtered -= baseApiTypes
#    possibilities[mayaType] = filtered



#===============================================================================
# Second attempt at querying hierarchy info, by finding common types in children,
# then filtering types found in parents... AND using common ancestry information
#===============================================================================

# build up some information about our hierarchy

def commonAncestor(mayaType1, mayaType2):
    if None in (mayaType1, mayaType2):
        return None

    def reversedParents(mayaType):
        # want the parents in order from most generic to most specific - that
        # way, we can go from left to right, comparing items until we get to one
        # that doesn't match
        return list(reversed(nodeTypeTree[mayaType][0])) + [mayaType]
    parents1 = reversedParents(mayaType1)
    parents2 = reversedParents(mayaType2)

    commonAncestor = None
    for i in xrange(min(len(parents1), len(parents2))):
        if parents1[i] == parents2[i]:
            commonAncestor = parents1[i]
        else:
            break
    return commonAncestor

apiTypeToRealMayaTypes = {}

# for a given api type, find the "most specific" maya type that can be an
# ancestor of all maya types that "contain" that api type
apiTypeToCommonMayaAncestor = {}
for mayaType, apiTypes in mayaToAllApi.iteritems():
    for apiType in apiTypes:
        apiTypeToRealMayaTypes.setdefault(apiType, []).append(mayaType)
        if apiType not in apiTypeToCommonMayaAncestor:
            apiTypeToCommonMayaAncestor[apiType] = mayaType
        else:
            apiTypeToCommonMayaAncestor[apiType] = commonAncestor(mayaType,
                                                              apiTypeToCommonMayaAncestor[apiType])

# now build the reverse dict - from maya type to a list of all api types that
# it is the common ancestor for
commonMayaAncestorToApiTypes = {}
for apiType, mayaType in apiTypeToCommonMayaAncestor.iteritems():
    commonMayaAncestorToApiTypes.setdefault(mayaType, []).append(apiType)

# now, get a list of maya types for which there is only ONE api type that has
# it as it's most-specific-common-ancestor...
commonMayaAncestorToSingleApi = {}
for mayaType, apiTypes in commonMayaAncestorToApiTypes.iteritems():
    if len(apiTypes) == 1:
        commonMayaAncestorToSingleApi[mayaType] = apiTypes[0]

# these are api types which are shared by all dependency nodes
baseApiTypes = set(['kBase', 'kNamedObject', 'kDependencyNode'])

parentDict = dict((mayaType, parents[0])
                  for mayaType, (parents, children) in nodeTypeTree.iteritems()
                  if parents)
nodeTreeObj =  trees.treeFromDict(parentDict)
#orderedTree = [ (x.value, tuple(y.value for y in x.parents()), tuple(y.value for y in x.childs()) ) \
#                for x in nodeTreeObj.preorder() ]

guessedByCommonAncestor = {}
guessedByName = {}
nameAncestorConflicts = {}
guessedByUnique = {}
multiplePossibilities = {}
noUnique = {}

noChildIntersection = set()
childIntersections = {}
childUnions = {}
parentUnions = {}
childPreorders = {}

def nodeToApiName(nodeName):
    return 'k' + util.capitalize(nodeName)

def getLowerCaseMapping(names):
    uniqueLowerNames = {}
    multiLowerNames = {}
    for name in names:
        lowerType = name.lower()
        if lowerType in multiLowerNames:
            multiLowerNames[lowerType].append(name)
        elif lowerType in uniqueLowerNames:
            multiLowerNames[lowerType] = [uniqueLowerNames.pop(lowerType), name]
        else:
            uniqueLowerNames[lowerType] = name
    return uniqueLowerNames, multiLowerNames

uniqueLowerMaya, multiLowerMaya = getLowerCaseMapping(allKnownNodes)
uniqueLowerApi, multiLowerApi = getLowerCaseMapping(allApiTypes)

if multiLowerMaya:
    print "#" * 60
    print "Warning!!!"
    print "maya node names differed only in case:"
    for types in multiLowerMaya.itervalues():
        print "    %s" % ', '.join(types)
    print "#" * 60

if multiLowerApi:
    print "#" * 60
    print "Warning!!!"
    print "api type names differed only in case:"
    for types in multiLowerApi.itervalues():
        print "    %s" % ', '.join(types)
    print "#" * 60

modifiers = {
             'base':'',
             'abstract':'',
             'node':'',
             'shape':'',
             'mod(?!(ify|ifier))':'modify',
             'mod(?!(ify|ifier))':'modifier',
             'modifier':'mod',
             'modify':'mod',
             'poly(?!gon)':'polygon',
             'polygon':'poly',
             'vert(?!(ex|ice))':'vertex',
             'vert(?!(ex|ice))':'vertice',
             'vertice':'vert',
             'vertex':'vert',
             'subd(?!iv)':'subdiv',
             'subd(?!iv)':'subdivision',
             'subdiv(?!ision)':'subd',
             'subdiv(?!ision)':'subdivision',
             'subdivision':'subd',
             'subdivision':'subdiv',
             '^th(custom)?':'plugin',
            }
modifiers = [(re.compile(find), replace)
             for find, replace in modifiers.iteritems()]

apiSuffixes = ['', 'node', 'shape', 'shapenode']

def guessApiTypeByName(nodeName, debug=False):
    # first, try the easy case...
    apiName = nodeToApiName(nodeName)
    if apiName in allApiTypes:
        if debug:
            print 'basic transform worked!'
        return apiName

    lowerNode = nodeName.lower()
    if lowerNode not in uniqueLowerMaya:
        if debug:
            print 'lower-case node name not unique...'
        return None

    # now, try with various modifications...
    possibleApiNames = set()

    possibleModifications = [(find, replace) for find, replace in modifiers
                             if find.search(lowerNode)]

    # find all possible combinations of all possible modifications
    for modifyNum in xrange(len(possibleModifications) + 1):
        for modifyCombo in itertools.combinations(possibleModifications, modifyNum):
            baseName = lowerNode
            for find, replace in modifyCombo:
                baseName = find.sub(replace, baseName)
            if debug:
                print [x[0].pattern for x in modifyCombo], baseName
            if not baseName:
                # if we've eliminated the name with our changes - ie,
                # 'shape' would go to '' - then skip
                continue
            if baseName != lowerNode and (baseName in uniqueLowerMaya
                                          or baseName in multiLowerMaya):
                # if after modification, our new name is the name of another
                # maya node, skip
                continue
            apiLower = 'k' + baseName
            if apiLower in uniqueLowerApi:
                possibleApiNames.add(uniqueLowerApi[apiLower])
            else:
                for suffix in apiSuffixes:
                    apiWithSuffix = apiLower + suffix
                    if apiWithSuffix in uniqueLowerApi:
                        possibleApiNames.add(uniqueLowerApi[apiWithSuffix])
    if debug:
        print possibleApiNames

    if len(possibleApiNames) == 1:
        return list(possibleApiNames)[0]
    return None

#def guessApiTypeByName(nodeName):
#    def isApiType(apiName):
#        return isinstance(getattr(api.MFn, apiName, None), int)
#
#    for suffix in ('', 'node', 'shape', 'shapenode'):
#        if suffix:
#            if not nodeName.lower().endswith(suffix):
#                continue
#            baseName = nodeName[:-len(suffix)]
#        else:
#            baseName = nodeName
#        if not baseName:
#            continue
#        apiName = nodeToApiName(baseName)
#        if isApiType(apiName):
#            return apiName
#    return None

# now going from bases to leaves,
for currentTree in nodeTreeObj.preorder():
    mayaType = currentTree.value
    if mayaType is None:
        continue

    if mayaType in manipulators:
        continue

    # find nodes for which we don't have an api type for yet...
    if mayaType in mayaToApi:
        assert mayaType in mayaToAllApi, "type %s was in mayaToApi but not mayaToAllApi" % mayaType
        continue

    uniqueApiTypes = set()

    # find intersection of all types shared by all children (for which we have info)
    childIntersection = None
    childUnion = set()
    childPreorder = []
    for childTreeNode in currentTree.preorder():
        childType = childTreeNode.value
        if childType == mayaType:
            continue
        childPreorder.append(childType)
        allChildApiTypes = mayaToAllApi.get(childType)
        if allChildApiTypes is not None:
            allChildApiTypes = set(allChildApiTypes)
            if childIntersection is None:
                childIntersection = allChildApiTypes
            else:
                childIntersection &= allChildApiTypes
            childUnion |= allChildApiTypes
    if childIntersection:
        childIntersections[mayaType] = childIntersection
    else:
        if childIntersection is None:
            childIntersection = set()
        noChildIntersection.add(mayaType)
    childUnions[mayaType] = childUnion
    childPreorders[mayaType] = childPreorder

    # find union of parent types
    parentUnion = set(baseApiTypes)
    for parentTreeNode in currentTree.parents():
        parentType = parentTreeNode.value
        if parentType is not None:
            parentUnion |= set(mayaToAllApi[parentType])
    parentUnions[mayaType] = parentUnion

    # unique types were found in children, but weren't found in parents
    uniqueApiTypes = childIntersection - parentUnion

    # information gathering is done... now try to figure out the apiType!
    apiType = None

    # see if there's exactly one api type that this maya type is the
    # most-specific-common-ancestor of...
    commonAncestorGuess = commonMayaAncestorToSingleApi.get(mayaType, None)

    # ...and see if we can guess by name...
    apiNameGuess = guessApiTypeByName(mayaType)

    if apiNameGuess:
        apiType = apiNameGuess
        guessedByName[mayaType] = apiType
        if commonAncestorGuess and commonAncestorGuess != apiNameGuess:
            nameAncestorConflicts[mayaType] = (apiNameGuess, commonAncestorGuess)
    elif commonAncestorGuess:
        apiType = commonAncestorGuess
        guessedByCommonAncestor[mayaType] = apiType
    elif uniqueApiTypes:
        # if we did have unique types...
        if len(uniqueApiTypes) == 1:
            # ...we're golden if there was only 1...
            apiType = list(uniqueApiTypes)[0]
            guessedByUnique[mayaType] = apiType
        else:
            # ...but a little stuck if there's more.
            multiplePossibilities[mayaType] = uniqueApiTypes
    else:
        # if name guess failed, and we have no unique ApiTypes, we'll have to
        # fall back on using the parent type
        parentType = currentTree.parent.value
        if parentType is None:
            apiType = 'kDependencyNode'
        else:
            apiType = mayaToApi.get(parentType)
        noUnique[mayaType] = apiType

    allApi = uniqueApiTypes | parentUnion
    if apiType is not None:
        allApi |= set([apiType])
        mayaToApi[mayaType] = apiType
    mayaToAllApi[mayaType] = sorted(allApi)

if nameAncestorConflicts:
    print "#" * 60
    print "Warning!!!"
    print "had conflicting name / common ancestor guess for these maya nodes:"
    for mayaType, (nameGuess, ancestorGuess) in nameAncestorConflicts.iteritems():
        print "    %20s - %20s / %s" % (mayaType, nameGuess, ancestorGuess)
    print "#" * 60

if multiplePossibilities:
    print "#" * 60
    print "Warning!!!"
    print "could not find a unique api type for these nodes:"
    for mayaType in sorted(multiplePossibilities):
        print "    %20s - %s" % (mayaType, ', '.join(sorted(multiplePossibilities[mayaType])))
    print "#" * 60
########NEW FILE########
__FILENAME__ = pymelControlPanel
"""
UI for controlling how api classes and mel commands are combined into pymel classes.

This UI modifies factories.apiToMelData which is pickled out to apiMelBridge.

It controls:
    which mel methods correspond to api methods
    disabling of api methods
    preference for overloaded methods (since currently only one overloaded method is supported)
    renaming of apiMethod


"""
from __future__ import with_statement
import inspect, re, os
import pymel.core as pm
import pymel.internal.factories as factories
import logging
logger = logging.getLogger(__name__)
if logger.level == logging.NOTSET:
    logger.setLevel(logging.INFO)

FRAME_WIDTH = 800
VERBOSE = True

class PymelControlPanel(object):
    def __init__(self):
        # key is a tuple of (class, method)
        self.classList = sorted( list( set( [ key[0] for key in factories.apiToMelData.keys()] ) ) )
        self.classFrames={}
        self.processClassFrames()
        self.buildUI()


    def buildUI(self):
        self.win = pm.window(title='Pymel Control Panel')
        self.win.show()

        with pm.paneLayout(configuration='vertical3', paneSize=([1,20,100], [3,20,100]) ) as self.pane:
            # Lef Column: Api Classes
            self.classScrollList = pm.textScrollList('apiClassList')

        # Center Column: Api Methods

        # Would LIKE to do it like this, but there is currently a bug with
        # objectType UI, such that even if
        #     layout('window4|paneLayout5', q=1, exists=1) == True
        # when you run:
        #     objectTypeUI('window4|paneLayout5')
        # you will get an error:
        #     RuntimeError: objectTypeUI: Object 'window4|paneLayout5' not found.

#        with formLayout() as apiForm:
#            #with scrollLayout() as scroll:
#            with tabLayout('apiMethodCol') as self.apiMethodCol:
#                pass
#            status = helpLine(h=60)

        # So, instead, we do it old-school...
        apiForm = pm.formLayout()
        self.apiMethodCol = pm.tabLayout('apiMethodCol')
        pm.setParent(apiForm)
        status = pm.cmds.helpLine(h=60)
        pm.setParent(self.pane)

        apiForm.attachForm( self.apiMethodCol, 'top', 5 )
        apiForm.attachForm( self.apiMethodCol, 'left', 5 )
        apiForm.attachForm( self.apiMethodCol, 'right', 5 )
        apiForm.attachControl( self.apiMethodCol, 'bottom', 5, status )
        apiForm.attachPosition( status, 'bottom', 5, 20 )
        apiForm.attachForm( status, 'bottom', 5 )
        apiForm.attachForm( status, 'left', 5 )
        apiForm.attachForm( status, 'right', 5 )

        # Right Column: Mel Methods
        melForm = pm.formLayout()
        label1 = pm.text( label='Unassigned Mel Methods' )
        self.unassignedMelMethodLister = pm.textScrollList()

        label2 = pm.text( label='Assigned Mel Methods' )
        self.assignedMelMethodLister = pm.textScrollList()

        label3 = pm.text( label='Disabled Mel Methods' )
        self.disabledMelMethodLister = pm.textScrollList()
        pm.setParent(self.pane)

        melForm.attachForm( label1, 'top', 5 )
        melForm.attachForm( label1, 'left', 5 )
        melForm.attachForm( label1, 'right', 5 )

        melForm.attachControl( self.unassignedMelMethodLister, 'top', 0, label1 )
        melForm.attachForm( self.unassignedMelMethodLister, 'left', 5 )
        melForm.attachForm( self.unassignedMelMethodLister, 'right', 5 )
        melForm.attachPosition( self.unassignedMelMethodLister, 'bottom', 5, 33 )

        melForm.attachControl( label2, 'top', 5,  self.unassignedMelMethodLister)
        melForm.attachForm( label2, 'left', 5 )
        melForm.attachForm( label2, 'right', 5 )

        melForm.attachControl( self.assignedMelMethodLister, 'top', 0, label2 )
        melForm.attachForm( self.assignedMelMethodLister, 'left', 5 )
        melForm.attachForm( self.assignedMelMethodLister, 'right', 5 )
        melForm.attachPosition( self.assignedMelMethodLister, 'bottom', 5, 66 )


        melForm.attachControl( label3, 'top', 5,  self.assignedMelMethodLister)
        melForm.attachForm( label3, 'left', 5 )
        melForm.attachForm( label3, 'right', 5 )

        melForm.attachControl( self.disabledMelMethodLister, 'top', 0, label3 )
        melForm.attachForm( self.disabledMelMethodLister, 'left', 5 )
        melForm.attachForm( self.disabledMelMethodLister, 'right', 5 )
        melForm.attachForm( self.disabledMelMethodLister, 'bottom', 5 )

        pm.setParent('..')

        pm.popupMenu(parent=self.unassignedMelMethodLister, button=3  )
        pm.menuItem(l='disable', c=pm.Callback( PymelControlPanel.disableMelMethod, self, self.unassignedMelMethodLister ) )

        pm.popupMenu(parent=self.assignedMelMethodLister, button=3  )
        pm.menuItem(l='disable', c=pm.Callback( PymelControlPanel.disableMelMethod, self, self.assignedMelMethodLister ) )

        pm.popupMenu(parent=self.disabledMelMethodLister, button=3  )
        pm.menuItem(l='enable', c=pm.Callback( PymelControlPanel.enableMelMethod))

        self.classScrollList.extend( self.classList )
        self.classScrollList.selectCommand( lambda: self.apiClassList_selectCB() )

        pm.scriptJob(uiDeleted=[str(self.win),cacheResults])

        self.win.show()


    def disableMelMethod(self, menu):
        msel = menu.getSelectItem()
        csel = self.classScrollList.getSelectItem()
        if msel and csel:
            method = msel[0]
            clsname = csel[0]
            menu.removeItem(method)
            self.disabledMelMethodLister.append( method  )
            #print clsname, method, factories.apiToMelData[ (clsname, method) ]
            factories.apiToMelData[ (clsname, method) ]['melEnabled'] = False

    def enableMelMethod(self):
        menu = self.disabledMelMethodLister
        msel = menu.getSelectItem()
        csel = self.classScrollList.getSelectItem()
        if msel and csel:
            method = msel[0]
            clsname = csel[0]
            menu.removeItem(method)
            self.unassignedMelMethodLister.append( method  )
            #print clsname, method, factories.apiToMelData[ (clsname, method) ]
            factories.apiToMelData[ (clsname, method) ].pop('melEnabled')

    @staticmethod
    def getMelMethods(className):
        """get all mel-derived methods for this class"""
        reg = re.compile('(.*[a-z])([XYZ])$')
        newlist = []
        origlist = factories.classToMelMap[className]
        for method in origlist:
            m = reg.search(method)
            if m:
                # strip off the XYZ component and replace with *
                newname = m.group(1) + '*'
                if newname not in newlist:
                    newlist.append(newname)
            else:
                newlist.append(method)
        return sorted(newlist)

    def apiClassList_selectCB(self, *args):
        sel = self.classScrollList.getSelectItem()
        if sel:
            self.buildClassColumn(sel[0])



    def assignMelMethod(self, method):
        #print "method %s is now assigned" % method
        if method in pm.util.listForNone( self.unassignedMelMethodLister.getAllItems() ):
            self.unassignedMelMethodLister.removeItem(method)
            self.assignedMelMethodLister.append( method )

    def unassignMelMethod(self, method):
        #print "method %s is now unassigned" % method
        if method in pm.util.listForNone( self.assignedMelMethodLister.getAllItems() ):
            self.assignedMelMethodLister.removeItem(method)
            self.unassignedMelMethodLister.append( method )



    def processClassFrames(self):
        """
        This triggers the generation of all the defaults for `factories.apiToMelData`, but it does
        not create any UI elements.  It creates `ClassFrame` instances, which in turn create
        `MethodRow` instances, but the creation of UI elements is delayed until a particular
        configuration is requested via `buildClassColumn`.
        """
        logger.info( 'processing all classes...' )
        for className in self.classList:
            melMethods = self.getMelMethods(className)
            logger.debug( '%s: mel methods: %s' % (className, melMethods) )
            for clsName, apiClsName in getClassHierarchy(className):
                if apiClsName and apiClsName not in ['list']:
                    if clsName not in self.classFrames:
                        frame = ClassFrame( self, clsName, apiClsName)
                        self.classFrames[clsName] = frame
                    # temporarily disable the melName updating until we figure out how to deal
                    # with base classes that are the parents of many others, and which therefore end up with
                    # methods derived from many different mel commands, which are only applicable for the inherited classes
                    # not for the base class on its own.  ( see ObjectSet and Character, for an example, specifically 'getIntersection' method )
                    #self.classFrames[clsName].updateMelNames( melMethods )
        logger.info( 'done processing classes' )

    def buildClassColumn(self, className ):
        """
        Build an info column for a class.  This column will include processed `ClassFrame`s for it and its parent classes
        """
        pm.setParent(self.apiMethodCol)
        self.apiMethodCol.clear()

        self.unassignedMelMethodLister.removeAll()
        self.assignedMelMethodLister.removeAll()
        self.disabledMelMethodLister.removeAll()

        melMethods = self.getMelMethods(className)
        for method in melMethods:
            # fix
            if (className, method) in factories.apiToMelData and factories.apiToMelData[ (className, method) ] == {'enabled':False}:
                d = factories.apiToMelData.pop( (className, method) )
                d.pop('enabled')
                d['melEnabled'] = False

            if (className, method) in factories.apiToMelData and factories.apiToMelData[(className, method)].get('melEnabled',True) == False:
                self.disabledMelMethodLister.append( method )
            else:
                self.unassignedMelMethodLister.append( method )


        #filter = set( ['double', 'MVector'] )
        filter = []
        count = 0
        for clsName, apiClsName in getClassHierarchy(className):
            if apiClsName:
                #print cls
                if clsName in self.classFrames:
                    logger.debug( "building UI for %s", clsName )
                    frame = self.classFrames[clsName].buildUI(filter)
                    self.apiMethodCol.setTabLabel( [frame, clsName] )
                    count+=1
                        #frame.setVisible(False)
                    #if i != len(mro)-1:
                    #    frame.setCollapse(True)
                else:
                    logger.debug( "skipping %s", clsName )
        self.apiMethodCol.setSelectTabIndex(count)

        #self.classFrames[className].frame.setCollapse(False)



class ClassFrame(object):
    def __init__(self, parent, className, apiClassName ):


        self.parent = parent
        self.className = className
        self.apiClassName = apiClassName
        self.rows = {}
        self.classInfo = factories.apiClassInfo[apiClassName]['methods']

        for method in self.classInfo.keys():
            row = MethodRow( self, self.className, self.apiClassName, method, self.classInfo[method] )

            self.rows[method] = row


    def updateMelNames(self, melMethods):
        logger.debug( '%s: updating melNames' % self.className )
        for rowName, row in self.rows.items():
            row.updateMelNames( melMethods )

    def buildUI(self, filter=None):

        count = 0
        #self.form = formLayout()
        with pm.frameLayout(collapsable=False, label='%s (%s)' % (self.className, self.apiClassName),
                            width = FRAME_WIDTH) as self.frame:
                            #labelAlign='top')

            with pm.tabLayout() as tab:

                invertibles = factories.apiClassInfo[self.apiClassName]['invertibles']
                usedMethods = []
                with pm.formLayout() as pairdForm:
                    tab.setTabLabel( [pairdForm, 'Paired'] )
                    with pm.scrollLayout() as pairedScroll:
                        with pm.columnLayout(visible=False, adjustableColumn=True) as pairedCol:

                            for setMethod, getMethod in invertibles:
                                pm.setParent(pairedCol) # column
                                frame = pm.frameLayout(label = '%s / %s' % (setMethod, getMethod),
                                                    labelVisible=True, collapsable=True,
                                                    collapse=True, width = FRAME_WIDTH)
                                col2 = pm.columnLayout()
                                pairCount = 0
                                pairCount += self.rows[setMethod].buildUI(filter)
                                pairCount += self.rows[getMethod].buildUI(filter)
                                usedMethods += [setMethod, getMethod]
                                if pairCount == 0:
                                    #deleteUI(col2)
                                    frame.setVisible(False)
                                    frame.setHeight(1)
                                count += pairCount
                            pairedCol.setVisible(True)
                pairdForm.attachForm( pairedScroll, 'top', 5 )
                pairdForm.attachForm( pairedScroll, 'left', 5 )
                pairdForm.attachForm( pairedScroll, 'right', 5 )
                pairdForm.attachForm( pairedScroll, 'bottom', 5 )

                with pm.formLayout() as unpairedForm:
                    tab.setTabLabel( [unpairedForm, 'Unpaired'] )
                    with pm.scrollLayout() as unpairedScroll:
                        with pm.columnLayout(visible=False ) as unpairedCol:
                            # For some reason, on linux, the unpairedCol height is wrong...
                            # track + set it ourselves
                            unpairedHeight = 10 # a little extra buffer...
                            #rowSpace = unpairedCol.getRowSpacing()
                            for methodName in sorted( self.classInfo.keys() ):
                                pm.setParent(unpairedCol)
                                if methodName not in usedMethods:
                                    frame = pm.frameLayout(label = methodName,
                                                        labelVisible=True, collapsable=True,
                                                        collapse=True, width = FRAME_WIDTH)
                                    col2 = pm.columnLayout()
                                    count += self.rows[methodName].buildUI(filter)
                                    unpairedHeight += self.rows[methodName].frame.getHeight()# + rowSpace
                            unpairedCol.setHeight(unpairedHeight)

                            #self.form.attachForm( self.frame, 'left', 2)
                            #self.form.attachForm( self.frame, 'right', 2)
                            #self.form.attachForm( self.frame, 'top', 2)
                            #self.form.attachForm( self.frame, 'bottom', 2)
                            unpairedCol.setVisible(True)
                unpairedForm.attachForm( unpairedScroll, 'top', 5 )
                unpairedForm.attachForm( unpairedScroll, 'left', 5 )
                unpairedForm.attachForm( unpairedScroll, 'right', 5 )
                unpairedForm.attachForm( unpairedScroll, 'bottom', 5 )
        return self.frame


class MethodRow(object):
    def __init__(self, parent, className, apiClassName, apiMethodName, methodInfoList):


        self.parent = parent
        self.className = className
        self.methodName = methodInfoList[0].get('pymelName', apiMethodName)
        self.apiClassName = apiClassName
        self.apiMethodName = apiMethodName
        self.methodInfoList = methodInfoList
        self.data = factories._getApiOverrideNameAndData(self.className, self.methodName)[1]
        self.classInfo = factories.apiClassInfo[self.apiClassName]['methods'][self.apiMethodName]
        try:
            enabledArray = self.getEnabledArray()
        except:
            print self.apiClassName, self.apiMethodName
            raise
        # DEFAULT VALUES


        # correct old values
        # we no longer store positive values, only negative -- meaning methods will be enabled by default
#        if 'enabled' in self.data and ( self.data['enabled'] == True  or sum(enabledArray) == 0 ):
#            logger.debug( '%s.%s: enabled array: %s' % ( self.className, self.methodName, enabledArray ) )
#            logger.debug( '%s.%s: removing enabled entry' % ( self.className, self.methodName) )
#            self.data.pop('enabled', None)


        # enabled
#        if not self.data.has_key( 'enabled' ):
#            self.data['enabled'] = True

        if self.methodName in factories.EXCLUDE_METHODS : # or sum(enabledArray) == 0:
            self.data['enabled']  = False


        # useName mode
        if not self.data.has_key( 'useName' ):
            self.data['useName'] = 'API'
        else:
            # correct old values
            useNameVal = self.data['useName']
            if useNameVal == True:
                self.data['useName'] = 'API'
            elif useNameVal == False:
                self.data['useName'] = 'MEL'
            elif useNameVal not in ['MEL', 'API']:
                self.data['useName'] = str(useNameVal)

        # correct old values
        if self.data.has_key('overloadPrecedence'):
            self.data['overloadIndex'] = self.data.pop('overloadPrecedence')

        # correct old values
        if self.data.has_key('melName'):
            #logger.debug( "correcting melName %s %s %s" % (self.className, self.methodName, str(self.data['melName']) ) )
            self.data['melName'] = str(self.data['melName'])


        overloadId = self.data.get('overloadIndex', 0)
        if overloadId is None:
            # in a previous test, it was determined there were no wrappable overload methods,
            # but there may be now.  try again.
            overloadId = 0

        # ensure we don't use a value that is not valid
        for i in range(overloadId, len(enabledArray)+1):
            try:
                if enabledArray[i]:
                    break
            except IndexError: # went too far, so none are valid
                overloadId = None
#        if val is None:
#            # nothing valid
#            self.data.pop('overloadIndex', None)
#        else:
        self.data['overloadIndex'] = overloadId

    def crossReference(self, melName):
        """ create an entry for the melName which points to the data being tracked for the api name"""

        factories.apiToMelData[ (self.className, melName ) ] = self.data

    def uncrossReference(self, melName):
        factories.apiToMelData.pop( (self.className, melName ) )

    def updateMelNames(self, melMethods):
        # melName
        if not self.data.has_key( 'melName' ):
            match = None
            for method in melMethods:
                methreg = re.compile(method.replace('*', '.{0,1}') + '$')
                #print self.methodName, methreg
                if methreg.match( self.methodName ):
                    match = str(method)
                    break
            if match:
                logger.debug( "%s.%s: adding melName %s" % ( self.className, self.methodName, match ) )
                self.data['melName'] = match
                self.crossReference( match )

    def buildUI(self, filter=None):

        if filter:
            match = False
            for i, info in enumerate( self.methodInfoList):
                argUtil = factories.ApiArgUtil( self.apiClassName, self.apiMethodName, i )
                if filter.intersection( argUtil.getInputTypes() + argUtil.getOutputTypes() ):
                    match = True
                    break
            if match == False:
                return False

        self.layout = { 'columnAlign'  : [1,'right'],
                   'columnAttach' : [1,'right',8] }

        #print className, self.methodName, melMethods
        isOverloaded = len(self.methodInfoList)>1
        self.frame = pm.frameLayout( w=FRAME_WIDTH, labelVisible=False, collapsable=False)
        logger.debug("building row for %s - %s" % (self.methodName, self.frame))
        col = pm.columnLayout()

        enabledArray = []
        self.rows = []
        self.overloadPrecedenceColl = None
        self.enabledChBx = pm.checkBox(label=self.methodName,
                    changeCommand=pm.CallbackWithArgs( MethodRow.enableCB, self ) )

        if isOverloaded:

            self.overloadPrecedenceColl = pm.radioCollection()
            for i in range( len(self.methodInfoList) ) :

                self.createMethodInstance(i)

        else:
            #row = rowLayout( self.methodName + '_rowMain', nc=2, cw2=[200, 400] )
            #self.enabledChBx = checkBox(label=self.methodName, changeCommand=CallbackWithArgs( MethodRow.enableCB, self ) )
            #text(label='')
            self.createMethodInstance(0)
            #setParent('..')

        pm.setParent(col)
        pm.separator(w=800, h=6)


        #self.row = rowLayout( self.methodName + '_rowSettings', nc=4, cw4=[200, 160, 180, 160] )
        #self.rows.append(row)


        self.row = pm.rowLayout( self.methodName + '_rowSettings', nc=2, cw2=[200, 220], **self.layout )
        self.rows.append(self.row)

        # create ui elements
        pm.text(label='Mel Equivalent')

        self.melNameTextField = pm.textField(w=170, editable=False)
        self.melNameOptMenu = pm.popupMenu(parent=self.melNameTextField,
                                        button=1,
                                        postMenuCommand=pm.Callback( MethodRow.populateMelNameMenu, self ) )
        pm.setParent('..')

        self.row2 = pm.rowLayout( self.methodName + '_rowSettings2', nc=3, cw3=[200, 180, 240], **self.layout )
        self.rows.append(self.row2)

        pm.text(label='Use Name')
        self.nameMode = pm.radioButtonGrp(label='', nrb=3, cw4=[1,50,50,50], labelArray3=['api', 'mel', 'other'] )
        self.altNameText = pm.textField(w=170, enable=False)
        self.altNameText.changeCommand( pm.CallbackWithArgs( MethodRow.alternateNameCB, self ) )
        self.nameMode.onCommand( pm.Callback( MethodRow.nameTypeCB, self ) )

        isEnabled = self.data.get('enabled', True)

        # UI SETUP

        melName = self.data.get('melName', '')

        try:
            #self.melNameOptMenu.setValue( melName )
            self.melNameTextField.setText(melName)
            if melName != '':
                self.parent.parent.assignMelMethod( melName )

        except RuntimeError:
            # it is possible for a method name to be listed here that was set from a different view,
            # where this class was a super class and more mel commands were available.  expand the option list,
            # and make this frame read-only
            pm.menuItem( label=melName, parent=self.melNameOptMenu )
            self.melNameOptMenu.setValue( melName )
            logger.debug( "making %s frame read-only" % self.methodName )
            self.frame.setEnable(False)


        self.enabledChBx.setValue( isEnabled )
        self.row.setEnable( isEnabled )
        self.row2.setEnable( isEnabled )

        name = self.data['useName']
        if name == 'API' :
            self.nameMode.setSelect( 1 )
            self.altNameText.setEnable(False)
        elif name == 'MEL' :
            self.nameMode.setSelect( 2 )
            self.altNameText.setEnable(False)
        else :
            self.nameMode.setSelect( 3 )
            self.altNameText.setText(name)
            self.altNameText.setEnable(True)


        if self.overloadPrecedenceColl:
            items = self.overloadPrecedenceColl.getCollectionItemArray()
            try:
                val = self.data['overloadIndex']

                if val is None:
                    logger.info( "no wrappable options for method %s" % self.methodName )
                    self.frame.setEnable( False )
                else:
                    self.overloadPrecedenceColl.setSelect( items[ val ] )
            except:
                pass

#            # ensure we don't use a value that is not valid
#            for val in range(val, len(enabledArray)+1):
#                try:
#                    if enabledArray[val]:
#                        break
#                except IndexError:
#                    val = None
#            if val is not None:
#                self.overloadPrecedenceColl.setSelect( items[ val ] )

        pm.setParent('..')

        pm.setParent('..') # frame
        pm.setParent('..') # column

        return True

    def enableCB(self, *args ):
        logger.debug( 'setting enabled to %s' % args[0] )
        if args[0] == False:
            self.data['enabled'] = False
        else:
            self.data.pop('enabled', None)
        self.row.setEnable( args[0] )

    def nameTypeCB(self ):
        logger.info( 'setting name type' )
        selected = self.nameMode.getSelect()
        if selected == 1:
            val = 'API'
            self.altNameText.setEnable(False)
        elif selected == 2:
            val = 'MEL'
            self.altNameText.setEnable(False)
        else:
            val = str(self.altNameText.getText())
            self.altNameText.setEnable(True)

        logger.debug( 'data %s' % self.data )
        self.data['useName'] = val

    def alternateNameCB(self, *args ):
        self.data['useName'] = str(args[0])

#    def formatAnnotation(self, apiClassName, methodName ):
#        defs = []
#        try:
#            for methodInfo in factories.apiClassInfo[apiClassName]['methods'][methodName] :
#                args = ', '.join( [ '%s %s' % (x[1],x[0]) for x in methodInfo['args'] ] )
#                defs.append( '%s( %s )' % ( methodName, args ) )
#            return '\n'.join( defs )
#        except KeyError:
#            print "could not find documentation for", apiClassName, methodName

    def overloadPrecedenceCB(self, i):
        logger.debug( 'overloadPrecedenceCB' )
        self.data['overloadIndex'] = i

    def melNameChangedCB(self, newMelName):
        oldMelName = str(self.melNameTextField.getText())
        if oldMelName:
            self.uncrossReference( oldMelName )
        if newMelName == '[None]':
            print "removing melName"
            self.data.pop('melName',None)
            self.parent.parent.unassignMelMethod( oldMelName )
            self.melNameTextField.setText('')
        else:
            print "adding melName", newMelName
            self.crossReference( newMelName )
            self.data['melName'] = newMelName
            self.parent.parent.assignMelMethod( newMelName )
            self.melNameTextField.setText(newMelName)

    def populateMelNameMenu(self):
        """called to populate the popup menu for choosing the mel equivalent to an api method"""
        self.melNameOptMenu.deleteAllItems()

        pm.menuItem(parent=self.melNameOptMenu, label='[None]', command=pm.Callback( MethodRow.melNameChangedCB, self, '[None]' ))
        # need to add a listForNone to this in windows
        items = self.parent.parent.unassignedMelMethodLister.getAllItems()
        if items:
            for method in items:
                pm.menuItem(parent=self.melNameOptMenu, label=method, command=pm.Callback( MethodRow.melNameChangedCB, self, str(method) ))

    def getEnabledArray(self):
        """returns an array of booleans that correspond to each override method and whether they can be wrapped"""
        array = []
        for i, info in enumerate( self.methodInfoList ):
            argUtil = factories.ApiArgUtil( self.apiClassName, self.apiMethodName, i )
            array.append( argUtil.canBeWrapped() )
        return array


    def createMethodInstance(self, i ):

        #setUITemplate('attributeEditorTemplate', pushTemplate=1)

        rowSpacing = [30, 20, 400]

        defs = []
        #try:
        argUtil = factories.ApiArgUtil( self.apiClassName, self.apiMethodName, i )
        proto = argUtil.getPrototype( className=False, outputs=True, defaults=False )

        enable = argUtil.canBeWrapped()

        if argUtil.isDeprecated():
            pm.text(l='DEPRECATED')
        # main info row
        row = pm.rowLayout( '%s_rowMain%s' % (self.methodName,i), nc=3, cw3=rowSpacing, enable=enable )
        self.rows.append(row)
        pm.text(label='')

        if self.overloadPrecedenceColl is not None:
            # toggle for overloaded methods
            pm.radioButton(label='', collection=self.overloadPrecedenceColl,
                                enable = enable,
                                onCommand=pm.Callback( MethodRow.overloadPrecedenceCB, self, i ))
        pm.text(   l='', #l=proto,
                annotation = self.methodInfoList[i]['doc'],
                enable = enable)

        pm.setParent('..')

        try:
            argList = factories.apiClassOverrides[self.apiClassName]['methods'][self.apiMethodName][i]['args']
        except (KeyError, IndexError):
            argList = self.methodInfoList[i]['args']

        returnType =  self.methodInfoList[i]['returnType']
        types = self.methodInfoList[i]['types']
        args = []

        for arg , type, direction in argList:
            type = str(types[arg])
            assert arg != 'return'
            self._makeArgRow( i, type, arg, direction, self.methodInfoList[i]['argInfo'][arg]['doc'] )

        if returnType:
            self._makeArgRow( i, returnType, 'return', 'return', self.methodInfoList[i]['returnInfo']['doc'] )

        pm.separator(w=800, h=14)

        return enable
#            methodInfo = factories.apiClassInfo[self.apiClassName]['methods'][self.apiMethodName][overloadNum]
#            args = ', '.join( [ '%s %s' % (x[1],x[0]) for x in methodInfo['args'] ] )
#            return  '( %s ) --> ' % ( args )
        #except:
        #    print "could not find documentation for", apiClassName, methodName


    def setUnitType(self, methodIndex, argName, unitType ):

        if self.apiClassName not in factories.apiClassOverrides:
            factories.apiClassOverrides[self.apiClassName] = { 'methods' : {} }

        methodOverrides = factories.apiClassOverrides[self.apiClassName]['methods']

        if self.apiMethodName not in methodOverrides:
            methodOverrides[self.apiMethodName] = {}

        if argName == 'return':
            if methodIndex not in methodOverrides[self.apiMethodName]:
                methodOverrides[self.apiMethodName][methodIndex] = { 'returnInfo' : {} }

            methodOverrides[self.apiMethodName][methodIndex]['returnInfo']['unitType'] = unitType

        else:
            if methodIndex not in methodOverrides[self.apiMethodName]:
                methodOverrides[self.apiMethodName][methodIndex] = { 'argInfo' : {} }

            if argName not in methodOverrides[self.apiMethodName][methodIndex]['argInfo']:
                methodOverrides[self.apiMethodName][methodIndex]['argInfo'][argName] = {}

            methodOverrides[self.apiMethodName][methodIndex]['argInfo'][argName]['unitType'] = unitType

    def setDirection(self, methodIndex, argName, direction ):

        if self.apiClassName not in factories.apiClassOverrides:
            factories.apiClassOverrides[self.apiClassName] = { 'methods' : {} }

        methodOverrides = factories.apiClassOverrides[self.apiClassName]['methods']

        if self.apiMethodName not in methodOverrides:
            methodOverrides[self.apiMethodName] = {}

        if methodIndex not in methodOverrides[self.apiMethodName]:
            methodOverrides[self.apiMethodName][methodIndex] = { }

        try:
            argList = methodOverrides[self.apiMethodName][methodIndex]['args']

        except KeyError:
            argList = self.methodInfoList[methodIndex]['args']

        newArgList = []
        inArgs = []
        outArgs = []
        for i_argName, i_argType, i_direction in argList:
            if i_argName == argName:
                argInfo = ( i_argName, i_argType, direction )
            else:
                argInfo = ( i_argName, i_argType, i_direction )

            if argInfo[2] == 'in':
                inArgs.append( i_argName )
            else:
                outArgs.append( i_argName )
            newArgList.append( argInfo )

            methodOverrides[self.apiMethodName][methodIndex] = { }

        methodOverrides[self.apiMethodName][methodIndex]['args'] = newArgList
        methodOverrides[self.apiMethodName][methodIndex]['inArgs'] = inArgs
        methodOverrides[self.apiMethodName][methodIndex]['outArgs'] = outArgs

    def _makeArgRow(self, methodIndex, type, argName, direction, annotation=''):
        COL1_WIDTH = 260
        COL2_WIDTH = 120
        pm.rowLayout( nc=4, cw4=[COL1_WIDTH,COL2_WIDTH, 70, 150], **self.layout )

        label = str(type)

        pm.text( l=label, ann=annotation )
        pm.text( l=argName, ann=annotation )

        if direction == 'return':
            pm.text( l='(result)' )
        else:
            direction_om = pm.optionMenu(l='', w=60, ann=annotation, cc=pm.CallbackWithArgs( MethodRow.setDirection, self, methodIndex, argName ) )
            for unit in ['in', 'out']:
                pm.menuItem(l=unit)
            direction_om.setValue(direction)

        if self._isPotentialUnitType(type) :
            om = pm.optionMenu(l='', ann=annotation, cc=pm.CallbackWithArgs( MethodRow.setUnitType, self, methodIndex, argName ) )
            for unit in ['unitless', 'linear', 'angular', 'time']:
                pm.menuItem(l=unit)
            if argName == 'return':
                try:
                    value = factories.apiClassOverrides[self.apiClassName]['methods'][self.apiMethodName][methodIndex]['returnInfo']['unitType']
                except KeyError:
                    pass
            else:
                try:
                    value = factories.apiClassOverrides[self.apiClassName]['methods'][self.apiMethodName][methodIndex]['argInfo'][argName]['unitType']
                except KeyError:
                    pass
            try:
                om.setValue(value)
            except: pass

        else:
            pm.text( l='', ann=annotation )
        pm.setParent('..')

    def _isPotentialUnitType(self, type):
        type = str(type)
        return type == 'MVector' or type.startswith('double')

def _getClass(className):
    for module in [pm.nodetypes, pm.datatypes, pm.general]:
        try:
            pymelClass = getattr(module, className)
            return pymelClass
        except AttributeError:
            pass

def getApiClassName( className ):
    pymelClass = _getClass(className)
    if pymelClass:

        apiClass = None
        apiClassName = None
        #if cls.__name__ not in ['object']:
        try:
            apiClass = pymelClass.__dict__[ '__apicls__']
            apiClassName = apiClass.__name__
        except KeyError:
            try:
                apiClass = pymelClass.__dict__[ 'apicls']
                apiClassName = apiClass.__name__
            except KeyError:
                #print "could not determine api class for", cls.__name__
                apiClassName = None
        return apiClassName
    else:
        logger.warning( "could not find class %s" % (className) )

def getClassHierarchy( className ):
    pymelClass = _getClass(className)
    if pymelClass:

        mro = list( inspect.getmro(pymelClass) )
        mro.reverse()

        for i, cls in enumerate(mro):
            #if cls.__name__ not in ['object']:
            try:
                apiClass = cls.__dict__[ '__apicls__']
                apiClassName = apiClass.__name__
            except KeyError:
                try:
                    apiClass = cls.__dict__[ 'apicls']
                    apiClassName = apiClass.__name__
                except KeyError:
                    #print "could not determine api class for", cls.__name__
                    apiClassName = None

            yield cls.__name__, apiClassName
    else:
        logger.warning( "could not find class %s" % (className) )



def setManualDefaults():
    # set some defaults
    # TODO : allow these defaults to be controlled via the UI
    pm.util.setCascadingDictItem( factories.apiClassOverrides, ('MFnTransform', 'methods', 'setScalePivot', 0, 'defaults', 'balance' ), True )
    pm.util.setCascadingDictItem( factories.apiClassOverrides, ('MFnTransform', 'methods', 'setRotatePivot', 0, 'defaults', 'balance' ), True )
    pm.util.setCascadingDictItem( factories.apiClassOverrides, ('MFnTransform', 'methods', 'setRotateOrientation', 0, 'defaults', 'balance' ), True )
    pm.util.setCascadingDictItem( factories.apiClassOverrides, ('MFnSet', 'methods', 'getMembers', 0, 'defaults', 'flatten' ), False )
    pm.util.setCascadingDictItem( factories.apiClassOverrides, ('MFnDagNode', 'methods', 'instanceCount', 0, 'defaults', 'total' ), True )
    pm.util.setCascadingDictItem( factories.apiClassOverrides, ('MFnMesh', 'methods', 'createColorSetWithName', 1, 'defaults', 'modifier' ), None )

    # add some manual invertibles: THESE MUST BE THE API NAMES
    invertibles = [ ('MPlug', 0, 'setCaching', 'isCachingFlagSet') ,
                    ('MPlug', 0, 'setChannelBox', 'isChannelBoxFlagSet'),
                    ('MFnTransform', 0, 'enableLimit', 'isLimited'),
                    ('MFnTransform', 0, 'setLimit', 'limitValue'),
                    ('MFnTransform', 0, 'set', 'transformation'),
                    ('MFnRadialField', 0, 'setType', 'radialType')
                     ]
    for className, methodIndex, setter, getter in invertibles:
        # append to the class-level invertibles list
        curr = pm.util.getCascadingDictItem( factories.apiClassInfo, (className, 'invertibles' ), [] )
        pair = (setter, getter)
        if pair not in curr:
            curr.append( pair )

        pm.util.setCascadingDictItem( factories.apiClassOverrides, (className, 'invertibles'), curr )

        # add the individual method entries
        pm.util.setCascadingDictItem( factories.apiClassOverrides, (className, 'methods', setter, methodIndex, 'inverse' ), (getter, True) )
        pm.util.setCascadingDictItem( factories.apiClassOverrides, (className, 'methods', getter, methodIndex, 'inverse' ), (setter, False) )

    nonInvertibles = [ ( 'MFnMesh', 0, 'setFaceVertexNormals', 'getFaceVertexNormals' ),
                        ( 'MFnMesh', 0, 'setFaceVertexNormal', 'getFaceVertexNormal' ) ]
    for className, methodIndex, setter, getter in nonInvertibles:
        pm.util.setCascadingDictItem( factories.apiClassOverrides, (className, 'methods', setter, methodIndex, 'inverse' ), None )
        pm.util.setCascadingDictItem( factories.apiClassOverrides, (className, 'methods', getter, methodIndex, 'inverse' ), None )
    fixSpace()

def fixSpace():
    "fix the Space enumerator"

    enum = pm.util.getCascadingDictItem( factories.apiClassInfo, ('MSpace', 'pymelEnums', 'Space') )
    keys = enum._keys.copy()
    #print keys
    val = keys.pop('postTransform', None)
    if val is not None:
        keys['object'] = val
        newEnum = pm.util.Enum( 'Space', keys )

        pm.util.setCascadingDictItem( factories.apiClassOverrides, ('MSpace', 'pymelEnums', 'Space'), newEnum )
    else:
        logger.warning( "could not fix Space")

def cacheResults():
    #return

    res = pm.confirmDialog( title='Cache Results?',
                         message="Would you like to write your changes to disk? If you choose 'No' your changes will be lost when you restart Maya.",
                        button=['Yes','No'],
                        cancelButton='No',
                        defaultButton='Yes')
    print res
    if res == 'Yes':
        doCacheResults()

def doCacheResults():
    print "---"
    print "adding manual defaults"
    setManualDefaults()
    print "merging dictionaries"
    # update apiClasIfno with the sparse data stored in apiClassOverrides
    factories.mergeApiClassOverrides()
    print "saving api cache"
    factories.saveApiCache()
    print "saving bridge"
    factories.saveApiMelBridgeCache()
    print "---"

########NEW FILE########
__FILENAME__ = rebuildcaches
#!/usr/bin/env python

#TODO: support OS's other than OSX. revert to default prefs

import sys, os
versions = '2008 2009 2010 2011'.split()

pymeldir = os.path.dirname(os.path.dirname(os.path.abspath(sys.argv[0])))
os.chdir(pymeldir)
mayapy = '/Applications/Autodesk/maya%(version)s/Maya.app/Contents/bin/mayapy'

def rebuild():
    for version in versions:
        print "rebuilding ", version
        os.system( 'cd ' + pymeldir + ';' + mayapy % locals() + ' ' + sys.argv[0] + ' test' )

def delete(caches):
    for version in versions:
        for cache in caches:
            if not cache.startswith('maya'):
                cache = 'maya' + cache[0].upper() + cache[1:]
            cachefile = os.path.join( pymeldir, 'pymel', 'cache', cache + version + '.zip')
            if os.path.exists(cachefile):
                print "removing", cachefile
                os.remove( cachefile )
            else:
                print "does not exist", cachefile

def load():
    sys.path.insert(0,pymeldir)
    #for x in sys.path:
    #    print x
    import pymel.core

if __name__ == '__main__':
    args = sys.argv[1:]
    assert args, 'no caches passed to rebuild'

    if args[0]=='test':
        load()
    else:
        delete(args)
        rebuild()
########NEW FILE########
__FILENAME__ = stubs
from pydoc import *         #@UnusedWildImport
import pydoc, sys, pprint   #@Reimport
import __builtin__
import os                   #@Reimport
import pkgutil              #@Reimport
import collections
import inspect
import ast

builtins = set(__builtin__.__dict__.values())

# some basic data types which may not exist...
if 'bytes' not in globals():
    bytes = str
if 'basestring' not in globals():
    basestring = str

def get_class(obj):
    '''Retrives the class of the given object.

    unfortunately, it seems there's no single way to query class that works in
    all cases - .__class__ doesn't work on some builtin-types, like
    re._pattern_type instances, and type() doesn't work on old-style
    classes...
    '''
    cls = type(obj)
    if cls == types.InstanceType:
        cls = obj.__class__
    return cls

def has_default_constructor(cls):
    '''Returns true if it's possible to make an instance of the class with no args.
    '''
    # these classes's __init__/__new__ are slot_wrapper objects, which we can't
    # query... but we know that they are ok...
    safe_methods = set()
    for safe_cls in (object, list, dict, tuple, set, frozenset, str, unicode):
        safe_methods.add(safe_cls.__init__)
        safe_methods.add(safe_cls.__new__)

    for method in (getattr(cls, '__init__', None), getattr(cls, '__new__', None)):
        if method in safe_methods:
            continue
        if method is None:
            # we got an old-style class that didn't define an __init__ or __new__...
            # it's ok..
            continue

        try:
            args, _, _, defaults = inspect.getargspec(method)
        except TypeError:
            # sometimes we get 'slot_wrapper' objects, which we can't query...
            # assume these are bad...
            return False
        if defaults is None:
            numDefaults = 0
        else:
            numDefaults = len(defaults)
        # there can be one 'mandatory' arg - which will be cls or self
        if len(args) > numDefaults + 1:
            return False
    return True

def is_dict_like(obj):
    '''Test whether the object is "similar" to a dict
    '''
    if isinstance(obj, collections.Mapping):
        return True
    for method in ('__getitem__', '__setitem__', 'keys'):
        if not inspect.ismethod(getattr(obj, method, None)):
            return False
    return True


class ModuleNamesVisitor(ast.NodeVisitor):
    def __init__(self):
        self.names = set()

    def visit(self, node):
        # if we have the module, recurse
        if isinstance(node, ast.Module):
            self.generic_visit(node)

        # we are looking for statements which could define a new name...
        elif isinstance(node, (ast.Assign,
                             ast.ClassDef,
                             ast.FunctionDef,
                             ast.Import,
                             ast.ImportFrom,
                             ast.For,
                             ast.With,
                             ast.TryExcept,
                            )):
            self.addNames(node)

    def addNames(self, obj):
        #print "addNames: %r" % obj
        # string... add it!
        if isinstance(obj, basestring):
            self.names.add(obj)

        # A name node... add if the context is right
        elif isinstance(obj, ast.Name):
            if isinstance(obj.ctx, (ast.Store, ast.AugStore, ast.Param)):
                self.addNames(obj.id)

        # An alias... check for 'foo as bar'
        elif isinstance(obj, ast.alias):
            if obj.asname:
                name = obj.asname
            else:
                name = obj.name
            if name != '*':
                self.addNames(name)

        # list/tuple.. iterate...
        elif isinstance(obj, (list, tuple)):
            for item in obj:
                self.addNames(item)
        elif isinstance(obj, (ast.Tuple, ast.List)):
            self.addNames(obj.elts)

        # Statements (or subparts)...
        elif isinstance(obj, ast.Assign):
            self.addNames(obj.targets)
        elif isinstance(obj, ast.ClassDef):
            self.addNames(obj.name)
        elif isinstance(obj, ast.FunctionDef):
            self.addNames(obj.name)
        elif isinstance(obj, ast.Import):
            self.addNames(obj.names)
        elif isinstance(obj, ast.ImportFrom):
            self.addNames(obj.names)
        elif isinstance(obj, ast.For):
            self.addNames(obj.target)
        elif isinstance(obj, ast.With):
            self.addNames(obj.optional_vars)
        elif isinstance(obj, ast.TryExcept):
            self.addNames(obj.handlers)
        elif isinstance(obj, ast.ExceptHandler):
            self.addNames(obj.name)

def get_static_module_names(module):
    '''Given a module object, tries to do static code analysis to find the names
    that will be defined at module level.
    '''
    path = module.__file__
    if path.endswith(('.pyc', '.pyo')):
        path = path[:-1]
    with open(path, 'r') as f:
        text = f.read()
    if not text.endswith('\n'):
        # for some reason, the parser requires the text end with a newline...
        text += '\n'
    moduleAst = ast.parse(text, path)
    visitor = ModuleNamesVisitor()
    visitor.visit(moduleAst)
    return visitor.names


# for the sake of stubtest, don't importy anything pymel/maya at module level
#import pymel.util as util

class NoUnicodeTextRepr(TextRepr):
    '''PyDev barfs when a unicode literal (ie, u'something') is in a pypredef
    file; use this repr to make sure they don't show up.
    '''
    def __init__(self):
        self.maxlevel = 6
        self.maxtuple = 100000
        self.maxlist = 100000
        self.maxarray = 100000
        self.maxdict = 100000
        self.maxset = 100000
        self.maxfrozenset = 100000
        self.maxdeque = 100000
        self.maxstring = 100000
        self.maxlong = 100000
        self.maxother = 100000

    def repr_unicode(self, uStr, level):
        return self.repr_string(str(uStr), level)

class StubDoc(Doc):
    """Formatter class for text documentation."""

    # ------------------------------------------- text formatting utilities
    _repr_instance = NoUnicodeTextRepr()
    # We don't care if it's compact, we just want it to parse right...
    repr = _repr_instance.repr

    ALLOWABLE_DOUBLE_UNDER_ATTRS = ('__version__', '__author__', '__date__',
                                    '__credits__')

    # Mapping of (module, dontImportThese)
    MODULE_EXCLUDES = {
                       'pymel.api':set(['pymel.internal.apicache']),
                       'pymel'    :set(['pymel.all']),
                       'maya.precomp':set(['precompmodule']),
                      }
    debugmodule = 'pymel.core'

    def __init__(self, *args, **kwargs):
        self.missing_modules = set([])
        self.module_map = {}
        self.id_map = {}
        self.static_module_names = {}
        self.safe_constructor_classes = set()
        if hasattr(Doc, '__init__'):
            Doc.__init__(self, *args, **kwargs)

    def bold(self, text):
        """Format a string in bold by overstriking."""
        return join(map(lambda ch: ch + '\b' + ch, text), '')

    def indent(self, text, prefix='    '):
        """Indent text by prepending a given prefix to each line."""
        if not text: return ''
        lines = split(text, '\n')
        lines = map(lambda line, prefix=prefix: prefix + line, lines)
        if lines: lines[-1] = rstrip(lines[-1])
        return join(lines, '\n')

    def section(self, title, contents):
        """Format a section with a given heading."""
        quotes = "'''" if '"""' in contents else '"""'
        return rstrip(self.indent( quotes +'\n' + contents + '\n' + quotes)) + '\n\n'

    def docstring(self, contents):
        """Format a section with a given heading."""
        quotes = "'''" if '"""' in contents else '"""'
        return quotes + '\n' + contents + '\n' + quotes + '\n\n'

    # ---------------------------------------------- type-specific routines

    def formattree(self, tree, modname, parent=None, prefix=''):
        """Render in text a class tree as returned by inspect.getclasstree()."""
        result = ''
        for entry in tree:
            if type(entry) is type(()):
                c, bases = entry
                result = result + prefix + self.classname(c, modname)
                if bases and bases != (parent,):
                    parents = map(lambda c, m=modname: self.classname(c, m), bases)
                    result = result + '(%s)' % join(parents, ', ')
                result = result + '\n'
            elif type(entry) is type([]):
                result = result + self.formattree(
                    entry, modname, c, prefix + '    ')
        return result

    importSubstitutions = {
                           # just leaving these here as examples of how to use,
                           # in case we need to use it again at some point
                           # in the future...

                           #'pymel.util.objectParser':'''
#class ProxyUni(object): pass
#class Parsed(ProxyUni): pass
#''',
                           #'precompmodule':''
                          }

    def docmodule(self, this_module, name=None, mod=None):
        """Produce text documentation for a given module object."""

        this_name = this_module.__name__ # ignore the passed-in name
        desc = splitdoc(getdoc(this_module))[1]
        result = ''
        self.module_map = {}
        self.id_map = {}
        self.missing_modules = set([])
        self.safe_constructor_classes = set()
        all = getattr(this_module, '__all__', None)

        if desc:
            result += result + self.docstring(desc)

        def get_source_module(obj):
            mod = inspect.getmodule(obj)
            if mod == __builtin__ and obj in builtins:
                return mod
            if (not mod or inspect.isbuiltin(obj) or isdata(obj)
                    or not mod.__name__ or mod.__name__.startswith('_')):
                mod = this_module
            return mod

        # set of all names in this module
        all_names = set()

        def get_unique_name(basename=None):
            if basename is None:
                basename = '_unknown'
            elif not basename.startswith('_'):
                # we only use this in cases where the name wasn't orignally
                # found in the module - ie, we're just trying to add in
                # something that isn't really supposed to be in the module, but
                # we need it there to refer to it...
                # ...therefore, we want to make sure the name is at least
                # hidden...
                basename = '_' + basename
            name = basename
            num = 2
            while name in all_names:
                name = '%s%s' % (basename, num)
                num += 1
            return name

        # these are all dicts that key off the object id...
        # we index by obj-id, instead of obj, because not all objects are
        # hashable, and we really only care about 'is' comparisons, not
        # equality comparisons...

        # this is a dict that maps from object id to a tuple
        #   (obj, objtype, source_module, names)
        # where obj is the object itself, objtype is one of the strings
        # module/class/func/data, and names is a list of the names/aliases under
        # which the object can be found in this module.
        id_to_data = {}

        OBJ = 0
        OBJTYPE = 1
        SOURCEMOD = 2
        NAMES = 3

        def add_obj(obj, name=None, source_module=None):
            id_obj = id(obj)
            if id_obj in id_to_data:
                # the object was already known - check that the source_module
                # is consistent, and add the name if needed
                objtype, old_source_module, names = id_to_data[id_obj][OBJTYPE:]

                if source_module is None:
                    # use the old source module..
                    source_module = old_source_module
                # if the source modules are different, but the 'new' module
                # is this module, we're okay - we couldn't find the object
                # in the desired source_module, so we're just moving it
                # into this one...
                elif (source_module != old_source_module
                        and source_module != this_module):
                    # ...otherwise, something weird is going on...
                    raise RuntimeError("got conflicting source modules for %s" % obj)

                # If we don't know the name, and the object already exists in
                # the module, then we don't need to do anything... we can just
                # use one of the names already assigned to the object...
                if name is not None:
                    # ...otherwise, we need to add the name to list of
                    # aliases for the object in this module...
                    if name not in names:
                        # if __name__ matches name, put the name at the
                        # front of the list of names, to make it the
                        # 'default' name...
                        if getattr(obj, '__name__', None) == name:
                            names.insert(0, name)
                        else:
                            names.append(name)
            else:
                # the object wasn't known... generate it's info...
                if name is None:
                    # we didn't know the name - generate a unique one, hopefully
                    # based off the object's name...
                    name = get_unique_name(getattr(obj, '__name__', None))
                if source_module is None:
                    source_module = get_source_module(obj)

                # now find the objtype...
                if inspect.ismodule(obj):
                    objtype = 'module'
                elif inspect.isclass(obj):
                    objtype = 'class'
                elif inspect.isroutine(obj):
                    objtype = 'func'
                else:
                    objtype = 'data'
                names = [name]
            id_to_data[id_obj] = (obj, objtype, source_module, names)


        # add all the objects that we have names for / should be in this
        # module
        for name, obj in inspect.getmembers(this_module):
            if (name.startswith('__') and name.endswith('__')
                    and name not in self.ALLOWABLE_DOUBLE_UNDER_ATTRS):
                continue
            add_obj(obj, name)

        def have_id_name(id_obj, name):
            data = id_to_data.get(id_obj, None)
            if data is None:
                return False
            return name in data[NAMES]

        # We now need to do two things:
        #  1) find the parent classes for any classes we will define in this
        #     module, and make sure that they are accessible under some name
        #     from within this module
        #  2) for all objects we will be importing from other modules, make
        #     sure we can actually find them under some name in that module;
        #     if not, change their source_module to THIS module (ie, so we
        #     define a dummy placeholder for it in this module)


        # Since both of these can end up adding new objects to the list of
        # objects defined in this module (ie, whose source_module == this_module),
        # which can then cause the need to check for updates on the other,
        # we run both in a loop until neither task finds any new things added
        # to this module's namespace

        # maps from the id of a class to it's parent classes, for classes
        # which we will define in this module...
        class_parents = {}
        def add_parent_classes():
            # deal with the classes - for classes in this module, we need to find
            # their base classes, and make sure they are also defined, or imported
            untraversed_classes = list(obj for (obj, objtype, source_module, names)
                                       in id_to_data.itervalues()
                                       if objtype == 'class'
                                       and source_module == this_module
                                       and id(obj) not in class_parents)
            new_to_this_module = 0
            while untraversed_classes:
                child_class = untraversed_classes.pop()
                try:
                    parents = [x for x in child_class.__bases__]
                except Exception:
                    print "problem iterating %s.__bases__" % child_class
                    parents = (object,)
                class_parents[id(child_class)] = parents

                for parent_class in parents:
                    id_parent = id(parent_class)
                    if id_parent not in id_to_data:
                        if parent_class in builtins:
                            continue

                        # We've found a class that's not in this namespace...
                        # ...but perhaps it's parent module is?
                        found_parent_mod = False
                        parent_mod = inspect.getmodule(parent_class)
                        if parent_mod:
                            if id(parent_mod) in id_to_data:
                                found_parent_mod = True
                            else:
                                mod_name = parent_mod.__name__
                                mod_name_split =  mod_name.split('.')
                                while mod_name_split:
                                    mod_name_split.pop()
                                    mod_name = '.'.join(mod_name_split)
                                    parent_mod = sys.modules.get(mod_name, None)
                                    if parent_mod is not None and id(parent_mod) in id_to_data:
                                        found_parent_mod = True
                                        break
                            if found_parent_mod:
                                # the parent module was there... skip this parent class..
                                continue

                        # we've found a new class... add it...
                        new_to_this_module += 1
                        add_obj(parent_class)
                        source_module = id_to_data[id_parent][SOURCEMOD]
                        if source_module == this_module:
                            untraversed_classes.append(parent_class)
            return new_to_this_module

        # maps from an id_obj to it's ('default') name in the source module
        import_other_name = {}
        # maps from module to a dict, mapping from id to names within that module
        other_module_names = {}
        def find_import_data():
            unknown_import_objs = list((obj, source_module) for (obj, objtype, source_module, names)
                                       in id_to_data.itervalues()
                                       if objtype != 'module'
                                          and source_module != this_module
                                          and id(obj) not in import_other_name)
            new_to_this_module = 0
            for obj, source_module in unknown_import_objs:
                id_obj = id(obj)
                other_id_names = other_module_names.get(source_module, None)
                if other_id_names is None:
                    other_id_names = {}
                    for other_name, other_obj in inspect.getmembers(source_module):
                        id_other = id(other_obj)
                        other_id_names.setdefault(id_other, []).append(other_name)
                    other_module_names[source_module] = other_id_names
                other_names = other_id_names.get(id_obj, None)
                if not other_names:
                    # we couldn't find obj in the desired module - we'll
                    # have to move it to this_module...
                    new_to_this_module += 1
                    # calling add_obj with the same obj but module as
                    # this_module will update it...
                    add_obj(obj, source_module=this_module)
                else:
                    # check to see if we've already found the object
                    # in the module - if so, only update the name if it's the
                    # __name__ of the object
                    name = getattr(obj, '__name__', None)
                    if name is None or name not in other_names:
                        name = other_names[0]
                    import_other_name[id_obj] = name

            return new_to_this_module

        new_to_this_module = 1
        while new_to_this_module:
            new_to_this_module = add_parent_classes() + find_import_data()

        # check the other modules for possible "from mod import *" action...
        importall_modules = []
        for other_mod, other_id_names in other_module_names.iteritems():
            other_all = getattr(other_mod, '__all__', None)
            visible_other = 0
            in_this = []
            for id_obj, other_names in other_id_names.iteritems():
                for other_name in other_names:
                    if not visiblename(other_name, other_all):
                        continue
                    visible_other += 1
                    if have_id_name(id_obj, other_name):
                        in_this.append((id_obj, other_name))
            # rough heuristic - if 90% of the objects can be found in this
            # module, we assume an import all was done... note that we're not
            # even checking if they're present in this module with the same
            # name... it's a rough heuristic anyway...
            if float(len(in_this)) / visible_other > .9:
                importall_modules.append(other_mod)
                # go through and REMOVE all the in_this entries from
                # id_to_data...
                for id_obj, other_name in in_this:
                    data = id_to_data[id_obj]
                    data[NAMES].remove(other_name)
                    if not data[NAMES]:
                        del id_to_data[id_obj]

        # We finally have all the objects that will be added to this module
        # (with their names in this module), all the parent clases for classes
        # defined here, and all the import names for objects being imported...

        # Now, sort them all into lists by type for objects defined in in
        # this module, and a list of imported for things in other modules...

        modules = []
        classes = []
        funcs = []
        data = []
        imported = []

        bins = {'module':modules,
                'class':classes,
                'func':funcs,
                'data':data
               }
        for id_obj, (obj, objtype, source_module, names) in id_to_data.iteritems():
            if source_module == this_module or objtype == 'module':
                bins[objtype].append((obj, names))
            else:
                imported.append((obj, names, source_module))

        # Before adding things, prepopulate our module_map and id_map

        for obj, names in modules:
            self.add_to_module_map(obj.__name__, names[0])

        for mod in importall_modules:
            self.add_to_module_map(mod.__name__, '')

        # eventually, might want to replace module_map and id_map
        # with id_to_data...
        for id_obj, (obj, objtype, source_module, names) in id_to_data.iteritems():
            if objtype == 'module':
                continue
            self.id_map[id_obj] = names[0]

        # Finally, go through and start writing stuff out! Go though by type:
        #
        #    1) module imports
        #    2) from MODULE import *
        #    3) from MODULE import OBJ
        #    4) class definitions
        #    5) func defs
        #    6) data

        if modules:
            contents = []
            #print "modules", this_module
            for obj, names in modules:
                for import_name in names:
                    realname = getattr(obj, '__name__', None)
                    if not realname:
                        print "Warning - could not get a name for module %s" % obj
                        continue
                    if realname == this_name:
                        continue
                    import_text = self.import_mod_text(this_module, realname, import_name)
                    if import_text:
                        contents.append(import_text)
            result = result + join(contents, '\n') + '\n\n'

        if importall_modules:
            # special-case handling for pymel.internal.pmcmds, which ends up
            # with a bunch of 'from pymel.core.X import *' commands
            if this_name == 'pymel.internal.pmcmds':
                importall_modules = [x for x in importall_modules
                                     if not getattr(x, '__name__', 'pymel.core').startswith('pymel.core')]
                imported = [(obj, names, source_module)
                            for obj, names, source_module in imported
                            if not getattr(source_module, '__name__', 'pymel.core').startswith('pymel.core')]
                if not any(x.__name__ == 'maya.cmds' for x in importall_modules):
                    import maya.cmds
                    importall_modules.append(maya.cmds)

            contents = []
            for mod in importall_modules:
                import_text = self.import_mod_text(this_module, mod.__name__, '*')
                if import_text:
                    contents.append(import_text)
            result = result + '\n'.join(contents) + '\n\n'

        if imported:
            contents = []
            for obj, names, source_module in imported:
                for name in names:
                    import_text = self.import_obj_text(source_module.__name__,
                                                       import_other_name[id(obj)],
                                                       name)
                    if import_text:
                        contents.append(import_text)
            result = result + '\n'.join(contents) + '\n\n'

        if classes:
            # sort in order of resolution
            def nonconflicting(classlist):
                for cls in classlist:
                    ancestors = set(inspect.getmro(cls)[1:])
                    if not ancestors.intersection(classlist):
                        yield cls

            sorted = []
            unsorted = set([x[0] for x in classes])

            while unsorted:
                for cls in nonconflicting(unsorted):
                    sorted.append(cls)
                unsorted.difference_update(sorted)

            contents = []
            classes = dict(classes)
            for cls in sorted:
                names = classes[cls]
                name = names[0]
                contents.append(self.document(cls, name, this_name))
                for alias in names[1:]:
                    contents.append('%s = %s' % (alias, name))
                # check if it has a default constructor... if so, add to the
                # list of classes that it is safe to create...
                if has_default_constructor(cls):
                    self.safe_constructor_classes.add(id(cls))

            classres = join(contents, '\n').split('\n')

            for i, line in enumerate(classres):
                if u'\xa0' in line:
                    print "bad char"
                    for j in range( max(i-10,0), min(i+10,len(classres)) ):
                        if j == i:
                            print '-'*80
                        print classres[j]
                        if j == i:
                            print '-'*80
                    classres[i] = ''.join(line.split( u'\xa0'))

            result = result + join(classres, '\n') + '\n\n'

        if funcs:
            contents = []
            for obj, names in funcs:
                name = names[0]
                contents.append(self.document(obj, name, this_name))
            for alias in names[1:]:
                contents.append('%s = %s' % (alias, name))
            result = result + join(contents, '\n') + '\n\n'

        if data:
            contents = []
            for obj, names in data:
                name = names[0]
                contents.append(self.docother(obj, name, this_name, maxlen=70))
            for alias in names[1:]:
                contents.append('%s = %s' % (alias, name))
            result = result + join(contents, '\n') + '\n\n'

#        if hasattr(this_module, '__version__'):
#            version = str(this_module.__version__)
#            if version[:11] == '$' + 'Revision: ' and version[-1:] == '$':
#                version = strip(version[11:-1])
#            result = result + self.section('VERSION', version) + '\n\n'
#        if hasattr(this_module, '__date__'):
#            result = result + self.section('DATE', str(this_module.__date__)) + '\n\n'
#        if hasattr(this_module, '__author__'):
#            result = result + self.section('AUTHOR', str(this_module.__author__)) + '\n\n'
#        if hasattr(this_module, '__credits__'):
#            result = result + self.section('CREDITS', str(this_module.__credits__)) + '\n\n'
        if self.missing_modules:
            contents = []
            for mod in self.missing_modules:
                import_text = self.import_mod_text(this_module, mod, '')
                if import_text:
                    contents.append(import_text)
            result = join(contents, '\n') + '\n\n'  + result
        self.safe_constructor_classes = set()
        return result

    def add_to_module_map(self, realname, newname):
        oldname = self.module_map.get(realname, None)
        if oldname is None:
            self.module_map[realname] = newname
            return
        else:
            # if either old or new is a 'from realname import *', that's the
            # best possible outcome...
            if not oldname or not newname:
                self.module_map[realname] = ''
                return
            # otherwise, check to see if one of the names matches the last
            # part of realname...
            final_name = realname.split('.')[-1]
            if final_name in (oldname, newname):
                self.module_map[realname] = final_name
                return

            # otherwise, just take whatever one has the shorter number of
            # parts, with tie going to the old_val...
            oldnum = len(oldname.split('.'))
            newnum = len(newname.split('.'))

            if oldnum < newnum:
                self.module_map[realname] = oldname
            elif oldnum > newnum:
                self.module_map[realname] = newname
            # tie, do nothing...
            return

    def module_has_static_name(self, module, name):
        if isinstance(module, basestring):
            module = sys.modules[module]
        elif not isinstance(module, types.ModuleType):
            raise TypeError(module)

        if module not in self.static_module_names:
            self.static_module_names[module] = get_static_module_names(module)
        return name in self.static_module_names[module]

    def classname(self, object, modname):
        """Get a class name and qualify it with a module name if necessary."""
        if id(object) in self.id_map:
            return self.id_map[id(object)]

        name = object.__name__
        missing = None
        realmodule = object.__module__
        # first, see if the object's module is THIS module...
        if realmodule not in [modname, '__builtin__']:
            # next, check if the module is in map of 'known' modules...
            if realmodule in self.module_map:
                newmodname = self.module_map[realmodule]
            else:
                newmodname = None
                missing = False
                # check all known modules... see if any of them have this module
                # in their contents...
                for m in self.module_map.keys():
                    mod = sys.modules[m]
                    #print '\t', m, mod
                    if object in mod.__dict__.values():
                        #print '\tfound'
                        newmodname = self.module_map[m]
                        break
                if not newmodname:
                    # try to see if any parent modules are known...
                    mod_parts = realmodule.split('.')
                    sub_parts = []
                    while mod_parts:
                        parentmod = '.'.join(mod_parts)
                        if parentmod in self.module_map:
                            # we have a parent module - so, ie,
                            # our class is xml.sax.handler.ErrorHandler,
                            # and we found the parent class xml.sax
                            # then our sub_parts will be ['handler']
                            # so we want to set modname to
                            #    (module_map['xml.sax']).handler...
                            newmodname = '.'.join([self.module_map[parentmod]] + sub_parts)
                            # we still need to make sure that the module gets imported,
                            # so that the parent module has the correct
                            # attributes on it - ie, if xml.sax exists, but
                            # we've never imported xml.sax.handler, the 'handler'
                            # attribute will not be on xml.sax
                            if sub_parts:
                                missing = True

                            # ...though we can add an entry to the module map
                            self.add_to_module_map(realmodule, newmodname)

                        sub_parts.insert(0, mod_parts.pop())

                if not newmodname:
                    missing = True
                    newmodname = realmodule
                if missing:
                    self.missing_modules.add(realmodule)
                    self.add_to_module_map(realmodule, realmodule)
            if newmodname:
                name = newmodname + '.' + name
        return name

    def docclass(self, object, name=None, mod=None):
        """Produce text documentation for a given class object."""
        realname = object.__name__
        name = name or realname
        bases = object.__bases__

        title = 'class ' + name

        if bases:
            parents = [self.classname(c, mod) for c in bases]
            title = title + '(%s)' % join(parents, ', ')
        title += ':\n'

        doc = getdoc(object)
        contents = doc and [self.docstring(doc) + '\n'] or []
        push = contents.append

        def spill(msg, attrs, predicate):
            ok, attrs = pydoc._split_list(attrs, predicate)
            if ok:
                for name, kind, homecls, value in ok:       #@UnusedVariable
                    push(self.document(getattr(object, name),
                                       name, mod, object))
            return attrs

        def spilldescriptors(msg, attrs, predicate):
            ok, attrs = pydoc._split_list(attrs, predicate)
            if ok:
                for name, kind, homecls, value in ok:       #@UnusedVariable
                    push(self._docdescriptor(name, value, mod))
            return attrs

        def spilldata(msg, attrs, predicate):
            ok, attrs = pydoc._split_list(attrs, predicate)
            if ok:
                for name, kind, homecls, value in ok:       #@UnusedVariable
                    if (hasattr(value, '__call__') or
                            inspect.isdatadescriptor(value)):
                        doc = getdoc(value)
                    else:
                        doc = None
                    push(self.docother(getattr(object, name),
                                       name, mod, maxlen=70, doc=doc) + '\n')
            return attrs

        attrs = filter(lambda data: visiblename(data[0]),
                       classify_class_attrs(object))

        thisclass = object
        attrs, inherited = pydoc._split_list(attrs, lambda t: t[2] is thisclass)

        if thisclass is __builtin__.object:
            attrs = inherited
        else:
            if attrs:
                tag = None

                # Sort attrs by name.
                attrs.sort()

                # Pump out the attrs, segregated by kind.
                attrs = spill("Methods %s:\n" % tag, attrs,
                              lambda t: t[1] == 'method')
                attrs = spill("Class methods %s:\n" % tag, attrs,
                              lambda t: t[1] == 'class method')
                attrs = spill("Static methods %s:\n" % tag, attrs,
                              lambda t: t[1] == 'static method')
                attrs = spilldescriptors("Data descriptors %s:\n" % tag, attrs,
                                         lambda t: t[1] == 'data descriptor')
                attrs = spilldata("Data and other attributes %s:\n" % tag, attrs,
                                  lambda t: t[1] == 'data')
            else:
                contents.append('pass')

        contents = '\n'.join(contents)

        return title + self.indent(rstrip(contents), '    ') + '\n\n'

    def formatvalue(self, object):
        """Format an argument default value as text."""
        # check if the object is os.environ...
        isEnviron = False
        if object == os.environ:
            isEnviron = True
        elif isinstance(object, dict):
            # If over 90% of the keys are in os.environ, assume it's os.environ
            if len(set(object) & set(os.environ)) > (len(object) * 0.9):
                isEnviron = True
        if isEnviron:
            objRepr = repr({'PROXY_FOR':'os.environ'})
        else:
            if isinstance(object, unicode):
                # pydev can't handle unicode literals - ie, u'stuff' - so
                # convert to normal strings
                object = str(object)
            objRepr = self.repr(object)
            if objRepr[0] == '<' and objRepr[-1] == '>':
                objRepr = repr(objRepr)
        return '=' + objRepr

    def docroutine(self, object, name=None, mod=None, cl=None):
        """Produce text documentation for a function or method object."""
        realname = object.__name__
        name = name or realname
        skipdocs = 0
        if inspect.ismethod(object):
            object = object.im_func

        title = name
        if inspect.isfunction(object):
            args, varargs, varkw, defaults = inspect.getargspec(object)
            argspec = inspect.formatargspec(
                args, varargs, varkw, defaults, formatvalue=self.formatvalue)
        else:
            argspec = '(*args, **kwargs)'
        decl = 'def ' + title + argspec + ':'

        if isinstance(object, staticmethod):
            decl = '@staticmethod\n' + decl
        elif isinstance(object, classmethod):
            decl = '@classmethod\n' + decl

        if skipdocs:
            return decl + 'pass\n'
        else:
            doc = getdoc(object) or ''
            return decl + '\n' + (doc and rstrip(self.indent(self.docstring(doc))) + '\n\n') + self.indent('pass') + '\n\n'

    def _docdescriptor(self, name, value, mod):
        results = []
        push = results.append

        if name:
            push(name + ' = None')
            push('\n')
        return ''.join(results)

    def docproperty(self, object, name=None, mod=None, cl=None):
        """Produce text documentation for a property."""
        return self._docdescriptor(name, object, mod)

    def docdata(self, object, name=None, mod=None, cl=None):
        """Produce text documentation for a data descriptor."""
        return self._docdescriptor(name, object, mod)

    def docother(self, object, name=None, mod=None, parent=None, maxlen=None, doc=None):
        """Produce text documentation for a data object."""
        if name in ['__metaclass__']:
            return ''

        safe_constructors = {}
        def has_safe_default_constructor(obj):
            # if the object is of a class that's defined in 'the current' stub
            # module, and that class has a default constructor, then we can
            # assume that it's safe to create one...
            cls = get_class(obj)
            id_cls = id(cls)
            if id_cls not in self.currentsafe_constructors:
                def _is_safe_cls(cls):
                    obj_module = getattr(cls, '__module__', None)
                    if self.current_module != obj_module:
                        return False
                    # ok, the class of the object seems to be from the current module...
                    # make doubly sure by checking the id_map
                    name = self.id_map.get(id(cls))
                    if not name:
                        return False



                result = _is_safe_cls(cls)
                safe_constructors[id_cls] = result
                return result
            return safe_constructors[id_cls]


        value = None
        if name == '__all__':
            value = pprint.pformat(object)
        elif id(get_class(object)) in self.safe_constructor_classes:
            cls_name = self.id_map[id(get_class(object))]
            value = '%s()' % cls_name
        else:
            try:
                if isinstance(object, (basestring, bytes, bool, int, long, float,
                                       complex)):
                    value = self.repr(object)
                elif is_dict_like(object):
                    value = '{}'
                elif isinstance(object, tuple):
                    value = '()'
                elif isinstance(object, collections.Sequence):
                    value = '[]'
                elif isinstance(object, frozenset):
                    value = 'frozenset()'
                elif isinstance(object, collections.Set):
                    value = 'set()'
                else:
                    value = 'None'
            except NameError:
                # doing 'isinstance(object, collections.Mapping)' can cause:
                # NameError: Unknown C global variable
                # in some situations... ie, maya.OpenMaya.cvar...
                # ...some sort of swig error?
                value = 'None'
        line = (name and name + ' = ' or '') + value + '\n'
        return line

    def import_mod_text(self, currmodule, importmodule, asname):
        # unfortunately, we need to use relative imports to avoid circular
        # import issues...
        ispkg = hasattr(currmodule, '__path__')
        currname = currmodule.__name__

        if importmodule in self.MODULE_EXCLUDES.get(currname, ()):
            print "%s had %s in MODULE_EXCLUDES" % (currname, importmodule)
            return ''

        if asname == '*':
            if importmodule in self.importSubstitutions:
                return self.importSubstitutions[importmodule]
            else:
                self.add_to_module_map(importmodule, '')
                return 'from ' + importmodule + ' import *'
        else:
            realname = importmodule

            realparts = realname.split('.')
            currparts = currname.split('.')
            importname = realname
            fromname = ''
            if currname == self.debugmodule:
                print '\t %-30s %-30s %s' % ( realname, importname, asname )

            #test for siblings - needed to avoid circular imports
            if len(realparts) == len(currparts):
                if realparts[:-1] == currparts[:-1] and not ispkg:
                    if currname == self.debugmodule:
                        print "\t\tsibling"
                    fromname = '.'
                    importname = realparts[-1]
            # test if importing a child - ie, pymel may have a .core attribute,
            # simply because at some point we imported pymel.core, but we don't
            # need / want an explicit import statement
            elif len(realparts) > len(currparts):
                if realparts[:len(currparts)] == currparts:
                    # Check that asname matches realname, so that if we do
                    #     import pymel.core.nt as nt
                    # from inside pymel.core, we still get the nt showing up
                    if asname == realparts[-1]:
                        # Ok, we have a child module, with the standard name,
                        # inside the parent module... it's still possible the
                        # parent module explicitly imported the child... so
                        # use the static code analysis of the module to see if
                        # this name is in the expected module names...
                        if not self.module_has_static_name(currmodule, asname):
                            if currname == self.debugmodule:
                                print "\t\tparent, and not in static module names - no import"
                            return ''

                    # if we're doing a renamed parent import, we want to make it
                    # relative to avoid circular imports
                    fromname = '.'
                    importname = '.'.join(realparts[len(currparts):])
            self.add_to_module_map(realname, asname if asname else importname)
            if importname in self.importSubstitutions:
                return '%s = None' % asname
            else:
                result = 'import ' + importname
                if importname != asname and asname:
                    result += ' as ' + asname
                if fromname:
                    result = 'from ' + fromname + ' ' + result
                return result

    def import_obj_text(self, importmodule, importname, asname):
        result = 'from %s import %s' % (importmodule, importname)
        if asname and asname != importname:
            result += (' as ' + asname)
        return result


stubs = StubDoc()

def packagestubs(packagename, outputdir='', extensions=('py', 'pypredef', 'pi'), exclude=None):
    import pymel.util as util

    def get_python_file(modname, extension, ispkg):
        basedir = os.path.join(outputdir, extension)
        if extension == 'pypredef':
            curfile = os.path.join(basedir, modname)
        else:
            curfile = os.path.join(basedir, *modname.split('.') )
            if ispkg:
                curfile = os.path.join(curfile, '__init__' )

        curfile = curfile + os.extsep + extension
        return curfile


    packagemod = __import__(packagename, globals(), locals(), ['dummy'], -1)
    # first, check to see if the given package is not a 'top level' module...and
    # if so, create any parent package dirs/__init__.py
    if '.' in packagename:
        for extension in extensions:
            if extension == 'pypredef':
                # pypredefs don't make directories / __init__.py
                continue
            parts = packagename.split('.')
            # if, ie, our packagename is 'my.long.sub.package', this will give us
            #   my
            #   my.long
            #   my.long.sub
            for i in xrange(1, len(parts)):
                parent_package = '.'.join(parts[:i])
                parent_file = get_python_file(parent_package, extension, True)
                parent_dir = os.path.dirname(parent_file)
                if not os.path.isdir(parent_dir):
                    os.makedirs(parent_dir)
                if not os.path.isfile(parent_file):
                    print "making empty %s" % parent_file
                    # this will "touch" the file - ie, create an empty one
                    with open(parent_file, 'a'):
                        pass

    for modname, mod, ispkg in util.subpackages(packagemod):
        print modname, ":"
        if not exclude or not re.match( exclude, modname ):
            contents = stubs.docmodule(mod)
        else:
            contents = ''
        for extension in extensions:
            basedir = os.path.join(outputdir, extension)
            if extension == 'pypredef':
                curfile = os.path.join(basedir, modname)
            else:
                curfile = os.path.join(basedir, *modname.split('.') )
                if ispkg:
                    curfile = os.path.join(curfile, '__init__' )

            curfile = curfile + os.extsep + extension

            curdir = os.path.dirname(curfile)
            if not os.path.isdir(curdir):
                os.makedirs(curdir)
            print "\t ...writing %s" % curfile
            with open( curfile, 'w' ) as f:
                f.write( contents )


def pymelstubs(extensions=('py', 'pypredef', 'pi'), modules=('pymel', 'maya'),
               pyRealUtil=False):
    """ Builds pymel stub files for autocompletion.

    Can build Python Interface files (pi) with extension='pi' for IDEs like wing."""

    pymeldir = os.path.dirname( os.path.dirname( sys.modules[__name__].__file__) )
    outputdir = os.path.join(pymeldir, 'extras', 'completion')
    print "Stub output dir:", outputdir
    if not os.path.exists(outputdir):
        os.makedirs(outputdir)

    for modulename in modules:
        print "making stubs for: %s" % modulename
        packagestubs(modulename, outputdir=outputdir, extensions=extensions,
                     # these two modules import PySide, and I don't want to
                     # bother with dealing with PySide + stubs right now...
                     # so we're just ignoring them...
                     exclude=re.compile(r'maya.app.general.(creaseSetEditor|mayaMixin)'))
    if pyRealUtil:
        # build a copy of 'py' stubs, that have a REAL copy of pymel.util...
        # useful to put on the path of non-maya python interpreters, in
        # situations where you want to be able to import the "dummy" maya/pymel
        # stubs, but still have acces to the handy non-maya-required pymel.util
        def copyDir(src, dest):
            #ignore if the source dir doesn't exist...
            if os.path.isdir(src):
                import shutil
                if os.path.isdir(dest):
                    shutil.rmtree(dest)
                elif os.path.isfile(dest):
                    raise RuntimeError("A file called %s existed (expected a dir or nothing)" % dest)
                shutil.copytree(src, dest)
            elif os.path.isfile(src):
                raise RuntimeError("A file called %s existed (expected a dir or nothing)" % src)

        pyDir = os.path.join(outputdir, 'py')
        pyRealUtilDir = os.path.join(outputdir, 'pyRealUtil')
        print "creating %s" % pyRealUtilDir
        copyDir(pyDir, pyRealUtilDir)

        srcUtilDir = os.path.join(pymeldir, 'pymel', 'util')
        destUtilDir = os.path.join(pyRealUtilDir, 'pymel', 'util')
        copyDir(srcUtilDir, destUtilDir)

    return outputdir

# don't start name with test - don't want it automatically run by nose
def stubstest(pystubdir, doprint=True):
    '''Test the stubs modules.

    Don't call this from 'inside maya', as we've probably already loaded all
    the various 'real' modules, which can give problems.
    '''
    def importError(modname):
        print 'error importing %s:' % modname
        import traceback
        bad.append( (modname, traceback.format_exc()) )

    bad = []
    print "Testing all modules in: %s" % pystubdir
    sys.path.insert(0, pystubdir)
    try:
        for importer, modname, ispkg in \
                pkgutil.walk_packages(path=[pystubdir],onerror=importError):
            print 'testing %s' % modname
            try:
                # Don't use the importer returned by walk_packages, as it
                # doesn't always properly update parent packages's dictionary
                # with submodule name - ie, you would do:
                # import pymel.all
                # print pymel.all
                # ...and find that pymel had no attribute 'all'
                #importer.find_module(modname).load_module(modname)
                __import__(modname, globals(), locals(), [])
            except Exception, error:
                print 'found bad module: %s - %s' % (modname, error)
                importError(modname)
    finally:
        sys.path.pop(0)
    print 'done walking modules'
    if doprint:
        for modname, error in bad:
            print '*' * 60
            print 'could not import %s:\n%s' % (modname, error)
    return bad

########NEW FILE########
__FILENAME__ = commands

import maya.cmds
import sys, os.path

# Locations of commandList file by OS type as returned by maya.cmds.about( os=True )
commandListLocations = {
    'nt' : 'bin',
    'win64' : 'bin',
    'mac' : 'MacOS',
    'linux' : 'lib',
    'linux64' : 'lib'
}

def __makeStubFunc( command, library ):
    def stubFunc( *args, **keywords ):
        """ Dynamic library stub function """
        maya.cmds.dynamicLoad( library )
        # call the real function which has replaced us
        return maya.cmds.__dict__[command]( *args, **keywords )
    return stubFunc

def processCommandList():
    """
    Process the "commandList" file that contains the mappings between command names and the
    libraries in which they are found.  This function will install stub functions in maya.cmds
    for all commands that are not yet loaded.  The stub functions will load the required library
    and then execute the command.
    """

    try:
        # Assume that maya.cmds.about and maya.cmds.internalVar are already registered
        #
        commandListPath = os.path.realpath( os.environ[ 'MAYA_LOCATION' ] )
        platform = maya.cmds.about( os=True )
        commandListPath = os.path.join( commandListPath, commandListLocations[platform], 'commandList' )

        file = open( commandListPath, 'r' )
        for line in file:
            commandName, library = line.split()
            if not commandName in maya.cmds.__dict__:
                maya.cmds.__dict__[commandName] = __makeStubFunc( commandName, library )
    except:
        sys.stderr.write("Unable to process commandList %s" % commandListPath)
        raise

# Copyright (C) 1997-2011 Autodesk, Inc., and/or its licensors.
# All rights reserved.
#
# The coded instructions, statements, computer programs, and/or related
# material (collectively the "Data") in these files contain unpublished
# information proprietary to Autodesk, Inc. ("Autodesk") and/or its licensors,
# which is protected by U.S. and Canadian federal copyright law and by
# international treaties.
#
# The Data is provided for use exclusively by You. You have the right to use,
# modify, and incorporate this Data into other products for purposes authorized
# by the Autodesk software license agreement, without fee.
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND. AUTODESK
# DOES NOT MAKE AND HEREBY DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTIES
# INCLUDING, BUT NOT LIMITED TO, THE WARRANTIES OF NON-INFRINGEMENT,
# MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, OR ARISING FROM A COURSE
# OF DEALING, USAGE, OR TRADE PRACTICE. IN NO EVENT WILL AUTODESK AND/OR ITS
# LICENSORS BE LIABLE FOR ANY LOST REVENUES, DATA, OR PROFITS, OR SPECIAL,
# DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES, EVEN IF AUTODESK AND/OR ITS
# LICENSORS HAS BEEN ADVISED OF THE POSSIBILITY OR PROBABILITY OF SUCH DAMAGES.


########NEW FILE########
__FILENAME__ = python

"""
!!!!!!!!
As of 2011, this file is no longer part of the 'official' maya distribution -
it is included here only to override it in older maya versions
!!!!!!!!


The maya.app.python module contains utilites which Maya uses to communicate
with Python.  These functions are not part of Maya's public API and may be
subject to change.

Simple test script to exercise these manually:

import maya.cmds as cmds
def e1():
    cmds.error("DUH")
def e2():
    e1()
def e3():
    cmds.ls(duh=1)
def e4():
    e3()
def e5():
    cmds.xform( q=True )
def e6():
    e5()

"""

import sys, traceback
import maya.utils

formatException = maya.utils._guiExceptHook


#
#def formatOtherException( exceptionType, exceptionObject, traceBack, detail ):
#    baseMsg = unicode(exceptionObject)
#    if detail > 0:
#        result = formatTraceback( detail==2, baseMsg, traceBack )
#    else:
#        result = baseMsg
#    return u'%s: %s' % ( exceptionType.__name__, result)
#
#def formatRuntimeException( exceptionType, exceptionObject ):
#    """
#    Return the exception information for RuntimeError exceptions only,
#    formatted as a string suitable for user consumption. Traceback
#    information for this exception, if requested, is appended through
#    the formatTraceback() function.
#    """
#    # Format the exception into a string
#    stringBuffer = StringIO.StringIO()
#    traceback.print_exception( exceptionType, exceptionObject, None,
#                               32, stringBuffer )
#    result = stringBuffer.getvalue().decode('utf8')
#    stringBuffer.close()
#    print `result`
#    return u'%s' % result.rstrip()



# Copyright (C) 1997-2006 Autodesk, Inc., and/or its licensors.
# All rights reserved.
#
# The coded instructions, statements, computer programs, and/or related
# material (collectively the "Data") in these files contain unpublished
# information proprietary to Autodesk, Inc. ("Autodesk") and/or its licensors,
# which is protected by U.S. and Canadian federal copyright law and by
# international treaties.
#
# The Data is provided for use exclusively by You. You have the right to use,
# modify, and incorporate this Data into other products for purposes authorized
# by the Autodesk software license agreement, without fee.
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND. AUTODESK
# DOES NOT MAKE AND HEREBY DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTIES
# INCLUDING, BUT NOT LIMITED TO, THE WARRANTIES OF NON-INFRINGEMENT,
# MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, OR ARISING FROM A COURSE
# OF DEALING, USAGE, OR TRADE PRACTICE. IN NO EVENT WILL AUTODESK AND/OR ITS
# LICENSORS BE LIABLE FOR ANY LOST REVENUES, DATA, OR PROFITS, OR SPECIAL,
# DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES, EVEN IF AUTODESK AND/OR ITS
# LICENSORS HAS BEEN ADVISED OF THE POSSIBILITY OR PROBABILITY OF SUCH DAMAGES.


########NEW FILE########
__FILENAME__ = basic
"""
This module is always imported during Maya's startup.  It is imported from
both the maya.app.startup.batch and maya.app.startup.gui scripts
"""
import atexit
import os.path
import sys
import traceback
import maya
import maya.app
import maya.app.commands
from maya import cmds, utils

def setupScriptPaths():
    """
    Add Maya-specific directories to sys.path
    """
    # Extra libraries
    #
    try:
        # Tkinter libraries are included in the zip, add that subfolder
        p = [p for p in sys.path if p.endswith('.zip')][0]
        sys.path.append( os.path.join(p,'lib-tk') )
    except:
        pass

    # Per-version prefs scripts dir (eg .../maya8.5/prefs/scripts)
    #
    prefsDir = cmds.internalVar( userPrefDir=True )
    sys.path.append( os.path.join( prefsDir, 'scripts' ) )

    # Per-version scripts dir (eg .../maya8.5/scripts)
    #
    scriptDir = cmds.internalVar( userScriptDir=True )
    sys.path.append( os.path.dirname(scriptDir) )

    # User application dir (eg .../maya/scripts)
    #
    appDir = cmds.internalVar( userAppDir=True )
    sys.path.append( os.path.join( appDir, 'scripts' ) )

def executeSetup(filename):
    """
    Look for the given file name in the search path and execute it in the "__main__"
    namespace
    """
    try:
        for path in sys.path[:]:
            scriptPath = os.path.join( path, filename )
            if os.path.isfile( scriptPath ):
                import __main__
                execfile( scriptPath, __main__.__dict__ )
    except Exception, err:
        # err contains the stack of everything leading to execfile,
        # while sys.exc_info returns the stack of everything after execfile
        try:
            # extract the stack trace for the current exception
            etype, value, tb = sys.exc_info()
            tbStack = traceback.extract_tb(tb)
        finally:
            del tb # see warning in sys.exc_type docs for why this is deleted here
        sys.stderr.write("Failed to execute %s\n" % filename)
        sys.stderr.write("Traceback (most recent call last):\n")
        # format the traceback, excluding our current level
        result = traceback.format_list( tbStack[1:] ) + traceback.format_exception_only(etype, value)
        sys.stderr.write(''.join(result))

def executeUserSetup():
    executeSetup('userSetup.py')

def executeSiteSetup():
    executeSetup('siteSetup.py')

# Set up sys.path to include Maya-specific user script directories.
setupScriptPaths()

# Set up string table instance for application
maya.stringTable = utils.StringTable()

# Set up auto-load stubs for Maya commands implemented in libraries which are not yet loaded
maya.app.commands.processCommandList()

# Set up the maya logger before userSetup.py runs, so that any custom scripts that
# use the logger will have it available
utils.shellLogHandler()

if not os.environ.has_key('MAYA_SKIP_USERSETUP_PY'):
    # Run the user's userSetup.py if it exists
    executeSiteSetup()
    executeUserSetup()

# Register code to be run on exit
atexit.register( maya.app.finalize )
# Copyright (C) 1997-2011 Autodesk, Inc., and/or its licensors.
# All rights reserved.
#
# The coded instructions, statements, computer programs, and/or related
# material (collectively the "Data") in these files contain unpublished
# information proprietary to Autodesk, Inc. ("Autodesk") and/or its licensors,
# which is protected by U.S. and Canadian federal copyright law and by
# international treaties.
#
# The Data is provided for use exclusively by You. You have the right to use,
# modify, and incorporate this Data into other products for purposes authorized
# by the Autodesk software license agreement, without fee.
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND. AUTODESK
# DOES NOT MAKE AND HEREBY DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTIES
# INCLUDING, BUT NOT LIMITED TO, THE WARRANTIES OF NON-INFRINGEMENT,
# MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, OR ARISING FROM A COURSE
# OF DEALING, USAGE, OR TRADE PRACTICE. IN NO EVENT WILL AUTODESK AND/OR ITS
# LICENSORS BE LIABLE FOR ANY LOST REVENUES, DATA, OR PROFITS, OR SPECIAL,
# DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES, EVEN IF AUTODESK AND/OR ITS
# LICENSORS HAS BEEN ADVISED OF THE POSSIBILITY OR PROBABILITY OF SUCH DAMAGES.


########NEW FILE########
__FILENAME__ = batch

"""
This module is imported during the startup of Maya in batch mode.
"""
import maya.app.startup.basic

pass
# Copyright (C) 1997-2011 Autodesk, Inc., and/or its licensors.
# All rights reserved.
#
# The coded instructions, statements, computer programs, and/or related
# material (collectively the "Data") in these files contain unpublished
# information proprietary to Autodesk, Inc. ("Autodesk") and/or its licensors,
# which is protected by U.S. and Canadian federal copyright law and by
# international treaties.
#
# The Data is provided for use exclusively by You. You have the right to use,
# modify, and incorporate this Data into other products for purposes authorized
# by the Autodesk software license agreement, without fee.
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND. AUTODESK
# DOES NOT MAKE AND HEREBY DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTIES
# INCLUDING, BUT NOT LIMITED TO, THE WARRANTIES OF NON-INFRINGEMENT,
# MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, OR ARISING FROM A COURSE
# OF DEALING, USAGE, OR TRADE PRACTICE. IN NO EVENT WILL AUTODESK AND/OR ITS
# LICENSORS BE LIABLE FOR ANY LOST REVENUES, DATA, OR PROFITS, OR SPECIAL,
# DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES, EVEN IF AUTODESK AND/OR ITS
# LICENSORS HAS BEEN ADVISED OF THE POSSIBILITY OR PROBABILITY OF SUCH DAMAGES.


########NEW FILE########
__FILENAME__ = gui

# module: maya.app.gui
#
# This module is imported during the startup of Maya in GUI mode.
#
import sys
import maya.app.startup.basic
import maya.app.baseUI
import maya.utils

# Replace sys.stdin with a GUI version that will request input from the user
sys.stdin = maya.app.baseUI.StandardInput()

# Replace sys.stdout and sys.stderr with versions that can output to Maya's
# GUI
sys.stdout = maya.utils.Output()
sys.stderr = maya.utils.Output( error=1 )

maya.utils.guiLogHandler()
# Copyright (C) 1997-2011 Autodesk, Inc., and/or its licensors.
# All rights reserved.
#
# The coded instructions, statements, computer programs, and/or related
# material (collectively the "Data") in these files contain unpublished
# information proprietary to Autodesk, Inc. ("Autodesk") and/or its licensors,
# which is protected by U.S. and Canadian federal copyright law and by
# international treaties.
#
# The Data is provided for use exclusively by You. You have the right to use,
# modify, and incorporate this Data into other products for purposes authorized
# by the Autodesk software license agreement, without fee.
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND. AUTODESK
# DOES NOT MAKE AND HEREBY DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTIES
# INCLUDING, BUT NOT LIMITED TO, THE WARRANTIES OF NON-INFRINGEMENT,
# MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, OR ARISING FROM A COURSE
# OF DEALING, USAGE, OR TRADE PRACTICE. IN NO EVENT WILL AUTODESK AND/OR ITS
# LICENSORS BE LIABLE FOR ANY LOST REVENUES, DATA, OR PROFITS, OR SPECIAL,
# DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES, EVEN IF AUTODESK AND/OR ITS
# LICENSORS HAS BEEN ADVISED OF THE POSSIBILITY OR PROBABILITY OF SUCH DAMAGES.


########NEW FILE########
__FILENAME__ = utils
"""
General utility functions that are not specific to Maya Commands or the
OpenMaya API.

Note:
By default, handlers are installed for the root logger.  This can be overriden
with env var MAYA_DEFAULT_LOGGER_NAME.
Env vars MAYA_GUI_LOGGER_FORMAT and MAYA_SHELL_LOGGER_FORMAT can be used to
override the default formatting of logging messages sent to the GUI and
shell respectively.

"""

# Note that several of the functions in this module are implemented in C++
# code, such as executeDeferred and executeInMainThreadWithResult

import logging
import os
import re
import sys
import traceback
import pydoc
import inspect
from maya import cmds

_shellLogHandler = None
_guiLogHandler = None

appLoggerName = os.environ.get('MAYA_DEFAULT_LOGGER_NAME', '')

def loadStringResourcesForModule( moduleName ):
    """
    Load the string resources associated with the given module

    Note that the argument must be a string containing the full name of the
    module (eg "maya.app.utils").  The module of that name must have been
    previously imported.

    The base resource file is assumed to be in the same location as the file
    defining the module and will have the same name as the module except with
    _res.py appended to it.  So, for the module foo, the resource file should
    be foo_res.py.

    If Maya is running in localized mode, then the standard location for
    localized scripts will also be searched (the location given by the
    command cmds.about( localizedResourceLocation=True ))

    Failure to find the base resources for the given module will trigger an
    exception. Failure to find localized resources is not an error.
    """
    try:
        module = sys.modules[moduleName]
    except:
        raise RuntimeError( 'Failed to load base string resources for module %s because it has not been imported' % moduleName )

    modulePath, moduleFileName = os.path.split( module.__file__ )
    moduleName, extension = os.path.splitext( moduleFileName )

    resourceFileName = moduleName + '_res.py'

    # Try to find the base version of the file next to the module
    try:
        baseVersionPath = os.path.join( modulePath, resourceFileName )
        execfile( baseVersionPath, {} )
    except:
        raise RuntimeError( 'Failed to load base string resources for module %s' % moduleName )

    if cmds.about( uiLanguageIsLocalized=True ):
        scriptPath = cmds.about( localizedResourceLocation=True )
        if scriptPath != '':
            localizedPath = os.path.join( scriptPath, 'scripts', resourceFileName )
            try:
                execfile( localizedPath, {} )
            # We don't generate any warnings or errors if localized
            # file is not there
            # TODO: we could consider issuing a warning in debug mode
            except IOError:
                pass
            except Exception, err:
                raise RuntimeError( 'Unexpected error encountered when attempting to load localized string resources for module %s: %s' % (moduleName,err) )

def getPossibleCompletions(input):
    """
    Utility method to handle command completion
    Returns in a list all of the possible completions that apply
    to the input string
    """

    import sys
    import rlcompleter
    completer = rlcompleter.Completer()

    listOfMatches=[]
    try:
        for index in xrange(sys.maxint):
            term = completer.complete(input, index)
            if term is None:
                break
            # avoid duplicate entries
            if len(listOfMatches) and listOfMatches[-1] == term:
                continue
            listOfMatches.append(term)
    except:
        pass

    return listOfMatches

def helpNonVerbose(thing, title='Python Library Documentation: %s', forceload=0):
    """
    Utility method to return python help in the form of a string

    thing - str or unicode name to get help on
    title - format string for help result
    forceload - argument to pydoc.resolve, force object's module to be reloaded from file

    returns formated help string
    """
    result = ""
    try:
        thingStr = thing.encode(cmds.about(codeset=True))
    except:
        thingStr = str(thing)

    try:
        # Possible two-stage object resolution!
        # Sometimes we get docs for strings, other times for objects
        #
        try:
            object, name = pydoc.resolve(thingStr, forceload)
        except:
            # Get an object from a string
            thingObj=eval(thingStr,sys.modules['__main__'].__dict__)
            object, name = pydoc.resolve(thingObj, forceload)
        desc = pydoc.describe(object)
        module = inspect.getmodule(object)
        if name and '.' in name:
            desc += ' in ' + name[:name.rfind('.')]
        elif module and module is not object:
            desc += ' in module ' + module.__name__
        doc = None
        text = pydoc.TextDoc()
        if not (inspect.ismodule(object) or
                inspect.isclass(object) or
                inspect.isroutine(object) or
                inspect.isgetsetdescriptor(object) or
                inspect.ismemberdescriptor(object) or
                isinstance(object, property)):
            # If the passed object is a piece of data or an instance,
            # document its available methods instead of its value.
            object = type(object)
            desc += ' object'
        # if the object is a maya command without a proper docstring,
        # then tack on the help for it
        elif module is cmds and inspect.isroutine(object):
            try:
                if len(object.__doc__) == 0:
                    doc = cmds.help(object.__name__)
            except:
                pass
        if not doc:
            doc = text.document(object, name)
        result = pydoc.plain(title % desc + '\n\n' + doc)

        # Remove multiple empty lines
        result = "\n".join([ line for line in result.splitlines() if line.strip()])
    except:
        pass
    return result

# ##############################################################################
# Logging
#

class MayaGuiLogHandler(logging.Handler):
    """
    A python logging handler that displays error and warning
    records with the appropriate color labels within the Maya GUI
    """
    def emit(self, record):
        from maya import OpenMaya
        msg = self.format(record)
        if record.levelno > logging.WARNING:
            # Error (40) Critical (50)
            OpenMaya.MGlobal.displayError(msg)
        elif record.levelno > logging.INFO:
            # Warning (30)
            OpenMaya.MGlobal.displayWarning(msg)
        else:
            # Debug (10) and Info (20)
            OpenMaya.MGlobal.displayInfo(msg)

def guiLogHandler():
    """
    Adds an additional handler to the root logger to print to
    the script editor.  Sets the shell/outputWindow handler to
    only print 'Critical' records, so that the logger's primary
    output is the script editor.
    Returns the handler.
    """
    global _guiLogHandler
    if _guiLogHandler is not None:
        return _guiLogHandler
    if _shellLogHandler is None:
        shellLogHandler()
    _shellLogHandler.setLevel(logging.CRITICAL)
    _guiLogHandler = MayaGuiLogHandler()
    format = os.environ.get('MAYA_GUI_LOGGER_FORMAT', '%(name)s : %(message)s')
    _guiLogHandler.setFormatter( logging.Formatter(format) )
    log = logging.getLogger(appLoggerName)
    log.addHandler(_guiLogHandler)
    return _guiLogHandler

def shellLogHandler():
    """
    Adds an additional handler to the root logger to print to sys.__stdout__
    Returns the handler.
    """
    global _shellLogHandler
    if _shellLogHandler is not None:
        return _shellLogHandler
    shellStream = os.environ.get('MAYA_SHELL_LOGGER_STREAM', '__stdout__')
    shellStream = getattr(sys, shellStream, sys.__stdout__)
    _shellLogHandler = logging.StreamHandler(shellStream)
    format = os.environ.get('MAYA_SHELL_LOGGER_FORMAT', '%(name)s : %(levelname)s : %(message)s')
    _shellLogHandler.setFormatter( logging.Formatter(format) )
    log = logging.getLogger(appLoggerName)
    log.addHandler(_shellLogHandler)
    log.setLevel(logging.INFO)
    return _shellLogHandler

# ##############################################################################
# Gui Exception Handling
#

def _guiExceptHook( exceptionType, exceptionObject, traceBack, detail=2 ):
    """
    Whenever Maya receives an error from the command engine it comes into here
    to format the message for display.
    Formatting is performed by formatGuiException.
        exceptionType   : Type of exception
        exceptionObject : Detailed exception information
        traceBack       : Exception traceback stack information
        detail          : 0 = no trace info, 1 = line/file only, 2 = full trace
    """
    try:
        return formatGuiException(exceptionType, exceptionObject, traceBack, detail)
    except:
        # get the stack and remove our current level
        etype, value, tb = sys.exc_info()
        tbStack = traceback.extract_tb(tb)
        del tb # see warning in sys.exc_type docs for why this is deleted here

        tbLines = []
        tbLines.append("Error in  maya.utils._guiExceptHook:\n")
        tbLines += traceback.format_list( tbStack[1:] ) + traceback.format_exception_only(etype, value)

        tbLines.append("\nOriginal exception was:\n")
        tbLines += traceback.format_exception(exceptionType, exceptionObject, traceBack)
        tbLines = _prefixTraceStack(tbLines)
        return ''.join(tbLines)

def formatGuiException(exceptionType, exceptionObject, traceBack, detail=2):
    """
    Format a trace stack into a string.

        exceptionType   : Type of exception
        exceptionObject : Detailed exception information
        traceBack       : Exception traceback stack information
        detail          : 0 = no trace info, 1 = line/file only, 2 = full trace

    To perform an action when an exception occurs without modifying Maya's
    default printing of exceptions, do the following::

        import maya.utils
        def myExceptCB(etype, value, tb):
            # do something here...
            return maya.utils._formatGuiException(etype, value, tb, detail)
        maya.utils.formatGuiException = myExceptCB

    """
    # originally, this code used
    #    exceptionMsg = unicode(exceptionObject.args[0])
    # Unfortunately, the problem with this is that the first arg is NOT always
    # the string message - ie, witness
    #    IOError(2, 'No such file or directory', 'non_existant.file')
    # The next guess would be to simply use
    #    exceptionMsg = unicode(exceptionObject).strip()
    # However, there are unfortunately unicode problems with exceptions:
    #    >>> str(IOError(2, 'foo', 'bar'))
    #    "[Errno 2] foo: 'bar'"
    #    >>> unicode(IOError(2, 'foo', 'bar'))
    #    u"(2, 'foo')"
    # Note that the unicode version gives the 'wrong' result; unfortunately, we
    # can't simply rely on str, as maya is a multilingual product that may have
    # unicode error strings.
    # The method below seems the most reliable way of getting the 'best' result

    exceptionMsg = unicode(exceptionObject).strip()
    # format the exception
    excLines = _decodeStack(traceback.format_exception_only(exceptionType, exceptionObject))
    # traceback may have failed to decode a unicode exception value
    # if so, we will swap the unicode back in
    if len(excLines) > 0:
        excLines[-1] = re.sub(r'<unprintable.*object>', exceptionMsg, excLines[-1])

    # use index of -1 because message may not have a ':'
    exceptionMsg = excLines[-1].split(':',1)[-1].strip()
    if detail == 0:
        result = exceptionType.__name__ + ': ' + exceptionMsg
    else:
        # extract a process stack from the tracekback object
        tbStack = traceback.extract_tb(traceBack)
        tbStack = _fixConsoleLineNumbers(tbStack)
        if detail == 1:
            # format like MEL error with line number
            if tbStack:
                file, line, func, text = tbStack[-1]
                result = u'%s: file %s line %s: %s' % (exceptionType.__name__, file, line, exceptionMsg)
            else:
                result = exceptionMsg
        else: # detail == 2
            # format the traceback stack
            tbLines = _decodeStack( traceback.format_list(tbStack) )
            if len(tbStack) > 0:
                tbLines.insert(0, u'Traceback (most recent call last):\n')

            # prefix the message to the stack trace so that it will be visible in
            # the command line
            result = ''.join( _prefixTraceStack([exceptionMsg+'\n'] + tbLines + excLines) )
    return result

# store a local unmodified copy
_formatGuiException = formatGuiException

# ###############################################################################
# Formatting helpers

def _prefixTraceStack(tbStack, prefix = '# '):
    """
    prefix with '#', being sure to get internal newlines. do not prefix first line
    as that will be added automatically.
    """
    result = ''.join(tbStack).rstrip().split('\n')
    size = len(result)-1
    for i, line in enumerate(result):
        if i < size:
            line += '\n'
        if i != 0:
            line = prefix + line
        result[i] = line
    return result

def _fixConsoleLineNumbers( tbStack ):
    result = []
    for file, line, func, text in tbStack:
        if file == '<maya console>':
            # In the Maya console the numbering is off by one so adjust
            line -= 1
        result.append( (file, line, func, text) )
    return result

def _decodeStack( tbStack ):
    encoding = cmds.about(codeset=True)
    return [ s.decode(encoding) for s in tbStack ]

# ###############################################################################
# Gui Results Formatting
#
def _guiResultHook(obj):
    """
    In GUI mode, called by the command engine to stringify a result for display.
    """
    return formatGuiResult(obj)

def formatGuiResult(obj):
    """
    Gets a string representation of a result object.

    To perform an action when a result is about to returned to the script editor
    without modifying Maya's default printing of results, do the following:

        import maya.utils
        def myResultCallback(obj):
            # do something here...
            return maya.utils._formatGuiResult(obj)
        maya.utils.formatGuiResult = myResultCallback
    """
    if isinstance(obj, str) or isinstance(obj, unicode):
        return obj
    else:
        return repr(obj)

# store a local unmodified copy
_formatGuiResult = formatGuiResult

# Copyright (C) 1997-2011 Autodesk, Inc., and/or its licensors.
# All rights reserved.
#
# The coded instructions, statements, computer programs, and/or related
# material (collectively the "Data") in these files contain unpublished
# information proprietary to Autodesk, Inc. ("Autodesk") and/or its licensors,
# which is protected by U.S. and Canadian federal copyright law and by
# international treaties.
#
# The Data is provided for use exclusively by You. You have the right to use,
# modify, and incorporate this Data into other products for purposes authorized
# by the Autodesk software license agreement, without fee.
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND. AUTODESK
# DOES NOT MAKE AND HEREBY DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTIES
# INCLUDING, BUT NOT LIMITED TO, THE WARRANTIES OF NON-INFRINGEMENT,
# MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, OR ARISING FROM A COURSE
# OF DEALING, USAGE, OR TRADE PRACTICE. IN NO EVENT WILL AUTODESK AND/OR ITS
# LICENSORS BE LIABLE FOR ANY LOST REVENUES, DATA, OR PROFITS, OR SPECIAL,
# DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES, EVEN IF AUTODESK AND/OR ITS
# LICENSORS HAS BEEN ADVISED OF THE POSSIBILITY OR PROBABILITY OF SUCH DAMAGES.


########NEW FILE########
__FILENAME__ = all
import sys
import pymel as _pymel
_pymel.all = sys.modules[__name__]

import internal
import internal.startup
doFinalize = internal.startup.finalizeEnabled
internal.startup.finalizeEnabled = False
import internal.plogging as plogging
import internal.factories as factories
import mayautils

#logger = plogging.getplogging.pymelLogger(__name__)
plogging.pymelLogger.debug( 'imported internal' )

import api
plogging.pymelLogger.debug( 'imported api' )

from core import *
plogging.pymelLogger.debug( 'imported core' )

# for wrapped math functions
from util.arrays import *

import core.datatypes as datatypes

import versions

from core import nodetypes
from core.nodetypes import *
from core.uitypes import *

# These two were imported into 'old' pymel top level module,
# so make sure they're imported here as well
import core
import tools

## some submodules do 'import pymel.core.pmcmds as cmds' -
## this ensures that when the user does 'from pymel import *',
## cmds is always maya.cmds
import maya.cmds as cmds

# Run delayed finalize now, so that if userSetup imports all,
# it has access to everything it should
internal.startup.finalizeEnabled = doFinalize
internal.startup.finalize()
########NEW FILE########
__FILENAME__ = allapi
import weakref

import pymel.util as util

# import all available Maya API methods in this module (api)
from maya.OpenMaya import *
from maya.OpenMayaAnim import *
try: from maya.OpenMayaCloth import *
except: pass
try : from maya.OpenMayaFX import *
except: pass
try : from maya.OpenMayaMPx import *
except: pass
if not MGlobal.mayaState() == MGlobal.kBatch:
    try : from maya.OpenMayaUI import *
    except: pass
try : from maya.OpenMayaRender import *
except: pass

# So, it seems that MScriptUtil().as*Ptr has a serious
# problem... basically, it looks like the returned
# ptrs don't have a reference to the MScriptUtil()
# that provides the actual storage for them -
# thus, it's possible for the MScriptUtil to get
# garbage collected, but still have the pointer
# to it in use - so it points to garbage (and
# generally causes a crash).
# To get around this, we create a wrapper for
# ptrs which also contains a reference to the
# MScriptUtil which contains the storage. Pass
# it around in place of the pointer - then, when
# the 'actual' pointer is needed (ie, immediately
# before feeding it into an api function), 'call'
# the SafeApiValue/Ptr object to return the 'true'
# pointer.
# Also, even SafeApiPtr is not completely safe -
# for instance, you cannot create 'throwaway' instances,
# like:
#   theApiFunc(SafeApiPtr('double')())
# ...as there is a chance that the MScriptUtil will be
# garbage collected before the api function tries to
# write into it's pointer...

# Note - I would have liked to have implemented this
# by simply attaching the MScriptUtil to the ptr -
# but you can't add attributes to the pointer object.
# My next idea was to use weakrefs to create a dictionary
# which maps ptrs to MScriptUtils - and clean it
# periodically as the ptrs are garbage collected. Alas,
# the pointer objects are also not compatible with
# weakref.  So, we have to use a 'non-transparent' wrapper...
# ie, we have to 'call' the object before feeding to
# the api function...

class SafeApiPtr(object):
    """
    A wrapper for api pointers which also contains a reference
    to the MScriptUtil which contains the storage. This helps
    ensure that the 'storage' for the pointer doesn't get
    wiped out before the pointer does. Pass the SafeApiPtr
    around in place of the 'true' pointer - then, when
    the 'true' pointer is needed (ie, immediately
    before feeding it into an api function), 'call'
    the SafeApiPtr object to return the 'true'
    pointer.

    Examples
    --------
    >>> from pymel.api.allapi import *
    >>> sel = MSelectionList()
    >>> sel.add('perspShape')
    >>> dag = MDagPath()
    >>> sel.getDagPath(0, dag)
    >>> cam = MFnCamera(dag)

    >>> aperMin = SafeApiPtr('double')
    >>> aperMax = SafeApiPtr('double')
    >>> cam.getFilmApertureLimits(aperMin(), aperMax())
    >>> print '%.5f, %.5f' % (aperMin.get(), aperMax.get())
    0.01378, 20.28991
    """

    def __init__(self, valueType, scriptUtil=None, size=1, asTypeNPtr=False):
        """
        :Parameters:
        valueType : `string`
            The name of the maya pointer type you would like
            returned - ie, 'int', 'short', 'float'.
        scriptUtil : `MScriptUtil`
            If you wish to use an existing MScriptUtil as
            the 'storage' for the value returned, specify it
            here - otherwise, a new MScriptUtil object is
            created.
        size : `int`
            If we want a pointer to an array, size indicates
            the number of items the array holds.  If we are
            creating an MScriptUtil, it will be initialized
            to hold this many items - if we are fed an
            MScriptUtil, then it is your responsibility to
            make sure it can hold the necessary number of items,
            or else maya will crash!
        asTypeNPtr : `bool`
            If we want a call to this SafeApiPtr to return a pointer
            for an argument such as:
               int2 &myArg;
            then we need to set asTypeNPtr to True:
               SafeApiPtr('int', size=2, asTypeNPtr=True)
            Otherwise, it is assumed that calling the object returns array
            ptrs:
               int myArg[2];
        """
        if not scriptUtil:
            self.scriptUtil = MScriptUtil()
            if size < 1:
                raise ValueError('size must be >= 1')
            else:
                # Value stored here doesn't matter - just make sure
                # it's large enough!
                self.scriptUtil.createFromList([0.0] * size, size)
        else:
            self.scriptUtil = scriptUtil
        self.size = size
        capValue = util.capitalize(valueType)
        self._normPtr = getattr(self.scriptUtil, 'as' + capValue + 'Ptr')()
        # Unforunately, arguments such as:
        #    float2 &foo;
        # need to be handled differently - calling it, we need
        # to return asFloat2Ptr()... but when indexing, use the same old
        # asFloatPtr() result to feed into getFloatArrayValue.
        # Also, note that asFloatPtr() must be called BEFORE asFloat2Ptr() -
        # if it is called after, the float2 ptr seems to get reset!
        if asTypeNPtr:
            self._nPtr = getattr(self.scriptUtil, 'as' + capValue +
                                 str(size) + 'Ptr')()
            self._ptr = self._nPtr
        else:
            self._ptr = self._normPtr
        self._getter = getattr(MScriptUtil, 'get' + capValue, None)
        self._setter = getattr(MScriptUtil, 'set' + capValue, None)
        self._indexGetter = getattr(MScriptUtil,
                                    'get' + capValue + 'ArrayItem', None)
        self._indexSetter = getattr(MScriptUtil,
                                    'set' + capValue + 'Array', None)

    def __call__(self):
        return self._ptr

    def get(self):
        """
        Dereference the pointer - ie, get the actual value we're pointing to.
        """
        return self._getter(self._normPtr)

    def set(self, value):
        """
        Store the actual value we're pointing to.
        """
        return self._setter(self._normPtr, value)

    def __getitem__(self, index):
        if index < 0 or index > (self.size - 1):
            raise IndexError(index)
        return self._indexGetter(self._normPtr, index)

    def __setitem__(self, index, value):
        if index < 0 or index > (self.size - 1):
            raise IndexError(index)
        return self._indexSetter(self._normPtr, index, value)

    def __len__(self):
        return self.size


# fast convenience tests on API objects
def isValidMObjectHandle(obj):
    if isinstance(obj, MObjectHandle) :
        return obj.isValid() and obj.isAlive()
    else :
        return False

def isValidMObject(obj):
    if isinstance(obj, MObject) :
        return not obj.isNull()
    else :
        return False

def isValidMPlug(obj):
    if isinstance(obj, MPlug) :
        return not obj.isNull()
    else :
        return False

def isValidMDagPath(obj):
    if isinstance(obj, MDagPath) :
        # when the underlying MObject is no longer valid, dag.isValid() will still return true,
        # but obj.fullPathName() will be an empty string
        return obj.isValid() and obj.fullPathName()
    else :
        return False

def isValidMNode(obj):
    if isValidMObject(obj) :
        return obj.hasFn(MFn.kDependencyNode)
    else :
        return False

def isValidMDagNode(obj):
    if isValidMObject(obj) :
        return obj.hasFn(MFn.kDagNode)
    else :
        return False

def isValidMNodeOrPlug(obj):
    return isValidMPlug(obj) or isValidMNode (obj)

# returns a MObject for an existing node
def toMObject(nodeName):
    """ Get the API MObject given the name of an existing node """
    sel = MSelectionList()
    obj = MObject()
    result = None
    try :
        sel.add( nodeName )
        sel.getDependNode( 0, obj )
        if isValidMObject(obj) :
            result = obj
    except :
        pass
    return result

def toApiObject(nodeName, dagPlugs=True):
    """ Get the API MPlug, MObject or (MObject, MComponent) tuple given the name
    of an existing node, attribute, components selection

    Parameters
    ----------
    dagPlugs : bool
        if True, plug result will be a tuple of type (MDagPath, MPlug)

    If we were unable to retrieve the node/attribute/etc, returns None
    """
    # special case check for empty string for speed...
    if not nodeName:
        return None

    sel = MSelectionList()
    try:
        sel.add( nodeName )
    except Exception:
        if "." in nodeName :
            # Compound Attributes
            #  sometimes the index might be left off somewhere in a compound attribute
            # (ex 'Nexus.auxiliary.input' instead of 'Nexus.auxiliary[0].input' )
            #  but we can still get a representative plug. this will return the equivalent of 'Nexus.auxiliary[-1].input'
            try:
                buf = nodeName.split('.')
                obj = toApiObject( buf[0] )
                if isinstance(obj,MDagPath):
                    mfn = MFnDagNode(obj)
                else:
                    mfn = MFnDependencyNode(obj)
                plug = mfn.findPlug( buf[-1], False )

                if dagPlugs: # and isValidMDagPath(obj) :
                    return (obj, plug)
                return plug
            except (RuntimeError,ValueError):
                pass
        return None
    else:
        if sel.length() != 1:
            return None
        if "." in nodeName :
            try:
                # Plugs
                plug = MPlug()
                sel.getPlug( 0, plug )
                if dagPlugs:
                    try:
                        # Plugs with DagPaths
                        sel.add( nodeName.split('.')[0] )
                        dag = MDagPath()
                        sel.getDagPath( 1, dag )

                        # TODO: if nucleus/symmetryConstraint bug ever fixed:
                        #   - remove entry in apiCache.ApiCache.API_TO_MFN_OVERRIDES
                        #   - remove hard-code setting of Nucleus's parent to DependNode
                        #   - remove 2 checks in allapi.toApiObject for objects which
                        #     can have an MDagPath but can't use MFnDagNode

                        if not dag.node().hasFn(MFn.kDagNode):
                            obj = MObject()
                            sel.getDependNode( 1, obj )
                            return (obj, plug)

                        #if isValidMDagPath(dag) :
                        return (dag, plug)
                    except RuntimeError: pass
                return plug

            except RuntimeError:
                # Components
                dag = MDagPath()
                comp = MObject()
                try:
                    sel.getDagPath( 0, dag, comp )
                except RuntimeError:
                    pass
                #if not isValidMDagPath(dag) :   return
                if not comp.isNull():
                    return (dag, comp)
                # We may have gotten a published container attribute, which
                # auto- magically converts to the contained node it references
                # when added to an MSelectionList
                splitName = nodeName.split('.')
                # Thankfully, it seems you can't index / get children off an
                # aliased attribute - ie, myNode.myAlias[0] and
                # myNode.myAlias.childAttr don't work, even if myAlias point
                # to a multi / compound attr
                if len(splitName) == 2:
                    obj = MObject()
                    try:
                        sel.add( splitName[0] )
                        sel.getDependNode(1, obj)
                    except RuntimeError:
                        pass
                    else:
                        # Since it seems there's no api way to get at the plug for
                        # a published / aliased container attr, we just check for
                        # aliases...
                        mfn = MFnDependencyNode(obj)
                        aliases = []
                        if mfn.getAliasList(aliases):
                            for aliasName, trueName in util.pairIter(aliases):
                                if aliasName == splitName[1]:
                                    return toApiObject('.'.join( (splitName[0], trueName) ))
        else:
            try:
                # DagPaths
                dag = MDagPath()
                sel.getDagPath( 0, dag )
                #if not isValidMDagPath(dag) : return

                # TODO: if nucleus/symmetryConstraint bug ever fixed:
                #   - remove entry in apiCache.ApiCache.API_TO_MFN_OVERRIDES
                #   - remove hard-code setting of Nucleus's parent to DependNode
                #   - remove 2 checks in allapi.toApiObject for objects which
                #     can have an MDagPath but can't use MFnDagNode

                if not dag.node().hasFn(MFn.kDagNode):
                    raise RuntimeError
                return dag

            except RuntimeError:
                # Objects
                obj = MObject()
                sel.getDependNode( 0, obj )
                #if not isValidMObject(obj) : return
                return obj

def toMDagPath(nodeName):
    """ Get an API MDagPAth to the node, given the name of an existing dag node """
    obj = toMObject (nodeName)
    if obj :
        dagFn = MFnDagNode (obj)
        dagPath = MDagPath()
        dagFn.getPath ( dagPath )
        return dagPath

# returns a MPlug for an existing plug
def toMPlug(plugName):
    """ Get the API MObject given the name of an existing plug (node.attribute) """
    nodeAndAttr = plugName.split('.', 1)
    obj = toMObject (nodeAndAttr[0])
    plug = None
    if obj :
        depNodeFn = MFnDependencyNode(obj)
        attr = depNodeFn.attribute(nodeAndAttr[1])
        plug = MPlug ( obj, attr )
        if plug.isNull() :
            plug = None
    return plug

def toComponentMObject( dagPath ):
    """
    get an MObject representing all components of the passed dagPath

    The component type that will be returned depends on the exact type of
    object passed in - for instance, a poly mesh will return a component
    representing all the kMeshVertComponents.

    The exact choice of component type is determined by MItGeometry.
    """

    component = MObject()
    sel = MSelectionList()
    mit = MItGeometry( dagPath )
    while not mit.isDone():
        # MItGeometry.component is deprecated
        comp = mit.currentItem()
        # merge is True
        sel.add( dagPath, comp, True )
        mit.next()
    sel.getDagPath( 0, dagPath, component )
    return component

# MDagPath, MPlug or MObject to name
# Note there is a kNamedObject API type but not corresponding MFn, thus
# I see no way of querying the name of something that isn't a kDependency node or a MPlug
# TODO : add components support, short/ long name support where applies
def MObjectName( obj ):
    """ Get the name of an existing MPlug, MDagPath or MObject representing a dependency node"""
    if isValidMPlug (obj) :
        return obj.name()
    elif isValidMNode (obj) :
        depNodeFn = MFnDependencyNode(obj)
        return depNodeFn.name()
    elif isValidMDagPath (obj):
        # return obj.fullPathName()
        return obj.partialPathName()
    else :
        return unicode(obj)


# names to MObjects function (expected to be faster to share one selectionList)
def nameToMObject( *args ):
    """ Get the API MObjects given names of existing nodes """
    sel = MSelectionList()
    for name in args :
        sel.add( name )
    result = []
    obj = MObject()
    for i in range(sel.length()) :
        try :
            sel.getDependNode( i, obj )
        except :
            result.append(None)
        if isValidMObject(obj) :
            result.append(obj)
        else :
            result.append(None)
    if len(result) == 1:
        return result[0]
    else :
        return tuple(result)

# wrap of api iterators

def MItNodes( *args, **kwargs ):
    """ Iterator on MObjects of nodes of the specified types in the Maya scene,
        if a list of tyes is passed as args, then all nodes of a type included in the list will be iterated on,
        if no types are specified, all nodes of the scene will be iterated on
        the types are specified as Maya API types """
    typeFilter = MIteratorType()
    if args :
        if len(args) == 1 :
            typeFilter.setFilterType ( args[0] )
        else :
            # annoying argument conversion for Maya API non standard C types
            typeIntM = MIntArray()
            MScriptUtil.createIntArrayFromList ( args,  typeIntM )
            typeFilter.setFilterList ( typeIntM )
        # we will iterate on dependancy nodes, not dagPaths or plugs
        typeFilter.setObjectType ( MIteratorType.kMObject )
    # create iterator with (possibly empty) typeFilter
    iterObj = MItDependencyNodes ( typeFilter )
    while not iterObj.isDone() :
        yield (iterObj.thisNode())
        iterObj.next()


# Iterators on nodes connections using MItDependencyGraph (ie listConnections/ listHistory)
def MItGraph (nodeOrPlug, *args, **kwargs):
    """ Iterate over MObjects of Dependency Graph (DG) Nodes or Plugs starting at a specified root Node or Plug,
        If a list of types is provided, then only nodes of these types will be returned,
        if no type is provided all connected nodes will be iterated on.
        Types are specified as Maya API types.
        The following keywords will affect order and behavior of traversal:
        upstream: if True connections will be followed from destination to source,
                  if False from source to destination
                  default is False (downstream)
        breadth: if True nodes will be returned as a breadth first traversal of the connection graph,
                 if False as a preorder (depth first)
                 default is False (depth first)
        plug: if True traversal will be at plug level (no plug will be traversed more than once),
              if False at node level (no node will be traversed more than once),
              default is False (node level)
        prune : if True will stop the iteration on nodes than do not fit the types list,
                if False these nodes will be traversed but not returned
                default is False (do not prune) """
#    startObj = MObject()
#    startPlug = MPlug()
    startObj = None
    startPlug = None
    if isValidMPlug(nodeOrPlug):
        startPlug = nodeOrPlug
    elif isValidMNode(nodeOrPlug) :
        startObj = nodeOrPlug
    else :
        raise ValueError, "'%s' is not a valid Node or Plug" % MObjectName(nodeOrPlug)
    upstream = kwargs.get('upstream', False)
    breadth = kwargs.get('breadth', False)
    plug = kwargs.get('plug', False)
    prune = kwargs.get('prune', False)
    if args :
        typeFilter = MIteratorType()
        if len(args) == 1 :
            typeFilter.setFilterType ( args[0] )
        else :
            # annoying argument conversion for Maya API non standard C types
            typeIntM = MIntArray()
            MScriptUtil.createIntArrayFromList ( args,  typeIntM )
            typeFilter.setFilterList ( typeIntM )
        # we start on a node or a plug
        if startPlug is not None :
            typeFilter.setObjectType ( MIteratorType.kMPlugObject )
        else :
            typeFilter.setObjectType ( MIteratorType.kMObject )
    # create iterator with (possibly empty) filter list and flags
    if upstream :
        direction = MItDependencyGraph.kUpstream
    else :
        direction = MItDependencyGraph.kDownstream
    if breadth :
        traversal = MItDependencyGraph.kBreadthFirst
    else :
        traversal =  MItDependencyGraph.kDepthFirst
    if plug :
        level = MItDependencyGraph.kPlugLevel
    else :
        level = MItDependencyGraph.kNodeLevel
    iterObj = MItDependencyGraph ( startObj, startPlug, typeFilter, direction, traversal, level )
    if prune :
        iterObj.enablePruningOnFilter()
    else :
        iterObj.disablePruningOnFilter()
    # iterates and yields MObjects
    while not iterObj.isDone() :
        yield (iterObj.thisNode())
        iterObj.next()

# Iterators on dag nodes hierarchies using MItDag (ie listRelatives)
def MItDag (root = None, *args, **kwargs) :
    """ Iterate over the hierarchy under a root dag node, if root is None, will iterate on whole Maya scene
        If a list of types is provided, then only nodes of these types will be returned,
        if no type is provided all dag nodes under the root will be iterated on.
        Types are specified as Maya API types.
        The following keywords will affect order and behavior of traversal:
        breadth: if True nodes Mobjects will be returned as a breadth first traversal of the hierarchy tree,
                 if False as a preorder (depth first)
                 default is False (depth first)
        underworld: if True traversal will include a shape's underworld (dag object parented to the shape),
              if False underworld will not be traversed,
              default is False (do not traverse underworld )
        depth : if True will return depth of each node.
        prune : if True will stop the iteration on nodes than do not fit the types list,
                if False these nodes will be traversed but not returned
                default is False (do not prune) """
    # startObj = MObject()
    # startPath = MDagPath()
    startObj = startPath = None
    if isValidMDagPath (root) :
        startPath = root
    elif isValidMDagNode (root) :
        startObj = root
    else :
        raise ValueError, "'%s' is not a valid Dag Node" % MObjectName(root)
    breadth = kwargs.get('breadth', False)
    underworld = kwargs.get('underworld', False)
    prune = kwargs.get('prune', False)
    path = kwargs.get('path', False)
    allPaths = kwargs.get('allPaths', False)
    if args :
        typeFilter = MIteratorType()
        if len(args) == 1 :
            typeFilter.setFilterType ( args[0] )
        else :
            # annoying argument conversion for Maya API non standard C types
            typeIntM = MIntArray()
            MScriptUtil.createIntArrayFromList ( args,  typeIntM )
            typeFilter.setFilterList ( typeIntM )
        # we start on a MDagPath or a Mobject
        if startPath is not None :
            typeFilter.setObjectType ( MIteratorType.kMDagPathObject )
        else :
            typeFilter.setObjectType ( MIteratorType.kMObject )
    # create iterator with (possibly empty) filter list and flags
    if breadth :
        traversal = MItDag.kBreadthFirst
    else :
        traversal =  MItDag.kDepthFirst
    iterObj = MItDag ( typeFilter, traversal )
    if root is not None :
        iterObj.reset ( typeFilter, startObj, startPath, traversal )

    if underworld :
        iterObj.traverseUnderWorld (True)
    else :
        iterObj.traverseUnderWorld (False)
    # iterates and yields MObject or MDagPath
    # handle prune ?

    # Must define dPath in loop or the iterator will yield
    # them as several references to the same object (thus with the same value each time)
    # instances must not be returned multiple times
    # could use a dict but it requires "obj1 is obj2" and not only "obj1 == obj2" to return true to
    # dic = {}
    # dic[obj1]=True
    # dic.has_key(obj2)
    instance = []
    # code doesn't look nice but Im putting the tests out of the iter loops to loose as little speed as possible,
    # will certainly define functions for each case
    if allPaths :
        dPathArray = MDagPathArray()
        while not iterObj.isDone() :
            if iterObj.isInstanced ( True ) :
                obj = iterObj.currentItem()
                if not obj in instance :
                    iterObj.getAllPaths(dPathArray)
                    nbDagPath = dPathArray.length()
                    for i in range(nbDagPath) :
                        dPath = MDagPath(dPathArray[i])
                        yield dPath
                    instance.append(obj)
            else :
                iterObj.getAllPaths(dPathArray)
                nbDagPath = dPathArray.length()
                for i in range(nbDagPath) :
                    dPath = MDagPath(dPathArray[i])
                    yield dPath
            iterObj.next()
    elif path :
        while not iterObj.isDone() :
            if iterObj.isInstanced ( True ) :
                obj = iterObj.currentItem()
                if not obj in instance :
                    dPath = MDagPath()
                    iterObj.getPath(dPath)
                    yield dPath
                    instance.append(obj)
            else :
                dPath = MDagPath()
                iterObj.getPath(dPath)
                yield dPath
            iterObj.next()
    else :
        while not iterObj.isDone() :
            obj = iterObj.currentItem()
            if iterObj.isInstanced ( True ) :
                if not obj in instance :
                    yield obj
                    instance.append(obj)
            else :
                yield obj
            iterObj.next()

# Essentially duplicated in datatypes - only difference is
# whether return value is a PyMel or api object
# Repeated for speed
def getPlugValue( plug ):
    """given an MPlug, get its value"""

    #if plug.isArray():
    #    raise TypeError, "array plugs of this type are not supported"

    obj = plug.attribute()
    apiType = obj.apiType()

    if apiType in [ MFn.kAttribute2Double, MFn.kAttribute2Float, MFn.kAttribute2Short, MFn.kAttribute2Int,
                    MFn.kAttribute3Double, MFn.kAttribute3Float, MFn.kAttribute3Short, MFn.kAttribute3Int,
                    MFn.kAttribute4Double,
                    MFn.kCompoundAttribute ] :
        res = []
        for i in range(plug.numChildren()):
            res.append( getPlugValue( plug.child(i) ) )
        return tuple(res)

    elif apiType in [ MFn.kDoubleLinearAttribute, MFn.kFloatLinearAttribute ] :
        return plug.asMDistance()

    elif apiType in [ MFn.kDoubleAngleAttribute, MFn.kFloatAngleAttribute ] :
        return plug.asMAngle()

    elif apiType == MFn.kTimeAttribute:
        return plug.asMTime()

    elif apiType == MFn.kNumericAttribute:
        #return getNumericPlugValue(plug)
        nAttr = MFnNumericAttribute(obj)
        dataType = nAttr.unitType()
        if dataType == MFnNumericData.kBoolean:
            return plug.asBool()

        elif dataType in [ MFnNumericData.kShort, MFnNumericData.kInt, MFnNumericData.kLong, MFnNumericData.kByte] :
            return plug.asInt()

        elif dataType in [ MFnNumericData.kFloat, MFnNumericData.kDouble, MFnNumericData.kAddr] :
            return plug.asDouble()
        raise "%s: unknown numeric attribute type: %s" % (plug.partialName(True, True, True, False, True, True), dataType)

    elif apiType == MFn.kEnumAttribute:
        return plug.asInt()

    elif apiType == MFn.kTypedAttribute:
        tAttr = MFnTypedAttribute( obj )
        dataType = tAttr.attrType()


        if dataType == MFnData.kInvalid:
            return None

        elif dataType == MFnData.kString:
            return plug.asString()

        elif dataType == MFnData.kNumeric:

            # all of the dynamic mental ray attributes fail here, but i have no idea why they are numeric attrs and not message attrs.
            # cmds.getAttr returns None, so we will too.
            try:
                dataObj = plug.asMObject()
            except:
                return

            try:
                numFn = MFnNumericData( dataObj )
            except RuntimeError:
                if plug.isArray():
                    raise TypeError, "%s: numeric arrays are not supported" % plug.partialName(True, True, True, False, True, True)
                else:
                    raise TypeError, "%s: attribute type is numeric, but its data cannot be interpreted numerically" % plug.partialName(True, True, True, False, True, True)
            dataType = numFn.numericType()

            if dataType == MFnNumericData.kBoolean:
                return plug.asBool()

            elif dataType in [ MFnNumericData.kShort, MFnNumericData.kInt, MFnNumericData.kLong, MFnNumericData.kByte] :
                return plug.asInt()

            elif dataType in [ MFnNumericData.kFloat, MFnNumericData.kDouble, MFnNumericData.kAddr] :
                return plug.asDouble()

            elif dataType == MFnNumericData.k2Short :
                ptr1 = SafeApiPtr('short')
                ptr2 = SafeApiPtr('short')

                numFn.getData2Short(ptr1(),ptr2())
                return ( ptr1.get(), ptr2.get() )

            elif dataType in [ MFnNumericData.k2Int, MFnNumericData.k2Long ]:
                ptr1 = SafeApiPtr('int')
                ptr2 = SafeApiPtr('int')

                numFn.getData2Int(ptr1(), ptr2())
                return ( ptr1.get(), ptr2.get() )

            elif dataType == MFnNumericData.k2Float :
                ptr1 = SafeApiPtr('float')
                ptr2 = SafeApiPtr('float')

                numFn.getData2Float(ptr1(), ptr2())
                return ( ptr1.get(), ptr2.get() )

            elif dataType == MFnNumericData.k2Double :
                ptr1 = SafeApiPtr('double')
                ptr2 = SafeApiPtr('double')

                numFn.getData2Double(ptr1(), ptr2())
                return ( ptr1.get(), ptr2.get() )

            elif dataType == MFnNumericData.k3Float:
                ptr1 = SafeApiPtr('float')
                ptr2 = SafeApiPtr('float')
                ptr3 = SafeApiPtr('float')

                numFn.getData3Float(ptr1(), ptr2(), ptr3())
                return ( ptr1.get(), ptr2.get(), ptr3.get() )

            elif dataType ==  MFnNumericData.k3Double:
                ptr1 = SafeApiPtr('double')
                ptr2 = SafeApiPtr('double')
                ptr3 = SafeApiPtr('double')

                numFn.getData3Double(ptr1(), ptr2(), ptr3())
                return ( ptr1.get(), ptr2.get(), ptr3.get() )

            elif dataType == MFnNumericData.kChar :
                return plug.asChar()

            raise TypeError, "%s: Unsupported numeric attribute: %s" % (plug.partialName(True, True, True, False, True, True),dataType)

        elif dataType == MFnData.kMatrix :
            return MFnMatrixData( plug.asMObject() ).matrix()

        elif dataType == MFnData.kDoubleArray :
            try:
                dataObj = plug.asMObject()
            except RuntimeError:
                return []
            return MFnDoubleArrayData( dataObj ).array()

        elif dataType == MFnData.kIntArray :
            try:
                dataObj = plug.asMObject()
            except RuntimeError:
                return []
            return MFnIntArrayData( dataObj ).array()

        elif dataType == MFnData.kPointArray :
            try:
                dataObj = plug.asMObject()
            except RuntimeError:
                return []
            return MFnPointArrayData( dataObj ).array()

        elif dataType == MFnData.kVectorArray :
            try:
                dataObj = plug.asMObject()
            except RuntimeError:
                return []
            return MFnVectorArrayData( dataObj ).array()

        elif dataType == MFnData.kStringArray :
            try:
                dataObj = plug.asMObject()
            except RuntimeError:
                return []
            return MFnStringArrayData( dataObj ).array()
        raise TypeError, "%s: Unsupported typed attribute: %s" % (plug.partialName(True, True, True, False, True, True),dataType)

    raise TypeError, "%s: Unsupported Type: %s" % (plug.partialName(True, True, True, False, True, True), obj.apiTypeStr())

########NEW FILE########
__FILENAME__ = plugins
"""
Maya API plugin utilities

A quick example::

    from pymel.api.plugins import Command
    class testCmd(Command):
        def doIt(self, args):
            print "doIt..."

    testCmd.register()
    cmds.testCmd()
    testCmd.deregister()

An example of a plugin which creates a node:

    import math

    import pymel.api.plugins as plugins
    import maya.OpenMaya as om

    class PymelSineNode(plugins.DependNode):
        '''Example node adapted from maya's example sine node plugin

        Shows how much easier it is to create a plugin node using pymel.api.plugins
        '''
        # For quick testing, if _typeId is not defined, pymel will create one by
        # hashing the node name. For longer-term uses, you should explicitly set
        # own typeId like this
        #
        # (NOTE - if using the automatic typeId generation, the hashlib python
        # builtin library must be functional / working from within maya... due
        # to dynamic library linking issues (ie, libssl, libcrypto), this
        # may not always be the case out-of-the-box on some linux distros
        _typeId = om.MTypeId(0x900FF)

        # by default, the name of the node will be the name of the class - to
        # override and set your own maya node name, do this:
        #_name = 'PymelSineNode'

        @classmethod
        def initialize(cls):
            # input
            nAttr = om.MFnNumericAttribute()
            cls.input = nAttr.create( "input", "in", om.MFnNumericData.kFloat, 0.0 )
            nAttr.setStorable(1)
            cls.addAttribute( cls.input )

            # output
            cls.output = nAttr.create( "output", "out", om.MFnNumericData.kFloat, 0.0 )
            nAttr.setStorable(1)
            nAttr.setWritable(1)
            cls.addAttribute( cls.output )

            # set attributeAffects relationships
            cls.attributeAffects( cls.input, cls.output )

        def compute(self, plug, dataBlock):
            if ( plug == self.output ):
                dataHandle = dataBlock.inputValue( self.input )
                inputFloat = dataHandle.asFloat()
                result = math.sin( inputFloat )
                outputHandle = dataBlock.outputValue( self.output )
                outputHandle.setFloat( result )
                dataBlock.setClean( plug )
                return om.MStatus.kSuccess
            return om.MStatus.kUnknownParameter

    ## initialize the script plug-in
    def initializePlugin(mobject):
        PymelSineNode.register(mobject)

    # uninitialize the script plug-in
    def uninitializePlugin(mobject):
        PymelSineNode.deregister(mobject)
"""




import sys
import os
import inspect
from collections import defaultdict

import maya.OpenMaya as om
import maya.OpenMayaMPx as mpx
import maya.cmds

#===============================================================================
# Errors
#===============================================================================
class PluginError(Exception): pass
class PluginRegistryError(PluginError): pass
class AlreadyRegisteredError(PluginRegistryError): pass
class NotRegisteredError(PluginRegistryError): pass

#===============================================================================
# General Info
#===============================================================================

# Gives a map from an MPx class name to it's enum name in MPxNode.Type
# Because different versions of maya may not have all these MPxNodes, we need
# to store as strings, and retrieve from mpx
# Constructed by manual inspection of names in MPxNode.Type
mpxNamesToEnumNames = {
    'MPxNode':'kDependNode',
    'MPxPolyTrg':'kDependNode',             # has no unique enum
    'MPxLocatorNode':'kLocatorNode',
    'MPxDeformerNode':'kDeformerNode',
    'MPxManipContainer':'kManipContainer',
    'MPxSurfaceShape':'kSurfaceShape',
    'MPxComponentShape':'kSurfaceShape',    # has no unique enum
    'MPxFieldNode':'kFieldNode',
    'MPxEmitterNode':'kEmitterNode',
    'MPxSpringNode':'kSpringNode',
    'MPxIkSolverNode':'kIkSolverNode',
    'MPxHardwareShader':'kHardwareShader',
    'MPxHwShaderNode':'kHwShaderNode',
    'MPxTransform':'kTransformNode',
    'MPxObjectSet':'kObjectSet',
    'MPxFluidEmitterNode':'kFluidEmitterNode',
    'MPxImagePlane':'kImagePlaneNode',
    'MPxParticleAttributeMapperNode':'kParticleAttributeMapperNode',
    'MPxCameraSet':'kCameraSetNode',
    'MPxConstraint':'kConstraintNode',
    'MPxManipulatorNode':'kManipulatorNode',
#    'MPxRepMgr':'kRepMgr',
#    'MPxRepresentation':'kRepresentation',
    'MPxAssembly':'kAssembly',
    }

# Gives a map from an MPx class name to it's enum name in MFn.Type
# Constructed by a combination of _buildMpxNamesToApiEnumNames and manual
# inspection of names in MFn.Type
mpxNamesToApiEnumNames = {
    'MPxNode': 'kPluginDependNode',
    'MPxPolyTrg': 'kPluginDependNode',   # has no unique enum
    'MPxLocatorNode': 'kPluginLocatorNode',
    'MPxDeformerNode': 'kPluginDeformerNode',
    'MPxManipContainer': 'kPluginManipContainer',  # added manually
    'MPxSurfaceShape': 'kPluginShape',
    'MPxComponentShape': 'kPluginShape', # has no unique enum
    'MPxFieldNode': 'kPluginFieldNode',
    'MPxEmitterNode': 'kPluginEmitterNode',
    'MPxSpringNode': 'kPluginSpringNode',
    'MPxIkSolverNode': 'kPluginIkSolver',
    'MPxHardwareShader': 'kPluginHardwareShader',
    'MPxHwShaderNode': 'kPluginHwShaderNode',
    'MPxTransform': 'kPluginTransformNode',
    'MPxObjectSet': 'kPluginObjectSet',
    'MPxFluidEmitterNode': 'kPluginEmitterNode',
    'MPxImagePlane': 'kPluginImagePlaneNode',
    'MPxParticleAttributeMapperNode' : 'kPluginParticleAttributeMapperNode', # added manually
    'MPxCameraSet': 'kPluginCameraSet',
    'MPxConstraint': 'kPluginConstraintNode',
    'MPxManipulatorNode':'kPluginManipulatorNode', # added manually
    'MPxRepMgr':'kPluginRepMgr',  # guessed?
    'MPxRepresentation':'kPluginRepresentation', # guessed?
    'MPxAssembly':'kAssembly',
    }

# Gives a map from an MPx class name to it's maya node type name
# Constructed from a combination of _buildMpxNamesToMayaNodes and manual
# guess + check with nodeType(isTypeName=True)
mpxNamesToMayaNodes = {
    'MPxNode': u'THdependNode',
    'MPxPolyTrg': u'THdependNode',
    'MPxLocatorNode': u'THlocatorShape',
    'MPxDeformerNode': u'THdeformer',
    'MPxManipContainer': u'THmanipContainer',  # guessed + confirmed
    'MPxSurfaceShape': u'THsurfaceShape',
    'MPxComponentShape': u'THsurfaceShape',
    'MPxFieldNode': u'THdynField',
    'MPxEmitterNode': u'THdynEmitter',
    'MPxSpringNode': u'THdynSpring',
    'MPxIkSolverNode': u'THikSolverNode',
    'MPxHardwareShader': u'THhardwareShader',
    'MPxHwShaderNode': u'THhwShader',
    'MPxTransform': u'THcustomTransform',
    'MPxObjectSet': u'THobjectSet',
    'MPxFluidEmitterNode': u'THfluidEmitter',
    'MPxImagePlane': u'THimagePlane',
    'MPxParticleAttributeMapperNode': u'THarrayMapper',
    'MPxCameraSet': u'THcameraSet',
    'MPxConstraint': u'THconstraint',
    'MPxManipulatorNode':'THmanip', # guessed + confirmed
    'MPxRepMgr':'THdependNode',  # no clue...?
    'MPxRepresentation':'THdependNode', # no clue...?
    'MPxAssembly':'THassembly',
    }

mpxClassesToMpxEnums = {}
missingMPx = []
for _mpxName, _enumName in mpxNamesToEnumNames.iteritems():
    _mpxCls = getattr(mpx, _mpxName, None)

    if _mpxCls:
        _enum = getattr(mpx.MPxNode, _enumName, None)
        if _enum is not None:
            mpxClassesToMpxEnums[_mpxCls] = _enum
        else:
            print "warning: could not find enum MPxNode.%s for class %s" % (_enumName, _mpxName)
    else:
        missingMPx.append(_mpxName)

for _mpxName in missingMPx:
    mpxNamesToEnumNames.pop(_mpxName, None)
    mpxNamesToApiEnumNames.pop(_mpxName, None)
    mpxNamesToMayaNodes.pop(_mpxName, None)

del _mpxName, _enumName, _enum

pluginMayaTypes = set(mpxNamesToMayaNodes.itervalues())

NON_CREATABLE = set(['MPxManipContainer',
                     'MPxManipulatorNode',
                     'MPxParticleAttributeMapperNode',
                    ])

_enumToStr = None
def enumToStr():
    '''Returns a dictionary mapping from an MPxNode node type enum to it's
    string name.
    Useful for debugging purposes.
    '''
    global _enumToStr
    if _enumToStr is None:
        _enumToStr = {}
        for name, val in inspect.getmembers(mpx.MPxNode, lambda x: isinstance(x, int)):
            if name.startswith('k'):
                _enumToStr[val] = name
    return _enumToStr

_allMPx = None
def allMPx():
    '''
    Returns a list of all MPx classes
    '''
    global _allMPx
    if _allMPx is None:
        _allMPx = []
        for _, cls in inspect.getmembers(mpx, lambda x: inspect.isclass(x) and issubclass(x, mpx.MPxNode)):
            _allMPx.append(cls)
    return _allMPx

# We want to make sure we know if maya adds a new MPx class!
_new = [_mpx.__name__ for _mpx in allMPx() if _mpx not in mpxClassesToMpxEnums]
if _new:
    import pymel.internal.plogging as plog
    _logger = plog.getLogger('pymel')
    _logger.raiseLog(_logger.WARNING, 'found new MPx classes: %s'
                                       % ', '.join(_new))

#===============================================================================
# Plugin Registration / loading
#===============================================================================

registered = set()

pyNodeMethods = {}

def _pluginModule():
    return inspect.getmodule( lambda: None )

def _pluginName():
    return _pluginModule().__name__.split('.')[-1]

def _pluginFile():
    return inspect.getsourcefile( lambda:None )
#    module = sys.modules[__name__]
#    print module, __name__
#    return module.__file__

def _loadPlugin():
    thisFile = _pluginFile()
    if not maya.cmds.pluginInfo( thisFile, query=1, loaded=1 ):
        maya.cmds.loadPlugin( thisFile )

def _unloadPlugin():
    thisFile = _pluginFile()
    if maya.cmds.pluginInfo( thisFile, query=1, loaded=1 ):
        maya.cmds.unloadPlugin( thisFile )

def _getPlugin(object=None):
    if object is None:
        _loadPlugin()
        mobject = mpx.MFnPlugin.findPlugin( _pluginName() )
        plugin = mpx.MFnPlugin(mobject)
    elif isinstance(object, om.MObject):
        plugin = mpx.MFnPlugin(object)
    elif isinstance(object, mpx.MFnPlugin):
        plugin = object
    else:
        raise TypeError('expected an MFnPlugin instance or an MObject that can be cast to an MFnPlugin')
    return plugin

# allow this file to be loaded as its own dummy plugin
# Initialize the script plug-in
def initializePlugin(mobject):
    "do not call directly"
    pass

# Uninitialize the script plug-in
def uninitializePlugin(mobject):
    "do not call directly"

    #print "getmodule", inspect.getmodule( None )
    #mod = _pluginModule()

    #when uninitializePlugin is called it is execfile'd which changes the module in which this code runs.
    #we need to get the correct module first

    # FIXME: determine a reliable way to get this module's name when it is being execfile'd
    global registered
    mod = sys.modules['pymel.api.plugins']

    plugin = mpx.MFnPlugin(mobject)
    for obj in registered:
        print "deregistering", obj.name()
        obj.deregisterCommand(plugin)
    registered = set()

#===============================================================================
# Plugin Mixin Classes
#===============================================================================

class BasePluginMixin(object):
    # The name of the command or the node type
    _name = None

    # You can manually set this, or just leave it at None to let pymel
    # automatically determine it from the base classes
    _mpxType = None

    @classmethod
    def getMpxType(cls):
        if cls._mpxType is None:
            for pClass in inspect.getmro(cls):
                if pClass in mpxClassesToMpxEnums:
                    cls._mpxType = pClass
                    break
        return cls._mpxType

    @classmethod
    def mayaName(cls):
        if cls._name is None:
            cls._name = cls.__name__
        return cls._name

    _typeId = None

    # Defined here just so it can be shared between MPxTransformationMatrix
    # and DependNode
    @classmethod
    def getTypeId(cls, nodeName=None):
        if cls._typeId is None:
            if nodeName is None:
                nodeName = cls.mayaName()
            cls._typeId = cls._devTypeIdHash(nodeName)
        return cls._typeId

    @classmethod
    def _devTypeIdHash(cls, name):
        '''hashes the given string to a MTypeId, somewhere in the dev range
        (0x80000 - 0xfffff)
        '''
        import hashlib

        start = 0x80000
        end = 0xfffff
        size = (end - start) + 1
        md5 = hashlib.md5()
        md5.update(name)
        id = start + long(md5.hexdigest(), 16) % size
        return om.MTypeId(id)

    @classmethod
    def create(cls):
        inst = cls()
        return mpx.asMPxPtr( inst )

    @classmethod
    def _getRegisteredPluginObj(cls):
        # plugin registry should NOT be inherited from parents!
        if '_registeredPlugin_data' not in cls.__dict__:
            cls._registeredPlugin_data = None
        return cls._registeredPlugin_data

    @classmethod
    def _setRegisteredPluginObj(cls, val):
        if val and cls.isRegistered():
            raise AlreadyRegisteredError("Class %s is already registered to a plugin" % cls.__name__)
        cls._registeredPlugin_data = val

    @classmethod
    def register(cls, plugin=None):
        """Used to register this MPx object wrapper with the maya plugin.

        By default the command will be registered to a dummy plugin provided by pymel.

        If using from within a plugin module's ``initializePlugin`` or
        ``uninitializePlugin`` callback, pass along the MObject given to these
        functions.

        When implementing the derived MPx wrappers, do not override this -
        instead, override _registerOverride
        """
        global registered
        useThisPlugin = (plugin is None)
        mplugin = _getPlugin(plugin)

        cls._setRegisteredPluginObj(mplugin.object())

        cls._registerOverride(mplugin, useThisPlugin)
        if useThisPlugin:
            registered.add(cls)

    @classmethod
    def _registerOverride(cls, mplugin, useThisPlugin):
        '''Override this to implement the actual registration behavior for
        the MPx class.
        '''
        return

    @classmethod
    def deregister(cls, plugin=None):
        """
        If using from within a plugin module's ``initializePlugin`` or
        ``uninitializePlugin`` callback, pass along the MObject given to these
        functions.
        """
        global registered
        if not cls.isRegistered():
            raise NotRegisteredError("Class %s is not registered to a plugin" % cls.__name__)

        useThisPlugin = (plugin is None)
        mplugin = _getPlugin(plugin)
        cls._deregisterOverride(mplugin, useThisPlugin)
        if plugin is None:
            registered.remove(cls)

        cls._setRegisteredPluginObj(None)

    @classmethod
    def _deregisterOverride(cls, mplugin, useThisPlugin):
        '''Override this to implement the actual deregistration behavior for
        the MPx class.
        '''
        return

    @classmethod
    def isRegistered(cls):
        return bool(cls._getRegisteredPluginObj())

#===============================================================================
# Plugin Classes - inherit from these!
#===============================================================================


class Command(BasePluginMixin, mpx.MPxCommand):
    """create a subclass of this with a doIt method"""
    @classmethod
    def createSyntax(cls):
        return om.MSyntax()

    @classmethod
    def _registerOverride(cls, mplugin, useThisPlugin):
        name = cls.mayaName()
        mplugin.registerCommand( name, cls.create, cls.createSyntax )
        if useThisPlugin:
            import pymel.core
            pymel.core._addPluginCommand(mplugin.name(), name)

    @classmethod
    def _deregisterOverride(cls, mplugin, useThisPlugin):
        '''Override this to implement the actual deregistration behavior for
        the MPx class.
        '''
        name = cls.mayaName()
        mplugin.deregisterCommand( name )
        if useThisPlugin:
            import pymel.core
            pymel.core._removePluginCommand(mplugin.name(), name)

class TransformationMatrix(BasePluginMixin, mpx.MPxTransformationMatrix):
    _typeId = None
    # Override to do nothing - should be (de)registered by the transform!
    @classmethod
    def register(cls, plugin=None): pass
    @classmethod
    def deregister(cls, plugin=None): pass

class DependNode(BasePluginMixin, mpx.MPxNode):
    # You can manually set this, or just leave it at None to let pymel
    # automatically determine it from the MPxType
    _typeEnum = None

    # If this is left as None, a 'reasonable' default will be made based on a
    # hash of the node name in the user range... to ensure no name clashes,
    # though, you should get a node id from Autodesk!
    _typeId = None

    @classmethod
    def getTypeEnum(cls):
        if cls._typeEnum is None:
            cls._typeEnum = mpxClassesToMpxEnums[cls.getMpxType()]
        return cls._typeEnum

    _classification = None

    _callbacks = defaultdict(list)

    @classmethod
    def initialize(cls):
        return

    @classmethod
    def _registerOverride(cls, mplugin, useThisPlugin):
        nodeName = cls.mayaName()

        # PyNodeMethods
        global pyNodeMethods
        pluginPynodeMethods = pyNodeMethods.setdefault(mplugin.name(), {})
        pluginPynodeMethods[nodeName] = {}
        for _, clsObj in inspect.getmembers(cls):
            if isinstance(clsObj, PyNodeMethod):
                pluginPynodeMethods[nodeName][clsObj.name] = clsObj.func

        cls._nodeRegisterOverride( nodeName, mplugin )

        if useThisPlugin:
            import pymel.core
            pymel.core._addPluginNode(mplugin.name(), nodeName)
        # callbacks
        for cbname, reg in [
                    ('timeChanged', om.MDGMessage.addTimeChangeCallback),
                    ('forcedUpdate', om.MDGMessage.addForceUpdateCallback),
                    ('nodeAdded', om.MDGMessage.addNodeAddedCallback),
                    ('nodeRemoved', om.MDGMessage.addNodeRemovedCallback),
                    #('connectionMade', om.MDGMessage.addConnectionCallback), # conflicts with MPxNode.connectionMade
                    ('preConnectionMade', om.MDGMessage.addPreConnectionCallback)]:
            if hasattr(cls, cbname):
                cb = getattr(cls, cbname)
                # TODO: assert cb is a classmethod, maybe check number of inputs too
                cls._callbacks[nodeName].append(reg(cb, nodeName))

    @classmethod
    def _nodeRegisterOverride( cls, nodeName, mplugin ):
        registerArgs = [ nodeName, cls.getTypeId(), cls.create, cls.initialize,
                         cls.getTypeEnum() ]
        if cls._classification:
            registerArgs.append(cls._classification)
        mplugin.registerNode( *registerArgs )


    @classmethod
    def _deregisterOverride(cls, mplugin, useThisPlugin):
        '''Override this to implement the actual deregistration behavior for
        the MPx class.
        '''
        nodeName = cls.mayaName()

        # PyNodeMethods
        global pyNodeMethods
        pyNodeMethods.get(mplugin.name(), {}).pop(nodeName, None)

        mplugin.deregisterNode( cls.getTypeId() )
        if useThisPlugin:
            import pymel.core
            pymel.core._removePluginNode(mplugin.name(), nodeName)
        for id in cls._callbacks.pop(nodeName, []):
            om.MMessage.removeCallback(id)

    @classmethod
    def isAbstractClass(cls):
        # MPxPolyTrg returns True
        return False

# new in 2014
if hasattr(mpx, 'MPxAssembly'):
    class Assembly(DependNode, mpx.MPxAssembly): pass

class CameraSet(DependNode, mpx.MPxCameraSet): pass

class Constraint(DependNode, mpx.MPxConstraint): pass

class DeformerNode(DependNode, mpx.MPxDeformerNode): pass

class EmitterNode(DependNode, mpx.MPxEmitterNode): pass

class FluidEmitterNode(EmitterNode, mpx.MPxFluidEmitterNode): pass

class FieldNode(DependNode, mpx.MPxFieldNode): pass

class HardwareShader(DependNode, mpx.MPxHardwareShader): pass

class HwShaderNode(DependNode, mpx.MPxHwShaderNode): pass

class IkSolverNode(DependNode, mpx.MPxIkSolverNode): pass

class ImagePlane(DependNode, mpx.MPxImagePlane): pass

class LocatorNode(DependNode, mpx.MPxLocatorNode): pass

class ManipContainer(DependNode, mpx.MPxManipContainer): pass

class ManipulatorNode(DependNode, mpx.MPxManipulatorNode): pass

class ObjectSet(DependNode, mpx.MPxObjectSet): pass

class ParticleAttributeMapperNode(DependNode, mpx.MPxParticleAttributeMapperNode): pass

class PolyTrg(DependNode, mpx.MPxPolyTrg): pass

class SpringNode(DependNode, mpx.MPxSpringNode): pass

class SurfaceShape(DependNode, mpx.MPxSurfaceShape): pass

class ComponentShape(SurfaceShape, mpx.MPxComponentShape): pass

class Transform(DependNode, mpx.MPxTransform):
    # Bug in python - can't just use MPxTransformationMatrix, as there's a
    # problem with MPxTransformationMatrix.baseTransformationMatrixId
    _transformMatrix = TransformationMatrix

    @classmethod
    def _nodeRegisterOverride( cls, nodeName, mplugin ):
        registerArgs = [ nodeName, cls.getTypeId(), cls.create, cls.initialize,
                         cls._transformMatrix.create,
                         cls._transformMatrix.getTypeId() ]
        if cls._classification:
            registerArgs.append(cls._classification)
        mplugin.registerTransform( *registerArgs )

# these 2 appear to temporary or debugging types? they existed at some point in
# the beta for 2013, then went away?
#if hasattr(mpx, 'MPxRepMgr'):
#    class RepMgr(DependNode, mpx.MPxRepMgr): pass

#if hasattr(mpx, 'MPxRepresentation'):
#    class Representation(DependNode, mpx.MPxRepresentation): pass


#===============================================================================
# Plugin Class Helpers
#===============================================================================

class PyNodeMethod(object):
    '''Used as a decorator, placed on methods on a plugin node class, to signal
    that these methods should be placed on to PyNode objects constructed for
    the resulting depend nodes.

    >>> class FriendlyNode(DependNode):
    ...     _typeId = om.MTypeId(654748)
    ...     @PyNodeMethod
    ...     def introduce(self):
    ...         print "Hi, I'm an instance of a MyNode PyNode - my name is %s!" % self.name()
    >>> FriendlyNode.register()
    >>> import pymel.core as pm
    >>> frank = pm.createNode('FriendlyNode', name='Frank')
    >>> frank.introduce()
    Hi, I'm an instance of a MyNode PyNode - my name is Frank!
    '''
    def __init__(self, func, name=None):
        if name is None:
            name = func.__name__
        self.func = func
        self.name = name


#===============================================================================
# Querying Plugin Hierarchy
#===============================================================================

def _buildPluginHierarchy(dummyClasses=None):
    '''Dynamically query the mel node hierarchy for all plugin node types

    This command must be run from within a running maya session - ie, where
    maya.cmds, etc are accessible.
    '''
    import pymel.internal.apicache as apicache

    if dummyClasses is None:
        dummyClasses = _createDummyPluginNodeClasses()

    # note that we always try to query inheritance, even for node types in
    # NON_CREATABLE, because post 2012, we should be able to query inheritance
    # without needing to create a node...
    inheritances = {}
    for pluginType, dummyClass in dummyClasses.iteritems():
        nodeType = dummyClass.mayaName()
        wasRegistered = dummyClass.isRegistered()
        if not wasRegistered:
            dummyClass.register()
        try:
            try:
                inheritance = apicache.getInheritance(nodeType)
            except apicache.ManipNodeTypeError:
                continue
        finally:
            if not wasRegistered:
                dummyClass.deregister()
        if not inheritance:
            # If there was a problem creating a node - for instance, in the
            # case of MPxParticleAttributeMapperNode...
            continue
        assert inheritance[-1] == nodeType
        inheritances[pluginType] = inheritance[:-1]
    return inheritances


def _buildMpxNamesToApiEnumNames(dummyClasses=None, dummyNodes=None):
    import pymel.api as api
    mpxNamesToEnumNames = {}
    with _DummyPluginNodesMaker(dummyClasses=dummyClasses,
                                alreadyCreated=dummyNodes) as nodeMaker:
        for mpxCls, mayaNode in nodeMaker.nodes.iteritems():
            mobj = api.toMObject(mayaNode)
            mpxNamesToEnumNames[mpxCls.__name__] = mobj.apiTypeStr()
    return mpxNamesToEnumNames

def _buildAll():
    with _DummyPluginNodesMaker() as nodeMaker:
        hierarchy = _buildPluginHierarchy(dummyClasses=nodeMaker.dummyClasses)
        mpxClassesToMpxEnums = _buildMpxNamesToApiEnumNames(dummyClasses=nodeMaker.dummyClasses,
                                                 dummyNodes=nodeMaker.nodes)
        mpxToMaya = _buildMpxNamesToMayaNodes(hierarchy=hierarchy)
    return hierarchy, mpxToMaya, mpxClassesToMpxEnums

def _buildMpxNamesToMayaNodes(hierarchy=None):
    if hierarchy is None:
        hierarchy = _buildPluginHierarchy()
    mpxNamesToMayaNodes = {}
    for mpxCls, parents in hierarchy.iteritems():
        if not parents:
            mayaType = hierarchy[mpx.MPxNode][-1]
        else:
            mayaType = parents[-1]
        mpxNamesToMayaNodes[mpxCls.__name__] = mayaType
    return mpxNamesToMayaNodes

def _createDummyPluginNodeClasses():
    '''Registers with the dummy pymel plugin a dummy node type for each MPxNode
    subclass

    returns a dictionary mapping from MPx class to a pymel dummy class of that
    type
    '''
    pymelPlugClasses = []

    for obj in globals().itervalues():
        if inspect.isclass(obj) and issubclass(obj, DependNode):
            pymelPlugClasses.append(obj)

    dummyClasses = {}
    for cls in pymelPlugClasses:
        class DummyClass(cls):
            _name = 'dummy' + cls.__name__
        DummyClass.__name__ = 'Dummy' + cls.__name__
        dummyClasses[DummyClass.getMpxType()] = DummyClass

    return dummyClasses

class _DummyPluginNodesMaker(object):
    def __init__(self, dummyClasses=None, alreadyCreated=None):
        if dummyClasses is None:
            dummyClasses = _createDummyPluginNodeClasses()
        self.dummyClasses = dummyClasses
        self.toUnregister = []
        self.nodes = {}
        if alreadyCreated is None:
            alreadyCreated = {}
        self.alreadyCreated = alreadyCreated
        if self.alreadyCreated:
            self.nodes.update(self.alreadyCreated)
        self.toDelete = []

    def __enter__(self):
        for mpxCls, pyCls in self.dummyClasses.iteritems():
            if not pyCls.isRegistered():
                self.toUnregister.append(pyCls)
                pyCls.register()
            if mpxCls not in self.alreadyCreated:
                if mpxCls.__name__ in NON_CREATABLE:
                    continue
                newNode = maya.cmds.createNode(pyCls.mayaName())
                parent = maya.cmds.listRelatives(newNode, parent=1)
                self.nodes[mpxCls] = newNode
                if parent:
                    self.toDelete.append(parent)
                else:
                    self.toDelete.append(newNode)
        return self

    def __exit__(self, type, value, traceback):
        if self.toDelete:
            maya.cmds.delete(*self.toDelete)
        for pyCls in self.toUnregister:
            pyCls.deregister()

#def _repoplulate():
#    print "repopulate"
#    try:
#        global registered
#        commands = maya.cmds.pluginInfo(_pluginName(), query=1, command=1)
#        registered = registered
#    except:
#        pass
#
#_repoplulate()


# when we reload, should we deregister all plugins??? or maybe we can just repopulate registered
#_unloadPlugin()

#==============================================================================
# Utility functions
#==============================================================================

def mayaPlugins():
    '''all maya plugins in the maya install directory'''
    import pymel.mayautils

    mayaLoc = pymel.mayautils.getMayaLocation()
    # need to set to os.path.realpath to get a 'canonical' path for string comparison...
    plugins = []
    pluginPaths = [os.path.realpath(x) for x in os.environ['MAYA_PLUG_IN_PATH'].split(os.path.pathsep)]
    for pluginPath in [x for x in pluginPaths if x.startswith( mayaLoc ) and os.path.isdir(x) ]:
        for x in os.listdir( pluginPath ):
            if os.path.isfile( os.path.join(pluginPath,x)):
                if not maya.cmds.pluginInfo(x, q=1, loaded=1):
                    plugins.append(x)
    return plugins

def loadAllMayaPlugins():
    '''will load all maya-installed plugins

    WARNING: tthe act of loading all the plugins may crash maya, especially if
    done from a non-GUI session
    '''
    import logging
    logger = logging.getLogger('pymel')
    logger.debug("loading all maya plugins...")
    for plugin in mayaPlugins():
        try:
            maya.cmds.loadPlugin( plugin, quiet=1 )
        except RuntimeError: pass
    logger.debug("...done loading all maya plugins")

def unloadAllPlugins(skipErrors=False, exclude=('DirectConnect',)):
    import logging
    logger = logging.getLogger('pymel')

    logger.debug("unloading all plugins...")
    loadedPlugins = maya.cmds.pluginInfo(q=True, listPlugins=True)
    # loadedPlugins may be None
    if loadedPlugins:
        # could just unload all plugins at once with:
        # maya.cmds.unloadPlugin(force=True, *loadedPlugins)
        # ...but if we do one at a time, we can at least get debugging info
        # on which one crashed...
        for plug in loadedPlugins:
            if plug in exclude:
                continue
            logger.debug("...unloading: %s" % plug)
            try:
                maya.cmds.unloadPlugin(plug, force=True)
            except Exception:
                if skipErrors:
                    import traceback
                    logger.warning("Error unloading plugin %s:" % plug)
                    logger.warning(traceback.format_exc())
                else:
                    raise
    logger.debug("...done unloading all plugins")

# It's not possible to query all plugin commands that a plugin registers with
# pluginInfo, so this holds a list of plugin commands that we still want to
# wrap.
# With 2012, we can now query modelEditor, constraint, and control commands.
# Unfortunately, we still can't get context commands... so UNREPORTED_COMMANDS
# is still necessary
# We sort by type of command, so that if pluginInfo does have the necessary
# flag for reporting, we can just use that.
UNREPORTED_COMMANDS = {
    'command':{},       # all versions of maya should support this flag!
    'modelEditorCommand':{'stereoCamera':['stereoCameraView']},
    'controlCommand':{},
    'constraintCommand':{},
    'contextCommand':{}, # currently no pluginInfo flag for this in any version, but I'm an optimist...
    #'other':{}, # just to hold any commands we may want that don't fall in other categories
    }

def pluginCommands(pluginName, reportedOnly=False):
    '''Returns the list of all commands that the plugin provides, to the best
    of our knowledge.

    Note that depending on your version of maya, this may not actually be the
    list of all commands provided.
    '''
    import logging
    logger = logging.getLogger('pymel')

    commands = []
    for cmdType, pluginToCmds in UNREPORTED_COMMANDS.iteritems():
        try:
            moreCmds = maya.cmds.pluginInfo(pluginName, query=1, **{cmdType:1})
        except TypeError:  # will get this if it's a flag pluginInfo doesn't know
            if reportedOnly:
                moreCmds = []
            else:
                moreCmds = pluginToCmds.get(pluginName, [])
        except Exception:
            logger.error("Failed to get %s list from %s" % (cmdType, pluginName))
            moreCmds = []

        # moreCmds may be None, as pluginInfo will return None
        if moreCmds:
            commands.extend(moreCmds)
    return commands
########NEW FILE########
__FILENAME__ = animation
"""functions related to animation"""

import pymel.util as _util
import pymel.internal.factories as _factories
import general as _general
import pymel.versions as versions

import pymel.internal.pmcmds as cmds

def currentTime( *args, **kwargs ):
    """
Modifications:
    - if no args are provided, the command returns the current time
    """

    if not args and not kwargs:
        return cmds.currentTime(q=1)
    else:
        return cmds.currentTime(*args, **kwargs)

def getCurrentTime():
    """get the current time as a float"""
    return cmds.currentTime(q=1)

def setCurrentTime( time ):
    """set the current time """
    return cmds.currentTime(time)

def listAnimatable( *args, **kwargs ):
    """
Modifications:
    - returns an empty list when the result is None
    - returns wrapped classes
    """
    return map( _general.PyNode, _util.listForNone(cmds.listAnimatable( *args, **kwargs ) ) )

def keyframe( *args, **kwargs ):
    """
Modifications:
    - returns an empty list when the result is None
    - if both valueChange and timeChange are queried, the result will be a list of (time,value) pairs
    """
    res = _util.listForNone( cmds.keyframe(*args, **kwargs) )
    if kwargs.get('query', kwargs.get('q', False) ) and \
            kwargs.get('valueChange', kwargs.get('vc', False) ) and kwargs.get('timeChange', kwargs.get('tc', False) ):
        return list(_util.pairIter(res))
    return res

def deformer(*args, **kwargs):
    return map( _general.PyNode, cmds.deformer(*args, **kwargs) )

def _constraint( func ):
    def constraintWithWeightSyntax(*args, **kwargs):
        """
Maya Bug Fix:
  - when queried, angle offsets would be returned in radians, not current angle unit

Modifications:
  - added new syntax for querying the weight of a target object, by passing the constraint first::

        aimConstraint( 'pCube1_aimConstraint1', q=1, weight ='pSphere1' )
        aimConstraint( 'pCube1_aimConstraint1', q=1, weight =['pSphere1', 'pCylinder1'] )
        aimConstraint( 'pCube1_aimConstraint1', q=1, weight =[] )
        """
        if kwargs.get( 'query', kwargs.get('q', False) and len(args)==1) :
            # Fix the big with angle offset query always being in radians
            if kwargs.get( 'offset', kwargs.get('o', None) ):
                return _general.getAttr(str(args[0]) + ".offset")

            # try seeing if we can apply the new weight query syntax
            targetObjects =  kwargs.get( 'weight', kwargs.get('w', None) )
            if targetObjects is not None:
                # old way caused KeyError if 'w' not in kwargs, even if 'weight' was!
                # targetObjects = kwargs.get( 'weight', kwargs['w'] )
                constraint = args[0]
                if 'constraint' in cmds.nodeType( constraint, inherited=1 ):
                    if not _util.isIterable( targetObjects ):
                        targetObjects = [targetObjects]
                    elif not targetObjects:
                        targetObjects = func( constraint, q=1, targetList=1 )

                    constraintObj = cmds.listConnections( constraint + '.constraintParentInverseMatrix', s=1, d=0 )[0]
                    args = targetObjects + [constraintObj]
                    kwargs.pop('w',None)
                    kwargs['weight'] = True
        res = func(*args, **kwargs)
        if kwargs.get( 'query', kwargs.get('q', False) and len(args)==1) :
            if kwargs.get( 'weightAliasList', kwargs.get('wal', None) ):
                res = [_general.Attribute(args[0] + '.' + attr) for attr in res]
            elif kwargs.get( 'worldUpObject', kwargs.get('wuo', None) ):
                res = _factories.unwrapToPyNode(res)
            elif kwargs.get( 'targetList', kwargs.get('tl', None) ):
                res = _factories.toPyNodeList(res)
        return res

    constraint = constraintWithWeightSyntax
    if versions.current() < versions.v2009:
        def constraintWithVectorFix(*args, **kwargs):
            """
    Maya Bug Fix:
      - when queried, upVector, worldUpVector, and aimVector returned the name of the constraint instead of the desired values

            """
            if kwargs.get( 'query', kwargs.get('q', False) and len(args)==1) :

                # Fix the big with upVector, worldUpVector, and aimVector
                attrs = [
                'upVector', 'u',
                'worldUpVector', 'wu',
                'aimVector', 'a' ]

                for attr in attrs:
                    if attr in kwargs:
                        return _general.datatypes.Vector( _general.getAttr(str(args[0]) + "." + attr ) )
            return constraintWithWeightSyntax(*args, **kwargs)
        constraintWithVectorFix.__doc__ += constraintWithWeightSyntax.__doc__
        constraint = constraintWithVectorFix

    constraint.__name__ = func.__name__
    return constraint

for contstraintCmdName in ('''aimConstraint geometryConstraint normalConstraint
                              orientConstraint parentConstraint pointConstraint
                              pointOnPolyConstraint poleVectorConstraint
                              scaleConstraint tangentConstraint''').split():
    cmd = getattr(cmds, contstraintCmdName, None)
    if cmd:
        globals()[contstraintCmdName] = _constraint(cmd)

_factories.createFunctions( __name__, _general.PyNode )



########NEW FILE########
__FILENAME__ = context
"""
Contains all context command functions (previously 'ctx').
"""

import pymel.internal.factories as _factories
_factories.createFunctions( __name__ )
########NEW FILE########
__FILENAME__ = datatypes
"""
A wrap of Maya's Vector, Point, Color, Matrix, TransformationMatrix, Quaternion, EulerRotation types
"""

import sys
import math, copy
import operator, colorsys

import pymel.util as util
import pymel.api as _api
from pymel.util.arrays import *
from pymel.util.arrays import _toCompOrArrayInstance
import pymel.internal.factories as _factories

# in python2.6/maya2010 'as' becomes a keyword.
# TODO:  add a version check:
if sys.version_info >= (2,6):
    AS_UNITS = 'asUnits'
else:
    AS_UNITS = 'as'

# patch some Maya api classes that miss __iter__ to make them iterable / convertible to list
def _patchMVector() :
    def __len__(self):
        """ Number of components in the Maya api Vector, ie 3 """
        return 3
    type.__setattr__(_api.MVector, '__len__', __len__)
    def __iter__(self):
        """ Iterates on all components of a Maya api Vector """
        for i in xrange(len(self)) :
            yield _api.MVector.__getitem__(self, i)
    type.__setattr__(_api.MVector, '__iter__', __iter__)

def _patchMFloatVector() :
    def __len__(self):
        """ Number of components in the Maya api FloatVector, ie 3 """
        return 3
    type.__setattr__(_api.MFloatVector, '__len__', __len__)
    def __iter__(self):
        """ Iterates on all components of a Maya api FloatVector """
        for i in xrange(len(self)) :
            yield _api.MFloatVector.__getitem__(self, i)
    type.__setattr__(_api.MFloatVector, '__iter__', __iter__)

def _patchMPoint() :
    def __len__(self):
        """ Number of components in the Maya api Point, ie 4 """
        return 4
    type.__setattr__(_api.MPoint, '__len__', __len__)
    def __iter__(self):
        """ Iterates on all components of a Maya api Point """
        for i in xrange(len(self)) :
            yield _api.MPoint.__getitem__(self, i)
    type.__setattr__(_api.MPoint, '__iter__', __iter__)

def _patchMFloatPoint() :
    def __len__(self):
        """ Number of components in the Maya api FloatPoint, ie 4 """
        return 4
    type.__setattr__(_api.MFloatPoint, '__len__', __len__)
    def __iter__(self):
        """ Iterates on all components of a Maya api FloatPoint """
        for i in xrange(len(self)) :
            yield _api.MFloatPoint.__getitem__(self, i)
    type.__setattr__(_api.MFloatPoint, '__iter__', __iter__)

def _patchMColor() :
    def __len__(self):
        """ Number of components in the Maya api Color, ie 4 """
        return 4
    type.__setattr__(_api.MColor, '__len__', __len__)
    def __iter__(self):
        """ Iterates on all components of a Maya api Color """
        for i in xrange(len(self)) :
            yield _api.MColor.__getitem__(self, i)
    type.__setattr__(_api.MColor, '__iter__', __iter__)

def _patchMMatrix() :
    def __len__(self):
        """ Number of rows in the Maya api Matrix, ie 4.
            Not to be confused with the number of components (16) given by the size method """
        return 4
    type.__setattr__(_api.MMatrix, '__len__', __len__)
    def __iter__(self):
        """ Iterates on all 4 rows of a Maya api Matrix """
        for r in xrange(4) :
            yield Array([_api.MScriptUtil.getDoubleArrayItem(_api.MMatrix.__getitem__(self, r), c) for c in xrange(4)])
    type.__setattr__(_api.MMatrix, '__iter__', __iter__)

def _patchMFloatMatrix() :
    def __len__(self):
        """ Number of rows in the Maya api FloatMatrix, ie 4.
            Not to be confused with the number of components (16) given by the size method """
        return 4
    type.__setattr__(_api.MFloatMatrix, '__len__', __len__)
    def __iter__(self):
        """ Iterates on all 4 rows of a Maya api FloatMatrix """
        for r in xrange(4) :
            yield Array([_api.MScriptUtil.getFloatArrayItem(_api.MFloatMatrix.__getitem__(self, r), c) for c in xrange(4)])
    type.__setattr__(_api.MFloatMatrix, '__iter__', __iter__)

def _patchMTransformationMatrix() :
    def __len__(self):
        """ Number of rows in the Maya api Matrix, ie 4.
            Not to be confused with the number of components (16) given by the size method """
        return 4
    type.__setattr__(_api.MTransformationMatrix, '__len__', __len__)
    def __iter__(self):
        """ Iterates on all 4 rows of a Maya api TransformationMatrix """
        return self.asMatrix().__iter__()
    type.__setattr__(_api.MTransformationMatrix, '__iter__', __iter__)

def _patchMQuaternion() :
    def __len__(self):
        """ Number of components in the Maya api Quaternion, ie 4 """
        return 4
    type.__setattr__(_api.MQuaternion, '__len__', __len__)
    def __iter__(self):
        """ Iterates on all components of a Maya api Quaternion """
        for i in xrange(len(self)) :
            yield _api.MQuaternion.__getitem__(self, i)
    type.__setattr__(_api.MQuaternion, '__iter__', __iter__)

def _patchMEulerRotation() :
    def __len__(self):
        """ Number of components in the Maya api EulerRotation, ie 3 """
        return 3
    type.__setattr__(_api.MEulerRotation, '__len__', __len__)
    def __iter__(self):
        """ Iterates on all components of a Maya api EulerRotation """
        for i in xrange(len(self)) :
            yield _api.MEulerRotation.__getitem__(self, i)
    type.__setattr__(_api.MEulerRotation, '__iter__', __iter__)

_patchMVector()
_patchMFloatVector()
_patchMPoint()
_patchMFloatPoint()
_patchMColor()
_patchMMatrix()
_patchMFloatMatrix()
_patchMTransformationMatrix()
_patchMQuaternion()
_patchMEulerRotation()

# the meta class of metaMayaWrapper
class MetaMayaArrayTypeWrapper(_factories.MetaMayaTypeWrapper) :
    """ A metaclass to wrap Maya array type classes such as Vector, Matrix """

    def __new__(mcl, classname, bases, classdict):
        """ Create a new wrapping class for a Maya api type, such as Vector or Matrix """

        if 'shape' in classdict :
            # fixed shape means also fixed ndim and size
            shape = classdict['shape']
            ndim = len(shape)
            size = reduce(operator.mul, shape, 1)
            if 'ndim' not in classdict :
                classdict['ndim'] = ndim
            elif classdict['ndim'] != ndim :
                raise ValueError, "class %s shape definition %s and number of dimensions definition %s do not match" % (classname, shape, ndim)
            if 'size' not in classdict :
                classdict['size'] = size
            elif classdict['size'] != size :
                raise ValueError, "class %s shape definition %s and size definition %s do not match" % (classname, shape, size)

        # create the new class
        newcls = super(MetaMayaArrayTypeWrapper, mcl).__new__(mcl, classname, bases, classdict)

        try :
            apicls = newcls.apicls
        except :
            apicls = None
        try :
            shape = newcls.shape
        except :
            shape = None
        try :
            cnames = newcls.cnames
        except :
            cnames = ()

        if shape is not None :
            # fixed shape means also fixed ndim and size
            ndim = len(shape)
            size = reduce(operator.mul, shape, 1)

            if cnames :
                # definition for component names
                type.__setattr__(newcls, 'cnames', cnames )
                subsizes = [reduce(operator.mul, shape[i+1:], 1) for i in xrange(ndim)]
                for index, compname in enumerate(cnames) :
                    coords = []
                    for i in xrange(ndim) :
                        c = index//subsizes[i]
                        index -= c*subsizes[i]
                        coords.append(c)
                    if len(coords) == 1 :
                        coords = coords[0]
                    else :
                        coords = tuple(coords)


#                    def _get(self):
#                        return self.__getitem__(coords)
#                    _get.__name__ = '_get_' + compname
#
#                    # FIXME : the set property does not do anything in python 2.4 !!!  It doesn't even get called.
#
#                    def _set(self, val):
#                        self.__setitem__(coords, val)
#
#                    _set.__name__ = '_set_' + compname
#
#                    p = property( _get, _set, None, 'set and get %s component' % compname )

                    cmd = "property( lambda self: self.__getitem__(%s) ,  lambda self, val: self.__setitem__(%s,val) )" % (coords, coords)
                    p = eval(cmd)

                    if compname not in classdict :
                        type.__setattr__(newcls, compname, p)
                    else :
                        raise AttributeError, "component name %s clashes with class method %r" % (compname, classdict[compname])
        elif cnames :
            raise ValueError, "can only define component names for classes with a fixed shape/size"

        # constants for shape, ndim, size
        if shape is not None :
            type.__setattr__(newcls, 'shape', shape)
        if ndim is not None :
            type.__setattr__(newcls, 'ndim', ndim)
        if size is not None :
            type.__setattr__(newcls, 'size', size)
        #__slots__ = ['_data', '_shape', '_size']
        # add component names to read-only list
        readonly = newcls.__readonly__
        if hasattr(newcls, 'shape') :
            readonly['shape'] = None
        if hasattr(newcls, 'ndim') :
            readonly['ndim'] = None
        if hasattr(newcls, 'size') :
            readonly['size'] = None
        if 'cnames' not in readonly :
            readonly['cnames'] = None
        type.__setattr__(newcls, '__readonly__', readonly)

#        print "created class", newcls
#        print "bases", newcls.__bases__
#        print "readonly", newcls.__readonly__
#        print "slots", newcls.__slots__
        return newcls

# generic math function that can operate on Arrays herited from arrays
# (min, max, sum, prod...)

# Functions that work on vectors will now be inherited from Array and properly defer
# to the class methods


class Vector(VectorN) :
    """
    A 3 dimensional vector class that wraps Maya's api Vector class

        >>> from pymel.all import *
        >>> import pymel.core.datatypes as dt
        >>>
        >>> v = dt.Vector(1, 2, 3)
        >>> w = dt.Vector(x=1, z=2)
        >>> z = dt.Vector( dt.Vector.xAxis, z=1)

        >>> v = dt.Vector(1, 2, 3, unit='meters')
        >>> print v
        [1.0, 2.0, 3.0]
    """
    __metaclass__ = MetaMayaArrayTypeWrapper
    __slots__ = ()
    # class specific info
    apicls = _api.MVector
    cnames = ('x', 'y', 'z')
    shape = (3,)
    unit = None
    def __new__(cls, *args, **kwargs):
        shape = kwargs.get('shape', None)
        ndim = kwargs.get('ndim', None)
        size = kwargs.get('size', None)
        # will default to class constant shape = (3,), so it's just an error check to catch invalid shapes,
        # as no other option is actually possible on Vector, but this method could be used to allow wrapping
        # of Maya array classes that can have a variable number of elements
        shape, ndim, size = cls._expandshape(shape, ndim, size)

        new = cls.apicls.__new__(cls)
        cls.apicls.__init__(new)
        return new

    def __init__(self, *args, **kwargs):
        """ __init__ method, valid for Vector, Point and Color classes """
        cls = self.__class__

        if args :
            # allow both forms for arguments
            if len(args)==1 and hasattr(args[0], '__iter__') :
                args = args[0]
            # shortcut when a direct api init is possible
            try :
                self.assign(args)
            except :
                # special exception to the rule that you cannot drop data in Arrays __init__
                # to allow all conversion from Vector derived classes (MPoint, MColor) to a base class
                # special case for MPoint to cartesianize if necessary
                # note : we may want to premultiply MColor by the alpha in a similar way
                if isinstance(args, _api.MPoint) and args.w != 1.0 :
                    args = copy.deepcopy(args).cartesianize()
                if isinstance(args, _api.MColor) and args.a != 1.0 :
                    # note : we may want to premultiply Color by the alpha in a similar way
                    pass
                if isinstance(args, _api.MVector) or isinstance(args, _api.MPoint) or isinstance(args, _api.MColor) :
                    args = tuple(args)
                    if len(args) > len(self) :
                        args = args[slice(self.shape[0])]
                super(Vector, self).__init__(*args)

        if hasattr(cls, 'cnames') and len(set(cls.cnames) & set(kwargs)) :
            # can also use the form <componentname>=<number>
            l = list(self.flat)
            setcomp = False
            for i, c in enumerate(cls.cnames) :
                if c in kwargs :
                    if float(l[i]) != float(kwargs[c]) :
                        l[i] = float(kwargs[c])
                        setcomp = True
            if setcomp :
                try :
                    self.assign(l)
                except :
                    msg = ", ".join(map(lambda x,y:x+"=<"+util.clsname(y)+">", cls.cnames, l))
                    raise TypeError, "in %s(%s), at least one of the components is of an invalid type, check help(%s) " % (cls.__name__, msg, cls.__name__)

        # units handling
        self.unit = kwargs.get('unit', None)
        if self.unit is not None :
            self.assign([Distance(x, self.unit) for x in self])

    def __repr__(self):
        if hasattr( self, 'unit' ) and self.unit:
            return "dt.%s(%s, unit='%s')" % (self.__class__.__name__, str(self), self.unit)
        else:
            return "dt.%s(%s)" % (self.__class__.__name__, str(self))


    # for compatibility with base classes Array that actually hold a nested list in their _data attribute
    # here, there is no _data attribute as we subclass _api.MVector directly, thus v.data is v
    # for wraps

    def _getdata(self):
        return self.apicls(self)
    def _setdata(self, value):
        self.assign(value)
    def _deldata(self):
        if hasattr(self.apicls, 'clear') :
            self.apicls.clear(self)
        else :
            raise TypeError, "cannot clear stored elements of %s" % (self.__class__.__name__)

    data = property(_getdata, _setdata, _deldata, "The Vector/FloatVector/Point/FloatPoint/Color data")

    # overloads for assign and get though standard way should be to use the data property
    # to access stored values

    def assign(self, value):
        """ Wrap the Vector api assign method """
        # don't accept instances as assign works on exact types
        if type(value) != self.apicls and type(value) != type(self) :
            if not hasattr(value, '__iter__') :
                value = (value,)
            value = self.apicls(*value)
        self.apicls.assign(self, value)
        return self

    # API get, actually not faster than pulling self[i] for such a short structure
    def get(self):
        """ Wrap the Vector api get method """
        # need to keep a ref to the MScriptUtil alive until
        # all pointers aren't needed...
        ms = _api.MScriptUtil()
        l = (0,)*self.size
        ms.createFromDouble ( *l )
        p = ms.asDoublePtr ()
        self.apicls.get(self, p)
        return tuple([ms.getDoubleArrayItem ( p, i ) for i in xrange(self.size)])

    def __len__(self):
        """ Number of components in the Vector instance, 3 for Vector, 4 for Point and Color """
        return self.apicls.__len__(self)

    # __getitem__ / __setitem__ override

    # faster to override __getitem__ cause we know Vector only has one dimension
    def __getitem__(self, i):
        """ Get component i value from self """
        if hasattr(i, '__iter__') :
            i = list(i)
            if len(i) == 1 :
                i = i[0]
            else :
                raise IndexError, "class %s instance %s has only %s dimension(s), index %s is out of bounds" % (util.clsname(self), self, self.ndim, i)
        if isinstance(i, slice) :
            return _toCompOrArrayInstance(list(self)[i], VectorN)
            try :
                return _toCompOrArrayInstance(list(self)[i], VectorN)
            except :
                raise IndexError, "class %s instance %s is of size %s, index %s is out of bounds" % (util.clsname(self), self, self.size, i)
        else :
            if i < 0 :
                i = self.size + i
            if i<self.size and not i<0 :
                if hasattr(self.apicls, '__getitem__') :
                    return self.apicls.__getitem__(self, i)
                else :
                    return list(self)[i]
            else :
                raise IndexError, "class %s instance %s is of size %s, index %s is out of bounds" % (util.clsname(self), self, self.size, i)

    # as _api.Vector has no __setitem__ method, so need to reassign the whole Vector
    def __setitem__(self, i, a):
        """ Set component i value on self """
        v = VectorN(self)
        v.__setitem__(i, a)
        self.assign(v)

    # iterator override

    # TODO : support for optional __iter__ arguments
    def __iter__(self, *args, **kwargs):
        """ Iterate on the api components """
        return self.apicls.__iter__(self.data)
    def __contains__(self, value):
        """ True if at least one of the vector components is equal to the argument """
        return value in self.__iter__()

    # common operators without an api equivalent are herited from VectorN

    # operators using the Maya API when applicable, but that can delegate to VectorN

    def __eq__(self, other):
        """ u.__eq__(v) <==> u == v
            Equivalence test """
        try :
            return bool(self.apicls.__eq__(self, other))
        except Exception:
            return bool(super(Vector, self).__eq__(other))
    def __ne__(self, other):
        """ u.__ne__(v) <==> u != v
            Equivalence test """
        return (not self.__eq__(other))
    def __neg__(self):
        """ u.__neg__() <==> -u
            The unary minus operator. Negates the value of each of the components of u """
        return self.__class__(self.apicls.__neg__(self))
    def __add__(self, other) :
        """ u.__add__(v) <==> u+v
            Returns the result of the addition of u and v if v is convertible to a VectorN (element-wise addition),
            adds v to every component of u if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__add__(self, other))
        except Exception:
            return self.__class__._convert(super(Vector, self).__add__(other))
    def __radd__(self, other) :
        """ u.__radd__(v) <==> v+u
            Returns the result of the addition of u and v if v is convertible to a VectorN (element-wise addition),
            adds v to every component of u if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__radd__(self, other))
        except Exception:
            return self.__class__._convert(super(Vector, self).__radd__(other))
    def __iadd__(self, other):
        """ u.__iadd__(v) <==> u += v
            In place addition of u and v, see __add__ """
        try :
            return self.__class__(self.__add__(other))
        except Exception:
            return NotImplemented
    def __sub__(self, other) :
        """ u.__sub__(v) <==> u-v
            Returns the result of the substraction of v from u if v is convertible to a VectorN (element-wise substration),
            substract v to every component of u if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__sub__(self, other))
        except Exception:
            return self.__class__._convert(super(Vector, self).__sub__(other))
    def __rsub__(self, other) :
        """ u.__rsub__(v) <==> v-u
            Returns the result of the substraction of u from v if v is convertible to a VectorN (element-wise substration),
            replace every component c of u by v-c if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__rsub__(self, other))
        except Exception:
            return self.__class__._convert(super(Vector, self).__rsub__(other))
    def __isub__(self, other):
        """ u.__isub__(v) <==> u -= v
            In place substraction of u and v, see __sub__ """
        try :
            return self.__class__(self.__sub__(other))
        except Exception:
            return NotImplemented
    def __div__(self, other):
        """ u.__div__(v) <==> u/v
            Returns the result of the division of u by v if v is convertible to a VectorN (element-wise division),
            divide every component of u by v if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__div__(self, other))
        except Exception:
            return self.__class__._convert(super(Vector, self).__div__(other))
    def __rdiv__(self, other):
        """ u.__rdiv__(v) <==> v/u
            Returns the result of of the division of v by u if v is convertible to a VectorN (element-wise division),
            invert every component of u and multiply it by v if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__rdiv__(self, other))
        except Exception:
            return self.__class__._convert(super(Vector, self).__rdiv__(other))
    def __idiv__(self, other):
        """ u.__idiv__(v) <==> u /= v
            In place division of u by v, see __div__ """
        try :
            return self.__class__(self.__div__(other))
        except Exception:
            return NotImplemented
    # action depends on second object type
    def __mul__(self, other) :
        """ u.__mul__(v) <==> u*v
            The multiply '*' operator is mapped to the dot product when both objects are Vectors,
            to the transformation of u by matrix v when v is a MatrixN,
            to element wise multiplication when v is a sequence,
            and multiplies each component of u by v when v is a numeric type. """
        try :
            res = self.apicls.__mul__(self, other)
            assert res is not NotImplemented
        except Exception:
            res = super(Vector, self).__mul__(other)
        if util.isNumeric(res) or res is NotImplemented:
            return res
        else :
            return self.__class__._convert(res)

    def __rmul__(self, other):
        """ u.__rmul__(v) <==> v*u
            The multiply '*' operator is mapped to the dot product when both objects are Vectors,
            to the left side multiplication (pre-multiplication) of u by matrix v when v is a MatrixN,
            to element wise multiplication when v is a sequence,
            and multiplies each component of u by v when v is a numeric type. """
        try :
            res = self.apicls.__rmul__(self, other)
        except :
            res = super(Vector, self).__rmul__(other)
        if util.isNumeric(res) :
            return res
        else :
            return self.__class__._convert(res)
    def __imul__(self, other):
        """ u.__imul__(v) <==> u *= v
            Valid for Vector * Matrix multiplication, in place transformation of u by Matrix v
            or Vector by scalar multiplication only """
        try :
            return self.__class__(self.__mul__(other))
        except :
            return NotImplemented
    # special operators
    def __xor__(self, other):
        """ u.__xor__(v) <==> u^v
            Defines the cross product operator between two 3D vectors,
            if v is a MatrixN, u^v is equivalent to u.transformAsNormal(v) """
        if isinstance(other, VectorN) :
            return self.cross(other)
        elif isinstance(other, MatrixN) :
            return self.transformAsNormal(other)
        else :
            return NotImplemented
    def __ixor__(self, other):
        """ u.__xor__(v) <==> u^=v
            Inplace cross product or transformation by inverse transpose of v is v is a MatrixN """
        try :
            return self.__class__(self.__xor__(other))
        except :
            return NotImplemented

    # wrap of other API MVector methods, we use the api method if possible and delegate to Vector else

    def isEquivalent(self, other, tol=None):
        """ Returns true if both arguments considered as Vector are equal within the specified tolerance """
        if tol is None :
            tol = _api.MVector_kTol
        try :
            nself, nother = coerce(self, other)
        except :
            return False
        if isinstance(nself, Vector) :
            return bool(nself.apicls.isEquivalent(nself, nother, tol))
        else :
            return bool(super(Vector, nself).isEquivalent(nother, tol))
    def isParallel(self, other, tol=None):
        """ Returns true if both arguments considered as Vector are parallel within the specified tolerance """
        if tol is None :
            tol = _api.MVector_kTol
        try :
            return bool(self.apicls.isParallel(Vector(self), Vector(other), tol))
        except :
            return super(Vector, self).isParallel(other, tol)
    def distanceTo(self, other):
        try :
            return self.apicls.distanceTo(Point(self), Point(other))
        except :
            return super(Vector, self).dist(other)
    def length(self):
        """ Return the length of the vector """
        return Vector.apicls.length(Vector(self))
    def sqlength(self):
        """ Return the square length of the vector """
        return self.dot(self)
    def normal(self):
        """ Return a normalized copy of self """
        return self.__class__(Vector.apicls.normal(Vector(self)))
    def normalize(self):
        """ Performs an in place normalization of self """
        if type(self) is Vector :
            Vector.apicls.normalize(self)
        else :
            self.assign(self.normal())

    # additional api methods that work on Vector only, and don't have an equivalent on VectorN

    def rotateTo(self, other):
        """ u.rotateTo(v) --> Quaternion
            Returns the Quaternion that represents the rotation of the Vector u into the Vector v
            around their mutually perpendicular axis. It amounts to rotate u by angle(u, v) around axis(u, v) """
        if isinstance(other, Vector) :
            return Quaternion(Vector.apicls.rotateTo(Vector(self), Vector(other)))
        else :
            raise TypeError, "%r is not a Vector instance" % other
    def rotateBy(self, *args):
        """ u.rotateBy(*args) --> Vector
            Returns the result of rotating u by the specified arguments.
            There are several ways the rotation can be specified:
            args is a tuple of one Matrix, TransformationMatrix, Quaternion, EulerRotation
            arg is tuple of 4 arguments, 3 rotation value and an optionnal rotation order
            args is a tuple of one Vector, the axis and one float, the angle to rotate around that axis in radians"""
        if args :
            if len(args) == 2 and isinstance(args[0], Vector) :
                return self.__class__(self.apicls.rotateBy(self, Quaternion(Vector(args[0]), float(args[1]))))
            elif len(args) == 1 and isinstance(args[0], Matrix) :
                return self.__class__(self.apicls.rotateBy(self, args[0].rotate))
            else :
                return self.__class__(self.apicls.rotateBy(self, EulerRotation(unit='radians', *args)))
        else :
            return self

#    def asUnit(self, unit) :
#        #kUnit = Distance.kUnit(unit)
#        return self.__class__( [ Distance(x).asUnit(unit) for x in self ]  )
#
#    def asUnit(self) :
#        return self.asUnit(self.unit)
#
#    def asUIUnit()nits()self) :
#        return self.asUnit(Distance.getUIUnit())
#
#    def asInternalUnit(self) :
#        return self.asUnit(Distance.getInternalUnit())
#
#    def asMillimeter(self) :
#        return self.asUnit('millimeter')
#    def asCentimeters(self) :
#        return self.asUnit('centimeters')
#    def asKilometers(self) :
#        return self.asUnit('kilometers')
#    def asMeters(self) :
#        return self.asUnit('meters')
#
#    def asInches(self) :
#        return self.asUnit('inches')
#    def asFeet(self) :
#        return self.asUnit('feet')
#    def asYards(self) :
#        return self.asUnit('yards')
#    def asMiles(self) :
#        return self.asUnit('miles')

    # additional api methods that work on Vector only, but can also be delegated to VectorN

    def transformAsNormal(self, other):
        """ Returns the vector transformed by the matrix as a normal
            Normal vectors are not transformed in the same way as position vectors or points.
            If this vector is treated as a normal vector then it needs to be transformed by
            post multiplying it by the inverse transpose of the transformation matrix.
            This method will apply the proper transformation to the vector as if it were a normal. """
        if isinstance(other, Matrix) :
            return self.__class__._convert(Vector.apicls.transformAsNormal(Vector(self), Matrix(other)))
        else :
            return self.__class__._convert(super(Vector, self).transformAsNormal(other))
    def dot(self, other):
        """ dot product of two vectors """
        if isinstance(other, Vector) :
            return Vector.apicls.__mul__(Vector(self), Vector(other))
        else :
            return super(Vector, self).dot(other)
    def cross(self, other):
        """ cross product, only defined for two 3D vectors """
        if isinstance(other, Vector) :
            return self.__class__._convert(Vector.apicls.__xor__(Vector(self), Vector(other)))
        else :
            return self.__class__._convert(super(Vector, self).cross(other))
    def axis(self, other, normalize=False):
        """ u.axis(v) <==> angle(u, v) --> Vector
            Returns the axis of rotation from u to v as the vector n = u ^ v
            if the normalize keyword argument is set to True, n is also normalized """
        if isinstance(other, Vector) :
            if normalize :
                return self.__class__._convert(Vector.apicls.__xor__(Vector(self), Vector(other)).normal())
            else :
                return self.__class__._convert(Vector.apicls.__xor__(Vector(self), Vector(other)))
        else :
            return self.__class__._convert(super(Vector, self).axis(other, normalize))
    def angle(self, other):
        """ u.angle(v) <==> angle(u, v) --> float
            Returns the angle (in radians) between the two vectors u and v
            Note that this angle is not signed, use axis to know the direction of the rotation """
        if isinstance(other, Vector) :
            return Vector.apicls.angle(Vector(self), Vector(other))
        else :
            return super(Vector, self).angle(other)

    # methods without an api equivalent

    # cotan on MVectors only takes 2 arguments
    def cotan(self, other):
        """ u.cotan(v) <==> cotan(u, v) --> float :
            cotangent of the a, b angle, a and b should be MVectors"""
        return VectorN.cotan(self, other)

    # rest derived from VectorN class

class FloatVector(Vector) :
    """ A 3 dimensional vector class that wraps Maya's api FloatVector class,
        It behaves identically to Vector, but it also derives from api's FloatVector
        to keep api methods happy
        """
    apicls = _api.MFloatVector

# Point specific functions

def planar(p, *args, **kwargs):
    """ planar(p[, q, r, s (...), tol=tolerance]) --> bool
        Returns True if all provided MPoints are planar within given tolerance """
    if not isinstance(p, Point) :
        try :
            p = Point(p)
        except :
            raise TypeError, "%s is not convertible to type Point, planar is only defined for n MPoints" % (util.clsname(p))
    return p.planar(*args, **kwargs)
def center(p, *args):
    """ center(p[, q, r, s (...)]) --> Point
        Returns the Point that is the center of p, q, r, s (...) """
    if not isinstance(p, Point) :
        try :
            p = Point(p)
        except :
            raise TypeError, "%s is not convertible to type Point, center is only defined for n MPoints" % (util.clsname(p))
    return p.center(*args)
def bWeights(p, *args):
    """ bWeights(p[, p0, p1, (...), pn]) --> tuple
        Returns a tuple of (n0, n1, ...) normalized barycentric weights so that n0*p0 + n1*p1 + ... = p  """
    if not isinstance(p, Point) :
        try :
            p = Point(p)
        except :
            raise TypeError, "%s is not convertible to type Point, bWeights is only defined for n MPoints" % (util.clsname(p))
    return p.bWeights(*args)


class Point(Vector):
    """ A 4 dimensional vector class that wraps Maya's api Point class,
        """
    apicls = _api.MPoint
    cnames = ('x', 'y', 'z', 'w')
    shape = (4,)

    def __melobject__(self):
        """Special method for returning a mel-friendly representation. In this case, a cartesian 3D point """
        return self.cartesian()

#    # base methods are inherited from Vector

    # we only show the x, y, z components on an iter
    def __len__(self):
        l = len(self.data)
        if self.w == 1.0 :
            l -= 1
        return l

    def __iter__(self, *args, **kwargs):
        """ Iterate on the api components """
        l = len(self)
        for c in list(self.apicls.__iter__(self.data))[:l] :
            yield c

    # modified operators, when adding 2 Point consider second as Vector
    def __add__(self, other) :
        """ u.__add__(v) <==> u+v
            Returns the result of the addition of u and v if v is convertible to a VectorN (element-wise addition),
            adds v to every component of u if v is a scalar """
        # prb with coerce when delegating to VectorN, either redefine coerce for Point or other fix
        # if isinstance(other, Point) :
        #    other = Vector(other)
        try :
            other = Vector(other)
        except :
            pass
        try :
            return self.__class__._convert(self.apicls.__add__(self, other))
        except :
            return self.__class__._convert(super(Vector, self).__add__(other))
    def __radd__(self, other) :
        """ u.__radd__(v) <==> v+u
            Returns the result of the addition of u and v if v is convertible to a VectorN (element-wise addition),
            adds v to every component of u if v is a scalar """
        if isinstance(other, Point) :
            other = Vector(other)
        try :
            return self.__class__._convert(self.apicls.__radd__(self, other))
        except :
            return self.__class__._convert(super(Point, self).__radd__(other))
    def __iadd__(self, other):
        """ u.__iadd__(v) <==> u += v
            In place addition of u and v, see __add__ """
        try :
            return self.__class__(self.__add__(other))
        except :
            return NotImplemented


    # specific api methods
    def cartesianize (self) :
        """ p.cartesianize() --> Point
            If the point instance p is of the form P(W*x, W*y, W*z, W), for some scale factor W != 0,
            then it is reset to be P(x, y, z, 1).
            This will only work correctly if the point is in homogenous form or cartesian form.
            If the point is in rational form, the results are not defined. """
        return self.__class__(self.apicls.cartesianize(self))
    def cartesian (self) :
        """ p.cartesian() --> Point
            Returns the cartesianized version of p, without changing p. """
        t = copy.deepcopy(self)
        self.apicls.cartesianize(t)
        return t
    def rationalize (self) :
        """ p.rationalize() --> Point
            If the point instance p is of the form P(W*x, W*y, W*z, W) (ie. is in homogenous or (for W==1) cartesian form),
            for some scale factor W != 0, then it is reset to be P(x, y, z, W).
            This will only work correctly if the point is in homogenous or cartesian form.
            If the point is already in rational form, the results are not defined. """
        return self.__class__(self.apicls.rationalize(self))
    def rational (self) :
        """ p.rational() --> Point
            Returns the rationalized version of p, without changing p. """
        t = copy.deepcopy(self)
        self.apicls.rationalize(t)
        return t
    def homogenize (self) :
        """ p.homogenize() --> Point
            If the point instance p is of the form P(x, y, z, W) (ie. is in rational or (for W==1) cartesian form),
            for some scale factor W != 0, then it is reset to be P(W*x, W*y, W*z, W). """
        return self.__class__(self.apicls.homogenize(self))
    def homogen (self) :
        """ p.homogen() --> Point
            Returns the homogenized version of p, without changing p. """
        t = copy.deepcopy(self)
        self.apicls.homogenize(t)
        return t

    # additionnal methods

    def isEquivalent(self, other, tol=None):
        """ Returns true if both arguments considered as Point are equal within the specified tolerance """
        if tol is None :
            tol = _api.MPoint_kTol
        try :
            nself, nother = coerce(self, other)
        except :
            return False
        if isinstance(nself, Point) :
            return bool(nself.apicls.isEquivalent(nself, nother, tol))
        else :
            return bool(super(Point, nself).isEquivalent(nother, tol))
    def axis(self, start, end, normalize=False):
        """ a.axis(b, c) --> Vector
            Returns the axis of rotation from point b to c around a as the vector n = (b-a)^(c-a)
            if the normalize keyword argument is set to True, n is also normalized """
        return Vector.axis(start-self, end-self, normalize=normalize)
    def angle(self, start, end):
        """ a.angle(b, c) --> float
            Returns the angle (in radians) of rotation from point b to c around a.
            Note that this angle is not signed, use axis to know the direction of the rotation """
        return Vector.angle(start-self, end-self)
    def cotan(self, start, end):
        """ a.cotan(b, c) --> float :
            cotangent of the (b-a), (c-a) angle, a, b, and c should be MPoints representing points a, b, c"""
        return VectorN.cotan(start-self, end-self)
    def planar(self, *args, **kwargs):
        """ p.planar(q, r, s (...), tol=tolerance) --> bool
            Returns True if all provided points are planar within given tolerance """
        if len(args) > 2 :
            tol = kwargs.get('tol', None)
            n = (args[0]-self)^(args[1]-self)
            return reduce(operator.and_, map(lambda x:n.isParallel(x, tol), [(args[0]-self)^(a-self) for a in args[2:]]), True)
        else :
            return True
    def center(self, *args):
        """ p.center(q, r, s (...)) --> Point
            Returns the Point that is the center of p, q, r, s (...) """
        return sum((self,)+args) / float(len(args) + 1)
    def bWeights(self, *args):
        """ p.bWeights(p0, p1, (...), pn) --> tuple
            Returns a tuple of (n0, n1, ...) normalized barycentric weights so that n0*p0 + n1*p1 + ... = p.
            This method works for n points defining a concave or convex n sided face,
            always returns positive normalized weights, and is continuous on the face limits (on the edges),
            but the n points must be coplanar, and p must be inside the face delimited by (p0, ..., pn) """
        if args :
            p = self
            q = list(args)
            np = len(q)
            w = VectorN(0.0, size=np)
            weightSum = 0.0
            pOnEdge = False;
            tol = _api.MPoint_kTol
            # all args should be MPoints
            for i in xrange(np) :
                if not isinstance(q[i], Point) :
                    try :
                        q[i] = Point(q[i])
                    except :
                        raise TypeError, "cannot convert %s to Point, bWeights is defined for n MPoints" % (util.clsname(q[i]))
            # if p sits on an edge, it' a limit case and there is an easy solution,
            # all weights are 0 but for the 2 edge end points
            for i in xrange(np) :
                next = (i+1) % np

                e = ((q[next]-q[i]) ^ (p-q[i])).sqlength()
                l = (q[next]-q[i]).sqlength()
                if e <= (tol * l) :
                    if l < tol :
                        # p is on a 0 length edge, point and next point are on top of each other, as is p then
                        w[i] = 0.5
                        w[next] = 0.5
                    else :
                        # p is somewhere on that edge between point and next point
                        di = (p-q[i]).length()
                        w[next] = float(di / sqrt(l))
                        w[i] = 1.0 - w[next]
                    # in both case update the weights sum and mark p as being on an edge,
                    # problem is solved
                    weightSum += 1.0
                    pOnEdge = True
                    break
            # If p not on edge, use the cotangents method
            if not pOnEdge :
                for i in xrange(np) :
                    prev = (i+np-1) % np
                    next = (i+1) % np

                    lenSq = (p - q[i]).sqlength()
                    w[i] = ( q[i].cotan(p, q[prev]) + q[i].cotan(p, q[next]) ) / lenSq
                    weightSum += w[i]

            # then normalize result
            if abs(weightSum) :
                w /= weightSum
            else :
                raise ValueError, "failed to compute bWeights for %s and %s.\nThe point bWeights are computed for must be inside the planar face delimited by the n argument points" % (self, args)

            return tuple(w)
        else :
            return ()


class FloatPoint(Point) :
    """ A 4 dimensional vector class that wraps Maya's api FloatPoint class,
        It behaves identically to Point, but it also derives from api's FloatPoint
        to keep api methods happy
        """
    apicls = _api.MFloatPoint


class Color(Vector):
    """ A 4 dimensional vector class that wraps Maya's api Color class,
        It stores the r, g, b, a components of the color, as normalized (Python) floats
        """
    apicls = _api.MColor
    cnames = ('r', 'g', 'b', 'a')
    shape = (4,)
    # modes = ('rgb', 'hsv', 'cmy', 'cmyk')
    modes = ('rgb', 'hsv')

    # constants
    red = _api.MColor(1.0, 0.0, 0.0)
    green = _api.MColor(0.0, 1.0, 0.0)
    blue = _api.MColor(0.0, 0.0, 1.0)
    white = _api.MColor(1.0, 1.0, 1.0)
    black = _api.MColor(0.0, 0.0, 0.0)
    opaque = _api.MColor(0.0, 0.0, 0.0, 1.0)
    clear = _api.MColor(0.0, 0.0, 0.0, 0.0)

    # static methods
    @staticmethod
    def rgbtohsv(c):
        c = tuple(c)
        return tuple(colorsys.rgb_to_hsv(*clamp(c[:3]))+c[3:4])
    @staticmethod
    def hsvtorgb(c):
        c = tuple(c)
        # return colorsys.hsv_to_rgb(clamp(c[0]), clamp(c[1]), clamp(c[2]))
        return tuple(colorsys.hsv_to_rgb(*clamp(c[:3]))+c[3:4])

    # TODO : could define rgb and hsv iterators and allow __setitem__ and __getitem__ on these iterators
    # like (it's more simple) it's done in ArrayIter
    def _getrgba(self):
        return tuple(self)
    def _setrgba(self, value):
        if not hasattr(value, '__iter__') :
            # the way api interprets a single value
            # value = (None, None, None, value)
            value = (value,)*4
        l = list(self)
        for i, v in enumerate(value[:4]) :
            if v is not None :
                l[i] = float(v)
        self.assign(*l)
    rgba = property(_getrgba, _setrgba, None, "The r,g,b,a Color components""")
    def _getrgb(self):
        return self.rgba[:3]
    def _setrgb(self, value):
        if not hasattr(value, '__iter__') :
            value = (value,)*3
        self.rgba = value[:3]
    rgb = property(_getrgb, _setrgb, None, "The r,g,b Color components""")

    def _gethsva(self):
        return tuple(Color.rgbtohsv(self))
    def _sethsva(self, value):
        if not hasattr(value, '__iter__') :
            # the way api interprets a single value
            # value = (None, None, None, value)
            value = (value,)*4
        l = list(Color.rgbtohsv(self))
        for i, v in enumerate(value[:4]) :
            if v is not None :
                l[i] = float(v)
        self.assign(*Color.hsvtorgb(self))
    hsva = property(_gethsva, _sethsva, None, "The h,s,v,a Color components""")
    def _gethsv(self):
        return tuple(Color.rgbtohsv(self))[:3]
    def _sethsv(self, value):
        if not hasattr(value, '__iter__') :
            value = (value,)*3
        self.hsva = value[:3]
    hsv = property(_gethsv, _sethsv, None, "The h,s,v,a Color components""")
    def _geth(self):
        return self.hsva[0]
    def _seth(self, value):
        self.hsva = (value, None, None, None)
    h = property(_geth, _seth, None, "The h Color component""")
    def _gets(self):
        return self.hsva[1]
    def _sets(self, value):
        self.hsva = (None, value, None, None)
    s = property(_gets, _sets, None, "The s Color component""")
    def _getv(self):
        return self.hsva[2]
    def _setv(self, value):
        self.hsva = (None, None, value, None)
    v = property(_getv, _setv, None, "The v Color component""")

    # __new__ is herited from Point/Vector, need to override __init__ to accept hsv mode though

    def __init__(self, *args, **kwargs):
        """ Init a Color instance
            Can pass one argument being another Color instance , or the color components """
        cls = self.__class__
        mode = kwargs.get('mode', None)
        if mode is not None and mode not in cls.modes :
            raise ValueError, "unknown mode %s for %s" % (mode, util.clsname(self))
        # can also use the form <componentname>=<number>
        # for now supports only rgb and hsv flags
        hsvflag = {}
        rgbflag = {}
        for a in 'hsv' :
            if a in kwargs :
                hsvflag[a] = kwargs[a]
        for a in 'rgb' :
            if a in kwargs :
                rgbflag[a] = kwargs[a]
        # can't mix them
        if hsvflag and rgbflag :
            raise ValueError, "can not mix r,g,b and h,s,v keyword arguments in a %s declaration" % util.clsname(self)
        # if no mode specified, guess from what keyword arguments where used, else use 'rgb' as default
        if mode is None :
            if hsvflag :
                mode = 'hsv'
            else :
                mode = 'rgb'
        # can't specify a mode and use keywords of other modes
        if mode is not 'hsv' and hsvflag :
            raise ValueError, "Can not use h,s,v keyword arguments while specifying %s mode in %s" % (mode, util.clsname(self))
        elif mode is not 'rgb' and rgbflag :
            raise ValueError, "Can not use r,g,b keyword arguments while specifying %s mode in %s" % (mode, util.clsname(self))
        # NOTE: do not try to use mode with _api.Color, it seems bugged as of 2008
            #import colorsys
            #colorsys.rgb_to_hsv(0.0, 0.0, 1.0)
            ## Result: (0.66666666666666663, 1.0, 1.0) #
            #c = _api.Color(_api.Color.kHSV, 0.66666666666666663, 1.0, 1.0)
            #print "# Result: ",c[0], c[1], c[2], c[3]," #"
            ## Result:  1.0 0.666666686535 1.0 1.0  #
            #c = _api.Color(_api.Color.kHSV, 0.66666666666666663*360, 1.0, 1.0)
            #print "# Result: ",c[0], c[1], c[2], c[3]," #"
            ## Result:  1.0 240.0 1.0 1.0  #
            #colorsys.hsv_to_rgb(0.66666666666666663, 1.0, 1.0)
            ## Result: (0.0, 0.0, 1.0) #
        # we'll use Color only to store RGB values internally and do the conversion a read/write if desired
        # which I think make more sense anyway
        # quantize (255, 65535, no quantize means colors are 0.0-1.0 float values)
        # Initializing api's Color with int values seems also not to always behave so we quantize first and
        # use a float init always
        quantize = kwargs.get('quantize', None)
        if quantize is not None :
            try :
                quantize = float(quantize)
            except :
                raise ValueError, "quantize must be a numeric value, not %s" % (util.clsname(quantize))
        # can be initilized with a single argument (other Color, Vector, VectorN)
        if len(args)==1 :
            args = args[0]
        # we dont rely much on Color api as it doesn't seem totally finished, and do some things directly here
        if isinstance(args, self.__class__) or isinstance(args, self.apicls) :
            # alternatively could be just ignored / output as warning
            if quantize :
                raise ValueError, "Can not quantize a Color argument, a Color is always stored internally as float color" % (mode, util.clsname(self))
            if mode == 'rgb' :
                args = VectorN(args)
            elif mode == 'hsv' :
                args = VectorN(cls.rgbtohsv(args))
        else :
            # single alpha value, as understood by api will break coerce behavior in operations
            # where other operand is a scalar
            #if not hasattr(args, '__iter__') :
            #    args = VectorN(0.0, 0.0, 0.0, args)
            if hasattr(args, '__len__') :
                shape = (min(len(args), cls.size),)
            else :
                shape = cls.shape
            args = VectorN(args, shape=shape)
            # quantize if needed
            if quantize :
                args /= quantize
            # pad to a full Color size
            args.stack(self[len(args):])

        # apply keywords arguments, and convert if mode is not rgb
        if mode == 'rgb' :
            if rgbflag :
                for i, a in enumerate('rgb') :
                    if a in rgbflag :
                        if quantize :
                            args[i] = float(rgbflag[a]) / quantize
                        else :
                            args[i] = float(rgbflag[a])
        elif mode == 'hsv' :
            if hsvflag :
                for i, a in enumerate('hsv') :
                    if a in hsvflag :
                        if quantize :
                            args[i] = float(hsvflag[a]) / quantize
                        else :
                            args[i] = float(hsvflag[a])
            args = VectorN(cls.hsvtorgb(args))
        # finally alpha keyword
        a = kwargs.get('a', None)
        if a is not None :
            if quantize :
                args[-1] = float(a) / quantize
            else :
                args[-1] = float(a)

        try :
            self.assign(args)
        except :
            msg = ", ".join(map(lambda x,y:x+"=<"+util.clsname(y)+">", mode, args))
            raise TypeError, "in %s(%s), at least one of the components is of an invalid type, check help(%s) " % (util.clsname(self), msg, util.clsname(self))

    def __melobject__(self):
        """Special method for returning a mel-friendly representation. In this case, a 3-component color (RGB) """
        return [self.r, self.g, self.b]

    # overriden operators

    # defined for two MColors only
    def __add__(self, other) :
        """ c.__add__(d) <==> c+d
            Returns the result of the addition of MColors c and d if d is convertible to a Color,
            adds d to every component of c if d is a scalar """
        # prb with coerce when delegating to VectorN, either redefine coerce for Point or other fix
        # if isinstance(other, Point) :
        #    other = Vector(other)
        try :
            other = Color(other)
        except :
            pass
        try :
            return self.__class__._convert(self.apicls.__add__(self, other))
        except :
            return self.__class__._convert(super(Vector, self).__add__(other))
    def __radd__(self, other) :
        """ c.__radd__(d) <==> d+c
            Returns the result of the addition of MColors c and d if d is convertible to a Color,
            adds d to every component of c if d is a scalar """
        try :
            other = Color(other)
        except :
            pass
        try :
            return self.__class__._convert(self.apicls.__radd__(self, other))
        except :
            return self.__class__._convert(super(Point, self).__radd__(other))
    def __iadd__(self, other):
        """ c.__iadd__(d) <==> c += d
            In place addition of c and d, see __add__ """
        try :
            return self.__class__(self.__add__(other))
        except :
            return NotImplemented
    def __sub__(self, other) :
        """ c.__add__(d) <==> c+d
            Returns the result of the substraction of Color d from c if d is convertible to a Color,
            substract d from every component of c if d is a scalar """
        try :
            other = Color(other)
        except :
            pass
        try :
            return self.__class__._convert(self.apicls.__sub__(self, other))
        except :
            return self.__class__._convert(super(Vector, self).__sub__(other))
    def __rsub__(self, other) :
        """ c.__rsub__(d) <==> d-c
            Returns the result of the substraction of Color c from d if d is convertible to a Color,
            replace every component c[i] of c by d-c[i] if d is a scalar """
        try :
            other = Color(other)
        except :
            pass
        try :
            return self.__class__._convert(self.apicls.__rsub__(self, other))
        except :
            return self.__class__._convert(super(Point, self).__rsub__(other))
    def __isub__(self, other):
        """ c.__isub__(d) <==> c -= d
            In place substraction of d from c, see __sub__ """
        try :
            return self.__class__(self.__sub__(other))
        except :
            return NotImplemented
    # action depends on second object type
    # TODO : would be nice to define LUT classes and allow MColor * LUT transform
    # overloaded operators
    def __mul__(self, other):
        """ a.__mul__(b) <==> a*b
            If b is a 1D sequence (Array, VectorN, Color), __mul__ is mapped to element-wise multiplication,
            If b is a MatrixN, __mul__ is similar to Point a by MatrixN b multiplication (post multiplication or transformation of a by b),
            multiplies every component of a by b if b is a single numeric value """
        if isinstance(other, MatrixN) :
            # will defer to MatrixN rmul
            return NotImplemented
        else :
            # will defer to Array.__mul__
            return Array.__mul__(self, other)
    def __rmul__(self, other):
        """ a.__rmul__(b) <==> b*a
            If b is a 1D sequence (Array, VectorN, Color), __mul__ is mapped to element-wise multiplication,
            If b is a MatrixN, __mul__ is similar to MatrixN b by Point a matrix multiplication,
            multiplies every component of a by b if b is a single numeric value """
        if isinstance(other, MatrixN) :
            # will defer to MatrixN mul
            return NotImplemented
        else :
            # will defer to Array.__rmul__
            return Array.__rmul__(self, other)
    def __imul__(self, other):
        """ a.__imul__(b) <==> a *= b
            In place multiplication of VectorN a and b, see __mul__, result must fit a's type """
        res = self*other
        if isinstance(res, self.__class__) :
            return self.__class__(res)
        else :
            raise TypeError, "result of in place multiplication of %s by %s is not a %s" % (clsname(self), clsname(other), clsname(self))


    # additionnal methods, to be extended
    def over(self, other):
        """ c1.over(c2): Composites c1 over other c2 using c1's alpha, the resulting color has the alpha of c2 """
        if isinstance(other, Color) :
            a = self.a
            return Color(Vector(other).blend(Vector(self), self.a), a=other.a)
        else :
            raise TypeError, "over is defined for Color instances, not %s" % (util.clsname(other))
    # return Vector instead ? Keeping alpha doesn't make much sense
    def premult(self):
        """ Premultiply Color r, g and b by it's alpha and resets alpha to 1.0 """
        return self.__class__(Vector(self)*self.a)
    def gamma(self, g):
        """ c.gamma(g) applies gamma correction g to Color c, g can be a scalar and then will be applied to r, g, b
            or an iterable of up to 3 (r, g, b) independant gamma correction values """
        if not hasattr(g, '__iter__') :
            g = (g,)*3+(1.0,)
        else :
            g = g[:3]+(1.0,)*(4-len(g[:3]))
        return gamma(self, g)
    def hsvblend(self, other, weight=0.5):
        """ c1.hsvblend(c2) --> Color
            Returns the result of blending c1 with c2 in hsv space, using the given weight """
        c1 = list(self.hsva)
        c2 = list(other.hsva)
        if abs(c2[0]-c1[0]) >= 0.5 :
            if abs(c2[0]-c1[0]) == 0.5 :
                c1[1], c2[1] = 0.0, 0.0
            if c1[0] > 0.5 :
                c1[0] -= 1.0
            if c2[0] > 0.5 :
                c2[0] -= 1.0
        c = blend(c1, c2, weight=weight)
        if c[0] < 0.0 :
            c[0] += 1.0
        return self.__class__(c, mode='hsv')


# to specify space of transforms

class Space(_api.MSpace):
    apicls = _api.MSpace
    __metaclass__ = _factories.MetaMayaTypeWrapper
    pass

Spaces = Space.Space

def equivalentSpace(space1, space2, rotationOnly=False):
    '''Compare the two given space values to see if they are equal

    Parameters
    ----------
    space1 : int or str
        the first space to compare (may be either the integer enum value, or the
        api enum name - ie, "kPostTransform" - or the pymel enum name - ie,
        "postTransform" )
    space2 : int or str
        the seoncd space to compare (may be either the integer enum value, or
        the api enum name - ie, "kPostTransform" - or the pymel enum name - ie,
        "postTransform")
    rotationOnly : bool
        If true, then compare the spaces, assuming we are only considering
        rotation - in rotation, transform is the same as preTransform/object
        (the reason being that in maya, preTransform means rotation +
        translation are both defined in the preTransform/object coordinate
        system, while transform means rotation is defined in preTransform/object
        coordinates, while translate is given in the postTransform space...
        which matches the way maya applies transforms)
    '''
    translated = []
    for space in space1, space2:
        space = _factories.ApiArgUtil.castInputEnum('MSpace', 'Space', space)
        if rotationOnly:
            # for the purposes of rotations, maya treats transform and
            # preTransform/object as the same (the reason being that in maya,
            # preTransform means both rotation + translation are both defined in
            # the preTransform/object coordinate system, while transform means
            # rotation is defined in preTransform/object coordinates, while
            # translate is given in the postTransform space... which matches the
            # way maya applies transforms)
            if space == _api.MSpace.kTransform:
                space = _api.MSpace.kPreTransform
            translated.append(space)


#kInvalid
#    kTransform
#Transform matrix (relative) space
#    kPreTransform
#Pre-transform matrix (geometry)
#    kPostTransform
#Post-transform matrix (world) space
#    kWorld
#transform in world space
#    kObject
#Same as pre-transform space
#    kLast

# sadly TransformationMatrix.RotationOrder and EulerRotation.RotationOrder don't match

#class MRotationOrder(int):
#    pass

#kInvalid
#    kXYZ
#    kYZX
#    kZXY
#    kXZY
#    kYXZ
#    kZYX
#    kLast


#    kXYZ
#    kYZX
#    kZXY
#    kXZY
#    kYXZ
#    kZYX

# functions that work on MatrixN (det(), inv(), ...) herited from arrays
# and properly defer to the class methods

# For row, column order, see the definition of a TransformationMatrix in docs :
# T  = |  1    0    0    0 |
#      |  0    1    0    0 |
#      |  0    0    1    0 |
#      |  tx   ty   tz   1 |
# and m(r, c) should return value of cell at r row and c column :
# t = _api.TransformationMatrix()
# t.setTranslation(_api.Vector(1, 2, 3), _api.MSpace.kWorld)
# m = t.asMatrix()
# mm(3,0)
# 1.0
# mm(3,1)
# 2.0
# mm(3,2)
# 3.0

class Matrix(MatrixN):
    """
        A 4x4 transformation matrix based on api Matrix

        >>> from pymel.all import *
        >>> import pymel.core.datatypes as dt
        >>>
        >>> i = dt.Matrix()
        >>> print i.formated()
        [[1.0, 0.0, 0.0, 0.0],
         [0.0, 1.0, 0.0, 0.0],
         [0.0, 0.0, 1.0, 0.0],
         [0.0, 0.0, 0.0, 1.0]]

        >>> v = dt.Matrix(1, 2, 3)
        >>> print v.formated()
        [[1.0, 2.0, 3.0, 0.0],
         [1.0, 2.0, 3.0, 0.0],
         [1.0, 2.0, 3.0, 0.0],
         [1.0, 2.0, 3.0, 0.0]]


    """
    __metaclass__ = MetaMayaArrayTypeWrapper
    apicls = _api.MMatrix
    shape = (4, 4)
    cnames = ('a00', 'a01', 'a02', 'a03',
               'a10', 'a11', 'a12', 'a13',
               'a20', 'a21', 'a22', 'a23',
               'a30', 'a31', 'a32', 'a33' )

    # constants

    identity = _api.MMatrix()

    def __new__(cls, *args, **kwargs):
        shape = kwargs.get('shape', None)
        ndim = kwargs.get('ndim', None)
        size = kwargs.get('size', None)
        # will default to class constant shape = (4, 4), so it's just an error check to catch invalid shapes,
        # as no other option is actually possible on Matrix, but this method could be used to allow wrapping
        # of Maya array classes that can have a variable number of elements
        shape, ndim, size = cls._expandshape(shape, ndim, size)

        new = cls.apicls.__new__(cls)
        cls.apicls.__init__(new)
        return new

    def __init__(self, *args, **kwargs):
        """ __init__ method, valid for Vector, Point and Color classes """
        cls = self.__class__

        if args :
            # allow both forms for arguments
            if len(args)==1 and hasattr(args[0], '__iter__') :
                args = args[0]
#            shape = kwargs.get('shape', None)
#            ndim = kwargs.get('ndim', None)
#            size = kwargs.get('size', None)
#            if shape is not None or ndim is not None or size is not None :
#                shape, ndim, size = cls._expandshape(shape, ndim, size)
#                args = MatrixN(args, shape=shape, ndim=ndim, size=size)
            # shortcut when a direct api init is possible
            try :
                self.assign(args)
            except :
                super(MatrixN, self).__init__(*args)
                # value = list(Matrix(value, shape=self.shape).flat)
                # data = self.apicls()
                # _api.MScriptUtil.createMatrixFromList ( value, data )

        if hasattr(cls, 'cnames') and len(set(cls.cnames) & set(kwargs)) :
            # can also use the form <componentname>=<number>
            l = list(self.flat)
            setcomp = False
            for i, c in enumerate(cls.cnames) :
                if c in kwargs :
                    if float(l[i]) != float(kwargs[c]) :
                        l[i] = float(kwargs[c])
                        setcomp = True
            if setcomp :
                try :
                    self.assign(l)
                except :
                    msg = ", ".join(map(lambda x,y:x+"=<"+util.clsname(y)+">", cls.cnames, l))
                    raise TypeError, "in %s(%s), at least one of the components is of an invalid type, check help(%s) " % (cls.__name__, msg, cls.__name__)

    # for compatibility with base classes Array that actually hold a nested list in their _data attribute
    # here, there is no _data attribute as we subclass _api.Vector directly, thus v.data is v
    # for wraps

    def _getdata(self):
        return self
    def _setdata(self, value):
        self.assign(value)
    def _deldata(self):
        if hasattr(self.apicls, 'clear') :
            self.apicls.clear(self)
        else :
            raise TypeError, "cannot clear stored elements of %s" % (self.__class__.__name__)

    data = property(_getdata, _setdata, _deldata, "The Matrix/FloatMatrix/TransformationMatrix/Quaternion/EulerRotation data")

    # set properties for easy acces to translation / rotation / scale of a Matrix or derived class
    # some of these will only yield dependable results if Matrix is a TransformationMatrix and some
    # will always be zero for some classes (ie only rotation has a value on a Quaternion

    def _getTranslate(self):
        t = TransformationMatrix(self)
        return Vector(t.getTranslation( _api.MSpace.kTransform) )
    def _setTranslate(self, value):
        t = TransformationMatrix(self)
        t.setTranslation ( Vector(value), _api.MSpace.kTransform )
        self.assign(t.asMatrix())
    translate = property(_getTranslate, _setTranslate, None, "The translation expressed in this Matrix, in transform space")
    def _getRotate(self):
        t = TransformationMatrix(self)
        return Quaternion(t.rotation())
    def _setRotate(self, value):
        t = TransformationMatrix(self)
        q = Quaternion(value)
        t.rotateTo(q)
        # values = (q.x, q.y, q.z, q.w)
        # t.setRotationQuaternion(q.x, q.y, q.z, q.w)
        self.assign(t.asMatrix())
    rotate = property(_getRotate, _setRotate, None, "The rotation expressed in this Matrix, in transform space")
    def _getScale(self):
        # need to keep a ref to the MScriptUtil alive until
        # all pointers aren't needed...
        t = TransformationMatrix(self)
        ms = _api.MScriptUtil()
        ms.createFromDouble ( 1.0, 1.0, 1.0 )
        p = ms.asDoublePtr ()
        t.getScale (p, _api.MSpace.kTransform);
        return Vector([ms.getDoubleArrayItem (p, i) for i in range(3)])
    def _setScale(self, value):
        t = TransformationMatrix(self)
        # need to keep a ref to the MScriptUtil alive until
        # all pointers aren't needed...
        ms = _api.MScriptUtil()
        ms.createFromDouble (*Vector(value))
        p = ms.asDoublePtr ()
        t.setScale ( p, _api.MSpace.kTransform)
        self.assign(t.asMatrix())
    scale = property(_getScale, _setScale, None, "The scale expressed in this Matrix, in transform space")

    def __melobject__(self):
        """Special method for returning a mel-friendly representation. In this case, a flat list of 16 values """
        return [ x for x in self.flat ]

    # some Matrix derived classes can actually be represented as matrix but not stored
    # internally as such by the API

    def asMatrix(self, percent=None):
        "The matrix representation for this Matrix/TransformationMatrix/Quaternion/EulerRotation instance"
        if percent is not None and percent != 1.0 :
            if type(self) is not TransformationMatrix :
                self = TransformationMatrix(self)
            return Matrix(self.apicls.asMatrix(self, percent))
        else :
            if type(self) is Matrix :
                return self
            else :
                return Matrix(self.apicls.asMatrix(self))

    matrix = property(asMatrix, None, None, "The Matrix representation for this Matrix/TransformationMatrix/Quaternion/EulerRotation instance")

    # overloads for assign and get though standard way should be to use the data property
    # to access stored values
    def assign(self, value):
        # don't accept instances as assign works on exact _api.Matrix type
        data = None
        if type(value) == self.apicls or type(value) == type(self) :
            data = value
        elif hasattr(value, 'asMatrix') :
            data = value.asMatrix()
        else :
            value = list(MatrixN(value).flat)
            if len(value) == self.size :
                data = self.apicls()
                if isinstance(data, _api.MFloatMatrix):
                    _api.MScriptUtil.createFloatMatrixFromList ( value, data )
                elif isinstance(data, _api.MMatrix):
                    _api.MScriptUtil.createMatrixFromList ( value, data )
                else:
                    tmp = _api.MMatrix()
                    _api.MScriptUtil.createMatrixFromList ( value, tmp )
                    data = self.apicls( tmp )
            else :
                raise TypeError, "cannot assign %s to a %s" % (value, util.clsname(self))

        self.apicls.assign(self, data)
        return self

    # API get, actually not faster than pulling self[i] for such a short structure
    def get(self):
        """ Wrap the Matrix api get method """
        mat = self.matrix
        return tuple(tuple(_api.MScriptUtil.getDoubleArrayItem ( _api.MMatrix.__getitem__(mat, r), c) for c in xrange(Matrix.shape[1])) for r in xrange(Matrix.shape[0]))
        # ptr = _api.Matrix(self.matrix).matrix
        # return tuple(tuple(_api.MScriptUtil.getDouble2ArrayItem ( ptr, r, c) for c in xrange(Matrix.shape[1])) for r in xrange(Matrix.shape[0]))

    def __len__(self):
        """ Number of components in the Matrix instance """
        return self.apicls.__len__(self)

    # iterator override
    # TODO : support for optionnal __iter__ arguments
    def __iter__(self, *args, **kwargs):
        """ Iterate on the Matrix rows """
        return self.apicls.__iter__(self.data)
    # contains is herited from Array contains

    # __getitem__ / __setitem__ override
    def __getitem__(self, index):
        """ m.__getitem__(index) <==> m[index]
            Get component index value from self.
            index can be a single numeric value or slice, thus one or more rows will be returned,
            or a row,column tuple of numeric values / slices """
        m = MatrixN(self)
        # print list(m)
        return m.__getitem__(index)
        # return super(MatrixN, self).__getitem__(index)

    # deprecated and __getitem__ should accept slices anyway
    def __getslice__(self, start, end):
        return self.__getitem__(slice(start, end))

    # as _api.Matrix has no __setitem__ method
    def __setitem__(self, index, value):
        """ m.__setitem__(index, value) <==> m[index] = value
            Set value of component index on self
            index can be a single numeric value or slice, thus one or more rows will be returned,
            or a row,column tuple of numeric values / slices """
        m = MatrixN(self)
        m.__setitem__(index, value)
        self.assign(m)

    # deprecated and __setitem__ should accept slices anyway
    def __setslice__(self, start, end, value):
        self.__setitem__(slice(start, end), value)

    def __delitem__(self, index) :
        """ Cannot delete from a class with a fixed shape """
        raise TypeError, "deleting %s from an instance of class %s will make it incompatible with class shape" % (index, clsname(self))

    def __delslice__(self, start, end):
        self.__delitem__(slice(start, end))

    # TODO : wrap double Matrix:: operator() (unsigned int row, unsigned int col ) const

    # common operators herited from MatrixN

    # operators using the Maya API when applicable
    def __eq__(self, other):
        """ m.__eq__(v) <==> m == v
            Equivalence test """
        try :
            return bool(self.apicls.__eq__(self, other))
        except :
            return bool(super(Matrix, self).__eq__(other))
    def __ne__(self, other):
        """ m.__ne__(v) <==> m != v
            Equivalence test """
        return (not self.__eq__(other))
    def __neg__(self):
        """ m.__neg__() <==> -m
            The unary minus operator. Negates the value of each of the components of m """
        return self.__class__(self.apicls.__neg__(self))
    def __add__(self, other) :
        """ m.__add__(v) <==> m+v
            Returns the result of the addition of m and v if v is convertible to a MatrixN (element-wise addition),
            adds v to every component of m if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__add__(self, other))
        except :
            return self.__class__._convert(super(Matrix, self).__add__(other))
    def __radd__(self, other) :
        """ m.__radd__(v) <==> v+m
            Returns the result of the addition of m and v if v is convertible to a MatrixN (element-wise addition),
            adds v to every component of m if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__radd__(self, other))
        except :
            return self.__class__._convert(super(Matrix, self).__radd__(other))
    def __iadd__(self, other):
        """ m.__iadd__(v) <==> m += v
            In place addition of m and v, see __add__ """
        try :
            return self.__class__(self.__add__(other))
        except :
            return NotImplemented
    def __sub__(self, other) :
        """ m.__sub__(v) <==> m-v
            Returns the result of the substraction of v from m if v is convertible to a MatrixN (element-wise substration),
            substract v to every component of m if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__sub__(self, other))
        except :
            return self.__class__._convert(super(Matrix, self).__sub__(other))
    def __rsub__(self, other) :
        """ m.__rsub__(v) <==> v-m
            Returns the result of the substraction of m from v if v is convertible to a MatrixN (element-wise substration),
            replace every component c of m by v-c if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__rsub__(self, other))
        except :
            return self.__class__._convert(super(Matrix, self).__rsub__(other))
    def __isub__(self, other):
        """ m.__isub__(v) <==> m -= v
            In place substraction of m and v, see __sub__ """
        try :
            return self.__class__(self.__sub__(other))
        except :
            return NotImplemented
    # action depends on second object type
    def __mul__(self, other) :
        """ m.__mul__(x) <==> m*x
            If x is a MatrixN, __mul__ is mapped to matrix multiplication m*x, if x is a VectorN, to MatrixN by VectorN multiplication.
            Otherwise, returns the result of the element wise multiplication of m and x if x is convertible to Array,
            multiplies every component of b by x if x is a single numeric value """
        try :
            return self.__class__._convert(self.apicls.__mul__(self, other))
        except :
            return self.__class__._convert(super(Matrix, self).__mul__(other))
    def __rmul__(self, other):
        """ m.__rmul__(x) <==> x*m
            If x is a MatrixN, __rmul__ is mapped to matrix multiplication x*m, if x is a VectorN (or Vector or Point or Color),
            to transformation, ie VectorN by MatrixN multiplication.
            Otherwise, returns the result of the element wise multiplication of m and x if x is convertible to Array,
            multiplies every component of m by x if x is a single numeric value """
        try :
            return self.__class__._convert(self.apicls.__rmul__(self, other))
        except :
            return self.__class__._convert(super(Matrix, self).__rmul__(other))
    def __imul__(self, other):
        """ m.__imul__(n) <==> m *= n
            Valid for Matrix * Matrix multiplication, in place multiplication of MatrixN m by MatrixN n """
        try :
            return self.__class__(self.__mul__(other))
        except :
            return NotImplemented
    # __xor__ will defer to Vector __xor__

    # API added methods

    def setToIdentity (self) :
        """ m.setToIdentity() <==> m = a * b
            Sets MatrixN to the identity matrix """
        try :
            self.apicls.setToIdentity(self)
        except :
            self.assign(self.__class__())
        return self
    def setToProduct ( self, left, right ) :
        """ m.setToProduct(a, b) <==> m = a * b
            Sets MatrixN to the result of the product of MatrixN a and MatrixN b """
        try :
            self.apicls.setToProduct(self.__class__(left), self.__class__(right))
        except :
            self.assign(self.__class__(self.__class__(left) * self.__class__(right)))
        return self
    def transpose(self):
        """ Returns the transposed Matrix """
        try :
            return self.__class__._convert(self.apicls.transpose(self))
        except :
            return self.__class__._convert(super(Matrix, self).transpose())
    def inverse(self):
        """ Returns the inverse Matrix """
        try :
            return self.__class__._convert(self.apicls.inverse(self))
        except :
            return self.__class__._convert(super(Matrix, self).inverse())
    def adjoint(self):
        """ Returns the adjoint (adjugate) Matrix """
        try :
            return self.__class__._convert(self.apicls.adjoint(self))
        except :
            return self.__class__._convert(super(Matrix, self).adjugate())
    def homogenize(self):
        """ Returns a homogenized version of the Matrix """
        try :
            return self.__class__._convert(self.apicls.homogenize(self))
        except :
            return self.__class__._convert(super(Matrix, self).homogenize())
    def det(self):
        """ Returns the determinant of this Matrix instance """
        try :
            return self.apicls.det4x4(self)
        except :
            return super(Matrix, self).det()
    def det4x4(self):
        """ Returns the 4x4 determinant of this Matrix instance """
        try :
            return self.apicls.det4x4(self)
        except :
            return super(Matrix, self[:4,:4]).det()
    def det3x3(self):
        """ Returns the determinant of the upper left 3x3 submatrix of this Matrix instance,
            it's the same as doing det(m[0:3, 0:3]) """
        try :
            return self.apicls.det3x3(self)
        except :
            return super(Matrix, self[:3,:3]).det()
    def isEquivalent(self, other, tol=_api.MVector_kTol):
        """ Returns true if both arguments considered as Matrix are equal within the specified tolerance """
        try :
            nself, nother = coerce(self, other)
        except :
            return False
        if isinstance(nself, Matrix) :
            return bool(nself.apicls.isEquivalent(nself, nother, tol))
        else :
            return bool(super(MatrixN, nself).isEquivalent(nother, tol))
    def isSingular(self) :
        """ Returns True if the given Matrix is singular """
        try :
            return bool(self.apicls.isSingular(self))
        except :
            return super(MatrixN, self).isSingular()

    # additionnal methods

    def blend(self, other, weight=0.5):
        """ Returns a 0.0-1.0 scalar weight blend between self and other Matrix,
            blend mixes Matrix as transformation matrices """
        if isinstance(other, Matrix) :
            return self.__class__(self.weighted(1.0-weight)*other.weighted(weight))
        else :
            return blend(self, other, weight=weight)
    def weighted(self, weight):
        """ Returns a 0.0-1.0 scalar weighted blend between identity and self """
        if type(self) is not TransformationMatrix :
            self = TransformationMatrix(self)
        return self.__class__._convert(self.asMatrix(weight))

class FloatMatrix(Matrix) :
    """ A 4x4 matrix class that wraps Maya's api FloatMatrix class,
        It behaves identically to Matrix, but it also derives from api's FloatMatrix
        to keep api methods happy
        """
    apicls = _api.MFloatMatrix

class TransformationMatrix(Matrix):
    apicls = _api.MTransformationMatrix

    def _getTranslate(self):
        return Vector(self.getTranslation(_api.MSpace.kTransform))
    def _setTranslate(self, value):
        self.setTranslation ( Vector(value), _api.MSpace.kTransform )
    translate = property(_getTranslate, _setTranslate, None, "The translation expressed in this TransformationMatrix, in transform space")

    def _getRotate(self):
        return Quaternion(self.apicls.rotation(self))
    def _setRotate(self, value):
        self.rotateTo(Quaternion(value))
    rotate = property(_getRotate, _setRotate, None, "The quaternion rotation expressed in this TransformationMatrix, in transform space")

    def rotateTo(self, value):
        '''Set to the given rotation (and result self)

        Value may be either a Quaternion, EulerRotation object, or a list of
        floats; if it is floats, if it has length 4 it is interpreted as
        a Quaternion; if 3, as a EulerRotation.
        '''
        if not isinstance(value, (Quaternion, EulerRotation,
                              _api.MQuaternion, _api.MEulerRotation)):
            if len(value) == 3:
                value = EulerRotation(value)
            elif len(value) == 4:
                value = Quaternion(value)
            else:
                raise ValueError('arg to rotateTo must be a Quaternion, EulerRotation, or an iterable of 3 or 4 floats')
        return self.__class__(self.apicls.rotateTo(self, value))

    def eulerRotation(self):
        return EulerRotation(self.apicls.eulerRotation(self))
    def _getEuler(self):
        return self.eulerRotation()
    def _setEuler(self, value):
        self.rotateTo(EulerRotation(value))
    euler = property(_getEuler, _getEuler, None, "The euler rotation expressed in this TransformationMatrix, in transform space")


    # The apicls getRotation needs a "RotationOrder &" object, which is
    # impossible to make in python...
    # So instead, wrap eulerRotation
    def getRotation(self):
        return self.eulerRotation()
    def setRotation(self, *args):
        self.rotateTo(EulerRotation(*args))

    def _getScale(self):
        # need to keep a ref to the MScriptUtil alive until
        # all pointers aren't needed...
        ms = _api.MScriptUtil()
        ms.createFromDouble ( 1.0, 1.0, 1.0 )
        p = ms.asDoublePtr ()
        self.getScale (p, _api.MSpace.kTransform);
        return Vector([ms.getDoubleArrayItem (p, i) for i in range(3)])
    def _setScale(self, value):
        # need to keep a ref to the MScriptUtil alive until
        # all pointers aren't needed...
        ms = _api.MScriptUtil()
        ms.createFromDouble (*Vector(value))
        p = ms.asDoublePtr ()
        self.setScale ( p, _api.MSpace.kTransform)
    scale = property(_getScale, _setScale, None, "The scale expressed in this TransformationMatrix, in transform space")



class EulerRotation(Array):
    """
    unit handling:
    >>> from pymel.all import *
    >>> import pymel.core.datatypes as dt
    >>>
    >>> currentUnit(angle='degree')
    u'degree'
    >>> e = dt.EulerRotation([math.pi,0,0], unit='radians')
    >>> e
    dt.EulerRotation([3.14159265359, 0.0, 0.0], unit='radians')
    >>> e2 = dt.EulerRotation([180,0,0], unit='degrees')
    >>> e2
    dt.EulerRotation([180.0, 0.0, 0.0])
    >>> e.isEquivalent( e2 )
    True
    >>> e == e2
    True

    units are only displayed when they do not match the current ui unit
    >>> dt.Angle.getUIUnit() # check current angular unit
    'degrees'
    >>> e
    dt.EulerRotation([3.14159265359, 0.0, 0.0], unit='radians')
    >>> dt.Angle.setUIUnit('radians')  # change to radians
    >>> e
    dt.EulerRotation([3.14159265359, 0.0, 0.0])


    """
    __metaclass__ = MetaMayaArrayTypeWrapper
    apicls = _api.MEulerRotation
    shape = (3,)
    cnames = ('x', 'y', 'z')

    RotationOrder = _factories.apiClassInfo['MEulerRotation']['pymelEnums']['RotationOrder']

    def _getorder(self):
        return self.RotationOrder[self.apicls.__dict__['order'].__get__(self, self.apicls)]
    def _setorder(self, val):
        self.apicls.__dict__['order'].__set__(self, self.RotationOrder.getIndex(val))
    order = property(_getorder, _setorder)

    def __new__(cls, *args, **kwargs):
#        shape = kwargs.get('shape', None)
#        ndim = kwargs.get('ndim', None)
#        size = kwargs.get('size', None)
#
        new = cls.apicls.__new__(cls)
        cls.apicls.__init__(new)
        return new

    def __init__(self, *args, **kwargs):
        """ __init__ method for EulerRotation """
        self.unit = None
        self.assign(*args, **kwargs)

    def setDisplayUnit(self, unit):
        if unit not in Angle.Unit:
            raise TypeError, "%s is not a valid angular unit.  See Angle.Unit for the list of valid units"
        self.unit = unit

    def __repr__(self):
        argStrs = [str(self)]
        if self.unit != Angle.getUIUnit():
            argStrs.append('unit=%r' % self.unit)
        if self.order != 'XYZ':
            argStrs.append('order=%r' % str(self.order))
        return "dt.%s(%s)" % (self.__class__.__name__, ', '.join(argStrs))

    def __iter__(self):
        for i in range(self.size):
            yield self[i]

    def __getitem__(self, i):
        return Angle( self._getitem(i), 'radians' ).asUnit(self.unit)
    def __setitem__(self, key, val):
        kwargs = {}
        if key in self.cnames:
            kwargs[key] = val
        else:
            kwargs[self.cnames[key]] = val
        self.assign(**kwargs)

    # faster to override __getitem__ cause we know Vector only has one dimension
    def _getitem(self, i):
        """ Get component i value from self """
        if hasattr(i, '__iter__') :
            i = list(i)
            if len(i) == 1 :
                i = i[0]
            else :
                raise IndexError, "class %s instance %s has only %s dimension(s), index %s is out of bounds" % (util.clsname(self), self, self.ndim, i)
        if isinstance(i, slice) :
            return _toCompOrArrayInstance(list(self)[i], VectorN)
            try :
                return _toCompOrArrayInstance(list(self)[i], VectorN)
            except :
                raise IndexError, "class %s instance %s is of size %s, index %s is out of bounds" % (util.clsname(self), self, self.size, i)
        else :
            if i < 0 :
                i = self.size + i
            if i<self.size and not i<0 :
                if hasattr(self.apicls, '__getitem__') :
                    return self.apicls.__getitem__(self, i)
                else :
                    return list(self)[i]
            else :
                raise IndexError, "class %s instance %s is of size %s, index %s is out of bounds" % (util.clsname(self), self, self.size, i)

    def assign(self, *args, **kwargs):
        """ Wrap the Quaternion api assign method """
        # After processing, we want to have args be in a format such that
        # we may do:
        # apicls.assign(*args)
        # This means that either:
        #   args is a list/tuple of

        if 'unit' in kwargs:
            self.unit = kwargs['unit']
        elif self.unit is None:
            self.unit = Angle.getUIUnit()

        if len(args) == 1 and isinstance(args[0], _api.MTransformationMatrix):
            args = [args[0].asMatrix()]

        # api MEulerRotation assign accepts Matrix, Quaternion and EulerRotation
        validSingleObjs = (_api.MMatrix, _api.MQuaternion, _api.MEulerRotation)
        if len(args) == 1 and isinstance(args[0], validSingleObjs):
            self.unit = 'radians'
            self.apicls.assign(self, args[0])
        elif args:
            if len(args) == 1:
                args = list(args[0])
            elif len(args) == 2 and isinstance(args[1], (basestring, util.EnumValue) ):
                args = list(args[0]) + [args[1]]
            else:
                # convert to list, as we may have to do modifications
                args = list(args)

            # If only 3 rotation angles supplied, and current order is
            # not default, make sure we maintain it
            if self.order != 'XYZ' and len(args) == 3:
                args.append(self.apicls.__dict__['order'].__get__(self, self.apicls))

            elif len(args) == 4 and isinstance(args[3], (basestring, util.EnumValue) ) :
                # allow to initialize directly from 3 rotations and a rotation order as string
                args[3] = self.RotationOrder.getIndex(args[3])

            # In case they do something like pass in a mix of Angle objects and
            # float numbers, convert to correct unit one-by-one...
            for i in xrange(3):
                if isinstance(args[i], Angle):
                    args[i] = args[i].asUnit('radians')
                elif self.unit != 'radians' and not isinstance(args[i], Angle):
                    args[i] = Angle(args[i], self.unit).asUnit('radians')
            self.apicls.setValue(self, *args)

        # We do kwargs as a separate step after args, instead of trying to combine
        # them, in case they do something like pass in a EulerRotation(myMatrix, y=2)
        if hasattr(self, 'cnames') and len(set(self.cnames) & set(kwargs)) :
            # can also use the form <componentname>=<number>
            l = list(self.flat)
            setcomp = False
            for i, c in enumerate(self.cnames) :
                if c in kwargs :
                    if float(l[i]) != float(kwargs[c]) :
                        l[i] = float(kwargs[c])
                        setcomp = True
            if setcomp :
                try :
                    self.assign(l)
                except :
                    msg = ", ".join(map(lambda x,y:x+"=<"+util.clsname(y)+">", cls.cnames, l))
                    raise TypeError, "in %s(%s), at least one of the components is of an invalid type, check help(%s) " % (cls.__name__, msg, cls.__name__)

        return self

    # API get, actually not faster than pulling self[i] for such a short structure
    def get(self):
        """ Wrap the MEulerRotation api get method """
        # need to keep a ref to the MScriptUtil alive until
        # all pointers aren't needed...
        ms = _api.MScriptUtil()
        l = (0,)*self.size
        ms.createFromDouble ( *l )
        p = ms.asDoublePtr ()
        self.apicls.get(self, p)
        return tuple([ms.getDoubleArrayItem ( p, i ) for i in xrange(self.size)])

    def __contains__(self, value):
        """ True if at least one of the vector components is equal to the argument """
        return value in self.__iter__()

    def __len__(self):
        return self.apicls.__len__(self)

    # common operators without an api equivalent are herited from VectorN

    # operators using the Maya API when applicable, but that can delegate to VectorN

    def __eq__(self, other):
        """ u.__eq__(v) <==> u == v
            Equivalence test """
        if isinstance( other, self.apicls ):
            return bool(self.apicls.__eq__(self, other))
        else :
            return bool(super(EulerRotation, self).__eq__(other))
    def __ne__(self, other):
        """ u.__ne__(v) <==> u != v
            Equivalence test """
        return (not self.__eq__(other))
    def __neg__(self):
        """ u.__neg__() <==> -u
            The unary minus operator. Negates the value of each of the components of u """
        return self.__class__(self.apicls.__neg__(self))
    def __add__(self, other) :
        """ u.__add__(v) <==> u+v
            Returns the result of the addition of u and v if v is convertible to a VectorN (element-wise addition),
            adds v to every component of u if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__add__(self, other))
        except :
            return self.__class__._convert(super(EulerRotation, self).__add__(other))
    def __radd__(self, other) :
        """ u.__radd__(v) <==> v+u
            Returns the result of the addition of u and v if v is convertible to a VectorN (element-wise addition),
            adds v to every component of u if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__radd__(self, other))
        except :
            return self.__class__._convert(super(EulerRotation, self).__radd__(other))
    def __iadd__(self, other):
        """ u.__iadd__(v) <==> u += v
            In place addition of u and v, see __add__ """
        try :
            return self.__class__(self.__add__(other))
        except :
            return NotImplemented
    def __sub__(self, other) :
        """ u.__sub__(v) <==> u-v
            Returns the result of the substraction of v from u if v is convertible to a VectorN (element-wise substration),
            substract v to every component of u if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__sub__(self, other))
        except :
            return self.__class__._convert(super(EulerRotation, self).__sub__(other))
    def __rsub__(self, other) :
        """ u.__rsub__(v) <==> v-u
            Returns the result of the substraction of u from v if v is convertible to a VectorN (element-wise substration),
            replace every component c of u by v-c if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__rsub__(self, other))
        except :
            return self.__class__._convert(super(EulerRotation, self).__rsub__(other))
    def __isub__(self, other):
        """ u.__isub__(v) <==> u -= v
            In place substraction of u and v, see __sub__ """
        try :
            return self.__class__(self.__sub__(other))
        except :
            return NotImplemented
    def __div__(self, other):
        """ u.__div__(v) <==> u/v
            Returns the result of the division of u by v if v is convertible to a VectorN (element-wise division),
            divide every component of u by v if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__div__(self, other))
        except :
            return self.__class__._convert(super(EulerRotation, self).__div__(other))
    def __rdiv__(self, other):
        """ u.__rdiv__(v) <==> v/u
            Returns the result of of the division of v by u if v is convertible to a VectorN (element-wise division),
            invert every component of u and multiply it by v if v is a scalar """
        try :
            return self.__class__._convert(self.apicls.__rdiv__(self, other))
        except :
            return self.__class__._convert(super(EulerRotation, self).__rdiv__(other))
    def __idiv__(self, other):
        """ u.__idiv__(v) <==> u /= v
            In place division of u by v, see __div__ """
        try :
            return self.__class__(self.__div__(other))
        except :
            return NotImplemented
    # action depends on second object type
    def __mul__(self, other) :
        """ u.__mul__(v) <==> u*v
            The multiply '*' operator is mapped to the dot product when both objects are Vectors,
            to the transformation of u by matrix v when v is a MatrixN,
            to element wise multiplication when v is a sequence,
            and multiplies each component of u by v when v is a numeric type. """
        try :
            res = self.apicls.__mul__(self, other)
        except :
            res = super(EulerRotation, self).__mul__(other)
        if util.isNumeric(res) :
            return res
        else :
            return self.__class__._convert(res)
    def __rmul__(self, other):
        """ u.__rmul__(v) <==> v*u
            The multiply '*' operator is mapped to the dot product when both objects are Vectors,
            to the left side multiplication (pre-multiplication) of u by matrix v when v is a MatrixN,
            to element wise multiplication when v is a sequence,
            and multiplies each component of u by v when v is a numeric type. """
        try :
            res = self.apicls.__rmul__(self, other)
        except :
            res = super(EulerRotation, self).__rmul__(other)
        if util.isNumeric(res) :
            return res
        else :
            return self.__class__._convert(res)
    def __imul__(self, other):
        """ u.__imul__(v) <==> u *= v
            Valid for EulerRotation * Matrix multiplication, in place transformation of u by Matrix v
            or EulerRotation by scalar multiplication only """
        try :
            return self.__class__(self.__mul__(other))
        except :
            return NotImplemented
    # special operators
#    def __xor__(self, other):
#        """ u.__xor__(v) <==> u^v
#            Defines the cross product operator between two 3D vectors,
#            if v is a MatrixN, u^v is equivalent to u.transformAsNormal(v) """
#        if isinstance(other, VectorN) :
#            return self.cross(other)
#        elif isinstance(other, MatrixN) :
#            return self.transformAsNormal(other)
#        else :
#            return NotImplemented
#    def __ixor__(self, other):
#        """ u.__xor__(v) <==> u^=v
#            Inplace cross product or transformation by inverse transpose of v is v is a MatrixN """
#        try :
#            return self.__class__(self.__xor__(other))
#        except :
#            return NotImplemented


class Quaternion(Matrix):
    apicls = _api.MQuaternion
    shape = (4,)
    cnames = ('x', 'y', 'z', 'w')

    def __new__(cls, *args, **kwargs):
        shape = kwargs.get('shape', None)
        ndim = kwargs.get('ndim', None)
        size = kwargs.get('size', None)
        # will default to class constant shape = (4,), so it's just an error check to catch invalid shapes,
        # as no other option is actually possible on Quaternion, but this method could be used to allow wrapping
        # of Maya array classes that can have a variable number of elements
        shape, ndim, size = cls._expandshape(shape, ndim, size)

        new = cls.apicls.__new__(cls)
        cls.apicls.__init__(new)
        return new

    def __init__(self, *args, **kwargs):
        """ __init__ method for Quaternion """
        cls = self.__class__

        if args :
            # allow both forms for arguments
            if len(args)==1 and hasattr(args[0], '__iter__') :
                args = args[0]

            rotate = getattr(args, 'rotate', None)
            # TransformationMatrix, Quaternion, EulerRotation api classes can convert to a rotation Quaternion
            if rotate is not None and not callable(rotate):
                args = args.rotate
                self.unit = 'radians'

            elif len(args) == 4 and isinstance(args[3], (basestring, util.EnumValue)): # isinstance(args[3], EulerRotation.RotationOrder) ) :
                quat = _api.MQuaternion()
                quat.assign(EulerRotation(*args, **kwargs))
                args = quat
                # allow to initialize directly from 3 rotations and a rotation order

            elif len(args) == 2 and isinstance(args[0], VectorN) and isinstance(args[1], float) :
                # some special init cases are allowed by the api class, want to authorize
                # Quaternion(Vector axis, float angle) as well as Quaternion(float angle, Vector axis)
                args = (float(args[1]), Vector(args[0]))
            # shortcut when a direct api init is possible

            try :
                self.assign(args)
            except :
                super(Array, self).__init__(*args)

        if hasattr(cls, 'cnames') and len(set(cls.cnames) & set(kwargs)) :
            # can also use the form <componentname>=<number>
            l = list(self.flat)
            setcomp = False
            for i, c in enumerate(cls.cnames) :
                if c in kwargs :
                    if float(l[i]) != float(kwargs[c]) :
                        l[i] = float(kwargs[c])
                        setcomp = True
            if setcomp :
                try :
                    self.assign(l)
                except :
                    msg = ", ".join(map(lambda x,y:x+"=<"+util.clsname(y)+">", cls.cnames, l))
                    raise TypeError, "in %s(%s), at least one of the components is of an invalid type, check help(%s) " % (cls.__name__, msg, cls.__name__)

    # set properties for easy acces to translation / rotation / scale of a MMatrix or derived class
    # some of these will only yield dependable results if MMatrix is a MTransformationMatrix and some
    # will always be zero for some classes (ie only rotation has a value on a MQuaternion

    def _getTranslate(self):
        return Vector(0.0, 0.0, 0.0)
    translate = property(_getTranslate, None, None, "The translation expressed in this MMQuaternion, which is always (0.0, 0.0, 0.0)")
    def _getRotate(self):
        return self
    def _setRotate(self, value):
        self.assign(Quaternion(value))
    rotate = property(_getRotate, _setRotate, None, "The rotation expressed in this Quaternion, in transform space")
    def _getScale(self):
        return Vector(1.0, 1.0, 1.0)
    scale = property(_getScale, None, None, "The scale expressed in this Quaternion, which is always (1.0, 1.0, 1.0)")

    # overloads for assign and get though standard way should be to use the data property
    # to access stored values

    def assign(self, value):
        """ Wrap the Quaternion api assign method """
        # api Quaternion assign accepts Matrix, Quaternion and EulerRotation
        if isinstance(value, Matrix) :
            value = value.rotate
        else :
            if not hasattr(value, '__iter__') :
                value = (value,)
            value = self.apicls(*value)
        self.apicls.assign(self, value)
        return self

    # API get, actually not faster than pulling self[i] for such a short structure
    def get(self):
        """ Wrap the Quaternion api get method """
        # need to keep a ref to the MScriptUtil alive until
        # all pointers aren't needed...
        ms = _api.MScriptUtil()
        l = (0,)*self.size
        ms.createFromDouble ( *l )
        p = ms.asDoublePtr ()
        self.apicls.get(self, p)
        return tuple([ms.getDoubleArrayItem ( p, i ) for i in xrange(self.size)])

    def __getitem__(self,i):
        return self._getitem(i)

    # faster to override __getitem__ cause we know Quaternion only has one dimension
    def _getitem(self, i):
        """ Get component i value from self """
        if hasattr(i, '__iter__') :
            i = list(i)
            if len(i) == 1 :
                i = i[0]
            else :
                raise IndexError, "class %s instance %s has only %s dimension(s), index %s is out of bounds" % (util.clsname(self), self, self.ndim, i)
        if isinstance(i, slice) :
            try :
                return list(self)[i]
            except :
                raise IndexError, "class %s instance %s is of size %s, index %s is out of bounds" % (util.clsname(self), self, self.size, i)
        else :
            if i < 0 :
                i = self.size + i
            if i<self.size and not i<0 :
                if hasattr(self.apicls, '__getitem__') :
                    res = self.apicls.__getitem__(self, i)
                else :
                    res = list(self)[i]
                return res
            else :
                raise IndexError, "class %s instance %s is of size %s, index %s is out of bounds" % (util.clsname(self), self, self.size, i)


    # as _api.Vector has no __setitem__ method, so need to reassign the whole Vector
    def __setitem__(self, i, a):
        """ Set component i value on self """
        v = VectorN(self)
        v.__setitem__(i, a)
        self.assign(v)

    def __iter__(self):
        for i in range(self.size):
            yield self[i]

    def __len__(self):

        # api incorrectly returns 4. this might make sense if it did not simply return z a second time as the fourth element
        return self.size
#
#    # TODO : support for optional __iter__ arguments
#    def __iter__(self, *args, **kwargs):
#        """ Iterate on the api components """
#        return self.apicls.__iter__(self.data)

    def __contains__(self, value):
        """ True if at least one of the vector components is equal to the argument """
        return value in self.__iter__()


class Unit(float):
    __slots__ = ['unit', 'data', 'value', '_unit']
    @classmethod
    def getUIUnit(cls):
        """
            Returns the global UI units currently in use for that type
        """
        return cls.sUnit(cls.apicls.uiUnit())
    @classmethod
    def setUIUnit(cls, unit=None):
        """
            Sets the global UI units currently to use for that type
        """
        if unit is None :
            cls.apicls.setUIUnit(cls.apicls.internalUnit())
        else :
            cls.apicls.setUIUnit(cls.kUnit(unit))

    @classmethod
    def getInternalUnit(cls):
        """
            Returns the inernal units currently in use for that type
        """
        return cls.sUnit(cls.apicls.internalUnit())

    @classmethod
    def uiToInternal (cls, value) :
        d = cls(value, cls.getUIUnit())
        return d.asInternalUnit()

    @classmethod
    def kUnit(cls, unit=None):
        """
            Converts a string unit name to the internal int unit enum representation
        """
        if unit :
            return cls.Unit.getIndex(unit)
        else :
            return cls.apicls.uiUnit()

    @classmethod
    def sUnit(cls, unit=None) :
        """
            Converts an internal int unit enum representation tp the string unit name
        """
        if unit :
            return cls.Unit.getKey(unit)
        else :
            return str(cls.unit[cls.apicls.uiUnit()])

    def getUnit(self):
        """
            Returns the units currently in effect for this instance
        """
        return self.__class__.sUnit(self._unit)
#    def setUnit(self, unit=None) :
#        """
#            Sets the units currently in effect for this instance
#        """
#        self._unit = self.__class__.kUnit(unit)
    unit = property(getUnit, None, None, "The units currently in effect for this instance")

    def __new__(cls, value, unit=None) :
        unit = cls.kUnit(unit)
        if isinstance(value, cls.apicls):
            value = getattr(value, AS_UNITS)(unit)
        elif isinstance(value, cls):
            value = value.asUnit(unit)
        #data = cls.apicls(value, unit)
        # the float representation uses internal units so that arithmetics work
        #newobj = float.__new__(cls, data.asUnit(cls.apicls.internalUnit()))
        #newobj = float.__new__(cls, data.asUnit(unit))
        newobj = float.__new__(cls, value)
        #ewobj._data = data
        newobj._unit = unit
        newobj._data = cls.apicls(value, unit)
        return newobj

    def assign(self, *args):
        if isinstance (args, self.__class__) :
            args = (args._data, args._unit)
        self._data.assign(*args)

    def __repr__(self) :
        return 'dt.%s(%s, unit=%r)' % ( self.__class__.__name__, self, self.unit )

    def asUnit(self, unit) :
        # in python2.6/maya2010 'as' becomes a keyword.
        return getattr( self._data, AS_UNITS )( self.__class__.kUnit(unit) )

#    def asUnit(self) :
#        return self.asUnit(self.unit)

    def asUIUnit(self) :
        return self.asUnit(self.__class__.getUIUnit())

    def asInternalUnit(self) :
        return self.asUnit(self.__class__.getInternalUnit())

class Time(Unit):
    apicls = _api.MTime
    Unit = _factories.apiClassInfo['MTime']['pymelEnums']['Unit']



class Distance( Unit ) :
    """
        >>> from pymel.core import *
        >>> import pymel.core.datatypes as dt
        >>>
        >>> dt.Distance.getInternalUnit()
        'centimeters'
        >>> dt.Distance.setUIUnit('meters')
        >>> dt.Distance.getUIUnit()
        'meters'

        >>> d = dt.Distance(12)
        >>> d.unit
        'meters'
        >>> print d
        12.0
        >>> print repr(d)
        dt.Distance(12.0, unit='meters')
        >>> print d.asUIUnit()
        12.0
        >>> print d.asInternalUnit()
        1200.0

        >>> dt.Distance.setUIUnit('centimeters')
        >>> dt.Distance.getUIUnit()
        'centimeters'
        >>> e = dt.Distance(12)
        >>> e.unit
        'centimeters'
        >>> print e
        12.0
        >>> str(e)
        '12.0'
        >>> print repr(e)
        dt.Distance(12.0, unit='centimeters')
        >>> print e.asUIUnit()
        12.0
        >>> print e.asInternalUnit()
        12.0

        >>> f = dt.Distance(12, 'feet')
        >>> print f
        12.0
        >>> print repr(f)
        dt.Distance(12.0, unit='feet')
        >>> f.unit
        'feet'
        >>> print f.asUIUnit()
        365.76
        >>> dt.Distance.setUIUnit('meters')
        >>> dt.Distance.getUIUnit()
        'meters'
        >>> print f.asUIUnit()
        3.6576
        >>> dt.Distance.getInternalUnit()
        'centimeters'
        >>> print f.asInternalUnit()
        365.76

        >>> print f.asFeet()
        12.0
        >>> print f.asMeters()
        3.6576
        >>> print f.asCentimeters()
        365.76

        >>> dt.Distance.setUIUnit()
        >>> dt.Distance.getUIUnit()
        'centimeters'
    """
    apicls = _api.MDistance
    Unit = _factories.apiClassInfo['MDistance']['pymelEnums']['Unit']

    def asMillimeter(self) :
        return self.asUnit('millimeter')
    def asCentimeters(self) :
        return self.asUnit('centimeters')
    def asKilometers(self) :
        return self.asUnit('kilometers')
    def asMeters(self) :
        return self.asUnit('meters')

    def asInches(self) :
        return self.asUnit('inches')
    def asFeet(self) :
        return self.asUnit('feet')
    def asYards(self) :
        return self.asUnit('yards')
    def asMiles(self) :
        return self.asUnit('miles')


class Angle( Unit ):
    apicls = _api.MAngle
    Unit = _factories.apiClassInfo['MAngle']['pymelEnums']['Unit']

    def asRadians(self):
        return self.asUnit('radians')
    def asDegrees(self):
        return self.asUnit('degrees')
    def asAngMinutes(self):
        return self.asUnit('angMinutes')
    def asAngSeconds(self):
        return self.asUnit('angSeconds')


class BoundingBox( _api.MBoundingBox):
    apicls = _api.MBoundingBox
    __metaclass__ = _factories.MetaMayaTypeWrapper
    def __init__(self, *args):
        if len(args) == 2:
            args = list(args)
            if not isinstance( args[0], _api.MPoint ):
                args[0] = Point( args[0] )
            if not isinstance( args[1], _api.MPoint ):
                args[1] = Point( args[1] )
        _api.MBoundingBox.__init__(self, *args)
    def __str__(self):
        return 'dt.%s(%s,%s)' % (self.__class__.__name__, self.min(), self.max())
    def __repr__(self):
        return str(self)
    def __getitem__(self,item):
        if item == 0:
            return self.min()
        elif item == 1:
            return self.max()
        raise IndexError, "Index out of range"
    def __melobject__(self):
        """A flat list of 6 values [minx, miny, minz, maxx, maxy, maxz]"""
        return list(self.min()) + list(self.max())

    repr = __str__
    w = property( _factories.wrapApiMethod( _api.MBoundingBox, 'width'  ) )
    h = property( _factories.wrapApiMethod( _api.MBoundingBox, 'height'  ) )
    d = property( _factories.wrapApiMethod( _api.MBoundingBox, 'depth'  ) )

#_factories.ApiTypeRegister.register( 'MVector', Vector )
#_factories.ApiTypeRegister.register( 'MMatrix', Matrix )
#_factories.ApiTypeRegister.register( 'MPoint', Point )
#_factories.ApiTypeRegister.register( 'MColor', Color )
#_factories.ApiTypeRegister.register( 'MQuaternion', Quaternion )
#_factories.ApiTypeRegister.register( 'MEulerRotation', EulerRotation )
_factories.ApiTypeRegister.register( 'MTime', Time, inCast=lambda x: Time(x)._data )
_factories.ApiTypeRegister.register( 'MDistance', Distance, outCast=lambda instance, result: Distance(result,'centimeters').asUIUnit())
_factories.ApiTypeRegister.register( 'MAngle', Angle, outCast=lambda instance, result: Angle(result,'radians').asUIUnit())


#_floatUpConvertDict = {_api.MFloatArray:_api.MDoubleArray,
#                       _api.MFloatMatrix:_api.MMatrix,
#                       _api.MFloatPoint:_api.MPoint,
#                       _api.MFloatPointArray:_api.MPointArray,
#                       _api.MFloatVector:_api.MVector,
#                       _api.MFloatVectorArray:_api.MVectorArray,
#                       FloatMatrix:Matrix,
#                       FloatPoint:Point,
#                       FloatVector:Vector
#                       }
#def _floatUpConvert(input):
#    """Will convert various Float* objects to their corresponding double object
#
#    ie, api.MFloatMatrix => api.MMatrix, FloatPoint => Point
#    """
#    newClass = _floatUpConvertDict.get(input.__class__)
#    if newClass:
#        return newClass(input)
#    else:
#        return input

def getPlugValue( plug ):
    """given an MPlug, get its value as a pymel-style object"""

    #if plug.isArray():
    #    raise TypeError, "array plugs of this type are not supported"

    obj = plug.attribute()
    apiType = obj.apiType()

    # Float Pairs
    if apiType in [ _api.MFn.kAttribute2Double, _api.MFn.kAttribute2Float ] :
        res = []
        for i in range(plug.numChildren()):
            res.append( getPlugValue( plug.child(i) ) )
        if isinstance(res[0],Distance): return Vector(res)
        return res

    # Integer Groups
    elif apiType in [ _api.MFn.kAttribute2Short, _api.MFn.kAttribute2Int, _api.MFn.kAttribute3Short, _api.MFn.kAttribute3Int ] :
        res = []
        for i in range(plug.numChildren()):
            res.append( getPlugValue( plug.child(i) ) )
        return res

    # Float Groups
    elif apiType in [  _api.MFn.kAttribute3Double, _api.MFn.kAttribute3Float, _api.MFn.kAttribute4Double ] :
        res = []
        for i in range(plug.numChildren()):
            res.append( getPlugValue( plug.child(i) ) )

        if isinstance(res[0],Distance):
            return Vector(res)
        elif _api.MFnAttribute(obj).isUsedAsColor():
            return Color(res)
        return res

    # Compound
    elif apiType in [ _api.MFn.kCompoundAttribute ] :
        res = []
        for i in range(plug.numChildren()):
            res.append( getPlugValue( plug.child(i) ) )
        return tuple(res)

    # Distance
    elif apiType in [ _api.MFn.kDoubleLinearAttribute, _api.MFn.kFloatLinearAttribute ] :
        val = plug.asMDistance()
        unit = _api.MDistance.uiUnit()
        # as becomes a keyword in python 2.6
        return Distance( getattr(val, AS_UNITS)( unit ), unit )

    # Angle
    elif apiType in [ _api.MFn.kDoubleAngleAttribute, _api.MFn.kFloatAngleAttribute ] :
        val = plug.asMAngle()
        unit = _api.MAngle.uiUnit()
        # as becomes a keyword in python 2.6
        return Angle( getattr(val, AS_UNITS), unit )

    # Time
    elif apiType == _api.MFn.kTimeAttribute:
        val = plug.asMTime()
        unit = _api.MTime.uiUnit()
        # as becomes a keyword in python 2.6
        return Time( getattr(val, AS_UNITS), unit )

    elif apiType == _api.MFn.kNumericAttribute:
        nAttr = _api.MFnNumericAttribute(obj)
        dataType = nAttr.unitType()
        if dataType == _api.MFnNumericData.kBoolean:
            return plug.asBool()

        elif dataType in [ _api.MFnNumericData.kShort, _api.MFnNumericData.kInt, _api.MFnNumericData.kLong, _api.MFnNumericData.kByte] :
            return plug.asInt()

        elif dataType in [ _api.MFnNumericData.kFloat, _api.MFnNumericData.kDouble, _api.MFnNumericData.kAddr] :
            return plug.asDouble()
        raise "%s: unknown numeric attribute type: %s" % (plug.partialName(True, True, True, False, True, True), dataType)

    elif apiType == _api.MFn.kEnumAttribute:
        # TODO : use EnumValue class?
        return plug.asInt()

    elif apiType == _api.MFn.kTypedAttribute:
        tAttr = _api.MFnTypedAttribute( obj )
        dataType = tAttr.attrType()


        if dataType == _api.MFnData.kInvalid: # 0
            return None

        elif dataType == _api.MFnData.kNumeric: # 1

            # all of the dynamic mental ray attributes fail here, but i have no idea why they are numeric attrs and not message attrs.
            # cmds.getAttr returns None, so we will too.
            try:
                dataObj = plug.asMObject()
            except:
                return

            try:
                numFn = _api.MFnNumericData( dataObj )
            except RuntimeError:
                if plug.isArray():
                    raise TypeError, "%s: numeric arrays are not supported" % plug.partialName(True, True, True, False, True, True)
                else:
                    raise TypeError, "%s: attribute type is numeric, but its data cannot be interpreted numerically" % plug.partialName(True, True, True, False, True, True)
            dataType = numFn.numericType()

            if dataType == _api.MFnNumericData.kBoolean:
                return plug.asBool()

            elif dataType in [ _api.MFnNumericData.kShort, _api.MFnNumericData.kInt, _api.MFnNumericData.kLong, _api.MFnNumericData.kByte] :
                return plug.asInt()

            elif dataType in [ _api.MFnNumericData.kFloat, _api.MFnNumericData.kDouble, _api.MFnNumericData.kAddr] :
                return plug.asDouble()

            elif dataType == _api.MFnNumericData.k2Short :
                ptr1 = _api.SafeApiPtr('short')
                ptr2 = _api.SafeApiPtr('short')

                numFn.getData2Short(ptr1(), ptr2())
                return ( ptr1.get(), ptr2.get() )

            elif dataType in [ _api.MFnNumericData.k2Int, _api.MFnNumericData.k2Long ]:
                ptr1 = _api.SafeApiPtr('int')
                ptr2 = _api.SafeApiPtr('int')

                numFn.getData2Int(ptr1(), ptr2())
                return ( ptr1.get(), ptr2.get() )

            elif dataType == _api.MFnNumericData.k2Float :
                ptr1 = _api.SafeApiPtr('float')
                ptr2 = _api.SafeApiPtr('float')

                numFn.getData2Float(ptr1(), ptr2())
                return ( ptr1.get(), ptr2.get() )

            elif dataType == _api.MFnNumericData.k2Double :
                ptr1 = _api.SafeApiPtr('double')
                ptr2 = _api.SafeApiPtr('double')

                numFn.getData2Double(ptr1(), ptr2())
                return ( ptr1.get(), ptr2.get() )

            elif dataType == _api.MFnNumericData.k3Float:
                ptr1 = _api.SafeApiPtr('float')
                ptr2 = _api.SafeApiPtr('float')
                ptr3 = _api.SafeApiPtr('float')

                numFn.getData3Float(ptr1(), ptr2(), ptr3())
                return ( ptr1.get(), ptr2.get(), ptr3.get() )

            elif dataType ==  _api.MFnNumericData.k3Double:
                ptr1 = _api.SafeApiPtr('double')
                ptr2 = _api.SafeApiPtr('double')
                ptr3 = _api.SafeApiPtr('double')

                numFn.getData3Double(ptr1(), ptr2(), ptr3())
                return ( ptr1.get(), ptr2.get(), ptr3.get() )

            elif dataType == _api.MFnNumericData.kChar :
                return plug.asChar()

            raise TypeError, "%s: Unsupported numeric attribute: %s" % (plug.partialName(True, True, True, False, True, True),dataType)

        elif dataType == _api.MFnData.kString: # 4
            return plug.asString()

        elif dataType == _api.MFnData.kMatrix : # 5
            return Matrix( _api.MFnMatrixData( plug.asMObject() ).matrix() )

        elif dataType == _api.MFnData.kStringArray : # 6
            try:
                dataObj = plug.asMObject()
            except RuntimeError:
                return []
            array = _api.MFnStringArrayData( dataObj ).array()
            return [ array[i] for i in range(array.length()) ]

        elif dataType == _api.MFnData.kDoubleArray : # 7
            try:
                dataObj = plug.asMObject()
            except RuntimeError:
                return []
            array = _api.MFnDoubleArrayData( dataObj ).array()
            return [ array[i] for i in range(array.length()) ]

        elif dataType == _api.MFnData.kIntArray : # 8
            try:
                dataObj = plug.asMObject()
            except RuntimeError:
                return []
            array = _api.MFnIntArrayData( dataObj ).array()
            return [ array[i] for i in range(array.length()) ]

        elif dataType == _api.MFnData.kPointArray : # 9
            try:
                dataObj = plug.asMObject()
            except RuntimeError:
                return []
            array = _api.MFnPointArrayData( dataObj ).array()
            return [ Point(array[i]) for i in range(array.length()) ]

        elif dataType == _api.MFnData.kVectorArray : # 10
            try:
                dataObj = plug.asMObject()
            except RuntimeError:
                return []
            array = _api.MFnVectorArrayData( dataObj ).array()
            return [ Vector(array[i]) for i in range(array.length()) ]

        # this block crashes maya under certain circumstances
#        elif dataType == _api.MFnData.kComponentList : # 11
#            try:
#                dataObj = plug.asMObject()
#            except RuntimeError:
#                return []
#            array = _api.MFnComponentListData( dataObj )
#            return array
#            #return [ Vector(array[i]) for i in range(array.length()) ]

        raise TypeError, "%s: Unsupported typed attribute: %s" % (plug.partialName(True, True, True, False, True, True),dataType)

    raise TypeError, "%s: Unsupported Type: %s" % (plug.partialName(True, True, True, False, True, True), _factories.apiEnumsToApiTypes.get( apiType, apiType ))

def _testMVector() :

    print "Vector class:", dir(Vector)
    u = Vector()
    print u
    print "Vector instance:", dir(u)
    print repr(u)
    print Vector.__readonly__
    print Vector.__slots__
    print Vector.shape
    print Vector.ndim
    print Vector.size
    print u.shape
    print u.ndim
    print u.size
    # should fail
    u.shape = 2

    u.assign(Vector(4, 5, 6))
    print repr(u)
    #Vector([4.0, 5.0, 6.0])
    u = Vector(1, 2, 3)
    print repr(u)
    # Vector([1.0, 2.0, 3.0])
    print len(u)
    # 3
    # inherits from VectorN --> Array
    print isinstance(u, VectorN)
    # True
    print isinstance(u, Array)
    # True
    # as well as _api.Vector
    print isinstance(u, _api.MVector)
    # True
    # accepted directly by API methods
    M = _api.MTransformationMatrix()
    M.setTranslation ( u, _api.MSpace.kWorld )
    # need conversion on the way back though
    u = Vector(M.getTranslation ( _api.MSpace.kWorld ))
    print repr(u)
    # Vector([1.0, 2.0, 3.0])

    u = Vector(x=1, y=2, z=3)
    print repr(u)
    # Vector([1.0, 2.0, 3.0])
    u = Vector([1, 2], z=3)
    print repr(u)
    # Vector([1.0, 2.0, 3.0])
    u = Vector(_api.MPoint(1, 2, 3))
    print repr(u)
    # Vector([1.0, 2.0, 3.0])
    print "u = Vector(VectorN(1, 2, 3))"
    u = Vector(VectorN(1, 2, 3))
    print repr(u)
    # Vector([1.0, 2.0, 3.0])
    u = Vector(1)
    print repr(u)
    # Vector([1.0, 1.0, 1.0])
    u = Vector(1,2)
    print repr(u)
    # Vector([1.0, 2.0, 0.0])
    u = Vector(VectorN(1, shape=(2,)))
    print repr(u)
    # Vector([1.0, 1.0, 0.0])
    u = Vector(Point(1, 2, 3))
    print repr(u)
    # Vector([1.0, 2.0, 3.0])
    u = Vector(Point(1, 2, 3, 1), y=20, z=30)
    print repr(u)
    # Vector([1.0, 20.0, 30.0])
    # should fail
    print "Vector(VectorN(1, 2, 3, 4))"
    try :
        u = Vector(VectorN(1, 2, 3, 4))
    except :
        print "will raise ValueError: could not cast [1, 2, 3, 4] to Vector of size 3, some data would be lost"



    print u.get()
    # (1.0, 20.0, 30.0)
    print u[0]
    1.0
    u[0] = 10
    print repr(u)
    # Vector([10.0, 20.0, 30.0])
    print (10 in u)
    # True
    print list(u)
    # [10.0, 20.0, 30.0]

    u = Vector.xAxis
    v = Vector.yAxis
    print Vector.xAxis
    print str(Vector.xAxis)
    print unicode(Vector.xAxis)
    print repr(Vector.xAxis)

    print "u = Vector.xAxis:"
    print repr(u)
    # Vector([1.0, 0.0, 0.0])
    print "v = Vector.yAxis:"
    print repr(v)
    # Vector([0.0, 1.0, 0.0])
    n = u ^ v
    print "n = u ^ v:"
    print repr(n)
    # Vector([0.0, 0.0, 1.0])
    print "n.x=%s, n.y=%s, n.z=%s" % (n.x, n.y, n.z)
    # n.x=0.0, n.y=0.0, n.z=1.0
    n = u ^ VectorN(v)
    print "n = u ^ VectorN(v):"
    print repr(n)
    # Vector([0.0, 0.0, 1.0])
    n = u ^ [0, 1, 0]
    print "n = u ^ [0, 1, 0]:"
    print repr(n)
    # Vector([0.0, 0.0, 1.0])
    n[0:2] = [1, 1]
    print "n[0:2] = [1, 1]:"
    print repr(n)
    # Vector([1.0, 1.0, 1.0])
    print "n = n * 2 :"
    n = n*2
    print repr(n)
    # Vector([2.0, 2.0, 2.0])
    print "n = n * [0.5, 1.0, 2.0]:"
    n = n*[0.5, 1.0, 2.0]
    print repr(n)
    # Vector([1.0, 2.0, 4.0])
    print "n * n :"
    print n * n
    # 21.0
    print repr(n.clamp(1.0, 2.0))
    # Vector([1.0, 2.0, 2.0])
    print repr(-n)
    # Vector([-1.0, -2.0, -4.0])
    w = u + v
    print repr(w)
    # Vector([1.0, 1.0, 0.0])
    p = Point(1, 2, 3)
    q = u + p
    print repr(q)
    # Point([2.0, 2.0, 3.0, 1.0])
    q = p + u
    print repr(q)
    # Point([2.0, 2.0, 3.0, 1.0])
    print repr(p+q)
    # Point([3.0, 4.0, 6.0, 1.0])
    w = u + VectorN(1, 2, 3, 4)
    print repr(w)
    # VectorN([2.0, 2.0, 3.0, 4])
    print repr(u+2)
    # Vector([3.0, 2.0, 2.0])
    print repr(2+u)
    # Vector([3.0, 2.0, 2.0])
    print repr(p+2)
    # Point([3.0, 4.0, 5.0, 1.0])
    print repr(2+p)
    # Point([3.0, 4.0, 5.0, 1.0])
    print repr(p + u)
    # Point([2.0, 2.0, 3.0, 1.0])
    print repr(VectorN(1, 2, 3, 4) + u)
    # VectorN([2.0, 2.0, 3.0, 4])
    print repr([1, 2, 3] + u)
    # Vector([2.0, 2.0, 3.0])


    u = Vector(1, 2, 3)
    print repr(u)
    # Vector([1.0, 2.0, 3.0])
    print u.length()
    # 3.74165738677
    print length(u)
    # 3.74165738677
    print length([1, 2, 3])
    # 3.74165738677
    print length(VectorN(1, 2, 3))
    # 3.74165738677
    print VectorN(1, 2, 3).length()
    # 3.74165738677
    print length(VectorN(1, 2, 3, 4))
    # 5.47722557505
    print VectorN(1, 2, 3, 4).length()
    # 5.47722557505
    print length(1)
    # 1.0
    print length([1, 2])
    # 2.2360679775
    print length([1, 2, 3])
    # 3.74165738677
    print length([1, 2, 3, 4])
    # 5.47722557505
    print length([1, 2, 3, 4], 0)
    # 5.47722557505
    print length([1, 2, 3, 4], (0,))
    # 5.47722557505
    print length([[1, 2], [3, 4]], 1)
    # [3.16227766017, 4.472135955]
    # should fail
    try :
        print length([1, 2, 3, 4], 1)
    except :
        print "Will raise ValueError, \"axis 0 is the only valid axis for a Vector, 1 invalid\""

    u = Vector(1, 2, 3)
    print repr(u)
    # Vector([1.0, 2.0, 3.0])
    print u.sqlength()
    # 14
    print repr(u.normal())
    # Vector([0.267261241912, 0.534522483825, 0.801783725737])
    u.normalize()
    print repr(u)
    # Vector([0.267261241912, 0.534522483825, 0.801783725737])

    u = Vector(1, 2, 3)
    print repr(u)
    # Vector([1.0, 2.0, 3.0])
    w = u + [0.01, 0.01, 0.01]
    print repr(w)
    # Vector([1.01, 2.01, 3.01])
    print (u == u)
    # True
    print (u == w)
    # False
    print (u == Vector(1.0, 2.0, 3.0))
    # True
    print (u == [1.0, 2.0, 3.0])
    # False
    print (u == Point(1.0, 2.0, 3.0))
    # False
    print u.isEquivalent([1.0, 2.0, 3.0])
    # True
    print u.isEquivalent(Vector(1.0, 2.0, 3.0))
    # True
    print u.isEquivalent(Point(1.0, 2.0, 3.0))
    # True
    print u.isEquivalent(w)
    # False
    print u.isEquivalent(w, 0.1)
    # True

    u = Vector(1, 0, 0)
    print repr(u)
    # Vector([1.0, 0.0, 0.0])
    v = Vector(0.707, 0, -0.707)
    print repr(v)
    # Vector([0.707, 0.0, -0.707])
    print repr(axis(u, v))
    # Vector([-0.0, 0.707, 0.0])
    print repr(u.axis(v))
    # Vector([-0.0, 0.707, 0.0])
    print repr(axis(VectorN(u), VectorN(v)))
    # VectorN([-0.0, 0.707, 0.0])
    print repr(axis(u, v, normalize=True))
    # Vector([-0.0, 1.0, 0.0])
    print repr(v.axis(u, normalize=True))
    # Vector([-0.0, -1.0, 0.0])
    print repr(axis(VectorN(u), VectorN(v), normalize=True))
    # VectorN([-0.0, 1.0, 0.0])
    print angle(u,v)
    # 0.785398163397
    print v.angle(u)
    # 0.785398163397
    print angle(VectorN(u), VectorN(v))
    # 0.785398163397
    print cotan(u, v)
    # 1.0
    print repr(u.rotateTo(v))
    # Quaternion([-0.0, 0.382683432365, 0.0, 0.923879532511])
    print repr(u.rotateBy(u.axis(v), u.angle(v)))
    # Vector([0.707106781187, 0.0, -0.707106781187])
    q = Quaternion([-0.0, 0.382683432365, 0.0, 0.923879532511])
    print repr(u.rotateBy(q))
    # Vector([0.707106781187, 0.0, -0.707106781187])
    print u.distanceTo(v)
    # 0.765309087885
    print u.isParallel(v)
    # False
    print u.isParallel(2*u)
    # True
    print repr(u.blend(v))
    # Vector([0.8535, 0.0, -0.3535])

    print "end tests Vector"

def _testMPoint() :

    print "Point class", dir(Point)
    print hasattr(Point, 'data')
    p = Point()
    print repr(p)
    # Point([0.0, 0.0, 0.0])
    print "Point instance", dir(p)
    print hasattr(p, 'data')
    print repr(p.data)
    # <maya.OpenMaya.Point; proxy of <Swig Object of type 'Point *' at 0x84a1270> >

    p = Point(1, 2, 3)
    print repr(p)
    # Point([1.0, 2.0, 3.0])
    v = Vector(p)
    print repr(v)
    # Vector([1.0, 2.0, 3.0])
    V = VectorN(p)
    print repr(V)
    # VectorN([1.0, 2.0, 3.0, 1.0])
    print list(p)
    # [1.0, 2.0, 3.0]
    print len(p)
    # 3
    print p.size
    # 4
    print p.x, p.y, p.z, p.w
    # 1.0 2.0 3.0 1.0
    print p[0], p[1], p[2], p[3]
    # 1.0 2.0 3.0 1.0
    p.get()
    # 1.0 2.0 3.0 1.0

    # accepted by api
    q = _api.MPoint()
    print q.distanceTo(p)
    # 3.74165738677

    # support for non cartesian points still there

    p = Point(1, 2, 3, 2)
    print repr(p)
    # Point([1.0, 2.0, 3.0, 2.0])
    v = Vector(p)
    print repr(v)
    # Vector([0.5, 1.0, 1.5])
    V = VectorN(p)
    print repr(V)
    # VectorN([1.0, 2.0, 3.0, 2.0])
    print list(p)
    # [1.0, 2.0, 3.0, 2.0]
    print len(p)
    # 4
    print p.size
    # 4
    print p.x, p.y, p.z, p.w
    # 1.0 2.0 3.0 2.0
    print p[0], p[1], p[2], p[3]
    # 1.0 2.0 3.0 2.0
    p.get()
    # 1.0 2.0 3.0 2.0

    # accepted by api
    q = _api.MPoint()
    print q.distanceTo(p)
    # 1.87082869339

    p = Point(_api.MPoint())
    print repr(p)
    # Point([0.0, 0.0, 0.0])
    p = Point(1)
    print repr(p)
    # Point([1.0, 1.0, 1.0])
    p = Point(1, 2)
    print repr(p)
    # Point([1.0, 2.0, 0.0])
    p = Point(1, 2, 3)
    print repr(p)
    # Point([1.0, 2.0, 3.0])
    p = Point(_api.MPoint(1, 2, 3))
    print repr(p)
    # Point([1.0, 2.0, 3.0])
    p = Point(VectorN(1, 2))
    print repr(p)
    # Point([1.0, 2.0, 0.0])
    p = Point(Vector(1, 2, 3))
    print repr(p)
    # Point([1.0, 2.0, 3.0])
    p = Point(_api.MVector(1, 2, 3))
    print repr(p)
    # Point([1.0, 2.0, 3.0])
    p = Point(VectorN(1, 2, 3, 4))
    print repr(p)
    # Point([1.0, 2.0, 3.0, 4.0])
    print repr(Vector(p))
    # Vector([0.25, 0.5, 0.75])
    print repr(VectorN(p))
    # VectorN([1.0, 2.0, 3.0, 4.0])
    p = Point(p, w=1)
    print repr(p)
    # Point([1.0, 2.0, 3.0])
    print repr(Vector(p))
    # Vector([1.0, 2.0, 3.0])
    print repr(VectorN(p))
    # VectorN([1.0, 2.0, 3.0, 1.0])

    p = Point.origin
    print repr(p)
    # Point([0.0, 0.0, 0.0])
    p = Point.xAxis
    print repr(p)
    # Point([1.0, 0.0, 0.0])

    p = Point(1, 2, 3)
    print repr(p)
    # Point([1.0, 2.0, 3.0])
    print repr(p + Vector([1, 2, 3]))
    # Point([2.0, 4.0, 6.0])
    print repr(p + Point([1, 2, 3]))
    # Point([2.0, 4.0, 6.0])
    print repr(p + [1, 2, 3])
    # Point([2.0, 4.0, 6.0])
    print repr(p + [1, 2, 3, 1])
    # Point([2.0, 4.0, 6.0])
    print repr(p + Point([1, 2, 3, 1]))
    # Point([2.0, 4.0, 6.0])
    print repr(p + [1, 2, 3, 2])
    # Point([2.0, 4.0, 6.0, 3.0])    TODO : convert to Point always?
    print repr(p + Point([1, 2, 3, 2]))
    # Point([1.5, 3.0, 4.5])

    print repr(Vector([1, 2, 3]) + p)
    # Point([2.0, 4.0, 6.0])
    print repr(Point([1, 2, 3]) + p)
    # Point([2.0, 4.0, 6.0])
    print repr([1, 2, 3] + p)
    # Point([2.0, 4.0, 6.0])
    print repr([1, 2, 3, 1] + p)
    # Point([2.0, 4.0, 6.0])
    print repr(Point([1, 2, 3, 1]) + p)
    # Point([2.0, 4.0, 6.0])
    print repr([1, 2, 3, 2] + p)
    # Point([2.0, 4.0, 6.0, 3.0])
    print repr(Point([1, 2, 3, 2]) + p)
    # Point([1.5, 3.0, 4.5])

    # various operation, on cartesian and non cartesian points

    print "p = Point(1, 2, 3)"
    p = Point(1, 2, 3)
    print repr(p)
    # Point([1.0, 2.0, 3.0])
    print "p/2"
    print repr(p/2)
    # Point([0.5, 1.0, 1.5])
    print "p*2"
    print repr(p*2)
    # Point([2.0, 4.0, 6.0])
    print "q = Point(0.25, 0.5, 1.0)"
    q = Point(0.25, 0.5, 1.0)
    print repr(q)
    # Point([0.25, 0.5, 1.0])
    print repr(q+2)
    # Point([2.25, 2.5, 3.0])
    print repr(q/2)
    # Point([0.125, 0.25, 0.5])
    print repr(p+q)
    # Point([1.25, 2.5, 4.0])
    print repr(p-q)
    # Vector([0.75, 1.5, 2.0])
    print repr(q-p)
    # Vector([-0.75, -1.5, -2.0])
    print repr(p-(p-q))
    # Point([0.25, 0.5, 1.0])
    print repr(Vector(p)*Vector(q))
    # 4.25
    print repr(p*q)
    # 4.25
    print repr(p/q)
    # Point([4.0, 4.0, 3.0])

    print "p = Point(1, 2, 3)"
    p = Point(1, 2, 3)
    print repr(p)
    # Point([1.0, 2.0, 3.0])
    print "p/2"
    print repr(p/2)
    # Point([0.5, 1.0, 1.5])
    print "p*2"
    print repr(p*2)
    # Point([2.0, 4.0, 6.0])
    print "q = Point(0.25, 0.5, 1.0, 0.5)"
    q = Point(0.25, 0.5, 1.0, 0.5)
    print repr(q)
    # Point([0.25, 0.5, 1.0, 0.5])
    r = q.deepcopy()
    print repr(r)
    # Point([0.25, 0.5, 1.0, 0.5])
    print repr(r.cartesianize())
    # Point([0.5, 1.0, 2.0])
    print repr(r)
    # Point([0.5, 1.0, 2.0])
    print repr(q)
    # Point([0.25, 0.5, 1.0, 0.5])
    print repr(q.cartesian())
    # Point([0.5, 1.0, 2.0])
    r = q.deepcopy()
    print repr(r)
    # Point([0.25, 0.5, 1.0, 0.5])
    print repr(r.rationalize())
    # Point([0.5, 1.0, 2.0, 0.5])
    print repr(r)
    # Point([0.5, 1.0, 2.0, 0.5])
    print repr(q.rational())
    # Point([0.5, 1.0, 2.0, 0.5])
    r = q.deepcopy()
    print repr(r.homogenize())
    # Point([0.125, 0.25, 0.5, 0.5])
    print repr(r)
    # Point([0.125, 0.25, 0.5, 0.5])
    print repr(q.homogen())
    # Point([0.125, 0.25, 0.5, 0.5])
    print repr(q)
    # Point([0.25, 0.5, 1.0, 0.5])
    print Vector(q)
    # [0.5, 1.0, 2.0]
    print Vector(q.cartesian())
    # [0.5, 1.0, 2.0]
    # ignore w
    print "q/2"
    print repr(q/2)
    # Point([0.125, 0.25, 0.5, 0.5])
    print "q*2"
    print repr(q*2)
    # Point([0.5, 1.0, 2.0, 0.5])
    print repr(q+2)             # cartesianize is done by Vector add
    # Point([2.5, 3.0, 4.0])

    print repr(q)
    # Point([0.25, 0.5, 1.0, 0.5])
    print repr(p+Vector(1, 2, 3))
    # Point([2.0, 4.0, 6.0])
    print repr(q+Vector(1, 2, 3))
    # Point([1.5, 3.0, 5.0])
    print repr(q.cartesian()+Vector(1, 2, 3))
    # Point([1.5, 3.0, 5.0])

    print repr(p-q)
    # Vector([0.5, 1.0, 1.0])
    print repr(p-q.cartesian())
    # Vector([0.5, 1.0, 1.0])
    print repr(q-p)
    # Vector([-0.5, -1.0, -1.0])
    print repr(p-(p-q))
    # Point([0.5, 1.0, 2.0])
    print repr(Vector(p)*Vector(q))
    # 4.25
    print repr(p*q)
    # 4.25
    print repr(p/q)             # need explicit homogenize as division not handled by api
    # Point([4.0, 4.0, 3.0, 2.0])    TODO : what do we want here ?
    # Vector([2.0, 2.0, 1.5])
    # additionnal methods

    print "p = Point(x=1, y=2, z=3)"
    p = Point(x=1, y=2, z=3)
    print p.length()
    # 3.74165738677
    print p[:1].length()
    # 1.0
    print p[:2].length()
    # 2.2360679775
    print p[:3].length()
    # 3.74165738677

    p = Point(1.0, 0.0, 0.0)
    q = Point(0.707, 0.0, -0.707)
    print repr(p)
    # Point([1.0, 0.0, 0.0, 1.0])
    print repr(q)
    # Point([0.707, 0.0, -0.707, 1.0])
    print repr(q-p)
    # Vector([-0.293, 0.0, -0.707])
    print repr(axis(Point.origin, p, q))
    # Vector([-0.0, 0.707, 0.0])
    print repr(Point.origin.axis(p, q))
    # Vector([-0.0, 0.707, 0.0])
    print repr(Point.origin.axis(q, p))
    # Vector([0.0, -0.707, 0.0])
    print angle(Point.origin, p, q)
    # 0.785398163397
    print angle(Point.origin, q, p)
    # 0.785398163397
    print Point.origin.angle(p, q)
    # 0.785398163397
    print p.distanceTo(q)
    # 0.765309087885
    print (q-p).length()
    # 0.765309087885
    print cotan(Point.origin, p, q)
    # 1.0
    # obviously True
    print planar(Point.origin, p, q)
    # True
    r = center(Point.origin, p, q)
    print repr(r)
    # Point([0.569, 0.0, -0.235666666667, 1.0])
    print planar(Point.origin, p, q, r)
    # True
    print planar(Point.origin, p, q, r+Vector(0.0, 0.1, 0.0))
    # False
    print bWeights(r, Point.origin, p, q)
    # (0.33333333333333337, 0.33333333333333331, 0.33333333333333343)

    p = Point([0.33333, 0.66666, 1.333333, 0.33333])
    print repr(round(p, 3))
    # Point([0.333, 0.667, 1.333, 0.333])

    print "end tests Point"

def _testMColor() :

    print "Color class", dir(Color)
    print hasattr(Color, 'data')
    c = Color()
    print repr(c)
    # Color([0.0, 0.0, 0.0, 1.0])
    print "Color instance", dir(c)
    print hasattr(c, 'data')
    print repr(c.data)
    # Color([0.0, 0.0, 0.0, 1.0])
    c = Color(_api.MColor())
    print repr(c)
    # Color([0.0, 0.0, 0.0, 1.0])
    # using api convetion of single value would mean alpha
    # instead of VectorN convention of filling all with value
    # which would yield # Color([0.5, 0.5, 0.5, 0.5]) instead
    # This would break coerce behavior for Color
    print "c = Color(0.5)"
    c = Color(0.5)
    print repr(c)
    # Color([0.5, 0.5, 0.5, 0.5])
    print "c = round(Color(128, quantize=255), 2)"
    c = Color(128, quantize=255)
    print repr(c)
    # Color([0.501999974251, 0.501999974251, 0.501999974251, 0.501999974251])
    c = Color(255, 128, b=64, a=32, quantize=255)
    print repr(c)
    # Color([1.0 0.501999974251 0.250999987125 0.125490196078])

    print "c = Color(1, 1, 1)"
    c = Color(1, 1, 1)
    print repr(c)
    # Color([1.0, 1.0, 1.0, 1.0])
    print "c = round(Color(255, 0, 255, g=128, quantize=255, mode='rgb'), 2)"
    c = round(Color(255, 0, 255, g=128, quantize=255, mode='rgb'), 2)
    print repr(c)
    # Color([1.0, 0.5, 1.0, 1.0])

    print "c = round(Color(255, b=128, quantize=255, mode='rgb'), 2)"
    c = round(Color(255, b=128, quantize=255, mode='rgb'), 2)
    print repr(c)
    # Color([1.0, 1.0, 0.5, 1.0])
    print "c = Color(1, 0.5, 2, 0.5)"
    c = Color(1, 0.5, 2, 0.5)
    print repr(c)
    # Color([1.0, 0.5, 2.0, 0.5])
    print "c = Color(0, 65535, 65535, quantize=65535, mode='hsv')"
    c = Color(0, 65535, 65535, quantize=65535, mode='hsv')
    print repr(c)
    # Color([1.0, 0.0, 0.0, 1.0])
    print "c.rgb"
    print repr(c.rgb)
    # (1.0, 0.0, 0.0)
    print "c.hsv"
    print repr(c.hsv)
    # (0.0, 1.0, 1.0)
    d = Color(c, v=0.5, mode='hsv')
    print repr(d)
    # Color([0.5, 0.0, 0.0, 1.0])
    print repr(d.hsv)
    # (0.0, 1.0, 0.5)
    print "c = Color(Color.blue, v=0.5)"
    c = Color(Color.blue, v=0.5)
    print repr(c)
    # Color([0.0, 0.0, 0.5, 1.0])
    print "c.hsv"
    print c.hsv
    # (0.66666666666666663, 1.0, 0.5)
    c.r = 1.0
    print repr(c)
    # Color([1.0, 0.0, 0.5, 1.0])
    print "c.hsv"
    print c.hsv
    # (0.91666666666666663, 1.0, 1.0)

    print "c = Color(1, 0.5, 2, 0.5).clamp()"
    c = Color(1, 0.5, 2, 0.5).clamp()
    print repr(c)
    # Color([1.0, 0.5, 1.0, 0.5])
    print c.hsv
    # (0.83333333333333337, 0.5, 1.0)

    print "Color(c, v=0.5)"
    d = Color(c, v=0.5)
    print repr(d)
    # Color([0.5, 0.25, 0.5, 0.5])
    print "d.hsv"
    print d.hsv
    # (0.83333333333333337, 0.5, 0.5)

    print "c = Color(0.0, 0.5, 1.0, 0.5)"
    c = Color(0.0, 0.5, 1.0, 0.5)
    print repr(c)
    # Color(0.0, 0.5, 1.0, 0.5)
    print "d = c.gamma(2.0)"
    d = c.gamma(2.0)
    print repr(d)
    # Color([0.0, 0.25, 1.0, 0.5])

    print "c = Color.red.blend(Color.blue, 0.5)"
    c = Color.red.blend(Color.blue, 0.5)
    print repr(c)
    # Color([0.5, 0.0, 0.5, 1.0])
    print c.hsv
    # (0.83333333333333337, 1.0, 0.5)
    c = Color.red.hsvblend(Color.blue, 0.5)
    print repr(c)
    # Color([1.0, 0.0, 1.0, 1.0])
    print c.hsv
    # (0.83333333333333337, 1.0, 1.0)

    print "c = Color(0.25, 0.5, 0.75, 0.5)"
    c = Color(0.25, 0.5, 0.75, 0.5)
    print repr(c)
    # Color([0.25, 0.5, 0.75, 0.5])
    print "d = Color.black"
    d = Color.black
    print repr(d)
    # Color([0.0, 0.0, 0.0, 1.0])
    print "c.over(d)"
    print repr(c.over(d))
    # Color([0.125, 0.25, 0.375, 1.0])
    print "d.over(c)"
    print repr(d.over(c))
    # Color([0.0, 0.0, 0.0, 0.5])
    print "c.premult()"
    print repr(c.premult())
    # Color([0.125, 0.25, 0.375, 1.0])

    # herited from Vector

    print "c = Color(0.25, 0.5, 1.0, 1.0)"
    c = Color(0.25, 0.5, 1.0, 1.0)
    print repr(c)
    # Color([0.25, 0.5, 1.0, 1.0])
    print "d = Color(2.0, 1.0, 0.5, 0.25)"
    d = Color(2.0, 1.0, 0.5, 0.25)
    print repr(d)
    # Color([2.0, 1.0, 0.5, 0.25])
    print "-c"
    print repr(-c)
    # Color([-0.25, -0.5, -1.0, 1.0])
    print "e = c*d"
    e = c*d
    print repr(e)
    # Color([0.5, 0.5, 0.5, 0.25])
    print "e + 2"
    print repr(e+2)
    # Color([2.5, 2.5, 2.5, 0.25])
    print "e * 2.0"               # mult by scalar float is defined in api for colors and also multiplies alpha
    print repr(e*2.0)
    # Color([1.0, 1.0, 1.0, 0.5])
    print "e / 2.0"               # as is divide, that ignores alpha now for some reason
    print repr(e/2.0)
    # Color([0.25, 0.25, 0.25, 0.25])
    print "e+Vector(1, 2, 3)"
    print repr(e+Vector(1, 2, 3))
    # Color([1.5, 2.5, 3.5, 0.25])
    # how to handle operations on colors ?
    # here behaves like api but does it make any sense
    # for colors as it is now ?
    print "c+c"
    print repr(c+c)
    # Color([0.5, 1.0, 2.0, 1.0])
    print "c+d"
    print repr(c+d)
    # Color([2.25, 1.5, 1.5, 1.0])
    print "d-c"
    print repr(d-c)
    # Color([1.75, 0.5, -0.5, 0.25])

    print "end tests Color"

def _testMMatrix() :

    print "Matrix class", dir(Matrix)
    m = Matrix()
    print m.formated()
    #[[1.0, 0.0, 0.0, 0.0],
    # [0.0, 1.0, 0.0, 0.0],
    # [0.0, 0.0, 1.0, 0.0],
    # [0.0, 0.0, 0.0, 1.0]]
    print m[0, 0]
    # 1.0
    print repr(m[0:2, 0:3])
    # [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]
    print m(0, 0)
    # 1.0
    print "Matrix instance:", dir(m)
    print Matrix.__readonly__
    print Matrix.__slots__
    print Matrix.shape
    print Matrix.ndim
    print Matrix.size
    print m.shape
    print m.ndim
    print m.size
    # should fail
    m.shape = (4, 4)
    m.shape = 2

    print dir(Space)

    m = Matrix.identity
    # inherits from MatrixN --> Array
    print isinstance(m, MatrixN)
    # True
    print isinstance(m, Array)
    # True
    # as well as _api.Matrix
    print isinstance(m, _api.MMatrix)
    # True
    # accepted directly by API methods
    n = _api.MMatrix()
    m = n.setToProduct(m, m)
    print repr(m)
    print repr(n)

    # inits
    m = Matrix(range(16))
    print m.formated()
    #[[0.0, 1.0, 2.0, 3.0],
    # [4.0, 5.0, 6.0, 7.0],
    # [8.0, 9.0, 10.0, 11.0],
    # [12.0, 13.0, 14.0, 15.0]]
    M = Array(range(16), shape=(8, 2))
    m = Matrix(M)
    print m.formated()
    #[[0.0, 1.0, 2.0, 3.0],
    # [4.0, 5.0, 6.0, 7.0],
    # [8.0, 9.0, 10.0, 11.0],
    # [12.0, 13.0, 14.0, 15.0]]
    M = MatrixN(range(9), shape=(3, 3))
    m = Matrix(M)
    print m.formated()
    #[[0.0, 1.0, 2.0, 0.0],
    # [3.0, 4.0, 5.0, 0.0],
    # [6.0, 7.0, 8.0, 0.0],
    # [0.0, 0.0, 0.0, 1.0]]
    # inherits from MatrixN --> Array
    print isinstance(m, MatrixN)
    # True
    print isinstance(m, Array)
    # True
    # as well as _api.Matrix
    print isinstance(m, _api.MMatrix)
    # True
    # accepted directly by API methods
    n = _api.MMatrix()
    m = n.setToProduct(m, m)
    print repr(m)
    print repr(n)
    t = _api.MTransformationMatrix()
    t.setTranslation ( Vector(1, 2, 3), _api.MSpace.kWorld )
    m = Matrix(t)
    print m.formated()
    #[[1.0, 0.0, 0.0, 0.0],
    # [0.0, 1.0, 0.0, 0.0],
    # [0.0, 0.0, 1.0, 0.0],
    # [1.0, 2.0, 3.0, 1.0]]
    m = Matrix(m, a30=10)
    print m.formated()
    #[[1.0, 0.0, 0.0, 0.0],
    # [0.0, 1.0, 0.0, 0.0],
    # [0.0, 0.0, 1.0, 0.0],
    # [10.0, 2.0, 3.0, 1.0]]
    # should fail
    print "Matrix(range(20)"
    try :
        m = Matrix(range(20))
        print m.formated()
    except :
        print "will raise ValueError: cannot initialize a Matrix of shape (4, 4) from (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19), some information would be lost, use an explicit resize or trim"

    m = Matrix.identity
    M = m.trimmed(shape=(3, 3))
    print repr(M)
    # MatrixN([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])
    print M.formated()
    #[[1.0, 0.0, 0.0],
    # [0.0, 1.0, 0.0],
    # [0.0, 0.0, 1.0]]
    try:
        m.trim(shape=(3, 3))
    except :
        print "will raise TypeError: new shape (3, 3) is not compatible with class Matrix"

    print m.nrow
    # 4
    print m.ncol
    # 4
    # should fail
    try :
        m.nrow = 3
    except :
        print "will raise TypeError: new shape (3, 4) is not compatible with class Matrix"
    print list(m.row)
    # [Array([1.0, 0.0, 0.0, 0.0]), Array([0.0, 1.0, 0.0, 0.0]), Array([0.0, 0.0, 1.0, 0.0]), Array([0.0, 0.0, 0.0, 1.0])]
    print list(m.col)
    # [Array([1.0, 0.0, 0.0, 0.0]), Array([0.0, 1.0, 0.0, 0.0]), Array([0.0, 0.0, 1.0, 0.0]), Array([0.0, 0.0, 0.0, 1.0])]

    m = Matrix( MatrixN(range(9), shape=(3, 3)).trimmed(shape=(4, 4), value=10) )
    print m.formated()
    #[[0.0, 1.0, 2.0, 10.0],
    # [3.0, 4.0, 5.0, 10.0],
    # [6.0, 7.0, 8.0, 10.0],
    # [10.0, 10.0, 10.0, 10.0]]

    print m.get()
    # ((0.0, 1.0, 2.0, 10.0), (3.0, 4.0, 5.0, 10.0), (6.0, 7.0, 8.0, 10.0), (10.0, 10.0, 10.0, 10.0))
    print repr(m[0])
    # [0.0, 1.0, 2.0, 10.0]
    m[0] = 10
    print m.formated()
    #[[10.0, 10.0, 10.0, 10.0],
    # [3.0, 4.0, 5.0, 10.0],
    # [6.0, 7.0, 8.0, 10.0],
    # [10.0, 10.0, 10.0, 10.0]]
    print (10 in m)
    # True
    print list(m)
    # [Array([10.0, 10.0, 10.0, 10.0]), Array([3.0, 4.0, 5.0, 10.0]), Array([6.0, 7.0, 8.0, 10.0]), Array([10.0, 10.0, 10.0, 10.0])]
    print list(m.flat)
    # [10.0, 10.0, 10.0, 10.0, 3.0, 4.0, 5.0, 10.0, 6.0, 7.0, 8.0, 10.0, 10.0, 10.0, 10.0, 10.0]

    u = Vector.xAxis
    v = Vector.yAxis
    print Vector.xAxis
    print str(Vector.xAxis)
    print unicode(Vector.xAxis)
    print repr(Vector.xAxis)

    print "u = Vector.xAxis:"
    print repr(u)

    # trans matrix : t: 1, 2, 3, r: 45, 90, 30, s: 0.5, 1.0, 2.0
    m = Matrix([0.0, 4.1633363423443383e-17, -0.5, 0.0, 0.25881904510252079, 0.96592582628906831, 1.3877787807814459e-16, 0.0, 1.9318516525781366, -0.51763809020504159, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0])
    print "m:"
    print round(m, 2).formated()
    #[[0.0, 0.0, -0.5, 0.0],
    # [0.26, 0.97, 0.0, 0.0],
    # [1.93, -0.52, 0.0, 0.0],
    # [1.0, 2.0, 3.0, 1.0]]

    x = Vector.xAxis
    y = Vector.yAxis
    z = Vector.zAxis
    u = Vector(1, 2, 3)
    print "u:"
    print repr(u)
    # Vector([1, 2, 3])
    print "u*m"
    print repr(u*m)
    # Vector([6.31319304794, 0.378937381963, -0.5])
    print "m*u"
    print repr(m*u)
    # Vector([-1.5, 2.19067069768, 0.896575472168])

    p=Point(1, 10, 100, 1)
    print "p:"
    print repr(p)
    # Point([1.0, 10.0, 100.0, 1.0])
    print "p*m"
    print repr(p*m)
    # Point([196.773355709, -40.1045507576, 2.5, 1.0])
    print "m*p"
    print repr(m*p)
    # Point([-50.0, 9.91807730799, -3.24452924947, 322.0])

    print "v = [1, 2, 3]*m"
    v = VectorN([1, 2, 3])*m
    print repr(v)
    # VectorN([6.31319304794, 0.378937381963, -0.5])
    print "v = [1, 2, 3, 1]*m"
    v = VectorN([1, 2, 3, 1])*m
    print repr(v)
    # VectorN([7.31319304794, 2.37893738196, 2.5, 1.0])
    # should fail
    print "VectorN([1, 2, 3, 4, 5])*m"
    try :
        v = VectorN([1, 2, 3, 4, 5])*m
    except :
        print "Will raise ValueError: vector of size 5 and matrix of shape (4, 4) are not conformable for a VectorN * MatrixN multiplication"

    # herited

    print "m = Matrix(range(1, 17))"
    m = Matrix(range(1, 17))
    print m.formated()
    #[[1.0, 2.0, 3.0, 4.0],
    # [5.0, 6.0, 7.0, 8.0],
    # [9.0, 10.0, 11.0, 12.0],
    # [13.0, 14.0, 15.0, 16.0]]
    # element wise
    print "[1, 10, 100]*m"
    print repr([1, 10, 100]*m)
    # Matrix([[1.0, 20.0, 300.0, 0.0], [5.0, 60.0, 700.0, 0.0], [9.0, 100.0, 1100.0, 0.0], [13.0, 140.0, 1500.0, 0.0]])
    print "M = MatrixN(range(20), shape=(4, 5))"
    M = MatrixN(range(1, 21), shape=(4, 5))
    print M.formated()
    #[[1, 2, 3, 4, 5],
    # [6, 7, 8, 9, 10],
    # [11, 12, 13, 14, 15],
    # [16, 17, 18, 19, 20]]
    print "m*M"
    n = m*M
    print (n).formated()
    #[[110.0, 120.0, 130.0, 140.0, 150.0],
    # [246.0, 272.0, 298.0, 324.0, 350.0],
    # [382.0, 424.0, 466.0, 508.0, 550.0],
    # [518.0, 576.0, 634.0, 692.0, 750.0]]
    print util.clsname(n)
    # MatrixN
    print "m*2"
    n = m*2
    print (n).formated()
    #[[2.0, 4.0, 6.0, 8.0],
    # [10.0, 12.0, 14.0, 16.0],
    # [18.0, 20.0, 22.0, 24.0],
    # [26.0, 28.0, 30.0, 32.0]]
    print util.clsname(n)
    # Matrix
    print "2*m"
    n = 2*m
    print (n).formated()
    #[[2.0, 4.0, 6.0, 8.0],
    # [10.0, 12.0, 14.0, 16.0],
    # [18.0, 20.0, 22.0, 24.0],
    # [26.0, 28.0, 30.0, 32.0]]
    print util.clsname(n)
    # Matrix
    print "m+2"
    n=m+2
    print (n).formated()
    #[[3.0, 4.0, 5.0, 6.0],
    # [7.0, 8.0, 9.0, 10.0],
    # [11.0, 12.0, 13.0, 14.0],
    # [15.0, 16.0, 17.0, 18.0]]
    print util.clsname(n)
    # Matrix
    print "2+m"
    n=2+m
    print (n).formated()
    #[[3.0, 4.0, 5.0, 6.0],
    # [7.0, 8.0, 9.0, 10.0],
    # [11.0, 12.0, 13.0, 14.0],
    # [15.0, 16.0, 17.0, 18.0]]
    print util.clsname(n)
    # Matrix
    try :
        m.setToProduct(m, M)
    except :
        print """Will raise TypeError:  cannot initialize a Matrix of shape (4, 4) from (Array([0, 1, 2, 3, 4]), Array([5, 6, 7, 8, 9]), Array([10, 11, 12, 13, 14]), Array([15, 16, 17, 18, 19])) of shape (4, 5),
                                        as it would truncate data or reduce the number of dimensions"""



    print m.isEquivalent(m*M)
    # False

    # trans matrix : t: 1, 2, 3, r: 45, 90, 30, s: 0.5, 1.0, 2.0
    m = Matrix([0.0, 4.1633363423443383e-17, -0.5, 0.0, 0.25881904510252079, 0.96592582628906831, 1.3877787807814459e-16, 0.0, 1.9318516525781366, -0.51763809020504159, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0])
    print "m:"
    print round(m, 2).formated()
    #[[0.0, 0.0, -0.5, 0.0],
    # [0.26, 0.97, 0.0, 0.0],
    # [1.93, -0.52, 0.0, 0.0],
    # [1.0, 2.0, 3.0, 1.0]]
    print "m.transpose():"
    print round(m.transpose(),2).formated()
    #[[0.0, 0.26, 1.93, 1.0],
    # [0.0, 0.97, -0.52, 2.0],
    # [-0.5, 0.0, 0.0, 3.0],
    # [0.0, 0.0, 0.0, 1.0]]
    print "m.isSingular():"
    print m.isSingular()
    # False
    print "m.inverse():"
    print round(m.inverse(),2).formated()
    #[[0.0, 0.26, 0.48, 0.0],
    # [0.0, 0.97, -0.13, 0.0],
    # [-2.0, 0.0, 0.0, 0.0],
    # [6.0, -2.19, -0.22, 1.0]]
    print "m.adjoint():"
    print round(m.adjoint(),2).formated()
    #[[0.0, 0.26, 0.48, 0.0],
    # [0.0, 0.97, -0.13, 0.0],
    # [-2.0, 0.0, -0.0, 0.0],
    # [6.0, -2.19, -0.22, 1.0]]
    print "m.adjugate():"
    print round(m.adjugate(),2).formated()
    #[[0.0, 0.26, 0.48, 0.0],
    # [0.0, 0.97, -0.13, 0.0],
    # [-2.0, 0.0, -0.0, 0.0],
    # [6.0, -2.19, -0.22, 1.0]]
    print "m.homogenize():"
    print round(m.homogenize(),2).formated()
    #[[0.0, 0.0, -1.0, 0.0],
    # [0.26, 0.97, 0.0, 0.0],
    # [0.97, -0.26, -0.0, 0.0],
    # [1.0, 2.0, 3.0, 1.0]]
    print "m.det():"
    print m.det()
    # 1.0
    print "m.det4x4():"
    print m.det4x4()
    # 1.0
    print "m.det3x3():"
    print m.det3x3()
    # 1.0
    print "m.weighted(0.5):"
    print round(m.weighted(0.5),2).formated()
    #[[0.53, 0.0, -0.53, 0.0],
    # [0.09, 0.99, 0.09, 0.0],
    # [1.05, -0.2, 1.05, 0.0],
    # [0.5, 1.0, 1.5, 1.0]]
    print "m.blend(Matrix.identity, 0.5):"
    print round(m.blend(Matrix.identity, 0.5),2).formated()
    #[[0.53, 0.0, -0.53, 0.0],
    # [0.09, 0.99, 0.09, 0.0],
    # [1.05, -0.2, 1.05, 0.0],
    # [0.5, 1.0, 1.5, 1.0]]

    print "end tests Matrix"

def _testMTransformationMatrix() :

    q = Quaternion()
    print repr(q)
    # Quaternion([0.0, 0.0, 0.0, 1.0])
    q = Quaternion(1, 2, 3, 0.5)
    print repr(q)
    # Quaternion([1.0, 2.0, 3.0, 0.5])
    q = Quaternion(0.785, 0.785, 0.785, "xyz")
    print repr(q)
    # Quaternion([0.191357439088, 0.461717715523, 0.191357439088, 0.844737481223])

    m = Matrix()
    m.rotate = q
    print repr(m)
    # Matrix([[0.500398163355, 0.499999841466, -0.706825181105, 0.0], [-0.146587362969, 0.853529322022, 0.499999841466, 0.0], [0.853295859083, -0.146587362969, 0.500398163355, 0.0], [0.0, 0.0, 0.0, 1.0]])


    print "TransformationMatrix class", dir(TransformationMatrix)
    m = TransformationMatrix()
    print m.formated()
    #[[1.0, 0.0, 0.0, 0.0],
    # [0.0, 1.0, 0.0, 0.0],
    # [0.0, 0.0, 1.0, 0.0],
    # [0.0, 0.0, 0.0, 1.0]]
    print m[0, 0]
    # 1.0
    print m[0:2, 0:3]
    # [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]
    print "TransformationMatrix instance:", dir(m)
    print TransformationMatrix.__readonly__
    print TransformationMatrix.__slots__
    print TransformationMatrix.shape
    print TransformationMatrix.ndim
    print TransformationMatrix.size
    print m.shape
    print m.ndim
    print m.size
    # should fail
    m.shape = (4, 4)
    m.shape = 2

    print dir(Space)

    m = TransformationMatrix.identity
    # inherits from MatrixN --> Array
    print isinstance(m, MatrixN)
    # True
    print isinstance(m, Array)
    # True
    # as well as _api.TransformationMatrix and _api.Matrix
    print isinstance(m, _api.MTransformationMatrix)
    # True
    print isinstance(m, _api.MMatrix)
    # True

    # accepted directly by API methods
    n = _api.MMatrix()
    n = n.setToProduct(m, m)
    print repr(n)

    n = _api.MTransformationMatrix()
    n = n.assign(m)
    print repr(n)

    m = TransformationMatrix.identity
    m.rotation = Quaternion()
    print repr(m)
    print m.formated()


    n = TransformationMatrix.identity
    n.translation = Vector(1, 2, 3)
    print n.formated()
    print repr(n)

    o = m*n
    print repr(o)
    print o.formated()

    print "end tests TransformationMatrix"

if __name__ == '__main__' :
    print Distance.getInternalUnit()
    # centimeters
    print Distance.getUIUnit()
    # centimeters
    Distance.setUIUnit('meters')
    print Distance.getUIUnit()
    # meters
    d = Distance(12)
    print d.unit
    # meters
    print d
    1200.0
    print repr(d)
    Distance(12.0, unit='meters')
    print d.asUnit()
    12.0
    print d.asInternalUnit()
    1200.0

    import doctest
    doctest.testmod(verbose=True)

    _testMVector()
    _testMPoint()
    _testMColor()
    _testMMatrix()
    _testMTransformationMatrix()



########NEW FILE########
__FILENAME__ = effects
"""Functions related to fx"""

import pymel.internal.factories as _factories
import general as _general
_factories.createFunctions( __name__, _general.PyNode )

########NEW FILE########
__FILENAME__ = general
"""
Contains general node and attribute functions, as well as the main `PyNode` base class.

For the rest of the class hierarchy, including `DependNode <pymel.core.nodetypes.DependNode>`, `Transform <pymel.core.nodetypes.Transform>`,
and `Attribute <pymel.core.nodetypes.Attribute>`, see :mod:`pymel.core.nodetypes`.


"""
from __future__ import with_statement

import sys
import os
import re
import itertools
import inspect

import pymel.internal.pmcmds as cmds
import pymel.util as _util
import pymel.internal.factories as _factories
import pymel.internal.pwarnings as _warnings
import pymel.internal.startup as _startup
import pymel.api as _api
import pymel.versions as _versions
import datatypes
from maya.cmds import about as _about
from pymel.internal import getLogger as _getLogger
_logger = _getLogger(__name__)


# TODO: factories.functionFactory should automatically handle conversion of output to PyNodes...
#       ...so we shouldn't always have to do it here as well?

# Get config settings for checking if an attribute is referenced before changing the lock state
CHECK_ATTR_BEFORE_LOCK = _startup.pymel_options.get('check_attr_before_lock', False)

def _getPymelTypeFromObject(obj, name):
    if obj.hasFn(_api.MFn.kDependencyNode):
        fnDepend = _api.MFnDependencyNode( obj )
        mayaType = fnDepend.typeName()
        import nodetypes
        # make sure that if we have a dag node, we return at least DagNode
        # instead of DependNode - otherwise, we will end up with
        # __apiobjects__ = {'MDagPath':MDagPath(...)}, but a pymel type of
        # DependNode... and DependNode.__apihandle__() always assumes that
        # MObjectHandle is always in __apiobjects__
        pymelType = getattr( nodetypes, _util.capitalize(mayaType),
                             nodetypes.DagNode if obj.hasFn(_api.MFn.kDagNode)
                             else nodetypes.DependNode )
        pymelType = _factories.virtualClasses.getVirtualClass(pymelType, obj, name, fnDepend)
    elif obj.hasFn(_api.MFn.kComponent):
        compTypes = _factories.apiEnumsToPyComponents.get(obj.apiType(), None)
        if compTypes is None:
            _logger.raiseLog(_logger.DEBUG, 'Got an instance of a component which could not be mapped to a pymel class: %s' % obj.apiTypeStr())
            compTypes = [Component]
        if len(compTypes) != 1:
            _logger.raiseLog(_logger.WARNING, 'Got an instance of a component with more than one possible PyNode type: %s' % obj.apiTypeStr())
        pymelType = compTypes[0]
    elif obj.hasFn(_api.MFn.kAttribute):
        pymelType = AttributeDefaults
    else:
        raise RuntimeError('Could not determine pymel type for object of type %s' % obj.apiTypeStr())

    return pymelType

def _getPymelType(arg, name) :
    """ Get the correct Pymel Type for an object that can be a MObject, PyNode or name of an existing Maya object,
        if no correct type is found returns DependNode by default.

        If the name of an existing object is passed, the name and MObject will be returned
        If a valid MObject is passed, the name will be returned as None
        If a PyNode instance is passed, its name and MObject will be returned
        """

    obj = None
    results = {}

    isAttribute = False

    #--------------------------
    # API object testing
    #--------------------------
    if isinstance(arg, _api.MObject) :
        results['MObjectHandle'] = _api.MObjectHandle( arg )
        obj = arg

    elif isinstance(arg, _api.MObjectHandle) :
        results['MObjectHandle'] = arg
        obj = arg.object()

    elif isinstance(arg, _api.MDagPath) :
        results['MDagPath'] = arg
        obj = arg.node()

    elif isinstance(arg, _api.MPlug) :
        isAttribute = True
        obj = arg
        results['MPlug'] = obj
        if _api.isValidMPlug(arg):
            pymelType = Attribute
        else :
            raise MayaAttributeError, "Unable to determine Pymel type: the passed MPlug is not valid"

#    #---------------------------------
#    # No Api Object : Virtual PyNode
#    #---------------------------------
#    elif objName :
#        # non existing node
#        pymelType = DependNode
#        if '.' in objName :
#            # TODO : some better checking / parsing
#            pymelType = Attribute
    else :
        raise ValueError( "Unable to determine Pymel type for %r" % (arg,) )

    if not isAttribute:
        pymelType = _getPymelTypeFromObject( obj, name )

    return pymelType, results
#-----------------------------------------------
#  Enhanced Commands
#-----------------------------------------------

# TODO: possible bugfix for 'parent'?
# Docs state 'If there is only a single object specified then the selected objects are parented to that object. '
# ...but actual behavior is to parent the named object (and any other selected objects) to the last selected object

#-----------------------
#  Object Manipulation
#-----------------------

def select(*args, **kwargs):
    """
Modifications:
  - passing an empty list no longer causes an error.
      instead, the selection is cleared if the selection mod is replace (the default);
      otherwise, it does nothing

    """
    try:
        cmds.select(*args, **kwargs)
    except TypeError, msg:
        if args == ([],):
            for modeFlag in ('add', 'af', 'addFirst',
                             'd', 'deselect',
                             'tgl', 'toggle'):
                if kwargs.get(modeFlag, False):
                    return
            # The mode is replace, clear the selection
            cmds.select(cl=True)
        else:
            raise TypeError, msg
#select.__doc__ = mel.help('select') + select.__doc__


# TODO: make it handle multiple objects, like original command
def move(*args, **kwargs):
    """
Modifications:
  - allows any iterable object to be passed as first argument::

        move("pSphere1", [0,1,2])

NOTE: this command also reorders the argument order to be more intuitive, with the object first
    """
    obj = None
    if args and isinstance(args[0], (basestring, PyNode)):
        obj = args[0]
        args = args[1:]

    if len(args) == 1 and _util.isIterable(args[0]):
        args = tuple(args[0])
    if obj is not None:
        args = args + (obj,)
    return cmds.move(*args, **kwargs)

def scale(obj, *args, **kwargs):
    """
Modifications:
  - allows any iterable object to be passed as first argument::

        scale("pSphere1", [0,1,2])

NOTE: this command also reorders the argument order to be more intuitive, with the object first
    """
    if len(args) == 1 and _util.isIterable(args[0]):
        args = tuple(args[0])
    args = args + (obj,)
    return cmds.scale(*args, **kwargs)

def rotate(obj, *args, **kwargs):
    """
Modifications:
  - allows any iterable object to be passed as first argument::

        rotate("pSphere1", [0,1,2])

NOTE: this command also reorders the argument order to be more intuitive, with the object first
    """
    if len(args) == 1 and _util.isIterable(args[0]):
        args = tuple(args[0])
    args = args + (obj,)
    return cmds.rotate(*args, **kwargs)



#-----------------------
#  Attributes
#-----------------------

def connectAttr( source, destination, **kwargs ):
    """
Maya Bug Fix:
  - even with the 'force' flag enabled, the command would raise an error if the connection already existed.

    """
    if kwargs.get('force', False) or kwargs.get('f', False):
        try:
            cmds.connectAttr( source, destination, **kwargs )
        except RuntimeError, e:
            if str(e) != 'Maya command error':
                # we only want to pass on a certain connection error.  all others we re-raise
                raise e
    else:
        cmds.connectAttr( source, destination, **kwargs )

def disconnectAttr( source, destination=None, inputs=None, outputs=None,
                    **kwargs ):
    """
Modifications:
  - If no destination is passed, then all inputs will be disconnected if inputs
      is True, and all outputs will be disconnected if outputs is True; if
      neither are given (or both are None), both all inputs and all outputs
      will be disconnected
    """

    if destination:
        if inputs:
            raise ValueError('inputs/outputs flags may not be used in combination with a destination')
        cmds.disconnectAttr( source, destination, **kwargs )
    else:
        disconnectionDirs = []
        if inputs is None and outputs is None:
            inputs = True
            outputs = True
        if inputs:
            disconnectionDirs.append('inputs')
        if outputs:
            disconnectionDirs.append('outputs')

        for disconnectDir in disconnectionDirs:
            disconnectingInputs = (disconnectDir == 'inputs')
            connections = cmds.listConnections(source,
                                               source=disconnectingInputs,
                                               destination=(not disconnectingInputs),
                                               connections=True,
                                               plugs=True)
            # stupid maya.cmds returns None instead of []...
            if connections is None: continue

            # if disconnectingInputs, results from listConnections will be returned in dest, src order -
            # reverse the list to flip this to src, dest
            if disconnectingInputs:
                connections.reverse()

            for src, dest in _util.pairIter(connections):
                cmds.disconnectAttr( src, dest, **kwargs )

def getAttr( attr, default=None, **kwargs ):
    """
Maya Bug Fix:
  - maya pointlessly returned vector results as a tuple wrapped in a list ( ex.  '[(1,2,3)]' ). This command unpacks the vector for you.

Modifications:
  - casts double3 datatypes to `Vector`
  - casts matrix datatypes to `Matrix`
  - casts vectorArrays from a flat array of floats to an array of Vectors
  - when getting a multi-attr, maya would raise an error, but pymel will return a list of values for the multi-attr
  - added a default argument. if the attribute does not exist and this argument is not None, this default value will be returned
  - added support for getting message attributes
    """
    def listToMat( l ):
        return datatypes.Matrix(
            [     [    l[0], l[1], l[2], l[3]    ],
            [    l[4], l[5], l[6], l[7]    ],
            [    l[8], l[9], l[10], l[11]    ],
            [    l[12], l[13], l[14], l[15] ]    ])

    def listToVec( l ):
        vecRes = []
        for i in range( 0, len(res), 3):
            vecRes.append( datatypes.Vector( res[i:i+3] ) )
        return vecRes

    # stringify fix
    if isinstance(attr, Attribute):
        attr = attr.name(placeHolderIndices=False)
    else:
        attr = unicode(attr)

    try:
        res = cmds.getAttr( attr, **kwargs)

        if isinstance(res, list) and len(res):
            if isinstance(res[0], tuple):
                typ = cmds.getAttr( attr, type=1)
                if typ == 'pointArray':
                    return [ datatypes.Point(x) for x in res ]
                elif typ == 'vectorArray':
                    return [ datatypes.Vector(x) for x in res ]
                res = res[0]
                if typ == 'double3':

                    return datatypes.Vector(list(res))

            #elif cmds.getAttr( attr, type=1) == 'matrix':
            #    return listToMat(res)
            else:
                try:
                    return {
                        'matrix': listToMat,
                        'vectorArray' : listToVec
                        }[cmds.getAttr( attr, type=1)](res)
                except KeyError: pass
        return res

    # perhaps it error'd because it's a mixed compound, or a multi attribute
    except RuntimeError, e:
        try:
            pyattr = Attribute(attr)
            # mixed compound takes precedence, because by default, compound attributes are returned by getAttr, but
            # mixed compounds cannot be expressed in a mel array.
            if pyattr.isCompound():
                return [child.get() for child in pyattr.getChildren() ]
            elif pyattr.isMulti():
                if pyattr.type() == 'message':
                    return pyattr.listConnections()
                return [pyattr[i].get() for i in range(pyattr.numElements())]
            # re-raise error
            elif pyattr.type() == 'message':
                connects = pyattr.listConnections()
                if connects:
                    return connects[0]
                else:
                    return None
            raise
        except AttributeError:
            if default is not None:
                return default
            # raise original RuntimeError
            raise e


class AmbiguityWarning(Warning):
    pass

# getting and setting
def setAttr( attr, *args, **kwargs):
    """
Maya Bug Fix:
  - setAttr did not work with type matrix.

Modifications:
  - No need to set type, this will automatically be determined
  - Adds support for passing a list or tuple as the second argument for datatypes such as double3.
  - When setting stringArray datatype, you no longer need to prefix the list with the number of elements - just pass a list or tuple as with other arrays
  - Added 'force' kwarg, which causes the attribute to be added if it does not exist.
        - if no type flag is passed, the attribute type is based on type of value being set (if you want a float, be sure to format it as a float, e.g.  3.0 not 3)
        - currently does not support compound attributes
        - currently supported python-to-maya mappings:

            python type  maya type
            ============ ===========
            float        double
            ------------ -----------
            int          long
            ------------ -----------
            str          string
            ------------ -----------
            bool         bool
            ------------ -----------
            Vector       double3
            ------------ -----------
            Matrix       matrix
            ------------ -----------
            [str]        stringArray
            ============ ===========


    >>> addAttr( 'persp', longName= 'testDoubleArray', dataType='doubleArray')
    >>> setAttr( 'persp.testDoubleArray', [0,1,2])
    >>> setAttr( 'defaultRenderGlobals.preMel', 'sfff')

  - Added ability to set enum attributes using the string values; this may be
    done either by setting the 'asString' kwarg to True, or simply supplying
    a string value for an enum attribute.

    """
    datatype = kwargs.get( 'type', kwargs.get( 'typ', None) )

    # if there is only one argument we do our special pymel tricks
    if len(args) == 1:

        arg = args[0]

        # force flag
        force = kwargs.pop('force', kwargs.pop('f', False) )

        # asString flag
        asString = kwargs.pop('asString', None)

        # vector, matrix, and arrays
        if _util.isIterable(arg):
            if datatype is None:
                # if using force flag and the attribute does not exist
                # we can infer the type from the passed value
                #attr = Attribute(attr)
                if force and not cmds.objExists(attr): #attr.exists():
                    import pymel.util.nameparse as nameparse
                    attrName = nameparse.parse( attr )
                    assert attrName.isAttributeName(), "passed object is not an attribute"
                    try:
                        if isinstance( arg[0], (basestring, _util.ProxyUnicode ) ):
                            datatype = 'stringArray'
                        elif isinstance( arg[0], (list,datatypes.Vector) ):
                            datatype = 'vectorArray'
                        elif isinstance( arg[0], (list,datatypes.Point) ):
                            datatype = 'pointArray'
                        elif isinstance( arg, datatypes.Vector):
                            datatype = 'double3'
                        elif isinstance( arg,  datatypes.Matrix ):
                            datatype = 'matrix'
                        elif isinstance( arg[0], int ):
                            datatype = 'Int32Array'
                        elif isinstance( arg[0], float ):
                            datatype = 'doubleArray'
                            if len(arg)==3:
                                _logger.warn(
                                    "The supplied value will be interperted as a 'doubleArray' and not as a 'double3' (vector). "
                                    "Supply an explicit 'datatype' argument to avoid this warning." )
                        else:
                            raise ValueError, "pymel.core.setAttr: %s is not a supported type for use with the force flag" % type(arg[0])

                        #_logger.debug("adding %r as %r", attr, datatype)
                        addAttr( attrName.nodePath, ln=attrName.attribute, dt=datatype )

                    # empty array is being passed
                    # if the attribute exists, this is ok
                    except IndexError:
                        raise ValueError, "pymel.core.setAttr: when setting 'force' keyword to create a new array attribute, you must provide an array with at least one element"

                    except TypeError:
                        raise ValueError, "pymel.core.setAttr: %s is not a supported type" % type(args)

                else:
                    if isinstance( arg, datatypes.Vector):
                        datatype = 'double3'
                    elif isinstance( arg, datatypes.Matrix ):
                        datatype = 'matrix'
                    else:
                        datatype = getAttr( attr, type=1)
                        if not datatype:
                            datatype = addAttr( attr, q=1, dataType=1) #[0] # this is returned as a single element list
                if datatype:
                    kwargs['type'] = datatype

            try:
                arg = arg.__melobject__()
            except AttributeError:
                pass
            if datatype == 'stringArray':
                # string arrays:
                #    first arg must be the length of the array being set
                # ex:
                #     setAttr('loc.strArray',["first", "second", "third"] )
                # becomes:
                #     cmds.setAttr('loc.strArray',3,"first", "second", "third",type='stringArray')
                args = tuple( [len(arg)] + arg )

            elif datatype in ['vectorArray', 'pointArray']:
                if _versions.current() < _versions.v2011:
                    # vector arrays:
                    #    first arg must be the length of the array being set
                    #    empty values are placed between vectors
                    # ex:
                    #     setAttr('loc.vecArray',[1,2,3],[4,5,6],[7,8,9] )
                    # becomes:
                    #     cmds.setAttr('loc.vecArray',3,[1,2,3],"",[4,5,6],"",[7,8,9],type='vectorArray')
                    arg = list(arg)
                    size = len(arg)
                    try:
                        tmpArgs = [arg.pop(0)]
                        for filler, real in zip( [""]*(size-1), arg ):
                            tmpArgs.append( filler )
                            tmpArgs.append( real )
                    except IndexError:
                        tmpArgs = []

                    args = tuple( [size] + tmpArgs )
                else:
                    # vector arrays:
                    #    first arg must be the length of the array being set
                    #    empty values are placed between vectors
                    # ex:
                    #     setAttr('loc.vecArray',[1,2,3],[4,5,6],[7,8,9] )
                    # becomes:
                    #     cmds.setAttr('loc.vecArray',3,[1,2,3],[4,5,6],[7,8,9],type='vectorArray')
                    arg = list(arg)
                    size = len(arg)
                    args = tuple( [size] + arg )

                #print args

            elif datatype in ['Int32Array', 'doubleArray']:
                # int32 and double arrays:
                #   actually fairly sane
                # ex:
                #     setAttr('loc.doubleArray',[1,2,3] )
                # becomes:
                #     cmds.setAttr('loc.doubleArray',[1,2,3],type='doubleArray')
                args = (tuple(arg),)
            else:
                # others: short2, short3, long2, long3, float2, etc...
                #    args must be expanded
                # ex:
                #     setAttr('loc.foo',[1,2,3] )
                # becomes:
                #     cmds.setAttr('loc.foo',1,2,3 )
                args = tuple(arg)

        # non-iterable types
        else:
            if datatype is None:
                #attr = Attribute(attr)
                if force and not cmds.objExists(attr): #attr.exists():
                    import pymel.util.nameparse as nameparse
                    attrName = nameparse.parse( attr )
                    assert attrName.isAttributeName(), "passed object is not an attribute"
                    if isinstance( arg, basestring ):
                        addAttr( attrName.nodePath, ln=attrName.attribute, dt='string' )
                        kwargs['type'] = 'string'
                    elif isinstance( arg, int ):
                        addAttr( attrName.nodePath, ln=attrName.attribute, at='long' )
                    elif isinstance( arg, float ):
                        addAttr( attrName.nodePath, ln=attrName.attribute, at='double' )
                    elif isinstance( arg, bool ):
                        addAttr( attrName.nodePath, ln=attrName.attribute, at='bool' )
                    else:
                        raise TypeError, "%s.setAttr: %s is not a supported type for use with the force flag" % ( __name__, type(arg) )

                elif isinstance(arg, (basestring, _util.ProxyUnicode)):
                    if asString is None:
                        if isinstance(attr, Attribute):
                            attrType = attr.type()
                        else:
                            attrType = cmds.getAttr(attr, type=1)
                        asString = (attrType == 'enum')
                    if asString:
                        val = getEnums(attr).get(arg)
                        if val is None:
                            raise MayaAttributeEnumError(attr, arg)
                        arg = val
                        args = (val,)
                    else:
                        kwargs['type'] = 'string'

    if datatype == 'matrix' and _versions.current() < _versions.v2011:
        import language
        #language.mel.setAttr( attr, *args, **kwargs )
        strFlags = [ '-%s %s' % ( key, language.pythonToMel(val) ) for key, val in kwargs.items() ]
        cmd = 'setAttr %s %s %s' % ( attr, ' '.join( strFlags ), ' '.join( [str(x) for x in args] ) )
        import maya.mel as _mm
        #print cmd
        _mm.eval(cmd)
        return

    # stringify fix
    attr = unicode(attr)

    try:
        #print args, kwargs
        cmds.setAttr( attr, *args, **kwargs)
    except TypeError, msg:
        val = kwargs.pop( 'type', kwargs.pop('typ', False) )
        typ = addAttr( attr, q=1, at=1)
        if val == 'string' and typ == 'enum':
            enums = addAttr(attr, q=1, en=1).split(":")
            index = enums.index( args[0] )
            args = ( index, )
            cmds.setAttr( attr, *args, **kwargs)
        else:
            raise TypeError, msg
    except RuntimeError, msg:
        # normally this is handled in pmcmds, but setAttr error is different for some reason
        # can't use 'startswith' because of Autodesk test strings wrapped in commas
        if 'No object matches name: ' in str(msg):
            raise _objectError(attr)
        else:
            # re-raise
            raise

def addAttr( *args, **kwargs ):
    """
Modifications:
  - allow python types to be passed to set -at type
            str         string
            float       double
            int         long
            bool        bool
            Vector      double3
  - when querying dataType, the dataType is no longer returned as a list
  - when editing hasMinValue, hasMaxValue, hasSoftMinValue, or hasSoftMaxValue the passed boolean value was ignored
    and the command instead behaved as a toggle.  The behavior is now more intuitive::

        >>> addAttr('persp', ln='test', at='double', k=1)
        >>> addAttr('persp.test', query=1, hasMaxValue=True)
        False
        >>> addAttr('persp.test', edit=1, hasMaxValue=False)
        >>> addAttr('persp.test', query=1, hasMaxValue=True)
        False
        >>> addAttr('persp.test', edit=1, hasMaxValue=True)
        >>> addAttr('persp.test', query=1, hasMaxValue=True)
        True

  - allow passing a list or dict instead of a string for enumName
    """
    at = kwargs.pop('attributeType', kwargs.pop('at', None ))
    if at is not None:
        try:
            kwargs['at'] = {
                float: 'double',
                int: 'long',
                bool: 'bool',
                datatypes.Vector: 'double3',
                str: 'string',
                unicode: 'string'
            }[at]
        except KeyError:
            kwargs['at'] = at

    if kwargs.get( 'e', kwargs.get('edit',False) ):
            for editArg, value in kwargs.iteritems():
                if editArg not in ('e', 'edit') and value:
                    break
            if editArg in ('hasMinValue', 'hnv', 'hasMaxValue', 'hxv', 'hasSoftMinValue', 'hsn', 'hasSoftMaxValue', 'hsx'):
                # bugfix: hasM*Value works as a toggle, regardless of whether you specify True or False
                if bool(value) != bool(cmds.addAttr(*args, **{'query':True, editArg:True})):
                    return cmds.addAttr(*args, **kwargs)
                else:
                    # otherwise, don't do anything, bc the value is already correct
                    return

    # translate dict or list for enumName
    enums = kwargs.pop('en', kwargs.pop('enumName', None))
    if enums is not None:
        kwargs['enumName'] = _toEnumStr(enums)

    # MObject stringify Fix
    #args = map(unicode, args)
    res = cmds.addAttr( *args, **kwargs )
    if kwargs.get( 'q', kwargs.get('query',False) ):
        # When addAttr is queried, and has multiple other query flags - ie,
        #   addAttr('joint1.sweetpea', q=1, parent=1, dataType=1)
        # ... it seems to ignore every kwarg but the 'first'
        for queriedArg, value in kwargs.iteritems():
            if queriedArg not in ('q', 'query') and value:
                break
        if queriedArg in ('dt', 'dataType'):
            # If the attr is not a dynamic attribute, maya.cmds prints:
            #    Error: '...' is not a dynamic attribute of node '...'.
            # ...but does NOT raise an exception
            # Because it will be more consistent with maya.cmds, and because
            # attributeType already behaves like this, we will do the same -
            # allow maya.cmds to print it's error message, and return None, but
            # not raise an exception
            if res is not None:
                res = res[0]
        elif queriedArg in ('p', 'parent'):
            node = None
            if args:
                node = PyNode(args[0])
            else:
                node = ls(sl=1)[0]
            if isinstance(node, Attribute):
                node = node.node()
            res = node.attr(res)

#    else:
#        # attempt to gather Attributes we just made
#        # this is slightly problematic because compound attributes are invalid
#        # until all of their children are created, as in these example from the docs
#
#        #addAttr( longName='sampson', numberOfChildren=5, attributeType='compound' )
#        #addAttr( longName='homeboy', attributeType='matrix', parent='sampson' )
#        #addAttr( longName='midge', attributeType='message', parent='sampson' )
#        #addAttr( longName='damien', attributeType='double', parent='sampson' )
#        #addAttr( longName='elizabeth', attributeType='double', parent='sampson' )
#        #addAttr( longName='sweetpea', attributeType='double', parent='sampson' )
#
#
#        if not args:
#            args=cmds.ls(sl=1,l=1)
#        longName = kwargs.pop( 'longName', kwargs.get('ln',None) )
#        shortName = kwargs.pop( 'shortName', kwargs.get('sn',None) )
#        name = longName if longName else shortName
#        assert name, "could not determine name of attribute"
#        res = [ Attribute(x + '.' + name) for x in args]

    return res

def hasAttr( pyObj, attr, checkShape=True ):
    """convenience function for determining if an object has an attribute.
    If checkShape is enabled, the shape node of a transform will also be checked for the attribute.

    :rtype: `bool`
    """
    if not isinstance( pyObj, PyNode ):
        raise TypeError, "hasAttr requires a PyNode instance and a string"

    import nodetypes
    if isinstance( pyObj, nodetypes.Transform ):
        try:
            pyObj.attr(attr,checkShape=checkShape)
            return True
        except AttributeError:
            return False

    try:
        pyObj.attr(attr)
        return True
    except AttributeError:
        return False

#-----------------------
#  Attr Enums
#-----------------------

def _toEnumStr(enums):
    if isinstance(enums, dict):
        firstKey = enums.iterkeys().next()
        firstVal = enums.itervalues().next()
        if isinstance(firstKey, basestring) and isinstance(firstVal, int):
            enums = ['%s=%s' % (key, val) for key, val in enums.iteritems()]
        elif isinstance(firstKey, int) and isinstance(firstVal, basestring):
            enums = ['%s=%s' % (val, key) for key, val in enums.iteritems()]
        else:
            raise ValueError('dict must map from strings to ints, or vice-versa')
    if isinstance(enums, basestring):
        enumStr = enums
    else:
        enumStr = ":".join(enums)
    return enumStr

def setEnums(attr, enums):
    cmds.addAttr(attr, e=1, en=_toEnumStr(enums))

def getEnums(attr):
    """
    :rtype: `util.enum.EnumDict`

    >>> addAttr( "persp", ln='numbers', at='enum', enumName="zero:one:two:thousand=1000:three")
    >>> numbers = Attribute('persp.numbers').getEnums()
    >>> sorted(numbers.items())
    [(u'one', 1), (u'thousand', 1000), (u'three', 1001), (u'two', 2), (u'zero', 0)]
    >>> numbers[1]
    u'one'
    >>> numbers['thousand']
    1000

    """
    if isinstance(attr, Attribute):
        attrName = attr.attrName()
        node = attr.node().name()
    else:
        node, attrName = unicode(attr).rsplit('.', 1)
    enum_list = cmds.attributeQuery(attrName, node=node,
                                    listEnum=True)[0].split(':')

    enum_dict = {}
    index = 0
    for enum in enum_list:
        try:
            name, value = enum.split(u'=')
            index = int(value)
            enum = name
        except:
            pass
        enum_dict[enum] = index
        index += 1

    return _util.enum.EnumDict(enum_dict)

#-----------------------
#  List Functions
#-----------------------

#def listAttr(*args, **kwargs):
#    """
#Modifications:
#  - returns an empty list when the result is None
#    """
#    return _util.listForNone(cmds.listAttr(*args, **kwargs))

def listConnections(*args, **kwargs):
    """
Modifications:
  - returns an empty list when the result is None
  - returns an empty list (with a warning) when the arg is an empty list, tuple,
        set, or frozenset, making it's behavior consistent with when None is
        passed, or no args and nothing is selected (would formerly raise a
        TypeError)
  - When 'connections' flag is True, the attribute pairs are returned in a 2D-array::

        [['checker1.outColor', 'lambert1.color'], ['checker1.color1', 'fractal1.outColor']]

  - added sourceFirst keyword arg. when sourceFirst is true and connections is also true,
        the paired list of plugs is returned in (source,destination) order instead of (thisnode,othernode) order.
        this puts the pairs in the order that disconnectAttr and connectAttr expect.
  - added ability to pass a list of types

    :rtype: `PyNode` list
    """
    # We need to force casting to Attribute, as opposed to just Pynode,
    # if we are returning plugs, because PyNode will prefer component
    # objects over attributes when there is amibiguity - ie,
    # PyNode('myNode.rotatePivot') will give a component
    args = tuple(None if isinstance(x, (list, tuple, set, frozenset)) and not x
                 else x for x in args)
    plugs = kwargs.get('plugs', kwargs.get('p', False))
    if plugs:
        CastObj = Attribute
    else:
        CastObj = PyNode

    def makePairs(l):
        if l is None:
            return []
        return [(CastObj(a), CastObj(b)) for (a, b) in _util.pairIter(l)]

    # group the core functionality into a funcion, so we can call in a loop when passed a list of types
    def doIt(**kwargs):
        if kwargs.get('connections', kwargs.get('c', False) ) :

            if kwargs.pop('sourceFirst',False):
                source = kwargs.get('source', kwargs.get('s', True ) )
                dest = kwargs.get('destination', kwargs.get('d', True ) )

                if source:
                    if not dest:
                        return [ (s, d) for d, s in makePairs( cmds.listConnections( *args,  **kwargs ) ) ]
                    else:
                        res = []
                        kwargs.pop('destination', None)
                        kwargs['d'] = False
                        res = [ (s, d) for d, s in makePairs( cmds.listConnections( *args,  **kwargs )) ]

                        kwargs.pop('source', None)
                        kwargs['s'] = False
                        kwargs['d'] = True
                        return makePairs(cmds.listConnections( *args,  **kwargs )) + res

                # if dest passes through to normal method

            return makePairs( cmds.listConnections( *args,  **kwargs ) )

        else:
            return map(CastObj, _util.listForNone(cmds.listConnections( *args,  **kwargs )) )

    # if passed a list of types, concatenate the resutls
    # NOTE: there may be duplicate results if a leaf type and it's parent are both passed: ex.  animCurve and animCurveTL
    types = kwargs.get('type', kwargs.get('t',None))
    if _util.isIterable(types):
        types = list(set(types)) # remove dupes from types list
        kwargs.pop('type',None)
        kwargs.pop('t',None)
        res = []
        for type in types:
            ikwargs = kwargs.copy()
            ikwargs['type'] = type
            res += doIt(**ikwargs)
        return res
    else:
        return doIt(**kwargs)

def listHistory( *args, **kwargs ):
    """
Modifications:
  - returns an empty list when the result is None
  - raises a RuntimeError when the arg is an empty list, tuple, set, or
        frozenset, making it's behavior consistent with when None is passed, or
        no args and nothing is selected (would formerly raise a TypeError)
  - added a much needed 'type' filter
  - added an 'exactType' filter (if both 'exactType' and 'type' are present, 'type' is ignored)

    :rtype: `DependNode` list

    """
    args = tuple(None if isinstance(x, (list, tuple, set, frozenset)) and not x
                 else x for x in args)
    type = exactType = None
    if 'type' in kwargs:
        type = kwargs.pop('type')
    if 'exactType' in kwargs:
        exactType = kwargs.pop('exactType')

    results = [PyNode(x) for x in _util.listForNone(cmds.listHistory( *args,  **kwargs ))]

    if exactType:
        results = [x for x in results if x.nodeType() == exactType]
    elif type:
        results = [x for x in results if type in x.nodeType(inherited=True)]

    return results


def listFuture( *args, **kwargs ):
    """
Modifications:
  - returns an empty list when the result is None
  - added a much needed 'type' filter
  - added an 'exactType' filter (if both 'exactType' and 'type' are present, 'type' is ignored)

    :rtype: `DependNode` list

    """
    kwargs['future'] = True

    return listHistory(*args, **kwargs)


def listRelatives( *args, **kwargs ):
    """
Maya Bug Fix:
  - allDescendents and shapes flags did not work in combination
  - noIntermediate doesn't appear to work

Modifications:
  - returns an empty list when the result is None
  - returns an empty list when the arg is an empty list, tuple, set, or
        frozenset, making it's behavior consistent with when None is passed, or
        no args and nothing is selected (would formerly raise a TypeError)
  - returns wrapped classes
  - fullPath is forced on to ensure that all returned node paths are unique

    :rtype: `DependNode` list
    """
    args = tuple(None if isinstance(x, (list, tuple, set, frozenset)) and not x
                 else x for x in args)
    kwargs['fullPath'] = True
    kwargs.pop('f', None)
    # Stringify Fix
    #args = [ unicode(x) for x in args ]
    if kwargs.get( 'allDescendents', kwargs.get('ad', False) ) and kwargs.pop( 'shapes', kwargs.pop('s', False) ):
        kwargs['fullPath'] = True
        kwargs.pop('f', None)

        res = cmds.listRelatives( *args, **kwargs)
        if res is None:
            return []
        return ls( res, shapes=1)

    results = map(PyNode, _util.listForNone(cmds.listRelatives(*args, **kwargs)))
    #Fix that noIntermediate doesn't seem to work in list relatives
    if kwargs.get('noIntermediate',kwargs.get('ni',False)):
        return [ result for result in results if not result.intermediateObject.get()]
    return results


def ls( *args, **kwargs ):
    """
Modifications:
  - Returns PyNode objects, not "names" - all flags which do nothing but modify
    the string name of returned objects are ignored (ie, 'long'); note that
    the 'allPaths' flag DOES have an effect, as PyNode objects are aware of
    their dag paths (ie, two different instances of the same object will result
    in two unique PyNodes)
  - Added new keyword: 'editable' - this will return the inverse set of the readOnly flag. i.e. non-read-only nodes
  - Added new keyword: 'regex' - pass a valid regular expression string, compiled regex pattern, or list thereof.

        >>> group('top')
        nt.Transform(u'group1')
        >>> duplicate('group1')
        [nt.Transform(u'group2')]
        >>> group('group2')
        nt.Transform(u'group3')
        >>> ls(regex='group\d+\|top') # don't forget to escape pipes `|`
        [nt.Transform(u'group1|top'), nt.Transform(u'group2|top')]
        >>> ls(regex='group\d+\|top.*')
        [nt.Transform(u'group1|top'), nt.Camera(u'group1|top|topShape'), nt.Transform(u'group2|top'), nt.Camera(u'group2|top|topShape')]
        >>> ls(regex='group\d+\|top.*', cameras=1)
        [nt.Camera(u'group2|top|topShape'), nt.Camera(u'group1|top|topShape')]
        >>> ls(regex='\|group\d+\|top.*', cameras=1) # add a leading pipe to search for full path
        [nt.Camera(u'group1|top|topShape')]

    The regular expression will be used to search the full DAG path, starting from the right, in a similar fashion to how globs currently work.
    Technically speaking, your regular expression string is used like this::

        re.search( '(\||^)' + yourRegexStr + '$', fullNodePath )

    :rtype: `PyNode` list
    """
    kwargs['long'] = True
    kwargs.pop('l', None)

#    # TODO: make this safe for international unicode characters
#    validGlobChars = re.compile('[a-zA-Z0-9_|.*?\[\]]+$')
#    newArgs = []
#    regexArgs = []
#    for arg in args:
#        if isinstance(arg, (list, tuple)):
#            # maya only goes one deep, and only checks for lists or tuples
#            for subarg in arg:
#                if isinstance(subarg, basestring) and not validGlobChars.match(subarg):
#                    regexArgs.append(subarg)
#                else:
#                    newArgs.append(subarg)
#        elif isinstance(arg, basestring) and not validGlobChars.match(arg):
#            regexArgs.append(arg)
#        else:
#            newArgs.append(arg)

    regexArgs = kwargs.pop('regex', [])
    if not isinstance(regexArgs, (tuple,list)):
        regexArgs = [regexArgs]

    for i,val in enumerate(regexArgs):
        # add a prefix which allows the regex to match against a dag path, mounted at the right
        if isinstance(val,basestring):
            if not val.endswith('$'):
                val = val + '$'
            val = re.compile('(\||^)' + val)
        elif not isinstance(val,re._pattern_type):
            raise TypeError( 'regex flag must be passed a valid regex string, a compiled regex object, or a list of these types. got %s' % type(val).__name__ )
        regexArgs[i] = val

    editable = kwargs.pop('editable', False)

    res = _util.listForNone(cmds.ls(*args, **kwargs))
    if regexArgs:
        tmp = res
        res = []
        for x in tmp:
            for reg in regexArgs:
                if reg.search(x):
                    res.append(x)
                    break

    if editable:
        kwargs['readOnly'] = True
        kwargs.pop('ro',True)
        roNodes = _util.listForNone(cmds.ls(*args, **kwargs))
        # faster way?
        return map( PyNode, filter( lambda x: x not in roNodes, res ) )


    if kwargs.get( 'readOnly', kwargs.get('ro', False) ):
        # when readOnly is provided showType is ignored
        return map(PyNode, res)

    if kwargs.get( 'showType', kwargs.get('st', False) ):
        tmp = res
        res = []
        for i in range(0,len(tmp),2):
            res.append( PyNode( tmp[i] ) )
            res.append( tmp[i+1] )
        return res

    if kwargs.get( 'nodeTypes', kwargs.get('nt', False) ):
        return res

#    kwargs['showType'] = True
#    tmp = _util.listForNone(cmds.ls(*args, **kwargs))
#    res = []
#    for i in range(0,len(tmp),2):
#        res.append( PyNode( tmp[i], tmp[i+1] ) )
#
#    return res
    return map(PyNode, res)


#    showType = kwargs.get( 'showType', kwargs.get('st', False) )
#    kwargs['showType'] = True
#    kwargs.pop('st',None)
#    res = []
#    if kwargs.get( 'readOnly', kwargs.get('ro', False) ):
#
#        ro = cmds.ls(*args, **kwargs) # showType flag will be ignored
#
#        # this was unbelievably slow
#
#        kwargs.pop('readOnly',None)
#        kwargs.pop('ro',None)
#        all = cmds.ls(*args, **kwargs)
#        for pymel.core.node in ro:
#            try:
#                idx = all.index(pymel.core.node)
#                all.pop(idx)
#                typ = all.pop(idx+1)
#                res.append( PyNode( pymel.core.node, typ ) )
#                if showType:
#                    res.append( typ )
#            except ValueError: pass
#        return res
#    else:
#        tmp = _util.listForNone(cmds.ls(*args, **kwargs))
#        for i in range(0,len(tmp),2):
#            typ = tmp[i+1]
#            res.append( PyNode( tmp[i],  ) )
#            if showType:
#                res.append( typ )
#
#        return res


def listTransforms( *args, **kwargs ):
    """
Modifications:
  - returns wrapped classes

    :rtype: `Transform` list
    """
    kwargs['ni']=True
    res = cmds.ls(*args, **kwargs)
    if not res:
        return res
    res = cmds.listRelatives(  res, p=1, path=1 )
    if res is None:
        return []
    #res = list(set(res)) # ruins the order, but prevents dupes, which can happend when a transform has more than one shape
    return [PyNode(x) for x in res] #, ['transform']*len(res) )


def listSets(*args, **kwargs):
    '''
Modifications:
  - returns wrapped classes
  - if called without arguments and keys works as with allSets=True
  :rtype: `PyNode` list
    '''
    #cmds.listSets() reports existance of defaultCreaseDataSet which does not
    #exist if checked with cmds.objExists at least linux-2010
    if not args and not kwargs:
        kwargs['allSets'] = True
    return [PyNode(x) for x in _util.listForNone(cmds.listSets( *args,  **kwargs))
            if not x == 'defaultCreaseDataSet' ]

#-----------------------
#  Objects
#-----------------------

def nodeType( node, **kwargs ):
    """
    Note: this will return the dg node type for an object, like maya.cmds.nodeType,
    NOT the pymel PyNode class.  For objects like components or attributes,
    nodeType will return the dg type of the node to which the PyNode is attached.

    :rtype: `unicode`
    """
    # still don't know how to do inherited via _api
    if kwargs.get( 'inherited', kwargs.get( 'i', False) ):
        return cmds.nodeType( unicode(node), **kwargs )

#    obj = None
#    objName = None

    import nodetypes

    if isinstance(node, nodetypes.DependNode) :
        pass
        #obj = node.__apimobject__()
    elif isinstance(node, Attribute) :
        node = node.plugNode()
#    elif isinstance(node, _api.MObject) :
#        # TODO : convert MObject attributes to DependNode
#        if _api.isValidMObjectHandle(_api.MObjectHandle(node)) :
#            obj = node
#        else :
#            obj = None
    else:
    #if isinstance(node,basestring) :
        #obj = _api.toMObject( node.split('.')[0] )
        # don't spend the extra time converting to MObject
        # don't do unicode(node) - let pmcmds wrap handle it - 'node' may
        #     actually be a single item list, which cmds.nodeType accepts as a
        #    valid arg
        return cmds.nodeType( node, **kwargs )
        #raise TypeError, "Invalid input %r." % node

    if kwargs.get( 'apiType', kwargs.get( '_api', False) ):
        return node.__apimobject__().apiTypeStr()
    # default
    try:
        return node.__apimfn__().typeName()
    except RuntimeError: pass

def group( *args, **kwargs ):
    """
Modifications
  - if no objects are passed or selected, the empty flag is automatically set
Maya Bug Fix:
  - corrected to return a unique name
    """
    if not args and not cmds.ls(sl=1):
        kwargs['empty'] = True

    newGroup = cmds.group(*args, **kwargs)

    if cmds.versions.current() >= cmds.versions.v2014:
        # bug was fixed in 2014, so we can just cast to a PyNode and return...
        return PyNode(newGroup)
    else:
        # found an interesting bug. group does not return a unique path, so the following line
        # will error if the passed name is in another group somewhere:
        # Transform( cmds.group( name='foo') )
        # luckily the group command always selects the last created node, so we can just use selected()[0]
        return selected()[0]

    #except RuntimeError, msg:
    #    print msg
    #    if msg == 'Not enough objects or values.':
    #        kwargs['empty'] = True
    #        return Transform( cmds.group(**kwargs) )

def parent( *args, **kwargs ):
    """
Modifications:
    - if parent is 'None', world=True is automatically set
    - if the given parent is the current parent, don't error (similar to mel)
    """
    if args and args[-1] is None:
        if not kwargs.get('w', kwargs.get('world', True)):
            raise ValueError('No parent given, but parent to world explicitly set to False')
        if 'world' in kwargs:
            del kwargs['world']
        kwargs['w']=True
    elif 'world' in kwargs:
        # Standardize on 'w', for easier checking later
        kwargs['w'] = kwargs['world']
        del kwargs['world']

    # if you try to parent to the current parent, maya errors...
    # check for this and return if that's the case
    if args:
        nodes = cmds.ls(args, type='dagNode')
    else:
        nodes = cmds.ls(sl=1, type='dagNode')

    if nodes:
        if kwargs.get('w', False):
            parent = None
            children = nodes
        else:
            parent = PyNode(nodes[-1])
            children = nodes[:-1]

        def getParent(obj):
            parent = cmds.listRelatives(obj, parent=1)
            if not parent:
                return None
            else:
                return parent[0]
        if all(getParent(child) == parent for child in children):
            return [PyNode(x) for x in children]

    result = cmds.parent(*args, **kwargs)
    return [PyNode(x) for x in result]

# Because cmds.duplicate only ever returns node names (ie, NON-UNIQUE, and
# therefore, nearly useless names - yes, the function that is MOST LIKELY to
# create non-unique node names only ever returns node names - we need to use
# a node-tracking approach to duplicate, so that we can propery cast to
# PyNodes after... need to get autodesk to add a flag to duplicate, to return
# shortest-unqiue names, or full path names!

# Utility

def _pathFromMObj(mObj, fullPath=False):
    """
    Return a unique path to an mObject
    """
    if mObj.hasFn(_api.MFn.kDagNode):
        if fullPath:
            result = _api.MFnDagNode(mObj).fullPathName()
        else:
            result = _api.MFnDagNode(mObj).partialPathName()
    elif mObj.hasFn(_api.MFn.kDependencyNode):
        result = _api.MFnDependencyNode(mObj).name()
    else:
        raise TypeError("mObj must be either DagNode or DependencyNode - got a %s" % mObj.apiTypeStr())
    return result

# Node Callbacks --

def _nodeAddedCallback(list_):
    def callback(mObj, clientData):
#         luma.logger.debug("Checking node of type %s" % mObj.apiTypeStr())
#         luma.logger.debug("seeing whether %s should be added" %
#                           _pathFromMObj(mObj, fullPath=True))
        handle = _api.MObjectHandle(mObj)
        list_.append(handle)
    return callback

# from http://github.com/jspatrick/RigIt/blob/master/lib/NodeTracking.py


class NodeTracker(object):
    '''
    A class for tracking Maya Objects as they are created and deleted.
    Can (and probably should) be used as a context manager
    '''
    def __init__(self):
        self._addedCallbackID = None
        self._objects = []

    def startTrack(self):
        if not self._addedCallbackID:
            # luma.logger.debug("%s: Beginning object tracking" % str(self))
            self._addedCallbackID = _api.MDGMessage.addNodeAddedCallback(
                _nodeAddedCallback(self._objects))
#             luma.logger.debug("registered node added callback")

    def endTrack(self):
        """
        Stop tracking and remove the callback
        """
        if self._addedCallbackID:
#             luma.logger.debug("%s: Ending object tracking" % str(self))
            _api.MMessage.removeCallback(self._addedCallbackID)
            self._addedCallbackID = None
#             luma.logger.debug("deregistered node added callback")

    def getNodes(self, returnType='PyNode'):
        """
        Return a list of maya objects as strings.

        Parameters
        ----------
        returnType : {'PyNode', 'str', 'MObject'}
        """
        returnTypes = ('PyNode', 'str', 'MObject')
        if returnType not in returnTypes:
            raise ValueError('returnType must be one of: %s'
                             % ', '.join(repr(x) for x in returnTypes))

        result = []

        toRemove = []
        for objHandle in self._objects:
            # luma.logger.debug("Object valid status: %s" % str(objHandle.isValid()))
            # luma.logger.debug("Object alive status: %s" %
            # str(objHandle.isAlive()))
            if not objHandle.isValid():
                toRemove.append(objHandle)
            else:
                mobj = objHandle.object()
                nodeName = _pathFromMObj(mobj)
                # pymel's undo node should be ignored
                if nodeName != '__pymelUndoNode':
                    if returnType == 'MObject':
                        result.append(mobj)
                    else:
                        result.append(nodeName)

        for objHandle in toRemove:
            self._objects.remove(objHandle)

        if returnType == 'PyNode':
            result = [PyNode(n) for n in result]

        return result

    def isTracking(self):
        """
        Return True/False
        """
        if self._addedCallbackID:
            return True
        return False

    def reset(self):
        self.endTrack()
        self._objects = []

    def __enter__(self):
        self.startTrack()
        return self

    def __exit__(self, exctype, excval, exctb):
        self.endTrack()


def duplicate( *args, **kwargs ):
    """
Modifications:
  - new option: addShape
        If addShape evaluates to True, then all arguments fed in must be shapes, and each will be duplicated and added under
        the existing parent transform, instead of duplicating the parent transform.
        The following arguments are incompatible with addShape, and will raise a ValueError if enabled along with addShape:
            renameChildren (rc), instanceLeaf (ilf), parentOnly (po), smartTransform (st)
  - returns wrapped classes
  - returnRootsOnly is forced on for dag objects. This is because the duplicate command does not use full paths when returning
    the names of duplicated objects and will fail if the name is not unique.
    """
    addShape = kwargs.pop('addShape', False)
    kwargs.pop('rr', None)

    fakeReturnRoots = False
    if cmds.ls(dag=1,*args):
        # TODO: provide a real fix?
        # in general, we want to turn on 'returnRootsOnly' with dag nodes -
        # however, there is a bug with returnRootsOnly and underworld nodes...
        # not sure what to do about this in general, but for now, adding a
        # special case check to see if there's only one arg, and it's an
        # underworld node, in which case we don't need returnRoots...

        def inUnderWorld(arg):
            if isinstance(arg, PyNode):
                return arg.inUnderWorld()
            else:
                return '->' in arg
        if len(args) == 1 and inUnderWorld(args[0]):
            fakeReturnRoots = True
        else:
            kwargs['returnRootsOnly'] = True

    if not addShape:
        if args:
            origArgs = args
        else:
            origArgs = ls(sl=1)
        with NodeTracker() as tracker:
            nodeNames = cmds.duplicate(*args, **kwargs)
            newNodes = tracker.getNodes(returnType='MObject')
        if fakeReturnRoots:
            del nodeNames[len(origArgs):]

        # Ok, now we have a list of the string names, and a list of
        # newly-created MObjects... we need to try to correlate them, since the
        # nodeNames may not be unique
        pyNodes = []
        nameToNewNodes = None
        for i, name in enumerate(nodeNames):
            try:
                node = PyNode(name)
            except MayaObjectError:
                # damn, it wasn't globally unique...

                # first, see if it's name is unique, in the set of newNodes..

                # ... to do this, we make a dict from node-name to PyNode...
                if nameToNewNodes is None:
                    mfnDep = _api.MFnDependencyNode()
                    nameToNewNodes = {}
                    for mobj in newNodes:
                        mfnDep.setObject(mobj)
                        mobjNodeName = mfnDep.name()
                        newPyNode = PyNode(mobj)
                        nameToNewNodes.setdefault(mobjNodeName, []).append(newPyNode)

                sameNames = nameToNewNodes[name]
                if len(sameNames) == 1:
                    # yay, there was only one created node with this name!
                    node = sameNames[0]
                else:
                    # darn, we have multiple options to choose from... find the
                    # first one with the same parent as the corresponding
                    # original node with the same index...
                    if i >= len(origArgs):
                        # uh oh, we have more results returned than we fed in..
                        # panic, and just take the first one with same name...
                        node = sameNames[0]
                    else:
                        origArg = origArgs[i]
                        if isinstance(origArg, PyNode):
                            origNode = origArg
                        else:
                            origNode = PyNode(origArg)
                        origParent = origNode.getParent()
                        for newNode in sameNames:
                            if newNode.getParent() == origParent:
                                node = newNode
                                break
                        else:
                            # uh oh, we couldn't find a new node with the same
                            # name and matching parent... panic, and just take
                            # the first one with same name...
                            node = sameNames[0]
            pyNodes.append(node)
        return pyNodes
    else:
        for invalidArg in ('renameChildren', 'rc', 'instanceLeaf', 'ilf',
                           'parentOnly', 'po', 'smartTransform', 'st'):
            if kwargs.get(invalidArg, False) :
                raise ValueError("duplicate: argument %r may not be used with 'addShape' argument" % invalidArg)
        name=kwargs.pop('name', kwargs.pop('n', None))

        newShapes = []
        for origShape in [PyNode(x) for x in args]:
            if 'shape' not in cmds.nodeType(origShape.name(), inherited=True):
                raise TypeError('addShape arg of duplicate requires all arguments to be shapes (non-shape arg: %r)'
                                % origShape)

            # This is somewhat complex, because if we have a transform with
            # multiple shapes underneath it,
            #   a) The transform and all shapes are always duplicated
            #   b) After duplication, there is no reliable way to distinguish
            #         which shape is the duplicate of the one we WANTED to
            #         duplicate (cmds.shapeCompare does not work on all types
            #         of shapes - ie, subdivs)

            # To get around this, we:
            # 1) duplicate the transform ONLY (result: dupeTransform1)
            # 2) instance the shape we want under the new transform
            #    (result: dupeTransform1|instancedShape)
            # 3) duplicate the new transform
            #    (result: dupeTransform2, dupeTransform2|duplicatedShape)
            # 4) delete the transform with the instance (delete dupeTransform1)
            # 5) place an instance of the duplicated shape under the original
            #    transform (result: originalTransform|duplicatedShape)
            # 6) delete the extra transform (delete dupeTransform2)
            # 7) rename the final shape (if requested)

            # 1) duplicate the transform ONLY (result: dupeTransform1)
            dupeTransform1 = duplicate(origShape, parentOnly=1)[0]

            # 2) instance the shape we want under the new transform
            #    (result: dupeTransform1|instancedShape)
            cmds.parent(origShape, dupeTransform1, shape=True, addObject=True,
                        relative=True)

            # 3) duplicate the new transform
            #    (result: dupeTransform2, dupeTransform2|duplicatedShape)
            dupeTransform2 = duplicate(dupeTransform1, **kwargs)[0]

            # 4) delete the transform with the instance (delete dupeTransform1)
            delete(dupeTransform1)

            # 5) place an instance of the duplicated shape under the original
            #    transform (result: originalTransform|duplicatedShape)
            origParent = origShape.getParent()
            dupeShape = dupeTransform2.getShape()
            try:
                newShape = PyNode(cmds.parent(dupeShape, origParent, shape=True,
                                              addObject=True, relative=True)[0])
            except RuntimeError, e:
                # Maya 2014 introduced a bug (Change request #: BSPR-12597) with
                # using parent to instance a shape, where it will error when
                # trying to make some material connections...

                # Ie, try to run this:

                    # import maya.cmds as cmds
                    # def getShape(trans):
                    #     return cmds.listRelatives(trans, children=True, shapes=True)[0]
                    #
                    # cmds.file(new=1, f=1)
                    # shapeTransform = cmds.polyCube(name='singleShapePoly')[0]
                    # origShape = getShape(shapeTransform)
                    # dupeTransform1 = cmds.duplicate(origShape, parentOnly=1)[0]
                    # cmds.parent(origShape, dupeTransform1, shape=True, addObject=True, relative=True)
                    # dupeTransform2 = cmds.duplicate(dupeTransform1)[0]
                    # cmds.delete(dupeTransform1)
                    # dupeShape = getShape(dupeTransform2)
                    # cmds.parent(dupeShape, shapeTransform, shape=True, addObject=True, relative=True)
                # then maya gives this:
                    # Error: Connection not made: 'singleShapePolyShape2.instObjGroups[1]' -> 'initialShadingGroup.dagSetMembers[2]'. Source is not connected.
                    # Connection not made: 'singleShapePolyShape2.instObjGroups[1]' -> 'initialShadingGroup.dagSetMembers[2]'. Destination attribute must be writable.
                    # Connection not made: 'singleShapePolyShape2.instObjGroups[1]' -> 'initialShadingGroup.dagSetMembers[2]'. Destination attribute must be writable.

                if _versions.current() >= _versions.v2014:
                    # Would like to check that the dupe is due to the above bug,
                    # but sometimes the error string is the one above, about
                    # connections, and sometimes it's the more generic "Maya
                    # command error"... and this isn't very safe for
                    # international translations anyway...
                    # ...so, we just ASSUME that the runtime error was due to
                    # the above bug... if there was an error that caused it to
                    # not duplicate, we will fail to find the new shape, and
                    # we will re-raise the error...

                    # we should still be able to figure out which the newShape
                    # is, since there should only be two instances of it, and it
                    # should be the one under the old parent...
                    shapes = origParent.getShapes()
                    for shape in shapes:
                        if shape.isInstanceOf(dupeShape):
                            newShape = shape
                            break
                    else:
                        raise

            # 6) delete the extra transform (delete dupeTransform2)
            delete(dupeTransform2)

            # 7) rename the final shape (if requested)
            if name is not None:
                newShape.rename(name)

            newShapes.append(newShape)
        select(newShapes, r=1)
        return newShapes

#def instance( *args, **kwargs ):
#    """
#Modifications:
#  - returns wrapped classes
#    """
#    return map(PyNode, cmds.instance( *args, **kwargs ) )

'''
def attributeInfo( *args, **kwargs ):
    """
Modifications:
  - returns an empty list when the result is None
  - returns wrapped classes
    """

    return map(PyNode, _util.listForNone(cmds.attributeInfo(*args, **kwargs)))
'''

def rename( obj, newname, **kwargs):
    """
Modifications:
    - if the full path to an object is passed as the new name, the shortname of the object will automatically be used
    """
    import nodetypes, other
    # added catch to use object name explicitly when object is a Pymel Node
    if isinstance( newname, nodetypes.DagNode ):
        newname = newname.nodeName()
    else:
        newname = other.DagNodeName(newname).nodeName()

    return PyNode( cmds.rename( obj, newname, **kwargs ) )

def createNode( *args, **kwargs):
    res = cmds.createNode( *args, **kwargs )
    # createNode can sometimes return None, if the shared=True and name= an object that already exists
    if res:
        return PyNode(res)


def sets( *args, **kwargs):
    """
Modifications
  - resolved confusing syntax: operating set is always the first and only arg:

        >>> from pymel.core import *
        >>> f=newFile(f=1) #start clean
        >>>
        >>> shdr, sg = createSurfaceShader( 'blinn' )
        >>> shdr
        nt.Blinn(u'blinn1')
        >>> sg
        nt.ShadingEngine(u'blinn1SG')
        >>> s,h = polySphere()
        >>> s
        nt.Transform(u'pSphere1')
        >>> sets( sg, forceElement=s ) # add the sphere
        nt.ShadingEngine(u'blinn1SG')
        >>> sets( sg, q=1)  # check members
        [nt.Mesh(u'pSphereShape1')]
        >>> sets( sg, remove=s )
        nt.ShadingEngine(u'blinn1SG')
        >>> sets( sg, q=1)
        []

  - returns wrapped classes

    """
    setSetFlags = [
    'subtract', 'sub',
    'union', 'un',
    'intersection', 'int',
    'isIntersecting', 'ii',
    'isMember', 'im',
    'split', 'sp',
    'addElement', 'add',
    'include', 'in',
    'remove', 'rm',
    'forceElement', 'fe'
    ]
    setFlags = [
    'copy', 'cp',
    'clear', 'cl',
    'flatten', 'fl'
    ]

    #args = (objectSet,)

    #     this:
    #        sets('myShadingGroup', forceElement=1)
    #    must be converted to:
    #        sets(forceElement='myShadingGroup')


    for flag, value in kwargs.items():
        if flag in setSetFlags:
            kwargs[flag] = args[0]

            # move arg over to kwarg
            if _util.isIterable(value):
                args = tuple(value)
            elif isinstance( value, (basestring,PyNode) ):
                args = (value,)
            else:
                args = ()
            break
        elif flag in setFlags:
            kwargs[flag] = args[0]
            args = ()
            break


#    # the case where we need to return a list of objects
#    if kwargs.get( 'query', kwargs.get('q',False) ):
#        size = len(kwargs)
#        if size == 1 or (size==2 and kwargs.get( 'nodesOnly', kwargs.get('no',False) )  ) :
#            return map( PyNode, _util.listForNone(cmds.sets( *args, **kwargs )) )

    # Just get the result, then check if it's a list, rather than trying to
    # parse the kwargs...
    result = cmds.sets( *args, **kwargs )
    if isinstance(result, (bool, int, long, float)):
        return result
    if _util.isIterable(result):
        return map( PyNode, _util.listForNone(result) )
    elif result is None:
        return []
    else:
        return PyNode(result)

    '''
    #try:
    #    elements = elements[0]
    #except:
    #    pass

    #print elements
    if kwargs.get('query', kwargs.get( 'q', False)):
        #print "query", kwargs, len(kwargs)
        if len(kwargs) == 1:
            # list of elements

            return set( cmds.sets( elements, **kwargs ) or [] )
        # other query
        return cmds.sets( elements, **kwargs )

    elif kwargs.get('clear', kwargs.get( 'cl', False)):
        return cmds.sets( **kwargs )


    #if isinstance(elements,basestring) and cmds.ls( elements, sets=True):
    #    elements = cmds.sets( elements, q=True )

    #print elements, kwargs
    nonCreationArgs = set([
                'edit', 'e',
                'isIntersecting', 'ii',
                'isMember', 'im',
                'subtract', 'sub',
                'union', 'un',
                'intersection', 'int'])
    if len( nonCreationArgs.intersection( kwargs.keys()) ):
        #print "creation"
        return cmds.sets( *elements, **kwargs )

    # Creation
    #args = _convertListArgs(args)
    #print "creation"
    return ObjectSet(cmds.sets( *elements, **kwargs ))
    '''

def delete(*args, **kwargs):
    """
Modifications:
  - the command will not fail on an empty list
    """
    #if kwargs.pop('safe',False):
        # empty list
    if len(args) ==1 and _util.isIterable(args[0]) and not args[0]:
        return

    cmds.delete(*args, **kwargs)



def getClassification( *args ):
    """
Modifications:
  - previously returned a list with a single colon-separated string of classifications. now returns a list of classifications

    :rtype: `unicode` list
    """
    return cmds.getClassification(*args)[0].split(':')


#--------------------------
# New Commands
#--------------------------

def uniqueObjExists( name ):
    '''Returns True if name uniquely describes an object in the scene.
    '''
    all = cmds.ls(name)
    # in case result is None...
    return all and len(all) == 1

def selected( **kwargs ):
    """ls -sl"""
    kwargs['sl'] = 1
    return ls( **kwargs )


_thisModule = sys.modules[__name__]

#def spaceLocator(*args, **kwargs):
#    """
#Modifications:
#    - returns a locator instead of a list with a single locator
#    """
#    res = cmds.spaceLocator(**kwargs)
#    try:
#        return Transform(res[0])
#    except:
#        return res

def instancer(*args, **kwargs):
    """
Maya Bug Fix:
  - name of newly created instancer was not returned
    """
    # instancer does not like PyNode objects
    args = map( unicode, args )
    if kwargs.get('query', kwargs.get('q',False)):
        return cmds.instancer(*args, **kwargs)
    if kwargs.get('edit', kwargs.get('e',False)):
        cmds.instancer(*args, **kwargs)
        return PyNode( args[0], 'instancer' )
    else:
        instancers = cmds.ls(type='instancer')
        cmds.instancer(*args, **kwargs)
        return PyNode( list( set(cmds.ls(type='instancer')).difference( instancers ) )[0], 'instancer' )

#--------------------------
# PyNode Exceptions
#--------------------------
class MayaObjectError(TypeError):
    _objectDescription = 'Object'
    def __init__(self, node=None):
        self.node = unicode(node)
    def __str__(self):
        msg = "Maya %s does not exist (or is not unique):" % (self._objectDescription)
        if self.node:
            msg += ": %r" % (self.node)
        return msg

class MayaNodeError(MayaObjectError):
    _objectDescription = 'Node'

class MayaAttributeError(MayaObjectError, AttributeError):
    _objectDescription = 'Attribute'

class MayaAttributeEnumError(MayaAttributeError):
    _objectDescription = 'Attribute Enum'
    def __init__(self, node=None, enum=None):
        super(MayaAttributeEnumError, self).__init__(node)
        self.enum = enum
    def __str__(self):
        msg = super(MayaAttributeEnumError, self).__str__()
        if self.enum:
            msg += " - %r" % (self.enum)
        return msg

class MayaComponentError(MayaAttributeError):
    _objectDescription = 'Component'

class MayaParticleAttributeError(MayaComponentError):
    _objectDescription = 'Per-Particle Attribute'

def _objectError(objectName):
    # TODO: better name parsing
    if '.' in objectName:
        return MayaAttributeError(objectName)
    return MayaNodeError(objectName)

#--------------------------
# Object Wrapper Classes
#--------------------------

class PyNode(_util.ProxyUnicode):
    """
    Abstract class that is base for all pymel nodes classes.

    The names of nodes and attributes can be passed to this class, and the appropriate subclass will be determined.

        >>> PyNode('persp')
        nt.Transform(u'persp')
        >>> PyNode('persp.tx')
        Attribute(u'persp.translateX')

    If the passed node or attribute does not exist an error will be raised.

    """

    _name = None              # unicode

    # for DependNode : _api.MObjectHandle
    # for DagNode    : _api.MDagPath
    # for Attribute  : _api.MPlug

    _node = None              # Attribute Only: stores the PyNode for the plug's node
    __apiobjects__ = {}
    def __new__(cls, *args, **kwargs):
        """ Catch all creation for PyNode classes, creates correct class depending on type passed.


        For nodes:
            MObject
            MObjectHandle
            MDagPath
            string/unicode

        For attributes:
            MPlug
            MDagPath, MPlug
            string/unicode
        """
        import nodetypes
        #print cls.__name__, cls

        pymelType = None
        obj = None
        name = None
        attrNode = None
        argObj = None
        if args :


            if len(args)>1 :
                # Attribute passed as two args: ( node, attr )
                # valid types:
                #    node : MObject, MObjectHandle, MDagPath
                #    attr : MPlug  (TODO: MObject and MObjectHandle )
                # One very important reason for allowing an attribute to be specified as two args instead of as an MPlug
                # is that the node can be represented as an MDagPath which will differentiate between instances, whereas
                # an MPlug loses this distinction.

                attrNode = args[0]
                argObj = args[1]

                #-- First Argument: Node
                # ensure that the node object is a PyNode object
                if not isinstance( attrNode, nodetypes.DependNode ):
                    attrNode = PyNode( attrNode )

#                #-- Second Argument: Plug or Component
#                # convert from string to _api objects.
#                if isinstance(argObj,basestring) :
#                    argObj = _api.toApiObject( argObj, dagPlugs=False )
#
#                # components
#                elif isinstance( argObj, int ) or isinstance( argObj, slice ):
#                    argObj = attrNode._apiobject


            else:
                argObj = args[0]

                # the order of the following 3 checks is important, as it is in increasing generality

                if isinstance( argObj, Attribute ):
                    attrNode = argObj._node
                    argObj = argObj.__apiobjects__['MPlug']
                elif isinstance( argObj, Component ):
                    try:
                        argObj = argObj._node.__apiobjects__[ 'MDagPath']
                    except KeyError:
                        argObj = argObj._node.__apiobjects__['MObjectHandle']

                elif isinstance( argObj, PyNode ):
                    try:
                        argObj = argObj.__apiobjects__[ 'MDagPath']
                    except KeyError:
                        argObj = argObj.__apiobjects__['MObjectHandle']

                elif hasattr( argObj, '__module__') and argObj.__module__.startswith( 'maya.OpenMaya' ) :
                    pass

                #elif isinstance(argObj,basestring) : # got rid of this check because of nameparse objects
                else:
                    # didn't match any known types. treat as a string
                    # convert to string then to _api objects.
                    try:
                        name = unicode(argObj)
                    except Exception:
                        raise MayaNodeError
                    else:
                        res = _api.toApiObject(name, dagPlugs=True)
                        # DagNode Plug
                        if isinstance(res, tuple):
                            # Plug or Component
                            #print "PLUG or COMPONENT", res
                            attrNode = PyNode(res[0])
                            argObj = res[1]

                            # There are some names which are both components and
                            #    attributes: ie, scalePivot / rotatePivot
                            # toApiObject (and MSelectionList) will return the
                            #    component in these ambigious cases; therefore,
                            #    if we're explicitly trying to make an Attribute - ie,
                            #        Attribute('myCube.scalePivot')
                            #    ... make sure to cast it to one in these cases
                            if issubclass(cls, Attribute) and \
                                    isinstance(argObj, _api.MObject) and \
                                    _api.MFnComponent().hasObj(argObj) and \
                                    '.' in name:
                                attrName = name.split('.', 1)[1]
                                if attrNode.hasAttr(attrName):
                                    return attrNode.attr(attrName)
                        # DependNode Plug
                        elif isinstance(res, _api.MPlug):
                            attrNode = PyNode(res.node())
                            argObj = res
                        # Other Object
                        elif res:
                            argObj = res
                        else:
                            # Removed ability to create components such as
                            #   PyNode('myCube.vtx')
                            # because of inconsistency - in general, for
                            #   PyNode(stringName)
                            # stringName should be a valid mel name, ie
                            #   cmds.select(stringName)
                            # should work

#                            # Check if it's a component that's normally indexed,
#                            # but has no index specified - ie, myPoly.vtx,
#                            # instead of the (mel-valid) myPoly.vtx[*]
#                            dotSplit = name.split('.')
#                            if len(dotSplit) == 2:
#                                try:
#                                    res = PyNode(dotSplit[0])
#                                except MayaObjectError:
#                                    pass
#                                else:
#                                    try:
#                                        argObj = getattr(res, dotSplit[1])
#                                    except AttributeError:
#                                        pass
#                                    else:
#                                        if isinstance(argObj, cls):
#                                            return argObj

                            # non-existent objects
                            # the object doesn't exist: raise an error

                            # note - at one point, I briefly changed things so
                            # that the code would check to see if the name
                            # existed, but had multiple matches, or didn't
                            # exist at all, and made it so MayaObjectError
                            # would give a more informative error message
                            # depending...

                            # ...but it had potential performance implications -
                            # at best, it was doing an extra cmds.objExists...
                            # ...and objExists wasn't fast enough, considering
                            # we will easily be trying to create 1000s of
                            # PyNodes, and the command gets slower as the size
                            # of the scene increases...
                            raise _objectError(name)


            #-- Components
            if validComponentIndexType(argObj):
                #pymelType, obj, name = _getPymelType( attrNode._apiobject )
                obj = {'ComponentIndex' : argObj }
                # if we are creating a component class using an int or slice, then we must specify a class type:
                #    valid:    MeshEdge( myNode, 2 )
                #    invalid:  PyNode( myNode, 2 )
                assert issubclass(cls,Component), "%s is not a Component class" % cls.__name__

            #-- All Others
            else:
                pymelType, obj = _getPymelType( argObj, name )
                if attrNode is None and issubclass(pymelType, Attribute):
                    attrNode = PyNode(obj['MPlug'].node())

            #print pymelType, obj, name, attrNode

            # Virtual (non-existent) objects will be cast to their own virtual type.
            # so, until we make that, we're rejecting them
            assert obj is not None# real objects only
            #assert obj or name

        else :
            # create node if possible
            if issubclass(cls,nodetypes.DependNode):
                newNode = None
                vClassInfo = _factories.virtualClasses.getVirtualClassInfo(cls)
                #----------------------------------
                # Pre Creation
                #----------------------------------
                postArgs = {}
                if vClassInfo and vClassInfo.preCreate:
                    kwargs = vClassInfo.preCreate(**kwargs)
                    if isinstance(kwargs, tuple):
                        assert len(kwargs) == 2, "preCreate must either 1 or 2 dictionaries of keyword arguments"
                        kwargs, postArgs = kwargs
                        assert isinstance(postArgs, dict), "preCreate second return value must be a dictionary of keyword arguments"
                    assert isinstance(kwargs, dict), "_preCreateVirtual must return a dictionary of keyword arguments"

                #----------------------------------
                # Creation
                #----------------------------------
                if vClassInfo and vClassInfo.create:
                    newNode = vClassInfo.create(**kwargs)
                    assert isinstance(newNode, basestring), "_createVirtual must return the name created node"

                elif hasattr(cls, '__melcmd__') and not cls.__melcmd_isinfo__:
                    try:
                        _logger.debug( 'creating node of type %s using %s' % (cls.__melnode__, cls.__melcmd__.__name__ ) )
                        res = cls.__melcmd__(**kwargs)
                    except Exception, e:
                        _logger.debug( 'failed to create %s' % e )
                        pass
                    else:
                        if isinstance(res,list):
                            # we only want to return a single object
                            for x in res:
                                typ = cmds.nodeType(x)
                                if typ == cls.__melnode__:
                                    newNode = x
                                    break
                                elif typ == 'transform':
                                    shape = cmds.listRelatives( x, s=1)
                                    if shape and cmds.nodeType(shape[0]) == cls.__melnode__:
                                        newNode = shape[0]
                                        break
                            if newNode is None:
                                raise ValueError, "could not find type %s in result %s returned by %s" % ( cls.__name__, res, cls.__melcmd__.__name__ )
                        elif cls.__melnode__ == nodeType(res): #isinstance(res,cls):
                            newNode = res
                        else:
                            raise ValueError, "unexpect result %s returned by %s" % ( res, cls.__melcmd__.__name__ )
                else:
                    _logger.debug( 'creating node of type %s using createNode' % cls.__melnode__ )
                    try:
                        newNode = createNode( cls.__melnode__, **kwargs )
                    except RuntimeError:
                        # FIXME: should we really be passing on this?
                        pass

                #----------------------------------
                # Post Creation
                #----------------------------------
                if newNode:
                    if vClassInfo and vClassInfo.postCreate:
                        vClassInfo.postCreate(newNode, **postArgs)
                    return cls(newNode)

            raise ValueError, 'PyNode expects at least one argument: an object name, MObject, MObjectHandle, MDagPath, or MPlug'

        # print "type:", pymelType
        # print "PyNode __new__ : called with obj=%r, cls=%r, on object of type %s" % (obj, cls, pymelType)
        # if an explicit class was given (ie: pyObj=DagNode(u'pCube1')) just check if actual type is compatible
        # if none was given (ie generic pyObj=PyNode('pCube1')) then use the class corresponding to the type we found
        newcls = None

        if cls is not PyNode :
            # a PyNode class was explicitly required, if an existing object was passed to init check that the object type
            # is compatible with the required class, if no existing object was passed, create an empty PyNode of the required class
            # There is one exception type:  MeshVertex( Mesh( 'pSphere1') )
            # TODO : can add object creation option in the __init__ if desired

            if not pymelType or not issubclass( pymelType, cls ):
                if issubclass( cls, Component ):
                    newcls = cls
                else:
                    raise TypeError, "Determined type is %s, which is not a subclass of desired type %s" % ( pymelType.__name__, cls.__name__ )
            else:
                newcls = pymelType
        else :
            newcls = pymelType

        if newcls :
            self = super(PyNode, cls).__new__(newcls)
            self._name = name
            if attrNode:
                self._node = attrNode

            self.__apiobjects__ = obj
            return self
        else :
            raise TypeError, "Cannot make a %s out of a %r object" % (cls.__name__, pymelType)

    def __init__(self, *args, **kwargs):
        # this  prevents the _api class which is the second base, from being automatically instantiated. This __init__ should
        # be overridden on subclasses of PyNode
        pass


    def __melobject__(self):
        """Special method for returning a mel-friendly representation."""
        return self.name()

    def __apimfn__(self):
        try:
            # if we have it, check that the mobject is still valid by calling
            # __apimobject__
            self.__apimobject__()
            # ...if it is valid, go ahead and return the cached MFn
            return self.__apiobjects__['MFn']
        except KeyError:
            if self.__apicls__:
                # use whatever type is appropriate
                obj = self.__apiobject__()
                if obj:
                    try:
                        mfn = self.__apicls__(obj)
                        self.__apiobjects__['MFn'] = mfn

                    except RuntimeError:
                        # when using PyNodes in strange places, like node
                        # creation callbacks, the proper MFn does not work yet,
                        # so we default to a super class and we don't save it,
                        # so that we can get the right one later
                        if isinstance(obj, _api.MDagPath):
                            mfn = _api.MFnDagNode( obj )
                            _logger.warning( "Could not create desired MFn. Defaulting to MFnDagNode." )

                        elif isinstance(obj, _api.MObject):
                            mfn = _api.MFnDependencyNode( obj )
                            _logger.warning( "Could not create desired MFn. Defaulting to MFnDependencyNode." )
                        else:
                            raise
                    return mfn
    def __repr__(self):
        """
        :rtype: `unicode`
        """
        return u"%s(%r)" % (self.__class__.__name__, self.name())

    def __radd__(self, other):
        if isinstance(other, basestring):
            return other.__add__( self.name() )
        else:
            raise TypeError, "cannot concatenate '%s' and '%s' objects" % ( other.__class__.__name__, self.__class__.__name__)

    def __reduce__(self):
        """allows PyNodes to be pickled"""
        return (PyNode, (self.name(),) )

    def __eq__(self, other):
        """
        :rtype: `bool`
        """
        if isinstance(other,PyNode):
            try:
                apiobj = other.__apiobject__()
            except TypeError: # intermixing MDagPath with MObject
                return False
        else:
            try:
                apiobj = PyNode(other).__apiobject__()
            except:
                return False

        try:
            return self.__apiobject__() == apiobj
        except:
            return False

    def __ne__(self, other):
        """
        :rtype: `bool`
        """
        # != does not work for MDagPath (maybe others) iff MDagPaths are equal (returns True)
        return not self == other


    def __nonzero__(self):
        """
        :rtype: `bool`
        """
        return self.exists()

    def __lt__(self, other):
        if isinstance(other, (basestring,PyNode) ):
            return self.name().__lt__( unicode(other) )
        else:
            return NotImplemented

    def __gt__(self, other):
        if isinstance(other, (basestring,PyNode) ):
            return self.name().__gt__( unicode(other) )
        else:
            return NotImplemented

    def __le__(self, other):
        if isinstance(other, (basestring,PyNode) ):
            return self.name().__le__( unicode(other) )
        else:
            return NotImplemented

    def __ge__(self, other):
        if isinstance(other, (basestring,PyNode) ):
            return self.name().__ge__( unicode(other) )
        else:
            return NotImplemented
    #-----------------------------------------
    # Name Info and Manipulation
    #-----------------------------------------

    def stripNamespace(self, *args, **kwargs):
        """
        Returns the object's name with its namespace removed.  The calling instance is unaffected.
        The optional levels keyword specifies how many levels of cascading namespaces to strip, starting with the topmost (leftmost).
        The default is 0 which will remove all namespaces.

        :rtype: `other.NameParser`

        """
        import other
        return other.NameParser(self).stripNamespace(*args, **kwargs)

    def swapNamespace(self, prefix):
        """Returns the object's name with its current namespace replaced with the provided one.
        The calling instance is unaffected.

        :rtype: `other.NameParser`
        """
        import other
        return other.NameParser(self).swapNamespace(prefix)

    def namespaceList(self):
        """Useful for cascading references.  Returns all of the namespaces of the calling object as a list

        :rtype: `unicode` list
        """
        return self.lstrip('|').rstrip('|').split('|')[-1].split(':')[:-1]

    def addPrefix(self, prefix):
        """Returns the object's name with a prefix added to the beginning of the name

        :rtype: `other.NameParser`
        """
        import other
        return other.NameParser(self).addPrefix(prefix)


#    def attr(self, attr):
#        """access to attribute of a node. returns an instance of the Attribute class for the
#        given attribute."""
#        return Attribute( '%s.%s' % (self, attr) )

    def exists(self, **kwargs):
        "objExists"
        try:
            if self.__apiobject__() :
                return True
        except MayaObjectError:
            pass
        return False

    objExists = exists

    nodeType = cmds.nodeType

    def select(self, **kwargs):
        forbiddenKeys = ['all', 'allDependencyNodes', 'adn', 'allDagObjects' 'ado', 'clear', 'cl']
        for key in forbiddenKeys:
            if key in kwargs:
                raise TypeError, "'%s' is an inappropriate keyword argument for object-oriented implementation of this command" % key
        # stringify
        return cmds.select( self.name(), **kwargs )

    def deselect( self ):
        self.select( deselect=1 )

    def listSets(self, *args, **kwargs):
        '''
        Returns list of sets this object belongs

        listSets -o $this

        :rtype: 'PyNode' list
        '''
        return listSets(o=self, *args, **kwargs)


    listConnections = listConnections

    connections = listConnections

    listHistory = listHistory

    history = listHistory

    listFuture = listFuture

    future = listFuture

# This was supposed to be removed in the 1.0 update, but somehow got left out...
deprecated_str_methods = ['__getitem__']
strDeprecateDecorator = _warnings.deprecated( 'Convert to string first using str() or PyNode.name()', 'PyNode' )

def _deprecatePyNode():
    def makeDeprecatedMethod(method):
        def f(self, *args):
            proxyMethod = getattr( _util.ProxyUnicode, method )
            return proxyMethod(self,*args)

        f.__doc__ = "deprecated\n"
        f.__name__ = method
        g = strDeprecateDecorator(f)
        setattr( PyNode, method, g)


    for method in deprecated_str_methods:
        makeDeprecatedMethod( method )

_deprecatePyNode()


_factories.pyNodeNamesToPyNodes['PyNode'] = PyNode

#def _MObjectIn(x):
#    if isinstance(x,PyNode): return x.__apimobject__()
#    return PyNode(x).__apimobject__()
#def _MDagPathIn(x):
#    if isinstance(x,DagNode): return x.__apimdagpath__()
#    return PyNode(x).__apimdagpath__()
#def _MPlugIn(x):
#    if isinstance(x,Attribute): return x.__apimplug__()
#    return PyNode(x).__apimplug__()
#def _MPlugOut(self,x):
#    try: return Attribute(self.node(), x)
#    except: pass
#    return Attribute(x)
#_factories.ApiTypeRegister.register('MObject', PyNode, inCast=_MObjectIn )
#_factories.ApiTypeRegister.register('MDagPath', DagNode, inCast=_MDagPathIn )
#_factories.ApiTypeRegister.register('MPlug', Attribute, inCast=_MPlugIn, outCast=_MPlugOut )

def _getParent( getter, obj, generations):
    '''If generations is None, then a list of all the parents is returned.
    '''
    if generations == 0:
        return obj

    x = obj
    allParents = [obj]
    if generations is None:
        i = -1
    else:
        i = generations

    # If generations is positive, we will stop as soon as we get to the parent
    # we need; otherwise, we will get all the parents
    while i != 0:
        try:
            x = getter( x )
        except Exception:
            break
        if x is None:
            break
        allParents.append(x)
        i -= 1

    if generations is None:
        return allParents[1:]

    if generations >= 1:
        if generations < len(allParents):
            return allParents[generations]
        else:
            return None
    elif generations < 0:
        if -generations > len(allParents):
            return None
        else:
            return allParents[generations]

class Attribute(PyNode):
    """Attribute class

    see pymel docs for details on usage
    """

    #


    """
    Attributes
    ==========

    The Attribute class is your one-stop shop for all attribute related functions. Those of us who have spent time using MEL
    have become familiar with all the many commands for operating on attributes.  This class gathers them all into one
    place. If you forget or are unsure of the right method name, just ask for help by typing `help(Attribute)`.

    For the most part, the names of the class equivalents to the maya.cmds functions follow a fairly simple pattern:
    `setAttr` becomes `Attribute.set`, `getAttr` becomes `Attribute.get`, `connectAttr` becomes `Attribute.connect` and so on.
    Here's a simple example showing how the Attribute class is used in context.

        >>> from pymel.core import *
        >>> cam = PyNode('persp')
        >>> if cam.visibility.isKeyable() and not cam.visibility.isLocked():
        ...     cam.visibility.set( True )
        ...     cam.visibility.lock()
        ...
        >>> print cam.v.type()      # shortnames also work
        bool

    Accessing Attributes
    --------------------

    You can access an attribute class in three ways.  The first two require that you already have a `PyNode` object.

    Shorthand
    ~~~~~~~~~

    The shorthand method is the most visually appealing and readable -- you simply access the maya attribute as a normal python attribute --
    but it has one major drawback: **if the attribute that you wish to acess has the same name as one of the attributes or methods of the
    python class then it will fail**.

        >>> cam  # continue from where we left off above
        Transform(u'persp')
        >>> cam.visibility # long name access
        Attribute(u'persp.visibility')
        >>> cam.v # short name access
        Attribute(u'persp.visibility')

    Keep in mind, that regardless of whether you use the long or short name of the attribute, you are accessing the same underlying API object.
    If you need the attribute formatted as a string in a particular way, use `Attribute.name`, `Attribute.longName`, `Attribute.shortName`,
    `Attribute.plugAttr`, or `Attribute.lastPlugAttr`.


    attr Method
    ~~~~~~~~~~~
    The attr method is the safest way to access an attribute, and can even be used to access attributes that conflict with
    python methods, which would fail using shorthand syntax. This method is passed a string which
    is the name of the attribute to be accessed.

        >>> cam.attr('visibility')
        Attribute(u'persp.visibility')

    Unlike the shorthand syntax, this method is capable of being passed attributes which are passed in as variables:

        >>> for axis in ['scaleX', 'scaleY', 'scaleZ']:
        ...     cam.attr( axis ).lock()

    Direct Instantiation
    ~~~~~~~~~~~~~~~~~~~~
    The last way of getting an attribute is by directly instantiating the class. You can pass the attribute name as a string, or if you have one handy,
    pass in an api MPlug object.  If you don't know whether the string name represents a node or an attribute, you can always instantiate via the `PyNode`
    class, which will determine the appropriate class automaticallly.

    explicitly request an Attribute:

        >>> Attribute( 'persp.visibility' )
        Attribute(u'persp.visibility')

    let PyNode figure it out for you:

        >>> PyNode( 'persp.translate' )
        Attribute(u'persp.translate')


    Setting Attributes Values
    -------------------------

    To set the value of an attribute, you use the `Attribute.set` method.

        >>> cam.translateX.set(0)

    to set an attribute that expects a double3, you can use any iterable with 3 elements:

        >>> cam.translate.set([4,5,6])
        >>> cam.translate.set(datatypes.Vector([4,5,6]))

    Getting Attribute Values
    ------------------------
    To get the value of an attribute, you use the `Attribute.get` method. Keep in mind that, where applicable, the values returned will
    be cast to pymel classes. This example shows that rotation (along with translation and scale) will be returned as a `Vector`.

        >>> t = cam.translate.get()
        >>> print t
        [4.0, 5.0, 6.0]
        >>> # translation is returned as a vector class
        >>> print type(t)
        <class 'pymel.core.datatypes.Vector'>

    `set` is flexible in the types that it will accept, but `get` will always return the same type
    for a given attribute. This can be a potential source of confusion:

        >>> value = [4,5,6]
        >>> cam.translate.set(value)
        >>> result = cam.translate.get()
        >>> value == result
        False
        >>> # why is this? because result is a Vector and value is a list
        >>> # use `Vector.isEquivalent` or cast the list to a `list`
        >>> result == datatypes.Vector(value)
        True
        >>> result.isEquivalent(value)
        True

    Connecting Attributes
    ---------------------
    As you might expect, connecting and disconnecting attributes is pretty straightforward.

        >>> cam.rotateX.connect( cam.rotateY )
        >>> cam.rotateX.disconnect( cam.rotateY )

    there are also handy operators for connection (`Attribute.__rshift__`) and disconnection (`Attribute.__floordiv__`)

        >>> c = polyCube(name='testCube')[0]
        >>> cam.tx >> c.tx    # connect
        >>> cam.tx.outputs()
        [nt.Transform(u'testCube')]
        >>> cam.tx // c.tx    # disconnect
        >>> cam.tx.outputs()
        []


    """
    __metaclass__ = _factories.MetaMayaTypeWrapper
    __apicls__ = _api.MPlug
    attrItemReg = re.compile( '\[(\d+)\]$')

#    def __init__(self, *args, **kwargs ):
#        self.apicls.__init__(self, self._apiobject )

    def __apiobject__(self) :
        "Return the default API object (MPlug) for this attribute, if it is valid"
        return self.__apimplug__()

    def __apimobject__(self):
        "Return the MObject for this attribute, if it is valid"
        try:
            handle = self.__apiobjects__['MObjectHandle']
        except:
            handle = _api.MObjectHandle( self.__apiobjects__['MPlug'].attribute() )
            self.__apiobjects__['MObjectHandle'] = handle
        if _api.isValidMObjectHandle( handle ):
            return handle.object()

        raise MayaAttributeError

    def __apimplug__(self) :
        "Return the MPlug for this attribute, if it is valid"
        # check validity
        #self.__apimobject__()
        return self.__apiobjects__['MPlug']

    def __apimdagpath__(self) :
        "Return the MDagPath for the node of this attribute, if it is valid"
        try:
            return self.node().__apimdagpath__()
        except AttributeError: pass

    def __apimattr__(self) :
        "Return the MFnAttribute for this attribute, if it is valid"
        try:
            if 'MFnAttribute' not in self.__apiobjects__:
                self.__apiobjects__['MFnAttribute'] = _api.MFnAttribute(self.__apimobject__())
            return self.__apiobjects__['MFnAttribute']
        except Exception:
            raise MayaAttributeError


#    def __init__(self, attrName):
#        assert isinstance( _api.__apiobject__(), _api.MPlug )

#        if '.' not in attrName:
#            raise TypeError, "%s: Attributes must include the node and the attribute. e.g. 'nodeName.attributeName' " % self
#        self._name = attrName
#        # TODO : MObject support
#        self.__dict__['_multiattrIndex'] = 0
#

    __getitem__ = _factories.wrapApiMethod(_api.MPlug, 'elementByLogicalIndex', '__getitem__')
    #elementByPhysicalIndex = _factories.wrapApiMethod( _api.MPlug, 'elementByPhysicalIndex' )

    def removeMultiInstance(self, index, break_=False):
        if isinstance(index, slice):
            # plug indices are sparse, so we don't bother using
            # slice.indices(len), since all that does is potentially truncate
            # the indices we get back
            indices = xrange(index.start, index.stop, index.step)
        else:
            indices = [index]
        for i in indices:
            cmds.removeMultiInstance(self[i], b=break_)
    __delitem__ = removeMultiInstance


    def attr(self, attr):
        """
        :rtype: `Attribute`
        """
        node = self.node()
        try:
            plug = self.__apimplug__()
            # if this plug is an array we can't properly get the child plug
            if plug.isArray():
                return node.attr(attr)
            else:
                attrObj = node.__apimfn__().attribute(attr)
                return Attribute( node, plug.child( attrObj ) )
        except RuntimeError:
            # raise our own MayaAttributeError, which subclasses AttributeError and MayaObjectError
            raise MayaAttributeError( '%s.%s' % (self, attr) )


    def __getattr__(self, attr):
        try:
            return self.attr(attr)
        except MayaAttributeError:
            raise AttributeError,"%r has no attribute or method named '%s'" % (self, attr)
    # Added the __call__ so to generate a more appropriate exception when a class method is not found
    def __call__(self, *args, **kwargs):
        raise TypeError("The object <%s> does not support the '%s' method" % (repr(self.node()), self.plugAttr()))

    # Need an iterator which is NOT self, so that we can have independent
    # iterators - ie, so if we do:
    #     zip(self, self)
    # we get
    #     ( (self[0], self[0]), (self[1], self[1]), (self[2], self[2]) ... )
    # and not
    #     ( (self[0], self[1]), (self[2], self[3]), (self[4], self[5]) ... )
    def __iter__(self):
        """
        iterator for multi-attributes

            >>> from pymel.core import *
            >>> f=newFile(f=1) #start clean
            >>>
            >>> at = PyNode( 'defaultLightSet.dagSetMembers' )
            >>> nt.SpotLight()
            nt.SpotLight(u'spotLightShape1')
            >>> nt.SpotLight()
            nt.SpotLight(u'spotLightShape2')
            >>> nt.SpotLight()
            nt.SpotLight(u'spotLightShape3')
            >>> for x in at: print x
            ...
            defaultLightSet.dagSetMembers[0]
            defaultLightSet.dagSetMembers[1]
            defaultLightSet.dagSetMembers[2]
        """
        if self.isMulti():
            for i in self._getArrayIndices()[1]:
                yield self[i]
            #return self[0]
        else:
            raise TypeError, "%s is not a multi-attribute and cannot be iterated over" % self

    def __str__(self):
        """
        :rtype: `str`
        """
        return str(self.name())

    def __unicode__(self):
        """
        :rtype: `unicode`
        """
        return self.name()

    def __eq__(self, other):
        """
        :rtype: `bool`
        """
        thisPlug = self.__apimplug__()
        try:
            thisIndex = thisPlug.logicalIndex()
        except RuntimeError:
            thisIndex = None

        if not isinstance(other,Attribute):
            try:
                other = PyNode(other)
                if not hasattr(other, '__apimplug__'):
                    return False
            except (ValueError,TypeError): # could not cast to PyNode
                return False

        otherPlug = other.__apimplug__()
        # foo.bar[10] and foo.bar[20] and foo.bar eval to the same object in _api.  i don't think this is very intuitive.
        try:
            otherIndex = otherPlug.logicalIndex()
        except RuntimeError:
            otherIndex = None
        return thisPlug == otherPlug and thisIndex == otherIndex

    def __hash__(self):
        """
        :rtype: `int`
        """
        return (self.plugNode(), self.name(includeNode=False) ).__hash__()

    def __ne__(self, other):
        """
        :rtype: `bool`
        """
        return not self.__eq__(other)

    def name(self, includeNode=True, longName=True, fullAttrPath=False,
             fullDagPath=False, placeHolderIndices=True):
        """ Returns the name of the attribute (plug)

            >>> tx = SCENE.persp.t.tx
            >>> tx.name()
            u'persp.translateX'
            >>> tx.name(includeNode=False)
            u'translateX'
            >>> tx.name(longName=False)
            u'persp.tx'
            >>> tx.name(fullAttrPath=True, includeNode=False)
            u'translate.translateX'

            >>> vis = SCENE.perspShape.visibility
            >>> vis.name()
            u'perspShape.visibility'
            >>> vis.name(fullDagPath=True)
            u'|persp|perspShape.visibility'

            >>> og = SCENE.persp.instObjGroups.objectGroups
            >>> og.name()
            u'persp.instObjGroups[-1].objectGroups'
            >>> og.name(placeHolderIndices=False)
            u'persp.instObjGroups.objectGroups'

        :rtype: `unicode`
        """

        obj = self.__apimplug__()
        if obj:
            name = ''
            node = self.plugNode()
            if includeNode:
                import nodetypes
                if isinstance(node, nodetypes.DagNode):
                    name = node.name(long=fullDagPath)
                else:
                    name = node.name()
                name += '.'


            name += obj.partialName(    False, #includeNodeName
                                        True, #includeNonMandatoryIndices
                                        True, #includeInstancedIndices
                                        False, #useAlias
                                        fullAttrPath, #useFullAttributePath
                                        longName #useLongNames
                                    )
            if not placeHolderIndices:
                name  = name.replace('[-1]', '')
            return name
        raise MayaObjectError(self._name)


#    def attributeName(self):
#        pass
#
#    def attributeNames(self):
#        pass


    def plugNode(self):
        """plugNode

        :rtype: `DependNode`
        """
        # we shouldn't have to use this
        #if self._node is None:
        #    self._node = PyNode(self.__apimplug__().node())

        return self._node

    node = plugNode

    def plugAttr(self, longName=False, fullPath=False):
        """
            >>> from pymel.core import *
            >>> at = SCENE.persp.t.tx
            >>> at.plugAttr(longName=False, fullPath=False)
            u'tx'
            >>> at.plugAttr(longName=False, fullPath=True)
            u't.tx'
            >>> at.plugAttr(longName=True, fullPath=True)
            u'translate.translateX'

        :rtype: `unicode`
        """
        return self.name(includeNode=False,
                         longName=longName,
                         fullAttrPath=fullPath)


    def lastPlugAttr(self, longName=False):
        """
            >>> from pymel.core import *
            >>> at = SCENE.persp.t.tx
            >>> at.lastPlugAttr(longName=False)
            u'tx'
            >>> at.lastPlugAttr(longName=True)
            u'translateX'

        :rtype: `unicode`
        """
        return self.name(includeNode=False,
                         longName=longName,
                         fullAttrPath=False)


    def longName(self, fullPath=False ):
        """
            >>> from pymel.core import *
            >>> at = SCENE.persp.t.tx
            >>> at.longName(fullPath=False)
            u'translateX'
            >>> at.longName(fullPath=True)
            u'translate.translateX'

        :rtype: `unicode`
        """
        return self.name(includeNode=False,
                         longName=True,
                         fullAttrPath=fullPath)

    def shortName(self, fullPath=False):
        """
            >>> from pymel.core import *
            >>> at = SCENE.persp.t.tx
            >>> at.shortName(fullPath=False)
            u'tx'
            >>> at.shortName(fullPath=True)
            u't.tx'

        :rtype: `unicode`
        """
        return self.name(includeNode=False,
                         longName=False,
                         fullAttrPath=fullPath)

    def nodeName( self ):
        """The node part of this plug as a string

        :rtype: `unicode`
        """
        return self.plugNode().name()

    def attrName( self, longName=False, includeNode=False ):
        """Just the name of the attribute for this plug

        This will have no indices, no parent attributes, etc...
        This is suitable for use with cmds.attributeQuery

            >>> at = SCENE.persp.instObjGroups.objectGroups
            >>> at.name()
            u'persp.instObjGroups[-1].objectGroups'
            >>> at.attrName()
            u'og'
            >>> at.attrName(longName=True)
            u'objectGroups'
        """
        # Need to implement this with MFnAttribute - anything
        # with MPlug will have the [-1]...
        attr = self.__apimattr__()
        if longName:
            name = attr.name()
        else:
            name = attr.shortName()
        if includeNode:
            name = self.nodeName() + '.' + name
        return name

    def namespace(self, *args, **kwargs):
        return self.node().namespace(*args, **kwargs)

    def array(self):
        """
        Returns the array (multi) attribute of the current element:

            >>> n = Attribute(u'initialShadingGroup.groupNodes[0]')
            >>> n.isElement()
            True
            >>> n.array()
            Attribute(u'initialShadingGroup.groupNodes')

        This method will raise an error for attributes which are not elements of
        an array:

            >>> m = Attribute(u'initialShadingGroup.groupNodes')
            >>> m.isElement()
            False
            >>> m.array()
            Traceback (most recent call last):
            ...
            TypeError: initialShadingGroup.groupNodes is not an array (multi) attribute

        :rtype: `Attribute`
        """
        try:
            return Attribute( self._node, self.__apimplug__().array() )
            #att = Attribute(Attribute.attrItemReg.split( self )[0])
            #if att.isMulti() :
            #    return att
            #else :
            #    raise TypeError, "%s is not a multi attribute" % self
        except:
            raise TypeError, "%s is not an array (multi) attribute" % self


    # TODO : do not list all children elements by default, allow to do
    #        skinCluster1.weightList.elements() for first level elements weightList[x]
    #        or skinCluster1.weightList.weights.elements() for all weightList[x].weights[y]

    def elements(self):
        """
        ``listAttr -multi``

        Return a list of strings representing all the attributes in the array.

        If you don't need actual strings, it is recommended that you simply iterate through the elements in the array.
        See `Attribute.__iter__`.

        Modifications:
          - returns an empty list when the result is None
        """
        if self.isElement():
            arrayAttr = self.array()
        else:
            arrayAttr = self
        return _util.listForNone(cmds.listAttr(arrayAttr, multi=True))

#    def item(self):
#        try:
#            return int(Attribute.attrItemReg.search(self).group(1))
#        except: return None

    def getArrayIndices(self):
        """
        Get all set or connected array indices. Raises an error if this is not an array Attribute

        :rtype: `int` list
        """
        try:
            return self._getArrayIndices()[1]
        except RuntimeError:
            raise TypeError, "%s is not an array (multi) attribute" % self

    def numElements(self):
        """
        The number of elements in an array attribute. Raises an error if this is not an array Attribute

        Be aware that ``getAttr(..., size=1)`` does not always produce the expected value. It is recommend
        that you use `Attribute.numElements` instead.  This is a maya bug, *not* a pymel bug.

            >>> from pymel.core import *
            >>> f=newFile(f=1) #start clean
            >>>
            >>> dls = SCENE.defaultLightSet
            >>> dls.dagSetMembers.numElements()
            0
            >>> nt.SpotLight() # create a light, which adds to the lightSet
            nt.SpotLight(u'spotLightShape1')
            >>> dls.dagSetMembers.numElements()
            1
            >>> nt.SpotLight() # create another light, which adds to the lightSet
            nt.SpotLight(u'spotLightShape2')
            >>> dls.dagSetMembers.numElements()
            2

        :rtype: `int`
        """

        try:
            return self._getArrayIndices()[0]
        except RuntimeError:
            raise TypeError, "%s is not an array (multi) attribute" % self

    item = _factories.wrapApiMethod( _api.MPlug, 'logicalIndex', 'item' )
    index = _factories.wrapApiMethod( _api.MPlug, 'logicalIndex', 'index' )

    # enums
    getEnums = getEnums
    setEnums = setEnums

    # getting and setting
    set = setAttr
    get = getAttr

    setKey = _factories.functionFactory( cmds.setKeyframe, rename='setKey' )


#----------------------
#xxx{ Connections
#----------------------

    def isConnectedTo(self, other, ignoreUnitConversion=False, checkLocalArray=False, checkOtherArray=False ):
        """
        Determine if the attribute is connected to the passed attribute.

        If checkLocalArray is True and the current attribute is a multi/array, the current attribute's elements will also be tested.

        If checkOtherArray is True and the passed attribute is a multi/array, the passed attribute's elements will also be tested.

        If checkLocalArray and checkOtherArray are used together then all element combinations will be tested.

        """

        if cmds.isConnected( self, other, ignoreUnitConversion=ignoreUnitConversion):
            return True

        if checkLocalArray and self.isMulti():
            for elem in self:
                if elem.isConnectedTo(other, ignoreUnitConversion=ignoreUnitConversion, checkLocalArray=False, checkOtherArray=checkOtherArray):
                    return True

        if checkOtherArray:
            other = Attribute(other)
            if other.isMulti():
                for elem in other:
                    if self.isConnectedTo(elem, ignoreUnitConversion=ignoreUnitConversion, checkLocalArray=False, checkOtherArray=False):
                        return True


        return False

    ## does not work because this method cannot return a value, it is akin to +=
    #def __irshift__(self, other):
    #    """operator for 'isConnected'
    #        sphere.tx >>= box.tx
    #    """
    #    return cmds.isConnected(self, other)


    connect = connectAttr

    def __rshift__(self, other):
        """
        operator for 'connectAttr'

            >>> from pymel.core import *
            >>> SCENE.persp.tx >> SCENE.top.tx  # connect
            >>> SCENE.persp.tx // SCENE.top.tx  # disconnect
        """
        return connectAttr( self, other, force=True )

    disconnect = disconnectAttr

    def __floordiv__(self, other):
        """
        operator for 'disconnectAttr'

            >>> from pymel.core import *
            >>> SCENE.persp.tx >> SCENE.top.tx  # connect
            >>> SCENE.persp.tx // SCENE.top.tx  # disconnect
        """
        # no return
        cmds.disconnectAttr( self, other )

    def inputs(self, **kwargs):
        """
        ``listConnections -source 1 -destination 0``

        see `Attribute.connections` for the full ist of flags.

        :rtype: `PyNode` list
        """

        kwargs['source'] = True
        kwargs.pop('s', None )
        kwargs['destination'] = False
        kwargs.pop('d', None )

        return listConnections(self, **kwargs)

    def outputs(self, **kwargs):
        """
        ``listConnections -source 0 -destination 1``

        see `Attribute.connections` for the full ist of flags.

        :rtype: `PyNode` list
        """

        kwargs['source'] = False
        kwargs.pop('s', None )
        kwargs['destination'] = True
        kwargs.pop('d', None )

        return listConnections(self, **kwargs)

    def insertInput(self, node, nodeOutAttr, nodeInAttr ):
        """connect the passed node.outAttr to this attribute and reconnect
        any pre-existing connection into node.inAttr.  if there is no
        pre-existing connection, this method works just like connectAttr.

        for example, for two nodes with the connection::

            a.out-->b.in

        running this command::

            b.insertInput( 'c', 'out', 'in' )

        causes the new connection order (assuming 'c' is a node with 'in' and 'out' attributes)::

            a.out-->c.in
            c.out-->b.in
        """
        inputs = self.inputs(plugs=1)
        self.connect( node + '.' + nodeOutAttr, force=1 )
        if inputs:
            inputs[0].connect( node + '.' + nodeInAttr )

    @_factories.addMelDocs( 'setKeyframe' )
    def setKey(self, **kwargs):
        kwargs.pop( 'attribute', None )
        kwargs.pop( 'at', None )
        return cmds.setKeyframe( self, **kwargs )
#}
#----------------------
#xxx{ Info and Modification
#----------------------

    def getAlias(self, **kwargs):
        """
        Returns the alias for this attribute, or None.

        The alias of the attribute is set through
        Attribute.setAlias, or the aliasAttr command.
        """
        alias = self.node().__apimfn__().plugsAlias(self.__apimplug__())
        if alias:
            return alias
        else:
            return None

    def setAlias(self, alias):
        """
        Sets the alias for this attribute (similar to aliasAttr).
        """
        cmds.aliasAttr(alias, self.name())

#    def add( self, **kwargs):
#        kwargs['longName'] = self.plugAttr()
#        kwargs.pop('ln', None )
#        return addAttr( self.node(), **kwargs )

    def delete(self):
        """deleteAttr"""
        return cmds.deleteAttr( self )

    def remove( self, **kwargs):
        'removeMultiInstance'
        #kwargs['break'] = True
        return cmds.removeMultiInstance( self, **kwargs )

    # Edge, Vertex, CV Methods
#    def getTranslation( self, **kwargs ):
#        """xform -translation"""
#        kwargs['translation'] = True
#        kwargs['query'] = True
#        return datatypes.Vector( cmds.xform( self, **kwargs ) )

    #----------------------
    # Info Methods
    #----------------------

    def isDirty(self, **kwargs):
        """
        :rtype: `bool`
        """
        return cmds.isDirty(self, **kwargs)

    def setDirty(self, **kwargs):
        cmds.dgdirty(self, **kwargs)

    def evaluate(self, **kwargs):
        cmds.dgeval(self, **kwargs)

    def affects( self, **kwargs ):
        rawResult = cmds.affects( self.plugAttr(), self.node() )
        if not rawResult:
            return []
        return [Attribute( '%s.%s' % ( self.node(), x )) for x in rawResult]

    def affected( self, **kwargs ):
        rawResult = cmds.affects( self.plugAttr(), self.node(), by=True  )
        if not rawResult:
            return []
        return [Attribute( '%s.%s' % ( self.node(), x )) for x in rawResult]

    class  _TempRealIndexedAttr(object):
        '''When used with the 'with statement', will return a 'sibling' of the
        whose indices all exist - creating indices if needed.

        If any indices are created, they will be destroyed in exit.
        '''
        def __init__(self, attr):
            self.origAttr = attr

            # indexed attrs whose indice we have created, and will need to
            # delete when done
            self.toDelete = None

        def _getRealIndexedElem(self, plug, i):
            parent = self.chain[i - 1]
            indices = parent.getArrayIndices()
            if plug.index() in indices:
                return plug
            if indices:
                #print "plug didn't exist, but parent had existing indices..."
                return parent[indices[0]]
            # Because it was the Great One's number...
            newPlug = parent[99]
            #print "plug didn't exist, parent had no existing indices..."
            try:
                # this should create a 'real' instance at that index
                newPlug.get()
            except Exception:
                pass

            self.chain[i] = newPlug
            # Only need to delete the 'topmost' plug
            if self.toDelete is None:
                self.toDelete = newPlug

        def __enter__(self):
            self.chain = self.origAttr.getAllParents(arrays=True)
            self.chain.reverse()
            self.chain.append(self.origAttr)

            # traverse, starting from upper-most parent, as we may need to
            # replace children with 'real' ones as we go down
            for i in xrange(len(self.chain)):
                #print 'processing:', i
                elem = self.chain[i]
                if self.toDelete:
                    #print 'need new plug due to upstream change'
                    # We've already had to make a new attribute upstream,
                    # which means we need to grab a 'new' object for every
                    # element downstream.
                    if elem.isChild():
                        newPlug = self.chain[i-1].attr(elem.attrName())
                        self.chain[i] = newPlug
                    elif elem.isElement():
                        self._getRealIndexedElem(elem, i)
                elif elem.isElement():
                    self._getRealIndexedElem(elem, i)
            return self.chain[-1]

        def __exit__(self, type, value, traceback):
            if self.toDelete is not None:
                cmds.removeMultiInstance(self.toDelete.name())

    # getAttr info methods
    def type(self):
        """
        getAttr -type

        :rtype: `unicode`
        """
        # Note - currently, this returns 'TdataCompound' even for multi,
        # NON-compound attributes, if you feed it the array plug (ie, not
        # an indexed element plug)
        # Not sure this is really desirable, but changing would be backward
        # incompatible... revisit this later?
        with self._TempRealIndexedAttr(self) as realAttr:
            res = cmds.getAttr(realAttr.name(), type=True)
            if res:
                return res
            # Sometimes getAttr seems to fail with dynamic attributes...
            if realAttr.isDynamic():
                at = cmds.addAttr(realAttr.name(), q=1, attributeType=1)
                if isinstance(at, (list, tuple)):
                    at = at[0]
                if at != 'typed':
                    return at
                dt = cmds.addAttr(realAttr.name(), q=1, dataType=1)
                if isinstance(dt, (list, tuple)):
                    dt = dt[0]
                return dt

    def setLocked(self, locked, checkReference=CHECK_ATTR_BEFORE_LOCK):
        '''
        Sets the locked state for this plug's value. A plug's locked state determines whether or not the plug's value can be changed.

        :Parameters:
            locked : `bool`
                True if this plug's value is to be locked
            checkReference : `bool`
                Set True to raise errors on referenced attributes.

                By default pymel and the maya api do not check if the node is referenced before
                setting the locked state. This is unsafe because changes to the locked state on
                referenced nodes are not saved with the scene.
        '''

        if checkReference and self.node().isReferenced():
            raise AttributeError("The attribute '%s' is from a referenced file, and cannot be %s."
                                 % (self, ('unlocked', 'locked')[locked]))
        else:
            self._setLocked(locked)

    def lock(self, checkReference=CHECK_ATTR_BEFORE_LOCK):
        "setAttr -locked 1"
        return self.setLocked(True, checkReference=checkReference)

    def unlock(self, checkReference=CHECK_ATTR_BEFORE_LOCK):
        "setAttr -locked 0"
        return self.setLocked(False, checkReference=checkReference)

    def isMuted(self):
        """
        mute -q

        :rtype: `bool`
        """
        return cmds.mute(self.name(), q=1)

    def mute(self, **kwargs):
        """
        mute
         Mutes the attribute.
        """
        cmds.mute(self.name(), **kwargs)

    def unmute(self, **kwargs):
        """
        mute -disable -force
         Unmutes the attribute
        """

        kwargs.setdefault('disable', True)
        kwargs.setdefault('force', True)
        cmds.mute(self.name(), **kwargs)

    def isSettable(self):
        """getAttr -settable

        :rtype: `bool`
        """
        # use MPlug.isFreeToChange, as it doesn't have the issues that getAttr
        # does with multi-compound attributes with no indices existing
        #return cmds.getAttr(self.name(placeHolderIndices=False), settable=True)
        return self.__apimplug__().isFreeToChange() == _api.MPlug.kFreeToChange

    # attributeQuery info methods
    def isHidden(self):
        """
        attributeQuery -hidden

        :rtype: `bool`
        """
        return cmds.attributeQuery(self.attrName(), node=self.node(), hidden=True)

    def isConnectable(self):
        """
        attributeQuery -connectable

        :rtype: `bool`
        """
        return cmds.attributeQuery(self.attrName(), node=self.node(), connectable=True)
    def isUsedAsColor(self):
        """
        attributeQuery -usedAsColor
        """
        return cmds.attributeQuery(self.attrName(), node=self.node(),uac=True)


    def indexMatters(self):
        return self.__apimattr__().indexMatters()

    isMulti = _factories.wrapApiMethod( _api.MPlug, 'isArray', 'isMulti' )


    def exists(self):
        """
        Whether the attribute actually exists.

        In spirit, similar to 'attributeQuery -exists'...
        ...however, also handles multi (array) attribute elements, such as plusMinusAverage.input1D[2]

        :rtype: `bool`
        """
        if not self.node().exists():
            return False

        if self.isElement():
            arrayExists = self.array().exists()
            if not arrayExists:
                return False

            # If the array exists, now check the array indices...
            indices = self.array().getArrayIndices()
            return bool(indices and self.index() in indices)
        elif self.isChild():
            # attributeQuery doesn't handle multi-compound attributes well...
            # so need to traverse all the way up the parent chain
            return self.parent().exists()
        else:
            try:
                return bool( cmds.attributeQuery(self.lastPlugAttr(), node=self.node(), exists=True) )
            except TypeError:
                return False

#}
#--------------------------
#xxx{ Ranges
#--------------------------

    def getSoftMin(self):
        """attributeQuery -softMin
            Returns None if softMin does not exist.

        :rtype: `float`
        """
        if cmds.attributeQuery(self.lastPlugAttr(), node=self.node(), softMinExists=True):
            return cmds.attributeQuery(self.lastPlugAttr(), node=self.node(), softMin=True)[0]

    def getSoftMax(self):
        """attributeQuery -softMax
            Returns None if softMax does not exist.

        :rtype: `float`
        """
        if cmds.attributeQuery(self.lastPlugAttr(), node=self.node(), softMaxExists=True):
            return cmds.attributeQuery(self.lastPlugAttr(), node=self.node(), softMax=True)[0]

    def getMin(self):
        """attributeQuery -min
            Returns None if min does not exist.

        :rtype: `float`
        """
        if cmds.attributeQuery(self.lastPlugAttr(), node=self.node(), minExists=True):
            return cmds.attributeQuery(self.lastPlugAttr(), node=self.node(), min=True)[0]

    def getMax(self):
        """attributeQuery -max
            Returns None if max does not exist.

        :rtype: `float`
        """
        if cmds.attributeQuery(self.lastPlugAttr(), node=self.node(), maxExists=True):
            return cmds.attributeQuery(self.lastPlugAttr(), node=self.node(), max=True)[0]

    def getSoftRange(self):
        """attributeQuery -softRange
            returns a two-element list containing softMin and softMax. if the attribute does not have
            a softMin or softMax the corresponding element in the list will be set to None.

        :rtype: [`float`, `float`]
        """
        softRange = []
        softRange.append( self.getSoftMin() )
        softRange.append( self.getSoftMax() )
        return softRange


    def getRange(self):
        """attributeQuery -range
            returns a two-element list containing min and max. if the attribute does not have
            a softMin or softMax the corresponding element will be set to None.

        :rtype: `float`
        """
        range = []
        range.append( self.getMin() )
        range.append( self.getMax() )
        return range

    def setMin(self, newMin):
        self.setRange(newMin, 'default')

    def setMax(self, newMax):
        self.setRange('default', newMax)

    def setSoftMin(self, newMin):
        self.setSoftRange(newMin, 'default')

    def setSoftMax(self, newMax):
        self.setSoftRange('default', newMax)

    def setRange(self, *args):
        """provide a min and max value as a two-element tuple or list, or as two arguments to the
        method. To remove a limit, provide a None value.  for example:

            >>> from pymel.core import *
            >>> s = polyCube()[0]
            >>> s.addAttr( 'new' )
            >>> s.new.setRange( -2, None ) #sets just the min to -2 and removes the max limit
            >>> s.new.setMax( 3 ) # sets just the max value and leaves the min at its previous default
            >>> s.new.getRange()
            [-2.0, 3.0]

        """

        self._setRange('hard', *args)

    def setSoftRange(self, *args):
        self._setRange('soft', *args)

    def _setRange(self, limitType, *args):

        if len(args)==2:
            newMin = args[0]
            newMax = args[1]

        if len(args)==1:
            try:
                newMin = args[0][0]
                newMax = args[0][1]
            except:
                raise TypeError, "Please provide a min and max value as a two-element tuple or list, or as two arguments to the method. To ignore a limit, provide a None value."


#        # first find out what connections are going into and out of the object
#        ins = self.inputs(p=1)
#        outs = self.outputs(p=1)
#
#        # get the current value of the attr
#        val = self.get()
#
#        # break the connections if they exist
#        self.disconnect()

        # MIN
        # if 'default' is passed, we retain the current value
        if newMin == 'default':
            pass
        elif newMin is None:
            if limitType == 'hard':
                addAttr(self, edit=1, hasMinValue=False)
            else:
                addAttr(self, edit=1, hasSoftMinValue=False)
        else:
            if limitType == 'hard':
                addAttr(self, edit=1, minValue=newMin)
            else:
                addAttr(self, edit=1, softMinValue=newMin)


        # MAX
        # if 'default' is passed, we retain the current value
        if newMax == 'default':
            pass
        elif newMax is None:
            if limitType == 'hard':
                addAttr(self, edit=1, hasMaxValue=False)
            else:
                addAttr(self, edit=1, hasSoftMaxValue=False)
        else:
            if limitType == 'hard':
                addAttr(self, edit=1, maxValue=newMax)
            else:
                addAttr(self, edit=1, softMaxValue=newMax)


#        # set the value to be what it used to be
#        self.set(val)
#
#        # remake the connections
#        for conn in ins:
#            conn >> self
#
#        for conn in outs:
#            self >> outs


#    def getChildren(self):
#        """attributeQuery -listChildren"""
#        return map(
#            lambda x: Attribute( self.node() + '.' + x ),
#            _util.listForNone( cmds.attributeQuery(self.lastPlugAttr(), node=self.node(), listChildren=True) )
#                )
#}
#--------------------------
#xxx{ Relatives
#--------------------------

    def getChildren(self):
        """attributeQuery -listChildren

        :rtype: `Attribute` list
        """
        res = []
        for i in range(self.numChildren() ):
            res.append( Attribute( self.node(), self.__apimfn__().child(i) ) )
        return res
    children = getChildren

    def iterDescendants(self, levels=None, leavesOnly=False):
        '''Yields all attributes "below" this attribute, recursively,
        traversing down both through multi/array elements, and through
        compound attribute children.

        Parameters
        ----------
        levels : int or None
            the number of levels deep to descend; each descent from an array
            to an array element, and from a compound to it's child, counts as
            one level (so, if you have a compound-multi attr parentAttr, to get
            to parentAttr[0].child would require levels to be at least 2); None
            means no limit
        leavesOnly : bool
            if True, then results will only be returned if they do not have any
            children to recurse into (either because it's not an arry or
            compound, or because we've hit the levels limit)
        '''
        if levels is None:
            nextLevels = None
        elif levels <= 0:
            return
        else:
            nextLevels = levels - 1

        def hasArrayChildren(attr):
            return attr.isArray() and attr.evaluateNumElements()

        def isLeaf(attr):
            return ((nextLevels is not None and nextLevels <= 0) or
                    (not attr.isCompound() and not hasArrayChildren(attr)))

        if self.isArray():
            children = iter(self)
        elif self.isCompound():
            children = self.getChildren()
        else:
            children = []

        for child in children:
            leaf = isLeaf(child)
            if not leavesOnly or leaf:
                yield child
            if not leaf:
                for grandChild in child.iterDescendants(levels=nextLevels,
                                                        leavesOnly=leavesOnly):
                    yield grandChild


    def getSiblings(self):
        """
        attributeQuery -listSiblings

        :rtype: `Attribute` list
        """
        try:
            return self.getParent().getChildren()
        except:
            pass
    siblings = getSiblings

    @_warnings.deprecated('use Attribute.getParent instead', 'Attribute')
    def firstParent(self):
        "deprecated: use getParent instead"

        try:
            return Attribute( self.node(), self.__apimfn__().parent() )
        except:
            pass

    @staticmethod
    def _getAttrParent(plug):
        if plug.isChild():
            return plug.parent()
        else:
            return None

    @staticmethod
    def _getAttrOrMultiParent(plug):
        if plug.isChild():
            return plug.parent()
        elif plug.isElement():
            return plug.array()
        else:
            return None


    def getParent(self, generations=1, arrays=False):
        """
        Modifications:
            - added optional generations keyword arg, which gives the number of
              levels up that you wish to go for the parent

              Negative values will traverse from the top.

              A value of 0 will return the same node.
              The default value is 1.

              If generations is None, it will be interpreted as 'return all
              parents', and a list will be returned.

              Since the original command returned None if there is no parent,
              to sync with this behavior, None will be returned if generations
              is out of bounds (no IndexError will be thrown).

            - added optional arrays keyword arg, which if True, will also
              traverse from an array element to an array plug

        :rtype: `Attribute`
        """
        if arrays:
            getter = self._getAttrOrMultiParent
        else:
            getter = self._getAttrParent

        res = _getParent(getter, self.__apimfn__(), generations)
        if generations is None:
            if res is None:
                return []
            return [Attribute(self.node(), x) for x in res]
        elif res is not None:
            return Attribute( self.node(), res )

    def getAllParents(self, arrays=False):
        """
        Return a list of all parents above this.

        Starts from the parent immediately above, going up.

        :rtype: `Attribute` list
        """
        return self.getParent(generations=None, arrays=arrays)

    parent = getParent

def _MObjectIn(x):
    if isinstance(x,PyNode): return x.__apimobject__()
    return PyNode(x).__apimobject__()
def _MDagPathIn(x):
    if isinstance(x,PyNode): return x.__apimdagpath__()
    return PyNode(x).__apimdagpath__()
def _MPlugIn(x):
    if isinstance(x,PyNode): return x.__apimplug__()
    return PyNode(x).__apimplug__()
def _MPlugOut(self,x):
    return PyNode(self.node(), x)
    #try: return PyNode(self.node(), x)
    #except: pass
    #return PyNode(x)
_factories.ApiTypeRegister.register('MObject', PyNode, inCast=_MObjectIn )
_factories.ApiTypeRegister.register('MDagPath', PyNode, inCast=_MDagPathIn )
_factories.ApiTypeRegister.register('MPlug', PyNode, inCast=_MPlugIn, outCast=_MPlugOut )



# TODO:
# -----
# Seperate out _makeComponentHandle and _setComponentHandle - ie, order should be:
#    1. _makeComponentHandle
#    2. _makeMFnComponent
#    3. _setComponentHandle
# Implement makeComponentFromIndex - have it return an MObject handle
# Implement multiple component labels! (ie, surface iso can be 'u' or 'v')
# Add 'setCompleteData' when we can find how many components (instead of just 'setComplete')
# Handle multiple _ComponentLabel__'s that refer to different flavors of same component type -
#    ie, NurbsSurface.u/.v/.uv, transform.rotatePivot/scalePivot
# NurbsSurfaceRange
# Make it work with multiple component types in single component(?)

def _formatSlice(sliceObj):
    startIndex, stopIndex, step = sliceObj.start, sliceObj.stop, sliceObj.step
    if startIndex == stopIndex:
        sliceStr = '%s' % startIndex
    elif step is not None and step != 1:
        sliceStr = '%s:%s:%s' % (startIndex, stopIndex, step)
    else:
        sliceStr = '%s:%s' % (startIndex, stopIndex)
    return sliceStr


ProxySlice = _util.proxyClass( slice, 'ProxySlice', module=__name__, dataAttrName='_slice', makeDefaultInit=True)
# prevent auto-completion generator from getting confused
ProxySlice.__module__ = __name__

# Really, don't need to have another class inheriting from
# the proxy class, but do this so I can define a method using
# normal class syntax...
class HashableSlice(ProxySlice):
    def __init__(self, *args, **kwargs):
        if len(args) == 1 and not kwargs and isinstance(args[0], (slice, HashableSlice)):
            if isinstance(args[0], HashableSlice):
                self._slice = args[0]._slice
            else:
                self._slice = args[0]
        else:
            self._slice = slice(*args, **kwargs)

    def __hash__(self):
        if not hasattr(self, '_hash'):
            self._hash = (self.start, self.stop, self.step).__hash__()
        return self._hash

    def _toNormalSlice(self):
        return slice(self.start, self.stop, self.step)

    def __cmp__(self, other):
        if isinstance(other, HashableSlice):
            other = other._toNormalSlice()
        elif not isinstance(other, slice):
            return -1
        return slice.__cmp__(self._toNormalSlice(), other)

    @property
    def start(self):
        return self._slice.start

    @property
    def stop(self):
        return self._slice.stop

    @property
    def step(self):
        return self._slice.step

class Component( PyNode ):
    """
    Abstract base class for pymel components.
    """

    __metaclass__ = _factories.MetaMayaComponentWrapper
    _mfncompclass = _api.MFnComponent
    _apienum__ = _api.MFn.kComponent
    _ComponentLabel__ = None

    # Maya 2008 and earlier have no kUint64SingleIndexedComponent /
    # MFnUint64SingleIndexedComponent...
    _componentEnums = [_api.MFn.kComponent,
                       _api.MFn.kSingleIndexedComponent,
                       _api.MFn.kDoubleIndexedComponent,
                       _api.MFn.kTripleIndexedComponent]

    if hasattr(_api.MFn, 'kUint64SingleIndexedComponent'):
        _hasUint64 = True
        _componentEnums.append(_api.MFn.kUint64SingleIndexedComponent)
    else:
        _hasUint64 = False


    @classmethod
    def _componentMObjEmpty(cls, mobj):
        """
        Returns true if the given component mobj is empty (has no elements).
        """

#        Note that a component marked as complete will return elementCount == 0,
#        even if it is not truly empty.
#
#        Even MFnComponent.isEmpty will sometimes "lie" if component is complete.
#
#        Try this:
#
#        import maya.OpenMaya as api
#        import maya.cmds as cmds
#
#        melSphere = cmds.sphere()[0]
#        selList = _api.MSelectionList()
#        selList.add(melSphere + '.cv[*][*]')
#        compObj = _api.MObject()
#        dagPath = _api.MDagPath()
#        selList.getDagPath(0, dagPath, compObj)
#        mfnComp = _api.MFnDoubleIndexedComponent(compObj)
#        print "is empty:", mfnComp.isEmpty()
#        print "is complete:", mfnComp.isComplete()
#        print "elementCount:", mfnComp.elementCount()
#        print
#        mfnComp.setComplete(True)
#        print "is empty:", mfnComp.isEmpty()
#        print "is complete:", mfnComp.isComplete()
#        print "elementCount:", mfnComp.elementCount()
#        print
#        mfnComp.setComplete(False)
#        print "is empty:", mfnComp.isEmpty()
#        print "is complete:", mfnComp.isComplete()
#        print "elementCount:", mfnComp.elementCount()
#        print

        mfnComp = _api.MFnComponent(mobj)
        completeStatus = mfnComp.isComplete()
        if completeStatus:
            mfnComp.setComplete(False)
        isEmpty = mfnComp.isEmpty()
        if completeStatus:
            mfnComp.setComplete(True)
        return isEmpty

    def __init__(self, *args, **kwargs ):
        # the Component class can be instantiated several ways:
        # Component(dagPath, component):
        #    args get stored on self._node and
        #    self.__apiobjects__['MObjectHandle'] respectively
        # Component(dagPath):
        #    in this case, stored on self.__apiobjects__['MDagPath']
        #    (self._node will be None)

        # First, ensure that we have a self._node...
        if not self._node :
            dag = self.__apiobjects__['MDagPath']
            self._node = PyNode(dag)
        assert(self._node)

        # Need to do indices checking even for non-dimensional
        # components, because the ComponentIndex might be used to
        # specify the 'flavor' of the component - ie, 'scalePivot' or
        # 'rotatePivot' for Pivot components
        self._indices = self.__apiobjects__.get('ComponentIndex', None)

        if self._indices:
            if _util.isIterable(self._ComponentLabel__):
                oldCompLabel = set(self._ComponentLabel__)
            else:
                oldCompLabel = set( (self._ComponentLabel__,) )
            if isinstance(self._indices, dict):
                if len(self._indices) > 1:
                    assert set(self._indices.iterkeys()).issubset(oldCompLabel)
                    self._ComponentLabel__ = self._indices.keys()
                else:
                    # dict only has length 1..
                    self._ComponentLabel__ = self._indices.keys()[0]
                    self._indices = self._indices.values()[0]
            if isinstance(self._indices, ComponentIndex) and self._indices.label:
                assert self._indices.label in oldCompLabel
                self._ComponentLabel__ = self._indices.label
        elif 'MObjectHandle' not in self.__apiobjects__:
            # We're making a component by ComponentClass(shapeNode)...
            # set a default label if one is specified
            if self._defaultLabel():
                self._ComponentLabel__ = self._defaultLabel()

    def __apimdagpath__(self) :
        "Return the MDagPath for the node of this component, if it is valid"
        try:
            #print "NODE", self.node()
            return self.node().__apimdagpath__()
        except AttributeError: pass

    def __apimobject__(self) :
        "get the MObject for this component if it is valid"
        handle = self.__apihandle__()
        if _api.isValidMObjectHandle( handle ) :
            return handle.object()
        # Can't use self.name(), as that references this!
        raise MayaObjectError( self._completeNameString() )

    def __apiobject__(self) :
        return self.__apimobject__()

    def __apihandle__(self) :
        if 'MObjectHandle' not in self.__apiobjects__:
            handle = self._makeComponentHandle()
            if not handle or not _api.isValidMObjectHandle(handle):
                raise MayaObjectError( self._completeNameString() )
            self.__apiobjects__['MObjectHandle'] = handle
        return self.__apiobjects__['MObjectHandle']

    def __apicomponent__(self):
        mfnComp = self.__apiobjects__.get('MFnComponent', None)
        if mfnComp is None:
            mfnComp = self._mfncompclass(self.__apimobject__())
            self.__apiobjects__['MFnComponent'] = mfnComp
        return mfnComp

    def __apimfn__(self):
        return self.__apicomponent__()

    def __eq__(self, other):
        if not hasattr(other, '__apicomponent__'):
            return False
        return self.__apicomponent__().isEqual( other.__apicomponent__().object() )

    def __nonzero__(self):
        """
        :rtype: `bool`
        """
        return bool(len(self))

    def __str__(self):
        return str(self.name())

    def __unicode__(self):
        return self.name()

    def _completeNameString(self):
        return u'%s.%s' % ( self.node(), self.plugAttr())

    def _makeComponentHandle(self):
        component = None
        # try making from MFnComponent.create, if _mfncompclass has it defined
        if ('create' in dir(self._mfncompclass) and
            self._apienum__ not in self._componentEnums + [None]):
            try:
                component = self._mfncompclass().create(self._apienum__)
            # Note - there's a bug with kSurfaceFaceComponent - can't use create
            except RuntimeError:
                pass
            else:
                if not _api.isValidMObject(component):
                    component = None

        # that didn't work - try checking if we have a valid plugAttr
        if not component and self.plugAttr():
            try:
                component = _api.toApiObject(self._completeNameString())[1]
            except Exception:
                pass
            else:
                if not _api.isValidMObject(component):
                    component = None

        # component objects we create always start out 'complete'
        mfnComp = self._mfncompclass(component)
        mfnComp.setComplete(True)

        return _api.MObjectHandle(component)

    def __melobject__(self):
        selList = _api.MSelectionList()
        selList.add(self.__apimdagpath__(), self.__apimobject__(), False)
        strings = []
        selList.getSelectionStrings(0, strings)
        nodeName = self.node().name() + '.'
        strings = [ nodeName + x.split('.',1)[-1] for x in strings ]
        if not strings:
            return self._completeNameString()
        elif len(strings) == 1:
            return strings[0]
        else:
            return strings

    def _defaultLabel(self):
        """
        Intended for classes such as NurbsSurfaceRange which have multiple possible
        component labels (ie, u, v, uv), and we want to specify a 'default' one
        so that we can do NurbsSurfaceRange(myNurbsSurface).

        This should be None if either the component only has one label, or picking
        a default doesn't make sense (ie, in the case of Pivot, we have no
        idea whether the user would want the scale or rotate pivot, so
        doing Pivot(myObject) makes no sense...
        """
        return None

    def name(self):
        melObj = self.__melobject__()
        if isinstance(melObj, basestring):
            return melObj
        return repr(melObj)

    def node(self):
        return self._node

    def namespace(self, *args, **kwargs):
        return self.node().namespace(*args, **kwargs)

    # just for backward compatibility with old Component class (though the
    # only place this WAS used was with particles...)
    plugNode = node

    def plugAttr(self):
        return self._ComponentLabel__

    def isComplete(self, *args, **kwargs):
        return self._isCompleteMfnComp(self.__apicomponent__())

    def _isCompleteMfnComp(self, mfncomp):
        return mfncomp.isComplete()

    @staticmethod
    def numComponentsFromStrings(*componentStrings):
        """
        Does basic string processing to count the number of components
        given a number of strings, which are assumed to be the valid mel names
        of components.
        """
        numComps = 0
        for compString in componentStrings:
            indices = re.findall(r'\[[^\]]*\]', compString)
            newComps = 1
            if indices:
                for index in indices:
                    if ':' in index:
                        indexSplit = index.split(':')
                        # + 1 is b/c mel indices are inclusive
                        newComps *= int(indexSplit[1]) - int(indexSplit[0]) + 1
            numComps += newComps
        return numComps

class DimensionedComponent( Component ):
    """
    Components for which having a __getitem__ of some sort makes sense

    ie, myComponent[X] would be reasonable.
    """
    # All components except for the pivot component and the unknown ones are
    # indexable in some manner

    dimensions = 0

    def __init__(self, *args, **kwargs ):
        # the Component class can be instantiated several ways:
        # Component(dagPath, component):
        #    args get stored on self._node and
        #    self.__apiobjects__['MObjectHandle'] respectively
        # Component(dagPath):
        #    in this case, stored on self.__apiobjects__['MDagPath']
        #    (self._node will be None)
        super(DimensionedComponent, self).__init__(*args, **kwargs)

        isComplete = True

        # If we're fed an MObjectHandle already, we don't allow
        # __getitem__ indexing... unless it's complete
        handle = self.__apiobjects__.get('MObjectHandle', None)
        if handle is not None:
            mfncomp = self._mfncompclass(handle.object())
            if not self._isCompleteMfnComp(mfncomp):
                isComplete = False

        if isinstance(self._indices, dict) and len(self._indices) > 1:
            isComplete = False

        # If the component is complete, we allow further indexing of it using
        # __getitem__
        # Whether or not __getitem__ indexing is allowed, and what dimension
        # we are currently indexing, is stored in _partialIndex
        # If _partialIndex is None, __getitem__ indexing is NOT allowed
        # Otherwise, _partialIndex should be a ComponentIndex object,
        # and it's length indicates how many dimensions have already been
        # specified.
        if isComplete:
            # Do this test before doing 'if self._indices',
            # because an empty ComponentIndex will be 'False',
            # but could still have useful info (like 'label')!
            if isinstance(self._indices, ComponentIndex):
                if len(self._indices) < self.dimensions:
                    self._partialIndex = self._indices
                else:
                    self._partialIndex = None
            elif self._indices:
                self._partialIndex = None
            else:
                self._partialIndex = ComponentIndex(label=self._ComponentLabel__)
        else:
            self._partialIndex = None

    def _completeNameString(self):
        # Note - most multi-dimensional components allow selection of all
        # components with only a single index - ie,
        #    myNurbsSurface.cv[*]
        # will work, even though nurbs cvs are double-indexed
        # However, some multi-indexed components WON'T work like this, ie
        #    myNurbsSurface.sf[*]
        # FAILS, and you MUST do:
        #    myNurbsSurface.sf[*][*]
        # ...However, some multi-indexed components (well, only LatticePoint
        # that I know of) will give incorrect results with
        #    ffd1LatticeShape.pt[*][*][*]
        # ...and so you must do
        #    ffd1LatticeShape.pt[*]
        return (super(DimensionedComponent, self)._completeNameString() +
                 ('[*]' * self.dimensions))

    def _makeComponentHandle(self):
        indices = self._standardizeIndices(self._indices)
        handle = self._makeIndexedComponentHandle(indices)
        return handle

    def _makeIndexedComponentHandle(self, indices):
        """
        Returns an MObjectHandle that points to a maya component object with
        the given indices.
        """
        selList = _api.MSelectionList()
        def addComp(compName):
            try:
                selList.add(compName)
            except RuntimeError:
                raise MayaComponentError(compName)

        if len(indices) == 1 and self._isCompleteIndex(indices[0]):
            addComp(self._completeNameString())
        else:
            for index in indices:
                compName = Component._completeNameString(self)
                for dimNum, dimIndex in enumerate(index):
                    if isinstance(dimIndex, (slice, HashableSlice)):
                        # by the time we're gotten here, standardizedIndices
                        # should have either flattened out slice-indices
                        # (DiscreteComponents) or disallowed slices with
                        # step values (ContinuousComponents)
                        if dimIndex.start == dimIndex.stop == None:
                            dimIndex = '*'
                        else:
                            if dimIndex.start is None:
                                if isinstance(self, DiscreteComponent):
                                    start = 0
                                else:
                                    partialIndex = ComponentIndex(('*',)*dimNum,
                                                                  index.label)
                                    start = self._dimRange(partialIndex)[0]
                            else:
                                start = dimIndex.start
                            if dimIndex.stop is None:
                                partialIndex = ComponentIndex(('*',)*dimNum,
                                                              index.label)
                                stop= self._dimRange(partialIndex)[1]
                            else:
                                stop = dimIndex.stop
                            dimIndex = "%s:%s" % (start, stop)
                    compName += '[%s]' % dimIndex
                addComp(compName)
        compMobj = _api.MObject()
        dagPath = _api.MDagPath()
        selList.getDagPath(0, dagPath, compMobj)
        return _api.MObjectHandle(compMobj)

    VALID_SINGLE_INDEX_TYPES = []  # re-define in derived!

    # For situations in which we want a component object to represent ALL the
    # possible components of that type - ie, all the vertices - it is a LOT
    # faster to special case that situation, rather than the default behavior,
    # which will flatten out the components into a list, etc.
    # However, the shortcut for "complete" components will not work for all
    # component types (ie, subdiv components), so this function controls whether
    # it will be used.
    _ALLOW_COMPLETE_SHORTCUT = True

    # in addition, for some types, it may USUALLY be allowable to use [*]
    # syntax, but in some specific instances, it will cause problems... ie,
    # for empty meshes, doing
    #    pCubeShape1.vtx[*]
    # will error...
    def _allowCompleteShortcut(self):
        # check for the empty mesh problem by grabbing the node's mfn - if it's
        # a dag node, we have problems
        return (self._ALLOW_COMPLETE_SHORTCUT
                and not issubclass(_api.MFnDagNode,
                                   type(self.node().__apimfn__())))


    def _standardizeIndices(self, indexObjs, allowIterable=True, label=None,
                            allowComplete=True):
        """
        Convert indexObjs to an iterable of ComponentIndex objects.

        indexObjs may be a member of VALID_SINGLE_INDEX_TYPES, a
        ComponentIndex object, or an iterable of such items (if allowIterable),
        or 'None'
        """
        # For speed, we want to allow through "entire component" indices,
        # without flattening... but only if "allowComplete" is True
        if not self._allowCompleteShortcut():
            allowComplete = False

        if indexObjs is None:
            indexObjs = ComponentIndex(label=label)

        indices = set()
        # Convert single objects to a list
        if isinstance(indexObjs, self.VALID_SINGLE_INDEX_TYPES):
            if self.dimensions == 1:
                if (isinstance(indexObjs, (slice, HashableSlice)) and not
                        (allowComplete and self._isCompleteIndex(indexObjs))):
                    return self._standardizeIndices(self._sliceToIndices(indexObjs), label=label)
                else:
                    indices.add(ComponentIndex((indexObjs,), label=label))
            else:
                raise IndexError("Single Index given for a multi-dimensional component")
        elif isinstance(indexObjs, ComponentIndex):
            if label and indexObjs.label and label != indexObjs.label:
                raise IndexError('ComponentIndex object had a different label than desired (wanted %s, found %s)'
                                 % (label, indexObjs.label))
            if allowComplete and self._isCompleteIndex(indexObjs):
                indices.add(self._completeIndex(label=label))
            else:
                indices.update(self._flattenIndex(indexObjs))
        elif isinstance(indexObjs, dict):
            # Dicts are used to specify component labels for a group of indices at once...
            for dictLabel, dictIndices in indexObjs.iteritems():
                if label and label != dictLabel:
                    raise IndexError('ComponentIndex object had a different label than desired (wanted %s, found %s)'
                                     % (label, dictLabel))
                indices.update(self._standardizeIndices(dictIndices, label=dictLabel))
        elif allowIterable and _util.isIterable(indexObjs):
            for index in indexObjs:
                indices.update(self._standardizeIndices(index,
                                                        allowIterable=False,
                                                        label=label))
                if (allowComplete and len(indices) == 1
                        and self._isCompleteIndex(list(indices)[0])):
                    break
                allowComplete = False
        else:
            raise IndexError("Invalid indices for component: %r" % (indexObjs,) )
        return tuple(indices)

    def _completeIndex(self, label=None):
        return ComponentIndex((HashableSlice(None),) * self.dimensions, label=label)

    def _isCompleteIndex(self, indexObj):
        '''Return true if the indexObj represents the entire set of indices possible for this component'''
        if isinstance(indexObj, ComponentIndex):
            return (len(indexObj) == 0
                    or indexObj == self._completeIndex(label=indexObj.label))
        elif self.dimensions == 1:
            return indexObj == slice(None)
        return False

    def _sliceToIndices(self, sliceObj):
        raise NotImplementedError

    def _flattenIndex(self, index, allowIterable=True):
        """
        Given a ComponentIndex object, which may be either a partial index (ie,
        len(index) < self.dimensions), or whose individual-dimension indices
        might be slices or iterables, return an flat list of ComponentIndex
        objects.
        """
        # Some components - such as face-vertices - need to know the previous
        # indices to be able to fully expand the remaining indices... ie,
        # faceVertex[1][2][:] may result in a different expansion than for
        # faceVertex[3][8][:]...
        # for this reason, we need to supply the previous indices to
        # _sliceToIndices, and expand on a per-partial-index basis
        while len(index) < self.dimensions:
            index = ComponentIndex(index + (HashableSlice(None),))

        indices = [ComponentIndex(label=index.label)]
        for dimIndex in index:
            if isinstance(dimIndex, (slice, HashableSlice)):
                newIndices = []
                for oldPartial in indices:
                    newIndices.extend(self._sliceToIndices(dimIndex,
                                                           partialIndex=oldPartial))
                indices = newIndices
            elif _util.isIterable(dimIndex):
                if allowIterable:
                    newIndices = []
                    for oldPartial in indices:
                        for indice in dimIndex:
                            newIndices.append(oldPartial + (indice,))
                    indices = newIndices
                else:
                    raise IndexError(index)
            elif isinstance(dimIndex, (float, int, long)) and dimIndex < 0:
                indices = [x + (self._translateNegativeIndice(dimIndex,x),)
                           for x in indices]
            else:
                indices = [x + (dimIndex,) for x in indices]
        return indices

    def _translateNegativeIndice(self, negIndex, partialIndex):
        raise NotImplementedError

    def __getitem__(self, item):
        if self.currentDimension() is None:
            raise IndexError("Indexing only allowed on an incompletely "
                             "specified component (ie, 'cube.vtx')")
        self._validateGetItemIndice(item)
        return self.__class__(self._node,
            ComponentIndex(self._partialIndex + (item,)))

    def _validateGetItemIndice(self, item, allowIterables=True):
        """
        Will raise an appropriate IndexError if the given item
        is not suitable as a __getitem__ indice.
        """
        if allowIterables and _util.isIterable(item):
            for x in item:
                self._validateGetItemIndice(x, allowIterables=False)
            return
        if not isinstance(item, self.VALID_SINGLE_INDEX_TYPES):
            raise IndexError("Invalid indice type for %s: %r" %
                             (self.__class__.__name__,
                              item.__class__.__name__) )
        if isinstance(item, (slice, HashableSlice)):
            if item.step and item.step < 0:
                raise IndexError("Components do not support slices with negative steps")
            # 'None' compares as less than all numbers, so need
            # to check for it explicitly
            if item.start is None and item.stop is None:
                # If it's an open range, [:], and slices are allowed,
                # it's valid
                return
            elif item.start is None:
                minIndex = maxIndex = item.stop
            elif item.stop is None:
                minIndex = maxIndex = item.start
            else:
                maxIndex = max(item.start, item.stop)
                minIndex = min(item.start, item.stop)
            if (not isinstance(maxIndex, self.VALID_SINGLE_INDEX_TYPES) or
                not isinstance(minIndex, self.VALID_SINGLE_INDEX_TYPES)):
                raise IndexError("Invalid slice start or stop value")
        else:
            maxIndex = minIndex = item
        allowedRange = self._dimRange(self._partialIndex)
        if minIndex < allowedRange[0] or maxIndex > allowedRange[1]:
            raise IndexError("Indice %s out of range %s" % (item, allowedRange))

    def _dimRange(self, partialIndex):
        """
        Returns (minIndex, maxIndex) for the next dimension index after
        the given partialIndex.
        The range is inclusive.
        """
        raise NotImplemented

    def _dimLength(self, partialIndex):
        """
        Given a partialIndex, returns the maximum value for the first
         unspecified dimension.
        """
        # Implement in derived classes - no general way to determine the length
        # of components!
        raise NotImplementedError

    def currentDimension(self):
        """
        Returns the dimension index that an index operation - ie, self[...] /
        self.__getitem__(...) - will operate on.

        If the component is completely specified (ie, all dimensions are
        already indexed), then None is returned.
        """
        if not hasattr(self, '_currentDimension'):
            indices = self._partialIndex
            if (indices is not None and
                len(indices) < self.dimensions):
                self._currentDimension = len(indices)
            else:
                self._currentDimension = None
        return self._currentDimension

class ComponentIndex( tuple ):
    """
    Class used to specify a multi-dimensional component index.

    If the length of a ComponentIndex object < the number of dimensions,
    then the remaining dimensions are taken to be 'complete' (ie, have not yet
    had indices specified).
    """
    def __new__(cls, *args, **kwargs):
        """
        :Parameters:
        label : `string`
            Component label for this index.
            Useful for components whose 'mel name' may vary - ie, an isoparm
            may be specified as u, v, or uv.
        """
        label = kwargs.pop('label', None)
        self = tuple.__new__(cls, *args, **kwargs)
        if not label and args and isinstance(args[0], ComponentIndex) and args[0].label:
            self.label = args[0].label
        else:
            self.label = label
        return self

    def __add__(self, other):
        if isinstance(other, ComponentIndex) and other.label:
            if not self.label:
                label = other.label
            else:
                if other.label != self.label:
                    raise ValueError('cannot add two ComponentIndex objects with different labels')
                label = self.label
        else:
            label = self.label
        return ComponentIndex(itertools.chain(self, other), label=label)

    def __repr__(self):
        return "%s(%s, label=%r)" % (self.__class__.__name__,
                                     super(ComponentIndex, self).__repr__(),
                                     self.label)

def validComponentIndexType( argObj, allowDicts=True, componentIndexTypes=None):
    """
    True if argObj is of a suitable type for specifying a component's index.
    False otherwise.

    Dicts allow for components whose 'mel name' may vary - ie, a single
    isoparm component may have, u, v, or uv elements; or, a single pivot
    component may have scalePivot and rotatePivot elements.  The key of the
    dict would indicate the 'mel component name', and the value the actual
    indices.

    Thus:
       {'u':3, 'v':(4,5), 'uv':ComponentIndex((1,4)) }
    would represent single component that contained:
       .u[3]
       .v[4]
       .v[5]
       .uv[1][4]

    Derived classes should implement:
    _dimLength
    """
    if not componentIndexTypes:
        componentIndexTypes = (int, long, float, slice, HashableSlice, ComponentIndex)

    if allowDicts and isinstance(argObj, dict):
        for value in argObj.itervalues():
            if not validComponentIndexType(value, allowDicts=False):
                return False
        return True
    else:
        if isinstance(argObj, componentIndexTypes):
            return True
        elif isinstance( argObj, (list,tuple) ) and len(argObj):
            for indice in argObj:
                if not isinstance(indice, componentIndexTypes):
                    return False
            else:
                return True
    return False

class DiscreteComponent( DimensionedComponent ):
    """
    Components whose dimensions are discretely indexed.

    Ie, there are a finite number of possible components, referenced by integer
    indices.

    Example: polyCube.vtx[38], f.cv[3][2]

    Derived classes should implement:
    _dimLength
    """

    VALID_SINGLE_INDEX_TYPES = (int, long, slice, HashableSlice)

    def __init__(self, *args, **kwargs):
        self.reset()
        super(DiscreteComponent, self).__init__(*args, **kwargs)

    def _isCompleteMfnComp(self, mfncomp):
        # for components created through MSelectionList - ie, pm.PyNode('pCube1.vtx[0]')
        # - we may get back an MFnComponent object that actually has all the
        # indices, but is not marked as complete
        # check both if it is marked "isComplete", and if it has a number of
        # components equal to the number that this object has
        if mfncomp.isComplete():
            return True
        else:
            try:
                totalSize = self.totalSize()
            except NotImplementedError:
                return False
            return mfncomp.elementCount() == totalSize

    def _sliceToIndices(self, sliceObj, partialIndex=None):
        """
        Converts a slice object to an iterable of the indices it represents.

        If a partialIndex is supplied, then sliceObj is taken to be a slice
        at the next dimension not specified by partialIndex - ie,

        myFaceVertex._sliceToIndices(slice(1,-1), partialIndex=ComponentIndex((3,)))

        might be used to get a component such as

        faceVertices[3][1:-1]
        """

        if partialIndex is None:
            partialIndex = ComponentIndex()

        # store these in local variables, to avoid constantly making
        # new slice objects, since slice objects are immutable
        start = sliceObj.start
        stop = sliceObj.stop
        step = sliceObj.step

        if start is None:
            start = 0

        if step is None:
            step = 1

        # convert 'maya slices' to 'python slices'...
        # ie, in maya, someObj.vtx[2:3] would mean:
        #  (vertices[2], vertices[3])
        # in python, it would mean:
        #  (vertices[2],)
        if stop is not None and stop >= 0:
            stop += 1

        if stop is None or start < 0 or stop < 0 or step < 0:
            start, stop, step = slice(start, stop, step).indices(self._dimLength(partialIndex))

        # Made this return a normal list for easier debugging...
        # ... can always make it back to a generator if need it for speed
        for rawIndex in xrange(start, stop, step):
            yield ComponentIndex(partialIndex + (rawIndex,))
#        return [ComponentIndex(partialIndex + (rawIndex,))
#                for rawIndex in xrange(start, stop, step)]

    def _makeIndexedComponentHandle(self, indices):
        # We could always create our component using the selection list
        # method; but since this has to do string processing, it is slower...
        # so use MFnComponent.addElements method if possible.
        handle = Component._makeComponentHandle(self)
        if (self._componentMObjEmpty(handle.object())
                and not (len(indices) == 1 and self._isCompleteIndex(indices[0]))):
            mayaArrays = []
            for dimIndices in zip(*indices):
                mayaArrays.append(self._pyArrayToMayaArray(dimIndices))
            mfnComp = self._mfncompclass(handle.object())
            mfnComp.setComplete(False)
            if mayaArrays:
                mfnComp.addElements(*mayaArrays)
            return handle
        else:
            return super(DiscreteComponent, self)._makeIndexedComponentHandle(indices)

    @classmethod
    def _pyArrayToMayaArray(cls, pythonArray):
        mayaArray = _api.MIntArray()
        _api.MScriptUtil.createIntArrayFromList( list(pythonArray), mayaArray)
        return mayaArray

    def _dimRange(self, partialIndex):
        dimLen = self._dimLength(partialIndex)
        return (-dimLen, dimLen - 1)

    def _translateNegativeIndice(self, negIndex, partialIndex):
        assert negIndex < 0
        return self._dimLength(partialIndex) + negIndex

    def __iter__(self):
        # We proceed in two ways, depending on whether we're a
        # completely-specified component (ie, no longer indexable),
        # or partially-specified (ie, still indexable).
        for compIndex in self._compIndexObjIter():
            yield self.__class__(self._node, compIndex)

    def _compIndexObjIter(self):
        """
        An iterator over all the indices contained by this component,
        as ComponentIndex objects (which are a subclass of tuple).
        """
        if self.currentDimension() is None:
            # we're completely specified, do flat iteration
            return self._flatIter()
        else:
            # we're incompletely specified, iterate across the dimensions!
            return self._dimensionIter()

    # Essentially identical to _compIndexObjIter, except that while
    # _compIndexObjIter, this is intended for use by end-user,
    # and so if it's more 'intuitive' to return some other object,
    # it will be overriden in derived classes to do so.
    # ie, for Component1D, this will return ints
    indicesIter = _compIndexObjIter

    def indices(self):
        """
        A list of all the indices contained by this component.
        """
        return list(self.indicesIter())

    def _dimensionIter(self):
        # If we're incompletely specified, then if, for instance, we're
        # iterating through all the vertices of a poly with 500,000 verts,
        # then it's a huge waste of time / space to create a list of
        # 500,000 indices in memory, then iterate through it, when we could
        # just as easily generate the indices as we go with an xrange
        # Since an MFnComponent is essentially a flat list of such indices
        # - only it's stored in maya's private memory space - we AVOID
        # calling __apicomponent__ in this case!

        # self._partialIndex may have slices...
        for index in self._flattenIndex(self._partialIndex):
            yield index

    def _flatIter(self):
        #If we're completely specified, we assume that we NEED
        # to have some sort of list of indicies just in order to know
        # what this component obejct holds (ie, we might have
        # [1][4], [3][80], [3][100], [4][10], etc)
        # ...so we assume that we're not losing any speed / memory
        # by iterating through a 'list of indices' stored in memory
        # in our case, this list of indices is the MFnComponent object
        # itself, and is stored in maya's memory, but the idea is the same...

        # This code duplicates much of currentItem - keeping both
        # for speed, as _flatIter may potentially have to plow through a lot of
        # components, so we don't want to make an extra function call...

        dimensionIndicePtrs = []
        mfncomp = self.__apicomponent__()
        for _ in xrange(self.dimensions):
            dimensionIndicePtrs.append(_api.SafeApiPtr('int'))

        for flatIndex in xrange(len(self)):
            mfncomp.getElement(flatIndex, *[x() for x in dimensionIndicePtrs])
            yield ComponentIndex( [x.get() for x in dimensionIndicePtrs] )

    def __len__(self):
        return self.__apicomponent__().elementCount()

    def count(self):
        return len(self)

    # default implementation assumes that each dimension has a consistent
    # number of components - so total number of components is
    #   sizeDim1 * sizeDim2 * ... * sizeDimN
    # if this is not the case (ie, for faceVertex, or subds), need to override
    # this - either with a "correct" method, or an implementation that raises
    # NotImplementedError
    def totalSize(self):
        '''The maximum possible number of components

        ie, for a polygon cube, the totalSize for verts would be 8, for edges
        would be 12, and for faces would be 6
        '''
        if not self.dimensions:
            return 0
        totalSize = 1
        partialIndex = ComponentIndex()
        for _ in xrange(self.dimensions):
            totalSize *= self._dimLength(partialIndex)
            partialIndex += (0,)
        return totalSize

    def setIndex(self, index):
        if not 0 <= index < len(self):
            raise IndexError
        self._currentFlatIndex = index
        return self

    def getIndex(self):
        '''Returns the current 'flat list' index for this group of components -
        ie, if this component holds the vertices:
            [5, 7, 12, 13, 14, 25]
        then if the 'flat list' index is 2, then we are pointing to vertex 12.
        '''
        return self._currentFlatIndex

    def currentItem(self):
        # This code duplicates much of _flatIter - keeping both
        # for speed, as _flatIter may potentially have to plow through a lot of
        # components, so we don't want to make an extra function call...

        dimensionIndicePtrs = []
        mfncomp = self.__apicomponent__()
        for _ in xrange(self.dimensions):
            dimensionIndicePtrs.append(_api.SafeApiPtr('int'))

        mfncomp.getElement(self._currentFlatIndex, *[x() for x in dimensionIndicePtrs])
        curIndex = ComponentIndex( [x.get() for x in dimensionIndicePtrs] )
        return self.__class__(self._node, curIndex)

    def currentItemIndex(self):
        '''Returns the component indices for the current item in this component
        group

        If the component type has more then one dimension, the return result
        will be a ComponentIndex object which is a sub-class of tuple; otherwise,
        it will be a single int.

        These values correspond to the indices that you would use when selecting
        components in mel - ie, vtx[5], cv[3][2]
        '''
        # Again, duplicates some code in currentItem/_flatIter for speed
        dimensionIndicePtrs = []
        mfncomp = self.__apicomponent__()
        for _ in xrange(self.dimensions):
            dimensionIndicePtrs.append(_api.SafeApiPtr('int'))

        mfncomp.getElement(self._currentFlatIndex, *[x() for x in dimensionIndicePtrs])
        if self.dimensions == 1:
            return dimensionIndicePtrs[0].get()
        else:
            return ComponentIndex( [x.get() for x in dimensionIndicePtrs] )

    def next(self):
        if self._stopIteration:
            raise StopIteration
        elif not self:
            self._stopIteration = True
            raise StopIteration
        else:
            toReturn = self.currentItem()
            try:
                self.setIndex(self.getIndex() + 1)
            except IndexError:
                self._stopIteration = True
            return toReturn

    def reset(self):
        self._stopIteration = False
        self._currentFlatIndex = 0


class ContinuousComponent( DimensionedComponent ):
    """
    Components whose dimensions are continuous.

    Ie, there are an infinite number of possible components, referenced by
    floating point parameters.

    Example: nurbsCurve.u[7.48], nurbsSurface.uv[3.85][2.1]

    Derived classes should implement:
    _dimRange
    """
    VALID_SINGLE_INDEX_TYPES = (int, long, float, slice, HashableSlice)

    def _standardizeIndices(self, indexObjs, **kwargs):
        return super(ContinuousComponent, self)._standardizeIndices(indexObjs,
                                                           allowIterable=False,
                                                           **kwargs)

    def _sliceToIndices(self, sliceObj, partialIndex=None):
        # Note that as opposed to a DiscreteComponent, where we
        # always want to flatten a slice into it's discrete elements,
        # with a ContinuousComponent a slice is a perfectly valid
        # indices... the only caveat is we need to convert it to a
        # HashableSlice, as we will be sticking it into a set...
        if sliceObj.step != None:
            raise MayaComponentError("%ss may not use slice-indices with a 'step' -  bad slice: %s" %
                                 (self.__class__.__name__, sliceObj))
        if partialIndex is None:
            partialIndex = ComponentIndex()
        if sliceObj.start == sliceObj.stop == None:
            return (partialIndex + (HashableSlice(None), ), )
        else:
            return (partialIndex +
                    (HashableSlice(sliceObj.start, sliceObj.stop),), )

    def __iter__(self):
        raise TypeError("%r object is not iterable" % self.__class__.__name__)

    def _dimLength(self, partialIndex):
        # Note that in the default implementation, used
        # by DiscreteComponent, _dimRange depends on _dimLength.
        # In ContinuousComponent, the opposite is True - _dimLength
        # depends on _dimRange
        range = self._dimRange(partialIndex)
        return range[1] - range[0]

    def _dimRange(self, partialIndex):
        # Note that in the default implementation, used
        # by DiscreteComponent, _dimRange depends on _dimLength.
        # In ContinuousComponent, the opposite is True - _dimLength
        # depends on _dimRange
        raise NotImplementedError

    def _translateNegativeIndice(self, negIndex, partialIndex):
        return negIndex

class Component1DFloat( ContinuousComponent ):
    dimensions = 1

    def index(self):
        return self.indices()[0]

class Component2DFloat( ContinuousComponent ):
    dimensions = 2

class Component1D( DiscreteComponent ):
    _mfncompclass = _api.MFnSingleIndexedComponent
    _apienum__ = _api.MFn.kSingleIndexedComponent
    dimensions = 1

    def index(self):
        return self.indices()[0]

    @staticmethod
    def _sequenceToComponentSlice( array ):
        """given an array, convert to a maya-formatted slice"""

        return [ HashableSlice( x.start, x.stop-1, x.step) for x in _util.sequenceToSlices( array ) ]


    def name(self):
        # this function produces a name that uses extended slice notation, such as vtx[10:40:2]
        melobj = self.__melobject__()
        if isinstance(melobj, basestring):
            return melobj
        else:
            compSlice = self._sequenceToComponentSlice( self.indicesIter() )
            sliceStr = ','.join( [ _formatSlice(x) for x in compSlice ] )
            return self._completeNameString().replace( '*', sliceStr )

    def _flatIter(self):
        # for some reason, the command to get an element is 'element' for
        # 1D components, and 'getElement' for 2D/3D... so parent class's
        # _flatIter won't work!
        # Just as well, we get a more efficient iterator for 1D comps...
        mfncomp = self.__apicomponent__()
        for flatIndex in xrange(len(self)):
            yield ComponentIndex( (mfncomp.element(flatIndex),) )

    def currentItem(self):
        mfncomp = self.__apicomponent__()
        return self.__class__(self._node, mfncomp.element(self._currentFlatIndex))

    def currentItemIndex(self):
        '''Returns the component indices for the current item in this component
        group

        If the component type has more then one dimension, the return result
        will be a ComponentIndex object which is a sub-class of tuple; otherwise,
        it will be a single int.

        These values correspond to the indices that you would use when selecting
        components in mel - ie, vtx[5], cv[3][2]
        '''
        # Again, duplicates some code in currentItem/_flatIter for speed
        mfncomp = self.__apicomponent__()
        return mfncomp.element(self._currentFlatIndex)

    def indicesIter(self):
        """
        An iterator over all the indices contained by this component,
        as integers.
        """
        for compIndex in self._compIndexObjIter():
            yield compIndex[0]

class Component2D( DiscreteComponent ):
    _mfncompclass = _api.MFnDoubleIndexedComponent
    _apienum__ = _api.MFn.kDoubleIndexedComponent
    dimensions = 2

class Component3D( DiscreteComponent ):
    _mfncompclass = _api.MFnTripleIndexedComponent
    _apienum__ = _api.MFn.kTripleIndexedComponent
    dimensions = 3

# Mixin class for components which use MIt* objects for some functionality
class MItComponent( Component ):
    """
    Abstract base class for pymel components that can be accessed via iterators.

    (ie, `MeshEdge`, `MeshVertex`, and `MeshFace` can be wrapped around
    MItMeshEdge, etc)

    If deriving from this class, you should set __apicls__ to an appropriate
    MIt* type - ie, for MeshEdge, you would set __apicls__ = _api.MItMeshEdge
    """
#
    def __init__(self, *args, **kwargs ):
        super(MItComponent, self).__init__(*args, **kwargs)

    def __apimit__(self, alwaysUnindexed=False):
        # Note - the iterator should NOT be stored, as if it gets out of date,
        # it can cause crashes - see, for instance, MItMeshEdge.geomChanged
        # Since we don't know how the user might end up using the components
        # we feed out, and it seems like asking for trouble to have them
        # keep track of when things such as geomChanged need to be called,
        # we simply never retain the MIt for long..
        if self._currentFlatIndex == 0 or alwaysUnindexed:
            return self.__apicls__( self.__apimdagpath__(), self.__apimobject__() )
        else:
            return self.__apicls__( self.__apimdagpath__(), self.currentItem().__apimobject__() )

    def __apimfn__(self):
        return self.__apimit__()

class MItComponent1D( MItComponent, Component1D ): pass

class Component1D64( DiscreteComponent ):
    _ALLOW_COMPLETE_SHORTCUT = False

    if Component._hasUint64:
        _mfncompclass = _api.MFnUint64SingleIndexedComponent
        _apienum__ = _api.MFn.kUint64SingleIndexedComponent

    else:
        _mfncompclass = _api.MFnComponent
        _apienum__ = _api.MFn.kComponent

    def totalSize(self):
        raise NotImplementedError

    if Component._hasUint64 and hasattr(_api, 'MUint64'):
        # Note that currently the python api has zero support for MUint64's
        # This code is just here because I'm an optimist...
        @classmethod
        def _pyArrayToMayaArray(cls, pythonArray):
            mayaArray = _api.MUint64Array(len(pythonArray))
            for i, value in enumerate(pythonArray):
                mayaArray.set(value, i)
            return mayaArray
    else:
        # Component indices aren't sequential, and without MUint64, the only
        # way to check if a given indice is valid is by trying to insert it
        # into an MSelectionList... since this is both potentially fairly
        # slow, for now just going to 'open up the gates' as far as
        # validation is concerned...
        _max32 = 2**32
        def _dimLength(self, partialIndex):
            return self._max32

        # The ContinuousComponent version works fine for us - just
        # make sure we grab the original function object, not the method
        # object, since we don't inherit from ContinuousComponent
        _sliceToIndices = ContinuousComponent._sliceToIndices.im_func

        # We're basically having to fall back on strings here, so revert 'back'
        # to the string implementation of various methods...
        _makeIndexedComponentHandle = DimensionedComponent._makeIndexedComponentHandle

        def __len__(self):
            if hasattr(self, '_storedLen'):
                return self._storedLen
            else:
                # subd MIt*'s have no .count(), and there is no appropriate
                # MFn, so count it using strings...
                melStrings = self.__melobject__()
                if _util.isIterable(melStrings):
                    count = Component.numComponentsFromStrings(*melStrings)
                else:
                    count = Component.numComponentsFromStrings(melStrings)
                self._storedLen = count
                return count

        # The standard _flatIter relies on being able to use element/getElement
        # Since we can't use these, due to lack of MUint64, fall back on
        # string processing...
        _indicesRe = re.compile( r'\[((?:\d+(?::\d+)?)|\*)\]'*2 + '$' )
        def _flatIter(self):
            if not hasattr(self, '_fullIndices'):
                melobj = self.__melobject__()
                if isinstance(melobj, basestring):
                    melobj = [melobj]
                indices = [ self._indicesRe.search(x).groups() for x in melobj ]
                for i, indicePair in enumerate(indices):
                    processedPair = []
                    for dimIndice in indicePair:
                        if dimIndice == '*':
                            processedPair.append(HashableSlice(None))
                        elif ':' in dimIndice:
                            start, stop = dimIndice.split(':')
                            processedPair.append(HashableSlice(int(start),
                                                               int(stop)))
                        else:
                            processedPair.append(int(dimIndice))
                    indices[i] = ComponentIndex(processedPair)
                self._fullIndices = indices
            for fullIndex in self._fullIndices:
                for index in self._flattenIndex(fullIndex):
                    yield index

    # kUint64SingleIndexedComponent components have a bit of a dual-personality
    # - though internally represented as a single-indexed long-int, in almost
    # all of the "interface", they are displayed as double-indexed-ints:
    # ie, if you select a subd vertex, it might be displayed as
    #    mySubd.smp[256][4388]
    # Since the end user will mostly "see" the component as double-indexed,
    # the default pymel indexing will be double-indexed, so we set dimensions
    # to 2, and then hand correct cases where self.dimensions affects how
    # we're interacting with the kUint64SingleIndexedComponent
    dimensions = 2

#-----------------------------------------
# Specific Components...
#-----------------------------------------


class MeshVertex( MItComponent1D ):
    __apicls__ = _api.MItMeshVertex
    _ComponentLabel__ = "vtx"
    _apienum__ = _api.MFn.kMeshVertComponent

    def _dimLength(self, partialIndex):
        return self.node().numVertices()

    def setColor(self,color):
        for i in self.indices():
            self.node().setVertexColor( color, i )

    def connectedEdges(self):
        """
        :rtype: `MeshEdge` list
        """
        array = _api.MIntArray()
        self.__apimfn__().getConnectedEdges(array)
        return MeshEdge( self, self._sequenceToComponentSlice( [ array[i] for i in range( array.length() ) ] ) )

    def connectedFaces(self):
        """
        :rtype: `MeshFace` list
        """
        array = _api.MIntArray()
        self.__apimfn__().getConnectedFaces(array)
        return MeshFace( self, self._sequenceToComponentSlice( [ array[i] for i in range( array.length() ) ] ) )

    def connectedVertices(self):
        """
        :rtype: `MeshVertex` list
        """
        array = _api.MIntArray()
        self.__apimfn__().getConnectedVertices(array)
        return MeshVertex( self, self._sequenceToComponentSlice( [ array[i] for i in range( array.length() ) ] ) )

    def isConnectedTo(self, component):
        """
        pass a component of type `MeshVertex`, `MeshEdge`, `MeshFace`, with a single element

        :rtype: bool
        """
        if isinstance(component,MeshFace):
            return self.isConnectedToFace( component.currentItemIndex() )
        if isinstance(component,MeshEdge):
            return self.isConnectedToEdge( component.currentItemIndex() )
        if isinstance(component,MeshVertex):
            array = _api.MIntArray()
            self.__apimfn__().getConnectedVertices(array)
            return component.currentItemIndex() in [ array[i] for i in range( array.length() ) ]
        raise TypeError, 'type %s is not supported' % type(component)

    def getColor(self, *args, **kwargs):
        # Want all possible versions of this command, so easiest to just manually
        # wrap (particularly want to be able to invoke with no args!
        color = _api.MColor()
        self.__apimfn__().getColor(color, *args, **kwargs)
        return datatypes.Color(color)

class MeshEdge( MItComponent1D ):
    __apicls__ = _api.MItMeshEdge
    _ComponentLabel__ = "e"
    _apienum__ = _api.MFn.kMeshEdgeComponent

    def _dimLength(self, partialIndex):
        return self.node().numEdges()


    def connectedEdges(self):
        """
        :rtype: `MeshEdge` list
        """
        array = _api.MIntArray()
        self.__apimfn__().getConnectedEdges(array)
        return MeshEdge( self, self._sequenceToComponentSlice( [ array[i] for i in range( array.length() ) ] ) )

    def connectedFaces(self):
        """
        :rtype: `MeshFace` list
        """
        array = _api.MIntArray()
        self.__apimfn__().getConnectedFaces(array)
        return MeshFace( self, self._sequenceToComponentSlice( [ array[i] for i in range( array.length() ) ] ) )

    def connectedVertices(self):
        """
        :rtype: `MeshVertex` list
        """

        index0 = self.__apimfn__().index(0)
        index1 = self.__apimfn__().index(1)
        return ( MeshVertex(self,index0), MeshVertex(self,index1) )

    def isConnectedTo(self, component):
        """
        :rtype: bool
        """
        if isinstance(component,MeshFace):
            return self.isConnectedToFace( component.currentItemIndex() )
        if isinstance(component,MeshEdge):
            return self.isConnectedToEdge( component.currentItemIndex() )
        if isinstance(component,MeshVertex):
            index0 = self.__apimfn__().index(0)
            index1 = self.__apimfn__().index(1)
            return component.currentItemIndex() in [index0, index1]

        raise TypeError, 'type %s is not supported' % type(component)

class MeshFace( MItComponent1D ):
    __apicls__ = _api.MItMeshPolygon
    _ComponentLabel__ = "f"
    _apienum__ = _api.MFn.kMeshPolygonComponent

    def _dimLength(self, partialIndex):
        return self.node().numFaces()

    def connectedEdges(self):
        """
        :rtype: `MeshEdge` list
        """
        array = _api.MIntArray()
        self.__apimfn__().getConnectedEdges(array)
        return MeshEdge( self, self._sequenceToComponentSlice( [ array[i] for i in range( array.length() ) ] ) )

    def connectedFaces(self):
        """
        :rtype: `MeshFace` list
        """
        array = _api.MIntArray()
        self.__apimfn__().getConnectedFaces(array)
        return MeshFace( self, self._sequenceToComponentSlice( [ array[i] for i in range( array.length() ) ] ) )

    def connectedVertices(self):
        """
        :rtype: `MeshVertex` list
        """
        array = _api.MIntArray()
        self.__apimfn__().getConnectedVertices(array)
        return MeshVertex( self, self._sequenceToComponentSlice( [ array[i] for i in range( array.length() ) ] ) )

    def isConnectedTo(self, component):
        """
        :rtype: bool
        """
        if isinstance(component,MeshFace):
            return self.isConnectedToFace( component.currentItemIndex() )
        if isinstance(component,MeshEdge):
            return self.isConnectedToEdge( component.currentItemIndex() )
        if isinstance(component,MeshVertex):
            return self.isConnectedToVertex( component.currentItemIndex() )

        raise TypeError, 'type %s is not supported' % type(component)
MeshFace.numVertices = MeshFace.polygonVertexCount

class MeshUV( Component1D ):
    _ComponentLabel__ = "map"
    _apienum__ = _api.MFn.kMeshMapComponent

    def _dimLength(self, partialIndex):
        return self._node.numUVs()

class MeshVertexFace( Component2D ):
    _ComponentLabel__ = "vtxFace"
    _apienum__ = _api.MFn.kMeshVtxFaceComponent

    # getting all the mel strings for MeshVertexFace is SLLOOOWW - so check if
    # it's complete, and if so, just return the .vtxFace[*] form
    def __melobject__(self):
        if self.isComplete():
            return self._completeNameString()
        else:
            return super(MeshVertexFace, self).__melobject__()

    def _dimLength(self, partialIndex):
        if len(partialIndex) == 0:
            return self._node.numVertices()
        elif len(partialIndex) == 1:
            return self._node.vtx[partialIndex[0]].numConnectedFaces()

    def totalSize(self):
        return self.node().numFaceVertices()

    def _sliceToIndices(self, sliceObj, partialIndex=None):
        if not partialIndex:
            # If we're just grabbing a slice of the first index,
            # the verts, we can proceed as normal...
            for x in super(MeshVertexFace, self)._sliceToIndices(sliceObj, partialIndex):
                yield x

        # If we're iterating over the FACES attached to a given vertex,
        # which may be a random set - say, (3,6,187) - not clear how to
        # interpret an index 'range'
        else:
            if (sliceObj.start not in (0, None) or
                sliceObj.stop is not None or
                sliceObj.step is not None):
                raise ValueError('%s objects may not be indexed with slices, execpt for [:]' %
                                 self.__class__.__name__)

            # get a MitMeshVertex ...
            mIt = _api.MItMeshVertex(self._node.__apimdagpath__())

            # Even though we're not using the result stored in the int,
            # STILL need to store a ref to the MScriptUtil - otherwise,
            # there's a chance it gets garbage collected before the
            # api function call is made, and it writes the value into
            # the pointer...
            intPtr = _api.SafeApiPtr('int')
            mIt.setIndex(partialIndex[0], intPtr())
            intArray = _api.MIntArray()
            mIt.getConnectedFaces(intArray)
            for i in xrange(intArray.length()):
                yield partialIndex + (intArray[i],)

    def _validateGetItemIndice(self, item, allowIterables=True):
        """
        Will raise an appropriate IndexError if the given item
        is not suitable as a __getitem__ indice.
        """
        if len(self._partialIndex) == 0:
            return super(MeshVertexFace, self)._validateGetItemIndice(item)
        if allowIterables and _util.isIterable(item):
            for _ in item:
                self._validateGetItemIndice(item, allowIterables=False)
            return
        if isinstance(item, (slice, HashableSlice)):
            if slice.start == slice.stop == slice.step == None:
                return
            raise IndexError("only completely open-ended slices are allowable"\
                             " for the second indice of %s objects" %
                             self.__class__.__name__)
        if not isinstance(item, self.VALID_SINGLE_INDEX_TYPES):
            raise IndexError("Invalid indice type for %s: %r" %
                             (self.__class__.__name__,
                              item.__class__.__name__) )

        for fullIndice in self._sliceToIndices(slice(None),
                                               partialIndex=self._partialIndex):
            if item == fullIndice[1]:
                return
        raise IndexError("vertex-face %s-%s does not exist" %
                         (self._partialIndex[0], item))

## Subd Components

class SubdVertex( Component1D64 ):
    _ComponentLabel__ = "smp"
    _apienum__ = _api.MFn.kSubdivCVComponent

class SubdEdge( Component1D64 ):
    _ComponentLabel__ = "sme"
    _apienum__ = _api.MFn.kSubdivEdgeComponent

    # There is a currently a bug with subd edges, where if you do:
    #        import maya.cmds as cmds
    #        cmds.file(new=1, f=1)
    #        polyCube = cmds.polyCube()[0]
    #        subd = cmds.polyToSubdiv(polyCube)[0]
    #        cmds.select(subd + '.sme[*][*]')
    # ...maya crashes. as a hack to to help avoid crashing, define the complete
    # component as just containing the first edge...

    # GET RID OF THIS ONCE THE CRASH BUG IS FIXED!!!
    def _completeNameString(self):
        return Component._completeNameString(self) + '[0][0]'

class SubdFace( Component1D64 ):
    _ComponentLabel__ = "smf"
    _apienum__ = _api.MFn.kSubdivFaceComponent

class SubdUV( Component1D ):
    # ...because you can't select subduv comps with '*' - ie, this doesn't work:
    #    cmds.select('subdivCube1Shape.smm[*]')
    _ALLOW_COMPLETE_SHORTCUT = False

    _ComponentLabel__ = "smm"
    _apienum__ = _api.MFn.kSubdivMapComponent

    # This implementation failed because
    # it appears that you can have a subd shape
    # with no uvSet elements
    # (shape.uvSet.evaluateNumElements() == 0)
    # but with valid .smm's
#    def _dimLength(self, partialIndex):
#        # My limited tests reveal that
#        # subds with multiple uv sets
#        # mostly just crash a lot
#        # However, when not crashing, it
#        # SEEMS that you can select
#        # a .smm[x] up to the size
#        # of the largest possible uv
#        # set, regardless of which uv
#        # set is current...
#        max = 0
#        for elemPlug in self._node.attr('uvSet'):
#            numElements = elemPlug.evaluateNumElements()
#            if numElements > max:
#                max = numElements
#        # For some reason, if there are 206 elements
#        # in the uvSet, the max indexable smm's go from
#        # .smm[0] to .smm[206] - ie, num elements + 1...?
#        return max + 1


    # ok - some weirdness in trying to find what the maximum
    # allowable smm index is...
    # To see what I mean, uncomment this and try it in maya:
#from pymel.core import *
#import sys
#import platform
#
#def testMaxIndex():
#
#
#    def interpreterBits():
#        """
#        Returns the number of bits of the architecture the interpreter was compiled on
#        (ie, 32 or 64).
#
#        :rtype: `int`
#        """
#        return int(re.match(r"([0-9]+)(bit)?", platform.architecture()[0]).group(1))
#
#    subdBase = polyCube()[0]
#    subdTrans = polyToSubdiv(subdBase)[0]
#    subd = subdTrans.getShape()
#    selList = _api.MSelectionList()
#    try:
#        selList.add("%s.smm[0:%d]" % (subd.name(), sys.maxint))
#    except:
#        print "sys.maxint (%d) failed..." % sys.maxint
#    else:
#        print "sys.maxint (%d) SUCCESS" % sys.maxint
#    try:
#        selList.add("%s.smm[0:%d]" % (subd.name(), 2 ** interpreterBits() - 1))
#    except:
#        print "2 ** %d - 1 (%d) failed..." % (interpreterBits(), 2 ** interpreterBits() - 1)
#    else:
#        print "2 ** %d - 1 (%d) SUCCESS" % (interpreterBits(), 2 ** interpreterBits() - 1)
#    try:
#        selList.add("%s.smm[0:%d]" % (subd.name(), 2 ** interpreterBits()))
#    except:
#        print "2 ** %d (%d) failed..." % (interpreterBits(), 2 ** interpreterBits())
#    else:
#        print "2 ** %d (%d) SUCCESS" % (interpreterBits(), 2 ** interpreterBits())
#    try:
#        selList.add("%s.smm[0:%d]" % (subd.name(), 2 ** 31 - 1))
#    except:
#        print "2 ** 31 - 1 (%d) failed..." % (2 ** 31 - 1)
#    else:
#        print "2 ** 31 - 1 (%d) SUCCESS" % (2 ** 31 - 1)
#    try:
#        selList.add("%s.smm[0:%d]" % (subd.name(), 2 ** 31))
#    except:
#        print "2 ** 31 (%d) failed..." % (2 ** 31)
#    else:
#        print "2 ** 31 (%d) SUCCESS" % (2 ** 31)
#    try:
#        selList.add("%s.smm[0:%d]" % (subd.name(), 2 ** 32 - 1))
#    except:
#        print "2 ** 32 - 1 (%d) failed..." % (2 ** 32 - 1)
#    else:
#        print "2 ** 32 - 1 (%d) SUCCESS" % (2 ** 32 - 1)
#    try:
#        selList.add("%s.smm[0:%d]" % (subd.name(), 2 ** 32))
#    except:
#        print "2 ** 32 (%d) failed..." % (2 ** 32)
#    else:
#        print "2 ** 32 (%d) SUCCESS" % (2 ** 32)
#

    # On Windows XP x64, Maya2009x64, 2**64 -1 works (didn't try others at the time)
    # ...but on Linux Maya2009x64, and OSX Maya2011x64, I get this weirdness:
#sys.maxint (9223372036854775807) failed...
#2 ** 64 - 1 (18446744073709551615) failed...
#2 ** 64 (18446744073709551616) failed...
#2 ** 31 - 1 (2147483647) SUCCESS
#2 ** 31 (2147483648) failed...
#2 ** 32 - 1 (4294967295) failed...
#2 ** 32 (4294967296) SUCCESS

    # So, given the inconsistencies here, just going to use
    # 2**31 -1... hopefully nobody needs more uv's than that
    _MAX_INDEX = 2 ** 31 - 1
    _tempSel = _api.MSelectionList()
    _maxIndexRe = re.compile(r'\[0:([0-9]+)\]$')
    def _dimLength(self, partialIndex):
        # Fall back on good ol' string processing...
        # unfortunately, .smm[*] is not allowed -
        # so we have to provide a 'maximum' value...
        self._tempSel.clear()
        self._tempSel.add(Component._completeNameString(self) +
                          '[0:%d]' % self._MAX_INDEX)
        selStrings = []
        self._tempSel.getSelectionStrings(0, selStrings)
        try:
            # remember the + 1 for the 0'th index
            return int(self._maxIndexRe.search(selStrings[0]).group(1)) + 1
        except AttributeError:
            raise RuntimeError("Couldn't determine max index for %s" %
                               Component._completeNameString(self))

    def totalSize(self):
        raise NotImplementedError

    # SubdUV's don't work with .smm[*] - so need to use
    # explicit range instead - ie, .smm[0:206]
    def _completeNameString(self):
        # Note - most multi-dimensional components allow selection of all
        # components with only a single index - ie,
        #    myNurbsSurface.cv[*]
        # will work, even though nurbs cvs are double-indexed
        # However, some multi-indexed components WON'T work like this, ie
        #    myNurbsSurface.sf[*]
        # FAILS, and you MUST do:
        #    myNurbsSurface.sf[*][*]
        return (super(DimensionedComponent, self)._completeNameString() +
                 ('[:%d]' % self._dimLength(None) ))

## Nurbs Curve Components

class NurbsCurveParameter( Component1DFloat ):
    _ComponentLabel__ = "u"
    _apienum__ = _api.MFn.kCurveParamComponent

    def _dimRange(self, partialIndex):
        return self._node.getKnotDomain()

class NurbsCurveCV( MItComponent1D ):
    __apicls__ = _api.MItCurveCV
    _ComponentLabel__ = "cv"
    _apienum__ = _api.MFn.kCurveCVComponent

    def _dimLength(self, partialIndex):
        return self.node().numCVs()

class NurbsCurveEP( Component1D ):
    _ComponentLabel__ = "ep"
    _apienum__ = _api.MFn.kCurveEPComponent

    def _dimLength(self, partialIndex):
        return self.node().numEPs()

class NurbsCurveKnot( Component1D ):
    _ComponentLabel__ = "knot"
    _apienum__ = _api.MFn.kCurveKnotComponent

    def _dimLength(self, partialIndex):
        return self.node().numKnots()

## NurbsSurface Components

class NurbsSurfaceIsoparm( Component2DFloat ):
    _ComponentLabel__ = ("u", "v", "uv")
    _apienum__ = _api.MFn.kIsoparmComponent

    def __init__(self, *args, **kwargs):
        super(NurbsSurfaceIsoparm, self).__init__(*args, **kwargs)
        # Fix the bug where running:
        #
        # import maya.cmds as cmds
        # cmds.sphere()
        # cmds.select('nurbsSphere1.uv[*][*]')
        # print cmds.ls(sl=1)
        # cmds.select('nurbsSphere1.u[*][*]')
        # print cmds.ls(sl=1)
        #
        # Gives two different results:
        # [u'nurbsSphere1.u[0:4][0:1]']
        # [u'nurbsSphere1.u[0:4][0:8]']

        # to fix this, change 'uv' comps to 'u' comps
        if hasattr(self, '_partialIndex'):
            self._partialIndex = self._convertUVtoU(self._partialIndex)
        if 'ComponentIndex' in self.__apiobjects__:
            self.__apiobjects__['ComponentIndex'] = self._convertUVtoU(self.__apiobjects__['ComponentIndex'])
        if hasattr(self, '_indices'):
            self._indices = self._convertUVtoU(self._indices)
        self._ComponentLabel__ = self._convertUVtoU(self._ComponentLabel__)

    @classmethod
    def _convertUVtoU(cls, index):
        if isinstance(index, dict):
            if 'uv' in index:
                # convert over index['uv']
                oldUvIndex = cls._convertUVtoU(index['uv'])
                if 'u' in index:
                    # First, make sure index['u'] is a list
                    if (isinstance(index['u'], ComponentIndex) or
                        not isinstance(index['u'], (list, tuple))):
                        index['u'] = [index['u']]
                    elif isinstance(index['u'], tuple):
                        index['u'] = list(index['u'])

                    # then add on 'uv' contents
                    if (isinstance(oldUvIndex, ComponentIndex) or
                        not isinstance(oldUvIndex, (list, tuple))):
                        index['u'].append(oldUvIndex)
                    else:
                        index['u'].extend(oldUvIndex)
                else:
                    index['u'] = oldUvIndex
                del index['uv']
        elif isinstance(index, ComponentIndex):
            # do this check INSIDE here, because, since a ComponentIndex is a tuple,
            # we don't want to change a ComponentIndex object with a 'v' index
            # into a list in the next elif clause!
            if index.label == 'uv':
                index.label = 'u'
        elif isinstance(index, (list, tuple)) and not isinstance(index, ComponentIndex):
            index = [cls._convertUVtoU(x) for x in index]
        elif isinstance(index, basestring):
            if index == 'uv':
                index = 'u'
        return index

    def _defaultLabel(self):
        return 'u'

    def _dimRange(self, partialIndex):
        minU, maxU, minV, maxV = self._node.getKnotDomain()
        if len(partialIndex) == 0:
            if partialIndex.label == 'v':
                param = 'v'
            else:
                param = 'u'
        else:
            if partialIndex.label == 'v':
                param = 'u'
            else:
                param = 'v'
        if param == 'u':
            return minU, maxU
        else:
            return minV, maxV

class NurbsSurfaceRange( NurbsSurfaceIsoparm ):
    _ComponentLabel__ = ("u", "v", "uv")
    _apienum__ = _api.MFn.kSurfaceRangeComponent

    def __getitem__(self, item):
        if self.currentDimension() is None:
            raise IndexError("Indexing only allowed on an incompletely "
                             "specified component")
        self._validateGetItemIndice(item)
        # You only get a NurbsSurfaceRange if BOTH indices are slices - if
        # either is a single value, you get an isoparm
        if (not isinstance(item, (slice, HashableSlice)) or
              (self.currentDimension() == 1 and
               not isinstance(self._partialIndex[0], (slice, HashableSlice)))):
            return NurbsSurfaceIsoparm(self._node, self._partialIndex + (item,))
        else:
            return super(NurbsSurfaceRange, self).__getitem__(item)

class NurbsSurfaceCV( Component2D ):
    _ComponentLabel__ = "cv"
    _apienum__ = _api.MFn.kSurfaceCVComponent

    def _dimLength(self, partialIndex):
        if len(partialIndex) == 0:
            return self.node().numCVsInU()
        elif len(partialIndex) == 1:
            return self.node().numCVsInV()
        else:
            raise ValueError('partialIndex %r too long for %s._dimLength' %
                             (partialIndex, self.__class__.__name__))

class NurbsSurfaceEP( Component2D ):
    _ComponentLabel__ = "ep"
    _apienum__ = _api.MFn.kSurfaceEPComponent

    def _dimLength(self, partialIndex):
        if len(partialIndex) == 0:
            return self.node().numEPsInU()
        elif len(partialIndex) == 1:
            return self.node().numEPsInV()
        else:
            raise ValueError('partialIndex %r too long for %s._dimLength' %
                             (partialIndex, self.__class__.__name__))

class NurbsSurfaceKnot( Component2D ):
    _ComponentLabel__ = "knot"
    _apienum__ = _api.MFn.kSurfaceKnotComponent

    def _dimLength(self, partialIndex):
        if len(partialIndex) == 0:
            return self.node().numKnotsInU()
        elif len(partialIndex) == 1:
            return self.node().numKnotsInV()
        else:
            raise ValueError('partialIndex %r too long for %s._dimLength' %
                             (partialIndex, self.__class__.__name__))

class NurbsSurfaceFace( Component2D ):
    _ComponentLabel__ = "sf"
    _apienum__ = _api.MFn.kSurfaceFaceComponent

    def _dimLength(self, partialIndex):
        if len(partialIndex) == 0:
            return self.node().numSpansInU()
        elif len(partialIndex) == 1:
            return self.node().numSpansInV()
        else:
            raise IndexError("partialIndex %r for %s must have length <= 1" %
                             (partialIndex, self.__class__.__name__))

## Lattice Components

class LatticePoint( Component3D ):
    _ComponentLabel__ = "pt"
    _apienum__ = _api.MFn.kLatticeComponent

    def _dimLength(self, partialIndex):
        if len(partialIndex) > 2:
            raise ValueError('partialIndex %r too long for %s._dimLength' %
                             (partialIndex, self.__class__.__name__))
        return self.node().getDivisions()[len(partialIndex)]

    def _completeNameString(self):
        # ...However, some multi-indexed components (well, only LatticePoint
        # that I know of) will give incorrect results with
        #    ffd1LatticeShape.pt[*][*][*]
        # ...and so you must do
        #    ffd1LatticeShape.pt[*]
        return Component._completeNameString(self) + '[*]'

## Pivot Components

class Pivot( Component ):
    _ComponentLabel__ = ("rotatePivot", "scalePivot")
    _apienum__ = _api.MFn.kPivotComponent


## Particle Components

class ParticleComponent( Component1D ):
    _ComponentLabel__ = "pt"
    _apienum__ = _api.MFn.kDynParticleSetComponent

    def attr(self, attr):
        try:
            return cmds.particle( self._node, q=1, attribute=attr, order=self._currentFlatIndex)
        except RuntimeError:
            raise MayaParticleAttributeError('%s.%s' % (self, attr))

    def __getattr__(self, attr):
        # MayaParticleAttributeError is a subclass of AttributeError, so if
        # it is raised, that should signal it was not found
        return self.attr(attr)

    def _dimLength(self, partialIndex):
        return self.node().pointCount()

#class ComponentArray(object):
#    def __init__(self, name):
#        self._name = name
#        self._iterIndex = 0
#        self._node = self.node()
#
#    def __str__(self):
#        return self._name
#
#    def __repr__(self):
#        return "ComponentArray(u'%s')" % self
#
#    #def __len__(self):
#    #    return 0
#
#    def __iter__(self):
##        """iterator for multi-attributes
##
##            >>> for attr in SCENE.persp.attrInfo(multi=1)[0]:
##            ...     print attr
##
##        """
#        return self
#
#    def next(self):
##        """iterator for multi-attributes
##
##            >>> for attr in SCENE.persp.attrInfo(multi=1)[0]:
##            ...    print attr
##
##        """
#        if self._iterIndex >= len(self):
#            raise StopIteration
#        else:
#            new = self[ self._iterIndex ]
#            self._iterIndex += 1
#            return new
#
#    def __getitem__(self, item):
#
#        def formatSlice(item):
#            step = item.step
#            if step is not None:
#                return '%s:%s:%s' % ( item.start, item.stop, step)
#            else:
#                return '%s:%s' % ( item.start, item.stop )
#
#
##        if isinstance( item, tuple ):
##            return [ Component(u'%s[%s]' % (self, formatSlice(x)) ) for x in  item ]
##
##        elif isinstance( item, slice ):
##            return Component(u'%s[%s]' % (self, formatSlice(item) ) )
##
##        else:
##            return Component(u'%s[%s]' % (self, item) )
#
#        if isinstance( item, tuple ):
#            return [ self.returnClass( self._node, formatSlice(x) ) for x in  item ]
#
#        elif isinstance( item, (slice, HashableSlice) ):
#            return self.returnClass( self._node, formatSlice(item) )
#
#        else:
#            return self.returnClass( self._node, item )
#
#
#    def plugNode(self):
#        'plugNode'
#        return PyNode( str(self).split('.')[0])
#
#    def plugAttr(self):
#        """plugAttr"""
#        return '.'.join(str(self).split('.')[1:])
#
#    node = plugNode
#
#class _Component(object):
#    """
#    Abstract base class for component types like vertices, edges, and faces.
#
#    This class is deprecated.
#    """
#    def __init__(self, node, item):
#        self._item = item
#        self._node = node
#
#    def __repr__(self):
#        return "%s('%s')" % (self.__class__.__name__, self)
#
#    def node(self):
#        'plugNode'
#        return self._node
#
#    def item(self):
#        return self._item
#
#    def move( self, *args, **kwargs ):
#        return move( self, *args, **kwargs )
#    def scale( self, *args, **kwargs ):
#        return scale( self, *args, **kwargs )
#    def rotate( self, *args, **kwargs ):
#        return rotate( self, *args, **kwargs )

class AttributeDefaults(PyNode):
    __metaclass__ = _factories.MetaMayaTypeWrapper
    __apicls__ = _api.MFnAttribute

    def __apiobject__(self) :
        "Return the default API object for this attribute, if it is valid"
        return self.__apimobject__()

    def __apimobject__(self):
        "Return the MObject for this attribute, if it is valid"
        try:
            handle = self.__apiobjects__['MObjectHandle']
        except:
            handle = self.__apiobjects__['MPlug'].attribute()
            self.__apiobjects__['MObjectHandle'] = handle
        if _api.isValidMObjectHandle( handle ):
            return handle.object()

        raise MayaAttributeError

    def __apimplug__(self) :
        "Return the MPlug for this attribute, if it is valid"
        # check validity
        #self.__apimobject__()
        return self.__apiobjects__['MPlug']

    def __apimdagpath__(self) :
        "Return the MDagPath for the node of this attribute, if it is valid"
        try:
            return self.node().__apimdagpath__()
        except AttributeError: pass

    def name(self):
        return self.__apimfn__().name()


#-----------------------------------------------
#  Global Settings
#-----------------------------------------------


#-----------------------------------------------
#  Scene Class
#-----------------------------------------------

class Scene(object):
    """
    The Scene class provides an attribute-based method for retrieving `PyNode` instances of
    nodes in the current scene.

        >>> SCENE = Scene()
        >>> SCENE.persp
        nt.Transform(u'persp')
        >>> SCENE.persp.t
        Attribute(u'persp.translate')

    An instance of this class is provided for you with the name `SCENE`.
    """
    __metaclass__ = _util.Singleton
    def __getattr__(self, obj):
        if obj.startswith('__') and obj.endswith('__'):
            try:
                return self.__dict__[obj]
            except KeyError:
                raise AttributeError, "type object %r has no attribute %r" % (self.__class__.__name__, obj)

        return PyNode( obj )

SCENE = Scene()






_factories.createFunctions( __name__, PyNode )

########NEW FILE########
__FILENAME__ = language
"""
Functions and classes related to scripting, including `MelGlobals` and `Mel`
"""
import sys, os, inspect
from getpass import getuser as _getuser
import system
import collections

import maya.mel as _mm
import maya.cmds as _mc

import pymel.util as util
import pymel.internal.pmcmds as cmds
import pymel.internal.factories as _factories
import pymel.internal.cmdcache as _cmdcache
import pymel.api as _api
import datatypes


#--------------------------
# Mel <---> Python Glue
#--------------------------

MELTYPES = ['string', 'string[]', 'int', 'int[]', 'float', 'float[]', 'vector', 'vector[]']

def isValidMelType( typStr ):
    """:rtype: bool"""
    return typStr in MELTYPES

def _flatten(iterables):
    for it in iterables:
        if util.isIterable(it):
            for element in it:
                yield element
        else:
            yield it

def pythonToMel(arg):
    """
    convert a python object to a string representing an equivalent value in mel

    iterables are flattened.

    mapping types like dictionaries have their key value pairs flattened:
        { key1 : val1, key2 : val2 }  -- >  ( key1, val1, key2, val2 )

    """
    if arg is None:
        return ''
    if arg is True or arg is False:
        return str(arg).lower()
    if util.isNumeric(arg):
        return str(arg)
    if isinstance(arg, datatypes.Vector):
        return '<<%f,%f,%f>>' % ( arg[0], arg[1], arg[2] )
    if util.isIterable(arg):
        if util.isMapping(arg):
            arg = list(_flatten(arg.iteritems()))
        else:
            arg = list(_flatten(arg))
        forceString = False
        for each in arg:
            if not util.isNumeric(each):
                forceString = True
                break

        if forceString:
            newargs = [ '"%s"' % x for x in arg ]
        else:
            newargs = [ str(x) for x in arg ]

        return '{%s}' % ','.join( newargs )

    # in order for PyNodes to get wrapped in quotes we have to treat special cases first,
    # we cannot simply test if arg is an instance of basestring because PyNodes are not
    return '"%s"' % cmds.encodeString(str(arg))

def pythonToMelCmd(*commandAndArgs, **kwargs):
    '''Given a mel command name, and a set of python args / kwargs, return
    a mel string used to call the given command.

    Note that the first member of commandAndArgs is the command name, and is
    required; the remainder are the args to it.  We use this odd signature to
    avoid any name conflicts with mel flag names - ie, the signature used to be:
        pythonToMelCmd(command, *args, **kwargs)
    but this caused problems with the mel "button" function, which has a
    "command" flag.
    '''
    if not commandAndArgs:
        raise TypeError("pythonToMelCmd needs at least one arg, the"
                        " mel command name")
    command = commandAndArgs[0]
    args = commandAndArgs[1:]

    strArgs = [pythonToMel(arg) for arg in args]

    if kwargs:
        # keyword args trigger us to format as a command rather than a procedure
        strFlags = []
        if command in _factories.cmdlist:
            flags = _factories.cmdlist[command]['flags']
            shortFlags = _factories.cmdlist[command]['shortFlags']
        else:
#            # Make a dummy flags dict - basically, just assume that q / e
#            # are bool flags with no args...
#            flags = {'query':{'args': bool,
#                              'longname': 'query',
#                              'numArgs': 0,
#                              'shortname': 'q'},
#                     'edit': {'args': bool,
#                              'longname': 'edit',
#                              'numArgs': 0,
#                              'shortname': 'e'}}
#            shortFlags = {'q':'query', 'e':'edit'}
            # Changed my mind - decided it's safest for unknown commands to
            # make no assumptions.  If they want a flag that takes no args,
            # they can use arg=None...
            flags = {}
            shortFlags = {}
        for key, val in kwargs.iteritems():
            flagInfo = None
            if key in flags:
                flagInfo = flags[key]
            elif key in shortFlags:
                flagInfo = flags[shortFlags[key]]
            if (flagInfo and flagInfo.get('args') == bool
                         and flagInfo.get('numArgs') == 0):
                # we have a boolean argument that takes no args!
                # doing something like '-q 1' will raise an error, just
                # do '-q'
                strFlags.append('-%s' % key)
            elif (isinstance(val, (tuple, list))
                    and len(val) == flagInfo.get('numArgs')):
                strFlags.append('-%s %s' % ( key, ' '.join(pythonToMel(x) for x in val )))
            else:
                strFlags.append('-%s %s' % ( key, pythonToMel(val) ))
        cmdStr = '%s %s %s' % ( command, ' '.join( strFlags ), ' '.join( strArgs ) )
    else:
        # procedure
        cmdStr = '%s(%s)' % ( command, ','.join( strArgs ) )
    return cmdStr

def getMelType( pyObj, exactOnly=True, allowBool=False, allowMatrix=False ):
    """
    return the name of the closest MEL type equivalent for the given python object.
    MEL has no true boolean or matrix types, but it often reserves special treatment for them in other ways.
    To control the handling of these types, use `allowBool` and `allowMatrix`.
    For python iterables, the first element in the array is used to determine the type. for empty lists, 'string[]' is
    returned.

        >>> from pymel.all import *
        >>> getMelType( 1 )
        'int'
        >>> p = SCENE.persp
        >>> getMelType( p.translate.get() )
        'vector'
        >>> getMelType( datatypes.Matrix )
        'int[]'
        >>> getMelType( datatypes.Matrix, allowMatrix=True )
        'matrix'
        >>> getMelType( True )
        'int'
        >>> getMelType( True, allowBool=True)
        'bool'
        >>> # make a dummy class
        >>> class MyClass(object): pass
        >>> getMelType( MyClass ) # returns None
        >>> getMelType( MyClass, exactOnly=False )
        'MyClass'

    :Parameters:
        pyObj
            can be either a class or an instance.
        exactOnly : bool
            If True and no suitable MEL analog can be found, the function will return None.
            If False, types which do not have an exact mel analog will return the python type name as a string
        allowBool : bool
            if True and a bool type is passed, 'bool' will be returned. otherwise 'int'.
        allowMatrix : bool
            if True and a `Matrix` type is passed, 'matrix' will be returned. otherwise 'int[]'.

    :rtype: `str`


    """

    if inspect.isclass(pyObj):

        if issubclass( pyObj, basestring ) : return 'string'
        elif allowBool and issubclass( pyObj, bool ) : return 'bool'
        elif issubclass( pyObj, int ) : return 'int'
        elif issubclass( pyObj, float ) : return 'float'
        elif issubclass( pyObj, datatypes.VectorN ) : return 'vector'
        elif issubclass( pyObj, datatypes.MatrixN ) :
            if allowMatrix:
                return 'matrix'
            else:
                return 'int[]'

        elif not exactOnly:
            return pyObj.__name__

    else:
        if isinstance( pyObj, datatypes.VectorN ) : return 'vector'
        elif isinstance( pyObj, datatypes.MatrixN ) :
            if allowMatrix:
                return 'matrix'
            else:
                return 'int[]'
        elif util.isIterable( pyObj ):
            try:
                return getMelType( pyObj[0], exactOnly=True ) + '[]'
            except IndexError:
                # TODO : raise warning
                return 'string[]'
            except:
                return
        if isinstance( pyObj, basestring ) : return 'string'
        elif allowBool and isinstance( pyObj, bool ) : return 'bool'
        elif isinstance( pyObj, int ) : return 'int'
        elif isinstance( pyObj, float ) : return 'float'


        elif not exactOnly:
            return type(pyObj).__name__


# TODO : convert array variables to a semi-read-only list ( no append or extend, += is ok ):
# using append or extend will not update the mel variable
class MelGlobals( dict ):
    """ A dictionary-like class for getting and setting global variables between mel and python.
    an instance of the class is created by default in the pymel namespace as melGlobals.

    to retrieve existing global variables, just use the name as a key

    >>> melGlobals['gResourceFileList'] #doctest: +ELLIPSIS
    [u'defaultRunTimeCommands.res.mel', u'localizedPanelLabel.res.mel', ...]
    >>> # works with or without $
    >>> melGlobals['gFilterUIDefaultAttributeFilterList']  #doctest: +ELLIPSIS
    [u'DefaultHiddenAttributesFilter', u'animCurveFilter', ..., u'publishedFilter']

    creating new variables requires the use of the initVar function to specify the type

    >>> melGlobals.initVar( 'string', 'gMyStrVar' )
    '$gMyStrVar'
    >>> melGlobals['gMyStrVar'] = 'fooey'

    The variable will now be accessible within MEL as a global string.
    """
    #__metaclass__ = util.Singleton
    melTypeToPythonType = {
        'string'    : str,
        'int'       : int,
        'float'     : float,
        'vector'    : datatypes.Vector
        }

#    class MelGlobalArray1( tuple ):
#        def __new__(cls, type, variable, *args, **kwargs ):
#
#            self = tuple.__new__( cls, *args, **kwargs )
#
#            decl_name = variable
#            if type.endswith('[]'):
#                type = type[:-2]
#                decl_name += '[]'
#
#            self._setItemCmd = "global %s %s; %s" % ( type, decl_name, variable )
#            self._setItemCmd += '[%s]=%s;'
#            return self
#
#        def setItem(self, index, value ):
#            _mm.eval(self._setItemCmd % (index, value) )

    class MelGlobalArray( util.defaultlist ):
        #__metaclass__ = util.metaStatic
        def __init__(self, type, variable, *args, **kwargs ):

            if type.endswith('[]'):
                type = type[:-2]

            pyType = MelGlobals.melTypeToPythonType[ type ]
            util.defaultlist.__init__( self, pyType, *args, **kwargs )

            declaration = MelGlobals._get_decl_statement(type, variable)
            self._setItemCmd = "%s; %s" % ( declaration, variable )
            self._setItemCmd += '[%s]=%s;'


        def __setitem__(self, index, value ):
            _mm.eval(self._setItemCmd % (index, pythonToMel(value) ))
            super(MelGlobalArray, self).__setitem__(index, value)
        setItem = __setitem__

        # prevent these from
        def append(self, val): raise AttributeError
        def extend(self, val): raise AttributeError



    typeMap = {}
    VALID_TYPES = MELTYPES


    def __getitem__(self, variable ):
        return self.__class__.get( variable )

    def __setitem__(self, variable, value):
        return self.__class__.set( variable, value )

    @classmethod
    def _formatVariable(cls, variable):
        # TODO : add validity check
        if not variable.startswith( '$'):
            variable = '$' + variable
        if variable.endswith('[]'):
            variable = variable[:-2]
        return variable

    @classmethod
    def getType(cls, variable):
        variable = cls._formatVariable(variable)
        info = mel.whatIs( variable ).split()
        if len(info)==2 and info[1] == 'variable':
            MelGlobals.typeMap[variable] = info[0]
            return info[0]
        raise TypeError, "Cannot determine type for this variable. Use melGlobals.initVar first."

    @classmethod
    def _get_decl_statement(cls, type, variable):
        decl_name = cls._formatVariable(variable)
        if type.endswith('[]'):
            type = type[:-2]
            decl_name += '[]'
        return "global %s %s" % (type, decl_name)

    @classmethod
    def initVar( cls, type, variable ):
        if type not in MELTYPES:
            raise TypeError, "type must be a valid mel type: %s" % ', '.join( [ "'%s'" % x for x in MELTYPES ] )
        variable = cls._formatVariable(variable)
        _mm.eval( cls._get_decl_statement(type, variable)  )
        MelGlobals.typeMap[variable] = type
        return variable

    @classmethod
    def get( cls, variable, type=None  ):
        """get a MEL global variable.  If the type is not specified, the mel ``whatIs`` command will be used
        to determine it."""

        variable = cls._formatVariable(variable)
        if type is None:
            try:
                type = MelGlobals.typeMap[variable]
            except KeyError:
                try:
                    type = cls.getType(variable)
                except TypeError:
                    raise KeyError, variable

        variable = cls.initVar(type, variable)

        if type.endswith('[]'):
            array=True
            proc_name = 'pymel_get_global_' + type.replace('[]', 'Array')
        else:
            array=False
            proc_name = 'pymel_get_global_' + type
        declaration = cls._get_decl_statement(type, variable)
        cmd = "global proc %s %s() { %s; return %s; } %s();" % (type, proc_name, declaration, variable, proc_name )
        #print cmd
        res = _mm.eval( cmd  )
        if array:
            return MelGlobals.MelGlobalArray(type, variable, res)
        else:
            return MelGlobals.melTypeToPythonType[type](res)

    @classmethod
    def set( cls, variable, value, type=None ):
        """set a mel global variable"""
        variable = cls._formatVariable(variable)
        if type is None:
            try:
                type = MelGlobals.typeMap[variable]
            except KeyError:
                type = cls.getType(variable)

        variable = cls.initVar(type, variable)
        declaration = cls._get_decl_statement(type, variable)
        cmd = "%s; %s=%s;" % ( declaration, variable, pythonToMel(value) )

        #print cmd
        _mm.eval( cmd  )

    @classmethod
    def keys(cls):
        """list all global variables"""
        return mel.env()

melGlobals = MelGlobals()

# for backward compatibility
def getMelGlobal(type, variable) :
    return melGlobals.get(variable, type)
def setMelGlobal(type, variable, value) :
    return melGlobals.set(variable, value, type)


class Catch(object):
    """Reproduces the behavior of the mel command of the same name. if writing pymel scripts from scratch, you should
        use the try/except structure. This command is provided for python scripts generated by py2mel.  stores the
        result of the function in catch.result.

        >>> if not catch( lambda: myFunc( "somearg" ) ):
        ...    result = catch.result
        ...    print "succeeded:", result

        """
    #__metaclass__ = util.Singleton
    result = None
    success = None
    def __call__(self, func, *args, **kwargs ):
        try:
            Catch.result = func(*args, **kwargs)
            Catch.success = True
            return 0
        except:
            Catch.success = False
            return 1

    def reset(self):
        Catch.result = None
        Catch.success = None

catch = Catch()


class OptionVarList(tuple):

    def __new__(cls, val, key):
        self = tuple.__new__(cls, val)
        return self

    def __init__(self, val, key):
        # tuple's init is object.__init__, which takes no args...
        #tuple.__init__(self, val)
        self.key = key

    def __setitem__(self, key, val):
        raise TypeError, '%s object does not support item assignment - try casting to a list, and assigning the whole list to the optionVar' % self.__class__.__name__


    def appendVar( self, val ):
        """values appended to the OptionVarList with this method will be added to the Maya optionVar at the key denoted by self.key.
        """

        if isinstance( val, basestring):
            return cmds.optionVar( stringValueAppend=[self.key,val] )
        if isinstance( val, int):
            return cmds.optionVar( intValueAppend=[self.key,val] )
        if isinstance( val, float):
            return cmds.optionVar( floatValueAppend=[self.key,val] )
        raise TypeError, 'unsupported datatype: strings, ints, floats and their subclasses are supported'

    append = appendVar

class OptionVarDict(collections.MutableMapping):
    """
    A dictionary-like class for accessing and modifying optionVars.

        >>> from pymel.all import *
        >>> optionVar['test'] = 'dooder'
        >>> optionVar['test']
        u'dooder'

        >>> if 'numbers' not in env.optionVars:
        ...     optionVar['numbers'] = [1,24,7]
        >>> optionVar['numbers'].appendVar( 9 )
        >>> numArray = optionVar.pop('numbers')
        >>> print numArray
        [1, 24, 7, 9]
        >>> optionVar.has_key('numbers') # previous pop removed the key
        False
    """
    def __call__(self, *args, **kwargs):
        return cmds.optionVar(*args, **kwargs)

    # use more efficient method provided by cmds.optionVar
    # (or at least, I hope it's more efficient...)
    def __contains__(self, key):
        return bool( cmds.optionVar( exists=key ) )

    # not provided by MutableMapping
    def has_key(self, key):
        return self.__contains__(key)

    def __getitem__(self,key):
        if key not in self:
            raise KeyError, key
        val = cmds.optionVar( q=key )
        if isinstance(val, list):
            val = OptionVarList( val, key )
        return val

    def __setitem__(self,key,val):
        if isinstance( val, basestring):
            return cmds.optionVar( stringValue=[key,val] )
        if isinstance( val, (int, bool)):
            return cmds.optionVar( intValue=[key,int(val)] )
        if isinstance( val, float):
            return cmds.optionVar( floatValue=[key,val] )
        if isinstance( val, (list,tuple) ):
            if len(val) == 0:
                return cmds.optionVar( clearArray=key )
            listType = type(val[0])
            if issubclass( listType , basestring):
                flag = 'stringValue'
            elif issubclass( listType , int):
                flag = 'intValue'
            elif issubclass( listType , float):
                flag  = 'floatValue'
            else:
                raise TypeError, ('%r is unsupported; Only strings, ints, float, lists, and their subclasses are supported' % listType)

            cmds.optionVar(**{flag:[key,val[0]]}) # force to this datatype
            flag += "Append"
            for elem in val[1:]:
                if not isinstance( elem, listType):
                    raise TypeError, 'all elements in list must be of the same datatype'
                cmds.optionVar( **{flag:[key,elem]} )

    def keys(self):
        return cmds.optionVar( list=True )

    def pop(self, key):
        val = cmds.optionVar( q=key )
        cmds.optionVar( remove=key )
        return val

    def __delitem__(self,key):
        self.pop(key)

    def iterkeys(self):
        for key in self.keys():
            yield key
    __iter__ = iterkeys

    def __len__(self):
        return len(self.keys())

optionVar = OptionVarDict()

class Env(object):
    """ A Singleton class to represent Maya current optionVars and settings """
    #__metaclass__ = util.Singleton

    optionVars = OptionVarDict()
    #grid = Grid()
    #playbackOptions = PlaybackOptions()

    # TODO : create a wrapper for os.environ which allows direct appending and popping of individual env entries (i.e. make ':' transparent)
    envVars = os.environ

    def setConstructionHistory( self, state ):
        cmds.constructionHistory( tgl=state )
    def getConstructionHistory(self):
        return cmds.constructionHistory( q=True, tgl=True )
    def sceneName(self):
        return system.Path(cmds.file( q=1, sn=1))

    def setUpAxis( self, axis, rotateView=False ):
        """This flag specifies the axis as the world up direction. The valid axis are either 'y' or 'z'."""
        cmds.upAxis( axis=axis, rotateView=rotateView )

    def getUpAxis(self):
        """This flag gets the axis set as the world up direction. The valid axis are either 'y' or 'z'."""
        return cmds.upAxis( q=True, axis=True )

    def user(self):
        return _getuser()
    def host(self):
        return _gethostname()

    def getTime( self ):
        return cmds.currentTime( q=1 )
    def setTime( self, val ):
        cmds.currentTime( val )
    time = property( getTime, setTime )

    def getMinTime( self ):
        return cmds.playbackOptions( q=1, minTime=1 )
    def setMinTime( self, val ):
        cmds.playbackOptions( minTime=val )
    minTime = property( getMinTime, setMinTime )

    def getMaxTime( self ):
        return cmds.playbackOptions( q=1, maxTime=1 )
    def setMaxTime( self, val ):
        cmds.playbackOptions( maxTime=val )
    maxTime = property( getMaxTime, setMaxTime )

    def getAnimStartTime( self ):
        return cmds.playbackOptions( q=1, animationStartTime=1 )
    def setAnimStartTime( self, val ):
        cmds.playbackOptions( animationStartTime=val )
    animStartTime = property(getAnimStartTime, setAnimStartTime)

    def getAnimEndTime( self ):
        return cmds.playbackOptions( q=1, animationEndTime=1 )
    def setAnimEndTime( self, val ):
        cmds.playbackOptions( animationEndTime=val )
    animEndTime = property(getAnimEndTime, setAnimEndTime)

    def getPlaybackTimes(self):
        return (self.animStartTime, self.minTime, self.maxTime,
                self.animEndTime)
    def setPlaybackTimes(self, playbackTimes):
        if len(playbackTimes) != 4:
            raise ValueError("must have 4 playback times")
        self.animStartTime = playbackTimes[0]
        self.minTime = playbackTimes[1]
        self.maxTime = playbackTimes[2]
        self.animEndTime = playbackTimes[3]
    playbackTimes = property(getPlaybackTimes, setPlaybackTimes)

env = Env()

#--------------------------
# Maya.mel Wrapper
#--------------------------

class MelError(RuntimeError):
    """Generic MEL error"""
    pass

class MelConversionError(MelError,TypeError):
    """MEL cannot process a conversion or cast between data types"""
    pass

class MelUnknownProcedureError(MelError,NameError):
    """The called MEL procedure does not exist or has not been sourced"""
    pass

class MelArgumentError(MelError,TypeError):
    """The arguments passed to the MEL script are incorrect"""
    pass

class MelSyntaxError(MelError,SyntaxError):
    """The MEL script has a syntactical error"""
    pass

class Mel(object):
    """This class is a convenience for calling mel scripts from python, but if you are like me, you'll quickly find that it
    is a necessity. It allows mel scripts to be called as if they were python functions: it automatically formats python
    arguments into a command string which is executed via maya.mel.eval.  An instance of this class is already created for you
    when importing pymel and is called `mel`.



    default:
        >>> import maya.mel as mel
        >>> # create the proc
        >>> mel.eval( 'global proc myScript( string $stringArg, float $floatArray[] ){}')
        >>> # run the script
        >>> mel.eval( 'myScript("firstArg", {1.0, 2.0, 3.0})')

    pymel:
        >>> from pymel.all import *
        >>> # create the proc
        >>> mel.eval( 'global proc myScript( string $stringArg, float $floatArray[] ){}')
        >>> # run the script
        >>> mel.myScript("firstArg", [1.0, 2.0, 3.0])

    The above is a very simplistic example. The advantages of pymel.mel over maya.mel.eval are more readily
    apparent when we want to pass a python object to our mel procedure:

    default:
        >>> import maya.cmds as cmds
        >>> node = "lambert1"
        >>> color = cmds.getAttr( node + ".color" )[0]
        >>> mel.eval('myScript("%s",{%f,%f,%f})' % (cmds.nodeType(node), color[0], color[1], color[2])   )

    pymel:
        >>> from pymel.all import *
        >>> node = PyNode("lambert1")
        >>> mel.myScript( node.type(), node.color.get() )

    In this you can see how `pymel.core.mel` allows you to pass any python object directly to your mel script as if
    it were a python function, with no need for formatting arguments.  The resulting code is much more readable.

    Another advantage of this class over maya.mel.eval is its handling of mel errors.  If a mel procedure fails to
    execute, you will get the specific mel error message in the python traceback, and, if they are enabled, line numbers!

    For example, in the example below we redeclare the myScript procedure with a line that will result in an error:

        >>> commandEcho(lineNumbers=1)  # turn line numbers on
        >>> mel.eval( '''
        ... global proc myScript( string $stringArg, float $floatArray[] ){
        ...     float $donuts = `ls -type camera`;}
        ... ''')
        >>> mel.myScript( 'foo', [] )
        Traceback (most recent call last):
            ...
        MelConversionError: Error during execution of MEL script: line 2: ,Cannot convert data of type string[] to type float.,
        Calling Procedure: myScript, in Mel procedure entered interactively.
          myScript("foo",{})

    Notice that the error raised is a `MelConversionError`.  There are several MEL exceptions that may be raised,
    depending on the type of error encountered: `MelError`, `MelConversionError`, `MelArgumentError`, `MelSyntaxError`, and `MelUnknownProcedureError`.

    Here's an example showing a `MelArgumentError`, which also demonstrates the additional traceback
    information that is provided for you, including the file of the calling script.

        >>> mel.startsWith('bar') # doctest: +ELLIPSIS
        Traceback (most recent call last):
          ...
        MelArgumentError: Error during execution of MEL script: Line 1.18: ,Wrong number of arguments on call to startsWith.,
        Calling Procedure: startsWith, in file "..."
          startsWith("bar")

    Lastly, an example of `MelUnknownProcedureError`

        >>> mel.poop()
        Traceback (most recent call last):
          ...
        MelUnknownProcedureError: Error during execution of MEL script: line 1: ,Cannot find procedure "poop".,

    .. note:: To remain backward compatible with maya.cmds, all MEL exceptions inherit from `MelError`, which in turn inherits from `RuntimeError`.


    """
    # proc is not an allowed name for a global procedure, so it's safe to use as an attribute
    proc = None
    def __getattr__(self, command):
        if command.startswith('__') and command.endswith('__'):
            try:
                return self.__dict__[command]
            except KeyError:
                raise AttributeError, "object has no attribute '%s'" % command

        def _call(*args, **kwargs):
            cmd = pythonToMelCmd(command, *args, **kwargs)

            try:
                self.__class__.proc = command
                return self.eval(cmd)
            finally:
                self.__class__.proc = None
        return _call


    @classmethod
    def mprint( cls, *args):
        """mel print command in case the python print command doesn't cut it. i have noticed that python print does not appear
        in certain output, such as the rush render-queue manager."""
        #print r"""print (%s\\n);""" % pythonToMel( ' '.join( map( str, args)))
        _mm.eval( r"""print (%s);""" % pythonToMel( ' '.join( map( str, args))) + '\n' )

    @classmethod
    def source( cls, script, language='mel' ):
        """use this to source mel or python scripts.
        language : 'mel', 'python'
            When set to 'python', the source command will look for the python equivalent of this mel file, if
            it exists, and attempt to import it. This is particularly useful when transitioning from mel to python
            via mel2py, with this simple switch you can change back and forth from sourcing mel to importing python.

        """

        if language == 'mel':
            cls.eval( """source "%s";""" % script )

        elif language == 'python':
            script = util.path( script )
            modulePath = script.namebase
            folder = script.parent
            print modulePath
            if not sys.modules.has_key(modulePath):
                print "importing"
                module = __import__(modulePath, globals(), locals(), [''])
                sys.modules[modulePath] = module

        else:
            raise TypeError, "language keyword expects 'mel' or 'python'. got '%s'" % language

    @classmethod
    def eval( cls, cmd ):
        """
        evaluate a string as a mel command and return the result.

        Behaves like maya.mel.eval, with several improvements:
            - returns pymel `Vector` and `Matrix` classes
            - when an error is encountered a `MelError` exception is raised, along with the line number (if enabled) and exact mel error.

        >>> mel.eval( 'attributeExists("persp", "translate")' )
        0
        >>> mel.eval( 'interToUI( "fooBarSpangle" )' )
        u'Foo Bar Spangle'

        """
        # should return a value, like _mm.eval
        #return _mm.eval( cmd )
        # get this before installing the callback
        undoState = _mc.undoInfo(q=1, state=1)
        lineNumbers = _mc.commandEcho(q=1,lineNumbers=1)
        _mc.commandEcho(lineNumbers=1)
        global errors
        errors = [] # a list to store each error line
        def errorCallback( nativeMsg, messageType, data ):
            global errors
            if messageType == _api.MCommandMessage.kError:
                if nativeMsg:
                    errors +=  [ nativeMsg ]

        # setup the callback:
        # assigning ids to a list avoids the swig memory leak warning, which would scare a lot of people even though
        # it is harmless.  hoping we get a real solution to this so that we don't have to needlessly accumulate this data
        id = _api.MCommandMessage.addCommandOutputCallback( errorCallback, None )


        try:
            res = _api.MCommandResult()
            _api.MGlobal.executeCommand( cmd, res, False, undoState )
        except Exception:
            # these two lines would go in a finally block, but we have to maintain python 2.4 compatibility for maya 8.5
            _api.MMessage.removeCallback( id )
            _mc.commandEcho(lineNumbers=lineNumbers)
            # 8.5 fix
            if hasattr(id, 'disown'):
                id.disown()

            msg = '\n'.join( errors )

            if 'Cannot find procedure' in msg:
                e = MelUnknownProcedureError
            elif 'Wrong number of arguments' in msg:
                e = MelArgumentError
                if cls.proc:
                    # remove the calling proc, it will be added below
                    msg = msg.split('\n', 1)[1].lstrip()
            elif 'Cannot convert data' in msg or 'Cannot cast data' in msg:
                e = MelConversionError
            elif 'Syntax error' in msg:
                e = MelSyntaxError
            else:
                e = MelError
            message = "Error during execution of MEL script: %s" % ( msg )
            fmtCmd = '\n'.join( [ '  ' + x for x in cmd.split('\n') ] )


            if cls.proc:
                if e is not MelUnknownProcedureError:
                    file = _mm.eval('whatIs "%s"' % cls.proc)
                    if file.startswith( 'Mel procedure found in: '):
                        file = 'file "%s"' % os.path.realpath(file.split(':')[1].lstrip())
                    message += '\nCalling Procedure: %s, in %s' % (cls.proc, file )
                    message += '\n' + fmtCmd
            else:
                message += '\nScript:\n%s' % fmtCmd
            raise e, message
        else:
            # these two lines would go in a finally block, but we have to maintain python 2.4 compatibility for maya 8.5
            _api.MMessage.removeCallback( id )
            _mc.commandEcho(lineNumbers=lineNumbers)
            # 8.5 fix
            if hasattr(id, 'disown'):
                id.disown()
            resType = res.resultType()

            if resType == _api.MCommandResult.kInvalid:
                return
            elif resType == _api.MCommandResult.kInt:
                result = _api.SafeApiPtr('int')
                res.getResult(result())
                return result.get()
            elif resType == _api.MCommandResult.kIntArray:
                result = _api.MIntArray()
                res.getResult(result)
                return [ result[i] for i in range( result.length() ) ]
            elif resType == _api.MCommandResult.kDouble:
                result = _api.SafeApiPtr('double')
                res.getResult(result())
                return result.get()
            elif resType == _api.MCommandResult.kDoubleArray:
                result = _api.MDoubleArray()
                res.getResult(result)
                return [ result[i] for i in range( result.length() ) ]
            elif resType == _api.MCommandResult.kString:
                return res.stringResult()
            elif resType == _api.MCommandResult.kStringArray:
                result = []
                res.getResult(result)
                return result
            elif resType == _api.MCommandResult.kVector:
                result = _api.MVector()
                res.getResult(result)
                return datatypes.Vector(result)
            elif resType == _api.MCommandResult.kVectorArray:
                result = _api.MVectorArray()
                res.getResult(result)
                return [ datatypes.Vector(result[i]) for i in range( result.length() ) ]
            elif resType == _api.MCommandResult.kMatrix:
                result = _api.MMatrix()
                res.getResult(result)
                return datatypes.Matrix(result)
            elif resType == _api.MCommandResult.kMatrixArray:
                result = _api.MMatrixArray()
                res.getResult(result)
                return [ datatypes.Matrix(result[i]) for i in range( result.length() ) ]

    @staticmethod
    def error( msg, showLineNumber=False ):
        if showLineNumber:
            flags = ' -showLineNumber true '
        else:
            flags = ''
        _mm.eval( """error %s %s""" % ( flags, pythonToMel( msg) ) )

    @staticmethod
    def warning( msg, showLineNumber=False ):
        if showLineNumber:
            flags = ' -showLineNumber true '
        else:
            flags = ''
        _mm.eval( """warning %s %s""" % ( flags, pythonToMel( msg) ) )

    @staticmethod
    def trace( msg, showLineNumber=False ):
        if showLineNumber:
            flags = ' -showLineNumber true '
        else:
            flags = ''
        _mm.eval( """trace %s %s""" % ( flags, pythonToMel( msg) ) )

    @staticmethod
    def tokenize( *args ):
        raise NotImplementedError, "Calling the mel command 'tokenize' from python will crash Maya. Use the string split method instead."

    # just a convenient alias
    globals = melGlobals

mel = Mel()


def conditionExists(conditionName):
    """
    Returns True if the named condition exists, False otherwise.

    Note that 'condition' here refers to the type used by 'isTrue' and 'scriptJob', NOT to the condition NODE.
    """
    return conditionName in cmds.scriptJob(listConditions=True)


#class MayaGlobals(object):
#    """
#    A Singleton class to represent Maya current optionVars and settings which are global
#    to all of maya and are not saved with the scene.
#    """
#    __metaclass__ = util.Singleton
#
#    optionVars = OptionVarDict()
#    #grid = Grid()
#    #playbackOptions = PlaybackOptions()
#
#    # TODO : create a wrapper for os.environ which allows direct appending and popping of individual env entries (i.e. make ':' transparent)
#    envVars = os.environ
#    @staticmethod
#    def setConstructionHistory( state ):
#        cmds.constructionHistory( tgl=state )
#    @staticmethod
#    def getConstructionHistory(self):
#        return cmds.constructionHistory( q=True, tgl=True )
#
#    @staticmethod
#    def setUpAxis( axis, rotateView=False ):
#        """This flag specifies the axis as the world up direction. The valid axis are either 'y' or 'z'."""
#        cmds.upAxis( axis=axis.lower(), rotateView=rotateView )
#
#    @staticmethod
#    def getUpAxis(self):
#        """This flag gets the axis set as the world up direction. The valid axis are either 'y' or 'z'."""
#        return cmds.upAxis( q=True, axis=True )
#
#    @staticmethod
#    def user():
#        return getuser()
#
#    @staticmethod
#    def host():
#        return gethostname()
#

#class SceneGlobals(object):
#    """
#    A Static Singleton class to represent scene-dependent settings.
#    """
#    __metaclass__ = util.Singleton
#
#    @staticmethod
#    def sceneName():
#        return system.Path(cmds.file( q=1, sn=1))
#
#    @util.universalmethod
#    def getTime(obj):
#        return cmds.currentTime( q=1 )
#
#    @util.universalmethod
#    def setTime( obj, val ):
#        cmds.currentTime( val )
#    time = property( getTime, setTime )
#
#    @staticmethod
#    def getMinTime():
#        return cmds.playbackOptions( q=1, minTime=1 )
#    @staticmethod
#    def setMinTime( val ):
#        cmds.playbackOptions( minTime=val )
#    minTime = property( getMinTime, setMinTime )
#
#    @staticmethod
#    def getMaxTime():
#        return cmds.playbackOptions( q=1, maxTime=1 )
#    @staticmethod
#    def setMaxTime( val ):
#        cmds.playbackOptions( maxTime=val )
#
#    maxTime = property( getMaxTime, setMaxTime )

#env = Env()

_factories.createFunctions( __name__ )

########NEW FILE########
__FILENAME__ = modeling
"""functions related to modeling"""

import pymel.internal.factories as _factories
import pymel.internal.pmcmds as cmds
import general as _general

def pointPosition( *args, **kwargs ):
    return _general.datatypes.Point( cmds.pointPosition(*args, **kwargs) )

def curve( *args, **kwargs ):
    """
Maya Bug Fix:
  - name parameter only applied to transform. now applies to shape as well
    """
    # curve returns a transform
    name = kwargs.pop('name', kwargs.pop('n', None))
    res = _general.PyNode( cmds.curve(*args, **kwargs) )
    if name:
        res.rename(name)
    return res

def surface( *args, **kwargs ):
    """
Maya Bug Fix:
  - name parameter only applied to transform. now applies to shape as well
    """
    # surface returns a shape
    name = kwargs.pop('name', kwargs.pop('n', None))
    res = _general.PyNode( cmds.surface(*args, **kwargs) )
    if name:
        res.getParent().rename(name)
    return res

_factories.createFunctions( __name__, _general.PyNode )
########NEW FILE########
__FILENAME__ = nodetypes
"""
Contains classes corresponding to the Maya type hierarchy, including `DependNode`, `Transform`, `Mesh`, and `Camera`.
"""
import sys, os, re
import inspect, itertools, math

import pymel.util as _util
import pymel.internal.pmcmds as cmds #@UnresolvedImport
import pymel.internal.factories as _factories
import pymel.api as _api #@UnresolvedImport
import pymel.internal.apicache as _apicache
import pymel.internal.pwarnings as _warnings
from pymel.internal import getLogger as _getLogger
import datatypes
_logger = _getLogger(__name__)

# to make sure Maya is up
import pymel.internal as internal
import pymel.versions as versions

from maya.cmds import about as _about
import maya.mel as mm

#from general import *
import general
import other
from animation import listAnimatable as _listAnimatable
from system import namespaceInfo as _namespaceInfo, FileReference as _FileReference

_thisModule = sys.modules[__name__]

#__all__ = ['Component', 'MeshEdge', 'MeshVertex', 'MeshFace', 'Attribute', 'DependNode' ]

## Mesh Components

# If we're reloading, clear the pynode types out
_factories.clearPyNodeTypes()

class DependNode( general.PyNode ):
    __apicls__ = _api.MFnDependencyNode
    __metaclass__ = _factories.MetaMayaNodeWrapper
    #-------------------------------
    #    Name Info and Manipulation
    #-------------------------------
#    def __new__(cls,name,create=False):
#        """
#        Provides the ability to create the object when creating a class
#
#            >>> n = pm.Transform("persp",create=True)
#            >>> n.__repr__()
#            # Result: nt.Transform(u'persp1')
#        """
#        if create:
#            ntype = cls.__melnode__
#            name = createNode(ntype,n=name,ss=1)
#        return general.PyNode.__new__(cls,name)

#    def __init__(self, *args, **kwargs ):
#        self.apicls.__init__(self, self._apiobject.object() )

    @_util.universalmethod
    def __melobject__(self):
        """Special method for returning a mel-friendly representation."""
        if isinstance(self, DependNode):
            # For instance, return the node's name...
            return self.name()
        else:
            # For the class itself, return the mel node name
            return self.__melnode__

    def __repr__(self):
        """
        :rtype: `unicode`
        """
        return u"nt.%s(%r)" % (self.__class__.__name__, self.name())

    def _updateName(self) :
        # test validity
        self.__apimobject__()
        self._name = self.__apimfn__().name()
        return self._name

    def name(self, update=True, stripNamespace=False) :
        """
        :rtype: `unicode`
        """

        if update or self._name is None:
            try:
                self._updateName()
            except general.MayaObjectError:
                _logger.warn( "object %s no longer exists" % self._name )
        name = self._name
        if stripNamespace:
            name = name.rsplit(':', 1)[-1]
        return name

    def namespace(self, root=False):
        """Returns the namespace of the object with trailing colon included.

        See `DependNode.parentNamespace` for a variant which does not include
        the trailing colon.

        By default, if the object is in the root namespace, an empty string is
        returned; if root is True, ':' is returned in this case.

        :rtype: `unicode`

        """
        ns = self.parentNamespace()
        if ns or root:
            ns += ':'
        return ns

    def shortName(self):
        """
        This produces the same results as `DependNode.name` and is included to simplify looping over lists
        of nodes that include both Dag and Depend nodes.

        :rtype: `unicode`
        """
        return self.name()

    def longName(self):
        """
        This produces the same results as `DependNode.name` and is included to simplify looping over lists
        of nodes that include both Dag and Depend nodes.

        :rtype: `unicode`
        """
        return self.name()

    def nodeName(self, **kwargs):
        """
        This produces the same results as `DependNode.name` and is included to simplify looping over lists
        of nodes that include both Dag and Depend nodes.

        :rtype: `unicode`
        """
        return self.name(**kwargs)

    #rename = rename
    def rename( self, name, **kwargs ):
        """
        :rtype: `DependNode`
        """
        #self.setName( name ) # no undo support

        #check for preserveNamespace a pymel unique flag
        if kwargs.pop('preserveNamespace', False):
            name = self.namespace(root=True) + name

        #ensure shortname
        if '|' in name:
            name = name.split('|')[-1]

        return general.rename(self, name, **kwargs)

    def __apiobject__(self) :
        "get the default API object (MObject) for this node if it is valid"
        return self.__apimobject__()

    def __apimobject__(self) :
        "get the MObject for this node if it is valid"
        handle = self.__apihandle__()
        if _api.isValidMObjectHandle( handle ) :
            return handle.object()
        raise general.MayaNodeError( self._name )

    def __apihandle__(self) :
        return self.__apiobjects__['MObjectHandle']


    def __str__(self):
        return "%s" % self.name()

    def __unicode__(self):
        return u"%s" % self.name()

    if versions.current() >= versions.v2009:
        def __hash__(self):
            return self.__apihandle__().hashCode()

    def node(self):
        """for compatibility with Attribute class

        :rtype: `DependNode`

        """
        return self




    #--------------------------
    #    Modification
    #--------------------------

    def lock( self, **kwargs ):
        'lockNode -lock 1'
        #kwargs['lock'] = True
        #kwargs.pop('l',None)
        #return cmds.lockNode( self, **kwargs)
        return self.setLocked( True )

    def unlock( self, **kwargs ):
        'lockNode -lock 0'
        #kwargs['lock'] = False
        #kwargs.pop('l',None)
        #return cmds.lockNode( self, **kwargs)
        return self.setLocked( False )

    def cast( self, swapNode, **kwargs):
        """nodeCast"""
        return cmds.nodeCast( self, swapNode, *kwargs )


    duplicate = general.duplicate

#--------------------------
#xxx{    Presets
#--------------------------

    def savePreset(self, presetName, custom=None, attributes=[]):

        kwargs = {'save':True}
        if attributes:
            kwargs['attributes'] = ' '.join(attributes)
        if custom:
            kwargs['custom'] = custom

        return cmds.nodePreset( presetName, **kwargs)

    def loadPreset(self, presetName):
        kwargs = {'load':True}
        return cmds.nodePreset( presetName, **kwargs)

    def deletePreset(self, presetName):
        kwargs = {'delete':True}
        return cmds.nodePreset( presetName, **kwargs)

    def listPresets(self):
        kwargs = {'list':True}
        return cmds.nodePreset( **kwargs)
#}

#--------------------------
#xxx{    Info
#--------------------------
    type = general.nodeType


    def referenceFile(self):
        """referenceQuery -file
        Return the reference file to which this object belongs.  None if object is not referenced

        :rtype: `FileReference`

        """
        try:
            return _FileReference( cmds.referenceQuery( self, f=1) )
        except RuntimeError:
            None

    isReadOnly = _factories.wrapApiMethod( _api.MFnDependencyNode, 'isFromReferencedFile', 'isReadOnly' )

    def classification(self):
        'getClassification'
        return general.getClassification( self.type() )
        #return self.__apimfn__().classification( self.type() )

#}
#--------------------------
#xxx{   Connections
#--------------------------

    def inputs(self, **kwargs):
        """listConnections -source 1 -destination 0

        :rtype: `PyNode` list
        """
        kwargs['source'] = True
        kwargs.pop('s', None )
        kwargs['destination'] = False
        kwargs.pop('d', None )
        return general.listConnections(self, **kwargs)

    def outputs(self, **kwargs):
        """listConnections -source 0 -destination 1

        :rtype: `PyNode` list
        """
        kwargs['source'] = False
        kwargs.pop('s', None )
        kwargs['destination'] = True
        kwargs.pop('d', None )

        return general.listConnections(self, **kwargs)

    def sources(self, **kwargs):
        """listConnections -source 1 -destination 0

        :rtype: `PyNode` list
        """
        kwargs['source'] = True
        kwargs.pop('s', None )
        kwargs['destination'] = False
        kwargs.pop('d', None )
        return general.listConnections(self, **kwargs)

    def destinations(self, **kwargs):
        """listConnections -source 0 -destination 1

        :rtype: `PyNode` list
        """
        kwargs['source'] = False
        kwargs.pop('s', None )
        kwargs['destination'] = True
        kwargs.pop('d', None )

        return general.listConnections(self, **kwargs)

    def shadingGroups(self):
        """list any shading groups in the future of this object - works for
        shading nodes, transforms, and shapes

        Also see listSets(type=1) - which returns which 'rendering sets' the
        object is a member of (and 'rendering sets' seem to consist only of
        shading groups), whereas this method searches the object's future for
        any nodes of type 'shadingEngine'.

        :rtype: `DependNode` list
        """
        return self.future(type='shadingEngine')

#}
#--------------------------
#xxx{    Attributes
#--------------------------
    def __getattr__(self, attr):
        try :
            return getattr(super(general.PyNode, self), attr)
        except AttributeError :
            try:
                return DependNode.attr(self,attr)
            except general.MayaAttributeError, e:
                # since we're being called via __getattr__ we don't know whether the user was intending
                # to get a class method or a maya attribute, so we raise a more generic AttributeError
                raise AttributeError,"%r has no attribute or method named '%s'" % (self, attr)

    @_util.universalmethod
    def attrDefaults(obj, attr): #@NoSelf
        """
        Access to an attribute of a node.  This does not require an instance:

            >>> nt.Transform.attrDefaults('tx').isKeyable()
            True

        but it can use one if needed ( for example, for dynamically created attributes )

            >>> nt.Transform(u'persp').attrDefaults('tx').isKeyable()

        Note: this is still experimental.
        """
        if inspect.isclass(obj):
            self = None
            cls = obj # keep things familiar
        else:
            self = obj # keep things familiar
            cls = type(obj)

        attributes = cls.__apiobjects__.setdefault('MFnAttributes', {})
        attrObj = attributes.get(attr, None)
        if not _api.isValidMObject(attrObj):
            def toAttrObj(apiObj):
                try:
                    attrObj = apiObj.attribute(attr)
                    if attrObj.isNull():
                        raise RuntimeError
                except RuntimeError:
                    # just try it first, then check if it has the attribute if
                    # we errored (as opposed to always check first if the node
                    # has the attribute), on the assumption that this will be
                    # "faster" for most cases, where the node actually DOES have
                    # the attribute...
                    if not apiObj.hasAttribute(attr):
                        raise general.MayaAttributeError('%s.%s' % (cls.__melnode__, attr))
                    else:
                        # don't know why we got this error, so just reraise
                        raise
                return attrObj

            if self is None:
                if hasattr(_api, 'MNodeClass'):
                    # Yay, we have MNodeClass, use it!
                    nodeCls = _api.MNodeClass(cls.__melnode__)
                    attrObj = toAttrObj(nodeCls)
                else:
                    # We don't have an instance of the node, we need
                    # to make a ghost one...
                    with _apicache._GhostObjMaker(cls.__melnode__) as nodeObj:
                        if nodeObj is None:
                            # for instance, we get this if we have an abstract class...
                            raise RuntimeError("Unable to get attribute defaults for abstract node class %s, in versions prior to 2012" % cls.__melnode__)
                        nodeMfn = cls.__apicls__(nodeObj)
                        attrObj = toAttrObj(nodeMfn)
            else:
                nodeMfn = self.__apimfn__()
                attrObj = toAttrObj(nodeMfn)
            attributes[attr] = attrObj
        return general.AttributeDefaults( attrObj )

    def attr(self, attr):
        """
        access to attribute plug of a node. returns an instance of the Attribute class for the
        given attribute name.

        :rtype: `Attribute`
        """
        return self._attr(attr, False)

    # Just have this alias because it will sometimes return attributes for an
    # underlying shape, which we may want for DagNode.attr, but don't want for
    # DependNode.attr (and using the on-shape result, instead of throwing it
    # away and then finding it again on the shape, saves time for the DagNode
    # case)
    def _attr(self, attr, allowOtherNode):
        #return Attribute( '%s.%s' % (self, attr) )
        try :
            if '.' in attr or '[' in attr:
                # Compound or Multi Attribute
                # there are a couple of different ways we can proceed:
                # Option 1: back out to _api.toApiObject (via general.PyNode)
                # return Attribute( self.__apiobject__(), self.name() + '.' + attr )

                # Option 2: nameparse.
                # this avoids calling self.name(), which can be slow
                import pymel.util.nameparse as nameparse
                nameTokens = nameparse.getBasicPartList( 'dummy.' + attr )
                result = self.__apiobject__()
                for token in nameTokens[1:]: # skip the first, bc it's the node, which we already have
                    if isinstance( token, nameparse.MayaName ):
                        if isinstance( result, _api.MPlug ):
                            # you can't get a child plug from a multi/array plug.
                            # if result is currently 'defaultLightList1.lightDataArray' (an array)
                            # and we're trying to get the next plug, 'lightDirection', then we need a dummy index.
                            # the following line will reuslt in 'defaultLightList1.lightDataArray[-1].lightDirection'
                            if result.isArray():
                                result = self.__apimfn__().findPlug( unicode(token) )
                            else:
                                result = result.child( self.__apimfn__().attribute( unicode(token) ) )
                        else: # Node
                            result = self.__apimfn__().findPlug( unicode(token) )
#                                # search children for the attribute to simulate  cam.focalLength --> perspShape.focalLength
#                                except TypeError:
#                                    for i in range(fn.childCount()):
#                                        try: result = _api.MFnDagNode( fn.child(i) ).findPlug( unicode(token) )
#                                        except TypeError: pass
#                                        else:break
                    if isinstance( token, nameparse.NameIndex ):
                        if token.value != -1:
                            result = result.elementByLogicalIndex( token.value )
                plug = result
            else:
                try:
                    plug = self.__apimfn__().findPlug( attr, False )
                except RuntimeError:
                    # Don't use .findAlias, as it always returns the 'base'
                    # attribute - ie, if the alias is to foo[0].bar, it will
                    # just point to foo
                    # aliases
                    #obj = _api.MObject()
                    #self.__apimfn__().findAlias( attr, obj )
                    #plug = self.__apimfn__().findPlug( obj, False )

                    # the following technique gets aliased attributes as well. turning dagPlugs to off saves time because we already
                    # know the dagNode. however, certain attributes, such as rotatePivot, are detected as components,
                    # despite the fact that findPlug finds them as MPlugs. need to look into this
                    # TODO: test speed versus above method
                    try:
                        plug = _api.toApiObject(self.name() + '.' + attr, dagPlugs=False)
                    except RuntimeError:
                        raise
                    if not isinstance(plug, _api.MPlug):
                        raise RuntimeError

                if not (allowOtherNode or plug.node() == self.__apimobject__()):
                    # we could have gotten an attribute on a shape object,
                    # which we don't want
                    raise RuntimeError
            return general.Attribute( self.__apiobject__(), plug )

        except RuntimeError:
            # raise our own MayaAttributeError, which subclasses AttributeError and MayaObjectError
            raise general.MayaAttributeError( '%s.%s' % (self, attr) )

    hasAttr = general.hasAttr

    @_factories.addMelDocs('setAttr')
    def setAttr( self, attr, *args, **kwargs):
        # for now, using strings is better, because there is no MPlug support
        return general.setAttr( "%s.%s" % (self, attr), *args, **kwargs )

    @_factories.addMelDocs('setAttr')
    def setDynamicAttr( self, attr, *args, **kwargs):
        """
        same as `DependNode.setAttr` with the force flag set to True.  This causes
        the attribute to be created based on the passed input value.
        """

        # for now, using strings is better, because there is no MPlug support
        kwargs['force'] = True
        return general.setAttr( "%s.%s" % (self, attr), *args, **kwargs )

    @_factories.addMelDocs('getAttr')
    def getAttr( self, attr, *args, **kwargs ):
        # for now, using strings is better, because there is no MPlug support
        return general.getAttr( "%s.%s" % (self, attr), *args,  **kwargs )

    @_factories.addMelDocs('addAttr')
    def addAttr( self, attr, **kwargs):
        # for now, using strings is better, because there is no MPlug support
        assert 'longName' not in kwargs and 'ln' not in kwargs
        kwargs['longName'] = attr
        return general.addAttr( unicode(self), **kwargs )

    @_factories.addMelDocs('deleteAttr')
    def deleteAttr( self, attr, *args, **kwargs ):
        # for now, using strings is better, because there is no MPlug support
        return general.deleteAttr( "%s.%s" % (self, attr), *args,  **kwargs )

    @_factories.addMelDocs('connectAttr')
    def connectAttr( self, attr, destination, **kwargs ):
        # for now, using strings is better, because there is no MPlug support
        return general.connectAttr( "%s.%s" % (self, attr), destination, **kwargs )

    @_factories.addMelDocs('disconnectAttr')
    def disconnectAttr( self, attr, destination=None, **kwargs ):
        # for now, using strings is better, because there is no MPlug support
        return general.disconnectAttr( "%s.%s" % (self, attr), destination, **kwargs )


    listAnimatable = _listAnimatable

    def listAttr( self, **kwargs):
        """
        listAttr

        Modifications:
          - returns an empty list when the result is None
          - added 'alias' keyword to list attributes that have aliases
          - added 'topLevel' keyword to only return attributes that are not
            compound children; may not be used in combination with
            'descendants'
          - added 'descendants' keyword to return all top-level attributes
            and all their descendants; note that the standard call may return
            some attributes that 'descendants' will not, if there are compound
            multi attributes with no existing indices; ie, the standard call
            might return "node.parentAttr[-1].childAttr", but the 'descendants'
            version would only return childAttr if an index exists for
            parentAttr, ie "node.parentAttr[0].childAttr"; may not be used in
            combination with 'topLevel'
        :rtype: `Attribute` list

        """
        topLevel = kwargs.pop('topLevel', False)
        descendants = kwargs.pop('descendants', False)
        if descendants:
            if topLevel:
                raise ValueError("may not specify both topLevel and descendants")
            # get the topLevel ones, then aggregate all the descendants...
            topChildren = self.listAttr(topLevel=True, **kwargs)
            res = list(topChildren)
            for child in topChildren:
                res.extend(child.iterDescendants())
            return res

        alias = kwargs.pop('alias', False)
        # stringify fix
        res = map( lambda x: self.attr(x), _util.listForNone(cmds.listAttr(self.name(), **kwargs)))
        if alias:
            res = [x[1] for x in self.listAliases() if x[1] in res]

#            aliases = dict( (x[1], x[0]) for x in general.aliasAttr(self.name()) )
#            tmp = res
#            res = []
#            for at in tmp:
#                try:
#                    res.append( aliases[at], at )
#                except KeyError:
#                    pass
        if topLevel:
            res = [x for x in res if x.getParent() is None]
        return res

    def listAliases( self ):
        """
        aliasAttr

        Modifications:
          - returns an empty list when the result is None
          - when queried, returns a list of (alias, `Attribute`) pairs.

        :rtype: (`str`, `Attribute`) list

        """

        #tmp = _util.listForNone(cmds.aliasAttr(self.name(),query=True))
        tmp = []
        self.__apimfn__().getAliasList(tmp)
        res = []
        for i in range(0,len(tmp),2):
            res.append((tmp[i], general.Attribute(self.node() + '.' + tmp[i+1])))
        return res


    def attrInfo( self, **kwargs):
        """attributeInfo

        :rtype: `Attribute` list
        """
        # stringify fix
        return map( lambda x: self.attr(x) , _util.listForNone(cmds.attributeInfo(self.name(), **kwargs)))


#}
#-----------------------------------------
#xxx{ Name Info and Manipulation
#-----------------------------------------

# Now just wraps NameParser functions

    def stripNum(self):
        """Return the name of the node with trailing numbers stripped off. If no trailing numbers are found
        the name will be returned unchanged.

        >>> from pymel.core import *
        >>> SCENE.lambert1.stripNum()
        u'lambert'

        :rtype: `unicode`
        """
        return other.NameParser(self).stripNum()

    def extractNum(self):
        """Return the trailing numbers of the node name. If no trailing numbers are found
        an error will be raised.

        >>> from pymel.core import *
        >>> SCENE.lambert1.extractNum()
        u'1'

        :rtype: `unicode`
        """
        return other.NameParser(self).extractNum()

    def nextUniqueName(self):
        """Increment the trailing number of the object until a unique name is found

        If there is no trailing number, appends '1' to the name.

        :rtype: `unicode`
        """
        return other.NameParser(self).nextUniqueName()

    def nextName(self):
        """Increment the trailing number of the object by 1

        Raises an error if the name has no trailing number.

        >>> from pymel.core import *
        >>> SCENE.lambert1.nextName()
        DependNodeName(u'lambert2')

        :rtype: `unicode`
        """
        return other.NameParser(self).nextName()

    def prevName(self):
        """Decrement the trailing number of the object by 1

        Raises an error if the name has no trailing number.

        :rtype: `unicode`
        """
        return other.NameParser(self).prevName()

    @classmethod
    def registerVirtualSubClass( cls, nameRequired=False ):
        """
        Deprecated
        """
        _factories.registerVirtualClass(cls, nameRequired)

#}

if versions.current() >= versions.v2011:
    class ContainerBase(DependNode):
        __metaclass__ = _factories.MetaMayaNodeWrapper
        pass

    class Entity(ContainerBase):
        __metaclass__ = _factories.MetaMayaNodeWrapper
        pass

else:
    class Entity(DependNode):
        __metaclass__ = _factories.MetaMayaNodeWrapper
        pass

class DagNode(Entity):

    #:group Path Info and Modification: ``*parent*``, ``*Parent*``, ``*child*``, ``*Child*``
    """
    """

    __apicls__ = _api.MFnDagNode
    __metaclass__ = _factories.MetaMayaNodeWrapper

#    def __init__(self, *args, **kwargs ):
#        self.apicls.__init__(self, self.__apimdagpath__() )
    _componentAttributes = {}

    def comp(self, compName):
        """
        Will retrieve a Component object for this node; similar to
        DependNode.attr(), but for components.

        :rtype: `Component`
        """
        if compName in self._componentAttributes:
            compClass = self._componentAttributes[compName]
            if isinstance(compClass, tuple):
                # We have something like:
                # 'uIsoparm'    : (NurbsSurfaceIsoparm, 'u')
                # need to specify what 'flavor' of the basic
                # component we need...
                return compClass[0](self, {compClass[1]:general.ComponentIndex(label=compClass[1])})
            else:
                return compClass(self)
        # if we do self.getShape(), and this is a shape node, we will
        # enter a recursive loop if compName isn't actually a comp:
        # since shape doesn't have 'getShape', it will call __getattr__
        # for 'getShape', which in turn call comp to check if it's a comp,
        # which will call __getattr__, etc
        # ..soo... check if we have a 'getShape'!
        # ...also, don't use 'hasattr', as this will also call __getattr__!
        try:
            object.__getattribute__(self, 'getShape')
        except AttributeError:
            raise general.MayaComponentError( '%s.%s' % (self, compName) )
        else:
            shape = self.getShape()
            if shape:
                return shape.comp(compName)

    def listComp(self, names=False):
        """Will return a list of all component objects for this object

        Is to .comp() what .listAttr() is to .attr(); will NOT check the shape
        node.

        Parameters
        ----------
        names : bool
            By default, will return a list of actual usabale pymel Component
            objects; if you just want a list of string names which would
            be compatible with .comp(), set names to True
        """
        keys = sorted(self._componentAttributes.keys())
        if names:
            return keys

        compTypes = set()
        comps = []
        # use the sorted keys, so the order matches that returned by names,
        # minus duplicate entries for aliases
        for name in keys:
            compType = self._componentAttributes[name]
            if compType not in compTypes:
                compTypes.add(compType)
                comps.append(self.comp(name))
        return comps


    def _updateName(self, long=False) :
        #if _api.isValidMObjectHandle(self._apiobject) :
            #obj = self._apiobject.object()
            #dagFn = _api.MFnDagNode(obj)
            #dagPath = _api.MDagPath()
            #dagFn.getPath(dagPath)
        dag = self.__apimdagpath__()
        if dag:
            name = dag.partialPathName()
            if not name:
                raise general.MayaNodeError

            self._name = name
            if long :
                return dag.fullPathName()

        return self._name

    def name(self, update=True, long=False) :

        if update or long or self._name is None:
            try:
                return self._updateName(long)
            except general.MayaObjectError:
                _logger.warn( "object %s no longer exists" % self._name )
        return self._name

    def longName(self,stripNamespace=False,levels=0):
        """
        The full dag path to the object, including leading pipe ( | )

        :rtype: `unicode`
        """
        if stripNamespace:
            name = self.name(long=True)
            nodes = []
            for x in name.split('|'):
                y = x.split('.')
                z = y[0].split(':')
                if levels:
                    y[0] = ':'.join( z[min(len(z)-1,levels):] )

                else:
                    y[0] = z[-1]
                nodes.append( '.'.join( y ) )
            stripped_name = '|'.join( nodes)
            return stripped_name

        return self.name(long=True)
    fullPath = longName

    def shortName( self ):
        """
        The shortest unique name.

        :rtype: `unicode`
        """
        return self.name(long=False)

    def nodeName( self, stripNamespace=False, stripUnderWorld=True ):
        """
        Just the name of the node, without any dag path

        :rtype: `unicode`
        """
        parts = self.name().rsplit('>', 1)
        if len(parts) > 1:
            # underworld nodes use -> as a separator.
            # e.g. foo|bar|this->|plate|plateShape
            underworld, name = parts[-2:]
            # get shortname of component after the underworld separator (->)
            name = name.rsplit('|', 1)[-1]
            if not stripUnderWorld:
                name = underworld + '>' + name
        else:
            name = parts[0]
        name = name.rsplit('|', 1)[-1]

        if stripNamespace:
            name = name.rsplit(':', 1)[-1]
        return name


    def __apiobject__(self) :
        "get the MDagPath for this object if it is valid"
        return self.__apimdagpath__()

    def __apimdagpath__(self) :
        "get the MDagPath for this object if it is valid"

        try:
            dag = self.__apiobjects__['MDagPath']
            # test for validity: if the object is not valid an error will be raised
            self.__apimobject__()
            return dag
        except KeyError:
            # class was instantiated from an MObject, but we can still retrieve the first MDagPath

            #assert argObj.hasFn( _api.MFn.kDagNode )
            dag = _api.MDagPath()
            # we can't use self.__apimfn__() becaue the mfn is instantiated from an MDagPath
            # which we are in the process of finding out
            mfn = _api.MFnDagNode( self.__apimobject__() )
            mfn.getPath(dag)
            self.__apiobjects__['MDagPath'] = dag
            return dag
#            if dag.isValid():
#                #argObj = dag
#                if dag.fullPathName():
#                    argObj = dag
#                else:
#                    print 'produced valid MDagPath with no name: %s(%s)' % ( argObj.apiTypeStr(), _api.MFnDependencyNode(argObj).name() )

    def __apihandle__(self) :
        try:
            handle = self.__apiobjects__['MObjectHandle']
        except KeyError:
            try:
                handle = _api.MObjectHandle( self.__apiobjects__['MDagPath'].node() )
            except RuntimeError:
                raise general.MayaNodeError( self._name )
            self.__apiobjects__['MObjectHandle'] = handle
        return handle

#    def __apimfn__(self):
#        if self._apimfn:
#            return self._apimfn
#        elif self.__apicls__:
#            obj = self._apiobject
#            if _api.isValidMDagPath(obj):
#                try:
#                    self._apimfn = self.__apicls__(obj)
#                    return self._apimfn
#                except KeyError:
#                    pass

#    def __init__(self, *args, **kwargs):
#        if self._apiobject:
#            if isinstance(self._apiobject, _api.MObjectHandle):
#                dagPath = _api.MDagPath()
#                _api.MDagPath.getAPathTo( self._apiobject.object(), dagPath )
#                self._apiobject = dagPath
#
#            assert _api.isValidMDagPath( self._apiobject )


#    def __init__(self, *args, **kwargs) :
#        if args :
#            arg = args[0]
#            if len(args) > 1 :
#                comp = args[1]
#            if isinstance(arg, DagNode) :
#                self._name = unicode(arg.name())
#                self._apiobject = _api.MObjectHandle(arg.object())
#            elif _api.isValidMObject(arg) or _api.isValidMObjectHandle(arg) :
#                objHandle = _api.MObjectHandle(arg)
#                obj = objHandle.object()
#                if _api.isValidMDagNode(obj) :
#                    self._apiobject = objHandle
#                    self._updateName()
#                else :
#                    raise TypeError, "%r might be a dependencyNode, but not a dagNode" % arg
#            elif isinstance(arg, basestring) :
#                obj = _api.toMObject (arg)
#                if obj :
#                    # creation for existing object
#                    if _api.isValidMDagNode (obj):
#                        self._apiobject = _api.MObjectHandle(obj)
#                        self._updateName()
#                    else :
#                        raise TypeError, "%r might be a dependencyNode, but not a dagNode" % arg
#                else :
#                    # creation for inexistent object
#                    self._name = arg
#            else :
#                raise TypeError, "don't know how to make a DagNode out of a %s : %r" % (type(arg), arg)



#--------------------------------
#xxx{  Path Info and Modification
#--------------------------------
    def root(self):
        """rootOf

        :rtype: `unicode`
        """
        return DagNode( '|' + self.longName()[1:].split('|')[0] )

#    def hasParent(self, parent ):
#        try:
#            return self.__apimfn__().hasParent( parent.__apiobject__() )
#        except AttributeError:
#            obj = _api.toMObject(parent)
#            if obj:
#               return self.__apimfn__().hasParent( obj )
#
#    def hasChild(self, child ):
#        try:
#            return self.__apimfn__().hasChild( child.__apiobject__() )
#        except AttributeError:
#            obj = _api.toMObject(child)
#            if obj:
#               return self.__apimfn__().hasChild( obj )
#
#    def isParentOf( self, parent ):
#        try:
#            return self.__apimfn__().isParentOf( parent.__apiobject__() )
#        except AttributeError:
#            obj = _api.toMObject(parent)
#            if obj:
#               return self.__apimfn__().isParentOf( obj )
#
#    def isChildOf( self, child ):
#        try:
#            return self.__apimfn__().isChildOf( child.__apiobject__() )
#        except AttributeError:
#            obj = _api.toMObject(child)
#            if obj:
#               return self.__apimfn__().isChildOf( obj )

    def isInstanceOf(self, other):
        """
        :rtype: `bool`
        """
        if isinstance( other, general.PyNode ):
            return self.__apimobject__() == other.__apimobject__()
        else:
            try:
                return self.__apimobject__() == general.PyNode(other).__apimobject__()
            except:
                return False

    def instanceNumber(self):
        """
        returns the instance number that this path represents in the DAG. The instance number can be used to determine which
        element of the world space array attributes of a DAG node to connect to get information regarding this instance.

        :rtype: `int`
        """
        return self.__apimdagpath__().instanceNumber()


    def getInstances(self, includeSelf=True):
        """
        :rtype: `DagNode` list

        >>> from pymel.core import *
        >>> f=newFile(f=1) #start clean
        >>>
        >>> s = polyPlane()[0]
        >>> instance(s)
        [nt.Transform(u'pPlane2')]
        >>> instance(s)
        [nt.Transform(u'pPlane3')]
        >>> s.getShape().getInstances()
        [nt.Mesh(u'pPlane1|pPlaneShape1'), nt.Mesh(u'pPlane2|pPlaneShape1'), nt.Mesh(u'pPlane3|pPlaneShape1')]
        >>> s.getShape().getInstances(includeSelf=False)
        [nt.Mesh(u'pPlane2|pPlaneShape1'), nt.Mesh(u'pPlane3|pPlaneShape1')]

        """
        d = _api.MDagPathArray()
        self.__apimfn__().getAllPaths(d)
        thisDagPath = self.__apimdagpath__()
        result = [ general.PyNode( _api.MDagPath(d[i])) for i in range(d.length()) if includeSelf or not d[i] == thisDagPath ]

        return result

    def getOtherInstances(self):
        """
        same as `DagNode.getInstances` with includeSelf=False.

        :rtype: `DagNode` list
        """
        return self.getInstances(includeSelf=False)

    def firstParent(self):
        """firstParentOf

        :rtype: `DagNode`
        """
        try:
            return DagNode( '|'.join( self.longName().split('|')[:-1] ) )
        except TypeError:
            return DagNode( '|'.join( self.split('|')[:-1] ) )

#    def numChildren(self):
#        """
#        see also `childCount`
#
#        :rtype: `int`
#        """
#        return self.__apimdagpath__().childCount()

#    def getParent(self, **kwargs):
#        # TODO : print warning regarding removal of kwargs, test speed difference
#        parent = _api.MDagPath( self.__apiobject__() )
#        try:
#            parent.pop()
#            return general.PyNode(parent)
#        except RuntimeError:
#            pass
#
#    def getChildren(self, **kwargs):
#        # TODO : print warning regarding removal of kwargs
#        children = []
#        thisDag = self.__apiobject__()
#        for i in range( thisDag.childCount() ):
#            child = _api.MDagPath( thisDag )
#            child.push( thisDag.child(i) )
#            children.append( general.PyNode(child) )
#        return children

    def firstParent2(self, **kwargs):
        """unlike the firstParent command which determines the parent via string formatting, this
        command uses the listRelatives command
        """


        kwargs['parent'] = True
        kwargs.pop('p',None)
        #if longNames:
        kwargs['fullPath'] = True
        kwargs.pop('f',None)

        try:
            res = cmds.listRelatives( self, **kwargs)[0]
        except TypeError:
            return None

        res = general.PyNode( res )
        return res

    @staticmethod
    def _getDagParent(dag):
        if dag.length() <= 1:
            return None
        # Need a copy as we'll be modifying it...
        parentDag = _api.MDagPath(dag)
        parentDag.pop()

        # do a check for underworld paths - if we have a path:
        # |rootTrans|rootShape -> |underwoldTrans|underworldShape
        # then two parents up, we will get:
        # |rootTrans|rootShape ->
        # ...whose .node() will be unusable. check for this scenario, and if
        # we get it, skip this dag path, so we go straight to:
        # |rootTrans|rootShape

        pathCount = parentDag.pathCount()
        if pathCount > 1:
            # get just the last "path piece" - if it is "empty", do an extra
            # pop, to get out of the underworld
            underworldPath = _api.MDagPath()
            parentDag.getPath(underworldPath, pathCount - 1)
            if underworldPath.length() == 0:
                parentDag.pop()

        return parentDag

    def getParent(self, generations=1):
        """
        Modifications:
            - added optional generations flag, which gives the number of levels up that you wish to go for the parent;
              ie:
                  >>> from pymel.core import *
                  >>> select(cl=1)
                  >>> bottom = group(n='bottom')
                  >>> group(n='almostThere')
                  nt.Transform(u'almostThere')
                  >>> group(n='nextLevel')
                  nt.Transform(u'nextLevel')
                  >>> group(n='topLevel')
                  nt.Transform(u'topLevel')
                  >>> bottom.longName()
                  u'|topLevel|nextLevel|almostThere|bottom'
                  >>> bottom.getParent(2)
                  nt.Transform(u'nextLevel')

              Negative values will traverse from the top:

                  >>> bottom.getParent(generations=-3)
                  nt.Transform(u'almostThere')

              A value of 0 will return the same node.
              The default value is 1.

              If generations is None, it will be interpreted as 'return all
              parents', and a list will be returned.

              Since the original command returned None if there is no parent, to sync with this behavior, None will
              be returned if generations is out of bounds (no IndexError will be thrown).

        :rtype: `DagNode`
        """

        # Get the parent through the api - listRelatives doesn't handle instances correctly,
        # and string processing seems unreliable...

        res = general._getParent(self._getDagParent, self.__apimdagpath__(), generations)

        if generations is None:
            if res is None:
                return []
            return [general.PyNode(x) for x in res]
        elif res is not None:
            return general.PyNode( res )

    def getAllParents(self):
        """
        Return a list of all parents above this.

        Starts from the parent immediately above, going up.

        :rtype: `DagNode` list
        """
        return self.getParent(generations=None)

    def getChildren(self, **kwargs ):
        """
        see also `childAtIndex`

        for flags, see pymel.core.general.listRelatives

        :rtype: `DagNode` list
        """
        kwargs['children'] = True
        kwargs.pop('c',None)

        return general.listRelatives( self, **kwargs)

    def getSiblings(self, **kwargs ):
        """
        for flags, see pymel.core.general.listRelatives

        :rtype: `DagNode` list
        """
        #pass
        try:
            return [ x for x in self.getParent().getChildren(**kwargs) if x != self]
        except:
            return []

    def listRelatives(self, **kwargs ):
        """
        for flags, see pymel.core.general.listRelatives

        :rtype: `PyNode` list
        """
        return general.listRelatives( self, **kwargs)


    def setParent( self, *args, **kwargs ):
        """
        parent

        Modifications:
            - if parent is 'None', world=True is automatically set
            - if the given parent is the current parent, don't error

        """
        result = general.parent(self, *args, **kwargs)
        if result:
            result = result[0]
        return result

    def addChild( self, child, **kwargs ):
        """parent (reversed)

        :rtype: `DagNode`
        """
        cmds.parent( child, self, **kwargs )
        if not isinstance( child, general.PyNode ):
            child = general.PyNode(child)
        return child

    def __or__(self, child, **kwargs):
        """
        operator for `addChild`. Use to easily daisy-chain together parenting operations.
        The operation order visually mimics the resulting dag path:

            >>> from pymel.core import *
            >>> s = polySphere(name='sphere')[0]
            >>> c = polyCube(name='cube')[0]
            >>> t = polyTorus(name='torus')[0]
            >>> s | c | t
            nt.Transform(u'torus')
            >>> print t.fullPath()
            |sphere|cube|torus

        :rtype: `DagNode`
        """
        return self.addChild(child,**kwargs)

#}
    #instance = instance

    #--------------------------
    #    Shading
    #--------------------------

    def isDisplaced(self):
        """Returns whether any of this object's shading groups have a displacement shader input

        :rtype: `bool`
        """
        for sg in self.shadingGroups():
            if len( sg.attr('displacementShader').inputs() ):
                return True
        return False

    def hide(self):
        self.visibility.set(0)

    def show(self):
        self.visibility.set(1)

    def isVisible(self, checkOverride=True):
        if not self.attr('visibility').get():
            return False
        if (checkOverride and self.attr('overrideEnabled').get()
                and not self.attr('overrideVisibility').get()):
            return False
        parent = self.getParent()
        if not parent:
            return True
        else:
            return parent.isVisible(checkOverride=checkOverride)

    def setObjectColor( self, color=None ):
        """This command sets the dormant wireframe color of the specified objects to an integer
        representing one of the user defined colors, or, if set to None, to the default class color"""

        kwargs = {}
        if color:
            kwargs['userDefined'] = color
        cmds.color(self, **kwargs)

    def makeLive( self, state=True ):
        if not state:
            cmds.makeLive(none=True)
        else:
            cmds.makeLive(self)





class Shape(DagNode):
    __metaclass__ = _factories.MetaMayaNodeWrapper
    def getTransform(self): pass

    def setParent(self, *args, **kwargs):
        if 'shape' not in kwargs and 's' not in kwargs:
            kwargs['s'] = True
        super(Shape, self).setParent(*args, **kwargs)
#class Joint(Transform):
#    pass


class Camera(Shape):
    __metaclass__ = _factories.MetaMayaNodeWrapper

    def applyBookmark(self, bookmark):
        kwargs = {}
        kwargs['camera'] = self
        kwargs['edit'] = True
        kwargs['setCamera'] = True

        cmds.cameraView( bookmark, **kwargs )

    def addBookmark(self, bookmark=None):
        kwargs = {}
        kwargs['camera'] = self
        kwargs['addBookmark'] = True
        if bookmark:
            kwargs['name'] = bookmark

        cmds.cameraView( **kwargs )

    def removeBookmark(self, bookmark):
        kwargs = {}
        kwargs['camera'] = self
        kwargs['removeBookmark'] = True
        kwargs['name'] = bookmark

        cmds.cameraView( **kwargs )

    def updateBookmark(self, bookmark):
        kwargs = {}
        kwargs['camera'] = self
        kwargs['edit'] = True
        kwargs['setView'] = True

        cmds.cameraView( bookmark, **kwargs )

    def listBookmarks(self):
        return self.bookmarks.inputs()

    @_factories.addMelDocs('dolly')
    def dolly(self, distance, relative=True):
        kwargs = {}
        kwargs['distance'] = distance
        if relative:
            kwargs['relative'] = True
        else:
            kwargs['absolute'] = True
        cmds.dolly(self, **kwargs)

    @_factories.addMelDocs('roll')
    def roll(self, degree, relative=True):
        kwargs = {}
        kwargs['degree'] = degree
        if relative:
            kwargs['relative'] = True
        else:
            kwargs['absolute'] = True
        cmds.roll(self, **kwargs)

    #TODO: the functionFactory is causing these methods to have their docs doubled-up,  in both pymel.track, and pymel.Camera.track
    #dolly = _factories.functionFactory( cmds.dolly  )
    #roll = _factories.functionFactory( cmds.roll  )
    orbit = _factories.functionFactory( cmds.orbit  )
    track = _factories.functionFactory( cmds.track )
    tumble = _factories.functionFactory( cmds.tumble )


class Transform(DagNode):
    __metaclass__ = _factories.MetaMayaNodeWrapper
    _componentAttributes = {'rotatePivot' : (general.Pivot, 'rotatePivot'),
                            'scalePivot'  : (general.Pivot, 'scalePivot')}
#    def __getattr__(self, attr):
#        try :
#            return super(general.PyNode, self).__getattr__(attr)
#        except AttributeError, msg:
#            try:
#                return self.getShape().attr(attr)
#            except AttributeError:
#                pass
#
#            # it doesn't exist on the class
#            try:
#                return self.attr(attr)
#            except MayaAttributeError, msg:
#                # try the shape
#                try: return self.getShape().attr(attr)
#                except AttributeError: pass
#                # since we're being called via __getattr__ we don't know whether the user was trying
#                # to get a class method or a maya attribute, so we raise a more generic AttributeError
#                raise AttributeError, msg

    def __getattr__(self, attr):
        """
        Checks in the following order:
            1. Functions on this node class
            2. Attributes on this node class
            3. Functions on this node class's shape
            4. Attributes on this node class's shape
        """
        try :
            #print "Transform.__getattr__(%r)" % attr
            # Functions through normal inheritance
            res = DependNode.__getattr__(self,attr)
        except AttributeError, e:
            # Functions via shape inheritance , and then, implicitly, Attributes
            for shape in self.getShapes():
                try:
                    return getattr(shape,attr)
                except AttributeError: pass
            raise e
        return res

    def __setattr__(self, attr, val):
        """
        Checks in the following order:
            1. Functions on this node class
            2. Attributes on this node class
            3. Functions on this node class's shape
            4. Attributes on this node class's shape
        """
        try :
            #print "Transform.__setattr__", attr, val
            # Functions through normal inheritance
            return DependNode.__setattr__(self,attr,val)
        except AttributeError, e:
            # Functions via shape inheritance , and then, implicitly, Attributes
            #print "Trying shape"
            shape = self.getShape()
            if shape:
                try:
                    return setattr(shape,attr, val)
                except AttributeError: pass
            raise e

    def attr(self, attr, checkShape=True):
        """
        when checkShape is enabled, if the attribute does not exist the transform but does on the shape, then the shape's attribute will
        be returned.

        :rtype: `Attribute`
        """
        #print "ATTR: Transform"
        try :
            res = self._attr(attr, checkShape)
        except general.MayaAttributeError, e:
            if checkShape:
                try:
                    res = self.getShape().attr(attr)
                except AttributeError:
                    raise e
            raise e
        return res

#    def __getattr__(self, attr):
#        if attr.startswith('__') and attr.endswith('__'):
#            return super(general.PyNode, self).__getattr__(attr)
#
#        at = Attribute( '%s.%s' % (self, attr) )
#
#        # if the attribute does not exist on this node try the shape node
#        if not at.exists():
#            try:
#                childAttr = getattr( self.getShape(), attr)
#                try:
#                    if childAttr.exists():
#                        return childAttr
#                except AttributeError:
#                    return childAttr
#            except (AttributeError,TypeError):
#                pass
#
#        return at
#
#    def __setattr__(self, attr,val):
#        if attr.startswith('_'):
#            attr = attr[1:]
#
#        at = Attribute( '%s.%s' % (self, attr) )
#
#        # if the attribute does not exist on this node try the shape node
#        if not at.exists():
#            try:
#                childAttr = getattr( self.getShape(), attr )
#                try:
#                    if childAttr.exists():
#                        return childAttr.set(val)
#                except AttributeError:
#                    return childAttr.set(val)
#            except (AttributeError,TypeError):
#                pass
#
#        return at.set(val)

    """
    def move( self, *args, **kwargs ):
        return move( self, *args, **kwargs )
    def scale( self, *args, **kwargs ):
        return scale( self, *args, **kwargs )
    def rotate( self, *args, **kwargs ):
        return rotate( self, *args, **kwargs )
    def align( self, *args, **kwargs):
        args = (self,) + args
        cmds.align(self, *args, **kwargs)
    """
    # NOTE : removed this via proxyClass
#    # workaround for conflict with translate method on basestring
#    def _getTranslate(self):
#        return self.__getattr__("translate")
#    def _setTranslate(self, val):
#        return self.__setattr__("translate", val)
#    translate = property( _getTranslate , _setTranslate )

    def getShape( self, **kwargs ):
        """
        :rtype: `DagNode`
        """
        kwargs['shapes'] = True
        try:
            return self.getChildren( **kwargs )[0]
        except IndexError:
            pass

    def getShapes( self, **kwargs ):
        """
        :rtype: `DagNode`
        """
        kwargs['shapes'] = True
        return self.getChildren( **kwargs )


    def ungroup( self, **kwargs ):
        return cmds.ungroup( self, **kwargs )


#    @_factories.editflag('xform','scale')
#    def setScale( self, val, **kwargs ):
#        cmds.xform( self, **kwargs )

#    @_factories.editflag('xform','rotation')
#    def setRotationOld( self, val, **kwargs ):
#        cmds.xform( self, **kwargs )
#
#    @_factories.editflag('xform','translation')
#    def setTranslationOld( self, val, **kwargs ):
#        cmds.xform( self, **kwargs )
#
#    @_factories.editflag('xform','scalePivot')
#    def setScalePivotOld( self, val, **kwargs ):
#        cmds.xform( self, **kwargs )
#
#    @_factories.editflag('xform','rotatePivot')
#    def setRotatePivotOld( self, val, **kwargs ):
#        cmds.xform( self, **kwargs )

#    @_factories.editflag('xform','pivots')
#    def setPivots( self, val, **kwargs ):
#        cmds.xform( self, **kwargs )

#    @_factories.editflag('xform','rotateAxis')
#    def setRotateAxisOld( self, val, **kwargs ):
#        cmds.xform( self, **kwargs )
#
#    @_factories.editflag('xform','shear')
#    def setShearingOld( self, val, **kwargs ):
#        cmds.xform( self, **kwargs )


    @_factories.addMelDocs('xform','rotateAxis')
    def setMatrix( self, val, **kwargs ):
        """xform -scale"""
        kwargs['matrix'] = val
        cmds.xform( self, **kwargs )

#    @_factories.queryflag('xform','scale')
#    def getScaleOld( self, **kwargs ):
#        return datatypes.Vector( cmds.xform( self, **kwargs ) )

    def _getSpaceArg(self, space, kwargs):
        "for internal use only"
        if kwargs.pop( 'worldSpace', kwargs.pop('ws', False) ):
            space = 'world'
        elif kwargs.pop( 'objectSpace', kwargs.pop('os', False) ):
            space = 'object'
        return space

    def _isRelativeArg(self, kwargs ):

        isRelative = kwargs.pop( 'relative', kwargs.pop('r', None) )
        if isRelative is None:
            isRelative = not kwargs.pop( 'absolute', kwargs.pop('a', True) )
        return isRelative

#    @_factories.queryflag('xform','translation')
#    def getTranslationOld( self, **kwargs ):
#        return datatypes.Vector( cmds.xform( self, **kwargs ) )

    @_factories.addApiDocs( _api.MFnTransform, 'setTranslation' )
    def setTranslation(self, vector, space='object', **kwargs):
        if self._isRelativeArg(kwargs):
            return self.translateBy(vector, space, **kwargs)
        space = self._getSpaceArg(space, kwargs )
        return self._setTranslation(vector, space=space)

    @_factories.addApiDocs( _api.MFnTransform, 'getTranslation' )
    def getTranslation(self, space='object', **kwargs):
        space = self._getSpaceArg(space, kwargs )
        return self._getTranslation(space=space)

    @_factories.addApiDocs( _api.MFnTransform, 'translateBy' )
    def translateBy(self, vector, space='object', **kwargs):
        space = self._getSpaceArg(space, kwargs )
        curr = self._getTranslation(space)
        self._translateBy(vector, space)
        new = self._getTranslation(space)
        undoItem = _factories.ApiUndoItem(Transform.setTranslation, (self, new, space), (self, curr, space) )
        _factories.apiUndo.append( undoItem )

    @_factories.addApiDocs( _api.MFnTransform, 'setScale' )
    def setScale(self, scale, **kwargs):
        if self._isRelativeArg(kwargs):
            return self.scaleBy(scale, **kwargs)
        return self._setScale(scale)

    @_factories.addApiDocs( _api.MFnTransform, 'scaleBy' )
    def scaleBy(self, scale, **kwargs):
        curr = self.getScale()
        self._scaleBy(scale)
        new = self.getScale()
        undoItem = _factories.ApiUndoItem(Transform.setScale, (self, new), (self, curr) )
        _factories.apiUndo.append( undoItem )

    @_factories.addApiDocs( _api.MFnTransform, 'setShear' )
    def setShear(self, shear, **kwargs):
        if self._isRelativeArg(kwargs):
            return self.shearBy(shear, **kwargs)
        return self._setShear(shear)

    @_factories.addApiDocs( _api.MFnTransform, 'shearBy' )
    def shearBy(self, shear, **kwargs):
        curr = self.getShear()
        self._shearBy(shear)
        new = self.getShear()
        undoItem = _factories.ApiUndoItem(Transform.setShear, (self, new), (self, curr) )
        _factories.apiUndo.append( undoItem )


#    @_factories.queryflag('xform','rotatePivot')
#    def getRotatePivotOld( self, **kwargs ):
#        return datatypes.Vector( cmds.xform( self, **kwargs ) )

    @_factories.addApiDocs( _api.MFnTransform, 'setRotatePivot' )
    def setRotatePivot(self, point, space='object', balance=True, **kwargs):
        space = self._getSpaceArg(space, kwargs )
        return self._setRotatePivot(point, space=space, balance=balance)

    @_factories.addApiDocs( _api.MFnTransform, 'rotatePivot' )
    def getRotatePivot(self, space='object', **kwargs):
        space = self._getSpaceArg(space, kwargs )
        return self._getRotatePivot(space=space)

    @_factories.addApiDocs( _api.MFnTransform, 'setRotatePivotTranslation' )
    def setRotatePivotTranslation(self, vector, space='object', **kwargs):
        space = self._getSpaceArg(space, kwargs )
        return self._setRotatePivotTranslation(vector, space=space)

    @_factories.addApiDocs( _api.MFnTransform, 'rotatePivotTranslation' )
    def getRotatePivotTranslation(self, space='object', **kwargs):
        space = self._getSpaceArg(space, kwargs )
        return self._getRotatePivotTranslation(space=space)


#    @_factories.queryflag('xform','rotation')
#    def getRotationOld( self, **kwargs ):
#        return datatypes.Vector( cmds.xform( self, **kwargs ) )

    @_factories.addApiDocs( _api.MFnTransform, 'setRotation' )
    def setRotation(self, rotation, space='object', **kwargs):
        '''
    Modifications:
      - rotation may be given as an EulerRotation, Quaternion, or iterable of 3
        or 4 components (to specify an euler/quaternion, respectively)
        '''
        # quaternions are the only method that support a space parameter
        if self._isRelativeArg(kwargs):
            return self.rotateBy(rotation, space, **kwargs)
        spaceIndex =  datatypes.Spaces.getIndex(self._getSpaceArg(space, kwargs))

        if not isinstance(rotation, (_api.MQuaternion, _api.MEulerRotation)):
            rotation = list(rotation)
            if len(rotation) == 3:
                # using datatypes.Angle(x) means current angle-unit should be
                # respected
                rotation = [ datatypes.Angle( x ).asRadians() for x in rotation ]
                rotation = _api.MEulerRotation( *rotation )
            elif len(rotation) == 4:
                rotation = _api.MQuaternion(*rotation)
            else:
                raise ValueError("rotation given to setRotation must have either 3 or 4 elements (for euler or quaternion, respectively)")
        if isinstance(rotation, _api.MEulerRotation):
            # MFnTransform.setRotation doesn't have a (non-deprecated) override
            # which takes euler angles AND a transform space... this sort of
            # makes sense, since the "unique" information that euler angles can
            # potentially carry - ie, rotation > 360 degress - only really makes
            # sense within the "transform" space. So, only use EulerRotation if
            # we're using transform space...
            if datatypes.equivalentSpace(spaceIndex, _api.MSpace.kTransform,
                                         rotationOnly=True):
                self.__apimfn__().setRotation(rotation)
                return
            else:
                rotation = rotation.asQuaternion()
        self.__apimfn__().setRotation(rotation, spaceIndex )

#    @_factories.addApiDocs( _api.MFnTransform, 'getRotation' )
#    def getRotation(self, space='object', **kwargs):
#        # quaternions are the only method that support a space parameter
#        space = self._getSpaceArg(space, kwargs )
#        quat = _api.MQuaternion()
#        _api.MFnTransform(self.__apimfn__()).getRotation(quat, datatypes.Spaces.getIndex(space) )
#        return datatypes.EulerRotation( quat.asEulerRotation() )

    @_factories.addApiDocs( _api.MFnTransform, 'getRotation', overloadIndex=1 )
    def getRotation(self, space='object', quaternion=False, **kwargs):
        '''
    Modifications:
      - added 'quaternion' keyword arg, to specify whether the result
        be returned as a Quaternion object, as opposed to the default
        EulerRotation object
      - added 'space' keyword arg, which defaults to 'object'
        '''
        # quaternions are the only method that support a space parameter
        space = self._getSpaceArg(space, kwargs )
        if space.lower() in ('object', 'pretransform', 'transform') and not quaternion:
            # In this case, we can just go straight to the EulerRotation,
            # without having to go through Quaternion - this means we will
            # get information like angles > 360 degrees
            euler = _api.MEulerRotation()
            self.__apimfn__().getRotation(euler)
            rot = datatypes.EulerRotation(euler)
        else:
            rot = self._getRotation(space=space)
            if not quaternion:
                rot =  rot.asEulerRotation()
        if isinstance(rot, datatypes.EulerRotation):
            rot.setDisplayUnit( datatypes.Angle.getUIUnit() )
        return rot


    @_factories.addApiDocs( _api.MFnTransform, 'rotateBy' )
    def rotateBy(self, rotation, space='object', **kwargs):
        space = self._getSpaceArg(space, kwargs )
        curr = self.getRotation(space)
        self._rotateBy(rotation, space)
        new = self.getRotation(space)
        undoItem = _factories.ApiUndoItem(Transform.setRotation, (self, new, space), (self, curr, space) )
        _factories.apiUndo.append( undoItem )


#    @_factories.queryflag('xform','scalePivot')
#    def getScalePivotOld( self, **kwargs ):
#        return datatypes.Vector( cmds.xform( self, **kwargs ) )

    @_factories.addApiDocs( _api.MFnTransform, 'setScalePivot' )
    def setScalePivot(self, point, space='object', balance=True, **kwargs):
        space = self._getSpaceArg(space, kwargs )
        return self._setScalePivot(point, space=space, balance=balance)

    @_factories.addApiDocs( _api.MFnTransform, 'scalePivot' )
    def getScalePivot(self, space='object', **kwargs):
        space = self._getSpaceArg(space, kwargs )
        return self._getScalePivot(space=space)

    @_factories.addApiDocs( _api.MFnTransform, 'setScalePivotTranslation' )
    def setScalePivotTranslation(self, vector, space='object', **kwargs):
        space = self._getSpaceArg(space, kwargs )
        return self._setScalePivotTranslation(vector, space=space)

    @_factories.addApiDocs( _api.MFnTransform, 'scalePivotTranslation' )
    def getScalePivotTranslation(self, space='object', **kwargs):
        space = self._getSpaceArg(space, kwargs )
        return self._getScalePivotTranslation(space=space)

    @_factories.queryflag('xform','pivots')
    def getPivots( self, **kwargs ):
        res = cmds.xform( self, **kwargs )
        return ( datatypes.Vector( res[:3] ), datatypes.Vector( res[3:] )  )

    @_factories.queryflag('xform','rotateAxis')
    def getRotateAxis( self, **kwargs ):
        return datatypes.Vector( cmds.xform( self, **kwargs ) )

#    @_factories.queryflag('xform','shear')
#    def getShearOld( self, **kwargs ):
#        return datatypes.Vector( cmds.xform( self, **kwargs ) )

    @_factories.queryflag('xform','matrix')
    def getMatrix( self, **kwargs ):
        return datatypes.Matrix( cmds.xform( self, **kwargs ) )

    #TODO: create API equivalent of `xform -boundingBoxInvisible` so we can replace this with _api.
    def getBoundingBox(self, invisible=False, space='object'):
        """xform -boundingBox and xform -boundingBoxInvisible

        :rtype: `BoundingBox`


        """
        kwargs = {'query' : True }
        if invisible:
            kwargs['boundingBoxInvisible'] = True
        else:
            kwargs['boundingBox'] = True
        if space=='object':
            kwargs['objectSpace'] = True
        elif space=='world':
            kwargs['worldSpace'] = True
        else:
            raise ValueError('unknown space %r' % space)

        res = cmds.xform( self, **kwargs )
        #return ( datatypes.Vector(res[:3]), datatypes.Vector(res[3:]) )
        return datatypes.BoundingBox( res[:3], res[3:] )

    def getBoundingBoxMin(self, invisible=False, space='object'):
        """
        :rtype: `Vector`
        """
        return self.getBoundingBox(invisible, space)[0]
        #return self.getBoundingBox(invisible).min()

    def getBoundingBoxMax(self, invisible=False, space='object'):
        """
        :rtype: `Vector`
        """
        return self.getBoundingBox(invisible, space)[1]
        #return self.getBoundingBox(invisible).max()

#    def centerPivots(self, **kwargs):
#        """xform -centerPivots"""
#        kwargs['centerPivots'] = True
#        cmds.xform( self, **kwargs )
#
#    def zeroTransformPivots(self, **kwargs):
#        """xform -zeroTransformPivots"""
#        kwargs['zeroTransformPivots'] = True
#        cmds.xform( self, **kwargs )


class Joint(Transform):
    __metaclass__ = _factories.MetaMayaNodeWrapper
    connect = _factories.functionFactory( cmds.connectJoint, rename='connect')
    disconnect = _factories.functionFactory( cmds.disconnectJoint, rename='disconnect')
    insert = _factories.functionFactory( cmds.insertJoint, rename='insert')

if versions.isUnlimited():
    class FluidEmitter(Transform):
        __metaclass__ = _factories.MetaMayaNodeWrapper
        fluidVoxelInfo = _factories.functionFactory( cmds.fluidVoxelInfo, rename='fluidVoxelInfo')
        loadFluid = _factories.functionFactory( cmds.loadFluid, rename='loadFluid')
        resampleFluid = _factories.functionFactory( cmds.resampleFluid, rename='resampleFluid')
        saveFluid = _factories.functionFactory( cmds.saveFluid, rename='saveFluid')
        setFluidAttr = _factories.functionFactory( cmds.setFluidAttr, rename='setFluidAttr')
        getFluidAttr = _factories.functionFactory( cmds.getFluidAttr, rename='getFluidAttr')

class RenderLayer(DependNode):
    def listMembers(self, fullNames=True):
        if fullNames:
            return map( general.PyNode, _util.listForNone( cmds.editRenderLayerMembers( self, q=1, fullNames=True) ) )
        else:
            return _util.listForNone( cmds.editRenderLayerMembers( self, q=1, fullNames=False) )

    def addMembers(self, members, noRecurse=True):
        cmds.editRenderLayerMembers( self, members, noRecurse=noRecurse )

    def removeMembers(self, members ):
        cmds.editRenderLayerMembers( self, members, remove=True )

    def listAdjustments(self):
        return map( general.PyNode, _util.listForNone( cmds.editRenderLayerAdjustment( self, layer=1, q=1) ) )

    def addAdjustments(self, members):
        return cmds.editRenderLayerAdjustment( members, layer=self )

    def removeAdjustments(self, members ):
        return cmds.editRenderLayerAdjustment( members, layer=self, remove=True )

    def setCurrent(self):
        cmds.editRenderLayerGlobals( currentRenderLayer=self)

class DisplayLayer(DependNode):
    def listMembers(self, fullNames=True):
        if fullNames:
            return map( general.PyNode, _util.listForNone( cmds.editDisplayLayerMembers( self, q=1, fullNames=True) ) )
        else:
            return _util.listForNone( cmds.editDisplayLayerMembers( self, q=1, fullNames=False) )

    def addMembers(self, members, noRecurse=True):
        cmds.editDisplayLayerMembers( self, members, noRecurse=noRecurse )

    def removeMembers(self, members ):
        cmds.editDisplayLayerMembers( self, members, remove=True )

    def setCurrent(self):
        cmds.editDisplayLayerMembers( currentDisplayLayer=self)

class Constraint(Transform):
    def setWeight( self, weight, *targetObjects ):
        inFunc = getattr( cmds, self.type() )
        if not targetObjects:
            targetObjects = self.getTargetList()

        constraintObj = self.constraintParentInverseMatrix.inputs()[0]
        args = list(targetObjects) + [constraintObj]
        return inFunc(  *args, **{'edit':True, 'weight':weight} )

    def getWeight( self, *targetObjects ):
        inFunc = getattr( cmds, self.type() )
        if not targetObjects:
            targetObjects = self.getTargetList()

        constraintObj = self.constraintParentInverseMatrix.inputs()[0]
        args = list(targetObjects) + [constraintObj]
        return inFunc(  *args, **{'query':True, 'weight':True} )

class GeometryShape(Shape):
    def __getattr__(self, attr):
        #print "Mesh.__getattr__", attr
        try:
            return self.comp(attr)
        except general.MayaComponentError:
            #print "getting super", attr
            return super(GeometryShape,self).__getattr__(attr)

class DeformableShape(GeometryShape):
    @classmethod
    def _numCVsFunc_generator(cls, formFunc, spansPlusDegreeFunc, spansFunc,
                              name=None, doc=None):
        """
        Intended to be used by NurbsCurve / NurbsSurface to generate
        functions which give the 'true' number of editable CVs,
        as opposed to just numSpans + degree.
        (The two values will differ if we have a periodic curve).

        Note that this will usually need to be called outside/after the
        class definition, as formFunc/spansFunc/etc will not be defined
        until then, as they are added by the metaclass.
        """
        def _numCvs_generatedFunc(self, editableOnly=True):
            if editableOnly and formFunc(self) == self.Form.periodic:
                return spansFunc(self)
            else:
                return spansPlusDegreeFunc(self)
        if name:
            _numCvs_generatedFunc.__name__ = name
        if doc:
            _numCvs_generatedFunc.__doc__ = doc
        return _numCvs_generatedFunc

    @classmethod
    def _numEPsFunc_generator(cls, formFunc, spansFunc,
                              name=None, doc=None):
        """
        Intended to be used by NurbsCurve / NurbsSurface to generate
        functions which give the 'true' number of editable EPs,
        as opposed to just numSpans.
        (The two values will differ if we have a periodic curve).

        Note that this will usually need to be called outside/after the
        class definition, as formFunc/spansFunc will not be defined
        until then, as they are added by the metaclass.
        """
        def _numEPs_generatedFunc(self, editableOnly=True):
            if editableOnly and formFunc(self) == self.Form.periodic:
                return spansFunc(self)
            else:
                return spansFunc(self) + 1
        if name:
            _numEPs_generatedFunc.__name__ = name
        if doc:
            _numEPs_generatedFunc.__doc__ = doc
        return _numEPs_generatedFunc

class ControlPoint(DeformableShape): pass
class CurveShape(DeformableShape): pass
class NurbsCurve(CurveShape):
    __metaclass__ = _factories.MetaMayaNodeWrapper
    _componentAttributes = {'u'           : general.NurbsCurveParameter,
                            'cv'          : general.NurbsCurveCV,
                            'controlVerts': general.NurbsCurveCV,
                            'ep'          : general.NurbsCurveEP,
                            'editPoints'  : general.NurbsCurveEP,
                            'knot'        : general.NurbsCurveKnot,
                            'knots'       : general.NurbsCurveKnot}

# apiToMelBridge maps MFnNurbsCurve.numCVs => NurbsCurve._numCVsApi
NurbsCurve.numCVs = \
    NurbsCurve._numCVsFunc_generator(NurbsCurve.form,
                                     NurbsCurve._numCVsApi,
                                     NurbsCurve.numSpans,
                                     name='numCVs',
                                     doc =
        """
        Returns the number of CVs.

        :Parameters:
        editableOnly : `bool`
            If editableOnly evaluates to True (default), then this will return
            the number of cvs that can be actually edited (and also the highest
            index that may be used for cv's - ie, if
                myCurve.numCVs(editableOnly=True) == 4
            then allowable cv indices go from
                myCurve.cv[0] to mySurf.cv[3]

            If editablyOnly is False, then this will return the underlying
            number of cvs used to define the mathematical curve -
            degree + numSpans.

            These will only differ if the form is 'periodic', in which
            case the editable number will be numSpans (as the last 'degree'
            cv's are 'locked' to be the same as the first 'degree' cvs).
            In all other cases, the number of cvs will be degree + numSpans.

        :Examples:
            >>> from pymel.core import *
            >>> # a periodic curve
            >>> myCurve = curve(name='periodicCurve1', d=3, periodic=True, k=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), pw=[(4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (0, 5.5, 0, 1), (-4, 4, 0, 1), (-5.5, 0, 0, 1), (-4, -4, 0, 1), (0, -5.5, 0, 1), (4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1)] )
            >>> myCurve.cv
            NurbsCurveCV(u'periodicCurveShape1.cv[0:7]')
            >>> myCurve.numCVs()
            8
            >>> myCurve.numCVs(editableOnly=False)
            11
            >>>
            >>> # an open curve
            >>> myCurve = curve(name='openCurve1', d=3, periodic=False, k=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), pw=[(4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (0, 5.5, 0, 1), (-4, 4, 0, 1), (-5.5, 0, 0, 1), (-4, -4, 0, 1), (0, -5.5, 0, 1), (4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1)] )
            >>> myCurve.cv
            NurbsCurveCV(u'openCurveShape1.cv[0:10]')
            >>> myCurve.numCVs()
            11
            >>> myCurve.numCVs(editableOnly=False)
            11

        :rtype: `int`
        """)

NurbsCurve.numEPs = \
    NurbsCurve._numEPsFunc_generator(NurbsCurve.form,
                                       NurbsCurve.numSpans,
                                       name='numEPs',
                                       doc =
        """
        Returns the number of EPs.

        :Examples:
            >>> from pymel.core import *
            >>> # a periodic curve
            >>> myCurve = curve(name='periodicCurve2', d=3, periodic=True, k=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), pw=[(4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (0, 5.5, 0, 1), (-4, 4, 0, 1), (-5.5, 0, 0, 1), (-4, -4, 0, 1), (0, -5.5, 0, 1), (4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1)] )
            >>> myCurve.ep
            NurbsCurveEP(u'periodicCurveShape2.ep[0:7]')
            >>> myCurve.numEPs()
            8
            >>>
            >>> # an open curve
            >>> myCurve = curve(name='openCurve2', d=3, periodic=False, k=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), pw=[(4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (0, 5.5, 0, 1), (-4, 4, 0, 1), (-5.5, 0, 0, 1), (-4, -4, 0, 1), (0, -5.5, 0, 1), (4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1)] )
            >>> myCurve.ep
            NurbsCurveEP(u'openCurveShape2.ep[0:8]')
            >>> myCurve.numEPs()
            9

        :rtype: `int`
        """)



class SurfaceShape(ControlPoint): pass

class NurbsSurface(SurfaceShape):
    __metaclass__ = _factories.MetaMayaNodeWrapper
    _componentAttributes = {'u'           : (general.NurbsSurfaceRange, 'u'),
                            'uIsoparm'    : (general.NurbsSurfaceRange, 'u'),
                            'v'           : (general.NurbsSurfaceRange, 'v'),
                            'vIsoparm'    : (general.NurbsSurfaceRange, 'v'),
                            'uv'          : (general.NurbsSurfaceRange, 'uv'),
                            'cv'          : general.NurbsSurfaceCV,
                            'controlVerts': general.NurbsSurfaceCV,
                            'ep'          : general.NurbsSurfaceEP,
                            'editPoints'  : general.NurbsSurfaceEP,
                            'knot'        : general.NurbsSurfaceKnot,
                            'knots'       : general.NurbsSurfaceKnot,
                            'sf'          : general.NurbsSurfaceFace,
                            'faces'       : general.NurbsSurfaceFace}

# apiToMelBridge maps MFnNurbsCurve._numCVsInU => NurbsCurve._numCVsInUApi
NurbsSurface.numCVsInU = \
    NurbsSurface._numCVsFunc_generator(NurbsSurface.formInU,
                                       NurbsSurface._numCVsInUApi,
                                       NurbsSurface.numSpansInU,
                                       name='numCVsInU',
                                       doc =
        """
        Returns the number of CVs in the U direction.

        :Parameters:
        editableOnly : `bool`
            If editableOnly evaluates to True (default), then this will return
            the number of cvs that can be actually edited (and also the highest
            index that may be used for u - ie, if
                mySurf.numCVsInU(editableOnly=True) == 4
            then allowable u indices go from
                mySurf.cv[0][*] to mySurf.cv[3][*]

            If editablyOnly is False, then this will return the underlying
            number of cvs used to define the mathematical curve in u -
            degreeU + numSpansInU.

            These will only differ if the form in u is 'periodic', in which
            case the editable number will be numSpansInU (as the last 'degree'
            cv's are 'locked' to be the same as the first 'degree' cvs).
            In all other cases, the number of cvs will be degreeU + numSpansInU.

        :Examples:
            >>> from pymel.core import *
            >>> # a periodic surface
            >>> mySurf = surface(name='periodicSurf1', du=3, dv=1, fu='periodic', fv='open', ku=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), kv=(0, 1), pw=[(4, -4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, 0, 1), (5.5, 0, -2.5, 1), (4, 4, 0, 1), (4, 4, -2.5, 1), (0, 5.5, 0, 1), (0, 5.5, -2.5, 1), (-4, 4, 0, 1), (-4, 4, -2.5, 1), (-5.5, 0, 0, 1), (-5.5, 0, -2.5, 1), (-4, -4, 0, 1), (-4, -4, -2.5, 1), (0, -5.5, 0, 1), (0, -5.5, -2.5, 1), (4, -4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, 0, 1), (5.5, 0, -2.5, 1), (4, 4, 0, 1), (4, 4, -2.5, 1)] )
            >>> sorted(mySurf.cv[:][0].indices())        # doctest: +ELLIPSIS
            [ComponentIndex((0, 0), ... ComponentIndex((7, 0), label=None)]
            >>> mySurf.numCVsInU()
            8
            >>> mySurf.numCVsInU(editableOnly=False)
            11
            >>>
            >>> # an open surface
            >>> mySurf = surface(name='openSurf1', du=3, dv=1, fu='open', fv='open', ku=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), kv=(0, 1), pw=((4, -4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, 0, 1), (5.5, 0, -2.5, 1), (4, 4, 0, 1), (4, 4, -2.5, 1), (0, 5.5, 0, 1), (0, 5.5, -2.5, 1), (-4, 4, 0, 1), (-4, 4, -2.5, 1), (-5.5, 0, 0, 1), (-5.5, 0, -2.5, 1), (-4, -4, 0, 1), (-4, -4, -2.5, 1), (0, -5.5, 0, 1), (0, -5.5, -2.5, 1), (4, -4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, 0, 1), (5.5, 0, -2.5, 1), (4, 4, 0, 1), (4, 4, -2.5, 1)) )
            >>> sorted(mySurf.cv[:][0].indices())        # doctest: +ELLIPSIS
            [ComponentIndex((0, 0), ... ComponentIndex((10, 0), label=None)]
            >>> mySurf.numCVsInU()
            11
            >>> mySurf.numCVsInU(editableOnly=False)
            11

        :rtype: `int`
        """)

# apiToMelBridge maps MFnNurbsCurve._numCVsInV => NurbsCurve._numCVsInVApi
NurbsSurface.numCVsInV = \
    NurbsSurface._numCVsFunc_generator(NurbsSurface.formInV,
                                       NurbsSurface._numCVsInVApi,
                                       NurbsSurface.numSpansInV,
                                       name='numCVsInV',
                                       doc =
        """
        Returns the number of CVs in the V direction.

        :Parameters:
        editableOnly : `bool`
            If editableOnly evaluates to True (default), then this will return
            the number of cvs that can be actually edited (and also the highest
            index that may be used for v - ie, if
                mySurf.numCVsInV(editableOnly=True) == 4
            then allowable v indices go from
                mySurf.cv[*][0] to mySurf.cv[*][3]

            If editablyOnly is False, then this will return the underlying
            number of cvs used to define the mathematical curve in v -
            degreeV + numSpansInV.

            These will only differ if the form in v is 'periodic', in which
            case the editable number will be numSpansInV (as the last 'degree'
            cv's are 'locked' to be the same as the first 'degree' cvs).
            In all other cases, the number of cvs will be degreeV + numSpansInV.

        :Examples:
            >>> from pymel.core import *
            >>> # a periodic surface
            >>> mySurf = surface(name='periodicSurf2', du=1, dv=3, fu='open', fv='periodic', ku=(0, 1), kv=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), pw=[(4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (0, 5.5, 0, 1), (-4, 4, 0, 1), (-5.5, 0, 0, 1), (-4, -4, 0, 1), (0, -5.5, 0, 1), (4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, -2.5, 1), (4, 4, -2.5, 1), (0, 5.5, -2.5, 1), (-4, 4, -2.5, 1), (-5.5, 0, -2.5, 1), (-4, -4, -2.5, 1), (0, -5.5, -2.5, 1), (4, -4, -2.5, 1), (5.5, 0, -2.5, 1), (4, 4, -2.5, 1)] )
            >>> sorted(mySurf.cv[0].indices())         # doctest: +ELLIPSIS
            [ComponentIndex((0, 0), ... ComponentIndex((0, 7), label='cv')]
            >>> mySurf.numCVsInV()
            8
            >>> mySurf.numCVsInV(editableOnly=False)
            11
            >>>
            >>> # an open surface
            >>> mySurf = surface(name='openSurf2', du=1, dv=3, fu='open', fv='open', ku=(0, 1), kv=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), pw=[(4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (0, 5.5, 0, 1), (-4, 4, 0, 1), (-5.5, 0, 0, 1), (-4, -4, 0, 1), (0, -5.5, 0, 1), (4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, -2.5, 1), (4, 4, -2.5, 1), (0, 5.5, -2.5, 1), (-4, 4, -2.5, 1), (-5.5, 0, -2.5, 1), (-4, -4, -2.5, 1), (0, -5.5, -2.5, 1), (4, -4, -2.5, 1), (5.5, 0, -2.5, 1), (4, 4, -2.5, 1)] )
            >>> sorted(mySurf.cv[0].indices())          # doctest: +ELLIPSIS
            [ComponentIndex((0, 0), ... ComponentIndex((0, 10), label='cv')]
            >>> mySurf.numCVsInV()
            11
            >>> mySurf.numCVsInV(editableOnly=False)
            11

        :rtype: `int`
        """)

NurbsSurface.numEPsInU = \
    NurbsSurface._numEPsFunc_generator(NurbsSurface.formInU,
                                       NurbsSurface.numSpansInU,
                                       name='numEPsInU',
                                       doc =
        """
        Returns the number of EPs in the U direction.

        :Examples:
            >>> from pymel.core import *
            >>> # a periodic surface
            >>> mySurf = surface(name='periodicSurf3', du=3, dv=1, fu='periodic', fv='open', ku=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), kv=(0, 1), pw=[(4, -4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, 0, 1), (5.5, 0, -2.5, 1), (4, 4, 0, 1), (4, 4, -2.5, 1), (0, 5.5, 0, 1), (0, 5.5, -2.5, 1), (-4, 4, 0, 1), (-4, 4, -2.5, 1), (-5.5, 0, 0, 1), (-5.5, 0, -2.5, 1), (-4, -4, 0, 1), (-4, -4, -2.5, 1), (0, -5.5, 0, 1), (0, -5.5, -2.5, 1), (4, -4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, 0, 1), (5.5, 0, -2.5, 1), (4, 4, 0, 1), (4, 4, -2.5, 1)] )
            >>> sorted(mySurf.ep[:][0].indices())      # doctest: +ELLIPSIS
            [ComponentIndex((0, 0), ... ComponentIndex((7, 0), label=None)]
            >>> mySurf.numEPsInU()
            8
            >>>
            >>> # an open surface
            >>> mySurf = surface(name='openSurf3', du=3, dv=1, fu='open', fv='open', ku=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), kv=(0, 1), pw=[(4, -4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, 0, 1), (5.5, 0, -2.5, 1), (4, 4, 0, 1), (4, 4, -2.5, 1), (0, 5.5, 0, 1), (0, 5.5, -2.5, 1), (-4, 4, 0, 1), (-4, 4, -2.5, 1), (-5.5, 0, 0, 1), (-5.5, 0, -2.5, 1), (-4, -4, 0, 1), (-4, -4, -2.5, 1), (0, -5.5, 0, 1), (0, -5.5, -2.5, 1), (4, -4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, 0, 1), (5.5, 0, -2.5, 1), (4, 4, 0, 1), (4, 4, -2.5, 1)] )
            >>> sorted(mySurf.ep[:][0].indices())      # doctest: +ELLIPSIS
            [ComponentIndex((0, 0), ... ComponentIndex((8, 0), label=None)]
            >>> mySurf.numEPsInU()
            9

        :rtype: `int`
        """)

NurbsSurface.numEPsInV = \
    NurbsSurface._numEPsFunc_generator(NurbsSurface.formInV,
                                       NurbsSurface.numSpansInV,
                                       name='numEPsInV',
                                       doc =
        """
        Returns the number of EPs in the V direction.

        :Examples:
            >>> from pymel.core import *
            >>> # a periodic surface
            >>> mySurf = surface(name='periodicSurf4', du=1, dv=3, fu='open', fv='periodic', ku=(0, 1), kv=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), pw=[(4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (0, 5.5, 0, 1), (-4, 4, 0, 1), (-5.5, 0, 0, 1), (-4, -4, 0, 1), (0, -5.5, 0, 1), (4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, -2.5, 1), (4, 4, -2.5, 1), (0, 5.5, -2.5, 1), (-4, 4, -2.5, 1), (-5.5, 0, -2.5, 1), (-4, -4, -2.5, 1), (0, -5.5, -2.5, 1), (4, -4, -2.5, 1), (5.5, 0, -2.5, 1), (4, 4, -2.5, 1)] )
            >>> sorted(mySurf.ep[0][:].indices())      # doctest: +ELLIPSIS
            [ComponentIndex((0, 0), ... ComponentIndex((0, 7), label=None)]
            >>> mySurf.numEPsInV()
            8
            >>>
            >>> # an open surface
            >>> mySurf = surface(name='openSurf4', du=1, dv=3, fu='open', fv='open', ku=(0, 1), kv=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), pw=[(4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (0, 5.5, 0, 1), (-4, 4, 0, 1), (-5.5, 0, 0, 1), (-4, -4, 0, 1), (0, -5.5, 0, 1), (4, -4, 0, 1), (5.5, 0, 0, 1), (4, 4, 0, 1), (4, -4, -2.5, 1), (5.5, 0, -2.5, 1), (4, 4, -2.5, 1), (0, 5.5, -2.5, 1), (-4, 4, -2.5, 1), (-5.5, 0, -2.5, 1), (-4, -4, -2.5, 1), (0, -5.5, -2.5, 1), (4, -4, -2.5, 1), (5.5, 0, -2.5, 1), (4, 4, -2.5, 1)] )
            >>> sorted(mySurf.ep[0][:].indices())      # doctest: +ELLIPSIS
            [ComponentIndex((0, 0), ... ComponentIndex((0, 8), label=None)]
            >>> mySurf.numEPsInV()
            9

        :rtype: `int`
        """)


class Mesh(SurfaceShape):
    """
    The Mesh class provides wrapped access to many API methods for querying and modifying meshes.  Be aware that
    modifying meshes using API commands outside of the context of a plugin is still somewhat uncharted territory,
    so proceed at our own risk.


    The component types can be accessed from the `Mesh` type (or it's transform) using the names you are
    familiar with from MEL:

        >>> from pymel.core import *
        >>> p = polySphere( name='theMoon', sa=7, sh=7 )[0]
        >>> p.vtx
        MeshVertex(u'theMoonShape.vtx[0:43]')
        >>> p.e
        MeshEdge(u'theMoonShape.e[0:90]')
        >>> p.f
        MeshFace(u'theMoonShape.f[0:48]')

    They are also accessible from their more descriptive alternatives:

        >>> p.verts
        MeshVertex(u'theMoonShape.vtx[0:43]')
        >>> p.edges
        MeshEdge(u'theMoonShape.e[0:90]')
        >>> p.faces
        MeshFace(u'theMoonShape.f[0:48]')

    As you'd expect, these components are all indexible:

        >>> p.vtx[0]
        MeshVertex(u'theMoonShape.vtx[0]')

    The classes themselves contain methods for getting information about the component.

        >>> p.vtx[0].connectedEdges()
        MeshEdge(u'theMoonShape.e[0,6,42,77]')

    This class provides support for python's extended slice notation. Typical maya ranges express a start and stop value separated
    by a colon.  Extended slices add a step parameter and can also represent multiple ranges separated by commas.
    Thus, a single component object can represent any collection of indices.

    This includes start, stop, and step values.

        >>> # do every other edge between 0 and 10
        >>> for edge in p.e[0:10:2]:
        ...     print edge
        ...
        theMoonShape.e[0]
        theMoonShape.e[2]
        theMoonShape.e[4]
        theMoonShape.e[6]
        theMoonShape.e[8]
        theMoonShape.e[10]

    Negative indices can be used for getting indices relative to the end:

        >>> p.edges  # the full range
        MeshEdge(u'theMoonShape.e[0:90]')
        >>> p.edges[5:-10]  # index 5 through to 10 from the last
        MeshEdge(u'theMoonShape.e[5:80]')

    Just like with python ranges, you can leave an index out, and the logical result will follow:

        >>> p.edges[:-10]  # from the beginning
        MeshEdge(u'theMoonShape.e[0:80]')
        >>> p.edges[20:]
        MeshEdge(u'theMoonShape.e[20:90]')

    Or maybe you want the position of every tenth vert:

        >>> for x in p.vtx[::10]:
        ...     print x, x.getPosition()
        ...
        theMoonShape.vtx[0] [0.270522117615, -0.900968849659, -0.339223951101]
        theMoonShape.vtx[10] [-0.704405844212, -0.623489797115, 0.339223951101]
        theMoonShape.vtx[20] [0.974927902222, -0.222520858049, 0.0]
        theMoonShape.vtx[30] [-0.704405784607, 0.623489797115, -0.339224010706]
        theMoonShape.vtx[40] [0.270522087812, 0.900968849659, 0.339223980904]


    To be compatible with Maya's range notation, these slices are inclusive of the stop index.

        >>> # face at index 8 will be included in the sequence
        >>> for f in p.f[4:8]: print f
        ...
        theMoonShape.f[4]
        theMoonShape.f[5]
        theMoonShape.f[6]
        theMoonShape.f[7]
        theMoonShape.f[8]

    >>> from pymel.core import *
    >>> obj = polyTorus()[0]
    >>> colors = []
    >>> for i, vtx in enumerate(obj.vtx):   # doctest: +SKIP
    ...     edgs=vtx.toEdges()              # doctest: +SKIP
    ...     totalLen=0                      # doctest: +SKIP
    ...     edgCnt=0                        # doctest: +SKIP
    ...     for edg in edgs:                # doctest: +SKIP
    ...         edgCnt += 1                 # doctest: +SKIP
    ...         l = edg.getLength()         # doctest: +SKIP
    ...         totalLen += l               # doctest: +SKIP
    ...     avgLen=totalLen / edgCnt        # doctest: +SKIP
    ...     #print avgLen                   # doctest: +SKIP
    ...     currColor = vtx.getColor(0)     # doctest: +SKIP
    ...     color = datatypes.Color.black   # doctest: +SKIP
    ...     # only set blue if it has not been set before
    ...     if currColor.b<=0.0:            # doctest: +SKIP
    ...         color.b = avgLen            # doctest: +SKIP
    ...     color.r = avgLen                # doctest: +SKIP
    ...     colors.append(color)            # doctest: +SKIP


    """
    __metaclass__ = _factories.MetaMayaNodeWrapper
#    def __init__(self, *args, **kwargs ):
#        SurfaceShape.__init__(self, self._apiobject )
#        self.vtx = MeshEdge(self.__apimobject__() )
    _componentAttributes = {'vtx'   : general.MeshVertex,
                            'verts' : general.MeshVertex,
                            'e'     : general.MeshEdge,
                            'edges' : general.MeshEdge,
                            'f'     : general.MeshFace,
                            'faces' : general.MeshFace,
                            'map'   : general.MeshUV,
                            'uvs'   : general.MeshUV,
                            'vtxFace'   : general.MeshVertexFace,
                            'faceVerts' : general.MeshVertexFace}

    # Unfortunately, objects that don't yet have any mesh data - ie, if you do
    # createNode('mesh') - can't be fed into MFnMesh (even though it is a mesh
    # node).  This means that all the methods wrapped from MFnMesh won't be
    # usable in this case.  While it might make sense for some methods - ie,
    # editing methods like collapseEdges - to fail in this situation, some
    # basic methods like numVertices should still be usable.  Therefore,
    # we override some of these with the mel versions (which still work...)
    numVertices = _factories.makeCreateFlagMethod( cmds.polyEvaluate, 'vertex', 'numVertices' )
    numEdges = _factories.makeCreateFlagMethod( cmds.polyEvaluate, 'edge', 'numEdges' )
    numFaces = _factories.makeCreateFlagMethod( cmds.polyEvaluate, 'face', 'numFaces' )

    numTriangles = _factories.makeCreateFlagMethod( cmds.polyEvaluate, 'triangles', 'numTriangles' )
    numSelectedTriangles = _factories.makeCreateFlagMethod( cmds.polyEvaluate, 'triangleComponent', 'numSelectedTriangles' )
    numSelectedFaces = _factories.makeCreateFlagMethod( cmds.polyEvaluate, 'faceComponent', 'numSelectedFaces' )
    numSelectedEdges = _factories.makeCreateFlagMethod( cmds.polyEvaluate, 'edgeComponent', 'numSelectedEdges' )
    numSelectedVertices = _factories.makeCreateFlagMethod( cmds.polyEvaluate, 'vertexComponent', 'numSelectedVertices' )

    area = _factories.makeCreateFlagMethod( cmds.polyEvaluate, 'area'  )
    worldArea = _factories.makeCreateFlagMethod( cmds.polyEvaluate, 'worldArea' )

    if versions.current() >= versions.v2009:
        @_factories.addApiDocs( _api.MFnMesh, 'currentUVSetName' )
        def getCurrentUVSetName(self):
            return self.__apimfn__().currentUVSetName( self.instanceNumber() )

        @_factories.addApiDocs( _api.MFnMesh, 'currentColorSetName' )
        def getCurrentColorSetName(self):
            return self.__apimfn__().currentColorSetName( self.instanceNumber() )

    else:
        @_factories.addApiDocs( _api.MFnMesh, 'currentUVSetName' )
        def getCurrentUVSetName(self):
            return self.__apimfn__().currentUVSetName()

        @_factories.addApiDocs( _api.MFnMesh, 'currentColorSetName' )
        def getCurrentColorSetName(self):
            return self.__apimfn__().currentColorSetName()

    @_factories.addApiDocs( _api.MFnMesh, 'numColors' )
    def numColors(self, colorSet=None):
        mfn = self.__apimfn__()
        # If we have an empty mesh, we will get an MFnDagNode...
        if not isinstance(mfn, _api.MFnMesh):
            return 0
        args = []
        if colorSet:
            args.append(colorSet)
        return mfn.numColors(*args)

# Unfortunately, objects that don't yet have any mesh data - ie, if you do
# createNode('mesh') - can't be fed into MFnMesh (even though it is a mesh
# node).  This means that all the methods wrapped from MFnMesh won't be
# usable in this case.  While it might make sense for some methods - ie,
# editing methods like collapseEdges - to fail in this situation, some
# basic methods like numVertices should still be usable.  Therefore,
# we override some of these with the mel versions (which still work...)

def _makeApiMethodWrapForEmptyMesh(apiMethodName, baseMethodName=None,
                                   resultName=None, defaultVal=0):
    if baseMethodName is None:
        baseMethodName = '_' + apiMethodName
    if resultName is None:
        resultName = apiMethodName

    baseMethod = getattr(Mesh, baseMethodName)

    @_factories.addApiDocs( _api.MFnMesh, apiMethodName )
    def methodWrapForEmptyMesh(self, *args, **kwargs):
        # If we have an empty mesh, we will get an MFnDagNode...
        mfn = self.__apimfn__()
        if not isinstance(mfn, _api.MFnMesh):
            return defaultVal
        return baseMethod(self, *args, **kwargs)
    methodWrapForEmptyMesh.__name__ = resultName
    return methodWrapForEmptyMesh

for _apiMethodName in '''numColorSets
                    numFaceVertices
                    numNormals
                    numUVSets
                    numUVs'''.split():
    _wrappedFunc = _makeApiMethodWrapForEmptyMesh(_apiMethodName)
    setattr(Mesh, _wrappedFunc.__name__, _wrappedFunc)

class Subdiv(SurfaceShape):
    __metaclass__ = _factories.MetaMayaNodeWrapper

    _componentAttributes = {'smp'   : general.SubdVertex,
                            'verts' : general.SubdVertex,
                            'sme'   : general.SubdEdge,
                            'edges' : general.SubdEdge,
                            'smf'   : general.SubdFace,
                            'faces' : general.SubdFace,
                            'smm'   : general.SubdUV,
                            'uvs'   : general.SubdUV}

    def getTweakedVerts(self, **kwargs):
        return cmds.querySubdiv( action=1, **kwargs )

    def getSharpenedVerts(self, **kwargs):
        return cmds.querySubdiv( action=2, **kwargs )

    def getSharpenedEdges(self, **kwargs):
        return cmds.querySubdiv( action=3, **kwargs )

    def getEdges(self, **kwargs):
        return cmds.querySubdiv( action=4, **kwargs )

    def cleanTopology(self):
        cmds.subdCleanTopology(self)

class Lattice(ControlPoint):
    __metaclass__ = _factories.MetaMayaNodeWrapper
    _componentAttributes = {'pt'    : general.LatticePoint,
                            'points': general.LatticePoint}

class Particle(DeformableShape):
    __apicls__ = _api.MFnParticleSystem
    __metaclass__ = _factories.MetaMayaNodeWrapper
    _componentAttributes = {'pt'    : general.ParticleComponent,
                            'points': general.ParticleComponent}
    # for backwards compatibility
    Point = general.ParticleComponent

    # for backwards compatibility, keep these two, even though the api wrap
    # will also provide 'count'
    def pointCount(self):
        return cmds.particle( self, q=1,count=1)
    num = pointCount

class SelectionSet( _api.MSelectionList):
    apicls = _api.MSelectionList
    __metaclass__ = _factories.MetaMayaTypeWrapper

    def __init__(self, objs):
        """ can be initialized from a list of objects, another SelectionSet, an MSelectionList, or an ObjectSet"""
        if isinstance(objs, _api.MSelectionList ):
            _api.MSelectionList.__init__(self, objs)

        elif isinstance(objs, ObjectSet ):
            _api.MSelectionList.__init__(self, objs.asSelectionSet() )

        else:
            _api.MSelectionList.__init__(self)
            for obj in objs:
                if isinstance(obj, (DependNode, DagNode) ):
                    self.apicls.add( self, obj.__apiobject__() )
                elif isinstance(obj, general.Attribute):
                    self.apicls.add( self, obj.__apiobject__(), True )
    #            elif isinstance(obj, Component):
    #                sel.add( obj.__apiobject__(), True )
                elif isinstance( obj, basestring ):
                    self.apicls.add( self, obj )
                else:
                    raise TypeError

    def __melobject__(self):
        # If the list contains components, THEIR __melobject__ is a list -
        # so need to iterate through, and flatten if needed
        melList = []
        for selItem in self:
            selItem = selItem.__melobject__()
            if _util.isIterable(selItem):
                melList.extend(selItem)
            else:
                melList.append(selItem)
        return melList

    def __len__(self):
        """:rtype: `int` """
        return self.apicls.length(self)

    def __contains__(self, item):
        """:rtype: `bool` """
        if isinstance(item, (DependNode, DagNode, general.Attribute) ):
            return self.apicls.hasItem(self, item.__apiobject__())
        elif isinstance(item, general.Component):
            raise NotImplementedError, 'Components not yet supported'
        else:
            return self.apicls.hasItem(self, general.PyNode(item).__apiobject__())

    def __repr__(self):
        """:rtype: `str` """
        names = []
        self.apicls.getSelectionStrings( self, names )
        return 'nt.%s(%s)' % ( self.__class__.__name__, names )


    def __getitem__(self, index):
        """:rtype: `PyNode` """
        if index >= len(self):
            raise IndexError, "index out of range"

        plug = _api.MPlug()
        obj = _api.MObject()
        dag = _api.MDagPath()
        comp = _api.MObject()

        # Go from most specific to least - plug, dagPath, dependNode
        try:
            self.apicls.getPlug( self, index, plug )
            assert not plug.isNull()
        except (RuntimeError, AssertionError):
            try:
                self.apicls.getDagPath( self, index, dag, comp )
            except RuntimeError:
                try:
                    self.apicls.getDependNode( self, index, obj )
                    return general.PyNode( obj )
                except:
                    pass
            else:
                if comp.isNull():
                    return general.PyNode( dag )
                else:
                    return general.PyNode( dag, comp )
        else:
            return general.PyNode( plug )


    def __setitem__(self, index, item):

        if isinstance(item, (DependNode, DagNode, general.Attribute) ):
            return self.apicls.replace(self, index, item.__apiobject__())
        elif isinstance(item, general.Component):
            raise NotImplementedError, 'Components not yet supported'
        else:
            return self.apicls.replace(self, general.PyNode(item).__apiobject__())

    def __and__(self, s):
        "operator for `SelectionSet.getIntersection`"
        return self.getIntersection(s)

    def __iand__(self, s):
        "operator for `SelectionSet.intersection`"
        return self.intersection(s)

    def __or__(self, s):
        "operator for `SelectionSet.getUnion`"
        return self.getUnion(s)

    def __ior__(self, s):
        "operator for `SelectionSet.union`"
        return self.union(s)

    def __lt__(self, s):
        "operator for `SelectionSet.isSubSet`"
        return self.isSubSet(s)

    def __gt__(self, s):
        "operator for `SelectionSet.isSuperSet`"
        return self.isSuperSet(s)

    def __sub__(self, s):
        "operator for `SelectionSet.getDifference`"
        return self.getDifference(s)

    def __isub__(self, s):
        "operator for `SelectionSet.difference`"
        return self.difference(s)

    def __xor__(self, s):
        "operator for `SelectionSet.symmetricDifference`"
        return self.getSymmetricDifference(s)

    def __ixor__(self, s):
        "operator for `SelectionSet.symmetricDifference`"
        return self.symmetricDifference(s)

    def add(self, item):

        if isinstance(item, (DependNode, DagNode, general.Attribute) ):
            return self.apicls.add(self, item.__apiobject__())
        elif isinstance(item, general.Component):
            raise NotImplementedError, 'Components not yet supported'
        else:
            return self.apicls.add(self, general.PyNode(item).__apiobject__())


    def pop(self, index):
        """:rtype: `PyNode` """
        if index >= len(self):
            raise IndexError, "index out of range"
        return self.apicls.remove(self, index )


    def isSubSet(self, other):
        """:rtype: `bool`"""
        if isinstance(other, ObjectSet):
            other = other.asSelectionSet()
        return set(self).issubset(other)

    def isSuperSet(self, other, flatten=True ):
        """:rtype: `bool`"""
        if isinstance(other, ObjectSet):
            other = other.asSelectionSet()
        return set(self).issuperset(other)

    def getIntersection(self, other):
        """:rtype: `SelectionSet`"""
        # diff = self-other
        # intersect = self-diff
        diff = self.getDifference(other)
        return self.getDifference(diff)

    def intersection(self, other):
        diff = self.getDifference(other)
        self.difference(diff)

    def getDifference(self, other):
        """:rtype: `SelectionSet`"""
        # create a new SelectionSet so that we don't modify our current one
        newSet = SelectionSet( self )
        newSet.difference(other)
        return newSet

    def difference(self, other):
        if not isinstance( other, _api.MSelectionList ):
            other = SelectionSet( other )
        self.apicls.merge( self, other, _api.MSelectionList.kRemoveFromList )

    def getUnion(self, other):
        """:rtype: `SelectionSet`"""
        newSet = SelectionSet( self )
        newSet.union(other)
        return newSet

    def union(self, other):
        if not isinstance( other, _api.MSelectionList ):
            other = SelectionSet( other )
        self.apicls.merge( self, other, _api.MSelectionList.kMergeNormal )


    def getSymmetricDifference(self, other):
        """
        Also known as XOR

        :rtype: `SelectionSet`
        """
        # create a new SelectionSet so that we don't modify our current one
        newSet = SelectionSet( self )
        newSet.symmetricDifference(other)
        return newSet

    def symmetricDifference(self, other):
        if not isinstance( other, _api.MSelectionList ):
            other = SelectionSet( other )
        # FIXME: does kXOR exist?  completion says only kXORWithList exists
        self.apicls.merge( self, other, _api.MSelectionList.kXOR )

    def asObjectSet(self):
        return general.sets( self )
#    def intersect(self, other):
#        self.apicls.merge( other, _api.MSelectionList.kXORWithList )



class ObjectSet(Entity):
    """
    The ObjectSet class and `SelectionSet` class work together.  Both classes have a very similar interface,
    the primary difference is that the ObjectSet class represents connections to an objectSet node, while the
    `SelectionSet` class is a generic set, akin to pythons built-in `set`.


    create some sets:

        >>> from pymel.core import *
        >>> f=newFile(f=1) #start clean
        >>>
        >>> s = sets()  # create an empty set
        >>> s.union( ls( type='camera') )  # add some cameras to it
        >>> s.members()  # doctest: +SKIP
        [nt.Camera(u'sideShape'), nt.Camera(u'frontShape'), nt.Camera(u'topShape'), nt.Camera(u'perspShape')]
        >>> sel = s.asSelectionSet() # or as a SelectionSet
        >>> sel # doctest: +SKIP
        nt.SelectionSet([u'sideShape', u'frontShape', u'topShape', u'perspShape'])
        >>> sorted(sel) # as a sorted list
        [nt.Camera(u'frontShape'), nt.Camera(u'perspShape'), nt.Camera(u'sideShape'), nt.Camera(u'topShape')]

    Operations between sets result in `SelectionSet` objects:

        >>> t = sets()  # create another set
        >>> t.add( 'perspShape' )  # add the persp camera shape to it
        >>> s.getIntersection(t)
        nt.SelectionSet([u'perspShape'])
        >>> diff = s.getDifference(t)
        >>> diff #doctest: +SKIP
        nt.SelectionSet([u'sideShape', u'frontShape', u'topShape'])
        >>> sorted(diff)
        [nt.Camera(u'frontShape'), nt.Camera(u'sideShape'), nt.Camera(u'topShape')]
        >>> s.isSuperSet(t)
        True



    """


#        >>> u = sets( s&t ) # intersection
#        >>> print u.elements(), s.elements()
#        >>> if u < s: print "%s is a sub-set of %s" % (u, s)
#
#    place a set inside another, take1
#
#        >>> # like python's built-in set, the add command expects a single element
#        >>> s.add( t )
#
#    place a set inside another, take2
#
#        >>> # like python's built-in set, the update command expects a set or a list
#        >>> t.update([u])
#
#        >>> # put the sets back where they were
#        >>> s.remove(t)
#        >>> t.remove(u)
#
#    now put the **contents** of a set into another set
#
#        >>> t.update(u)
#
#    mixed operation between pymel.core.ObjectSet and built-in set
#
#        >>> v = set(['polyCube3', 'pSphere3'])
#        >>> print s.intersection(v)
#        >>> print v.intersection(s)  # not supported yet
#        >>> u.clear()
#
#        >>> delete( s )
#        >>> delete( t )
#        >>> delete( u )
#
#
#    these will return the results of the operation as python sets containing lists of pymel node classes::
#
#        s&t     # s.intersection(t)
#        s|t     # s.union(t)
#        s^t     # s.symmetric_difference(t)
#        s-t     # s.difference(t)
#
#    the following will alter the contents of the maya set::
#
#        s&=t    # s.intersection_update(t)
#        s|=t    # s.update(t)
#        s^=t    # s.symmetric_difference_update(t)
#        s-=t    # s.difference_update(t)
#
#    def _elements(self):
#        """ used internally to get a list of elements without casting to node classes"""
#        return sets( self, q=True)
#    #-----------------------
#    # Maya Methods
#    #-----------------------

    __metaclass__ = _factories.MetaMayaNodeWrapper
    #-----------------------
    # Python ObjectSet Methods
    #-----------------------

    @classmethod
    def _getApiObjs(cls, item, tryCast=True):
        """
        Returns a tuple of api objects suitable (after unpacking) for
        feeding to most of the MFnSet methods (ie, remove, isMember, etc)
        """
        if isinstance(item, DagNode):
            return ( item.__apimdagpath__(), _api.MObject() )
        elif isinstance(item, (DependNode, general.Attribute) ):
            return ( item.__apiobject__(), )
        elif isinstance(item, general.Component):
            return ( item.__apimdagpath__(), item.__apimobject__() )
        elif tryCast:
            return cls._getApiObjs(general.PyNode(item), tryCast=False)
        else:
            raise TypeError(item)

    def __contains__(self, item):
        """:rtype: `bool` """
        return self.__apimfn__().isMember(*self._getApiObjs(item))

    def __getitem__(self, index):
        return self.asSelectionSet()[index]

    def __len__(self):
        """:rtype: `int`"""
        return cmds.sets(self, q=1, size=1)


    #def __eq__(self, s):
    #    return s == self._elements()

    #def __ne__(self, s):
    #    return s != self._elements()

    def __and__(self, s):
        "operator for `ObjectSet.getIntersection`"
        return self.getIntersection(s)

    def __iand__(self, s):
        "operator for `ObjectSet.intersection`"
        return self.intersection(s)

    def __or__(self, s):
        "operator for `ObjectSet.getUnion`"
        return self.getUnion(s)

    def __ior__(self, s):
        "operator for `ObjectSet.union`"
        return self.union(s)

#    def __lt__(self, s):
#        "operator for `ObjectSet.isSubSet`"
#        return self.isSubSet(s)
#
#    def __gt__(self, s):
#        "operator for `ObjectSet.isSuperSet`"
#        return self.isSuperSet(s)

    def __sub__(self, s):
        "operator for `ObjectSet.getDifference`"
        return self.getDifference(s)

    def __isub__(self, s):
        "operator for `ObjectSet.difference`"
        return self.difference(s)

    def __xor__(self, s):
        "operator for `ObjectSet.symmetricDifference`"
        return self.getSymmetricDifference(s)

    def __ixor__(self, s):
        "operator for `ObjectSet.symmetricDifference`"
        return self.symmetricDifference(s)

#
#    def subtract(self, set2):
#        return sets( self, subtract=set2 )
#
#    def add(self, element):
#        return sets( self, add=[element] )
#
#    def clear(self):
#        return sets( self, clear=True )
#
#    def copy(self ):
#        return sets( self, copy=True )
#
#    def difference(self, elements):
#        if isinstance(elements,basestring):
#            elements = cmds.sets( elements, q=True)
#        return list(set(self.elements()).difference(elements))
#
#        '''
#        if isinstance(s, ObjectSet) or isinstance(s, str):
#            return sets( s, subtract=self )
#
#        s = sets( s )
#        res = sets( s, subtract=self )
#        cmds.delete(s)
#        return res'''
#
#    def difference_update(self, elements ):
#        return sets( self, remove=elements)
#
#    def discard( self, element ):
#        try:
#            return self.remove(element)
#        except TypeError:
#            pass
#
#    def intersection(self, elements):
#        if isinstance(elements,basestring):
#            elements = cmds.sets( elements, q=True)
#        return set(self.elements()).intersection(elements)
#
#    def intersection_update(self, elements):
#        self.clear()
#        sets( self, add=self.intersections(elements) )
#
#
#    def remove( self, element ):
#        return sets( self, remove=[element])
#
#    def symmetric_difference(self, elements):
#        if isinstance(elements,basestring):
#            elements = cmds.sets( elements, q=True)
#        return set(self.elements()).symmetric_difference(elements)
#
#    def union( self, elements ):
#        if isinstance(elements,basestring):
#            elements = cmds.sets( elements, q=True)
#        return set(self.elements()).union(elements)
#
#    def update( self, set2 ):
#        sets( self, forceElement=set2 )

    def members(self, flatten=False):
        """return members as a list
        :rtype: `list`
        """
        return list( self.asSelectionSet(flatten) )

    @_warnings.deprecated( 'Use ObjectSet.members instead', 'ObjectSet' )
    def elements(self, flatten=False):
        """return members as a list
        :rtype: `list`
        """
        return list( self.asSelectionSet(flatten) )

    def flattened(self):
        """return a flattened list of members.  equivalent to `ObjectSet.members(flatten=True)`
        :rtype: `list`
        """
        return self.members(flatten=True)

    def resetTo(self, newContents ):
        """clear and set the members to the passed list/set"""
        self.clear()
        self.addMembers( newContents )


    def add(self, item):
        return self.__apimfn__().addMember(*self._getApiObjs(item))

    def remove(self, item):
        try:
            return self.__apimfn__().removeMember(*self._getApiObjs(item))
        except RuntimeError:
            # Provide a more informative error if object is not in set
            if item not in self:
                try:
                    itemStr = repr(item)
                except Exception:
                    itemStr = 'item'
                raise ValueError("%s not in set %r" % (itemStr, self))
            else:
                raise

    def isSubSet(self, other):
        """:rtype: `bool`"""
        return self.asSelectionSet().isSubSet(other)

    def isSuperSet(self, other ):
        """:rtype: `bool`"""
        return self.asSelectionSet().isSuperSet(other)

    def isEqual(self, other ):
        """
        do not use __eq__ to test equality of set contents. __eq__ will only tell you if
        the passed object is the same node, not if this set and the passed set
        have the same contents.
        :rtype: `bool`
        """
        return self.asSelectionSet() == SelectionSet(other)


    def getDifference(self, other):
        """:rtype: `SelectionSet`"""
        sel = self.asSelectionSet()
        sel.difference(other)
        return sel

    def difference(self, other):
        sel = self.getDifference(other)
        self.resetTo(sel)

    def getSymmetricDifference(self, other):
        """also known as XOR
        :rtype: `SelectionSet`
        """
        sel = self.getSymmetricDifference()
        sel.difference(other)
        return sel

    def symmetricDifference(self, other):
        sel = self.symmetricDifference(other)
        self.resetTo(sel)

    def getIntersection(self, other):
        """:rtype: `SelectionSet`"""
        if isinstance(other, ObjectSet):
            return self._getIntersection(other)

        #elif isinstance(other, SelectionSet) or hasattr(other, '__iter__'):
        selSet = self.asSelectionSet()
        selSet.intersection(other)
        return selSet

        #raise TypeError, 'Cannot perform intersection with non-iterable type %s' % type(other)

    def intersection(self, other):
        sel = self.getIntersection(other)
        self.resetTo(sel)


    def getUnion(self, other):
        """:rtype: `SelectionSet`"""
        if isinstance(other, ObjectSet):
            return self._getUnion(other)

        selSet = self.asSelectionSet()
        selSet.union(other)
        return selSet

    def union(self, other):
        self.addMembers(other)

    def isRenderable(self):
        '''Mimics cmds.sets(self, q=True, renderable=True).

        Alternatively you can use isinstance(someset, pm.nt.ShadingEngine)
        since shadingEngine is the only renderable set in maya now
        '''
        return bool(cmds.sets(self, q=True, r=True))

class ShadingEngine(ObjectSet):
    @classmethod
    def _getApiObjs(cls, item, tryCast=True):
        # Since shading groups can't contain transforms, as a convenience,
        # use getShape on any transforms
        if isinstance(item, Transform):
            shape = item.getShape()
            if shape:
                return cls._getApiObjs(shape)
            else:
                try:
                    itemStr = repr(item)
                except Exception:
                    itemStr = 'item'
                raise TypeError("%s has no shape, and %s objects cannot contain Transforms" % (itemStr, cls.__name__))
        else:
            return super(ShadingEngine, cls)._getApiObjs(item, tryCast=tryCast)

class AnimLayer(ObjectSet):
    __metaclass__ = _factories.MetaMayaNodeWrapper

    def getAttribute(self):
        '''Retrieve the attributes animated on this AnimLayer
        '''
        # Unfortunately, cmds.animLayer('MyAnimLayer', q=1, attribute=1)
        # returns none unique attribute names, ie,
        #   MyNode.myAttr
        # even if there are foo|MyNode and bar|MyNode in the scene, and there
        # doesn't seem to be a flag to tell it to give unique / full paths.
        # Therefore, query it ourselves, by gettin inputs to dagSetMembers.
        # Testing has shown that animLayers only use dagSetMembers, and never
        # dnSetMembers - if you add a non-dag node to an animLayer, it makes
        # a connection to dagSetMembers; and even if you manually make a connection
        # to dnSetMembers, those connections don't seem to show up in
        # animLayer(q=1, attribute=1)
        return self.attr('dagSetMembers').inputs(plugs=1)

    getAttributes = getAttribute

class AnimCurve(DependNode):
    __metaclass__ = _factories.MetaMayaNodeWrapper

    def addKeys(self,time,values,tangentInType='linear',tangentOutType='linear',unit=None):
        if not unit:
            unit = _api.MTime.uiUnit()
        times = _api.MTimeArray()
        for frame in time: times.append(_api.MTime(frame,unit))
        keys = _api.MDoubleArray()
        for value in values: keys.append(value)
        return self.__apimfn__().addKeys( times, keys,
                                          _factories.apiClassInfo['MFnAnimCurve']['enums']['TangentType']['values'].getIndex('kTangent'+tangentInType.capitalize()),
                                          _factories.apiClassInfo['MFnAnimCurve']['enums']['TangentType']['values'].getIndex('kTangent'+tangentOutType.capitalize()))

class GeometryFilter(DependNode): pass
class SkinCluster(GeometryFilter):
    __metaclass__ = _factories.MetaMayaNodeWrapper

    def getWeights(self, geometry, influenceIndex=None):
        if not isinstance(geometry, general.PyNode):
            geometry = general.PyNode(geometry)

        if isinstance( geometry, Transform ):
            try:
                geometry = geometry.getShape()
            except:
                raise TypeError, "%s is a transform with no shape" % geometry

        if isinstance(geometry, GeometryShape):
            components = _api.toComponentMObject( geometry.__apimdagpath__() )
        elif isinstance(geometry, general.Component):
            components = geometry.__apiobject__()

        else:
            raise TypeError

        if influenceIndex is not None:
            weights = _api.MDoubleArray()
            self.__apimfn__().getWeights( geometry.__apimdagpath__(), components, influenceIndex, weights )
            return iter(weights)
        else:
            weights = _api.MDoubleArray()
            index = _api.SafeApiPtr('uint')
            self.__apimfn__().getWeights( geometry.__apimdagpath__(), components, weights, index() )
            index = index.get()
            args = [iter(weights)] * index
            return itertools.izip(*args)

    def setWeights(self, geometry, influnces, weights, normalize=True):
        if not isinstance(geometry, general.PyNode):
            geometry = general.PyNode(geometry)

        if isinstance( geometry, Transform ):
            try:
                geometry = geometry.getShape()
            except:
                raise TypeError, "%s is a transform with no shape" % geometry

        if isinstance(geometry, GeometryShape):
            components = _api.toComponentMObject( geometry.__apimdagpath__() )
        elif isinstance(geometry, general.Component):
            components = geometry.__apiobject__()

        else:
            raise TypeError

        if not isinstance(influnces,_api.MIntArray):
            api_influnces = _api.MIntArray()
            for influnce in influnces:
                api_influnces.append(influnce)
            influnces = api_influnces

        if not isinstance(weights,_api.MDoubleArray):
            api_weights = _api.MDoubleArray()
            for weight in weights:
                api_weights.append(weight)
            weights = api_weights

        old_weights = _api.MDoubleArray()
        su = _api.MScriptUtil()
        su.createFromInt(0)
        index = su.asUintPtr()
        self.__apimfn__().getWeights( geometry.__apimdagpath__(), components, old_weights, index )
        return self.__apimfn__().setWeights( geometry.__apimdagpath__(), components, influnces, weights, normalize, old_weights )

    @_factories.addApiDocs( _api.MFnSkinCluster, 'influenceObjects' )
    def influenceObjects(self):
        return self._influenceObjects()[1]

    def numInfluenceObjects(self):
        return self._influenceObjects()[0]

# TODO: if nucleus/symmetryConstraint bug ever fixed:
#   - remove entry in apiCache.ApiCache.API_TO_MFN_OVERRIDES
#   - remove hard-code setting of Nucleus's parent to DependNode
#   - remove 2 checks in allapi.toApiObject for objects which can have an MDagPath
#     but can't use MFnDagNode

if _apicache.NUCLEUS_MFNDAG_BUG:
    # nucleus has a weird bug where, even though it inherits from transform, and
    # can be parented in the dag, etc, you can't create an MFnTransform or
    # MFnDagNode for it... therefore, hardcode it's PyNode to inherit from
    # DependNode
    class Nucleus(DependNode):
        __metaclass__ = _factories.MetaMayaNodeWrapper

if _apicache.SYMMETRY_CONSTRAINT_MFNDAG_BUG:
    class SymmetryConstraint(DependNode):
        __metaclass__ = _factories.MetaMayaNodeWrapper


# TODO: if hikHandle bug ever fixed:
#   - remove entry in apiCache.ApiCache.API_TO_MFN_OVERRIDES
#   - remove hard-code setting of HikHandle's parent to Transform
class HikHandle(Transform):
    __metaclass__ = _factories.MetaMayaNodeWrapper

class JointFfd(DependNode):
    __metaclass__ = _factories.MetaMayaNodeWrapper

class TransferAttributes(DependNode):
    __metaclass__ = _factories.MetaMayaNodeWrapper

_factories.ApiTypeRegister.register( 'MSelectionList', SelectionSet )


def _createPyNodes():

    dynModule = _util.LazyLoadModule(__name__, globals())

    for mayaType, parents, children in _factories.nodeHierarchy:

        if mayaType == 'dependNode':
        # This seems like the more 'correct' way of doing it - only node types
        # that are currently available have PyNodes created for them - but
        # changing it so some PyNodes are no longer available until their
        # plugin is loaded may create backwards incompatibility issues...
#        if (mayaType == 'dependNode'
#                or mayaType not in _factories.mayaTypesToApiTypes):
            continue

        parentMayaType = parents[0]
        #print "superNodeType: ", superNodeType, type(superNodeType)
        if parentMayaType is None:
            _logger.warning("could not find parent node: %s", mayaType)
            continue

        #className = _util.capitalize(mayaType)
        #if className not in __all__: __all__.append( className )

        if _factories.isMayaType(mayaType):
            _factories.addPyNode( dynModule, mayaType, parentMayaType )

    sys.modules[__name__] = dynModule


# Initialize Pymel classes to API types lookup
#_startTime = time.time()
_createPyNodes()
#_logger.debug( "Initialized Pymel PyNodes types list in %.2f sec" % time.time() - _startTime )

dynModule = sys.modules[__name__]
#def listToMSelection( objs ):
#    sel = _api.MSelectionList()
#    for obj in objs:
#        if isinstance(obj, DependNode):
#            sel.add( obj.__apiobject__() )
#        elif isinstance(obj, Attribute):
#            sel.add( obj.__apiobject__(), True )
#        elif isinstance(obj, Component):
#            pass
#            #sel.add( obj.__apiobject__(), True )
#        else:
#            raise TypeError

########NEW FILE########
__FILENAME__ = other
"""
Functions which are not listed in the maya documentation, such as commands created by plugins,
as well as the name parsing classes `DependNodeName`, `DagNodeName`, and `AttributeName`.
"""

import re
import inspect

import pymel.internal.pmcmds as cmds
import pymel.internal.factories as _factories
_factories.createFunctions( __name__ )


#--------------------------
# Object Wrapper Classes
#--------------------------

class NameParser(unicode):
    PARENT_SEP = '|'

    def __new__(cls, strObj):
        """Casts a string to a pymel class. Use this function if you are unsure which class is the right one to use
        for your object."""
        strObj = unicode(strObj)
        # the if statement was failing for some types (ex: pymel.node.Vertex),
        # so forcing into unicode string:
        if cls is not NameParser:
            newcls = cls
        else:
            newcls = _getParserClass(strObj)
        self = super(NameParser, cls).__new__(newcls, strObj)
        return self

    def __repr__(self):
        return u"%s(%s)" % (self.__class__.__name__, super(NameParser, self).__repr__())

    #def __unicode__(self):
    #    return u"%s" % self

    def __getattr__(self, attr):
        """
            >>> NameParser('foo:bar').spangle
            AttributeName(u'foo:bar.spangle')

        """
        if attr.startswith('__') and attr.endswith('__'):
            return super(NameParser, self).__getattr__(attr)

        return AttributeName( '%s.%s' % (self, attr) )

        #raise AttributeNameError, 'AttributeName does not exist %s' % attr

    def stripNamespace(self, levels=0):
        """
        Returns a new instance of the object with its namespace removed.  The calling instance is unaffected.
        The optional levels keyword specifies how many levels of cascading namespaces to strip, starting with the topmost (leftmost).
        The default is 0 which will remove all namespaces.

            >>> NameParser('foo:bar.spangle').stripNamespace()
            AttributeName(u'bar.spangle')

        """

        nodes = []
        for dagElem in self.split('|'):
            attrSplit = dagElem.split('.')
            spaceSplit = attrSplit[0].split(':')
            if levels:
                attrSplit[0] = ':'.join( spaceSplit[min(len(spaceSplit)-1,levels):] )
            else:
                attrSplit[0] = spaceSplit[-1]
            nodes.append( '.'.join( attrSplit ) )
        return self.__class__( '|'.join( nodes) )

    def stripGivenNamespace(self, namespace, partial=True):
        """
        Returns a new instance of the object with any occurrences of the given namespace removed.  The calling instance is unaffected.
        The given namespace may end with a ':', or not.
        If partial is True (the default), and the given namespace has parent namespaces (ie, 'one:two:three'),
        then any occurrences of any parent namespaces are also stripped - ie, 'one' and 'one:two' would
        also be stripped.  If it is false, only namespaces

            >>> NameParser('foo:bar:top|foo:middle|foo:bar:extra:guy.spangle').stripGivenNamespace('foo:bar')
            AttributeName(u'top|middle|extra:guy.spangle')

            >>> NameParser('foo:bar:top|foo:middle|foo:bar:extra:guy.spangle').stripGivenNamespace('foo:bar', partial=False)
            AttributeName(u'top|foo:middle|extra:guy.spangle')
        """
        prefixSplit = namespace.rstrip(':').split(':')

        nodes = []
        for dagElem in self.split('|'):
            attrSplit = dagElem.split('.')
            spaceSplit = attrSplit[0].split(':')
            if partial:
                for toStrip in prefixSplit:
                    if spaceSplit[0] == toStrip:
                        spaceSplit.pop(0)
                    else:
                        break
            else:
                if spaceSplit[:len(prefixSplit)] == prefixSplit:
                    spaceSplit = spaceSplit[len(prefixSplit):]
                attrSplit[0] = spaceSplit[-1]
            attrSplit[0] = ':'.join( spaceSplit )
            nodes.append( '.'.join( attrSplit ) )
        return self.__class__( '|'.join( nodes) )

    def swapNamespace(self, prefix):
        """Returns a new instance of the object with its current namespace replaced with the provided one.
        The calling instance is unaffected."""
        if not prefix.endswith(':'):
            prefix += ':'
        return self.__class__.addPrefix( self.stripNamespace(), prefix)

    def namespaceList(self):
        """Useful for cascading references.  Returns all of the namespaces of the calling object as a list"""
        return self.lstrip('|').rstrip('|').split('|')[-1].split(':')[:-1]

    def namespace(self):
        """Returns the namespace of the object with trailing colon included"""
        nsList = self.namespaceList()
        if nsList:
            return  ':'.join(nsList) + ':'
        return ''

    def addPrefix(self, prefix):
        'addPrefixToName'
        name = self
        leadingSlash = False
        if name.startswith('|'):
            name = name[1:]
            leadingSlash = True
        name = self.__class__( '|'.join( map( lambda x: prefix+x, name.split('|') ) ) )
        if leadingSlash:
            name = '|' + name
        return self.__class__( name )

    def attr(self, attr):
        """access to AttributeName of a node. returns an instance of the AttributeName class for the
        given AttributeName.

            >>> NameParser('foo:bar').attr('spangle')
            AttributeName(u'foo:bar.spangle')

        """
        return AttributeName( '%s.%s' % (self, attr) )



class AttributeName(NameParser):
    """

    """
    attrItemReg = re.compile( '\[(\d+:*\d*)\]$')

    #def __repr__(self):
    #    return "AttributeName('%s')" % self

    def __init__(self, attrName):
        attrName = unicode(attrName)
        if '.' not in attrName:
            raise TypeError, "%s: AttributeNames must include the node and the AttributeName. e.g. 'nodeName.AttributeNameName' " % self
        self.__dict__['_multiattrIndex'] = 0

    def __getitem__(self, item):
        return AttributeName('%s[%s]' % (self, item) )

    # Added the __call__ so to generate a more appropriate exception when a class method is not found
    def __call__(self, *args, **kwargs):
        raise TypeError("The object <%s> does not support the '%s' method" % (repr(self.node()), self.plugAttr()))


    def array(self):
        """
        Returns the array (multi) AttributeName of the current element
            >>> n = AttributeName('lambert1.groupNodes[0]')
            >>> n.array()
            AttributeName(u'lambert1.groupNodes')
        """
        try:
            return AttributeName(AttributeName.attrItemReg.split( self )[0])
        except:
            raise TypeError, "%s is not a multi AttributeName" % self

    def plugNode(self):
        """plugNode

        >>> NameParser('foo:bar.spangle.banner').plugNode()
        DependNodeName(u'foo:bar')

        """
        return NameParser( unicode(self).split('.')[0])

    node = plugNode

    def plugAttr(self):
        """plugAttr

        >>> NameParser('foo:bar.spangle.banner').plugAttr()
        u'spangle.banner'

        """
        return '.'.join(unicode(self).split('.')[1:])

    def lastPlugAttr(self):
        """
        >>> NameParser('foo:bar.spangle.banner').lastPlugAttr()
        u'banner'

        """
        return self.split('.')[-1]


    def nodeName( self ):
        'basename'
        return self.split('|')[-1]

    def item(self, asSlice=False, asString=False):
        try:
            item = AttributeName.attrItemReg.search(self).group(1)
            if asString:
                return "[%s]" % unicode(item)
            val = item.split(":")
            val = map(int,val)
            if len(val)>1:
                return asSlice and slice(*val) or val
            return val[0]
        except: return None


    def getParent(self, generations=1):
        """
        Returns the parent attribute

        Modifications:
            - added optional generations flag, which gives the number of levels up that you wish to go for the parent;
              ie:
                  >>> AttributeName("Cube1.multiComp[3].child.otherchild").getParent(2)
                  AttributeName(u'Cube1.multiComp[3]')

              Negative values will traverse from the top, not counting the initial node name:

                  >>> AttributeName("Cube1.multiComp[3].child.otherchild").getParent(-2)
                  AttributeName(u'Cube1.multiComp[3].child')

              A value of 0 will return the same node.
              The default value is 1.

              Since the original command returned None if there is no parent, to sync with this behavior, None will
              be returned if generations is out of bounds (no IndexError will be thrown).
        """

        if generations==0:
            return self

        split = self.split('.')
        if -len(split) < generations < len(split) - 1:
            if generations < 0:
                # Move it one over to account for the initial node name
                splitIndex = 1 - generations
            else:
                splitIndex = -generations
            try:
                return AttributeName('.'.join(split[:splitIndex]))
            except:
                pass

    def addAttr( self, **kwargs):
        kwargs['longName'] = self.plugAttr()
        kwargs.pop('ln', None )
        from pymel.core.general import addAttr
        return addAttr( self.node(), **kwargs )

    def setAttr(self, *args, **kwargs):
        from pymel.core.general import setAttr
        return setAttr(self, *args, **kwargs)

    set = setAttr
    add = addAttr

    def exists(self):
        node = self.plugNode()
        attr = self.plugAttr()
        if not node or not attr:
            return False

        if not cmds.objExists(node):
            return False

        # short name
        if attr in cmds.listAttr( node, shortNames=1) + cmds.listAttr( node):
            return True

        return False


class DependNodeName( NameParser ):
    #-------------------------------
    #    Name Info and Manipulation
    #-------------------------------

    def node(self):
        """for compatibility with AttributeName class"""
        return self

    def nodeName(self):
        """for compatibility with DagNodeName class"""
        return self

    def exists(self, **kwargs):
        "objExists"
        return bool( cmds.objExists(self, **kwargs) )


    _numPartReg = re.compile('([0-9]+)$')

    def stripNum(self):
        """Return the name of the node with trailing numbers stripped off. If no trailing numbers are found
        the name will be returned unchanged."""
        try:
            return DependNodeName._numPartReg.split(self)[0]
        except IndexError:
            return unicode(self)

    def extractNum(self):
        """Return the trailing numbers of the node name. If no trailing numbers are found
        an error will be raised."""

        try:
            return DependNodeName._numPartReg.split(self)[1]
        except IndexError:
            raise ValueError, "No trailing numbers to extract on object %s" % self

    def nextUniqueName(self):
        """
        Increment the trailing number of the object until a unique name is found

        If there is no trailing number, appends '1' to the name.
        Will always return a different name than the current name, even if the
            current name already does not exist.
        """
        try:
            name = self.nextName()
        except ValueError:
            name = self.__class__(self + '1')
        while name.exists():
            name = name.nextName()
        return name

    def nextName(self):
        """Increment the trailing number of the object by 1"""

        groups = DependNodeName._numPartReg.split(self)
        if len(groups) > 1:
            num = groups[1]
            formatStr = '%s%0' + unicode(len(num)) + 'd'
            return self.__class__(formatStr % ( groups[0], (int(num) + 1) ))
        else:
            raise ValueError, "could not find trailing numbers to increment on object %s" % self

    def prevName(self):
        """Decrement the trailing number of the object by 1"""
        groups = DependNodeName._numPartReg.split(self)
        if len(groups) > 1:
            num = groups[1]
            formatStr = '%s%0' + unicode(len(num)) + 'd'
            return self.__class__(formatStr % ( groups[0], (int(num) - 1) ))
        else:
            raise ValueError, "could not find trailing numbers to decrement on object %s" % self

class DagNodeName(DependNodeName):

#    def __eq__(self, other):
#        """ensures that we compare longnames when checking for dag node equality"""
#        try:
#            return unicode(self.longName()) == unicode(DagNodeName(other).longName())
#        except (TypeError,IndexError):
#            return unicode(self) == unicode(other)
#
#    def __ne__(self, other):
#        """ensures that we compare longnames when checking for dag node equality"""
#        try:
#            return unicode(self.longName()) != unicode(DagNodeName(other).longName())
#        except (TypeError,IndexError):
#            return unicode(self) != unicode(other)

    #--------------------------
    #    DagNodeName Path Info
    #--------------------------
    def root(self):
        'rootOf'
        return DagNodeName( '|' + self.longName()[1:].split('|')[0] )

    def getRoot(self):
        """unlike the root command which determines the parent via string formatting, this
        command uses the listRelatives command"""

        par = None
        cur = self
        while 1:
            par = cur.getParent()
            if not par:
                break
            cur = par
        return cur

    def firstParent(self):
        'firstParentOf'

        return DagNodeName( '|'.join( self.split('|')[:-1] ) )

    def getParent(self, generations=1):
        """
        Returns the parent node

        Modifications:
            - added optional generations flag, which gives the number of levels up that you wish to go for the parent;
              ie:
                  >>> DagNodeName("NS1:TopLevel|Next|ns2:Third|Fourth").getParent(2)
                  DagNodeName(u'NS1:TopLevel|Next')

              Negative values will traverse from the top, not counting the initial node name:

                  >>> DagNodeName("NS1:TopLevel|Next|ns2:Third|Fourth").getParent(-3)
                  DagNodeName(u'NS1:TopLevel|Next|ns2:Third')

              A value of 0 will return the same node.
              The default value is 1.

              Since the original command returned None if there is no parent, to sync with this behavior, None will
              be returned if generations is out of bounds (no IndexError will be thrown).
        """

        if generations==0:
            return self

        split = self.split('|')
        if -len(split) <= generations < len(split):
            try:
                return DagNodeName('|'.join(split[:-generations]))
            except:
                pass


#    def shortName( self ):
#        'shortNameOf'
#        try:
#            return self.__class__( cmds.ls( self )[0] )
#        except:
#            return self

    def nodeName( self ):
        'basename'
        return self.split('|')[-1]



def _getParserClass(strObj):
    # First, see if strObj is actually a PyNode - in that case, get the class
    # based off the node...
    mro = set([cls.__name__ for cls in inspect.getmro(type(strObj))])
    # doing string comparison so we don't have to import core.general/nodetypes
    if 'PyNode' in mro:
        if 'DagNode' in mro:
            newcls = DagNodeName
        elif 'Attribute' in mro:
            newcls = AttributeName
        else:
            newcls = DependNodeName
    else:
        strObj = unicode(strObj)

        if '.' in strObj:
            newcls = AttributeName
                # Return Component Arrays ======================================================
                #            attr = obj.array().plugAttr()
                #            if attr in ["f","vtx","e","map"]:
                #                comps = getattr(Mesh(obj.node()), attr)
                #                return comps.__getitem__(obj.item(asSlice=1))
                #            else:
                #                return obj
                #===============================================================================


        elif '|' in strObj:
            newcls = DagNodeName
        else:
            newcls = DependNodeName
    return newcls



########NEW FILE########
__FILENAME__ = rendering
"""Functions related to rendering"""

import pymel.util as _util
import pymel.internal.factories as _factories
import general as _general
import language as _language
import pymel.internal.pmcmds as cmds



def shadingNode( *args, **kwargs):
    res = cmds.shadingNode( *args, **kwargs )
    if res is not None:
        return _general.PyNode( res )

def createSurfaceShader( shadertype, name=None ):
    """
    create a shader and shading group


    """
    classification = _general.getClassification( shadertype )
    #print classification

    newShader = None
    import nodetypes
    #if 'shader/surface' in classification:
    if 'rendernode/mentalray/material' in classification:
        newShader = nodetypes.DependNode(_language.mel.mrCreateCustomNode( "-asShader", "", shadertype))
    else:
        newShader = nodetypes.DependNode(_language.mel.renderCreateNode( "-asShader", "surfaceShader", shadertype, "", 0, 0, 0, 1, 0, ""))
    #else:
    #    raise TypeError, "%s is not a valid surface shader type. shader must be classified as 'shader/surface'" % shadertype
    sg = newShader.shadingGroups()[0]
    if name:
        newShader = newShader.rename(name)
        sg = sg.rename( name + 'SG')
    return newShader, sg

def lsThroughFilter( *args, **kwargs):
    """
Modifications:
  - returns an empty list when the result is None
  - returns wrapped classes
    """
    return map(_general.PyNode, _util.listForNone(cmds.lsThroughFilter(*args, **kwargs)))

def pointLight(*args,**kwargs):
    """
Maya Bug Fix:
  - name flag was ignored
    """
    if kwargs.get('query', kwargs.get('q', False)) or kwargs.get('edit', kwargs.get('e', False)):
        return cmds.pointLight(*args, **kwargs)

    else:
        name = kwargs.pop('name', kwargs.pop('n', False ) )
        if name:
            tmp = cmds.pointLight(*args, **kwargs)
            tmp = cmds.rename( cmds.listRelatives( tmp, parent=1)[0], name)
            return _general.PyNode( cmds.listRelatives( tmp, shapes=1)[0] )

    return _general.PyNode( cmds.pointLight(*args, **kwargs)  )

def spotLight(*args,**kwargs):
    """
Maya Bug Fix:
  - name flag was ignored
    """
    if kwargs.get('query', kwargs.get('q', False)) or kwargs.get('edit', kwargs.get('e', False)):
        return cmds.spotLight(*args, **kwargs)

    else:
        name = kwargs.pop('name', kwargs.pop('n', False ) )
        if name:
            tmp = cmds.spotLight(*args, **kwargs)
            tmp = cmds.rename( cmds.listRelatives( tmp, parent=1)[0], name)
            return _general.PyNode( cmds.listRelatives( tmp, shapes=1)[0])

    return _general.PyNode( cmds.spotLight(*args, **kwargs)  )

def directionalLight(*args,**kwargs):
    """
Maya Bug Fix:
  - name flag was ignored
    """

    if kwargs.get('query', kwargs.get('q', False)) or kwargs.get('edit', kwargs.get('e', False)):
        return cmds.directionalLight(*args, **kwargs)

    else:
        name = kwargs.pop('name', kwargs.pop('n', False ) )
        if name:
            tmp = cmds.directionalLight(*args, **kwargs)
            tmp = cmds.rename( cmds.listRelatives( tmp, parent=1)[0], name)
            return _general.PyNode( cmds.listRelatives( tmp, shapes=1)[0] )

    return _general.PyNode( cmds.directionalLight(*args, **kwargs)  )

def ambientLight(*args,**kwargs):
    """
Maya Bug Fix:
  - name flag was ignored
    """
    if kwargs.get('query', kwargs.get('q', False)) or kwargs.get('edit', kwargs.get('e', False)):
        return cmds.ambientLight(*args, **kwargs)

    else:
        name = kwargs.pop('name', kwargs.pop('n', False ) )
        if name:
            tmp = cmds.ambientLight(*args, **kwargs)
            tmp = cmds.rename( cmds.listRelatives( tmp, parent=1)[0], name)
            return _general.PyNode( cmds.listRelatives( tmp, shapes=1)[0] )

    return _general.PyNode( cmds.ambientLight(*args, **kwargs)  )

#def createRenderLayer(*args, **kwargs):
#    return _general.PyNode( cmds.createRenderLayer(*args, **kwargs) )
#
#def createDisplayLayer(*args, **kwargs):
#    return _general.PyNode( cmds.createDisplayLayer(*args, **kwargs) )

_factories.createFunctions( __name__, _general.PyNode )

########NEW FILE########
__FILENAME__ = runtime
"""
Runtime commands. These are kept in their own namespace to prevent conflict with other functions and classes.
"""

import pymel.internal.factories as _factories
_factories.createFunctions( __name__ )
########NEW FILE########
__FILENAME__ = system

"""
Functions and classes relating to files, references, and system calls.

In particular, the system module contains the functionality of maya.cmds.file. The file command should not be imported into
the default namespace because it conflicts with python's builtin file class. Since the file command has so many flags,
we decided to kill two birds with one stone: by breaking the file command down into multiple functions -- one for each
primary flag -- the resulting functions are more readable and allow the file command's functionality to be used directly
within the pymel namespace.

for example, instead of this:

    >>> res = cmds.file( 'test.ma', exportAll=1, preserveReferences=1, type='mayaAscii', force=1 ) # doctest: +SKIP

you can do this:

    >>> expFile = exportAll( 'test.ma', preserveReferences=1, force=1)

some of the new commands were changed slightly from their flag name to avoid name clashes and to add to readability:

    >>> importFile( expFile )  # flag was called import, but that's a python keyword
    >>> ref = createReference( expFile )
    >>> ref # doctest: +ELLIPSIS
    FileReference(u'.../test.ma', refnode=u'testRN')

Notice that the 'type' flag is set automatically for you when your path includes a '.mb' or '.ma' extension.

Paths returned by these commands are either a `Path` or a `FileReference`, so you can use object-oriented path methods with
the results::

    >>> expFile.exists()
    True
    >>> expFile.remove()  # cleanup
    Path('/Volumes/newhome/paulm/maya_pymel_test/projects/default/test.ma')

"""

import sys
import os
import warnings

import maya.mel as _mel
import maya.OpenMaya as _OpenMaya

from pymel.util.scanf import fscanf
from pymel.util.decoration import decorator
import pymel.util as _util
import pymel.internal.factories as _factories
import pymel.internal as _internal
import pymel.internal.pmcmds as cmds
import pymel.versions as versions

_logger = _internal.getLogger(__name__)


try:
    from pymel.internal.startup import pymel_options as _pymel_options
    # attempt to import a custom path class to use as the base for pymel's Path class
    basePathName = _pymel_options['path_class']
    buf = basePathName.split('.')
    moduleName = '.'.join(buf[:-1])
    className = buf[-1]
    try:
        pathModule = __import__(moduleName, globals(), locals(), [''])
    except Exception, e:
        _logger.warning( "Could not import %r module containing custom base Path class: %s" % ( moduleName, str(e) ) )
        raise AssertionError

    try:
        pathClass = getattr(pathModule, className)
        _logger.info( "Using custom path class %s" % ( basePathName ) )
    except AttributeError, e:
        _logger.warning( "Custom path class %s could not be found in module %s" % ( className, pathModule ) )
        raise AssertionError
except (KeyError, AssertionError):
    pathClass = _util.path


def _getTypeFromExtension(path):
    ext = Path(path).ext
    return str(Translator.fromExtension(ext))

def _setTypeKwargFromExtension(path, kwargs):
    if 'type' not in kwargs and 'typ' not in kwargs:
        try:
            fileType = _getTypeFromExtension(path)
        except Exception:
            pass
        else:
            if fileType and fileType != 'None':
                kwargs['type'] = fileType

# Bring the MGlobal.display* methods into this namespace, for convenience
displayError = _OpenMaya.MGlobal.displayError
displayWarning = _OpenMaya.MGlobal.displayWarning
displayInfo = _OpenMaya.MGlobal.displayInfo

def feof( fileid ):
    """Reproduces the behavior of the mel command of the same name. if writing pymel scripts from scratch,
    you should use a more pythonic construct for looping through files:

    >>> f = open('myfile.txt') # doctest: +SKIP
    ... for line in f:
    ...     print line

    This command is provided for python scripts generated by mel2py"""

    pos = fileid.tell()
    fileid.seek(0,2) # goto end of file
    end = fileid.tell() #get final position
    fileid.seek(pos)
    return pos == end


@_factories.addMelDocs( 'file', 'sceneName')
def sceneName():
    # We don't just use cmds.file(q=1, sceneName=1)
    # because it was sometimes returning an empty string,
    # even when there was a valid file
    name = Path(_OpenMaya.MFileIO.currentFile())
    if name.basename() == untitledFileName() and \
            cmds.file(q=1, sceneName=1) == '':
        return Path()
    return name

def untitledFileName():
    """
    Obtain the base filename used for untitled scenes. In localized environments, this string will contain a translated value.
    """
    return _mel.eval('untitledFileName()')

def undoInfo(*args, **kwargs):
    """
Modifications:
    - when state is turned off, also clears pymel's api undo queue
    """
    if kwargs.get('state', kwargs.get('st', None )) in [False, 0]:
        _factories.apiUndo.flushUndo()
    return cmds.undoInfo(*args, **kwargs)

def flushUndo():
    """
Modifications:
    - also clears pymel's api undo queue
    """
    _factories.apiUndo.flushUndo()
    return cmds.flushUndo()

class UndoChunk(object):
    '''Context manager for encapsulating code in a single undo.

    Use in a with statement
    Wrapper for cmds.undoInfo(openChunk=1)/cmds.undoInfo(closeChunk=1)

    >>> import pymel.core as pm
    >>> pm.ls("MyNode*", type='transform')
    []
    >>> with pm.UndoChunk():
    ...     res = pm.createNode('transform', name="MyNode1")
    ...     res = pm.createNode('transform', name="MyNode2")
    ...     res = pm.createNode('transform', name="MyNode3")
    >>> pm.ls("MyNode*", type='transform')
    [nt.Transform(u'MyNode1'), nt.Transform(u'MyNode2'), nt.Transform(u'MyNode3')]
    >>> pm.undo() # Due to the undo chunk, all three are undone at once
    >>> pm.ls("MyNode*", type='transform')
    []
    '''
    def __enter__(self):
        cmds.undoInfo(openChunk=1)
        return self

    def __exit__(*args, **kwargs):
        cmds.undoInfo(closeChunk=1)

#===============================================================================
# Namespace
#===============================================================================
class Namespace(unicode):

    @classmethod
    def getCurrent(cls):
        return cls(cmds.namespaceInfo(cur=1))

    @classmethod
    def create(cls, name):
        ns = cmds.namespace(add=name)
        return cls(ns)

    def __new__(cls, namespace, create=False):
        namespace = ":" + namespace.strip(":")
        if not cmds.namespace(exists=namespace):
            if not create:
                raise ValueError("Namespace '%s' does not exist" % namespace)
            else:
                current = Namespace.getCurrent()
                Namespace(":").setCurrent()
                for part in namespace.split(":")[1:]:
                    if not cmds.namespace(exists=part):
                        cmds.namespace(add=part)
                    cmds.namespace(set=part)
                current.setCurrent()

        self = super(Namespace, cls).__new__(cls, namespace)
        return self

    def __repr__(self):
        return "%s(%s)" % (self.__class__.__name__, super(Namespace, self).__repr__())

    def __add__(self, other):
        return "%s:%s" % (self.rstrip(':'), other.lstrip(":"))

    def __cmp__(self, other):
        return cmp(self.strip(":"), str(other).strip(":"))

    __eq__ = lambda self, other: self.__cmp__(other)==0
    __ne__ = lambda self, other: self.__cmp__(other)!=0
    __le__ = lambda self, other: self.__cmp__(other)<=0
    __lt__ = lambda self, other: self.__cmp__(other)<0
    __ge__ = lambda self, other: self.__cmp__(other)>=0
    __gt__ = lambda self, other: self.__cmp__(other)>0

    def splitAll(self):
        return self.strip(":").split(":")

    def shortName(self):
        return self.splitAll()[-1]

    def getParent(self):
        if (unicode(self)!=u":"):
            return self.__class__(':'.join(self.splitAll()[:-1]))

    def ls(self, pattern="*", **kwargs):
        return general.ls(self + pattern, **kwargs)

    def getNode(self, nodeName, verify=True):
        node = general.PyNode(self + nodeName)
        if verify and not node.exists():
            raise Exception("Node '%s' does not exist" % node)
        return node

    def listNamespaces(self, recursive=False, internal=False):
        '''List the namespaces contained within this namespace.

        :parameters:
        recursive : `bool`
            Set to True to enable recursive search of sub (and sub-sub, etc)
            namespaces
        internal : `bool`
            By default, this command filters out certain automatically created
            maya namespaces (ie, :UI, :shared); set to True to show these
            internal namespaces as well
        '''
        curNS = Namespace.getCurrent()

        self.setCurrent()
        try:
            namespaces = map(self.__class__, cmds.namespaceInfo(listOnlyNamespaces=True) or [])

            if not internal:
                for i in [":UI",":shared"]:
                    if i in namespaces:
                        namespaces.remove(i)

            if recursive:
                childNamespaces = []
                for ns in namespaces:
                    childNamespaces.extend(ns.listNamespaces(recursive, internal))
                namespaces.extend(childNamespaces)
        finally:
            curNS.setCurrent()

        return namespaces

    def listNodes(self, recursive=False, internal=False):
        '''List the nodes contained within this namespace.

        :parameters:
        recursive : `bool`
            Set to True to enable recursive search of sub (and sub-sub, etc)
            namespaces
        internal : `bool`
            By default, this command filters out nodes in certain automatically
            created maya namespaces (ie, :UI, :shared); set to True to show
            these internal namespaces as well
        '''
        curNS = Namespace.getCurrent()

        self.setCurrent()
        try:
            if not internal or versions.current() < versions.v2011:
                # Default for recursive is false
                nodes = namespaceInfo(listOnlyDependencyNodes=True, dagPath=True)
                if recursive:
                    namespaces = self.listNamespaces(recursive=False, internal=internal)

                    for ns in namespaces:
                        nodes.extend(ns.listNodes(recursive=recursive,
                                                      internal=internal))
            else:
                nodes = namespaceInfo(listOnlyDependencyNodes=True, dagPath=True,
                                      recurse=recursive)
        finally:
            curNS.setCurrent()

        return nodes

    def setCurrent(self):
        cmds.namespace(set=self)


    def clean(self, haltOnError=True, reparentOtherChildren=True):
        '''Deletes all nodes in this namespace

        Parameters
        ----------
        haltOnError : bool
            If true, and reparentOtherChildren is set, and there is an error in
            reparenting, then raise an Exception (no rollback is performed);
            otherwise, ignore the failed reparent, and continue
        reparentOtherChildren : bool
            If True, then if any transforms in this namespace have children NOT
            in this namespace, then will attempt to reparent these children
            under world (errors during these reparenting attempts is controlled
            by haltOnError)
        '''
        cur = Namespace.getCurrent()
        self.setCurrent()
        toDelete = cmds.namespaceInfo(ls=1, dp=1) or []
        cur.setCurrent()

        if toDelete:
            if reparentOtherChildren:
                for o in general.ls(toDelete, transforms=True):
                    # Note that we only need to check IMMEDIATE children...
                    # because we're iterating through ALL transforms in this
                    # namespace
                    for c in o.getChildren(fullPath=True, type='transform'):
                        if self != c.namespace():
                            _logger.warning("Preserving %r, which was parented under %r" % (c, o))
                            try:
                                c.setParent(world=True)
                            except Exception, e:
                                if haltOnError:
                                    raise
                                _logger.error("Could not preserve %r (%s)" % (c,e))

                toDelete = general.ls(toDelete)
            if toDelete:
                _logger.debug("Deleting %d nodes from namespace '%s'" % (len(toDelete), self))
                for n in toDelete:
                    _logger.log(5, "\t%s" % n)
                    n.unlock()
                general.delete(toDelete)

    def move(self, other, force=False):
        cmds.namespace(moveNamespace=(self, other), force=force)


    # TODO:
    # - add in "proper" handling for new 2013 flags:
    #    deleteNamespaceContent (if False, error if non-empty)
    #    mergeNamespaceWithRoot
    #    mergeNamespaceWithParent
    # - need to investigate exact way in which 2013 flags work (with sub-
    #   namespaces, with children in other namespaces, etc), and possibly
    #   add in support for flags to control recursive behavior, and handling of
    #   children of transforms that are NOT in this namespace
    def remove(self, haltOnError=True, reparentOtherChildren=True):
        '''Removes this namespace

        Recursively deletes any nodes and sub-namespaces

        Parameters
        ----------
        haltOnError : bool
            If true, and reparentOtherChildren is set, and there is an error in
            reparenting, then raise an Exception (no rollback is performed);
            otherwise, ignore the failed reparent, and continue
        reparentOtherChildren : bool
            If True, then if any transforms in this namespace have children NOT
            in this namespace, then will attempt to reparent these children
            under world (errors during these reparenting attempts is controlled
            by haltOnError)
        '''
        self.clean(haltOnError=haltOnError,
                   reparentOtherChildren=reparentOtherChildren)
        for subns in self.listNamespaces():
            subns.remove(haltOnError=haltOnError,
                         reparentOtherChildren=reparentOtherChildren)
        cmds.namespace(removeNamespace=self)


def listNamespaces_old():
    """
    Deprecated
    Returns a list of the namespaces of referenced files.
    REMOVE In Favor of listReferences('dict') ?"""
    try:
        return [ cmds.file( x, q=1, namespace=1) for x in cmds.file( q=1, reference=1)  ]
    except:
        return []

def listNamespaces(root=None, recursive=False, internal=False):
    """Returns a list of the namespaces in the scene"""
    return Namespace(root or ":").listNamespaces(recursive, internal)


def namespaceInfo(*args, **kwargs):
    """
Modifications:
    - returns an empty list when the result is None
    - returns wrapped classes for listOnlyDependencyNodes
    """
    pyNodeWrap = kwargs.get('lod', kwargs.get('listOnlyDependencyNodes', False) )
    if pyNodeWrap:
        kwargs.pop('dp', False)
        kwargs['dagPath'] = True

    res = cmds.namespaceInfo(*args, **kwargs)

    if any( kwargs.get(x, False) for x in ('ls', 'listNamespace',
                                           'lod', 'listOnlyDependencyNodes',
                                           'lon', 'listOnlyNamespaces') ):
        res = _util.listForNone(res)

    if pyNodeWrap:
        import general
        nodes = []
        for x in res:
            try:
                nodes.append(general.PyNode(x))
            except general.MayaNodeError:
                # some ui objects/tools - like '|CubeCompass' -
                # get returned... so just ignore any nodes we can't create
                pass
        res = nodes

    return res

#-----------------------------------------------
#  Translator Class
#-----------------------------------------------

class Translator(object):
    """
    >>> ascii = Translator('mayaAscii')
    >>> ascii.ext
    u'ma'
    >>> bin = Translator.fromExtension( 'mb' )
    >>> bin
    Translator(u'mayaBinary')
    >>> bin.name
    u'mayaBinary'
    >>> bin.hasReadSupport()
    True

    """

    @staticmethod
    def listRegistered( ):
        return cmds.translator(q=1,list=1)

    @staticmethod
    def fromExtension( ext ):
        if ext.startswith('.'):
            ext = ext[1:]
        for k in Translator.listRegistered():
            t = Translator(k)
            if ext == t.ext:
                return t

    def __init__(self, name):
        assert name in cmds.translator(q=1,list=1), "%s is not the name of a registered translator" % name
        self._name = unicode(name)

    def __str__(self):
        return self._name

    def __repr__(self):
        return '%s(%r)' % ( self.__class__.__name__, self._name )

    def extension(self):
        return cmds.translator(self._name, q=1, ext=1)
    ext = property(extension)
    name = property(__str__)
    def filter(self):
        return cmds.translator(self._name, q=1, filter=1)
    def optionsScript(self):
        return cmds.translator(self._name, q=1, optionsScript=1)

    def hasReadSupport(self):
        return bool( cmds.translator(self._name, q=1, readSupport=1) )
    def hasWriteSupport(self):
        return ( cmds.translator(self._name, q=1, writeSupport=1) )

    def getDefaultOptions(self):
        return cmds.translator(self._name, q=1, defaultOptions=1)
    def setDefaultOptions(self, options):
        cmds.translator(self._name, e=1, defaultOptions=options)
    def getFileCompression(self):
        return cmds.translator(self._name, q=1, fileCompression=1)
    def setFileCompression(self, compression):
        cmds.translator(self._name, e=1, fileCompression=compression)


#-----------------------------------------------
#  Workspace Class
#-----------------------------------------------

class WorkspaceEntryDict(object):
    def __init__(self, entryType):
        self.entryType = entryType
    def __repr__(self):
        return '%s(%r)' % ( self.__class__.__name__, self.entryType )
    def __getitem__(self, item):
        res = cmds.workspace( item, **{'q' : 1, self.entryType + 'Entry' : 1 } )
        if not res:
            raise KeyError, item
        return res
    def __setitem__(self, item, value):
        return cmds.workspace( **{self.entryType: [item, value] } )
    def __contains__(self, key):
        return key in self.keys()
    def items(self):
        entries = _util.listForNone( cmds.workspace( **{'q' : 1, self.entryType : 1 } ) )
        res = []
        for i in range( 0, len(entries), 2):
            res.append( (entries[i], entries[i+1] ) )
        return res
    def keys(self):
        return cmds.workspace( **{'q' : 1, self.entryType + 'List': 1 } )
    def values(self):
        entries = _util.listForNone( cmds.workspace( **{'q' : 1, self.entryType : 1 } ) )
        res = []
        for i in range( 0, len(entries), 2):
            res.append( entries[i+1] )
        return res
    def get(self, item, default=None):
        try:
            return self.__getitem__(item)
        except KeyError:
            return default
    def __iter__(self):
        return iter(self.keys())
    has_key = __contains__


class Workspace(object):
    """
    This class is designed to lend more readability to the often confusing workspace command.
    The four types of workspace entries (objectType, fileRule, renderType, and variable) each
    have a corresponding dictiony for setting and accessing these mappings.

        >>> from pymel.all import *
        >>> workspace.fileRules['mayaAscii']
        u'scenes'
        >>> workspace.fileRules.keys() # doctest: +ELLIPSIS
        [...u'mayaAscii', u'mayaBinary',...]
        >>> 'mayaBinary' in workspace.fileRules
        True
        >>> workspace.fileRules['super'] = 'data'
        >>> workspace.fileRules.get( 'foo', 'some_default' )
        'some_default'

    the workspace dir can be confusing because it works by maintaining a current working directory that is persistent
    between calls to the command.  In other words, it works much like the unix 'cd' command, or python's 'os.chdir'.
    In order to clarify this distinction, the names of these flags have been changed in their class method counterparts
    to resemble similar commands from the os module.

    old way (still exists for backward compatibility)
        >>> proj = workspace(query=1, dir=1)
        >>> proj  # doctest: +ELLIPSIS
        u'...'
        >>> workspace(create='mydir')
        >>> workspace(dir='mydir') # move into new dir
        >>> workspace(dir=proj) # change back to original dir

    new way
        >>> proj = workspace.getcwd()
        >>> proj  # doctest: +ELLIPSIS
        Path('...')
        >>> workspace.mkdir('mydir')
        >>> workspace.chdir('mydir')
        >>> workspace.chdir(proj)

    All paths are returned as an pymel.core.system.Path class, which makes it easy to alter or join them on the fly.
        >>> workspace.path / workspace.fileRules['mayaAscii']  # doctest: +ELLIPSIS
        Path('...')

    """
    __metaclass__ = _util.Singleton

    objectTypes = WorkspaceEntryDict( 'objectType' )
    fileRules     = WorkspaceEntryDict( 'fileRule' )
    renderTypes = WorkspaceEntryDict( 'renderType' )
    variables     = WorkspaceEntryDict( 'variable' )

#    def __init__(self):
#        self.objectTypes = WorkspaceEntryDict( 'objectType' )
#        self.fileRules     = WorkspaceEntryDict( 'fileRule' )
#        self.renderTypes = WorkspaceEntryDict( 'renderType' )
#        self.variables     = WorkspaceEntryDict( 'variable' )

    @classmethod
    def open(self, workspace):
        return cmds.workspace( workspace, openWorkspace=1 )
    @classmethod
    def save(self):
        return cmds.workspace( saveWorkspace=1 )
    @classmethod
    def update(self):
        return cmds.workspace( update=1 )
    @classmethod
    def new(self, workspace):
        return cmds.workspace( workspace, newWorkspace=1 )
    @classmethod
    def getName(self):
        return cmds.workspace( q=1, act=1 )
    @classmethod
    def getPath(self):
        return Path(cmds.workspace( q=1, fullName=1 ))
    @classmethod
    def chdir(self, newdir):
        return cmds.workspace( dir=newdir )
    @classmethod
    def getcwd(self):
        return Path(cmds.workspace( q=1, dir=1 ))
    @classmethod
    def mkdir(self, newdir):
        return cmds.workspace( cr=newdir )
    @property
    def path(self):
        return Path(cmds.workspace( q=1, fullName=1 ))
    @property
    def name(self):
        return cmds.workspace( q=1, act=1 )

    def __call__(self, *args, **kwargs):
        """provides backward compatibility with cmds.workspace by allowing an instance
        of this class to be called as if it were a function"""
        return cmds.workspace( *args, **kwargs )

    def expandName(self, path):
        return cmds.workspace(expandName=path)

workspace = Workspace()

#-----------------------------------------------
#  FileInfo Class
#-----------------------------------------------

class FileInfo( object ):
    """
    store and get custom data specific to this file:

        >>> from pymel.all import *
        >>> fileInfo['lastUser'] = env.user()

    if the python structures have valid __repr__ functions, you can
    store them and reuse them later:

        >>> fileInfo['cameras'] = str( ls( cameras=1) )
        >>> camList = eval(fileInfo['cameras'])
        >>> camList[0]
        nt.Camera(u'frontShape')

    for backward compatibility it retains it's original syntax as well:

        >>> fileInfo( 'myKey', 'myData' )

    """
    __metaclass__ = _util.Singleton

    def __contains__(self, item):
        return item in self.keys()

    def __getitem__(self, item):
        result = cmds.fileInfo(item, q=1)
        if not result:
            raise KeyError(item)
        elif len(result) > 1:
            raise RuntimeError("error getting fileInfo for key %r - more than one value returned" % item)
        else:
            return result[0]

    def __setitem__(self, item, value):
        cmds.fileInfo( item, value )

    def __delitem__(self, item):
        cmds.fileInfo( remove=item )

    def __call__(self, *args, **kwargs):
        if kwargs.get('query', kwargs.get('q', False) ):
            return self.items()
        else:
            cmds.fileInfo( *args, **kwargs )

    def items(self):
        res = cmds.fileInfo( query=1)
        newRes = []
        for i in range( 0, len(res), 2):
            newRes.append( (res[i], res[i+1]) )
        return newRes

    def keys(self):
        res = cmds.fileInfo( query=1)
        newRes = []
        for i in range( 0, len(res), 2):
            newRes.append(  res[i] )
        return newRes

    def values(self):
        res = cmds.fileInfo( query=1)
        newRes = []
        for i in range( 0, len(res), 2):
            newRes.append( res[i+1] )
        return newRes

    def pop(self, *args):
        if len(args) > 2:
            raise TypeError, 'pop expected at most 2 arguments, got %d' % len(args)
        elif len(args) < 1:
            raise TypeError, 'pop expected at least 1 arguments, got %d' % len(args)

        if args[0] not in self.keys():
            try:
                return args[1]
            except IndexError:
                raise KeyError, args[0]

        cmds.fileInfo( rm=args[0])
    def __iter__(self):
        return iter(self.keys())
    has_key = __contains__

    def get(self, key, default=None):
        if key in self:
            return self[key]
        else:
            return default

fileInfo = FileInfo()



#-----------------------------------------------
#  File Classes
#-----------------------------------------------

class Path(pathClass):
    """A basic Maya file class. it gets most of its power from the path class written by Jason Orendorff.
    see path.py for more documentation."""
    def __repr__(self):
        return "%s('%s')" % (self.__class__.__name__, self)

    getTypeName = _factories.makeQueryFlagMethod( cmds.file, 'type' )
    setSubType = _factories.makeQueryFlagMethod( cmds.file, 'subType', 'setSubType')
#
#class CurrentFile(Path):
#    getRenameToSave = classmethod( _factories.makeQueryFlagMethod( cmds.file, 'renameToSave', 'getRenameToSave'))
#    setRenameToSave = classmethod( _factories.make_factories.createflagMethod( cmds.file, 'renameToSave', 'setRenameToSave'))
#    anyModified = classmethod( _factories.makeQueryFlagMethod( cmds.file, 'anyModified'))
#    @classmethod
#    @_factories.addMelDocs( 'file', 'lockFile')
#    def lock(self):
#        return cmds.file( lockFile=True)
#
#    @classmethod
#    @_factories.addMelDocs( 'file', 'lockFile')
#    def unlock(self):
#        return cmds.file( lockFile=False)
#    isModified = classmethod( _factories.makeQueryFlagMethod( cmds.file, 'modified', 'isModified'))
#    setModified = classmethod( _factories.make_factories.createflagMethod( cmds.file, 'modified', 'setModified'))
#
#    isWritableInScene = _factories.makeQueryFlagMethod( cmds.file, 'writable' )
#    @classmethod
#    @_factories.addMelDocs( 'file', 'sceneName')
#    def name(self):
#        return Path( _OpenMaya.MFileIO.currentFile() )





#===============================================================================
# FileReference
#===============================================================================

def iterReferences( parentReference=None, recursive=False, namespaces=False,
                    refNodes=False, references=True, recurseType='depth',
                    loaded=None, unloaded=None):
    """
    returns references in the scene as a list of value tuples.

    The values in the tuples can be namespaces, refNodes (as PyNodes), and/or
    references (as FileReferences), and are controlled by their respective
    keywords (and are returned in that order).  If only one of the three options
    is True, the result will not be a list of value tuples, but will simply be a
    list of values.

    Parameters
    ----------
    parentReference : string, `Path`, or `FileReference`
        a reference to get sub-references from. If None (default), the current
        scene is used.

    recursive : bool
        recursively determine all references and sub-references

    namespaces : bool
        controls whether namespaces are returned

    refNodes : bool
        controls whether reference PyNodes are returned

    refNodes : bool
        controls whether FileReferences returned

    recurseType : string
        if recursing, whether to do a 'breadth' or 'depth' first search;
        defaults to a 'depth' first

    loaded : bool or None
        whether to return loaded references in the return result; if both of
        loaded/unloaded are not given (or None), then both are assumed True;
        if only one is given, the other is assumed to have the opposite boolean
        value

    unloaded : bool or None
        whether to return unloaded references in the return result; if both of
        loaded/unloaded are not given (or None), then both are assumed True;
        if only one is given, the other is assumed to have the opposite boolean
        value
    """
    import general

    validRecurseTypes = ('breadth', 'width')
    if recurseType not in validRecurseTypes:
        ValueError('%s was not an acceptable value for recurseType - must be one of %s' % (recurseType, ', '.join(validRecurseTypes)))

    if parentReference is None:
        refs = cmds.file(q=1, reference=1)
    else:
        refs = cmds.file(parentReference, q=1, reference=1)

    if loaded is None and unloaded is None:
        loaded = True
        unloaded = True
    elif loaded is None:
        loaded = not unloaded
    elif unloaded is None:
        unloaded = not loaded

    if not (loaded or unloaded):
        return

    #print "reference", parentReference
    while refs:
        #if recursive and recurseType == 'breadth':
        ref = refs.pop(0)
        row = []

        refNode = cmds.file(ref, q=1, referenceNode=1)
        refNode = general.PyNode( refNode )

        wasLoaded = cmds.referenceQuery(refNode, isLoaded=1)

        # If we are only looking for loaded, and this isn't, we can bail
        # immediately... any child references will also be unloaded
        if not unloaded and not wasLoaded:
            continue

        refObj = None
        if namespaces:
            refObj = FileReference(refNode)
            row.append(refObj.fullNamespace)
        if refNodes:
            row.append(refNode)
        if references:
            if refObj is None:
                refObj = FileReference(refNode)
            row.append(refObj)
        if len(row) == 1:
            row = row[0]
        else:
            row = tuple(row)

        if ((loaded and wasLoaded) or (unloaded and not wasLoaded)):
            yield row
        if recursive:
            if recurseType == 'depth':
                for x in iterReferences(parentReference=ref,
                                        recursive=True,
                                        namespaces=namespaces,
                                        refNodes=refNodes,
                                        references=references,
                                        loaded=loaded,
                                        unloaded=unloaded):
                    #print "yield sub"
                    yield x
            elif recurseType == 'breadth':
                refs.extend(cmds.file(ref, q=1, reference=1))
        #print "for done"
    #print "done"

def listReferences(parentReference=None, recursive=False, namespaces=False,
                   refNodes=False, references=True, loaded=None, unloaded=None):
    """
    Like iterReferences, except returns a list instead of an iterator.

    """
    return list(iterReferences(parentReference=parentReference,
                               recursive=recursive,
                               namespaces=namespaces,
                               refNodes=refNodes,
                               references=references,
                               loaded=loaded,
                               unloaded=unloaded))

listReferences.__doc__ += iterReferences.__doc__

#def getReferences( reference=None, recursive=False, namespaces=True, refNodes=False, asDict=True ):
#    """
#    returns references in the scene as (namespace, FileReference) pairs
#
#    :param reference: a reference to get sub-references from. If None (default), the current scene is used.
#    :type reference: string, `Path`, or `FileReference`
#
#    :param recursive: recursively determine all references and sub-references
#    :type recursive: bool
#
#    """
#    import general
#    import other
##    if asDict:
##        assert not (namespaces and refNodes)
#
#    res = []
#    if reference is None:
#        refs = zip( cmds.file( q=1, reference=1), cmds.file( q=1, reference=1, unresolvedName=1) )
#    else:
#        refs = zip( cmds.file( reference, q=1, reference=1), cmds.file( reference, q=1, reference=1, unresolvedName=1) )
#
#    for ref, unresolvedRef in refs:
#        row = []
#        print ref, cmds.file( ref, q=1, namespace=1)
#        refNode = cmds.file( ref, q=1, referenceNode=1)
#
#        fileRef = FileReference(ref, unresolvedPath=unresolvedRef)
#        if namespaces:
#            row.append( other.DependNodeName( refNode ).namespace() + cmds.file( ref, q=1, namespace=1)  )
#        if refNodes:
#            row.append( general.PyNode( refNode ) )
#        row.append( fileRef )
#        res.append( row )
#        if recursive:
#            res += getReferences(reference=ref, recursive=True, namespaces=namespaces, refNodes=refNodes)
#
#    return res

def getReferences(parentReference=None, recursive=False):
    return dict( iterReferences( parentReference=parentReference, recursive=recursive, namespaces=True, refNodes=False ) )

#@decorator
#def suspendReferenceUpdates(func):
#    def suspendedRefUpdateFunc(*args, **kw):
#        ReferenceCache.deferReferenceUpdates(True)
#        try:
#            ret = func(*args, **kw)
#        finally:
#            ReferenceCache.deferReferenceUpdates(False)
#        return ret
#    return suspendedRefUpdateFunc
#
#class ReferenceCache(object):
#    """
#    For the sake of speeding up the process of identifying File References in the scene
#    and properly associating with their respective namespace/reference-node/fullpath,
#    a set of API callbacks is set-up which triggers a file-reference cache refresh.
#
#    This callback mechanism can be suspended temporarily, which is useful when a process
#    needs to change the state of several references at once (loading/unloading, adding/removing).
#    Use the 'deferReferenceUpdates' function or the 'suspendReferenceUpdates' decorator
#    """
#
#    _deferReferenceUpdates = False
#    _callbacks = []
#    _allFiles = []
#    byNamespace = {}
#    byRefNode = {}
#    byFullPath = {}
#    callbacksEnabled = False
#
#    @classmethod
#    def deferReferenceUpdates(cls, state):
#        if state:
#            msg = "SUSPENDING "
#        else:
#            msg = "Enabling"
#        _logger.debug("%s Reference Updates" % (msg))
#        cls._deferReferenceUpdates = state
#
#
#    @classmethod
#    def refresh(cls):
#
#        import general
#        import other
#
#        cls.byNamespace.clear()
#        cls.byRefNode.clear()
#        cls.byFullPath.clear()
#
#        def getRefs(reference=None, currNamespace='' ):
#            res = []
#            args = []
#            if reference is not None:
#                args.append(reference)
#
#            resolved = cmds.file(  q=1, reference=1, *args )
#            unresolved = cmds.file( q=1, reference=1, unresolvedName=1, *args )
#
#            assert len(resolved) == len(unresolved)
#
#            for ref, unresolvedRef in zip( resolved, unresolved ):
#                row = []
#                # we cannot reliably get refNode in a nested reference scenario, but it's ok
#                # we can get the refFile directly from refNode using MFileIO.getReferenceFileByNode()
#                # so there's no real need to keep a dictionary
#
#                namespace = cmds.file( ref, q=1, namespace=1)
#                fullNamespace = currNamespace + namespace
#                row.append( ref )
#                row.append( unresolvedRef )
#                #row.append( refNode )
#                res.append( row )
#                row.append( fullNamespace )
#
#                res += getRefs(ref, fullNamespace + ':' )
#
#            return res
#
#        refData = getRefs()
#        _logger.info("Refreshing %s references..." % len(refData))
#
#        for path, unresolvedPath, namespace in refData:
#
#            #fr = ( fullpath, unresolvedPath )
#
#            _logger.debug("Found %s" % path)
#            #refNode = general.PyNode( refNode )
#            data = ( path, unresolvedPath )
#            # The FileReference Object is inserted into the dictionray under multiple keys
#            # so that it can be easily found using a full-namespace, a reference-node name, or a filepath
#            cls.byNamespace[namespace] = data
#            #cls.byRefNode[refNode] = data
#            cls.byFullPath[path.replace("/","\\")] = data
#            cls.byFullPath[path.replace("\\","/")] = data
#
#    @classmethod
#    def _getAllFileReferences(cls):
#        ret =  [v for (k,v) in cls.byNamspace.iteritems() ]
#        if not ret:
#            cls.refresh()
#            ret =  [v for (k,v) in cls.byNamspace.iteritems()]
#        return ret
#
#    @classmethod
#    def setupFileReferenceCallbacks(cls):
#        cls.callbacksEnabled = True
#
#        def refererencesUpdated(*args):
#            if cls._deferReferenceUpdates:
#                return
#            cls.refresh()
#
#        messages = ['kAfterReference', 'kAfterRemoveReference', 'kAfterImportReference', 'kAfterExportReference', 'kSceneUpdate']
#        for msg in messages:
#            _logger.debug("Setting up File-Reference Callback: %s" % msg)
#            cb = _OpenMaya.MSceneMessage.addCallback(getattr(_OpenMaya.MSceneMessage,msg), refererencesUpdated, None)
#            if hasattr(cb, 'disown'):
#                cb.disown()     # suppresses those swig 'memory leak' warnings
#            cls._callbacks.append(cb)
#
#    @classmethod
#    def getPaths(cls, path=None, namespace=None):
#
#        # there's no guarantee that:
#        #  the namespace has not changed since the last cache refresh
#        #  the refNode has not been renamed since the last cache refresh (doesn't matter if we're using > 2009, where node hashing is not based on name)
#        if not cls.callbacksEnabled or namespace:
#            # force refresh (only need to try once)
#            attempts=1
#            cls.refresh()
#        else:
#            # try twice (refresh if failed the first time)
#            attempts = 2
#
#        while attempts:
#            try:
#                if path:
#                    resolvedPath, unresolvedPath = cls.byFullPath[path]
##                elif refnode:
##                    refnode = general.PyNode(refnode)
##                    data = ReferenceCache.byRefNode[refnode]
#                elif namespace:
#                    resolvedPath, unresolvedPath = cls.byNamespace[namespace]
#
#                return resolvedPath, unresolvedPath
#            except KeyError:
#                attempts -= 1
#                if attempts:
#                    ReferenceCache.refresh()
#        raise ValueError("Could not find FileReference (args: %s)" % [path, namespace])

class FileReference(object):
    """
    A class for manipulating references which inherits Path and path.  you can create an
    instance by supplying the path to a reference file, its namespace, or its reference node to the
    appropriate keyword. The namespace and reference node of the reference can be retreived via
    the namespace and refNode properties. The namespace property can also be used to change the namespace
    of the reference.

    Use listReferences command to return a list of references as instances of the FileReference class.

    It is important to note that instances of this class will have their copy number stripped off
    and stored in an internal variable upon creation.  This is to maintain compatibility with the numerous methods
    inherited from the path class which requires a real file path. When calling built-in methods of FileReference,
    the path will automatically be suffixed with the copy number before being passed to maya commands, thus ensuring
    the proper results in maya as well.

    """

#    the reference class now uses a reference node as it's basis, because if we store the refNode as a PyNode, we can
#    quickly and automatically get any updates made to its name through outside methods.  almost any reference info can be queried using the
#    refNode (without resorting to a path, which might change without us knowing), including resolved and unresolved
#    paths.  namespaces are still the one weak spot, for which we must first get a path with copy number.  the use of
#    a refNode precludes the need for the caching system, so long as a) using referenceQuery to get file paths from a refNode
#    provides adequate performance, and b) using referenceQuery in __init__ to get a refNode from a path is os agnostic.
#    in general, since almost all the internal queries use the refNode,
#    there should be little need for the paths, except for displaying to the user.

    def __init__(self, pathOrRefNode=None, namespace=None, refnode=None):
        import general, nodetypes
        self._refNode = None
        if pathOrRefNode:
            if isinstance(pathOrRefNode, (basestring,Path)):
                try:
                    self._refNode = general.PyNode( cmds.referenceQuery( str(pathOrRefNode), referenceNode=1 ) )
                except RuntimeError:
                    pass
            if not self._refNode:
                if isinstance( pathOrRefNode, nodetypes.Reference ):
                    self._refNode = pathOrRefNode
                else:
                    try:
                        self._refNode = general.PyNode( pathOrRefNode )
                    except general.MayaObjectError:
                        self._refNode = general.PyNode( cmds.file( pathOrRefNode, q=1, referenceNode=True) )
        elif namespace:
            namespace = namespace.rstrip(':')
            for iNamespace, iRefNode in iterReferences(namespaces=True, recursive=True, refNodes=True, references=False):
                if namespace == iNamespace:
                    self._refNode = iRefNode
                    break
            if self._refNode is None:
                raise RuntimeError,"Could not find a reference with the namespace %r" % namespace

        elif refnode:
            self._refNode = general.PyNode( refnode )

        assert self._refNode.type() == 'reference'

#        def create(path, unresolvedPath ):
#            """Actually create the FileReference object"""
#            def splitCopyNumber(path):
#                """Return a tuple with the path and the copy number. Second element will be None if no copy number"""
#                buf = path.split('{')
#                try:
#                    return ( buf[0], int(buf[1][:-1]) )
#                except:
#                    return (path, None)
#
#            path, copyNumber = splitCopyNumber(path)
#            unresolvedPath, copyNumber2 = splitCopyNumber(unresolvedPath)
#            assert copyNumber == copyNumber2, "copy number of %s is not the same as %s" % ( path, unresolvedPath )
#            self._file = Path(path)
#            self._copyNumber = copyNumber
#            self._unresolvedPath = Path(unresolvedPath)
#            #self._refNode = refNode
#            #return self
#
#        # Direct mappings:
#        # refNode --> refFile:  MFileIO.getReferenceFileByNode( refNode )
#        # refFile --> refNode:  cmds.file( refFile, q=1, referenceNode=1)
#        # refFile --> namespace:  refNode.namespace() + cmds.file( refFile, q=1, namespace=1)
#        self._refNode = None
#
#        import general
#        if unresolvedPath:
#            # check to ensure it's legit
#            assert path in ReferenceCache.byFullPath,  "%s is not a valid reference file" % path
#            return create(path, unresolvedPath)
#
#        if refnode:
#            refNode = general.PyNode(refnode)
#            self._refNode = refNode
#            # refNode is all we need for now. we can get anything else from this when it is asked for
#            return
#
#
#
#        resolvedPath, unresolvedPath = ReferenceCache.getPaths( path, namespace )
#        create( resolvedPath, unresolvedPath )



    def __melobject__(self):
        return self.withCopyNumber()

    def __repr__(self):
        return u'%s(%r, refnode=%r)' % ( self.__class__.__name__, self.withCopyNumber(), unicode(self.refNode) )

    def __str__(self):
        return self.withCopyNumber()

    def __gt__(self, other):
        return self.withCopyNumber().__gt__(unicode(other))
    def __ge__(self, other):
        return self.withCopyNumber().__ge__(unicode(other))
    def __lt__(self, other):
        return self.withCopyNumber().__lt__(unicode(other))
    def __le__(self, other):
        return self.withCopyNumber().__le__(unicode(other))
    def __eq__(self, other):
        return self.withCopyNumber().__eq__(unicode(other))
    def __ne__(self, other):
        return self.withCopyNumber().__ne__(unicode(other))

    def __hash__(self):
        return hash(self.withCopyNumber())

    def subReferences(self):
        namespace = self.namespace + ':'
        res = {}
        for x in cmds.file( self, q=1, reference=1):
            try:
                res[namespace + cmds.file( x, q=1, namespace=1)] = FileReference(x)
            except Exception, e:
                _logger.warn("Could not get namespace for '%s': %s" % (x,e))
        return res

    @_factories.addMelDocs('namespace', 'exists')
    def namespaceExists(self):
        return cmds.namespace(ex=self.namespace)

    def _getNamespace(self): return cmds.file( self.withCopyNumber(), q=1, ns=1)
    def _setNamespace(self, namespace):return cmds.file( self.withCopyNumber(), e=1, ns=namespace)
    namespace = property(_getNamespace, _setNamespace)

    @property
    def fullNamespace(self):
        if self.refNode.isReferenced():
            # getting the fullnamespace for a referenced node is actually a
            # little tricky... initially, we just used the namespace of the
            # reference node itself, and tacked on the namespace associated with
            # this reference

            # Unfortunately, this doesn't work, because it's possible for the
            # reference node itself to be placed in a namespace other than
            # the root.

            # As an example, say we have a "cube.ma", which contains a node,
            # "cubeShape", and we reference that into another scene, creating a
            # reference node called "cubeRN", and associating a namespace
            # "cubeNS".

            # So, the cube node would be ":cubeNS:cubeShape", and the reference
            # node would be ":cubeRN"

            # However, it is actually possible for the reference node itself to
            # be in some other, totally non-related namespace - say,
            # "dead_parrot_NS". In this situation, we would have:
            #    :dead_parrot_NS:cubeRN
            #    :cubeNS:cubeShape
            # Note that cubeShape did NOT inherit the dead_parrot_NS of the
            # reference node which created it!

            # also, we can't use cmds.referenceQuery(parentNamespace=1), as this
            # also does the "wrong" thing, and returns the namespace of the
            # reference node - ie, it would return "dead_parrot_NS"...
            parentFile = cmds.referenceQuery(str(self.refNode), parent=1,
                                             filename=1)
            parentNamespace = FileReference(parentFile).fullNamespace
            if not parentNamespace.endswith(':'):
                parentNamespace += ':'
        else:
            parentNamespace = ''
        return "%s%s" % (parentNamespace, self.namespace)

    @property
    def refNode(self):
        return self._refNode

    @property
    def path(self):
        # TODO: check in cache to see if this has changed
#        if not ReferenceCache.callbacksEnabled or _internal.Version.current < _internal.Version.v2009:
#            ReferenceCache.refresh()
#
#        return ReferenceCache[ self.refNode ]._file

        #path = self.withCopyNumber().split('{')[0]
        path = cmds.referenceQuery( self.refNode, filename=1, withoutCopyNumber=1 )
        return Path(path)

    def withCopyNumber(self):
        """return the path with the copy number at the end"""
        # the file path is subject to change
        path = cmds.referenceQuery( self.refNode, filename=1 )
        return path

#        if self._copyNumber is not None:
#            return u'%s{%d}' % (self.path(), self._copyNumber)
#        return unicode( self.path() )

    def unresolvedPath(self):
        path = cmds.referenceQuery( self.refNode, filename=1, unresolvedName=1, withoutCopyNumber=1 )
        return Path(path)

    def parent(self):
        '''Returns the parent FileReference object, or None
        '''
        parentNode = cmds.referenceQuery(self.refNode, referenceNode=1,
                                         parent=1)
        if parentNode is None:
            return None
        else:
            return FileReference(refnode=parentNode)


#    @_factories.createflag('file', 'importReference')
#    def importContents(self, **kwargs):
#        return cmds.file( self.withCopyNumber(), **kwargs )

    @_factories.addMelDocs('file', 'importReference')
    def importContents(self, removeNamespace=False):
        ns = self.namespace
        res = cmds.file( rfn=self.refNode, importReference=1 )
        #res = cmds.file( rfn=self.refNode, importReference=1 )
        if removeNamespace:
            cmds.namespace( mv=(ns, ':'), f=1 )
            cmds.namespace( rm=ns )
        return res

#    @_factories.createflag('file', 'removeReference')
#    def remove(self, **kwargs):
#        return cmds.file( self.withCopyNumber(), **kwargs )

    @_factories.addMelDocs('file', 'removeReference')
    def remove(self):
        return cmds.file( rfn=self.refNode, removeReference=1 )

#    @_factories.addMelDocs('file', 'unloadReference')
#    def unload(self):
#        return cmds.file( self.withCopyNumber(), unloadReference=1 )

    @_factories.addMelDocs('file', 'unloadReference')
    def unload(self):
        return cmds.file( rfn=self.refNode, unloadReference=1 )

    @_factories.addMelDocs('file', 'loadReference')
    def load(self, newFile=None, **kwargs):
        if not newFile:
            args = ()
        else:
            args = (newFile,)
        return cmds.file( loadReference=self.refNode,*args, **kwargs )

    @_factories.addMelDocs('file', 'loadReference')
    def replaceWith(self, newFile, **kwargs):
        return self.load(newFile, **kwargs)

    @_factories.addMelDocs('file', 'cleanReference')
    def clean(self, **kwargs):
        return cmds.file( cleanReference=self.refNode, **kwargs )

    @_factories.addMelDocs('file', 'lockReference')
    def lock(self):
        return cmds.file( self.withCopyNumber(), lockReference=1 )

    @_factories.addMelDocs('file', 'lockReference')
    def unlock(self):
        return cmds.file( self.withCopyNumber(), lockReference=0 )

#    @_factories.addMelDocs('file', 'deferReference')
#    def isDeferred(self):
#        return cmds.file( self.withCopyNumber(), q=1, deferReference=1 )

    @_factories.addMelDocs('file', 'deferReference')
    def isDeferred(self):
        return cmds.file( rfn=self.refNode, q=1, deferReference=1 )

    @_factories.addMelDocs('file', 'deferReference')
    def isLoaded(self):
        return not cmds.file( rfn=self.refNode, q=1, deferReference=1 )

    @_factories.addMelDocs('referenceQuery', 'nodes')
    def nodes(self):
        import general
        nodes = cmds.referenceQuery(str(self.refNode), nodes=1, dagPath=1)
        if not nodes:
            nodes = []
        return [general.PyNode(x) for x in nodes]

    @_factories.addMelDocs('file', 'copyNumberList')
    def copyNumberList(self):
        """returns a list of all the copy numbers of this file"""
        return cmds.file( self, q=1, copyNumberList=1 )

    @_factories.addMelDocs('file', 'selectAll')
    def selectAll(self):
        return cmds.file( self.withCopyNumber(), selectAll=1 )


    @_factories.addMelDocs('file', 'usingNamespaces')
    def isUsingNamespaces(self):
        return cmds.file( self.withCopyNumber(), q=1, usingNamespaces=1 )

    @_factories.addMelDocs('file', 'exportAnimFromReference')
    def exportAnim( self, exportPath, **kwargs ):
        kwargs['exportAnimFromReference'] = 1
        _setTypeKwargFromExtension(exportPath, kwargs)
        return Path(cmds.file( exportPath, rfn=self.refNode, **kwargs))

    @_factories.addMelDocs('file', 'exportSelectedAnimFromReference')
    def exportSelectedAnim( self, exportPath, **kwargs ):
        kwargs['exportSelectedAnimFromReference'] =1
        _setTypeKwargFromExtension(exportPath, kwargs)
        return Path(cmds.file( exportPath, rfn=self.refNode, **kwargs))


    def getReferenceEdits(self, **kwargs):
        """Get a list of ReferenceEdit objects for this node

        Adapted from:
        referenceQuery -editString -onReferenceNode <self.refNode>

        Notes
        -----
        By default, removes all edits. If neither of successfulEdits or
        failedEdits is given, they both default to True. If only one is given,
        the other defaults to the opposite value.
        """

        kwargs.pop('editStrings', None)
        kwargs.pop('es', None)
        edits = referenceQuery(self.refNode, editStrings=True,
                               onReferenceNode=self.refNode, **kwargs)
        return edits

    def removeReferenceEdits(self, editCommand=None, force=False, **kwargs):
        """Remove edits from the reference.

        Parameters
        ----------
        editCommand : str
            If specified, remove only edits of a particular type: addAttr,
            setAttr, connectAttr, disconnectAttr or parent
        force : bool
            Unload the reference if it is not unloaded already
        successfulEdits : bool
            Whether to remove successful edits
        failedEdits : bool
            Whether to remove failed edits

        Notes
        -----
        By default, removes all edits. If neither of successfulEdits or
        failedEdits is given, they both default to True. If only one is given,
        the other defaults to the opposite value. This will only succeed on
        unapplied edits (ie, on unloaded nodes, or failed edits)... However,
        like maya.cmds.file/maya.cmds.referenceEdit, no error will be raised
        if there are no unapplied edits to work on. This may change in the
        future, however...
        """

        if force and self.isLoaded():
            self.unload()

        if editCommand:
            kwargs['editCommand'] = editCommand

        _translateEditFlags(kwargs)
        kwargs.pop('r', None)
        kwargs['removeEdits'] = True
        cmds.referenceEdit(str(self.refNode), **kwargs)

def _translateEditFlags(kwargs, addKwargs=True):
    '''Given the pymel values for successfulEdits/failedEdits (which may be
    True, False, or None), returns the corresponding maya.cmds values to use
    '''
    successful = kwargs.pop('successfulEdits', kwargs.pop('scs', None))
    failed = kwargs.pop('failedEdits', kwargs.pop('fld', None))

    if successful is None and failed is None:
        successful = True
        failed = True
    elif successful is None:
        successful = not failed
    elif failed is None:
        failed = not successful

    if addKwargs:
        kwargs['successfulEdits'] = successful
        kwargs['failedEdits'] = failed
    return successful, failed


def referenceQuery(*args, **kwargs):
    """
    Modifications:
    - When queried for 'es/editStrings', returned a list of ReferenceEdit objects
    - By default, removes all edits. If neither of successfulEdits or
      failedEdits is given, they both default to True. If only one is given,
      the other defaults to the opposite value.
    """
    if kwargs.get("editStrings", kwargs.get("es")):
        from general import PyNode, MayaNodeError, MayaAttributeError

        fr = None
        if isinstance(args[0], FileReference):
            fr = args[0]
        else:
            target = None
            try:
                target = PyNode(args[0])
            except (MayaNodeError, MayaAttributeError):
                pass

            if target:
                if target.type()=='reference':
                    fr = FileReference(refnode=target)
                else:
                    fr = target.referenceFile()
            else:
                target = Path(args[0])
                if target.isfile():
                    fr = FileReference(target)

            if not isinstance(fr, FileReference):
                # Last ditch - just try casting to a FileReference
                fr = FileReference(args[0])

        successfulEdits, failedEdits = _translateEditFlags(kwargs,
                                                           addKwargs=False)

        modes = []
        if failedEdits:     modes.append(False)
        if successfulEdits: modes.append(True)

        allEdits = []
        for mode in modes:
            #print "cmds.referenceQuery(%r, failedEdits=%r, successfulEdits=%r, **%r)" % (fr.refNode, not mode, mode, kwargs)
            edits = cmds.referenceQuery(fr.refNode,
                                        failedEdits = not mode,
                                        successfulEdits = mode,
                                        **kwargs)
            if edits is None:
                edits = []
            allEdits.extend(ReferenceEdit(edit, fr, mode) for edit in edits)
        return allEdits
    else:
        if isinstance(args[0], FileReference):
            args = list(args)
            args[0] = args[0].refNode
        return cmds.referenceQuery(*args, **kwargs)

import general, other

def _safeEval(s):
    try:
        return eval(s)
    except:
        return s

def _safePyNode(n):
    try:
        return general.PyNode(_safeEval(n))
    except:
        if "." in n:
            return other.AttributeName(n)
        else:
            return other.DependNodeName(n)

class ReferenceEdit(str):
    """
    Parses a reference edit command string into various components based on the edit type.
    This is the class returned by pymel's version of the 'referenceQuery' command.
    """

    def __new__(cls, editStr, fileReference=None, successful=None):
        self = str.__new__(cls, editStr)
        self.type = self.split()[0]
        self.fileReference = fileReference
        self.successful = successful
        return self

    def _getNamespace(self):
        # Lazy load the namespace as it can be expensive to query
        return self.fileReference and self.fileReference.namespace

    def _getFullNamespace(self):
        return self.fileReference and self.fileReference.fullNamespace

    namespace = _util.cacheProperty(_getNamespace, "_namespace")
    fullNamespace = _util.cacheProperty(_getFullNamespace, "_fullNamespace")

    def _getRawEditData(self):
        import pymel.tools.mel2py as mel2py
        pyCmd = "".join(mel2py.mel2pyStr(self + ";").splitlines()[1:])  # chop off the 'import pymel' line
        args, kwargs = eval("dummy" + "".join(pyCmd.partition("(")[1:]), {}, dict(dummy=lambda *x,**y: (x, y)))
        editData = {}
        editData['args'] = args
        editData['kwargs'] = kwargs
        return editData

    def _getEditData(self):
        """
        Returns a dictionary with the relevant data for this reference edit.
        Each edit type will have a different set of keys.
        """
        if self.fileReference:
            def _safeRefPyNode(n):
                n = _safePyNode(_safeEval(n))
                if self.namespace in str(n):
                    ns = self.fileReference.refNode.namespace()
                    if not ns==":":
                        n = n.addPrefix(ns)
                return n
        else:
            def _safeRefPyNode(n):
                return _safePyNode(_safeEval(n))

        editData = self.rawEditData()

        elements = self.split()
        elements.pop(0)

        if self.type=="addAttr":
            editData['node'] = _safeRefPyNode(elements.pop(-1))
            editData['attribute'] = elements.pop(1)
        elif self.type=="setAttr":
            editData['node'] = _safeRefPyNode(elements.pop(0))
            editData['value'] = " ".join(elements)
        elif self.type=="parent":
            editData['node'] = _safeRefPyNode(elements.pop(-1))
            if elements[-1]=="-w":
                editData['child'] = '<World>'
            else:
                editData['child'] = _safePyNode(elements.pop(-1))
        elif self.type=="disconnectAttr":
            if elements[0].startswith("-"):
                elements.append(elements.pop(0))
            refNode, otherNode = map(_safeRefPyNode, elements[:2])
            editData['sourceNode'] = refNode
            editData['targetNode'] = otherNode
            otherNode, refNode = sorted([otherNode, refNode], key=lambda  n: self.namespace in n)
            editData['node'] = refNode
            del elements[:2]
        elif self.type=="connectAttr":
            if elements[0].startswith("-"):
                elements.append(elements.pop(0))
            refNode, otherNode = map(_safeRefPyNode, elements[:2])
            editData['sourceNode'] = refNode
            editData['targetNode'] = otherNode
            otherNode, refNode = sorted([otherNode, refNode], key=lambda  n: self.namespace in n)
            editData['node'] = refNode
            del elements[:2]
        else:
            editData['node'] = _safeRefPyNode(elements.pop(0))
        editData['parameters'] = map(str, elements)

        return editData

    def remove(self, force=False):
        """Remove the reference edit. if 'force=True' then the reference will be unloaded from the scene (if it is not already unloaded)"""
        if self.fileReference.isLoaded():
            if not force:
                raise Exception("Cannon remove edits while reference '%s' is loaded. Unload the reference first, or use the 'force=True' flag." % self.fileReference)
            self.fileReference.unload()
        cmds.referenceEdit(self.editData['node'], removeEdits=True, successfulEdits=True, failedEdits=True, editCommand=self.type)

    editData = _util.cacheProperty(_getEditData,"_editData")
    rawEditData = _util.cacheProperty(_getRawEditData,"_rawEditData")

# TODO: anyModified, modified, errorStatus, executeScriptNodes, lockFile, lastTempFile, renamingPrefixList, renameToSave ( api : mustRenameToSave )
# From API: isReadingFile, isWritingFile, isOpeningFile, isNewingFile, isImportingFile

def _correctPath(path):
    # make paths absolute
    if not os.path.isabs(path) and path != '' and path != untitledFileName():
        path = os.path.normpath(cmds.workspace(q=1,fullName=1) + '/' + path)
    return path

@_factories.addMelDocs('file', 'reference')
def createReference( filepath, **kwargs ):
    kwargs['reference'] = True
    res = cmds.file(filepath, **kwargs)
    if kwargs.get('returnNewNodes', kwargs.get('rnn', False) ):
        return [ general.PyNode(x) for x in res ]
    return FileReference(res)

@_factories.addMelDocs('file', 'loadReference')
def loadReference( filepath, **kwargs ):
    kwargs['loadReference'] = True
    res = cmds.file(filepath, **kwargs)
    if kwargs.get('returnNewNodes', kwargs.get('rnn', False) ):
        return [ general.PyNode(x) for x in res ]
    return FileReference(res)

@_factories.addMelDocs('file', 'exportAll')
def exportAll( exportPath, **kwargs ):
    _setTypeKwargFromExtension(exportPath, kwargs)
    kwargs['exportAll'] = True
    res = cmds.file(exportPath, **kwargs)
    if res is None:
        res = exportPath
    return Path(_correctPath(res))

@_factories.addMelDocs('file', 'exportAsReference')
def exportAsReference( exportPath, **kwargs ):
    _setTypeKwargFromExtension(exportPath, kwargs)
    kwargs['exportAsReference'] = True
    res = cmds.file(exportPath, **kwargs)
    if res is None:
        return FileReference(exportPath)
    return FileReference(res)

@_factories.addMelDocs('file', 'exportSelected')
def exportSelected( exportPath, **kwargs ):
    _setTypeKwargFromExtension(exportPath, kwargs)
    kwargs['exportSelected'] = True
    res = cmds.file(exportPath, **kwargs)
    if res is None:
        res = exportPath
    return Path(_correctPath(res))

@_factories.addMelDocs('file', 'exportAnim')
def exportAnim( exportPath, **kwargs ):
    _setTypeKwargFromExtension(exportPath, kwargs)
    kwargs['exportAnim'] = True
    res = cmds.file(exportPath, **kwargs)
    if res is None:
        res = exportPath
    return Path(_correctPath(res))

@_factories.addMelDocs('file', 'exportSelectedAnim')
def exportSelectedAnim( exportPath, **kwargs ):
    _setTypeKwargFromExtension(exportPath, kwargs)
    kwargs['exportSelectedAnim'] = True
    res = cmds.file(exportPath, **kwargs)
    if res is None:
        res = exportPath
    return Path(_correctPath(res))

@_factories.addMelDocs('file', 'exportAnimFromReference')
def exportAnimFromReference( exportPath, **kwargs ):
    _setTypeKwargFromExtension(exportPath, kwargs)
    kwargs['exportAnimFromReference'] = True
    res = cmds.file(exportPath, **kwargs)
    if res is None:
        res = exportPath
    return Path(_correctPath(res))

@_factories.addMelDocs('file', 'exportSelectedAnimFromReference')
def exportSelectedAnimFromReference( exportPath, **kwargs ):
    _setTypeKwargFromExtension(exportPath, kwargs)
    kwargs['exportSelectedAnimFromReference'] = True
    res = cmds.file(exportPath, **kwargs)
    if res is None:
        res = exportPath
    return Path(_correctPath(res))

@_factories.addMelDocs('file', 'i')
def importFile( filepath, **kwargs ):
    kwargs['i'] = True
    res = cmds.file(filepath, **kwargs)
    if kwargs.get('returnNewNodes', kwargs.get('rnn', False) ):
        return [ general.PyNode(x) for x in res ]
    # does not return anything

@_factories.createflag('file', 'newFile')
def newFile( **kwargs ):
    """
Modifications:
    - returns empty string, for consistency with sceneName()
      ...if you wish to know the untitled scene name, use untitledFileName()
    """
    cmds.file(**kwargs)
    return ''

@_factories.createflag('file', 'open')
def openFile( filepath, **kwargs ):
    res = cmds.file( filepath, **kwargs)
    if kwargs.get('returnNewNodes', kwargs.get('rnn', False) ):
        return [ general.PyNode(x) for x in res ]
    # this command seems to return the last accessed file, which may be a reference
    # i think we're better off spitting the passed path back out
#    if res is None:
#        return Path(filepath)
#    return Path(res)
    return sceneName()

@_factories.addMelDocs('file', 'rename')
def renameFile(newname, *args, **kwargs):
    # we take args and kwargs just for backward compatibility... (only kwarg
    # we use is type/typ)

    # maya retains some sense of whether a file is .ma or .mb, independent of
    # the file name - you can confirm this by doing:
    #    >> cmds.file(new=1, f=1)
    #    >> print cmds.file(q=1, type=1)
    #    ['mayaBinary']
    #    >> cmds.file(rename='foo.ma')
    #    >> print cmds.file(q=1, type=1)
    #    ['mayaBinary']
    #    >> cmds.file(type='mayaAscii')
    #    >> print cmds.file(q=1, type=1)
    #    ['mayaAscii']

    # therefore, we need to set the type OURSELVES when renaming, since this
    # is what is normally desired...

    _setTypeKwargFromExtension(newname, kwargs)
    # for backwards compatability, and because the rename flag cannot be used
    # with any other flags, we mostly throw out the given kwargs...
    fileType = kwargs.get('type', kwargs.get('typ'))
    if fileType is not None:
        cmds.file(type=fileType)
    return Path(cmds.file(rename=newname))

@_factories.addMelDocs('file', 'save')
def saveFile(**kwargs):
    kwargs.pop('s', None)
    kwargs['save'] = True
    return Path(cmds.file(**kwargs))


def saveAs(newname, **kwargs):
    _setTypeKwargFromExtension(newname, kwargs)
    cmds.file(rename=newname )
    kwargs['save']=True
    cmds.file( **kwargs)
    return Path( newname )

#ReferenceCache.setupFileReferenceCallbacks()

#createReference = _factories.make_factories.createflagCmd( 'createReference', cmds.file, 'reference', __name__, returnFunc=FileReference )
#loadReference = _factories.make_factories.createflagCmd( 'loadReference', cmds.file, 'loadReference',  __name__, returnFunc=FileReference )
#exportAnim = _factories.make_factories.createflagCmd( 'exportAnim', cmds.file, 'exportAnim',  __name__, returnFunc=Path )
#exportAnimFromReference = _factories.make_factories.createflagCmd( 'exportAnimFromReference', cmds.file, 'exportAnimFromReference',  __name__, returnFunc=Path )
#exportSelectedAnim = _factories.make_factories.createflagCmd( 'exportSelectedAnim', cmds.file, 'exportSelectedAnim',  __name__, returnFunc=Path )
#exportSelectedAnimFromReference = _factories.make_factories.createflagCmd( 'exportSelectedAnimFromReference', cmds.file, 'exportSelectedAnimFromReference', __name__,  returnFunc=Path )
#importFile = _factories.make_factories.createflagCmd( 'importFile', cmds.file, 'i',  __name__, returnFunc=Path )
#newFile = _factories.make_factories.createflagCmd( 'newFile', cmds.file, 'newFile',  __name__, returnFunc=Path )
#openFile = _factories.make_factories.createflagCmd( 'openFile', cmds.file, 'open',  __name__, returnFunc=Path )
#renameFile = _factories.make_factories.createflagCmd( 'renameFile', cmds.file, 'rename',  __name__, returnFunc=Path )

_factories.createFunctions( __name__ )

########NEW FILE########
__FILENAME__ = uitypes
import sys, re
import pymel.util as _util
import pymel.internal.pmcmds as cmds
import pymel.internal.factories as _factories
import pymel.internal as _internal
import pymel.versions as _versions
import maya.mel as _mm
_logger = _internal.getLogger(__name__)

def _resolveUIFunc(name):
    if isinstance(name, basestring):
        import windows
        try:
            return getattr(windows,name)
        except AttributeError:
            try:
                cls = getattr(dynModule,name)
                return cls.__melcmd__()
            except (KeyError, AttributeError):
                pass
    else:
        import inspect
        if inspect.isfunction(name):
            return name
        elif inspect.isclass(name) and issubclass(name, PyUI):
            name.__melcmd__()

    raise ValueError, "%r is not a known ui type" % name

if _versions.current() >= _versions.v2011:

    def toQtObject(mayaName):
        """
        Given the name of a Maya UI element of any type, return the corresponding QWidget or QAction.
        If the object does not exist, returns None

        When using this function you don't need to specify whether UI type is a control, layout,
        window, or menuItem, the first match -- in that order -- will be returned. If you have the full path to a UI object
        this should always be correct, however, if you only have the short name of the UI object,
        consider using one of the more specific variants: `toQtControl`, `toQtLayout`, `toQtWindow`, or `toQtMenuItem`.

        .. note:: Requires PyQt
        """
        import maya.OpenMayaUI as mui
        import sip
        import PyQt4.QtCore as qtcore
        import PyQt4.QtGui as qtgui
        ptr = mui.MQtUtil.findControl(mayaName)
        if ptr is None:
            ptr = mui.MQtUtil.findLayout(mayaName)
            if ptr is None:
                ptr = mui.MQtUtil.findMenuItem(mayaName)
        if ptr is not None:
            return sip.wrapinstance(long(ptr), qtcore.QObject)

    def toQtControl(mayaName):
        """
        Given the name of a May UI control, return the corresponding QWidget.
        If the object does not exist, returns None

        .. note:: Requires PyQt
        """
        import maya.OpenMayaUI as mui
        import sip
        import PyQt4.QtCore as qtcore
        import PyQt4.QtGui as qtgui
        ptr = mui.MQtUtil.findControl(mayaName)
        if ptr is not None:
            return sip.wrapinstance(long(ptr), qtgui.QWidget)

    def toQtLayout(mayaName):
        """
        Given the name of a May UI control, return the corresponding QWidget.
        If the object does not exist, returns None

        .. note:: Requires PyQt
        """
        import maya.OpenMayaUI as mui
        import sip
        import PyQt4.QtCore as qtcore
        import PyQt4.QtGui as qtgui
        ptr = mui.MQtUtil.findLayout(mayaName)
        if ptr is not None:
            return sip.wrapinstance(long(ptr), qtgui.QWidget)

    def toQtWindow(mayaName):
        """
        Given the name of a May UI control, return the corresponding QWidget.
        If the object does not exist, returns None

        .. note:: Requires PyQt
        """
        import maya.OpenMayaUI as mui
        import sip
        import PyQt4.QtCore as qtcore
        import PyQt4.QtGui as qtgui
        ptr = mui.MQtUtil.findWindow(mayaName)
        if ptr is not None:
            return sip.wrapinstance(long(ptr), qtgui.QWidget)

    def toQtMenuItem(mayaName):
        """
        Given the name of a May UI menuItem, return the corresponding QAction.
        If the object does not exist, returns None

        This only works for menu items. for Menus, use toQtControl or toQtObject

        .. note:: Requires PyQt
        """
        import maya.OpenMayaUI as mui
        import sip
        import PyQt4.QtCore as qtcore
        import PyQt4.QtGui as qtgui
        ptr = mui.MQtUtil.findMenuItem(mayaName)
        if ptr is not None:
            return sip.wrapinstance(long(ptr), qtgui.QAction)

# really, this should be in core.windows; but, due to that fact that this module
# is "higher" in the import hierarchy than core.windows, and we need this function
# here, we're just defining it here
@_factories.addMelDocs( 'objectTypeUI' )
def objectTypeUI(name, **kwargs):
    try:
        return cmds.objectTypeUI(name, **kwargs)
    except RuntimeError, topError:
        try:
            # some ui types (radioCollections) can only be identified with their shortname
            return cmds.objectTypeUI(name.split('|')[-1], **kwargs)
        except RuntimeError:
            # we cannot query the type of rowGroupLayout children: check common types for these
            uiType = None
            typesToCheck = 'checkBox floatField button floatSlider intSlider ' \
                    'floatField textField intField optionMenu radioButton'.split()
            if _versions.current() >= _versions.v2012_SP2:
                # 2012 SP2 introducted a bug where doing:
                # win = cmds.window(menuBar=True)
                # cmds.objectTypeUI(win)
                # would error...
                typesToCheck.append('window')
            for cmdName in typesToCheck:
                if getattr(cmds, cmdName)( name, ex=1, q=1):
                    uiType = cmdName
                    break
            if uiType:
                return uiType
            raise topError

class PyUI(unicode):
    def __new__(cls, name=None, create=False, **kwargs):
        """
        Provides the ability to create the PyUI Element when creating a class::

            import pymel.core as pm
            n = pm.Window("myWindow",create=True)
            n.__repr__()
            # Result: Window('myWindow')
        """

        if cls is PyUI:
            try:
                uiType = objectTypeUI(name)
            except RuntimeError:
                uiType = 'PyUI'
            uiType =  _uiTypesToCommands.get(uiType, uiType)

            try:
                newcls = getattr(dynModule, _util.capitalize(uiType) )
            except AttributeError:
                newcls = PyUI
                # objectTypeUI for panels seems to return weird results -
                # ie, TmodelPane ... check for them this way.
                # Other types should be detected correctly by objectTypeUI,
                # but this just provides a failsafe...
                for testType in 'panel scriptedPanel window control layout menu'.split():
                    if getattr(cmds, testType)( name, ex=1, q=1):
                        newcls = getattr(dynModule, _util.capitalize(testType),
                                         PyUI )
                        if newcls != PyUI:
                            break
        else:
            newcls = cls

        if not newcls is PyUI:
            if cls._isBeingCreated(name, create, kwargs):
                name = newcls.__melcmd__(name, **kwargs)
                _logger.debug("PyUI: created... %s" % name)
            else:
                # find the long name
                if '|' not in name and not issubclass(newcls,
                                                (Window,
                                                 Panel,
                                                 dynModule.ScriptedPanel,
                                                 dynModule.RadioCollection,
                                                 dynModule.ToolCollection)):
                    import windows
                    try:
                        if issubclass(newcls,Layout):
                            parent = windows.layout(name, q=1, p=1)
                        elif issubclass(newcls,OptionMenu):
                            parent = windows.optionMenu(name, q=1, p=1)
                        elif issubclass(newcls,Menu):
                            parent = windows.menu(name, q=1, p=1)
                        else:
                            parent = windows.control(name, q=1, p=1)
                        if parent:
                            name = parent + '|' + name

                    except RuntimeError:
                        # editors don't have a long name, so we keep the short name
                        if name not in cmds.lsUI( long=True,editors=True):
                            raise


        # correct for optionMenu
        if newcls == PopupMenu and cmds.optionMenu( name, ex=1 ):
            newcls = OptionMenu
        return unicode.__new__(newcls,name)

    @staticmethod
    def _isBeingCreated( name, create, kwargs):
        """
        create a new node when any of these conditions occur:
           name is None
           create is True
           parent flag is set
        """
        return not name or create or ( 'q' not in kwargs and kwargs.get('parent', kwargs.get('p', None)) )

    def __repr__(self):
        return u"ui.%s('%s')" % (self.__class__.__name__, self)
    def parent(self):
        buf = unicode(self).split('|')[:-1]
        if len(buf)==2 and buf[0] == buf[1] and _versions.current() < _versions.v2011:
            # pre-2011, windows with menus can have a strange name:
            # ex.  window1|window1|menu1
            buf = buf[:1]
        if not buf:
            return None
        return PyUI( '|'.join(buf) )
    getParent = parent

    def shortName(self):
        return unicode(self).split('|')[-1]
    def name(self):
        return unicode(self)
    def window(self):
        return Window( self.name().split('|')[0] )

    delete = _factories.functionFactory( 'deleteUI', rename='delete' )
    rename = _factories.functionFactory( 'renameUI', rename='rename' )
    type = objectTypeUI

    @classmethod
    def exists(cls, name):
        return cls.__melcmd__( name, exists=True )

    if _versions.current() >= _versions.v2011:
        asQtObject = toQtControl

class Panel(PyUI):
    """pymel panel class"""
    __metaclass__ = _factories.MetaMayaUIWrapper
    # note that we're not actually customizing anything, but
    # we're declaring it here because other classes will have this
    # as their base class, so we need to make sure it exists first

_withParentStack = []
_withParentMenuStack = []

class Layout(PyUI):
    def __enter__(self):
        global _withParentStack
        _withParentStack.append(self)
        self.makeDefault()
        return self

    def __exit__(self, type, value, traceback):
        global _withParentStack
        _withParentStack.pop()
        if _withParentStack:
            parent = _withParentStack[-1]
        else:
            parent = self.pop()
            while parent and objectTypeUI(parent) == u'rowGroupLayout':
                parent = parent.pop()
        cmds.setParent(parent)

    def children(self):
        #return [ PyUI( self.name() + '|' + x) for x in self.__melcmd__(self, q=1, childArray=1) ]
        kids = cmds.layout(self, q=1, childArray=1)
        if kids:
            return [ PyUI( self.name() + '|' + x) for x in kids ]
        return []

    getChildren = children

    # TODO: add depth firt and breadth first options
    def walkChildren(self):
        """
        recursively yield all children of this layout
        """
        for child in self.children():
            yield child
            if hasattr(child, 'walkChildren'):
                for subChild in child.walkChildren():
                    yield subChild

    def findChild(self, shortName, recurse=False):
        if recurse:
            for child in self.walkChildren():
                if child.shortName() == shortName:
                    return child
        else:
            for child in self.children():
                if child.shortName() == shortName:
                    return child

    def addChild(self, uiType, name=None, **kwargs):
        if isinstance(uiType, basestring):
            uiType = getattr(dynModule, uiType)
        assert hasattr(uiType, '__call__'), 'argument uiType must be the name of a known ui type, a UI subclass, or a callable object'
        args = []
        if name:
            args.append(name)
        if kwargs:
            if 'parent' in kwargs or 'p' in kwargs:
                _logger.warn('parent flag is set by addChild automatically. passed value will be ignored' )
                kwargs.pop('parent', None)
                kwargs.pop('p', None)
        kwargs['parent'] = self
        res = uiType(*args, **kwargs)
        if not isinstance(res, PyUI):
            res = PyUI(res)
        return res

    def makeDefault(self):
        """
        set this layout as the default parent
        """
        cmds.setParent(self)

    def pop(self):
        """
        set the default parent to the parent of this layout
        """
        p = self.parent()
        cmds.setParent(p)
        return p

    def clear(self):
        children = self.getChildArray()
        if children:
            for child in self.getChildArray():
                cmds.deleteUI(child)

    if _versions.current() >= _versions.v2011:
        asQtObject = toQtLayout

# customized ui classes
class Window(Layout):
    """pymel window class"""
    __metaclass__ = _factories.MetaMayaUIWrapper

#    if _versions.current() < _versions.v2011:
#        # don't set
#        def __enter__(self):
#            return self

    def __exit__(self, type, value, traceback):
        super(Window, self).__exit__(type, value, traceback)
        self.show()

    def show(self):
        cmds.showWindow(self)

    def delete(self):
        cmds.deleteUI(self, window=True)

    def layout(self):
        name = self.name()
        for layout in sorted(cmds.lsUI(long=True, controlLayouts=True)):
            # since we are sorted, shorter will be first, and the first layout we come across will be the base layout
            if layout.startswith(name):
                return PyUI(layout)

#            # create a child and then delete it to get the layout
#            res = self.addChild(cmds.columnLayout)
#            layout = res.parent()
#            res.delete()
#            return layout

    def children(self):
        res = self.layout()
        return [res] if res else []

    getChildren = children

    def window(self):
        return self

    def parent(self):
        return None
    getParent = parent

    if _versions.current() >= _versions.v2011:
        asQtObject = toQtWindow

class FormLayout(Layout):
    __metaclass__ = _factories.MetaMayaUIWrapper

    def __new__(cls, name=None, **kwargs):
        if kwargs:
            [kwargs.pop(k, None) for k in ['orientation', 'ratios', 'reversed', 'spacing']]

        self = Layout.__new__(cls, name, **kwargs)
        return self


    def __init__(self, name=None, orientation='vertical', spacing=2, reversed=False, ratios=None, **kwargs):
        """
        spacing - absolute space between controls
        orientation - the orientation of the layout [ AutoLayout.HORIZONTAL | AutoLayout.VERTICAL ]
        """
        Layout.__init__(self, **kwargs)
        self._spacing = spacing
        self._orientation = self.Orientation.getIndex(orientation)
        self._reversed = reversed
        self._ratios = ratios and list(ratios) or []

    def attachForm(self, *args):
        kwargs = {'edit':True}
        kwargs['attachForm'] = [args]
        cmds.formLayout(self,**kwargs)

    def attachControl(self, *args):
        kwargs = {'edit':True}
        kwargs['attachControl'] = [args]
        cmds.formLayout(self,**kwargs)

    def attachNone(self, *args):
        kwargs = {'edit':True}
        kwargs['attachNone'] = [args]
        cmds.formLayout(self,**kwargs)

    def attachPosition(self, *args):
        kwargs = {'edit':True}
        kwargs['attachPosition'] = [args]
        cmds.formLayout(self,**kwargs)

    HORIZONTAL = 0
    VERTICAL = 1
    Orientation = _util.enum.Enum( 'Orientation', ['horizontal', 'vertical'] )

    def flip(self):
        """Flip the orientation of the layout """
        self._orientation = 1-self._orientation
        self.redistribute(*self._ratios)

    def reverse(self):
        """Reverse the children order """
        self._reversed = not self._reversed
        self._ratios.reverse()
        self.redistribute(*self._ratios)

    def reset(self):
        self._ratios = []
        self._reversed = False
        self.redistribute()


    def redistribute(self,*ratios):
        """
        Redistribute the child controls based on the ratios.
        If not ratios are given (or not enough), 1 will be used
        """

        sides = [["top","bottom"],["left","right"]]

        children = self.getChildArray()
        if not children:
            return
        if self._reversed:
            children.reverse()

        ratios = list(ratios) or self._ratios or []
        ratios += [1]*(len(children)-len(ratios))
        self._ratios = ratios
        total = sum(ratios)

        for i, child in enumerate(children):
            for side in sides[self._orientation]:
                self.attachForm(child,side,self._spacing)

            if i==0:
                self.attachForm(child,
                    sides[1-self._orientation][0],
                    self._spacing)
            else:
                self.attachControl(child,
                    sides[1-self._orientation][0],
                    self._spacing,
                    children[i-1])

            if ratios[i]:
                self.attachPosition(children[i],
                    sides[1-self._orientation][1],
                    self._spacing,
                    float(sum(ratios[:i+1]))/float(total)*100)
            else:
                self.attachNone(children[i],
                    sides[1-self._orientation][1])

    def vDistribute(self,*ratios):
        self._orientation = int(self.Orientation.vertical)
        self.redistribute(*ratios)

    def hDistribute(self,*ratios):
        self._orientation = int(self.Orientation.horizontal)
        self.redistribute(*ratios)

class AutoLayout(FormLayout):
    """
    AutoLayout behaves exactly like `FormLayout`, but will call redistribute automatically
    at the end of a 'with' statement block
    """
    def __exit__(self, type, value, traceback):
        self.redistribute()
        super(AutoLayout, self).__exit__(type, value, traceback)

class RowLayout(Layout):
    __metaclass__ = _factories.MetaMayaUIWrapper

class TextScrollList(PyUI):
    __metaclass__ = _factories.MetaMayaUIWrapper
    def extend( self, appendList ):
        """ append a list of strings"""

        for x in appendList:
            self.append(x)

    def selectIndexedItems( self, selectList ):
        """select a list of indices"""
        for x in selectList:
            self.selectIndexedItem(x)

    def removeIndexedItems( self, removeList ):
        """remove a list of indices"""
        for x in removeList:
            self.removeIndexedItem(x)

    def selectAll(self):
        """select all items"""
        numberOfItems = self.getNumberOfItems()
        self.selectIndexedItems(range(1,numberOfItems+1))

class Menu(PyUI):
    __metaclass__ = _factories.MetaMayaUIWrapper

    def __enter__(self):
        global _withParentMenuStack
        _withParentMenuStack.append(self)
        self.makeDefault()
        return self

    def __exit__(self, type, value, traceback):
        global _withParentMenuStack
        _withParentMenuStack.pop()
        if _withParentMenuStack:
            cmds.setParent(_withParentMenuStack[-1], menu=True)
        else:
            parent = self
            while True:
                parent = parent.parent()
                # Maya 2012 Service Pack 2 (or SAP1, SP1) introduces a bug where
                # '' is returned, instead of None; problem being that doing
                # cmds.setParent(None, menu=True) is valid, but
                # cmds.setParent('', menu=True) is not
                if parent == '':
                    parent = None
                try:
                    cmds.setParent(parent, menu=True)
                except RuntimeError:
                    continue
                break

    def getItemArray(self):
        """ Modified to return pymel instances """
        children = cmds.menu(self,query=True,itemArray=True)
        if children:
            return [MenuItem(item) for item in cmds.menu(self,query=True,itemArray=True)]
        else:
            return []

    def makeDefault(self):
        """
        set this layout as the default parent
        """
        cmds.setParent(self, menu=True)

class PopupMenu(Menu):
    __metaclass__ = _factories.MetaMayaUIWrapper

class OptionMenu(PopupMenu):
    __metaclass__ = _factories.MetaMayaUIWrapper

    def addMenuItems( self, items, title=None):
        """ Add the specified item list to the OptionMenu, with an optional 'title' item """
        if title:
            cmds.menuItem(l=title, en=0, parent=self)
        for item in items:
            cmds.menuItem(l=item, parent=self)

    def clear(self):
        """ Clear all menu items from this OptionMenu """
        for t in self.getItemListLong() or []:
            cmds.deleteUI(t)
    addItems = addMenuItems

class OptionMenuGrp(RowLayout):
    __metaclass__ = _factories.MetaMayaUIWrapper

    def menu(self):
        for child in self.children():
            if isinstance(child, OptionMenu):
                return child

    # Want to set both the menu to the child |OptionMenu item, and the normal
    # parent to this...
    def __enter__(self):
        self.menu().__enter__()
        return super(OptionMenuGrp, self).__enter__()

    def __exit__(self, type, value, traceback):
        self.menu().__exit__(type, value, traceback)
        return super(OptionMenuGrp, self).__exit__(type, value, traceback)

class SubMenuItem(Menu):
    def getBoldFont(self):
        return cmds.menuItem(self,query=True,boldFont=True)

    def getItalicized(self):
        return cmds.menuItem(self,query=True,italicized=True)

    if _versions.current() >= _versions.v2011:
        asQtObject = toQtMenuItem

class CommandMenuItem(PyUI):
    __metaclass__ = _factories.MetaMayaUIWrapper
    __melui__ = 'menuItem'
    def __enter__(self):
        SubMenuItem(self).__enter__()
        return self

    def __exit__(self, type, value, traceback):
        return SubMenuItem(self).__exit__(type, value, traceback)

def MenuItem(name=None, create=False, **kwargs):
    if PyUI._isBeingCreated(name, create, kwargs):
        cls = CommandMenuItem
    else:
        try:
            uiType = objectTypeUI(name)
        except RuntimeError:
            cls = SubMenuItem
        else:
            if uiType == 'subMenuItem':
                cls = SubMenuItem
            else:
                cls = CommandMenuItem
    return cls(name, create, **kwargs)

class UITemplate(object):
    """
    from pymel.core import *

    # force deletes the template if it already exists
    template = ui.UITemplate( 'ExampleTemplate', force=True )

    template.define( button, width=100, height=40, align='left' )
    template.define( frameLayout, borderVisible=True, labelVisible=False )

    #    Create a window and apply the template.
    #
    with window():
        with template:
            with columnLayout( rowSpacing=5 ):
                with frameLayout():
                    with columnLayout():
                        button( label='One' )
                        button( label='Two' )
                        button( label='Three' )

                with frameLayout():
                    with columnLayout():
                        button( label='Red' )
                        button( label='Green' )
                        button( label='Blue' )
    """
    def __init__(self, name=None, force=False):
        if name and cmds.uiTemplate( name, exists=True ):
            if force:
                cmds.deleteUI( name, uiTemplate=True )
            else:
                self._name = name
                return
        args = [name] if name else []
        self._name = cmds.uiTemplate( *args )

    def __repr__(self):
        return '%s(%r)' % ( self.__class__.__name__, self._name)

    def __enter__(self):
        self.push()
        return self

    def __exit__(self, type, value, traceback):
        self.pop()

    def name(self):
        return self._name

    def push(self):
        cmds.setUITemplate(self._name, pushTemplate=True)

    def pop(self):
        cmds.setUITemplate( popTemplate=True)

    def define(self, uiType, **kwargs):
        """
        uiType can be:
            - a ui function or class
            - the name of a ui function or class
            - a list or tuple of the above
        """
        if isinstance(uiType, (list,tuple)):
            funcs = [ _resolveUIFunc(x) for x in uiType ]
        else:
            funcs = [_resolveUIFunc(uiType)]
        kwargs['defineTemplate'] = self._name
        for func in funcs:
            func(**kwargs)

    @staticmethod
    def exists(name):
        return cmds.uiTemplate( name, exists=True )

class AELoader(type):
    """
    Metaclass used by `AETemplate` class to create wrapping and loading mechanisms when an AETemplate instance is created
    """
    _loaded = []
    def __new__(cls, classname, bases, classdict):
        newcls = super(AELoader, cls).__new__(cls, classname, bases, classdict)
        try:
            nodeType = newcls.nodeType()
        except ValueError:
            _logger.debug("could not determine node type for " + classname)
        else:
            modname = classdict['__module__']
            if modname == '__builtin__':
                # since the module is __builtin__ our AE was probably included in the body of a scripted
                # plugin, which is called by maya in a strange way ( execfile? ).
                # give it a real home so we can load it later.
                mod = sys.modules['__builtin__']
                setattr( mod, classname, newcls )

            template = 'AE'+nodeType+'Template'
            cls.makeAEProc(modname, classname, template)
            if template not in cls._loaded:
                cls._loaded.append(template)
        return newcls

    @staticmethod
    def makeAEProc(modname, classname, procname):
        _logger.debug("making AE loader procedure: %s" % procname)
        contents = '''global proc %(procname)s( string $nodeName ){
        python("import %(__name__)s;%(__name__)s.AELoader.load('%(modname)s','%(classname)s','" + $nodeName + "')");}'''
        d = locals().copy()
        d['__name__'] = __name__
        import maya.mel as mm
        mm.eval( contents % d )

    @staticmethod
    def load(modname, classname, nodename):
        mod = __import__(modname, globals(), locals(), [classname], -1)
        try:
            cls = getattr(mod,classname)
            cls(nodename)
        except Exception:
            print "failed to load python attribute editor template '%s.%s'" % (modname, classname)
            import traceback
            traceback.print_exc()

    @classmethod
    def loadedTemplates(cls):
        "Return the names of the loaded templates"
        return cls._loaded

class AETemplate(object):
    """
    To create an Attribute Editor template using python, do the following:
     	1. create a subclass of `uitypes.AETemplate`
    	2. set its ``_nodeType`` class attribute to the name of the desired node type, or name the class using the
    convention ``AE<nodeType>Template``
    	3. import the module

    AETemplates which do not meet one of the two requirements listed in step 2 will be ignored.  To ensure that your
    Template's node type is being detected correctly, use the ``AETemplate.nodeType()`` class method::

        import AETemplates
        AETemplates.AEmib_amb_occlusionTemplate.nodeType()

    As a convenience, when pymel is imported it will automatically import the module ``AETemplates``, if it exists,
    thereby causing any AETemplates within it or its sub-modules to be registered. Be sure to import pymel
    or modules containing your ``AETemplate`` classes before opening the Atrribute Editor for the node types in question.

    To check which python templates are loaded::

    	from pymel.core.uitypes import AELoader
    	print AELoader.loadedTemplates()
    """

    __metaclass__ = AELoader

    _nodeType = None
    def __init__(self, nodeName):
        self._nodeName = nodeName

    @property
    def nodeName(self):
        return self._nodeName

    @classmethod
    def nodeType(cls):
        if cls._nodeType:
            return cls._nodeType
        else:
            m = re.match('AE(.+)Template$', cls.__name__)
            if m:
                return m.groups()[0]
            else:
                raise ValueError("You must either name your AETemplate subclass of the form 'AE<nodeType>Template' or set the '_nodeType' class attribute")
    @classmethod
    def controlValue(cls, nodeName, control):
        return cmds.editorTemplate(queryControl=(nodeName,control))
    @classmethod
    def controlLabel(cls, nodeName, control):
        return cmds.editorTemplate(queryLabel=(nodeName,control))
    @classmethod
    def reload(cls):
        "Reload the template. Beware, this reloads the module in which the template exists!"
        nodeType = cls.nodeType()
        form = "AttrEd" + nodeType + "FormLayout"
        exists = cmds.control(form, exists=1) and cmds.formLayout(form, q=1, ca=1)

        if exists:
            sel = cmds.ls(sl=1)
            cmds.select(cl=True)
            cmds.deleteUI(form)
            if sel:
                cmds.select(sel)
        reload(sys.modules[cls.__module__])

    def addControl(self, control, label=None, changeCommand=None, annotation=None, preventOverride=False, dynamic=False):
        args = [control]
        kwargs = {'preventOverride':preventOverride}
        if dynamic:
            kwargs['addDynamicControl'] = True
        else:
            kwargs['addControl'] = True
        if changeCommand:
            if hasattr(changeCommand, '__call__'):
                import pymel.tools.py2mel
                name = self.__class__.__name__ + '_callCustom_changeCommand_' + control
                changeCommand = pymel.tools.py2mel.py2melProc(changeCommand, procName=name, argTypes=['string'])
            args.append(changeCommand)
        if label:
            kwargs['label'] = label
        if annotation:
            kwargs['annotation'] = annotation
        cmds.editorTemplate(*args, **kwargs)
    def callCustom(self, newFunc, replaceFunc, *attrs):
        #cmds.editorTemplate(callCustom=( (newFunc, replaceFunc) + attrs))
        import pymel.tools.py2mel
        if hasattr(newFunc, '__call__'):
            name = self.__class__.__name__ + '_callCustom_newFunc_' + '_'.join(attrs)
            newFunc = pymel.tools.py2mel.py2melProc(newFunc, procName=name, argTypes=['string']*len(attrs))
        if hasattr(replaceFunc, '__call__'):
            name = self.__class__.__name__ + '_callCustom_replaceFunc_' + '_'.join(attrs)
            replaceFunc = pymel.tools.py2mel.py2melProc(replaceFunc, procName=name, argTypes=['string']*len(attrs))
        args = (newFunc, replaceFunc) + attrs
        cmds.editorTemplate(callCustom=1, *args)

    def suppress(self, control):
        cmds.editorTemplate(suppress=control)
    def dimControl(self, nodeName, control, state):
        #nodeName = nodeName if nodeName else self.nodeName
        #print "dim", nodeName
        cmds.editorTemplate(dimControl=(nodeName, control, state))

    def beginLayout(self, name, collapse=True):
        cmds.editorTemplate(beginLayout=name, collapse=collapse)
    def endLayout(self):
        cmds.editorTemplate(endLayout=True)

    def beginScrollLayout(self):
        cmds.editorTemplate(beginScrollLayout=True)
    def endScrollLayout(self):
        cmds.editorTemplate(endScrollLayout=True)

    def beginNoOptimize(self):
        cmds.editorTemplate(beginNoOptimize=True)
    def endNoOptimize(self):
        cmds.editorTemplate(endNoOptimize=True)

    def interruptOptimize(self):
        cmds.editorTemplate(interruptOptimize=True)
    def addSeparator(self):
        cmds.editorTemplate(addSeparator=True)
    def addComponents(self):
        cmds.editorTemplate(addComponents=True)
    def addExtraControls(self, label=None):
        kwargs = {}
        if label:
            kwargs['extraControlsLabel'] = label
        cmds.editorTemplate(addExtraControls=True, **kwargs)

    #TODO: listExtraAttributes


dynModule = _util.LazyLoadModule(__name__, globals())

def _createUIClasses():
    for funcName in _factories.uiClassList:
        # Create Class
        classname = _util.capitalize(funcName)
        try:
            cls = dynModule[classname]
        except KeyError:
            if classname.endswith( ('Layout', 'Grp') ):
                bases = (Layout,)
            elif classname.endswith('Panel'):
                bases = (Panel,)
            else:
                bases = (PyUI,)
            dynModule[classname] = (_factories.MetaMayaUIWrapper, (classname, bases, {}) )

_createUIClasses()

class MainProgressBar(dynModule.ProgressBar):
    '''Context manager for main progress bar

    If an exception occur after beginProgress() but before endProgress() maya
    gui becomes unresponsive. Use this class to escape this behavior.

     :Parameters:
        minValue : int
            Minimum or startingvalue of progress indicatior. If the progress
            value is less than the minValue, the progress value will be set
            to the minimum.  Default value is 0

        maxValue : int
            The maximum or endingvalue of the progress indicator. If the
            progress value is greater than the maxValue, the progress value
            will be set to the maximum. Default value is 100.

        interuruptable : bool
            Set to True if the isCancelled flag should respond to attempts to
            cancel the operation. Setting this to true will put make the help
            line display message to the user indicating that they can cancel
            the operation.

    Here's an example:

    .. python::
        with MainProgressBar(0,20,True) as bar:
            bar.setStatus('Calculating...')
            for i in range(0,20):
                bar.setProgress(i)
                if bar.getIsCancelled():
                    break
    '''
    def __new__(cls, minValue=0, maxValue=100, interruptable=True):
        from language import melGlobals
        bar = dynModule.ProgressBar.__new__(
            cls, melGlobals['gMainProgressBar'], create=False)
        bar.setMinValue(minValue)
        bar.setMaxValue(maxValue)
        bar.setIsInterruptable(interruptable)
        return bar

    def __enter__(self):
        self.beginProgress()
        return self

    def __exit__(self, *args):
        self.endProgress()

class VectorFieldGrp( dynModule.FloatFieldGrp ):
    def __new__(cls, name=None, create=False, *args, **kwargs):
        if create:
            kwargs.pop('nf', None)
            kwargs['numberOfFields'] = 3
            name = cmds.floatFieldGrp( name, *args, **kwargs)

        return dynModule.FloatFieldGrp.__new__( cls, name, create=False, *args, **kwargs )

    def getVector(self):
        import datatypes
        x = cmds.floatFieldGrp( self, q=1, v1=True )
        y = cmds.floatFieldGrp( self, q=1, v2=True )
        z = cmds.floatFieldGrp( self, q=1, v3=True )
        return datatypes.Vector( [x,y,z] )

    def setVector(self, vec):
        cmds.floatFieldGrp( self, e=1, v1=vec[0], v2=vec[1], v3=vec[2] )

class PathButtonGrp( dynModule.TextFieldButtonGrp ):
    PROMPT_FUNCTION = 'promptForPath'

    def __new__(cls, name=None, create=False, *args, **kwargs):

        if create:
            import windows

            kwargs.pop('bl', None)
            kwargs['buttonLabel'] = 'Browse'
            kwargs.pop('bc', None)
            kwargs.pop('buttonCommand', None)

            name = cmds.textFieldButtonGrp( name, *args, **kwargs)

            promptFunction = getattr(windows, cls.PROMPT_FUNCTION)
            def setPathCB(name):
                f = promptFunction()
                if f:
                    cmds.textFieldButtonGrp( name, e=1, text=f, forceChangeCommand=True)

            import windows
            cb = windows.Callback( setPathCB, name )
            cmds.textFieldButtonGrp( name, e=1, buttonCommand=cb )

        return super(PathButtonGrp, cls).__new__( cls, name, create=False, *args, **kwargs )

    def setPath(self, path, **kwargs):
        kwargs['forceChangeCommand'] = kwargs.pop('fcc',kwargs.pop('forceChangeCommand',True))
        self.setText( path , **kwargs )

    def getPath(self):
        import system
        return system.Path( self.getText() )

class FolderButtonGrp( PathButtonGrp ):
    PROMPT_FUNCTION = 'promptForFolder'

# most of the keys here are names that are only used in certain circumstances
_uiTypesToCommands = {
    'radioCluster':'radioCollection',
    'rowGroupLayout' : 'rowLayout',
    'TcolorIndexSlider' : 'rowLayout',
    'TcolorSlider' : 'rowLayout',
    'floatingWindow' : 'window'
    }

dynModule._lazyModule_update()


########NEW FILE########
__FILENAME__ = windows
"""
Functions for creating UI elements, as well as their class counterparts.
"""

import re, sys, functools, traceback

import pymel.util as _util
import pymel.internal.pmcmds as cmds
import pymel.internal.factories as _factories
import pymel.internal as _internal
import pymel.versions as _versions

from pymel.internal.factories import Callback, CallbackWithArgs

from language import mel, melGlobals
from system import Path as _Path
# Don't import uitypes  - we want to finish setting up the commands in this
# module before creating the uitypes classes; this way, the methods on the
# uitypes classes can use the functions from THIS module, and inherit things
# like simpleCommandWraps, etc
#import uitypes as _uitypes

_logger = _internal.getLogger(__name__)

_thisModule = sys.modules[__name__]
# Note - don't do
#     __import__('pymel.core.windows').XXX
# ...as this will get the 'original' module, not the dynamic one!
# Do:
#    import pymel.core.windows; import sys; sys.modules[pymel.core.windows].XXX
# instead!
thisModuleCmd = "import %s; import sys; sys.modules[%r]" % (__name__, __name__)

#-----------------------------------------------
#  Enhanced UI Commands
#-----------------------------------------------

def _lsUI( **kwargs ):
    long = kwargs.pop( 'long', kwargs.pop( 'l', True ) )
    head = kwargs.pop( 'head', kwargs.pop( 'hd', None ) )
    tail = kwargs.pop( 'tail', kwargs.pop( 'tl', None) )

    if not kwargs:
        kwargs = {
            'windows': 1, 'panels' : 1, 'editors' : 1, 'controls' : 1, 'controlLayouts' : 1,
            'collection' : 1, 'radioMenuItemCollections' : 1, 'menus' : 1, 'menuItems' : 1,
            'contexts' : 0, 'cmdTemplates' : 1
            }
    kwargs['long'] = long
    if head is not None: kwargs['head'] = head
    if tail is not None: kwargs['tail'] = tail
    return _util.listForNone(cmds.lsUI(**kwargs))

# all optionMenus are popupMenus, but not all popupMenus are optionMenus
_commandsToUITypes = {
    'optionMenu':'popupMenu',
    }

def _findLongName(name, type=None):
    # this remap is currently for OptionMenu, but the fix only works in 2011
    # lsUI won't list popupMenus or optionMenus
    kwargs = { 'long' : True}
    if type:
        kwargs['type'] = _commandsToUITypes.get(type, type)

    uiObjs = _util.listForNone(_lsUI( **kwargs ))
    res = [ x for x in uiObjs if x.endswith( '|' + name) ]
    if len(res) > 1:
        raise ValueError, "found more than one UI element matching the name %s" % name
    elif len(res) == 0:
        raise ValueError, "could not find a UI element matching the name %s" % name
    return res[0]

def lsUI( **kwargs ):
    """
Modified:
  - long defaults to True
  - if no type is passed, defaults to all known types
    """
    import uitypes
    return [ uitypes.PyUI(x) for x in _lsUI( **kwargs ) ]

scriptTableCmds = {}

def scriptTable(*args, **kwargs):
    """
Maya Bug Fix:
    - fixed getCellCmd to work with python functions, previously only worked with mel callbacks
        IMPORTANT: you cannot use the print statement within the getCellCmd callback function or your values will not be returned to the table
    """
    import uitypes
    cb = kwargs.pop('getCellCmd', kwargs.pop('gcc',None) )
    cc = kwargs.pop('cellChangedCmd', kwargs.pop('ccc',None) )

    uiName = cmds.scriptTable( *args, **kwargs )
    if "q" in kwargs or "query" in kwargs:
        return uiName

    kwargs.clear()
    if cb:
        if hasattr(cb, '__call__'):
            procName = 'getCellMel%d' % len(scriptTableCmds.keys())
            key = '%s_%s' % (uiName,procName)

            procCmd = """global proc string %s( int $row, int $column ) {
                            return python(%s.scriptTableCmds['%s'](" + $row + "," + $column + ")");}
                      """ %  (procName, thisModuleCmd, key)
            mel.eval( procCmd )
            scriptTableCmds[key] = cb

            # create a scriptJob to clean up the dictionary of functions
            cmds.scriptJob(uiDeleted=(uiName, lambda *x: scriptTableCmds.pop(key,None)))
            cb = procName
        kwargs['getCellCmd'] = cb
    if cc:
        if hasattr(cc, '__call__'):
            procName = 'cellChangedCmd%d' % len(scriptTableCmds.keys())
            key = '%s_%s' % (uiName,procName)
            # Note - don't do
            #     __import__('pymel.core.windows').XXX
            # ...as this will get the 'original' module, not the dynamic one!
            # Do:
            #    import pymel.core.windows; import sys; sys.modules[pymel.core.windows].XXX
            # instead!
            procCmd = """global proc int %s( int $row, int $column, string $val) {
                            return python("%s.scriptTableCmds['%s'](" + $row + "," + $column + ",'" + $val + "')");}
                      """ %  (procName, thisModuleCmd, key)
            mel.eval( procCmd )
            scriptTableCmds[key] = cc

            # create a scriptJob to clean up the dictionary of functions
            cmds.scriptJob(uiDeleted=(uiName, lambda *x: scriptTableCmds.pop(key,None)))
            cc = procName
        kwargs['cellChangedCmd'] = cc

    if kwargs:
        cmds.scriptTable( uiName, e=1, **kwargs)
    return uitypes.ScriptTable(uiName)

def getPanel(*args, **kwargs):
    typeOf = kwargs.pop('typeOf', kwargs.pop('to', None) )
    if typeOf:
        # typeOf flag only allows short names
        kwargs['typeOf'] = typeOf.rsplit('|',1)[-1]
    return cmds.getPanel(*args, **kwargs )
#
#
#def textScrollList( *args, **kwargs ):
#    """
#Modifications:
#  - returns an empty list when the result is None for queries: selectIndexedItem, allItems, selectItem queries
#    """
#    res = cmds.textScrollList(*args, **kwargs)
#    return _factories.listForNoneQuery( res, kwargs, [('selectIndexedItem', 'sii'), ('allItems', 'ai'), ('selectItem', 'si',)] )
#
#def optionMenu( *args, **kwargs ):
#    """
#Modifications:
#  - returns an empty list when the result is None for queries: itemListLong, itemListShort queries
#    """
#    res = cmds.optionMenu(*args, **kwargs)
#    return _factories.listForNoneQuery( res, kwargs, [('itemListLong', 'ill'), ('itemListShort', 'ils')] )
#
#def optionMenuGrp( *args, **kwargs ):
#    """
#Modifications:
#  - returns an empty list when the result is None for queries: itemlistLong, itemListShort queries
#    """
#    res = cmds.optionMenuGrp(*args, **kwargs)
#    return _factories.listForNoneQuery( res, kwargs, [('itemListLong', 'ill'), ('itemListShort', 'ils')] )
#
#def modelEditor( *args, **kwargs ):
#    """
#Modifications:
#  - casts to PyNode for queries: camera
#    """
#    res = cmds.modelEditor(*args, **kwargs)
#    if kwargs.get('query', kwargs.get('q')) and kwargs.get( 'camera', kwargs.get('cam')):
#        import general
#        return general.PyNode(res)
#    return res

#===============================================================================
# Provides classes and functions to facilitate UI creation in Maya
#===============================================================================

def verticalLayout(*args, **kwargs):
    kwargs['orientation'] = 'vertical'
    return autoLayout(*args, **kwargs)

def horizontalLayout(*args, **kwargs):
    kwargs['orientation'] = 'horizontal'
    return autoLayout(*args, **kwargs)

def promptBox(title, message, okText, cancelText, **kwargs):
    """ Prompt for a value. Returns the string value or None if cancelled """
    ret = promptDialog(t=title, m=message, b=[okText,cancelText], db=okText, cb=cancelText,**kwargs)
    if ret==okText:
        return promptDialog(q=1,tx=1)

def promptBoxGenerator(*args, **kwargs):
    """ Keep prompting for values until cancelled """
    while 1:
        ret = promptBox(*args, **kwargs)
        if not ret: return
        yield ret

def confirmBox(title, message, yes="Yes", no="No", *moreButtons, **kwargs):
    """ Prompt for confirmation.

    Parameters
    ----------
    title : str
        The title of the confirmation window
    message : str
        The message in the body of the window
    yes : str
        The label of the first/'yes' button
    no : str
        The label of the second/'no' button
    moreButtons : tuple of str
        strings indicating the labels for buttons beyond the second
    returnButton : boolean
        by default, if there are only two buttons, the return value is a boolean
        indicating whether the 'yes' button was pressed; if you wish to always
        force the label of the pressed button to be returned, set this to True
    kwargs : dict of objects
        keyword args to pass to the underlying confirmDialog call

    Returns
    -------
    result : bool or str
        by default, if there are only two buttons, the return value is a boolean
        indicating whether the 'yes' button was pressed; otherwise, if there
        were more than two buttons or the returnButton keyword arg was set to
        True, the name of the pressed button is returned (or the dismissString,
        as explained in the docs for confirmDialog)
    """

    returnButton = kwargs.pop('returnButton', False)
    default = kwargs.get("db", kwargs.get("defaultButton")) or yes

    ret = confirmDialog(t=title,    m=message,     b=[yes,no] + list(moreButtons),
                           db=default,
                           ma="center", cb=no, ds=no)
    if moreButtons or returnButton:
        return ret
    else:
        return (ret==yes)

def informBox(title, message, ok="Ok"):
    """ Information box """
    confirmDialog(t=title, m=message, b=[ok], db=ok)


class PopupError( Exception ):
    """Raise this exception in your scripts to cause a confirmDialog to be opened displaying the error message.
    After the user presses 'OK', the exception will be raised as normal. In batch mode the promptDialog is not opened.

    Parameters
    ----------
    msgOrException : str or Exception instance
        If a string, then the actual exception object returned / raised will
        be a PopupError instance, and the message displayed will be this arg;
        if an Exception instance, then the expection object returned / raised
        will be the given instance
    title : str
        title of the dialog
    button : str
        text on the confirm button of the dialog
    msg : str Or None
        If msgOrException was not an exception instance, this is ignored; if it
        is, then this controls what the displayed message is. If it is None,
        then the displayed message is the first arg of the exception instance,
        or the empty string if it has no args. If it is a string, then that will
        be the displayed message.
    icon : str
        icon to use for the confirm dialog (see confirmDialog docs for available
        icons)
    """
    def __new__(cls, msgOrException, title='Error', button='Ok', msg=None,
                icon='critical'):
        if not isinstance(msgOrException, (basestring, Exception)):
            raise TypeError(msgOrException)

        if not cmds.about(batch=1):
            if not isinstance(msgOrException, Exception):
                msg = msgOrException
            elif msg is None:
                args = getattr(msgOrException, 'args', [])
                if args:
                    msg = args[0]
                else:
                    msg = ''
            confirmDialog(title=title, message=msg, button=button, icon=icon)
        if isinstance(msgOrException, Exception):
            return msgOrException
        else:
            return super(PopupError, cls).__new__(cls, msgOrException)

    def __init__(self, msg, *args, **kwargs):
        super(PopupError, self).__init__(msg)

def promptForFolder():
    """ Prompt the user for a folder path """

    # a little trick that allows us to change the top-level 'folder' variable from
    # the nested function ('getfolder') - use a single-element list, and change its content
    folder = [None]
    def getfolder(*args):
        folder[0] = args[0]
    ret = cmds.fileBrowserDialog(m=4, fc=getfolder, an="Get Folder")
    folder = _Path(folder[0])
    if folder.exists():
        return folder


def promptForPath(**kwargs):
    """ Prompt the user for a folder path """

    if cmds.about(linux=1):
        return _Path(fileDialog(**kwargs))

    else:
        # a little trick that allows us to change the top-level 'folder' variable from
        # the nested function ('getfolder') - use a single-element list, and change its content

        folder = [None]
        def getfolder(*args):
            folder[0] = args[0]

        kwargs.pop('fileCommand',None)
        kwargs['fc'] = getfolder

        if 'mode' not in kwargs:
            kwargs['mode'] = 0

        kwargs['an'] = kwargs.pop('an', kwargs.pop('actionName', "Select File"))
        ret = cmds.fileBrowserDialog(**kwargs)
        folder = _Path(folder[0])
        if folder:
            #Ensure something was entered/selected. But don't test if it exists
            # as this would break mode 1/100+ causing them to return None
            return folder


def fileDialog(*args, **kwargs):
    ret = cmds.fileDialog(*args, **kwargs )
    if ret:
        return _Path( ret )

def showsHourglass(func):
    """ Decorator - shows the hourglass cursor until the function returns """
    def decoratedFunc(*args, **kwargs):
        cmds.waitCursor(st=True)
        try:
            return func(*args, **kwargs)
        finally:
            cmds.waitCursor(st=False)
    decoratedFunc.__doc__ = func.__doc__
    decoratedFunc.__name__ = func.__name__
    decoratedFunc.__module__ = func.__module__
    return decoratedFunc



def pathButtonGrp( name=None, *args, **kwargs ):
    import uitypes
    if name is None or not cmds.textFieldButtonGrp( name, ex=1 ):
        create = True
    else:
        create = False

    return uitypes.PathButtonGrp( name=name, create=create, *args, **kwargs )

def folderButtonGrp( name=None, *args, **kwargs ):
    import uitypes
    if name is None or not cmds.textFieldButtonGrp( name, ex=1 ):
        create = True
    else:
        create = False

    return uitypes.FolderButtonGrp( name=name, create=create, *args, **kwargs )

def vectorFieldGrp( *args, **kwargs ):
    import uitypes
    return uitypes.VectorFieldGrp( *args, **kwargs )


def uiTemplate(name=None, force=False, exists=None):
    import uitypes
    if exists:
        return cmds.uiTemplate(name, exists=1)
    else:
        return uitypes.UITemplate(name=name, force=force)

def setParent(*args, **kwargs):
    """
Modifications
  - returns None object instead of the string 'NONE'
    """
    import uitypes
    result = cmds.setParent(*args, **kwargs)
    if kwargs.get('query', False) or kwargs.get('q', False):
        if result == 'NONE':
            result = None
        else:
            result = uitypes.PyUI(result)
    return result

def currentParent():
    "shortcut for ``ui.PyUI(setParent(q=1))`` "

    return setParent(q=1)

def currentMenuParent():
    "shortcut for ``ui.PyUI(setParent(q=1, menu=1))`` "
    return setParent(q=1, menu=1)

# fix a bug it becomes impossible to create a menu after setParent has been called
def menu(*args, **kwargs):
    """
Modifications
  - added ability to query parent
    """
    if _versions.current() < _versions.v2011:
        # on create only
        if not ( kwargs.get('query', False) or kwargs.get('q', False) ) \
            and not ( kwargs.get('edit', False) or kwargs.get('e', False) ) \
            and not ( kwargs.get('parent', False) or kwargs.get('p', False) ):
            kwargs['parent'] = cmds.setParent(q=1)

    if ( kwargs.get('query', False) or kwargs.get('q', False) ) \
            and ( kwargs.get('parent', False) or kwargs.get('p', False) ):
        name = unicode(args[0])
        if '|' not in name:
            try:
                name = _findLongName(name, 'menu')
            except ValueError:
                name = _findLongName(name, 'popupMenu')
        return name.rsplit('|',1)[0]

    result = cmds.menu(*args, **kwargs)

    if ( kwargs.get('query', False) or kwargs.get('q', False) ) \
            and ( kwargs.get('itemArray', False) or kwargs.get('ia', False) ) \
            and result is None:
        result = []
    return result

def _createClassCommands():
    def createCallback( classname ):
        """
        create a callback that will trigger lazyLoading
        """
        def callback(*args, **kwargs):
            import uitypes
            res = getattr(uitypes, classname)(*args, **kwargs)
            return res
        return callback

    for funcName in _factories.uiClassList:
        # Create Class
        classname = _util.capitalize(funcName)
        #cls = _uitypes[classname]

        # Create Function
        func = _factories.functionFactory( funcName, createCallback(classname), _thisModule, uiWidget=True )
        if func:
            func.__module__ = __name__
            setattr(_thisModule, funcName, func)


def _createOtherCommands():
    moduleShortName = __name__.split('.')[-1]
    nonClassFuncs = set(_factories.moduleCmds[moduleShortName]).difference(_factories.uiClassList)
    for funcName in nonClassFuncs:
        func = _factories.functionFactory( funcName, returnFunc=None, module=_thisModule )
        if func:
            func.__module__ = __name__
            setattr(_thisModule, funcName, func)
            # want this call to work regardless of order we call _createClassCommandParis / _createCommands
            if sys.modules[__name__] != _thisModule:
                setattr( sys.modules[__name__], funcName, func )

_createClassCommands()
_createOtherCommands()

def autoLayout(*args, **kwargs):
    import uitypes
    return uitypes.AutoLayout(*args, **kwargs)

autoLayout.__doc__ = formLayout.__doc__

def subMenuItem(*args, **kwargs):
    """
    shortcut for ``menuItem(subMenu=True)``
    """
    kwargs['subMenu'] = True
    return menuItem(*args, **kwargs)


#class ValueControlGrp( UI ):
#    def __new__(cls, name=None, create=False, dataType=None, numberOfControls=1, **kwargs):
#
#        if cls._isBeingCreated(name, create, kwargs):
#            assert dataType
#            if not isinstance(dataType, basestring):
#                try:
#                    dataType = dataType.__name__
#                except AttributeError:
#                    dataType = str(dataType)
#
#            # if a dataType such as float3 or int2 was passed, get the number of ctrls
#            try:
#                numberOfControls = int(re.search( '(\d+)$', dataType ).group(0))
#            except:
#                pass
#
#            dataType = dataType.lower()
#
#            kwargs.pop('dt',None)
#            kwargs['docTag'] = dataType
##            kwargs.pop('nf', None)
##            kwargs['numberOfFields'] = 3
##            name = cmds.floatFieldGrp( name, *args, **kwargs)
#
#        #labelStr = kwargs.pop( 'label', kwargs.pop('l', str(dataType) ) )
#        if dataType in ["bool"]:
#            ctrl = _uitypes.CheckBoxGrp
#            getter = ctrl.getValue1
#            setter = ctrl.setValue1
#            #if hasDefault: ctrl.setValue1( int(default) )
#
#        elif dataType in ["int"]:
#            ctrl = _uitypes.IntFieldGrp
#            getter = ctrl.getValue1
#            setter = ctrl.setValue1
#            #if hasDefault: ctrl.setValue1( int(default) )
#
#        elif dataType in ["float"]:
#            ctrl = _uitypes.FloatFieldGrp
#            getter = ctrl.getValue1
#            setter = ctrl.setValue1
#            #if hasDefault: ctrl.setValue1( float(default) )
#
#        elif dataType in ["vector", "Vector"]:
#            ctrl = VectorFieldGrp
#            getter = ctrl.getVector
#            setter = ctrl.setValue1
#            #if hasDefault: ctrl.setVector( default )
#
#        elif dataType in ["path", "Path", "FileReference"]:# or pathreg.search( argName.lower() ):
#            ctrl = PathButtonGrp
#            getter = ctrl.getPath
#            setter = ctrl.setPath
#            #if hasDefault: ctrl.setText( default.__repr__() )
#
#        elif dataType in ["string", "unicode", "str"]:
#            ctrl = _uitypes.TextFieldGrp
#            getter = ctrl.getText
#            setter = ctrl.setText
#            #if hasDefault: ctrl.setText( str(default) )
#        else:
#             raise TypeError
##        else:
##            ctrl = _uitypes.TextFieldGrp( l=labelStr )
##            getter = makeEvalGetter( ctrl.getText )
##            #setter = ctrl.setValue1
##            #if hasDefault: ctrl.setText( default.__repr__() )
#        cls.__melcmd__ = staticmethod( ctrl.__melcmd__ )
#        self = ctrl.__new__( cls, name, create, **kwargs )
#        self.getter = getter
#        self.ctrlClass = ctrl
#        return self
#
#    def getValue(self):
#        return self.getter(self)

def valueControlGrp(name=None, create=False, dataType=None, slider=True, value=None, numberOfControls=1, **kwargs):
    """
    This function allows for a simplified interface for automatically creating UI's to control numeric values.

    A dictionary of keywords shared by all controls can be created and passed to this function and settings which don't pertain
    to the element being created will will be ignore.  For example, 'precision' will be ignored by all non-float UI and
    'sliderSteps' will be ignore by all non-slider UIs.

    :Parameters:
        dataType : string or class type
            The dataType that the UI should control.  It can be a type object or the string name of the type.
            For example for a boolean, you can specify 'bool' or pass in the bool class. Also, if the UI is meant to
            control an array, you can pass the type name as a stirng with a integer suffix representing the array length. ex. 'bool3'

        numberOfControls : int
            A parameter for specifying the number of controls per control group.  For example, for a checkBoxGrp, numberOfControls
            will map to the 'numberOfCheckBoxes' keyword.

        slider : bool
            Specify whether or not sliders should be used for int and float controls. Ignored for other
            types, as well as for int and float arrays

        value : int, int list, bool, bool list, float, float list, string, unicode, Path, Vector,
            The value for the control. If the value is for an array type, it should be a list or tuple of the appropriate
            number of elements.

    A straightforward example:

    .. python::

        settings = {}
        settings['step'] = 1
        settings['precision'] = 3
        settings['vertical'] = True # for all checkBoxGrps, lay out vertically
        win = window()
        columnLayout()
        setUITemplate( 'attributeEditorTemplate', pushTemplate=1 )
        boolCtr = valueControlGrp( dataType='bool', label='bool', **settings)
        bool3Ctr = valueControlGrp( dataType='bool', label='bool', numberOfControls=3, **settings)
        intCtr = valueControlGrp( dataType=int, label='int', slider=False, **settings)
        intSldr = valueControlGrp( dataType=int, label='int', slider=True, **settings)
        int3Ctrl= valueControlGrp( dataType=int, label='int', numberOfControls=3, **settings)
        floatCtr = valueControlGrp( dataType=float, label='float', slider=False, **settings)
        floatSldr = valueControlGrp( dataType=float, label='float', slider=True, **settings)
        pathCtrl = valueControlGrp( dataType=Path, label='path', **settings)
        win.show()


    Here's an example of how this is meant to be used in practice:

    .. python::

        settings = {}
        settings['step'] = 1
        settings['precision'] = 3
        win = window()
        columnLayout()
        types=[ ( 'donuts?',
                    bool,
                    True ),
                # bool arrays have a special label syntax that allow them to pass sub-labels
                ( [ 'flavors', ['jelly', 'sprinkles', 'glazed']],
                    'bool3',
                    [0,1,0]),
                ( 'quantity',
                  int,
                  12 ),
                ( 'delivery time',
                  float,
                  .69)
                ]
        for label, dt, val in types:
            valueControlGrp( dataType=dt, label=label, value=val, **settings)
        win.show()

    """
    import uitypes

    def makeGetter( ctrl, methodName, num ):
        def getter( ):
            res = []
            for i in range( num ):
                res.append( getattr(ctrl, methodName + str(i+1) )() )
            return res
        return getter

    def makeSetter( ctrl, methodName, num ):
        def setter( args ):
            for i in range( num ):
                getattr(ctrl, methodName + str(i+1) )(args[i])
        return setter

    # the options below are only valid for certain control types.  they can always be passed to valueControlGrp, but
    # they will be ignore if not applicable to the control for this dataType.  this allows you to create a
    # preset configuration and pass it to the valueControlGrp for every dataType -- no need for creating switches, afterall
    # that's the point of this function

    sliderArgs = [ 'sliderSteps', 'ss', 'dragCommand', 'dc' ]
    fieldArgs = [ 'field', 'f', 'fieldStep', 'fs', 'fieldMinValue', 'fmn', 'fieldMaxValue', 'fmx' ]
    fieldSliderArgs = ['step', 's', 'minValue', 'min', 'maxValue', 'max', 'extraLabel', 'el'] + sliderArgs + fieldArgs
    floatFieldArgs = ['precision', 'pre']
    verticalArgs = ['vertical', 'vr'] #checkBoxGrp and radioButtonGrp only

    if uitypes.PyUI._isBeingCreated(name, create, kwargs):
        assert dataType, "You must pass a dataType when creating a new control"
        if not isinstance(dataType, basestring):
            try:
                dataType = dataType.__name__
            except AttributeError:
                dataType = str(dataType)

        # if a dataType such as float3 or int2 was passed, get the number of ctrls
        try:
            buf = re.split( '(\d+)', dataType )
            dataType = buf[0]
            numberOfControls = int(buf[1])
        except:
            pass
    else:
        # control command lets us get basic info even when we don't know the ui type
        dataType = control( name, q=1, docTag=1)
        assert dataType

    numberOfControls = int(numberOfControls)
    if numberOfControls < 1:
        numberOfControls = 1
    elif numberOfControls > 4:
        numberOfControls = 4

    #dataType = dataType.lower()
    kwargs.pop('dt',None)
    kwargs['docTag'] = dataType

    if dataType in ["bool"]:
        if numberOfControls > 1:
            kwargs.pop('ncb', None)
            kwargs['numberOfCheckBoxes'] = numberOfControls

        # remove field/slider and float kwargs
        for arg in fieldSliderArgs + floatFieldArgs:
            kwargs.pop(arg, None)

        # special label handling
        label = kwargs.get('label', kwargs.get('l',None) )
        if label is not None:
            # allow label passing with additional sub-labels:
            #    ['mainLabel', ['subLabel1', 'subLabel2', 'subLabel3']]
            if _util.isIterable(label):
                label, labelArray = label
                kwargs.pop('l',None)
                kwargs['label'] = label
                kwargs['labelArray' + str(numberOfControls) ] = labelArray

        ctrl = uitypes.CheckBoxGrp( name, create, **kwargs )

        if numberOfControls > 1:
            getter = makeGetter(ctrl, 'getValue', numberOfControls)
            setter = makeSetter(ctrl, 'setValue', numberOfControls)
        else:
            getter = ctrl.getValue1
            setter = ctrl.setValue1
        #if hasDefault: ctrl.setValue1( int(default) )

    elif dataType in ["int"]:
        if numberOfControls > 1:
            kwargs.pop('nf', None)
            kwargs['numberOfFields'] = numberOfControls
            slider = False

        if slider:
            # remove float kwargs
            for arg in floatFieldArgs + verticalArgs:
                kwargs.pop(arg, None)
            # turn the field on by default
            if 'field' not in kwargs and 'f' not in kwargs:
                kwargs['field'] = True

            ctrl = uitypes.IntSliderGrp( name, create, **kwargs )
            getter = ctrl.getValue
            setter = ctrl.setValue
        else:
            # remove field/slider and float kwargs
            for arg in fieldSliderArgs + floatFieldArgs + verticalArgs:
                kwargs.pop(arg, None)
            ctrl = uitypes.IntFieldGrp( name, create, **kwargs )

            getter = ctrl.getValue1
            setter = ctrl.setValue1
        #if hasDefault: ctrl.setValue1( int(default) )

    elif dataType in ["float"]:
        if numberOfControls > 1:
            kwargs.pop('nf', None)
            kwargs['numberOfFields'] = numberOfControls
            slider = False

        if slider:
            for arg in verticalArgs:
                kwargs.pop(arg, None)

            # turn the field on by default
            if 'field' not in kwargs and 'f' not in kwargs:
                kwargs['field'] = True
            ctrl = uitypes.FloatSliderGrp( name, create, **kwargs )
            getter = ctrl.getValue
            setter = ctrl.setValue
        else:
            # remove field/slider kwargs
            for arg in fieldSliderArgs + verticalArgs:
                kwargs.pop(arg, None)
            ctrl = uitypes.FloatFieldGrp( name, create, **kwargs )
            getter = ctrl.getValue1
            setter = ctrl.setValue1
        #if hasDefault: ctrl.setValue1( float(default) )

    elif dataType in ["vector", "Vector"]:
        # remove field/slider kwargs
        for arg in fieldSliderArgs + floatFieldArgs + verticalArgs:
            kwargs.pop(arg, None)
        ctrl = VectorFieldGrp( name, create, **kwargs )
        getter = ctrl.getVector
        setter = ctrl.setValue1
        #if hasDefault: ctrl.setVector( default )

    elif dataType in ["path", "Path", "FileReference"]:# or pathreg.search( argName.lower() ):
        # remove field/slider kwargs
        for arg in fieldSliderArgs + floatFieldArgs + verticalArgs:
            kwargs.pop(arg, None)
        ctrl = PathButtonGrp( name, create, **kwargs )
        getter = ctrl.getPath
        setter = ctrl.setPath
        #if hasDefault: ctrl.setText( default.__repr__() )

    elif dataType in ["string", "unicode", "str"]:
        # remove field/slider kwargs
        for arg in fieldSliderArgs + floatFieldArgs + verticalArgs:
            kwargs.pop(arg, None)
        ctrl = uitypes.TextFieldGrp( name, create, **kwargs )
        getter = ctrl.getText
        setter = ctrl.setText
        #if hasDefault: ctrl.setText( str(default) )
    else:
        raise TypeError, "Unsupported dataType: %s" % dataType
#        else:
#            ctrl = uitypes.TextFieldGrp( l=labelStr )
#            getter = makeEvalGetter( ctrl.getText )
#            #setter = ctrl.setValue1
#            #if hasDefault: ctrl.setText( default.__repr__() )

        #new = ctrl( name, create, **kwargs )
    ctrl.getValue = getter
    ctrl.setValue = setter
    ctrl.dataType = ctrl.getDocTag

    if value is not None:
        ctrl.setValue(value)

    # TODO : remove setDocTag
    return ctrl


def getMainProgressBar():
    import uitypes
    return uitypes.ProgressBar(melGlobals['gMainProgressBar'])

# Now that we've actually created all the functions, it should be safe to import
# uitypes...
if _versions.current() >= _versions.v2011:
    from uitypes import toQtObject, toQtLayout, toQtControl, toQtMenuItem, toQtWindow

from uitypes import objectTypeUI
########NEW FILE########
__FILENAME__ = apicache
""" Imports Maya API methods in the 'api' namespace, and defines various utilities for Python<->API communication """

# They will be imported / redefined later in Pymel, but we temporarily need them here
import inspect
import re
import itertools

import pymel.api as api
import pymel.versions as versions
import pymel.util as _util
import startup
import plogging as _plogging
from pymel.api.plugins import mpxNamesToApiEnumNames

_logger = _plogging.getLogger(__name__)

if versions.current() < versions.v2014:
    NUCLEUS_MFNDAG_BUG = True
    SYMMETRY_CONSTRAINT_MFNDAG_BUG = False
elif versions.current() == versions.v2014:
    NUCLEUS_MFNDAG_BUG = False
    SYMMETRY_CONSTRAINT_MFNDAG_BUG = True
else:
    NUCLEUS_MFNDAG_BUG = False
    SYMMETRY_CONSTRAINT_MFNDAG_BUG = False

#===============================================================================
# Utility classes
#===============================================================================

class ApiEnum(tuple):
    def __str__(self): return '.'.join( [str(x) for x in self] )
    def __repr__(self):
        return '%s( %s )' % (self.__class__.__name__, super(ApiEnum, self).__repr__())
    def pymelName(self):
        import pymel.internal.factories as factories
        parts = list(self)
        pymelName = factories.apiClassNameToPymelClassName(self[0])
        if pymelName is not None:
            parts[0] = pymelName
        return '.'.join( [str(x) for x in parts] )

if versions.current() < versions.v2012:
    # Before 2012, api had Enum, and when we unpickle the caches, it will
    # need to be there... could rebuild the caches (like I had to do with
    # mayaApiMelBridge) but don't really want to...
    api.Enum = ApiEnum
    Enum = ApiEnum

def _defaultdictdict(cls, val=None):
    if val is None:
        return _util.defaultdict(dict)
    else:
        return _util.defaultdict(dict, val)

#===============================================================================
# ghost objects
#===============================================================================

class GhostObjsOkHere(object):
    _OK = False

    @classmethod
    def OK(cls):
        return cls._OK

    def __enter__(self):
        self.oldOK = self.OK()
        type(self)._OK = True
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        type(self)._OK = self.oldOK

def _makeDgModGhostObject(mayaType, dagMod, dgMod):
    if versions.current() >= versions.v2012:
        # only time post-2012 when we should have to call this func is when
        # rebuilding caches - ie, running from inside ApiCache
        if not GhostObjsOkHere.OK():
            _logger.raiseLog(_logger.WARNING, '_makeDgModGhostObject should be unnecessary in maya versions past 2012 (except when rebuilding cache)')

    # we create a dummy object of this type in a dgModifier (or dagModifier)
    # as the dgModifier.doIt() method is never called, the object
    # is never actually created in the scene

    # Note: at one point, if we didn't call the dgMod/dagMod.deleteNode method,
    # and we call this function while loading a scene (for instance, if the scene requires
    # a plugin that isn't loaded, and defines custom node types), then the nodes were still
    # somehow created, despite never explicitly calling doIt()...
    # ... however, this seems to no longer be the case, and the deleteNode calls are apparently
    # harmful
    if type(dagMod) is not api.MDagModifier or type(dgMod) is not api.MDGModifier :
        raise ValueError, "Need a valid MDagModifier and MDGModifier or cannot return a valid MObject"

    # Regardless of whether we're making a DG or DAG node, make a parent first -
    # for some reason, this ensures good cleanup (don't ask me why...??)
    parent = dagMod.createNode ( 'transform', api.MObject())

    try :
        # DependNode
        obj = dgMod.createNode ( mayaType )
    except RuntimeError:
        # DagNode
        try:
            obj = dagMod.createNode ( mayaType, parent )
        except Exception, err:
            _logger.debug("Error trying to create ghost node for '%s': %s" %  (mayaType, err))
            return None

    if api.isValidMObject(obj) :
        return obj
    else :
        _logger.debug("Error trying to create ghost node for '%s'" %  mayaType)
        return None

class InvalidNodeTypeError(Exception): pass
class ManipNodeTypeError(InvalidNodeTypeError): pass

class _GhostObjMaker(object):
    '''Context used to get an mobject which we can query within this context.

    Automatically does any steps need to create and destroy the mobj within
    the context

    (Note - None may be returned in the place of any mobj)
    '''
    def __init__(self, mayaTypes, dagMod=None, dgMod=None, manipError=True,
                 multi=False):
        self.multi = multi
        if not multi:
            mayaTypes = [mayaTypes]
        self.mayaTypes = mayaTypes

        if dagMod is None:
            dagMod = api.MDagModifier()
        if dgMod is None:
            dgMod = api.MDGModifier()
        self.dagMod = dagMod
        self.dgMod = dgMod

        self.dagGhosts = False
        self.dgGhosts = False
        #self.theMod = None

        self.manipError = manipError
        self.byMayaType = {}
        self.ghosts = set()

    def __enter__(self):
        import maya.cmds as cmds

        for mayaType in self.mayaTypes:
            # check if an obj of the given type already exists in the scene, and
            # if so, use it
            madeGhost = False
            allObj = cmds.ls(exactType=mayaType)
            if allObj:
                obj = api.toMObject(allObj[0])
            else:
                if mayaType in ApiCache.CRASH_TYPES:
                    # the two items in CRASH_TYPES are both manips...
                    if self.manipError:
                        raise ManipNodeTypeError
                    obj = None
                else:
                    obj = _makeDgModGhostObject(mayaType, self.dagMod, self.dgMod)
                if obj is not None:
                    self.ghosts.add(mayaType)
                    madeGhost = True

            if obj is not None:
                if (self.manipError
                    and (obj.hasFn( api.MFn.kManipulator )
                         or obj.hasFn( api.MFn.kManipContainer )
                         or obj.hasFn( api.MFn.kPluginManipContainer )
                         or obj.hasFn( api.MFn.kPluginManipulatorNode )
                         or obj.hasFn( api.MFn.kManipulator2D )
                         or obj.hasFn( api.MFn.kManipulator3D )
                         or obj.hasFn( api.MFn.kManip2DContainer)
                        )
                   ):
                    raise ManipNodeTypeError

                if madeGhost and not (self.dagGhosts and self.dgGhosts):
                    if obj.hasFn( api.MFn.kDagNode ):
                        self.dagGhosts = True
                    else:
                        self.dgGhosts = True
            self.byMayaType[mayaType] = obj

        # Note that we always create a "real" instance of the object by
        # calling doIt()... we used to not call doIt(), in which case
        # the mobject would actually still be queryable, but not in the
        # scene - thus the "ghost" obj - but this would create problems in
        # some cases - ie, if this was triggered during reference loading,
        # the objects would actually be entered into the scene... and
        # because we didn't call undoIt, they wouldn't get cleaned up
        if self.dagGhosts:
            self.dagMod.doIt()
        if self.dgGhosts:
            self.dgMod.doIt()
        if self.multi:
            return self.byMayaType
        else:
            return obj

    def __exit__(self, exc_type, exc_value, traceback):
        try:
            if self.dagGhosts:
                self.dagMod.undoIt()
            if self.dgGhosts:
                self.dgMod.undoIt()
        except RuntimeError:
            stillExist = []
            for mayaType in self.ghosts:
                obj = self.byMayaType[mayaType]
                if obj is not None and api.isValidMObjectHandle(api.MObjectHandle(obj)):
                    stillExist.append(obj)
            if stillExist:
                mfnDag = api.MFnDagNode()
                mfnDep = api.MFnDependencyNode()
                names = []
                for obj in stillExist:
                    if obj.hasFn( api.MFn.kDagNode ):
                        # we need to delete the parent, since it will have
                        # created a parent transform too
                        mfnDag.setObject(obj)
                        mfnDag.setObject(mfnDag.parent(0))
                        names.append(mfnDag.partialPathName())
                    else:
                        mfnDep.setObject(obj)
                        names.append(mfnDep.name())
                print names
                #import maya.cmds as cmds
                #cmds.delete(names)

                mfnDag = api.MFnDagNode()
                dagMod = api.MDagModifier()
                dgMod = api.MDGModifier()

                delDag = False
                delDg = False

                for obj in stillExist:
                    if obj.hasFn( api.MFn.kDagNode ):
                        # we need to delete the parent, since it will have
                        # created a parent transform too
                        mfnDag.setObject(obj)
                        dagMod.deleteNode(mfnDag.parent(0))
                    else:
                        dgMod.deleteNode(obj)
                if delDag:
                    dagMod.doIt()
                if delDg:
                    dgMod.doIt()

#===============================================================================
# Utilities for query maya node info
#===============================================================================
_ABSTRACT_SUFFIX = ' (abstract)'
_ASSET_PREFIX = 'adskAssetInstanceNode_'

if hasattr(api, 'MNodeClass'):
    # if we have MNodeClass, this is easy...
    def isPluginNode(nodeName):
        try:
            api.MNodeClass(nodeName).pluginName()
            return True
        except RuntimeError:
            return False

else:
    # otherwise, we have to query all plugins...
    def isPluginNode(nodeName):
        import maya.cmds as cmds
        for plugin in cmds.pluginInfo(q=1, listPlugins=True):
            plugNodes = cmds.pluginInfo(plugin, q=1, dependNode=True)
            # plugNodes may be None...
            if plugNodes and nodeName in plugNodes:
                return True
        return False

# You'd think getting a comprehensive list of node types would be easy, but
# due to strange behavior of various edge cases, it can be tricky...
def _getMayaTypes(real=True, abstract=True, basePluginTypes=True, addAncestors=True,
                  noManips=True, noPlugins=False, returnRealAbstract=False):
    '''Returns a list of maya types

    Parameters
    ----------
    real : bool
        Include the set of real/createable nodes
    abstract : bool
        Include the set of abstract nodes (as defined by allNodeTypes(includeAbstract=True)
    basePluginTypes : bool
        Include the set of "base" plugin maya types (these are not returned by
        allNodeTypes(includeAbstract=True), and so, even though these types are
        abstract, this set shares no members with those added by the abstract
        flag
    addAncestors : bool
        If true, add to the list of nodes returned all of their ancestors as
        well
    noManips : bool
        If true, filter out any manipulator node types
    noPlugins : bool
        If true, filter out any nodes defined in plugins (note - if
        basePluginTypes is True, and noPlugins is False, the basePluginTypes
        will still be returned, as these types are not themselves defined in
        the plugin)
    returnRealAbstract : bool
        if True, will return two sets, realNodes and abstractNodes; otherwise,
        returns a single set of all the desired nodes (more precisely, realNodes
        is defined as the set of directly createdable nodes matching the
        criteria, and abstract are all non-createable nodes matching the
        criteria)
    '''
    import maya.cmds as cmds

    # keep track of which nodes were abstract - this can be useful later,
    # especially pre-2012
    abstractNodes = set()
    realNodes = set()
    if abstract or addAncestors:
        # if we want abstract, need to do extra processing to strip the
        # trailing ' (abstract)'
        raw = cmds.allNodeTypes(includeAbstract=True)
        for node in raw:
            if node.endswith(_ABSTRACT_SUFFIX):
                node = node[:-len(_ABSTRACT_SUFFIX)]
                # For some reason, maya returns these names with cmds.allNodeTypes(includeAbstract=True):
                #   adskAssetInstanceNode_TlightShape
                #   adskAssetInstanceNode_TdnTx2D
                #   adskAssetInstanceNode_TdependNode
                # ...but they show up in parent hierarchies with a 'T' in front, ie:
                #   cmds.nodeType(adskMaterial, isTypeName=True, inherited=True)
                #           == [u'TadskAssetInstanceNode_TdependNode', u'adskMaterial']
                # the 'T' form is also what is needed to use it as an arg to nodeType...
                # ...so, stick the 'T' in front...
                if node.startswith(_ASSET_PREFIX):
                    node = 'T' + node
                abstractNodes.add(node)
            else:
                if not real:
                    continue
                realNodes.add(node)
    elif real:
        realNodes.update(cmds.allNodeTypes())

    if basePluginTypes:
        import pymel.api.plugins
        abstractNodes.update(pymel.api.plugins.pluginMayaTypes)
    if addAncestors or noManips:
        # There are a few nodes which will not be returned even by
        # allNodeTypes(includeAbstract=True), but WILL show up in the
        # inheritance hierarchies...

        # iterate over first real nodes, then abstract nodes... this lets us
        # take advantage of inheritance caching - especially pre-2012, where
        # inheritance chain of abstract nodes is not directly queryable -
        # since getInheritance will cache the inheritance chain of the given
        # node, AND all it's parents

        # make a copy of what we iterate over, as we will be modifying
        # realNodes and abstractNodes as we go...
        for mayaType in list(itertools.chain(realNodes, abstractNodes)):
            try:
                ancestors = getInheritance(mayaType, checkManip3D=noManips)
            except ManipNodeTypeError:
                realNodes.discard(mayaType)
                abstractNodes.discard(mayaType)
            except RuntimeError:
                # was an error querying - happens with some node types, like
                # adskAssetInstanceNode_TdnTx2D
                continue
            else:
                if addAncestors and ancestors:
                    abstractNodes.update(set(ancestors) - realNodes)
    if noPlugins:
        for nodeSet in (realNodes, abstractNodes):
            # need to modify in place, so make copy of nodeSet...
            for node in list(nodeSet):
                if isPluginNode(node):
                    nodeSet.remove(node)

    # we may have put nodes in realNodes or abstractNodes for info purposes...
    # make sure they are cleared before returning results, if needed...
    if not real:
        realNodes = set()
    if not abstract:
        abstractNodes = set()

    if returnRealAbstract:
        return realNodes, abstractNodes
    else:
        return realNodes | abstractNodes

def _getAbstractMayaTypes(**kwargs):
    kwargs.setdefault('real', False)
    kwargs['abstract'] = True
    return _getMayaTypes(**kwargs)

def _getRealMayaTypes(**kwargs):
    kwargs['real'] = True
    kwargs.setdefault('abstract', False)
    kwargs.setdefault('basePluginTypes', False)
    kwargs.setdefault('addAncestors', False)
    return _getMayaTypes(**kwargs)

def _getAllMayaTypes(**kwargs):
    kwargs['real'] = True
    kwargs['abstract'] = True
    return _getMayaTypes(**kwargs)

_fixedLineages = {}
_cachedInheritances = {}

def getInheritance( mayaType, checkManip3D=True, checkCache=True,
                    updateCache=True ):
    """Get parents as a list, starting from the node after dependNode, and
    ending with the mayaType itself.

    Raises a ManipNodeTypeError if the node type fed in was a manipulator
    """

    # To get the inheritance post maya2012, we use nodeType(isTypeName=True),
    # which means we don't need a real node. However, in maya < 2012, nodeType
    # requires a real node.  To do get these without poluting the scene we use the
    # _GhostObjMaker, which on enter, uses a dag/dg modifier, and calls the doIt
    # method; we then get the lineage, and on exit, it calls undoIt.
    global _cachedInheritances
    if checkCache and mayaType in _cachedInheritances:
        return _cachedInheritances[mayaType]

    import maya.cmds as cmds
    lineage = None
    if versions.current() >= versions.v2012:
        # We now have nodeType(isTypeName)! yay!
        try:
            lineage = cmds.nodeType(mayaType, isTypeName=True, inherited=True)
        except RuntimeError:
            pass
    else:
        with _GhostObjMaker(mayaType) as obj:
            if obj is not None:
                if obj.hasFn( api.MFn.kDagNode ):
                    name = api.MFnDagNode(obj).partialPathName()
                else:
                    name = api.MFnDependencyNode(obj).name()
                if not obj.isNull() and not obj.hasFn( api.MFn.kManipulator3D ) and not obj.hasFn( api.MFn.kManipulator2D ):
                    lineage = cmds.nodeType( name, inherited=1)
    if lineage is None:
        global _fixedLineages
        if not _fixedLineages:
            if versions.current() >= versions.v2012:
                controlPoint = cmds.nodeType('controlPoint', isTypeName=True,
                                             inherited=True)
            else:
                controlPoint = [u'containerBase',
                    u'entity',
                    u'dagNode',
                    u'shape',
                    u'geometryShape',
                    u'deformableShape',
                    u'controlPoint']
            # maya2013 introduced shadingDependNode...
            if versions.current() >= versions.v2013:
                texture2d = ['shadingDependNode', 'texture2d']
            else:
                texture2d = ['texture2d']
            # For whatever reason, nodeType(isTypeName) returns
            # None for the following mayaTypes:
            _fixedLineages = {
                'node':[],
                'file':texture2d + [u'file'],
                'lattice':controlPoint + [u'lattice'],
                'mesh':controlPoint + [u'surfaceShape', u'mesh'],
                'nurbsCurve':controlPoint + [u'curveShape', u'nurbsCurve'],
                'nurbsSurface':controlPoint + [u'surfaceShape', u'nurbsSurface'],
                'time':[u'time']
            }
        if mayaType in _fixedLineages:
            lineage = _fixedLineages[mayaType]
        else:
            raise RuntimeError("Could not query the inheritance of node type %s" % mayaType)
    elif checkManip3D and 'manip3D' in lineage:
        raise ManipNodeTypeError
    try:
        assert (mayaType == 'node' and lineage == []) or lineage[-1] == mayaType
    except Exception:
        print mayaType, lineage
        raise

    if updateCache and lineage:
        # add not just this lineage, but all parent's lineages as well...
        for i in xrange(len(lineage), 0, -1):
            thisLineage = lineage[:i]
            thisNode = thisLineage[-1]
            oldVal = _cachedInheritances.get(thisNode)
            if oldVal and oldVal != thisLineage:
                _logger.raiseLog(_logger.WARNING, "lineage for node %s changed (from %s to %s)" % (thisNode, oldVal, thisLineage))
            _cachedInheritances[thisNode] = thisLineage
    return lineage

#===============================================================================
# Name utilities
#===============================================================================

def nodeToApiName(nodeName):
    return 'k' + _util.capitalize(nodeName)

def getLowerCaseMapping(names):
    uniqueLowerNames = {}
    multiLowerNames = {}
    for name in names:
        lowerType = name.lower()
        if lowerType in multiLowerNames:
            multiLowerNames[lowerType].append(name)
        elif lowerType in uniqueLowerNames:
            multiLowerNames[lowerType] = [uniqueLowerNames.pop(lowerType), name]
        else:
            uniqueLowerNames[lowerType] = name
    return uniqueLowerNames, multiLowerNames

API_NAME_MODIFIERS = {
    'base':'',
    'abstract':'',
    'node':'',
    'shape':'',
    'mod(?!(ify|ifier))':'modify',
    'mod(?!(ify|ifier))':'modifier',
    'modifier':'mod',
    'modify':'mod',
    'poly(?!gon)':'polygon',
    'polygon':'poly',
    'vert(?!(ex|ice))':'vertex',
    'vert(?!(ex|ice))':'vertice',
    'vertice':'vert',
    'vertex':'vert',
    'subd(?!iv)':'subdiv',
    'subd(?!iv)':'subdivision',
    'subdiv(?!ision)':'subd',
    'subdiv(?!ision)':'subdivision',
    'subdivision':'subd',
    'subdivision':'subdiv',
    '^th(custom)?':'plugin',
    }
API_NAME_MODIFIERS = [(re.compile(find), replace)
                      for find, replace in API_NAME_MODIFIERS.iteritems()]

apiSuffixes = ['', 'node', 'shape', 'shapenode']

#===============================================================================
# Cache classes
#===============================================================================

class ApiMelBridgeCache(startup.SubItemCache):
    NAME = 'mayaApiMelBridge'
    DESC = 'the API-MEL bridge'
    COMPRESSED = True
    USE_VERSION = False
    _CACHE_NAMES = '''apiToMelData apiClassOverrides'''.split()

    CACHE_TYPES = {'apiToMelData':_defaultdictdict}
    STORAGE_TYPES = {'apiToMelData':dict}


class ApiCache(startup.SubItemCache):
    NAME = 'mayaApi'
    DESC = 'the API cache'
    COMPRESSED = True
    USE_VERSION = True
    _CACHE_NAMES = '''apiTypesToApiEnums apiEnumsToApiTypes mayaTypesToApiTypes
                   apiTypesToApiClasses apiClassInfo'''.split()


    EXTRA_GLOBAL_NAMES = tuple(['mayaTypesToApiEnums'])

    # Descriptions of various elements:

    # Maya static info :
    # Initializes various static look-ups to speed up Maya types conversions
    # self.apiClassInfo
    # self.apiTypesToApiEnums
    # self.apiEnumsToApiTypes
    # self.apiTypesToApiClasses

    # Lookup of currently existing Maya types as keys with their corresponding API type as values.
    # Not a read only (static) dict as these can change (if you load a plugin)
    # self.mayaTypesToApiTypes

    # lookup tables for a direct conversion between Maya type to their MFn::Types enum
    # self.mayaTypesToApiEnums

    # creating these will crash Maya!
    CRASH_TYPES = {
        'xformManip':'kXformManip',
        'moveVertexManip':'kMoveVertexManip',
    }

    # hold any overrides for mayaTypesToApiTypes...
    # ie, for cases where the name guess is wrong, or for weird plugin types
    # that don't inherit from an mpx type (ie, vectorRenderGlobals), etc
    MAYA_TO_API_OVERRIDES = {
                             # this what is returned by
                             # allNodeTypes(includeAbstract=True)
                             'node':'kDependencyNode',

                             # this is the name pymel uses
                             'dependNode':'kDependencyNode',

                             # a strange one - a plugin node that has an
                             # apitype... is in studioImport.so... also has a
                             # doc entry...
                             'smear':'kSmear',

                             # plugin node that's not in all distributions
                             # (ie, it's missing in Linux), so just include it
                             # here
                             'vectorRenderGlobals':'kDependencyNode',
                            }

    # TODO: if nucleus/symmetryConstraint bug ever fixed:
    #   - remove entry in apiCache.ApiCache.API_TO_MFN_OVERRIDES
    #   - remove hard-code setting of Nucleus's parent to DependNode
    #   - remove 2 checks in allapi.toApiObject for objects which can have an
    #     MDagPath but can't use MFnDagNode

    API_TO_MFN_OVERRIDES = {
                            'kHikHandle':api.MFnTransform, # hikHandle inherits from ikHandle, but is not compatible with MFnIkHandle
                            'kFfdDualBase':api.MFnDependencyNode, # jointFfd inherits from ffd, but is not compatible with MFnLatticeDeformer
                            'kTransferAttributes':api.MFnDependencyNode, # transferAttributes inherits from weightGeometryFilter, but is not compatible with MFnWeightGeometryFilter or MFnGeometryFilter
                           }

    if NUCLEUS_MFNDAG_BUG:
        # fun one - even though it can be parented and inherits from transform,
        # it's incompatible with MFnTransform or even MFnDagNode
        API_TO_MFN_OVERRIDES['kNucleus'] = api.MFnDependencyNode
    if SYMMETRY_CONSTRAINT_MFNDAG_BUG:
        API_TO_MFN_OVERRIDES['kSymmetryConstraint'] = api.MFnDependencyNode

    DEFAULT_API_TYPE = 'kDependencyNode'

    def __init__(self, docLocation=None):
        super(ApiCache, self).__init__()
        for name in self.EXTRA_GLOBAL_NAMES:
            setattr(self, name, {})
        self.docLocation = docLocation

    def _buildMayaToApiInfo(self):

        self._buildMayaNodeInfo()
        # Fixes for types that don't have a MFn by doing a node creation and testing it
        unknownTypes = set()
        toCreate = []

        self.mayaTypesToApiTypes = self._buildMayaReservedTypes()

        # do real nodes first - on pre-2012, can't directly query inheritance of
        # abstract nodes, so relying on caching of parent hierarchies when
        # querying a real hierarchy is the only way to get inheritance info
        # for abstract types
        for mayaType in itertools.chain(self.realMayaTypes,
                                        self.abstractMayaTypes):
            if mayaType not in self.mayaTypesToApiTypes:
                toCreate.append(mayaType)

        if toCreate:
            # Put in a debug, because ghost nodes can be problematic...
            _logger.debug("Starting to create ghost nodes...")

            with GhostObjsOkHere():
                with _GhostObjMaker(toCreate, manipError=False, multi=True) as typeToObj:
                    for mayaType in toCreate:
                        obj = typeToObj[mayaType]
                        if obj :
                            apiType = obj.apiTypeStr()
                            self.mayaTypesToApiTypes[mayaType] = apiType
                        else:
                            unknownTypes.add(mayaType)
            # Put in a debug, because ghost nodes can be problematic...
            _logger.debug("...finished creating ghost nodes")

        if len(unknownTypes) > 0:
            _logger.warn("Unable to get maya-to-api type info for the following nodes: %s" % ", ".join(unknownTypes))
            for mayaType in unknownTypes:
                # For unknown types, use the parent type
                try:
                    inheritance = getInheritance(mayaType)
                except (ManipNodeTypeError, RuntimeError):
                    continue
                apiType = None

                # if we have a node A, and we get back it's inheritance as:
                #    [E, D, C, B, A]
                # ...and 'D' is the first parent that we can find info for, we
                # may as well set the types for 'B' and 'C' parents as well...
                # also, this means that we may already have set THIS mayaType
                # (if it was the parent of another unknown node we already set),
                # so we loop through all nodes in inheritance, including this
                # type
                toSet = [mayaType]
                if inheritance:
                    for parent in reversed(inheritance):
                        apiType = self.mayaTypesToApiTypes.get(parent)
                        if apiType:
                            break
                        else:
                            toSet.append(parent)
                if not apiType:
                    apiType = self.DEFAULT_API_TYPE
                for node in toSet:
                    self.mayaTypesToApiTypes[node] = apiType

        for mayaType, apiType in self.mayaTypesToApiTypes.iteritems() :
            self.addMayaType( mayaType, apiType )

    def _buildApiTypesList(self):
        """the list of api types is static.  even when a plugin registers a new maya type, it will be associated with
        an existing api type"""

        self.apiTypesToApiEnums = dict( inspect.getmembers(api.MFn, lambda x:type(x) is int))
        self.apiEnumsToApiTypes = dict( (self.apiTypesToApiEnums[k], k) for k in self.apiTypesToApiEnums.keys())


    def _buildMayaReservedTypes(self, force=False):
        """
        Build a list of Maya reserved types.

        These cannot be created directly from the API, thus the dgMod trick to
        find the corresponding Maya type won't work
        """
        reservedMayaTypes = {}

        # start with plugin types
        import pymel.api.plugins as plugins
        for mpxName, mayaNode in plugins.mpxNamesToMayaNodes.iteritems():
            reservedMayaTypes[mayaNode] = plugins.mpxNamesToApiEnumNames[mpxName]

        for mayaType in self.abstractMayaTypes:
            if mayaType in reservedMayaTypes:
                continue
            apiGuess = self._guessApiTypeByName(mayaType)
            if apiGuess:
                reservedMayaTypes[mayaType] = apiGuess

        reservedMayaTypes.update(self.MAYA_TO_API_OVERRIDES)
        # filter to make sure all these types exist in current version (some are Maya2008 only)
        reservedMayaTypes = dict((item[0], item[1])
                                      for item in reservedMayaTypes.iteritems()
                                      if item[1] in self.apiTypesToApiEnums)

        return reservedMayaTypes

    # TODO: eventually, would like to move the node-heirarchy-building stuff
    # from cmdcache into here... we could then cache the node inheritance info,
    # instead of constantly re-querying it in various places...
    def _buildMayaNodeInfo(self):
        '''Stores tempory information about maya nodes + names
        '''
        if getattr(self, '_builtMayaNodeInfo', False):
            return

        if not self.apiTypesToApiEnums:
            self._buildApiTypesList()

        self.realMayaTypes, self.abstractMayaTypes = _getAllMayaTypes(returnRealAbstract=True)
        self.allMayaTypes = self.realMayaTypes | self.abstractMayaTypes

        self.uniqueLowerMaya, self.multiLowerMaya = getLowerCaseMapping(self.allMayaTypes)
        self.allLowerMaya = set(self.uniqueLowerMaya) | set(self.multiLowerMaya)
        self.uniqueLowerApi, self.multiLowerApi = getLowerCaseMapping(self.apiTypesToApiEnums)
        self._builtMayaNodeInfo = True
        return

    # _buildMayaNodeInfo must already have been called...
    def _guessApiTypeByName(self, nodeName):
        # first, try the easy case...
        apiName = nodeToApiName(nodeName)
        if apiName in self.apiTypesToApiEnums:
            return apiName

        lowerNode = nodeName.lower()
        if lowerNode not in self.uniqueLowerMaya:
            return None

        # now, try with various modifications...
        possibleApiNames = set()

        possibleModifications = [(find, replace)
                                 for find, replace in API_NAME_MODIFIERS
                                 if find.search(lowerNode)]

        # find all possible combinations of all possible modifications
        for modifyNum in xrange(len(possibleModifications) + 1):
            for modifyCombo in itertools.combinations(possibleModifications, modifyNum):
                baseName = lowerNode
                for find, replace in modifyCombo:
                    baseName = find.sub(replace, baseName)
                if not baseName:
                    # if we've eliminated the name with our changes - ie,
                    # 'shape' would go to '' - then skip
                    continue
                if baseName != lowerNode and baseName in self.allLowerMaya:
                    # if after modification, our new name is the name of another
                    # maya node, skip
                    continue
                apiLower = 'k' + baseName
                if apiLower in self.uniqueLowerApi:
                    possibleApiNames.add(self.uniqueLowerApi[apiLower])
                else:
                    for suffix in apiSuffixes:
                        apiWithSuffix = apiLower + suffix
                        if apiWithSuffix in self.uniqueLowerApi:
                            possibleApiNames.add(self.uniqueLowerApi[apiWithSuffix])

        if len(possibleApiNames) == 1:
            return list(possibleApiNames)[0]
        return None

    # Note - it's possible there are multiple substrings of the same length
    # that are all "tied" for longest - this method will only return the first
    # it finds
    @staticmethod
    def _longestCommonSubstring(str1, str2):
        if str1 == str2:
            return [str1]

        if len(str1) > len(str2):
            longer = str1
            shorter = str2
        else:
            longer = str2
            shorter = str1
        maxSize = len(shorter)
        for strSize in xrange(maxSize, 0, -1):
            for startPos in xrange(0, maxSize - strSize + 1):
                subStr = shorter[startPos:startPos + strSize]
                if subStr in longer:
                    return subStr
        return ''

    @staticmethod
    def _bestMatches(theStr, otherStrings, minLength=2, caseSensitive=False):
        if not caseSensitive:
            theStr = theStr.lower()
        byLength = {}
        for otherString in otherStrings:
            if caseSensitive:
                compOther = otherString
            else:
                compOther = otherString.lower()
            size = len(_longestCommonSubstring(theStr, compOther))
            byLength.setdefault(size, []).append(otherString)
        longest = max(byLength)
        if longest >= minLength:
            return byLength[longest]
        else:
            return []

    def _buildApiClassInfo(self):
        _logger.debug("Starting ApiCache._buildApiClassInfo...")
        from pymel.internal.parsers import ApiDocParser
        self.apiClassInfo = {}
        parser = ApiDocParser(api, enumClass=ApiEnum, docLocation=self.docLocation)

        for name, obj in inspect.getmembers( api, lambda x: type(x) == type and x.__name__.startswith('M') ):
            if not name.startswith( 'MPx' ):
                try:
                    info = parser.parse(name)
                    self.apiClassInfo[ name ] = info
                except (IOError, OSError, ValueError,IndexError), e:
                    import errno
                    baseMsg = "failed to parse docs for %r:" % name
                    if isinstance(e, (IOError, OSError)) and e.errno == errno.ENOENT:
                        # If we couldn't parse because we couldn't find the
                        # file, only raise a warning... there are many classes
                        # (ie, MClothTriangle) that don't have a doc page...
                        _logger.warning(baseMsg)
                        _logger.warning("%s: %s" % (name, e))
                    else:
                        import traceback
                        _logger.error(baseMsg)
                        _logger.error(traceback.format_exc())

        _logger.debug("...finished ApiCache._buildApiClassInfo")

    def _buildApiTypeToApiClasses(self):
        self.apiTypesToApiClasses = {}
        def _MFnType(x) :
            if x == api.MFnBase :
                return self.apiEnumsToApiTypes[ 1 ]  # 'kBase'
            else :
                try :
                    return self.apiEnumsToApiTypes[ x().type() ]
                except :
                    return self.apiEnumsToApiTypes[ 0 ] # 'kInvalid'

        # all of maya OpenMaya api is now imported in module api's namespace
        mfnClasses = inspect.getmembers(api, lambda x: inspect.isclass(x) and issubclass(x, api.MFnBase))
        for name, mfnClass in mfnClasses:
            current = _MFnType(mfnClass)
            if not current:
                _logger.warning("MFnClass gave MFnType %s" % current)
            elif current == 'kInvalid':
                _logger.warning("MFnClass gave MFnType %s" % current)
            else:
                self.apiTypesToApiClasses[ current ] = mfnClass
        # we got our map by going from Mfn to enum; however, multiple enums can
        # map to the same MFn, so need to fill in the gaps of missing enums for
        # enums to MFn...

        # we do this by querying the maya hierarchy, and marching up it until
        # we find an entry that IS in apiTypesToApiClasses
        for mayaType, apiType in self.mayaTypesToApiTypes.iteritems():
            if apiType not in self.apiTypesToApiClasses:
                self._getOrSetApiClass(apiType, mayaType)

    def _getOrSetApiClass(self, apiType, mayaType):
        if apiType not in self.apiTypesToApiClasses:
            if apiType in self.API_TO_MFN_OVERRIDES:
                mfnClass = self.API_TO_MFN_OVERRIDES[apiType]
            else:
                mfnClass = self._getApiClassFromMayaInheritance(apiType, mayaType)
            self.apiTypesToApiClasses[apiType] = mfnClass
        return self.apiTypesToApiClasses[apiType]

    def _getApiClassFromMayaInheritance(self, apiType, mayaType):
        mfnClass = None
        try:
            inheritance = getInheritance(mayaType)
        except Exception:
            pass
        else:
            # inheritance always ends with that node type... so skip that...
            for mayaParentType in reversed(inheritance[:-1]):
                parentApiType = self.mayaTypesToApiTypes.get(mayaParentType)
                if parentApiType:
                    parentMfn = self.apiTypesToApiClasses.get(parentApiType)
                    if parentMfn:
                        mfnClass = parentMfn
                        break
        if not mfnClass:
            mfnClass = api.MFnDependencyNode
        return mfnClass

    def _buildApiRelationships(self) :
        """
        Used to rebuild api info from scratch.

        WARNING: will load all maya-installed plugins, without making an
        attempt to return the loaded plugins to the state they were at before
        this command is run.  Also, the act of loading all the plugins may
        crash maya, especially if done from a non-GUI session
        """
        # Put in a debug, because this can be crashy
        _logger.debug("Starting ApiCache._buildApiTypeHierarchy...")


        if not startup.mayaStartupHasRun():
            startup.mayaInit()
        import maya.cmds

        import pymel.api.plugins as plugins
        # load all maya plugins

        # There's some weirdness with plugin loading on windows XP x64... if
        # you have a fresh user profile, and do:

        # import maya.standalone
        # maya.standalone.initialize()
        # import maya.mel as mel
        # mel.eval('''source "initialPlugins.mel"''')

        # ..then things work.  But if you import maya.OpenMaya:

        # import maya.standalone
        # maya.standalone.initialize()
        # import maya.OpenMaya
        # import maya.mel as mel
        # mel.eval('''source "initialPlugins.mel"''')

        # ...it crashes when loading Mayatomr.  Also, oddly, if you load
        # Mayatomr directly, instead of using initialPlugins.mel, it also
        # crashes:

        # import maya.standalone
        # maya.standalone.initialize()
        # import maya.cmds
        # maya.cmds.loadPlugin('C:\\3D\\Autodesk\\Maya2012\\bin\\plug-ins\\Mayatomr.mll')

        # Anyway, for now, adding in the line to do sourcing of initialPlugins.mel
        # until I can figure out if it's possible to avoid this crash...
        import maya.mel
        maya.mel.eval('source "initialPlugins.mel"')
        plugins.loadAllMayaPlugins()

        self._buildApiClassInfo()

        self._buildMayaToApiInfo()
        self._buildApiTypeToApiClasses()

        _logger.debug("...finished ApiCache._buildApiTypeHierarchy")

    def addMayaType(self, mayaType, apiType=None, updateObj=None):
        """ Add a type to the MayaTypes lists. Fill as many dictionary caches as we have info for.

            - mayaTypesToApiTypes
            - mayaTypesToApiEnums

        if updateObj is given, this instance will first be updated from it,
        before the mayaType is added.
        """

        if apiType is not 'kInvalid' :
            apiEnum = getattr( api.MFn, apiType )
            self.mayaTypesToApiTypes[mayaType] = apiType
            self.mayaTypesToApiEnums[mayaType] = apiEnum

    def removeMayaType(self, mayaType, updateObj=None):
        """ Remove a type from the MayaTypes lists.

            - mayaTypesToApiTypes
            - mayaTypesToApiEnums

        if updateObj is given, this instance will first be updated from it,
        before the mayaType is added.
        """
        self.mayaTypesToApiEnums.pop( mayaType, None )
        self.mayaTypesToApiTypes.pop( mayaType, None )

    def read(self, raw=False):
        data = super(ApiCache, self).read()
        if not raw:
            # Before 2012, we cached reservedMayaTypes and reservedApiTypes,
            # even though they weren't used...
            if data is not None and len(data) != len(self._CACHE_NAMES):
                if len(data) == 8 and versions.current() < versions.v2012:
                    data = data[2:6] + data[7:]
                else:
                    # we need to rebuild, return None
                    data = None
        return data

    def rebuild(self):
        """Rebuild the api cache from scratch

        Unlike 'build', this does not attempt to load a cache file, but always
        rebuilds it by parsing the docs, etc.
        """
        _logger.info( "Rebuilding the API Caches..." )

        # fill out the data structures
        self._buildApiTypesList()
        #_buildMayaTypesList()

        self._buildApiRelationships()

        # merge in the manual overrides: we only do this when we're rebuilding or in the pymelControlPanel
        _logger.info( 'merging in dictionary of manual api overrides')
        self._mergeClassOverrides()

    def _mergeClassOverrides(self, bridgeCache=None):
        if bridgeCache is None:
            bridgeCache = ApiMelBridgeCache()
            bridgeCache.build()
        _util.mergeCascadingDicts( bridgeCache.apiClassOverrides, self.apiClassInfo, allowDictToListMerging=True )

    def melBridgeContents(self):
        return self._mayaApiMelBridge.contents()

    def extraDicts(self):
        return tuple( getattr(self, x) for x in self.EXTRA_GLOBAL_NAMES )

########NEW FILE########
__FILENAME__ = cmdcache
# Built-in imports
import os, re, inspect, keyword

# Maya imports
import maya.cmds as cmds
import maya.mel as mm

# PyMEL imports
import pymel.util as util
import pymel.versions as versions

# Module imports
from . import plogging
from . import startup

_logger = plogging.getLogger(__name__)

moduleNameShortToLong = {
    'modeling'   : 'Modeling',
    'rendering'  : 'Rendering',
    'effects'    : 'Effects',
    'animation'  : 'Animation',
    'windows'    : 'Windows',
    'system'     : 'System',
    'general'    : 'General',
    'language'   : 'Language'
}

#: these are commands which need to be manually added to the list parsed from the docs
moduleCommandAdditions = {
    'windows' : ['connectControl', 'deleteUI','uiTemplate','setUITemplate','renameUI','setParent','objectTypeUI','lsUI', 'disable', 'dimWhen'],
    'general' : ['encodeString', 'format', 'assignCommand', 'commandEcho', 'condition', 'evalDeferred', 'isTrue', 'itemFilter', 'itemFilterAttr',
                 'itemFilterRender', 'itemFilterType', 'pause', 'refresh', 'stringArrayIntersector', 'selectionConnection']
}

#: secondary flags can only be used in conjunction with other flags so we must exclude them when creating classes from commands.
#: because the maya docs do not specify in any parsable way which flags are secondary modifiers, we must maintain this dictionary.
#: once this list is reliable enough and includes default values, we can use them as keyword arguments in the class methods that they modify.
secondaryFlags = {
    'xform' : ( ( 'absolute',         None,[] ),
                ( 'relative',         None,[] ),
                ( 'euler',            None,['relative'] ),
                ( 'objectSpace',      True, ['scalePivot', 'rotatePivot', 'rotateAxis', 'rotation', 'rotateTranslation', 'translation', 'matrix', 'boundingBox', 'boundingBoxInvisible', 'pivots'] ),
                ( 'worldSpace',       False, ['scalePivot', 'rotatePivot', 'rotateAxis', 'rotation', 'rotateTranslation', 'translation', 'matrix', 'boundingBox', 'boundingBoxInvisible', 'pivots'] ),
                ( 'preserve',         None,['scalePivot', 'rotatePivot', 'rotateOrder', 'rotateAxis', 'centerPivots'] ),
                ( 'worldSpaceDistance', None,['scalePivot', 'rotatePivot', 'scaleTranslation', 'rotateTranslation', 'translation', 'pivots'] )
            ),
    'file' : ( ( 'loadAllDeferred', False, ['open'] ),
               ( 'loadNoReferences', False, ['open', 'i', 'reference', 'loadReference'] ),
               ( 'loadReferenceDepth', None, ['open', 'i', 'reference', 'loadReference'] ),
               ( 'force',           False, ['open', 'newFile', 'save', 'exportAll', 'exportSelected', 'exportAnim',
                                      'exportSelectedAnim', 'exportAnimFromReference', 'exportSelectedAnimFromReference' ] ),
               ( 'constructionHistory', True, ['exportSelected'] ),
               ( 'channels',         True, ['exportSelected'] ),
               ( 'constraints',      True, ['exportSelected'] ),
               ( 'expressions',      True, ['exportSelected'] ),
               ( 'shader',           True, ['exportSelected'] ),
               ( 'defaultNamespace', False, ['reference', 'i'] ),
               ( 'deferReference',   False, ['reference', 'i'] ),
               ( 'editCommand',      None, ['cleanReference'] ),
               ( 'groupReference',   False, ['reference', 'i'] ),
               ( 'groupLocator',  None,['reference'] ),
               ( 'groupName',  None,['reference', 'i'] ),
               ( 'namespace',  None,['reference', 'exportAsReference', 'namespace'] ),
               ( 'referenceNode',  None,['reference', 'exportAnimFromReference', 'exportSelectedAnimFromReference'] ),
               ( 'renameAll', None,['i'] ),
               ( 'renamingPrefix',  None,['reference', 'i','exportAsReference'] ),
               #( 'saveTextures', "unlessRef", ['saveAs']),
               ( 'swapNamespace',  None, ['reference', 'i'] ),
               ( 'sharedReferenceFile',  None, ['reference'] ),
               ( 'sharedNodes',  None, ['reference'] ),
               ( 'returnNewNodes',  False, ['open', 'reference', 'i', 'loadReference' ] ),
               #( 'loadSettings', ),
               ( 'preserveReferences',  False, ['i', 'exportAll', 'exportSelected'] ),
               ( 'preSaveScript', None, ['save'] ),
               ( 'postSaveScript', None, ['save'] ),
               ( 'type', None, ['open', 'newFile', 'save', 'exportAll', 'exportSelected', 'exportAnim',
                                      'exportSelectedAnim', 'exportAnimFromReference', 'exportSelectedAnimFromReference' ] ),
             ),
    'joint' : ( ( 'absolute',     True, ['position'] ),
                ( 'relative',     True, ['position'] ) )
}



UI_COMMANDS ="""attrColorSliderGrp        attrControlGrp
                attrEnumOptionMenu        attrEnumOptionMenuGrp
                attrFieldGrp              attrFieldSliderGrp
                attrNavigationControlGrp  attributeMenu
                colorIndexSliderGrp       colorSliderButtonGrp
                colorSliderGrp            columnLayout
                colorEditor               floatField
                floatFieldGrp             floatScrollBar
                floatSlider               floatSlider2
                floatSliderButtonGrp      floatSliderGrp
                frameLayout               iconTextButton
                iconTextCheckBox          iconTextRadioButton
                iconTextRadioCollection   iconTextScrollList
                iconTextStaticLabel       intField
                intFieldGrp               intScrollBar
                intSlider                 intSliderGrp
                paneLayout                panel
                radioButton               radioButtonGrp
                radioCollection           radioMenuItemCollection
                symbolButton              symbolCheckBox
                textCurves                textField
                textFieldButtonGrp        textFieldGrp
                text                      textScrollList
                toolButton                toolCollection
                window                    blendShapeEditor
                blendShapePanel           button
                checkBox                  checkBoxGrp
                confirmDialog             fontDialog
                formLayout                menu
                menuBarLayout             menuEditor
                menuItem                  menuSet
                promptDialog              scrollField
                scrollLayout              scriptedPanel
                scriptedPanelType         shelfButton
                shelfLayout               shelfTabLayout
                tabLayout                 outlinerEditor
                optionMenu                outlinerPanel
                optionMenuGrp             animCurveEditor
                animDisplay               separator
                visor                     layout
                layoutDialog              layerButton
                hyperGraph                hyperPanel
                hyperShade                rowColumnLayout
                rowLayout                 renderLayerButton
                renderWindowEditor        glRenderEditor
                scriptTable               keyframeStats
                keyframeOutliner          canvas
                channelBox                gradientControl
                gradientControlNoAttr     gridLayout
                messageLine               popupMenu
                modelEditor               modelPanel
                helpLine                  hardwareRenderPanel
                image                     nodeIconButton
                commandLine               progressBar
                defaultLightListCheckBox  exclusiveLightCheckBox
                shellField                clipSchedulerOutliner
                clipEditor                deviceEditor
                devicePanel               dynRelEdPanel
                dynRelEditor              dynPaintEditor
                nameField                 cmdScrollFieldExecuter
                cmdScrollFieldReporter    cmdShell
                nameField                 palettePort """.split()

#: creation commands whose names do not match the type of node they return require this dict
#: to resolve which command the class should wrap
nodeTypeToNodeCommand = {
    #'failed'            : 'clip',
    #'failed'            : 'clipSchedule',
    'airField'          : 'air',
    'dragField'         : 'drag',
    'emitter'           : 'emitter',
    'turbulenceField'   : 'turbulence',
    #'failed' : 'effector',
    'volumeAxisField'   : 'volumeAxis',
    'uniformField'      : 'uniform',
    'gravityField'      : 'gravity',
    #'failed'            : 'event',
    #'failed'            : 'pointCurveConstraint',
    #'failed'            : 'deformer',
    #'failed'            : 'constrain',
    'locator'           : 'spaceLocator',
    'vortexField'       : 'vortex',
    'makeNurbTorus'     : 'torus',
    'makeNurbCone'      : 'cone',
    'makeNurbCylinder'  : 'cylinder',
    'nurbsCurve'        : 'curve', # returns a single transform, but creates a nurbsCurve
    'makeNurbSphere'    : 'sphere',
    'makeNurbCircle'    : 'circle',
    'makeNurbPlane'     : 'nurbsPlane',
    'makeNurbsSquare'   : 'nurbsSquare',
    'makeNurbCube'      : 'nurbsCube',
    'skinPercent'       : 'skinCluster',
    'file'              : None, # prevent File node from using cmds.file
    'nurbsSurface'      : 'surface',
    'annotationShape'   : 'annotate',
    'condition'         : None, # prevent Condition node from using cmds.condition (which is for script conditions)
}


cmdlistOverrides = {}
#util.setCascadingDictItem( cmdlistOverrides, ( 'optionMenu', 'shortFlags', 'sl', 'modes' ), ['create', 'query', 'edit'] )
util.setCascadingDictItem( cmdlistOverrides, ( 'optionMenu', 'flags', 'select', 'modes' ),  ['create', 'query', 'edit'] )
util.setCascadingDictItem( cmdlistOverrides, ( 'ikHandle', 'flags', 'jointList', 'modes' ), ['query'] )
#util.setCascadingDictItem( cmdlistOverrides, ( 'ikHandle', 'shortFlags', 'jl', 'modes' ),   ['query'] )
util.setCascadingDictItem( cmdlistOverrides, ( 'keyframe', 'flags', 'index', 'args' ), 'timeRange' ) # make sure this is a time range so it gets proper slice syntax

# Need to override this, rather than having it deteced from testNodeCmd, because
# it crashes testNodeCmd
util.setCascadingDictItem( cmdlistOverrides, ( 'pointOnPolyConstraint', 'resultNeedsUnpacking', ), True )

def getCmdInfoBasic( command ):
    typemap = {
             'string'  : unicode,
             'length'  : float,
             'float'   : float,
             'angle'   : float,
             'int'     : int,
             'unsignedint' : int,
             'on|off'  : bool,
             'script'  : callable,
             'name'    : 'PyNode'
    }
    flags = {}
    shortFlags = {}
    removedFlags = {}
    try:
        lines = cmds.help( command ).split('\n')
    except RuntimeError:
        pass
    else:
        synopsis = lines.pop(0)
        # certain commands on certain platforms have an empty first line
        if not synopsis:
            synopsis = lines.pop(0)
        #_logger.debug(synopsis)
        if lines:
            lines.pop(0) # 'Flags'
            #_logger.debug(lines)

            for line in lines:
                line = line.replace( '(Query Arg Mandatory)', '' )
                line = line.replace( '(Query Arg Optional)', '' )
                tokens = line.split()

                try:
                    tokens.remove('(multi-use)')
                    multiuse = True
                except ValueError:
                    multiuse = False
                #_logger.debug(tokens)
                if len(tokens) > 1 and tokens[0].startswith('-'):


                    args = [ typemap.get(x.lower(), util.uncapitalize(x) ) for x in tokens[2:] ]
                    numArgs = len(args)

                    # lags with no args in mel require a boolean val in python
                    if numArgs == 0:
                        args = bool
                        # numArgs will stay at 0, which is the number of mel arguments.
                        # this flag should be renamed to numMelArgs
                        #numArgs = 1
                    elif numArgs == 1:
                        args = args[0]

                    longname = str(tokens[1][1:])
                    shortname = str(tokens[0][1:])


                    if longname in keyword.kwlist:
                        removedFlags[ longname ] = shortname
                        longname = shortname
                    elif shortname in keyword.kwlist:
                        removedFlags[ shortname ] = longname
                        shortname = longname
                    #sometimes the longname is empty, so we'll use the shortname for both
                    elif longname == '':
                        longname = shortname

                    flags[longname] = { 'longname' : longname, 'shortname' : shortname, 'args' : args, 'numArgs' : numArgs, 'docstring' : '' }
                    if multiuse:
                        flags[longname].setdefault('modes', []).append('multiuse')
                    shortFlags[shortname] = longname

    #except:
    #    pass
        #_logger.debug("could not retrieve command info for", command)
    res = { 'flags': flags, 'shortFlags': shortFlags, 'description' : '', 'example': '', 'type' : 'other' }
    if removedFlags:
        res['removedFlags'] = removedFlags
    return res

def getCmdInfo( command, version, python=True ):
    """Since many maya Python commands are builtins we can't get use getargspec on them.
    besides most use keyword args that we need the precise meaning of ( if they can be be used with
    edit or query flags, the shortnames of flags, etc) so we have to parse the maya docs"""
    from parsers import CommandDocParser, mayaDocsLocation

    basicInfo = getCmdInfoBasic(command)

    try:
        docloc = mayaDocsLocation(version)
        if python:
            docloc = os.path.join( docloc , 'CommandsPython/%s.html' % (command) )
        else:
            docloc = os.path.join( docloc , 'Commands/%s.html' % (command) )

        f = open( docloc )
        parser = CommandDocParser(command)
        parser.feed( f.read() )
        f.close()

        example = parser.example
        example = example.rstrip()
        if python:
            pass

        # start with basic info, gathered using mel help command, then update with info parsed from docs
        # we copy because we need access to the original basic info below
        basicFlags = basicInfo.get('flags', {})
        flags = basicInfo['flags'].copy()
        flags.update( parser.flags )

        # if we have a "true" mel boolean flag, then getCmdInfoBasic will return
        # numArgs == 0, but parsing the PYTHON docs will return a numArgs of 1;
        # keep the numArgs of 0
        for flag, flagInfo in parser.flags.iteritems():
            if flagInfo.get('args') == bool and flagInfo.get('numArgs') == 1:
                basicFlagInfo = basicFlags.get(flag, {})
                if (basicFlagInfo.get('args') == bool
                        and basicFlagInfo.get('numArgs') == 0):
                    flagInfo['numArgs'] = 0

        if command in secondaryFlags:
            for secondaryFlag, defaultValue, modifiedList in secondaryFlags[command]:
                #_logger.debug(command, "2nd", secondaryFlag)
                flags[secondaryFlag]['modified'] = modifiedList
                #_logger.debug(sorted(modifiedList))
                #_logger.debug(sorted(parser.flags.keys()))
                for primaryFlag in modifiedList:
                    #_logger.debug(command, "1st", primaryFlag)
                    if 'secondaryFlags' in parser.flags[primaryFlag]:
                        flags[primaryFlag]['secondaryFlags'].append(secondaryFlag)
                    else:
                        flags[primaryFlag]['secondaryFlags'] = [secondaryFlag]


        # add shortname lookup
        #_logger.debug((command, sorted( basicInfo['flags'].keys() )))
        #_logger.debug((command, sorted( flags.keys() )))

        # args and numArgs is more reliable from mel help command than from parsed docs,
        # so, here we put that back in place and create shortflags.

        # also use original 'multiuse' info...

        for flag, flagData in flags.items():
            basicFlagData = basicFlags.get(flag)
            if basicFlagData:
                if 'args' in basicFlagData and 'numargs' in basicFlagData:
                    flagData['args'] = basicFlagData['args']
                    flagData['numArgs'] = basicFlagData['numArgs']
                    if (        'multiuse' in basicFlagData.get('modes', [])
                            and 'multiuse' not in  flagData.get('modes', [])):
                        flagData.setdefault('modes', []).append('multiuse')

        shortFlags = basicInfo['shortFlags']
        res = { 'flags': flags,
                'shortFlags': shortFlags,
                'description' : parser.description,
                'example': example }
        try:
            res['removedFlags'] = basicInfo['removedFlags']
        except KeyError: pass
        return res


    except IOError:
        _logger.debug("could not find docs for %s" % command)
        return basicInfo

        #raise IOError, "cannot find maya documentation directory"

def fixCodeExamples(style='maya', force=False):
    """cycle through all examples from the maya docs, replacing maya.cmds with pymel and inserting pymel output.

    NOTE: this can only be run from gui mode
    WARNING: back up your preferences before running

    TODO: auto backup and restore of maya prefs
    """

    manipSize = cmds.manipOptions( q=1, handleSize=1 )[0]
    manipScale = cmds.manipOptions( q=1, scale=1 )[0]
    animOptions = []
    animOptions.append( cmds.animDisplay( q=1, timeCode=True ) )
    animOptions.append( cmds.animDisplay( q=1, timeCodeOffset=True )  )
    animOptions.append( cmds.animDisplay( q=1, modelUpdate=True ) )

    openWindows = cmds.lsUI(windows=True)
    examples = CmdExamplesCache().read()
    processedExamples = CmdProcessedExamplesCache().read()
    processedExamples = {} if processedExamples is None else processedExamples
    allCmds = set(examples.keys())
    # put commands that require manual interaction first
    manualCmds = ['fileBrowserDialog', 'fileDialog', 'fileDialog2', 'fontDialog']
    skipCmds = ['colorEditor', 'emit', 'finder', 'doBlur', 'messageLine', 'renderWindowEditor',
                'ogsRender', 'webBrowser', 'deleteAttrPattern', 'grabColor']
    allCmds.difference_update(manualCmds)
    sortedCmds = manualCmds + sorted(allCmds)
    for command in sortedCmds:
        example = examples[command]

        if not force and command in processedExamples:
            _logger.info("%s: already completed. skipping." % command)
            continue

        _logger.info("Starting command %s", command)

        if style == 'doctest' :
            DOC_TEST_SKIP = ' #doctest: +SKIP'
        else:
            DOC_TEST_SKIP = ''

        # change from cmds to pymel
        reg = re.compile(r'\bcmds\.')
        example = example.replace('import maya.cmds as cmds', 'import pymel.core as pm' + DOC_TEST_SKIP, 1)
        example = reg.sub( 'pm.', example )

        #example = example.replace( 'import maya.cmds as cmds', 'import pymel as pm\npm.newFile(f=1) #fresh scene' )

        lines = example.split('\n')
        if len(lines)==1:
            _logger.info("removing empty example for command %s", command)
            examples.pop(command)
            processedExamples[command] = ''
            # write out after each success so that if we crash we don't have to start from scratch
            CmdProcessedExamplesCache().write(processedExamples)
            continue

        if command in skipCmds:
            example = '\n'.join( lines )
            processedExamples[command] = example
            # write out after each success so that if we crash we don't have to start from scratch
            CmdProcessedExamplesCache().write(processedExamples)

        #lines.insert(1, 'pm.newFile(f=1) #fresh scene')
        # create a fresh scene. this does not need to be in the docstring unless we plan on using it in doctests, which is probably unrealistic
        cmds.file(new=1,f=1)

        newlines = []
        statement = []

        # narrowed down the commands that cause maya to crash to these prefixes
        if re.match( '(dis)|(dyn)|(poly)', command) :
            evaluate = False
        elif command in skipCmds:
            evaluate = False
        else:
            evaluate = True

        # gives a little leniency for where spaces are placed in the result line
        resultReg = re.compile('# Result:\s*(.*) #$')
        try: # funky things can happen when executing maya code: some exceptions somehow occur outside the eval/exec
            for i, line in enumerate(lines):
                res = None
                # replace with pymel results  '# Result: 1 #'
                m = resultReg.match(line)
                if m:
                    if evaluate is False:
                        line = m.group(1)
                        newlines.append('    ' + line)
                else:
                    if evaluate:
                        if line.strip().endswith(':') or line.startswith(' ') or line.startswith('\t'):
                            statement.append(line)
                        else:
                            # evaluate the compiled statement using exec, which can do multi-line if statements and so on
                            if statement:
                                try:
                                    #_logger.debug("executing %s", statement)
                                    exec( '\n'.join(statement) )
                                    # reset statement
                                    statement = []
                                except Exception, e:
                                    _logger.info("stopping evaluation %s", str(e))# of %s on line %r" % (command, line)
                                    evaluate = False
                            try:
                                _logger.debug("evaluating: %r" % line)
                                res = eval( line )
                                #if res is not None: _logger.info("result", repr(repr(res)))
                                #else: _logger.info("no result")
                            except:
                                #_logger.debug("failed evaluating:", str(e))
                                try:
                                    exec( line )
                                except (Exception, TypeError), e:
                                    _logger.info("stopping evaluation %s", str(e))# of %s on line %r" % (command, line)
                                    evaluate = False
                    if style == 'doctest':
                        if line.startswith(' ') or line.startswith('\t'):
                            newlines.append('    ... ' + line  )
                        else:
                            newlines.append('    >>> ' + line + DOC_TEST_SKIP )

                        if res is not None:
                            newlines.append( '    ' + repr(res) )
                    else:
                        newlines.append('    ' + line )
                        if res is not None:
                            newlines.append( '    # Result: %r #' % (res,) )

            if evaluate:
                _logger.info("successful evaluation! %s", command)

            example = '\n'.join( newlines )
            processedExamples[command] = example
        except Exception, e:
            raise
            #_logger.info("FAILED: %s: %s" % (command, e) )
        else:
            # write out after each success so that if we crash we don't have to start from scratch
            CmdProcessedExamplesCache().write(processedExamples)

        # cleanup opened windows
        for ui in set(cmds.lsUI(windows=True)).difference(openWindows):
            try: cmds.deleteUI(ui, window=True)
            except:pass

    _logger.info("Done Fixing Examples")

    # restore manipulators and anim options
    print [manipSize, manipScale]
    cmds.manipOptions( handleSize=manipSize, scale=manipScale )
    print animOptions
    cmds.animDisplay( e=1, timeCode=animOptions[0], timeCodeOffset=animOptions[1], modelUpdate=animOptions[2])

    #CmdExamplesCache(examples)


def getModuleCommandList( category, version=None ):
    from parsers import CommandModuleDocParser
    parser = CommandModuleDocParser(category, version)
    return parser.parse()

def getCallbackFlags(cmdInfo):
    """used parsed data and naming convention to determine which flags are callbacks"""
    commandFlags = []
    try:
        flagDocs = cmdInfo['flags']
    except KeyError:
        pass
    else:
        for flag, data in flagDocs.items():
            if data['args'] in ['script', callable] or 'command' in flag.lower():
                commandFlags += [flag, data['shortname']]
    return commandFlags

def getModule(funcName, knownModuleCmds):
    # determine to which module this function belongs
    module = None
    if funcName in ['eval', 'file', 'filter', 'help', 'quit']:
        module = None
    elif funcName.startswith('ctx') or funcName.endswith('Ctx') or funcName.endswith('Context'):
        module = 'context'
    #elif funcName in self.uiClassList:
    #    module = 'uiClass'
    #elif funcName in nodeHierarchyTree or funcName in nodeTypeToNodeCommand.values():
    #    module = 'node'
    else:
        for moduleName, commands in knownModuleCmds.iteritems():
            if funcName in commands:
                module = moduleName
                break
        if module is None:
            if mm.eval('whatIs "%s"' % funcName ) == 'Run Time Command':
                module = 'runtime'
            else:
                module = 'other'
    return module

#-----------------------------------------------
#  Command Help Documentation
#-----------------------------------------------
_cmdArgMakers = {}
def cmdArgMakers(force=False):
    global _cmdArgMakers

    if _cmdArgMakers and not force:
        return _cmdArgMakers

    def makeCircle():
        return cmds.circle()[0]
    def makeEp():
        return makeCircle() + '.ep[1]'
    def makeSphere():
        return cmds.polySphere()[0]
    def makeCube():
        return cmds.polyCube()[0]
    def makeIk():
        j1 = cmds.joint()
        j2 = cmds.joint()
        return cmds.ikHandle(j1, j2, solver='ikRPsolver')[0]
    def makeJoint():
        return cmds.joint()
    def makeSkin():
        j1 = cmds.joint()
        j2 = cmds.joint()
        sphere = makeSphere()
        return cmds.skinCluster(j1, j2, sphere)[0]

    _cmdArgMakers = \
        { 'tangentConstraint'   : ( makeCircle, makeCube ),
          'poleVectorConstraint': ( makeSphere, makeIk ),
          'pointCurveConstraint': ( makeEp, ),
          'skinCluster'         : ( makeJoint, makeJoint, makeSphere ),
        }

    constraintCmds = [x for x in dir(cmds)
                      if x.endswith('onstraint')
                         and not cmds.runTimeCommand(x, q=1, exists=1)
                         and x != 'polySelectConstraint']

    for constrCmd in constraintCmds:
        if constrCmd not in _cmdArgMakers:
            _cmdArgMakers[constrCmd] = ( makeSphere, makeCube )

    return _cmdArgMakers

def nodeCreationCmd(func, nodeType):
    argMakers = cmdArgMakers()

    # compile the args list for node creation
    createArgs = argMakers.get(nodeType, [])
    if createArgs:
        createArgs = [argMaker() for argMaker in createArgs]

    # run the function
    return func(*createArgs)

def testNodeCmd( funcName, cmdInfo, nodeCmd=False, verbose=False ):

    _logger.info(funcName.center( 50, '='))

    if funcName in [ 'character', 'lattice', 'boneLattice', 'sculpt', 'wire' ]:
        _logger.debug("skipping")
        return cmdInfo

    # These cause crashes... confirmed that pointOnPolyConstraint still
    # crashes in 2012
    dangerousCmds = ['doBlur', 'pointOnPolyConstraint']
    if funcName in dangerousCmds:
        _logger.debug("skipping 'dangerous command'")
        return cmdInfo

    def _formatCmd( cmd, args, kwargs ):
        args = [ x.__repr__() for x in args ]
        kwargs = [ '%s=%s' % (key, val.__repr__()) for key, val in kwargs.items() ]
        return '%s( %s )' % ( cmd, ', '.join( args+kwargs ) )

    def _objectToType( result ):
        "convert a an instance or list of instances to a python type or list of types"
        if isinstance(result, list):
            return [ type(x) for x in result ]
        else:
            return type(result)

    _castList = [float, int, bool]

#    def _listIsCastable(resultType):
#        "ensure that all elements are the same type and that the types are castable"
#        try:
#            typ = resultType[0]
#            return typ in _castList and all([ x == typ for x in resultType ])
#        except IndexError:
#            return False

    module = cmds

    try:
        func = getattr(module, funcName)
    except AttributeError:
        _logger.warning("could not find function %s in modules %s" % (funcName, module.__name__))
        return cmdInfo

    # get the current list of objects in the scene so we can cleanup later, after we make nodes
    allObjsBegin = set( cmds.ls(l=1) )
    try:

        # Attempt to create the node
        cmds.select(cl=1)

        # the arglist passed from creation to general testing
        args = []
        constrObj = None
        if nodeCmd:

            #------------------
            # CREATION
            #------------------
            obj = nodeCreationCmd(func, funcName)

            if isinstance(obj, list):
                _logger.debug("Return %s", obj)
                if len(obj) == 1:
                    _logger.info("%s: creation return values need unpacking" % funcName)
                    cmdInfo['resultNeedsUnpacking'] = True
                elif not obj:
                    raise ValueError, "returned object is an empty list"
                objTransform = obj[0]
                obj = obj[-1]

            if obj is None:
                #emptyFunctions.append( funcName )
                raise ValueError, "Returned object is None"

            elif not cmds.objExists( obj ):
                raise ValueError, "Returned object %s is Invalid" % obj

            args = [obj]

    except (TypeError,RuntimeError, ValueError), msg:
        _logger.debug("failed creation: %s", msg)

    else:
        objType = cmds.objectType(obj)
        #------------------
        # TESTING
        #------------------

        #(func, args, data) = cmdList[funcName]
        #(usePyNode, baseClsName, nodeName)
        flags = cmdInfo['flags']

        hasQueryFlag = flags.has_key( 'query' )
        hasEditFlag = flags.has_key( 'edit' )

        anyNumRe = re.compile('\d+')

        for flag in sorted(flags.keys()):
            flagInfo = flags[flag]
            if flag in ['query', 'edit']:
                continue

            assert flag != 'ype', "%s has bad flag" % funcName

            # special case for constraints
            if constrObj and flag in ['weight']:
                flagargs = [constrObj] + args
            else:
                flagargs = args

            try:
                modes = flagInfo['modes']
                testModes = False
            except KeyError, msg:
                #raise KeyError, '%s: %s' % (flag, msg)
                #_logger.debug(flag, "Testing modes")
                flagInfo['modes'] = []
                modes = []
                testModes = True

            # QUERY
            val = None
            argtype = flagInfo['args']

            if 'query' in modes or testModes == True:
                if hasQueryFlag:
                    kwargs = {'query':True, flag:True}
                else:
                    kwargs = { flag:True }

                cmd = _formatCmd(funcName, flagargs, kwargs)
                try:
                    _logger.debug(cmd)
                    val = func( *flagargs, **kwargs )
                    #_logger.debug('val: %r' % (val,))
                    resultType = _objectToType(val)

                    # ensure symmetry between edit and query commands:
                    # if this flag is queryable and editable, then its queried value should be symmetric to its edit arguments
                    if 'edit' in modes and argtype != resultType:
                        # there are certain patterns of asymmetry which we can safely correct:
                        singleItemList = (isinstance( resultType, list)
                                          and len(resultType) ==1
                                          and 'multiuse' not in flagInfo.get('modes', []))

                        # [bool] --> bool
                        if singleItemList and resultType[0] == argtype:
                            _logger.info("%s, %s: query flag return values need unpacking" % (funcName, flag))
                            flagInfo['resultNeedsUnpacking'] = True
                            val = val[0]

                        # [int] --> bool
                        elif singleItemList and argtype in _castList and resultType[0] in _castList:
                            _logger.info("%s, %s: query flag return values need unpacking and casting" % (funcName, flag))
                            flagInfo['resultNeedsUnpacking'] = True
                            flagInfo['resultNeedsCasting'] = True
                            val = argtype(val[0])

                        # int --> bool
                        elif argtype in _castList and resultType in _castList:
                            _logger.info("%s, %s: query flag return values need casting" % (funcName, flag))
                            flagInfo['resultNeedsCasting'] = True
                            val = argtype(val)
                        else:
                            # no valid corrctions found
                            _logger.info(cmd)
                            _logger.info("\treturn mismatch")
                            _logger.info('\tresult: %s', val.__repr__())
                            _logger.info('\tpredicted type: %s', argtype)
                            _logger.info('\tactual type:    %s', resultType)
                            # value is no good. reset to None, so that a default will be generated for edit
                            val = None

                    else:
                        _logger.debug("\tsucceeded")
                        _logger.debug('\tresult: %s', val.__repr__())
                        _logger.debug('\tresult type:    %s', resultType)

                except TypeError, msg:
                    # flag is no longer supported
                    if str(msg).startswith( 'Invalid flag' ):
                        #if verbose:
                        _logger.info("removing flag %s %s %s", funcName, flag, msg)
                        shortname = flagInfo['shortname']
                        flagInfo.pop(flag,None)
                        flagInfo.pop(shortname,None)
                        modes = [] # stop edit from running
                    else:
                        _logger.info(cmd)
                        _logger.info("\t" + str(msg).rstrip('\n'))
                    val = None

                except RuntimeError, msg:
                    _logger.info(cmd)
                    _logger.info("\tRuntimeError: " + str(msg).rstrip('\n') )
                    val = None
                except ValueError, msg:
                    _logger.info(cmd)
                    _logger.info("\tValueError: " + str(msg).rstrip('\n') )
                    val = None
                else:
                    # some flags are only in mel help and not in maya docs, so we don't know their
                    # supported per-flag modes.  we fill that in here
                    if 'query' not in flagInfo['modes']:
                        flagInfo['modes'].append('query')
            # EDIT
            if 'edit' in modes or testModes == True:

                #_logger.debug("Args:", argtype)
                try:
                    # we use the value returned from query above as defaults for putting back in as edit args
                    # but if the return was empty we need to produce something to test on.
                    # NOTE: this is just a guess
                    if val is None:

                        if isinstance(argtype, list):
                            val = []
                            for typ in argtype:
                                if type == unicode or isinstance(type,basestring):
                                    val.append('persp')
                                else:
                                    if 'query' in modes:
                                        val.append( typ(0) )
                                    # edit only, ensure that bool args are True
                                    else:
                                        val.append( typ(1) )
                        else:
                            if argtype == unicode or isinstance(argtype,basestring):
                                val = 'persp'
                            elif 'query' in modes:
                                val = argtype(0)
                            else:
                                # edit only, ensure that bool args are True
                                val = argtype(1)

                    kwargs = {'edit':True, flag:val}
                    cmd = _formatCmd(funcName, args, kwargs)
                    _logger.debug(cmd)

                    # some commands will either delete or rename a node, ie:
                    #     spaceLocator(e=1, name=...)
                    #     container(e=1, removeContainer=True )
                    # ...which will then make subsequent cmds fail.
                    # To get around this, we need to undo the cmd.
                    try:
                        cmds.undoInfo(openChunk=True)
                        editResult = func( *args, **kwargs )
                    finally:
                        cmds.undoInfo(closeChunk=True)

                    if not cmds.objExists(obj):
                        # cmds.camera(e=1, name=...) does weird stuff - it
                        # actually renames the parent transform, even if you give
                        # the name of the shape... which means the shape
                        # then gets a second 'Shape1' tacked at the end...
                        # ...and in addition, undo is broken as well.
                        # So we need a special case for this, where we rename...
                        if objType == 'camera' and flag == 'name':
                            _logger.info('\t(Undoing camera rename)')
                            renamePattern = anyNumRe.sub('*', obj)
                            possibleRenames = cmds.ls(renamePattern, type=objType)
                            possibleRenames = [x for x in possibleRenames
                                               if x not in allObjsBegin]
                            # newName might not be the exact same as our original,
                            # but as long as it's the same maya type, and isn't
                            # one of the originals, it shouldn't matter...
                            newName = possibleRenames[-1]
                            cmds.rename(newName, obj)
                        else:
                            _logger.info('\t(Undoing cmd)')
                            cmds.undo()
                    _logger.debug("\tsucceeded")
                    #_logger.debug('\t%s', editResult.__repr__())
                    #_logger.debug('\t%s %s', argtype, type(editResult))
                    #_logger.debug("SKIPPING %s: need arg of type %s" % (flag, flagInfo['argtype']))
                except TypeError, msg:
                    if str(msg).startswith( 'Invalid flag' ):
                        #if verbose:
                        # flag is no longer supported
                        _logger.info("removing flag %s %s %s", funcName, flag, msg)
                        shortname = flagInfo['shortname']
                        flagInfo.pop(flag,None)
                        flagInfo.pop(shortname,None)
                    else:
                        _logger.info(funcName)
                        _logger.info("\t" + str(msg).rstrip('\n'))
                        _logger.info("\tpredicted arg: %s", argtype)
                        if not 'query' in modes:
                            _logger.info("\tedit only")
                except RuntimeError, msg:
                    _logger.info(cmd)
                    _logger.info("\t" + str(msg).rstrip('\n'))
                    _logger.info("\tpredicted arg: %s", argtype)
                    if not 'query' in modes:
                        _logger.info("\tedit only")
                except ValueError, msg:
                    _logger.info(cmd)
                    _logger.info("\tValueError: " + str(msg).rstrip('\n') )
                    val = None
                else:
                    if 'edit' not in flagInfo['modes']:
                        flagInfo['modes'].append('edit')

    # cleanup
    allObjsEnd = set( cmds.ls(l=1) )
    newObjs = list(allObjsEnd.difference(  allObjsBegin ) )
    if newObjs:
        cmds.delete( newObjs )
    return cmdInfo

def _getNodeHierarchy( version=None ):
    """
    get node hierarchy as a list of 3-value tuples:
        ( nodeType, parents, children )
    """
    import pymel.util.trees as trees
    import pymel.internal.apicache as apicache

    if versions.current() >= versions.v2012:
        # We now have nodeType(isTypeName)! yay!
        inheritances = {}
        for nodeType in apicache._getAllMayaTypes():
            try:
                inheritances[nodeType] = apicache.getInheritance(nodeType)
            except apicache.ManipNodeTypeError:
                continue
            except Exception:
                print "Error getting inheritance: %s" % nodeType
                raise

        parentTree = {}
        # Convert inheritance lists node=>parent dict
        for nodeType, inheritance in inheritances.iteritems():
            for i in xrange(len(inheritance)):
                child = inheritance[i]
                if i == 0:
                    if child == 'dependNode':
                        continue
                    else:
                        parent = 'dependNode'
                else:
                    parent = inheritance[i - 1]

                if child in parentTree:
                    assert parentTree[child] == parent, "conflicting parents: node type '%s' previously determined parent was '%s'. now '%s'" % (child, parentTree[child], parent)
                else:
                    parentTree[child] = parent
        nodeHierarchyTree = trees.treeFromDict(parentTree)
    else:
        from .parsers import NodeHierarchyDocParser
        parser = NodeHierarchyDocParser(version)
        nodeHierarchyTree = trees.IndexedTree(parser.parse())
    return [ (x.value, tuple(y.value for y in x.parents()), tuple(y.value for y in x.childs()) ) \
             for x in nodeHierarchyTree.preorder() ]


class CmdExamplesCache(startup.PymelCache):
    NAME = 'mayaCmdsExamples'
    DESC = 'the list of Maya command examples'
    USE_VERSION = True

class CmdProcessedExamplesCache(CmdExamplesCache):
    USE_VERSION = False

class CmdDocsCache(startup.PymelCache):
    NAME = 'mayaCmdsDocs'
    DESC = 'the Maya command documentation'

class CmdCache(startup.SubItemCache):
    NAME = 'mayaCmdsList'
    DESC = 'the list of Maya commands'
    _CACHE_NAMES = '''cmdlist nodeHierarchy uiClassList
                        nodeCommandList moduleCmds'''.split()
    CACHE_TYPES = {'nodeHierarchy':list,
                   'uiClassList':list,
                   'nodeCommandList':list,
                   }

    def rebuild(self) :
        """Build and save to disk the list of Maya Python commands and their arguments

        WARNING: will unload existing plugins, then (re)load all maya-installed
        plugins, without making an attempt to return the loaded plugins to the
        state they were at before this command is run.  Also, the act of
        loading all the plugins may crash maya, especially if done from a
        non-GUI session
        """
        # Put in a debug, because this can be crashy
        _logger.debug("Starting CmdCache.rebuild...")

        # With extension can't get docs on unix 64
        # path is
        # /usr/autodesk/maya2008-x64/docs/Maya2008/en_US/Nodes/index_hierarchy.html
        # and not
        # /usr/autodesk/maya2008-x64/docs/Maya2008-x64/en_US/Nodes/index_hierarchy.html

        long_version = versions.installName()

        from parsers import mayaDocsLocation
        cmddocs = os.path.join(mayaDocsLocation(long_version), 'CommandsPython')
        assert os.path.exists(cmddocs), "Command documentation does not exist: %s" % cmddocs

        _logger.info("Rebuilding the maya node hierarchy...")

        # Load all plugins to get the nodeHierarchy / nodeFunctions
        import pymel.api.plugins as plugins

        # We don't want to add in plugin nodes / commands - let that be done
        # by the plugin callbacks.  However, unloading mechanism is not 100%
        # ... sometimes functions get left in maya.cmds... and then trying
        # to use those left-behind functions can cause crashes (ie,
        # FBXExportQuaternion). So check which methods SHOULD be unloaded
        # first, so we know to skip those if we come across them even after
        # unloading the plugin
        pluginCommands = set()
        loadedPlugins = cmds.pluginInfo(q=True, listPlugins=True)
        if loadedPlugins:
            for plug in loadedPlugins:
                plugCmds = plugins.pluginCommands(plug)
                if plugCmds:
                    pluginCommands.update(plugCmds)

        plugins.unloadAllPlugins()

        self.nodeHierarchy = _getNodeHierarchy(long_version)
        nodeFunctions = [ x[0] for x in self.nodeHierarchy ]
        nodeFunctions += nodeTypeToNodeCommand.values()


        _logger.info("Rebuilding the list of Maya commands...")

        #nodeHierarchyTree = trees.IndexedTree(self.nodeHierarchy)
        self.uiClassList = UI_COMMANDS
        self.nodeCommandList = []
        tmpModuleCmds = {}
        for moduleName, longname in moduleNameShortToLong.items():
            tmpModuleCmds[moduleName] = getModuleCommandList( longname, long_version )

        tmpCmdlist = inspect.getmembers(cmds, callable)

        #self.moduleCmds = defaultdict(list)
        self.moduleCmds = dict( (k,[]) for k in moduleNameShortToLong.keys() )
        self.moduleCmds.update( {'other':[], 'runtime': [], 'context': [], 'uiClass': [] } )

        def addCommand(funcName):
            _logger.debug('adding command: %s' % funcName)
            module = getModule(funcName, tmpModuleCmds)

            cmdInfo = {}

            if module:
                self.moduleCmds[module].append(funcName)

            if module != 'runtime':
                cmdInfo = getCmdInfo(funcName, long_version)

                if module != 'windows':
                    if funcName in nodeFunctions:
                        self.nodeCommandList.append(funcName)
                        cmdInfo = testNodeCmd( funcName, cmdInfo, nodeCmd=True, verbose=True  )
                    #elif module != 'context':
                    #    cmdInfo = testNodeCmd( funcName, cmdInfo, nodeCmd=False, verbose=True  )

            cmdInfo['type'] = module
            flags = getCallbackFlags(cmdInfo)
            if flags:
                cmdInfo['callbackFlags'] = flags

            self.cmdlist[funcName] = cmdInfo

#            # func, args, (usePyNode, baseClsName, nodeName)
#            # args = dictionary of command flags and their data
#            # usePyNode = determines whether the class returns its 'nodeName' or uses PyNode to dynamically return
#            # baseClsName = for commands which should generate a class, this is the name of the superclass to inherit
#            # nodeName = most creation commands return a node of the same name, this option is provided for the exceptions
#            try:
#                self.cmdlist[funcName] = args, pymelCmdsList[funcName] )
#            except KeyError:
#                # context commands generate a class based on unicode (which is triggered by passing 'None' to baseClsName)
#                if funcName.startswith('ctx') or funcName.endswith('Ctx') or funcName.endswith('Context'):
#                     self.cmdlist[funcName] = (funcName, args, (False, None, None) )
#                else:
#                    self.cmdlist[funcName] = (funcName, args, () )

        for funcName, _ in tmpCmdlist :
            if funcName in pluginCommands:
                _logger.debug("command %s was a plugin command that should have been unloaded - skipping" % funcName)
                continue
            addCommand(funcName)

        # split the cached data for lazy loading
        cmdDocList = {}
        examples = {}
        for cmdName, cmdInfo in self.cmdlist.iteritems():
            try:
                examples[cmdName] = cmdInfo.pop('example')
            except KeyError:
                pass

            newCmdInfo = {}
            if 'description' in cmdInfo:
                newCmdInfo['description'] = cmdInfo.pop('description')
            newFlagInfo = {}
            if 'flags' in cmdInfo:
                for flag, flagInfo in cmdInfo['flags'].iteritems():
                    newFlagInfo[flag] = { 'docstring' : flagInfo.pop('docstring') }
                newCmdInfo['flags'] = newFlagInfo

            if newCmdInfo:
                cmdDocList[cmdName] = newCmdInfo

        CmdDocsCache().write(cmdDocList)
        CmdExamplesCache().write(examples)

    def build(self):
        super(CmdCache, self).build()

        # corrections that are always made, to both loaded and freshly built caches
        util.mergeCascadingDicts( cmdlistOverrides, self.cmdlist )
        # add in any nodeCommands added after cache rebuild
        self.nodeCommandList = set(self.nodeCommandList).union(nodeTypeToNodeCommand.values())
        self.nodeCommandList = sorted( self.nodeCommandList )


        for module, funcNames in moduleCommandAdditions.iteritems():
            for funcName in funcNames:
                currModule = self.cmdlist[funcName]['type']
                if currModule != module:
                    self.cmdlist[funcName]['type'] = module
                    id = self.moduleCmds[currModule].index(funcName)
                    self.moduleCmds[currModule].pop(id)
                    self.moduleCmds[module].append(funcName)
        return (self.cmdlist,self.nodeHierarchy,self.uiClassList,self.nodeCommandList,self.moduleCmds)

########NEW FILE########
__FILENAME__ = factories
"""
Contains the wrapping mechanisms that allows pymel to integrate the api and maya.cmds into a unified interface
"""

# Built-in imports
import re
import types
import os
import inspect
import sys
import textwrap
import time
import traceback
from operator import itemgetter

# Maya imports
import maya.cmds as cmds
import maya.mel as mm

# PyMEL imports
import pymel.api as api
import pymel.util as util
from pymel.util.conditions import Always, Condition
import pymel.versions as versions

# Module imports
from . import apicache
from . import cmdcache
from . import plogging
from . import pmcmds

_logger = plogging.getLogger(__name__)

# Initialize the cache globals

# Doing an initialization here mainly just for auto-completion, and to
# see these variables are defined here when doing text searches; the values
# are set inside loadApi/CmdCache

# ApiCache
apiTypesToApiEnums = None
apiEnumsToApiTypes = None
mayaTypesToApiTypes = None
apiTypesToApiClasses = None
apiClassInfo = None

mayaTypesToApiEnums = None

# ApiMelBridgeCache
apiToMelData  = None
apiClassOverrides = None

# CmdCache
cmdlist = None
nodeHierarchy = None
uiClassList = None
nodeCommandList = None
moduleCmds = None


# Though the global variables and the attributes on _apiCacheInst SHOULD
# always point to the same objects - ie,
#    _apiCacheInst.apiClassInfo is apiClassInfo
# should be true, I'm paranoid they will get out of sync, so I'm
# treating _apiCacheInst as though it ISN'T in sync, and needs to be updated
# whenever we interact with it...

def loadApiCache():
    _logger.debug("Loading api cache...")
    _start = time.time()

    global _apiCacheInst
    global _apiMelBridgeCacheInst

    _apiCacheInst = apicache.ApiCache()
    _apiCacheInst.build()
    _apiMelBridgeCacheInst = apicache.ApiMelBridgeCache()
    _apiMelBridgeCacheInst.build()
    _setApiCacheGlobals()

    _elapsed = time.time() - _start
    _logger.debug( "Initialized API Cache in in %.2f sec" % _elapsed )

def _setApiCacheGlobals():
    global _apiCacheInst
    global _apiMelBridgeCacheInst

    for names, values in [ (_apiCacheInst.cacheNames(),
                                _apiCacheInst.contents()),
                           (_apiMelBridgeCacheInst.cacheNames(),
                                _apiMelBridgeCacheInst.contents()),
                           (_apiCacheInst.EXTRA_GLOBAL_NAMES,
                                _apiCacheInst.extraDicts()) ]:
        for name, val in zip(names, values):
            globals()[name] = val

def loadCmdCache():
    _logger.debug("Loading cmd cache...")
    _start = time.time()

    global _cmdCacheInst

    global cmdlist, nodeHierarchy, uiClassList, nodeCommandList, moduleCmds

    _cmdCacheInst = cmdcache.CmdCache()
    _cmdCacheInst.build()
    _setCmdCacheGlobals()

    _elapsed = time.time() - _start
    _logger.debug( "Initialized Cmd Cache in in %.2f sec" % _elapsed )

def _setCmdCacheGlobals():
    global _cmdCacheInst

    for name, val in zip(_cmdCacheInst.cacheNames(), _cmdCacheInst.contents()):
        globals()[name] = val


def saveApiCache():
    global _apiCacheInst
    _apiCacheInst.save(globals())

def saveApiMelBridgeCache():
    global _apiMelBridgeCacheInst
    _apiMelBridgeCacheInst.save(globals())

def mergeApiClassOverrides():
    global _apiCacheInst
    global _apiMelBridgeCacheInst
    _apiCacheInst.update(globals())
    _apiMelBridgeCacheInst.update(globals())
    _apiCacheInst._mergeClassOverrides(_apiMelBridgeCacheInst)
    _setApiCacheGlobals()

loadApiCache()
loadCmdCache()


#---------------------------------------------------------------
#        Mappings and Lists
#---------------------------------------------------------------

DOC_WIDTH = 120

EXCLUDE_METHODS = ['type', 'className', 'create', 'name' ]

#: controls whether command docstrings will contain examples parsed from autodesk docs
# examples are usually only included when creating documentation, otherwise it's too much info
includeDocExamples = bool( os.environ.get( 'PYMEL_INCLUDE_EXAMPLES', False ) )

#Lookup from PyNode type name as a string to PyNode type as a class
pyNodeNamesToPyNodes = {}

#Lookup from MFn to PyNode name
apiClassNamesToPyNodeNames = {}

#Lookup from Api Enums to Pymel Component Classes
#
#A list of possible component classes is always returned (even if it's only
#of length one).
apiEnumsToPyComponents = {}

#child:parent lookup of the pymel classes that derive from DependNode
pyNodeTypesHierarchy = {}


#: for certain nodes, the best command on which to base the node class cannot create nodes, but can only provide information.
#: these commands require special treatment during class generation because, for them the 'create' mode is the same as other node's 'edit' mode
nodeTypeToInfoCommand = {
    #'mesh' : 'polyEvaluate',
    'transform' : 'xform'
}

def toPyNode(res):
    "returns a PyNode object"
    if res is not None and res != '':
        import pymel.core.general
        return pymel.core.general.PyNode(res)

def unwrapToPyNode(res):
    "unwraps a 1-item list, and returns a PyNode object"
    if res is not None and res[0]:
        import pymel.core.general
        return pymel.core.general.PyNode(res[0])

def toPyUI(res):
    "returns a PyUI object"
    if res is not None:
        import pymel.core.uitypes
        return pymel.core.uitypes.PyUI(res)

def toPyType(moduleName, objectName):
    """
    Returns a function which casts it's single argument to
    an object with the given name in the given module (name).

    The module / object are given as strings, so that the module
    may be imported when the function is called, to avoid
    making factories dependent on, say, pymel.core.general or
    pymel.core.uitypes
    """
    def toGivenClass(res):
        # Use the 'from moduleName import objectName' form of
        # __import__, because that guarantees it returns the
        # 'bottom' module (ie, myPackage.myModule, NOT myPackage),
        # note that __import__ doesn't actually insert objectName into
        # the locals... which we don't really want anyway
        module = __import__(moduleName, globals(), locals(), [objectName], -1)
        cls = getattr(module, objectName)
        if res is not None:
            return cls(res)
    toGivenClass.__name__ = 'to%s' % util.capitalize(objectName)
    toGivenClass.__doc__ = "returns a %s object" % objectName
    return toGivenClass

def toPyNodeList(res):
    "returns a list of PyNode objects"
    if res is None:
        return []
    import pymel.core.general
    return [ pymel.core.general.PyNode(x) for x in res ]

def splitToPyNodeList(res):
    "converts a whitespace-separated string of names to a list of PyNode objects"
    return toPyNodeList(res.split())

def toPyUIList(res):
    "returns a list of PyUI objects"
    if res is None:
        return []
    import pymel.core.uitypes
    return [ pymel.core.uitypes.PyUI(x) for x in res ]

def toPyTypeList(moduleName, objectName):
    """
    Returns a function which casts the members of it's iterable
    argument to the given class.
    """
    def toGivenClassList(res):
        module = __import__(moduleName, globals(), locals(), [objectName], -1)
        cls = getattr(module, objectName)
        if res is None:
            return []
        return [ cls(x) for x in res ]
    toGivenClassList.__name__ = 'to%sList' % util.capitalize(objectName)
    toGivenClassList.__doc__ = "returns a list of %s objects" % objectName
    return toGivenClassList

def raiseError(typ, *args):
    def f(res):
        raise typ(*args)
    return f

class Flag(Condition):
    def __init__(self, longName, shortName, truthValue=True):
        """
        Conditional for evaluating if a given flag is present.

        Will also check that the given flag has the required
        truthValue (True, by default). If you don't care
        about the truthValue (ie, you want to have the condition
        evaluate to true as long as the flag is present),
        set truthValue to None.
        """
        self.shortName = shortName
        self.longName = longName
        self.truthValue = truthValue

    def eval(self, kwargs):
        for arg in (self.shortName, self.longName):
            if arg in kwargs:
                if self.truthValue is None or \
                    bool(kwargs[arg]) == self.truthValue:
                    return True
        return False

    def __str__(self):
        return self.longName

# TODO: commands that don't return anything, but perhaps should?
# affectedNet (PyNodes created)

simpleCommandWraps = {
    'createRenderLayer' : [ (toPyNode, Always) ],
    'createDisplayLayer': [ (toPyNode, Always) ],
    'distanceDimension' : [ (toPyNode, Always) ],
    'listAttr'          : [ (util.listForNone, Always) ],
    'instance'          : [ (toPyNodeList, Always) ],

    'getPanel'          : [ ( toPyType('pymel.core.uitypes', 'Panel'),
                              Flag('containing', 'c', None) |
                                Flag('underPointer', 'up') |
                                Flag('withFocus', 'wf')),
                            ( toPyTypeList('pymel.core.uitypes', 'Panel'),
                              ~Flag('typeOf', 'to', None) )
                          ],

    'textScrollList'    : [ ( util.listForNone,
                              Flag('query', 'q') &
                               (Flag('selectIndexedItem', 'sii') |
                                Flag('allItems', 'ai') |
                                Flag('selectItem', 'si')) )
                          ],

    'optionMenu'        : [ ( util.listForNone,
                              Flag('query', 'q') &
                               (Flag('itemListLong', 'ill') |
                                Flag('itemListShort', 'ils')) )
                          ],

    'optionMenuGrp'     : [ ( util.listForNone,
                              Flag('query', 'q') &
                               (Flag('itemListLong', 'ill') |
                                Flag('itemListShort', 'ils')) )
                          ],

    'modelEditor'       : [ ( toPyNode,
                              Flag('query', 'q') & Flag('camera', 'cam') )
                          ],

    'ikHandle'          : [ ( toPyNode,
                              Flag('query', 'q') & Flag('endEffector', 'ee') ),
                            ( toPyNodeList,
                              Flag('query', 'q') & Flag('jointList', 'jl') ),
                          ],
    'skinCluster'       : [ ( toPyNodeList,
                              Flag('query', 'q') &
                                (Flag('geometry', 'g') |
                                 Flag('deformerTools', 'dt') |
                                 Flag('influence', 'inf') |
                                 Flag('weightedInfluence', 'wi') )),
                          ],
    'addDynamic'        : [ ( toPyNodeList, Always ) ],
    'addPP'             : [ ( toPyNodeList, Always ) ],
    'animLayer'         : [ ( toPyNode,
                              Flag('query', 'q') &
                               (Flag('root', 'r') |
                                Flag('bestLayer', 'bl') |
                                Flag('parent', 'p')) ),
                            ( toPyNodeList,
                              Flag('query', 'q') &
                               (Flag('children', 'c') |
                                Flag('attribute', 'at') |
                                Flag('bestAnimLayer', 'blr') |
                                Flag('animCurves', 'anc') |
                                Flag('baseAnimCurves', 'bac') |
                                Flag('blendNodes', 'bld') |
                                Flag('affectedLayers', 'afl') |
                                Flag('parent', 'p')) )
                          ],
    'annotate'          : [ ( lambda res: toPyNode(res.strip()), Always ) ],
    'arclen'            : [ ( toPyNode, Flag(' constructionHistory', 'ch') ) ],
    'art3dPaintCtx'     : [ ( splitToPyNodeList,
                              Flag('query', 'q') &
                               (Flag('shapenames', 'shn') |
                                Flag('shadernames', 'hnm')) )
                          ],
    'artAttrCtx'        : [ ( splitToPyNodeList,
                              Flag('query', 'q') &
                                Flag('paintNodeArray', 'pna') )
                          ],
    'container'        : [ ( toPyNodeList,
                              Flag('query', 'q') &
                                (Flag('nodeList', 'nl') |
                                 Flag('connectionList', 'cl') ) ),
                           ( toPyNode,
                              Flag('query', 'q') &
                                (Flag('findContainer', 'fc') |
                                 Flag('asset', 'a') ) ),
                           ( lambda res: [(toPyNode(res[i]),res[i+1]) for i in range(0, len(res), 2)],
                              Flag('query', 'q') &
                                Flag('bindAttr', 'ba') & ~(Flag('publishName', 'pn') | Flag('publishAsParent', 'pap') | Flag('publishAsChild', 'pac')) ),
                           ( raiseError( ValueError, 'In query mode bindAttr can *only* be used with the publishName, publishAsParent and publishAsChild flags'),
                              Flag('query', 'q') &
                                Flag('unbindAttr', 'ua') & ~(Flag('publishName', 'pn') | Flag('publishAsParent', 'pap') | Flag('publishAsChild', 'pac'))),
                          ],
}
#---------------------------------------------------------------

if includeDocExamples:
    examples = cmdcache.CmdProcessedExamplesCache().read()
    for cmd, example in examples.iteritems():
        try:
            cmdlist[cmd]['example'] = example
        except KeyError:
            print "found an example for an unknown command:", cmd
            pass

#cmdlist, nodeHierarchy, uiClassList, nodeCommandList, moduleCmds = cmdcache.buildCachedData()

# FIXME
#: stores a dictionary of pymel classnames to mel method names
classToMelMap = util.defaultdict(list)

def _getApiOverrideNameAndData(classname, pymelName):
    if apiToMelData.has_key( (classname,pymelName) ):

        data = apiToMelData[(classname,pymelName)]
        try:
            nameType = data['useName']
        except KeyError:
            # Not sure why it was a big deal if useName wasn't set...?
            #_logger.warn( "no 'useName' key set for %s.%s" % (classname, pymelName) )
            nameType = 'API'

        if nameType == 'API':
            pass
        elif nameType == 'MEL':
            pymelName = data['melName']
        else:
            pymelName = nameType
    else:
        # set defaults
        #_logger.debug( "creating default api-to-MEL data for %s.%s" % ( classname, pymelName ) )
        data = { 'enabled' : pymelName not in EXCLUDE_METHODS }
        apiToMelData[(classname,pymelName)] = data


    #overloadIndex = data.get( 'overloadIndex', None )
    return pymelName, data


def getUncachedCmds():
    return list( set( map( itemgetter(0), inspect.getmembers( cmds, callable ) ) ).difference( cmdlist.keys() ) )





#-----------------------
# Function Factory
#-----------------------
docCacheLoaded = False
def loadCmdDocCache():
    global docCacheLoaded
    if docCacheLoaded:
        return
    data = cmdcache.CmdDocsCache().read()
    util.mergeCascadingDicts(data, cmdlist)
    docCacheLoaded = True

def _addCmdDocs(func, cmdName):
    # runtime functions have no docs
    if cmdlist[cmdName]['type'] == 'runtime':
        return func

    if func.__doc__:
        docstring = func.__doc__ + '\n\n'
    else:
        docstring = ''
    util.addLazyDocString( func, addCmdDocsCallback, cmdName, docstring )
    return func

def addCmdDocsCallback(cmdName, docstring=''):
    loadCmdDocCache()

    cmdInfo = cmdlist[cmdName]

    #docstring = cmdInfo['description'] + '\n\n' + '\n'.join(textwrap.wrap(docstring.strip(), DOC_WIDTH))

    docstring = '\n'.join(textwrap.wrap(cmdInfo['description'], DOC_WIDTH)) + '\n\n' + docstring.strip()

#    if func.__doc__:
#        docstring += func.__doc__ + '\n\n'

    docstring = docstring.rstrip() + '\n\n'

    flagDocs = cmdInfo['flags']

    if flagDocs and sorted(flagDocs.keys()) != ['edit', 'query']:

        widths = [3, 100, 32, 32]
        altwidths = [ widths[0] + widths[1] ] + widths[2:]
        rowsep = '    +' + '+'.join( [ '-'*(w-1) for w in widths ] ) + '+\n'
        headersep = '    +' + '+'.join( [ '='*(w-1) for w in widths ] ) + '+\n'

        def makerow( items, widths ):
            return '    |' + '|'.join( ' ' + i.ljust(w-2) for i, w in zip( items, widths ) ) + '|\n'


        docstring += 'Flags:\n'

        if includeDocExamples:
            docstring += rowsep
            docstring += makerow( ['Long name (short name)', 'Argument Types', 'Properties'], altwidths )
            docstring += headersep

        for flag in sorted(flagDocs.keys()):
            if flag in ['edit', 'query']: continue
            docs = flagDocs[flag]

            # type
            try:
                typ = docs['args']
            except KeyError, e:
                raise KeyError("Error retrieving doc information for: %s, %s\n%s" % (cmdName, flag, e))
            if isinstance(typ, list):
                try:
                    typ = [ x.__name__ for x in typ ]
                except:
                    typ = [ str(x) for x in typ ]
                typ = ', '.join(typ)
            else:
                try:
                    typ = typ.__name__
                except: pass

            # docstring
            descr = docs.get('docstring', '')

            # modes
            tmpmodes = docs.get('modes', [])
            modes = []
            if 'create' in tmpmodes: modes.append('create')
            if 'query' in tmpmodes: modes.append('query')
            if 'edit' in tmpmodes: modes.append('edit')

            if includeDocExamples:
                for data in util.izip_longest( ['**%s (%s)**' % (flag, docs['shortname'])],
                                            textwrap.wrap( '*%s*' % typ, widths[2]-2 ),
                                            [ '.. image:: /images/%s.gif' % m for m in modes],
                                            fillvalue='' ):
                    docstring += makerow( data, altwidths )

                #docstring += makerow( ['**%s (%s)**' % (flag, docs['shortname']), '*%s*' % typ, ''], altwidths )
                #for m in modes:
                #    docstring += makerow( ['', '', '.. image:: /images/%s.gif' % m], altwidths )

                docstring += rowsep

                descr_widths = [widths[0], sum(widths[1:])]
                if descr:
                    for line in textwrap.wrap( descr.strip('|'), sum(widths[1:])-2 ):
                        docstring += makerow( ['', line], descr_widths )
                    # add some filler at the bottom
                    docstring += makerow( ['', '  ..'], descr_widths )
                else:
                    docstring += makerow( ['', ''], descr_widths )

                # empty row for spacing
                #docstring += rowsep
                #docstring += makerow( ['']*len(widths), widths )
                # closing separator
                docstring += rowsep

            else:
                descr = '\n'.join([ '      '+x for x in textwrap.wrap(descr, DOC_WIDTH)])
                # add trailing newline
                descr = descr + '\n' if descr else ''
                docstring += '  - %s %s [%s]\n%s\n' % (
                                            (flag + ' : ' + docs['shortname']).ljust(30),
                                            ('('+typ+')').ljust(15),
                                            ','.join( modes ),
                                             descr )
#            #modified
#            try:
#                modified = docs['modified']
#                if modified:
#                    docstring += '        - modifies: *%s*\n' % ( ', '.join( modified ))
#            except KeyError: pass
#
#            #secondary flags
#            try:
#                docstring += '        - secondary flags: *%s*\n' % ( ', '.join(docs['secondaryFlags'] ))
#            except KeyError: pass
#
            #args


    docstring += '\nDerived from mel command `maya.cmds.%s`\n' % (cmdName)

    if includeDocExamples and cmdInfo.get('example',None):
        #docstring = ".. |create| image:: /images/create.gif\n.. |edit| image:: /images/edit.gif\n.. |query| image:: /images/query.gif\n\n" + docstring
        docstring += '\n\nExample::\n\n' + cmdInfo['example']

    return docstring

    #func.__doc__ = docstring
    #return func

def _addFlagCmdDocs(func, cmdName, flag, docstring=''):
    util.addLazyDocString( func, addFlagCmdDocsCallback, cmdName, flag, docstring )
    return func

def addFlagCmdDocsCallback(cmdName, flag, docstring):
    loadCmdDocCache()
    allFlagInfo = cmdlist[cmdName]['flags']
    try:
        flagInfo = allFlagInfo[flag]
    except KeyError:
        _logger.warn('could not find any info on flag %s' % flag)
    else:
        if docstring:
            docstring += '\n\n'

        newdocs = flagInfo.get('docstring', '')
        if newdocs:
            docstring += newdocs + '\n\n'

        if 'secondaryFlags' in flagInfo:
            docstring += 'Flags:\n'
            for secondaryFlag in flagInfo['secondaryFlags']:
                flagdoc = allFlagInfo[secondaryFlag]['docstring']
                docstring += '  - %s:\n%s\n' % (secondaryFlag,
                                            '\n'.join( ['      '+ x for x in textwrap.wrap( flagdoc, DOC_WIDTH)] ) )

        docstring += '\nDerived from mel command `maya.cmds.%s`\n' % (cmdName)
    return docstring

#    func.__doc__ = docstring
#    return func


def _getTimeRangeFlags(cmdName):
    """used parsed data and naming convention to determine which flags are callbacks"""

    commandFlags = set()
    try:
        flagDocs = cmdlist[cmdName]['flags']
    except KeyError:
        pass
    else:
        for flag, data in flagDocs.iteritems():
            args = data['args']
            if isinstance(args, basestring) and args.lower() == 'timerange':
                commandFlags.update([flag, data['shortname']])
    return commandFlags


class Callback(object):
    """
    Enables deferred function evaluation with 'baked' arguments.
    Useful where lambdas won't work...

    It also ensures that the entire callback will be be represented by one
    undo entry.

    Example:

    .. python::

        import pymel as pm
        def addRigger(rigger, **kwargs):
            print "adding rigger", rigger

        for rigger in riggers:
            pm.menuItem(
                label = "Add " + str(rigger),
                c = Callback(addRigger,rigger,p=1))   # will run: addRigger(rigger,p=1)
    """

    MAX_RECENT_ERRORS = 10

    # keeps information for the most recent callback errors
    recentErrors = []

    CallbackErrorLog = util.namedtuple('CallbackErrorLog', 'callback exception trace creationTrace')

    @classmethod
    def logCallbackError(cls, callback, exception=None, trace=None,
                         creationTrace=None):
        if exception is None:
            exception = sys.exc_value
        if trace is None:
            trace = traceback.format_exc()
        if creationTrace is None:
            if isinstance(callback, Callback):
                creationTrace = ''.join(callback.traceback)
            else:
                creationTrace = ''
        cls.recentErrors.insert(0, cls.CallbackErrorLog(callback, exception,
                                                        trace, creationTrace))
        if len(cls.recentErrors) > cls.MAX_RECENT_ERRORS:
            del cls.recentErrors[cls.MAX_RECENT_ERRORS:]

    @classmethod
    def formatRecentError(cls, index=0):
        info = cls.recentErrors[index]
        msg = '''Error calling %s in a callback:
Callback Creation Trace:
%s

Error Trace:
%s
''' % (info.callback, info.creationTrace, info.trace)
        return msg

    @classmethod
    def printRecentError(cls, index=0):
        print cls.formatRecentError(index=index)

    def __init__(self,func,*args,**kwargs):
        self.func = func
        self.args = args
        self.kwargs = kwargs
        self.traceback = traceback.format_stack()

    def __call__(self,*args):
        cmds.undoInfo(openChunk=1)
        try:
            try:
                return self.func(*self.args, **self.kwargs)
            except Exception, e:
                self.logCallbackError(self)
                raise
        finally:
            cmds.undoInfo(closeChunk=1)

class CallbackWithArgs(Callback):
    def __call__(self,*args,**kwargs):
        # not sure when kwargs would get passed to __call__,
        # but best not to remove support now
        kwargsFinal = self.kwargs.copy()
        kwargsFinal.update(kwargs)
        cmds.undoInfo(openChunk=1)
        try:
            try:
                return self.func(*self.args + args, **kwargsFinal)
            except Exception, e:
                self.logCallbackError(self)
                raise
        finally:
            cmds.undoInfo(closeChunk=1)

def fixCallbacks(inFunc, commandFlags, funcName=None ):
    """
    Prior to maya 2011, when a user provides a custom callback functions for a
    UI elements, such as a checkBox, when the callback is triggered it is passed
    a string instead of a real python values.

    For example, a checkBox changeCommand returns the string 'true' instead of
    the python boolean True. This function wraps UI commands to correct the
    problem and also adds an extra flag to all commands with callbacks called
    'passSelf'.  When set to True, an instance of the calling UI class will be
    passed as the first argument.

    if inFunc has been renamed, pass a funcName to lookup command info in apicache.cmdlist
    """

    if not funcName:
        funcName = pmcmds.getCmdName(inFunc)

    if not commandFlags:
        #commandFlags = []
        return inFunc

    argCorrector = None
    if versions.current() < versions.v2011:
        # wrap ui callback commands to ensure that the correct types are returned.
        # we don't have a list of which command-callback pairs return what type, but for many we can guess based on their name.
        if funcName.startswith('float'):
            argCorrector = float
        elif funcName.startswith('int'):
            argCorrector = int
        elif funcName.startswith('checkBox') or funcName.startswith('radioButton'):
            argCorrector = lambda x: x == 'true'


    # need to define a seperate var here to hold
    # the old value of newFunc, b/c 'return newFunc'
    # would be recursive
    beforeUiFunc = inFunc

    def _makeCallback( origCallback, args, doPassSelf ):
        """this function is used to make the callback, so that we can ensure the origCallback gets
        "pinned" down"""
        #print "fixing callback", key
        creationTraceback = ''.join(traceback.format_stack())
        def callback(*cb_args):
            if argCorrector:
                newargs = [argCorrector(arg) for arg in cb_args]
            else:
                newargs = list(cb_args)

            if doPassSelf:
                newargs = [ args[0] ] + newargs
            newargs = tuple(newargs)
            try:
                res = origCallback( *newargs )
            except Exception, e:
                # if origCallback was ITSELF a Callback obj, it will have
                # already logged the error..
                if not isinstance(origCallback, Callback):
                    Callback.logCallbackError(origCallback,
                                              creationTrace=creationTraceback)
                raise
            if isinstance(res, util.ProxyUnicode):
                res = unicode(res)
            return res
        return callback

    def newUiFunc( *args, **kwargs):

        if len(args):
            doPassSelf = kwargs.pop('passSelf', False)
        else:
            doPassSelf = False

        for key in commandFlags:
            try:
                cb = kwargs[ key ]
                if callable(cb):
                    kwargs[ key ] = _makeCallback( cb, args, doPassSelf )
            except KeyError: pass

        return beforeUiFunc(*args, **kwargs)

    newUiFunc.__name__ = funcName
    newUiFunc.__module__ = inFunc.__module__
    newUiFunc.__doc__ = inFunc.__doc__

    return  newUiFunc

def functionFactory( funcNameOrObject, returnFunc=None, module=None, rename=None, uiWidget=False ):
    """
    create a new function, apply the given returnFunc to the results (if any)
    Use pre-parsed command documentation to add to __doc__ strings for the
    command.
    """

    #if module is None:
    #   module = _thisModule

    inFunc = None
    if isinstance( funcNameOrObject, basestring ):
        funcName = funcNameOrObject

        # make sure that we import from pmcmds, not cmds
        if module and module!=cmds:
            try:
                inFunc = getattr(module, funcName)
                customFunc = True
            except AttributeError:
                #if funcName == 'lsThroughFilter': #_logger.debug("function %s not found in module %s" % ( funcName, module.__name__))
                pass

        if not inFunc:
            try:
                inFunc = getattr(pmcmds,funcName)
                customFunc = False
                #if funcName == 'lsThroughFilter': #_logger.debug("function %s found in module %s: %s" % ( funcName, cmds.__name__, inFunc.__name__))
            except AttributeError:
                #_logger.debug('Cannot find function %s' % funcNameOrObject)
                return
    else:
        funcName = pmcmds.getCmdName(funcNameOrObject)
        inFunc = funcNameOrObject
        customFunc = True

    # Do some sanity checks...
    if not callable(inFunc):
        _logger.warn('%s not callable' % funcNameOrObject)
        return

    cmdInfo = cmdlist[funcName]
    funcType = type(inFunc)
    # python doesn't like unicode function names
    funcName = str(funcName)

    if funcType == types.BuiltinFunctionType:
        try:
            newFuncName = inFunc.__name__
            if funcName != newFuncName:
                _logger.warn("Function found in module %s has different name than desired: %s != %s. simple fix? %s" % ( inFunc.__module__, funcName, newFuncName, funcType == types.FunctionType and returnFunc is None))
        except AttributeError:
            _logger.warn("%s had no '__name__' attribute" % inFunc)

    timeRangeFlags = _getTimeRangeFlags(funcName)

    # some refactoring done here - to avoid code duplication (and make things clearer),
    # we now ALWAYS do things in the following order:
        # 1. Perform operations which modify the execution of the function (ie, adding return funcs)
        # 2. Modify the function descriptors - ie, __doc__, __name__, etc


    # 1. Perform operations which modify the execution of the function (ie, adding return funcs)

    newFunc = inFunc

    if timeRangeFlags:
        # need to define a seperate var here to hold
        # the old value of newFunc, b/c 'return newFunc'
        # would be recursive
        beforeTimeRangeFunc = newFunc
        def newFuncWithTimeRangeFlags(*args, **kwargs):
            for flag in timeRangeFlags:
                try:
                    # allow for open-ended time ranges:
                    # (1,None), (1,), slice(1,None), "1:"
                    # (None,100), slice(100), ":100"
                    # (None,None), ":"
                    rawVal = kwargs[flag]
                except KeyError:
                    continue
                else:
                    # in mel, you would do:
                    #   keyframe -time "1:10"
                    # in order to get the same behavior in python, you would
                    # have to do:
                    #   cmds.keyframe(time=("1:10",))
                    # ...which is lame. So, standardize everything by throwing
                    # it inside of a tuple...

                    # we only DON'T put it in a tuple, if it already IS a tuple/
                    # list, AND it doesn't look like a simple range - ie,
                    #   cmds.keyframe(time=(1,10))
                    # will get converted to
                    #   cmds.keyframe(time=((1,10),))
                    # but
                    #   cmds.keyframe(time=('1:3', [1,5]))
                    # will be left alone...
                    if (isinstance(rawVal, (list, tuple))
                        and 1 <= len(rawVal) <= 2
                        and all(isinstance(x, (basestring, int, long, float))
                                for x in rawVal)):
                        values = list(rawVal)
                    else:
                        values = [rawVal]

                    for i, val in enumerate(values):
                        if isinstance(val, slice):
                            val = [val.start, val.stop]
                        elif isinstance(val, tuple):
                            val = list(val)

                        if isinstance(val, list):
                            if len(val) == 1:
                                val.append(None)
                            if len(val) == 2 and None in val:
                                # easiest way to get accurate min/max bounds
                                # is to convert to the string form...
                                val = ':'.join('' if x is None else str(x)
                                               for x in val)
                            else:
                                val = tuple(val)
                        values[i] = val
                    kwargs[flag] = values
            return beforeTimeRangeFunc(*args, **kwargs)
        newFunc = newFuncWithTimeRangeFlags

    if returnFunc:
        # need to define a seperate var here to hold
        # the old value of newFunc, b/c 'return newFunc'
        # would be recursive
        beforeReturnFunc = newFunc
        def newFuncWithReturnFunc(*args, **kwargs):
            res = beforeReturnFunc(*args, **kwargs)
            if not kwargs.get('query', kwargs.get('q',False)): # and 'edit' not in kwargs and 'e' not in kwargs:
                if isinstance(res, list):
                    # some node commands unnecessarily return a list with a single object
                    if cmdInfo.get('resultNeedsUnpacking',False):
                        res = returnFunc(res[0])
                    else:
                        try:
                            res = map( returnFunc, res )
                        except: pass

                elif res:
                    try:
                        res = returnFunc( res )
                    except Exception, e:
                        pass
            return res
        newFunc = newFuncWithReturnFunc

    createUnpack = cmdInfo.get('resultNeedsUnpacking', False)
    unpackFlags = set()
    for flag, flagInfo in cmdInfo.get('flags', {}).iteritems():
        if flagInfo.get('resultNeedsUnpacking', False):
            unpackFlags.add(flagInfo.get('longname', flag))
            unpackFlags.add(flagInfo.get('shortname', flag))

    if (createUnpack or unpackFlags):
        beforeUnpackFunc = newFunc
        def newFuncWithUnpack(*args, **kwargs):
            res = beforeUnpackFunc(*args, **kwargs)
            if isinstance(res, list) and len(res) == 1:
                if kwargs.get('query', kwargs.get('q',False)):
                    # query mode...
                    if not unpackFlags.isdisjoint(kwargs):
                        res = res[0]
                else:
                    if createUnpack:
                        res = res[0]
            return res
        newFunc = newFuncWithUnpack

    if funcName in simpleCommandWraps:
        # simple wraps: we only do these for functions which have not been manually customized
        wraps = simpleCommandWraps[funcName]
        beforeSimpleWrap = newFunc
        def simpleWrapFunc(*args, **kwargs):
            res = beforeSimpleWrap(*args, **kwargs)
            for func, wrapCondition in wraps:
                if wrapCondition.eval(kwargs):
                    res = func(res)
                    break
            return res
        newFunc = simpleWrapFunc
        doc = 'Modifications:\n'
        for func, wrapCondition in wraps:
            if wrapCondition != Always:
                # use only the long flag name
                flags = ' for flags: ' + str(wrapCondition)
            elif len(wraps)>1:
                flags = ' for all other flags'
            else:
                flags = ''
            if func.__doc__:
                funcString = func.__doc__.strip()
            else:
                funcString = pmcmds.getCmdName(func) + '(result)'
            doc += '  - ' + funcString + flags + '\n'

        newFunc.__doc__  = doc

    #----------------------------
    # UI commands with callbacks
    #----------------------------

    callbackFlags = cmdInfo.get('callbackFlags', None)
    if callbackFlags:
        newFunc = fixCallbacks( newFunc, callbackFlags, funcName )

    # Check if we have not been wrapped yet. if we haven't and our input function is a builtin or we're renaming
    # then we need a wrap. otherwise we can just change the __doc__ and __name__ and move on
    if newFunc == inFunc and (type(newFunc) == types.BuiltinFunctionType or rename):
        # we'll need a new function: we don't want to touch built-ins, or
        # rename an existing function, as that can screw things up... just modifying docs
        # of non-builtin should be fine, though
        def newFunc(*args, **kwargs):
            return inFunc(*args, **kwargs)

    # 2. Modify the function descriptors - ie, __doc__, __name__, etc
    if customFunc:
        # copy over the exisitng docs
        if not newFunc.__doc__:
            newFunc.__doc__ = inFunc.__doc__
        elif inFunc.__doc__:
            newFunc.__doc__ = inFunc.__doc__
    _addCmdDocs(newFunc, funcName)

    if rename:
        newFunc.__name__ = rename
    else:
        newFunc.__name__ = funcName

    return newFunc

def makeCreateFlagMethod( inFunc, flag, newMethodName=None, docstring='', cmdName=None, returnFunc=None ):
    #name = 'set' + flag[0].upper() + flag[1:]
    if cmdName is None:
        cmdName = pmcmds.getCmdName(inFunc)

    if returnFunc:
        def wrappedMelFunc(*args, **kwargs):
            if len(args)<=1:
                kwargs[flag]=True
            elif len(args)==2:
                kwargs[flag]=args[1]
                args = (args[0],)
            else:
                kwargs[flag]=args[1:]
                args = (args[0],)
            return returnFunc(inFunc( *args, **kwargs ))
    else:
        def wrappedMelFunc(*args, **kwargs):
            if len(args)<=1:
                kwargs[flag]=True
            elif len(args)==2:
                kwargs[flag]=args[1]
                args = (args[0],)
            else:
                kwargs[flag]=args[1:]
                args = (args[0],)
            return inFunc( *args, **kwargs )

    if newMethodName:
        wrappedMelFunc.__name__ = newMethodName
    else:
        wrappedMelFunc.__name__ = flag

    return _addFlagCmdDocs(wrappedMelFunc, cmdName, flag, docstring )

def createflag( cmdName, flag ):
    """create flag decorator"""
    def create_decorator(method):
        wrappedMelFunc = makeCreateFlagMethod( method, flag, pmcmds.getCmdName(method), cmdName=cmdName )
        wrappedMelFunc.__module__ = method.__module__
        return wrappedMelFunc
    return create_decorator
'''
def secondaryflag( cmdName, flag ):
    """query flag decorator"""
    def secondary_decorator(method):
        return makeSecondaryFlagCmd( method, method.__name__, flag, cmdName=cmdName )
    return secondary_decorator
'''

def makeQueryFlagMethod( inFunc, flag, newMethodName=None, docstring='', cmdName=None, returnFunc=None ):
    #name = 'get' + flag[0].upper() + flag[1:]
    if cmdName is None:
        cmdName = pmcmds.getCmdName(inFunc)


    if returnFunc:
        def wrappedMelFunc(self, **kwargs):
            kwargs['query']=True
            kwargs[flag]=True
            return returnFunc( inFunc( self, **kwargs ) )
    else:
        def wrappedMelFunc(self, **kwargs):
            kwargs['query']=True
            kwargs[flag]=True
            return inFunc( self, **kwargs )

    if newMethodName:
        wrappedMelFunc.__name__ = newMethodName
    else:
        wrappedMelFunc.__name__ = flag

    return _addFlagCmdDocs(wrappedMelFunc, cmdName, flag, docstring )

def queryflag( cmdName, flag ):
    """query flag decorator"""
    def query_decorator(method):
        wrappedMelFunc = makeQueryFlagMethod( method, flag, pmcmds.getCmdName(method), cmdName=cmdName )
        wrappedMelFunc.__module__ = method.__module__
        return wrappedMelFunc
    return query_decorator


def makeEditFlagMethod( inFunc, flag, newMethodName=None, docstring='', cmdName=None):
    #name = 'set' + flag[0].upper() + flag[1:]
    if cmdName is None:
        cmdName = pmcmds.getCmdName(inFunc)

    def wrappedMelFunc(self, val=True, **kwargs):
        kwargs['edit']=True
        kwargs[flag]=val
        try:
            return inFunc( self, **kwargs )
        except TypeError:
            kwargs.pop('edit')
            return inFunc( self, **kwargs )

    if newMethodName:
        wrappedMelFunc.__name__ = newMethodName
    else:
        wrappedMelFunc.__name__ = flag

    return _addFlagCmdDocs(wrappedMelFunc, cmdName, flag, docstring )


def editflag( cmdName, flag ):
    """edit flag decorator"""
    def edit_decorator(method):
        wrappedMelFunc = makeEditFlagMethod(  method, flag, pmcmds.getCmdName(method), cmdName=cmdName )
        wrappedMelFunc.__module__ = method.__module__
        return wrappedMelFunc
    return edit_decorator


def addMelDocs( cmdName, flag=None ):
    """decorator for adding docs"""

    if flag:
        # A method generated from a flag
        def doc_decorator(method):
            wrappedMelFunc = _addFlagCmdDocs(method, cmdName, flag )
            wrappedMelFunc.__module__ = method.__module__
            return wrappedMelFunc
    else:
        # A command
        def doc_decorator(func):
            try:
                wrappedMelFunc = _addCmdDocs(func, cmdName )
                wrappedMelFunc.__module__ = func.__module__
            except KeyError:
                _logger.info(("No documentation available %s command" % ( cmdName ) ))
                wrappedMelFunc = func
            return wrappedMelFunc

    return doc_decorator

def listForNoneQuery(res, kwargs, flags):
    "convert a None to an empty list on the given query flags"
    if res is None and kwargs.get('query', kwargs.get('q', False ) ) and \
        bool( [ True for long, short in flags if kwargs.get(long, kwargs.get(short, False ))] ):
        return []
    return res


def createFunctions( moduleName, returnFunc=None ):
    module = sys.modules[moduleName]
    moduleShortName = moduleName.split('.')[-1]
    for funcName in moduleCmds[ moduleShortName ] :
        if funcName in nodeCommandList:
            func = functionFactory( funcName, returnFunc=returnFunc, module=module )
        else:
            func = functionFactory( funcName, returnFunc=None, module=module )
        if func:
            func.__module__ = moduleName
            setattr( module, funcName, func )


#: overrideMethods specifies methods of base classes which should not be overridden by sub-classes
overrideMethods = {}
overrideMethods['Constraint'] = ('getWeight', 'setWeight')


class ApiTypeRegister(object):
    """"
    Use this class to register the classes and functions used to wrap api methods.

    there are 4 dictionaries of functions maintained by this class:
        - inCast : for casting input arguments to a type that the api method expects
        - outCast: for casting the result of the api method to a type that pymel expects (outCast expect two args (self, obj) )
        - refInit: for initializing types passed by reference or via pointer
        - refCast: for casting the pointers to pymel types after they have been passed to the method

    To register a new type call `ApiTypeRegister.register`.
    """
    types = {}
    inCast = {}
    outCast = {}
    refInit = {}
    refCast = {}
    arrayItemTypes = {}
    doc = {}

    @staticmethod
    def _makeRefFunc(capitalizedApiType, size=1, **kwargs):
        """
        Returns a function which will return a SafeApiPtr object of the given
        type.

        This ensures that each created ref stems from a unique MScriptUtil,
        so no two refs point to the same storage!

        :Parameters:
        size : `int`
            If other then 1, the returned function will initialize storage for
            an array of the given size.
        """
        def makeRef():
            return api.SafeApiPtr(capitalizedApiType, size=size, **kwargs)
        return makeRef

    @staticmethod
    def _makeApiArraySetter( type, inCast ):
        iterable = hasattr(inCast, '__iter__')
        def setArray( array ):
            arrayPtr = type()
            if iterable:
                [ arrayPtr.append( inCast(*x) ) for x in array ]
            else:
                [ arrayPtr.append( inCast(x) ) for x in array ]
            return arrayPtr
        setArray.__name__ = 'set_' + type.__name__
        return setArray

    @staticmethod
    def _makeArraySetter( apiTypeName, length, initFunc ):
        def setArray( array ):
            if len(array) != length:
                raise ValueError, 'Input list must contain exactly %s %ss' % ( length, apiTypeName )
            safeArrayPtr = initFunc()
            for i, val in enumerate( array ):
                safeArrayPtr[i] = val
            #_logger.debug("result %s" % safeArrayPtr)
            return safeArrayPtr
        setArray.__name__ = 'set_' + apiTypeName + str(length) + 'Array'
        return setArray

    @staticmethod
    def _makeArrayGetter( apiTypeName, length ):
        def getArray( safeArrayPtr ):
            return [ x for x in safeArrayPtr]
        getArray.__name__ = 'get_' + apiTypeName + str(length) + 'Array'
        return getArray

    @classmethod
    def getPymelType(cls, apiType):
        """
        We need a way to map from api name to pymelName.  we start by looking up types which are registered
        and then fall back to naming convention for types that haven't been registered yet. Perhaps pre-register
        the names? """
        try:
            #_logger.debug("getting %s from dict" % apiType)
            return cls.types[apiType]
        except KeyError:
            try:
                # convert to pymel naming convetion  MTime -> Time,  MVector -> Vector
                #_logger.debug("getting pymelName %s" % apiType)
                buf = re.split( '(?:MIt)|(?:MFn)|(?:M)', apiType)
                #_logger.debug(buf)
                assert buf[1]
                return buf[1]
            except IndexError:
                raise

    @classmethod
    def isRegistered(cls, apiTypeName):
        return apiTypeName in cls.types

    @classmethod
    def register(cls, apiTypeName, pymelType, inCast=None, outCast=None, apiArrayItemType=None):
        """
        pymelType is the type to be used internally by pymel.  apiType will be hidden from the user
        and converted to the pymel type.
        apiTypeName is the name of an apiType as a string
        if apiArrayItemType is set, it should be the api type that represents each item in the array"""

        #apiTypeName = pymelType.__class__.__name__
        capType = util.capitalize( apiTypeName )

        # register type
        cls.types[apiTypeName] = pymelType.__name__

        if apiArrayItemType:
            cls.arrayItemTypes[apiTypeName] = apiArrayItemType
        # register result casting
        if outCast:
            cls.outCast[apiTypeName] = outCast
        elif apiArrayItemType is not None:
            pass
        else:
            cls.outCast[apiTypeName] = lambda self, x: pymelType(x)

        # register argument casting
        if inCast:
            cls.inCast[apiTypeName] = inCast
        elif apiArrayItemType is not None:
            pass # filled out below
        else:
            cls.inCast[apiTypeName] = pymelType

        if apiTypeName in ['float', 'double', 'bool', 'int', 'short', 'long', 'uint']:
            initFunc = cls._makeRefFunc( capType )
            getFunc = api.SafeApiPtr.get
            cls.refInit[apiTypeName] = initFunc
            cls.refCast[apiTypeName] = getFunc
            for i in [2,3,4]:
                # Register arrays for this up to size for - ie,
                #   int myVar[2];
                iapiArrayTypename = apiTypeName + '__array' + str(i)
                arrayInitFunc = cls._makeRefFunc( capType, size=i)
                cls.refInit[iapiArrayTypename] = arrayInitFunc
                cls.inCast[iapiArrayTypename]  = cls._makeArraySetter( apiTypeName, i, arrayInitFunc )
                cls.refCast[iapiArrayTypename] = cls._makeArrayGetter( apiTypeName, i )
                cls.types[iapiArrayTypename] = tuple([pymelType.__name__]*i)
                # Check if there is an explicit maya type for n of these - ie,
                #   int2 myVar;
                apiTypeNameN = apiTypeName + str(i)
                castNFuncName = 'as' + capType + str(i) + 'Ptr'
                if hasattr(api.MScriptUtil, castNFuncName):
                    nInitFunc = cls._makeRefFunc(apiTypeName, size=i, asTypeNPtr=True)
                    cls.refInit[apiTypeNameN] = nInitFunc
                    cls.inCast[apiTypeNameN]  = cls._makeArraySetter( apiTypeName, i, nInitFunc )
                    cls.refCast[apiTypeNameN] = cls._makeArrayGetter( apiTypeName, i )
                    cls.types[apiTypeNameN] = tuple([pymelType.__name__]*i)
        else:
            try:
                apiType = getattr( api, apiTypeName )
            except AttributeError:
                if apiArrayItemType:
                    cls.refInit[apiTypeName] = list
                    cls.inCast[apiTypeName] = lambda x: [ apiArrayItemType(y) for y in x ]
                    cls.refCast[apiTypeName] = None
                    cls.outCast[apiTypeName] = None

            else:
                #-- Api Array types
                if apiArrayItemType:

                    cls.refInit[apiTypeName] = apiType
                    cls.inCast[apiTypeName] = cls._makeApiArraySetter( apiType, apiArrayItemType )
                    # this is double wrapped because of the crashes occuring with MDagPathArray. not sure if it's applicable to all arrays
                    if apiType == api.MDagPathArray:
                        cls.refCast[apiTypeName] = lambda x:       [ pymelType( apiArrayItemType(x[i]) ) for i in range( x.length() ) ]
                        cls.outCast[apiTypeName] = lambda self, x: [ pymelType( apiArrayItemType(x[i]) ) for i in range( x.length() ) ]
                    else:
                        cls.refCast[apiTypeName] = lambda x:       [ pymelType( x[i] ) for i in range( x.length() ) ]
                        cls.outCast[apiTypeName] = lambda self, x: [ pymelType( x[i] ) for i in range( x.length() ) ]

                #-- Api types
                else:
                    cls.refInit[apiTypeName] = apiType
                    cls.refCast[apiTypeName] = pymelType
                    try:
                        # automatically handle array types that correspond to this api type (e.g.  MColor and MColorArray )
                        arrayTypename = apiTypeName + 'Array'
                        apiArrayType = getattr( api, arrayTypename )
                        # e.g.  'MColorArray', Color, api.MColor
                        ApiTypeRegister.register(arrayTypename, pymelType, apiArrayItemType=apiType)
                    except AttributeError:
                        pass



ApiTypeRegister.register('float', float)
ApiTypeRegister.register('double', float)
ApiTypeRegister.register('bool', bool)
ApiTypeRegister.register('int', int)
ApiTypeRegister.register('short', int)
ApiTypeRegister.register('uint', int)
ApiTypeRegister.register('uchar', int)
#ApiTypeRegister.register('long', int)
ApiTypeRegister.register('MString', unicode )
ApiTypeRegister.register('MStringArray', list, apiArrayItemType=unicode )
ApiTypeRegister.register('MIntArray', int, apiArrayItemType=int)
ApiTypeRegister.register('MFloatArray', float, apiArrayItemType=float)
ApiTypeRegister.register('MDoubleArray', float, apiArrayItemType=float)

class ApiArgUtil(object):

    def __init__(self, apiClassName, methodName, methodIndex=0 ):
        """If methodInfo is None, then the methodIndex will be used to lookup the methodInfo from apiClassInfo"""
        self.apiClassName = apiClassName
        self.methodName = methodName


        if methodIndex is None:
            try:
                methodInfoList = apiClassInfo[apiClassName]['methods'][methodName]
            except KeyError:
                raise TypeError, "method %s of %s cannot be found" % (methodName, apiClassName)
            else:
                for i, methodInfo in enumerate( methodInfoList ):

                    #argInfo = methodInfo['argInfo']

                    #argList = methodInfo['args']
                    argHelper = ApiArgUtil(apiClassName, methodName, i)

                    if argHelper.canBeWrapped() :
                        methodIndex = i
                        break

                # if it is still None then we didn't find anything
                if methodIndex is None:
                    raise TypeError, "method %s of %s cannot be wrapped" % (methodName, apiClassName)

        self.methodInfo = apiClassInfo[apiClassName]['methods'][methodName][methodIndex]
        self.methodIndex = methodIndex

    def iterArgs(self, inputs=True, outputs=True, infoKeys=[]):
        res = []
        for argname, argtype, direction in self.methodInfo['args']:

            if direction == 'in':
                if not inputs:
                    continue
            else:
                if not outputs:
                    continue

            if infoKeys:
                arg_res = [argname]
                argInfo = self.methodInfo['argInfo'][argname]
                for key in infoKeys:
                    arg_res.append( argInfo[key] )
            else:
                arg_res = argname
            res.append( arg_res )
        return res

    def inArgs(self):
        return self.methodInfo['inArgs']

    def outArgs(self):
        return self.methodInfo['outArgs']

    def argList(self):
        return self.methodInfo['args']

    def argInfo(self):
        return self.methodInfo['argInfo']

    def getGetterInfo(self):
        try:
            inverse, isgetter = self.methodInfo['inverse']
            if isgetter:
                if hasattr( getattr(api, self.apiClassName), inverse ):
                    return ApiArgUtil( self.apiClassName, inverse, self.methodIndex )
        except:
            pass

    @staticmethod
    def isValidEnum( enumTuple ):
        if apiClassInfo.has_key(enumTuple[0]) and \
            apiClassInfo[enumTuple[0]]['enums'].has_key(enumTuple[1]):
            return True
        return False

    def hasOutput(self):
        if self.methodInfo['outArgs'] or self.methodInfo['returnType']:
            return True
        return False

    def canBeWrapped(self):
        defaults = self.methodInfo['defaults']
        #argList = methodInfo['args']
        returnType =  self.methodInfo['returnType']
        # ensure that we can properly cast all the args and return values
        try:
            if returnType is not None:
                # Enum: ensure existence
                if isinstance( returnType, tuple ):
                    assert self.isValidEnum(returnType), '%s.%s(): invalid return enum: %s' % (self.apiClassName, self.methodName, returnType)

                # Other: ensure we can cast result
                else:
                    assert  returnType in ApiTypeRegister.outCast or \
                            returnType == self.apiClassName, \
                    '%s.%s(): invalid return type: %s' % (self.apiClassName, self.methodName, returnType)

            for argname, argtype, direction in self.methodInfo['args'] :
                # Enum
                if isinstance( argtype, tuple ):
                    assert self.isValidEnum(argtype), '%s.%s(): %s: invalid enum: %s' % (self.apiClassName, self.methodName, argname, argtype)

                # Input
                else:
                    if direction == 'in':
                        assert  argtype in ApiTypeRegister.inCast or \
                                defaults.has_key(argname) or \
                                argtype == self.apiClassName, \
                        '%s.%s(): %s: invalid input type %s' % (self.apiClassName, self.methodName, argname, argtype)

                        #if argname in ['instance', 'instanceNumber']: print '%s.%s(): %s: %r' % (self.apiClassName, self.methodName, argname, argtype)
                    # Output
                    elif direction == 'out':
                        assert argtype in ApiTypeRegister.refInit and argtype in ApiTypeRegister.refCast, '%s.%s(): %s: invalid output type %s' % (self.apiClassName, self.methodName, argname, argtype)
                        #try:
                        #    assert argtype.type() in refInit, '%s.%s(): cannot cast referece arg %s of type %s' % (apiClassName, methodName, argname, argtype)
                        #except AttributeError:
                        #    assert argtype in refInit, '%s.%s(): cannot cast referece arg %s of type %s' % (apiClassName, methodName, argname, argtype)
                    else:
                        # in+out, or something else weird...
                        return False
        except AssertionError, msg:
            #_logger.debug( str(msg) )
            return False

        #_logger.debug("%s: valid" % self.getPrototype())
        return True

#    def castEnum(self, argtype, input ):
#        if isinstance( input, int):
#            return input
#
#        elif input[0] != 'k' or not input[1].isupper():
#            input = 'k' + util.capitalize(input)
#            return apiClassInfo[argtype[0]]['enums'][argtype[1]].index(input)

    def getInputTypes(self):
        inArgs = self.methodInfo['inArgs']
        types = self.methodInfo['types']
        return [str(types[x]) for x in inArgs ]

    def getOutputTypes(self):
        ret = self.methodInfo['returnType']
        if ret is None:
            ret = []
        else:
            ret = [str(ret)]

        outArgs =  self.methodInfo['outArgs']
        types = self.methodInfo['types']
        return ret + [str(types[x]) for x in outArgs ]

    def getReturnType(self):
        return self.methodInfo['returnType']

    def getPymelName(self ):
        pymelName = self.methodInfo.get('pymelName',self.methodName)
        try:
            pymelClassName = apiClassNamesToPyNodeNames[self.apiClassName]
            pymelName, data = _getApiOverrideNameAndData( pymelClassName, pymelName )
        except KeyError:
            pass
        return pymelName

    def getMethodDocs(self):
        return self.methodInfo['doc']

    def getPrototype(self, className=True, methodName=True, outputs=False, defaults=False):
        inArgs = self.methodInfo['inArgs']
        outArgs =  self.methodInfo['outArgs']
        returnType =  self.methodInfo['returnType']
        types = self.methodInfo['types']
        args = []

        for x in inArgs:
            arg = str(types[x]) + ' ' + x
            if defaults:
                try:
                    #_logger.debug(self.methodInfo['defaults'][x])
                    arg += '=' + str(self.methodInfo['defaults'][x])
                except KeyError: pass
            args.append( arg )

        proto = "(%s)" % (', '.join( args ) )
        if methodName:
            proto = self.methodName + proto
            if className:
                proto = self.apiClassName + '.' + proto


        if outputs:
            results = []
            if returnType:
                results.append(returnType)
            for x in outArgs:
                results.append( types[x] )

            if len(results)==1:
                proto += ' --> ' + str(results[0])
            elif len(results):
                proto += ' --> (%s)' % ', '.join( [str(x) for x in results] )
        return proto

    def castInput(self, argName, input, cls):
        # enums
        argtype = self.methodInfo['types'][argName]
        if isinstance( argtype, tuple ):
            # convert enum as a string or int to an int

            #if isinstance( input, int):
            #    return input

            apiClassName, enumName = argtype
            return self.castInputEnum(apiClassName, enumName, input)

        elif input is not None:
#            try:

            f = ApiTypeRegister.inCast[argtype]
            if f is None:
                return input

            input = self.toInternalUnits(argName, input)
            return f( input )
#            except:
#                if input is None:
#                    # we should do a check to ensure that the default is None, but for now, just return
#                    return input
#                if argtype != cls.__name__:
#                    raise TypeError, "Cannot cast a %s to %s" % ( type(input).__name__, argtype )
#                return cls(input)

    @classmethod
    def castInputEnum(cls, apiClassName, enumName, input):
        # pymelEnums should now have both api key names ("kPostTransform") and
        # pymel names ("postTransform") available as keys now, with the pymel
        # form the default... so only need to check pymelEnum, not
        #  apiClassInfo[apiClassName]['enums'][enumName]['values'].getIndex(input)
        try:
            return apiClassInfo[apiClassName]['pymelEnums'][enumName].getIndex(input)
        except ValueError:
            raise ValueError, "expected an enum of type %s.%s: got %r" % ( apiClassName, enumName, input )


    def fromInternalUnits(self, result, instance=None):
        # units
        unit = self.methodInfo['returnInfo'].get('unitType',None)
        returnType = self.methodInfo['returnInfo']['type']
        #_logger.debug(unit)
        #returnType in ['MPoint'] or
        if unit == 'linear' or returnType == 'MPoint':
            unitCast = ApiTypeRegister.outCast['MDistance']
            if util.isIterable(result):
                result = [ unitCast(instance,val) for val in result ]
            else:
                result = unitCast(instance,result)

        # maybe this should not be hardwired here
        # the main reason it is hardwired is because we don't want to convert the w component, which we
        # would do if we iterated normally
        elif returnType == 'MPoint':
            #_logger.debug("linear")
            unitCast = ApiTypeRegister.outCast['MDistance']
            result = [ unitCast(instance,result[0]), unitCast(instance,result[1]), unitCast(instance,result[2]) ]

        elif unit == 'angular':
            #_logger.debug("angular")
            unitCast = ApiTypeRegister.outCast['MAngle']
            if util.isIterable(result):
                result = [ unitCast(instance,val) for val in result ]
            else:
                result = unitCast(instance,result)
        return result

    def toInternalUnits(self, arg, input ):
        # units
        info = self.methodInfo['argInfo'][arg]
        unit = info.get('unitType',None)
        if unit == 'linear':
            #_logger.debug("setting linear")
            unitCast = ApiTypeRegister.inCast['MDistance']
            if util.isIterable(input):
                input = [ unitCast(val).asInternalUnit() for val in input ]
            else:
                input = unitCast(input).asInternalUnit()

        elif unit == 'angular':
            #_logger.debug("setting angular")
            unitCast = ApiTypeRegister.inCast['MAngle']
            if util.isIterable(input):
                input = [ unitCast(val).asInternalUnit() for val in input ]
            else:
                input = unitCast(input).asInternalUnit()

        return input

    def castResult(self, instance, result ):
        returnType = self.methodInfo['returnType']
        if returnType:
            # special case check - some functions return an MObject, but return
            # an empty/null MObject if no node was found - ie, MFnCharacter.getClipScheduler
            # In these cases, return None...
            if (returnType == 'MObject' and isinstance(result, api.MObject)
                    and result.isNull()):
                return None

            # enums
            if isinstance( returnType, tuple ):
                #raise NotImplementedError
                apiClassName, enumName = returnType
                try:
                    # TODO: return EnumValue type

                    # convert int result into pymel string name.
                    return apiClassInfo[apiClassName]['pymelEnums'][enumName][result]
                except KeyError:
                    raise ValueError, "expected an enum of type %s.%s" % ( apiClassName, enumName )

            else:
                #try:
                f = ApiTypeRegister.outCast[returnType]
                if f is None:
                    return result

                result = self.fromInternalUnits(result, instance)

                return f( instance, result )
#                except:
#                    cls = instance.__class__
#                    if returnType != cls.__name__:
#                        raise TypeError, "Cannot cast a %s to %s" % ( type(result).__name__, returnType )
#                    return cls(result)



    def initReference(self, argtype):
        return ApiTypeRegister.refInit[argtype]()

    def castReferenceResult(self,argtype,outArg):
        # special case check - some functions return an MObject, but return
        # an empty/null MObject if no node was found - ie, MFnContainer.getParentContainer
        # In these cases, return None...
        if (argtype == 'MObject' and isinstance(outArg, api.MObject)
                and outArg.isNull()):
            return None

        f = ApiTypeRegister.refCast[ argtype ]
        #_logger.debug("castReferenceResult")
        #_logger.debug( "%s %s %s" % (f, argtype, outArg) )
        if f is None:
            return outArg

        result = self.fromInternalUnits(outArg)
        return f( result )




    def getDefaults(self):
        "get a list of defaults"
        defaults = []
        defaultInfo = self.methodInfo['defaults']
        inArgs = self.methodInfo['inArgs']
        nargs = len(inArgs)
        for i, arg in enumerate( inArgs ):
            if arg in defaultInfo:
                default = defaultInfo[arg]

            # FIXME : these defaults should probably not be set here since this is supposed to be
            # a "dumb" registry of data.  perhaps move them to the controlPanel

            # set MSpace.Space enum to object space by default, but only if it is the last arg or
            # the next arg has a default ( i.e. kwargs must always come after args )
#            elif str(self.methodInfo['types'][arg]) == 'MSpace.Space' and \
#                (   i==(nargs-1) or ( i<(nargs-1) and inArgs[i+1] in defaultInfo )  ):
#                    default = apicache.ApiEnum(['MSpace', 'Space', 'kWorld'])  # should be kPostTransform?  this is what xform defaults to...

            else:
                continue

            if isinstance(default, apicache.ApiEnum ):
                # convert enums from apiName to pymelName. the default will be the readable string name
                apiClassName, enumName, enumValue = default
                try:
                    enumList = apiClassInfo[apiClassName]['enums'][enumName]['values']
                except KeyError:
                    _logger.warning("Could not find enumerator %s", default)
                else:
                    index = enumList.getIndex(enumValue)
                    default = apiClassInfo[apiClassName]['pymelEnums'][enumName][index]
            defaults.append( default )

        return defaults

    def isStatic(self):
        return self.methodInfo['static']

    def isDeprecated(self):
        return self.methodInfo.get('deprecated', False)


class ApiUndo:
    """
    this is based on a clever prototype that Dean Edmonds posted on python_inside_maya
    awhile back.  it works like this:

        - using the API, create a garbage node with an integer attribute,
          lock it and set it not to save with the scene.
        - add an API callback to the node, so that when the special attribute
          is changed, we get a callback
        - the API queue is a list of simple python classes with undoIt and
          redoIt methods.  each time we add a new one to the queue, we increment
          the garbage node's integer attribute using maya.cmds.
        - when maya's undo or redo is called, it triggers the undoing or
          redoing of the garbage node's attribute change (bc we changed it using
          MEL/maya.cmds), which in turn triggers our API callback.  the callback
          runs the undoIt or redoIt method of the class at the index taken from
          the numeric attribute.

    """
    __metaclass__ = util.Singleton

    def __init__( self ):
        self.node_name = '__pymelUndoNode'
        self.cb_enabled = True
        self.undo_queue = []
        self.redo_queue = []


    def _attrChanged(self, msg, plug, otherPlug, data):
        if self.cb_enabled\
           and (msg & api.MNodeMessage.kAttributeSet != 0) \
           and (plug == self.cmdCountAttr):


#            #count = cmds.getAttr(self.node_name + '.cmdCount')
#            #print count
            if api.MGlobal.isUndoing():
                #cmds.undoInfo(state=0)
                self.cb_enabled = False
                cmdObj = self.undo_queue.pop()
                cmdObj.undoIt()
                self.redo_queue.append(cmdObj)
                #cmds.undoInfo(state=1)
                self.cb_enabled = True

            elif api.MGlobal.isRedoing():
                #cmds.undoInfo(state=0)
                self.cb_enabled = False
                cmdObj = self.redo_queue.pop()
                cmdObj.redoIt()
                self.undo_queue.append(cmdObj)
                #cmds.undoInfo(state=1)
                self.cb_enabled = True

    def _attrChanged_85(self):
        print "attr changed", self.cb_enabled, api.MGlobal.isUndoing()
        if self.cb_enabled:

            if api.MGlobal.isUndoing():
                cmdObj = self.undo_queue.pop()
                print "calling undoIt"
                cmdObj.undoIt()
                self.redo_queue.append(cmdObj)

            elif api.MGlobal.isRedoing():
                cmdObj = self.redo_queue.pop()
                print "calling redoIt"
                cmdObj.redoIt()
                self.undo_queue.append(cmdObj)

    def _createNode( self ):
        """
        Create the undo node.

        Any type of node will do. I've chosen a 'facade' node since it
        doesn't have too much overhead and won't get deleted if the user
        optimizes the scene.

        Note that we don't want to use Maya commands here because they
        would pollute Maya's undo queue, so we use API calls instead.
        """

        ns = api.MNamespace.currentNamespace()
        api.MNamespace.setCurrentNamespace(':')
        self.flushUndo()

        dgmod = api.MDGModifier()
        self.undoNode = dgmod.createNode('facade')
        dgmod.renameNode(self.undoNode, self.node_name)
        dgmod.doIt()

        api.MNamespace.setCurrentNamespace(ns)

        # Add an attribute to keep a count of the commands in the stack.
        attrFn = api.MFnNumericAttribute()
        self.cmdCountAttr = attrFn.create( 'cmdCount', 'cc',
                                           api.MFnNumericData.kInt
                                           )

        nodeFn = api.MFnDependencyNode(self.undoNode)
        self.node_name = nodeFn.name()
        nodeFn.addAttribute(self.cmdCountAttr)

        nodeFn.setDoNotWrite(True)
        nodeFn.setLocked(True)

        try:
            api.MMessage.removeCallback( self.cbid )
            if hasattr(self.cbid, 'disown'):
                self.cbid.disown()
        except:
            pass
        self.cbid = api.MNodeMessage.addAttributeChangedCallback( self.undoNode, self._attrChanged )

    def append(self, cmdObj):
        if not cmds.undoInfo(q=1, state=1):
            # if undo is off, don't add to the undo queue
            return

        self.cb_enabled = False

        # Increment the undo node's command count. We want this to go into
        # Maya's undo queue because changes to this attr will trigger our own
        # undo/redo code.
        try:
            count = cmds.getAttr(self.node_name + '.cmdCount')
        except Exception:
            if not cmds.objExists(self.node_name):
                self._createNode()
                count = cmds.getAttr(self.node_name + '.cmdCount')
            else:
                raise

        cmds.setAttr(self.node_name + '.cmdCount', count + 1)

        # Append the command to the end of the undo queue.
        self.undo_queue.append(cmdObj)

        # Clear the redo queue.
        self.redo_queue = []

        # Re-enable the callback.
        self.cb_enabled = True

    def execute(self, cmdObj, *args):
        # Execute the command object's 'doIt' method.
        res = cmdObj.doIt(*args)
        self.append(cmdObj)
        return res

    def flushUndo( self, *args ):
        self.undo_queue = []
        self.redo_queue = []
        self.cb_enabled = False


apiUndo = ApiUndo()

class ApiUndoItem(object):
    """A simple class that reprsents an undo item to be undone or redone."""
    __slots__ = ['_setter', '_redo_args', '_undo_args', '_redo_kwargs',
                 '_undo_kwargs']
    def __init__(self, setter, redoArgs, undoArgs, redoKwargs=None,
                 undoKwargs=None):
        self._setter = setter
        self._redo_args = redoArgs
        self._undo_args = undoArgs
        if redoKwargs is None:
            redoKwargs = {}
        self._redo_kwargs = redoKwargs
        if undoKwargs is None:
            undoKwargs = {}
        self._undo_kwargs = undoKwargs

    def redoIt(self):
        self._setter(*self._redo_args, **self._redo_kwargs)
    doIt = redoIt

    def undoIt(self):
        self._setter(*self._undo_args, **self._undo_kwargs)


class ApiRedoUndoItem(ApiUndoItem):
    """Similar to the base ApiUndoItem, but allows specifying a separate
    function for the redoer and the undoer"""
    __slots__ = ['_undoer']
    def __init__(self, redoer, redoArgs, undoer, undoArgs, redoKwargs=None,
                 undoKwargs=None):
        super(ApiRedoUndoItem, self).__init__(redoer, redoArgs, undoArgs,
                                              redoKwargs=redoKwargs,
                                              undoKwargs=undoKwargs)
        self._undoer = undoer

    def undoIt(self):
        self._undoer(*self._undo_args, **self._undo_kwargs)

_DEBUG_API_WRAPS = False
if _DEBUG_API_WRAPS:
    _apiMethodWraps = {}

def wrapApiMethod( apiClass, methodName, newName=None, proxy=True, overloadIndex=None ):
    """
    create a wrapped, user-friendly API method that works the way a python method should: no MScriptUtil and
    no special API classes required.  Inputs go in the front door, and outputs come out the back door.


    Regarding Undo
    --------------

    The API provides many methods which are pairs -- one sets a value
    while the other one gets the value.  the naming convention of these
    methods follows a fairly consistent pattern.  so what I did was
    determine all the get and set pairs, which I can use to automatically
    register api undo items:  prior to setting something, we first *get*
    it's existing value, which we can later use to reset when undo is
    triggered.

    This API undo is only for PyMEL methods which are derived from API
    methods.  it's not meant to be used with plugins.  and since it just
    piggybacks maya's MEL undo system, it won't get cross-mojonated.

    Take `MFnTransform.setTranslation`, for example. PyMEL provides a wrapped copy of this as
    `Transform.setTranslation`.   when pymel.Transform.setTranslation is
    called, here's what happens in relation to undo:

        #. process input args, if any
        #. call MFnTransform.getTranslation() to get the current translation.
        #. append to the api undo queue, with necessary info to undo/redo
           later (the current method, the current args, and the current
           translation)
        #. call MFnTransform.setTranslation() with the passed args
        #. process result and return it


    :Parameters:

        apiClass : class
            the api class
        methodName : string
            the name of the api method
        newName : string
            optionally provided if a name other than that of api method is desired
        proxy : bool
            If True, then __apimfn__ function used to retrieve the proxy class. If False,
            then we assume that the class being wrapped inherits from the underlying api class.
        overloadIndex : None or int
            which of the overloaded C++ signatures to use as the basis of our wrapped function.


        """

    #getattr( api, apiClassName )

    apiClassName = apiClass.__name__
    try:
        method = getattr( apiClass, methodName )
    except AttributeError:
        return

    argHelper = ApiArgUtil(apiClassName, methodName, overloadIndex)
    undoable = True # controls whether we print a warning in the docs

    if newName is None:
        pymelName = argHelper.getPymelName()
    else:
        pymelName = newName

    if argHelper.canBeWrapped() :

        if argHelper.isDeprecated():
            _logger.debug("%s.%s is deprecated" % (apiClassName, methodName))
        inArgs = argHelper.inArgs()
        outArgs = argHelper.outArgs()
        argList = argHelper.argList()
        argInfo = argHelper.argInfo()

        getterArgHelper = argHelper.getGetterInfo()

        if argHelper.hasOutput() :
            getterInArgs = []
            # query method ( getter )
            #if argHelper.getGetterInfo() is not None:

            # temporarily supress this warning, until we get a deeper level
#            if getterArgHelper is not None:
#                _logger.warn( "%s.%s has an inverse %s, but it has outputs, which is not allowed for a 'setter'" % (
#                                                                            apiClassName, methodName, getterArgHelper.methodName ) )

        else:
            # edit method ( setter )
            if getterArgHelper is None:
                #_logger.debug( "%s.%s has no inverse: undo will not be supported" % ( apiClassName, methodName ) )
                getterInArgs = []
                undoable = False
            else:
                getterInArgs = getterArgHelper.inArgs()


        # create the function
        def wrappedApiFunc( self, *args ):
            do_args = []
            outTypeList = []

            undoEnabled = getterArgHelper is not None and cmds.undoInfo(q=1, state=1) and apiUndo.cb_enabled
            #outTypeIndex = []

            if len(args) != len(inArgs):
                raise TypeError, "%s() takes exactly %s arguments (%s given)" % ( methodName, len(inArgs), len(args) )

            # get the value we are about to set
            if undoEnabled:
                getterArgs = []  # args required to get the current state before setting it
                undo_args = []  # args required to reset back to the original (starting) state  ( aka "undo" )
                missingUndoIndices = [] # indices for undo args that are not shared with the setter and which need to be filled by the result of the getter
                inCount = 0
                for name, argtype, direction in argList :
                    if direction == 'in':
                        arg = args[inCount]
                        undo_args.append(arg)
                        if name in getterInArgs:
                            # gather up args that are required to get the current value we are about to set.
                            # these args are shared between getter and setter pairs
                            getterArgs.append(arg)
                            #undo_args.append(arg)
                        else:
                            # store the indices for
                            missingUndoIndices.append(inCount)
                            #undo_args.append(None)
                        inCount +=1

                getter = getattr( self, getterArgHelper.getPymelName() )
                setter = getattr( self, pymelName )

                try:
                    getterResult = getter( *getterArgs )
                except RuntimeError:
                    _logger.error( "the arguments at time of error were %r" % getterArgs)
                    raise

                # when a command returns results normally and passes additional outputs by reference, the result is returned as a tuple
                # otherwise, always as a list
                if not isinstance( getterResult, tuple ):
                    getterResult = (getterResult,)

                for index, result in zip(missingUndoIndices, getterResult ):
                    undo_args[index] = result


            inCount = totalCount = 0
            for name, argtype, direction in argList :
                if direction == 'in':
                    arg = args[inCount]
                    do_args.append( argHelper.castInput( name, arg, self.__class__ ) )
                    inCount +=1
                else:
                    val = argHelper.initReference(argtype)
                    do_args.append( val )
                    outTypeList.append( (argtype, totalCount) )
                    #outTypeIndex.append( totalCount )
                totalCount += 1


            if undoEnabled:
                undoItem = ApiUndoItem(setter, do_args, undo_args)
                apiUndo.append( undoItem )

            # Do final SafeApiPtr => 'true' ptr conversion
            final_do_args = []
            for arg in do_args:
                if isinstance(arg, api.SafeApiPtr):
                    final_do_args.append(arg())
                else:
                    final_do_args.append(arg)
            if argHelper.isStatic():
                result = method( *final_do_args )
            else:
                if proxy:
                    # due to the discrepancies between the API and Maya node hierarchies, our __apimfn__ might not be a
                    # subclass of the api class being wrapped, however, the api object can still be used with this mfn explicitly.
                    mfn = self.__apimfn__()
                    if not isinstance(mfn, apiClass):
                        mfn = apiClass( self.__apiobject__() )
                    result = method( mfn, *final_do_args )
                else:
                    result = method( self, *final_do_args )
            result = argHelper.castResult( self, result )

            if len(outArgs):
                if result is not None:
                    result = [result]
                else:
                    result = []

                for outType, index in outTypeList:
                    outArgVal = do_args[index]
                    res = argHelper.castReferenceResult( outType, outArgVal )
                    result.append( res )

                if len(result) == 1:
                    result = result[0]
                else:
                    result = tuple(result)
            return result

        wrappedApiFunc.__name__ = pymelName

        _addApiDocs( wrappedApiFunc, apiClass, methodName, overloadIndex, undoable )

        # format EnumValue defaults
        defaults = []
        for default in argHelper.getDefaults():
            if isinstance( default, util.EnumValue ):
                defaults.append( str(default) )
            else:
                defaults.append( default )

        if defaults:
            pass
            #_logger.debug("defaults: %s" % defaults)

        wrappedApiFunc = util.interface_wrapper( wrappedApiFunc, ['self'] + inArgs, defaults=defaults )
        wrappedApiFunc._argHelper = argHelper

        global _DEBUG_API_WRAPS
        if _DEBUG_API_WRAPS:
            import weakref
            global _apiMethodWraps
            classWraps = _apiMethodWraps.setdefault(apiClassName, {})
            methodWraps = classWraps.setdefault(methodName, [])
            methodWraps.append({'index':argHelper.methodIndex,
                                'funcRef':weakref.ref(wrappedApiFunc),
                               })

        # do the debug stuff before turning into a classmethod, because you
        # can't create weakrefs of classmethods (don't ask me why...)
        if argHelper.isStatic():
            wrappedApiFunc = classmethod(wrappedApiFunc)

        if argHelper.isDeprecated():
            beforeDeprecationWrapper = wrappedApiFunc
            def wrappedApiFunc(*args, **kwargs):
                import warnings
                warnings.warn("%s.%s is deprecated" % (apiClassName,
                                                       methodName),
                              DeprecationWarning, stacklevel=2)
                beforeDeprecationWrapper(*args, **kwargs)
        return wrappedApiFunc

def addApiDocs(apiClass, methodName, overloadIndex=None, undoable=True):
    """decorator for adding API docs"""

    def doc_decorator(func):
        return _addApiDocs( func, apiClass, methodName, overloadIndex, undoable)

    return doc_decorator

def _addApiDocs( wrappedApiFunc, apiClass, methodName, overloadIndex=None, undoable=True):

    util.addLazyDocString( wrappedApiFunc, addApiDocsCallback, apiClass, methodName, overloadIndex, undoable, wrappedApiFunc.__doc__ )
    return wrappedApiFunc

def addApiDocsCallback( apiClass, methodName, overloadIndex=None, undoable=True, origDocstring=''):
    apiClassName = apiClass.__name__

    argHelper = ApiArgUtil(apiClassName, methodName, overloadIndex)
    inArgs = argHelper.inArgs()
    outArgs = argHelper.outArgs()
    argList = argHelper.argList()
    argInfo = argHelper.argInfo()

    def formatDocstring(type):
        """
        convert
        "['one', 'two', 'three', ['1', '2', '3']]"
        to
        "[`one`, `two`, `three`, [`1`, `2`, `3`]]"
        """
        if not isinstance(type, list):
            pymelType = ApiTypeRegister.types.get(type,type)
        else:
            pymelType = type

        if isinstance(pymelType, apicache.ApiEnum):
            pymelType = pymelType.pymelName()

        doc = repr(pymelType).replace("'", "`")
        if type in ApiTypeRegister.arrayItemTypes.keys():
            doc += ' list'
        return doc

    # Docstrings
    docstring = argHelper.getMethodDocs()
    # api is no longer in specific units, it respect UI units like MEL
    docstring = docstring.replace( 'centimeter', 'linear unit' )
    docstring = docstring.replace( 'radian', 'angular unit' )

    S = '    '
    if len(inArgs):
        docstring += '\n\n:Parameters:\n'
        for name in inArgs :
            info = argInfo[name]
            type = info['type']
            typeStr = formatDocstring(type)

            docstring += S + '%s : %s\n' % (name, typeStr )
            docstring += S*2 + '%s\n' % (info['doc'])
            if isinstance( type, apicache.ApiEnum ):
                apiClassName, enumName = type
                enumValues = apiClassInfo[apiClassName]['pymelEnums'][enumName].keys()
                docstring += '\n' + S*2 + 'values: %s\n' % ', '.join( [ '%r' % x for x in enumValues if x not in ['invalid', 'last' ] ] )



    # Results doc strings
    results = []
    returnType = argHelper.getReturnType()
    if returnType:
        rtype = formatDocstring(returnType)
        results.append( rtype )
    for argname in outArgs:
        rtype = argInfo[argname]['type']
        rtype = formatDocstring(rtype)
        results.append( rtype )

    if len(results) == 1:
        results = results[0]
        docstring += '\n\n:rtype: %s\n' % results
    elif results:
        docstring += '\n\n:rtype: (%s)\n' %  ', '.join(results)

    docstring += '\nDerived from api method `%s.%s.%s`\n' % (apiClass.__module__, apiClassName, methodName)
    if not undoable:
        docstring += '\n**Undo is not currently supported for this method**\n'

    if origDocstring:
        docstring = origDocstring + '\n' + docstring

    return docstring

class MetaMayaTypeWrapper(util.metaReadOnlyAttr) :
    """ A metaclass to wrap Maya api types, with support for class constants """

    _originalApiSetAttrs = {}

    class ClassConstant(object):
        """Class constant"""
        def __init__(self, value):
            self.value = value
        def __repr__(self):
            return '%s.%s(%s)' % ( self.__class__.__module__,  self.__class__.__name__, repr(self.value) )
        def __str__(self):
            return self.__repr__()
        def __get__(self, instance, owner):
            # purposedly authorize notation MColor.blue but not MColor().blue,
            # the constants are a class property and are not defined on instances
            if instance is None :
                # note that conversion to the correct type is done here
                return owner(self.value)
            else :
                raise AttributeError, "Class constants on %s are only defined on the class" % (owner.__name__)
        def __set__(self, instance, value):
            raise AttributeError, "class constant cannot be set"
        def __delete__(self, instance):
            raise AttributeError, "class constant cannot be deleted"

    def __new__(cls, classname, bases, classdict):
        """ Create a new class of metaClassConstants type """

        #_logger.debug( 'MetaMayaTypeWrapper: %s' % classname )
        removeAttrs = []
        # define __slots__ if not defined
        if '__slots__' not in classdict :
            classdict['__slots__'] = ()
        try:
            apicls = classdict['apicls']
            proxy=False
        except KeyError:
            try:
                apicls = classdict['__apicls__']
                proxy=True
            except KeyError:
                apicls = None

        if apicls is not None:
            if apicls.__name__ not in apiClassNamesToPyNodeNames:
                #_logger.debug("ADDING %s to %s" % (apicls.__name__, classname))
                apiClassNamesToPyNodeNames[apicls.__name__] = classname

            if not proxy and apicls not in bases:
                #_logger.debug("ADDING BASE %s" % classdict['apicls'])
                bases = bases + (classdict['apicls'],)
            try:
                classInfo = apiClassInfo[apicls.__name__]
            except KeyError:
                _logger.info("No api information for api class %s" % ( apicls.__name__ ))
            else:
                #------------------------
                # API Wrap
                #------------------------

                # Find out methods herited from other bases than apicls to avoid
                # unwanted overloading
                herited = {}
                for base in bases :
                    if base is not apicls :
                        # basemro = inspect.getmro(base)
                        for attr in dir(base) :
                            if attr not in herited :
                                herited[attr] = base

                ##_logger.debug("Methods info: %(methods)s" % classInfo)
                # Class Methods
                for methodName, info in classInfo['methods'].items():
                    # don't rewrap if already herited from a base class that is not the apicls
                    #_logger.debug("Checking method %s" % (methodName))

                    try:
                        pymelName = info[0]['pymelName']
                        removeAttrs.append(methodName)
                    except KeyError:
                        pymelName = methodName

#                    if classname == 'DependNode' and pymelName in ('setName','getName'):
#                        raise Exception('debug')

                    pymelName, data = _getApiOverrideNameAndData( classname, pymelName )

                    overloadIndex = data.get( 'overloadIndex', None )

                    assert isinstance( pymelName, str ), "%s.%s: %r is not a valid name" % ( classname, methodName, pymelName)

                    # TODO: some methods are being wrapped for the base class,
                    # and all their children - ie, MFnTransform.transformation()
                    # gets wrapped for Transform, Place3dTexture,
                    # HikGroundPlane, etc...
                    # Figure out why this happens, and stop it!
                    if pymelName not in herited:
                        if overloadIndex is not None:
                            if data.get('enabled', True):
                                if pymelName not in classdict:
                                    #_logger.debug("%s.%s autowrapping %s.%s usng proxy %r" % (classname, pymelName, apicls.__name__, methodName, proxy))
                                    method = wrapApiMethod( apicls, methodName, newName=pymelName, proxy=proxy, overloadIndex=overloadIndex )
                                    if method:
                                        #_logger.debug("%s.%s successfully created" % (classname, pymelName ))
                                        classdict[pymelName] = method
                                    #else: #_logger.debug("%s.%s: wrapApiMethod failed to create method" % (apicls.__name__, methodName ))
                                #else: #_logger.debug("%s.%s: skipping" % (apicls.__name__, methodName ))
                            #else: #_logger.debug("%s.%s has been manually disabled, skipping" % (apicls.__name__, methodName))
                        #else: #_logger.debug("%s.%s has no wrappable methods, skipping" % (apicls.__name__, methodName))
                    #else: #_logger.debug("%s.%s already herited from %s, skipping" % (apicls.__name__, methodName, herited[pymelName]))

                if 'pymelEnums' in classInfo:
                    # Enumerators

                    for enumName, enum in classInfo['pymelEnums'].items():
                        classdict[enumName] = enum


            if not proxy:
                #if removeAttrs:
                #    #_logger.debug( "%s: removing attributes %s" % (classname, removeAttrs) )
                def __getattribute__(self, name):
                    #_logger.debug(name )
                    if name in removeAttrs and name not in EXCLUDE_METHODS: # tmp fix
                        #_logger.debug("raising error")
                        raise AttributeError, "'"+classname+"' object has no attribute '"+name+"'"
                    #_logger.debug("getting from %s" % bases[0])
                    # newcls will be defined by the time this is called...
                    return super(newcls, self).__getattribute__(name)

                classdict['__getattribute__'] = __getattribute__

                if cls._hasApiSetAttrBug(apicls):
                    # correct the setAttr bug by wrapping the api's
                    # __setattr__ to handle data descriptors...
                    origSetAttr = apicls.__setattr__
                    # in case we need to restore the original setattr later...
                    # ... as we do in a test for this bug!
                    cls._originalApiSetAttrs[apicls] = origSetAttr
                    def apiSetAttrWrap(self, name, value):
                        if hasattr(self.__class__, name):
                            if hasattr(getattr(self.__class__, name), '__set__'):
                                # we've got a data descriptor with a __set__...
                                # don't use the apicls's __setattr__
                                return super(apicls, self).__setattr__(name, value)
                        return origSetAttr(self, name, value)
                    apicls.__setattr__ = apiSetAttrWrap


        # create the new class
        newcls = super(MetaMayaTypeWrapper, cls).__new__(cls, classname, bases, classdict)

        # shortcut for ensuring that our class constants are the same type as the class we are creating
        def makeClassConstant(attr):
            try:
                # return MetaMayaTypeWrapper.ClassConstant(newcls(attr))
                return MetaMayaTypeWrapper.ClassConstant(attr)
            except Exception, e:
                _logger.warn( "Failed creating %s class constant (%s): %s" % (classname, attr, e) )
        #------------------------
        # Class Constants
        #------------------------
        if hasattr(newcls, 'apicls') :
            # type (api type) used for the storage of data
            apicls  = newcls.apicls
            if apicls is not None:
                # build some constants on the class
                constant = {}
                # constants in class definition will be converted from api class to created class
                for name, attr in newcls.__dict__.iteritems() :
                    # to add the wrapped api class constants as attributes on the wrapping class,
                    # convert them to own class
                    if isinstance(attr, apicls) :
                        if name not in constant :
                            constant[name] = makeClassConstant(attr)
                # we'll need the api clas dict to automate some of the wrapping
                # can't get argspec on SWIG creation function of type built-in or we could automate more of the wrapping
                apiDict = dict(inspect.getmembers(apicls))
                # defining class properties on the created class
                for name, attr in apiDict.iteritems() :
                    # to add the wrapped api class constants as attributes on the wrapping class,
                    # convert them to own class
                    if isinstance(attr, apicls) :
                        if name not in constant :
                            constant[name] = makeClassConstant(attr)
                # update the constant dict with herited constants
                mro = inspect.getmro(newcls)
                for parentCls in mro :
                    if isinstance(parentCls, MetaMayaTypeWrapper) :
                        for name, attr in parentCls.__dict__.iteritems() :
                            if isinstance(attr, MetaMayaTypeWrapper.ClassConstant) :
                                if not name in constant :
                                    constant[name] = makeClassConstant(attr.value)

                # build the protected list to make some class ifo and the constants read only class attributes
                # new.__slots__ = ['_data', '_shape', '_ndim', '_size']
                # type.__setattr__(newcls, '__slots__', slots)

                # set class constants as readonly
#                readonly = newcls.__readonly__
#                if 'apicls' not in readonly :
#                    readonly['apicls'] = None
#                for c in constant.keys() :
#                    readonly[c] = None
#                type.__setattr__(newcls, '__readonly__', readonly)
                # store constants as class attributes
                for name, attr in constant.iteritems() :
                    type.__setattr__(newcls, name, attr)

            #else :   raise TypeError, "must define 'apicls' in the class definition (which Maya API class to wrap)"


        if hasattr(newcls, 'apicls') and not ApiTypeRegister.isRegistered(newcls.apicls.__name__):
            ApiTypeRegister.register( newcls.apicls.__name__, newcls )

        return newcls

    @classmethod
    def _hasApiSetAttrBug(cls, apiClass):
        """
        Maya has a bug on windows where some api objects have a __setattr__
        that bypasses properties (and other data descriptors).

        This tests if the given apiClass has such a bug.
        """
        class MyClass1(object):
            def __init__(self):
                self._bar = 'not set'
            def _setBar(self, val):
                self._bar = val
            def _getBar(self):
                return self._bar
            bar = property(_getBar, _setBar)

        class MyClass2(MyClass1, apiClass): pass

        foo2 = MyClass2()
        foo2.bar = 7
        # Here, on windows, MMatrix's __setattr__ takes over, and
        # (after presumabably determining it didn't need to do
        # whatever special case thing it was designed to do)
        # instead of calling the super's __setattr__, which would
        # use the property, inserts it into the object's __dict__
        # manually
        return bool(foo2.bar != 7)

class _MetaMayaCommandWrapper(MetaMayaTypeWrapper):
    """
    A metaclass for creating classes based on a maya command.

    Not intended to be used directly; instead, use the descendants: MetaMayaNodeWrapper, MetaMayaUIWrapper
    """

    _classDictKeyForMelCmd = None

    def __new__(cls, classname, bases, classdict):
        #_logger.debug( '_MetaMayaCommandWrapper: %s' % classname )

        newcls = super(_MetaMayaCommandWrapper, cls).__new__(cls, classname, bases, classdict)

        #-------------------------
        #   MEL Methods
        #-------------------------
        melCmdName, infoCmd = cls.getMelCmd(classdict)

        classdict = {}
        try:
            cmdInfo = cmdlist[melCmdName]
        except KeyError:
            pass
            #_logger.debug("No MEL command info available for %s" % melCmdName)
        else:
            pmSourceFunc = False
            try:
                cmdModule = __import__( 'pymel.core.' + cmdInfo['type'] , globals(), locals(), [''])
                func = getattr(cmdModule, melCmdName)
                pmSourceFunc = True
            except (AttributeError, TypeError):
                func = getattr(pmcmds,melCmdName)

            # add documentation
            classdict['__doc__'] = util.LazyDocString( (newcls, cls.docstring, (melCmdName,), {} ) )
            classdict['__melcmd__'] = staticmethod(func)
            classdict['__melcmdname__'] = melCmdName
            classdict['__melcmd_isinfo__'] = infoCmd

            filterAttrs = ['name', 'getName', 'setName'] + classdict.keys()
            filterAttrs += overrideMethods.get( bases[0].__name__ , [] )
            #filterAttrs += newcls.__dict__.keys()

            parentClasses = [ x.__name__ for x in inspect.getmro( newcls )[1:] ]
            for flag, flagInfo in cmdInfo['flags'].items():
                # don't create methods for query or edit, or for flags which only serve to modify other flags
                if flag in ['query', 'edit'] or 'modified' in flagInfo:
                    continue


                if flagInfo.has_key('modes'):
                    # flags which are not in maya docs will have not have a modes list unless they
                    # have passed through testNodeCmds
                    #continue
                    modes = flagInfo['modes']

                    # query command
                    if 'query' in modes:
                        methodName = 'get' + util.capitalize(flag)
                        classToMelMap[classname].append( methodName )

                        if methodName not in filterAttrs and \
                                ( not hasattr(newcls, methodName) or cls.isMelMethod(methodName, parentClasses) ):

                            # 'enabled' refers to whether the API version of this method will be used.
                            # if the method is enabled that means we skip it here.
                            if (not apiToMelData.has_key((classname,methodName))
                                    or apiToMelData[(classname,methodName)].get('melEnabled',False)
                                    or not apiToMelData[(classname,methodName)].get('enabled',True)):
                                returnFunc = None

                                if flagInfo.get( 'resultNeedsCasting', False):
                                    returnFunc = flagInfo['args']

                                # don't unpack if the source i
                                if (flagInfo.get( 'resultNeedsUnpacking', False)
                                        and not pmSourceFunc):
                                    if returnFunc:
                                        # can't do:
                                        #   returnFunc = lambda x: returnFunc(x[0])
                                        # ... as this would create a recursive function!
                                        origReturnFunc = returnFunc
                                        returnFunc = lambda x: origReturnFunc(x[0])
                                    else:
                                        returnFunc = lambda x: x[0]

                                wrappedMelFunc = makeQueryFlagMethod( func, flag, methodName,
                                     returnFunc=returnFunc )

                                #_logger.debug("Adding mel derived method %s.%s()" % (classname, methodName))
                                classdict[methodName] = wrappedMelFunc
                            #else: #_logger.debug(("skipping mel derived method %s.%s(): manually disabled or overridden by API" % (classname, methodName)))
                        #else: #_logger.debug(("skipping mel derived method %s.%s(): already exists" % (classname, methodName)))
                    # edit command:
                    if 'edit' in modes or ( infoCmd and 'create' in modes ):
                        # if there is a corresponding query we use the 'set' prefix.
                        if 'query' in modes:
                            methodName = 'set' + util.capitalize(flag)
                        #if there is not a matching 'set' and 'get' pair, we use the flag name as the method name
                        else:
                            methodName = flag

                        classToMelMap[classname].append( methodName )

                        if methodName not in filterAttrs and \
                                ( not hasattr(newcls, methodName) or cls.isMelMethod(methodName, parentClasses) ):
                            if not apiToMelData.has_key((classname,methodName)) \
                                or apiToMelData[(classname,methodName)].get('melEnabled',False) \
                                or not apiToMelData[(classname,methodName)].get('enabled', True):
                                #FIXME: shouldn't we be able to use the wrapped pymel command, which is already fixed?
                                fixedFunc = fixCallbacks( func, melCmdName )

                                wrappedMelFunc = makeEditFlagMethod( fixedFunc, flag, methodName)
                                #_logger.debug("Adding mel derived method %s.%s()" % (classname, methodName))
                                classdict[methodName] = wrappedMelFunc
                            #else: #_logger.debug(("skipping mel derived method %s.%s(): manually disabled" % (classname, methodName)))
                        #else: #_logger.debug(("skipping mel derived method %s.%s(): already exists" % (classname, methodName)))

        for name, attr in classdict.iteritems() :
            type.__setattr__(newcls, name, attr)

        return newcls

    @classmethod
    def getMelCmd(cls, classdict):
        """
        Retrieves the name of the mel command the generated class wraps, and whether it is an info command.

        Intended to be overridden in derived metaclasses.
        """
        return util.uncapitalize(cls.__name__), False

    @classmethod
    def isMelMethod(cls, methodName, parentClassList):
        """
        Deteremine if the passed method name exists on a parent class as a mel method
        """
        for classname in parentClassList:
            if methodName in classToMelMap[classname]:
                return True
        return False

    @classmethod
    def docstring(cls, melCmdName):
        try:
            cmdInfo = cmdlist[melCmdName]
        except KeyError:
            #_logger.debug("No MEL command info available for %s" % melCmdName)
            classdoc = ''
        else:
            loadCmdDocCache()
            classdoc = 'class counterpart of mel function `%s`\n\n%s\n\n' % (melCmdName, cmdInfo['description'])
        return classdoc

class MetaMayaNodeWrapper(_MetaMayaCommandWrapper) :
    """
    A metaclass for creating classes based on node type.  Methods will be added to the new classes
    based on info parsed from the docs on their command counterparts.
    """
    def __new__(cls, classname, bases, classdict):
        # If the class explicitly gives it's mel node name, use that - otherwise, assume it's
        # the name of the PyNode, uncapitalized
        #_logger.debug( 'MetaMayaNodeWrapper: %s' % classname )
        nodeType = classdict.get('__melnode__')

        if nodeType is None:
            # check for a virtual class...
            if '_isVirtual' in classdict or any(hasattr(b, '_isVirtual')
                                                for b in bases):
                for b in bases:
                    if hasattr(b, '__melnode__'):
                        nodeType = b.__melnode__
                        break
                else:
                    raise RuntimeError("Could not determine mel node type for virtual class %r" % classname)
            else:
                # not a virtual class, just use the classname
                nodeType = util.uncapitalize(classname)
            classdict['__melnode__'] = nodeType

        addMayaType( nodeType )
        apicls = toApiFunctionSet( nodeType )
        if apicls is not None:
            classdict['__apicls__'] = apicls

        PyNodeType = super(MetaMayaNodeWrapper, cls).__new__(cls, classname, bases, classdict)
        ParentPyNode = [x for x in bases if issubclass(x, util.ProxyUnicode)]
        assert len(ParentPyNode), "%s did not have exactly one parent PyNode: %s (%s)" % (classname, ParentPyNode, bases)
        addPyNodeType( PyNodeType, ParentPyNode )
        return PyNodeType


    @classmethod
    def getMelCmd(cls, classdict):
        """
        Retrieves the name of the mel command for the node that the generated class wraps,
        and whether it is an info command.

        Derives the command name from the mel node name - so '__melnode__' must already be set
        in classdict.
        """
        nodeType = classdict['__melnode__']
        infoCmd = False
        try:
            nodeCmd = cmdcache.nodeTypeToNodeCommand[ nodeType ]
        except KeyError:
            try:
                nodeCmd = nodeTypeToInfoCommand[ nodeType ]
                infoCmd = True
            except KeyError:
                nodeCmd = nodeType
        return nodeCmd, infoCmd


class MetaMayaUIWrapper(_MetaMayaCommandWrapper):
    """
    A metaclass for creating classes based on on a maya UI type/command.
    """

    def __new__(cls, classname, bases, classdict):
        # If the class explicitly gives it's mel ui command name, use that - otherwise, assume it's
        # the name of the PyNode, uncapitalized
        uiType= classdict.setdefault('__melui__', util.uncapitalize(classname))

        # TODO: implement a option at the cmdlist level that triggers listForNone
        # TODO: create labelArray for *Grp ui elements, which passes to the correct arg ( labelArray3, labelArray4, etc ) based on length of passed array

        return super(MetaMayaUIWrapper, cls).__new__(cls, classname, bases, classdict)

    @classmethod
    def getMelCmd(cls, classdict):
        return classdict['__melui__'], False

class MetaMayaComponentWrapper(MetaMayaTypeWrapper):
    """
    A metaclass for creating components.
    """
    def __new__(cls, classname, bases, classdict):
        newcls = super(MetaMayaComponentWrapper, cls).__new__(cls, classname, bases, classdict)
        apienum = getattr(newcls, '_apienum__', None)
#        print "addng new component %s - '%s' (%r):" % (newcls, classname, classdict),
        if apienum:
            if apienum not in apiEnumsToPyComponents:
                apiEnumsToPyComponents[apienum] = [newcls]
            else:
                oldEntries = apiEnumsToPyComponents[apienum]

                # if the apienum is already present, check if this class is a
                # subclass of an already present class
                newEntries  = []
                for oldEntry in oldEntries:
                    for base in bases:
                        if issubclass(base, oldEntry):
                            break
                    else:
                        newEntries.append(oldEntry)
                newEntries.append(newcls)
                apiEnumsToPyComponents[apienum] = newEntries
        return newcls


def addPyNodeCallback( dynModule, mayaType, pyNodeTypeName, parentPyNodeTypeName, extraAttrs=None):
    #_logger.debug( "%s(%s): creating" % (pyNodeTypeName,parentPyNodeTypeName) )
    try:
        ParentPyNode = getattr( dynModule, parentPyNodeTypeName )
    except AttributeError:
        _logger.debug("error creating class %s: parent class %r not in dynModule %s" % (pyNodeTypeName, parentPyNodeTypeName, dynModule.__name__))
        return

    classDict = {'__melnode__':mayaType}
    if extraAttrs:
        classDict.update(extraAttrs)
    if pyNodeTypeName in pyNodeNamesToPyNodes:
        PyNodeType = pyNodeNamesToPyNodes[pyNodeTypeName]
    else:
        try:
            PyNodeType = MetaMayaNodeWrapper(pyNodeTypeName, (ParentPyNode,), classDict)
        except TypeError, msg:
            # for the error: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases
            _logger.error("Could not create new PyNode: %s(%s): %s" % (pyNodeTypeName, ParentPyNode.__name__, msg ))
            import new
            PyNodeType = new.classobj(pyNodeTypeName, (ParentPyNode,), {})
            #_logger.debug(("Created new PyNode: %s(%s)" % (pyNodeTypeName, parentPyNodeTypeName)))

        PyNodeType.__module__ = dynModule.__name__
    setattr( dynModule, pyNodeTypeName, PyNodeType )
    return PyNodeType

def addCustomPyNode(dynModule, mayaType, extraAttrs=None):
    """
    create a PyNode, also adding each member in the given maya node's inheritance if it does not exist.

    This function is used for creating PyNodes via plugins, where the nodes parent's might be abstract
    types not yet created by pymel.  also, this function ensures that the newly created node types are
    added to pymel.all, if that module has been imported.

    """
    try:
        inheritance = apicache.getInheritance( mayaType )
    except apicache.ManipNodeTypeError:
        _logger.debug( "could not create a PyNode for manipulator type %s" % mayaType)
        return
    except Exception:
        import traceback
        _logger.debug(traceback.format_exc())
        inheritance = None

    if not inheritance or not util.isIterable(inheritance):
        _logger.warn( "could not get inheritance for mayaType %s" % mayaType)
    else:
        #__logger.debug(mayaType, inheritance)
        #__logger.debug("adding new node:", mayaType, apiEnum, inheritence)
        # some nodes in the hierarchy for this node might not exist, so we cycle through all
        parent = 'dependNode'

        for node in inheritance:
            nodeName = addPyNode( dynModule, node, parent, extraAttrs=extraAttrs )
            parent = node
            if 'pymel.all' in sys.modules:
                # getattr forces loading of Lazy object
                setattr( sys.modules['pymel.all'], nodeName, getattr(dynModule,nodeName) )

def addPyNode( dynModule, mayaType, parentMayaType, extraAttrs=None ):
    """
    create a PyNode type for a maya node.
    """

    #_logger.debug("addPyNode adding %s->%s on dynModule %s" % (mayaType, parentMayaType, dynModule))
    # unicode is not liked by metaNode
    pyNodeTypeName = str( util.capitalize(mayaType) )
    parentPyNodeTypeName = str(util.capitalize(parentMayaType))

    # If pymel.all is loaded, we will need to get the actual node in order to
    # store it on pymel.all, so in that case don't bother with the lazy-loading
    # behavior...
    if 'pymel.all' in sys.modules:
        newType = addPyNodeCallback( dynModule, mayaType, pyNodeTypeName, parentPyNodeTypeName, extraAttrs )
        setattr( sys.modules['pymel.all'], pyNodeTypeName, newType )
    # otherwise, do the lazy-loading thing
    else:
        try:
            dynModule[pyNodeTypeName]
        except KeyError:
            #_logger.info( "%s(%s): setting up lazy loading" % ( pyNodeTypeName, parentPyNodeTypeName ) )
            dynModule[pyNodeTypeName] = ( addPyNodeCallback,
                                       ( dynModule, mayaType, pyNodeTypeName, parentPyNodeTypeName, extraAttrs ) )
    return pyNodeTypeName

def removePyNode( dynModule, mayaType ):
    pyNodeTypeName = str( util.capitalize(mayaType) )
    removePyNodeType( pyNodeTypeName )

    _logger.debug('removing %s from %s' % (pyNodeTypeName, dynModule.__name__))
    dynModule.__dict__.pop(pyNodeTypeName,None)

    # delete the lazy loader too, so it does not regenerate the object
    # Note - even doing a 'hasattr' will trigger the lazy loader, so just
    # delete blind!
    try:
        delattr(dynModule.__class__, pyNodeTypeName)
    except Exception:
        pass
    if 'pymel.all' in sys.modules:
        try:
            delattr(sys.modules['pymel.all'], pyNodeTypeName)
        except AttributeError:
            pass
    removeMayaType( mayaType )

def addPyNodeType( pyNodeType, parentPyNode ):
    pyNodeNamesToPyNodes[pyNodeType.__name__] = pyNodeType
    pyNodeTypesHierarchy[pyNodeType] = parentPyNode

def removePyNodeType( pyNodeTypeName ):
    pyNodeType = pyNodeNamesToPyNodes.pop( pyNodeTypeName, None )
    pyNodeTypesHierarchy.pop( pyNodeType, None )

def clearPyNodeTypes():
    pyNodeNamesToPyNodes.clear()
    pyNodeTypesHierarchy.clear()

def addMayaType(mayaType, apiType=None):
    """ Add a type to the MayaTypes lists. Fill as many dictionary caches as we have info for.

        - mayaTypesToApiTypes
        - mayaTypesToApiEnums
    """
    if apiType is None:
        apiType = mayaTypeToApiType(mayaType)

    global _apiCacheInst
    _apiCacheInst.addMayaType(mayaType, apiType, globals())
    _setApiCacheGlobals()

def removeMayaType(mayaType):
    """ Remove a type from the MayaTypes lists.

        - mayaTypesToApiTypes
        - mayaTypesToApiEnums
    """
    global _apiCacheInst
    _apiCacheInst.removeMayaType(mayaType, globals())
    _setApiCacheGlobals()

VirtualClassInfo = util.namedtuple('VirtualClassInfo',
            'vclass parent nameRequired isVirtual preCreate create postCreate')

class VirtualClassError(Exception): pass

class VirtualClassManager(object):
    # these methods are particularly dangerous to override, so we prohibit it...

    # ...note that I don't know of any SPECIFIC problems with __init__ and
    # __new__... but we formerly disabled (nearly) all double-underscore
    # methods, and I THINK one of the main culprits was __init__ and __new__.
    # (At the very least, if they wanted to allow new args, the user would have
    # to modify both, because of the limitation in python that __new__ cannot
    # modify the args passed to __init__.)  If there is a great demand for
    # allowing __init__/__new__, we may remove these from the list...

    # __str__ is obviously dangerous, since in places the assumption is
    # essentially made that str(node) == node.name()...
    INVALID_ATTRS = set(['__init__', '__new__', '__str__'])

    def __init__(self):
        self._byVirtualClass = {}
        self._byParentClass = util.defaultdict(list)

    def register( self, vclass, nameRequired=False, isVirtual='_isVirtual',
                  preCreate='_preCreateVirtual',
                  create='_createVirtual',
                  postCreate='_postCreateVirtual', ):
        """Register a new virtual class

        Allows a user to create their own subclasses of leaf PyMEL node classes,
        which are returned by `general.PyNode` and all other pymel commands.

        The process is fairly simple:
            1.  Subclass a PyNode class.  Be sure that it is a leaf class,
                meaning that it represents an actual Maya node type and not an
                abstract type higher up in the hierarchy.
            2.  Add an _isVirtual classmethod that accepts two arguments: an
                MObject/MDagPath instance for the current object, and its name.
                It should return True if the current object meets the
                requirements to become the virtual subclass, or else False.
            3.  Add optional _preCreate, _create, and _postCreate methods.  For
                more on these, see below
            4.  Register your subclass by calling
                factories.registerVirtualClass. If the _isVirtual callback
                requires the name of the object, set the keyword argument
                nameRequired to True. The object's name is not always
                immediately available and may take an extra calculation to
                retrieve, so if nameRequired is not set the name argument
                passed to your callback could be None.

        The creation of custom nodes may be customized with the use of
        isVirtual, preCreate, create, and postCreate functions; these are
        functions (or classmethods) which are called before / during / after
        creating the node.

        The isVirtual method is required - it is the callback used on instances
        of the base (ie, 'real') objects to determine whether they should be
        considered an instance of this virtual class. It's input is an MObject
        and an optional name (if nameRequired is set to True). It should return
        True to indicate that the given object is 'of this class', False
        otherwise. PyMEL code should not be used inside the callback, only API
        and maya.cmds. Keep in mind that once your new type is registered, its
        test will be run every time a node of its parent type is returned as a
        PyMEL node class, so be sure to keep your tests simple and fast.

        The preCreate function is called prior to node creation and gives you a
        chance to modify the kwargs dictionary; they are fed the kwargs fed to
        the creation command, and return either 1 or 2 dictionaries; the first
        dictionary is the one actually passed to the creation command; the
        second, if present, is passed to the postCreate command.

        The create method can be used to override the 'default' node creation
        command;  it is given the kwargs given on node creation (possibly
        altered by the preCreate), and must return the string name of the
        created node. (...or any another type of object (such as an MObject),
        as long as the postCreate and class.__init__ support it.)

        The postCreate function is called after creating the new node, and
        gives you a chance to modify it.  The method is passed the PyNode of
        the newly created node, as well as the second dictionary returned from
        the preCreate function as kwargs (if it was returned). You can use
        PyMEL code here, but you should avoid creating any new nodes.

        By default, any method named '_isVirtual', '_preCreateVirtual',
        '_createVirtual', or '_postCreateVirtual' on the class is used; if
        present, these must be classmethods or staticmethods.

        Other methods / functions may be used by passing a string or callable
        to the preCreate / postCreate kwargs.  If a string, then the method
        with that name on the class is used; it should be a classmethod or
        staticmethod present at the time it is registered.

        The value None may also be passed to any of these args (except isVirtual)
        to signal that no function is to be used for these purposes.

        If more than one subclass is registered for a node type, the registered
        callbacks will be run newest to oldest until one returns True. If no
        test returns True, then the standard node class is used. Also, for each
        base node type, if there is already a virtual class registered with the
        same name and module, then it is removed. (This helps alleviate
        registered callbacks from piling up if, for instance, a module is
        reloaded.)

        Overriding methods of PyMEL base classes should be performed with care,
        because certain methods are used internally and altering their results
        may cause PyMEL to error or behave unpredictably.  This is particularly
        true for special methods like __setattr__, __getattr__, __setstate__,
        __getstate__, etc.  Some methods are considered too dangerous to modify,
        and registration will fail if the user defines an override for them;
        this set includes __init__, __new__, and __str__.

        For a usage example, see examples/customClasses.py

        :parameters:
        nameRequired : `bool`
            True if the _isVirtual callback requires the string name to operate
            on. The object's name is not always immediately avaiable and may
            take an extra calculation to retrieve.
        isVirtual: `str` or callable
            the function to determine whether an MObject is an instance of this
            class; should take an MObject and name, returns True / or False
        preCreate: `str` or callable
            the function used to modify kwargs before being passed to the
            creation function
        create: `str` or callable
            function to use instead of the standard node creation method;
            takes whatever args are given to the cl
        postCreate: `str` or callable
            the function used to modify the PyNode after it is created.
        """
        if isinstance(isVirtual, basestring):
            isVirtual = getattr(vclass, isVirtual, None)
        if isinstance(preCreate, basestring):
            preCreate = getattr(vclass, preCreate, None)
        if isinstance(create, basestring):
            create = getattr(vclass, create, None)
        if isinstance(postCreate, basestring):
            postCreate = getattr(vclass, postCreate, None)

        # assert that we are a leaf class
        parentCls = None
        for each_cls in inspect.getmro(vclass):
            # we've reached a pymel node. we're done
            if each_cls.__module__.startswith('pymel.core'):
                parentCls = each_cls
                break
            else:
                # it's a custom class: test for disallowed attributes
                badAttrs = self.INVALID_ATTRS.intersection(each_cls.__dict__)
                if badAttrs:
                    raise ValueError, 'invalid attribute name(s) %s: these special attributes are not allowed on virtual nodes' % ', '.join(badAttrs)

        assert parentCls, "passed class must be a subclass of a PyNode type"
        #assert issubclass( vclass, parentCls ), "%s must be a subclass of %s" % ( vclass, parentCls )

        vclass.__melnode__ = parentCls.__melnode__

        # filter out any pre-existing classes with the same name / module as
        # this one, because leaving stale callbacks in the list will slow things
        # down
        for vClassInfo in self._byParentClass[parentCls]:
            otherVcls = vClassInfo.vclass
            if otherVcls.__name__ == vclass.__name__ and otherVcls.__module__ == vclass.__module__:
                self.unregister(otherVcls)

        #TODO:
        # inspect callbacks to ensure proper number of args and kwargs ( create callback must support **kwargs )
        # ensure that the name of our node does not conflict with a real node

        vClassInfo = VirtualClassInfo(vclass, parentCls, nameRequired, isVirtual, preCreate, create, postCreate)
        self._byParentClass[parentCls].append( vClassInfo )
        self._byVirtualClass[vclass] = vClassInfo

    def unregister(self, vcls):
        try:
            vClassInfo = self._byVirtualClass.pop(vcls)
        except KeyError:
            raise VirtualClassError('%r was not registered as a virtual class' % vcls)
        self._byParentClass[vClassInfo.parent].remove(vClassInfo)

    def getVirtualClass(self, baseClass, obj, name=None, fnDepend=None):
        '''Returns the virtual class to use for the given baseClass + obj, or
        the original baseClass if no virtual class matches.
        '''
        vClasses = self._byParentClass.get(baseClass)
        if not vClasses:
            return baseClass
        for vClassInfo in reversed(vClasses):
            if vClassInfo.nameRequired and name is None:
                if fnDepend is None:
                    fnDepend = api.MFnDependencyNode(obj)
                name = fnDepend.name()

            if vClassInfo.isVirtual(obj, name):
                return vClassInfo.vclass
        return baseClass

    def getVirtualClassInfo(self, vclass):
        '''Given a virtual class, returns it's registered VirtualClassInfo
        '''
        return self._byVirtualClass.get(vclass)

virtualClasses = VirtualClassManager()

# for backwards compatibility + ease of access
registerVirtualClass = virtualClasses.register

#-------------------------------------------------------------------------------

def isValidPyNode (arg):
    return pyNodeTypesHierarchy.has_key(arg)

def isValidPyNodeName (arg):
    return pyNodeNamesToPyNodes.has_key(arg)

def toApiTypeStr( obj, default=None ):
    if isinstance( obj, int ):
        return apiEnumsToApiTypes.get( obj, default )
    elif isinstance( obj, basestring ):
        return mayaTypesToApiTypes.get( obj, default)
    elif isinstance( obj, util.ProxyUnicode ):
        mayaType = getattr( obj, '__melnode__', None)
        return mayaTypesToApiTypes.get( mayaType, default)

def toApiTypeEnum( obj, default=None ):
    if isinstance( obj, util.ProxyUnicode ):
        obj = getattr( obj, '__melnode__', default )
    try:
        return apiTypesToApiEnums[obj]
    except KeyError:
        return mayaTypesToApiEnums.get(obj, default)

def toApiFunctionSet( obj ):
    if isinstance( obj, basestring ):
        try:
            return apiTypesToApiClasses[ obj ]
        except KeyError:
            if obj in mayaTypesToApiTypes:
                mayaType = obj
                apiType = mayaTypesToApiTypes[obj]
                return _apiCacheInst._getOrSetApiClass(apiType, mayaType)
            else:
                return None
    elif isinstance( obj, int ):
        try:
            return apiTypesToApiClasses[ apiEnumsToApiTypes[ obj ] ]
        except KeyError:
            return None

def apiClassNameToPymelClassName(apiName, allowGuess=True):
    '''Given the name of an api class, such as MFnTransform, MSpace, MAngle,
    returns the name of the corresponding pymel class.

    If allowGuessing, and we cannot find a registered type that matches, will
    try to do string parsing to guess the pymel name.

    Returns None if it was unable to determine the name.
    '''
    pymelName = apiClassNamesToPyNodeNames.get(apiName, None)
    if pymelName is None:
        if allowGuess:
            try:
                pymelName = ApiTypeRegister.getPymelType(apiName)
            except Exception:
                pass
        else:
            pymelName = ApiTypeRegister.types.get(apiName, None)
    return pymelName

# get the API type from a maya type
def mayaTypeToApiType(mayaType) :
    """ Get the Maya API type from the name of a Maya type """
    try:
        return mayaTypesToApiTypes[mayaType]
    except KeyError:
        apiType = None
        if versions.current() >= versions.v2012:
            import pymel.api.plugins as plugins
            try:
                inheritance = apicache.getInheritance(mayaType,
                                                      checkManip3D=False)
            except Exception:
                inheritance = None
            if inheritance:
                for mayaType in reversed(inheritance[:-1]):
                    apiType = mayaTypesToApiTypes.get(mayaType)
                    if apiType:
                        break

        if not apiType:
            apiType = 'kInvalid'
            # we need to actually create the obj to query it...
            with apicache._GhostObjMaker(mayaType) as obj:
                if obj is not None and api.isValidMObject(obj):
                    apiType = obj.apiTypeStr()
        mayaTypesToApiTypes[mayaType] = apiType
        return apiType

def isMayaType(mayaType):
    '''Whether the given type is a currently-defined maya node name
    '''
    # using objectType instead of MNodeClass or nodeType(isTypeName) because
    # it's available < 2012
    return bool(cmds.objectType(tagFromType=mayaType))

# Keep around for debugging/info gathering...
def getComponentTypes():
    # WTF is kMeshFaceVertComponent?? it doesn't inherit from MFnComponent,
    # and there's also a kMeshVtxFaceComponent (which does)??
    mfnCompBase = api.MFnComponent()
    mfnCompTypes = (api.MFnSingleIndexedComponent(),
                    api.MFnDoubleIndexedComponent(),
                    api.MFnTripleIndexedComponent())
    # Maya 2008 and before didn't haveMFnUint64SingleIndexedComponent
    if hasattr(api.MFn, 'kUint64SingleIndexedComponent'):
        mfnCompTypes += (api.MFnUint64SingleIndexedComponent(),)

    componentTypes = {}
    for compType in mfnCompTypes + (mfnCompBase,):
        componentTypes[compType.type()] = []

    for apiEnum in apiEnumsToApiTypes:
        if mfnCompBase.hasObj(apiEnum):
            for compType in mfnCompTypes:
                if compType.hasObj(apiEnum):
                    break
            else:
                compType = mfnCompBase
            componentTypes[compType.type()].append(apiEnum)

    return componentTypes

########NEW FILE########
__FILENAME__ = parsers
import re, os.path, platform
from HTMLParser import HTMLParser
import pymel.util as util
import pymel.versions as versions
import plogging
from pymel.mayautils import getMayaLocation

try:
    from pymel.util.external.BeautifulSoup import BeautifulSoup, NavigableString
except ImportError:
    from BeautifulSoup import BeautifulSoup, NavigableString
from keyword import iskeyword as _iskeyword

FLAGMODES = ('create', 'query', 'edit', 'multiuse')

_logger = plogging.getLogger(__name__)

def mayaIsRunning():
    """
    Returns True if maya.cmds have  False otherwise.

    Early in interactive startup it is possible for commands to exist but for Maya to not yet be initialized.

    :rtype: bool
    """

    # Implementation is essentially just a wrapper for getRunningMayaVersionString -
    # this function was included for clearer / more readable code

    try :
        from maya.cmds import about
        about(version=True)
        return True
    except :
        return False

def mayaDocsLocation(version=None):
    docLocation = os.environ.get('MAYA_DOC_DIR')

    if (not docLocation and (version is None or version == versions.installName() )
            and mayaIsRunning()):
        # Return the doc location for the running version of maya
        from maya.cmds import showHelp
        docLocation = showHelp("", q=True, docs=True)

        # Older implementations had no trailing slash, but the result returned by
        # showHelp has a trailing slash... so eliminate any trailing slashes for
        # consistency
        while docLocation != "" and os.path.basename(docLocation) == "":
            docLocation = os.path.dirname(docLocation)

    # Want the docs for a different version, or maya isn't initialized yet
    if not docLocation or not os.path.isdir(docLocation):
        docBaseDir = os.environ.get('MAYA_DOC_BASE_DIR')
        if not docBaseDir:
            docBaseDir = getMayaLocation(version) # use original version
            if docBaseDir is None and version is not None:
                docBaseDir = getMayaLocation(None)
                _logger.warning("Could not find an installed Maya for exact version %s, using first installed Maya location found in %s" % (version, docBaseDir) )

            if platform.system() == 'Darwin':
                docBaseDir = os.path.dirname(os.path.dirname(docBaseDir))
            docBaseDir = os.path.join(docBaseDir, 'docs')

        if version:
            short_version = versions.parseVersionStr(version, extension=False)
        else:
            short_version = versions.shortName()
        docLocation = os.path.join(docBaseDir , 'Maya%s' % short_version, 'en_US')

    return os.path.realpath(docLocation)

#---------------------------------------------------------------
#        Doc Parser
#---------------------------------------------------------------
class CommandDocParser(HTMLParser):

    def __init__(self, command):
        self.command = command
        self.flags = {}  # shortname, args, docstring, and a list of modes (i.e. edit, create, query)
        self.currFlag = ''
        # iData is used to track which type of data we are putting into flags, and corresponds with self.datatypes
        self.iData = 0
        self.pcount = 0
        self.active = False  # this is set once we reach the portion of the document that we want to parse
        self.description = ''
        self.example = ''
        self.emptyModeFlags = [] # when flags are in a sequence ( lable1, label2, label3 ), only the last flag has queryedit modes. we must gather them up and fill them when the last one ends
        HTMLParser.__init__(self)

    def __repr__(self):
        return '%s(%r)' % (self.__class__.__name__, self.command)

    def startFlag(self, data):
        #_logger.debug(self, data)
        #assert data == self.currFlag
        self.iData = 0
        self.flags[self.currFlag] = {'longname': self.currFlag, 'shortname': None, 'args': None,
                                     'numArgs': None, 'docstring': '', 'modes': [] }

    def addFlagData(self, data):
        # encode our non-unicode 'data' string to unicode
        data = data.decode('utf-8')
        # now saftely encode it to non-unicode ascii, ignorning unknown characters
        data = data.encode('ascii', 'ignore')
        # Shortname
        if self.iData == 0:
            self.flags[self.currFlag]['shortname'] = data.lstrip('-\r\n')

        # Arguments
        elif self.iData == 1:
            typemap = {
             'string'  : unicode,
             'float'   : float,
             'double'  : float,
             'linear'  : float,
             'angle'   : float,
             'int'     : int,
             'uint'    : int,
             'int64'   : int,
             'index'   : int,
             'integer'  : int,
             'boolean'  : bool,
             'script'   : 'script',
             'name'     : 'PyNode',
             'select'   : 'PyNode',
             'time'     : 'time',
             'timerange': 'timerange',
             'floatrange':'floatrange',
             '...'      : '...' # means that there is a variable number of args. we don't do anything with this yet
            }
            args = [x.strip() for x in data.replace('[', '').replace(']', '').split(',') if x.strip()]
            for i, arg in enumerate(args):
                if arg not in typemap:
                    _logger.error("%s: %s: unknown arg type %r" % (self, self.currFlag, arg))
                else:
                    args[i] = typemap[arg]
            numArgs = len(args)
            if numArgs == 0:
                args = bool
                #numArgs = 1
                # numArgs will stay at 0, which is the number of mel arguments.
                # this flag should be renamed to numMelArgs
            elif numArgs == 1:
                args = args[0]

            self.flags[self.currFlag]['args'] = args
            self.flags[self.currFlag]['numArgs'] = numArgs

        # Docstring
        else:
            #self.flags[self.currFlag]['docstring'] += data.replace( '\r\n', ' ' ).strip() + " "
            data = data.replace( 'In query mode, this flag needs a value.', '' )
            data = data.replace( 'Flag can appear in Create mode of command', '' )
            data = data.replace( 'Flag can appear in Edit mode of command', '' )
            data = data.replace( 'Flag can appear in Query mode of command', '' )
            data = data.replace( '\r\n', ' ' ).lstrip()
            data = data.replace( '\n', ' ' ).lstrip()
            data = data.strip('{}\t')
            data = data.replace('*', '\*') # for reStructuredText
            self.flags[self.currFlag]['docstring'] += data
        self.iData += 1

    def endFlag(self):
        # cleanup last flag
        #data = self.flags[self.currFlag]['docstring']

        #_logger.debug(("ASSERT", data.pop(0), self.currFlag))
        try:
            if not self.flags[self.currFlag]['modes']:
                self.emptyModeFlags.append(self.currFlag)
            elif self.emptyModeFlags:
                    #_logger.debug("past empty flags:", self.command, self.emptyModeFlags, self.currFlag)
                    basename = re.match( '([a-zA-Z]+)', self.currFlag ).groups()[0]
                    modes = self.flags[self.currFlag]['modes']
                    self.emptyModeFlags.reverse()
                    for flag in self.emptyModeFlags:
                        if re.match( '([a-zA-Z]+)', flag ).groups()[0] == basename:
                            self.flags[flag]['modes'] = modes
                        else:
                            break

                    self.emptyModeFlags = []
        except KeyError, msg:
            pass
            #_logger.debug(self.currFlag, msg)

    def handle_starttag(self, tag, attrs):
        #_logger.debug("begin: %s tag: %s" % (tag, attrs))
        attrmap = dict(attrs)
        if not self.active:
            if tag == 'a':
                name = attrmap.get('name', None)
                if name == 'hFlags':
                    #_logger.debug('ACTIVE')
                    self.active = 'flag'
                elif name == 'hExamples':
                    #_logger.debug("start examples")
                    self.active = 'examples'
        elif tag == 'a' and 'name' in attrmap:
            self.endFlag()
            newFlag = attrmap['name'][4:]
            newFlag = newFlag.lstrip('-')
            self.currFlag = newFlag
            self.iData = 0
            #_logger.debug("NEW FLAG", attrs)
            #self.currFlag = attrs[0][1][4:]

        elif tag == 'img':
            mode = attrmap.get('title', None)
            if mode in FLAGMODES:
                #_logger.debug("MODES", attrs[1][1])
                self.flags[self.currFlag]['modes'].append(mode)
        elif tag == 'h2':
            self.active = False

    def handle_endtag(self, tag):
        #if tag == 'p' and self.active == 'command': self.active = False
        #_logger.debug("end: %s" % tag)
        if not self.active:
            if tag == 'p':
                if self.pcount == 3:
                    self.active = 'command'
                else:
                    self.pcount += 1
        elif self.active == 'examples' and tag == 'pre':
            self.active = False

    def handle_entityref(self,name):
        if self.active == 'examples':
            self.example += r'"'

    def handle_data(self, data):
        if not self.active:
            return
        elif self.active == 'flag':
            if self.currFlag:
                stripped = data.strip()
                if stripped == 'Return value':
                    self.active=False
                    return

                if data and stripped and stripped not in ['(',')', '=', '], [']:
                    #_logger.debug("DATA", data)

                    if self.currFlag in self.flags:
                        self.addFlagData(data)
                    else:
                        self.startFlag(data)
        elif self.active == 'command':
            data = data.replace( '\r\n', ' ' )
            data = data.replace( '\n', ' ' )
            data = data.lstrip()
            data = data.strip('{}')
            data = data.replace('*', '\*') # for reStructuredText
            if '{' not in data and '}' not in data:
                self.description += data
            #_logger.debug(data)
            #self.active = False
        elif self.active == 'examples' and data != 'Python examples':
            #_logger.debug("Example\n")
            #_logger.debug(data)
            data = data.replace( '\r\n', '\n' )
            self.example += data
            #self.active = False


# class MayaDocsLoc(str) :
#    """ Path to the Maya docs, cached at pymel start """
#    __metaclass__ = util.Singleton

# TODO : cache doc location or it's evaluated for each getCmdInfo !
# MayaDocsLoc(mayaDocsLocation())

class NodeHierarchyDocParser(HTMLParser):

    def parse(self):
        docloc = mayaDocsLocation(self.version)
        if not os.path.isdir( docloc ):
            raise IOError, "Cannot find maya documentation. Expected to find it at %s" % docloc

        f = open( os.path.join( docloc , 'Nodes/index_hierarchy.html' ) )
        try:
            rawdata = f.read()
        finally:
            f.close()

        if versions.v2011 <= versions.current() < versions.v2012:
            # The maya 2011 doc doesn't parse correctly with HTMLParser - the
            # '< < <' lines get left out.  Use beautiful soup instead.
            soup = BeautifulSoup( rawdata, convertEntities='html' )
            for tag in soup.findAll(['tt', 'a']):
                # piggypack on current handle_starttag / handle_data
                self.handle_starttag(tag.name, tag.attrs)
                data = tag.string
                if data is not None:
                    self.handle_data(data)
        else:
            self.feed( rawdata )
        return self.tree

    def __init__(self, version=None):
        self.version = version
        self.currentTag = None
        self.depth = 0
        self.lastDepth = -1
        self.tree = None
        self.currentLeaves = []

        HTMLParser.__init__(self)
    def handle_starttag(self, tag, attrs):
        #_logger.debug("%s - %s" % (tag, attrs))
        self.currentTag = tag

    def handle_data(self, data):
        _logger.debug("data %r" % data)
        if self.currentTag == 'tt':
            self.depth = data.count('>')
            #_logger.debug("lastDepth: %s - depth: %s" % (self.lastDepth, self.depth))

        elif self.currentTag == 'a':
            data = data.lstrip()

            if self.depth == 0:
                if self.tree is None:
                    #_logger.debug("starting brand new tree: %s %s" % (self.depth, data))
                    self.tree = [data]
                else:
                    #_logger.debug("skipping %s", data)
                    return

            elif self.depth == self.lastDepth and self.depth > 0:
                #_logger.debug("adding to current level", self.depth, data)
                self.tree[ self.depth ].append( data )

            elif self.depth > self.lastDepth:
                #_logger.debug("starting new level: %s %s" % (self.depth, data))
                self.tree.append( [data] )

            elif self.depth < self.lastDepth:

                    for i in range(0, self.lastDepth-self.depth):
                        branch = self.tree.pop()
                        #_logger.debug("closing level %s - %s - %s" % (self.lastDepth, self.depth, self.tree[-1]))
                        currTree = self.tree[-1]
                        #if isinstance(currTree, list):
                        currTree.append( branch )
                        #else:
                        #    _logger.info("skipping", data)
                        #    self.close()
                        #    return

                    #_logger.debug("adding to level", self.depth, data)
                    self.tree[ self.depth ].append( data )
            else:
                return
            self.lastDepth = self.depth
            # with 2009 and the addition of the MPxNode, the hierarchy closes all the way out ( i.e. no  >'s )
            # this prevents the depth from getting set properly. as a workaround, we'll set it to 0 here,
            # then if we encounter '> >' we set the appropriate depth, otherwise it defaults to 0.
            self.depth = 0


def printTree( tree, depth=0 ):
    for branch in tree:
        if util.isIterable(branch):
            printTree( branch, depth+1)
        else:
            _logger.info('%s %s' % ('> '*depth,  branch))


class CommandModuleDocParser(HTMLParser):

    def parse(self):

        f = open( os.path.join( self.docloc , 'Commands/cat_' + self.category + '.html' ) )
        self.feed( f.read() )
        f.close()
        return self.cmdList

    def __init__(self, category, version=None ):
        self.cmdList = []
        self.category = category
        self.version = version

        docloc = mayaDocsLocation( '2009' if self.version=='2008' else self.version)
        self.docloc = docloc
        HTMLParser.__init__(self)

    def handle_starttag(self, tag, attrs):
        try:
            attrs = attrs[0]
            #_logger.debug(attrs)
            if tag == 'a' and attrs[0]=='href':
                cmd = attrs[1].split("'")[1].split('.')[0]
                self.cmdList.append( cmd )
                #_logger.debug(cmd)
        except IndexError: return

class ApiDocParser(object):
    OBSOLETE_MSG = ['NO SCRIPT SUPPORT.', 'This method is not available in Python.']
    DEPRECATED_MSG = ['This method is obsolete.', 'Deprecated:']

    # in enums with multiple keys per int value, which (pymel) key name to use
    # as the default - ie, in MSpace, both object and preTransformed map to 2;
    # since 'object' is in PYMEL_ENUM_DEFAULTS['Space'], that is preferred
    PYMEL_ENUM_DEFAULTS = {'Space':('object',)}

    def __init__(self, apiModule, version=None, verbose=False, enumClass=tuple,
                 docLocation=None):
        self.version = versions.installName() if version is None else version
        self.apiModule = apiModule
        self.verbose = verbose
        if docLocation is None:
            docLocation = mayaDocsLocation('2009' if self.version=='2008' else self.version)
        self.docloc = docLocation
        self.enumClass = enumClass
        if not os.path.isdir(self.docloc):
            raise IOError, "Cannot find maya documentation. Expected to find it at %s" % self.docloc

        self.enums = {}
        self.pymelEnums = {}
        self.methods=util.defaultdict(list)
        self.currentMethod=None
        self.badEnums = []

    def formatMsg(self, *args):
        return self.apiClassName + '.' + self.currentMethod + ': ' + ' '.join( [ str(x) for x in args ] )

    def xprint(self, *args):
        if self.verbose:
            print self.formatMsg(*args)

    def getPymelMethodNames(self):


        setReg = re.compile('set([A-Z].*)')

        allFnMembers = self.methods.keys()
        pymelNames = {}
        pairs = {}
        pairsList = []

        def addSetGetPair(setmethod, getMethod):
            pairsList.append( (setMethod,getMethod) )
            # pair 'set' with 'is/get'
            pairs[setMethod] = getMethod
            for info in self.methods[setMethod]:
                info['inverse'] = (getMethod, True)

            # pair 'is/get' with 'set'
            pairs[getMethod] = setMethod
            for info in self.methods[getMethod]:
                info['inverse'] = (setMethod, False)

        for member in allFnMembers:
            m = setReg.match(member)
            if m:
                # MFn api naming convention usually uses setValue(), value() convention for its set and get methods, respectively
                # setSomething()  &  something()  becomes  setSomething() & getSomething()
                # setIsSomething() & isSomething() becomes setSomething() & isSomething()
                basename = m.group(1)
                origGetMethod = util.uncapitalize(basename)
                setMethod = member  # for name clarity
                if origGetMethod in allFnMembers:
                    # fix set
                    if re.match( 'is[A-Z].*', origGetMethod):
                        newSetMethod = 'set' + origGetMethod[2:] # remove 'is' #member[5:]
                        pymelNames[setMethod] = newSetMethod
                        for info in self.methods[setMethod]:
                            info['pymelName'] = newSetMethod
                        addSetGetPair( setMethod, origGetMethod)


                    # fix get
                    else:
                        newGetMethod = 'g' + setMethod[1:] # remove 's'
                        pymelNames[origGetMethod] = newGetMethod
                        for info in self.methods[origGetMethod]:
                            info['pymelName'] = newGetMethod
                        addSetGetPair( setMethod, origGetMethod)


                else:
                    getMethod = 'get' + basename
                    isMethod = 'is' + basename
                    if getMethod in allFnMembers:
                        addSetGetPair( setMethod, getMethod )
                    elif isMethod in allFnMembers:
                        addSetGetPair( setMethod, isMethod )

        return pymelNames, pairsList



    def getClassFilename(self):
        filename = 'class'
        for tok in re.split( '([A-Z][a-z]*)', self.apiClassName ):
            if tok:
                if tok[0].isupper():
                    filename += '_' + tok.lower()
                else:
                    filename += tok
        return filename

    _capitalizedRe = re.compile('([A-Z0-9][a-z0-9]*)')

    def _apiEnumNamesToPymelEnumNames(self, apiEnumNames):
        """remove all common prefixes from list of enum values"""
        if isinstance(apiEnumNames, util.Enum):
            apiEnumNames = apiEnumNames._keys.keys()
        if len(apiEnumNames) > 1:
            # We first aim to remove all similar 'camel-case-group' prefixes, ie:
            # if our enums look like:
            #    kFooBar
            #    kFooSomeThing
            #    kFooBunnies
            # we want to get Bar, SomeThing, Bunnies

            # {'kFooBar':0, 'kFooSomeThing':1}
            #     => [['k', 'Foo', 'Some', 'Thing'], ['k', 'Foo', 'Bar']]
            splitEnums = [ [ y for y in self._capitalizedRe.split( x ) if y ] for x in apiEnumNames ]

            # [['k', 'Invalid'], ['k', 'Pre', 'Transform']]
            #     => [('k', 'k'), ('Foo', 'Foo'), ('Some', 'Bar')]
            splitZip = zip( *splitEnums )
            for partList in splitZip:
                if  tuple([partList[0]]*len(partList)) == partList:
                    [ x.pop(0) for x in splitEnums ]
                else: break
            # splitEnums == [['Some', 'Thing'], ['Bar']]

            joinedEnums = [ util.uncapitalize(''.join(x), preserveAcronymns=True ) for x in splitEnums]
            for i, enum in enumerate(joinedEnums):
                if _iskeyword(enum):
                    joinedEnums[i] = enum+'_'
                    self.xprint( "bad enum", enum )
                elif enum[0].isdigit():
                    joinedEnums[i] = 'k' + enum
                    self.xprint( "bad enum", enum )

                    #print joinedEnums
                    #print enumList
                    #break

            return dict(zip(apiEnumNames, joinedEnums))
        else:
            # if only 1 name or less, name is unaltered
            return dict((name, name) for name in apiEnumNames)

    def _apiEnumToPymelEnum(self, apiEnum, apiToPymelNames=None):
        defaultsSet = self.PYMEL_ENUM_DEFAULTS.get(apiEnum.name, set())
        defaults = {}
        if apiToPymelNames is None:
            apiToPymelNames = self._apiEnumNamesToPymelEnumNames(apiEnum)
        pymelKeyDict = {}
        docs = dict(apiEnum._docs)
        for apiName, val in apiEnum._keys.iteritems():
            # want to include docs, so make dict (key, doc) => val
            pymelKeyDict[apiName] = val
            pymelName = apiToPymelNames[apiName]
            pymelKeyDict[pymelName] = val

            doc = apiEnum._docs.get(apiName)
            if doc:
                docs[pymelName] = doc

            # in the pymel dict, the pymel name should always be the default
            # key for a value... but the original dict may also have multiple
            # keys for a value... so:
            #   if there is an entry in PYMEL_ENUM_DEFAULTS for this
            #     class/pymelName, then use that as the default
            #   otherwise, use the pymel equivalent of whatever the original
            #     api default was
            if (pymelName in defaultsSet
                    # need to check val not in defaults, or else we can override
                    # a value set due to defaultsSet
                    or (val not in defaults and apiName == apiEnum.getKey(val))):
                defaults[val] = pymelName
        return util.Enum(apiEnum.name, pymelKeyDict, multiKeys=True,
                         defaultKeys=defaults)

    def handleEnums( self, type ):
        missingTypes = ['MUint64']
        otherTypes = ['void', 'char', 'uchar',
                    'double', 'double2', 'double3', 'double4',
                    'float', 'float2', 'float3', 'float4',
                    'bool',
                    'int', 'int2', 'int3', 'int4',
                    'uint', 'uint2', 'uint3', 'uint4',
                    'short', 'short2', 'short3', 'short4',
                    'long', 'long2', 'long3',
                    'MString', 'MStringArray', 'MStatus']
        notTypes = ['MCallbackId']

        if type is None: return type

        # the enum is on another class
        if '::' in type:
            type = self.enumClass( type.split( '::') )

        # the enum is on this class
        elif type in self.enums:
            type = self.enumClass( [self.apiClassName, type] )

        elif type[0].isupper() and 'Ptr' not in type and not hasattr( self.apiModule, type ) and type not in otherTypes+missingTypes+notTypes:
            type = self.enumClass( [self.apiClassName, type] )
            if type not in self.badEnums:
                self.badEnums.append(type)
                _logger.warn( "Suspected Bad Enum: %s", type )
        else:
            type = str(type)
        return type

    def handleEnumDefaults( self, default, type ):

        if default is None: return default

        if isinstance( type, self.enumClass ):

            # the enum is on another class
            if '::' in default:
                apiClass, enumConst = default.split( '::')
                assert apiClass == type[0]
            else:
                enumConst = default

            return self.enumClass([type[0], type[1], enumConst])

        return default

    def getOperatorName(self, methodName):
        op = methodName[8:]
        #print "operator", methodName, op
        if op == '=':
            methodName = None
        else:

            methodName = {
                '*=' : '__rmult__',
                '*'  : '__mul__',
                '+=' : '__radd__',
                '+'  : '__add__',
                '-=' : '__rsub__',
                '-'  : '__sub__',
                '/=' : '__rdiv__',
                '/'  : '__div__',
                '==' : '__eq__',
                '!=' : '__neq__',
                '[]' : '__getitem__'}.get( op, None )
        return methodName

    def isSetMethod(self):
        if re.match( 'set[A-Z]', self.currentMethod ):
            return True
        else:
            return False

    def isGetMethod(self):
        if re.match( 'get[A-Z]', self.currentMethod ):
            return True
        else:
            return False

    def parseType(self, tokens):
        i=0
        for i, each in enumerate(tokens):
            if each not in [ '*', '&', 'const', 'unsigned']:
                argtype = tokens.pop(i)
                break
        else:
            # We didn't find any arg type - therefore everything
            # in buf is in the set('*', '&', 'const', 'unsigned')
            # ... so it's implicitly an unsigned int
            argtype = 'int'

        if 'unsigned' in tokens and argtype in ('char','int', 'int2',
                                             'int3', 'int4'):
            argtype = 'u' + argtype

        argtype = self.handleEnums(argtype)
        return argtype, tokens

    def parseTypes(self, proto):
        defaults={}
        names=[]
        types ={}
        typeQualifiers={}
        tmpTypes=[]
        # TYPES
        for paramtype in proto.findAll( 'td', **{'class':'paramtype'} ) :
            buf = []
            [ buf.extend(x.split()) for x in paramtype.findAll( text=True ) ] #if x.strip() not in ['', '*', '&', 'const', 'unsigned'] ]
            buf = [ x.strip().encode('ascii', 'ignore') for x in buf if x.strip() ]
            tmpTypes.append( self.parseType(buf) )

        # ARGUMENT NAMES
        i = 0
        for paramname in  proto.findAll( 'td', **{'class':'paramname'} )  :
            buf = [ x.strip().encode('ascii', 'ignore') for x in paramname.findAll( text=True ) if x.strip() not in['',','] ]
            if not buf: continue
            argname = buf[0]
            data = buf[1:]

            type, qualifiers = tmpTypes[i]
            default=None
            joined = ''.join(data).strip()

            if joined:
                joined = joined.encode('ascii', 'ignore')
                # break apart into index and defaults :  '[3] = NULL'
                brackets, default = re.search( '([^=]*)(?:\s*=\s*(.*))?', joined ).groups()

                if brackets:
                    numbuf = re.split( r'\[|\]', brackets)
                    if len(numbuf) > 1:
                        # Note that these two args need to be cast differently:
                        #   int2 foo;
                        #   int bar[2];
                        # ... so, instead of storing the type of both as
                        # 'int2', we make the second one 'int__array2'
                        type = type + '__array' + numbuf[1]
                    else:
                        print "this is not a bracketed number", repr(brackets), joined

                if default is not None:
                    try:
                        # Constants
                        default = {
                            'true' : True,
                            'false': False,
                            'NULL' : None
                        }[default]
                    except KeyError:
                        try:
                            if type in ['int', 'uint','long', 'uchar']:
                                default = int(default)
                            elif type in ['float', 'double']:
                                # '1.0 / 24.0'
                                if '/' in default:
                                    default = eval(default)
                                # '1.0e-5F'  --> '1.0e-5'
                                elif default.endswith('F'):
                                    default = float(default[:-1])
                                else:
                                    default = float(default)
                            else:
                                default = self.handleEnumDefaults(default, type)
                        except ValueError:
                            default = self.handleEnumDefaults(default, type)
                    # default must be set here, because 'NULL' may be set to back to None, but this is in fact the value we want
                    self.xprint('DEFAULT', default)
                    defaults[argname] = default

            types[argname] = type
            typeQualifiers[argname] = qualifiers
            names.append(argname)
            i+=1
        assert sorted(names) == sorted(types.keys()), 'name-type mismatch %s %s' %  (sorted(names), sorted(types.keys()) )
        return names, types, typeQualifiers, defaults

    def parseEnums(self, proto):
        enumValues={}
        enumDocs={}

        # get the doc portion...
        memdoc = proto.findNextSibling('div', 'memdoc')
        # ...then search through it's dl items, looking for one with text that
        # says "Enumerator"...
        enumRe = re.compile('Enumerator')
        for dl in memdoc.findAll('dl'):
            if dl.find(text=enumRe):
                break
        else:
            raise RuntimeError("couldn't find list of Enumerator items in enum %s" % self.currentMethod)
        # ...and each "em" in that should be the enumerator values...
        for em in dl.findAll('em'):
            enumKey = str(em.contents[-1])
            try:
                enumVal = getattr(self.apiClass, enumKey)
            except:
                _logger.warn( "%s.%s of enum %s does not exist" % ( self.apiClassName, enumKey, self.currentMethod))
                enumVal = None
            enumValues[ enumKey ] = enumVal
            # TODO:
            # do we want to feed the docstrings to the Enum object itself
            # (which seems to have support for docstrings)? Currently, we're
            # not...
            docItem = em.next.next.next.next.next

            if isinstance( docItem, NavigableString ):
                enumDocs[enumKey] = str(docItem).strip()
            else:
                enumDocs[enumKey] = str(docItem.contents[0]).strip()

        apiEnum = util.Enum(self.currentMethod, enumValues, multiKeys=True)
        apiToPymelNames = self._apiEnumNamesToPymelEnumNames(apiEnum)
        pymelEnum = self._apiEnumToPymelEnum(apiEnum,
                                             apiToPymelNames=apiToPymelNames)
        for apiName, pymelName in apiToPymelNames.iteritems():
            apiDoc = enumDocs.get(apiName)
            if apiDoc is not None:
                enumDocs[pymelName] = apiDoc

        enumInfo = {'values' : apiEnum,
                    'valueDocs' : enumDocs,

                      #'doc' : methodDoc
                    }
        return enumInfo, pymelEnum

    def isObsolete(self, proto):
        # ARGUMENT DIRECTION AND DOCUMENTATION
        addendum = proto.findNextSiblings( 'div', limit=1)[0]
        #try: self.xprint( addendum.findAll(text=True ) )
        #except: pass

        #if addendum.findAll( text = re.compile( '(This method is obsolete.)|(Deprecated:)') ):

        if addendum.findAll( text=lambda x: x in self.OBSOLETE_MSG ):
            self.xprint( "OBSOLETE" )
            self.currentMethod = None
            return True
        return False

    def parseMethodArgs(self, proto, returnType, names, types, typeQualifiers):
        directions={}
        docs={}
        deprecated = False
        returnDoc = ''

        addendum = proto.findNextSiblings( 'div', 'memdoc', limit=1)[0]
        #if self.currentMethod == 'createColorSet': raise NotImplementedError
        if addendum.findAll( text=lambda x: x in self.DEPRECATED_MSG ):
            self.xprint( "DEPRECATED" )
            #print self.apiClassName + '.' + self.currentMethod + ':' + ' DEPRECATED'
            deprecated = True

        methodDoc = addendum.p
        if methodDoc:
            methodDoc = ' '.join( methodDoc.findAll( text=True ) ).encode('ascii', 'ignore')
        else:
            methodDoc = ''

        tmpDirs = []
        tmpNames = []
        tmpDocs = []

        #extraInfo = addendum.dl.table
        #if self.version and int(self.version.split('-')[0]) < 2013:

        # 2012 introduced a new Doxygen version, which changed the api doc
        # format; also, even in 2013/2014, some pre-release builds of he docs
        # have used the pre-2012 format; so we can't just go by maya version...
        format2012 = self.doxygenVersion >= (1,7)

        if format2012:
            extraInfos = addendum.findAll('table', **{'class':'params'})
        else:
            #extraInfos = addendum.findAll(lambda tag: tag.name == 'table' and ('class', 'params') in tag.attrs)
            extraInfos = addendum.findAll(lambda tag: tag.name == 'dl' and ('class', 'return') not in tag.attrs and ('class', 'user') not in tag.attrs)
        if extraInfos:
            #print "NUMBER OF TABLES", len(extraInfos)
            if format2012:
                for extraInfo in extraInfos:
                    for tr in extraInfo.findAll('tr', recursive=False):
                        assert tr, "could not find name tr"
                        tds = tr.findAll('td', recursive=False)
                        assert tds, "could not find name td"
                        assert len(tds) == 3, "td list is unexpected length: %d" % len(tds)

                        paramDir = tds[0]
                        paramName = tds[1]

                        assert dict(paramDir.attrs).get('class') == 'paramdir', "First element in param table row was not a paramdir"
                        assert dict(paramName.attrs).get('class') == 'paramname', "Second element in param table row was not a paramname"

                        tmpDirs.append(paramDir.find(text=True).encode('ascii', 'ignore'))
                        tmpNames.append(paramName.find(text=True).encode('ascii', 'ignore'))
                        doc = ''.join(tds[2].findAll(text=True))
                        tmpDocs.append(doc.encode('ascii', 'ignore'))
            else:
                for extraInfo in extraInfos:
                    for tr in extraInfo.findAll( 'tr'):
                        assert tr, "could not find name tr"
                        tds = tr.findAll('td')
                        assert tds, "could not find name td"
                        assert len(tds) == 3, "td list is unexpected length: %d" % len(tds)

                        tt = tds[0].find('tt')
                        dir = tt.findAll( text=True, limit=1 )[0]
                        tmpDirs.append(dir.encode('ascii', 'ignore'))

                        name = tds[1].findAll( text=True, limit=1 )[0]
                        tmpNames.append(name.encode('ascii', 'ignore'))

                        doc = ''.join(tds[2].findAll( text=True))
                        tmpDocs.append(doc.encode('ascii', 'ignore'))

            assert len(tmpDirs) == len(tmpNames) == len(tmpDocs), \
                'names, types, and docs are of unequal lengths: %s vs. %s vs. %s' % (tmpDirs, tmpNames, tmpDocs)
            assert sorted(tmpNames) == sorted(typeQualifiers.keys()), 'name-typeQualifiers mismatch %s %s' %  (sorted(tmpNames), sorted(typeQualifiers.keys()) )
            #self.xprint(  sorted(tmpNames), sorted(typeQualifiers.keys()), sorted(typeQualifiers.keys()) )

            for name, dir, doc in zip(tmpNames, tmpDirs, tmpDocs) :
                if dir == '[in]':
                    # attempt to correct bad in/out docs
                    if re.search(r'\b([fF]ill|[sS]tor(age)|(ing))|([rR]esult)', doc ):
                        _logger.warn( "%s.%s(%s): Correcting suspected output argument '%s' based on doc '%s'" % (
                                                            self.apiClassName,self.currentMethod,', '.join(names), name, doc))
                        dir = 'out'
                    elif not re.match( 'set[A-Z]', self.currentMethod) and '&' in typeQualifiers[name] and types[name] in ['int', 'double', 'float', 'uint', 'uchar']:
                        _logger.warn( "%s.%s(%s): Correcting suspected output argument '%s' based on reference type '%s &' ('%s')'" % (
                                                            self.apiClassName,self.currentMethod,', '.join(names), name, types[name], doc))
                        dir = 'out'
                    else:
                        dir = 'in'
                elif dir == '[out]':
                    if types[name] == 'MAnimCurveChange':
                        _logger.warn( "%s.%s(%s): Setting MAnimCurveChange argument '%s' to an input arg (instead of output)" % (
                                                            self.apiClassName,self.currentMethod,', '.join(names), name))
                        dir = 'in'
                    else:
                        dir = 'out'
                elif dir == '[in,out]':
                    # it makes the most sense to treat these types as inputs
                    # maybe someday we can deal with dual-direction args...?
                    dir = 'in'
                else:
                    raise ValueError("direction must be either '[in]', '[out]', or '[in,out]'. got %r" % dir)

                assert name in names
                directions[name] = dir
                docs[name] = doc.replace('\n\r', ' ').replace('\n', ' ')


            # Documentation for Return Values
            if returnType:
                try:
                    returnDocBuf = addendum.findAll( 'dl', limit=1, **{'class':'return'} )[0].findAll( text=True )
                except IndexError:
                    pass
                else:
                    if returnDocBuf:
                        returnDoc = ''.join( returnDocBuf[1:] ).replace('\n\r', ' ').replace('\n', ' ').encode('ascii', 'ignore')
                    self.xprint(  'RETURN_DOC', repr(returnDoc)  )
        #assert len(names) == len(directions), "name lenght mismatch: %s %s" % (sorted(names), sorted(directions.keys()))
        return directions, docs, methodDoc, returnDoc, deprecated

    TYPEDEF_RE = re.compile('^typedef(\s|$)')

    def getMethodNameAndOutput(self, proto):
        # NAME AND RETURN TYPE
        memb = proto.find( 'td', **{'class':'memname'} )
        buf = []
        for text in memb.findAll(text=True):
            text = text.strip().encode('ascii', 'ignore')
            buf.extend(text.split())
        buf = [x for x in buf if x not in ['const', 'unsigned'] and x]

        assert buf, "could not parse a method name"

        methodName = returnType = returnQualifiers = None

        # typedefs aren't anything we care about (ie, may be a typedef of a
        # method - see MQtUtil.UITypeCreatorFn)
        if not self.TYPEDEF_RE.match(buf[0]):
            returnTypeToks = buf[:-1]
            methodName = buf[-1]

            methodName = methodName.split('::')[-1]
            returnType, returnQualifiers = self.parseType(returnTypeToks)

            # convert operators to python special methods
            if methodName.startswith('operator'):
                methodName = self.getOperatorName(methodName)
            else:
                #constructors and destructors
                if methodName.startswith('~') or methodName == self.apiClassName:
                    methodName = None
            # no MStatus in python
            if returnType in ['MStatus', 'void']:
                returnType = None

        return methodName, returnType, returnQualifiers

    DOXYGEN_VER_RE = re.compile('Generated by Doxygen ([0-9.]+)')

    def getDoxygenVersion(self, soup):
        doxyComment = soup.find(text=self.DOXYGEN_VER_RE)
        match = self.DOXYGEN_VER_RE.search(unicode(doxyComment))
        verStr = match.group(1)
        return tuple(int(x) for x in verStr.split('.'))

    def getClassPath(self):
        filename = self.getClassFilename() + '.html'
        apiBase = os.path.join(self.docloc , 'API')
        path = os.path.join(apiBase, filename)
        if not os.path.isfile(path):
            path = os.path.join(apiBase, 'cpp_ref', filename)
        return path

    def parseMethod(self, proto):
        methodName, returnType, returnQualifiers = self.getMethodNameAndOutput(proto)
        if methodName is None:
            return
        # convert to unicode
        self.currentMethod = str(methodName)
        try:
            if self.currentMethod == 'void(*':
                return
            # ENUMS
            if returnType == 'enum':
                self.xprint( "ENUM", returnType)
                #print returnType, methodName
                try:
                    #print enumList
                    enumData = self.parseEnums(proto)
                    self.enums[self.currentMethod] = enumData[0]
                    self.pymelEnums[self.currentMethod] = enumData[1]

                except AttributeError, msg:
                    _logger.error("FAILED ENUM: %s", msg)
                    import traceback
                    _logger.debug(traceback.format_exc())

            # ARGUMENTS
            else:
                self.xprint( "RETURN", returnType)

                # Static methods
                static = False
                try:
                    res = proto.findAll('code')
                    if res:
                        code = res[-1].string
                        if code and code.strip() == '[static]':
                            static = True
                except IndexError: pass

                if self.isObsolete(proto):
                    return

                names, types, typeQualifiers, defaults = self.parseTypes(proto)

                try:
                    directions, docs, methodDoc, returnDoc, deprecated = self.parseMethodArgs(proto, returnType, names, types, typeQualifiers)
                except AssertionError, msg:
                    _logger.error(self.formatMsg("FAILED", str(msg)))
                    return
                except AttributeError:
                    import traceback
                    _logger.error(self.formatMsg(traceback.format_exc()))
                    return

                argInfo={}
                argList=[]
                inArgs=[]
                outArgs=[]

                for argname in names[:] :
                    type = types[argname]
                    if argname not in directions:
                        self.xprint("Warning: assuming direction is 'in'")
                        directions[argname] = 'in'
                    direction = directions[argname]
                    doc = docs.get( argname, '')

                    if type == 'MStatus':
                        types.pop(argname)
                        defaults.pop(argname,None)
                        directions.pop(argname,None)
                        docs.pop(argname,None)
                        idx = names.index(argname)
                        names.pop(idx)
                    else:
                        if direction == 'in':
                            inArgs.append(argname)
                        else:
                            outArgs.append(argname)
                        argInfo[ argname ] = {'type': type, 'doc': doc }

                # correct bad outputs
                if self.isGetMethod() and not returnType and not outArgs:
                    for argname in names:
                        if '&' in typeQualifiers[argname]:
                            doc = docs.get(argname, '')
                            directions[argname] = 'out'
                            idx = inArgs.index(argname)
                            inArgs.pop(idx)
                            outArgs.append(argname)

                            _logger.warn( "%s.%s(%s): Correcting suspected output argument '%s' because there are no outputs and the method is prefixed with 'get' ('%s')" % (
                                                                           self.apiClassName,self.currentMethod, ', '.join(names), argname, doc))

                # now that the directions are correct, make the argList
                for argname in names:
                    type = types[argname]
                    self.xprint( "DIRECTIONS", directions )
                    direction = directions[argname]
                    data = ( argname, type, direction)
                    self.xprint( "ARG", data )
                    argList.append(  data )

                methodInfo = { 'argInfo': argInfo,
                              'returnInfo' : {'type' : returnType,
                                              'doc' : returnDoc,
                                              'qualifiers' : returnQualifiers},
                              'args' : argList,
                              'returnType' : returnType,
                              'inArgs' : inArgs,
                              'outArgs' : outArgs,
                              'doc' : methodDoc,
                              'defaults' : defaults,
                              #'directions' : directions,
                              'types' : types,
                              'static' : static,
                              'typeQualifiers' : typeQualifiers,
                              'deprecated' : deprecated }
                self.methods[self.currentMethod].append(methodInfo)
                return methodInfo
        finally:
            # reset
            self.currentMethod=None

    def setClass(self, apiClassName):
        self.enums = {}
        self.pymelEnums = {}
        self.methods=util.defaultdict(list)
        self.currentMethod=None
        self.badEnums = []

        self.apiClassName = apiClassName
        self.apiClass = getattr(self.apiModule, self.apiClassName)
        self.docfile = self.getClassPath()

        _logger.info( "parsing file %s" , self.docfile )

        with open( self.docfile ) as f:
            self.soup = BeautifulSoup( f.read(), convertEntities='html' )
        self.doxygenVersion = self.getDoxygenVersion(self.soup)

    def parse(self, apiClassName):
        self.setClass(apiClassName)
        for proto in self.soup.body.findAll( 'div', **{'class':'memproto'} ):
            self.parseMethod(proto)
        pymelNames, invertibles = self.getPymelMethodNames()
        return { 'methods' : dict(self.methods),
                 'enums' : self.enums,
                 'pymelEnums' : self.pymelEnums,
                 'pymelMethods' :  pymelNames,
                 'invertibles' : invertibles
                }

########NEW FILE########
__FILENAME__ = plogging
"pymel logging functions"
import sys, os

import logging
import logging.config
from logging import *
# The python 2.6 version of 'logging' hides these functions, so we need to import explcitly
from logging import getLevelName, root, info, debug, warning, error, critical
import ConfigParser

import maya
import pymel.util as util
import maya.utils
from maya.OpenMaya import MGlobal, MEventMessage, MMessage

from pymel.util.decoration import decorator


PYMEL_CONF_ENV_VAR = 'PYMEL_CONF'
PYMEL_LOGLEVEL_ENV_VAR = 'PYMEL_LOGLEVEL'
PYMEL_ERRORLEVEL_ENV_VAR = 'PYMEL_ERRORLEVEL'

#===============================================================================
# DEFAULT FORMAT SETUP
#===============================================================================

def _fixMayaOutput():
    if not hasattr( sys.stdout,"flush"):
        def flush(*args,**kwargs):
            pass
        try:
            sys.stdout.flush = flush
        except AttributeError:
            # second try
            #if hasattr(maya,"Output") and not hasattr(maya.Output,"flush"):
            class MayaOutput(maya.Output):
                def flush(*args,**kwargs):
                    pass
            maya.Output = MayaOutput()
            sys.stdout = maya.Output

_fixMayaOutput()

def getConfigFile():
    configFile = os.environ.get(PYMEL_CONF_ENV_VAR)
    if configFile and os.path.isfile(configFile):
        return configFile
    home = os.environ.get('HOME')
    if home:
        configFile = os.path.join( home, "pymel.conf")
        if os.path.isfile(configFile):
            return configFile
    moduleDir = os.path.dirname( os.path.dirname( sys.modules[__name__].__file__ ) )
    configFile = os.path.join(moduleDir,"pymel.conf")
    if os.path.isfile(configFile):
        return configFile
    raise IOError, "Could not find pymel.conf"

def getLogConfigFile():
    configFile = os.path.join(os.path.dirname(__file__),"user_logging.conf")
    if os.path.isfile(configFile):
        return configFile
    return getConfigFile()

assert hasattr(maya.utils, 'shellLogHandler'), "If you manually installed pymel, ensure " \
    "that pymel comes before Maya's site-packages directory on PYTHONPATH / sys.path.  " \
    "See pymel docs for more info."



#    Like logging.config.fileConfig, but intended only for pymel's loggers,
#    and less heavy handed - fileConfig will, for instance, wipe out all
#    handlers from logging._handlers, remove all handlers from logging.root, etc
def pymelLogFileConfig(fname, defaults=None, disable_existing_loggers=False):
    """
    Reads in a file to set up pymel's loggers.

    In most respects, this function behaves similarly to logging.config.fileConfig -
    consult it's help for details. In particular, the format of the config file
    must meet the same requirements - it must have the sections [loggers],
    [handlers], and [fomatters], and it must have an entry for [logger_root]...
    even if not options are set for it.

    It differs from logging.config.fileConfig in the following ways:

    1) It will not disable any pre-existing loggers which are not specified in
    the config file, unless disable_existing_loggers is set to True.

    2) Like logging.config.fileConfig, the default behavior for pre-existing
    handlers on any loggers whose settings are specified in the config file is
    to remove them; ie, ONLY the handlers explicitly given in the config will
    be on the configured logger.
    However, pymelLogFileConfig provides the ability to keep pre-exisiting
    handlers, by setting the 'remove_existing_handlers' option in the appropriate
    section to True.
    """
    cp = ConfigParser.ConfigParser(defaults)
    if hasattr(cp, 'readfp') and hasattr(fname, 'readline'):
        cp.readfp(fname)
    else:
        cp.read(fname)

    formatters = logging.config._create_formatters(cp)

    # _install_loggers will remove all existing handlers for the
    # root logger, and any other handlers specified... to override
    # this, save the existing handlers first
    root = logging.root
    # make sure you get a COPY of handlers!
    rootHandlers = root.handlers[:]
    oldLogHandlers = {}

    # Don't use getLogger while iterating through loggerDict, as that
    # may actually create a logger, and change the size of the dict
    # ...instead, just ignore any PlaceHolder instances we get, as they
    # won't have any handlers to worry about anyway
    # thanks to pierre.augeard for pointing this one out
    for loggerName, logger in root.manager.loggerDict.iteritems():
        # Make sure it's not a PlaceHolder
        if isinstance(logger, logging.Logger):
            # make sure you get a COPY of handlers!
            oldLogHandlers[loggerName] = logger.handlers[:]

    # critical section
    logging._acquireLock()
    try:
        # Handlers add themselves to logging._handlers
        handlers = logging.config._install_handlers(cp, formatters)

        if sys.version_info >= (2,6):
            logging.config._install_loggers(cp, handlers,
                                            disable_existing_loggers=0)
        else:
            logging.config._install_loggers(cp, handlers)
            # The _install_loggers function disables old-loggers, so we need to
            # re-enable them
            for k,v in logging.root.manager.loggerDict.iteritems():
                if hasattr(v, 'disabled') and v.disabled:
                    v.disabled = 0

        # Now re-add any removed handlers, if needed
        secNames = cp.get('loggers', 'keys').split(',')
        secNames = ['logger_' + x.strip() for x in secNames]
        _addOldHandlers(root, rootHandlers, 'logger_root', cp)
        for secName in secNames:
            if secName == 'logger_root':
                logger = root
                oldHandlers = rootHandlers
            else:
                logName = cp.get(secName, 'qualname')
                logger = logging.getLogger(logName)
                oldHandlers = oldLogHandlers.get(logName)
            if oldHandlers:
                _addOldHandlers(logger, oldHandlers, secName, cp)

    finally:
        logging._releaseLock()

def _addOldHandlers(logger, oldHandlers, secName, configParser):
    opts = configParser.options(secName)
    if 'remove_existing_handlers' not in opts:
        removeExisting = True
    else:
        removeExisting = eval(configParser.get(secName, 'remove_existing_handlers'))
    if not removeExisting:
        for handler in oldHandlers:
            if handler not in logger.handlers:
                logger.addHandler(handler)

maya.utils.shellLogHandler()

pymelLogFileConfig(getLogConfigFile())

rootLogger = logging.root

pymelLogger = logging.getLogger("pymel")

def environLogLevelOverride(logger):
    """If PYMEL_LOGLEVEL is set, make sure the logging level is at least that
    much for the given logger.
    """
    # variable must exist AND be non-empty
    environLevel = os.environ.get(PYMEL_LOGLEVEL_ENV_VAR)
    if environLevel:
        environLevel = nameToLevel(environLevel)
        currentLevel = logger.getEffectiveLevel()
        if not currentLevel or currentLevel > environLevel:
            logger.setLevel(environLevel)

def getLogger(name):
    """
    a convenience function that allows any module to setup a logger by simply
    calling `getLogger(__name__)`.  If the module is a package, "__init__" will
    be stripped from the logger name
    """
    suffix = '.__init__'
    if name.endswith(suffix):
        name = name[:-len(suffix)]
    logger = logging.getLogger(name)
    environLogLevelOverride(logger)
    addErrorLog(logger)
    # for convenience, stick 'DEBUG', 'INFO', 'WARNING', etc attributes onto
    # the logger itself
    for logEnumValue in logLevels.values():
        setattr(logger, logEnumValue.key, logEnumValue.index)
    return logger

# keep as an enumerator so that we can keep the order
logLevels = util.Enum( 'logLevels', dict([(getLevelName(n),n) for n in range(0,CRITICAL+1,10)]) )

def nameToLevel(name):
    try:
        return int(name)
    except ValueError:
        return logLevels.getIndex(name)

def levelToName(level):
    if not isinstance(level, int):
        raise TypeError(level)
    try:
        return logLevels.getKey(level)
    except ValueError:
        return str(level)

environLogLevelOverride(pymelLogger)


#===============================================================================
# DECORATORS
#===============================================================================

def timed(level=DEBUG):
    import time
    @decorator
    def timedWithLevel(func):
        logger = getLogger(func.__module__)
        def timedFunction(*arg, **kwargs):
            t = time.time()
            res = func(*arg, **kwargs)
            t = time.time() - t # convert to seconds float
            strSecs = time.strftime("%M:%S.", time.localtime(t)) + ("%.3f" % t).split(".")[-1]
            logger.log(level, 'Function %s(...) - finished in %s seconds' % (func.func_name, strSecs))
            return res
        return timedFunction
    return timedWithLevel


#===============================================================================
# INIT TO USER'S PREFERENCE
#===============================================================================


def _setupLevelPreferenceHook():
    """Sets up a callback so that the last used log-level is saved to the user preferences file"""

    LOGLEVEL_OPTVAR = 'pymel.logLevel'


    # retrieve the preference as a string name, for human readability.
    # we need to use MGlobal because cmds.optionVar might not exist yet
    # TODO : resolve load order for standalone.  i don't think that userPrefs is loaded yet at this point in standalone.
    levelName = os.environ.get( PYMEL_LOGLEVEL_ENV_VAR,
                                MGlobal.optionVarStringValue( LOGLEVEL_OPTVAR ) )
    if levelName:
        level =  min( logging.WARNING, nameToLevel(levelName) ) # no more than WARNING level
        pymelLogger.setLevel(level)
        pymelLogger.info("setting logLevel to user preference: %s (%d)" % (levelName, level) )

    func = pymelLogger.setLevel
    def setLevelHook(level, *args, **kwargs):

        levelName = levelToName(level)
        level = nameToLevel(level)
        ret = func(level, *args, **kwargs)
        pymelLogger.info("Log Level Changed to '%s'" % levelName)
        try:
            # save the preference as a string name, for human readability
            # we need to use MGlobal because cmds.optionVar might not exist yet
            MGlobal.setOptionVarValue( LOGLEVEL_OPTVAR, levelName )
        except Exception, e:
            pymelLogger.warning("Log Level could not be saved to the user-prefs ('%s')" % e)
        return ret

    setLevelHook.__doc__ = func.__doc__
    setLevelHook.__name__ = func.__name__
    pymelLogger.setLevel = setLevelHook

#===============================================================================
# ERROR LOGGER
#===============================================================================
ERRORLEVEL = None
ERRORLEVEL_DEFAULT = logging.ERROR
def raiseLog(logger, level, message, errorClass=RuntimeError):
    '''For use in situations in which you may wish to raise an error or simply
    print to a logger.

    Ie, if checking for things that "shouldn't" happen, may want to raise an
    error if a developer, but simply issue a warning and continue as gracefully
    as possible for normal end-users.

    So, if we make a call:
        raiseLog(_logger, _logger.INFO, "oh noes! something weird happened!")
    ...then what happens will depend on what the value of ERRORLEVEL (controlled
    by the environment var %s) is - if it was not set, or set to ERROR, or
    WARNING, then the call will result in issuing a _logger.info(...) call;
    if it was set to INFO or DEBUG, then an error would be raised.

    For convenience, raiseLog is installed onto logger instances created with
    the getLogger function in this module, so you can do:
        _logger.raiseLog(_logger.INFO, "oh noes! something weird happened!")
    '''
    # Initially wanted to have ERROR_LOGLEVEL controlled by the pymel.conf,
    # but I want to be able to use raiseLog in early startup, before pymel.conf
    # is read in pymel.internal.startup, so an environment variable seemed the
    # only way to go
    global ERRORLEVEL
    if ERRORLEVEL is None:
        levelName = os.environ.get(PYMEL_ERRORLEVEL_ENV_VAR)
        if levelName is None:
            ERRORLEVEL = ERRORLEVEL_DEFAULT
        else:
            ERRORLEVEL = nameToLevel(levelName)
    if level >= ERRORLEVEL:
        raise errorClass(message)
    else:
        logger.log(level, message)

def addErrorLog(logger):
    '''Adds an 'raiseLog' method to the given logger instance
    '''
    if 'raiseLog' not in logger.__dict__:
        # because we're installing onto an instance, and not a class, we have to
        # create our own wrapper which sets the logger
        def instanceErrorLog(*args, **kwargs):
            return raiseLog(logger, *args, **kwargs)
        instanceErrorLog.__doc__ = raiseLog.__doc__
        instanceErrorLog.__name__ = 'raiseLog'
        logger.raiseLog = instanceErrorLog
    return logger

#_setupLevelPreferenceHook()


########NEW FILE########
__FILENAME__ = pmcmds
'''
This module wraps maya.cmds to accept special pymel arguments.

There are a number of pymel objects which must be converted to a "mel-friendly"
representation. For example, in versions prior to 2009, some mel commands (ie, getAttr) which expect
string arguments will simply reject custom classes, even if they have a valid string representation.
Another Example is mel's matrix inputs, which expects a flat list of 16 flaots, while pymel's Matrix has a more typical
4x4 representation.

If you're having compatibility issues with your custom classes when passing them to maya.cmds,
simply add a __melobject__ function that returns a mel-friendly result and pass them to pymel's wrapped commands.

The wrapped commands in this module are the starting point for any other pymel customizations.

'''

import inspect
import sys
import re
import os

import pymel.util as util
import pymel.versions as versions
#import mayautils
import maya.cmds
import warnings

__all__ = ['getMelRepresentation']
_thisModule = sys.modules[__name__]

# In Maya <= 2011, the error would be:
#   TypeError: Object foo.bar is invalid
# In Maya 2012, it is:
#   ValueError: No object matches name: foo.bar
if versions.current() < versions.v2012:
    objectErrorType = TypeError
    objectErrorReg = re.compile(',?Object (.*) is invalid,?$')
else:
    objectErrorType = ValueError
    objectErrorReg = re.compile(',?No object matches name: ,?(.*)$')

def _testDecorator(function):
    def newFunc(*args, **kwargs):
        print "wrapped function for %s" % function.__name__
        return function(*args, **kwargs)
    newFunc.__name__ =  function.__name__
    newFunc.__doc__ =  function.__doc__
    return newFunc


def getCmdName(inFunc):
    '''Use in place of inFunc.__name__ when inFunc could be a maya.cmds cmd

    handles stubFuncs
    '''
    cmdName = inFunc.__name__
    if cmdName == 'stubFunc':
        sourceFile = inspect.getsourcefile(inFunc)
        if (isinstance(sourceFile, basestring) and
                os.path.join('maya','app','commands') in sourceFile):
            # Here's where it gets tricky... this is a fairly big hack, highly
            # dependent on the exact implementation of maya.app.commands.stubFunc...
            freevars = inFunc.func_code.co_freevars
            # in python 2.5, tuples don't have index / find methods
            if not hasattr(freevars, 'index'):
                freevars = list(freevars)
            freeVarIndex = freevars.index('command')
            if freeVarIndex:
                raise ValueError('could not find a command var in %s' % cmdName)
            cmdName = inFunc.func_closure[freeVarIndex].cell_contents
    return cmdName

def getMelRepresentation( args, recursionLimit=None, maintainDicts=True):
    """Will return a list which contains each element of the iterable 'args' converted to a mel-friendly representation.

    :Parameters:
        recursionLimit : int or None
            If an element of args is itself iterable, recursionLimit specifies the depth to which iterable elements
            will recursively search for objects to convert; if ``recursionLimit==0``, only the elements
            of args itself will be searched for PyNodes -  if it is 1, iterables within args will have getMelRepresentation called
            on them, etc.  If recursionLimit==None, then there is no limit to recursion depth.

        maintainDicts : bool
            In general, all iterables will be converted to tuples in the returned copy - however, if maintainDicts==True,
            then iterables for which ``util.isMapping()`` returns True will be returned as dicts.

    """
    if recursionLimit:
        recursionLimit -= 1


    if maintainDicts and util.isMapping(args):
        newargs = dict(args)
        argIterable = args.iteritems()
        isList = False
    else:
        newargs = list(args)
        argIterable = enumerate(args)
        isList = True

    for index, value in argIterable:
        try:
            newargs[index] = value.__melobject__()
        except AttributeError:
            if ( (not recursionLimit) or recursionLimit >= 0) and util.isIterable(value):
                # ...otherwise, recurse if not at recursion limit and  it's iterable
                newargs[index] = getMelRepresentation(value, recursionLimit, maintainDicts)
    if isList:
        newargs = tuple(newargs)
    return newargs


def addWrappedCmd(cmdname, cmd=None):
    if cmd is None:
        cmd = getattr(maya.cmds, cmdname)

    #if cmd.__name__ == 'dummyFunc': print cmdname

    def wrappedCmd(*args, **kwargs):
        # we must get the cmd each time, because maya delays loading of functions until they are needed.
        # if we don't reload we'll keep the dummyFunc around
        new_cmd = getattr(maya.cmds, cmdname)
        #print args, kwargs
        # convert args to mel-friendly representation
        new_args = getMelRepresentation(args)

        # flatten list. this is necessary for list of components.  see Issue 71.  however, be sure that it's not an empty list/tuple
        if len(new_args) == 1 and util.isIterable(new_args[0]) and len(new_args[0]): #isinstance( new_args[0], (tuple, list) ):
            new_args = new_args[0]

        new_kwargs = getMelRepresentation(kwargs)
        #print new_args, new_kwargs
        try:
            res = new_cmd(*new_args, **new_kwargs)
        except objectErrorType, e:
            m = objectErrorReg.match(str(e))
            if m:
                import pymel.core.general
                obj = m.group(1)
                raise pymel.core.general._objectError(obj)

            else:
                # re-raise error
                raise

        # when editing, some of maya.cmds functions return empty strings and some return idiotic statements like 'Values Edited'.
        # however, for UI's in particular, people use the edit command to get a pymel class for existing objects.
        # return None when we get an empty string
        try:
            if res=='' and kwargs.get('edit', kwargs.get('e', False) ):
                return None
        except AttributeError:
            pass
        return res

    wrappedCmd.__doc__ = cmd.__doc__

    oldname = getattr(cmd, '__name__', None)
    if isinstance(oldname, str):
        # Don't use cmd.__name__, as this could be 'stubFunc'
        wrappedCmd.__name__ = getCmdName(cmd)
    else:
        wrappedCmd.__name__ = str(cmdname)

    # for debugging, to make sure commands got wrapped...
    #wrappedCmd = _testDecorator(wrappedCmd)

    # so that we can identify that this is a wrapped maya command
    setattr( _thisModule, cmdname, wrappedCmd )
    #globals()[cmdname] = wrappedCmd

def removeWrappedCmd(cmdname):
    try:
        del cmdname
    except NameError:
        warnings.warn("%s not found in %s" % (cmdname, __name__))

def addAllWrappedCmds():
    for cmdname, cmd in inspect.getmembers(maya.cmds, callable):
        addWrappedCmd(cmdname, cmd)




########NEW FILE########
__FILENAME__ = pwarnings
"""
Redefine format warning to avoid getting garbage at end of line when raised directly from Maya console
and define a UserWarning class that does only print it's message (no line or module info)


"""
import warnings
from warnings import formatwarning, linecache

def formatwarning(message, category, filename, lineno, line=None):
    """Redefined format warning for maya."""
    if issubclass(category, ExecutionWarning) :
        s =  u"%s: %s\n" % (category.__name__, message)
    else :
        s =  u'%s: %s, at line %s, in "%s"\n' % (category.__name__, message, lineno, filename)
#        name, ext = os.path.splitext(filename)
#        line = ""
#        if ext == ".py" :
#            line = unicode(linecache.getline(filename, lineno)).strip()
#            if line:
#                s += (u"#\t %s" % line)
    return s

warnings.formatwarning = formatwarning

#def showwarning(message, category, filename, lineno, file=None, line=None):
#    msg = warnings.formatwarning(message, category, filename, lineno, line)
#    if file:
#        msg += " >> %r" % file
#    _logger.warning(msg)
#
#warnings.showwarning = showwarning

class ExecutionWarning (UserWarning) :
    """ Simple Warning class that doesn't print any information besides warning message """

def warn(*args, **kwargs):
    """ Default Maya warn which uses ExecutionWarning as the default warning class. """
    if len(args) == 1 and not isinstance(args[0], Warning):
        args = args + (ExecutionWarning,)
    stacklevel = kwargs.pop("stacklevel",1) + 1 # add to the stack-level so that this wrapper func is skipped
    return warnings.warn(stacklevel=stacklevel, *args, **kwargs)

def deprecated(funcOrMessage, className=None):
    """the decorator can either receive parameters or the function directly.

    If passed a message, the message will be appended to the standard deprecation warning and should serve to further
    clarify why the function is being deprecated and/or suggest an alternative function

    the className parameter is optional and should be included if the function is a method, since the name of the class
    cannot be automatically determined.
    """
    #@decorator
    def deprecated2(func):
        info = dict(
            name = func.__name__,
            module = func.__module__)

        def deprecationLoggedFunc(*args, **kwargs):
            warnings.warn(message % info, DeprecationWarning, stacklevel=2)  # add to the stack-level so that this wrapper func is skipped
            return func(*args, **kwargs)

        deprecationLoggedFunc.__name__ = func.__name__
        deprecationLoggedFunc.__module__ = func.__module__
        deprecationLoggedFunc.__doc__ = message % info + '\n'
        if func.__doc__:
            deprecationLoggedFunc.__doc__ += '\n' +  func.__doc__
        return deprecationLoggedFunc

    if className:
        objName = '%(module)s.' + className + '.%(name)s'
    else:
        objName = '%(module)s.%(name)s'
    basemessage = message = "The function '" + objName + "' is deprecated and will become unavailable in future pymel versions"
    # check if the decorator got a 'message' parameter
    if isinstance(funcOrMessage, basestring):
        message = basemessage + '. ' + funcOrMessage
        return deprecated2
    else:
        message = basemessage
        return deprecated2(funcOrMessage)

if __name__ == '__main__' :
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = startup
"""
Maya-related functions, which are useful to both `api` and `core`, including `mayaInit` which ensures
that maya is initialized in standalone mode.
"""
from __future__ import with_statement
import os.path, sys, glob, inspect
import maya
import maya.OpenMaya as om
import maya.utils

from pymel.util import picklezip, shellOutput, subpackages, refreshEnviron, namedtuple
import pymel.versions as versions
from pymel.mayautils import getUserPrefsDir
from pymel.versions import shortName, installName
import plogging


# There are FOUR different ways maya might be started, all of which are
# subtly different, that need to be considered / tested:
#
# 1) Normal gui
# 2) maya -prompt
# 3) Render
# 4) mayapy (or just straight up python)

_logger = plogging.getLogger(__name__)
try:
    import cPickle as pickle
except:
    _logger.warning("using pickle instead of cPickle: load performance will be affected")
    import pickle

#from maya.cmds import encodeString

isInitializing = False
# Setting this to False will make finalize() do nothing
finalizeEnabled = True
_finalizeCalled = False

# tells whether this maya package has been modified to work with pymel
pymelMayaPackage = hasattr(maya.utils, 'shellLogHandler') or versions.current() >= versions.v2011


def _moduleJoin(*args):
    """
    Joins with the base pymel directory.
    :rtype: string
    """
    moduleDir = os.path.dirname( os.path.dirname( sys.modules[__name__].__file__ ) )
    return os.path.realpath(os.path.join( moduleDir, *args))


def mayaStartupHasRun():
    """
    Returns True if maya.app.startup has already finished, False otherwise.
    """
    return 'maya.app.startup.gui' in sys.modules or 'maya.app.startup.batch' in sys.modules

def mayaStartupHasStarted():
    """
    Returns True if maya.app.startup has begun running, False otherwise.

    It's possible that maya.app.startup is in the process of running (ie,
    in maya.app.startup.basic, calling executeUserSetup) - unlike mayaStartup,
    this will attempt to detect if this is the case.
    """
    return hasattr(maya, 'stringTable')


def setupFormatting():
    import pprint
    import maya.utils
    def myResultCallback(obj):
        return pprint.pformat(obj)
    maya.utils.formatGuiResult = myResultCallback
    # prevent auto-completion generator from getting confused
    maya.utils.formatGuiResult.__module__ = 'maya.utils'

#def loadDynamicLibs():
#    """
#    due to a bug in maya.app.commands many functions do not return any value the first time they are run,
#    especially in standalone mode.  this function forces the loading of all dynamic libraries, which is
#    a very fast and memory-efficient process, which begs the question: why bother dynamically loading?
#
#    this function can only be run after maya.standalone is initialized
#    """
#
#    commandListPath = os.path.realpath( os.environ[ 'MAYA_LOCATION' ] )
#    commandListPath = os.path.join( commandListPath, libdir, 'commandList' )
#
#    import maya.cmds
#    assert hasattr( maya.cmds, 'dynamicLoad'), "maya.standalone must be initialized before running this function"
#    file = open( commandListPath, 'r' )
#    libraries = set( [ line.split()[1] for line in file] )
#    for library in libraries:
#        try:
#            maya.cmds.dynamicLoad(library)
#        except RuntimeError:
#            _logger.debug("Error dynamically loading maya library: %s" % library)

# Will test initialize maya standalone if necessary (like if scripts are run from an exernal interpeter)
# returns True if Maya is available, False either
def mayaInit(forversion=None) :
    """ Try to init Maya standalone module, use when running pymel from an external Python inerpreter,
    it is possible to pass the desired Maya version number to define which Maya to initialize


    Part of the complexity of initializing maya in standalone mode is that maya does not populate os.environ when
    parsing Maya.env.  If we initialize normally, the env's are available via maya (via the shell), but not in python
    via os.environ.

    Note: the following example assumes that MAYA_SCRIPT_PATH is not set in your shell environment prior to launching
    python or mayapy.

    >>> import maya.standalone            #doctest: +SKIP
    >>> maya.standalone.initialize()      #doctest: +SKIP
    >>> import maya.mel as mm             #doctest: +SKIP
    >>> print mm.eval("getenv MAYA_SCRIPT_PATH")    #doctest: +SKIP
    /Network/Servers/sv-user.luma-pictures.com/luma .....
    >>> import os                         #doctest: +SKIP
    >>> 'MAYA_SCRIPT_PATH' in os.environ  #doctest: +SKIP
    False

    The solution lies in `refreshEnviron`, which copies the environment from the shell to os.environ after maya.standalone
    initializes.

    :rtype: bool
    :return: returns True if maya.cmds required initializing ( in other words, we are in a standalone python interpreter )

    """
    _logger.debug( "startup.mayaInit: called" )
    setupFormatting()

    global isInitializing

    # test that Maya actually is loaded and that commands have been initialized,for the requested version

    aboutExists = False
    try :
        from maya.cmds import about
        aboutExists = True
    except ImportError:
        pass

    if aboutExists and mayaStartupHasStarted():
        # if this succeeded, we're initialized
        _logger.debug( "startup.mayaInit: maya already started - exiting" )
        isInitializing = False
        return False

    _logger.debug( "startup.mayaInit: running" )
    # for use with pymel compatible maya package
    os.environ['MAYA_SKIP_USERSETUP_PY'] = 'on'

    if not aboutExists and not sys.modules.has_key('maya.standalone'):
        try :
            _logger.debug( "startup.mayaInit: running standalone.initialize" )
            import maya.standalone #@UnresolvedImport
            maya.standalone.initialize(name="python")

            if versions.current() < versions.v2009:
                refreshEnviron()

        except ImportError, e:
            raise ImportError(str(e) + ": pymel was unable to intialize maya.standalone")

    try:
        from maya.cmds import about
    except Exception:
        _logger.error("maya.standalone was successfully initialized, but pymel failed to import maya.cmds (or it was not populated)")
        raise

    if not mayaStartupHasRun():
        _logger.debug( "running maya.app.startup" )
        # If we're in 'maya -prompt' mode, and a plugin loads pymel, then we
        # can have a state where maya.standalone has been initialized, but
        # the python startup code hasn't yet been run...
        if about(batch=True):
            import maya.app.startup.batch
        else:
            import maya.app.startup.gui

    # return True, meaning we had to initialize maya standalone
    isInitializing = True
    return True

def initMEL():
    if 'PYMEL_SKIP_MEL_INIT' in os.environ or pymel_options.get( 'skip_mel_init', False ) :
        _logger.info( "Skipping MEL initialization" )
        return

    _logger.debug( "initMEL" )
    mayaVersion = versions.installName()
    prefsDir = getUserPrefsDir()
    if prefsDir is None:
        _logger.error( "could not initialize user preferences: MAYA_APP_DIR not set" )
    elif not os.path.isdir(prefsDir):
        _logger.error( "could not initialize user preferences: %s does not exist" % prefsDir  )

    # TODO : use cmds.internalVar to get paths
    # got this startup sequence from autodesk support
    startup = [
        #'defaultRunTimeCommands.mel',  # sourced automatically
        #os.path.join( prefsDir, 'userRunTimeCommands.mel'), # sourced automatically
        'createPreferencesOptVars.mel',
        'createGlobalOptVars.mel',
        os.path.join( prefsDir, 'userPrefs.mel') if prefsDir else None,
        'initialStartup.mel',
        #$HOME/Documents/maya/projects/default/workspace.mel
        'initialPlugins.mel',
        #'initialGUI.mel', #GUI
        #'initialLayout.mel', #GUI
        #os.path.join( prefsDir, 'windowPrefs.mel'), #GUI
        #os.path.join( prefsDir, 'menuSetPrefs.mel'), #GUI
        #'hotkeySetup.mel', #GUI
        'namedCommandSetup.mel',
        os.path.join( prefsDir, 'userNamedCommands.mel' ) if prefsDir else None,
        #'initAfter.mel', #GUI
        os.path.join( prefsDir, 'pluginPrefs.mel' )  if prefsDir else None
    ]
    try:
        for f in startup:
            _logger.debug("running: %s" % f)
            if f is not None:
                if os.path.isabs(f) and not os.path.exists(f):
                    _logger.warning( "Maya startup file %s does not exist" % f )
                else:
                    # need to encode backslashes (used for windows paths)
                    if isinstance(f, unicode):
                        encoding = 'unicode_escape'
                    else:
                        encoding = 'string_escape'
                    #import pymel.core.language as lang
                    #lang.mel.source( f.encode(encoding)  )
                    import maya.mel
                    maya.mel.eval( 'source "%s"' % f.encode(encoding) )

    except Exception, e:
        _logger.error( "could not perform Maya initialization sequence: failed on %s: %s" % ( f, e) )

    try:
        # make sure it exists
        res = maya.mel.eval('whatIs "userSetup.mel"')
        if res != 'Unknown':
            maya.mel.eval( 'source "userSetup.mel"')
    except RuntimeError: pass

    _logger.debug("done running mel files")

def initAE():
    try:
        pkg = __import__('AETemplates')
    except ImportError:
        return False
    except Exception:
        import traceback
        traceback.print_exc()
        return False
    else:
        # import subpackages
        for data in subpackages(pkg):
            pass
    return True

def finalize():
    global finalizeEnabled
    global _finalizeCalled
    if not finalizeEnabled or _finalizeCalled:
        return
    _logger.debug('finalizing')
    # Set this to true HERE, as in running userSetup.py,
    # we could end up in here again, inside the initial finalize...
    _finalizeCalled = True

    global isInitializing
    if pymelMayaPackage and isInitializing:
        # this module is not encapsulated into functions, but it should already
        # be imported, so it won't run again
        assert 'maya.app.startup.basic' in sys.modules, \
            "something is very wrong. maya.app.startup.basic should be imported by now"
        import maya.app.startup.basic
        maya.app.startup.basic.executeUserSetup()

    state = om.MGlobal.mayaState()
    if state == om.MGlobal.kLibraryApp: # mayapy only
        initMEL()
        #fixMayapy2011SegFault()
    elif state == om.MGlobal.kInteractive:
        initAE()


# Have all the checks inside here, in case people want to insert this in their
# userSetup... it's currently not always on
def fixMayapy2011SegFault():
    currentVer = versions.current()
    # this was fixed in 2014, but in 2014, it will crash consistently if you use
    # the sceneAseembly plugin, and inconsistently even if you don't...
    if versions.v2011 <= currentVer < versions.v2013 or currentVer >= versions.v2014:
        import platform
        if platform.system() == 'Linux':
            if om.MGlobal.mayaState() == om.MGlobal.kLibraryApp: # mayapy only
                # In linux maya 2011, once maya has been initialized, if you try
                # to do a 'normal' sys.exit, it will crash with a segmentation
                # fault..
                # do a 'hard' os._exit to avoid this

                # note that, since there is no built-in support to tell from
                # within atexit functions what the exit code is, we cannot
                # guarantee returning the "correct" exit code... for instance,
                # if someone does:
                #    raise SystemExit(300)
                # we will instead return a 'normal' exit code of 0
                # ... but in general, the return code is a LOT more reliable now,
                # since it used to ALWAYS return non-zero...

                import sys
                import atexit

                # First, wrap sys.exit to store the exit code...
                _orig_exit = sys.exit

                # This is just in case anybody else needs to access the
                # original exit function...
                if not hasattr('sys', '_orig_exit'):
                    sys._orig_exit = _orig_exit
                def exit(status):
                    sys._exit_status = status
                    _orig_exit(status)
                sys.exit = exit

                def hardExit():
                    # run all the other exit handlers registered with
                    # atexit, then hard exit... this is easy, because
                    # atexit._run_exitfuncs pops funcs off the stack as it goes...
                    # so all we need to do is call it again
                    import sys
                    atexit._run_exitfuncs()
                    try:
                        print "pymel: hard exiting to avoid mayapy crash..."
                    except Exception:
                        pass
                    import os
                    import sys

                    exitStatus = getattr(sys, '_exit_status', None)
                    if exitStatus is None:
                        last_value = getattr(sys, 'last_value', None)
                        if last_value is not None:
                            if isinstance(last_value, SystemExit):
                                try:
                                    exitStatus = last_value.args[0]
                                except Exception: pass
                            if exitStatus is None:
                                exitStatus = 1
                    if exitStatus is None:
                        exitStatus = 0
                    os._exit(exitStatus)
                atexit.register(hardExit)

# Fix for non US encodings in Maya
def encodeFix():
    if mayaInit() :
        from maya.cmds import about

        mayaEncode = about(cs=True)
        pyEncode = sys.getdefaultencoding()     # Encoding tel que defini par sitecustomize
        if mayaEncode != pyEncode :             # s'il faut redefinir l'encoding
            #reload (sys)                       # attention reset aussi sys.stdout et sys.stderr
            #sys.setdefaultencoding(newEncode)
            #del sys.setdefaultencoding
            #print "# Encoding changed from '"+pyEncode+'" to "'+newEncode+"' #"
            if not about(b=True) :              # si pas en batch, donc en mode UI, redefinir stdout et stderr avec encoding Maya
                import maya.utils
                try :
                    import maya.app.baseUI
                    import codecs
                    # Replace sys.stdin with a GUI version that will request input from the user
                    sys.stdin = codecs.getreader(mayaEncode)(maya.app.baseUI.StandardInput())
                    # Replace sys.stdout and sys.stderr with versions that can output to Maya's GUI
                    sys.stdout = codecs.getwriter(mayaEncode)(maya.utils.Output())
                    sys.stderr = codecs.getwriter(mayaEncode)(maya.utils.Output( error=1 ))
                except ImportError :
                    _logger.debug("Unable to import maya.app.baseUI")


#===============================================================================
# Cache utilities
#===============================================================================

def _dump( data, filename, protocol = -1):
    with open(filename, mode='wb') as file:
        pickle.dump( data, file, protocol)

def _load(filename):
    with open(filename, mode='rb') as file:
        res = pickle.load(file)
        return res

class PymelCache(object):
    # override these
    NAME = ''   # ie, 'mayaApi'
    DESC = ''   # ie, 'the API cache' - used in error messages, etc
    COMPRESSED = True

    # whether to add the version to the filename when writing out the cache
    USE_VERSION = True

    def read(self):
        newPath = self.path()
        if self.COMPRESSED:
            func = picklezip.load
        else:
            func = _load

        _logger.debug(self._actionMessage('Loading', 'from', newPath))

        try:
            return func(newPath)
        except Exception, e:
            self._errorMsg('read', 'from', newPath, e)

    def write(self, data):
        newPath = self.path()
        if self.COMPRESSED:
            func = picklezip.dump
        else:
            func = _dump

        _logger.info(self._actionMessage('Saving', 'to', newPath))

        try :
            func( data, newPath, 2)
        except Exception, e:
            self._errorMsg('write', 'to', newPath, e)

    def path(self):
        if self.USE_VERSION:
            if hasattr(self, 'version'):
                short_version = str(self.version)
            else:
                short_version = shortName()
        else:
            short_version = ''

        newPath = _moduleJoin( 'cache', self.NAME+short_version )
        if self.COMPRESSED:
            newPath += '.zip'
        else:
            newPath += '.bin'
        return newPath

    @classmethod
    def _actionMessage(cls, action, direction, location):
        '''_actionMessage('eat', 'at', 'Joes') =>
            "eat cls.DESC at 'Joes'"
        '''
        description = cls.DESC
        if description:
            description = ' ' + description
        return "%s%s %s %r" % (action, description, direction, location)

    @classmethod
    def _errorMsg(cls, action, direction, path, error):
        '''_errorMessage('eat', 'at', 'Joes') =>
            'Unable to eat cls.DESC at Joes: error.msg'
        '''
        actionMsg = cls._actionMessage(action, direction, path)
        _logger.error("Unable to %s: %s" % (actionMsg, error))
        import traceback
        _logger.debug(traceback.format_exc())



# Considered using named_tuple, but wanted to make data stored in cache
# have as few dependencies as possible - ie, just a simple tuple
class SubItemCache(PymelCache):
    '''Used to store various maya information

    ie, api / cmd data parsed from docs

    To implement, create a subclass, which overrides at least the NAME, DESC,
    and _CACHE_NAMES attributes, and implements the rebuild method.

    Then to access data, you should initialize an instance, then call build;
    build will load the data from the cache file if possible, or call rebuild
    to build the data from scratch if not.  If the data had to be rebuilt,
    a new file cache will be saved.

    The data may then be accessed through attributes on the instance, with
    the names given in _CACHE_NAMES.

    >>> class NodeCache(SubItemCache):
    ...     NAME = 'mayaNodes'
    ...     DESC = 'the maya nodes cache'
    ...     COMPRESSED = False
    ...     _CACHE_NAMES = ['nodeTypes']
    ...     def rebuild(self):
    ...         import maya.cmds
    ...         self.nodeTypes = maya.cmds.allNodeTypes(includeAbstract=True)
    >>> cacheInst = NodeCache()
    >>> cacheInst.build()
    >>> 'polyCube' in cacheInst.nodeTypes
    True
    '''
    # Provides a front end for a pickled file, which should contain a
    # tuple of items; each item in the tuple is associated with a name from
    # _CACHE_NAMES

    # override this with a list of names for the items within the cache
    _CACHE_NAMES = []

    # Set this to the initialization contructor for each cache item;
    # if a given cache name is not present in ITEM_TYPES, DEFAULT_TYPE is
    # used
    # These are the types that the contents will 'appear' to be to the end user
    # (ie, the types returned by contents).
    # If the value needs to be converted before pickling, specify an entry
    # in STORAGE_TYPES
    # Both should be constructors which can either take no arguments, or
    # a single argument to initialize an instance.
    ITEM_TYPES = {}
    STORAGE_TYPES = {}
    DEFAULT_TYPE = dict

    def __init__(self):
        for name in self._CACHE_NAMES:
            self.initVal(name)

    def cacheNames(self):
        return tuple(self._CACHE_NAMES)

    def initVal(self, name):
        itemType = self.itemType(name)
        if itemType is None:
            val = None
        else:
            val = itemType()
        setattr(self, name, val)

    def itemType(self, name):
        return self.ITEM_TYPES.get(name, self.DEFAULT_TYPE)

    def build(self):
        """
        Used to rebuild cache, either by loading from a cache file, or rebuilding from scratch.
        """
        data = self.load()
        if data is None:
            self.rebuild()
            self.save()

    # override this...
    def rebuild(self):
        """Rebuild cache from scratch

        Unlike 'build', this does not attempt to load a cache file, but always
        rebuilds it by parsing the docs, etc.
        """
        pass

    def update(self, obj, cacheNames=None):
        '''Update all the various data from the given object, which should
        either be a dictionary, a list or tuple with the right number of items,
        or an object with the caches stored in attributes on it.
        '''
        if cacheNames is None:
            cacheNames = self.cacheNames()

        if isinstance(obj, dict):
            for key, val in obj.iteritems():
                setattr(self, key, val)
        elif isinstance(obj, (list, tuple)):
            if len(obj) != len(cacheNames):
                raise ValueError('length of update object (%d) did not match length of cache names (%d)' % (len(obj), len(cacheNames)))
            for newVal, name in zip(obj, cacheNames):
                setattr(self, name, newVal)
        else:
            for cacheName in cacheNames:
                setattr(self, cacheName, getattr(obj, cacheName))

    def load(self):
        '''Attempts to load the data from the cache on file.

        If it succeeds, it will update itself, and return the loaded items;
        if it fails, it will return None
        '''
        data = self.read()
        if data is not None:
            data = list(data)
            # if STORAGE_TYPES, need to convert back from the storage type to
            # the 'normal' type
            if self.STORAGE_TYPES:
                for name in self.STORAGE_TYPES:
                    index = self._CACHE_NAMES.index(name)
                    val = data[index]
                    val = self.itemType(name)(val)
                    data[index] = val
            data = tuple(data)
            self.update(data, cacheNames=self._CACHE_NAMES)
        return data

    def save(self, obj=None):
        '''Saves the cache

        Will optionally update the caches from the given object (which may be
        a dictionary, or an object with the caches stored in attributes on it)
        before saving
        '''
        if obj is not None:
            self.update(obj)
        data = self.contents()
        if self.STORAGE_TYPES:
            newData = []
            for name, val in zip(self._CACHE_NAMES, data):
                if name in self.STORAGE_TYPES:
                    val = self.STORAGE_TYPES[name](val)
                newData.append(val)
            data = tuple(newData)

        self.write(data)

    # was called 'caches'
    def contents(self):
        return tuple( getattr(self, x) for x in self.cacheNames() )

#===============================================================================
# Config stuff
#===============================================================================

def getConfigFile():
    return plogging.getConfigFile()

def parsePymelConfig():
    import ConfigParser

    types = {'skip_mel_init' : 'boolean',
             'check_attr_before_lock' : 'boolean',
            }
    defaults = {'skip_mel_init' : 'off',
                'check_attr_before_lock' : 'off',
               }

    config = ConfigParser.ConfigParser(defaults)
    config.read( getConfigFile() )

    d = {}
    for option in config.options('pymel'):
        getter = getattr( config, 'get' + types.get(option, '') )
        d[option] = getter( 'pymel', option )
    return d

pymel_options = parsePymelConfig()

########NEW FILE########
__FILENAME__ = mayautils
"Maya-specific utilities mostly pertaining to file paths. These do not require initialization of maya.standalone"

import os, sys, re, platform
import versions
import internal as _internal
_logger = _internal.getLogger(__name__)
from pymel.util import path as _path


sep = os.path.pathsep


def source (file, searchPath=None, recurse=False) :
    """Looks for a python script in the specified path (uses system path if no path is specified)
        and executes it if it's found """
    filepath = unicode(file)
    filename = os.path.basename(filepath)
    dirname = os.path.dirname(filepath)

    if searchPath is None :
        searchPath=sys.path
    if isinstance(searchPath, basestring ):
        searchPath = [searchPath]
    itpath = iter(searchPath)
    _logger.debug("looking for file as: "+filepath)
    while not os.path.exists(filepath) :
        try :
            p = os.path.abspath(os.path.realpath(itpath.next()))
            filepath = os.path.join(p, filename)
            _logger.debug('looking for file as: '+filepath)
            if recurse and not filepath.exists() :
                itsub = os.walk(p)
                while not os.path.exists(filepath) :
                    try :
                        root, dirs, files = itsub.next()
                        itdirs = iter(dirs)
                        while not os.path.exists(filepath) :
                            try :
                                filepath = os.path.join(root, itdirs.next(), filename)
                                _logger.debug('looking for file as: '+filepath)
                            except :
                                pass
                    except :
                        pass
        except :
            raise ValueError, "File '"+filename+"' not found in path"
            # In case the raise exception is replaced by a warning don't forget to return here
            return
    # _logger.debug("Executing: "+filepath)
    return execfile(filepath)

def getMayaLocation(version=None):
    """
    Get the location of Maya (defined as the directory above /bin)

    Uses the $MAYA_LOCATION environment variable and sys.executable path.

    If version is passed, will attempt to find a matching Maya location.  If the
    version found by the methods above does not match the requested version, 
    this function uses a simple find/replace heuristic to modify the path and test
    if the desired version exists.  If no matching version is found, returns None

    Remember to pass the FULL version (with extension if any) to this function! """
    try:
        loc = os.path.realpath( os.environ['MAYA_LOCATION'] )
    except:
        loc = os.path.dirname( os.path.dirname( sys.executable ) )
    # get the path of a different maya version than current
    if version:
        # note that a recursive loop between getMayaLocation / getMayaVersion
        # is avoided because getMayaVersion always calls getMayaLocation with
        # version == None
        actual_long_version = versions.installName()
        actual_short_version = versions.shortName()
        if version != actual_long_version:
            short_version = versions.parseVersionStr(version, extension=False)
            if version == short_version :
                try_version = actual_long_version.replace(actual_short_version, short_version)
            else :
                try_version = version
            try_loc = loc.replace( actual_long_version, try_version )
            if os.path.exists(try_loc) :
                loc = try_loc
            else :
                _logger.warn("No Maya found for version %s" % version )
                loc = None

    return loc

def getMayaAppDir(versioned=False):
    """
    Determine the Maya application directory, first by checking MAYA_APP_DIR, then by
    trying OS-specific defaults.

    if versioned is True, the current Maya version including '-x64' suffix, if applicable, will be appended.
    """
    appDir = os.environ.get('MAYA_APP_DIR',None)
    if appDir is None :
        if os.name == 'nt':
            appDir = os.environ.get('USERPROFILE',os.environ.get('HOME',None))
            if appDir is None:
                return

            # Vista or newer... version() returns "6.x.x"
            if int(platform.version().split('.')[0]) > 5:
                appDir = os.path.join( appDir, 'Documents')
            else:
                appDir = os.path.join( appDir, 'My Documents')
        else:
            appDir = os.environ.get('HOME',None)
            if appDir is None:
                return

        if platform.system() == 'Darwin':
            appDir = os.path.join( appDir, 'Library/Preferences/Autodesk/maya' )
        else:
            appDir = os.path.join( appDir, 'maya' )

    if versioned and appDir:
        appDir = os.path.join(appDir, versions.installName())

    return appDir

def getUserPrefsDir():
    appDir = getMayaAppDir(versioned=True)
    if appDir:
        return os.path.join(appDir, 'prefs')

def getUserScriptsDir():
    appDir = getMayaAppDir(versioned=True)
    if appDir:
        return os.path.join(appDir, 'scripts')

def executeDeferred(func, *args, **kwargs):
    """
    This is a wrap for maya.utils.executeDeferred.  Maya's version does not execute at all when in batch mode, so this
    function does a simple check to see if we're in batch or interactive mode.  In interactive it runs maya.utils.executeDeferred,
    and if we're in batch mode, it just executes the function.

    Use this function in your userSetup.py file if:
        1. you are importing pymel there
        2. you want to execute some code that relies on maya.cmds
        3. you want your userSetup.py to work in both interactive and standalone mode

    Example userSetup.py file::

        from pymel.all import *
        def delayedStartup():
           print "executing a command"
           pymel.about(apiVersion=1)
        mayautils.executeDeferred( delayedStartup )

    Takes a single parameter which should be a callable function.

    """
    import maya.utils
    import maya.OpenMaya
    if maya.OpenMaya.MGlobal.mayaState() == maya.OpenMaya.MGlobal.kInteractive:
        maya.utils.executeDeferred(func, *args, **kwargs)
    else:
        if isinstance(func, basestring):
            if args or kwargs:
                raise ValueError('if passing a string to be executed, no additional args may be passed')
            exec func
        else:
            func(*args, **kwargs)

def recurseMayaScriptPath(roots=[], verbose=False, excludeRegex=None, errors='warn', prepend=False):
    """
    Given a path or list of paths, recurses through directories appending to
    the MAYA_SCRIPT_PATH environment variable any found directories containing
    mel scripts

    The root directories, if given, are always added to the MAYA_SCRIPT_PATH,
    even if they don't contain any mel scripts.

    :Parameters:
        roots
            a single path or list of paths to recurse. if left to its default, will use the current
            MAYA_SCRIPT_PATH values

        verobse : bool
            verbose on or off

        excludeRegex : str
            string to be compiled to a regular expression of paths to skip.  This regex only needs to match
            the folder name

    """

    regex = '[.]|(obsolete)'

    if excludeRegex:
        assert isinstance(excludeRegex, basestring), "please pass a regular expression as a string"
        regex = regex + '|' + excludeRegex

    includeRegex =  "(?!(" + regex + "))" # add a negative lookahead assertion




    scriptPath = os.environ["MAYA_SCRIPT_PATH"]
    varList = scriptPath.split(os.path.pathsep)
    initalLen = len(varList)

    def addDir(toAdd):
        if toAdd not in varList:
            if prepend:
                _logger.debug("Prepending script path directory %s" % toAdd)
                varList.insert(0, toAdd)
            else:
                _logger.debug("Appending script path directory %s" % toAdd)
                varList.append(toAdd)

    if roots:
        if isinstance( roots, list) or isinstance( roots, tuple):
            rootVars = list(roots)
        else:
            rootVars = [roots]
        # Roots are always added to the script path, even if they don't have
        # .mel files
        for d in rootVars:
            addDir(d)
    ##  else expand the whole  environment  currently set
    else:
        rootVars = varList[:]



    _logger.debug("Recursing Maya script path")
    _logger.debug( "Only directories which match %s will be traversed" % includeRegex )
    for rootVar in rootVars:
        root = _path( rootVar )
        if re.match( includeRegex, root.name ) and root.exists():
            _logger.debug( "Searching for all valid script directories below %s" % rootVar )
            for f in root.walkdirs( errors=errors, regex=includeRegex ):
                try:
                    if len(f.files("*.mel")):
                        addDir(str(f))
                except OSError: pass

    if len(varList) > initalLen:
        os.environ["MAYA_SCRIPT_PATH"] = os.path.pathsep.join( varList )
        _logger.info("Added %d directories to Maya script path" % (len(varList) - initalLen) )
    else:
        _logger.info("Maya script path recursion did not find any paths to add")


########NEW FILE########
__FILENAME__ = envparse
"Parser for Maya.env"

import sys, os, os.path, logging
#import external.ply.lex as lex
try:
    from pymel.util.external.ply import lex
except ImportError:
    from ply import lex

from pymel.mayautils import getMayaAppDir

_logger = logging.getLogger(__name__)

# lexer and parser for the Maya.env file

# first level lexer : form LVAR ASSIGN VALUE, then second level parsing of VALUE
# variables substitution are done as in Maya, taking only into account already defined vars
# when line is encountered
class EnvLex :
    """ ply.lex lexer class to parse Maya.env file """

    def __init__(self):
        self.states = ( ('left','exclusive'), ('right','exclusive'), ('end','exclusive'), ('cancel','exclusive') )
        self.line = ''
    def build(self, **kwargs):
        self.lexer = lex.lex(object=self,**kwargs)

    tokens = (
        'COMMENT',
        'ASSIGN',
        'VAR',
        'VALUE',
        'OK',
        'CANCEL',
        'newline'
    )

    # First level parsing : form LVAR ASSIGN VALUE
    t_ANY_ignore_COMMENT = r'\#[^\n]*'
    # Ignore starting spaces only
    t_INITIAL_ignore = '^[ \t]+'
    t_left_ignore = '[ \t]+'
    t_right_ignore = '[ \t]+'
    # careful, there seems to be a nasty bug where ply.lex takes $ as its literal value instead of in the 'end of line' meaning ?
    t_end_ignore = '[ \t]+$'
    t_cancel_ignore = '[^\n]+'
    # Valid l-values are env var names, must come first in line (INITIAL sate)
    def t_VAR(self, t) :
        r'[^\\^\/^\:^\*^\"^\<^\>^\|^=^ ^\t^\n^#]+'
        # VAR can only be on left side of ASSIGN (INITIAL parser state)
        self.lexer.begin('left')
        self.line += t.value
        return t
    # Assignation sign, ignore spaces around it
    def t_left_ASSIGN(self, t):
        r'[ \t]*=[ \t]*'
        self.lexer.begin('right')
        t.value = t.value.strip()
        self.line += t.value
        return t
    # r-values will be parsed again depending on os name
    def t_right_VALUE(self, t):
        r'[^=^\n^#]+'
        # one and only one VALUE on right side of ASSIGN
        self.lexer.begin('end')
        self.line += t.value
        return t
    # More than one equal sign per line would be an error
    def t_right_ASSIGN(self, t):
        r'[ \t]*=[ \t]*'
        warnings.warn ( "Double '=' at line %i, format for a Maya.env line is <VAR> = <value>, line ignored" % (self.lexer.lineno), ExecutionWarning)
        # skip whole line
        self.lexer.begin('cancel')
        while self.lexer.lexpos<self.lexer.lexlen and self.lexer.lexdata[self.lexer.lexpos] != '\n' :
            self.lexer.skip(1)
    def t_end_ASSIGN(self, t):
        r'[ \t]*=[ \t]*'
        warnings.warn ( "More than one '=' at line %i, format for a Maya.env line is <VAR> = <value>, line ignored" % (self.lexer.lineno), ExecutionWarning)
        # skip whole line
        self.lexer.begin('cancel')
        while self.lexer.lexpos<self.lexer.lexlen and self.lexer.lexdata[self.lexer.lexpos] != '\n' :
            self.lexer.skip(1)
    # r-values will be parsed again depending on os name
    def t_end_VALUE(self, t):
        r'[^=^\n^#]+'
        # one and only one VALUE on right side of ASSIGN
        warnings.warn ( "More than one value at line %i, format for a Maya.env line is <VAR> = <value>, line ignored" % (self.lexer.lineno), ExecutionWarning)
        # skip whole line
        self.lexer.begin('cancel')
        while self.lexer.lexpos<self.lexer.lexlen and self.lexer.lexdata[self.lexer.lexpos] != '\n' :
            self.lexer.skip(1)
    # Ignore ending spaces and count line no
    def t_ANY_newline(self, t):
        r'[ \t]*\n+'
        st = self.lexer.current_state()
        if st == 'end' :
            t.type = 'OK'
            t.value = self.line
        elif st == 'INITIAL' :
            pass
        else :
            t.type = 'CANCEL'
            v = ''
            i = self.lexer.lexpos-2
            while i>0 and self.lexer.lexdata[i] != '\n' :
                v = self.lexer.lexdata[i] + v
                i -= 1
            t.value = v
        self.lexer.begin('INITIAL')
        self.line = ''
        # Cound nb of new lines, removing white space
        self.lexer.lineno += len(t.value.lstrip(' \t'))
        return t
    # Error handling rules
    def t_ANY_error(self, t):
        warnings.warn ( "Illegal character '%s' at line %i, ignored" % (t.value[0], self.lexer.lineno), ExecutionWarning)
        self.lexer.skip(1)
    def t_INITIAL_error(self, t):
        warnings.warn ( "Invalid VAR name '%s' at line %i, line ignored" % (t.value[0], self.lexer.lineno), ExecutionWarning)
        # skip whole line
        while self.lexer.lexpos<self.lexer.lexlen and self.lexer.lexdata[self.lexer.lexpos] != '\n' :
            self.lexer.skip(1)
    def t_left_error(self, t):
        warnings.warn ( "Illegal value '%s' at line %i, format for a Maya.env line is <VAR> = <value>, line ignored" % (t.value[0], self.lexer.lineno), ExecutionWarning)
        # skip whole line
        while self.lexer.lexpos<self.lexer.lexlen and self.lexer.lexdata[self.lexer.lexpos] != '\n' :
            self.lexer.skip(1)
    def t_right_error(self, t):
        warnings.warn ( "Illegal value '%s' at line %i, line ignored" % (t.value[0], self.lexer.lineno), ExecutionWarning)
        # skip whole line
        while self.lexer.lexpos<self.lexer.lexlen and self.lexer.lexdata[self.lexer.lexpos] != '\n' :
            self.lexer.skip(1)

    # Test it
    def test(self,data):
        self.lexer.input(data)
        while 1:
             tok = self.lexer.token()
             if not tok: break
             print tok

# second level lexer : os dependant parsing of values and variable substitution
class ValueLex :
    """ second level lexer to parse right-values depending on os name """

    class Warn :
        """ a ValueLex subclass to reset warning count """
        def __init__(self):
            self.SEP = False
            self.VAR = False
            self.PATH = False

    def __init__(self, symbols, osname = os.name):
        self.os = osname
        self.symbols = symbols
        self.line = 0
        self.warn = ValueLex.Warn()
    def build(self, **kwargs):
        self.lexer = lex.lex(object=self,**kwargs)

    tokens = (
        'SEP',
        'RVAR1',
        'RVAR2',
        'PATHSEP',
        'VALUE'
    )
    # ignore ending space
    t_ignore = '^[ \t]+'

    def t_SEP(self, t):
        r':;'
        if t.value==';' and self.os != 'nt' :
            # t.value = ':'
            if not self.warn.SEP :
                warnings.warn ( "Line %i: the ';' separator should only be used on nt os, on linux or osx use ':' rather" % self.lexer.lineno, ExecutionWarning)
                self.warn.SEP = True
        return t
    # Valid l-values are env var names, must come first in line (INITIAL sate)
    def t_RVAR1(self, t) :
        r'\$[^\\^/^:^*^"^<^>^|^=^ ^\t^\n^#^$]+'
        if self.os == 'nt' :
            if not self.warn.VAR :
                warnings.warn ( "Line %i: $VAR should be used on linux or osx, \%VAR\% on nt" % self.lexer.lineno, ExecutionWarning)
                self.warn.VAR = True
        v = t.value.lstrip('$')
        if self.symbols.has_key(v) :
            t.value = self.symbols[v]
        return t
    def t_RVAR2(self, t) :
        r'\%[^\\^/^:^*^"^<^>^|^=^ ^\t^\n^#]+\%'
        if self.os != 'nt' :
            if not self.warn.VAR :
                warnings.warn ( "Line %i: $VAR should be used on linux or osx, \%VAR\% on nt" % self.lexer.lineno, ExecutionWarning)
                self.warn.VAR = True
        v = t.value.strip('%')
        if self.symbols.has_key(v) :
            t.value = self.symbols[v]
        return t
    # Assignation sign, ignore spaces around it
    def t_PATHSEP(self, t) :
        r'\/|\\'
        if self.os != 'nt' and t.value == '\\':
            if not self.warn.PATH :
                warnings.warn ( "Line %i: the '\\' path separator should only be used on nt, on linux or osx use '/' rather" % self.lexer.lineno, ExecutionWarning)
                self.warn.PATH = True
        return t
    # we just return the rest as-is
    # TODO: warnings if it's a path and path doesn't exist ?
    # Would need to differentiate % or $ wether we are on nt or not but py.lex
    # handles definitions strangely, like they are static / source time evaluated
    # removed % from the list of excluded characters as some definitions seem to use it :
    # $RMSTREE/icons/%B
    # TODO : Never seen it elsewhere, must check it doesn't collide with %VARNAME% on NT
    def t_VALUE(self, t):
            r'[^=^\n^#^$]+'
            return t

    def t_error(self, t):
        warnings.warn ( "Illegal character '%s' at line %i, ignored" % (t.value[0], self.lexer.lineno), ExecutionWarning)
        self.lexer.skip(1)

    # Test it
    def test(self,data):
        self.lexer.input(data)
        while 1:
            tok = self.lexer.token()
            if not tok: break
            print tok

# Do the 2 level parse of a Maya.env format text and return a symbol table of the declared env vars
def parse(text, environ=os.environ, osname=os.name):
    symbols = environ.copy()
    newsymbols = {}
    # first level lexer
    envLex = EnvLex()
    envLex.build()
    sep = os.path.pathsep
    # easier if we have a closing newline before eof
    if not text.endswith('\n') :
        text += '\n'
    envLex.lexer.input(text)
    # second level lexer for values
    valueLex =  ValueLex(symbols, osname)
    valueLex.build()
    tok = 'dummy'
    while tok:
        tok = envLex.lexer.token()
        if tok is not None :
            if tok.type=='VAR' :
                var = tok.value
            elif tok.type=='VALUE' :
                value = tok.value
            elif tok.type=='OK' :
                # secondary parsing on value depending on os
                # update defined env vars up to now
                if var is not None :
                    # It's quite hard to guess what Maya does with pre-existant env vars when they are also declared
                    # in Maya.env. It seems to ignore Maya,env in most of these cases, except for MAYA_SCRIPT_PATH
                    # where it will add the content o Maya.env to the predefined var
                    # for PATH, MAYA_PLUGIN_PATH and LD_LIBRARY_PATH on linux it seems to add his own stuff, disreguarding
                    # Maya.env if the the variable was pre-existant. If you notice (or want) different behaviors you can
                    # change it here
                    newvalue = None
                    action = 'Ignore'
                    if symbols.has_key(var) :

                        # For these variables ONLY, maya will append the value in maya.env to an exisiting environment variable
                        # (Default is for already defined value to override value in maya.env)
                        # (note the LACK of PYTHONPATH here... boo!)
                        if var in ('MAYA_SCRIPT_PATH',
                                   'MAYA_PLUG_IN_PATH',
                                   'MAYA_MODULE_PATH',
                                   'XBMLANGPATH'):
                            newvalue = self.symbols[var]+sep
                            action = 'Add'
                    else :
                        newvalue = ''
                        action = 'Set'
                    if newvalue is not None :
                        # only display warning for a better feedback there,
                        # as even if it makes no sense we can in all cases affect the value to the env var
                        valueLex.symbols = symbols
                        valueLex.lexer.input(value)
                        valueLex.lexer.lineno = tok.lineno
                        valueLex.warn = ValueLex.Warn()
                        vtok = 'dummy'
                        while vtok:
                            vtok = valueLex.lexer.token()
                            if vtok is not None :
                                newvalue += vtok.value
                        symbols[var] = newvalue
                        newsymbols[var] = newvalue
                    if action == 'Set' :
                        print u"%s set to value %s" % (var, unicode(newvalue))
                    elif action == 'Add' :
                        print u"%s was already set, appending value: %s" % (var, unicode(newvalue))
                    elif action == 'Ignore' :
                        print u"%s was already set, ignoring line: %s" % (var, unicode(tok.value))
                var = value = None
            elif tok.type=='CANCEL' :
                print "Line was ignored due to parsing errors: %s" % unicode(tok.value)
                var = value = None
            else :
                pass

    return newsymbols

# parse the Maya.env file and set the environment variables and python path accordingly
def parseMayaenv(envLocation=None, version=None) :
    """ parse the Maya.env file and set the environement variablas and python path accordingly.
        You can specify a location for the Maya.env file or the Maya version"""
    name = 'Maya.env'


    envPath = None
    if envLocation :
        envPath = envLocation
        if not os.path.isfile(envPath) :
            envPath = os.path.join(envPath, name)

    # no Maya.env specified, we look for it in MAYA_APP_DIR
    if not envPath or not envPath.isfile() :
        maya_app_dir = getMayaAppDir()
        if not maya_app_dir:
            _logger.warn("Neither HOME nor MAYA_APP_DIR is set, unable to find location of Maya.env")
            return False

        # try to find which version of Maya should be initialized
        if not version :
            # try to query version, will only work if reparsing env from a working Maya
            version = Version.installName()
            if version is None:
                # if run from Maya provided mayapy / python interpreter, can guess version
                _logger.debug("Unable to determine which verson of Maya should be initialized, trying for Maya.env in %s" % maya_app_dir)
        # look first for Maya.env in 'version' subdir of MAYA_APP_DIR, then directly in MAYA_APP_DIR
        if version and os.path.isfile(os.path.join(maya_app_dir, version, name)) :
            envPath = os.path.join(maya_app_dir, version, name)
        else :
            envPath = os.path.join(maya_app_dir, name)

    # finally if we have a possible Maya.env, parse it
    if os.path.isfile(envPath) :
        try :
            envFile = open(envPath)
        except :
            _logger.warn ("Unable to open Maya.env file %s" % envPath )
            return False
        success = False
        try :
            envTxt = envFile.read()
            envVars = parse(envTxt)
            # update env vars
            for v in envVars :
                #_logger.debug("%s was set or modified" % v)
                os.environ[v] = envVars[v]
            # add to syspath
            if envVars.has_key('PYTHONPATH') :
                #_logger.debug("sys.path will be updated")
                plist = os.environ['PYTHONPATH'].split(os.pathsep)
                for p in plist :
                    if not p in sys.path :
                        sys.path.append(p)
            success = True
        finally :
            envFile.close()
            return success
    else :
        if version :
            print"Found no suitable Maya.env file for Maya version %s" % version
        else :
            print"Found no suitable Maya.env file"
        return False
########NEW FILE########
__FILENAME__ = ipymel
"""
prototype for a pymel ipython configuration

Current Features:
    tab completion of depend nodes, dag nodes, and attributes
    automatic import of pymel

Future Features:
    tab completion of PyNode attributes
    color coding of tab complete options:
        - to differentiate between methods and attributes
        - dag nodes vs depend nodes
        - shortNames vs longNames
    magic commands
    bookmarking of maya's recent project and files

To Use:
    place in your PYTHONPATH
    add the following line to the 'main' function of $HOME/.ipython/ipy_user_conf.py::

        import ipymel

Author: Chad Dombrova
Version: 0.1
"""
from optparse import OptionParser
try:
    import maya
except ImportError, e:
    print( "ipymel can only be setup if the maya package can be imported" )
    raise e


import IPython

ipy_ver = IPython.__version__.split('.')
ipy_ver = [int(x) if x.isdigit() else x for x in ipy_ver]

ver11 = ipy_ver >= [0,11]

if not ver11:
    def get_ipython():
        import IPython.ipapi
        return IPython.ipapi.get()

    IPython.ipapi.IPApi.define_magic = IPython.ipapi.IPApi.expose_magic
    import IPython.ColorANSI as coloransi
    from IPython.genutils import page
    from IPython.ipapi import UsageError
    import IPython.Extensions.ipy_completers

    def get_colors(obj):
        return color_table[obj.rc.colors].colors
else:
    import IPython.utils.coloransi as coloransi
    from IPython.core.page import page
    from IPython.core.error import UsageError

    def get_colors(obj):
        return color_table[ip.colors].colors


Colors = coloransi.TermColors
ColorScheme = coloransi.ColorScheme
ColorSchemeTable = coloransi.ColorSchemeTable

ip = None

try:
    import readline
except ImportError:
    import pyreadline as readline
delim = readline.get_completer_delims()
delim = delim.replace('|', '') # remove pipes
delim = delim.replace(':', '') # remove colon
#delim = delim.replace("'", '') # remove quotes
#delim = delim.replace('"', '') # remove quotes
readline.set_completer_delims(delim)

import inspect, re, glob,os,shlex,sys

# don't import pymel here, as this will trigger loading of maya/pymel
# immediately, and things in the userSetup.py won't get properly entered into
# the ipython shell's namespace... we need the startup of maya to happen
# from "within" ipython, ie, when we do:
#   ip.ex("from pymel.core import *")
# from pymel import core

# ...maya.cmds is ok to import before maya is started up, though - it just
# won't be populated yet...
import maya.cmds as cmds

_scheme_default = 'Linux'

# Build a few color schemes
NoColor = ColorScheme(
    'NoColor',{
    'instance'              : Colors.NoColor,
    'collapsed'             : Colors.NoColor,
    'tree'                  : Colors.NoColor,
    'transform'             : Colors.NoColor,
    'shape'                 : Colors.NoColor,
    'nonunique'             : Colors.NoColor,
    'nonunique_transform'   : Colors.NoColor,

    'normal'                : Colors.NoColor  # color off (usu. Colors.Normal)
    } )

LinuxColors = ColorScheme(
    'Linux',{
    'instance'              : Colors.LightCyan,
    'collapsed'             : Colors.Yellow,
    'tree'                  : Colors.Green,
    'transform'             : Colors.White,
    'shape'                 : Colors.LightGray,
    'nonunique'             : Colors.Red,
    'nonunique_transform'   : Colors.LightRed,

    'normal'                : Colors.Normal  # color off (usu. Colors.Normal)
    } )

LightBGColors = ColorScheme(
    'LightBG',{
    'instance'              : Colors.Cyan,
    'collapsed'             : Colors.LightGreen,
    'tree'                  : Colors.Blue,
    'transform'             : Colors.DarkGray,
    'shape'                 : Colors.Black,
    'nonunique'             : Colors.Red,
    'nonunique_transform'   : Colors.LightRed,

    'normal'                : Colors.Normal  # color off (usu. Colors.Normal)
    } )

# Build table of color schemes (needed by the dag_parser)
color_table = ColorSchemeTable([NoColor,LinuxColors,LightBGColors],
                                  _scheme_default)


def finalPipe(obj):
    """
    DAG nodes with children should end in a pipe (|), so that each successive pressing
    of TAB will take you further down the DAG hierarchy.  this is analagous to TAB
    completion of directories, which always places a final slash (/) after a directory.
    """

    if cmds.listRelatives( obj ):
        return obj + "|"
    return obj

def splitDag(obj):
    buf = obj.split('|')
    tail = buf[-1]
    path = '|'.join( buf[:-1] )
    return path, tail

def expand( obj ):
    """
    allows for completion of objects that reside within a namespace. for example,
    ``tra*`` will match ``trak:camera`` and ``tram``

    for now, we will hardwire the search to a depth of three recursive namespaces.
    TODO:
    add some code to determine how deep we should go

    """
    return (obj + '*', obj + '*:*', obj + '*:*:*')

def complete_node_with_no_path( node ):
    tmpres = cmds.ls( expand(node) )
    #print "node_with_no_path", tmpres, node, expand(node)
    res = []
    for x in tmpres:
        x =  finalPipe(x.split('|')[-1])
        #x = finalPipe(x)
        if x not in res:
            res.append( x )
    #print res
    return res

def complete_node_with_attr( node, attr ):
    #print "noe_with_attr", node, attr
    long_attrs = cmds.listAttr( node )
    short_attrs = cmds.listAttr( node , shortNames=1)
    # if node is a plug  ( 'persp.t' ), the first result will be the passed plug
    if '.' in node:
        attrs = long_attrs[1:] + short_attrs[1:]
    else:
        attrs = long_attrs + short_attrs
    return [ u'%s.%s' % ( node, a) for a in attrs if a.startswith(attr) ]

def pymel_name_completer(self, event):

    def get_children(obj):
        path, partialObj = splitDag(obj)
        #print "getting children", repr(path), repr(partialObj)

        try:
            fullpath = cmds.ls( path, l=1 )[0]
            if not fullpath: return []
            children = cmds.listRelatives( fullpath , f=1, c=1)
            if not children: return []
        except:
            return []

        matchStr = fullpath + '|' + partialObj
        #print "children", children
        #print matchStr, fullpath, path
        matches = [ x.replace( fullpath, path, 1) for x in children if x.startswith( matchStr ) ]
        #print matches
        return matches

    #print "\nnode", repr(event.symbol), repr(event.line)
    #print "\nbegin"
    line = event.symbol

    matches = None

    #--------------
    # Attributes
    #--------------
    m = re.match( r"""([a-zA-Z_0-9|:.]+)\.(\w*)$""", line)
    if m:
        node, attr = m.groups()
        if node == 'SCENE':
            res = cmds.ls( attr + '*' )
            if res:
                matches = ['SCENE.' + x for x in res if '|' not in x ]
        elif node.startswith('SCENE.'):
            node = node.replace('SCENE.', '')
            matches = ['SCENE.' + x for x in complete_node_with_attr(node, attr) if '|' not in x ]
        else:
            matches = complete_node_with_attr(node, attr)

    #--------------
    # Nodes
    #--------------

    else:
        # we don't yet have a full node
        if '|' not in line or (line.startswith('|') and line.count('|') == 1):
            #print "partial node"
            kwargs = {}
            if line.startswith('|'):
                kwargs['l'] = True
            matches = cmds.ls( expand(line), **kwargs )

        # we have a full node, get it's children
        else:
            matches = get_children(line)

    if not matches:
        raise IPython.ipapi.TryNext

    # if we have only one match, get the children as well
    if len(matches)==1:
        res = get_children(matches[0] + '|')
        matches += res
    return matches


def pymel_python_completer(self,event):
    """Match attributes or global python names"""
    import pymel.core as pm

    #print "python_matches"
    text = event.symbol
    #print repr(text)
    # Another option, seems to work great. Catches things like ''.<tab>
    m = re.match(r"(\S+(\.\w+)*)\.(\w*)$", text)

    if not m:
        raise IPython.ipapi.TryNext

    expr, attr = m.group(1, 3)
    #print type(self.Completer), dir(self.Completer)
    #print self.Completer.namespace
    #print self.Completer.global_namespace
    try:
        #print "first"
        obj = eval(expr, self.Completer.namespace)
    except:
        try:
            #print "second"
            obj = eval(expr, self.Completer.global_namespace)
        except:
            raise IPython.ipapi.TryNext
    #print "complete"
    if isinstance(obj, (pm.nt.DependNode, pm.Attribute) ):
        #print "isinstance"
        node = unicode(obj)
        long_attrs = cmds.listAttr( node )
        short_attrs = cmds.listAttr( node , shortNames=1)

        matches = []
        matches = self.Completer.python_matches(text)
        #print "here"
        # if node is a plug  ( 'persp.t' ), the first result will be the passed plug
        if '.' in node:
            attrs = long_attrs[1:] + short_attrs[1:]
        else:
            attrs = long_attrs + short_attrs
        #print "returning"
        matches += [ expr + '.' + at for at in attrs ]
        #import colorize
        #matches = [ colorize.colorize(x,'magenta') for x in matches ]
        return matches

    raise IPython.ipapi.TryNext

def buildRecentFileMenu():
    import pymel.core as pm

    if "RecentFilesList" not in pm.optionVar:
        return

    # get the list
    RecentFilesList = pm.optionVar["RecentFilesList"]
    nNumItems = len(RecentFilesList)
    RecentFilesMaxSize = pm.optionVar["RecentFilesMaxSize"]

#        # check if there are too many items in the list
#        if (RecentFilesMaxSize < nNumItems):
#
#            #if so, truncate the list
#            nNumItemsToBeRemoved = nNumItems - RecentFilesMaxSize
#
#            #Begin removing items from the head of the array (least recent file in the list)
#            for ($i = 0; $i < $nNumItemsToBeRemoved; $i++):
#
#                core.optionVar -removeFromArray "RecentFilesList" 0;
#
#            RecentFilesList = core.optionVar["RecentFilesList"]
#            nNumItems = len($RecentFilesList);


    # The RecentFilesTypeList optionVar may not exist since it was
    # added after the RecentFilesList optionVar. If it doesn't exist,
    # we create it and initialize it with a guess at the file type
    if nNumItems > 0 :
        if "RecentFilesTypeList" not in pm.optionVar:
            pm.mel.initRecentFilesTypeList( RecentFilesList )

        RecentFilesTypeList = pm.optionVar["RecentFilesTypeList"]


    #toNativePath
    # first, check if we are the same.

def open_completer(self, event):
    relpath = event.symbol
    #print event # dbg
    if '-b' in event.line:
        # return only bookmark completions
        bkms = self.db.get('bookmarks',{})
        return bkms.keys()


    if event.symbol == '-':
        print "completer"
        width_dh = str(len(str(len(ip.user_ns['_sh']) + 1)))
        print width_dh
        # jump in directory history by number
        fmt = '-%0' + width_dh +'d [%s]'
        ents = [ fmt % (i,s) for i,s in enumerate(ip.user_ns['_sh'])]
        if len(ents) > 1:
            return ents
        return []

    raise IPython.ipapi.TryNext

class TreePager(object):
    def __init__(self, colors, options):
        self.colors = colors
        self.options = options

    #print options.depth
    def do_level(self, obj, depth, isLast ):
        if isLast[-1]:
            sep = '`-- '
        else:
            sep = '|-- '
        #sep = '|__ '
        depth += 1
        branch = ''
        for x in isLast[:-1]:
            if x:
                branch += '    '
            else:
                branch += '|   '
        branch = self.colors['tree'] + branch + sep + self.colors['normal']

        children = self.getChildren(obj)
        name = self.getName(obj)

        num = len(children)-1

        if children:
            if self.options.maxdepth and depth >= self.options.maxdepth:
                state = '+'
            else:
                state = '-'
            pre = self.colors['collapsed'] + state + ' '
        else:
            pre = '  '

        yield  pre + branch + name + self.colors['normal'] + '\n'
        #yield  Colors.Yellow + branch + sep + Colors.Normal+ name + '\n'

        if not self.options.maxdepth or depth < self.options.maxdepth:
            for i, x in enumerate(children):
                for line in self.do_level(x, depth, isLast+[i==num]):
                    yield line

    def make_tree(self, roots):
        num = len(roots)-1
        tree = ''
        for i, x in enumerate(roots):
            for line in self.do_level(x, 0, [i==num]):
                tree += line
        return tree

class DagTree(TreePager):
    def getChildren(self, obj):
        if self.options.shapes:
            return obj.getChildren()
        else:
            return obj.getChildren(type='transform')

    def getName(self, obj):
        import pymel.core as pm
        name = obj.nodeName()

        if obj.isInstanced():
            if isinstance(obj, pm.nt.Transform):
                # keep transforms bolded
                color = self.colors['nonunique_transform']
            else:
                color = self.colors['nonunique']
            id = obj.instanceNumber()
            if id != 0:
                source = ' -> %s' % obj.getOtherInstances()[0]
            else:
                source = ''
            name = color + name + self.colors['instance'] + ' [' + str(id) + ']' + source
        elif not obj.isUniquelyNamed():
            if isinstance(obj, pm.nt.Transform):
                # keep transforms bolded
                color = self.colors['nonunique_transform']
            else:
                color = self.colors['nonunique']
            name = color + name
        elif isinstance(obj, pm.nt.Transform):
            # bold
            name = self.colors['transform'] + name
        else:
            name = self.colors['shape'] + name

        return name

dag_parser = OptionParser()
dag_parser.add_option("-d", type="int", dest="maxdepth")
dag_parser.add_option("-t", action="store_false", dest="shapes", default=True)
dag_parser.add_option("-s", action="store_true", dest="shapes" )
def magic_dag(self, parameter_s=''):
    """

    """
    import pymel.core as pm

    options, args = dag_parser.parse_args(parameter_s.split())
    colors = get_colors(self)
    dagtree = DagTree(colors, options)
    if args:
        roots = [pm.PyNode(args[0])]
    else:
        roots = pm.ls(assemblies=1)
    page(dagtree.make_tree(roots))

class DGHistoryTree(TreePager):
    def getChildren(self, obj):
        source, dest = obj
        return source.node().listConnections(plugs=True, connections=True, source=True, destination=False, sourceFirst=True)

    def getName(self, obj):
        source, dest = obj
        name = "%s -> %s" % (source, dest)
        return name

    def make_tree(self, root):
        import pymel.core as pm
        roots = pm.listConnections(root, plugs=True, connections=True, source=True, destination=False, sourceFirst=True)
        return TreePager.make_tree(self,roots)

dg_parser = OptionParser()
dg_parser.add_option("-d", type="int", dest="maxdepth")
dg_parser.add_option("-t", action="store_false", dest="shapes", default=True)
dg_parser.add_option("-s", action="store_true", dest="shapes" )
def magic_dghist(self, parameter_s=''):
    """

    """
    import pymel.core as pm

    options, args = dg_parser.parse_args(parameter_s.split())
    if not args:
        print "must pass in nodes to display the history of"
        return

    colors = get_colors(self)
    dgtree = DGHistoryTree(colors, options)

    roots = [pm.PyNode(args[0])]

    page(dgtree.make_tree(roots))

def magic_open(self, parameter_s=''):
    """Change the current working directory.

    This command automatically maintains an internal list of directories
    you visit during your IPython session, in the variable _sh. The
    command %dhist shows this history nicely formatted. You can also
    do 'cd -<tab>' to see directory history conveniently.

    Usage:

      openFile 'dir': changes to directory 'dir'.

      openFile -: changes to the last visited directory.

      openFile -<n>: changes to the n-th directory in the directory history.

      openFile --foo: change to directory that matches 'foo' in history

      openFile -b <bookmark_name>: jump to a bookmark set by %bookmark
         (note: cd <bookmark_name> is enough if there is no
          directory <bookmark_name>, but a bookmark with the name exists.)
          'cd -b <tab>' allows you to tab-complete bookmark names.

    Options:

    -q: quiet.  Do not print the working directory after the cd command is
    executed.  By default IPython's cd command does print this directory,
    since the default prompts do not display path information.

    Note that !cd doesn't work for this purpose because the shell where
    !command runs is immediately discarded after executing 'command'."""

    parameter_s = parameter_s.strip()
    #bkms = self.shell.persist.get("bookmarks",{})

    oldcwd = os.getcwd()
    numcd = re.match(r'(-)(\d+)$',parameter_s)
    # jump in directory history by number
    if numcd:
        nn = int(numcd.group(2))
        try:
            ps = ip.ev('_sh[%d]' % nn )
        except IndexError:
            print 'The requested directory does not exist in history.'
            return
        else:
            opts = {}
#        elif parameter_s.startswith('--'):
#            ps = None
#            fallback = None
#            pat = parameter_s[2:]
#            dh = self.shell.user_ns['_sh']
#            # first search only by basename (last component)
#            for ent in reversed(dh):
#                if pat in os.path.basename(ent) and os.path.isdir(ent):
#                    ps = ent
#                    break
#
#                if fallback is None and pat in ent and os.path.isdir(ent):
#                    fallback = ent
#
#            # if we have no last part match, pick the first full path match
#            if ps is None:
#                ps = fallback
#
#            if ps is None:
#                print "No matching entry in directory history"
#                return
#            else:
#                opts = {}


    else:
        #turn all non-space-escaping backslashes to slashes,
        # for c:\windows\directory\names\
        parameter_s = re.sub(r'\\(?! )','/', parameter_s)
        opts,ps = self.parse_options(parameter_s,'qb',mode='string')

    # jump to previous
    if ps == '-':
        try:
            ps = ip.ev('_sh[-2]' % nn )
        except IndexError:
            raise UsageError('%cd -: No previous directory to change to.')
#        # jump to bookmark if needed
#        else:
#            if not os.path.exists(ps) or opts.has_key('b'):
#                bkms = self.db.get('bookmarks', {})
#
#                if bkms.has_key(ps):
#                    target = bkms[ps]
#                    print '(bookmark:%s) -> %s' % (ps,target)
#                    ps = target
#                else:
#                    if opts.has_key('b'):
#                        raise UsageError("Bookmark '%s' not found.  "
#                              "Use '%%bookmark -l' to see your bookmarks." % ps)

    # at this point ps should point to the target dir
    if ps:
        ip.ex( 'openFile("%s", f=1)' % ps )
#            try:
#                os.chdir(os.path.expanduser(ps))
#                if self.shell.rc.term_title:
#                    #print 'set term title:',self.shell.rc.term_title  # dbg
#                    platutils.set_term_title('IPy ' + abbrev_cwd())
#            except OSError:
#                print sys.exc_info()[1]
#            else:
#                cwd = os.getcwd()
#                dhist = self.shell.user_ns['_sh']
#                if oldcwd != cwd:
#                    dhist.append(cwd)
#                    self.db['dhist'] = compress_dhist(dhist)[-100:]

#        else:
#            os.chdir(self.shell.home_dir)
#            if self.shell.rc.term_title:
#                platutils.set_term_title("IPy ~")
#            cwd = os.getcwd()
#            dhist = self.shell.user_ns['_sh']
#
#            if oldcwd != cwd:
#                dhist.append(cwd)
#                self.db['dhist'] = compress_dhist(dhist)[-100:]
#        if not 'q' in opts and self.shell.user_ns['_sh']:
#            print self.shell.user_ns['_sh'][-1]

def setup(shell):
    global ip
    if hasattr(shell, 'get_ipython'):
        ip = shell.get_ipython()
    else:
        ip = get_ipython()

    ip.set_hook('complete_command', pymel_python_completer , re_key = ".*" )
    ip.set_hook('complete_command', pymel_name_completer , re_key = "(.+(\s+|\())|(SCENE\.)" )
    ip.set_hook('complete_command', open_completer , str_key = "openf" )

    ip.ex("from pymel.core import *")
    # stuff in __main__ is not necessarily in ipython's 'main' namespace... so
    # if the user has something in userSetup.py that he wants put in the
    # "interactive" namespace, it won't be - unless we do this:
    ip.ex('from __main__ import *')
    # if you don't want pymel imported into the main namespace, you can replace the above with something like:
    #ip.ex("import pymel as pm")

    ip.define_magic('openf', magic_open)
    ip.define_magic('dag', magic_dag)
    ip.define_magic('dghist', magic_dghist)

    # add projects
    ip.ex("""
import os.path
for _mayaproj in optionVar.get('RecentProjectsList', []):
    _mayaproj = os.path.join( _mayaproj, 'scenes' )
    if _mayaproj not in _dh:
        _dh.append(_mayaproj)""")

    # add files
    ip.ex("""
import os.path
_sh=[]
for _mayaproj in optionVar.get('RecentFilesList', []):
    if _mayaproj not in _sh:
        _sh.append(_mayaproj)""")

def main():
    import IPython

    ipy_ver = IPython.__version__.split('.')
    ipy_ver = [int(x) if x.isdigit() else x for x in ipy_ver]

    if ipy_ver < [0,11]:
        import IPython.Shell

        shell = IPython.Shell.start()
        setup(shell)
        shell.mainloop()
    else:
        import IPython.frontend.terminal.ipapp
        app = IPython.frontend.terminal.ipapp.TerminalIPythonApp.instance()
        app.initialize()
        setup(app.shell)
        app.start()

if __name__ == '__main__':
    main()
########NEW FILE########
__FILENAME__ = loggingControl
import pymel.all as pymel
import logging, logging.handlers
import sys
logger = logging.getLogger(__name__)

logLevelNames = [logging.getLevelName(n) for n in xrange(0,logging.CRITICAL+1,10)]
levelsDict = dict(zip(logLevelNames, range(0,logging.CRITICAL+1,10)))
levelsDict.update(dict(zip(range(0,logging.CRITICAL+1,10), logLevelNames)))

def refreshLoggerHierarchy():
    for v in logging.Logger.manager.loggerDict.values():
        try:
            del v.children
        except:pass

    for k, v in sorted(logging.Logger.manager.loggerDict.items()):
            if  not isinstance(v, logging.Logger):
                continue
            try:
                if v not in v.parent.children:
                    v.parent.children.append(v)
            except:
                v.parent.children = [v]

def initMenu():
    return LoggingMenu(parent=pymel.melGlobals["gMainWindow"])




class LoggingMenu(pymel.Menu):

    def refreshLoggingMenu(self):
        #pymel.Menu(self).deleteAllItems(1)
        self.buildSubMenu(self, logging.root)

    def changeLevel(self, item, level):
        logger.debug("Setting %s log level to %s" % (item, level))
        item.setLevel(levelsDict[level])

    def buildLevelMenu(self, parent, item):
        for level in logLevelNames:
            pymel.menuItem(p=parent, checkBox=levelsDict[item.level]==level, l=level, c=pymel.Callback(self.changeLevel, item, level))

    def buildSubMenu(self, parent, logger):
        #levelsMenu = pymel.menuItem(l="%s <%s>" % (logger.name, levelsDict[logger.level]),p=parent, sm=True)
        self.buildLevelMenu(parent, logger)
        pymel.menuItem(d=1,p=parent)
        try:
            if logger.children:
                pymel.menuItem(l="Child Loggers:",p=parent,en=0)
                for item in logger.children:
                    subMenu = pymel.menuItem(l=item.name, sm=True, p=parent, tearOff=True, aob=True, pmo=True)
                    subMenu.postMenuCommand(pymel.Callback(self.buildSubMenu, parent=subMenu, logger=item))
                    subMenu.setPostMenuCommandOnce(True)
        except: pass
        pymel.menuItem(d=1,p=parent)
        if logger.handlers:
            pymel.menuItem(l="Streams:",p=parent,en=0)
            for item in logger.handlers:
                levelsMenu = pymel.menuItem(l="%s <%s>" % (item.__class__.__name__, levelsDict[item.level]), p=parent, sm=True, aob=True)
                self.buildLevelMenu(levelsMenu, item)
                pymel.menuItem(d=1,p=levelsMenu)
                pymel.menuItem(l="Set Formatter", p=levelsMenu, c=pymel.Callback(self.setFormatter, item))
                pymel.menuItem(l="Remove", p=parent, ob=True, c=pymel.Callback(logger.removeHandler, item))
        pymel.menuItem(l="<New Stream...>", p=parent, c=lambda *x: self.addHandler(logger))

    def setFormatter(self, handler):
        tips = """
        name, levelno, levelname, pathname, filename, module, lineno, funcName, created,
        asctime, msecs, relativeCreated, thread, threadName, process, message
        """
        fmt = pymel.promptBox("Logging","Set Format:\n" + tips, "Set", "Cancel", tx=logging.BASIC_FORMAT)
        if fmt:
            handler.setFormatter(logging.Formatter(fmt))

    def addHandler(self, logger):
        mode = pymel.confirmBox("Logging","Handler Type:", "File", "Script Editor", "Console", "Log Server", "Cancel")
        if mode=="Cancel":
            return
        elif mode=="File":
            f = pymel.fileDialog(mode=1, dm="Log File: *.log")
            if not f:
                return
            handler = logging.FileHandler(f)
        elif mode=="Script Editor":
            handler = logging.StreamHandler()
        elif mode=="Console":
            handler = logging.StreamHandler(sys.__stderr__)
        elif mode=="Log Server":
            from logServer import SocketHandler, kHostName
            server = pymel.promptBox("Logging","Log Server Address:", "Connect", "Cancel", tx="%s:%s" % (kHostName, logging.handlers.DEFAULT_TCP_LOGGING_PORT))
            host, sep, port = server.partition(":")
            handler = SocketHandler(host, int(port))

        level = pymel.confirmBox("Logging","Log Level:", *logLevelNames)
        if not level:
            return
        handler.setLevel(levelsDict[level])
        handler.setFormatter(logging.Formatter(logging.BASIC_FORMAT))
        logger.addHandler(handler)
        logger.info("Added %s-Handler to Logger '%s' at level %s" % (mode, logger.name, level))

    def __new__(cls, name="pymelLoggingControl", parent=None):
        if pymel.menu(name, ex=1):
            pymel.deleteUI(name)
        self = pymel.menu(name, l='Logging Control', aob=True, p=parent)
        return pymel.Menu.__new__(cls, self)

    def __init__(self, name=None, parent=None):
        self.postMenuCommand(self.refresh)

    def refresh(self, *args):
        refreshLoggerHierarchy()
        self.deleteAllItems(1)
#        if logging.root.handlers:
#            self.buildLevelMenu(self, logging.root.handlers[0])
        pymel.menuItem(l="Root Logger:",p=self,en=0)
        #pymel.menuItem(divider=1, p=self)
        #self.menuLoggerTree = pymel.menuItem(p=self, l="Logger Tree", sm=True, aob=True)
        self.refreshLoggingMenu()
        #self.menuLoggerTree.postMenuCommand(self.refreshLoggingMenu)


########NEW FILE########
__FILENAME__ = mellex
# ----------------------------------------------------------------------
# clex.py
#
# A lexer for ANSI C.
# ----------------------------------------------------------------------

import sys
sys.path.insert(0,"../..")

try:
    import pymel.util.external.ply.lex as lex
except ImportError:
    import ply.lex as lex

# Reserved words

#removed 'AUTO', 'CONST',  'CHAR', 'DOUBLE','ENUM', 'EXTERN', 'LONG', 'REGISTER', 'SHORT', 'SIGNED', 'STATIC', 'STRUCT', 'TYPEDEF','UNION', 'UNSIGNED', 'VOID', 'VOLATILE','GOTO',


reserved = (
    'BREAK', 'CASE', 'CONTINUE', 'DEFAULT', 'DO',
    'ELSE', 'FALSE', 'FLOAT', 'FOR', 'GLOBAL', 'IF', 'IN', 'INT', 'NO', 'ON', 'OFF', 'PROC',
    'RETURN', 'STRING', 'SWITCH', 'TRUE', 'VECTOR', 'MATRIX',
    'WHILE', 'YES',
    )

tokens = reserved + (
    # Literals (identifier, integer constant, float constant, string constant, char const)
    'ID', 'VAR', 'ICONST', 'FCONST', 'SCONST',
    #'LOBJECT', 'ROBJECT',

    # Operators (+,-,*,/,%,^,<<,>>, ||, &&, !, <, <=, >, >=, ==, !=)
    'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'MOD',
    'NOT', 'CROSS',
    'LOR', 'LAND',
    'LT', 'LE', 'GT', 'GE', 'EQ', 'NE',

    # Assignment (=, *=, /=, %=, +=, -=, ^=)
    'EQUALS', 'TIMESEQUAL', 'DIVEQUAL', 'MODEQUAL', 'PLUSEQUAL', 'MINUSEQUAL',
    'CROSSEQUAL',

    # Vector Component
    'COMPONENT',

    # Increment/decrement (++,--)
    'PLUSPLUS', 'MINUSMINUS',

    # Conditional operator (?)
    'CONDOP',

    # Delimeters ( ) [ ] { } , . ; :
    'LPAREN', 'RPAREN',
    'LBRACKET', 'RBRACKET',
    'LBRACE', 'RBRACE',
    'COMMA', 'SEMI', 'COLON',
    'CAPTURE',
    'LVEC', 'RVEC',

    # Comments
    'COMMENT', 'COMMENT_BLOCK',

    # Ellipsis (..)
    'ELLIPSIS',
    )

# Completely ignored characters
t_ignore           = ' \t\x0c'

# Newlines
def t_NEWLINE(t):
    r'\n+|\r+'
    t.lexer.lineno += t.value.count("\n")



# Operators
t_PLUS               = r'\+'
t_MINUS            = r'-'
t_TIMES               = r'\*'
t_DIVIDE           = r'/'
t_MOD               = r'%'
#t_OR               = r'\|'
#t_AND               = r'&'
t_NOT               = r'!'
t_CROSS               = r'\^'
t_LVEC               = r'<<'
t_RVEC                = r'>>'
t_LOR               = r'\|\|'
t_LAND               = r'&&'
t_LT               = r'<'
t_GT               = r'>'
t_LE               = r'<='
t_GE               = r'>='
t_EQ               = r'=='
t_NE               = r'!='

# Assignment operators

t_EQUALS           = r'='
t_TIMESEQUAL       = r'\*='
t_DIVEQUAL           = r'/='
t_MODEQUAL           = r'%='
t_PLUSEQUAL           = r'\+='
t_MINUSEQUAL       = r'-='
t_CROSSEQUAL       = r'^='

# Increment/decrement
t_PLUSPLUS           = r'\+\+'
t_MINUSMINUS       = r'--'

# ?
t_CONDOP           = r'\?'

# Delimeters
#t_LBRACKET           = r'\['
#t_RBRACKET           = r'\]'
t_LBRACE           = r'\{'
t_RBRACE           = r'\}'
t_COMMA               = r','
#t_SEMI               = r';'
t_COLON               = r':'
#t_COMPONENT           = r'\.[xyz]'

# Identifiers and reserved words

reserved_map = { }
for r in reserved:
    reserved_map[r.lower()] = r

#print reserved_map

id_state = None
suspend_depth = 0


def t_LPAREN(t):
    r'\('
    return t

def t_RPAREN(t):
    r'\)'
    return t

#def t_LOBJECT(t):
#    r'([|]?([:]?([.]?[A-Za-z_][\w]*)+)+)+?\['
#    return t

#def t_ROBJECT(t):
#    r'\]([|]?([:]?([.]?[A-Za-z_][\w]*)+)+)+?'
#    return t

def t_LBRACKET(t):
    r'\['
    return t

def t_RBRACKET(t):
    r'\]'
    return t

def t_CAPTURE(t):
    r'`'
    return t

def t_SEMI(t):
    r';'
    return t

def t_VAR(t):
    r'\$[A-Za-z_][\w_]*'
    return t

def t_COMPONENT(t):
    r'\.[xyz]'
    return t

def t_ELLIPSIS(t):
    r'\.\.'
    return t



def t_ID(t):
    # Starts with a letter or a pipe
    #
    # |path|myPrfx_1:myNode_1.myAttr_1[0].subAttr   or  ..
    #r'[A-Za-z_|](?:[\w_\.:|]|(?:\[\d+\]))*|\.\.'
    #r'[A-Za-z_|]([\w_\.:|]|(\[\d+\]))*|\.\.'
    #r'[A-Za-z_|][\w_\.:|]*(?:[\w_]|(?:\[\d+\]))+|[A-Za-z_]|\.\.'
    # '(%(id)s)*([.|](%(id)s)+)*[.|]?*|\.\.' % {'id': '[A-Za-z_][\w:]*(\[\d+\])?'}

    #   |    :    .     idName        [0]
    #r'([|]?([:]?([.]?[A-Za-z_][\w]*(\[\d+\])?)+)+)+?|\.\.'
    #   |    :    .     idName        [0] or [$var]
    #r'([|]?([:]?([.]?[A-Za-z_][\w]*(\[(\d+)|(\$[A-Za-z_][\w_]*)\])?)+)+)+?|\.\.'

    #r'[A-Za-z_][\w]*'
    r'([|]?([:]?([.]?[A-Za-z_][\w]*)+)+)+?'
    t.type = reserved_map.get(t.value,"ID")
    return t

#def t_OBJECT(t):
#
#    #   |    :    .     idName        [0]
#    #r'([|]?([:]?([.]?[A-Za-z_][\w]*(\[\d+\])?)+)+)+?|\.\.'
#
#    #r'[A-Za-z_][\w]|\.\.'
#    r'([|]?([:]?([.]?[A-Za-z_][\w]*)+)+)+?'
#    return t

# Integer literal
#t_ICONST = r'\d+([uU]|[lL]|[uU][lL]|[lL][uU])?'
t_ICONST = r'(0x[a-fA-F0-9]*)|\d+'

# Floating literal
#t_FCONST = r'((\d+)?(\.\d+)(e(\+|-)?(\d+))?|(\d+)e(\+|-)?(\d+))([lL]|[fF])?' # does not allow  1.
t_FCONST = r'(((\d+\.)(\d+)?|(\d+)?(\.\d+))(e(\+|-)?(\d+))?|(\d+)e(\+|-)?(\d+))([lL]|[fF])?'

# String literal
#t_SCONST = r'\"([^\\\n]|(\\.))*?\"' # does not allow \ for spanning multiple lines
#t_SCONST = '\"([^\n]|\r)*\"'
#t_SCONST = r'"([^\n]|\\\n)*?"'
t_SCONST = r'"([^\\\n]|(\\.)|\\\n)*?"'

# Comments
def t_COMMENT_BLOCK(t):
    r'/\*(.|\n)*?\*/|/\*(.|\n)*?$'
    #r'/\*(.|\n)*?\*/'

    #r'/\*(.|\n)*?\*/|/\*(.|\n)*?$'
    # the second half of this regex is for matching block comments that
    # are terminated by the end of the file instead of by */

    t.lexer.lineno += t.value.count('\n')
    return t

def t_COMMENT(t):
    r'//.*'
    #t.lexer.lineno += t.value.count('\n')
    return t

#def t_INVALID(t):
#    r'[.~\|\'"]'
#    # these symbols cannot be used on their own,
#    # without this entry, they would simply be ignored rather than raising an error
#    return t

#def t_error(t):
#    #print "Illegal character %s" % repr(t.value[0])
#    t.lexer.skip(1)

#def t_error(t):
#    return t

#lexer = lex.lex(optimize=1)
#lexer = lex.lex()
#if __name__ == "__main__":
#    lex.runmain(lexer)





########NEW FILE########
__FILENAME__ = melparse
#! /usr/local/bin/python

"""

Created from the ansi c example included with ply, which is based on the grammar in K&R, 2nd Ed.

"""


import sys, os, re, os.path, tempfile, string
import mellex

try:
    from pymel.util.external.ply import *
    import pymel.util.external.ply.lex
except ImportError:
    from ply import *
    import ply.lex

from pymel.util import unescape
from pymel.util.utilitytypes import TwoWayDict
import pymel
import pymel.util as util
import pymel.internal.factories as factories
import melscan

try:
    from pymel.core import *
except ImportError:
    print "maya.cmds module cannot be found. be sure to run this script through maya and not from the command line. Continuing, but without command support"

#mutableStr = proxyClass(str, 'mutableStr', module=__name__)

#  Global variables + constants ------------------------------------------------

FLAG_RE = re.compile("-\s*([A-Za-z][\w_]*)$")

NON_COMMENT_LINE_RE = re.compile('^\s*[^\s#]', re.MULTILINE)

# commands which should not be brought into main namespace
filteredCmds = ['file', 'filter', 'help', 'quit', 'sets', 'move', 'scale', 'rotate']
builtin_module = __import__('__main__').__builtins__
pythonReservedWords = ['and', 'del', 'from', 'not', 'while', 'as', 'elif', 'global', 'or',
                       'with', 'assert', 'else', 'if', 'pass', 'yield', 'break', 'except',
                       'import', 'print', 'class', 'exec', 'in', 'raise', 'continue',
                       'finally', 'is', 'return', 'def', 'for', 'lambda', 'try']

reserved= set( dir(builtin_module) )
reserved.update( pythonReservedWords )

mel_type_to_python_type = {
    'string'    : 'str',
    'int'       : 'int',
    'float'     : 'float',
    'vector'    : 'Vector',
    'matrix'    : 'Matrix',
    }

default_values = {
    'string'    : '""',
    'int'       : '0',
    'float'     : '0.0',
    'vector'    : 'Vector()',
    'matrix'    : 'Matrix()',
    }

tag = '# script created by pymel.tools.mel2py'

# Get the list of reserved words -- any variables or procedures that conflict with these keywords will be renamed with a trailing underscore
tokens = mellex.tokens

#  Formating functions----------------------------------------------------------

def format_substring(x, t):
    """convert:
            substring( var, 2, (len(var)) )
        to:
            var[1:]

        or:
            substring( var, 2, var2 )
        to:
            var[1:var2]

        or:
            substring( var, 3, var2 )
        to:
            var[1:var2]
            """
    def makeSlice( var, arg, offset=0):
        if arg.startswith('(') and arg.endswith(')'):
            arg = arg[1:-1]
        try:
            return str( int(arg)+offset )
        except ValueError:
            m = re.match( '\(*\s*len\s*\(\s*' + var + '\s*\)\s*\)*(.*)', arg )
            if m:
                return m.group(1).replace(' ', '')
                #return m.group(1)

            else:
                res = str(arg)
                if offset != 0:
                    res = res + str(offset)
                return res

    start = makeSlice(x[0], x[1], -1)
    end = makeSlice(x[0], x[2])

    return '%s[%s:%s]' % (x[0], start, end )

def format_tokenize(x,t):
    if len(x) > 2:
        return Token( '%s=%s.split(%s)' % (x[2],x[0],x[1]), 'string', tokenize=x[2] )
    else:
        return Token( '%s=%s.split()' % (x[1],x[0]), 'string', tokenize=x[1] )

def format_tokenize_size( tokenized, sizeVar ):
    """tokenize fix:
    tokenize passes a buffer by reference, and returns a size.
    we must return a list, and compute the size as a second operation::

        int $size = `tokenize "foo bar", $buffer, " "`;

        buffer = "foo bar".split(' ')
        size = len(buffer)

    """
    buf = tokenized.__dict__.pop( 'tokenize' )
    return tokenized + '\n' + sizeVar + " = len(%s)\n" % buf

def format_fread(x, t):
    formatStr = {
         'string': "%s",
        'float'    : "%f",
        'int'    : "%d",
        'vector': "%f %f %f"
    }[x[1].type]
    return "fscanf(%s,'%s')" % (x[0], formatStr)

def format_fopen(x, t):
    try:
        mode = x[1]
    except IndexError:
        mode = "'w'"
    return 'open(%s,%s)' % (x[0], mode)



def format_source(x, t):
    script = eval(x[0])
    name = os.path.splitext( os.path.basename(script) )[0]
    #print "formatting source", name
    moduleName = _melObj_to_pyModule( name )
    if moduleName:
        if moduleName not in t.lexer.imported_modules:
            t.lexer.imported_modules.add(moduleName)
        return ''
    else:
        return '%smel.source(%s)' % (t.lexer.pymel_namespace, x[0] )

def format_command(command, args, t):
    if len(args) == 1 and args[0].startswith('(') and args[0].endswith(')'):
        args[0] = args[0][1:-1]

    if t.lexer.verbose:
        print 'p_command: input_list', command, args

    # commands with custom replacements
    try:
        typ, remap_func = proc_remap[command]
        return Token( remap_func(args, t), typ )
    except KeyError: pass

    #flags = getCommandFlags(command)

    # new-style from cached info
    try:
        cmdInfo = factories.cmdlist[command]
    except KeyError:
        try:
            cmdInfo = melCmdFlagList[command]
        except KeyError:
            # Mel procedures and commands without help documentation
            #if flags is None:
            args = [repr(x) if isinstance(x, basestring) and FLAG_RE.match(x)
                    else x for x in args]
            args = ', '.join(args)

            # function is being called locally, within same file
            if command in t.lexer.global_procs:
                #returnType = t.lexer.global_procs[command]['returnType']
                return '%s(%s)' % (command, args)
            if command in t.lexer.local_procs:
                #returnType = t.lexer.local_procs[command]['returnType']
                return '_%s(%s)' % (command, args)
            if command in melCmdList:
                return '%s(%s)' % (command, args)

            module, returnType = _melProc_to_pyModule( t, command )

            if module:
                # the procedure is in the currently parsed script, but has not yet been placed in global or local procs.
                if module == t.lexer.root_module:
                    res = '%s(%s)' % (command, args)
                else:
                    t.lexer.imported_modules.add( module )
                    res = '%s.%s(%s)' % (module, command, args)
            else:
                res = '%smel.%s(%s)' % (t.lexer.pymel_namespace, command, args)

            return res

    # commands with help documentation
    try:
        #print 'FLAGS', t[1], flags
        #print 'ARGS', args
        kwargs = {}
        pargs = []
        argTally=[]
        numArgs = 0
        commandFlag = False
        queryMode = False
        currFlag = None
        for token in args:
            flagmatch = FLAG_RE.match( token )

            #  Flag ------------------------------------------------------------
            if flagmatch:
                if numArgs > 0:
                    #raise ValueError, 'reached a new flag before receiving all necessary args for last flag'
                    if t.lexer.verbose >= 1: print 'reached a new flag before receiving all necessary args for last flag'
                    kwargs[currFlag]='1'
                    numArgs=0

                #(numArgs, commandFlag) = flags[ token ]

                # remove dash (-) before flag
                token = token[1:]

                # a special dict has been creatd to return the new name of flags removed due to name conflicts
                try:
                    token = Token( cmdInfo['removedFlags'][token], token.type, token.lineno )
                except KeyError: pass

                try:
                    flagInfo = cmdInfo['flags'][token]
                except:
                    longname = cmdInfo['shortFlags'][token]
                    flagInfo = cmdInfo['flags'][longname]
                numArgs = flagInfo['numArgs']
                commandFlag = 'command' in flagInfo['longname'].lower()

                #print 'new flag', token, numArgs

                if numArgs == 0 or queryMode:
                    kwargs[token]='1'
                    numArgs=0
                else:
                    currFlag = token

                # moved this after the queryMode check, bc sometimes the query flag expects a value other than a boolean
                if token in ['q', 'query']:
                    queryMode = True

            elif numArgs == 1:
                # callbacks
                if commandFlag:

                    cbParser = MelParser()
                    #print "root module for callback parsing", t.lexer.root_module
                    cbParser.build(rootModule = t.lexer.root_module,
                                   pymelNamespace=t.lexer.pymel_namespace,
                                   verbosity=t.lexer.verbose,
                                   expressionsOnly=True,
                                   parentData=t.lexer.raw_parse_data)

                    # pre-parse cleanup

                    tmpToken = token.strip()

                    # remove enclosing parentheses
                    # note - this is not totally correct.. if you have:
                    #   ($stuff) + ($thing)
                    # if will still strip off the start and end parentheses..
                    # however, if there are any parse errors, we fall back on
                    # the "default" mel.eval, which should work...
                    while tmpToken.startswith('(') and tmpToken.endswith(')'):
                        tmpToken = tmpToken[1:-1]
                        tmpToken = tmpToken.strip()

                    # again, unescaping might not be correct.. ie, if you have:
                    #    "my number is: " + $i + "... yay!"
                    # ...you will end up with garbage...
                    tmpToken = unescape(tmpToken)

                    # before unescaping, we might have:
                    #   '"cmd; "'
                    # so, after unescaping, we have:
                    #   'cmd; '
                    # ...so we need to do another strip...
                    tmpToken = tmpToken.strip()

                    if not tmpToken.endswith( ';' ):
                        tmpToken += ';'
                    cb = re.compile(  '#(\d)' )
                    parts = cb.split( tmpToken  )
                    for i in range(1,len(parts),2):
                        parts[i] = '$args[%d]' % ( int(parts[i] ) -1 )
                    tmpToken = ''.join( parts )

                    #print tmpToken

                    # parse
                    try:
                        tmpToken = cbParser.parse( tmpToken )
                    except Exception:
#                        print "error parsing callback:"
#                        print "-" * 60
#                        print tmpToken
#                        print "-" * 60
#                        traceback.print_exc()
                        #print "callback translation failed", msg
                        token = 'lambda *args: %smel.eval(%s)' % (t.lexer.pymel_namespace, token)
                    else:
                        #print tmpToken

                        # ensure that the result is not empty
                        assert tmpToken.strip()

                        t.lexer.imported_modules.update( cbParser.lexer.imported_modules )

                        # post-parse cleanup
                        statements = [x.strip() for x in tmpToken.split('\n') if x.strip()]
                        if len(statements) == 1:
                            tmpToken = statements[0]
                        else:
                            # turn it into a list, just so we can execute all
                            # statements in a single lambda 'statement'
                            tmpToken = '[%s]' % ', '.join(statements)
                        token = 'lambda *args: %s' % (tmpToken)


                argTally.append(token)
                #print 'last flag arg', currFlag, argTally
                if len(argTally)==1:
                    argTally = argTally[0]
                else:
                    argTally = '(%s)' % ', '.join(argTally)

                # mutliuse flag, ex.  ls -type 'mesh' -type 'camera'
                if currFlag in kwargs:
                    if isinstance(kwargs[currFlag], list):
                        kwargs[currFlag].append( argTally )
                        #print "appending kwarg", currFlag, kwargs
                    else:
                        kwargs[currFlag] = [ kwargs[currFlag], argTally ]
                        #print "adding kwarg", currFlag, kwargs
                else:
                    #print "new kwarg", currFlag, kwargs
                    kwargs[currFlag] = argTally

                numArgs=0
                argTally=[]
                currFlag = None

            elif numArgs > 0:
                argTally.append(token)
                #print 'adding arg', currFlag, argTally
                numArgs-=1
            else:
                pargs.append(token)
        """
        try:
            if kwargs[-1].endswith('='):
                kwargs[-1] += '1';
        except IndexError:
            pass
        """

        #print 'final kw list', kwargs

        # functions that clash with python keywords and ui functions must use the cmds namespace
        if command in filteredCmds: # + uiCommands:
            command = '%scmds.%s' % (t.lexer.pymel_namespace, command)

        # eval command is the same as using maya.mel.eval.  special commands: error, warning, and trace
        elif command == 'eval' or command in melCmdFlagList:
            command = '%smel.%s' % (t.lexer.pymel_namespace, command)

#        # ironically, the python command is a nightmare to convert to pure
#        # python - we need a return value, which means we can't use 'exec', but
#        # we need to be able to execute arbitrary statements, like imports,
#        # which means we can't use eval.
#        # So, just use the maya.cmds.python command...
#        elif command == 'python':
#            return 'eval(%s)' % args[0]
#            #args = map( lambda x: x.strip('"'), args[0].split(' + ') )
#            #return ''.join(args)

        # cycle through our kwargs and format them
        for flag, value in kwargs.items():
            if value is None:
                value = '1'

            # multi-use flag
            #    mel:     ls -type "transform" -type "camera"
            #    python:    ls( type=["transform", "camera"] )
            if isinstance( value, list):
                #sep = ', '
                #if len(value) > t.lexer.format_options['kwargs_newline_threshhold']:
                #    sep = ',\n\t'
                #pargs.append( '%s=[%s]' % ( flag, sep.join(value) )  )
                value = assemble(t,'multiuse_flag', ', ', value, matchFormatting=True)
                pargs.append( Token( '%s=[%s]' % (flag, value), None, flag.lineno  ) )
            else:
                pargs.append( Token( '%s=%s'   % (flag, value), None, flag.lineno ) )

        #sep = ', '
        #if len(pargs) > t.lexer.format_options['args_newline_threshhold']:
        #    sep = ',\n\t'
        #res =  '%s(%s)' % (command, sep.join( pargs ) )
        res =  '%s(%s)' % (command, assemble( t, 'command_args', ', ', pargs, matchFormatting=True ) )
        res = t.lexer.pymel_namespace + res
        return res

    except KeyError, key:

        try:
            print command, args
            # remove string encapsulation
            subCmd = eval(args.pop(0))
            # in rare cases this might end up bing -e or -pi, which evaluate to numbers
            assert isinstance( subCmd, basestring )

            formattedSubCmd = format_command( subCmd, args, t )
            return '%s(%s)' % (command, formattedSubCmd)
        except (NameError, AssertionError):
            print "Error Parsing: Flag %s does not appear in help for command %s. Skipping command formatting" % (key, command)
            return '%s(%s) # <---- Formatting this command failed. You will have to fix this by hand' % (command, ', '.join(args))

def store_assignment_spillover( token, t ):
    if hasattr(token, '__dict__'):
        try:
            var = token.__dict__.pop( 'assignment' )
        except KeyError:
            pass
        else:
            t.lexer.spillover_pre.append( token + '\n' )
            #print "adding to spillover:", token, token.lineno
            token = var
    return token

def merge_assignment_spillover( t, curr_lineno, title='' ):
    result = ''
    if t.lexer.spillover_pre:
        #curr_lineno = t[token_index].lineno
        i=-1
        tokens = t.lexer.spillover_pre[:]
        t.lexer.spillover_pre = []
        for token in tokens:

            if token.lineno == curr_lineno:
                result += token
                #print "adding", title, token[:-1], "(", token.lineno, curr_lineno, t.lexer.lineno, ")"
                #t.lexer.spillover_pre.pop(0)
            else:
                #print "skipping", title, token[:-1], "(", token.lineno, curr_lineno, t.lexer.lineno, ")"
                t.lexer.spillover_pre.append(token)

    return result

def format_assignment_value( val, typ ):
    """
    when assigning a value in mel, values will be auto-cast to the type of the variable, but in python, the variable
    will simply become the new type.  to ensure that the python operates as in mel, we need to cast when assigning
    a value to a variable of a different type    """

    try:

        if typ != val.type:
            #print "assignment not same type", t[1].type, t[3].type
            val = Token(  '%s(%s)' % ( mel_type_to_python_type[typ], val ), **val.__dict__ )
            val.type = typ
            return val
    except:
        # one of the expressions did not have a type
        try:
            typ = val.type
        except:
            print "NO TYPE", val

    return val

def assemble(t, funcname, separator='', tokens=None, matchFormatting=False):

    #print "STARTING", lineno
    res = ''

    if len(t) > 1:

        if tokens is None:
            tokens = toList(t)

        tokType = None
        res = Token( '', None )
        for i, tok in enumerate( tokens ) :
            if i == 0:
                res += tok
            else:

                try:
                    if not t.lexer.expression_only and matchFormatting and tokens[i-1].lineno != tok.lineno:
                        res +=  separator + '\n' + entabLines( tok )
                    else:
                        res += separator + tok
                except AttributeError:
                    #print tokens[i-1], type(tokens[i-1]), tok, type(tok)
                    res += separator + tok
            try:
                if tok.type:
                    tokType = tok.type
                    #print 'assembled', funcname, p[i], type
            except: pass

        #res = Token( separator.join(tokens), type, t.lexer.lineno )
        #res = Token( res, tokType, lineno=t.lexer.lineno )
    #res = separator.join(p[1:])
    #

    if t.lexer.verbose >= 2:
        print "--------"
        print "%s - line %d" % (funcname, t.lexer.lineno)
        print "original token:\n%s" % list(str(x) for x in t)
        print "result:\n%s" % res
    elif t.lexer.verbose == 1:
        print funcname, res, t.lexer.lineno
    #elif t.lexer.verbose >= 1:
    #    print 'assembled', funcname

    #if p[0].find('def') >= 0:
    #    print funcname
    #    print "'%s'" % p[0]
    return res

def find_num_leading_space(text):
    '''Given a text block consisting of multiple lines, find the number of
    characters in the longest common whitespace that appears at the start of
    every non-empty line'''
    lines = text.split('\n')
    nonEmptyLines = [l for l in lines if l.strip()]
    if not nonEmptyLines:
        return 0

    first = nonEmptyLines[0]
    rest = nonEmptyLines[1:]

    for i, char in enumerate(first):
        if char not in ' \t':
            break
        for line in rest:
            if line[i] != char:
                break
    return i

def strip_leading_space(text):
    '''Given a text block consisting of multiple lines, strip out common
    whitespace that appears at the start of every non-empty line
    '''
    leadNum = find_num_leading_space(text)
    lines = text.split('\n')
    for i, line in enumerate(lines):
        # if some lines have only whitespace, it's possible that their leading
        # whitespace doesn't match, and we'll be stripping out something
        # different... but who cares?
        lines[i] = line[leadNum:]
    return '\n'.join(lines)

def format_singleline_comments(comments):
    comment = Comment.join(comments)
    lines = ['#' + line for line in comment.split('\n')]
    # make sure we have a final newline
    if lines[-1]:
        lines.append('')
    return '\n'.join(lines)

def format_multiline_string_comment(comments):
    lines = Comment.join(comments, stripCommonSpace=True).split('\n')

    # ok, even after removing "common" whitespace, if we have a comment
    # like:
    #   /*
    #    * foo
    #    */
    # this will get converted to:
    #   """
    #    * foo
    #    """
    # so, if the final line is nothing but whitespace, clear it...
    if not lines[-1].strip():
        lines[-1] = ''
    comment = '\n'.join(lines)

    if '"' in comment:
        comment = "'''" + comment + "'''\n"
    else:
        comment = '"""' + comment + '"""\n'
    return comment

def format_comments(comments):
    if isinstance(comments, Comment):
        comments = [comments]
    return ''.join(comment.format() for comment in comments)


def append_comments(t, funcname=''):
    if t.lexer.verbose:
        print "appending comments:", funcname, t.lexer.comment_queue
    t[0] += format_comments(t.lexer.comment_queue)
    t.lexer.comment_queue = []

def format_held_comments(t, funcname=''):
    try:
        commentList = t.lexer.comment_queue_hold.pop()
    except IndexError:
        return ''
    #commentList = ['# ' + x for x in commentList]

    if t.lexer.verbose:
        print t.lexer.comment_queue_hold
        print "adding held comments:", funcname, commentList

    return format_comments(commentList)

def format_held_comments_and_docstring(t, funcname=''):
    '''Splits the held comments into the last comment block and the rest of the
    comments, formats the rest of the comments normally, and formats the last
    block as a multiline string.

    A comment block is either a group of mel-single-line-comments, or a single
    mel-comment-block

    This is useful for grabbing the "last" comment before something, and
    formatting it for use as a docstrign - for instance, if we have, in mel:

        // Some section
        // -----------------------

        /*
         * docProc: does stuff
         */
        global proc docProc() {};

    ...then we only want to grab the last comment block, and format it as
    a docstring... similarly, if the situation is something like this:

        /*
         * Some long notes here
         *    batman
         *    superman
         *    king kong
         *    the tick
         */

        // proctopus
        // does stuff
        global proc proctopus() {};
    '''
    try:
        commentList = t.lexer.comment_queue_hold.pop()
    except IndexError:
        return '', ''

    if not commentList:
        return '', ''
    else:
        last = [commentList[-1]]
        rest = commentList[:-1]

    if last[0].type == 'COMMENT' and rest:
        # we need to find other single-line-comments..
        for i in xrange(-1, -len(rest) - 1, -1):
            if rest[i].type != 'COMMENT':
                i += 1
                break
        if i != 0:
            last = rest[i:] + last
            rest = rest[:i]

    return format_comments(rest), format_multiline_string_comment(last)


def entabLines( line ):
    buf = line.split('\n')
    #for x in buf:
    #    if x.startswith(''):
    #        print 'startswith space!', x

    res = '\n'.join( map( lambda x: '\t'+x, buf) )
    if line.endswith('\n'):
        res += '\n'
    return res

#  Utility functions -----------------------------------------------------------

def pythonizeName(name):
    alphaNumeric = string.ascii_letters + string.digits
    chars = []
    for char in name:
        if char not in alphaNumeric:
            chars.append('_')
        else:
            chars.append(char)
    if chars[0] in string.digits:
        # Since python treats names starting with '_' as
        # somewhat special, use another character...
        chars.insert(0, 'n')
    return ''.join(chars)

def getModuleBasename( script ):
    name = os.path.splitext( os.path.basename(script) )[0]
    return pythonizeName(name)

def findModule( moduleName ):
    for f in sys.path:
        f = os.path.join( f, moduleName  + '.py' )
        if os.path.isfile(f):
            # checks for a tag added by mel2py -- this is unreliable, but so is using simple name comparison
            # TODO : add a keyword for passing directories to look for pre-translated python scripts
            file = open(f, 'r')
            firstline = file.readline()
            file.close()
            if firstline.startswith(tag):
                return f
    return

#def _script_to_module( t, script ):
#    global batchData.currentFiles
#    global script_to_module
#
#    path, name = os.path.split(script)
#    if name.endswith('.mel'):
#        name += '.mel'
#
#    try:
#        return script_to_module[name]
#
#    except KeyError:
#
#        if not path:
#            result = mel.whatIs( name )
#            buf = result.split( ':' )
#            if buf[0] == 'Script found in':
#                fullpath = buf[1]
#            else:
#                return
#        else:
#            fullpath = os.path.join(path, name )
#
#
#        moduleName = getModuleBasename(fullpath)
#
#
#        # the mel file in which this proc is defined is being converted with this batch
#        if fullpath in batchData.currentFiles:
#            script_to_module[name] = moduleName
#            return moduleName
def fileInlist( file, fileList ):
    file = util.path(file)
    for dir in fileList:
        try:
            if file.samefile( dir ):
                return True
        except OSError: pass
    return False

def _melObj_to_pyModule( script ):
    """
    Return the module name this mel script / procedure will be converted to / found in.

    If the mel script is not being translated, returns None.
    """
    result = mel.whatIs( script )
    buf = result.split( ': ' )
    if buf[0] in [ 'Mel procedure found in', 'Script found in' ]:
        melfile = util.path( buf[1].lstrip() )
        melfile = melfile.canonicalpath()
        if batchData.currentModules.has_value(melfile):
            return batchData.currentModules.get_key(melfile)
    return None

def _melProc_to_pyModule(t, procedure):
    """
    determine if this procedure has been or will be converted into python, and if so, what module it belongs to
    """

    # if root_module is set to None that means we are doing a string conversion, and not a file conversion
    # we don't need to find out the current or future python module.  just use pymel.mel
    if t.lexer.root_module in [ None, '__main__']:
        return None, None

    global batchData

    try:
        return batchData.proc_to_module[procedure]
    except KeyError:
        # if the file currently being parsed is not being translated, then this parsing is just for information gathering.
        # no need to recursively parse any further
        moduleDataPairs = []
        if t.lexer.root_module not in batchData.currentModules:
            #print 'No recursive parsing for procedure %s in module %s' % (procedure, t.lexer.root_module)
            moduleName = None
        else:
            moduleName = _melObj_to_pyModule(procedure)

            if moduleName is not None:
                melfile = batchData.currentModules[moduleName]
                moduleDataPairs.append((moduleName, melfile.bytes()))
            elif t.lexer.root_module:
                moduleName = t.lexer.root_module
                moduleDataPairs.append((moduleName, t.lexer.raw_parse_data))

            if t.lexer.root_module and t.lexer.parent_data:
                moduleDataPairs.append((moduleName, t.lexer.parent_data))

        for moduleName, data in moduleDataPairs:
            #print "%s not seen yet: scanning %s" % ( procedure, melfile )
            cbParser = MelScanner()
            cbParser.build()

            try:
                proc_list, global_procs, local_procs = cbParser.parse(data)
            except lex.LexError:
                print "Error parsing mel file:", melfile
                global_procs = {}
            #print "global procs", global_procs
            for proc, procInfo in global_procs.items():
                #print proc, procInfo
                batchData.proc_to_module[proc] = (moduleName, procInfo['returnType'])

            if procedure in batchData.proc_to_module:
                break

#        else:
#            print "failed to get module"

        if procedure not in batchData.proc_to_module:
            #print "could not find script for procedure: %s" % procedure
            batchData.proc_to_module[procedure] = (None, None)

        return batchData.proc_to_module[procedure]

def vprint(t, *args):
    if t.lexer.verbose:
        print args

def toList(t):
    tokens = []
    for i in range(1, len(t)):
        if i is not None:
            tokens.append(t[i])
    return tokens

def hasNonCommentPyCode(pyCode):
    '''Returns True if the given chunk of python code has any lines that contain
    something other than a comment or whitespace
    '''
    if isinstance(pyCode, basestring):
        return bool(NON_COMMENT_LINE_RE.search(pyCode))
    else:
        return any(hasNonCommentPyCode(x) for x in pyCode)

#  Mel lookup data -------------------------------------------------------------

# dictionary of functions used to remap procedures to python commands
proc_remap = {

        # strings
        #'capitalizeString'         : ('string', lambda x, t: '%s.capitalize()'     % (x[0]) ), # not equiv
        'capitalizeString'         : ('string', lambda x, t: '%sutil.capitalize(%s)'     % (t.lexer.pymel_namespace,x[0]) ),
        'strip'                 : ('string', lambda x, t: '%s.strip()'         % (x[0]) ),
        'appendStringArray'     : ( None ,   lambda x, t: '%s += %s[:%s]'         % (x[0],x[1],x[2]) ),
        'stringArrayToString'     : ('string', lambda x, t: '%s.join(%s)'         % (x[1],x[0]) ),
        'stringArrayCatenate'    : ('string', lambda x, t: '%s + %s'             % (x[0],x[1]) ),
        'stringArrayContains'    : ('int',    lambda x, t: '%s in %s'             % (x[0],x[1]) ),
        'stringArrayCount'        : ('int',    lambda x, t: '%s.count(%s)'        % (x[1],x[0]) ),
        'stringArrayInsertAtIndex'    : ( None, lambda x, t: '%s.insert(%s,%s)'        % (x[1],x[0],x[2]) ),
        'stringArrayRemove'        : ('string[]', lambda x, t: '[x for x in %s if x not in %s]'    % (x[1],x[0]) ),
        'stringArrayRemoveAtIndex'    : ('string[]', lambda x, t: '%s.pop(%s)'        % (x[1],x[0]) ),
        #'stringArrayRemove'        : lambda x, t: 'filter( lambda x: x not in %s, %s )' % (x[0],x[1]) ),
        'stringToStringArray'    : ('string[]', lambda x, t: '%s.split(%s)'         % (x[0],x[1]) ),
        'startsWith'            : ('int',    lambda x, t: '%s.startswith(%s)'     % (x[0],x[1]) ),
        'endsWith'                : ('int',    lambda x, t: '%s.endswith(%s)'     % (x[0],x[1]) ),
        'tolower'                : ('string', lambda x, t: '%s.lower()'         % (x[0]) ),
        'toupper'                : ('string', lambda x, t: '%s.upper()'         % (x[0]) ),
        'tokenize'                : ('string[]', format_tokenize ),
        'substring'                : ('string', format_substring ),
        'substitute'            : ('string', lambda x, t: '%s.replace(%s,%s)'         % (x[1],x[0],x[2]) ),

        # misc. keywords
        'size'                     : ('int',    lambda x, t: 'len(%s)'             % (', '.join(x)) ),
        'print'                    : ( None ,   lambda x, t: 'print %s'             % (x[0]) ),
        'clear'                    : ( None ,   lambda x, t: '%s = []'                 % (x[0]) ),
        'eval'                     : ( None ,   lambda x, t: '%smel.eval(%s)'     % (t.lexer.pymel_namespace, x[0]) ),
        'python'                   : ( None ,   lambda x, t: '%spython(%s)'     % (t.lexer.pymel_namespace, x[0]) ),
        'sort'                    : ( None ,   lambda x, t: 'sorted(%s)'            % (x[0]) ),
        'source'                : ( None ,      format_source ),
        # error handling
        'catch'                    : ( 'int' ,   lambda x, t: '%scatch(lambda: %s)' % (t.lexer.pymel_namespace,x[0]) ),
        'catchQuiet'            : ( 'int' ,   lambda x, t: '%scatch(lambda: %s)' % (t.lexer.pymel_namespace,x[0]) ),

        # system

        # TODO: check that new version of system works...
        # 'system'                : ( 'string' ,   lambda x, t: ( 'commands.getoutput( %s )'     % (x[0]), t.lexer.imported_modules.add('commands') )[0] ),  # commands.getoutput doesn't work in windows
        'system'                : ( 'string' ,   lambda x, t: '%sinternal.shellOutput(%s, convertNewlines=False, stripTrailingNewline=False)'     % (t.lexer.pymel_namespace,x[0]) ),
        # TODO: create our own version of exec, as the return value of popen2 is NOT the same as exec
        'exec'                    : ( None ,   lambda x, t: ( 'os.popen2(%s)'     % (x[0]), t.lexer.imported_modules.add('os') )[0] ),
        'getenv'                : ( 'string', lambda x, t: ( 'os.environ[%s]'     % (x[0]), t.lexer.imported_modules.add('os') )[0] ),
        # TODO : this differs from mel equiv bc it does not return a value
        'putenv'                : ( None, lambda x, t: ( 'os.environ[%s] = %s'     % (x[0], x[1]), t.lexer.imported_modules.add('os') )[0] ),

        # math
        'deg_to_rad'            : ( 'float', lambda x, t: 'radians(%s)'     % (x[0]) ),
        'rad_to_deg'            : ( 'float', lambda x, t: 'degrees(%s)'     % (x[0]) ),

        # file i/o
        'fopen'                    : ('int',    format_fopen ),
        'fprint'                : ( None ,   lambda x, t: '%s.write(%s)' % (x[0], x[1]) ),
        'fclose'                : ( None ,   lambda x, t: '%s.close()' % (x[0]) ),
        'fflush'                : ( None ,   lambda x, t: '%s.flush()' % (x[0]) ),
        'fgetline'                : ( 'string' ,   lambda x, t: '%s.readline()' % (x[0]) ),
        'frewind'                : ( None ,   lambda x, t: '%s.seek(0)' % (x[0]) ),
        'fgetword'                : ( 'string' ,   lambda x, t: "%sfscanf(%s, '%%s')" % (t.lexer.pymel_namespace,x[0]) ),
        'feof'                    : ( 'int'    ,   lambda x, t: '%sfeof(%s)' % (t.lexer.pymel_namespace,x[0]) ),
        'fread'                    : ( 'string' ,   format_fread ),


        #'filetest'                : lambda x, t: (  (  t.lexer.imported_modules.add('os'),  # add os module for access()
        #                                        {     '-r' : "Path(%(path)s).access(os.R_OK)",
        #                                            '-l' : "Path(%(path)s).islink()",
        #                                            '-w' : "Path(%(path)s).access(os.W_OK)",
        #                                            '-x' : "Path(%(path)s).access(os.X_OK)",
        #                                            '-f' : "Path(%(path)s).isfile()",
        #                                            '-d' : "Path(%(path)s).isdir()",
        #                                            '-h' : "Path(%(path)s).islink()",
        #                                            '-f' : "Path(%(path)s).exists() and Path(%(path)s).getsize()",
        #                                            '-L' : "Path(%(path)s).islink()",
        #                                            }[ x[0] ] % { 'path' :x[1] })
        #                                        )[1],

        'filetest'                : ('int',    lambda x, t: (  (  t.lexer.imported_modules.update( ['os', 'os.path'] ),  # add os module for access()
                                                {     '-r' : "os.access(%(path)s, os.R_OK)",
                                                    '-l' : "os.path.islink(%(path)s)",
                                                    '-w' : "os.access(%(path)s, os.W_OK)",
                                                    '-x' : "os.access(%(path)s, os.X_OK)",
                                                    '-f' : "os.path.isfile(%(path)s)",
                                                    '-d' : "os.path.isdir(%(path)s)",
                                                    '-h' : "os.path.islink(%(path)s)",
                                                    '-f' : "os.path.exists(%(path)s) and os.path.getsize(%(path)s)",
                                                    '-L' : "os.path.islink(%(path)s)",
                                                    }[ x[0] ] % { 'path' :x[1] } )
                                                )[1] ),

        #'sysFile'                : lambda x, t: {     '-delete'    : "Path(%(path)s).remove()",
        #                                            '-del'        : "Path(%(path)s).remove()",
        #                                            '-rename'    : "Path(%(path)s).move(%(param)s)",
        #                                            '-ren'        : "Path(%(path)s).move(%(param)s)",
        #                                            '-move'        : "Path(%(path)s).move(%(param)s)",
        #                                            '-mov'        : "Path(%(path)s).move(%(param)s)",
        #                                            '-copy'        : "Path(%(path)s).copy(%(param)s)",
        #                                            '-cp'        : "Path(%(path)s).copy(%(param)s)",
        #                                            '-makeDir'    : "Path(%(path)s).mkdir()",
        #                                            '-md'         : "Path(%(path)s).mkdir()",
        #                                            '-removeEmptyDir' : "Path(%(path)s).removedirs()",
        #                                            '-red'         : "Path(%(path)s).removedirs()"
        #                                            }[ x[0] ] % { 'path' :x[-1], 'param':x[-2] }



        'sysFile'                : ('int',    lambda x, t: (  ( t.lexer.imported_modules.update( ['os', 'shutil'] ),
                                                {    '-delete'    : "os.remove(%(path)s)",
                                                    '-del'        : "os.remove(%(path)s)",
                                                    '-rename'    : "os.rename(%(path)s, %(param)s)",
                                                    '-ren'        : "os.rename(%(path)s, %(param)s)",
                                                    '-move'        : "os.rename(%(path)s, %(param)s)",
                                                    '-mov'        : "os.rename(%(path)s, %(param)s)",
                                                    '-copy'        : "shutil.copy(%(path)s, %(param)s)",
                                                    '-cp'        : "shutil.copy(%(path)s, %(param)s)",
                                                    '-makeDir'    : "os.mkdir(%(path)s)",
                                                    '-md'         : "os.mkdir(%(path)s) ",
                                                    '-removeEmptyDir' : "os.rmdir(%(path)s)",
                                                    '-red'         : "os.rmdir(%(path)s)",
                                                    }[ x[0] ] % { 'path' :x[-1], 'param':x[-2] } )
                                                )[1] )
}

#: mel commands which were not ported to python, but which have flags that need to be translated
melCmdFlagList = {
             'error'   : { 'flags': {'showLineNumber': { 'longname': 'showLineNumber', 'numArgs': 1, 'shortname': 'sl'} } },
             'warning' : { 'flags': {'showLineNumber': { 'longname': 'showLineNumber', 'numArgs': 1, 'shortname': 'sl'} } },
             'trace'   : { 'flags': {'showLineNumber': { 'longname': 'showLineNumber', 'numArgs': 1, 'shortname': 'sl'} } }
             }

#: mel commands which were not ported to python; if we find one of these in pymel, we'll assume it's a replacement
melCmdList = ['abs', 'angle', 'ceil', 'chdir', 'clamp', 'clear', 'constrainValue', 'cos', 'cross', 'deg_to_rad', 'delrandstr', 'dot', 'env', 'erf', 'error', 'exec', 'exists', 'exp', 'fclose', 'feof', 'fflush', 'fgetline', 'fgetword', 'filetest', 'floor', 'fmod', 'fopen', 'fprint', 'fread', 'frewind', 'fwrite', 'gamma', 'gauss', 'getenv', 'getpid', 'gmatch', 'hermite', 'hsv_to_rgb', 'hypot', 'linstep', 'log', 'mag', 'match', 'max', 'min', 'noise', 'pclose', 'popen', 'pow', 'print', 'putenv', 'pwd', 'rad_to_deg', 'rand', 'randstate', 'rgb_to_hsv', 'rot', 'seed', 'sign', 'sin', 'size', 'sizeBytes', 'smoothstep', 'sort', 'sphrand', 'sqrt', 'strcmp', 'substitute', 'substring', 'system', 'tan', 'tokenize', 'tolower', 'toupper', 'trace', 'trunc', 'unit', 'warning', 'whatIs'] #
melCmdList = [ x for x in melCmdList if not proc_remap.has_key(x) and ( hasattr(pymel,x) or hasattr(builtin_module,x) ) ]

#  Token -----------------------------------------------------------------------

class Token(str):
    def __new__(cls, val, type, lineno=None, **kwargs):
        self=str.__new__(cls,val)
        self.type = type
        if lineno is None:
            if hasattr(val, 'lineno') and isinstance(val.lineno, int):
                lineno = val.lineno
            elif hasattr(val, 'lexer'):
                lineno = val.lexer.lineno
        self.lineno = lineno
        self.__dict__.update( kwargs )
        return self

    def _getKwargs(self):
        kwargs = dict((key, val) for key, val in self.__dict__.iteritems()
                      if key not in ('val', 'type') and not key.startswith('__'))
        return kwargs

    def __getslice__(self, start, end):
        return type(self)(str.__getslice__(self, start, end), self.type,
                          **self._getKwargs())
    def __add__(self, other ):
        newdict = self.__dict__
        try:
            newdict.update( other.__dict__ )
        except: pass
        return Token( str.__add__( self, other ), **newdict  )

class ArrayToken(Token):
    def __new__(cls, val, type, size, lineno=None, **kwargs):
        self = Token.__new__(cls, val, type, lineno=lineno, **kwargs)
        self.size = size
        return self

#  BatchData -------------------------------------------------------------------

class BatchData(object):
    __metaclass__ = util.Singleton

    def __init__(self, **kwargs):
        self.currentModules = TwoWayDict()
        self.proc_to_module = {}
        self.scriptPath_to_parser = {}
        self.scriptPath_to_moduleText = {}
        self.basePackage = None
        self.outputDir = None
        for key in kwargs:
            setattr(self, key, kwargs[key])

global batchData
batchData = BatchData()

#  Comment ---------------------------------------------------------------------

class Comment(object):
    def __init__(self, token):
        if token.type not in ('COMMENT', 'COMMENT_BLOCK'):
            raise TypeError("Non-comment token type: %s" % token.type)
        self.type = token.type
        if token.type == 'COMMENT':
            self.value = token.value[2:]
        else:
            self.value = token.value[2:-2]
        self.pos = token.lexpos
        self.data = token.lexer.raw_parse_data

    def leadingSpace(self):
        chars = []
        pos = self.pos - 1
        while pos > 0:
            nextChar = self.data[pos]
            if nextChar == '\n':
                break
            elif nextChar not in ' \t':
                chars.append(' ')
            else:
                chars.append(nextChar)
            pos -= 1
        chars.reverse()
        return ''.join(chars)

    def withLeadingSpace(self):
        return self.leadingSpace() + self.value

    @classmethod
    def join(cls, comments, stripCommonSpace=False):
        if isinstance(comments, Comment):
            comments = [comments]
        if stripCommonSpace:
            result = '\n'.join(x.withLeadingSpace() for x in comments)
            result = strip_leading_space(result)
        else:
            result = '\n'.join(x.value for x in comments)
        return result

    def format(self):
        if self.type == 'COMMENT':
            return format_singleline_comments(self)
        elif self.type == 'COMMENT_BLOCK':
            return format_multiline_string_comment(self)

#  Parsing rules ----------------------------------------------------------------

"""
translation_unit
    external_declaration
        function_definition
        declaration
"""

def p_translation_unit(t):
    '''translation_unit : external_declaration
                        | translation_unit external_declaration'''
    t[0] = assemble(t, 'p_translation_unit')
    #print '\n'

# external-declaration:
def p_external_declaration(t):
    '''external_declaration : statement
                            | function_definition'''
    t[0] = assemble(t, 'p_external_declaration')
    #if t.lexer.verbose:
    #    print "external_declaration", t[0]

# function-definition:
def p_function_definition(t):
    '''function_definition :  function_declarator function_specifiers_opt ID seen_func LPAREN function_arg_list_opt RPAREN hold_comments compound_statement'''
    #t[0] = assemble(t, 'p_function_definition')


    # add to the ordered list of procs
    t.lexer.proc_list.append( t[3] )

    # global proc
    if t[1][0] == 'global':
        procDict = t.lexer.global_procs
        funcName = '%s' % (t[3],)
    else:
        procDict = t.lexer.local_procs
        # local proc gets prefixed with underscore
        funcName = '_%s' % (t[3],)

    procDict[ t[3] ] = { 'returnType' : t[2], 'args' : t[6] }

    comments, docstring = format_held_comments_and_docstring(t, 'func')
    # add the held comments after the func definition, as a docstring
    t[0] = "%s\ndef %s(%s):\n%s\n%s\n" % (comments, funcName, ', '.join(t[6]),
                                          entabLines(docstring),
                                          entabLines(t[9]))

def p_seen_func(t):
    '''seen_func :'''

    global batchData
    #print "seen_func", t[-1].__repr__(), t[-2].__repr__(), t[-3].__repr__()

    if t.lexer.root_module in batchData.currentModules:
        module = t.lexer.root_module
    else:
        module = None

    if t[-3][0] == 'global':

        #print "adding function: (%s) %s.%s, %s" % (  t.lexer.root_module, module, t[-1], t[-2] )
        batchData.proc_to_module[ t[-1] ] = ( module, t[-2] )
    #else:
    #    print "skipping function: (%s) %s.%s, %s" % (  t.lexer.root_module, module, t[-1], t[-2] )

def p_hold_comments(t):
    '''hold_comments :'''
    if t.lexer.verbose:
        print "holding", t.lexer.comment_queue
    t.lexer.comment_queue_hold.append( t.lexer.comment_queue )
    t.lexer.comment_queue = []

# function-specifiers
def p_function_specifiers_opt(t):
    '''function_specifiers_opt : type_specifier
                                  | type_specifier LBRACKET RBRACKET
                                  | empty'''
    # string
    # string[]
    #
    t[0] = assemble(t, 'p_function_specifiers_opt')

def p_function_declarator(t):
    '''function_declarator : GLOBAL PROC
                           | PROC'''
    # string
    # string[]
    #
    t[0] = t[1:]

def p_function_arg(t):
    '''function_arg : type_specifier variable
                    | type_specifier variable LBRACKET RBRACKET'''
    #t[0] = assemble(t, 'p_function_arg')
    t[0] = t[2]
    t.lexer.type_map[t[2]] = t[1]

def p_function_arg_list(t):
    '''function_arg_list : function_arg
                        | function_arg_list COMMA function_arg'''

    #t[0] = assemble(t, 'p_function_arg_list')
    if len(t)>2:
        t[0] = t[1] + [t[3]]
    # start a new list
    else:
        t[0] = [t[1]]

def p_function_arg_list_opt(t):
    '''function_arg_list_opt : function_arg_list
                        |  empty'''

    #t[0] = assemble(t, 'p_function_arg_list_opt')
    if not t[1]:
        t[0] = []
    else:
        t[0] = t[1]

# declaration:
def p_declaration_statement(t):
    '''declaration_statement : declaration_specifiers init_declarator_list SEMI'''
    # int var=6;
    # int var1=6, var2=9;
    #
    #t[0] = assemble(t, 'p_declaration_statement')

    def includeGlobalVar( var ):
        # handle whether we initialize this variable to the value of the mel global variable.
        # in some cases, the global variable is only for passing within the same script, in which
        # case the python global variable will suffice.  in other cases, we may want to retrieve a
        # global set by maya.

        incl_reg = t.lexer.global_var_include_regex    # if nothing set, match all
        excl_reg = t.lexer.global_var_exclude_regex        # if nothing set, match none
        if re.match(incl_reg, var) and not re.match(excl_reg, var):
            return True
        else:
            return False

    t[0] = ''

    isGlobal = False
    typ = t[1]
    if len(typ) == 2:
        assert typ[0] == 'global'
        typ = typ[1]
        isGlobal = True
    else:
        typ = typ[0]


    # each declaration is a two-element tuple: ( variable, value )
    for var, val in t[2]:


        if '[]' in var or isinstance(var, ArrayToken):
            iType = typ + '[]'
            array = True
        else:
            iType = typ
            array = False

        # this must occur after the bracket check, bc the globalVar attribute never includes brackets
        try:
            var = var.globalVar
        except AttributeError: pass

        # this must occur after the globalVar attribute check, bc otherwise it will convert the Token into a string
        origVar = var
        var = var.strip().strip('[]')

        # default initialization
        if val is None:
            # array initialization
            if '[]' in iType:
                if t.lexer.force_compatibility:
                    val = '%sutil.defaultlist(%s)' % ( t.lexer.pymel_namespace,
                                                     mel_type_to_python_type[typ] )
                elif isinstance(origVar, ArrayToken) and origVar.size:
                    val = '[%s] * (%s)' % (default_values[typ], origVar.size)
                else:
                    val = '[]'

            # non -array intitialization
            elif iType in default_values:
                val = default_values[iType]
            else:
                raise TypeError("unrecognized value type: %s" % iType)

            t.lexer.type_map[var] = iType

            # global variable -- overwrite init
            if isGlobal:

                t.lexer.global_vars.add( var )

                # this is the old method, leaving here in case we want to add a switch
                if False:
                    t[0] += 'global %s\n' % var
                    if includeGlobalVar( var):
                        t[0] += "%s = %sgetMelGlobal(%r, %r)\n" % (var, t.lexer.pymel_namespace, iType, var)
                else:
                    t[0] += "%smelGlobals.initVar(%r, %r)\n" % ( t.lexer.pymel_namespace, iType, var )

            else:
                t[0] += var + ' = ' + val + '\n'

        # initialize to value
        else:

            t[0] += merge_assignment_spillover( t, val.lineno, 'declaration_statement' )
            val = format_assignment_value( val, iType )

            try:
                if val.tokenize:
                    t[0] += format_tokenize_size(val,var)

            except:

                val = val.strip()
                if val.endswith('[]') and val != '[]':
                    val.strip('[]')

                t.lexer.type_map[var] = iType

                if isGlobal:

                    t.lexer.global_vars.add(var)

                    # this is the old method, leaving here in case we want to add a switch
                    if False:
                        t[0] += 'global %s\n' % var
                        t[0] += '%s=%s\n' % (var, val)
                        if includeGlobalVar( var):
                            t[0] += "%ssetMelGlobal( '%s', '%s', %s )\n" % ( t.lexer.pymel_namespace, iType, var, var)
                    else:
                        t[0] += "%smelGlobals.initVar( '%s', '%s' )\n" % ( t.lexer.pymel_namespace, iType, var )
                        t[0] += "%smelGlobals['%s'] = %s\n" % ( t.lexer.pymel_namespace, var, val)

                else:
                    if array and t.lexer.force_compatibility:
                        val = '%sutil.defaultlist(%s, %s)' % ( t.lexer.pymel_namespace,
                                                     mel_type_to_python_type[typ],
                                                     val )

                    t[0] += var + '=' + val + '\n'


    append_comments( t, 'declaration_statement' )


# declaration-specifiers
def p_declaration_specifiers(t):
    '''declaration_specifiers : type_specifier
                              | GLOBAL type_specifier'''
    # int
    # global int
    #
    if len(t) > 2:
        t[0] = (t[1], t[2])

    else:
        t[0] = (t[1], )
    #t[0] = assemble(t, 'p_declaration_specifiers', ' ')

# type-specifier:
def p_type_specifier(t):
    '''type_specifier : INT
                      | FLOAT
                      | STRING
                      | VECTOR
                      | MATRIX
                      '''
    t[0] = assemble(t, 'p_type_specifier')



# init-declarator-list:
def p_init_declarator_list(t):
    '''init_declarator_list : init_declarator
                            | init_declarator_list COMMA init_declarator'''
    # var=6;
    # var1=6, var2=9;
    #
    #t[0] = assemble(t, 'p_init_declarator_list')

    # add to list
    if len(t)>2:
        t[0] = t[1] + [t[3]]
    # start a new list
    else:
        t[0] = [t[1]]



# init-declarator
def p_init_declarator(t):
    '''init_declarator : declarator
                        | declarator EQUALS expression'''
    # var=6
    #
    #t[0] = assemble(t, 'p_init_declarator', ' ')

    if len(t) > 2:
        t[0] = (t[1], store_assignment_spillover( t[3], t) )

    else:
        t[0] = (t[1], None )



# declarator:
def p_declarator_1(t):
    '''declarator : variable'''
    t[0] = assemble(t, 'p_declarator')

def p_declarator_2(t):
    '''declarator :  declarator LBRACKET constant_expression_opt RBRACKET'''
#                    | LPAREN declarator RPAREN        removed 11/05 in effort to get cast_expression working
#                    | declarator LPAREN parameter_type_list RPAREN
#                    | declarator LPAREN identifier_list RPAREN
#                    | declarator LPAREN RPAREN '''
    # var
    # var[]
    # var[1]
    t[3] = store_assignment_spillover( t[3], t )
    t[0] = ArrayToken(t[1], 'string', t[3])
    #if len(t) == 5:
    #    if not t[3]:
    #        t[0] = t[1]


# Optional fields in abstract declarators
def p_constant_expression_opt_1(t):
    '''constant_expression_opt : empty'''
    t[0] = assemble(t, 'p_constant_expression_opt_1')

def p_constant_expression_opt_2(t):
    '''constant_expression_opt : constant_expression'''
    t[0] = assemble(t, 'p_constant_expression_opt_2')


# grammar-wise, identical to a statement; we have a different rule, only used as
# a clue for the python-conversion; anywhere there is a statement_required, if
# it translates to an "empty" python string, a "pass" statment must be
# substituted

# statement_required:
def p_statement_required(t):
    '''statement_required : statement'''
    if not hasNonCommentPyCode(t[1]):
        if t[1].strip():
            # if there was a comment or something, append pass
            t[1] += '\npass'
        else:
            # otherwise, just set it to pass
            t[1] = Token('pass', 'string', t.lexer.lineno)
        t[1]
    t[0] = assemble(t, 'p_statement_required')

# statement:
def p_statement_simple(t):
    '''statement : expression_statement
              | command_statement
              | compound_statement'''

    t[0] = assemble(t, 'p_statement_simple')

def p_statement_complex(t):
    '''statement : selection_statement
              | iteration_statement
              | jump_statement
              | declaration_statement'''
#              | comment'''
    if t.lexer.expression_only:
        raise ExpressionParseError("This mel code is not capable of being translated as a python expression")
    t[0] = assemble(t, 'p_statement_complex')

# labeled-statement:
#def REMOVED_labeled_statement_1(t):
#    '''labeled_statement : ID COLON statement'''
#    # N/A ?
#    t[0] = assemble(t, 'p_labeled_statement_1')



def p_labeled_statement_list(t):
    '''labeled_statement_list : labeled_statement
                  | labeled_statement_list labeled_statement'''

    if len(t) == 2:
        t[0] = [t[1]]
    else:
        t[0] = t[1] + [t[2]]

#def REMOVED_labeled_statement_2(t):
#    '''labeled_statement : CASE constant_expression COLON statement_list_opt'''
#    #t[0] = assemble(t, 'p_labeled_statement_2')
#    t[0] = ['case %s == ' + t[2] + ':\n'] + t[4]

#def REMOVED_labeled_statement_3(t):
#    '''labeled_statement : DEFAULT COLON statement_list'''
#    #t[0] = assemble(t, 'p_labeled_statement_3')
#
#    t[0] = ['else:\n'] + t[3]

def p_labeled_statement_2(t):
    '''labeled_statement : CASE constant_expression COLON statement_list_opt'''
    #t[0] = assemble(t, 'p_labeled_statement_2')
    fallthrough = True
    block = []
    for line in t[4]:
        lines = [ x + '\n' for x in line.split('\n')]
        block.extend(lines)

    i=0
    for i,line in enumerate(block):
        #print "--->", line
        if line.startswith('break'):
            #print "---breaking----"
            fallthrough = False
            break

    block = block[:i]

    t[0] = [t[2], block, fallthrough]

def p_labeled_statement_3(t):
    '''labeled_statement : DEFAULT COLON statement_list_opt'''
    #t[0] = assemble(t, 'p_labeled_statement_3')
    block = []
    for line in t[3]:
        if line.startswith('break'):
            fallthrough = False
            break
        block.append(line)
    t[0] = [None, block, False]

# expression-statement:
def p_expression_statement(t):
    '''expression_statement : expression_opt SEMI'''

    t[0] = merge_assignment_spillover( t, t[1].lineno, 'expression_statement'  )
    t[0] += t[1] + '\n'
    append_comments(t)

# compound-statement:
def p_compound_statement(t):
    '''compound_statement   : LBRACE statement_list RBRACE
                            | LBRACE RBRACE''' # causes reduce/reduce conflict with postfix_expression

    #print "compound, emptying queue:", t.lexer.comment_queue
    #t[0] = ''.join(t.lexer.comment_queue)
    #t.lexer.comment_queue = []

    #t[0] = assemble(t, 'p_compound_statement')

    if len(t) == 4:
        t[0] = ''.join(t[2])
    else:
        t[0] = 'pass\n'
        append_comments(t, 'compound_pass')

def p_statement_list_opt(t):
    '''statement_list_opt : statement_list
                  | empty'''
    #t[0] = assemble(t, 'p_expression_list_opt')
    if isinstance(t[1],list):
        t[0] = t[1]
    else:
        t[0] = []

# statement-list:
def p_statement_list(t):
    '''statement_list   : statement
                        | statement_list statement'''
    #t[0] = assemble(t, 'p_statement_list')
    if len(t) == 2:
        t[0] = [t[1]]
    else:
        t[0] = t[1] + [t[2]]

# selection-statement
def p_selection_statement_1(t):
    '''selection_statement : IF LPAREN expression RPAREN statement_required'''
    #t[0] = assemble(t, 'p_selection_statement_1')
    t[0] = merge_assignment_spillover( t, t[3].lineno, 'selection_statement_1' )
    t[0] += 'if %s:\n%s' % (t[3],entabLines(t[5]))


def p_selection_statement_2(t):
    '''selection_statement : IF LPAREN expression RPAREN statement_required ELSE hold_comments statement_required '''
    #t[0] = assemble(t, 'p_selection_statement_2')
    t[0] = merge_assignment_spillover( t, t[3].lineno, 'selection_statement_2' )
    t[0] += 'if %s:\n%s\n' % (t[3], entabLines(t[5]))

    # elif correction
    match = re.match( r'(?:\s*)(if\b.*:)', t[8] )
    elseStmnt = ''
    if match:
        elseStmnt='el%s\n%s' % ( match.group(1), t[8][match.end()+1:] )
    else:
        elseStmnt='else:\n%s' % ( entabLines(t[8]) )

    t[0] += format_held_comments( t, 'if/else') + elseStmnt

def p_selection_statement_3(t):
    '''selection_statement : SWITCH LPAREN expression RPAREN hold_comments LBRACE labeled_statement_list RBRACE'''
    #t[0] = assemble(t, 'p_selection_statement_3')

    """
    cases = t[7]  # a 2d list: a list of cases, each with a list of lines
    #cases[1:-1]:
    t[0] = ''
    #print cases
    for i,thiscase in enumerate(cases):
        #print 'MAIN', thiscase[0] % t[3]

        # create the first line of the statement block
        caseline = thiscase[0]
        if caseline.startswith('case'):
            if i==0:
                caseline = 'if' + caseline[4:]
            else:
                caseline = 'elif' + caseline[4:]
        try:
            t[0] += caseline % t[3]
        except TypeError:
            t[0] += caseline

        broken = False
        for case in cases[i:]:
            if broken == True:
                break
            for line in case[1:]:
                if line == 'break\n':
                    broken = True
                    break
                    t[0] += '\t' + line
    """
    t[0] = ''
    cases = t[7]  # a 2d list: a list of cases, each with a list of lines
    variable = t[3]
    i = 0
    control = ''

    while i < len(cases):

        if i == 0:
            control = 'if'
        else:
            control = 'elif'

        mainCondition = cases[i][0]
        conditions = set([])
        lines = []

        # cycle through cases until we stop falling through
        for j, (condition, block, fallthrough) in enumerate(cases[i:]):
            if fallthrough:
                if hasNonCommentPyCode(block):
                    lines += block
                else:
                    conditions.add(condition)
                    i += 1 # on the next while loop, we will skip this case, because it is now subsumed under the current case

            else:
                if hasNonCommentPyCode(block) or lines:
                    lines += block
                else:
                    lines.append( 'pass\n' )

                if condition is not None and len(conditions) == j:
                    conditions.add(condition)

                break

        i += 1
        conditions.add( mainCondition )
        conditions = list(conditions)
        block = entabLines( ''.join( lines ) )
        if len(conditions)>1:
            t[0] += '%s %s in (%s):\n%s' % ( control, variable, ', '.join(conditions), block )
        else:
            if conditions[0] is None:
                if not hasNonCommentPyCode(t[0]):
                    standIn = 'if False:\n%s\n' % entabLines('pass')
                    if t[0].strip():
                        # if there was a comment or something, append
                        t[0] += standIn
                    else:
                        # otherwise, just set it
                        t[0] = Token(standIn, 'string', t.lexer.lineno)
                t[0] +=  'else:\n%s' % ( block )
            else:
                t[0] +=  '%s %s == %s:\n%s' % ( control, variable, conditions[0], block )


    #print t[0]

    t[0] = format_held_comments(t, 'switch') + t[0]


#def REMOVED_selection_statement_3(t):
#    '''selection_statement : SWITCH LPAREN expression RPAREN hold_comments LBRACE labeled_statement_list RBRACE'''
#    #t[0] = assemble(t, 'p_selection_statement_3')
#
#    cases = t[7]  # a 2d list: a list of cases, each with a list of lines
#    #cases[1:-1]:
#    t[0] = ''
#    #print cases
#    for i in range(1,len(cases)):
#        # if previous block fell through
#        if cases[i-1][2]:
#            func_name = 'switch_%s_%s()' % (t[3], i+1)
#            if cases[i][0] is None:
#                func_name = 'switch_%s_default()' % (t[3])
#
#            t[0] += 'def %s:\n%s' % (func_name, entabLines(cases[i][1]))
#            cases[i][1] = func_name + '\n'
#
#    for i, (condition, x, x) in enumerate(cases):
#        if condition:
#            if i == 0:
#                t[0] += 'if %s == %s:\n' % (t[3], condition)
#            else:
#                t[0] += 'elif %s == %s:\n' % (t[3], condition)
#        else:
#            t[0] += 'else:\n'
#
#        for (x, block, fallthrough) in cases[i:]:
#            t[0] += entabLines(block)
#            if not fallthrough:
#                break
#
#    print t[0]
#
#    format_held_comments(t, 'switch')


# iteration_statement:
def p_iteration_statement_1(t):
    '''iteration_statement : WHILE LPAREN expression RPAREN hold_comments statement_required'''
    #t[0] = assemble(t, 'p_iteration_statement_1')
    t[0] = format_held_comments(t, 'while') + 'while %s:\n%s\n' % (t[3], entabLines(t[6]) )


def p_iteration_statement_2(t):
    '''iteration_statement : FOR LPAREN expression_list_opt SEMI expression_list_opt SEMI expression_list_opt RPAREN hold_comments statement_required'''
    #t[0] = assemble(t, 'p_iteration_statement_2')

    """
    =============================================
    RANGE : specific case, where only 1 cond.
    =============================================
    init   >=1
    cond   = 1
    update >=1

    other requirements:
    1) the iterator must exist alone on one
    side of the    conditional expression.
    2) the iterator can appear only once in the
    update expression
    ---------------------------------------------
    solution:
        add extra inits before beginning of loop
        add extra updates to end of each loop
    ---------------------------------------------

    int $i;
    for( $i=0, int $j=0; $i<10; $i++, $j++) print $i;



    i = 0
    j = 0
    for i in range(0,10):
        print i
        j+=1

    =============================================
    WHILE : all others
    =============================================
    init   >=0
    cond   >=0
    update >=0
    ---------------------------------------------
    solution:
        use a while statement
        add any inits before beginning of loop
        add any conditions to beginning of each loop
        add any updates to end of each loop
    ---------------------------------------------

    int $i=0;
    for(; ; )
    {
        print $i;
        if ($i > 10)
            break;
        $i++;
    }

    int $i;
    for(; ; $i++) {
        print $i;
        if ($i > 10)
            break;
    }



    i=0
    while 1:
        print i
        if i > 10:
            break
        i++


    """

    #------------------------------------------------------------------
    # for( init_expr; cond_expr; update_expr
    #------------------------------------------------------------------
    # for( iterator=start; iterator(relop)stop; iterator(+/-=)step )
    #------------------------------------------------------------------

    # regular expression for a variable
    var_reg = re.compile(r'[A-Za-z_][\w_]*')

    init_exprs = t[3]
    cond_exprs = t[5]
    update_exprs = t[7]
    statement_body = t[10]

    def default_formatting():
        t[0] = ''
        if init_exprs:
            t[0] += '\n'.join(init_exprs)

        t[0] += '\nwhile 1:\n'

        if cond_exprs:
            t[0] += entabLines( 'if not ( %s ):\n\tbreak\n' % ' or '.join(cond_exprs) )

        t[0] += entabLines( statement_body )

        if update_exprs:
            t[0] += entabLines('\n'.join( update_exprs ) + '\n')

        t[0] = format_held_comments(t, 'for') + t[0]

    if len(cond_exprs) == 1 and len(init_exprs) >= 1 and len(update_exprs) >=1:
        #---------------------------------------------
        # Conditional Expression  --> End
        #---------------------------------------------
        # the conditional expression becomes the end value of a range() function
        # there can be only one variable driven by the range expression, so there can be only one coniditional expression
        end = None
        regex = re.compile('\s*(<=|>=|<|>)\s*')
        cond_buf = regex.split(cond_exprs[0])
        try:
            cond_relop = cond_buf.pop(1)    # cond_buf now contains 2 values, one of which will become our iterator
        except IndexError:
            return default_formatting()

        cond_vars = set( filter( var_reg.match, cond_buf) )

        #---------------------------------------------
        # Update Expression --> Step
        #---------------------------------------------
        # The initialization is optional, so the next most important expression is the update expression.
        iterator = None
        step = None
        update_op = None
        count = 0
        regex = re.compile('\s*(\+\+|--|\+=|-=)\s*')
        for expr in update_exprs:
            # expr: i++
            update_buf = regex.split(expr)

            # update_opt:  ++
            try:
                update_op = update_buf.pop(1) # this might raise an indexError if the update expression followed the form:  $i = $i+1
                # find the variables in the update statement, and find which were also present in conditional statement
                update_vars = filter( var_reg.match, update_buf)
                iterator = list(cond_vars.intersection(update_vars))
                #print cond_vars, tmp, iterator
            except IndexError:
                count += 1
            else:
                if len(iterator) > 1:
                    '''raise ValueError, """Python does not support for loops of format '(init_exp; cond_exp; update_exp)'.
    In order to convert these statements to python, for loop iterator must appear only once in the update expression. I found %d (%s). Please correct this portion of the loop: %s.""" % ( len(iterator), ', '.join(iterator), t[7] )
                    '''
                    return default_formatting()
                try:
                    iterator = iterator[0]
                    update_buf.remove(iterator)
                    cond_buf.remove(iterator)
                    step = update_buf[0]
                    end = cond_buf[0]
                    break
                except:
                    iterator = None

        if iterator is None:
            '''raise ValueError, """Python does not support for loops of format '(init_exp; cond_exp; update_exp)'.
    In order to convert these statements to python, for loop iterator must appear alone on one side of the conditional expression. Please correct this portion of the loop: %s.""" % ( t[5] )
            '''
            return default_formatting()

        update_exprs.pop(count)

        #print "iterator:%s, update_op:%s, update_expr:%s, step:%s" % (iterator, update_op, update_exprs, step)

        # determine the step
        if update_op.startswith('-'):
            step = '-'+step
            if cond_relop == '>=':
                end = end + '-1'
        elif cond_relop == '<=':
            end = end + '+1'

        #---------------------------------------------
        # initialization --> start
        #---------------------------------------------
        start = None
        init_reg = re.compile('\s*=\s*')

        for expr in init_exprs:
            init_buf = init_reg.split(expr)
            try:
                init_buf.remove(iterator)
            except ValueError:
                pass
            else:
                if len(init_buf):
                    start = init_buf[0]
                else:
                    start = iterator

        #print "start: %s, end: %s, step: %s" % (start, end, step)

        if step == '1':
            t[0] = 'for %s in range(%s,%s):\n%s' % (iterator, start, end, entabLines(statement_body))
        else:
            t[0] = 'for %s in range(%s,%s,%s):\n%s' % (iterator, start, end, step, entabLines(statement_body) )

        if len( update_exprs ):
            t[0] += '\n' + entabLines('\n'.join(update_exprs) + '\n')

        t[0] = format_held_comments(t, 'for') + t[0]
    else:
        default_formatting()

def p_iteration_statement_3(t):
    '''iteration_statement : FOR LPAREN variable IN expression seen_FOR RPAREN hold_comments statement_required '''
    #t[0] = assemble(t, 'p_iteration_statement_3')
    t[0] = format_held_comments(t, 'for') + 'for %s in %s:\n%s' % (t[3], t[5], entabLines(t[9]))


def p_seen_FOR(t):
    '''seen_FOR :'''

    t.lexer.type_map[t[-3].strip()] = t[-1].type


def p_iteration_statement_4(t):
    '''iteration_statement : DO statement_required WHILE LPAREN expression RPAREN SEMI'''
    t[0] = assemble(t, 'p_iteration_statement_4')

    if t.lexer.force_compatibility:
        # if we're forcing compatibility, repeat the entire contents of the loop
        # once, then create a while loop...
        t[0] = t[2]    + '\n'
        t[0] += 'while %s:\n%s\n' % (t[5], entabLines(t[2]) )
        t[0] = format_held_comments(t, 'do while') + t[0]
    else:
        # otherwise, create a variable, first_run_of_do_while_loop=True
        # use a variable name unlikely to conflict with one the user is using!
        t[0] = 'first_run_of_do_while_loop = True\n'
        newCondition = 'first_run_of_do_while_loop or (%s)' % t[5]
        newBody = entabLines('first_run_of_do_while_loop = False\n%s' % t[2])
        t[0] += 'while %s:\n%s\n' % (newCondition, newBody )
        t[0] = format_held_comments(t, 'do while') + t[0]


# jump_statement:
def p_jump_statement(t):
    '''jump_statement : CONTINUE SEMI
                    | BREAK SEMI
                    | RETURN expression_opt SEMI'''
    t[0] = assemble(t, 'p_jump_statement')
    if len(t)==4:
        t[0] = t[1] + ' ' + t[2] + '\n'
    else:
        t[0] = t[1] + '\n'
    append_comments(t)

# optional expression
def p_expression_opt(t):
    '''expression_opt : empty
                      | expression'''
    t[0] = assemble(t, 'p_expression_opt')




# expression:
""""
ID
constant
SCONST
LPAREN expression RPAREN
    primary
        postfix
            unary
                cast
                    multiplicative
                        additive
                            shift
                                relational
                                    equality
                                        AND
                                            exclusive_or
                                                inclusive_or
                                                    logical_and
                                                        logical_or
                                                            conditional
                                                                constant
                                                                assignment
                                                                    expression
"""


def p_expression_list_opt(t):
    '''expression_list_opt : expression_list
                  | empty'''
    #t[0] = assemble(t, 'p_expression_list_opt')

    if isinstance(t[1],list):
        t[0] = t[1]
    else:
        t[0] = []

def p_expression_list(t):
    '''expression_list : expression
                  | expression_list COMMA expression'''
    # descendents: vector, array, for-loop

    #t[0] = assemble(t, 'p_expression')

    # new
    if len(t) == 2:
        t[0] = [t[1]]

    # append
    else:
        t[0] = t[1] + [t[3]]

def p_expression(t):
    '''expression : conditional_expression'''
    t[0] = assemble(t, 'p_expression')


# constant-expression
def p_constant_expression(t):
    '''constant_expression : conditional_expression'''
#                            | CAPTURE command CAPTURE'''
    t[0] = assemble(t, 'p_constant_expression')

# conditional-expression
def p_conditional_expression_1(t):
    '''conditional_expression : logical_or_expression'''
    t[0] = assemble(t, 'p_conditional_expression_1', ' ')


def p_conditional_expression_2(t):
    '''conditional_expression : logical_or_expression CONDOP expression COLON conditional_expression '''

    # ($x>1) ? 1 : 0  --->  (x>1) and 1 or 0
    t[1] = store_assignment_spillover( t[1], t )
    t[2] = 'and'
    t[3] = store_assignment_spillover( t[3], t )
    t[4] = 'or'
    t[5] = store_assignment_spillover( t[5], t )
    t[0] = assemble(t, 'p_conditional_expression_2', ' ')
    #t[0] = '%s and %s or %s' % ( t[1], t[3], t[5] )






# logical-or-expression
def p_logical_or_expression_1(t):
    '''logical_or_expression : logical_and_expression
                             | logical_or_expression LOR logical_and_expression'''

    if len(t) == 4:
        t[1] = store_assignment_spillover( t[1], t )
        t[2] = 'or'
        t[3] = store_assignment_spillover( t[3], t )

    t[0] = assemble(t, 'p_logical_or_expression', ' ')

# logical-and-expression
def p_logical_and_expression_1(t):
    '''logical_and_expression : assignment_expression
                              | logical_and_expression LAND assignment_expression'''

    if len(t) == 4:
        t[1] = store_assignment_spillover( t[1], t )
        t[2] = 'and'
        t[3] = store_assignment_spillover( t[3], t )
    t[0] = assemble(t, 'p_logical_and_expression', ' ')




# assigment_expression:
def p_assignment_expression(t):

    '''assignment_expression : equality_expression
                            | postfix_expression assignment_operator assignment_expression''' # changed first item from unary to postfix
#                            | CAPTURE assignment_expression CAPTURE'''
#                            | unary_expression assignment_operator CAPTURE assignment_expression CAPTURE'''

    if len(t) == 4:
        #print t[1], t[2], t[3]

        t[3] = format_assignment_value( t[3], t[1].type )

        if hasattr( t[3], 'tokenize' ):
            t[0] = format_tokenize_size(t[3],t[1])

        else:

            # remove array brackets:  string[]
            if t[2] and t[1].endswith('[]'):
                raise NotImplementedError, "I didn't think we'd make it here. the line below seems very wrong."
                #t[0] = ' '.join( [ t[1][:-2], t[1], t[2] ] )

            elif t[2] in ['=', ' = '] and  t.lexer.expression_only:
                raise TypeError, "This mel code is not capable of being translated as a python expression"

            # fill in the append string:
            #    start:        $foo[size($foo)] = $bar
            #    stage1:        foo[len(foo)] = bar
            #    stage2:        foo.append(%s) = bar
            #    stage3:        foo.append(bar)

            elif hasattr( t[1], 'appendingToArray' ):
                var = t[1].appendingToArray
                if hasattr( t[1], 'globalVar' ):
                    t[0] = '%s += [%s]' % ( var, t[3] )
                else:
                    t[0] = '%s.append(%s)' % ( var, t[3] )


            # setting item on a global array
            elif hasattr( t[1], 'globalVar') and hasattr( t[2], 'indexingItem' ):
                var, expr = t[1].indexingItem
                t[0] = var + '.setItem(%s,%s)' % ( expr, t[3])

#                elif t[1].endswith('.append(%s)'):  # replaced below due to a var[len(var)]
#                    t[0] = t[1] % t[3]
#
#
#                elif t[1].endswith(' += [%s]'): # replaced below due to a var[len(var)], special case for global variables
#                    t[0] = t[1] % t[3]

            else:
                t[0] = assemble(t, 'p_assignment_expression')
                t[0].assignment = t[1]

    else:
        t[0] = assemble(t, 'p_assignment_expression')

# assignment_operator:
def p_assignment_operator(t):
    '''
    assignment_operator : EQUALS
                        | TIMESEQUAL
                        | DIVEQUAL
                        | MODEQUAL
                        | PLUSEQUAL
                        | MINUSEQUAL
                        | CROSSEQUAL
                        '''
    t[0] = assemble(t, 'p_assignment_operator')

# equality-expression:
def p_equality_expression_1(t):
    '''equality_expression : relational_expression
                            | equality_expression EQ relational_expression
                            | equality_expression NE relational_expression'''

    if len(t) == 4:
        t[1] = store_assignment_spillover( t[1], t )
        t[3] = store_assignment_spillover( t[3], t )

    t[0] = assemble(t, 'p_equality_expression_3', ' ')

# relational-expression:

def p_relational_expression_1(t):
    '''relational_expression : shift_expression
                             | relational_expression LT shift_expression
                             | relational_expression GT shift_expression
                             | relational_expression LE shift_expression
                             | relational_expression GE shift_expression'''

    if len(t) == 4:
        t[1] = store_assignment_spillover( t[1], t )
        t[3] = store_assignment_spillover( t[3], t )

    t[0] = assemble(t, 'p_relational_expression_5')

# shift-expression
def p_shift_expression(t):
    'shift_expression : additive_expression'
    t[0] = assemble(t, 'p_shift_expression')

# additive-expression
def p_additive_expression(t):
    '''additive_expression : multiplicative_expression
                            | additive_expression PLUS multiplicative_expression
                            | additive_expression MINUS multiplicative_expression'''



    if len(t) == 4:
        t[1] = store_assignment_spillover( t[1], t )
        t[3] = store_assignment_spillover( t[3], t )

        if t[2] == '+':
            #print t[1], t[1].type, t[3], t[3].type
            if t[1].type == 'string' and t[3].type != 'string':
                t[0] = Token( '%s + str(%s)' % (t[1], t[3]) , 'string' )
                return
            elif t[3].type == 'string' and t[1].type != 'string':
                t[0] = Token( 'str(%s) + %s' % (t[1], t[3]), 'string' )
                return

    t[0] = assemble(t, 'p_additive_expression', ' ')


    #    if t[1].endswith('"'):
    #        t[0] = t[1][:-1] + '%s" % ' + t[3]

# multiplicative-expression

def p_multiplicative_expression(t):
    '''multiplicative_expression : cast_expression
                                | multiplicative_expression TIMES cast_expression
                                | multiplicative_expression DIVIDE cast_expression
                                | multiplicative_expression MOD cast_expression
                                | multiplicative_expression CROSS cast_expression'''
    if len(t) > 2:
        t[1] = store_assignment_spillover( t[1], t )
        t[3] = store_assignment_spillover( t[3], t )

    t[0] = assemble(t, 'p_multiplicative_expression', ' ')




# cast-expression:
def p_cast_expression(t):
    '''cast_expression : unary_expression
                        | unary_command_expression
                        | type_specifier LPAREN expression RPAREN
                        | LPAREN type_specifier RPAREN cast_expression'''
    # (int)myvar

    if len(t) == 5 and t[1] == '(':
        t[0] =  Token( '%s(%s)' % (mel_type_to_python_type[ t[2] ], t[4]) , t[2].type  )
        # skip assemble
        return

    # int( x+3 )
    if len(t) == 5 and t[1] == 'string':
        t[1] = mel_type_to_python_type[ t[1] ]

    t[0] = assemble(t, 'p_cast_expression')


# unary-expression
def p_unary_expression(t):
    '''unary_expression : postfix_expression
                        | unary_operator cast_expression'''

    if len(t)>2:
        if t[1] == '!':
            t[1] = 'not '

        t[2] = store_assignment_spillover( t[2], t )
        t[0] = Token( t[1] + t[2], t[2].type, t[2].lineno )

    else:
        t[0] = assemble(t, 'p_unary_expression')

def p_unary_expression_2(t):
    '''unary_expression : PLUSPLUS unary_expression
                        | MINUSMINUS unary_expression'''
    # ++$var --> var+=1
    #t[0] = Operation( t[2], t[1][0] + '=', '1')
    t[0] = assemble(t, 'p_unary_expression', '', [t[2], t[1][0] + '=1'] )
    t[0].assignment = t[2]

# unary-command-expression:
def p_unary_command_expression(t):
    '''unary_command_expression : procedure_expression
                                | unary_operator procedure_expression'''

    if len(t)>2 and t[1] == '!':
            t[1] = 'not '
    t[0] = assemble(t, 'p_unary_expression')

# unary-operator
def p_unary_operator(t):
    '''unary_operator : PLUS
                    | MINUS
                    | NOT'''
    t[0] = assemble(t, 'p_unary_operator')

#def p_catch_expression(t):
#    '''catch_expression : procedure_expression
#                    | CATCH expression'''
#    t[0] = assemble(t, 'p_catch_expression')

# procedure_expression
def p_procedure_expression(t):
    '''procedure_expression : command_expression
                             | procedure'''

    t[0] = assemble(t, 'p_procedure_expression')


#def p_procedure(t):
#    '''procedure : ID LPAREN procedure_expression_list RPAREN
#                 | ID LPAREN RPAREN '''
#    #t[0] = assemble(t, 'p_procedure')
#    #t[0] = 'mel.' + t[0]
#    if len(t) == 5:
#        t[0] = format_command( t[1], t[3], t )
#    else:
#        t[0] = format_command( t[1],[], t )

def p_procedure(t):
    '''procedure : ID LPAREN procedure_expression_list RPAREN
                    | ID LPAREN RPAREN'''

    # myProc( "this", 2 )
    # myProc()

    if len(t) == 5:
        t[0] = format_command( t[1], t[3], t )
    elif len(t) == 3:
        t[0] = format_command( t[1],[t[2]], t )
    else:
        t[0] = format_command( t[1],[], t )

def p_procedure_expression_list(t):
    '''procedure_expression_list : constant_expression
                               | procedure_expression_list COMMA constant_expression'''
                               #| procedure_expression_list COMMA comment command_expression'''

    #t[0] = assemble(t, 'p_procedure_expression_list', matchFormatting=False )

    if len(t)>2:
        t[0] = t[1] + [t[3]]
    else:
        t[0] = [t[1]]

    return

#    if len(t) == 4:
#        t[2] = None
#
#    elif len(t) == 5:
#        t[2] = None
#        t[3] += t[4]
#        t[4] = None
#
#    t[0] = assemble(t, 'p_procedure_expression_list', ', ')


# command expression
def p_command_expression(t):
    '''command_expression : CAPTURE command CAPTURE'''
    t[0] = t[2]

# postfix-expression:
def p_postfix_expression(t):
    '''postfix_expression : primary_expression
                            | postfix_expression PLUSPLUS
                            | postfix_expression MINUSMINUS'''
#                            | postfix_expression LBRACE initializer_list RBRACE'''
#                            | postfix_expression command_input_list'''

    # $var++ --> var += 1


    # ++ and -- must be converted to += and -=
    if len(t) == 3:
        t[2] = t[2][0] + '=1'
        t[0] = assemble(t, 'p_postfix_expression')
        t[0].assignment = t[1]
    else:
        t[0] = assemble(t, 'p_postfix_expression')


def p_postfix_expression_2(t):
    '''postfix_expression : LBRACE expression_list_opt RBRACE'''

    # array

    #t[0] = assemble(t, 'p_postfix_expression')
    #t[0] = '[%s]' % ', '.join(t[2])
    t[2] = [ store_assignment_spillover( x, t ) for x in t[2] ]
    t[0] = '[%s]' % assemble(t, 'p_postfix_expression_2', ', ', t[2], matchFormatting=True)

def p_postfix_expression_3(t):
    '''postfix_expression : LVEC vector_element_list RVEC'''

    # vector or matrix

    #t[0] = assemble(t, 'p_postfix_expression')
    t[2] = [ store_assignment_spillover( x, t ) for x in t[2] ]
    # FIXME:
    # it's possible for a MATRIX to be constructed using this syntax, ie:
    #   matrix $vectorMat[1][3] = << 1, 2, 3 >>;
    # ...yet the token we return is always "Vector" - fix any problems that may
    # result of assigned this into a matrix variable...
    t[0] = Token( 'Vector([%s])' % ', '.join(t[2]), 'vector', t.lexer.lineno )

def p_postfix_expression_4(t):
    '''postfix_expression : LVEC matrix_row_list RVEC'''

    # vector or matrix

    #t[0] = assemble(t, 'p_postfix_expression')
    t[2] = [[ store_assignment_spillover( x, t ) for x in row ] for row in t[2]]
    rows = ['[%s]' % ', '.join(row) for row in t[2]]
    t[0] = Token( 'Matrix([%s])' % ', '.join(rows), 'matrix', t.lexer.lineno )

def p_postfix_expression_5(t):
    '''postfix_expression : postfix_expression LBRACKET expression RBRACKET'''

    # array element index:
    # $var[2-4]
    type = t[1].type
    t[3] = store_assignment_spillover( t[3], t )
    if not t[3]:
        t[0] = t[1]
    elif t[3] == 'len(%s)' % t[1]:
        t[0] = t[1] + '[' + t[3] + ']'
        t[0].appendingToArray = str(t[1])

        #if hasattr( t[1], 'globalVar' ):
        #    t[0] = t[1] + ' += [%s]'
        #else:
        #    t[0] = t[1] + '.append(%s)'
    else:
        lenSubtractReg = re.compile( 'len\(%s\)\s*(-)' % t[1] )
        try:
            # assignment relative to the end of the array:   x[-1]
            t[0] = t[1] + '[%s]' % (''.join(lenSubtractReg.split( t[3] )) )
        except:
            t[0] = t[1] + '[%s]' % ( t[3] )

    # type is no longer an array
    try:
        t[0].type = type.strip('[]')
    except AttributeError: pass

    if hasattr( t[1], 'globalVar' ):
        t[0].indexingItem = ( t[1], t[3] )

# matrix_row_list:
def p_matrix_row_list_1(t):
    '''matrix_row_list : vector_element_list SEMI vector_element_list'''
    # new
    t[0] = [t[1], t[3]]

def p_matrix_row_list_2(t):
    '''matrix_row_list : matrix_row_list SEMI vector_element_list'''

    # append
    t[0] = t[1] + [t[3]]

# vector_element_list:
def p_vector_element_list(t):
    '''vector_element_list : expression
                           | vector_element_list COMMA expression'''
    # new
    if len(t) == 2:
        t[0] = [t[1]]

    # append
    else:
        t[0] = t[1] + [t[3]]

# primary-expression:
def p_primary_expression_paren(t):
    '''primary_expression :    LPAREN expression RPAREN'''

    t[0] = Token( t[1] + t[2] + t[3], t[2].type )

def p_primary_expression(t):
    '''primary_expression :    boolean
                          |    numerical_constant'''
    t[0] = assemble(t, 'p_primary_expression')
    if t.lexer.verbose >= 2:
        print "p_primary_expression", t[0]

def p_primary_expression1(t):
    '''primary_expression :     SCONST'''
    t[0] = Token(t[1], 'string', t.lexer.lineno)
    if t.lexer.verbose >= 2:
        print "p_primary_expression", t[0]

def p_primary_expression2(t):
    '''primary_expression :     variable'''
    t[0] = t[1]
    if t.lexer.verbose >= 2:
        print "p_primary_expression", t[0]

    #print "mapping", t[1], t.lexer.type_map.get(t[1], None)
    #print "p_primary_expression", t[0]

def p_numerical_constant(t):
    '''numerical_constant : int_constant
                          | float_constant'''
    t[0] = assemble(t, 'p_numerical_constant')

def p_int_constant(t):
    '''int_constant :     ICONST'''
    # not needed, python understands this notation without the conversion below
    #if t[1].startswith('0x'):
    #    t[1] = "int( '%s', 16 )" % t[1]
    t[0] = Token(t[1], 'int', t.lexer.lineno)

def p_float_constant(t):
    '''float_constant :     FCONST'''
    t[0] = Token(t[1], 'float', t.lexer.lineno)


# comment
#def p_comment(t):
#    '''comment : COMMENT'''
#    t[0] = '#' + t[1][2:] + '\n'

#def p_comment_block(t):
#    '''comment : COMMENT_BLOCK'''
#    t[0] = '"""%s"""' % t[1][2:-2] + '\n'


# types

def p_boolean_true(t):
    '''boolean : ON
                | TRUE
                | YES '''
    t[0] = 'True'
    if t.lexer.verbose >= 2:
        print "p_boolean_true", t[0]

def p_boolean_false(t):
    '''boolean : OFF
                | FALSE
                | NO '''
    t[0] = 'False'
    if t.lexer.verbose >= 2:
        print "p_boolean_false", t[0]

def p_variable(t):
    '''variable : VAR'''

    # TODO : resolve issue of global variables conflicting with reserved words
    # they will be suffixed with an underscore and won't be able to sync with
    # their mel equivalent

    t[1] = t[1].lstrip('$')
    if t[1] in pythonReservedWords:
        var = t[1] + '_'
    else:
        var = t[1]

    typ = t.lexer.type_map.get(var, None)

    if var in t.lexer.global_vars:
        t[0] = Token("%smelGlobals['%s']" % (t.lexer.pymel_namespace, var),
                     typ, t.lexer.lineno, globalVar=var)

    else:
        t[0] = Token(var, typ, t.lexer.lineno )

    if t.lexer.verbose >= 2:
        print "p_variable", t[0]

def p_variable_vector_component(t):
    '''variable :  VAR COMPONENT'''
    t[1] = t[1].lstrip('$')
    t[0] = Token(t[1]+t[2], 'float', t.lexer.lineno)
    if t.lexer.verbose >= 2:
        print "p_variable_vector_component", t[0]

# command_statement
# -- difference between a comamnd_statement and a command:
#        a command_statement is always followed by a semi-colon
#        a command_statement can receive a command_expression as input
def p_command_statement(t):
    '''command_statement : ID SEMI
            | ID command_statement_input_list SEMI'''

    vprint(t, "p_command_statement", t.lexer.lineno)
    if len(t) == 3:
        t[0] = format_command(t[1], [], t) + '\n'
    else:
        t[0] = format_command(t[1], t[2], t) + '\n'
    append_comments(t)

def p_command_statement_input_list(t):
    '''command_statement_input_list : command_statement_input
                                      | command_statement_input_list command_statement_input'''
    #t[0] = assemble(t, 'p_command_input_list')

    if len(t)>2:
        if isinstance(t[2], list):
            t[0] = t[1] + t[2]
        #print "append"
        else:
            t[0] = t[1] + [t[2]]
    else:
        #print "new"
        if isinstance(t[1], list):
            t[0] = t[1]
        else:
            t[0] = [t[1]]


def p_command_statement_input(t):
    '''command_statement_input : unary_expression
                                | command_flag
                                  | command_expression'''
    t[0] = assemble(t, 'p_command_statement_input')

def p_command_statement_input_2(t):
    '''command_statement_input     : object_list'''
    t[0] =  map( lambda x: "'%s'" % x, t[1])

def p_command_statement_input_3(t):
    '''command_statement_input     : ELLIPSIS'''
    t[0] = Token( "'%s'" % t[1], None, t.lexer.lineno )

# command
# -- difference between a comamnd_statement and a command:
#        a command_statement is always followed by a semi-colon
#        a command_statement can receive a command_expression as input
def p_command(t):
    '''command : ID
                | ID command_input_list'''
    #print "p_command"
    if len(t) == 2:
        t[0] = format_command(t[1],[], t)
    else:
        t[0] = format_command(t[1], t[2], t)


def p_command_input_list(t):
    '''command_input_list : command_input
                          | command_input_list command_input'''
    #t[0] = assemble(t, 'p_command_input_list')

    #t[0] = ' '.join(t[1:])
    if len(t)>2:
        if isinstance(t[2], list):
            t[0] = t[1] + t[2]
        #print "append"
        else:
            t[0] = t[1] + [t[2]]
    else:
        #print "new"
        if isinstance(t[1], list):
            t[0] = t[1]
        else:
            t[0] = [t[1]]

def p_command_input(t):
    '''command_input : unary_expression
                      | command_flag'''
    t[0] = assemble(t, 'p_command_input')

def p_command_input_2(t):
    '''command_input     : object_list'''
    t[0] =  map( lambda x: "'%s'" % x, t[1])

def p_command_input_3(t):
    '''command_input     : ELLIPSIS'''
    t[0] = Token( "'%s'" % t[1], None, t.lexer.lineno )

def p_object_list(t):
    '''object_list : object
                   | object_list object'''
    #t[0] = assemble(t, 'p_command_input_list')

    #t[0] = ' '.join(t[1:])
    if len(t)>2:
        #print "append"
        # `myFunc foo[0].bar` and `myFunc foo[0] .bar` appear the same to the lexer
        # we must check whitespace, and join or split where necessary
        lastObj = t[1][-1]
        #print lastObj #, t[1][-1].lexspan[1]
        #print t[2], t[2].lexspan[0]+1
        if lastObj.lexspan[1]+1 == t[2].lexspan[0]:
            # same object: join together with last element in the list and add to list
            #print t[1][-1].lexspan[1]+1, t[2].lexspan[0]
            joinedToken = Token( lastObj + t[2],
                                    'string',
                                    lastObj.lineno,
                                    lexspan = [ lastObj.lexspan[0], t[2].lexspan[1] ] )
            t[0] = t[1][:-1] + [ joinedToken ]
        else:
            t[0] = t[1] + [ t[2] ]
        #print t[0][-2], t[0][-2].lexspan
        #print t[0][-1], t[0][-1].lexspan
    else:
        #print "new"
        t[0] = [t[1]]
    #print "result", t[0]

def p_object_1(t):
    '''object    : ID'''
    if t.lexer.verbose >= 1:
        print 'p_object_1', t[1]
    #print t[1], t.lexpos(1), len(t[1]), t.lexpos(1)+len(t[1])
    t[0] = Token( t[1], 'string', lexspan=(t.lexpos(1),t.lexpos(1)+len(t[1])-1 ) )
    #t[0] = assemble(t, 'p_object_1')

#def p_object_2(t):
#    '''object    : LOBJECT expression RBRACKET
#                | LOBJECT expression ROBJECT'''
#    t[0] = assemble(t, 'p_object_2')



def p_object_2(t):
    '''object    : ID LBRACKET expression RBRACKET'''
    #print t.lexpos(1), t.lexpos(2),t.lexpos(3),t.lexpos(4)
    if t.lexer.verbose >= 1:
        print 'p_object_2'
    t[0] = Token( t[1]+t[2]+t[3]+t[4], 'string', lexspan=(t.lexpos(1),t.lexpos(4) ) )
    #t[0] = assemble(t, 'p_object_2')

def p_flag(t):
    '''command_flag : MINUS ID
                    | MINUS BREAK
                    | MINUS CASE
                    | MINUS CONTINUE
                    | MINUS DEFAULT
                    | MINUS DO
                    | MINUS ELSE
                    | MINUS FALSE
                    | MINUS FLOAT
                    | MINUS FOR
                    | MINUS GLOBAL
                    | MINUS IF
                    | MINUS IN
                    | MINUS INT
                    | MINUS NO
                    | MINUS ON
                    | MINUS OFF
                    | MINUS PROC
                    | MINUS RETURN
                    | MINUS STRING
                    | MINUS SWITCH
                    | MINUS TRUE
                    | MINUS VECTOR
                    | MINUS WHILE
                    | MINUS YES
                    '''

    # TODO: find complete list
    flag = t[1] +  t[2]

    #t[0] = assemble(t, 'p_flag', '', [flag]  )
    t[0] = Token( flag, 'flag', t.lexer.lineno )


# Other
def p_empty(t):
    '''empty : '''
    t[0] = assemble(t, 'p_empty')

def _error(t):
    if t.lexer.verbose:
        print "Error parsing script, attempting to read forward and restart parser"
    while 1:
        tok = yacc.token()             # Get the next token
        if not tok or tok.type == 'RBRACE': break
    yacc.restart()

def p_error(t):
    if t is None:
        raise ValueError, 'script has no contents'

    if t.type in ('COMMENT', 'COMMENT_BLOCK'):
        #print "Removing Comment", t.value
        # Just discard the token and tell the parser it's okay.
        t.lexer.comment_queue.append(Comment(t))
        yacc.errok()
    else:
        t.lexer.errors.append(t)
        #if t.lexer.verbose:
        #    print "Error parsing script at %s, attempting to read forward and restart parser" % t.value
        while 1:
            tok = yacc.token()             # Get the next token
            if not tok or tok.type == 'RBRACE': break
        yacc.restart()


#  Main Parser / Scanner Classes -----------------------------------------------

#import profile
# Build the grammar

lexer = lex.lex(module=mellex)

_outputdir = tempfile.gettempdir()
parser = yacc.yacc(method='''LALR''', debug=0, outputdir=_outputdir )

class MelParseError(Exception):
    def __init__(self, *args, **kwargs):
        self.data = kwargs.pop('data', None)
        self.file = kwargs.pop('file', None)
        self.lexer = kwargs.pop('lexer', None)
        super(MelParseError, self).__init__(*args, **kwargs)

    def __str__(self):
        base = super(MelParseError, self).__str__()
        if self.file:
            base += " - Error parsing %s - check for syntax errors" % self.file
        if self.lexer and self.lexer.errors:
            base += "\n\nErrors:\n"
            for errToken in self.lexer.errors:
                base += "line %d (%s): %s\n" % (errToken.lineno, errToken.type, errToken.value)
        return base

class ExpressionParseError(MelParseError, TypeError):
    '''Error when mel code cannot be parsed into a python expression
    '''
    pass

class MelParser(object):
    """The MelParser class around which all other mel2py functions are based."""
    def build(self, rootModule = None, pymelNamespace='', verbosity=0,
              addPymelImport=True, expressionsOnly=False,
              forceCompatibility=True, parentData=None ):

        # data storage
        self.lexer = lexer.clone()
        self.lexer.proc_list = []  # ordered list of procedures
        self.lexer.local_procs = {} # dictionary of local procedures and their related data
        self.lexer.global_procs = {} # dictionary of global procedures and their related data
        self.lexer.imported_modules = set([])  # imported external modules, pymel is assumed
        self.lexer.global_vars = set([])
        self.lexer.spillover_pre = []  # some operations require a single line to be split.
        self.lexer.comment_queue = []
        self.lexer.comment_queue_hold = []
        self.lexer.type_map = {}
        self.lexer.global_var_include_regex = 'gv?[A-Z_].*'     # maya global vars usually begin with 'gv_' or a 'g' followed by a capital letter
        #parser.global_var_include_regex = '.*'
        self.lexer.global_var_exclude_regex = '$'
        #parser.global_var_exclude_regex = 'g_lm.*'        # Luma's global vars begin with 'g_lm' and should not be shared with the mel environment

        # options
        if pymelNamespace and not pymelNamespace.endswith( '.' ):
            pymelNamespace = pymelNamespace + '.'
        self.lexer.pymel_namespace = pymelNamespace
        self.lexer.root_module = rootModule #the name of the module that the hypothetical code is executing in. default is None (i.e. __main__ )
        self.lexer.verbose = verbosity
        self.add_pymel_import = addPymelImport
        self.lexer.force_compatibility = forceCompatibility
        self.lexer.expression_only = expressionsOnly
        self.lexer.errors = []
        self.lexer.parent_data = parentData

    def parse(self, data):
        data = data.decode( 'utf-8', 'ignore')
        #data = data.encode( 'utf-8', 'ignore')
        data = data.replace( '\r\n', '\n' )
        data = data.replace( '\r', '\n' )

        self.lexer.raw_parse_data = data
        try:
            if self.lexer.verbose == 2:
                lex.input(data)
                while 1:
                    tok = lex.token()
                    if not tok: break      # No more input
                    print tok

            prev_modules = self.lexer.imported_modules.copy()

            self.lexer.comment_queue = []
            self.lexer.comment_queue_hold = []

            translatedStr = ''
            try:
                debug = (self.lexer.verbose >= 3)
                translatedStr = parser.parse(data, lexer=self.lexer, debug=debug)
                #translatedStr = simpleParser.parse(data, lexer=self.lexer)

            except ValueError:
                if self.lexer.comment_queue:
                    translatedStr = format_comments(self.lexer.comment_queue)
                else:
                    raise

            if translatedStr is None or self.lexer.errors:
                raise MelParseError(data=data, lexer=self.lexer)
            #except IndexError, msg:
            #    raise ValueError, '%s: %s' % (melfile, msg)
            #except AttributeError:
            #    raise ValueError, '%s: %s' % (melfile, "script has invalid contents")

            if not self.lexer.expression_only:
                new_modules = self.lexer.imported_modules.difference( prev_modules )

                header = ''

                # adding the pymel import statement should occur only on the
                # first execution of the parser or not at all.

                if self.add_pymel_import:
                    if not self.lexer.pymel_namespace:
                        header += 'from pymel.all import *\n'
                    elif self.lexer.pymel_namespace == 'pymel.':
                        header += 'import pymel.all as pymel\n'
                    else:
                        header += 'import pymel.all as %s\n' % self.lexer.pymel_namespace[:-1]
                    self.add_pymel_import = False

                for new_module in new_modules:
                    header += "import %s\n" % new_module
                translatedStr = header + translatedStr


            return translatedStr
        finally:
            self.lexer.raw_parse_data = None

scanner = yacc.yacc(method='''LALR''', debug=0, module=melscan, outputdir=_outputdir)



#simple = SimpleMelGrammar()
#standard = MelGrammar()
#parser = standard.parser
#parser = simple.parser

class MelScanner(object):
    """Basic mel parser which only tries to get information about procs"""
    def build(self):

        # data storage
        self.lexer = lexer.clone()
        self.lexer.proc_list = []  # ordered list of procedures
        self.lexer.local_procs = {} # dictionary of local procedures and their related data
        self.lexer.global_procs = {} # dictionary of global procedures and their related data
        self.lexer.global_vars = set([])


    def parse(self, data):
        data = data.decode('utf-8', 'ignore')
        #data = data.encode( 'utf-8', 'ignore')
        data = data.replace( '\r', '\n' )

        scanner.parse(data, lexer=self.lexer)
            #translatedStr = simpleParser.parse(data, lexer=self.lexer)

        return self.lexer.proc_list, self.lexer.global_procs, self.lexer.local_procs

#profile.run("yacc.yacc(method='''LALR''')")



########NEW FILE########
__FILENAME__ = melscan
import sys, os, re, os.path
import mellex

try:
    from pymel.util.external.ply import *
except ImportError:
    from ply import *

from pymel.util import unescape
import pymel
import pymel.util as util
import pymel.internal.factories as factories

tokens = mellex.tokens
def p_translation_unit(t):
    '''translation_unit : external_declaration
                        | translation_unit external_declaration'''
    pass
    #print "translation_unit"
    #t[0] = assemble(t, 'p_translation_unit')
    #print '\n'

# external-declaration:
def p_external_declaration(t):
    '''external_declaration : function_definition
                            | group'''
    pass
    #print "external_declaration", t[1]
    #t[0] = assemble(t, 'p_external_declaration')
    #if t.lexer.verbose:
    #    print "external_declaration", t[0]

# function-definition:
def p_function_definition(t):
    '''function_definition :  function_declarator function_specifiers_opt ID LPAREN function_arg_list_opt RPAREN group'''
    #t[0] = assemble(t, 'p_function_definition')

    # add to the ordered list of procs
    t.lexer.proc_list.append( t[3] )

    # global proc
    if t[1]:
        #print "adding global"
        t.lexer.global_procs[ t[3] ] = { 'returnType' : t[2], 'args' : t[5] }
        #t[0] = addHeldComments(t, 'func') + "def %s(%s):\n%s\n" % (t[3], ','.join(t[6]) , entabLines( t[9]) )

    # local proc gets prefixed with underscore
    else:
        #print "adding local"
        t.lexer.local_procs[ t[3] ] = { 'returnType' : t[2], 'args' : t[5] }
        #t[0] = addHeldComments(t, 'func') + "def _%s(%s):\n%s\n" % (t[3], ','.join(t[6]) , entabLines( t[9]) )

def p_function_declarator(t):
    '''function_declarator : GLOBAL PROC
                           | PROC'''
    # string
    # string[]
    #
    if len(t) == 2:
        #print "local proc"
        t[0] = False
    else:
        #print "global proc"
        t[0] = True

def p_type_specifier(t):
    '''type_specifier : INT
                      | FLOAT
                      | STRING
                      | VECTOR
                      | MATRIX
                      '''
    #print "type_specifier"
    t[0] = t[1]

# function-specifiers
def p_function_specifiers_opt(t):
    '''function_specifiers_opt : type_specifier
                                  | type_specifier LBRACKET RBRACKET
                                  | empty'''
    # string
    # string[]
    #
    #print "function_specifiers_opt"
    if len(t)==2:
        t[0] = t[1]
    else:
        t[0] = t[1] + '[]'
    #t[0] = assemble(t, 'p_function_specifiers_opt')



def p_function_arg(t):
    '''function_arg : type_specifier VAR
                    | type_specifier VAR LBRACKET RBRACKET'''
    #t[0] = assemble(t, 'p_function_arg')
    if len(t) == 3:
        t[0] = ( t[1], t[2] )
    else:
        t[0] = ( t[1]+'[]', t[2])

def p_function_arg_list(t):
    '''function_arg_list : function_arg
                        | function_arg_list COMMA function_arg'''

    #t[0] = assemble(t, 'p_function_arg_list')
    if len(t)>2:
        t[0] = t[1] + [t[3]]
    # start a new list
    else:
        t[0] = [t[1]]

def p_function_arg_list_opt(t):
    '''function_arg_list_opt : function_arg_list
                        |  empty'''

    #t[0] = assemble(t, 'p_function_arg_list_opt')
    if not t[1]:
        t[0] = []
    else:
        t[0] = t[1]



def p_declaration_specifiers(t):
    '''declaration_specifiers : type_specifier
                              | GLOBAL type_specifier'''
    #print "declaration_specifiers"
    if len(t) == 2:
        t[0] = ( None, t[1] )
    else:
        t[0] = ( t[1], t[2] )




def p_group_list_opt(t):
    '''group_list_opt : group_list
                | empty
                '''
    #print "group_list_opt"
    t[0] = t[1]

def p_group_list(t):
    '''group_list : group_list group
            | group'''
    pass
#    print "group_list"
#    if len(t) == 2:
#        t[0] = [t[1]]
#    else:
#        t[0] = t[1] + [t[2]]

def p_group(t):
    '''group : element
            | LBRACE group_list_opt RBRACE'''
    pass
#    if len(t) == 2:
#        print "group", t[1]
#        t[0] = t[1]
#    else:
#        print "adding brackets", t[2]
#        t[0] = t[2]

#def p_element_list_opt(t):
#    '''element_list_opt : element_list
#                | empty
#                '''
#    print "empty"
#    t[0] = t[1]
#
#def p_element_list(t):
#    '''element_list : element
#                | element_list element
#                '''
#    if len(t) == 2:
#        t[0] = [t[1]]
#    else:
#        t[0] = t[1] + [t[2]]

def p_element(t):
    '''element : declaration_specifiers
            | BREAK
            | CASE
            | CONTINUE
            | DEFAULT
            | DO
            | ELSE
            | FALSE
            | FOR
            | IF
            | IN
            | NO
            | ON
            | OFF
            | RETURN
            | SWITCH
            | TRUE
            | WHILE
            | YES
            | ID
            | VAR
            | ICONST
            | FCONST
            | SCONST
            | PLUS
            | MINUS
            | TIMES
            | DIVIDE
            | MOD
            | NOT
            | CROSS
            | LOR
            | LAND
            | LT
            | LE
            | GT
            | GE
            | EQ
            | NE
            | EQUALS
            | TIMESEQUAL
            | DIVEQUAL
            | MODEQUAL
            | PLUSEQUAL
            | MINUSEQUAL
            | CROSSEQUAL
            | COMPONENT
            | PLUSPLUS
            | MINUSMINUS
            | CONDOP
            | LPAREN
            | RPAREN
            | LBRACKET
            | RBRACKET
            | COMMA
            | SEMI
            | COLON
            | CAPTURE
            | LVEC
            | RVEC
            | COMMENT
            | COMMENT_BLOCK
            | ELLIPSIS

            '''
    #print "element", t[1]
    t[0] = t[1]

def p_empty(t):
    '''empty : '''
    pass
    #t[0] = assemble(t, 'p_empty')

#def p_error(t):
#    print "error"
#    pass

########NEW FILE########
__FILENAME__ = ui
from pymel.core.windows import *

class MelToPythonWindow(Window):

    def __new__(cls, name=None):
        self = window(title=name or "Mel To Python")
        return Window.__new__(cls, self)

    def convert(w):
        from .. import mel2pyStr
        if cmds.cmdScrollFieldExecuter(w.mel,q=1,hasSelection=1):
            cmds.cmdScrollFieldExecuter(w.mel,e=1,copySelection=1)
            cmds.cmdScrollFieldExecuter(w.python,e=1,clear=1)
            cmds.cmdScrollFieldExecuter(w.python,e=1,pasteSelection=1)
            mel = cmds.cmdScrollFieldExecuter(w.python,q=1,text=1)
        else:
            mel = cmds.cmdScrollFieldExecuter(w.mel,q=1,text=1)
        try:
            py = mel2pyStr(mel)
        except Exception, e:
            confirmDialog(t="Mel To Python",m="Conversion Error:\n%s" % e,b=["Ok"], db="Ok")
        else:
            cmds.cmdScrollFieldExecuter(w.python,e=1,text=py)


    def __init__(self):
        formLayout(slc=True, ratios=[1,.1,1], orientation=FormLayout.HORIZONTAL, childCreators = [
              cmdScrollFieldExecuter("mel", slc=True),
              button("button", slc=True, l="->", c=lambda *x: self.convert(), bgc=[.5,.7,1]),
              cmdScrollFieldExecuter("python", slc=True, st="python")
              ]).create(self.__dict__,parent=self,debug=1)

        self.setWidthHeight([600,800])
        self.show()


########NEW FILE########
__FILENAME__ = mel2pyCommand
#!/usr/bin/env mayapy
"""
version of mel2py which is intended to be used as a command-line script.

Symbolic link it to an easier-to-type name (ie, 'mel2py') in a directory on your path
"""

# Can't be a submodule of mel2py, because we wish to avoid importing mel2py (which
# triggers the entire maya-initialization process) if we're just printing usage,
# or there's an error processing command-line arguments.


class Options(dict):
    """
    Wrap of a dictionary object to get options parsed from OptionParser into a dict.
    """
    def __setattr__(self, name, value):
        if hasattr(self, name):
            super(self, Options).__setattr__(name, value)
        else:
            self[name] = value

def main():
    from optparse import OptionParser
    import sys

    usage = """%prog [options] input (outputDir)
Arguments:
  input
    May be a directory, a list of directories,
    the name of a mel file, a comma-separated list
    of mel files, or the name of a sourced procedure.
    If only the name of the mel file is passed,
    mel2py will attempt to determine the location
    of the file using the 'whatIs' mel command, which relies
    on the script already being sourced by maya."""
    parser = OptionParser(usage=usage)
    opts = Options()


    parser.add_option("-o", "--outputDir",
                      help="""Directory where resulting python files will be written to""")
    parser.add_option("-n", "--pymelNamespace",
                      help="the namespace into which pymel will be imported.  the default is '', which means ``from pymel.all import *``")
    parser.add_option("-c", "--forceCompatibility", action="store_true",
                      help="""If True, the translator will attempt to use non-standard python types in order to produce
python code which more exactly reproduces the behavior of the original mel file, but which
will produce "uglier" code.  Use this option if you wish to produce the most reliable code
without any manual cleanup.""")
    parser.add_option("-v", "--verbosity", type="int",
                      help="""Set to non-zero for a *lot* of feedback""")
    parser.add_option("-t", "--test", action="store_true",
                      help="""After translation, attempt to import the modules to test for errors""")
    parser.add_option("-r", "--recurse", action="store_true",
                      help="""If the input is a directory, whether or not to recursively search subdirectories as well""")
    parser.add_option("-e", "--exclude",
                      help="""A comma-separated list of files/directories to exclude from processing, if input is a directory.""")
    parser.add_option("-p", "--melPathOnly", action="store_true",
                      help="""If true, will only translate mel files found on the mel script path.""")
    parser.add_option("-b", "--basePackage",
                      help="""Gives the package that all translated modules will be a part of; if None or an empty string, all translated modules are assumed to have no base package.""")

    parser.set_defaults(outputDir=None,
            pymelNamespace='', forceCompatibility=False,
            verbosity=0 , test=False,
            recurse=False, exclude=(), melPathOnly=False)
    options, args = parser.parse_args(values=opts)
    if len(args) < 1:
        print "input argument is required!"
        parser.print_help()
        return
    elif len(args) > 2:
        print "mel2py supports at most 2 args - input, outputDir"
        parser.print_help()
        return
    exclude = options.get('exclude', False)
    if exclude:
        options['exclude'] = exclude.split(',')
    from pymel.tools.mel2py import mel2py
    if args and ',' in args[0]:
        args[0] = args[0].split(',')
    mel2py(*args, **options)

if __name__ == '__main__':
    main()
########NEW FILE########
__FILENAME__ = py2mel
"""
Convert python callables into MEL procedures
"""
import inspect
import re
import types
from pymel.util.arguments import isMapping, isIterable
from pymel.core.language import getMelType, isValidMelType, MELTYPES
import pymel.api.plugins as plugins
import maya.mel as _mm
import maya.OpenMayaMPx as mpx
import maya.OpenMaya as om

MAX_VAR_ARGS = 10
MAX_FLAG_ARGS = 6

_functionStore = {}

def _getFunction(function):
    # function is a string, so we must import its module and get the function object
    if isinstance(function, basestring):
        buf = function.split()
        funcName = buf.pop(-1)
        moduleName = '.'.join(buf)
        module = __import__(moduleName, globals(), locals(), [''])
        func = getattr(module, funcName)
    # function is a python object
    elif callable(function) :
        func = function
    else:
        raise TypeError, "argument must be a callable python object or the full, dotted path to the callable object as a string."

    return func

# Flatten a multi-list argument so that in can be passed as
# a list of arguments to a command.

def getMelArgs(function, exactMelType=True):
    """
    given a python function, return ( ( argName, melType ), { argName : default }, { argName : description } )

        function
        This can be a callable python object or the full, dotted path to the callable object as a string.

        If a string representing the python function is passed, it should include all packages and sub-modules, along
        with the function's name:  'path.to.myFunc'

    """

    melArgs = []
    melArgDefaults = {}

    parsedTypes = {}
    parsedDescr = {}

    function = _getFunction(function)

    funcName = function.__name__
    moduleName = function.__module__

    args, varargs, kwargs, defaults = inspect.getargspec(function)
    if inspect.ismethod(function):
        # remove self/cls
        args = args[1:]
#    # epydoc docstring parsing
#    try:
#        import epydoc.docbuilder
#    except ImportError:
#        pass
#    else:
#        try:
#            docindex = epydoc.docbuilder.build_doc_index( [moduleName], parse=True, introspect=True, add_submodules=False)
#            linker = epydoc.markup.DocstringLinker()
#            api_doc = docindex.get_valdoc( moduleName + '.' + funcName )
#        except Exception, msg:
#            print "epydoc parsing failed: %s" % msg
#        else:
#            arg_types = api_doc.arg_types
#            #print api_doc.arg_descrs
#            #print arg_types
#            for arg, descr in api_doc.arg_descrs:
#                # filter out args that are not actually in our function.  that means currently no support for *args and **kwargs
#                # not yet sure why, but the keys to arg_types are lists
#                arg = arg[0]
#                if arg in args: # or kwargs:
#                    parsedDescr[arg] = descr.to_plaintext( linker )
#                    try:
#                        argtype = arg_types[ arg ].to_plaintext( linker )
#                        parsedTypes[arg] = getMelType( pyType=argtype, exactMelType=exactMelType )
#                        #print arg, argtype, parsedTypes.get(arg)
#                    except KeyError: pass


    try:
        ndefaults = len(defaults)
    except:
        ndefaults = 0

    #print args, varargs, kwargs, defaults

    nargs = len(args)
    offset = nargs - ndefaults
    for i, arg in enumerate(args):

        if i >= offset:
            # keyword args with defaults
            default = defaults[i - offset]
            melType = getMelType(default, exactOnly=exactMelType)
            # a mel type of None means there is no mel analogue for this python object
#            if not isValidMelType( melType ):
#                # if it's None, then we go to parsed docs
#                if melType is None:
#                    melType = parsedTypes.get( arg, None )
#                try:
#                    default = default.__repr__()
#                except AttributeError:
#                    default = str(default)
            melArgDefaults[arg] = default
        else:
            # args without defaults
            # a mel type of None means there is no mel analogue for this python object
            melType = parsedTypes.get(arg, None)

        melArgs.append((arg, melType))

    return tuple(melArgs), melArgDefaults, parsedDescr

def py2melProc(function, returnType=None, procName=None, evaluateInputs=True, argTypes=None):
    """This is a work in progress.  It generates and sources a mel procedure which wraps the passed
    python function.  Theoretically useful for calling your python scripts in scenarios where Maya
    does not yet support python callbacks.

    The function is inspected in order to generate a MEL procedure which relays its
    arguments on to the python function.  However, Python features a very versatile argument structure whereas
    MEL does not.

        - python args with default values (keyword args) will be set to their MEL analogue, if it exists.
        - normal python args without default values default to strings. If 'evaluteInputs' is True, string arguments passed to the
            MEL wrapper proc will be evaluated as python code before being passed to your wrapped python
            function. This allows you to include a typecast in the string representing your arg::

                myWrapperProc( "Transform('persp')" );

        - *args : not yet implemented
        - **kwargs : not likely to be implemented


    function
        This can be a callable python object or the full, dotted path to the callable object as a string.

        If passed as a python object, the object's __name__ and __module__ attribute must point to a valid module
        where __name__ can be found.

        If a string representing the python object is passed, it should include all packages and sub-modules, along
        with the function's name:  'path.to.myFunc'

    procName
        Optional name of the mel procedure to be created.  If None, the name of the function will be used.

    evaluateInputs
        If True (default), string arguments passed to the generated mel procedure will be evaluated as python code, allowing
        you to pass a more complex python objects as an argument. For example:

        In python:
            >>> import pymel.tools.py2mel as py2mel
            >>> def myFunc( arg ):
            ...    for x in arg:
            ...       print x
            >>> py2mel.py2melProc( myFunc, procName='myFuncWrapper', evaluateInputs=True )

        Then, in mel::
            // execute the mel-to-python wrapper procedure
            myFuncWrapper("[ 1, 2, 3]");

        the string "[1,2,3]" will be converted to a python list [1,2,3] before it is executed by the python function myFunc
    """

    function = _getFunction(function)

    funcName = function.__name__

    melCompile = []
    melArgs = []
    melArrayToStrDecls = []
    argList, defaults, description = getMelArgs(function)

    if argTypes:
        if isMapping(argTypes):
            pass
        elif isIterable(argTypes):
            tmp = argTypes
            argTypes = {}
            for i, argType in enumerate(tmp):
                argTypes[argList[i][0]] = argType
        else:
            raise ValueError, "argTypes must be iterable or mapping type"
        for argType in argTypes.values():
            if not isValidMelType(argType):
                raise TypeError, "%r is not a valid mel type: %s" % (argType, ', '.join(MELTYPES))
    else:
        argTypes = {}

    for arg, melType in argList:
        melType = argTypes.get(arg, melType)
        if melType == 'string':
            compilePart = "'\" + $%s + \"'" % arg
            melCompile.append(compilePart)
        elif melType == None:
            melType = 'string'
            compilePart = "'\" + $%s + \"'" % arg
            compilePart = r'eval(\"\"\"%s\"\"\")' % compilePart
            melCompile.append(compilePart)
        elif melType.count('[]'):
            melArrayToStrDecls.append('string $_%s ="("; int $i=0;for($i; $i<size($%s); $i++) { $_%s += ($%s[$i] + ",");  } $_%s += ")";' % (arg, arg, arg, arg, arg))
            melCompile.append("'\" + $_%s + \"'" % arg)
        else:
            melCompile.append("\" + $%s + \"" % arg)

        if melType.count('[]'):
            melType = melType.replace('[]', '')
            melArgs.append('%s $%s[]' % (melType, arg))
        else:
            melArgs.append('%s $%s' % (melType, arg))

    if procName is None:
        procName = funcName

    procDef = """global proc %s %s( %s ){ %s
    python("import %s; %s._functionStore[%r](%s)");}""" % (returnType if returnType else '',
                                                            procName,
                                                            ', '.join(melArgs),
                                                            ''.join(melArrayToStrDecls),
                                                            __name__,
                                                            __name__,
                                                            repr(function),
                                                            ','.join(melCompile))
    _functionStore[repr(function)] = function

    _mm.eval(procDef)
    return procName
#--------------------------------------------------------
#  Scripted Command Wrapper
#--------------------------------------------------------

def _shortnameByCaps(name):
    """
    uses hungarian notation (aka camelCaps) to generate a shortname, with a maximum of 3 letters
        ex.

            myProc --> mp
            fooBar --> fb
            superCrazyLongProc --> scl
    """

    shortname = name[0]
    count = 1
    for each in name[1:]:
        if each.isupper() or each.isdigit():
            shortname += each.lower()
            count += 1
            if count == 3:
                break
    return shortname

def _shortnameByUnderscores(name):
    """
    for python methods that use underscores instead of camelCaps, with a maximum of 3 letters
    """

    buf = name.split('_')
    shortname = ''
    for i, token in enumerate(buf):
        shortname += token[0].lower()
        if i == 2:
            break
    return shortname

def _shortnameByConvention(name):
    """
    chooses between byUnderscores and ByCaps
    """

    if '_' in name:
        return _shortnameByUnderscores(name)
    return _shortnameByCaps(name)

def _shortnameByDoc(method):
    """
    a shortname can be explicitly set by adding the keyword shortname followed by a colon followed by the shortname

            ex.

            class foo():
                def bar():
                    'shortname: b'
                    # do some things
                    return

    """
    if hasattr(method, "__doc__") and method.__doc__:
        m = re.search('.*shortname: (\w+)', method.__doc__)
        if m:
            return m.group(1)

def _nonUniqueName(longname, shortname, shortNames, operation):
    if operation in ['skip', 'warn', 'error'] and shortname in shortNames:
        message = "default short name %r for flag %r is taken" % (shortname, longname)
        if operation == 'warn':
            print 'warning: ' + message
            return False
        elif operation == 'skip':
            print 'skipping: ' + message
            return True
        else:
            raise TypeError(message)

def _invalidName(commandName, longname, operation):
    if len(longname) < 4 and operation in ['skip', 'warn', 'error']:
        message = 'long flag names must be at least 4 characters long: %s -%r' % (commandName, longname.lower())
        if operation == 'warn':
            print 'warning: ' + message
            return False
        elif operation == 'skip':
            print 'skipping: ' + message
            return True
        else:
            raise TypeError(message)


def _getShortNames(objects, nonUniqueName):
    """uses several different methods to generate a shortname flag from the long name"""
    shortNames = []
    nonunique = {}
    for obj in objects:
        if isinstance(obj, (list, tuple)):
            longname = obj[0]
            if obj[0] is not None:
                shortname = _shortnameByDoc(obj[1])
        else:
            longname = obj
            shortname = None
        # try _shortnameByDoc first

        if not shortname:
            shortname = _shortnameByConvention(longname)

        if not shortname or shortname in shortNames:
            if _nonUniqueName(longname, shortname, shortNames, nonUniqueName):
                shortname = None
            else:
                shortname = longname[0]
                unique = False
                for each in longname[1:3]:
                    shortname += each.lower()
                    if shortname not in shortNames:
                        unique = True
                        break
                if not unique:
                    baseshort = shortname[:2]
                    while True:
                        count = nonunique.get(baseshort, 0) + 1
                        nonunique[baseshort] = count
                        shortname = baseshort + str(count)
                        if shortname not in shortNames:
                            break
                    #print 'could not find a unique shortname for %s: using %s'% ( methodName, shortname )
        shortNames.append((longname, shortname))
    return tuple(shortNames)

def _getArgInfo(obj, allowExtraKwargs=True, maxVarArgs=MAX_VAR_ARGS,
                filter=None):
    '''Returns a dict giving info about the arugments for the function/property

    If obj is None, will return the 'defaults'.
    '''
    # per flag query and edit settings
    canQuery = False
    canEdit = False
    defaults = {}
    argNames = []

    # object.__init__ is a 'slot wrapper', but can't find that type defined
    # anywhere...
    if isinstance(obj, (types.BuiltinFunctionType, type(object.__init__),
                        types.NoneType)):
        maxArgs = 0
    elif isinstance(obj, property):
        # enable edit and query to determine what the user intends to do with this get/set property
        if obj.fget:
            canQuery = True
        if obj.fset:
            canEdit = True
        maxArgs = 1
    else:
        argNames, extraArgs, extraKwargs, defaults = inspect.getargspec(obj)
        if defaults is None:
            defaults = {}
        if isinstance(obj, types.MethodType):
            # remove the self arg
            del argNames[0]
        if extraKwargs and not allowExtraKwargs:
            raise ValueError('arguments of the format **kwargs are not supported')

        #turn defaults into a dict
        defaults = dict(zip(argNames[-len(defaults):], defaults))

        if filter:
            newArgNames = []
            for argName in argNames:
                # can only filter out optional args
                if argName not in defaults or filter(argName):
                    newArgNames.append(argName)
                else:
                    del defaults[argName]
            argNames = newArgNames

        # a variable number of args can be passed to the flag. set the maximum number
        if extraArgs:
            maxArgs = maxVarArgs
        else:
            maxArgs = len(argNames)

    return {'maxArgs':maxArgs, 'canQuery':canQuery, 'canEdit':canEdit,
            'argNames':argNames, 'defaults':defaults}


class WrapperCommand(plugins.Command):
    _syntax = None
    _flagInfo = None
    _mainArgInfo = None

    @classmethod
    def createSyntax(cls):
        return cls._syntax

    def setResult(self, result):
        """
        convert to a valid result type
        """

#        int
#        double
#        bool
#        const MString
#        const MIntArray
#        const MDoubleArray
#        const MStringArray


        if result is None: return

        if isinstance(result, dict):
            #convert a dictionary into a 2d list
            newResult = []
            for key, value in result.items():
                newResult.append(key)
                newResult.append(value)
            mpx.MPxCommand.setResult(newResult)
        else:
            #try:
            mpx.MPxCommand.setResult(result)

    def parseCommandArgs(self, argData):
        argValues = []
        i = 0
        while(1):
            try:
                argValues.append(argData.commandArgumentString(i).encode())
            except RuntimeError:
                break
            else:
                i += 1
        return argValues

    def parseFlagArgs(self, argData):
        """
        cycle through known flags looking for any that have been set.

        :rtype: a list of (flagLongName, flagArgList) tuples
        """

        argValues = []
        for flag in self._flagInfo:
            if argData.isFlagSet(flag):
                canQuery = self._flagInfo[flag].get('canQuery', False)
                canEdit = self._flagInfo[flag].get('canEdit', False)
                if argData.isQuery():
                    if not canQuery:
                        raise SyntaxError, 'cannot use the query flag with %s' % flag
                elif argData.isEdit():
                    if not canEdit:
                        raise SyntaxError, 'cannot use the query edit with %s' % flag
                elif canQuery or canEdit:
                    raise SyntaxError, 'the %s flag must be used with either query or edit' % flag

                flagArgs = []
                maxArgs = self._flagInfo[flag]['maxArgs']
                for i in range(maxArgs):
                    try:
                        flagArgs.append(argData.flagArgumentString(flag, i))
                    except Exception:
                        break

                argValues.append((flag, flagArgs))
        return argValues

def py2melCmd(pyObj, commandName=None, register=True, includeFlags=None,
              excludeFlags=[], includeFlagArgs=None, excludeFlagArgs={},
              nonUniqueName='warn', invalidName='warn'):
    """
    Create a MEL command from a python function or class.

    A MEL command has two types of arguments: command arguments and flag arguments.  In the case of passing a function, the function's
    non-keyword arguments become the command arguments and the function's keyword arguments become the flag arguments.
    for example::

        def makeName( first, last, middle=''):
            if middle:
                return first + ' ' + middle + ' ' + last
            return first + ' ' + last

        import pymel as pm
        from pymel.tools.py2mel import py2melCmd
        cmd = py2melCmd( makeName, 'makeNameCmd' )
        pm.makeNameCmd( 'Homer', 'Simpson')
        # Result: Homer Simpson #
        pm.makeNameCmd( 'Homer', 'Simpson', middle='J.')
        # Result: Homer J. Simpson #

    Of course, the real advantage of this tool is that now your python function is available from within MEL as a command::

        makeNameCmd "Homer" "Simpson";
        // Result: Homer Simpson //
        makeNameCmd "Homer" "Simpson" -middle "J.";
        // Result: Homer J. Simpson //

    To remove the command, call the deregister method of the class returned by py2melCmd::

        cmd.deregister()

    This function attempts to automatically create short names (3 character max) based on the long names of the methods or arguments of the pass python object.
    It does this by looping through long names in alphabetical order and trying the following techniques until a unique short name is found:

            1. by docstring (methods only): check the method docstring looking for something of the form ``shortname: xyz``::
                class Foo():
                    def bar():
                        'shortname: b'
                        # do some things
                        return
            2. by convention:  if the name uses under_scores or camelCase, use the first letter of each "word" to generate a short name up to 3 letters long
            3. first letter
            4. first two letters
            5. first three letters
            6. first two letters plus a unique digit

    .. warning:: if you edit the python object that is passed to this function it may result in short names changing!  for example, if you have a class like the following::

                class Foo():
                    def bar():
                        pass

            ``Foo.bar`` will be assigned the short flag name 'b'. but if you later add the method ``Foo.baa``, it will be assigned the short flag name 'b' and 'bar' will be given 'ba'.
            **The only way to be completely sure which short name is assigned is to use the docstring method described above.**

    Parameters
    ----------
    commandName : str
        name given to the generated MEL command
    register : bool
        whether or not to automatically register the generated command.  If
        False, you will have to manually call the `register` method of the
        returned `WrapperCommand` instance
    includeFlags : list of str
        list of flags to include. if given, other flags will be ignored
    exludeFlags : list of str
        list of flags to exclude
    includeFlagArgs : dict from str to list of str
        for each flag, a list of arg names to include; if given, other args will
        be ignored
    excludeFlagArgs : dict from str to list of str
        for each flag, a list of arg names to exclude
    nonUniqueName : 'force', 'warn', 'skip', or 'error'
        what to do if a flag name is not unique
    invalidName: 'force', 'warn', 'skip', or 'error'
        what to do if a flag name is invalid

    """
    if not commandName:
        commandName = pyObj.__name__
    if includeFlagArgs is None:
        includeFlagArgs = {}

    def goodFlag(flag):
        return ((includeFlags is None or flag in includeFlags)
                and flag not in excludeFlags and not flag.startswith('_'))

    syntax = om.MSyntax()
    flagInfo = {}
    flags = []   # ordered list of flags
    if inspect.isfunction(pyObj):
        # args         --> command args
        # keyword args --> flags
        classWrap = False

        mainArgInfo = _getArgInfo(pyObj, allowExtraKwargs=False,
                                  filter=goodFlag)
        ndefaults = len(mainArgInfo['defaults'])

        # positional args become the command args
        cmdArgs = mainArgInfo['argNames'][:-ndefaults]

        # keyword args become the flags
        flags = mainArgInfo['argNames'][-ndefaults:]
        flags = [x for x in flags if goodFlag(x)]
        mainArgInfo['maxArgs'] = len(cmdArgs)
        mainArgInfo['argNames'] = cmdArgs

        for flag in flags:
            # currently keyword args only support one item per flag. eventually we may
            # detect when a keyword expects a list as an argument
            flagInfo[flag] = {'maxArgs':1}

    elif inspect.isclass(pyObj):
        # init/new args--> command args
        # methods      --> flags
        # method args  --> flag args
        classWrap = True

        # __init__ or __new__ becomes the command args
        try:
            initFunc = pyObj.__init__
        except AttributeError:
            initFunc = None
        if initFunc is None or initFunc == object.__init__:
            initFunc = object.__new__
        mainArgInfo = _getArgInfo(initFunc, filter=goodFlag)

        # methods become the flag args
        for longname, method in inspect.getmembers(pyObj, lambda x: inspect.ismethod(x) or isinstance(x, property)):
            if not goodFlag(longname):
                continue
            flags.append(longname)

            includeArgs = includeFlagArgs.get(longname)
            excludeArgs = excludeFlagArgs.get(longname, ())

            def goodFlagArg(flagArg):
                return ((includeArgs is None or flagArg in includeArgs)
                        and flagArg not in excludeArgs)

            argInfo = _getArgInfo(method, maxVarArgs=MAX_FLAG_ARGS,
                                  filter=goodFlagArg)
            argInfo['method'] = method
            argInfo['methodName'] = longname
            argInfo['type'] = type(method)
            flagInfo[longname] = argInfo


    # command args
    for _ in range(mainArgInfo['maxArgs']):
        syntax.addArg(om.MSyntax.kString)

    for origname, shortname in _getShortNames(flags, nonUniqueName):
        if shortname is None:
            # we skipped the flag
            continue
        longname = origname
        if _invalidName(commandName, longname, invalidName):
            continue
        if len(longname) < 4:
            longname = longname.ljust(4, 'x')

        # TODO: currently no check that LONG name is unique...
        # ...maybe roll this into _getShortNames... make it _getNames?
        if longname != origname:
            flagInfo[longname] = flagInfo.pop(origname)

        thisFlagInfo = flagInfo[longname]
        # NOTE: shortname and longname MUST be stored on the class or they will
        # get garbage collected and the names will be destroyed
        thisFlagInfo['shortname'] = shortname

        if thisFlagInfo['canQuery']:
            syntax.enableQuery(True)
        if thisFlagInfo['canEdit']:
            syntax.enableEdit(True)

        # currently keyword args only support one item per flag. eventually we may
        # detect when a keyword expects a list as an argument
        syntaxArgs = [shortname, longname] + ([om.MSyntax.kString] * thisFlagInfo['maxArgs'])
        syntax.addFlag(*syntaxArgs)

    class dummyCommand(WrapperCommand):
        _syntax = syntax
        _flagInfo = flagInfo
        _mainArgInfo = mainArgInfo
        def doIt(self, argList):

            argData = om.MArgParser(self.syntax(), argList)

            cmdArgs = self.parseCommandArgs(argData)
            flagArgs = self.parseFlagArgs(argData)

            if not classWrap:
                # doing a function wrap...

                # unpack the flag arguments, there should always only be 1
                kwargs = dict([(x[0], x[1][0]) for x in flagArgs])

                res = pyObj(*cmdArgs, **kwargs)
            else:
                # doing a class wrap...

                if len(flagArgs) != 1:
                    raise RuntimeError('only one flag can be used at a time for command %s' % commandName)
                longname, flagArgs = flagArgs[0]

                inst = pyObj(*cmdArgs)
                flagInfo = self._flagInfo[longname]
                attrType = flagInfo['type']
                methodName = flagInfo['methodName']

                if issubclass(attrType, types.MethodType): # method
                    # build out the args and kwargs...
                    # ...can't just pass flagArgs straight into our method using
                    #   myMethod(*flagArgs)
                    # ...because we may have filtered out some optional args, so
                    # the positional information isn't right...
                    ndefaults = len(flagInfo['defaults'])
                    args = flagArgs[:-ndefaults]

                    defaultNames = flagInfo['argNames'][-ndefaults:]
                    defaultVals = flagArgs[-ndefaults:]
                    kwargs = dict(zip(defaultNames, defaultVals))

                    res = getattr(inst, methodName)(*args, **kwargs)
                else: # property
                    if argData.isQuery():
                        res = getattr(inst, methodName)
                    elif argData.isEdit():
                        # property-defined flags can only take one arg
                        if len(flagArgs) != 1:
                            raise RuntimeError('flag %s for command %s may only have one arg' % (longname, commandName))
                        res = setattr(inst, methodName, flagArgs[0])
                    else:
                        raise SyntaxError, "properties must either be edited or queried"
            return self.setResult(res)

    dummyCommand.__name__ = commandName
    if register:
        dummyCommand.register()
    return dummyCommand


########NEW FILE########
__FILENAME__ = removePymelAll
#!/usr/bin/env python
'''This script may be used to "fix" python code that uses
"from pymel.all import *" so that it uses the approved "import pymel.core as pm"

Can be called on a single file, or on a directory to recurse through, looking
for .py files.

While I've tried to be careful with this (ie, it actually parses the code using
python's ast syntax parser, etc), there are undoubtedly some edge cases I've
missed. In other words...

USE AT YOUR OWN RISK!
'''


import argparse
import os
import sys
import inspect
import re
import shutil
import subprocess
import types
import itertools
import ast
import traceback
import __builtin__

THIS_FILE = os.path.abspath(inspect.getsourcefile(lambda:None))
THIS_DIR = os.path.dirname(THIS_FILE)

_READMODE = 'r'
if hasattr(file, 'newlines'):
    _READMODE = 'U'

def getStubPymelCore():
    if 'PYMEL_STUBS' in os.environ:
        stubPath = os.environ['PYMEL_STUBS']
    else:
        # this file should be in:
        #       pymel/tools/removePymelAll.py
        # while stubs usually at:
        #       extras/completion/py
        stubPath = os.path.join(os.dirname(os.dirname(THIS_DIR)), 'extras',
                                'completion', 'py')
    # make sure you've got the stubs loaded!
    #print stubPath
    sys.path.insert(0, stubPath)
    try:
        oldModules = {}
        for moduleName, mod in sys.modules.items():
            if (moduleName == 'pymel' or moduleName.startswith('pymel.')
                    or moduleName == 'maya' or moduleName.startswith('maya.')):
                oldModules[moduleName] = mod
                del sys.modules[moduleName]
        try:
            import pymel.core as pm
            return pm
        finally:
            for moduleName, mod in sys.modules.items():
                if (moduleName == 'pymel' or moduleName.startswith('pymel.')
                        or moduleName == 'maya' or moduleName.startswith('maya.')):
                    del sys.modules[moduleName]

            for moduleName, mod in oldModules.iteritems():
                sys.modules[moduleName] = mod
    finally:
        del sys.path[0]

def getModuleNames(module):
    names = set()
    for name, obj in inspect.getmembers(module):
        if name.startswith('_') or hasattr(__builtin__, name):
            #print "skipping: %s" % name
            continue
        names.add(name)
    return names

class Namespace(object):
    '''Represents a pymel namespace

    A global namespace is simply one with no parent
    '''
    def __init__(self, parent):
        self.parent = parent
        self.names = set()
        self._cachedAll = None

    def parents(self):
        if self.parent is None:
            return []
        else:
            return self.parent.parents() + [self.parent]

    def globals(self, name):


        if self.parent is None:
            return self
        else:
            return self.parents()[0]

    def add(self, name):
        self.names.add(name)

    def all(self):
        names = frozenset(self.names)
        if self.parent is None:
            return names
        else:
            return self.parent.all() | names


class PymelAllRemoveVisitor(ast.NodeVisitor):
    PYMEL_MODULE_NAMES = ('pm', 'pm.nt', 'pm.ui', 'pm.dt')

    def __init__(self):
        self.pymelAllNames = []
        self.globals = Namespace(None)
        self.currentNamespace = self.globals
        self.pymelNames = self.getPymelModuleNames()

    def getPymelModuleNames(self):
        pm = getStubPymelCore()
        pymelModules = {}
        for modName in self.PYMEL_MODULE_NAMES:
            split = modName.split('.', 1)
            if len(split) > 1:
                subName = split[1]
            else:
                subName = None
            if subName:
                mod = getattr(pm, subName)
            else:
                mod = pm
            pymelModules[modName] = mod

        pymelNames = {}
        for modName, module in pymelModules.iteritems():
            pymelNames[modName] = getModuleNames(module)

        return pymelNames

    def visit(self, node):
        # There are three classes of "special" nodes we care about:
        #    nodes which define a new namespace
        #    nodes which can define a new name in the current namespace
        #    "name" nodes (which we may need to replace)

        newNamespace = None
        # new namespace nodes
        if isinstance(node, (ast.FunctionDef, ast.Lambda)):
            if isinstance(node, ast.FunctionDef):
                # if it's a function def, we need to add it's name to the OLD
                # namespace...
                self.addNames(node.name)
            newNamespace = Namespace(self.currentNamespace)
            self.currentNamespace = newNamespace

        try:
            # new name statement nodes
            if isinstance(node, (ast.Assign,
                                 ast.ClassDef,
                                 ast.FunctionDef,
                                 ast.Import,
                                 ast.ImportFrom,
                                 ast.For,
                                 ast.With,
                                 ast.TryExcept,
                                )):
                self.addNames(node)

            elif isinstance(node, ast.Name):
                if not isinstance(node.ctx, (ast.Store, ast.AugStore,
                                             ast.Param)):
                    name = node.id
                    if name not in self.currentNamespace.all():
                        for module in self.PYMEL_MODULE_NAMES:
                            names = self.pymelNames[module]
                            if name in names:
                                # We found a name that was unrecognized, but WAS in
                                # one of the pymel modules... assume it's from pymel.all
                                self.addPymelAllName(node, module)
                                break

            # recurse into child nodes...
            self.generic_visit(node)
        finally:
            if newNamespace:
                self.currentNamespace = newNamespace.parent

    def addNames(self, obj):
        #print "addNames: %r" % obj
        # string... add it!
        if isinstance(obj, basestring):
            self.currentNamespace.add(obj)

        # A name node... add if the context is right
        elif isinstance(obj, ast.Name):
            if isinstance(obj.ctx, (ast.Store, ast.AugStore, ast.Param)):
                self.addNames(obj.id)

        # An alias... check for 'foo as bar'
        elif isinstance(obj, ast.alias):
            if obj.asname:
                name = obj.asname
            else:
                name = obj.name
            if name != '*':
                self.addNames(name)

        # list/tuple.. iterate...
        elif isinstance(obj, (list, tuple)):
            for item in obj:
                self.addNames(item)
        elif isinstance(obj, (ast.Tuple, ast.List)):
            self.addNames(obj.elts)

        # Statements (or subparts)...
        elif isinstance(obj, ast.Assign):
            self.addNames(obj.targets)
        elif isinstance(obj, ast.ClassDef):
            self.addNames(obj.name)
        elif isinstance(obj, ast.FunctionDef):
            # We should have already added the function's name to the OLD
            # namespace... if we're passing in the function def, assume we're
            # INSIDE the function's namespace, and only add in it's args...
            #self.addNames(obj.name)
            self.addNames(obj.args)
        elif isinstance(obj, ast.Import):
            self.addNames(obj.names)
        elif isinstance(obj, ast.ImportFrom):
            self.addNames(obj.names)
        elif isinstance(obj, ast.For):
            self.addNames(obj.target)
        elif isinstance(obj, ast.With):
            self.addNames(obj.optional_vars)
        elif isinstance(obj, ast.TryExcept):
            self.addNames(obj.handlers)
        elif isinstance(obj, ast.ExceptHandler):
            self.addNames(obj.name)
        elif isinstance(obj, ast.arguments):
            self.addNames(obj.args)
            self.addNames(obj.vararg)
            self.addNames(obj.kwarg)

    def addPymelAllName(self, nameNode, pymelModule):
        if not isinstance(nameNode, ast.Name):
            raise TypeError
        self.pymelAllNames.append((nameNode, pymelModule))

class PymelAllRemover(object):
    # oops - pm.nt.mm is a module, pm.mel is a pymel.core.language.Mel object!
    #REPLACEMENTS = {'pm.nt.mm':'pm.mel'}
    REPLACEMENTS = {}

    def __init__(self, filepath, text=None):
        self.filepath = filepath
        if text is None:
            with open(self.filepath, _READMODE) as f:
                text = f.read()
        if not text.endswith('\n'):
            # for some reason, the parser requires the text end with a newline...
            text += '\n'
        self.text = text
        self.moduleAst = ast.parse(self.text, self.filepath)

    def newText(self):
        newText = self.text.splitlines()
        visitor = PymelAllRemoveVisitor()
        visitor.visit(self.moduleAst)

        editOffsets = {}
        for nameNode, pymelModule in visitor.pymelAllNames:
            lineIndex = nameNode.lineno - 1
            editOffset = editOffsets.get(lineIndex, 0)
            line = newText[lineIndex]
            nameStart = nameNode.col_offset + editOffset
            nameEnd = nameStart + len(nameNode.id)
            before = line[:nameStart]
            name = line[nameStart:nameEnd]
            after = line[nameEnd:]
            if name != nameNode.id:
                msg = "expected to find %r at line %d, offset %d - got %r (full line: %r)" % (
                    nameNode.id, nameNode.lineno, col, lineSubstring, line)
                raise RuntimeError(msg)
            newName = pymelModule + '.' + name
            if newName in self.REPLACEMENTS:
                newName = self.REPLACEMENTS[newName]
            newText[lineIndex] = before + newName + after
            editOffsets[lineIndex] = editOffset + (len(newName) - len(name))
        return '\n'.join(newText)

PYTHON_FILE_RE = re.compile(r'^(?!\._).*(?<!\.noPymelAll)(?<!\.withPymelAll)\.pyw?$')
FROM_PYMEL_ALL_RE = re.compile(r'^from pymel\.all import \*[ \t]*(#[^\n]*)?\n', re.MULTILINE)
PYMEL_CORE_AS_PM_RE = re.compile(r'^import pymel.core as pm[ \t]*(#[^\n]*)?\n', re.MULTILINE)
def removePymelAll(filepath, p4merge=True, replace='ask', text=None):
    print "removePymelAll: %s" % filepath

    # if we have a directory, recurse
    if os.path.isdir(filepath):
        if text is not None:
            raise ValueError("when passing in a directory to removePymelAll, text may not be specified")
        for root, dirs, files in os.walk(filepath):
            for f in files:
                if not PYTHON_FILE_RE.match(f):
                    continue
                path = os.path.join(root, f)
                try:
                    with open(path, _READMODE) as filehandle:
                        text = filehandle.read()
                except (IOError, OSError), e:
                    print '!!!!!!!!!!!!!!!!'
                    print "Error reading %s:" % path
                    print '\n'.join(traceback.format_exception_only(type(e), e))
                if FROM_PYMEL_ALL_RE.search(text):
                    try:
                        removePymelAll(os.path.join(root, f), p4merge=p4merge, replace=replace, text=text)
                    except SyntaxError, e:
                        print '!!!!!!!!!!!!!!!!'
                        print "Error parsing %s:" % path
                        print '\n'.join(traceback.format_exception_only(type(e), e))
        return

    # otherwise, act on the single file
    remover = PymelAllRemover(filepath, text=text)
    filepath = remover.filepath
    newText = remover.newText()

    if FROM_PYMEL_ALL_RE.search(newText):
        if not PYMEL_CORE_AS_PM_RE.search(newText):
            newText = FROM_PYMEL_ALL_RE.sub('import pymel.core as pm\n', newText, 1)
        newText = FROM_PYMEL_ALL_RE.sub('', newText, 1)

    base, ext = os.path.splitext(filepath)
    newPath = base + '.noPymelAll' + ext
    with open(newPath, 'w') as f:
        f.write(newText)

    if os.path.isfile(newPath):
        if p4merge:
            subprocess.check_call(['p4merge', filepath, newPath])

        if os.path.isfile(newPath):
            oldPath = base + '.withPymelAll' + ext
            if replace == 'ask':
                prompt = "Do you wish to move %s to %s?\n(Old file will be moved to %s)\n" % (newPath, filepath, oldPath)
                answer = raw_input(prompt)
                replace = answer and answer[0].lower() == 'y'
            if replace:
                if os.path.isfile(oldPath):
                    os.remove(oldPath)
                shutil.move(filepath, oldPath)
                shutil.move(newPath, filepath)

def get_parser():
    parser = argparse.ArgumentParser(description='Convert scripts with "from pymel.all import *" to "import pymel.core as pm"',
                                     epilog='USE AT YOUR OWN RISK!')
    parser.add_argument('file', help='the .py script file to convert, or '
                        'directory to recurse for python files')
    parser.add_argument('--no-p4merge', dest='p4merge', action='store_false',
                        help="don't launch p4merge after conversion")
    parser.add_argument('--replace', dest='replace', action='store_true',
                        default='ask', help="automatically replace the original"
                        " file without asking")
    parser.add_argument('--no-replace', dest='replace', action='store_false',
                        default='ask', help="don't replace the original file "
                        "(and don't ask)")
    return parser

def main(argv=None):
    if argv is None:
        argv = sys.argv[1:]
    parser = get_parser()
    args = parser.parse_args(argv)
    removePymelAll(args.file, p4merge=args.p4merge, replace=args.replace)

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = pymelScrollFieldReporter
# TODO:
# modify this so that it uses MCommandMessage.addCommandOutputFilterCallback,
# and filters messages that we will be converting to python, and then just
# write the converted message ourselves straight to sys.stdout (which has been
# set to a maya.utils.MayaOutput)
# also, set this to just use pymel's pymel.api.plugin "plugin", so no need to
# install a this file as a plugin anywhere...


"""
to create a window:

window;
    paneLayout -configuration "single";
        pymelScrollFieldReporter;
showWindow;
"""


import sys, platform
import maya.OpenMaya as OpenMaya
import maya.OpenMayaMPx as OpenMayaMPx
import maya.OpenMayaUI as OpenMayaUI
import pymel.tools.mel2py as mel2py
from maya.cmds import encodeString

mparser = mel2py.melparse.MelParser()
mparser.build()

kPluginCmdName = "pymelScrollFieldReporter"

'''
# pass to scrollField
-clear(-clr)
-text(-t)    string

# can possibly be implemented
-saveSelection(-sv)    string
-saveSelectionToShelf(-svs)
-textLength(-tl)

# difficult or impossible to implement
-selectAll(-sla)
-select(-sl)    int int
-cutSelection(-ct)
-copySelection(-cp)
-pasteSelection(-pst)
-hasFocus(-hf)
-receiveFocusCommand(-rfc)    string

'''

kClear = ('clear', 'clr')
kText = ('text', 't')
kCmdReporter = ( 'cmdReporter', 'cr')

kMel = 'mel'
kPython = 'python'

filterFlags = {
    # filters
    'convertToPython'      : ( 'ctp', OpenMaya.MSyntax.kBoolean, False),
    'filterSourceType'     : ( 'fst', OpenMaya.MSyntax.kString, ''),
    'suppressPrintouts'    : ( 'spo', OpenMaya.MSyntax.kBoolean, False),
    'suppressInfo'         : ( 'si', OpenMaya.MSyntax.kBoolean, False),
    'suppressWarnings'     : ( 'sw', OpenMaya.MSyntax.kBoolean, False),
    'suppressErrors'       : ( 'se', OpenMaya.MSyntax.kBoolean, False),
    'suppressResults'      : ( 'sr', OpenMaya.MSyntax.kBoolean, False),
    'suppressStackTrace'   : ( 'sst', OpenMaya.MSyntax.kBoolean, False)
}

globalFilterFlags = {
    # global
    'echoAllCommands'    : ( 'eac', OpenMaya.MSyntax.kBoolean, False),
    'lineNumbers'        : ( 'ln', OpenMaya.MSyntax.kBoolean, False),
     'stackTrace'        : ( 'st', OpenMaya.MSyntax.kBoolean, False)
}

filterFlagNames = ['',
                'suppressPrintouts',    #1
                'suppressInfo',         #2
                'suppressWarnings',     #3
                'suppressErrors',       #4
                'suppressResults',      #5
                'suppressStackTrace' ]  #6

messageId = 0
messageIdSet = False
sourceType = kMel # 'mel' or 'python'

allHistory = []

callbackState = 'normal'

updateCmd = ''

# For XP x64 and Vista, system() returns 'Microsoft'
if platform.system() in ('Windows', 'Microsoft'):
    updateCmd = 'string $fWin=`window -q -frontWindow blah` + "|";string $x;for ($x in `lsUI -controlLayouts -long`) {if (startsWith( $x, $fWin ) ) {break;}};scrollField -e -insertionPosition %(len)d -insertText \"%(text)s\" "%(name)s";setFocus("%(name)s");setFocus($x);'
else:
    updateCmd = 'scrollField -e -insertionPosition %(len)d -insertText \"%(text)s\" "%(name)s";'

class Reporter(object):
    cmdReporter = None

    globalFilters = {
            'echoAllCommands'    : False,
            'lineNumbers'        : False,
             'stackTrace'        : False,
    }
    def __init__(self, *args, **kwargs):
        if not args:
            self.name = kPluginCmdName
        else:
            self.name = args[0]

        # set defaults
        self.filters = {
            # filters
            'convertToPython'     : False,
            'filterSourceType'    : '',
            'suppressPrintouts'   : False,
            'suppressInfo'        : False,
            'suppressWarnings'    : False,
            'suppressErrors'      : False,
            'suppressResults'     : False,
            'suppressStackTrace'  :  False
        }

        self.filters.update( kwargs )
        self.bufferLength = 0
        global allHistory
        self.history = allHistory[:]
        cmd = 'scrollField -wordWrap false -editable false "%s"' % self.name
        self.name = self.executeCommandResult( cmd )
        self.uiMessageID = OpenMayaUI.MUiMessage.addUiDeletedCallback( self.name, uiDeletedCallback, self.name )
        self.refreshHistory()



    def executeCommandOnIdle( self, cmd ):
        global callbackState
        if Reporter.globalFilters['echoAllCommands']:
            callbackState = 'ignoreCommand'
        OpenMaya.MGlobal.executeCommandOnIdle( cmd, False )

    def executeCommand( self, cmd ):
        global callbackState
        if Reporter.globalFilters['echoAllCommands']:
            callbackState = 'ignoreCommand'
        OpenMaya.MGlobal.executeCommand( cmd, False, False )

    def executeCommandResult( self, cmd ):
        global callbackState
        if Reporter.globalFilters['echoAllCommands']:
            callbackState = 'ignoreCommand'
        result = OpenMaya.MGlobal.executeCommandStringResult( cmd, False, False )
        return result

    def lineFilter( self, messageType, sourceType, nativeMsg, convertedMsg ):
        filterSourceType = self.filters['filterSourceType']

        if (not filterSourceType or filterSourceType != sourceType) and not self.filters.get( filterFlagNames[messageType], False ):
            if self.filters['convertToPython'] and convertedMsg is not None:
                return convertedMsg
            return nativeMsg

    def refreshHistory(self):
        output = ''
        for line in self.history:
            try:
                output += self.lineFilter( *line )
            except TypeError: pass
        self.bufferLength = len(output)
        cmd = 'scrollField -e -text \"%s\" "%s";' % ( output, self.name )
        self.executeCommand( cmd )

    def appendHistory(self, line ):
        self.history.append( line )
        output = self.lineFilter( *line )

        if output is not None:
            global callbackState

            cmd = updateCmd % { 'len' : self.bufferLength, 'text' : output, 'name' : self.name }

            #cmd =  % ( self.bufferLength, output, self.name )
            #cmd = 'scrollField -e -insertionPosition %d -insertText \"%s\" "%s";setFocus("%s")' % ( self.bufferLength, output, self.name, self.name )
            self.bufferLength += len(output)

            # f the line is a syntax error, we have to use OnIdle or maya will crash
            #if line[0] == OpenMaya.MCommandMessage.kError and line[1] == kMel and 'Syntax error' in line[2] : #line[2].endswith( 'Syntax error //\n'):
            if line[1] == kMel and ( callbackState == 'syntax_error' or line[0] in [OpenMaya.MCommandMessage.kError, OpenMaya.MCommandMessage.kWarning]  ):
                self.executeCommandOnIdle( cmd )
            else:
                self.executeCommand( cmd )

            return

    def setFilters( self, **filters ):
        self.filters.update( filters )
        self.refreshHistory()

    def setGlobalFilters( self, **filters ):
        global cmdReporter

        flags = ''
        for key, value in filters.items():
            if value: value = 1
            else: value = 0
            flags += '-%s %s ' % (key, value)

        cmd = 'cmdScrollFieldReporter -e %s "%s";' % ( flags, Reporter.cmdReporter )

        self.executeCommand( cmd )

        Reporter.globalFilters.update( filters )

    def getGlobalFilter(self, filter ):
        return Reporter.globalFilters[filter]


        cmd = 'cmdScrollFieldReporter -q -%s "%s";' % ( filter, Reporter.cmdReporter )


        #result = self.executeCommandResult( cmd )
        result = OpenMaya.MGlobal.executeCommandStringResult( cmd, False, False )


        return result

    def addCmdReporter( self, cmdReporter ):
        Reporter.cmdReporter = cmdReporter

    def clear(self):
        self.history = []
        cmd = 'scrollField -e -clear "%s";' % ( self.name )
        self.executeCommand( cmd )


    def text(self, text):
        cmd = 'scrollField -e -text "%s" "%s";' % ( text, self.name )
        self.executeCommand( cmd )

class ReporterDict(dict):
    def __getitem__(self, lookupName):
        lookupBuf = lookupName.split('|')
        for key, val in self.items():
            keyBuf = key.split('|')
            if keyBuf[-1*len(lookupBuf):] == lookupBuf:
                return val
        raise KeyError #, str(lookupName)

reporters = ReporterDict({})
#reporters = {}

def removeCallback(id):
    try:
        OpenMaya.MMessage.removeCallback( id )
    except:
        sys.stderr.write( "Failed to remove callback\n" )
        raise

def createCallback(stringData):
    # global declares module level variables that will be assigned
    global messageIdSet
    global messageId

    try:
        id = OpenMaya.MCommandMessage.addCommandOutputCallback( cmdCallback, stringData )
    except:
        sys.stderr.write( "Failed to install callback\n" )
        messageIdSet = False
    else:
        messageIdSet = True
    return id

def uiDeletedCallback( name ):
    #outputFile = open( '/var/tmp/commandOutput', 'a')
    #outputFile.write( 'before=%s\n' % reporters  )
    #outputFile.close()


    removeCallback( reporters[ name ].uiMessageID )
    reporters.pop( name )

    #outputFile = open( '/var/tmp/commandOutput', 'a')
    #outputFile.write( 'after=%s\n' % reporters  )
    #outputFile.close()

def cmdCallback( nativeMsg, messageType, data ):
    global callbackState

    #outputFile = open( '/var/tmp/commandOutput', 'a')
    #outputFile.write( '============\n%s\n%s %s, length %s \n' % (nativeMsg, messageType, callbackState, len(nativeMsg))  )
    #outputFile.close()


    if callbackState == 'ignoreCommand':
        callbackState = 'ignoreResult'
        return
    elif callbackState == 'ignoreResult':
        callbackState = 'normal'
        return

    global sourceType
    global allHistory

    syntaxError = False
    convertedMsg = None

    # Command History
    if messageType == OpenMaya.MCommandMessage.kHistory:
        callbackState = 'normal'
        #if nativeMsg.rfind(';') == len(nativeMsg)-2 : # and len(nativeMsg) >= 2:
        if nativeMsg.endswith(';\n') : # and len(nativeMsg) >= 2:
            sourceType = kMel
            try:
                #convertedMsg = mel2py.mel2pyStr( nativeMsg )
                convertedMsg = mparser.parse( nativeMsg )
            except Exception, msg:
                syntaxError = True
                pass
        else:
            sourceType = kPython

    # Display - unaltered strings, such as that printed by the print command
    elif messageType == OpenMaya.MCommandMessage.kDisplay and ( nativeMsg.endswith(';\n') or nativeMsg.startswith( '//' ) ):
        try:
            #convertedMsg = mel2py.mel2pyStr( nativeMsg )
            convertedMsg = mparser.parse( nativeMsg )
        except Exception, msg:
            pass
    else:
        try:
            nativeMsg = {
                    #OpenMaya.MCommandMessage.kDisplay: 'Output',
                    OpenMaya.MCommandMessage.kInfo: '',
                    OpenMaya.MCommandMessage.kWarning: 'Warning: ',
                    OpenMaya.MCommandMessage.kError: 'Error: ',
                    OpenMaya.MCommandMessage.kResult: 'Result: '
                }[ messageType ] + nativeMsg

            if sourceType == kMel:
                convertedMsg = '# %s #\n' % nativeMsg
                nativeMsg = '// %s //\n' % nativeMsg
            else:
                nativeMsg = '# %s #\n' % nativeMsg

        except KeyError:
            pass

    nativeMsg = encodeString( nativeMsg )
    if convertedMsg is not None:
        convertedMsg = encodeString( convertedMsg )

    #outputFile = open( '/var/tmp/commandOutput', 'a')
    #outputFile.write( '---------\n%s %s\n' % ( convertedMsg, sourceType ) )
    #outputFile.close()

    line = [ messageType, sourceType, nativeMsg, convertedMsg ]

    allHistory.append( line )

    #if messageType == OpenMaya.MCommandMessage.kError : # and 'Syntax error' in nativeMsg:
    #    return

    for reporter in reporters.values():
        reporter.appendHistory( line )

    if syntaxError:
        callbackState = 'syntax_error'

    #elif callbackState == 'syntax_error' and 'Syntax error' in nativeMsg:
    #    callbackState = 'normal'

    #global output
    #output += encodeString( message )

    #cmd = 'global string $gCommandReporter;cmdScrollFieldReporter -edit -text \"%s\" $gCommandReporter;' % output
    #cmd = 'scrollField -e -text \"%s\" %s;\n' % ( output, scrollFieldName )



    #OpenMaya.MGlobal.executeCommand( cmd, False, False )

# command
class scriptedCommand(OpenMayaMPx.MPxCommand):
    def __init__(self):
        OpenMayaMPx.MPxCommand.__init__(self)



    def doIt(self, args):
        #global messageId

        try:
            argData = OpenMaya.MArgDatabase(self.syntax(), args)
        except:
            name = kPluginCmdName
            reporter = Reporter( name )
            reporters[reporter.name] = reporter
            return self.setResult( reporter.name )
        try:
            name = argData.commandArgumentString(0)
        except:
            name = kPluginCmdName


        # QUERY
        if argData.isQuery():
            reporter = reporters[name]
            for key,data in filterFlags.items():
                if argData.isFlagSet( key ):
                    self.setResult( reporter.filters[ key ] )
                    return

            for key,data in globalFilterFlags.items():
                if argData.isFlagSet( key ):
                    self.setResult( reporter.getGlobalFilter( key ) )
                    return

            if argData.isFlagSet( kCmdReporter[0] ):
                self.setResult( reporter.cmdReporter )

        else:
            filters = {}
            for key,data in filterFlags.items():
                if argData.isFlagSet( key ):
                    if data[1] == OpenMaya.MSyntax.kBoolean:
                        filters[key] = argData.flagArgumentBool( key, 0 )
                    elif data[1] == OpenMaya.MSyntax.kString:
                        filters[key] = argData.flagArgumentString( key, 0 )

            globalFilters = {}
            for key,data in globalFilterFlags.items():
                if argData.isFlagSet( key ):
                    if data[1] == OpenMaya.MSyntax.kBoolean:
                        globalFilters[key] = argData.flagArgumentBool( key, 0 )

            # EDIT
            if argData.isEdit():
                reporter = reporters[name]
                if filters:
                    reporter.setFilters( **filters )
                if globalFilters:
                    reporter.setGlobalFilters( **globalFilters )

                if argData.isFlagSet( kClear[0] ):
                    reporter.clear()
                elif argData.isFlagSet( kText[0] ):
                    reporter.text( argData.flagArgumentString( kText[0], 0 ) )
                elif argData.isFlagSet( kCmdReporter[0] ):
                    reporter.addCmdReporter( argData.flagArgumentString( kCmdReporter[0], 0 ) )
            # CREATE
            else:
                reporter = Reporter( name, **filters )
                reporters[reporter.name] = reporter

                #outputFile = open( '/var/tmp/commandOutput', 'a')
                #outputFile.write( 'create %s\n' % ( reporters ) )
                #outputFile.close()

                #reporters[name] = reporter
            self.setResult( reporter.name )



        #result = OpenMaya.MGlobal.executeCommandStringResult( cmd, False, False )
        #self.setResult( result )
        #

# Creator
def cmdCreator():
    return OpenMayaMPx.asMPxPtr( scriptedCommand() )

# Syntax creator
def syntaxCreator():
    syntax = OpenMaya.MSyntax()
    syntax.addArg(OpenMaya.MSyntax.kString)
    syntax.enableQuery(True)
    syntax.enableEdit(True)
    for flag, data in filterFlags.items():
        syntax.addFlag( data[0], flag, data[1] )

    for flag, data in globalFilterFlags.items():
        syntax.addFlag( data[0], flag, data[1] )

    syntax.addFlag( kClear[1], kClear[0] )
    syntax.addFlag( kText[1], kText[0], OpenMaya.MSyntax.kString )
    syntax.addFlag( kCmdReporter[1], kCmdReporter[0], OpenMaya.MSyntax.kString )

    return syntax

# Initialize the script plug-in
def initializePlugin(mobject):
    mplugin = OpenMayaMPx.MFnPlugin(mobject)

    if OpenMaya.MGlobal.mayaVersion() == '8.5':
        raise NotImplementedError, "pymelScrollFieldReporter is only supported in Maya 2008 and later."
    try:
        mplugin.registerCommand( kPluginCmdName, cmdCreator, syntaxCreator )

        global messageIdSet
        global messageId
        if ( messageIdSet ):
            print "Message callback already installed"
        else:
            #print "Installing callback message"
            messageId = createCallback( '' )

    except:
        sys.stderr.write( "Failed to register command: %s\n" % kPluginCmdName )
        raise

# Uninitialize the script plug-in
def uninitializePlugin(mobject):
    global messageIdSet
    global messageId
    # Remove the callback
    if ( messageIdSet ):
        removeCallback( messageId )
    # Remove the plug-in command
    mplugin = OpenMayaMPx.MFnPlugin(mobject)
    try:
        mplugin.deregisterCommand( kPluginCmdName )
    except:
        sys.stderr.write( "Failed to unregister command: %s\n" % kPluginCmdName )
        raise

########NEW FILE########
__FILENAME__ = upgradeScripts
"""
This module provides functions for upgrading scripts from pymel 0.9 to 1.0.  It
fixes two types non-compatible code:
    - pymel.all is now the main entry-point for loading all pymel modules
        - import pymel         --> import pymel.all as pymel
        - import pymel as pm   --> import pymel.all as pm
        - from pymel import *  --> from pymel.all import *
    - pymel.mayahook.versions.Version is now pymel.versions

To use, run this in a script editor tab::

    import pymel.tools.upgradeScripts
    pymel.tools.upgradeScripts.upgrade()

This will print out all the modules that will be upgraded.  If everything looks good
run the following to perform the upgrade::

    pymel.tools.upgradeScripts.upgrade(test=False)

Once you're sure that the upgrade went smoothly, run::

    pymel.tools.upgradeScripts.cleanup()

This will delete the backup files.

If you need to undo the changes, run::

    pymel.tools.upgradeScripts.undo()

Keep in mind that this will restore files to their state at the time that you ran
``upgrade``.  If you made edits to the files after running ``upgrade`` they will
be lost.
"""


import sys, os.path, re, shutil
from collections import defaultdict
import pymel.core # we don't use this, but it ensures that maya and sys.path are properly initialized

#IMPORT_RE = re.compile( '(\s*import\s+(?:[a-zA-Z0-9_.,\s]+,\s*)?)(pymel(?:[.][a-zA-Z][a-zA-Z0-9_]+)*)((?:\s*,\s*[a-zA-Z][a-zA-Z0-9_.,\s]+)?(?:\s+as\s+([a-zA-Z][a-zA-Z0-9_]+))?(?:\s*))$' )
#IMPORT_RE = re.compile( r'(\s*import\s+(?:.*))(\bpymel(?:[.][a-zA-Z][a-zA-Z0-9_]+)*)(?:\s+as\s+([a-zA-Z][a-zA-Z0-9_]+))?(.*)$' )
IMPORT_RE = re.compile( r'(?P<start>\s*import\s+.*)(?P<pymel>\bpymel(?:[.][a-zA-Z][a-zA-Z0-9_]+)*\b)(?P<end>(?:\s+as\s+(?P<details>[a-zA-Z][a-zA-Z0-9_]+))?(?:.|\s)*)$' )
FROM_RE = re.compile( r'(?P<start>\s*from\s+)(?P<pymel>pymel(?:[.][a-zA-Z][a-zA-Z0-9_]+)*)(?P<end>(?:\s+import\s+(?P<details>[*]|(?:[a-zA-Z0-9_.,\s]+)))(?:\s*))$' )
#([a-zA-Z][a-zA-Z_.]+)([a-zA-Z][a-zA-Z_.]+)

LOGNAME = 'pymel_upgrade.log'
BACKUPEXT = '.pmbak'

last_logfile = None

def _getMayaAppDir():
    if not os.environ.has_key('MAYA_APP_DIR') :
        home = os.environ.get('HOME', os.environ.get('USERPROFILE', None) )
        if not home :
            return None
        else :
            if sys.platform == 'darwin':
                return os.path.join(home, 'Library/Preferences/Autodesk/maya')
            else:
                return os.path.join(home, 'maya')
    return os.environ['MAYA_APP_DIR']

objects = [
           ( 'Version',
             re.compile('([a-zA-Z_][a-zA-Z0-9_.]+[.])?(Version[.])([a-zA-Z_][a-zA-Z0-9_]*)'),
            ('pymel',
             'pymel.version',
             'pymel.internal',
             'pymel.internal.version' ),
            'versions',
            { 'current' : 'current()',
             'v85sp1' : 'v85_SP1',
             'v2008sp1' : 'v2008_SP1',
             'v2008ext2' : 'v2008_EXT2',
             'v2009ext1' : 'v2009_EXT1',
             'v2009sp1a' : 'v2009_SP1A'
            }
            )
           ]

PREFIX = 1
OBJECT = 2
SUFFIX = 3

class LogError(ValueError):pass

def _getLogfile(logfile, read=True):
    if logfile is None:
        global last_logfile
        if last_logfile:
            logfile = last_logfile

    if logfile is None:
        baseDir = _getMayaAppDir()
        if not baseDir:
            baseDir = os.curdir
        logfile = logfile = os.path.join(baseDir, LOGNAME)
        if read and not os.path.isfile( logfile ):
            raise LogError, "could not find an existing %s. please pass the path to this file, which was generated during upgrade" % LOGNAME
    return os.path.realpath(logfile)

def upgradeFile(filepath, test=True):
    """
    upgrade a single file
    """
    try:
        f = open(filepath)
        lines = f.readlines()
        f.close()
    except Exception, e:
        print str(e)
        return False, False

    modified = False
    uses_pymel = False
    pymel_namespaces =  defaultdict(set)
    rev_pymel_namespaces =  defaultdict(set)
    for i, line in enumerate(lines):
        m = IMPORT_RE.match(line)
        mode = None
        if not m:
            m = FROM_RE.match(line)
            mode = 'from'
        else:
            mode = 'import'
        if m:
            #start, pymel_module, end, details = m.groups()
            d= m.groupdict()
            start = d['start']
            pymel_module = d['pymel']
            end = d['end']
            details = d['details']

            if pymel_module == 'pymel.all':
                print "skipping. already uses 'pymel.all':",  filepath
                return False, True

            uses_pymel = True

            if pymel_module == 'pymel':
                # import pymel, foo  -->  import pymel.all as pymel, foo
                # import pymel as pm, foo  -->  import pymel.all as pm, foo
                # from pymel import foo  -->  from pymel.all import foo
                as_name = ' as pymel' if mode == 'import' and not details else ''
                lines[i] = start + 'pymel.all' + as_name + end
                modified = True

            if details:
                details = details.strip()

            if mode == 'import':
                if details:
                    pymel_namespaces[pymel_module].add(details)     # pymel.version -> version
                    # import pymel.internal as internal
                    # 'internal' -> 'pymel.internal'
                    rev_pymel_namespaces[details].add(pymel_module)
                else:
                    # 'import pymel'
                    pymel_namespaces[pymel_module].add(pymel_module)

                    # import pymel.internal
                    # 'pymel.internal' -> 'pymel.internal'
                    rev_pymel_namespaces[pymel_module].add(pymel_module)

            elif mode == 'from':
                details = '' if details == '*' else details
                for detail in details.split(','):
                    if detail:
                        module = pymel_module + '.' + detail
                    else:
                        module = pymel_module
                    pymel_namespaces[pymel_module].add(detail)

                    # from pymel import internal
                    # 'internal' -> 'pymel.internal'

                    # from pymel import *
                    # '' -> 'pymel'
                    rev_pymel_namespaces[detail].add(module)

        if uses_pymel:
            for obj, reg, obj_namespaces, replace, attr_remap in objects:
                parts = reg.split(line)
                if len(parts) > 1:
                    #print parts
                    for j in range(0, len(parts)-1, 4):
                        try:
                            ns = parts[j+PREFIX]
                        except IndexError, err:
                            pass
                        else:
                            ns = ns if ns else ''
                            #print '\t', `ns`
                            parts[j+PREFIX] = ns
                            #print "checking namespace", `ns`, 'against', dict(rev_pymel_namespaces)
                            for namespace, orig_namespaces in rev_pymel_namespaces.iteritems():
                                if namespace == '' or ns == namespace or ns.startswith(namespace + '.'):
                                    for orig_namespace in orig_namespaces:
                                        if namespace == '':
                                            expanded_ns = orig_namespace + '.' + ns
                                        else:
                                            expanded_ns = ns.replace(namespace, orig_namespace)
                                        #print 'expanded', expanded_ns
                                        if expanded_ns.rstrip('.') in obj_namespaces:
                                            #print "found namespace", `ns`, `expanded_ns`
                                            try:
                                                pmns = list(pymel_namespaces['pymel'])[0]
                                            except IndexError:
                                                print "warning: %s: no pymel namespace was found" % filepath
                                            else:
                                                if pmns =='':
                                                    parts[j+PREFIX] = replace + '.'
                                                else:
                                                    parts[j+PREFIX] = pmns + '.' + replace + '.'
                                                parts[j+OBJECT] = None

                                            attr = parts[j+SUFFIX]
                                            parts[j+SUFFIX] = attr_remap.get(attr, attr)
                                            break
                    lines[i] = ''.join( [ x for x in parts if x is not None] )
                    #print 'before:', `line`
                    #print 'after: ', `lines[i]`


    success = True

    if modified:
        if not test:
            tmpfile = filepath + '.tmp'
            try:
                f = open(tmpfile, 'w')
                f.writelines(lines)
                f.close()
            except (IOError, OSError), err:
                print "error writing temporary file: %s: %s" % ( tmpfile, err)
                success = False

            if success:
                try:
                    os.rename(filepath, filepath + BACKUPEXT)
                except (IOError, OSError), err:
                    print "error backing up file %s to %s.pmbak: %s" % ( filepath, filepath, err)
                    success = False
                else:
                    try:
                        os.rename(tmpfile, filepath)
                    except (IOError, OSError), err:
                        print "error renaming temp file: %s" % ( err)
                        success = False
                        print "attempting to restore original file"
                        try:
                            os.rename(filepath + BACKUPEXT, filepath)
                        except OSError, err:
                            print "could not restore original: %s" % ( err)

    return modified, success

def upgrade(logdir=None, test=True, excludeFolderRegex=None, excludeFileRegex=None, verbose=False, force=False):
    """
    search PYTHONPATH (aka. sys.path) and MAYA_SCRIPT_PATH for python files using
    pymel that should be upgraded

    Keywords
    --------

    :param logdir:
        directory to which to write the log of modified files
    :param test:
        when run in test mode (default) no files are changed
    :param excludeFolderRegex:
        a regex string which should match against a directory's basename, without parent path
    :param excludeFileRegex:
        a regex string which should match against a file's basename, without parent path or extension
    :param verbose:
        print more information during conversion
    :param force:
        by default, `upgrade` will skip files which already have already been processed,
        as determined by the existence of a backup file with a .pmbak extension. setting
        force to True will ignore this precaution
    """

    if test:
        print "running in test mode. set test=False to enable file editing"

    if excludeFolderRegex:
        assert isinstance(excludeFolderRegex, basestring), "excludeFolderRegex must be a string"
    if excludeFileRegex:
        assert isinstance(excludeFileRegex, basestring), "excludeFileRegex must be a string"


    logfile = os.path.join(_getLogfile(logdir, read=False))

    try:
        log = open(logfile, 'w' )
    except (IOError, OSError), err:
        print "could not create log file at %s. please pass a writable directory to 'logdir' keyword: %s" % ( logdir, err)
        return

    global last_logfile
    last_logfile = logfile

    completed = []
    try:
        for path in sys.path + os.environ['MAYA_SCRIPT_PATH'].split(os.pathsep):
        #for path in ['/Volumes/luma/_globalSoft/dev/chad/python/pymel']:
            for root, dirs, files in os.walk(path):
                for f in files:
                    if f.endswith('.py') and not f.startswith('.'):
                        if not excludeFileRegex or not re.match( excludeFileRegex, f[:-3] ):
                            fpath = os.path.realpath(os.path.join(root,f))
                            if fpath not in completed:
                                if os.path.exists(fpath+BACKUPEXT) and not force:
                                    print "file has already been converted. skipping: %s  (use force=True to force conversion)" % fpath
                                    if not test:
                                        # keep as part of the log so that undo will work
                                        log.write( fpath + '\n' )
                                else:
                                    modified, stat = upgradeFile( fpath, test )
                                    if modified and stat:
                                        print 'needs upgrading:' if test else 'upgraded:', fpath
                                        if not test:
                                            log.write( fpath + '\n' )
                                completed.append(fpath)
                        elif verbose:
                            print "skipping", os.path.join(root,f)

                #print 'before',  root, dirs

                # dirs must be modified in-place
                i = 0
                tmpdirs = dirs[:]
                for dir in tmpdirs:
                    #print '\t', `dir`
                    if dir.startswith('.') or dir == 'pymel' \
                            or not os.path.isfile(os.path.join(root, dir, '__init__.py')) \
                            or ( excludeFolderRegex and re.match( excludeFolderRegex, dir ) ):
                        del dirs[i]
                        if verbose:
                            print "skipping", os.path.join(root, dir)
                    else:
                        i += 1
                #print 'after', root, dirs

    except Exception, err:
        import traceback
        traceback.print_exc()
    finally:
        if not test:
            print "writing log to %s" % logfile
        log.close()

    if test:
        print "test complete"
        print "to upgrade the listed files run:\nupgrade(test=False)"
    else:
        print "upgrade complete. the original files have been renamed with a %s extension\n" % BACKUPEXT
        print "to remove the backed-up original files run:\ncleanup(%r)\n" % logfile
        print "to restore the original files run:\nundo(%r)" % logfile

def undoFile(filepath):
    """
    undo a single file
    """
    backup = filepath + BACKUPEXT
    if os.path.isfile(backup):
        try:
            os.rename(backup, filepath )
            print "restored", filepath
        except (IOError, OSError), err:
            print "error restoring file %s.pmbak to %s: %s" % ( filepath, filepath, err)
            return False
    else:
        print "error restoring %s: backup file does not exist: %s. skipping" % ( filepath, backup)
    return True

def _findbackups():
    undofiles = []
    for path in sys.path + os.environ['MAYA_SCRIPT_PATH'].split(os.pathsep):
        for root, dirs, files in os.walk(path):
            #print root
            for f in files:
                if f.endswith('.py' + BACKUPEXT) and not f.startswith('.'):
                    fpath = os.path.realpath(os.path.join(root,f.rstrip(BACKUPEXT)))
                    #print "adding", fpath
                    undofiles.append(fpath)
            i = 0
            tmpdirs = dirs[:]
            for dir in tmpdirs:
                #print '\t', `dir`
                if dir.startswith('.') or dir == 'pymel' \
                        or not os.path.isfile(os.path.join(root, dir, '__init__.py')):
                    del dirs[i]
                else:
                    i += 1
    return undofiles

def _getbackups(logfile, force):
    try:
        log = open(_getLogfile(logfile), 'r' )
    except LogError, e:
        if force:
            undofiles = _findbackups()
        else:
            raise LogError, str(e) + '.\nif you lost your logfile, set force=True to search sys.path for *.pmbak files to restore instead.'
    else:
        undofiles = [ x.rstrip() for x in log.readlines() if x]
        log.close()
    return undofiles

def undo(logfile=None, force=False):
    """
    undo converted files to their original state and remove backups

    :param logfile:
        the logfile containing the list of files to restore.  if None, the logfile
        will be determined in this order:
            1. last used logfile (module must have remained loaded since running upgrade)
            2. MAYA_APP_DIR
            3. current working directory
    :param force:
        if you've lost the original logfile, setting force to True will cause the function
        to recurse sys.path looking for backup files to restore instead of using the log.
        if your sys.path is setup exactly as it was during upgrade, all files should
        be restored, but without the log it is impossible to be certain.
    """
    undofiles = _getbackups(logfile, force)

    try:
        for file in undofiles:
            undoFile(file)
        print 'done'
    except Exception, err:
        import traceback
        traceback.print_exc()



def cleanup(logfile=None, force=False):
    """
    remove backed-up files.  run this when you are certain that the upgrade went
    smoothly and you no longer need the original backups.

    :param logfile:
    the logfile containing the list of files to restore.  if None, the logfile
    will be determined in this order:
        1. last used logfile (module must have remained loaded since running upgrade)
        2. MAYA_APP_DIR
        3. current working directory
    :param force:
        if you've lost the original logfile, setting force to True will cause the function
        to recurse sys.path looking for backup files to cleanup instead of using the log.
        if your sys.path is setup exactly as it was during upgrade, all files should
        be restored, but without the log it is impossible to be certain.
    """
    undofiles = _getbackups(logfile, force)

    try:
        for file in undofiles:
            bkup = file + BACKUPEXT
            try:
                print "removing", bkup
                os.remove(bkup)
            except (IOError, OSError), err:
                print "error removing file %s: %s" % ( bkup, err)
        print 'done'
    except Exception, err:
        import traceback
        traceback.print_exc()



########NEW FILE########
__FILENAME__ = arguments
"""
Defines arguments manipulation utilities, like checking if an argument is iterable, flattening a nested arguments list, etc.
These utility functions can be used by other util modules and are imported in util's main namespace for use by other pymel modules
"""

from collections import deque as _deque
import sys, operator, itertools

from utilitytypes import ProxyUnicode

# some functions used to need to make the difference between strings and non-string iterables when PyNode where unicode derived
# doing a hasattr(obj, '__iter__') test will fail for objects that implement __getitem__, but not __iter__, so try iter(obj)
def isIterable( obj ):
    """
    Returns True if an object is iterable and not a string or ProxyUnicode type, otherwise returns False.

    :rtype: bool"""
    if isinstance(obj,basestring): return False
    elif isinstance(obj,ProxyUnicode): return False
    try:
        iter(obj)
    except TypeError: return False
    else: return True

# consider only ints and floats numeric
def isScalar(obj):
    """
    Returns True if an object is a number or complex type, otherwise returns False.

    :rtype: bool"""
    return operator.isNumberType(obj) and not isinstance(obj,complex)

# TODO : this is unneeded as operator provides it, can call directly to operator methods
def isNumeric(obj):
    """
    Returns True if an object is a number type, otherwise returns False.

    :rtype: bool
    """
    return operator.isNumberType(obj)

def isSequence( obj ):
    """
    same as `operator.isSequenceType`

    :rtype: bool"""
    return operator.isSequenceType(obj)

def isMapping( obj ):
    """
    Returns True if an object is a mapping (dictionary) type, otherwise returns False.

    same as `operator.isMappingType`

    :rtype: bool"""
    return operator.isMappingType(obj)

clsname = lambda x:type(x).__name__

def convertListArgs( args ):
    if len(args) == 1 and isIterable(args[0]):
        return tuple(args[0])
    return args


def expandArgs( *args, **kwargs ) :
    """
    'Flattens' the arguments list: recursively replaces any iterable argument in *args by a tuple of its
    elements that will be inserted at its place in the returned arguments.

    By default will return elements depth first, from root to leaves.  Set postorder or breadth to control order.

    :Keywords:
        depth : int
            will specify the nested depth limit after which iterables are returned as they are

        type
            for type='list' will only expand lists, by default type='all' expands any iterable sequence

        postorder : bool
             will return elements depth first, from leaves to roots

        breadth : bool
            will return elements breadth first, roots, then first depth level, etc.

    For a nested list represent trees::

        a____b____c
        |    |____d
        e____f
        |____g

    preorder(default) :

        >>> expandArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'], limit=1 )
        ('a', 'b', ['c', 'd'], 'e', 'f', 'g')
        >>> expandArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'] )
        ('a', 'b', 'c', 'd', 'e', 'f', 'g')

    postorder :

        >>> expandArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'], postorder=True, limit=1)
        ('b', ['c', 'd'], 'a', 'f', 'g', 'e')
        >>> expandArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'], postorder=True)
        ('c', 'd', 'b', 'a', 'f', 'g', 'e')

    breadth :

        >>> expandArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'], limit=1, breadth=True)
        ('a', 'e', 'b', ['c', 'd'], 'f', 'g')
        >>> expandArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'], breadth=True)
        ('a', 'e', 'b', 'f', 'g', 'c', 'd')


    Note that with default depth (unlimited) and order (preorder), if passed a pymel Tree
    result will be the equivalent of doing a preorder traversal : [k for k in iter(theTree)] """

    tpe = kwargs.get('type', 'all')
    limit = kwargs.get('limit', sys.getrecursionlimit())
    postorder = kwargs.get('postorder', False)
    breadth = kwargs.get('breadth', False)
    if tpe=='list' or tpe==list :
        def _expandArgsTest(arg): return type(arg)==list
    elif tpe=='all' :
        def _expandArgsTest(arg): return isIterable(arg)
    else :
        raise ValueError, "unknown expand type=%s" % str(tpe)

    if postorder :
        return postorderArgs (limit, _expandArgsTest, *args)
    elif breadth :
        return breadthArgs (limit, _expandArgsTest, *args)
    else :
        return preorderArgs (limit, _expandArgsTest, *args)

def preorderArgs (limit=sys.getrecursionlimit(), testFn=isIterable, *args) :
    """ returns a list of a preorder expansion of args """
    stack = [(x,0) for x in args]
    result = _deque()
    while stack :
        arg, level = stack.pop()
        if testFn(arg) and level<limit :
            stack += [(x,level+1) for x in arg]
        else :
            result.appendleft(arg)

    return tuple(result)

def postorderArgs (limit=sys.getrecursionlimit(), testFn=isIterable, *args) :
    """ returns a list of  a postorder expansion of args """
    if len(args) == 1:
        return (args[0],)
    else:
        deq = _deque((x,0) for x in args)
        stack = []
        result = []
        while deq :
            arg, level = deq.popleft()
            if testFn(arg) and level<limit :
                deq = _deque( [(x, level+1) for x in arg] + list(deq))
            else :
                if stack :
                    while stack and level <= stack[-1][1] :
                        result.append(stack.pop()[0])
                    stack.append((arg, level))
                else :
                    stack.append((arg, level))
        while stack :
            result.append(stack.pop()[0])

        return tuple(result)

def breadthArgs (limit=sys.getrecursionlimit(), testFn=isIterable, *args) :
    """ returns a list of a breadth first expansion of args """
    deq = _deque((x,0) for x in args)
    result = []
    while deq :
        arg, level = deq.popleft()
        if testFn(arg) and level<limit :
            for a in arg :
                deq.append ((a, level+1))
        else :
            result.append(arg)

    return tuple(result)

# Same behavior as expandListArg but implemented as an Python iterator, the recursieve approach
# will be more memory efficient, but slower
def iterateArgs( *args, **kwargs ) :
    """ Iterates through all arguments list: recursively replaces any iterable argument in *args by a tuple of its
    elements that will be inserted at its place in the returned arguments.

    By default will return elements depth first, from root to leaves.  Set postorder or breadth to control order.

    :Keywords:
        depth : int
            will specify the nested depth limit after which iterables are returned as they are

        type
            for type='list' will only expand lists, by default type='all' expands any iterable sequence

        postorder : bool
             will return elements depth first, from leaves to roots

        breadth : bool
            will return elements breadth first, roots, then first depth level, etc.

    For a nested list represent trees::

        a____b____c
        |    |____d
        e____f
        |____g

    preorder(default) :

        >>> tuple(k for k in iterateArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'], limit=1 ))
        ('a', 'b', ['c', 'd'], 'e', 'f', 'g')
        >>> tuple(k for k in iterateArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'] ))
        ('a', 'b', 'c', 'd', 'e', 'f', 'g')

    postorder :

        >>> tuple(k for k in iterateArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'], postorder=True, limit=1 ))
        ('b', ['c', 'd'], 'a', 'f', 'g', 'e')
        >>> tuple(k for k in iterateArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'], postorder=True))
        ('c', 'd', 'b', 'a', 'f', 'g', 'e')

    breadth :

        >>> tuple(k for k in iterateArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'], limit=1, breadth=True))
        ('a', 'e', 'b', ['c', 'd'], 'f', 'g')
        >>> tuple(k for k in iterateArgs( 'a', ['b', ['c', 'd']], 'e', ['f', 'g'], breadth=True))
        ('a', 'e', 'b', 'f', 'g', 'c', 'd')

    Note that with default depth (-1 for unlimited) and order (preorder), if passed a pymel Tree
    result will be the equivalent of using a preorder iterator : iter(theTree) """

    tpe = kwargs.get('type', 'all')
    limit = kwargs.get('limit', sys.getrecursionlimit())
    postorder = kwargs.get('postorder', False)
    breadth = kwargs.get('breadth', False)
    if tpe=='list' or tpe==list :
        def _iterateArgsTest(arg): return type(arg)==list
    elif tpe=='all' :
        def _iterateArgsTest(arg): return isIterable(arg)
    else :
        raise ValueError, "unknown expand type=%s" % str(tpe)

    if postorder :
        for arg in postorderIterArgs (limit, _iterateArgsTest, *args) :
            yield arg
    elif breadth :
        for arg in breadthIterArgs (limit, _iterateArgsTest, *args) :
            yield arg
    else :
        for arg in preorderIterArgs (limit, _iterateArgsTest, *args) :
            yield arg

def preorderIterArgs (limit=sys.getrecursionlimit(), testFn=isIterable, *args) :
    """ iterator doing a preorder expansion of args """
    if limit :
        for arg in args :
            if testFn(arg) :
                for a in preorderIterArgs (limit-1, testFn, *arg) :
                    yield a
            else :
                yield arg
    else :
        for arg in args :
            yield arg

def postorderIterArgs (limit=sys.getrecursionlimit(), testFn=isIterable, *args) :
    """ iterator doing a postorder expansion of args """
    if limit :
        last = None
        for arg in args :
            if testFn(arg) :
                for a in postorderIterArgs (limit-1, testFn, *arg) :
                    yield a
            else :
                if last :
                    yield last
                last = arg
        if last :
            yield last
    else :
        for arg in args :
            yield arg

def breadthIterArgs (limit=sys.getrecursionlimit(), testFn=isIterable, *args) :
    """ iterator doing a breadth first expansion of args """
    deq = _deque((x,0) for x in args)
    while deq :
        arg, level = deq.popleft()
        if testFn(arg) and level<limit :
            for a in arg :
                deq.append ((a, level+1))
        else :
            yield arg

def preorder( iterable, testFn=isIterable, limit=sys.getrecursionlimit()):
    """ iterator doing a preorder expansion of args """
    if limit :
        for arg in iterable :
            if testFn(arg) :
                for a in preorderIterArgs (limit-1, testFn, *arg) :
                    yield a
            else :
                yield arg
    else :
        for arg in iterable :
            yield arg

def postorder( iterable, testFn=isIterable, limit=sys.getrecursionlimit()):
    """ iterator doing a postorder expansion of args """
    if limit :
        last = None
        for arg in iterable :
            if testFn(arg) :
                for a in postorderIterArgs (limit-1, testFn, *arg) :
                    yield a
            else :
                if last :
                    yield last
                last = arg
        if last :
            yield last
    else :
        for arg in iterable :
            yield arg

def breadth( iterable, testFn=isIterable, limit=sys.getrecursionlimit()):
    """ iterator doing a breadth first expansion of args """
    deq = _deque((x,0) for x in iterable)
    while deq :
        arg, level = deq.popleft()
        if testFn(arg) and level<limit :
            for a in arg :
                deq.append ((a, level+1))
        else :
            yield arg

def listForNone( res ):
    "returns an empty list when the result is None"
    if res is None:
        return []
    return res

# for discussion of implementation,
# see http://mail.python.org/pipermail/python-list/2008-January/474369.html for discussion...
def pairIter(sequence):
    '''
    Returns an iterator over every 2 items of sequence.

    ie, [x for x in pairIter([1,2,3,4])] == [(1,2), (3,4)]

    If sequence has an odd number of items, the last item will not be returned in a pair.
    '''
    theIter = iter(sequence)
    return itertools.izip(theIter,theIter)

def reorder( x, indexList=[], indexDict={} ):
    """
    Reorder a list based upon a list of positional indices and/or a dictionary of fromIndex:toIndex.

        >>> l = ['zero', 'one', 'two', 'three', 'four', 'five', 'six']
        >>> reorder( l, [1, 4] ) # based on positional indices: 0-->1, 1-->4
        ['one', 'four', 'zero', 'two', 'three', 'five', 'six']
        >>> reorder( l, [1, None, 4] ) # None can be used as a place-holder
        ['one', 'zero', 'four', 'two', 'three', 'five', 'six']
        >>> reorder( l, [1, 4], {5:6} )  # remapping via dictionary: move the value at index 5 to index 6
        ['one', 'four', 'zero', 'two', 'three', 'six', 'five']
    """

    x = list(x)
    num = len(x)
    popCount = 0
    indexValDict = {}

    for i, index in enumerate(indexList):
        if index is not None:
            val = x.pop( index-popCount )
            assert index not in indexDict, indexDict
            indexValDict[i] = val
            popCount += 1
    for k, v in indexDict.items():
        indexValDict[v] = x.pop(k-popCount)
        popCount += 1

    newlist = []
    for i in range(num):
        try:
            val = indexValDict[i]
        except KeyError:
            val = x.pop(0)
        newlist.append( val )
    return newlist

class RemovedKey(object):
    def __init__(self, oldVal):
        self.oldVal = oldVal

    def __eq__(self, other):
        return self.oldVal == other.oldVal

    def __ne__(self, other):
        return self.oldVal != other.oldVal

    def __repr__(self):
        return '%s(%r)' % (type(self).__name__, self.oldVal)

class AddedKey(object):
    def __init__(self, newVal):
        self.newVal = newVal

    def __eq__(self, other):
        return self.newVal == other.newVal

    def __ne__(self, other):
        return self.newVal != other.newVal

    def __repr__(self):
        return '%s(%r)' % (type(self).__name__, self.newVal)

def compareCascadingDicts(dict1, dict2, encoding=None, useAddedKeys=False):
    '''compares two cascading dicts

    Parameters
    ----------
    dict1 : dict, list, or tuple
        the first object to compare
    dict2 : dict, list, or tuple
        the second object to compare
    encoding : `str` or None or False
        controls how comparisons are made when one value is a str, and one is a
        unicode; if None, then comparisons are simply made with == (so ascii
        characters will compare equally); if the value False, then unicode and
        str are ALWAYS considered different - ie, u'foo' and 'foo' would not be
        considered equal; otherwise, it should be the name of a unicode
        encoding, which will be applied to the unicode string before comparing
    useAddedKeys : bool
        if True, then similarly to how 'RemovedKey' objects are used in the
        returned diferences object (see the Returns section), 'AddedKey' objects
        are used for keys which exist in dict2 but not in dict1; this allows
        a user to distinguish, purely by inspecting the differences dict, which
        keys are brand new, versus merely changed; mergeCascadingDicts will
        treat AddedKey objects exactly the same as though they were their
        contents - ie, useAddedKeys should make no difference to the behavior
        of mergeCascadingDicts

    Returns
    -------
    both : `set`
        keys that were present in both (non-recursively)
        (both, only1, and only2 should be discrete partitions of all the keys
        present in both dict1 and dict2)
    only1 : `set`
        keys that were present in only1 (non-recursively)
    only2 : `set`
        keys that were present in only2 (non-recursively)
    differences : `dict`
        recursive sparse dict containing information that was 'different' in
        dict2 - either not present in dict1, or having a different value in
        dict2, or removed in dict2 (in which case an instance of 'RemovedKey'
        will be set as the value in differences)
        Values that are different, and both dictionaries, will themselves have
        sparse entries, showing only what is different
        The return value should be such that if you do if you merge the
        differences with d1, you will get d2.
    '''
    if isinstance(dict1, (list, tuple)):
        dict1 = dict(enumerate(dict1))
    if isinstance(dict2, (list, tuple)):
        dict2 = dict(enumerate(dict2))
    v1 = set(dict1)
    v2 = set(dict2)
    both = v1 & v2
    only1 = v1 - both
    only2 = v2 - both

    recurseTypes = (dict, list, tuple)
    strUnicode = set([str, unicode])
    if useAddedKeys:
        differences = dict( (key, AddedKey(dict2[key])) for key in only2)
    else:
        differences = dict( (key, dict2[key]) for key in only2)
    differences.update( (key, RemovedKey(dict1[key])) for key in only1 )

    for key in both:
        val1 = dict1[key]
        val2 = dict2[key]

        areRecurseTypes = isinstance(val1, recurseTypes) and isinstance(val2, recurseTypes)
        if areRecurseTypes:
            # we have a type that we need to recurse into, and either they
            # compare not equal, or encoding is False (in which case they
            # may compare python-equal, but could have some str-unicode
            # equalities, so we need to verify for ourselves):
            if encoding is False or val1 != val2:
                subDiffs = compareCascadingDicts(val1, val2, encoding=encoding,
                                                 useAddedKeys=useAddedKeys)[-1]
                if subDiffs:
                    differences[key] = subDiffs
        else:
            # ok, we're not doing a recursive comparison...
            isStrUnicode = (set([type(val1), type(val2)]) == strUnicode)
            if isStrUnicode:
                # we have a string and a unicode - decide what to do based on
                # encoding setting
                if encoding is False:
                    equal = False
                elif encoding is None:
                    equal = (val1 == val2)
                else:
                    if type(val1) == unicode:
                        strVal = val2
                        unicodeVal = val1
                    else:
                        strVal = val1
                        unicodeVal = val2
                    try:
                        encoded = unicodeVal.encode(encoding)
                    except UnicodeEncodeError:
                        # if there's an encoding error, consider them different
                        equal = False
                    else:
                        equal = (encoded == strVal)
            else:
                equal = (val1 == val2)

            if not equal:
                differences[key] = val2

    return both, only1, only2, differences

def mergeCascadingDicts( from_dict, to_dict, allowDictToListMerging=False,
                         allowNewListMembers=False ):
    """
    recursively update to_dict with values from from_dict.

    if any entries in 'from_dict' are instances of the class RemovedKey,
    then the key containing that value will be removed from to_dict

    if allowDictToListMerging is True, then if to_dict contains a list,
    from_dict can contain a dictionary with int keys which can be used to
    sparsely update the list.

    if allowNewListMembers is True, and allowDictToListMerging is also True,
    then if merging an index into a list that currently isn't long enough to
    contain that index, then the list will be extended to be long enough (with
    None inserted in any intermediate indices)

    Note: if using RemovedKey objects and allowDictToList merging, then only
    indices greater than all of any indices updated / added should be removed,
    because the order in which items are updated / removed is indeterminate.
    """
    listMerge = allowDictToListMerging and isinstance(to_dict, list )
    if listMerge:
        contains = lambda key: isinstance(key,int) and 0 <= key < len(to_dict)
    else:
        contains = lambda key: key in to_dict

    for key, from_val in from_dict.iteritems():
        #print key, from_val
        if contains(key):
            if isinstance(from_val, RemovedKey):
                del to_dict[key]
                continue
            to_val = to_dict[key]
            #if isMapping(from_val) and ( isMapping(to_val) or (allowDictToListMerging and isinstance(to_val, list )) ):
            if hasattr(from_val, 'iteritems') and ( hasattr(to_val, 'iteritems')
                                                    or (allowDictToListMerging and isinstance(to_val, list )) ):
                mergeCascadingDicts( from_val, to_val, allowDictToListMerging )
            else:
                to_dict[key] = from_val
        else:
            if isinstance(from_val, RemovedKey):
                continue
            if listMerge and allowNewListMembers and key >= len(to_dict):
                to_dict.extend( (None,) * (key + 1 - len(to_dict)) )
            to_dict[key] = from_val

def setCascadingDictItem( dict, keys, value ):

    currentDict = dict
    for key in keys[:-1]:
        if key not in currentDict:
            currentDict[key] = {}
        currentDict = currentDict[key]
    currentDict[keys[-1]] = value

def getCascadingDictItem( dict, keys, default={} ):

    currentDict = dict
    for key in keys[:-1]:
        if isMapping(currentDict) and key not in currentDict:
            currentDict[key] = {}
        currentDict = currentDict[key]
    try:
        return currentDict[keys[-1]]
    except KeyError:
        return default

def sequenceToSlices( intList, sort=True ):
    """convert a sequence of integers into a tuple of slice objects"""
    slices = []

    if intList:
        if sort:
            intList = sorted(intList)
        start = intList[0]
        stop = None
        step = None
        lastStep = None
        lastVal = start
        for curr in intList[1:]:
            curr = int(curr)
            thisStep = curr - lastVal
            #assert thisStep > 0, "cannot have duplicate values. pass a set to be safe"

#            print
#            print "%s -> %s" % (lastVal, curr)
#            print "thisStep", thisStep
#            print "lastStep", lastStep
#            print "step", step
#            print "lastVal", lastVal
#            print (start, stop, step)
#            print slices

            if lastStep is None:
                # we're here bc the last iteration was the beginning of a new slice
                pass
            elif thisStep > 0 and thisStep == lastStep:
                # we found 2 in a row, they are the beginning of a new slice
                # setting step indicates we've found a pattern
                #print "found a pattern on", thisStep
                step = thisStep
            else:
                if step is not None:
                    # since step is set we know a pattern has been found (at least two in a row with same step)
                    # we also know that the current value is not part of this pattern, so end the old slice at the last value
                    if step == 1:
                        newslice = slice(start, lastVal+1, None)
                    else:
                        newslice = slice(start, lastVal+1, step)
                    thisStep = None
                    start = curr
                else:
                    if lastStep == 1:
                        newslice = slice(start, lastVal+1, lastStep )
                        thisStep = None
                        start = curr
                    else:
                        newslice = slice(start, stop+1 )
                        start = lastVal

#                print "adding", newslice
                slices.append( newslice )
                # start the new

                stop = None
                step = None


            lastStep = thisStep


            stop = lastVal
            lastVal = curr

        if step is not None:
            # end the old slice
            if step == 1:
                newslice = slice(start, lastVal+1, None)
            else:
                newslice = slice(start, lastVal+1, step)

            #print "adding", newslice
            slices.append( newslice )
        else:

            if lastStep == 1:
                slices.append( slice(start, lastVal+1, lastStep ) )

            else:
                slices.append( slice(start, start+1 ) )
                if lastStep is not None:
                    slices.append( slice(lastVal, lastVal+1 ) )

    return slices

def izip_longest(*args, **kwds):
    # izip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-
    fillvalue = kwds.get('fillvalue')
    def sentinel(counter = ([fillvalue]*(len(args)-1)).pop):
        yield counter()         # yields the fillvalue, or raises IndexError
    fillers = itertools.repeat(fillvalue)
    iters = [itertools.chain(it, sentinel(), fillers) for it in args]
    try:
        for tup in itertools.izip(*iters):
            yield tup
    except IndexError:
        pass

########NEW FILE########
__FILENAME__ = arrays
"""
A generic n-dimensionnal Array class serving as base for arbitrary length VectorN and MatrixN classes
"""

# NOTE: modified and added some methods that are closer to how Numpy works, as some people pointed out
# they didn't want non-Python dependencies.
# For instance implemented partially the neat multi index slicing, __getitem__ and __setitem__ as well
# as and item indexing for iterators,
# Tried to make the method names match so that it will be easier to include Numpy instead if desired.
# See http://www.numpy.org/

# TODO : try a numpy import and fallback to the included class if not successful ?

# TODO : trim does preserve sub-element identity, should trimmed do a copy or deepcopy (currently deepcopy)?
# resize / reshape should be checked and set to same behavior as well

import operator, itertools, copy, inspect, sys

from arguments import isNumeric, clsname
from utilitytypes import readonly, metaReadOnlyAttr
from math import pi, exp
import math, mathutils, sys
# 1.0/sys.maxint on 64-bit systems is too precise for maya to manage...
eps = 1.0/(2**30)
from __builtin__ import sum as _sum, min as _min, max as _max, abs as _abs
# 2.5 only for any and all
try :
    from __builtin__ import all as _all, any as _any
except :
    def _all(iterable):
        """ Return True if all elements of the iterable are true """
        for element in iterable:
            if not element:
                return False
        return True
    def _any(iterable):
        """ Return True if any element of the iterable is true """
        for element in iterable:
            if element:
                return True
        return False

_thisModule = sys.modules[__name__]

# internal utilities

def _toCompOrArray(value) :
    if hasattr(value, '__iter__') :
        if type(value) is not Array :
            value = Array(value)
    elif isNumeric(value) :
        # a single numeric value
        pass
    else :
        raise TypeError, "invalid value type %s cannot be converted to Array" % (clsname(value))
    return value

def _toCompOrArrayInstance(value, cls=None) :
    if cls == None :
        cls = Array
    if hasattr(value, '__iter__') :
        if not isinstance(value, cls) :
            value = cls(value)
    elif isNumeric(value) :
        # a single numeric value
        pass
    else :
        raise TypeError, "invalid value type %s cannot be converted to %s" % (clsname(value), cls.__name__)
    return value

def _shapeInfo(value) :
    shape, ndim, size = None, None, None
    if isinstance(value, Array) :
        shape = value.shape
        ndim = value.ndim
        size = value.size
    elif hasattr(value, '__iter__') :
        value = Array(value)
        shape = value.shape
        ndim = value.ndim
        size = value.size
    elif isNumeric(value) :
        shape = ()
        ndim = 0
        size = 1

    if shape is None :
        raise TypeError, "can only query shape information on Array or Array component (numeric), not %s" % (clsname(value))

    return shape, ndim, size


# override math and mathutils functions to make them accept iterables and operate element-wise on iterables

def _patchfn(basefn) :
    """ Overload the given base function to have it accept iterables """
    def fn(*args, **kwargs) :
        maxarg = Array([])
        maxsize = 0
        maxtype = None
        if args :
            method_name = '__'+basefn.__name__+'__'
            if hasattr(args[0], method_name) :
                return args[0].__getattribute__(method_name)(*args[1:], **kwargs)
            else :
                args = list(args)
                ln = len(args)
                for i in xrange(ln) :
                    if hasattr(args[i], '__iter__') :
                        t = type(args[i])
                        args[i] = Array(args[i])
                        s = args[i].size
                        if s >= maxsize :
                            # for equal sizes give preferences to Array subtypes for conversion
                            if issubclass(t, Array) or s > maxsize :
                                maxarg = args[i]
                                maxsize = maxarg.size
                                maxtype = t
                if maxsize > 0 :
                    try :
                        for i in xrange(ln) :
                            maxarg, args[i] = coerce(maxarg, args[i])
                    except :
                        return NotImplemented
                    allargs = zip(*args)
                    la = len(allargs)
                    # same for keyword arguments if applicable
                    for k in kwargs :
                        ka = kwargs[k]
                        try :
                            maxarg, ka = coerce(maxarg, ka)
                            # ka = Array(ka)
                        except :
                            ka = (ka,)*la
                        # if isinstance (ka, Array) :
                        #    maxarg, ka = coerce(maxarg, ka)
                        kwargs[k] = ka
                    allkw = [dict([(k, kwargs[k][i]) for k in kwargs])  for i in range(la)]
                    res = _toCompOrArray(fn(*a, **allkw[i]) for i, a in enumerate(allargs))
                    if hasattr(res, '__iter__') :
                        try :
                            res = maxtype(res)
                        except :
                            if isinstance(maxtype, Array) :
                                res = maxtype._convert(res)
                    return res

        return basefn(*args, **kwargs)

    fn.__name__ = basefn.__name__
    if basefn.__doc__ is None :
        basedoc = "No doc string was found on base function"
    else :
        basedoc = basefn.__doc__
    fn.__doc__ = basedoc + "\nThis function has been overriden from %s.%s to work element-wise on iterables" % (basefn.__module__, basefn.__name__)
    return fn

def patchMath() :
    """ Overload various math functions to work element-wise on iterables

        >>> A = Array([[0, pi/4.0], [pi/2.0, 3.0*pi/4.0], [pi, 5.0*pi/4.0], [3.0*pi/2.0, 7.0*pi/4.0]])
        >>> print round(A,2).formated()
        [[0.0, 0.79],
         [1.57, 2.36],
         [3.14, 3.93],
         [4.71, 5.5]]
        >>> print degrees(A).formated()
        [[0.0, 45.0],
         [90.0, 135.0],
         [180.0, 225.0],
         [270.0, 315.0]]
        >>> print round(sin(A), 2).formated()
        [[0.0, 0.71],
         [1.0, 0.71],
         [0.0, -0.71],
         [-1.0, -0.71]]
    """
    mathfn = inspect.getmembers(math, inspect.isbuiltin)
    for mfn in mathfn :
        fname = mfn[0]
        basefn = mfn[1]
        newfn = _patchfn(basefn)
        _thisModule.__setattr__(fname, newfn)

    mathutilsfn = inspect.getmembers(mathutils, inspect.isfunction)
    for mfn in mathutilsfn :
        fname = mfn[0]
        basefn = mfn[1]
        newfn = _patchfn(basefn)
        _thisModule.__setattr__(fname, newfn)

    # builtins that do not need to be manually redefined, curently only abs
    _thisModule.__setattr__('abs', _patchfn(_abs))

patchMath()

# some other overriden math or builtin functions operating on Arrays or derived classes
# NOTE : it's not very consistent that min and max accept a variable number of arguments and
# sum, prod, any, all don't? But it's the way it is with the builtins

def sum(a, start=0, axis=None):
    """ sum(a[, start=0[, axis=(axis0, axis1, ...)]]) --> numeric or Array

        Returns the sum of all the components of a, an iterable of values that support the add operator, plus start.
        If a is an Array and axis are specified will return an Array of sum(x) for x in a.axisiter(*axis)

        >>> A = Array([[1,2,3],[4,5,6]])
        >>> print A.formated()
        [[1, 2, 3],
         [4, 5, 6]]
        >>> sum(A)
        21
        >>> sum(A, axis=(0, 1))
        21
        >>> sum(A, axis=0)
        Array([5, 7, 9])
        >>> sum(A, axis=1)
        Array([6, 15])
    """
    if isinstance(a, Array) :
        axis = a._getaxis(axis, fill=True)
        return reduce(operator.add, a.axisiter(*axis), start)
    elif hasattr(a, '__iter__') :
        return _sum(a, start)
    else :
        return a+start

def prod(a, start=1, axis=None):
    """ prod(a[, start=1[, axis=(axis0, axis1, ...)]]) --> numeric or Array

        Returns the product of all the components of a, an iterable of values that support the mul operator, times start.
        If axis are specified will return an Array of prod(x) for x in a.axisiter(*axis).

        >>> A = Array([[1,2,3],[4,5,6]])
        >>> print A.formated()
        [[1, 2, 3],
         [4, 5, 6]]
        >>> prod(A)
        720
        >>> prod(A, axis=(0, 1))
        720
        >>> prod(A, axis=0)
        Array([4, 10, 18])
        >>> prod(A, axis=1)
        Array([6, 120])
    """
    if isinstance(a, Array) :
        axis = a._getaxis(axis, fill=True)
        return reduce(operator.mul, a.axisiter(*axis), start)
    elif hasattr(a, '__iter__') :
        return reduce(operator.mul, a, start)
    else :
        return a*start

def any(a, axis=None):
    """ any(a [,axis=(axis0, axis1, ...)]) --> bool or Array of booleans

        Returns True if any of the components of iterable a evaluate to True.
        If axis are specified will return an Array of any(x) for x in a.axisiter(*axis).

        >>> A = Array([[False,True,True],[False,True,False]])
        >>> print A.formated()
        [[False, True, True],
         [False, True, False]]
        >>> any(A)
        True
        >>> any(A, axis=(0, 1))
        True
        >>> any(A, axis=0)
        Array([False, True, True])
        >>> any(A, axis=1)
        Array([True, True])
    """
    if isinstance(a, Array) :
        axis = a._getaxis(axis, fill=True)
        it = a.axisiter(*axis)
        subshape = it.itemshape
        if subshape == () :
            return _any(it)
        else :
            return Array(map(_any, zip(*it)), shape=subshape)
    elif hasattr(a, '__iter__') :
        return _any(a)
    else :
        return bool(a)

def all(a, axis=None):
    """ all(a, [,axis=(axis0, axis1, ...)]) --> bool or Array of booleans

        Returns True if all the components of iterable a evaluate to True.
        If axis are specified will return an Array of all(x) for x in a.axisiter(*axis).

        >>> A = Array([[True,True,True],[False,True,False]])
        >>> print A.formated()
        [[True, True, True],
         [False, True, False]]
        >>> all(A)
        False
        >>> all(A, axis=(0, 1))
        False
        >>> all(A, axis=0)
        Array([False, True, False])
        >>> all(A, axis=1)
        Array([True, False])
    """
    if isinstance(a, Array) :
        axis = a._getaxis(axis, fill=True)
        it = a.axisiter(*axis)
        subshape = it.itemshape
        if subshape == () :
            return _all(it)
        else :
            return Array(map(_all, zip(*it)), shape=subshape)
    elif hasattr(a, '__iter__') :
        return _all(a)
    else :
        return bool(a)

def min(*args, **kwargs):
    """ min(iterable[, key=func[, axis=(axis0, axis1, ...)]]) --> value
        min(a, b, c, ...[, key=func[, axis=(axis0, axis1, ...)]]) --> value

        With a single iterable argument, return its smallest item.
        With two or more arguments, return the smallest argument.
        If the iterable argument is an Array instance, returns the smallest component of iterable.
        If axis are specified will return an Array of element-wise min(x) for x in a.axisiter(*axis).

        >>> A = Array([[6,3,4],[1,5,0.5]])
        >>> print A.formated()
        [[6, 3, 4],
         [1, 5, 0.5]]
        >>> min(A)
        0.5
        >>> min(A, axis=(0,1))
        0.5
        >>> min(A, axis=0)
        Array([1, 3, 0.5])
        >>> min(A, axis=1)
        Array([3, 0.5])
    """
    axis=kwargs.get('axis', None)
    key=kwargs.get('key', None)
    opt = {}
    if key is not None :
        opt['key'] = key
    if len(args) == 1 :
        a = args[0]
    else :
        a = args
    if isinstance(a, Array) :
        axis = a._getaxis(axis, fill=True)
        it = a.axisiter(*axis)
        subshape = it.itemshape
        if subshape == () :
            return _min(it, **opt)
        else :
            return Array(map(lambda x:_min(x, **opt), zip(*it)), shape=subshape)
    elif hasattr(a, '__iter__') :
        return _min(a, **opt)
    else :
        return a

def max(*args, **kwargs):
    """ max(iterable[, key=func[, axis=(axis0, axis1, ...)]]) --> value
        max(a, b, c, ...[, key=func[, axis=(axis0, axis1, ...)]]) --> value

        With a single iterable argument, return its largest item.
        With two or more arguments, return the largest argument.
        If the iterable argument is an Array instance, returns the largest component of iterable.
        If axis are specified will return an Array of element-wise max(x) for x in a.axisiter(*axis).

        >>> A = Array([[6,3,4],[1,5,0.5]])
        >>> print A.formated()
        [[6, 3, 4],
         [1, 5, 0.5]]
        >>> max(A)
        6
        >>> max(A, axis=(0, 1))
        6
        >>> max(A, axis=0)
        Array([6, 5, 4])
        >>> max(A, axis=1)
        Array([6, 5])
    """
    axis=kwargs.get('axis', None)
    key=kwargs.get('key', None)
    opt = {}
    if key is not None :
        opt['key'] = key
    if len(args) == 1 :
        a = args[0]
    else :
        a = args
    if isinstance(a, Array) :
        axis = a._getaxis(axis, fill=True)
        it = a.axisiter(*axis)
        subshape = it.itemshape
        if subshape == () :
            return _max(it, **opt)
        else :
            return Array(map(lambda x:_max(x, **opt), zip(*it)), shape=subshape)
    elif hasattr(a, '__iter__') :
        return _max(a, **opt)
    else :
        return a

# Array specific functions that also exist as methods on the Array classes

def sqlength(a, axis=None):
    """ sqlength(a[, axis=(axis0, axis1, ...)]) --> numeric or Array

        Returns square length of a, ie a*a or the sum of x*x for x in a if a is an iterable of numeric values.
        If a is an Array and axis are specified will return a list of sqlength(x) for x in a.axisiter(*axis).

        >>> A = Array([[0.5,0.5,-0.707],[0.707,-0.707,0.0]])
        >>> print A.formated()
        [[0.5, 0.5, -0.707],
         [0.707, -0.707, 0.0]]
        >>> sqlength(A)
        1.999547
        >>> sqlength(A, axis=(0,1))
        1.999547
        >>> sqlength(A, axis=0)
        Array([0.999849, 0.999698])
        >>> sqlength(A, axis=1)
        Array([0.749849, 0.749849, 0.499849])
    """
    a = VectorN._convert(a)
    if isinstance(a, VectorN) :
        # axis not used but this catches invalid axis errors
        # only valid axis for VectorN is (0,)
        if axis is not None :
            try :
                axis = a._getaxis(axis, fill=True)
            except :
                raise ValueError, "axis 0 is the only valid axis for a VectorN, %s invalid" % (axis)
        return a.sqlength()
    elif isinstance(a, Array) :
        axis = a._getaxis(axis, fill=True)
        return a.sqlength(*axis)
    else :
        raise TypeError, "sqlength not implemented for %s" % (clsname(a))

def length(a, axis=None):
    """ length(a[, axis=(axis0, axis1, ...)]) --> numeric or Array

        Returns length of a, sqrt(a*a) or the square root of the sum of x*x for x in a if a is an iterable of numeric values.
        If a is an Array and axis are specified will return a list of length(x) for x in a.axisiter(*axis).

        >>> A = Array([[0.5,0.5,-0.707],[0.707,-0.707,0.0]])
        >>> print A.formated()
        [[0.5, 0.5, -0.707],
         [0.707, -0.707, 0.0]]
        >>> round(length(A), 7)
        1.4140534
        >>> round(length(A, axis=(0,1)), 7)
        1.4140534
        >>> length(A, axis=0)
        Array([0.99992449715, 0.999848988598])
        >>> length(A, axis=1)
        Array([0.865938219505, 0.865938219505, 0.707])
    """
    return sqrt(sqlength(a, axis))

def normal(a, axis=None):
    """ normal(a[, axis=(axis0, axis1, ...)]) --> Array

        Returns a normalized copy of self: self/length(self, axis).

        >>> A = Array([[0.5,0.5,-0.707],[0.707,-0.707,0.0]])
        >>> print A.formated()
        [[0.5, 0.5, -0.707],
         [0.707, -0.707, 0.0]]
        >>> print normal(A).formated()
        [[0.353593437318, 0.353593437318, -0.499981120367],
         [0.499981120367, -0.499981120367, 0.0]]
        >>> print normal(A, axis=(0,1)).formated()
        [[0.353593437318, 0.353593437318, -0.499981120367],
         [0.499981120367, -0.499981120367, 0.0]]
        >>> print normal(A, axis=0).formated()
        [[0.5, 0.5, -0.707],
         [0.707, -0.707, 0.0]]
        >>> print normal(A, axis=1).formated()
        [[0.577408397894, 0.577408397894, -1.0],
         [0.816455474623, -0.816455474623, 0.0]]
    """
    a = VectorN._convert(a)
    if isinstance(a, VectorN) :
        # axis not used but this catches invalid axis errors
        # only valid axis for VectorN is (0,)
        if axis is not None :
            try :
                axis = a._getaxis(axis, fill=True)
            except :
                raise ValueError, "axis 0 is the only valid axis for a VectorN, %s invalid" % (axis)
        return a.normal()
    elif isinstance(a, Array) :
        axis = a._getaxis(axis, fill=True)
        return a.normal(*axis)
    else :
        raise TypeError, "normal not implemented for %s" % (clsname(a))

def dist(a, b, axis=None):
    """ dist(a, b[, axis=(axis0, axis1, ...)]) --> float or Array

        Returns the distance between a and b, ie length(b-a, axis)

        >>> A = Array([[0.5, 0.5, -0.707],[0.707, -0.707, 0.0]])
        >>> print A.formated()
        [[0.5, 0.5, -0.707],
         [0.707, -0.707, 0.0]]
        >>> B = Array([[0.51, 0.49, -0.71],[0.71, -0.70, 0.0]])
        >>> print B.formated()
        [[0.51, 0.49, -0.71],
         [0.71, -0.7, 0.0]]
        >>> length(B-A)
        0.016340134638368205
        >>> dist(A, B)
        0.016340134638368205
        >>> dist(A, B, axis=(0, 1))
        0.016340134638368205
        >>> dist(A, B, axis=0)
        Array([0.0144568322948, 0.00761577310586])
        >>> dist(A, B, axis=1)
        Array([0.0104403065089, 0.0122065556157, 0.003])
    """
    a = VectorN._convert(a)
    if isinstance(a, VectorN) :
        # axis not used but this catches invalid axis errors
        # only valid axis for VectorN is (0,)
        if axis is not None :
            try :
                axis = a._getaxis(axis, fill=True)
            except :
                raise ValueError, "axis 0 is the only valid axis for a MVector, %s invalid" % (axis)
        return a.dist()
    elif isinstance(a, Array) :
        axis = a._getaxis(axis, fill=True)
        return a.dist(b, *axis)
    else :
        raise TypeError, "dist not implemented for %s" % (clsname(a))

# iterator classes on a specific Array axis, supporting __getitem__ and __setitem__
# in a numpy like way

class ArrayIter(object):
    """ A general purpose iterator on Arrays.

        ArrayIter allows to iterate on one or more specified axis of an Array, in any order.

        For an Array of n dimensions, iterator on p axis will yield sub-arrays of n-p dimensions,
        numerical components if n-p is 0.

        >>> A = Array(range(1, 28), shape=(3, 3, 3))
        >>> print A.formated()
        [[[1, 2, 3],
          [4, 5, 6],
          [7, 8, 9]],
        <BLANKLINE>
         [[10, 11, 12],
          [13, 14, 15],
          [16, 17, 18]],
        <BLANKLINE>
         [[19, 20, 21],
          [22, 23, 24],
          [25, 26, 27]]]
        >>> [a for a in A]
        [Array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), Array([[10, 11, 12], [13, 14, 15], [16, 17, 18]]), Array([[19, 20, 21], [22, 23, 24], [25, 26, 27]])]
        >>> [a for a in ArrayIter(A, 0)]
        [Array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), Array([[10, 11, 12], [13, 14, 15], [16, 17, 18]]), Array([[19, 20, 21], [22, 23, 24], [25, 26, 27]])]
        >>> [a for a in ArrayIter(A, 1)]
        [Array([[1, 2, 3], [10, 11, 12], [19, 20, 21]]), Array([[4, 5, 6], [13, 14, 15], [22, 23, 24]]), Array([[7, 8, 9], [16, 17, 18], [25, 26, 27]])]
        >>> [a for a in ArrayIter(A, 2)]
        [Array([[1, 4, 7], [10, 13, 16], [19, 22, 25]]), Array([[2, 5, 8], [11, 14, 17], [20, 23, 26]]), Array([[3, 6, 9], [12, 15, 18], [21, 24, 27]])]
        >>> [a for a in ArrayIter(A, 0, 1)]
        [Array([1, 2, 3]), Array([4, 5, 6]), Array([7, 8, 9]), Array([10, 11, 12]), Array([13, 14, 15]), Array([16, 17, 18]), Array([19, 20, 21]), Array([22, 23, 24]), Array([25, 26, 27])]
        >>> [a for a in ArrayIter(A, 0, 2)]
        [Array([1, 4, 7]), Array([2, 5, 8]), Array([3, 6, 9]), Array([10, 13, 16]), Array([11, 14, 17]), Array([12, 15, 18]), Array([19, 22, 25]), Array([20, 23, 26]), Array([21, 24, 27])]
        >>> [a for a in ArrayIter(A, 0, 1, 2)]
        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]
        >>> [a for a in ArrayIter(A, 0, 2, 1)]
        [1, 4, 7, 2, 5, 8, 3, 6, 9, 10, 13, 16, 11, 14, 17, 12, 15, 18, 19, 22, 25, 20, 23, 26, 21, 24, 27]

        ArrayIter iterators support __len__, __getitem__,  __setitem__ and __delitem__ methods, it can be used
        to set whole sub-arrays in any order (for instance rows or columns in MatrixN)

        >>> A = Array(range(1, 10), shape=(3, 3))
        >>> print A.formated()
        [[1, 2, 3],
         [4, 5, 6],
         [7, 8, 9]]
        >>> [a for a in ArrayIter(A, 0, 1)]
        [1, 2, 3, 4, 5, 6, 7, 8, 9]
        >>> len(ArrayIter(A, 0, 1))
        9
        >>> ArrayIter(A, 0, 1)[5:9] = [4, 3, 2, 1]
        >>> print A.formated()
        [[1, 2, 3],
         [4, 5, 4],
         [3, 2, 1]]
        >>> [a for a in ArrayIter(A, 1)]
        [Array([1, 4, 3]), Array([2, 5, 2]), Array([3, 4, 1])]
        >>> len(ArrayIter(A, 1))
        3
        >>> ArrayIter(A, 1)[1] = [7, 8, 9]
        >>> print A.formated()
        [[1, 7, 3],
         [4, 8, 4],
         [3, 9, 1]]
        >>> ArrayIter(A, 0)[1] = 0
        >>> print A.formated()
        [[1, 7, 3],
         [0, 0, 0],
         [3, 9, 1]]
    """
    def __init__(self, data, *args) :
        """ it.__init__(a[, axis1[, axis2[, ...]]])

            Inits this Array iterator on Array a, using the specified list of axis, see ArrayIter help.
        """
        if len(args) == 1 and hasattr(args[0], '__iter__') :
            args = tuple(args[0])
        if isinstance(data, Array) :
            if args :
                axis = [int(x) for x in args]
            else :
                axis = [0]
            ndim = len(axis)
            size = 1
            coords = [slice(None)]*data.ndim
            shape = []
            for x in axis :
                if x < 0 or x >= data.ndim :
                    raise ValueError, "%s has %s dimensions, cannot iterate on axis %s" % (clsname(data), data.ndim, x)
                elif axis.count(x) > 1 :
                    raise ValueError, "axis %s is present more than once in ArrayIter axis list %s" % (x, axis)
                else :
                    coords[x] = 0
                    size *= data.shape[x]
                    shape.append(data.shape[x])
            itemshape = []
            for x in xrange(data.ndim) :
                if not x in axis :
                    itemshape.append(data.shape[x])

            self.base = data
            self.ndim = ndim
            self.size = size
            self.coords = coords
            self.axis = tuple(axis)
            self.shape = tuple(shape)
            self.itemshape = tuple(itemshape)
            self.itemdim = len(itemshape)
            self.itemsize = reduce(operator.mul, itemshape, 1)
            self.subsizes = [reduce(operator.mul, shape[i+1:], 1) for i in xrange(ndim)]
            #print "Base shape %s, Axis %s, Iter shape %s, iter dim %s, iter size %s, item shape %s, item dim %s, subsizes %s"\
            #         % (self.base.shape, self.axis, self.shape, self.ndim, self.size, self.itemshape, self.itemdim, self.subsizes)
        else :
            raise TypeError, "%s can only be built on Array" % clsname(self)
    def __length_hint__(self) :
        return self.size
    def __len__(self) :
        return self.size
    def __iter__(self) :
        return self

    def next(self):
        """ it.next() -> the next value, or raise StopIteration """
        for i in range(len(self.axis)-1, 0, -1) :
            if self.coords[self.axis[i]] == self.shape[i] :
                self.coords[self.axis[i]] = 0
                self.coords[self.axis[i-1]] += 1
        if self.coords[self.axis[0]] >= self.shape[0] :
            raise StopIteration

        val =  self.base.__getitem__(tuple(self.coords))
        self.coords[self.axis[-1]] += 1
        return val

    # fast internal version without checks or negative index / slice support
    def _toArrayCoords(self, item, subindex, default):
        owncoords = []
        for s in self.subsizes :
            c = item//s
            item -= c*s
            owncoords.append(c)
        coords = [default]*self.base.ndim
        # set coordinates that are defined by iterator
        for i,c in enumerate(owncoords) :
            coords[self.axis[i]] = c
        # fill in other coordinates (coords on iterated items)
        ls = len(subindex)
        s = 0
        for i,c in enumerate(coords) :
            if s >= ls :
                break
            if c == default :
                coords[i] = subindex[s]
                s += 1

        # remove useless trailing default coords, leaving a minimum of one coord
        while len(coords) > 1 and coords[-1] == default :
            del coords[-1]
        return tuple(coords)

    def toArrayCoords(self, index, default=None):
        """ it.toArrayCoords(index, default=None) --> list or tuple

            Converts an iterator item index (item of number index in the iterator) for that Array iterator to a tuple of axis coordinates for that Array,
            returns a single coordinates tuple or a list of coordinate tuples if index was a slice.
            If index is a multi-index (a tuple), the first element if index is checked against the iterator and the remaining elements are considered
            indices on the iterated sub-array (s).

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> [a for a in ArrayIter(A, 0, 1)]
            [1, 2, 3, 4, 5, 6, 7, 8, 9]
            >>> it = ArrayIter(A, 0, 1)
            >>> it[4]
            5
            >>> it.toArrayCoords(4)
            (1, 1)
            >>> A[1, 1]
            5
            >>> it[1:4]
            Array([2, 3, 4])
            >>> it.toArrayCoords(slice(1, 4))
            [(0, 1), (0, 2), (1, 0)]

            >>> [a for a in ArrayIter(A, 1)]
            [Array([1, 4, 7]), Array([2, 5, 8]), Array([3, 6, 9])]
            >>> it = ArrayIter(A, 1)
            >>> it[0]
            Array([1, 4, 7])
            >>> it.toArrayCoords(0)
            (None, 0)
            >>> it.toArrayCoords(0, default=slice(None))
            (slice(None, None, None), 0)
            >>> A[:, 0]
            Array([1, 4, 7])
            >>> it.toArrayCoords((0, 1))
            (1, 0)
            >>> it[0, 1]
            4
            >>> A[1, 0]
            4
        """
        if hasattr(index, '__iter__') :
            index = tuple(index)
        else :
            index = (index,)
        item = index[0]
        subindex = index[1:]
        # check validity of subindex if any
        if self.itemshape :
            subindex = self.base.__class__._checkindex(index=subindex, shape=self.itemshape, default=default)

        if isinstance(item, slice) :
            return [self._toArrayCoords(f, subindex, default) for f in range(self.size)[item]]
        else :
            item = int(item)
            if item < 0 :
                item = self.size + item
            if item>=0 and item<self.size :
                return self._toArrayCoords(item, subindex, default)
            else :
                raise IndexError, "item number %s for iterator of %s items is out of bounds" % (item, self.size)

    def __getitem__(self, index) :
        """ it.__getitem__(index) <==> it[index]

            Returns a single sub-Array or component corresponding to the iterator item designated by index, or an Array of values if index is a slice.

            Note : if it is an ArrayIter built on Array a, it's equivalent to a[c] for c in it.toArrayCoords(index)

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> [a for a in ArrayIter(A, 0, 1)]
            [1, 2, 3, 4, 5, 6, 7, 8, 9]
            >>> ArrayIter(A, 0, 1)[4]
            5
            >>> ArrayIter(A, 0, 1)[0:6]
            Array([1, 2, 3, 4, 5, 6])
            >>> [a for a in ArrayIter(A, 1)]
            [Array([1, 4, 7]), Array([2, 5, 8]), Array([3, 6, 9])]
            >>> ArrayIter(A, 1)[1]
            Array([2, 5, 8])
            >>> ArrayIter(A, 1)[1, 0]
            2
            >>> print ArrayIter(A, 1)[0:2, 0:2].formated()
            [[1, 4],
             [2, 5]]
            >>> print A.transpose()[0:2, 0:2].formated()
            [[1, 4],
             [2, 5]]
        """
        coords = self.toArrayCoords(index, default=slice(None))
        if type(coords) is list :
            return self.base.__class__._convert(self.base.__getitem__(c) for c in coords)
            # return Array(self.base.__getitem__(c) for c in coords)
        else :
            return self.base.__getitem__(coords)

    def __delitem__(self, index):
        """ it.__delitem__(index) <==> del it[index]

            Note : if it is an ArrayIter built on Array a, it's equivalent to del a[c] for c in it.toArrayCoords(index)

            Warning : Do not use __delitem__ during iteration

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> [a for a in ArrayIter(A, 0, 1)]
            [1, 2, 3, 4, 5, 6, 7, 8, 9]
            >>> del ArrayIter(A, 0, 1)[1]
            >>> [a for a in ArrayIter(A, 0, 1)]
            [4, 6, 7, 9]
            >>> print A.formated()
            [[4, 6],
             [7, 9]]
            >>> [a for a in ArrayIter(A, 1)]
            [Array([4, 7]), Array([6, 9])]
            >>> del ArrayIter(A, 1)[-1]
            >>> print A.formated()
            [[4],
             [7]]
        """
        coords = self.toArrayCoords(index, default=None)
        if type(coords) is list :
            for c in coords :
                self.base.__delitem__(c)
        else :
            self.base.__delitem__(coords)
        # update iterator
        self.__init__(self.base, *self.axis)

    def __setitem__(self, index, value) :
        """ it.__setitem__(index, value) <==> it[index] = value

            Returns a single sub-Array or component corresponding to the iterator item item, or an Array of values if index is a slice.

            Note : if it is an ArrayIter built on Array a, it's equivalent to a[c]=value for c in it.toArrayCoords(index) or
            a[c] = value[i] for i, c in enumerate(it.toArrayCoords(index)) if an iterable of values of suitable shapes was provided.

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> [a for a in ArrayIter(A, 0, 1)]
            [1, 2, 3, 4, 5, 6, 7, 8, 9]
            >>> ArrayIter(A, 0, 1)[4] = 10
            >>> [a for a in ArrayIter(A, 0, 1)]
            [1, 2, 3, 4, 10, 6, 7, 8, 9]
            >>> print A.formated()
            [[1, 2, 3],
             [4, 10, 6],
             [7, 8, 9]]
            >>> ArrayIter(A, 0, 1)[0:3] = 1
            >>> [a for a in ArrayIter(A, 0, 1)]
            [1, 1, 1, 4, 10, 6, 7, 8, 9]
            >>> print A.formated()
            [[1, 1, 1],
             [4, 10, 6],
             [7, 8, 9]]
            >>> ArrayIter(A, 0, 1)[5:9] = [4, 3, 2, 1]
            >>> [a for a in ArrayIter(A, 0, 1)]
            [1, 1, 1, 4, 10, 4, 3, 2, 1]
            >>> print A.formated()
            [[1, 1, 1],
             [4, 10, 4],
             [3, 2, 1]]
            >>> [a for a in ArrayIter(A, 1)]
            [Array([1, 4, 3]), Array([1, 10, 2]), Array([1, 4, 1])]
            >>> ArrayIter(A, 1)[1]
            Array([1, 10, 2])
            >>> ArrayIter(A, 1)[1, 1] = 5
            >>> print A.formated()
            [[1, 1, 1],
             [4, 5, 4],
             [3, 2, 1]]
            >>> ArrayIter(A, 1)[-1] = [7, 8, 9]
            >>> print A.formated()
            [[1, 1, 7],
             [4, 5, 8],
             [3, 2, 9]]
            >>> ArrayIter(A, 0)[1] = 0
            >>> print A.formated()
            [[1, 1, 7],
             [0, 0, 0],
             [3, 2, 9]]
        """
        coords = self.toArrayCoords(index, default=slice(None))

        # print "expected item shape: %s" % list(self.itemshape)
        value = _toCompOrArray(value)
        valueshape, valuedim, valuesize = _shapeInfo(value)

        if type(coords) is list :
            if valuedim <= self.itemdim :
                for c in coords :
                    self.base.__setitem__(c, value)
            elif hasattr(value, '__iter__') and valueshape[1:] == self.itemshape :
                lv = len(value)
                lc = len(coords)
                for i in xrange(lc) :
                    # repeat values if number of values < number of coords
                    self.base.__setitem__(coords[i], value[i%lv])
            else :
                raise ValueError, "value must be a single item (Array or component) of shape matching the iterated items shape, or an iterable of items, each of shape matching the iterated items shape"
        else :
            if valuedim <= self.itemdim :
                self.base.__setitem__(coords, value)
            else :
                raise ValueError, "iterated items shape and value shape do not match"



# A generic multi dimensional Array class
# NOTE : Numpy Array class could be used instead, just implemented the bare minimum inspired from it
class Array(object):
    """ A generic n-dimensional array class using nested lists for storage.

        Arrays can be built from numeric values, iterables, nested lists or other Array instances

        >>> Array()
        Array([])
        >>> Array(2)
        Array([2])
        >>> A = Array([[1, 2], [3, 4]])
        >>> print A.formated()
        [[1, 2],
         [3, 4]]
        >>> A = Array([1, 2], [3, 4])
        >>> print A.formated()
        [[1, 2],
         [3, 4]]
        >>> A = Array([[1, 2]])
        >>> print A.formated()
        [[1, 2]]
        >>> A = Array([1], [2], [3])
        >>> print A.formated()
        [[1],
         [2],
         [3]]
        >>> A = Array([[[1], [2], [3]]])
        >>> print A.formated()
        [[[1],
          [2],
          [3]]]

        You can query some Array characteristics with the properties shape, ndim (number of dimensions) and size,
        the total number of numeric components

        >>> A = Array(range(1, 10), shape=(3, 3))
        >>> print A.formated()
        [[1, 2, 3],
         [4, 5, 6],
         [7, 8, 9]]
        >>> A.shape
        (3, 3)
        >>> A.ndim
        2
        >>> A.size
        9

        Arrays are stored as nested lists and derive from the 'list' class.

        >>> A.data
        [Array([1, 2, 3]), Array([4, 5, 6]), Array([7, 8, 9])]
        >>> list(A)
        [Array([1, 2, 3]), Array([4, 5, 6]), Array([7, 8, 9])]

        Initialization from another Array does a shallow copy, not a deepcopy,
        unless the Array argument is resized / reshaped.

        >>> B = Array(A)
        >>> print B.formated()
        [[1, 2, 3],
         [4, 5, 6],
         [7, 8, 9]]
        >>> B == A
        True
        >>> B is A
        False
        >>> B[0] is A[0]
        True
        >>> C = Array([A])
        >>> print C.formated()
        [[[1, 2, 3],
          [4, 5, 6],
          [7, 8, 9]]]
        >>> C[0] is A
        True
        >>> C[0,0] is A[0]
        True

        You can pass optional shape information at creation with the keyword arguments
        shape, ndim and size. The provided data will be expanded to fit the desirable shape,
        either repeating it if it's a valid sub-array of the requested shape, or padding it with
        the Array default value (0 unless defined otherwise in an Array sub-class).

        Value will be repeated if it is a valid sub-array of the Array requested

        >>> A = Array(1, shape=(2, 2))
        >>> print A.formated()
        [[1, 1],
         [1, 1]]

        It will be padded otherwise, with the Array class default value

        >>> A = Array(1, 2, shape=(4,))
        >>> print A.formated()
        [1, 2, 0, 0]

        Or a combination of both, first pad it to a valid sub-array then repeat it

        >>> A = Array(1, 2, shape=(3, 3))
        >>> print A.formated()
        [[1, 2, 0],
         [1, 2, 0],
         [1, 2, 0]]

        Repeat can occur in any dimension

        >>> A = Array([1, 2, 3], shape=(3, 3))
        >>> print A.formated()
        [[1, 2, 3],
         [1, 2, 3],
         [1, 2, 3]]

        TODO :
        #>>> A = Array([[1], [2], [3]], shape=(3, 3))
        #>>> print A.formated()
        #[[1, 1, 1],
        # [2, 2, 2],
        # [3, 3, 3]]

        To avoid repetition, you can use a nested list of the desired number of dimensions

        >>> A = Array([1,2,3], shape=(3, 3))
        >>> print A.formated()
        [[1, 2, 3],
         [1, 2, 3],
         [1, 2, 3]]
        >>> A = Array([[1,2,3]], shape=(3, 3))
        >>> print A.formated()
        [[1, 2, 3],
         [0, 0, 0],
         [0, 0, 0]]

        If sub-array and requested array have same number of dimensions, padding with row / columns
        will be used (useful for the MatrixN sub-class or Array)

        >>> A = Array(range(1, 10), shape=(3, 3))
        >>> print A.formated()
        [[1, 2, 3],
         [4, 5, 6],
         [7, 8, 9]]
        >>> B = Array(A, shape=(4, 4))
        >>> print B.formated()
        [[1, 2, 3, 0],
         [4, 5, 6, 0],
         [7, 8, 9, 0],
         [0, 0, 0, 0]]

        Initialization will not allow to truncate data, if you provide more arguments than the
        requested array shape can fit, it will raise an exception.
        Use an explicit trim / resize or item indexing if you want to extract a sub-array

        >>> A = Array([1, 2, 3, 4, 5], shape=(2, 2))
        Traceback (most recent call last):
            ...
        TypeError: cannot initialize a Array of shape (2, 2) from [1, 2, 3, 4, 5] of shape (5,),
        as it would truncate data or reduce the number of dimensions
     """

    __metaclass__ = metaReadOnlyAttr
    __slots__ = ['_data', '_shape', '_ndim', '_size']
    __readonly__ = ('apicls', 'data', 'shape', 'ndim', 'size')
    # internal storage type, is expected to have __iter__, __len__,__getitem__, __setitem__, __delitem__ methods
    apicls = list

    # cache shape and size to save time
    def _cacheshape(self):
        shape = []
        sub = self.data
        while sub is not None :
            try :
                shape.append(len(sub))
                sub = sub[0]
            except :
                sub = None
        self._shape = tuple(shape)
        self._ndim = len(shape)
        self._size = reduce(operator.mul, shape, 1)
    def _getshape(self):
        return self._shape
    def _setshape(self, newshape):
        self.resize(newshape)

    # shape, ndim, size and data properties
    shape = property(_getshape, _setshape, None,
                     """ a.shape : tuple

                         Shape of the Array (number of dimensions and number of components in each dimension).

                         It can be queried, or set to change the Array's shape similarly to the reshape method.

                         >>> A = Array(range(1, 17), shape=(4, 4))
                         >>> print A.formated()
                         [[1, 2, 3, 4],
                          [5, 6, 7, 8],
                          [9, 10, 11, 12],
                          [13, 14, 15, 16]]
                         >>> S = A[0]
                         >>> A.shape=(2, 2, 4)
                         >>> print A.formated()
                         [[[1, 2, 3, 4],
                           [5, 6, 7, 8]],
                         <BLANKLINE>
                          [[9, 10, 11, 12],
                           [13, 14, 15, 16]]]
                         >>> A.shape=(4, 4)
                         >>> print A.formated()
                         [[1, 2, 3, 4],
                          [5, 6, 7, 8],
                          [9, 10, 11, 12],
                          [13, 14, 15, 16]]

                         Related : see Array.reshape method.
                     """)
    ndim = property(lambda x : x._ndim, None, None, "Number of dimensions of the Array")
    size = property(lambda x : x._size, None, None, "Total size of the Array (number of individual components)")

    # When wrapping a class we can't or don't want to subclass, store it in _data
    # and only access it through the standard data property (as derived classes or base
    # classes of this class might directly subclass the class they wrap and not have a _data attribute)
    # no check is done on the validity of data
    def _getdata(self):
        return self._data
    def _setdata(self, value):
        if isinstance(value, self.apicls) :
            self._data = value
        else :
            self._data = self.apicls(value)
        self._cacheshape()
    def _deldata(self):
        del self._data[:]
        self._cacheshape()
    data = property(_getdata, _setdata, _deldata, "The nested list storage for the Array data")

    # for compatibility with herited api types like MVector and MMatrix
    def assign(self, value):
        """ a.assign(b) --> Array

            Assigns the value of b to a, equivalent to using the data property : a.data = b.
            Besides changing a's value, it also returns the new a to conform to Maya's api assign.

            Note: assign acts as a shallow copy

            >>> A = Array(range(1, 5), shape=(2, 2))
            >>> B = Array()
            >>> B.assign(A)
            Array([[1, 2], [3, 4]])
            >>> print B.formated()
            [[1, 2],
             [3, 4]]
            >>> B == A
            True
            >>> B is A
            False
            >>> B[0] is A[0]
            True
        """
        if type(value) == type(self) :
            self.data = value.data
        else :
            self.data = self.__class__(value).data
        return self
    def get(self):
        """ a.get() --> Tuple

            Returns a's internally stored value as a nested tuple, a raw dump of the stored numeric components.

            >>> A = Array(range(1, 5), shape=(2, 2))
            >>> print A.get()
            ((1, 2), (3, 4))
        """
        res = []
        for a in self :
            if isinstance(a, Array) :
                res.append(a.get())
            else :
                res.append(a)
        return tuple(res)

    @classmethod
    def _shapecheck(cls, shape):
        """ A check for fixed ndim / shape classes """
        try :
            shape, ndim, size = cls._defaultshape(shape, None, None)
            return True
        except :
            return False

    @classmethod
    def _defaultshape(cls, shape=None, ndim=None, size=None):
        """ Checks provided shape and size vs class shape, dim and size,
            returns provided shape, dim and size if valid or
            class's default shape, dim, size tuple if they exist and none are provided """
        # check if class has fixed shape or dimensions
        cls_shape = cls_ndim = cls_size = None
        try :
            cls_shape = tuple(cls.shape)
            cls_ndim = len(cls_shape)
            cls_size = reduce(operator.mul, cls_shape, 1)
        except :
            try :
                cls_ndim = int(cls.ndim)
            except :
                pass
            try :
                cls_size = int(cls.size)
            except :
                pass

        if shape is not None :
            if not hasattr(shape, '__iter__') :
                newshape = (shape,)
            else :
                newshape = tuple(shape)
        else :
            if cls_shape is not None :
                newshape = cls_shape
            elif cls_ndim is not None :
                newshape = (-1,)*cls_ndim
            else :
                newshape = ()
        shapesize = shapedim = None
        if newshape :
            shapedim = len(newshape)
            if newshape and not list(newshape).count(-1) :
                shapesize = reduce(operator.mul, newshape, 1)

        if ndim is not None :
            newndim = ndim
        else :
            newndim = cls_ndim

        if newndim is not None :
            if not shapedim :
                newshape = newshape + (-1,)*newndim
            shapedim = len(newshape)
        else :
            newndim = shapedim

        if size is not None :
            newsize = size
        else :
            if shapesize is not None :
                newsize = shapesize
            else :
                newsize = cls_size

        # check for conformity with class constants
        if cls_size is not None and newsize != cls_size :
            raise TypeError, "class %s has a fixed size %s and it cannot be changed" % (cls.__name__, cls_size)
        if cls_ndim is not None and newndim != cls_ndim :
            raise TypeError, "class %s has a fixed number of dimensions %s and it cannot be changed" % (cls.__name__, cls_ndim)
#            if newdim < cls_ndim :
#                newshape = tuple([1]*(cls_ndim-newdim) + newshape)
#                newdim = cls_ndim
#            else :
#                raise TypeError, "class %s has a fixed number of dimensions %s and it cannot be changed" % (cls.__name__, cls_ndim)
        if cls_shape is not None and newshape != cls_shape :
            raise TypeError, "class %s has a fixed shape %s and it cannot be changed" % (cls.__name__, cls_shape)

        # check for coherence
        if newndim != shapedim :
            raise ValueError, "provided number of dimensions %s is incompatible with shape %s" % (newndim, newshape)
        if shapesize is not None and newsize != shapesize :
            raise ValueError, "provided size %s is incompatible with shape %s" % (newsize, newshape)

        return newshape, newndim, newsize

    @classmethod
    def _expandshape(cls, shape=None, ndim=None, size=None, reference=None):
        """ Expands shape that contains at most one undefined number of components for one dimension (-1) using known size """

        # check shape vs class attributes
        shape, ndim, size = cls._defaultshape(shape, ndim, size)

        # default to ndim = 1 if none specified and not a class constant
        # ndim = 0 would mean a single numeric value and we don't convert them to Arrays
        if not shape :
            if not ndim :
                ndim = 1
            shape = (-1,)*ndim
        if not ndim :
            ndim = len(shape)
        newshape = list(shape)
        nb = newshape.count(-1)
        if size is None :
            if nb > 0 :
                raise ValueError, "cannot expand shape %s without an indication of size" % (shape,)
            else :
                size = reduce(operator.mul, shape, 1)

        # expands unknown dimension sizes (-1) if size is known
        if nb > 0 :
            if nb > 1 :
                # ambiguous specification, more than one unknown dimension, means multiple ways to conform to size
                # unless size is 0
                if size == 0 :
                    newshape = [0]*ndim
                    newsize = 0
                else :
                    raise ValueError, "can only specify one unknown dimension on shape %s to try and fit it to size %s" % (shape, size)
            else :
                newsize = 1
                for i, dim in enumerate(newshape) :
                    idim = int(dim)
                    if idim == -1 :
                        unknown = i
                        break
                    else :
                        newsize *= idim
                if newsize :
                    newshape[unknown] = size / newsize
                else :
                    newshape[unknown] = 0
                newsize = reduce(operator.mul, newshape, 1)
            if newsize != size :
                raise ValueError, "unable to match the required size %s with shape %s" % (size, shape)
            shape = tuple(newshape)

        if not cls._shapecheck(shape) :
            raise TypeError, "shape %s is incompatible with class %s" % (shape, cls.__name__)

        return shape, ndim, size

    @classmethod
    def _checkindex(cls, index=None, shape=None, **kwargs):
        """ Check and expand index on Array of given shape,

            >>> A = Array(1, shape=(3, 3, 3))
            >>> print A.formated()
            [[[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]],
            <BLANKLINE>
             [[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]],
            <BLANKLINE>
             [[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]]]
            >>> Array._checkindex((slice(2,8),-1), shape=(3, 3, 3), default=slice(None))
            (slice(2, 3, 1), 2, slice(0, 3, 1))
            >>> Array._checkindex((slice(2,8),-1), shape=(3, 3, 3), default=slice(None), expand=True)
            ([2], [2], [0, 1, 2])
        """
        # shape, ndim, size = cls._expandshape(shape=shape)
        ndim = len(shape)
        default = kwargs.get('default',None)
        expand = kwargs.get('expand',False)
        if index is None:
            index = []
        elif hasattr(index, '__iter__') :
            if len(index) == 1 and hasattr(index[0], '__iter__') :
                index = list(index[0])
            else :
                index = list(index)
        else :
            index = [index]

        if index :
            assert len(index)<=ndim, "Array of shape %s has %s dimensions, cannot specify %s indices" % (shape, ndim, l)
            if default is not None :
                index = index + [default]*(ndim-len(index))
            for i in xrange(len(index)) :
                ind = index[i]
                if ind is None :
                    ind = default
                if ind is None :
                    if expand :
                        ind = []
                elif isinstance(ind, slice) :
                    if expand :
                        ind = range(shape[i])[ind]
                    else :
                        ind = slice(*ind.indices(shape[i]))
                else :
                    ind = int(ind)
                    if ind<0 :
                        ind = shape[i]+ind
                    if ind<0 or ind>= shape[i] :
                        raise ValueError, "Array of shape %s has %s components on axis %s, index %s from %s is out of bounds" % (shape, shape[i], i, ind, index)
                    if expand :
                        ind = [ind]
                index[i] = ind

        return tuple(index)

    def _getindex(self, index=None, **kwargs):
        """ Check and expand index on given Array,

            >>> A = Array(1, shape=(3, 3, 3))
            >>> print A.formated()
            [[[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]],
            <BLANKLINE>
             [[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]],
            <BLANKLINE>
             [[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]]]
            >>> A._getindex((slice(2,8),-1), default=slice(None))
            (slice(2, 3, 1), 2, slice(0, 3, 1))
            >>> A._getindex((slice(2,8),-1), default=slice(None), expand=True)
            ([2], [2], [0, 1, 2])
        """
        return self.__class__._checkindex(index=index, shape=self.shape, **kwargs)

    @classmethod
    def _checkaxis(cls, axis=None, shape=None, **kwargs):
        """ Check and expand a tuple of axis on Array,

            >>> A = Array(1, shape=(3, 3, 3))
            >>> print A.formated()
            [[[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]],
            <BLANKLINE>
             [[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]],
            <BLANKLINE>
             [[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]]]
            >>> Array._checkaxis(axis=(1,), shape=(3, 3, 3))
            (1,)
            >>> Array._checkaxis(shape=(3, 3, 3), fill=True)
            (0, 1, 2)
            >>> Array._checkaxis(shape=(3, 3, 3), fill=True, reverse=True)
            (2, 1, 0)
            >>> Array._checkaxis(axis=(1, 3), shape=(3, 3, 3))
            Traceback (most recent call last):
                ...
            ValueError: axis 3 in axis list (1, 3) doesn't exist for an Array of shape (3, 3, 3)
            >>> Array._checkaxis(axis=(1, 1, 2), shape=(3, 3, 3))
            Traceback (most recent call last):
                ...
            ValueError: axis 1 is present more than once in axis list (1, 1, 2)

        """
        shape, ndim, size = cls._expandshape(shape=shape)
        fill = kwargs.get('fill',False)
        reverse = kwargs.get('reverse',False)
        if axis is None :
            axis = []
        if not hasattr(axis, '__iter__') :
            axis = [axis]

        if len(axis) == 0 :
            if fill :
                if reverse :
                    axis = range(ndim-1, -1, -1)
                else :
                    axis = range(0, ndim, 1)
        else :
            try :
                if len(axis) == 1 and hasattr(axis[0], '__iter__') :
                    axis = [range(ndim)[x] for x in axis[0]]
                else :
                    axis = [range(ndim)[x] for x in axis]
            except IndexError :
                raise ValueError, "axis %s in axis list %s doesn't exist for an Array of shape %s" % (x, tuple(axis), shape)
            for x in axis :
                if axis.count(x) > 1 :
                    raise ValueError, "axis %s is present more than once in axis list %s" % (x, tuple(axis))

        return tuple(axis)


    def _getaxis(self, axis=None, **kwargs):
        """ Check and expand a tuple of axis on Array,

            >>> A = Array(1, shape=(3, 3, 3))
            >>> print A.formated()
            [[[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]],
            <BLANKLINE>
             [[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]],
            <BLANKLINE>
             [[1, 1, 1],
              [1, 1, 1],
              [1, 1, 1]]]
            >>> A._getaxis(axis=(1,))
            (1,)
            >>> A._getaxis(fill=True)
            (0, 1, 2)
            >>> A._getaxis(fill=True, reverse=True)
            (2, 1, 0)
            >>> A._getaxis(axis=(1, 3))
            Traceback (most recent call last):
                ...
            ValueError: axis 3 in axis list (1, 3) doesn't exist for an Array of shape (3, 3, 3)
            >>> A._getaxis(axis=(1, 1, 2))
            Traceback (most recent call last):
                ...
            ValueError: axis 1 is present more than once in axis list (1, 1, 2)

        """
        return self.__class__._checkaxis(axis=axis, shape=self.shape, **kwargs)

    # convert to class or closest base class
    @classmethod
    def _convert(cls, value, preserveShape=True):
        if preserveShape :
            try :
                array = Array(value)
                shape = array.shape
            except :
                raise TypeError, "%s cannot be converted to Array or any Array sub-class" % (clsname(value))
        else :
            shape = None
        for c in inspect.getmro(cls) :
            if issubclass(c, Array) :
                if isinstance(value, c) :
                    # return value directly so we don't add a shallow copy if type is already ok
                    return value
                else :
                    try :
                        # use array as if value was a generator, it would not be able to iterate again
                        return c(array, shape=shape)
                    except :
                        pass
        raise TypeError, "%s cannot be converted to %s" % (clsname(value), cls.__name__)

    @classmethod
    def _toCompOrConvert(cls, value):
        if isinstance(value, cls) :
            return value
        elif hasattr(value, '__iter__') :
            return cls._convert(value, preserveShape=True)
        elif isNumeric(value) :
            # a single numeric value
            return value
        else :
            raise TypeError, "invalid value type %s cannot be converted to %s or Array" % (clsname(value), cls.__name__)

    def __new__(cls, *args, **kwargs ):
        """ cls.__new__(...) --> cls

            Creates a new Array instance without calling __init__, the created instance will be of the
            class cls (an Array subclass) default shape (if any) and set to the class default value.
            See Array, MatrixN or VectorN help for more information.
        """
        shape = kwargs.get('shape', None)
        ndim = kwargs.get('ndim', None)
        size = kwargs.get('size', None)

        cls_size = getattr(cls, 'size', None)
        # for new default size to 0 if not specified or class constant
        if size is None and not shape and (not cls_size or
                                           inspect.ismethod(cls_size) or
                                           inspect.isdatadescriptor(cls_size)):
            size = 0


        shape, ndim, size = cls._expandshape(shape, ndim, size)

        # default value is set here (0 or [] for Arrays)
        defval = 0

        new = super(Array, Array).__new__(Array)
        if shape :
            new.data = [defval]*shape[-1]
        else :
            new.data = []
        for d in reversed(shape[:-1]) :
            next = super(Array, Array).__new__(Array)
            if d :
                # warning doing this means all sub-arrays would actually be the same object
                # next.data = [new]*d
                next.data = [copy.deepcopy(new) for i in range(d)]
            else :
                next.data = [new]
            new = next

        result = super(Array, cls).__new__(cls)
        result.data = new.data
        return result

    def __init__(self, *args, **kwargs):
        """ a.__init__(...)

            Initializes Array a from one or more iterable, nested lists or numeric values,
            See Array, MatrixN or VectorN help for more information.

            Note : __init__ from another Array acts as a shallow copy, not a deepcopy, unless
            the Array argument is resized or reshaped.
        """

        if args :
            cls = self.__class__

            data = None
            # decided not to support Arrays made of a single numeric as opposed to Numpy as it's just confusing
            if len(args) == 1 :
                args = args[0]
            # shortcut for Array subtypes
            if type(args) in (Array, MatrixN, VectorN) :
                # copy constructor
                data = super(Array, Array).__new__(Array)
                data.data = args
            elif hasattr(args, '__iter__') :
                # special cases to accommodate some herited Maya api classes
                # here classes that can convert to MMatrix and classes that don't expose
                # all components of their api base (MPoint)
                #if hasattr(args, 'asMatrix') :
                #    args = args.asMatrix()
                if isinstance(args, Array) and (args.size != len(args)) :
                    args = list(args.data)
                largs = []
                subshapes = []
                for arg in args :
                    # sub is either also an Array or a single numeric value
                    sub = _toCompOrArray(arg)
                    subshape, subdim, subsize = _shapeInfo(sub)
                    largs.append(sub)
                    subshapes.append(subshape)
                if not reduce(lambda x, y : x and y == subshapes[0], subshapes, True) :
                    raise ValueError, "all sub-arrays must have same shape"
                data = super(Array, Array).__new__(Array)
                data.data = largs
            elif isNumeric(args) :
                # allow initialize from a single numeric value
                data = args
            else :
                raise TypeError, "an %s element can only be another Array, an iterable of numerics or a numeric value" % (cls.__name__)

            if data is not None :
                # can re-shape on creation if self if of a specific diferent shape
                dshape, dndim, dsize = _shapeInfo(data)
                shape, ndim, size = _shapeInfo(self)
                if not size :
                    # if self was initialized by __new__ with a zero size, then if will adapt to the argument size,
                    # if class restrictions allow
                    shape, ndim, size = cls._defaultshape(None, None, None)
                if not size :
                    size = dsize
                if not shape :
                    if dshape :
                        # data is an Array
                        shape = dshape
                    else :
                        # data is single numeric
                        shape = (1,)
                if not ndim :
                    ndim = len(shape)

                if shape != dshape :
                    # accept expanding but not shrinking to catch casting errors
                    # will initialize self to at least an empty Array or an array of one numeric value,

                    # multiple -1 (MatrixN init for instance)
                    shape = list(shape)
                    unknown = shape.count(-1)
                    # multiple unknown dimensions can't be expanded with the size info, we'll use the new shape instead
                    if unknown > 1 :
                        difdim = max(ndim-dndim, 0)
                        # replace extra unknown dimensions with 1 from first dimensions
                        for i in range(difdim) :
                            if unknown > 1 :
                                if shape[i] == -1 :
                                    shape[i] = 1
                                    unknown -= 1
                            else :
                                break
                        # then for the last unkown dimensions, consider them common to the target class and data, copy data's
                        for i in range(difdim, ndim) :
                            if unknown > 1 :
                                if shape[i] == -1 :
                                    shape[i] = dshape[i+difdim]
                                    unknown -= 1
                            else :
                                break
                    shape = tuple(shape)

                    shape, ndim, size = cls._expandshape(shape, ndim, size)
                    # reshape / resize / retrim if needed
                    if shape != dshape :
                        if not dshape :
                            # data = Array.filled(data, shape)
                            data = cls(shape=shape).filled(data)
                        else :
                            if size >= dsize and ndim >= dndim :
                                if ndim == dndim and reduce(operator.and_, map(operator.ge, shape, dshape), True) :
                                    data = data.trimmed(shape=shape, value=self)
#                                    if self.shape == shape :
#                                        data = self.fitted(data)
#                                    else :
#                                        data = data.trimmed(shape)
                                else :
                                    try :
                                        data = cls(shape=shape).filled(data)
                                    except :
                                        data = data.resized(shape=shape, value=self)
                            else :
                                if isinstance (args, Array) :
                                    msg = "cannot cast a %s of shape %s to a %s of shape %s,\n" % (clsname(args), args.shape, cls.__name__, shape)
                                else :
                                    msg = "cannot initialize a %s of shape %s from %s of shape %s,\n" % (cls.__name__, shape, args, dshape)
                                msg += "as it would truncate data or reduce the number of dimensions"
                                raise TypeError, msg

                # check that the shape is compatible with the class, as some Array sub classes have fixed shapes / ndim
                if not cls._shapecheck(data.shape) :
                    raise TypeError, "shape of arguments %s is incompatible with class %s" % (data.shape, cls.__name__)

                # Maya 8.5 fix
                # this is a very bad workaround for a python2.4 bug.  datatypes.Vector uses a propert to emulate self.data
                # and ensure that the data is converted to api classes.  unfortunately, in python2.4 these properties are not
                # being called when self.data is set from here.  this workaround can be removed when we drop maya 8.5 support
                if hasattr(self,'_setdata'):
                    self._setdata(data.data)
                else:
                    self.data = data.data
            else :
                raise ValueError, "could not initialize a %s from the provided arguments %s" % (cls.__name__, args)

    def filled(self, value=None):
        """ a.filled([value]) --> Array

            Returns a copy (deepcopy) of a, filled with value for a's shape. If no value is given, a is filled with the class default.
            value will be expended with the class default values to the nearest matching sub array of a, then repeated.
            value can't be truncated and will raise an error if of a size superior to the size of the nearest matching sub array
            of the class, to avoid improper casts.

            Note : value is copied (deepcopy) as many times as it is inserted in a, not referenced.

            Examples:

            >>> Array(shape=(5,)).filled([0, 1, 2])
            Array([0, 1, 2, 0, 0])
            >>> Array(shape=(5,)).filled(2)
            Array([2, 2, 2, 2, 2])
            >>> print Array(shape=(2, 2)).filled(1).formated()
            [[1, 1],
             [1, 1]]
            >>> A = Array(shape=(3, 3)).filled([1, 2, 3])
            >>> print A.formated()
            [[1, 2, 3],
             [1, 2, 3],
             [1, 2, 3]]
            >>> A[0] == A[-1]
            True
            >>> A[0] is A[-1]
            False
            >>> A = Array(shape=(3, 3)).filled([1, 2])
            >>> print A.formated()
            [[1, 2, 0],
             [1, 2, 0],
             [1, 2, 0]]
            >>> Array(shape=(2, 2)).filled([1, 2, 3])
            Traceback (most recent call last):
                ...
            ValueError: value of shape (3,) cannot be fit in a Array of shape (2, 2), some data would be lost
        """
        cls = self.__class__
        shape = self.shape
        ndim = self.ndim
        size = self.size

        new = cls(shape=shape)

        if value is not None :
            value = _toCompOrArray(value)
            vshape, vdim, vsize = _shapeInfo(value)

            if not shape or shape == vshape :
                new = cls(copy.deepcopy(value), shape=vshape)
            elif vdim <= ndim and vsize <= size:
                subshape = shape[ndim-vdim:]
                if subshape != vshape :
                    subsize = reduce(operator.mul, subshape, 1)
                    if subsize >= vsize :
                        value.resize(shape=subshape)
                    else :
                        raise ValueError, "value of shape %s cannot be fit in a %s of shape %s, some data would be lost" % (vshape, cls.__name__, shape)
                if vdim < ndim :
                    siter = new.subiter(vdim)
                    for i in xrange(len(siter)) :
                        siter[i] = copy.deepcopy(value)
                else :
                    new = cls(copy.deepcopy(value), shape=shape)
            else :
                raise ValueError, "fill value has more dimensions or is larger than the specified desired shape"

        return new

    def fill(self, value=None):
        """ a.fill([value])

            Fills the array in place with the given value, if no value is given a is filled with the default class values

            Note : value is copied (deepcopy) as many times as it is inserted in a, not referenced.

            Examples:

            >>> A = Array(shape=(3, 3))
            >>> print A.formated()
            [[0, 0, 0],
             [0, 0, 0],
             [0, 0, 0]]
            >>> A.fill(10)
            >>> print A.formated()
            [[10, 10, 10],
             [10, 10, 10],
             [10, 10, 10]]
            >>> A.fill()
            >>> print A.formated()
            [[0, 0, 0],
             [0, 0, 0],
             [0, 0, 0]]
            >>> A.fill([1, 2])
            >>> print A.formated()
            [[1, 2, 0],
             [1, 2, 0],
             [1, 2, 0]]
            >>> A.fill([1, 2, 3])
            >>> print A.formated()
            [[1, 2, 3],
             [1, 2, 3],
             [1, 2, 3]]
            >>> A[0] == A[-1]
            True
            >>> A[0] is A[-1]
            False
        """
        new = self.filled(value=value)
        if type(new) is type(self) :
            self.assign(new)
        else :
            raise ValueError, "new shape %s is not compatible with class %s" % (shape, clsname(self))

    def appended(self, other, axis=0):
        """ a.appended(b[, axis=0]) --> Array

            Returns the Array obtained by appending b at the end of a as iterated on axis.

            Note : returns a deepcopy of a.appends(b[, axis=0]).

            Examples:

            >>> A = Array([])
            >>> print repr(A)
            Array([])
            >>> A = A.appended(1)
            >>> print A.formated()
            [1]
            >>> A = A.appended(2)
            >>> print A.formated()
            [1, 2]
            >>> A = Array([A])
            >>> print A.formated()
            [[1, 2]]
            >>> A = A.appended([4, 5], axis=0)
            >>> print A.formated()
            [[1, 2],
             [4, 5]]
            >>> A = A.appended([3, 6], axis=1)
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6]]
            >>> A = A.appended([7, 8, 9])
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> B = Array([A]).appended(A)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]]]
            >>> B[0] == B[1]
            True
            >>> B[0] is B[1]
            False
            >>> A == B[0]
            True
            >>> A is B[0]
            False
            >>> B = B.appended([0, 0, 0], axis=1)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [0, 0, 0]],
            <BLANKLINE>
             [[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [0, 0, 0]]]
            >>> B = B.appended([0, 0, 0, 1], axis=2)
            >>> print B.formated()
            [[[1, 2, 3, 0],
              [4, 5, 6, 0],
              [7, 8, 9, 0],
              [0, 0, 0, 1]],
            <BLANKLINE>
             [[1, 2, 3, 0],
              [4, 5, 6, 0],
              [7, 8, 9, 0],
              [0, 0, 0, 1]]]

        """
        cls = self.__class__
        new = Array(self.deepcopy())
        new.append(other, axis=axis)
        try :
            new = cls._convert(new)
        except :
            raise ValueError, "cannot append a %s of shape %s on axis %s of %s of shape %s" % (clsname(other), oshape, axis, clsname(self), shape)

        return new

    def append(self, other, axis=0):
        """ a.append(b[, axis=0])

            Modifies a by appending b at its end, as iterated on axis.

            Note : does not work as list append and appends a copy (deepcopy) of b, not a reference to b. However a is appended in place.

            Examples:

            >>> A = Array([])
            >>> print repr(A)
            Array([])
            >>> A.append(1)
            >>> print A.formated()
            [1]
            >>> A.append(2)
            >>> print A.formated()
            [1, 2]
            >>> A = Array([A])
            >>> print A.formated()
            [[1, 2]]
            >>> A.append([4, 5], axis=0)
            >>> print A.formated()
            [[1, 2],
             [4, 5]]
            >>> A.append([3, 6], axis=1)
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6]]
            >>> A.append([7, 8, 9])
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> B = Array([A])
            >>> B.append(A)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]]]
            >>> B[0] == B[1]
            True
            >>> B[0] is B[1]
            False
            >>> A == B[0]
            True
            >>> A is B[0]
            True
            >>> B.append([0, 0, 0], axis=1)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [0, 0, 0]],
            <BLANKLINE>
             [[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [0, 0, 0]]]
            >>> B.append([0, 0, 0, 1], axis=2)
            >>> print B.formated()
            [[[1, 2, 3, 0],
              [4, 5, 6, 0],
              [7, 8, 9, 0],
              [0, 0, 0, 1]],
            <BLANKLINE>
             [[1, 2, 3, 0],
              [4, 5, 6, 0],
              [7, 8, 9, 0],
              [0, 0, 0, 1]]]

        """
        cls = self.__class__
        shape, ndim, size = _shapeInfo(self)
        other = copy.deepcopy(_toCompOrArrayInstance(other))
        oshape, odim, osize = _shapeInfo(other)

        # one axis from 0 to ndim-1
        axis = int(axis)
        if axis < 0 :
            axis += ndim
        if axis not in range(ndim) :
            raise ValueError, "cannot append on axis %s, axis does not exist for %s of shape %s" % (axis, util.clsname(self), shape)
        itself = self.axisiter(axis);
        itemshape = itself.itemshape
        itemdim = len(itemshape)
        if itemshape :
            other = Array(shape=itemshape).filled(other)
        else :
            other = Array(other)
        if size :
            if axis > 0 :
                staxis = range(axis, -1, -1)+range(axis+1, ndim)
                nself = self.transpose(staxis)
                otaxis = staxis[1:]
                for i, a in enumerate(otaxis) :
                    if a > axis :
                        otaxis[i] = a-1
                nother = other.transpose(otaxis)
                if nother.ndim == itemdim :
                    nother = Array([nother])
                new = Array(list(nself)+list(nother))
                new = new.transpose(staxis)
            else :
                if other.ndim == itemdim :
                    other = Array([other])
                new = Array(list(self)+list(other))
        elif odim == 0 :
            if other.ndim == itemdim :
                other = Array([other])
            new = other

        try :
            new = cls._convert(new)
        except :
            raise ValueError, "cannot append a %s of shape %s on axis %s of %s of shape %s" % (clsname(other), oshape, axis, clsname(self), shape)

        if type(new) is type(self) :
            self.assign(new)
        else :
            raise ValueError, "new appended shape %s is not compatible with class %s" % (shape, clsname(self))

    def stacked(self, other, axis=0):
        """ a.stacked(b[, axis=0]) --> Array

            Returns the Array obtained by concatenating a and b on axis.

            Note : returns a deepcopy of a.stack(b[, axis=0]).

            Examples:

            >>> A = Array([])
            >>> print repr(A)
            Array([])
            >>> A = A.stacked([1])
            >>> print A.formated()
            [1]
            >>> A = A.stacked([2])
            >>> print A.formated()
            [1, 2]
            >>> A = Array([A])
            >>> print A.formated()
            [[1, 2]]
            >>> A = A.stacked([[4, 5]], axis=0)
            >>> print A.formated()
            [[1, 2],
             [4, 5]]
            >>> A = A.stacked([[3], [6]], axis=1)
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6]]
            >>> A = A.stacked([[7, 8, 9]])
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> B = Array([A])
            >>> B = B.stacked(B)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]]]
            >>> B[0] == B[1]
            True
            >>> B[0] is B[1]
            False
            >>> A == B[0]
            True
            >>> A is B[0]
            False
            >>> B = B.stacked([[[0, 0, 0]], [[0, 0, 0]]], axis=1)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [0, 0, 0]],
            <BLANKLINE>
             [[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [0, 0, 0]]]
            >>> B = B.stacked([[[0], [0], [0], [1]], [[0], [0], [0], [1]]], axis=2)
            >>> print B.formated()
            [[[1, 2, 3, 0],
              [4, 5, 6, 0],
              [7, 8, 9, 0],
              [0, 0, 0, 1]],
            <BLANKLINE>
             [[1, 2, 3, 0],
              [4, 5, 6, 0],
              [7, 8, 9, 0],
              [0, 0, 0, 1]]]

        """
        cls = self.__class__
        new = Array(self.deepcopy())
        new.stack(other, axis=axis)
        return cls._convert(new)

    def stack(self, other, axis=0):
        """ a.stack(b[, axis=0]) --> Array

            Modifies a by concatenating b at its end, as iterated on axis.

            Note : stacks a copy (deepcopy) of b, not a reference to b. However a is modified in place.

            Examples:

            >>> A = Array([])
            >>> print repr(A)
            Array([])
            >>> A.stack([1])
            >>> print A.formated()
            [1]
            >>> A.stack([2])
            >>> print A.formated()
            [1, 2]
            >>> A = Array([A])
            >>> print A.formated()
            [[1, 2]]
            >>> A.stack([[4, 5]], axis=0)
            >>> print A.formated()
            [[1, 2],
             [4, 5]]
            >>> A.stack([[3], [6]], axis=1)
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6]]
            >>> A.stack([[7, 8, 9]])
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> B = Array([A])
            >>> B.stack(B)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]]]
            >>> B[0] == B[1]
            True
            >>> B[0] is B[1]
            False
            >>> A == B[0]
            True
            >>> A is B[0]
            True
            >>> B.stack([[[0, 0, 0]], [[0, 0, 0]]], axis=1)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [0, 0, 0]],
            <BLANKLINE>
             [[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [0, 0, 0]]]
            >>> B.stack([[[0], [0], [0], [1]], [[0], [0], [0], [1]]], axis=2)
            >>> print B.formated()
            [[[1, 2, 3, 0],
              [4, 5, 6, 0],
              [7, 8, 9, 0],
              [0, 0, 0, 1]],
            <BLANKLINE>
             [[1, 2, 3, 0],
              [4, 5, 6, 0],
              [7, 8, 9, 0],
              [0, 0, 0, 1]]]

        """
        cls = self.__class__
        shape, ndim, size = _shapeInfo(self)
        other = copy.deepcopy(_toCompOrArrayInstance(other))
        oshape, odim, osize = _shapeInfo(other)
        if odim == ndim :
            # one axis from 0 to ndim-1
            axis = int(axis)
            if axis < 0 :
                axis += ndim
            if axis not in range(ndim) :
                raise ValueError, "cannot stack on axis %s, axis does not exist for %s of shape %s" % (axis, util.clsname(self), shape)
            itself = self.axisiter(axis);
            itother = other.axisiter(axis)
            if itself.itemshape == itother.itemshape :
                if axis > 0 :
                    taxis = range(axis, -1, -1)+range(axis+1, ndim)
                    nself = self.transpose(taxis)
                    nother = other.transpose(taxis)
                    new = Array(list(nself)+list(nother)).transpose(taxis)
                else :
                    new = Array(list(self)+list(other))
                new = cls._convert(new)
                if type(new) is type(self) :
                    self.assign(new)
                else :
                    raise ValueError, "new concatenated shape %s is not compatible with class %s" % (shape, clsname(self))
            else :
                raise ValueError, "cannot stack %s of shape %s and %s of shape %s on axis %s" % (clsname(self), shape, clsname(other), oshape, axis)
        else :
            raise ValueError, "cannot stack %s and %s has they have a different number of dimensions %s and %s" % (clsname(self), clsname(other), ndim, odim)

    def hstacked(self, other) :
        """ a.hstacked(b) <==> a.stacked(b, axis=-1)

            Returns the Array obtained by concatenating a and b on last axis.
            For a 2 dimensional Array/MatrixN, it stacks a and b horizontally.

            >>> A = Array([[1, 2], [4, 5]])
            >>> print A.formated()
            [[1, 2],
             [4, 5]]
            >>> A = A.hstacked([[3], [6]])
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6]]
        """
        return self.stacked(other, axis=-1)

    def hstack(self, other) :
        """ a.hstack(b) <==> a.stack(b, axis=-1)

            Modifies a by concatenating b at its end, as iterated on last axis.
            For a 2 dimensional Array/MatrixN, it stacks a and b horizontally.

            >>> A = Array([[1, 2], [4, 5]])
            >>> print A.formated()
            [[1, 2],
             [4, 5]]
            >>> A.hstack([[3], [6]])
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6]]
        """
        self.stack(other, axis=-1)

    def vstacked(self, other) :
        """ a.vstacked(b) <==> a.stacked(b, axis=0)

            Returns the Array obtained by concatenating a and b on first axis.
            For a 2 dimensional Array/MatrixN, it stacks a and b vertically.

            >>> A = Array([[1, 2], [3, 4]])
            >>> print A.formated()
            [[1, 2],
             [3, 4]]
            >>> A = A.vstacked([[5, 6]])
            >>> print A.formated()
            [[1, 2],
             [3, 4],
             [5, 6]]
        """
        return self.stacked(other, axis=0)

    def vstack(self, other) :
        """ a.vstack(b) <==> a.stack(b, axis=0)

            Modifies a by concatenating b at its end, as iterated on first axis.
            For a 2 dimensional Array/MatrixN, it stacks a and b vertically

            >>> A = Array([[1, 2], [3, 4]])
            >>> print A.formated()
            [[1, 2],
             [3, 4]]
            >>> A.vstack([[5, 6]])
            >>> print A.formated()
            [[1, 2],
             [3, 4],
             [5, 6]]
        """
        self.stack(other, axis=0)

    # aliases
    extended = vstacked
    extend = vstack

#    def repeated(self, repeat, axis):
#    # alow repeat onn multiple axis ..
#        pass
#
#    def repeat(self, repeat, axis):
#        pass

    # TODO : override and redefine these list herited methods for Arrays ?
#    def insert(self, index, other):
#        raise TypeError, "insert is not implemented for class %s" % (clsname(self))
#
#    def __reversed__(self, axis=None):
#        raise TypeError, "__reversed__ is not implemented for class %s" % (clsname(self))
#
#    def reverse(self, axis=None):
#        raise TypeError, "reverse is not implemented for class %s" % (clsname(self))
#
#    def pop(self, index):
#        raise TypeError, "pop is not implemented for class %s" % (clsname(self))
#
#    def remove(self, value):
#        raise TypeError, "remove is not implemented for class %s" % (clsname(self))
#
#    def sort(self, axis=None):
#        raise TypeError, "sort is not implemented for class %s" % (clsname(self))

    def reshaped(self, shape=None):
        """ a.reshaped(shape) --> Array

            Returns a copy the Array as reshaped according to the shape argument, without changing the Array's size
            (total number of components)

            Examples :

            >>> A = Array(range(1, 17), shape=(4, 4))
            >>> print A.formated()
            [[1, 2, 3, 4],
             [5, 6, 7, 8],
             [9, 10, 11, 12],
             [13, 14, 15, 16]]
            >>> B = A.reshaped(shape=(2, 2, 4))
            >>> print B.formated()
            [[[1, 2, 3, 4],
              [5, 6, 7, 8]],
            <BLANKLINE>
             [[9, 10, 11, 12],
              [13, 14, 15, 16]]]
            >>> A[0] == B[0, 0]
            True
            >>> A[0] is B[0, 0]
            False

        """
        ndim = None
        size = self.size
        newshape, newndim, newsize = self.__class__._expandshape(shape, ndim, size)
        if newsize != size :
            raise ValueError, "total size of new Array must be unchanged"

        return self.resized(newshape)

    def reshape(self, shape=None):
        """ a.reshaped(shape) <==> a.shape = shape

            Performs in-place reshape of array a according to the shape argument without changing the Array's size
            (total number of components).

            Note : as opposed to trim, reshape will reshuffle components and thus not preserve sub-arrays identity.

            Examples :

            >>> A = Array(range(1, 17), shape=(4, 4))
            >>> print A.formated()
            [[1, 2, 3, 4],
             [5, 6, 7, 8],
             [9, 10, 11, 12],
             [13, 14, 15, 16]]
            >>> S = A[0]
            >>> A.reshape(shape=(2, 2, 4))
            >>> print A.formated()
            [[[1, 2, 3, 4],
              [5, 6, 7, 8]],
            <BLANKLINE>
             [[9, 10, 11, 12],
              [13, 14, 15, 16]]]
            >>> S == A[0, 0]
            True
            >>> S is A[0, 0]
            False

        """
        ndim = None
        size = self.size
        newshape, newndim, newsize = self.__class__._expandshape(shape, ndim, size)
        if newsize != size :
            raise ValueError, "total size of new Array must be unchanged"

        self.resize(newshape)

    def resized(self, shape=None, value=None):
        """ a.resized([shape [, value]]) --> Array

            Returns a copy of the Array resized according to the shape argument.
            An optional value argument can be passed and will be used to fill the extra components
            of the new Array if the resize results in a size increase, otherwise the Array class default values are used.

            Examples :

            >>> A = Array(range(1, 17), shape=(4, 4))
            >>> print A.formated()
            [[1, 2, 3, 4],
             [5, 6, 7, 8],
             [9, 10, 11, 12],
             [13, 14, 15, 16]]
            >>> B = A.resized(shape=(2, 2, 4))
            >>> print B.formated()
            [[[1, 2, 3, 4],
              [5, 6, 7, 8]],
            <BLANKLINE>
             [[9, 10, 11, 12],
              [13, 14, 15, 16]]]
            >>> A[0] == B[0, 0]
            True
            >>> A[0] is B[0, 0]
            False
            >>> B = B.resized(shape=(2, 3, 3))
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[10, 11, 12],
              [13, 14, 15],
              [16, 0, 0]]]
            >>> B = B.resized(shape=(4, 5), value=1)
            >>> print B.formated()
            [[1, 2, 3, 4, 5],
             [6, 7, 8, 9, 10],
             [11, 12, 13, 14, 15],
             [16, 0, 0, 1, 1]]

        """
        cls = self.__class__
        newshape, newndim, nsize = cls._expandshape(shape, None, None)

        new = None
        for c in inspect.getmro(cls) :
            if issubclass(c, Array) :
                try :
                    new = c(shape=newshape).filled(value)
                    break
                except :
                    pass

        if new is not None :
            flatIter = self.flat
            newIter = new.flat
            ln = min(len(flatIter), len(newIter))
            for i in xrange(ln) :
                newIter[i] = flatIter[i]
            # return new.deepcopy() not needed
            return new
        else :
            if value is not None :
                raise TypeError, "%s cannot be initialized to shape %s with value %s, and has no base class that can" % (clsname(self), shape, value)
            else :
                raise TypeError, "%s cannot be initialized to shape %s, and has no base class that can" % (clsname(self), shape)

    def resize(self, shape=None, value=None):
        """ a.resize([shape[, value]])

            Performs in-place resize of array a according to the shape argument.
            An optional value argument can be passed and will be used to fill the newly created components
            if the resize results in a size increase, otherwise the Array class default values are used.

            Note : as opposed to trim, resize will reshuffle components and thus not preserve sub-arrays identity.

            Examples :

            >>> A = Array(range(1, 17), shape=(4, 4))
            >>> print A.formated()
            [[1, 2, 3, 4],
             [5, 6, 7, 8],
             [9, 10, 11, 12],
             [13, 14, 15, 16]]
            >>> S = A[0]
            >>> A.resize(shape=(2, 2, 4))
            >>> print A.formated()
            [[[1, 2, 3, 4],
              [5, 6, 7, 8]],
            <BLANKLINE>
             [[9, 10, 11, 12],
              [13, 14, 15, 16]]]
            >>> S == A[0, 0]
            True
            >>> S is A[0, 0]
            False
            >>> A.resize(shape=(2, 3, 3))
            >>> print A.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[10, 11, 12],
              [13, 14, 15],
              [16, 0, 0]]]
            >>> A.resize(shape=(4, 5), value=1)
            >>> print A.formated()
            [[1, 2, 3, 4, 5],
             [6, 7, 8, 9, 10],
             [11, 12, 13, 14, 15],
             [16, 0, 0, 1, 1]]

        """
        cls = self.__class__
        try :
            newshape, newndim, nsize = cls._expandshape(shape, None, None)
            new = cls(shape=newshape).filled(value)
        except :
            raise TypeError, "new shape %s is not compatible with class %s" % (shape, clsname(self))

        flatIter = self.flat
        newIter = new.flat
        ln = min(len(flatIter), len(newIter))
        for i in xrange(ln) :
            newIter[i] = flatIter[i]
        self.assign(new)

    def _fitloop(self, source):
        ldst = len(self)
        lsrc = len(source)
        lmin = min(ldst, lsrc)
        ndim = min(source.ndim, self.ndim)

        # copy when common shape, or recurse down
        for i in xrange(lmin) :
            if ndim == 1 or self[i].shape == source[i].shape :
                self[i] = source[i]
            else :
                self[i]._fitloop(source[i])

    def fitted(self, other):
        """ a.fitted(b) --> Array

            Returns the result of fitting the Array b in a.
            For every component of a that exists in b (there is a component of same coordinates in b),
            replace it with the value of the corresponding component in b.
            Both Arrays a and b must have same number of dimensions.

            Note : returns a copy (deepcopy) of a.fit(b)

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> B = Array(shape=(4, 3))
            >>> print B.formated()
            [[0, 0, 0],
             [0, 0, 0],
             [0, 0, 0],
             [0, 0, 0]]
            >>> C = B.fitted(A)
            >>> print C.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9],
             [0, 0, 0]]
            >>> C[0] == A[0]
            True
            >>> C[0] is A[0]
            False
            >>> C[-1] == B[-1]
            True
            >>> C[-1] is B[-1]
            False
            >>> B = Array(shape=(4, 4)).fitted(A)
            >>> print B.formated()
            [[1, 2, 3, 0],
             [4, 5, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 0]]
            >>> B = Array(shape=(2, 2)).fitted(A)
            >>> print B.formated()
            [[1, 2],
             [4, 5]]
        """
        new = self.deepcopy()
        new.fit(other)
        return new

    def fit(self, other):
        """ a.fit(b)

            Fits the Array b in a.
            For every component of a that exists in b (there is a component of same coordinates in b),
            replace it with the value of the corresponding component in b.
            Both Arrays a and b must have same number of dimensions.

            Note : copies (deepcopy) of b sub-arrays are fit in a, not references, but modification of a is done in-place.

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> B = Array(shape=(4, 3))
            >>> print B.formated()
            [[0, 0, 0],
             [0, 0, 0],
             [0, 0, 0],
             [0, 0, 0]]
            >>> S = B[-1]
            >>> B.fit(A)
            >>> print B.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9],
             [0, 0, 0]]
            >>> B[0] == A[0]
            True
            >>> B[0] is A[0]
            False
            >>> S == B[-1]
            True
            >>> S is B[-1]
            True
            >>> B = Array(shape=(4, 4))
            >>> B.fit(A)
            >>> print B.formated()
            [[1, 2, 3, 0],
             [4, 5, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 0]]
            >>> B = Array(shape=(2, 2))
            >>> B.fit(A)
            >>> print B.formated()
            [[1, 2],
             [4, 5]]
        """
        other = Array(other).deepcopy()
        if self.ndim != other.ndim :
            raise ValueError, "can only fit one Array in another if they have the same number of dimensions"
        self._fitloop(other)

    def _trimloop(self, source):
        ldst = len(self)
        lsrc = len(source)
        lmin = min(ldst, lsrc)
        ndim = min(source.ndim, self.ndim)

        # trim sub dimensions when common
        if ndim > 1 :
            for i in xrange(lmin) :
                self[i]._trimloop(source[i])
                # lst = list(self)
        self._cacheshape()

        # add if needed
        for i in range(ldst, lsrc) :
            self.append(source[i])
        # or remove if needed
        for i in range(ldst-1, lsrc-1, -1) :
            del self[i]
        # update shape
        self._cacheshape()
        # self.data = lst

    def trimmed(self, shape=None, value=None):
        """ a.trimmed([shape [, value]]) --> Array

            Returns the Array as "trimmed", re-sized according to the shape argument.
            The difference with a resize is that each dimension will be resized individually,
            thus the shape argument must have the same number of dimensions as the Array a.
            A value of -1 or None for a shape dimension size will leave it unchanged.
            An optional value argument can be passed and will be used to fill the newly created
            components if the trimmed results in a size increase, otherwise the class default values
            will be used to fill new components

            Note : returns a copy (deepcopy) of a.trim([shape [, value]])

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> B = A.trimmed(shape=(4, 3))
            >>> print B.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9],
             [0, 0, 0]]
            >>> B[0] == A[0]
            True
            >>> B[0] is A[0]
            False
            >>> B = A.trimmed(shape=(4, 4))
            >>> print B.formated()
            [[1, 2, 3, 0],
             [4, 5, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 0]]
            >>> B = A.trimmed(shape=(2, 2))
            >>> print B.formated()
            [[1, 2],
             [4, 5]]
        """
        cls = self.__class__
        if shape is None :
            newshape = []
        else :
            newshape = list(shape)
        newndim = len(newshape)
        if newndim != self.ndim :
            raise ValueError, "can only trim using a new shape of same number of dimensions as Array"
        oldshape = self.shape
        for i in xrange(newndim) :
            if newshape[i] == -1 or newshape[i] is None :
                newshape[i] = oldshape[i]

        # new will be a copy
        new = Array(shape=newshape).filled(value)
        new._fitloop(self)
        new = cls._convert(new)

        return new.deepcopy()

    def trim(self, shape=None, value=None):
        """ a.trim(shape)
            Performs in-place trimming of array a to given shape.
            An optional value argument can be passed and will be used to fill
            the newly created components if the resize results in a size increase.

            Note : a is modified in-place

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> S = A[0]
            >>> A.trim(shape=(4, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9],
             [0, 0, 0]]
            >>> S == A[0]
            True
            >>> S is A[0]
            True
            >>> A.trim(shape=(4, 4))
            >>> print A.formated()
            [[1, 2, 3, 0],
             [4, 5, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 0]]
            >>> A.trim(shape=(2, 2))
            >>> print A.formated()
            [[1, 2],
             [4, 5]]
        """
        if shape is None :
            newshape = []
        else :
            newshape = list(shape)
        newndim = len(newshape)
        if newndim != self.ndim :
            raise ValueError, "can only trim using a new shape of same number of dimensions as Array"
        oldshape = self.shape
        for i in xrange(newndim) :
            if newshape[i] == -1 or newshape[i] is None :
                newshape[i] = oldshape[i]

        if self.__class__._shapecheck(newshape) :
            source = self.__class__(shape=newshape).filled(value)
            self._trimloop(source)
        else :
            raise TypeError, "new shape %s is not compatible with class %s" % (shape, clsname(self))

    def __reduce__(self):
        """ __reduce__ is defined to allow pickling of Arrays """
        return (self.__class__, self.__getnewargs__())

    def __getnewargs__(self):
        return (tuple(self),)

    def copy(self):
        """ a.copy() <==> copy.copy(a)

            Returns a shallow copy of a

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> B = A.copy()
            >>> print B.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> print B == A
            True
            >>> print B is A
            False
            >>> print B[0] == A[0]
            True
            >>> print B[0] is A[0]
            True
        """
        return copy.copy(self)

    def deepcopy(self):
        """ a.deepcopy() <==> copy.deepcopy(a)

            Returns a deep copy of a

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> B = A.deepcopy()
            >>> print B.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> print B == A
            True
            >>> print B is A
            False
            >>> print B[0] == A[0]
            True
            >>> print B[0] is A[0]
            False
        """
        return copy.deepcopy(self)

    # display
    def __str__(self):
        return "[%s]" % ", ".join( map(str,self) )

    def __unicode__(self):
        return u"[%s]" % u", ".join( map(unicode,self) )

    def __repr__(self):
        return "%s(%s)" % (self.__class__.__name__, str(self))

    def _formatloop(self, level=0):
        subs = []
        try :
            for a in self :
                depth, substr = a._formatloop(level+1)
                subs.append(substr)
            if depth :
                msg = "[%s]" % (","+"\n"*depth+" "*(level+1)).join(subs)
            else :
                msg = "[%s]" % ", ".join(subs)
            return depth+1, msg
        except :
            return 1, str(self)

    def formated(self):
        """ a.formated() --> str

            Returns a string representing a formated output of Array a

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
        """
        return self._formatloop()[1]

    # wrap of list-like access methods
    def __len__(self):
        """ a.__len__() <==> len(a)

            Length of the first dimension of the array, ie len of the array considered as the top level list,
            thus len(a) == a.shape[0].

            >>> Array(shape=(3, 2)).__len__()
            3
        """
        return self.apicls.__len__(self.data)

    @staticmethod
    def _extract(x, index) :
        if isinstance(x, Array) :
            res = x.apicls.__getitem__(x.data, index)
        else :
            res = [Array._extract(a, index) for a in x]
        return res

    def __getitem__(self, index):
        """ a.__getitem__(index) <==> a[index]

            Get Array element from either a single (integer) or multiple (tuple) indices, supports slices.

            Note : __getitem__ returns reference that can be modified unless the sub-array had to be reconstructed.

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> print repr(A[0])
            Array([1, 2, 3])
            >>> print repr(A[-1])
            Array([7, 8, 9])
            >>> print repr(A[0, 0])
            1
            >>> print repr(A[-1, -1])
            9

            Multiple indices and slices are supported :

            >>> B = A[0:2, 0:2]
            >>> print B.formated()
            [[1, 2],
             [4, 5]]

            When sub-arrays are not broken / rebuilt by requested indexing, a reference is returned :

            >>> B = A[0:2]
            >>> print B.formated()
            [[1, 2, 3],
             [4, 5, 6]]
            >>> B[0] == A[0]
            True
            >>> B[0] is A[0]
            True

            Missing indices are equivalent to slice(None), noted ':', but as with list, a[:] returns
            a copy of a, not a reference to a.

            >>> B = A[0:2, :]
            >>> print B.formated()
            [[1, 2, 3],
             [4, 5, 6]]
            >>> B[0] == A[0]
            True
            >>> B[0] is A[0]
            False

            When sub-arrays are rebuilt, result is a copy.

            >>> B = A[:, 0:2]
            >>> print B.formated()
            [[1, 2],
             [4, 5],
             [7, 8]]
            >>> print repr(B[:,0])
            Array([1, 4, 7])
            >>> B[:,0] == A[:, 0]
            True
            >>> B[:,0] is A[:, 0]
            False

            Use __setindex__ to change the value of an indexed element in that case

            >>> A[:, 0:2] += 10
            >>> print A.formated()
            [[11, 12, 3],
             [14, 15, 6],
             [17, 18, 9]]
        """
        # TODO : Numpy like support for indices that are Arrays ?
        if not hasattr(index, '__iter__') :
            index = [index]
        else :
            index = list(index)
        if len(index) > self.ndim :
            raise ValueError, "%s coordinates provided for an Array of dimension %s" % (len(index), self.ndim)

        value = reduce(lambda x, y: Array._extract(x, y), index, self)
        # print "value and id", value, id(value)
        value = self.__class__._toCompOrConvert(value)
        # value = _toCompOrArray(value)
        # print "value and id", value, id(value)
        return value

    def __getslice__(self, start, end):
        """ Deprecated and __getitem__ should accept slices anyway """
        return self.__getitem__(slice(start, end))

    def _inject(self, index, value) :
        indices = range(self.shape[0])[index[0]]
        if not hasattr(indices, '__iter__') :
            indices = [indices]
            value = [value]
        ni = len(indices)
        if len(index) == 1 :
            # single dimension index, assign to storage
            for i in xrange(ni) :
                self.apicls.__setitem__(self.data, indices[i], value[i])
        else :
            # multi dimension index
            nextindex = index[1:]
            for i in xrange(ni) :
                self[indices[i]]._inject(nextindex, value[i])

    def __setitem__(self, index, value):
        """ a.__setitem__(index, value) <==> a[index] = value

            Set Array element from either a single (integer) or multiple (tuple) indices, supports slices.

            Note : if value is not reshaped / resized, it's a reference to value that is set at the indexed element,
            use an explicit deepcopy

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]

            If value doesn't have to be rebuilt, the indexed elements will hold a reference to value, otherwise a copy

            >>> S = Array([0, 0, 0])
            >>> A[0] = S
            >>> print A.formated()
            [[0, 0, 0],
             [4, 5, 6],
             [7, 8, 9]]
            >>> A[0] == S
            True
            >>> A[0] is S
            True
            >>> A[:, 2] = S
            >>> print A.formated()
            [[0, 0, 0],
             [4, 5, 0],
             [7, 8, 0]]
            >>> A[:, 2] == S
            True
            >>> A[:, 2] is S
            False

            Multiple indices and slices are supported :

            >>> A[0] = [2, 4, 6]
            >>> print A.formated()
            [[2, 4, 6],
             [4, 5, 0],
             [7, 8, 0]]
            >>> A[1, 1] = 10
            >>> print A.formated()
            [[2, 4, 6],
             [4, 10, 0],
             [7, 8, 0]]
            >>> A[:, -1] = [7, 8, 9]
            >>> print A.formated()
            [[2, 4, 7],
             [4, 10, 8],
             [7, 8, 9]]
            >>> A[:, 0:2] += 10
            >>> print A.formated()
            [[12, 14, 7],
             [14, 20, 8],
             [17, 18, 9]]

            Value is expanded / repeated as necessary to fit the indexed sub-array

            >>> A[0:2, 0:2] = 1
            >>> print A.formated()
            [[1, 1, 7],
             [1, 1, 8],
             [17, 18, 9]]
            >>> A[1:3, :] = [1, 2]
            >>> print A.formated()
            [[1, 1, 7],
             [1, 2, 0],
             [1, 2, 0]]
            >>> A[0:2, 1:3] = [1, 2]
            >>> print A.formated()
            [[1, 1, 2],
             [1, 1, 2],
             [1, 2, 0]]
            >>> A[0:2, 1:3] = [[1], [2]]
            >>> print A.formated()
            [[1, 1, 0],
             [1, 2, 0],
             [1, 2, 0]]

            It cannot be truncated however

            >>> A[0] = [1, 2, 3, 4]
            Traceback (most recent call last):
                ...
            ValueError: shape mismatch between value(s) and Array components or sub Arrays designated by the indexing
        """
        # NUMPY differences: expands by repeating last value
        """
            >>> A[0:2, 1:3] = [[1], [2]]
            >>> print A.formated()
            [[1, 1, 1],
             [1, 2, 2],
             [1, 2, 0]]
        """

        if not hasattr(index, '__iter__') :
            index = [index]
        else :
            index = list(index)
        if len(index) > self.ndim :
            raise ValueError, "%s coordinates provided for an Array of dimension %s" % (len(index), self.ndim)
        value = _toCompOrArray(value)
        vshape, vdim, vsize = _shapeInfo(value)
        subexpected = self.__getitem__(index)
        subshape, subdim, subsize = _shapeInfo(subexpected)
        # if we don't except a single numeric value
        if vshape != subshape :
            try :
                value = Array(value, shape=subshape)
            except :
                raise ValueError, "shape mismatch between value(s) and Array components or sub Arrays designated by the indexing"
        self._inject(index, value)

    def __setslice__(self, start, end, value):
        """ Deprecated and __setitem__ should accept slices anyway """
        self.__setitem__(slice(start, end), value)

    def _delete(self, index) :
        ls = len(self)
        li = len(index)
        if ls and li :
            next = li > 1
            for i in xrange(ls-1, -1, -1) :
                if i in index[0] :
                    self.apicls.__delitem__(self.data, i)
                    # self._cacheshape()
                elif next :
                    self[i]._delete(index[1:])

    def __delitem__(self, index) :
        """ a.__delitem__(index) <==> del a[index]

            Delete elements that match index from the Array.

            Note : as opposed to a.strip(index), do not collapse dimensions of the Array
            that end up with only one sub-array.

            >>> A = Array(xrange(1, 28), shape=(3, 3, 3))
            >>> print A.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[10, 11, 12],
              [13, 14, 15],
              [16, 17, 18]],
            <BLANKLINE>
             [[19, 20, 21],
              [22, 23, 24],
              [25, 26, 27]]]
            >>> A.shape
            (3, 3, 3)
            >>> S = A[0]
            >>> del A[1]
            >>> print A.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[19, 20, 21],
              [22, 23, 24],
              [25, 26, 27]]]
            >>> A.shape
            (2, 3, 3)
            >>> S == A[0]
            True
            >>> S is A[0]
            True
            >>> del A[-1]
            >>> print A.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]]]
            >>> A.shape
            (1, 3, 3)
            >>> del A[None, None, 1:3]
            >>> print A.formated()
            [[[1],
              [4],
              [7]]]
            >>> A.shape
            (1, 3, 1)
            >>> del A[None, 1:3]
            >>> print A.formated()
            [[[1]]]
            >>> A.shape
            (1, 1, 1)
            >>> del A[-1]
            >>> print A.formated()
            []
            >>> A.shape
            (0,)
        """
        # TODO : how to interpret slices (get rid of the "None" thing ?)
        #
        # >>> A = Array(xrange(1, 10), shape=(3, 3))
        # >>> print A.formated()
        # [[1, 2, 3],
        #  [4, 5, 6],
        #  [7, 8, 9]]
        # >>> del A[:, -1]
        # >>> print A.formated()
        # [[1, 2],
        #  [4, 5],
        #  [7, 8]]

        index = self._getindex(index, default=None, expand=True)
        # TODO : check what shape it would yield first
        if index :
            self._delete(index)
            self._cacheshape()
            if not self.__class__._shapecheck(self.shape) :
                raise TypeError, "deleting %s from an instance of class %s will make it incompatible with class shape" % (index, clsname(self))

    def __delslice__(self, start):
        """ deprecated and __setitem__ should accept slices anyway """
        self.__delitem__(slice(start, end))

    def deleted(self, *args):
        """ a.deleted(index) --> Array

            Returns a copy (deepcopy) of a with the elements designated by index deleted,
            as in a.__delitem__(index).

            Note : as opposed to a.stripped(index), do not collapse dimensions of the Array
            that end up with only one sub-array.

            >>> A = Array(xrange(1, 28), shape=(3, 3, 3))
            >>> print A.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[10, 11, 12],
              [13, 14, 15],
              [16, 17, 18]],
            <BLANKLINE>
             [[19, 20, 21],
              [22, 23, 24],
              [25, 26, 27]]]
            >>> A.shape
            (3, 3, 3)
            >>> B = A.deleted(1)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[19, 20, 21],
              [22, 23, 24],
              [25, 26, 27]]]
            >>> B.shape
            (2, 3, 3)
            >>> B[0] == A[0]
            True
            >>> B[0] is A[0]
            False
            >>> B = B.deleted(-1)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]]]
            >>> B.shape
            (1, 3, 3)
            >>> B = B.deleted(None, None, slice(1, 3))
            >>> print B.formated()
            [[[1],
              [4],
              [7]]]
            >>> B.shape
            (1, 3, 1)
            >>> B = B.deleted((None, slice(1, 3)))
            >>> print B.formated()
            [[[1]]]
            >>> B.shape
            (1, 1, 1)
            >>> B = B.deleted(-1)
            >>> print B.formated()
            []
            >>> B.shape
            (0,)
        """
        cls = self.__class__
        index = self._getindex(args, default=None, expand=True)
        if index :
            new = Array(self.deepcopy())
            new._delete(index)
            new._cacheshape()
            return cls._convert(new)

    def _strip(self, index) :
        ls = len(self)
        li = len(index)
        if ls and li :
            next = li > 1
            for i in xrange(ls-1, -1, -1) :
                if i in index[0] :
                    self.apicls.__delitem__(self.data, i)
                    # self._cacheshape()
                elif next :
                    self[i]._strip(index[1:])
            if len(self) == 1 and hasattr(self[0], '__iter__') :
                self.assign(self[0])

    def strip(self, *args) :
        """ a.strip(index)

            Strip the elements designated by index from a.

            Note : as opposed to a.__delete__(index), will collapse dimensions of the Array
            that end up with only one sub-array.

            >>> A = Array(xrange(1, 28), shape=(3, 3, 3))
            >>> print A.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[10, 11, 12],
              [13, 14, 15],
              [16, 17, 18]],
            <BLANKLINE>
             [[19, 20, 21],
              [22, 23, 24],
              [25, 26, 27]]]
            >>> A.shape
            (3, 3, 3)
            >>> S = A[0]
            >>> A.strip(1)
            >>> print A.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[19, 20, 21],
              [22, 23, 24],
              [25, 26, 27]]]
            >>> S == A[0]
            True
            >>> S is A[0]
            True
            >>> A.strip(-1)
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> S == A
            True
            >>> S is A
            False
            >>> S[0] == A[0]
            True
            >>> S[0] is A[0]
            True
            >>> A.strip(None, slice(1,3))
            >>> print A.formated()
            [[1],
             [4],
             [7]]
            >>> A.strip(-1)
            >>> print A.formated()
            [[1],
             [4]]
            >>> A.strip(-1)
            >>> print A.formated()
            [1]
            >>> A.strip(-1)
            >>> print A.formated()
            []
        """
        index = self._getindex(args, default=None, expand=True)
        # TODO : check what shape it would yield first
        if index :
            self._strip(index)
            self._cacheshape()
            if not self.__class__._shapecheck(self.shape) :
                raise TypeError, "stripping %s from an instance of class %s will make it incompatible with class shape" % (index, clsname(self))

    def stripped(self, *args):
        """ a.stripped(index) --> Array

            Returns a copy (deepcopy) of a with the elements designated by index stripped,
            as in a.strip(index)

            Note : as opposed to a.deleted(index), will collapse dimensions of the Array
            that end up with only one sub-array.

            >>> A = Array(xrange(1, 28), shape=(3, 3, 3))
            >>> print A.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[10, 11, 12],
              [13, 14, 15],
              [16, 17, 18]],
            <BLANKLINE>
             [[19, 20, 21],
              [22, 23, 24],
              [25, 26, 27]]]
            >>> A.shape
            (3, 3, 3)
            >>> B = A.stripped(1)
            >>> print B.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[19, 20, 21],
              [22, 23, 24],
              [25, 26, 27]]]
            >>> B[0] == A[0]
            True
            >>> B[0] is A[0]
            False
            >>> B = B.stripped(-1)
            >>> print B.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> B == A[0]
            True
            >>> B is A[0]
            False
            >>> B[0] == A[0, 0]
            True
            >>> B[0] is A[0,0]
            False
            >>> B = B.stripped(None, slice(1,3))
            >>> print B.formated()
            [[1],
             [4],
             [7]]
            >>> B = B.stripped(-1)
            >>> print B.formated()
            [[1],
             [4]]
            >>> B = B.stripped(-1)
            >>> print B.formated()
            [1]
            >>> B = B.stripped(-1)
            >>> print B.formated()
            []
        """
        cls = self.__class__
        index = self._getindex(args, default=None, expand=True)
        if index :
            new = self.deepcopy()
            new._strip(index)
            new._cacheshape()
            return cls._convert(new)

    def __iter__(self, *args, **kwargs) :
        """ a.__iter__(*args, **kwargs) <==> iter(a, *args, **kwargs)

            Default Array storage class iterator, operates on first axis only

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> [a for a in A]
            [Array([1, 2, 3]), Array([4, 5, 6]), Array([7, 8, 9])]
        """
        return self.apicls.__iter__(self.data, *args, **kwargs)

    def axisiter(self, *args) :
        """ a.axisiter([axis1[, axis2[, ...]]]) --> ArrayIter

            Returns an iterator using a specific axis or list of ordered axis.
            It is equivalent to transposing the Array using these ordered axis and iterating
            on the new Array for the remaining sub array dimension

            Note : ArrayIter ierators support __len__, __getitem__ and __setitem__

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> [a for a in A]
            [Array([1, 2, 3]), Array([4, 5, 6]), Array([7, 8, 9])]
            >>> [a for a in A.axisiter(0)]
            [Array([1, 2, 3]), Array([4, 5, 6]), Array([7, 8, 9])]
            >>> [a for a in A.axisiter(1)]
            [Array([1, 4, 7]), Array([2, 5, 8]), Array([3, 6, 9])]
            >>> [a for a in A.axisiter(0,1)]
            [1, 2, 3, 4, 5, 6, 7, 8, 9]
            >>> [a for a in A.axisiter(1,0)]
            [1, 4, 7, 2, 5, 8, 3, 6, 9]
        """
        return ArrayIter(self, *args)

    def subiter(self, dim=None) :
        """ a.subiter([dim=None]) --> ArrayIter

            Returns an iterator on all sub Arrays for a specific sub Array number of dimension.

            a.subiter(0) is equivalent to a.flat: lista sub-arrays of dimension 0, ie components
            a.subiter() is equivalent to self.subiter(self.ndim-1) and thus to self.__iter__()

            Note : ArrayIter iterators support __len__, __getitem__ and __setitem__

            >>> A = Array(range(1, 28), shape=(3, 3, 3))
            >>> print A.formated()
            [[[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]],
            <BLANKLINE>
             [[10, 11, 12],
              [13, 14, 15],
              [16, 17, 18]],
            <BLANKLINE>
             [[19, 20, 21],
              [22, 23, 24],
              [25, 26, 27]]]
            >>> [a for a in A.subiter(0)]
            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]
            >>> [a for a in A.subiter(1)]
            [Array([1, 2, 3]), Array([4, 5, 6]), Array([7, 8, 9]), Array([10, 11, 12]), Array([13, 14, 15]), Array([16, 17, 18]), Array([19, 20, 21]), Array([22, 23, 24]), Array([25, 26, 27])]
            >>> [a for a in A.subiter(2)]
            [Array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), Array([[10, 11, 12], [13, 14, 15], [16, 17, 18]]), Array([[19, 20, 21], [22, 23, 24], [25, 26, 27]])]
            >>> [a for a in A.subiter(3)]
            Traceback (most recent call last):
                ...
            ValueError: can only iterate for a sub-dimension inferior to Array's number of dimensions 3
        """
        ndim = self.ndim
        if dim is None :
            dim = ndim - 1
        iter_ndim = ndim - dim
        if iter_ndim > 0 :
            axis = tuple(x for x in xrange(iter_ndim))
            # print "subiter called on dim = %s, axis %s" % (dim, axis)
            return ArrayIter(self, axis)
        else :
            raise ValueError, "can only iterate for a sub-dimension inferior to Array's number of dimensions %s" % (ndim)

    @property
    def flat(self):
        """ a.flat --> ArrayIter

            Flat iterator on all components of the Array

            Note : ArrayIter iterators support __len__, __getitem__ and __setitem__

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> [a for a in A]
            [Array([1, 2, 3]), Array([4, 5, 6]), Array([7, 8, 9])]
            >>> [a for a in A.flat]
            [1, 2, 3, 4, 5, 6, 7, 8, 9]
            >>> A.flat[5:10] = [4, 3, 2, 1]
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 4],
             [3, 2, 1]]
        """
        return self.subiter(0)

    def _iterable_convert(self, itertype):
        return itertype(x._iterable_convert(itertype) if isinstance(x, Array)
                        else x for x in self)

    def tolist(self):
        """ a.tolist() --> list

            Returns that Array converted to a nested list

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print repr(A)
            Array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
            >>> print repr(list(A))
            [Array([1, 2, 3]), Array([4, 5, 6]), Array([7, 8, 9])]
            >>> print repr(A.tolist())
            [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
        """
        return self._iterable_convert(list)

    def totuple(self):
        """ a.totuple() --> tuple

            Returns that Array converted to a nested tuple

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print repr(A)
            Array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
            >>> print repr(tuple(A))
            (Array([1, 2, 3]), Array([4, 5, 6]), Array([7, 8, 9]))
            >>> print repr(A.totuple())
            ((1, 2, 3), (4, 5, 6), (7, 8, 9))
        """
        return self._iterable_convert(tuple)

    # mark this as unhashable, since it's mutable - if you need a hashable
    # representation, use totuple
    __hash__ = None

    def ravel(self):
        """ a.ravel() <==> Array(a.flat)

            Returns that Array flattened as to a one-dimensional array.

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print repr(A.ravel())
            Array([1, 2, 3, 4, 5, 6, 7, 8, 9])
        """
        return Array(self.flat)

    def __contains__(self, value):
        """ a.__contains__(b) <==> b in a

            Returns True if at least one of the sub-Arrays of a (down to individual components) is equal to b,
            False otherwise

            >>> A = Array(list(range(1, 6))+list(range(4, 0, -1)), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 4],
             [3, 2, 1]]
            >>> 5 in A
            True
            >>> [1, 2, 3] in A
            True
            >>> [1, 2] in A
            False
            >>> Array([[1, 2], [4, 5]]) in A
            False

            This behavior is unlike numpy arrays (where it would return True), but like builtin list

            >>> A in A
            False

            TODO :
            #>>> [1, 4, 3] in A
            #True
            #>>> [[1], [4], [3]] in A
            #True
        """
        shape = self.shape
        ndim = self.ndim
        if shape != () :
            value = _toCompOrArray(value)
            vshape, vdim, vsize = _shapeInfo(value)
            if vdim < ndim and self.shape[ndim-vdim:] == vshape[:] :
                for sub in self.subiter(vdim) :
                    if sub == value :
                        return True
        return False

    def count(self, value):
        """ a.count(b) --> int

            Returns the number of occurrences of b in a.

            >>> A = Array(list(range(1, 6))+list(range(4, 0, -1)), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 4],
             [3, 2, 1]]
            >>> A.count(5)
            1
            >>> A.count(4)
            2
            >>> A.count([1, 2, 3])
            1
            >>> A.count([1, 2])
            0
        """

        # TODO : like numpy count for column occurrences ?
        # >>> A.count([1, 4, 3])
        # 1
        # >>> A.count([[1], [4], [3]])
        # 1
        # >>> A.count(A)
        # 0


        res = 0
        shape = self.shape
        ndim = self.ndim
        if shape != () :
            value = _toCompOrArray(value)
            vshape, vdim, vsize = _shapeInfo(value)
            if vdim < ndim and self.shape[ndim-vdim:] == vshape[:] :
                for sub in self.subiter(vdim) :
                    if sub == value :
                        res += 1
        return res

    def index(self, value) :
        """ a.index(b) --> int or tuple

            Returns the index of the first occurrence of b in a.

            >>> A = Array(list(range(1, 6))+list(range(4, 0, -1)), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 4],
             [3, 2, 1]]
            >>> A.index(5)
            (1, 1)
            >>> A.index(4)
            (1, 0)
            >>> A.index([1, 2, 3])
            (0,)
            >>> A.index([1, 2])
            Traceback (most recent call last):
                ...
            ValueError: Array.index(x): x not in Array
        """

        # TODO : like numpy also search for column occurrences ?
        # >>> A.index([1, 4, 3])
        # 1
        # >>> A.index([[1], [4], [3]])
        # 1
        # >>> A.index(A)
        # Traceback (most recent call last):
        #     ...
        # ValueError: Array.index(x): x not in Array

        shape = self.shape
        ndim = self.ndim
        if shape != () :
            value = _toCompOrArray(value)
            vshape, vdim, vsize = _shapeInfo(value)
            if vdim < ndim and self.shape[ndim-vdim:] == vshape[:] :
                siter = self.subiter(vdim)
                for i, sub in enumerate(siter) :
                    if sub == value :
                        return siter.toArrayCoords(i)
        raise ValueError, "%s.index(x): x not in %s" % (clsname(self), clsname(self))

    # arithmetics and operators

    def __coerce__(self, other):
        """ coerce(a, b) -> (a1, b1)

            Return a tuple consisting of the two numeric arguments converted to
            a common type and shape, using the same rules as used by arithmetic operations.
            If coercion is not possible, return NotImplemented.

            b is cast to Array when possible

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> nA, nB = coerce(A, 1)
            >>> print nA.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> print nB.formated()
            [[1, 1, 1],
             [1, 1, 1],
             [1, 1, 1]]
            >>> nA, nB = coerce(A, [1, 2, 3])
            >>> print nA.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> print nB.formated()
            [[1, 2, 3],
             [1, 2, 3],
             [1, 2, 3]]

            Arguments can only be expanded, not truncated to avoid silent loss of data.

            >>> A = Array(range(4), shape=(2, 2))
            >>> nA, nB = coerce(A, [1, 2, 3, 4, 5])
            Traceback (most recent call last):
                ...
            TypeError: number coercion failed

            TODO : would be more explicit to get :
            TypeError: Array of shape (2, 2) and Array of shape (5,) cannot be converted to an common Array instance of same shape

            Arrays of dissimular shape are cast to same shape when possible, smallest size is cast to largest

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> B = Array(range(1, 5), shape=(2, 2))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> print B.formated()
            [[1, 2],
             [3, 4]]
            >>> nA, nB = coerce(A, B)
            >>> print nA.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> print nB.formated()
            [[1, 2, 0],
             [3, 4, 0],
             [0, 0, 0]]

            When coerce(x, y) is not doable, it defers to coerce(y, x)

            >>> nB, nA = coerce(B, A)
            >>> print nA.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> print nB.formated()
            [[1, 2, 0],
             [3, 4, 0],
             [0, 0, 0]]

            And does not raise an excepetion like :
                Traceback (most recent call last):
                    ...
                TypeError: Array of shape (2, 2) and Array of shape (3, 3) cannot be converted to an common Array instance of same shape
            as it could be expected without this __coerce__ mechanism.

            When mixing Array derived types, result are cast to the first base class of either argument that accepts both shapes,
            ie 'deepest' derived class is tried first, MatrixN before Array, etc.

            >>> A = Array(range(1, 10), shape=(3, 3))
            >>> M = MatrixN(range(1, 10), shape=(3, 3))
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> print M.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> nA, nM = coerce(A, M)
            >>> print repr(nA)
            MatrixN([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
            >>> print repr(nM)
            MatrixN([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
            >>> nM, nA = coerce(M, A)
            >>> print repr(nA)
            MatrixN([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
            >>> print repr(nM)
            MatrixN([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

            This allows to implement a common behavior for element-wise arithmetics between Arrays of same
            or dissimilar shapes, Arrays and types derived from Arrays, Arrays and numerics or iterables of numerics.

            All operators on Arrays that take 2 operands and work element-wise follow the following rules :

            Operands are cast to Array when possible

            >>> A = Array(range(4), shape=(2, 2))
            >>> print (A).formated()
            [[0, 1],
             [2, 3]]
            >>> print (A+1).formated()
            [[1, 2],
             [3, 4]]
            >>> print (A+[1, 2]).formated()
            [[1, 3],
             [3, 5]]

            Operands can only be expanded, not truncated to avoid silent loss of data.

            >>> print (A+[1, 2, 3, 4, 5]).formated()
            Traceback (most recent call last):
                ...
            TypeError: unsupported operand type(s) for +: 'Array' and 'list'

            TODO : it would be more explicit to get more specific error messages, like :
                TypeError: Array of shape (2, 2) and Array of shape (5,) cannot be converted to an common Array instance of same shape

            Arrays of dissimilar shape are cast to same shape by Array.__coerce__ if possible.

            >>> A = Array(range(9), shape=(3, 3))
            >>> B = Array(range(10, 50, 10), shape=(2, 2))
            >>> print (A+B).formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(A+B)
            Array

            As Array.__coerce__ cannot truncate data, it will defer to the other operand's __coerce__ if it exists,
            then to its 'right operation' (here __radd__) method if it exists and is defined for an Array left operand.

            >>> A = Array(range(10, 50, 10), shape=(2, 2))
            >>> B = Array(range(9), shape=(3, 3))
            >>> print (A+B).formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(A+B)
            Array

            Result is cast to the first applicable Array herited type of either operand

            >>> A = Array(range(9), shape=(3, 3))
            >>> M = MatrixN(range(10, 50, 10), shape=(2, 2))
            >>> print (A+M).formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(A+M)
            MatrixN
            >>> print (M+A).formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(M+A)
            MatrixN

            >>> A = Array(range(10, 50, 10), shape=(2, 2))
            >>> M = MatrixN(range(9), shape=(3, 3))
            >>> print (A+M).formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(A+M)
            MatrixN
            >>> print (M+A).formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(M+A)
            MatrixN

            Here result is cast to Array as a MatrixN can't have 3 dimensions

            >>> A = Array(range(10, 190, 10), shape=(2, 3, 3))
            >>> M = MatrixN(range(9), shape=(3, 3))
            >>> print (A+M).formated()
            [[[10, 21, 32],
              [43, 54, 65],
              [76, 87, 98]],
            <BLANKLINE>
             [[100, 111, 122],
              [133, 144, 155],
              [166, 177, 188]]]
            >>> print clsname(A+M)
            Array
            >>> print (M+A).formated()
            [[[10, 21, 32],
              [43, 54, 65],
              [76, 87, 98]],
            <BLANKLINE>
             [[100, 111, 122],
              [133, 144, 155],
              [166, 177, 188]]]
            >>> print clsname(M+A)
            Array

            There are cases where no type coercion is possible, as it would truncate data or reduce number
            of dimensions in either way, use an explicit conversion (trim, size, etc.) in that case :

            >>> A = Array(range(8), shape=(2, 2, 2))
            >>> M = MatrixN(range(9), shape=(3, 3))
            >>> print (A+M).formated()
            Traceback (most recent call last):
                ...
            TypeError: unsupported operand type(s) for +: 'Array' and 'MatrixN'

            TODO : return some more explicit messages in these cases

        """

        # print "coerce Array"
        if type(other) == type(self) :
            if len(other) == len(self) and other.shape == self.shape :
                return self, other
        else :
            try :
                other = _toCompOrArrayInstance(other)
            except :
                # returning NotImplemented defers to other.__coerce__(self) if applicable
                # raise TypeError, "%s is not convertible to an Array instance" % (clsname(other))
                return NotImplemented

        ocls = other.__class__
        scls = self.__class__
        # convert to most specific class if possible (MatrixN before Array, etc)
        if issubclass(ocls, scls) :
            mro = inspect.getmro(ocls)
        else :
            mro = inspect.getmro(scls)
        nself = None
        nother = None
        # always try to conform to shape of self, if it fails, will defer to coerce(other, self) anyway
        for c in mro :
            if issubclass(c, Array) :
                try :
                    nself = c(self)
                    nother = c(other, shape=nself.shape)
                    assert len(nself) == len(nother) and nself.shape == nother.shape
                    break;
                except :
                    pass

        if nself is not None and nother is not None :
            return nself, nother
        else :
            # raise TypeError, "%s of shape %s cannot be cast to a %s of shape %s or any common Array derived class of that shape" % (clsname(other), other.shape, clsname(self), self.shape)
            # returning NotImplemented instead of raising an exception defers to other.__coerce__(self) if applicable
            # TOTO : some more explicit error messages ?
            return NotImplemented

    # common operators

    def __eq__(self, other):
        """ a.__equ__(b) <==> a == b

            Equivalence operator, will only work for exact same type of a and b, check isEquivalent method to have it
            convert a and b to a common type (if possible).

            >>> Array(range(4), shape=(4)) == Array(range(4), shape=(1, 4))
            False
            >>> Array(range(4), shape=(2, 2)) == Array(range(4), shape=(2, 2))
            True
            >>> Array(range(4), shape=(2, 2)) == MatrixN(range(4), shape=(2, 2))
            False
        """
        if type(self) != type(other) :
            return False
        if self.shape != other.shape :
            return False
        return reduce(lambda x, y : x and y[0]==y[1], itertools.izip(self, other), True )
    def __ne__(self, other):
        """ a.__ne__(b) <==> a != b

            a.__ne__(b) returns not a.__equ__(b).

            >>> Array(range(4), shape=(4)) != Array(range(4), shape=(1, 4))
            True
            >>> Array(range(4), shape=(2, 2)) != Array(range(4), shape=(2, 2))
            False
            >>> Array(range(4), shape=(2, 2)) != MatrixN(range(4), shape=(2, 2))
            True
        """
        return (not self.__eq__(other))
    __neq__ = __ne__
    def __abs__(self):
        """ a.__abs__() <==> abs(a)

            Element-wise absolute value of a.

            >>> A = Array([[complex(1, 2), complex(2, 3)], [complex(4, 5), complex(6, 7)]])
            >>> print abs(A).formated()
            [[2.2360679775, 3.60555127546],
             [6.40312423743, 9.21954445729]]
            >>> A = Array(-1, 2, -3)
            >>> print repr(abs(A))
            Array([1, 2, 3])
        """
        return self.__class__(abs(x) for x in self)
    def __invert__(self):
        """ a.__invert__() <==> ~a

            Element-wise invert of a, as with '~', operator 'invert'

            >>> A = Array(range(4), shape=(2, 2))
            >>> print (~A).formated()
            [[-1, -2],
             [-3, -4]]
        """
        return self.__class__(operator.invert(x) for x in self)
    def __round__(self, ndigits=0):
        """ a.__round__([ndigits]) <==> round(a[, ndigits])

            Element-wise round to given precision in decimal digits (default 0 digits).
            This always returns an Array of floating point numbers.  Precision may be negative.

            >>> A = Array([1.0/x for x in range(1, 10)], shape=(3, 3))
            >>> print round(A, 2).formated()
            [[1.0, 0.5, 0.33],
             [0.25, 0.2, 0.17],
             [0.14, 0.13, 0.11]]
        """
        return self.__class__(round(x, ndigits) for x in self)
    def __pos__(self):
        """ a.__pos__() <==> +a

            Element-wise positive of a

            >>> A = Array(range(4), shape=(2, 2))
            >>> print (+A).formated()
            [[0, 1],
             [2, 3]]
        """
        return self.__class__(operator.pos(x) for x in self)
    def __neg__(self):
        """ a.__neg__() <==> -a

            Element-wise negation of a

            >>> A = Array(range(4), shape=(2, 2))
            >>> print (-A).formated()
            [[0, -1],
             [-2, -3]]
        """
        return self.__class__(operator.neg(x) for x in self)
    def __add__(self, other) :
        """ a.__add__(b) <==> a+b

            Returns the result of the element wise addition of a and b if b is convertible to Array,
            adds b to every component of a if b is a single numeric value

            Note : when the operands are 2 Arrays of different shapes, both are cast to the shape of largest size
            if possible. Created components are filled with class default value.

            Related : See the Array.__coerce__ method

            >>> A = Array(range(4), shape=(2, 2))
            >>> print (A).formated()
            [[0, 1],
             [2, 3]]
            >>> print (A+1).formated()
            [[1, 2],
             [3, 4]]
            >>> print (A+[1, 2]).formated()
            [[1, 3],
             [3, 5]]
            >>> A = Array(range(9), shape=(3, 3))
            >>> M = MatrixN(range(10, 50, 10), shape=(2, 2))
            >>> print (A+M).formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(A+M)
            MatrixN
            >>> A = Array(range(10, 50, 10), shape=(2, 2))
            >>> M = MatrixN(range(9), shape=(3, 3))
            >>> print (A+M).formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(A+M)
            MatrixN
        """
        try :
            nself, nother = coerce(self, other)
        except :
            # returning NotImplemented on self.__oper__(other) defers to other.__roper__(self) UNLESS self and other are of the same type
            return NotImplemented
        res = map(operator.add, nself, nother)
        return nself.__class__._convert(res)
    def __radd__(self, other) :
        """ a.__radd__(b) <==> b+a

            Returns the result of the element wise addition of a and b if b is convertible to Array,
            adds b to every component of a if b is a single numeric value

            Note : when the operands are 2 Arrays of different shapes, both are cast to the shape of largest size
            if possible. Created components are filled with class default value.

            Related : See the Array.__coerce__ method

            >>> A = Array(range(4), shape=(2, 2))
            >>> print (A).formated()
            [[0, 1],
             [2, 3]]
            >>> print (1+A).formated()
            [[1, 2],
             [3, 4]]
            >>> print ([1, 2]+A).formated()
            [[1, 3],
             [3, 5]]
            >>> A = Array(range(9), shape=(3, 3))
            >>> M = MatrixN(range(10, 50, 10), shape=(2, 2))
            >>> print (M+A).formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(M+A)
            MatrixN
            >>> A = Array(range(10, 50, 10), shape=(2, 2))
            >>> M = MatrixN(range(9), shape=(3, 3))
            >>> print (M+A).formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(M+A)
            MatrixN
        """
        return self.__add__(other)
    def __iadd__(self, other):
        """ a.__iadd__(b) <==> a += b

            In place addition of a and b, see __add__, result must fit a's type

            >>> A = Array(range(9), shape=(3, 3))
            >>> M = MatrixN(range(10, 50, 10), shape=(2, 2))
            >>> A += M
            >>> print A.formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(A)
            Array
            >>> A = Array(range(9), shape=(3, 3))
            >>> M = MatrixN(range(10, 50, 10), shape=(2, 2))
            >>> M += A
            >>> print M.formated()
            [[10, 21, 2],
             [33, 44, 5],
             [6, 7, 8]]
            >>> print clsname(M)
            MatrixN

            Result must be castable to the type of a

            >>> A = Array(range(12), shape=(2, 3, 2))
            >>> M = MatrixN(range(9), shape=(3, 3))
            >>> B = M + A
            >>> print B.formated()
            [[[0, 2],
              [4, 6],
              [8, 10]],
            <BLANKLINE>
             [[12, 14],
              [16, 9],
              [10, 11]]]
            >>> print clsname(B)
            Array
            >>> M += A
            Traceback (most recent call last):
                ...
            TypeError: cannot cast a Array of shape (2, 3, 2) to a MatrixN of shape (2, 6),
            as it would truncate data or reduce the number of dimensions
        """
        return self.__class__(self + other)
    def __sub__(self, other) :
        """ a.__sub__(b) <==> a-b
            Returns the result of the element wise substraction of b from a if b is convertible to Array,
            substracts b from every component of a if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.sub, nself, nother)
        return self.__class__._convert(res)
    def __rsub__(self, other) :
        """ a.__rsub__(b) <==> b-a
            Returns the result of the element wise substraction of a from b if b is convertible to Array,
            replace every component c of a by b-c if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.sub, nother, nself)
        return self.__class__._convert(res)
    def __isub__(self, other):
        """ a.__isub__(b) <==> a -= b
            In place substraction of a and b, see __sub__, result must fit a's type """
        return self.__class__(self.__sub__(other))
    def __mul__(self, other) :
        """ a.__mul__(b) <==> a*b
            Returns the result of the element wise multiplication of a and b if b is convertible to Array,
            multiplies every component of a by b if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.mul, nself, nother)
        return self.__class__._convert(res)
    def __rmul__(self, other):
        """ a.__mul__(b) <==> b*a
            Returns the result of the element wise multiplication of a and b if b is convertible to Array,
            multiplies every component of a by b if b is a single numeric value """
        return self.__mul__(other)
    def __imul__(self, other):
        """ a.__imul__(b) <==> a *= b
            In place multiplication of a and b, see __mul__, result must fit a's type """
        return self.__class__(self.__mul__(other))
    def __pow__(self, other, modulo=None):
        """ a.__pow__(b[, modulo]) <==> a**b or (a**b) % modulo
            With two arguments, equivalent to a**b.  With three arguments, equivalent to (a**b) % modulo, but may be more efficient (e.g. for longs).
            Returns the result of the element wise elevation to power of a by b if b is convertible to Array,
            elevates every component of a to power b if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(lambda x,y:x.__pow__(y, modulo), nself, nother)
        return self.__class__._convert(res)
    def __rpow__(self, other):
        """ a.__rpow__(b[, modulo]) <==> b**a or (b**a) % modulo
            With two arguments, equivalent to b**a.  With three arguments, equivalent to (b**a) % modulo, but may be more efficient (e.g. for longs).
            Returns the result of the element wise elevation to power of b by a if b is convertible to Array,
            replaces every component c of a by b elevated to power c if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(lambda x,y:x.__pow__(y, modulo), nother, nself)
        return self.__class__._convert(res)
    def __ipow__(self, other, modulo=None):
        """ a.__ipow__(b[, modulo]) <==> a**=b or a = (a**b) % modulo
            In place elevation to power of a by b, see __pow__, result must fit a's type """
        return self.__class__(self.__pow__(other, modulo))
    def __div__(self, other) :
        """ a.__div__(b) <==> a/b
            The division operator (/) is implemented by these methods. The __truediv__() method is used
            when __future__.division is in effect, otherwise __div__() is used.
            Returns the result of the element wise division of a by b if b is convertible to Array,
            divides every component of a by b if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.div, nself, nother)
        return self.__class__._convert(res)
    def __rdiv__(self, other) :
        """ a.__rdiv__(b) <==> b/a
            The division operator (/) is implemented by these methods. The __truediv__() method is used
            when __future__.division is in effect, otherwise __div__() is used.
            Returns the result of the element wise division of b by a if b is convertible to Array,
            replaces every component c of a by b/c if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.div, nother, nself)
        return self.__class__._convert(res)
    def __idiv__(self, other):
        """ a.__idiv__(b) <==> a /= b
            The division operator (/) is implemented by these methods. The __truediv__() method is used
            when __future__.division is in effect, otherwise __div__() is used.
            In place division of a by b, see __div__, result must fit a's type """
        return self.__class__(self.__div__(other))
    def __truediv__(self, other) :
        """ a.__truediv__(b) <==> a/b
            The division operator (/) is implemented by these methods. The __truediv__() method is used
            when __future__.division is in effect, otherwise __div__() is used.
            Returns the result of the element wise true division of a by b if b is convertible to Array,
            performs true division of every component of a by b if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.truediv, nself, nother)
    def __rtruediv__(self, other) :
        """ a.__rtruediv__(b) <==> b/a
            The division operator (/) is implemented by these methods. The __rtruediv__() method is used
            when __future__.division is in effect, otherwise __rdiv__() is used.
            Returns the result of the element wise true division of b by a if b is convertible to Array,
            replaces every component c of a by b/c if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.truediv, nother, nself)
    def __itruediv__(self, other):
        """ a.__itruediv__(b) <==> a /= b
            In place true division of a by b, see __truediv__, result must fit a's type """
        return self.__class__(self.__truediv__(other))
    def __floordiv__(self, other) :
        """ a.__floordiv__(b) <==> a//b
            Returns the result of the element wise floor division of a by b if b is convertible to Array,
            performs floor division of every component of a by b if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.floordiv, nself, nother)
    def __rfloordiv__(self, other) :
        """ a.__rfloordiv__(b) <==> b//a
            Returns the result of the element wise floor division of b by a if b is convertible to Array,
            replaces every component c of a by b//c if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.floordiv, nother, nself)
    def __ifloordiv__(self, other):
        """ a.__ifloordiv__(b) <==> a //= b
            In place true division of a by b, see __floordiv__, result must fit a's type """
        return self.__class__(self.__floordiv__(other))
    def __mod__(self, other) :
        """ a.__mod__(b) <==> a%b
            Returns the result of the element wise modulo of a by b if b is convertible to Array,
            performs modulo of every component of a by b if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.mod, nself, nother)
    def __rmod__(self, other) :
        """ a.__rmod__(b) <==> b%a
            Returns the result of the element wise modulo of b by a if b is convertible to Array,
            replaces every component c of a by b%c if b is a single numeric value """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        res = map(operator.mod, nother, nself)
    def __imod__(self, other):
        """ a.__imod__(b) <==> a %= b
            In place modulo of a by b, see __mod__, result must fit a's type """
        return self.__class__(self.__mod__(other))

    # more could be wrapped the same way, __divmod__, etc

    # additional methods that defer to a generic function patched to accept iterables

    def sum(self, *args, **kwargs):
        """ a.sum([axis0[, axis1[, ...[, start=0]]]]) <=> sum(a, start=start, axis=(axis0, axis1, ...))

            Returns the sum of all the components of a, plus start.
            If axis are specified will return an Array of sum(x) for x in a.axisiter(*axis), else will
            sum on all axis of a.

            >>> A = Array([[1,2,3],[4,5,6]])
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6]]
            >>> A.sum()
            21
            >>> A.sum(0, 1)
            21
            >>> A.sum(0)
            Array([5, 7, 9])
            >>> A.sum(1)
            Array([6, 15])
        """
        return sum(self, start=kwargs.get('start', 0), axis=kwargs.get('axis', args))
    def prod(self, *args, **kwargs):
        """ a.prod([axis0[, axis1[, ...[, start=0]]]]) <=> prod(a, start=start, axis=(axis0, axis1, ...))

            Returns the product of all the components of a, an iterable of values that support the mul operator, times start.
            If axis are specified will return an Array of prod(x) for x in a.axisiter(*axis).

            >>> A = Array([[1,2,3],[4,5,6]])
            >>> print A.formated()
            [[1, 2, 3],
             [4, 5, 6]]
            >>> A.prod()
            720
            >>> A.prod(0, 1)
            720
            >>> A.prod(0)
            Array([4, 10, 18])
            >>> A.prod(1)
            Array([6, 120])
        """
        return prod(self, start=kwargs.get('start', 1), axis=kwargs.get('axis', args))
    # __nonzero__ is not defined, use any or all
    def any(self, *args, **kwargs):
        """ a.any([axis0[, axis1[, ...]]]) <=> any(a, axis=(axis0, axis1, ...))

            Returns True if any of the components of iterable a evaluate to True.
            If axis are specified will return an Array of any(x) for x in a.axisiter(*axis).

            >>> A = Array([[False,True,True],[False,True,False]])
            >>> print A.formated()
            [[False, True, True],
             [False, True, False]]
            >>> A.any()
            True
            >>> A.any(0, 1)
            True
            >>> A.any(0)
            Array([False, True, True])
            >>> A.any(1)
            Array([True, True])
        """
        return any(self, axis=kwargs.get('axis', args))
    def all(self, *args, **kwargs):
        """ a.all([axis0[, axis1[, ...]]]) <=> all(a, axis=(axis0, axis1, ...))

            Returns True if all the components of iterable a evaluate to True.
            If axis are specified will return an Array of all(x) for x in a.axisiter(*axis).

            >>> A = Array([[True,True,True],[False,True,False]])
            >>> print A.formated()
            [[True, True, True],
             [False, True, False]]
            >>> A.all()
            False
            >>> A.all(0, 1)
            False
            >>> A.all(0)
            Array([False, True, False])
            >>> A.all(1)
            Array([True, False])
        """
        return all(self, axis=kwargs.get('axis', args))
    def min(self, *args, **kwargs):
        """ a.min([axis0[, axis1[, ...[, key=func]]]])  <==> min(a[, key=func[, axis=(axis0, axis1, ...)]])

            Returns the smallest component of a.
            If axis are specified will return an Array of element-wise min(x) for x in a.axisiter(*axis).

            >>> A = Array([[6,3,4],[1,5,0.5]])
            >>> print A.formated()
            [[6, 3, 4],
             [1, 5, 0.5]]
            >>> A.min()
            0.5
            >>> A.min(0, 1)
            0.5
            >>> A.min(0)
            Array([1, 3, 0.5])
            >>> A.min(1)
            Array([3, 0.5])
        """
        return min(self, axis=kwargs.get('axis', args), key=kwargs.get('key', None))
    def max(self, *args, **kwargs):
        """ a.max([axis0[, axis1[, ...[, key=func]]]])  <==> max(a[, key=func[, axis=(axis0, axis1, ...)]])

            Returns the greatest component of a.
            If axis are specified will return an Array of element-wise max(x) for x in a.axisiter(*axis).

            >>> A = Array([[6,3,4],[1,5,0.5]])
            >>> print A.formated()
            [[6, 3, 4],
             [1, 5, 0.5]]
            >>> A.max()
            6
            >>> A.max(0,1)
            6
            >>> A.max(0)
            Array([6, 5, 4])
            >>> A.max(1)
            Array([6, 5])
        """
        return max(self, axis=kwargs.get('axis', args), key=kwargs.get('key', None))

    # methods that are defined per Array class to allow overloading

    def sqlength(self, *args):
        """ a.sqlength(axis0, axis1, ...) <==> sqlength(a[, axis=(axis0, axis1, ...)])

            Returns square length of a, ie a*a or the sum of x*x for x in a if a is an iterable of numeric values.
            If a is an Array and axis are specified will return a list of sqlength(x) for x in a.axisiter(*axis).

            >>> A = Array([[0.5,0.5,-0.707],[0.707,-0.707,0.0]])
            >>> print A.formated()
            [[0.5, 0.5, -0.707],
             [0.707, -0.707, 0.0]]
            >>> A.sqlength()
            1.999547
            >>> A.sqlength(0,1)
            1.999547
            >>> A.sqlength(0)
            Array([0.999849, 0.999698])
            >>> A.sqlength(1)
            Array([0.749849, 0.749849, 0.499849])
        """
        axis = self._getaxis(args, fill=True)
        it = self.axisiter(*axis)
        subshape = it.itemshape
        if subshape == () :
            return reduce(operator.add, map(lambda x:x*x, it))
        else :
            return Array(a.sqlength() for a in it)
    def length(self, *args):
        """ a.length(axis0, axis1, ...) <==> length(a[, axis=(axis0, axis1, ...)])

            Returns length of a, sqrt(a*a) or the square root of the sum of x*x for x in a if a is an iterable of numeric values.
            If a is an Array and axis are specified will return a list of length(x) for x in a.axisiter(*axis).

            >>> A = Array([[0.5,0.5,-0.707],[0.707,-0.707,0.0]])
            >>> print A.formated()
            [[0.5, 0.5, -0.707],
             [0.707, -0.707, 0.0]]
            >>> round(A.length(), 7)
            1.4140534
            >>> round(A.length(0,1), 7)
            1.4140534
            >>> A.length(0)
            Array([0.99992449715, 0.999848988598])
            >>> A.length(1)
            Array([0.865938219505, 0.865938219505, 0.707])
        """
        return sqrt(self.sqlength(*args))
    def normal(self, *args):
        """ a.normal(axis0, axis1, ...) <==> normal(a[, axis=(axis0, axis1, ...)])

            Returns a normalized copy of self: self/self.length(axis0, axis1, ...).

            >>> A = Array([[0.5,0.5,-0.707],[0.707,-0.707,0.0]])
            >>> print A.formated()
            [[0.5, 0.5, -0.707],
             [0.707, -0.707, 0.0]]
            >>> print A.normal().formated()
            [[0.353593437318, 0.353593437318, -0.499981120367],
             [0.499981120367, -0.499981120367, 0.0]]
            >>> print A.normal(0,1).formated()
            [[0.353593437318, 0.353593437318, -0.499981120367],
             [0.499981120367, -0.499981120367, 0.0]]
            >>> print A.normal(0).formated()
            [[0.5, 0.5, -0.707],
             [0.707, -0.707, 0.0]]
            >>> print A.normal(1).formated()
            [[0.577408397894, 0.577408397894, -1.0],
             [0.816455474623, -0.816455474623, 0.0]]
        """
        try :
            return self / self.length(*args)
        except :
            return self
    def normalize(self, *args):
        """ Performs an in place normalization of self """
        self.assign(self.normal(*args))
    def dist(self, other, *args):
        """ a.dist(b, axis0, axis1, ...) <==> dist(a, b[, axis=(axis0, axis1, ...)])

            Returns the distance between a and b, ie length(b-a, axis)

            >>> A = Array([[0.5, 0.5, -0.707],[0.707, -0.707, 0.0]])
            >>> print A.formated()
            [[0.5, 0.5, -0.707],
             [0.707, -0.707, 0.0]]
            >>> B = Array([[0.51, 0.49, -0.71],[0.71, -0.70, 0.0]])
            >>> print B.formated()
            [[0.51, 0.49, -0.71],
             [0.71, -0.7, 0.0]]
            >>> A.dist(B)
            0.016340134638368205
            >>> A.dist(B, 0, 1)
            0.016340134638368205
            >>> A.dist(B, 0)
            Array([0.0144568322948, 0.00761577310586])
            >>> A.dist(B, 1)
            Array([0.0104403065089, 0.0122065556157, 0.003])
        """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        return (nother-nself).length(*args)
    def distanceTo(self, other):
        """ a.distanceTo(b) <==> a.dist(b)

            Equivalent to the dist method, for compatibility with Maya's API. Does not take axis arguements
        """
        return self.dist(other)

    def isEquivalent(self, other, tol=eps):
        """ a.isEquivalent(b[, tol]) --> bool

            Returns True if both arguments have same shape and distance between both Array arguments is inferior or equal to tol.

            >>> A = Array([[0.5,0.5,-0.707],[0.707,-0.707,0]])
            >>> B = Array([[0.51,0.49,-0.71],[0.71,-0.70,0]])
            >>> C = Array([[0.501,0.499,-0.706],[0.706,-0.708,0.01]])
            >>> A.dist(B)
            0.016340134638368205
            >>> A.dist(C)
            0.010246950765959599
            >>> A.isEquivalent(C, 0.015)
            True
            >>> A.isEquivalent(B, 0.015)
            False
            >>> A.isEquivalent(B, 0.020)
            True
        """
        if isinstance(other, Array) :
            try :
                nself, nother = coerce(self, other)
            except :
                try :
                    nother, nself = coerce(other, self)
                except :
                    return False
            if nself.shape == nother.shape :
                return nself.dist(nother) <= tol

        return False

    def transpose(self, *args):
        """ a.transpose([axis0[, axis1[, ...]]]) --> Array

            Returns a reordered / transposed along the specified axes.
            If no axes are given,or None is passed, switches the complete axes order.
            For a 2-d array, this is the usual matrix transpose.

            >>> A = Array(range(18), shape=(2,3,3))
            >>> print A.formated()
            [[[0, 1, 2],
              [3, 4, 5],
              [6, 7, 8]],
            <BLANKLINE>
             [[9, 10, 11],
              [12, 13, 14],
              [15, 16, 17]]]
            >>> print A.transpose().formated()
            [[[0, 9],
              [3, 12],
              [6, 15]],
            <BLANKLINE>
             [[1, 10],
              [4, 13],
              [7, 16]],
            <BLANKLINE>
             [[2, 11],
              [5, 14],
              [8, 17]]]
            >>> print A.transpose(0,2,1).formated()
            [[[0, 3, 6],
              [1, 4, 7],
              [2, 5, 8]],
            <BLANKLINE>
             [[9, 12, 15],
              [10, 13, 16],
              [11, 14, 17]]]

            >>> B=MatrixN(range(9), shape=(3, 3))
            >>> print B.formated()
            [[0, 1, 2],
             [3, 4, 5],
             [6, 7, 8]]
            >>> print B.transpose().formated()
            [[0, 3, 6],
             [1, 4, 7],
             [2, 5, 8]]
        """
        axis = self._getaxis(args, fill=True, reverse=True)
        if len(axis) != self.ndim :
            raise ValueError, "Transpose axis %s do not match array shape %s" % (axis, self.shape)
        else :
            return self.__class__._convert(Array([s for s in self.axisiter(*axis)], shape=(self.shape[x] for x in axis)))

    T = property(transpose, None, None, """The transposed array""")

    # arrays of complex values
    def conjugate(self):
        """ a.conjugate() <==> conjugate(a)

            Returns the element-wise complex.conjugate() of the Array.

            >>> A = Array([[complex(1, 2), complex(2, 3)], [complex(4, 5), complex(6, 7)]])
            >>> print A.formated()
            [[(1+2j), (2+3j)],
             [(4+5j), (6+7j)]]
            >>> print A.conjugate().formated()
            [[(1-2j), (2-3j)],
             [(4-5j), (6-7j)]]
            >>> print conjugate(A).formated()
            [[(1-2j), (2-3j)],
             [(4-5j), (6-7j)]]
            >>> A = Array(range(1, 5), shape=(2, 2))
            >>> print conjugate(A).formated()
            [[1, 2],
             [3, 4]]
        """
        return self.__class__(conjugate(x) for x in self)
    def real(self):
        """ a.real() <==> real(a)

            Returns the element-wise complex real part of the Array.

            >>> A = Array([[complex(1, 2), complex(2, 3)], [complex(4, 5), complex(6, 7)]])
            >>> print A.formated()
            [[(1+2j), (2+3j)],
             [(4+5j), (6+7j)]]
            >>> print A.real().formated()
            [[1.0, 2.0],
             [4.0, 6.0]]
            >>> print real(A).formated()
            [[1.0, 2.0],
             [4.0, 6.0]]
            >>> A = Array(range(1, 5), shape=(2, 2))
            >>> print real(A).formated()
            [[1, 2],
             [3, 4]]
        """
        return self.__class__(real(x) for x in self)
    def imag(self):
        """ a.real() <==> real(a)

            Returns the element-wise complex imaginary part of the Array.

            >>> A = Array([[complex(1, 2), complex(2, 3)], [complex(4, 5), complex(6, 7)]])
            >>> print A.formated()
            [[(1+2j), (2+3j)],
             [(4+5j), (6+7j)]]
            >>> print A.imag().formated()
            [[2.0, 3.0],
             [5.0, 7.0]]
            >>> print imag(A).formated()
            [[2.0, 3.0],
             [5.0, 7.0]]
            >>> A = Array(range(1, 5), shape=(2, 2))
            >>> print imag(A).formated()
            [[0, 0],
             [0, 0]]
        """
        return self.__class__(imag(x) for x in self)
    def blend(self, other, weight=0.5):
        """ a.blend(b[, weight=0.5]) <==> blend(a, b[, weights=0.5])

            Returns the result of blending from Array instance u to v according to
            either a scalar weight where blend will yield a*(1-weight) + b*weight Array,
            or a an iterable of independent weights.

            >>> A = Array(0, shape=(2, 2))
            >>> print A.formated()
            [[0, 0],
             [0, 0]]
            >>> B = Array(1, shape=(2, 2))
            >>> print B.formated()
            [[1, 1],
             [1, 1]]
            >>> print A.blend(B, weight=0.5).formated()
            [[0.5, 0.5],
             [0.5, 0.5]]
            >>> print blend(A, B).formated()
            [[0.5, 0.5],
             [0.5, 0.5]]
            >>> print blend(A, B, weight=[x/4.0 for x in range(4)]).formated()
            [[0.0, 0.25],
             [0.5, 0.75]]
            >>> print blend(A, B, weight=[[0.0, 0.25],[0.75, 1.0]]).formated()
            [[0.0, 0.25],
             [0.75, 1.0]]
        """
        try :
            nself, nother = coerce(self, other)
        except :
            return NotImplemented
        return self.__class__._convert(blend(self, other, weight=weight))
    def clamp(self, low=0, high=1):
        """ a.clamp([low=0[, high=1]]) <==> clamp (a, low, high)

            Returns the result of clamping each component of a between low and high if low and high are scalars,
            or the corresponding components of low and high if low and high are sequences of scalars

            >>> A = Array(range(4), shape=(2, 2))
            >>> print A.formated()
            [[0, 1],
             [2, 3]]
            >>> print A.clamp(1, 2).formated()
            [[1, 1],
             [2, 2]]
            >>> print clamp(A, 1, 2).formated()
            [[1, 1],
             [2, 2]]
            >>> print clamp(A, 0.0, [x/4.0 for x in range(4)]).formated()
            [[0, 0.25],
             [0.5, 0.75]]
        """
        return self.__class__._convert(clamp(self, low, high))

# functions that work on MatrixN (and just defer to MatrixN methods)

def det(value):
    """ det(m) --> float

        Returns the determinant of m, 0 if m is a singular MatrixN, m must be convertible to MatrixN.

        Related : see MatrixN.det(self) method.
    """
    if isinstance(value, MatrixN) :
        return value.det()
    elif isNumeric(value) :
        return value
    else :
        try :
            value = MatrixN(value)
        except :
            raise TypeError, "%s not convertible to MatrixN" % (clsname(value))
        return value.det()

def inv(value):
    """ inv(m) --> MatrixN

        Returns the inverse of m, if m is invertible, raises ZeroDivisionError otherwise.
        m must be convertible to MatrixN.

        Related : see MatrixN.inverse(self) method and MatrixN.I property
    """
    if isinstance(value, MatrixN) :
        return value.inverse()
    elif isNumeric(value) :
        return 1.0 / value
    else :
        try :
            value = MatrixN(value)
        except :
            raise TypeError, "%s not convertible to MatrixN" % (clsname(value))
        return value.inverse()

class MatrixN(Array):
    """ A generic size MatrixN class, basically a 2 dimensional Array.

        Most methods and behavior are herited from Array, with the limitation that a MatrixN must have
        exactly 2 dimensions.

        >>> M = MatrixN()
        >>> M
        MatrixN([[]])
        >>> M = MatrixN([])
        >>> M
        MatrixN([[]])
        >>> M = MatrixN([0, 1, 2])
        >>> print M.formated()
        [[0, 1, 2]]
        >>> M = MatrixN([[0, 1, 2]])
        >>> print M.formated()
        [[0, 1, 2]]
        >>> M = MatrixN([[0], [1], [2]])
        >>> print M.formated()
        [[0],
         [1],
         [2]]
        >>> M = MatrixN([[1, 2, 3], [4, 5, 6]])
        >>> print M.formated()
        [[1, 2, 3],
         [4, 5, 6]]
        >>> M = MatrixN(range(4), shape=(2, 2))
        >>> print M.formated()
        [[0, 1],
         [2, 3]]

        The MatrixN class has a constant ndim of 2

        >>> MatrixN.ndim
        2
        >>> M.ndim
        2
        >>> MatrixN.ndim = 3
        Traceback (most recent call last):
            ...
        AttributeError: attribute ndim is a read only class attribute and cannot be modified on class MatrixN
        >>> M.ndim = 3
        Traceback (most recent call last):
            ...
        AttributeError: 'MatrixN' object attribute 'ndim' is read-only

        It's protected against initialization or resizing to a shape that wouldn't be a MatrixN anymore

        >>> M = MatrixN([[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]])
        Traceback (most recent call last):
            ...
        TypeError: cannot initialize a MatrixN of shape (2, 6) from [[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]] of shape (2, 2, 3),
        as it would truncate data or reduce the number of dimensions

        >>> M.resize((2, 2, 3))
        Traceback (most recent call last):
            ...
        TypeError: new shape (2, 2, 3) is not compatible with class MatrixN

        Other Array types can be cast to MatrixN, but truncating data or reducing dimensions is not allowed
        to avoid silent loss of data in a conversion, use an explicit resize / trim / sub-array extraction

        >>> A = Array(range(9), shape=(3, 3))
        >>> M = MatrixN(A)
        >>> print M.formated()
        [[0, 1, 2],
         [3, 4, 5],
         [6, 7, 8]]
        >>> print clsname(M)
        MatrixN
        >>> A = Array([[[1, 2, 3], [4, 5, 6]], [[10, 20, 30], [40, 50, 60]]])
        >>> M = MatrixN(A)
        Traceback (most recent call last):
            ...
        TypeError: cannot cast a Array of shape (2, 2, 3) to a MatrixN of shape (2, 6),
        as it would truncate data or reduce the number of dimensions

        When initializing from a 1-d Array like a VectorN, dimension is upped to 2 by making it a row

        >>> V = VectorN(1, 2, 3)
        >>> M = MatrixN(V)
        >>> print M.formated()
        [[1, 2, 3]]

        Internally, rows are stored as Array though, not VectorN

        >>> M[0]
        Array([1, 2, 3])

        As for Array, __init__ is a shallow copy

        >>> A = Array(range(9), shape=(3, 3))
        >>> M = MatrixN(A)
        >>> M == A
        False
        >>> M is A
        False
        >>> M.isEquivalent(A)
        True
        >>> M[0] == A[0]
        True
        >>> M[0] is A[0]
        True
    """
    __slots__ = ['_data', '_shape', '_size']

    # A MatrixN is a two-dimensional Array, ndim is thus stored as a class readonly attribute
    ndim = 2

    def _getshape(self):
        if len(self) :
            return (len(self), len(self[0]))
        else :
            return (0, 0)
    def _setshape(self, newshape):
        self.resize(newshape)

    # shape, ndim, size and data properties
    shape = property(_getshape, _setshape, None,
                     """ m.shape : tuple of two ints

                         Shape of the MatrixN, the (nrow, ncol) tuple.

                         It can be queried, or set to change the MatrixN's shape similarly to the reshape method.

                         >>> M = MatrixN(range(1, 17), shape=(4, 4))
                         >>> print M.formated()
                         [[1, 2, 3, 4],
                          [5, 6, 7, 8],
                          [9, 10, 11, 12],
                          [13, 14, 15, 16]]
                         >>> M.shape=(2, 8)
                         >>> print M.formated()
                         [[1, 2, 3, 4, 5, 6, 7, 8],
                          [9, 10, 11, 12, 13, 14, 15, 16]]
                         >>> M.shape=(2, 2, 4)
                         Traceback (most recent call last):
                             ...
                         TypeError: new shape (2, 2, 4) is not compatible with class MatrixN

                         Related : see Array.reshape method.
                     """)
    size = property(lambda x : x.shape[0]*x.shape[1], None, None, "Total size of the MatrixN (number of individual components), ie nrow*ncol")

    def is_square(self):
        """ m.is_square() --> bool

            Returns True if m is a square MatrixN, it has the same number of rows and columns.

            >>> M = MatrixN(range(4), shape=(2, 2))
            >>> M.is_square()
            True
            >>> M = MatrixN(range(6), shape=(2, 3))
            >>> M.is_square()
            False
        """
        return self.shape[0] == self.shape[1]

    @classmethod
    def identity(cls, n):
        """ MatrixN.identity(n) --> MatrixN

            Returns the identity MatrixN of size n :
            a square n x n MatrixN of 0.0, with all diagonal components set to 1.0.

            >>> I = MatrixN.identity(4)
            >>> print I.formated()
            [[1.0, 0.0, 0.0, 0.0],
             [0.0, 1.0, 0.0, 0.0],
             [0.0, 0.0, 1.0, 0.0],
             [0.0, 0.0, 0.0, 1.0]]
        """
        return cls([[float(i==j) for i in xrange(n)] for j in xrange(n)])

    @classmethod
    def basis(cls, u, v, normalize=False):
        """ MatrixN.basis(u, v[, normalize=False]) --> MatrixN

            Returns the basis MatrixN built using u, v and u^v as coordinate axis,
            The a, b, n vectors are recomputed to obtain an orthogonal coordinate system as follows:
                n = u ^ v
                v = n ^ u
            if the normalize keyword argument is set to True, the vectors are also normalized

            >>> M = MatrixN.basis(VectorN(0, 1, 0), VectorN(0, 0, 1))
            >>> print M.formated()
            [[0, 0, 1],
             [1, 0, 0],
             [0, 1, 0]]
        """
        u = VectorN(u)
        v = VectorN(v)
        assert len(u) == len(v) == 3, 'basis is only defined for two Vectors of size 3'
        if normalize :
            u = normal(u)
            n = normal(cross(u, v))
            v = cross(n, u)
        else :
            n = cross(u, v)
            v = cross(n, u)
        return cls(MatrixN(u, v, n).transpose())

    # row and column size properties
    def _getnrow(self):
        return self.shape[0]
    def _setnrow(self, m):
        self.trim((m, self.shape[1]))
    nrow = property(_getnrow, _setnrow, None,
                    """ m.nrow : int

                        Number of rows in this MatrixN.

                        It can be queried, or set to reduce / expand the matrix similarly to the trim method.

                        >>> M = MatrixN(range(1, 10), shape=(3, 3))
                        >>> print M.formated()
                        [[1, 2, 3],
                         [4, 5, 6],
                         [7, 8, 9]]
                        >>> M.nrow, M.ncol
                        (3, 3)
                        >>> M.nrow, M.ncol = 4, 4
                        >>> print M.formated()
                        [[1, 2, 3, 0],
                         [4, 5, 6, 0],
                         [7, 8, 9, 0],
                         [0, 0, 0, 0]]
                    """)
    def _getncol(self):
        return self.shape[1]
    def _setncol(self, n):
        self.trim((self.shape[0], n))
    ncol = property(_getncol, _setncol, None,
                    """ m.ncol : int

                        Number of rows in this MatrixN.

                        It can be queried, or set to reduce / expand the matrix similarly to the trim method.

                        >>> M = MatrixN(range(1, 10), shape=(3, 3))
                        >>> print M.formated()
                        [[1, 2, 3],
                         [4, 5, 6],
                         [7, 8, 9]]
                        >>> M.nrow, M.ncol
                        (3, 3)
                        >>> M.nrow, M.ncol = 4, 4
                        >>> print M.formated()
                        [[1, 2, 3, 0],
                         [4, 5, 6, 0],
                         [7, 8, 9, 0],
                         [0, 0, 0, 0]]
                    """)

    # specific iterators
    @property
    def row(self):
        """ m.row --> ArrayIter

            Iterator on the MatrixN rows.
            Being an ArrayIter, it support __len__, __getitem__, __setitem__ and __delitem__

            >>> M = MatrixN(range(1, 10), shape=(3, 3))
            >>> M.nrow, M.ncol = 4, 4
            >>> M[-1, -1] = 1
            >>> print M.formated()
            [[1, 2, 3, 0],
             [4, 5, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 1]]
            >>> [r for r in M.row]
            [Array([1, 2, 3, 0]), Array([4, 5, 6, 0]), Array([7, 8, 9, 0]), Array([0, 0, 0, 1])]

            The row iterator indexing works like the MatrixN indexing and returns references.

            >>> r = M.row[0]
            >>> r
            Array([1, 2, 3, 0])
            >>> r == M[0]
            True
            >>> r is M[0]
            True

            Slices return shallow copies though

            >>> r = M.row[:2]
            >>> print r.formated()
            [[1, 2, 3, 0],
             [4, 5, 6, 0]]
            >>> print clsname(r)
            MatrixN

            >>> r == M[:2]
            True
            >>> r is M[:2]
            False
            >>> r[0] == M[0]
            True
            >>> r[0] is M[0]
            True

            Results can be indexed again, using Array indexing or MatrixN methods wether they're returned
            as Array (single lines / columns) or MatrixN (2 dimensionnal Array).

            >>> c = r.col[1]
            >>> c
            Array([2, 5])

            Multiple indexing is possible

            >>> M[0, 1]
            2
            >>> M.row[0][1]
            2
            >>> M.row[0, 1]
            2

            Values can be set as with MatrixN indexing

            >>> M.row[:2, 1] = 10
            >>> print M.formated()
            [[1, 10, 3, 0],
             [4, 10, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 1]]
            >>> r = M.row[:2]
            >>> r[:, 1] = [2, 5]
            >>> print M.formated()
            [[1, 2, 3, 0],
             [4, 5, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 1]]

            Rows can be deleted too

            >>> del M.row[-1]
            >>> del M[None, -1]
            >>> print M.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]

        """
        return self.axisiter(0)
    @property
    def col(self):
        """ m.col --> ArrayIter

            Iterator on the MatrixN columns
            Being an ArrayIter, it support __len__, __getitem__, __setitem__ and __delitem__

            >>> M = MatrixN(range(1, 10), shape=(3, 3))
            >>> M.nrow, M.ncol = 4, 4
            >>> M[-1, -1] = 1
            >>> print M.formated()
            [[1, 2, 3, 0],
             [4, 5, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 1]]
            >>> [c for c in M.col]
            [Array([1, 4, 7, 0]), Array([2, 5, 8, 0]), Array([3, 6, 9, 0]), Array([0, 0, 0, 1])]

            The col iterator has to rebuild sub-arrays and thus returns copies and not references.

            >>> c = M.col[0]
            >>> c
            Array([1, 4, 7, 0])
            >>> c == M[:,0]
            True
            >>> c is M[:,0]
            False

            Multiple columns are returned as rows in a new MatrixN

            >>> c = M.col[:2]
            >>> print c.formated()
            [[1, 4, 7, 0],
             [2, 5, 8, 0]]
            >>> print clsname(c)
            MatrixN

            >>> s = M[:,:2]
            >>> print s.formated()
            [[1, 2],
             [4, 5],
             [7, 8],
             [0, 0]]
            >>> print clsname(s)
            MatrixN

            TODO : is it what we want ? If so invert these

            # >>> c == s
            # True
            # >>> c == s.T
            # False

            Results can be indexed again, using Array indexing or MatrixN methods wether they're returned
            as Array (single lines / columns) or MatrixN (2 dimensionnal Array).

            >>> r = c.row[1]
            >>> r
            Array([2, 5, 8, 0])
            >>> r = s.row[1]
            >>> r
            Array([4, 5])

            Multiple indexing is possible

            >>> M[0, 1]
            2
            >>> M.col[1][0]
            2
            >>> M.col[1, 0]
            2

            As results are rebuilt Arrays, values can only b set for full columns

            >>> M.col[1]
            Array([2, 5, 8, 0])

            This won't work :

            >>> M.col[1][:2] = 10
            >>> print M.formated()
            [[1, 2, 3, 0],
             [4, 5, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 1]]

            But this will :

            >>> M.col[1, :2] = 10
            >>> print M.formated()
            [[1, 10, 3, 0],
             [4, 10, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 1]]

            >>> c = M.col[1]
            >>> c[:2] = [2, 5]
            >>> M.col[1] = c
            >>> print M.formated()
            [[1, 2, 3, 0],
             [4, 5, 6, 0],
             [7, 8, 9, 0],
             [0, 0, 0, 1]]

            Columns can be deleted too

            >>> del M.col[-1]
            >>> del M[-1]
            >>> print M.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]

        """
        return self.axisiter(1)

    # overloaded Array operators

    def __mul__(self, other):
        """ a.__mul__(b) <==> a*b

            If b is a MatrixN, __mul__ is mapped to matrix multiplication, if b is a VectorN, to MatrixN by VectorN multiplication,
            otherwise, returns the result of the element wise multiplication of a and b if b is convertible to Array,
            multiplies every component of a by b if b is a single numeric value """
        if isinstance(other, MatrixN) :
            return self.__class__._convert( [ [ dot(row,col) for col in other.col ] for row in self.row ] )
        elif isinstance(other, VectorN) :
            if other.size <= self.shape[1] :
                return other.__class__._convert( [ dot(row, other) for row in self.row ] [:other.size] )
            else :
                raise ValueError, "matrix of shape %s and vector of size %s are not conformable for a MatrixN * VectorN multiplication" % (self.size, other.shape)
        else :
            return Array.__mul__(self, other)
    def __rmul__(self, other):
        """ a.__rmul__(b) <==> b*a

            If b is a MatrixN, __rmul__ is mapped to matrix multiplication, if b is a VectorN, to VectorN by MatrixN multiplication,
            otherwise, returns the result of the element wise multiplication of a and b if b is convertible to Array,
            multiplies every component of a by b if b is a single numeric value """
        if isinstance(other, MatrixN) :
            return MatrixN( [ [ dot(row,col) for col in self.col ] for row in other.row ] )
        elif isinstance(other, VectorN) :
            if other.size <= self.shape[0] :
                return other.__class__._convert( [ dot(col, other) for col in self.col ] [:other.size] )
            else :
                raise ValueError, "vector of size %s and matrix of shape %s are not conformable for a VectorN * MatrixN multiplication" % (other.size, self.shape)
        else :
            return Array.__rmul__(self, other)
    def __imul__(self, other):
        """ a.__imul__(b) <==> a *= b

            In place multiplication of MatrixN a and b, see __mul__, result must fit a's type """
        res = self*other
        if isinstance(res, self.__class__) :
            return self.__class__(res)
        else :
            raise TypeError, "result of in place multiplication of %s by %s is not a %s" % (clsname(self), clsname(other), clsname(self))

    # specific methods

    def diagonal(self, offset=0, wrap=False) :
        """ m.diagonal([offset=0[, wrap=False]]) -> Array

            Returns the diagonal of the MatrixN with the given offset,
            i.e., the collection of elements of the form a[i,i+offset].
            If keyword wrap=True will wrap out of bounds indices

            Examples :

            >>> M = MatrixN([[1, 2], [4, 6]])
            >>> print M.formated()
            [[1, 2],
             [4, 6]]
            >>> M.diagonal()
            Array([1, 6])
            >>> M.diagonal(1)
            Array([2])
            >>> M.diagonal(1, wrap=True)
            Array([2, 4])
            >>> M.diagonal(-1)
            Array([2, 4])
            >>> M.diagonal(-1, wrap=True)
            Array([2, 4])
        """
        assert self.ndim == 2, "can only calculate diagonal on Array or sub Arrays of dimension 2"

        shape = self.shape
        #axis = self._getaxis(args, fill=True)
        #it = self.axisiter(axis)
        #print self.transpose(axis).formated()
        if wrap :
            return Array([self[i,(i+offset)%shape[1]] for i in xrange(shape[0])])
        else :
            l = []
            for i in xrange(shape[0]) :
                if (i+offset) < shape[1] :
                    l.append(self[i, (i+offset)])
            return Array(l)

    def trace(self, offset=0, wrap=False) :
        """ a.trace([offset=0[, wrap=False]]) -> float

            Returns the sum of the components on the diagonal, obtained by calling m.diagonal(offset, wrap).

            >>> M = MatrixN([[1, 2], [4, 6]])
            >>> print M.formated()
            [[1, 2],
             [4, 6]]
            >>> M.trace()
            7
            >>> M.trace(offset=1)
            2
            >>> M.trace(offset=1, wrap=True)
            6
            >>> M.trace(offset=-1)
            6
            >>> M.trace(offset=-1, wrap=True)
            6
        """
        return sum(self.diagonal(offset, wrap))

    def minor(self, i, j):
        """ m.minor(i, j) --> MatrixN

            Returns the MatrixN obtained by deleting row i and column j from m.

            >>> M = MatrixN(range(4), shape=(2, 2))
            >>> print M.formated()
            [[0, 1],
             [2, 3]]
            >>> M.minor(0, 0)
            MatrixN([[3]])
            >>> M.minor(0, 1)
            MatrixN([[2]])
            >>> M.minor(1, 0)
            MatrixN([[1]])
            >>> M.minor(1, 1)
            MatrixN([[0]])

            >>> M = MatrixN.identity(4)
            >>> M[:3, :3] = [float(i) for i in range(1, 10)]
            >>> print M.formated()
            [[1.0, 2.0, 3.0, 0.0],
             [4.0, 5.0, 6.0, 0.0],
             [7.0, 8.0, 9.0, 0.0],
             [0.0, 0.0, 0.0, 1.0]]
            >>> print M.minor(3, 3).formated()
            [[1.0, 2.0, 3.0],
             [4.0, 5.0, 6.0],
             [7.0, 8.0, 9.0]]
        """
        # TODO : the below example fails.  M.minor(0,0) returns an Array instead of MatrixN
        """
            >>> M = MatrixN([1])
            >>> M
            MatrixN([[1]])
            >>> M.minor(0, 0)
            MatrixN([])
        """

        index = self._getindex((i, j), default=None)
        m = self.deleted(index)
        return m

    def cofactor(self, i, j):
        """ m.cofactor(i, j) --> float

            Returns the cofactor of matrix m for index (i, j),
            the determinant of the MatrixN obtained by deleting row i and column j from m (the minor),
            signed by (-1)**(i+j).

            >>> M = MatrixN(range(1, 10), shape=(3, 3))
            >>> print M.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> print M.minor(2, 2).formated()
            [[1, 2],
             [4, 5]]
            >>> M.minor(2, 2).det()
            -3
            >>> M.cofactor(2, 2)
            -3
            >>> print M.minor(0, 1).formated()
            [[4, 6],
             [7, 9]]
            >>> M.minor(0, 1).det()
            -6
            >>> M.cofactor(0, 1)
            6
        """
        return ((-1)**(i+j))*self.minor(i, j).det()

    # sometimes called adjoint
    def adjugate(self):
        """ m.adjugate() --> MatrixN

            Returns the adjugate MatrixN of the square MatrixN m : the MatrixN of the cofactors of m.
            It's a square MatrixN of same size as m, where a component of index (i, j) is set to the value
            of m.cofactor(i, j).

            >>> M = MatrixN([ [100/(i+j) for i in xrange(1,5)] for j in xrange(4) ])
            >>> print M.formated()
            [[100, 50, 33, 25],
             [50, 33, 25, 20],
             [33, 25, 20, 16],
             [25, 20, 16, 14]]
            >>> print M[:1, :1].adjugate().formated()
            [[1]]
            >>> print M[:2, :2].adjugate().formated()
            [[33, -50],
             [-50, 100]]
            >>> print M[:3, :3].adjugate().formated()
            [[35, -175, 161],
             [-175, 911, -850],
             [161, -850, 800]]
            >>> print M[:4, :4].adjugate().formated()
            [[42, -210, 154, 49],
             [-210, 1054, -775, -245],
             [154, -775, 575, 175],
             [49, -245, 175, 63]]
        """
        assert self.is_square(), "Adjugate MatrixN can only be computed for a square MatrixN"
        n = self.nrow
        if n == 1 :
            a = self.__class__([[1]])
        elif n == 2 :
            a = self.__class__( [ [ self[1,1], -self[0,1] ],    \
                                  [-self[1,0], self[0,0] ] ] )
        elif n == 3 :
            a = self.__class__( [ [  (self[1,1]*self[2,2]-self[1,2]*self[2,1]), -(self[0,1]*self[2,2]-self[0,2]*self[2,1]),  (self[0,1]*self[1,2]-self[0,2]*self[1,1]) ], \
                                  [ -(self[1,0]*self[2,2]-self[1,2]*self[2,0]),  (self[0,0]*self[2,2]-self[0,2]*self[2,0]), -(self[0,0]*self[1,2]-self[0,2]*self[1,0]) ], \
                                  [  (self[1,0]*self[2,1]-self[1,1]*self[2,0]), -(self[0,0]*self[2,1]-self[0,1]*self[2,0]),  (self[0,0]*self[1,1]-self[0,1]*self[1,0]) ] ] )
        else :
            # generic cofactor expansion method
            a = self.__class__([[self.cofactor(j, i) for j in xrange(n)] for i in xrange(n)])

        return a

    def _gauss_jordan(self):
        nr, nc = self.shape
        assert nc >= nr, "MatrixN needs to have at least as much columns as rows to do a Gauss-Jordan elimination"
        m = self.deepcopy()
        nbperm = 0
        for i in xrange(nr) :
            maxr = i
            for j in xrange(i+1,nr) :
                if abs(m[j,i]) > abs(m[maxr,i]):
                    maxr = j
            # swap rows
            if maxr != i :
                m[i], m[maxr] = m[maxr], m[i]
                nbperm += 1
            if abs(m[i,i]) < eps :
                raise ZeroDivisionError, "MatrixN is singular"
            d = float(m[i,i])
            for j in xrange(i+1,nr) :
                # eliminate lower rows
                if abs(m[j,i]) >= eps :
                    f = m[j,i] / d
                    for k in xrange(i, nc) :
                        m[j,k] -= f * m[i,k]
                        # print m.formated()
                    # print m.formated()
        return m, nbperm

    def gauss(self):
        """ m.gauss() --> MatrixN

            Returns the triangular matrix obtained by Gauss-Jordan elimination on m,
            will raise a ZeroDivisionError if m cannot be triangulated.

            >>> M = MatrixN([ [1.0/(i+j) for i in xrange(1,7)] for j in xrange(6) ])
            >>> print round(M, 2).formated()
            [[1.0, 0.5, 0.33, 0.25, 0.2, 0.17],
             [0.5, 0.33, 0.25, 0.2, 0.17, 0.14],
             [0.33, 0.25, 0.2, 0.17, 0.14, 0.13],
             [0.25, 0.2, 0.17, 0.14, 0.13, 0.11],
             [0.2, 0.17, 0.14, 0.13, 0.11, 0.1],
             [0.17, 0.14, 0.13, 0.11, 0.1, 0.09]]
            >>> print round(M[:1, :1].gauss(), 2).formated()
            [[1.0]]
            >>> print round(M[:2, :2].gauss(), 2).formated()
            [[1.0, 0.5],
             [0.0, 0.08]]
            >>> print round(M[:3, :3].gauss(), 2).formated() # doctest: +SKIP
            [[1.0, 0.5, 0.33],
             [0.0, 0.08, 0.09],
             [0.0, 0.0, -0.01]]
            >>> print round(M[:4, :4].gauss(), 2).formated() # doctest: +SKIP
            [[1.0, 0.5, 0.33, 0.25],
             [0.0, 0.08, 0.09, 0.08],
             [0.0, 0.0, -0.01, -0.01],
             [0.0, 0.0, 0.0, 0.0]]
            >>> print round(M[:5, :5].gauss(), 2).formated()  # doctest: +SKIP
            [[1.0, 0.5, 0.33, 0.25, 0.2],
             [0.0, 0.08, 0.09, 0.08, 0.08],
             [0.0, 0.0, -0.01, -0.01, -0.01],
             [0.0, 0.0, 0.0, 0.0, 0.0],
             [0.0, 0.0, 0.0, -0.0, -0.0]]
            >>> print round(M[:6, :6].gauss(), 2).formated() # doctest: +SKIP
            [[1.0, 0.5, 0.33, 0.25, 0.2, 0.17],
             [0.0, 0.08, 0.09, 0.08, 0.08, 0.07],
             [0.0, 0.0, 0.01, 0.01, 0.01, 0.01],
             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
             [0.0, 0.0, 0.0, 0.0, -0.0, -0.0],
             [0.0, 0.0, 0.0, 0.0, 0.0, -0.0]]

            >>> M = MatrixN([[1, 2, 3], [2, 4, 6], [6, 7, 8]])
            >>> print M.formated()
            [[1, 2, 3],
             [2, 4, 6],
             [6, 7, 8]]
            >>> M.det()
            0
            >>> M.isSingular()
            True
            >>> print M.gauss().formated()
            Traceback (most recent call last):
                ...
            ZeroDivisionError: MatrixN is singular
        """
        return self._gauss_jordan()[0]

    def reduced(self):
        """ m.reduced() --> MatrixN

            Returns the reduced row echelon form of the matrix a by Gauss-Jordan elimination,
            followed by back substitution.

            >>> M = MatrixN([ [1.0/(i+j) for i in xrange(1,7)] for j in xrange(6) ])
            >>> print round(M, 2).formated()
            [[1.0, 0.5, 0.33, 0.25, 0.2, 0.17],
             [0.5, 0.33, 0.25, 0.2, 0.17, 0.14],
             [0.33, 0.25, 0.2, 0.17, 0.14, 0.13],
             [0.25, 0.2, 0.17, 0.14, 0.13, 0.11],
             [0.2, 0.17, 0.14, 0.13, 0.11, 0.1],
             [0.17, 0.14, 0.13, 0.11, 0.1, 0.09]]
            >>> print round(M[:1, :1].reduced(), 2).formated()
            [[1.0]]
            >>> print round(M[:2, :2].reduced(), 2).formated()
            [[1.0, 0.0],
             [0.0, 1.0]]
            >>> print round(M[:3, :3].reduced(), 2).formated() # doctest: +SKIP
            [[1.0, 0.0, 0.0],
             [0.0, 1.0, -0.0],
             [0.0, 0.0, 1.0]]
            >>> print round(M[:4, :4].reduced(), 2).formated() # doctest: +SKIP
            [[1.0, 0.0, 0.0, 0.0],
             [0.0, 1.0, -0.0, 0.0],
             [0.0, 0.0, 1.0, 0.0],
             [0.0, 0.0, 0.0, 1.0]]
            >>> print round(M[:5, :5].reduced(), 2).formated() # doctest: +SKIP
            [[1.0, 0.0, 0.0, 0.0, 0.0],
             [0.0, 1.0, -0.0, 0.0, -0.0],
             [0.0, 0.0, 1.0, 0.0, -0.0],
             [0.0, 0.0, 0.0, 1.0, -0.0],
             [0.0, 0.0, 0.0, -0.0, 1.0]]
            >>> print round(M[:6, :6].reduced(), 2).formated() # doctest: +SKIP
            [[1.0, 0.0, 0.0, 0.0, -0.0, 0.0],
             [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],
             [0.0, 0.0, 1.0, 0.0, -0.0, 0.0],
             [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],
             [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],
             [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]

            >>> M = MatrixN([[1, 2, 3], [2, 4, 6], [6, 7, 8]])
            >>> print M.formated()
            [[1, 2, 3],
             [2, 4, 6],
             [6, 7, 8]]
            >>> M.det()
            0
            >>> M.isSingular()
            True
            >>> print M.reduced().formated()
            Traceback (most recent call last):
                ...
            ZeroDivisionError: MatrixN is singular
        """
        m = self.gauss()
        nr, nc = m.shape
        for i in range(nr-1, -1, -1):
            # print m.formated()
            d  = float(m[i, i])
            for j in range(i):
                for k in range(nc-1, i-1, -1):
                    m[j,k] -=  m[i,k] * m[j, i] / d
                # print m.formated()
            m[i, i] /= d
            for j in range(nr, nc):
                m[i, j] /= d
        # print m.formated()
        return m

    def det(self):
        """ m.det() <==> det(m)

            Returns the determinant of m, 0 if MatrixN is singular.

            >>> M = MatrixN([ [100/(i+j) for i in xrange(1,7)] for j in xrange(6) ])
            >>> print M.formated()
            [[100, 50, 33, 25, 20, 16],
             [50, 33, 25, 20, 16, 14],
             [33, 25, 20, 16, 14, 12],
             [25, 20, 16, 14, 12, 11],
             [20, 16, 14, 12, 11, 10],
             [16, 14, 12, 11, 10, 9]]
            >>> M[:1, :1].det()
            100
            >>> M[:2, :2].det()
            800
            >>> M[:3, :3].det()
            63
            >>> M[:4, :4].det()
            7
            >>> M[:5, :5].det()
            -1199
            >>> M[:6, :6].det()
            452.0

            >>> M = MatrixN(range(1, 10), shape=(3, 3))
            >>> print M.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> M.det()
            0
        """
        assert self.is_square(), "determinant is only defined for a square MatrixN"
        n = self.nrow
        if n == 1:
            d = self[0,0]
        elif n == 2:
            d = self[0,0]*self[1,1] - self[0,1]*self[1,0]
        elif n == 3:
            # direct Leibniz formula
            d = self[0,0]*self[1,1]*self[2,2] + self[0,2]*self[1,0]*self[2,1] + self[0,1]*self[1,2]*self[2,0] \
                - self[0,2]*self[1,1]*self[2,0] - self[0,0]*self[1,2]*self[2,1] - self[0,1]*self[1,0]*self[2,2]
        elif n == 4:
            # using Laplace expansion theorem
            s0 = self[0,0]*self[1,1] - self[0,1]*self[1,0]
            s1 = self[0,0]*self[1,2] - self[0,2]*self[1,0]
            s2 = self[0,0]*self[1,3] - self[0,3]*self[1,0]
            s3 = self[0,1]*self[1,2] - self[0,2]*self[1,1]
            s4 = self[0,1]*self[1,3] - self[0,3]*self[1,1]
            s5 = self[0,2]*self[1,3] - self[0,3]*self[1,2]

            c0 = self[2,2]*self[3,3] - self[2,3]*self[3,2]
            c1 = self[2,1]*self[3,3] - self[2,3]*self[3,1]
            c2 = self[2,1]*self[3,2] - self[2,2]*self[3,1]
            c3 = self[2,0]*self[3,3] - self[2,3]*self[3,0]
            c4 = self[2,0]*self[3,2] - self[2,2]*self[3,0]
            c5 = self[2,0]*self[3,1] - self[2,1]*self[3,0]

            d = s0*c0 - s1*c1 + s2*c2 + s3*c3 - s4*c4 + s5*c5
        elif n < 6 :
            # cofactors, gets slower than Gauss-Jordan for sizes 6 and more
            d = 0
            for j in xrange(n) :
               d += self[0,j]*self.cofactor(0, j)  # ((-1)**j)*self.minor(0,j).det()
        else :
            # Gauss-Jordan elimination
            try :
                m, nbperm = self._gauss_jordan()
                d = prod(m.diagonal(), (-1)**nbperm)
            except ZeroDivisionError :
                # singular
                d = 0.0

        return d

    def isSingular(self, tol=eps):
        """ m.isSingular([tol]) --> bool

            Returns True if m is singular, ie it's determinant is smaller than the given tolerance.

            >>> M = MatrixN(range(1, 5), shape=(2, 2))
            >>> print M.formated()
            [[1, 2],
             [3, 4]]
            >>> M.det()
            -2
            >>> M.isSingular()
            False

            >>> M = MatrixN(range(1, 10), shape=(3, 3))
            >>> print M.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> M.det()
            0
            >>> M.isSingular()
            True
        """
        return (abs(self.det()) <= tol)

    def inverse(self):
        """ m.inverse() <==> inv(m)

            Returns the inverse MatrixN of m, if m is invertible, will raise a ValueError otherwise.

            >>> M = MatrixN([ [1.0/(i+j) for i in xrange(1,7)] for j in xrange(6) ])
            >>> print round(M, 2).formated()
            [[1.0, 0.5, 0.33, 0.25, 0.2, 0.17],
             [0.5, 0.33, 0.25, 0.2, 0.17, 0.14],
             [0.33, 0.25, 0.2, 0.17, 0.14, 0.13],
             [0.25, 0.2, 0.17, 0.14, 0.13, 0.11],
             [0.2, 0.17, 0.14, 0.13, 0.11, 0.1],
             [0.17, 0.14, 0.13, 0.11, 0.1, 0.09]]
            >>> print round(M[:1, :1].inverse(), 0).formated()
            [[1.0]]
            >>> print round(M[:2, :2].inverse(), 0).formated()
            [[4.0, -6.0],
             [-6.0, 12.0]]
            >>> print round(M[:3, :3].inverse(), 0).formated()
            [[9.0, -36.0, 30.0],
             [-36.0, 192.0, -180.0],
             [30.0, -180.0, 180.0]]
            >>> print round(M[:4, :4].inverse(), 0).formated()
            [[16.0, -120.0, 240.0, -140.0],
             [-120.0, 1200.0, -2700.0, 1680.0],
             [240.0, -2700.0, 6480.0, -4200.0],
             [-140.0, 1680.0, -4200.0, 2800.0]]
            >>> print round(M[:5, :5].inverse(), 0).formated()
            [[25.0, -300.0, 1050.0, -1400.0, 630.0],
             [-300.0, 4800.0, -18900.0, 26880.0, -12600.0],
             [1050.0, -18900.0, 79380.0, -117600.0, 56700.0],
             [-1400.0, 26880.0, -117600.0, 179200.0, -88200.0],
             [630.0, -12600.0, 56700.0, -88200.0, 44100.0]]
            >>> print round(M[:6, :6].inverse(), 0).formated()
            [[36.0, -630.0, 3360.0, -7560.0, 7560.0, -2772.0],
             [-630.0, 14700.0, -88200.0, 211680.0, -220500.0, 83160.0],
             [3360.0, -88200.0, 564480.0, -1411200.0, 1512000.0, -582120.0],
             [-7560.0, 211680.0, -1411200.0, 3628800.0, -3969000.0, 1552320.0],
             [7560.0, -220500.0, 1512000.0, -3969000.0, 4410000.0, -1746360.0],
             [-2772.0, 83160.0, -582120.0, 1552320.0, -1746360.0, 698544.0]]

            >>> M = MatrixN(range(1, 10), shape=(3, 3))
            >>> print M.formated()
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]
            >>> M.det()
            0
            >>> M.isSingular()
            True
            >>> print M.inverse().formated()
            Traceback (most recent call last):
                ...
            ValueError: MatrixN is not invertible
        """
        assert self.is_square(), "inverse is only defined for a square MatrixN, see linverse and rinverse"
        n = self.nrow
        try :
            if n == 1 :
                i = self.__class__(1.0/self[0, 0])
            elif n < 4 :
                # got direct formulas for both adjugate and determinant if n<4
                i = self.adjugate()/float(self.det())
            elif n < 6 :
                # by cofactors expansion : i = self.adjugate()/float(self.det())
                # here calculate determinant from the adjugate matrix components to avoid computing cofactors twice
                a = self.adjugate() # [[self.cofactor(j, i) for j in xrange(n)] for i in xrange(n)]
                d = 0.0
                for j in xrange(n) :
                    d += self[0,j]*a[j, 0]
                i = a/float(d)
            else :
                # by gauss-jordan elimination
                id = MatrixN.identity(n)
                m = self.hstacked(id).reduced()
                i = self.__class__(m[:, n:])
        except ZeroDivisionError :
            raise ValueError, "MatrixN is not invertible"

        return i

    inv = inverse

    I = property(inverse, None, None, """The inverse MatrixN""")

    def linverse(self):
        """ m.linverse() --> MatrixN

            Returns the left inverse matrix of m, the matrix n so that n * m = identity, if m is left-invertible,
            otherwise will raise a ValueError.
            If m is invertible then the left inverse of m is also it's right inverse, and it's inverse matrix.

            >>> M = MatrixN([[1, 2], [3, 4], [5, 6]])
            >>> print M.formated()
            [[1, 2],
             [3, 4],
             [5, 6]]
            >>> print round(M.linverse(), 2).formated()
            [[-1.33, -0.33, 0.67],
             [1.08, 0.33, -0.42]]
        """
        nr, nc = self.nrow, self.ncol
        assert nr >= nc, "a MatrixN can have an inverse if it is square and a left inverse only if it has more rows than columns"
        if nr == nc :
            return self.I
        else :
            t = self.T
            m = t * self
            return m.I * t

    def rinverse(self):
        """ m.rinverse() --> MatrixN

            Returns the right inverse matrix of m, the matrix n so that m * n = identity, if m is right-invertible,
            otherwise will raise a ValueError.
            If m is invertible then the right inverse of m is also it's left inverse, and it's inverse matrix.

            >>> M = MatrixN([[1, 2, 3], [4, 5, 6]])
            >>> print M.formated()
            [[1, 2, 3],
             [4, 5, 6]]
            >>> print round(M.rinverse(), 2).formated()
            [[-0.94, 0.44],
             [-0.11, 0.11],
             [0.72, -0.22]]
        """
        nr, nc = self.nrow, self.ncol
        assert nc >= nr, "a MatrixN can have an inverse if it is square and a right inverse only if it has more columns than rows"
        if nr == nc :
            return self.I
        else :
            t = self.T
            m = self * t
            return t * m.I

# functions that work on Vectors or 1-d Arrays

# only on size 3 Vectors

def cross(u, v):
    """ cross(u, v) --> VectorN

        Returns the cross product of u and v, u and v should be 3 dimensional vectors.

        >>> u = VectorN(1.0, 0.0, 0.0)
        >>> v = VectorN(0.0, 1.0, 0.0)
        >>> cross(u, v)
        VectorN([0.0, 0.0, 1.0])
        >>> cross(u, [0.0, 1.0, 0.0])
        VectorN([0.0, 0.0, 1.0])

        Related : see VectorN.cross method.
    """
    if not isinstance(u, VectorN) :
        try :
            u = VectorN(u)
        except :
            raise TypeError, "%s is not convertible to type VectorN, cross product is only defined for two Vectors of size 3" % (clsname(u))
    return u.cross(v)

def dot(u, v):
    """ dot(u, v) --> float

        Returns the dot product of u and v, u and v should be Vectors of identical size.

        >>> u = VectorN(1.0, 0.0, 0.0)
        >>> v = VectorN(0.707, 0.0, -0.707)
        >>> print round(dot(u, v), 3)
        0.707
        >>> print round(dot(u, [0.707, 0.0, -0.707]), 3)
        0.707

        Related : see VectorN.dot method.
    """
    if not isinstance(u, VectorN) :
        try :
            u = VectorN(u)
        except :
            raise TypeError, "%s is not convertible to type VectorN, dot product is only defined for two Vectors of identical size" % (clsname(u))
    return u.dot(v)

def outer(u, v):
    """ outer(u, v) --> MatrixN

        Returns the outer product of vectors u and v.

        >>> u = VectorN(1.0, 2.0, 3.0)
        >>> v = VectorN(10.0, 20.0, 30.0)
        >>> outer(u, v)
        MatrixN([[10.0, 20.0, 30.0], [20.0, 40.0, 60.0], [30.0, 60.0, 90.0]])
        >>> outer(u, [10.0, 20.0, 30.0])
        MatrixN([[10.0, 20.0, 30.0], [20.0, 40.0, 60.0], [30.0, 60.0, 90.0]])

        Related : see VectorN.outer method.
    """
    if not isinstance(u, VectorN) :
        try :
            u = VectorN(u)
        except :
            raise TypeError, "%s is not convertible to type VectorN, outer product is only defined for two Vectors" % (clsname(u))
    return u.outer(v)

def angle(a, b, c=None):
    """ angle(u, v) --> float

        Returns the angle of rotation between u and v.
        u and v should be 3 dimensional Vectors representing 3D vectors.

        Note: this angle is not signed, use axis to know the direction of the rotation.

        >>> u = VectorN(1.0, 0.0, 0.0)
        >>> v = VectorN(0.707, 0.0, -0.707)
        >>> print round(angle(u, v), 7)
        0.7853982
        >>> print round(angle(u, [0.707, 0.0, -0.707]), 7)
        0.7853982

        Alternatively can use the form angle(a, b, c), where a, b, c are 4 dimensional Vectors representing 3D points,
        it is then equivalent to angle(b-a, c-a)

        >>> o = VectorN(0.0, 1.0, 0.0, 1.0)
        >>> p = VectorN(1.0, 1.0, 0.0, 1.0)
        >>> q = VectorN(0.707, 1.0, -0.707, 1.0)
        >>> print round(angle(o, p, q), 7)
        0.7853982

        Related : see VectorN.angle method.
    """
    if not isinstance(a, VectorN) :
        try :
            a = VectorN(a)
        except :
            raise TypeError, "%s is not convertible to type VectorN, angle is only defined for 2 vectors or 3 points" % (clsname(a))
    if c is not None :
        return a.angle(b, c)
    else :
        return a.angle(b)

def axis(a, b, c=None, normalize=False):
    """ axis(u, v[, normalize=False]) --> VectorN

        Returns the axis of rotation from u to v as the vector n = u ^ v
        if the normalize keyword argument is set to True, n is also normalized.
        u and v should be 3 dimensional Vectors representing 3D vectors.

        >>> u = VectorN(1.0, 0.0, 0.0)
        >>> v = VectorN(0.707, 0.0, -0.707)
        >>> axis(u, v) == VectorN([0.0, 0.707, 0.0])
        True
        >>> axis(u, [0.707, 0.0, -0.707], normalize=True) == VectorN([-0.0, 1.0, 0.0])
        True

        Alternatively can use the form axis(a, b, c), where a, b, c are 4 dimensional Vectors representing 3D points,
        it is then equivalent to axis(b-a, c-a).

        >>> o = VectorN(0.0, 1.0, 0.0, 1.0)
        >>> p = VectorN(1.0, 1.0, 0.0, 1.0)
        >>> q = VectorN(0.707, 1.0, -0.707, 1.0)
        >>> axis(o, p, q, normalize=True) == VectorN([0.0, 1.0, 0.0])
        True

        Related : see VectorN.axis method.
    """
    if not isinstance(a, VectorN) :
        try :
            a = VectorN(a)
        except :
            raise TypeError, "%s is not convertible to type VectorN, axis is only defined for 2 vectors or 3 points" % (clsname(a))
    if c is not None :
        return a.axis(b, c, normalize=normalize)
    else :
        return a.axis(b, normalize=normalize)

def cotan(a, b, c=None) :
    """ cotan(u, v) --> float :

        Returns the cotangent of the u, v angle, u and v should be 3 dimensional Vectors representing 3D vectors.

        >>> u = VectorN(1.0, 0.0, 0.0)
        >>> v = VectorN(0.707, 0.0, -0.707)
        >>> cotan(u, v)
        1.0
        >>> cotan(u, [0.707, 0.0, -0.707])
        1.0

        Alternatively can use the form cotan(a, b, c), where a, b, c are 4 dimensional Vectors representing 3D points,
        it is then equivalent to cotan(b-a, c-a).

        >>> o = VectorN(0.0, 1.0, 0.0, 1.0)
        >>> p = VectorN(1.0, 1.0, 0.0, 1.0)
        >>> q = VectorN(0.707, 1.0, -0.707, 1.0)
        >>> cotan(o, p, q)
        1.0

        Related : see VectorN.cotan method.
    """
    if not isinstance(a, VectorN) :
        try :
            a = VectorN(a)
        except :
            raise TypeError, "%s is not convertible to type VectorN, cotangent product is only defined for 2 vectors or 3 points" % (clsname(a))
    if c is not None :
        return a.cotan(b, c)
    else :
        return a.cotan(b)

#
#    VectorN Class
#

class VectorN(Array):
    """
        A generic size VectorN class derived from Array, basically a 1 dimensional Array.

        Most methods and behavior are herited from Array, with the limitation that a MatrixN must have
        exactly 2 dimensions.

        >>> V = VectorN()
        >>> V
        VectorN([])
        >>> V = VectorN([0, 1, 2])
        >>> V
        VectorN([0, 1, 2])
        >>> V = VectorN(0, 1, 2)
        >>> V
        VectorN([0, 1, 2])
        >>> M = MatrixN([[0], [1], [2]])
        >>> print M.formated()
        [[0],
         [1],
         [2]]
        >>> V = VectorN(M.col[0])
        >>> V
        VectorN([0, 1, 2])

        The VectorN class has a constant ndim of 1

        >>> VectorN.ndim
        1
        >>> V.ndim
        1
        >>> VectorN.ndim = 2
        Traceback (most recent call last):
            ...
        AttributeError: attribute ndim is a read only class attribute and cannot be modified on class VectorN
        >>> V.ndim = 2
        Traceback (most recent call last):
            ...
        AttributeError: 'VectorN' object attribute 'ndim' is read-only

        It's protected against initialization or resizing to a shape that wouldn't be a VectorN anymore

        >>> V = VectorN([[0, 1], [2, 3]])
        Traceback (most recent call last):
            ...
        TypeError: cannot initialize a VectorN of shape (4,) from [[0, 1], [2, 3]] of shape (2, 2),
        as it would truncate data or reduce the number of dimensions

        >>> V.resize((2, 2))
        Traceback (most recent call last):
            ...
        TypeError: new shape (2, 2) is not compatible with class VectorN

        Other Array types can be cast to VectorN, but truncating data or reducing dimensions is not allowed
        to avoid silent loss of data in a conversion, use an explicit resize / trim / sub-array extraction

        >>> A = Array(range(4), shape=(4,))
        >>> V = VectorN(A)
        >>> V
        VectorN([0, 1, 2, 3])

        >>> A = Array(range(4), shape=(2, 2))
        >>> V = VectorN(A)
        Traceback (most recent call last):
            ...
        TypeError: cannot cast a Array of shape (2, 2) to a VectorN of shape (4,),
        as it would truncate data or reduce the number of dimensions

        As for Array, __init__ is a shallow copy, note that as VectorN don't have sub-arrays,
        shallow and deep copy amounts to the same thing.

        >>> A = Array(range(4), shape=(4,))
        >>> V = VectorN(A)
        >>> V == A
        False
        >>> V is A
        False
        >>> V.isEquivalent(A)
        True
        >>> V[0] == A[0]
        True
        >>> V[0] is A[0]
        True
    """
    __slots__ = ['_data', '_shape', '_size']

    #A VectorN is a one-dimensional Array, ndim is thus stored as a class readonly attribute
    ndim = 1

    def _getshape(self):
        return (len(self),)
    def _setshape(self, newshape):
        self.resize(newshape)
    # shape, ndim, size and data properties
    shape = property(_getshape, _setshape, None,
                     """ v.shape : tuple of one int

                         Shape of the VectorN, as Vectors are one-dimensional Arrays: v.shape = (v.size,).

                         It can be queried, or set to change the VectorN's shape similarly to the resize method,
                         as the only way to change a VectorN's shape is to resize it.

                         >>> V = VectorN(1, 2, 3)
                         >>> V
                         VectorN([1, 2, 3])
                         >>> V.shape=(4)
                         >>> V
                         VectorN([1, 2, 3, 0])
                         >>> V.shape=(2, 2)
                         Traceback (most recent call last):
                             ...
                         TypeError: new shape (2, 2) is not compatible with class VectorN

                         Related : see Array.resize method.
                     """)
    # ndim = property(lambda x : 1, None, None, "A VectorN is a one-dimensional Array")
    size = property(lambda x : len(x), None, None, "Number of components in the VectorN")

    # common operators are herited from Arrays

    # overloaded operators
    def __mul__(self, other):
        """ a.__mul__(b) <==> a*b

            If b is a VectorN, __mul__ is mapped to the dot product of the two vectors a and b,
            If b is a MatrixN, __mul__ is mapped to VectorN a by MatrixN b multiplication (post multiplication or transformation of a by b),
            otherwise, returns the result of the element wise multiplication of a and b if b is convertible to Array,
            multiplies every component of a by b if b is a single numeric value
        """
        if isinstance(other, VectorN) :
            return self.dot(other)
        elif isinstance(other, MatrixN) :
            # will defer to MatrixN rmul
            return NotImplemented
        else :
            # will defer to Array.__mul__
            return Array.__mul__(self, other)
    def __rmul__(self, other):
        """ a.__rmul__(b) <==> b*a

            If b is a VectorN, __rmul__ is mapped to the dot product of the two vectors a and b,
            If b is a MatrixN, __rmul__ is mapped to MatrixN b by VectorN a multiplication,
            otherwise, returns the result of the element wise multiplication of b and a if b is convertible to Array,
            multiplies every component of a by b if b is a single numeric value
        """
        if isinstance(other, VectorN) :
            return self.dot(other)
        elif isinstance(other, MatrixN) :
            # will defer to MatrixN mul
            return NotImplemented
        else :
            # will defer to Array.__rmul__
            return Array.__rmul__(self, other)
    def __imul__(self, other):
        """ a.__imul__(b) <==> a *= b

            In place multiplication of VectorN a and b, see __mul__, result must fit a's type
        """
        res = self*other
        if isinstance(res, self.__class__) :
            return self.__class__(res)
        else :
            raise TypeError, "result of in place multiplication of %s by %s is not a %s" % (clsname(self), clsname(other), clsname(self))

    # special operators
    def __xor__(self, other):
        """ a.__xor__(b) <==> a^b

            Defines the cross product operator between two vectors,
            if b is a MatrixN, a^b is equivalent to transforming a by the inverse transpose MatrixN of b,
            often used to transform normals
        """
        if isinstance(other, VectorN) :
            return self.cross(other)
        elif isinstance(other, MatrixN) :
            return self.transformAsNormal(other)
        else :
            return NotImplemented
    def __ixor__(self, other):
        """ a.__xor__(b) <==> a^=b

            Inplace cross product or transformation by inverse transpose MatrixN of b is v is a MatrixN
        """
        res = self.__xor__(other)
        if isinstance(res, self.__class__) :
            return self.__class__(res)
        else :
            raise TypeError, "result of in place multiplication of %s by %s is not a %s" % (clsname(self), clsname(other), clsname(self))

    # additional methods

    def cross(self, other):
        """ u.cross(v) <==> cross(u, v)

            cross product of u and v, u and v should be 3 dimensional vectors.

        """
        try :
            nself, nother = coerce(VectorN(self), other)
            assert len(nself) == len(nother) == 3
        except :
            raise TypeError, "%s not convertible to %s, cross product is only defined for two Vectors of size 3" % (clsname(other), clsname(self))
        return VectorN([nself[1]*nother[2] - nself[2]*nother[1],
                nself[2]*nother[0] - nself[0]*nother[2],
                nself[0]*nother[1] - nself[1]*nother[0]])
    def dot(self, other):
        """ u.dot(v) <==> dot(u, v)

            dot product of u and v, u and v should be Vectors of identical size.


        """
        try :
            nself, nother = coerce(VectorN(self), other)
            assert len(nself) == len(nother)
        except :
            raise TypeError, "%s not convertible to %s, dot product is only defined for two Vectors of identical size" % (clsname(other), clsname(self))
        return reduce(operator.add, map(operator.mul, nself, nother))
    def outer(self, other):
        """ u.outer(v) <==> outer(u, v)

            Outer product of vectors u and v
        """
        try :
            nself, nother = coerce(VectorN(self), other)
        except :
            raise TypeError, "%s not convertible to %s, outer product is only defined for two Vectors" % (clsname(other), clsname(self))
        return MatrixN([nother*x for x in nself])
    def transformAsNormal(self, other):
        """ u.transformAsNormal(m) --> VectorN

            Equivalent to transforming u by the inverse transpose MatrixN of m, used to transform normals.

        """
        try :
            nother = MatrixN(other)
        except :
            raise TypeError, "%s not convertible to MatrixN" % (clsname(other))
        return nother.transpose().inverse().__rmul__(self)

    # min, max etc methods derived from array

    # length methods can be more efficient than for Arrays as there is only one axis
    def sqlength(self):
        """ u.sqlength() --> float

            Returns the square length of u, ie u.dot(u).

        """
        return reduce(operator.add, map(lambda x:x**2, self))
    def length(self):
        """ u.length() --> float

            Returns the length of u, ie sqrt(u.dot(u))

        """
        return sqrt(self.sqlength())
    def normal(self):
        """ u.normal() --> VectorN

            Returns a normalized copy of self. Overriden to be consistant with Maya API and MEL unit command,
            does not raise an exception if self if of zero length, instead returns a copy of self

        """
        try :
            return self/self.length()
        except :
            return self
    unit = normal
    def isParallel(self, other, tol=eps):
        """ u.isParallel(v[, tol]) --> bool

            Returns True if both arguments considered as VectorN are parallel within the specified tolerance
        """
        try :
            nself, nother = coerce(VectorN(self), other)
        except :
            raise TypeError, "%s not convertible to %s, isParallel is only defined for two Vectors" % (clsname(other), clsname(self))
        return (abs(nself.dot(nother) - nself.length()*nother.length()) <= tol)
    def angle(self, other, third=None):
        """ u.angle(v) <==> angle(u, v) --> float

            Returns the angle of rotation between u and v, 3 dimensional Vectors representing 3D vectors.

            Note : this angle is not signed, use axis to know the direction of the rotation

            Alternatively can use the form a.angle(b, c), where a, b, c are 4 dimensional Vectors representing 3D points,
            it is then equivalent to angle(b-a, c-a)

        """
        if third is not None :
            try :
                nself, nother = coerce(VectorN(self), other)
                nself, nthird = coerce(VectorN(self), third)
                assert len(nself) == len(nother) == len(nthird) == 4
            except :
                raise TypeError, "angle is defined for 3 vectors of size 4 representing 3D points"
            nself, nother = (nother-nself)[:3], (nthird-nself)[:3]
        else :
            try :
                nself, nother = coerce(VectorN(self), other)
                assert len(nself) == len(nother) == 3
            except :
                raise TypeError, "angle is defined for 2 vectors of size 3 representing 3D vectors"
        l = float(nself.length() * nother.length())
        if l > 0 :
            return acos( nself.dot(nother) / l )
        else :
            return 0.0
    def axis(self, other, third=None, normalize=False):
        """ u.axis(v[, normalize=False]) <==> axis(u, v[, normalize=False])

            Returns the axis of rotation from u to v as the vector n = u ^ v, u and v
            being 3 dimensional Vectors representing 3D vectors.
            If the normalize keyword argument is set to True, n is also normalized.


            Alternatively can use the form a.axis(b, c), where a, b, c are 4 dimensional Vectors representing 3D points,
            it is then equivalent to axis(b-a, c-a).

        """
        if third is not None :
            try :
                nself, nother = coerce(VectorN(self), other)
                nself, nthird = coerce(VectorN(self), third)
                assert len(nself) == len(nother) == len(nthird) == 4
            except :
                raise TypeError, "axis is defined for 3 vectors of size 4 representing 3D points"
            nself, nother = (nother-nself)[:3], (nthird-nself)[:3]
        else :
            try :
                nself, nother = coerce(VectorN(self), other)
                assert len(nself) == len(nother) == 3
            except :
                raise TypeError, "axis is defined for 2 vectors of size 3 representing 3D vectors"
        if normalize :
            return nself.cross(nother).normal()
        else :
            return nself.cross(nother)
    def cotan(self, other, third=None):
        """ u.cotan(v) <==> cotan(u, v)

            Returns the cotangent of the u, v angle, u and v should be 3 dimensional Vectors representing 3D vectors.

            Alternatively can use the form a.cotan(b, c), where a, b, c are 4 dimensional Vectors representing 3D points,
            it is then equivalent to cotan(b-a, c-a)
        """
        if third is not None :
            try :
                nself, nother = coerce(VectorN(self), other)
                nself, nthird = coerce(VectorN(self), third)
                assert len(nself) == len(nother) == len(nthird) == 4
            except :
                raise TypeError, "cotan is defined for 3 vectors of size 4 representing 3D points"
            nself, nother = (nother-nself)[:3], (nthird-nself)[:3]
        else :
            try :
                nself, nother = coerce(VectorN(self), other)
                assert len(nself) == len(nother) == 3
            except :
                raise TypeError, "cotan is defined for 2 vectors of size 3 representing 3D vectors"
        return (nself.dot(nother)) / (nself.cross(nother)).length()

    def projectionOnto(self, other):
        """Returns the projection of this vector onto other vector."""
        try :
            nself, nother = coerce(VectorN(self), other)
        except :
            raise NotImplemented, "%s not convertible to %s" % (clsname(other), clsname(self))
        return VectorN( (nself.dot(nother) /  nother.sqlength()) * nother )
    # blend and clamp derived from Array



if __name__ == '__main__' :
    import doctest
    doctest.testmod(verbose=True)

########NEW FILE########
__FILENAME__ = common
"""
Commonly used utilities
"""

import os
import re
import sys
import platform
import pkgutil
import inspect
from re import escape
from path import path
#-----------------------------------------------
#  Pymel Internals
#-----------------------------------------------

#===============================================================================
# Strings
#===============================================================================

def capitalize(s):
    """
    Python's string 'capitalize' method is NOT equiv. to mel's capitalize, which preserves
    capital letters.

        >>> capitalize( 'fooBAR' )
        'FooBAR'
        >>> 'fooBAR'.capitalize()
        'Foobar'

    :rtype: string
    """
    return s[0].upper() + s[1:]

def uncapitalize(s, preserveAcronymns=False):
    """preserveAcronymns enabled ensures that 'NTSC' does not become 'nTSC'

    :rtype: string

    """
    try:
        if preserveAcronymns and s[0:2].isupper():
            return s
    except IndexError: pass

    return s[0].lower() + s[1:]

def unescape( s ):
    """
    :rtype: string
    """
    chars = [ r'"', r"'" ]
    for char in chars:
        tokens = re.split( r'(\\*)' + char,  s )
        for i in range(1,len(tokens),2 ):
            if tokens[i]:
                tokens[i] = tokens[i][:-1]+'"'
        s = ''.join(tokens)
    return s

#===============================================================================
# Deprecated types
#===============================================================================

def cacheProperty(getter, attr_name, fdel=None, doc=None):
    """a property type for getattr functions that only need to be called once per instance.
        future calls to getattr for this property will return the previous non-null value.
        attr_name is the name of an attribute in which to store the cached values"""
    def fget(obj):
        val = None

        if hasattr(obj,attr_name):
            val = getattr(obj, attr_name)
            #print "cacheProperty: retrieving cache: %s.%s = %s" % (obj, attr_name, val)

        if val is None:
            #print "cacheProperty: running getter: %s.%s" %  (obj, attr_name)
            val = getter(obj)
            #print "cacheProperty: caching: %s.%s = %s" % (obj, attr_name, val)
            setattr(obj, attr_name, val )
        return val

    def fset(obj, val):
        #print "cacheProperty: setting attr %s.%s=%s" % (obj, attr_name, val)
        setattr(obj, attr_name, val)

    return property( fget, fset, fdel, doc)

#===============================================================================
# System
#===============================================================================

def timer( command='pass', number=10, setup='import pymel' ):
    import timeit
    t = timeit.Timer(command, setup)
    time = t.timeit(number=number)
    print "command took %.2f sec to execute" % time
    return time

def interpreterBits():
    """
    Returns the number of bits of the architecture the interpreter was compiled on
    (ie, 32 or 64).

    :rtype: `int`
    """
    # NOTE: platform.architecture()[0] returns '64bit' on OSX 10.6 (Snow Leopard)
    # even when Maya is running in 32-bit mode. The struct technique
    # is more reliable.
    return struct.calcsize("P") * 8
    return int(re.match(r"([0-9]+)(bit)?", platform.architecture()[0]).group(1))

#===============================================================================
# Filesystem
#===============================================================================

def toZip( directory, zipFile ):
    """Sample for storing directory to a ZipFile"""
    import zipfile

    zipFile = path(zipFile)
    if zipFile.exists(): zipFile.remove()

    z = zipfile.ZipFile(
        zipFile, 'w', compression=zipfile.ZIP_DEFLATED
    )
    if not directory.endswith(os.sep):
        directory += os.sep

    directory = path(directory)

    for subdir in directory.dirs('[a-z]*') + [directory]:
        print "adding ", subdir
        for fname in subdir.files('[a-z]*'):
            archiveName = fname.replace( directory, '' )
            z.write( fname, archiveName, zipfile.ZIP_DEFLATED )
    z.close()
    return zipFile

#===============================================================================
# inspection
#===============================================================================

def subpackages(packagemod):
    """
    Given a module object, returns an iterator which yields a tuple (modulename, moduleobject, ispkg)
    for the given module and all it's submodules/subpackages.
    """
    modpkgs = []
    modpkgs_names = set()
    if hasattr(packagemod, '__path__'):
        yield packagemod.__name__, packagemod, True
        for importer, modname, ispkg in pkgutil.walk_packages(packagemod.__path__, packagemod.__name__+'.'):
            if modname not in sys.modules:
                try:
                    mod = importer.find_module(modname).load_module(modname)
                except Exception, e:
                    print "error importing %s: %s" %  ( modname, e)
            else:
                mod = sys.modules[modname]
            yield modname, mod, ispkg
    else:
        yield packagemod.__name__, packagemod, False

########NEW FILE########
__FILENAME__ = conditions
#------------------------------------------------------------------------------
# Condition objects - used for chaining together tests that yield True/False results
#------------------------------------------------------------------------------

class Condition(object):
    """
    Used to chain together objects for conditional testing.
    """
    class NO_DATA(Exception): pass

    def __init__(self, value=None):
        self.value = value

    def eval(self, data=NO_DATA):
        return bool(self.value)

    def __or__(self, other):
        return Or(self, other)
    def __ror__(self, other):
        return Or(other, self)

    def __and__(self, other):
        return And(self, other)
    def __rand__(self, other):
        return And(other, self)

    def __invert__(self):
        return Inverse(self)

    def __nonzero__(self):
        return self.eval()

    def __str__(self):
        return str(self.value)

Always = Condition(True)

Never = Condition(False)

class Inverse(Condition):
    def __init__(self, toInvert):
        self.toInvert = toInvert

    def eval(self, data=Condition.NO_DATA):
        return not self.toInvert.eval(data)

    def __str__(self):
        return "not %s" % self.toInvert

class AndOrAbstract(Condition):
    def __init__(self, *args):
        self.args = []
        for arg in args:
            if isinstance(arg, self.__class__):
                self.args.extend(arg.args)
            else:
                self.args.append(arg)

    def eval(self, data=Condition.NO_DATA):
        for arg in self.args:
            if isinstance(arg, Condition):
                val = arg.eval(data)
            else:
                val = bool(arg)
            if val == self._breakEarly:
                return self._breakEarly
        return not self._breakEarly

    def __str__(self):
        return "(%s)" % self._strJoiner.join([str(x) for x in self.args])

class And(AndOrAbstract):
    _breakEarly = False
    _strJoiner = ' and '

class Or(AndOrAbstract):
    _breakEarly = True
    _strJoiner = ' or '
########NEW FILE########
__FILENAME__ = decoration


def decorated(origFunc, newFunc, decoration=None):
    """
    Copies the original function's name/docs/signature to the new function, so that the docstrings
    contain relevant information again.
    Most importantly, it adds the original function signature to the docstring of the decorating function,
    as well as a comment that the function was decorated. Supports nested decorations.
    """

    if not hasattr(origFunc, '_decorated'):
        # a func that has yet to be treated - add the original argspec to the docstring
        import inspect
        try:
            newFunc.__doc__ = "Original Arguments: %s\n\n" % inspect.formatargspec(*inspect.getargspec(origFunc))
        except TypeError:
            newFunc.__doc__ = "\n"
        if origFunc.__doc__:
            newFunc.__doc__ += origFunc.__doc__
    else:
        newFunc.__doc__ = origFunc.__doc__
    if decoration:
        newFunc.__doc__ += "\n(Decorated by %s)" % decoration
    newFunc.__name__ = origFunc.__name__
    newFunc.__module__ = origFunc.__module__
    newFunc._decorated = True   # stamp the function as decorated

def decorator(func):
    """
    Decorator for decorators. Calls the 'decorated' function above for the decorated function, to preserve docstrings.
    """
    def decoratorFunc(origFunc):
        newFunc = func(origFunc)
        decorated(origFunc, newFunc, "%s.%s" % (func.__module__, func.__name__))
        return newFunc
    decorated(func,decoratorFunc, "%s.%s" % (__name__, "decorator"))
    return decoratorFunc



def interface_wrapper( doer, args=[], varargs=None, varkw=None, defaults=None ):
    """
    A wrapper which allows factories to programatically create functions with
    precise input arguments, instead of using the argument catch-all:

        >>> def f( *args, **kwargs ): #doctest: +SKIP
        ...     pass

    The inputs args, varargs, varkw, and defaults match the outputs of inspect.getargspec

    :param doer: the function to be wrapped.
    :param args: a list of strings to be used as argument names, in proper order
    :param defaults: a list of default values for the arguments. must be less than or equal
        to args in length. if less than, the last element of defaults will be paired with the last element of args,
        the second-to-last with the second-to-last and so on ( see inspect.getargspec ). Arguments
        which pair with a default become keyword arguments.
    """


    # TODO: ensure doer has only an *args parameter

    name = doer.__name__
    storageName = doer.__name__ + '_interfaced'
    g = { storageName : doer }
    kwargs=[]
    if defaults is None:
        ndefaults = 0
    else:
        ndefaults = len(defaults)
    offset = len(args) - ndefaults

    if offset < 0:
        raise TypeError, "The number of defaults cannot exceed the number of arguments"
    for i, arg in enumerate(args):
        # cannot be unicode
        if i >= offset:
            default = defaults[i-offset]
            if not hasattr(default, '__repr__'):
                raise ValueError, "default values must have a __repr__ method"
            defaultStr = repr(default)
            kwargs.append( '%s=%s' % (arg, defaultStr ) )
        else:
            kwargs.append( str(arg) )

    if varargs:
        kwargs.append( '*' + varargs )
    elif varkw:
        kwargs.append( '**' + varkw )

    defStr = """def %s( %s ):
        return %s(%s)""" % (name, ','.join(kwargs), storageName, ','.join(args) )

    exec( defStr ) in g

    func = g[name]
    func.__doc__ = doer.__doc__
    func.__module__ = doer.__module__
    return func

########NEW FILE########
__FILENAME__ = enum
# -*- coding: utf-8 -*-

# enum.py
# Part of enum, a package providing enumerated types for Python.
#
# Copyright © 2007 Ben Finney
# This is free software; you may copy, modify and/or distribute this work
# under the terms of the GNU General Public License, version 2 or later
# or, at your option, the terms of the Python license.

"""Robust enumerated type support in Python

This package provides a module for robust enumerations in Python.

An enumeration object is created with a sequence of string arguments
to the Enum() constructor:

    >>> from enum import Enum
    >>> Colours = Enum('Colours', ['red', 'blue', 'green'])
    >>> Weekdays = Enum('Weekdays', ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun'])

The return value is an immutable sequence object with a value for each
of the string arguments. Each value is also available as an attribute
named from the corresponding string argument:

    >>> pizza_night = Weekdays[4]
    >>> shirt_colour = Colours.green

The values are constants that can be compared with values from
the same enumeration, as well as with integers or strings; comparison with other
values will invoke Python's fallback comparisons:

    >>> pizza_night == Weekdays.fri
    True
    >>> shirt_colour > Colours.red
    True
    >>> shirt_colour == "green"
    True

Each value from an enumeration exports its sequence index
as an integer, and can be coerced to a simple string matching the
original arguments used to create the enumeration:

    >>> str(pizza_night)
    'fri'
    >>> shirt_colour.index
    2
"""

__author_name__ = "Ben Finney"
__author_email__ = "ben+python@benfinney.id.au"
#__author__ = "%s <%s>" % (__author_name__, __author_email__) # confuses epydoc
__date__ = "2007-01-24"
__copyright__ = "Copyright © %s %s" % (
    __date__.split('-')[0], __author_name__
)
__license__ = "Choice of GPL or Python license"
__url__ = "http://cheeseshop.python.org/pypi/enum/"
__version__ = "0.4.3"

import operator

class EnumException(Exception):
    """ Base class for all exceptions in this module """
    def __init__(self):
        if self.__class__ is EnumException:
            raise NotImplementedError, \
                "%s is an abstract class for subclassing" % self.__class__

class EnumEmptyError(AssertionError, EnumException):
    """ Raised when attempting to create an empty enumeration """

    def __str__(self):
        return "Enumerations cannot be empty"

class EnumBadKeyError(TypeError, EnumException):
    """ Raised when creating an Enum with non-string keys """

    def __init__(self, key):
        self.key = key

    def __str__(self):
        return "Enumeration keys must be strings: %r" % (self.key,)

class EnumImmutableError(TypeError, EnumException):
    """ Raised when attempting to modify an Enum """

    def __init__(self, *args):
        self.args = args

    def __str__(self):
        return "Enumeration does not allow modification"

class EnumBadDefaultKeyError(ValueError, EnumException):
    """ Raised when a supplied default key for a value was not present """
    def __init__(self, val, key):
        self.val = val
        self.key = key

    def __str__(self):
        return "Given default key %r for index %r not present in keys" % (self.key, self.val)

class EnumValue(object):
    """ A specific value of an enumerated type """

    def __init__(self, enumtype, index, key, doc=None):
        """ Set up a new instance """
        self.__enumtype = enumtype
        self.__index = index
        self.__key = key
        self.__doc = doc

    def __get_enumtype(self):
        return self.__enumtype
    enumtype = property(__get_enumtype)

    def __get_key(self):
        return self.__key
    key = property(__get_key)

    def __str__(self):
        return "%s" % (self.key)
    def __int__(self):
        return self.index

    def __get_index(self):
        return self.__index
    index = property(__get_index)

    def __repr__(self):
        if self.__doc:
            return "EnumValue(%r, %r, %r, %r, %r)" % (
                self.__enumtype._name,
                self.__index,
                self.__key,
                self.__doc,
            )
        else:
            return "EnumValue(%r, %r, %r)" % (
                self.__enumtype._name,
                self.__index,
                self.__key,
            )

    def _asTuple(self):
        return (self.__index, self.__key, self.__doc)

    def __hash__(self):
        return hash(self.__index)

#    def __cmp__(self, other):
#        result = NotImplemented
#        self_type = self.enumtype
#        try:
#            assert self_type == other.enumtype
#            result = cmp(self.index, other.index)
#        except (AssertionError, AttributeError):
#            result = NotImplemented
#
#        return result

    def __cmp__(self, other):
        result = NotImplemented
        self_type = self.enumtype
        try:
            assert self_type == other.enumtype
            result = cmp(self.index, other.index)
        except (AssertionError, AttributeError):
            if isinstance(other, basestring):
                result=cmp(self.key, other)
            elif isinstance(other, int):
                result=cmp(self.index, other)
            else:
                result = NotImplemented

        return result

# Modified to support multiple keys for the same value
class Enum(object):
    """ Enumerated type """

    def __init__(self, name, keys, **kwargs):
        """ Create an enumeration instance

        :Parameters:
        name : `str`
            The name of this enumeration
        keys : `dict` from `str` to `int`, or iterable of keys
            The keys for the enumeration; if this is a dict, it should map
            from key to it's value (ie, from string to int)
            Otherwise, it should be an iterable of keys, where their index
            within the iterable is their value -ie, passing either of these
            would give the same result:
                {'Red':0,'Green':1,'Blue':2}
                ('Red', 'Green', 'Blue')
        multiKeys : `bool`
            Defaults to False
            If True, allows multiple keys per value - ie,
                Enum('Names', {'Bob':0,'Charles':1,'Chuck':1}, multiKeys=True)
            When looking up a key from a value, a single key is always returned
            - see defaultKeys for a discussion of which key this is.
            When multiKeys is enabled, the length of keys and values may not be
            equal.
            If False (default), then the end result enum will always have a
            one-to-one key / value mapping; if multiple keys are supplied for a
            a single value, then which key is used is indeterminate (an error
            will not be raised).
        defaultKeys : `dict` from `int` to `string`
            If given, should be a map from values to the 'default' key to
            return for that value when using methods like getKey(index)
            This will only be used if the value actually has multiple keys
            mapping to it, and in this case, the specified default key must be
            present within keys (if not, a EnumBadDefaultKeyError is raised).
            If there are multiple keys for a given value, and no defaultKey is
            provided, which one is used is undefined.
        docs : `dict` from `str` to `int, or None
            if given, should provide a map from keys to an associated docstring
            for that key; the dict need not provide an entry for every key
        """

        if not keys:
            raise EnumEmptyError()

        defaultKeys = kwargs.pop('defaultKeys', {})
        multiKeys = kwargs.pop('multiKeys', False)
        docs = kwargs.pop('docs', {})

        # Keys for which there are multiple keys mapping to the same
        # value, but are not the default key for that value
        extraKeys = {}

        if operator.isMappingType(keys):
            if not multiKeys:
                reverse = dict( [ (v,k) for k,v in keys.items() ] )
            else:
                reverse = dict()
                for key, val in keys.iteritems():
                    reverse.setdefault(val, []).append(key)
                for val, keyList in reverse.iteritems():
                    if len(keyList) == 1:
                        defaultKey = keyList[0]
                    else:
                        if val in defaultKeys:
                            defaultKey = defaultKeys[val]
                            if defaultKey not in keyList:
                                raise EnumBadDefaultKeyError(val, defaultKey)
                        else:
                            defaultKey = keyList[0]
                        for multiKey in keyList:
                            if multiKey != defaultKey:
                                extraKeys[multiKey] = val
                    reverse[val] = defaultKey
            keygen = [ ( v, reverse[v]) for v in sorted(reverse.keys()) ]
            values = {}
        else:
            keygen = enumerate( keys )
            values = [None] * len(keys)

        value_type= kwargs.get('value_type', EnumValue)
        #keys = tuple(keys)

        keyDict = {}
        for val, key in keygen:
            #print val, key
            value = value_type(self, val, key, docs.get(key))
            values[val] = value
            keyDict[key] = val
            try:
                super(Enum, self).__setattr__(key, value)
            except TypeError, e:
                raise EnumBadKeyError(key)

        for key, val in extraKeys.iteritems():
            # throw away any docs for the extra keys
            keyDict[key] = val

        if not operator.isMappingType(values):
            values = tuple(values)

        super(Enum, self).__setattr__('_keys', keyDict)
        super(Enum, self).__setattr__('_values', values)
        super(Enum, self).__setattr__('_docs', docs)
        super(Enum, self).__setattr__('_name', name)

    @property
    def name(self):
        return self._name

    def __eq__(self, other):
        if not isinstance(other, Enum):
            return False
        if not self._keys == other._keys:
            return False
        # For values, can't just compare them straight up, as the values
        # contain a ref to this Enum class, and THEIR compare compares the
        # Enum class - which would result in a recursive cycle
        # Instead, compare the values' _asTuple
        def valTuples(enum):
            return dict((key, val._asTuple()) for (key, val)
                        in enum._values.iteritems())
        return valTuples(self) == valTuples(other)

    def __ne__(self, other):
        return not self == other

    def __repr__(self):
        return '%s(\n%s)' % (self.__class__.__name__, ',\n'.join([ repr(v) for v in self.values()]))

    def __str__(self):
        return '%s%s' % (self.__class__.__name__, self.keys())

    def __setattr__(self, name, value):
        raise EnumImmutableError(name)

    def __delattr__(self, name):
        raise EnumImmutableError(name)

    def __len__(self):
        return len(self._values)

    def __getitem__(self, index):
        return self._values[index]

    def __setitem__(self, index, value):
        raise EnumImmutableError(index)

    def __delitem__(self, index):
        raise EnumImmutableError(index)

    def __iter__(self):
        return iter(self._values)

    def __contains__(self, value):
        is_member = False
        if isinstance(value, basestring):
            is_member = (value in self._keys)
        else:
            # EnumValueCompareError was never defined...
#            try:
#                is_member = (value in self._values)
#            except EnumValueCompareError:
#                is_member = False
            is_member = (value in self._values)
        return is_member

    def getIndex(self, key):
        """Get an index value from a key
        This method always returns an index. If a valid index is passed instead
        of a key, the index will be returned unchanged.  This is useful when you
        need an index, but are not certain whether you are starting with a key
        or an index.

            >>> units = Enum('units', ['invalid', 'inches', 'feet', 'yards', 'miles', 'millimeters', 'centimeters', 'kilometers', 'meters'])
            >>> units.getIndex('inches')
            1
            >>> units.getIndex(3)
            3
            >>> units.getIndex('hectares')
            Traceback (most recent call last):
              ...
            ValueError: invalid enumerator key: 'hectares'
            >>> units.getIndex(10)
            Traceback (most recent call last):
              ...
            ValueError: invalid enumerator index: 10
        """
        if isinstance(key, int):
            # got a potential index : checking if it's valid
            if key in self._values:
                return key
            else:
                raise ValueError, "invalid enumerator index: %r" % (key,)
        else:
            # got a key: retrieving index
            try:
                return self._keys[str(key)]
            except:
                raise ValueError, "invalid enumerator key: %r" % (key,)

    def getKey(self, index):
        """
        Get a key value from an index
        This method always returns a key. If a valid key is passed instead of an
        index, the key will be returned unchanged.  This is useful when you need
        a key, but are not certain whether you are starting with a key or an
        index.

            >>> units = Enum('units', ['invalid', 'inches', 'feet', 'yards', 'miles', 'millimeters', 'centimeters', 'kilometers', 'meters'])
            >>> units.getKey(2)
            'feet'
            >>> units.getKey('inches')
            'inches'
            >>> units.getKey(10)
            Traceback (most recent call last):
              ...
            ValueError: invalid enumerator index: 10
            >>> units.getKey('hectares')
            Traceback (most recent call last):
              ...
            ValueError: invalid enumerator key: 'hectares'
        """

        if isinstance(index, int):
            # got an index: retrieving key
            try:
                return self._values[index].key
            except:
                raise ValueError, "invalid enumerator index: %r" % index
        else:
            # got a potential key : checking if it's valid
            if str(index) in self._keys:
                return index
            else:
                raise ValueError, "invalid enumerator key: %r" % index


    def values(self):
        "return a list of `EnumValue`s"
        if operator.isMappingType(self._values):
            return tuple([ self._values[k] for k in sorted(self._values.keys()) ])
        else:
            return self._values

    def keys(self):
        "return a list of keys as strings"
        if not hasattr(self, '_keyStrings'):
            if operator.isMappingType(self._values):
                keyStrings = tuple([ self._values[k].key for k in sorted(self._values.keys()) ])
            else:
                keyStrings = tuple([ v.key for v in self._values ])
            super(Enum, self).__setattr__('_keyStrings', keyStrings)
        return self._keyStrings

import utilitytypes
class EnumDict(utilitytypes.EquivalencePairs):
    """
    This class provides a dictionary type for storing enumerations.  Keys are string labels, while
    values are enumerated integers.

    To instantiate, pass a sequence of string arguments to the EnumDict() constructor:

        >>> from enum import EnumDict
        >>> Colours = EnumDict(['red', 'blue', 'green'])
        >>> Weekdays = EnumDict(['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun'])
        >>> sorted(Weekdays.items())
        [('fri', 4), ('mon', 0), ('sat', 5), ('sun', 6), ('thu', 3), ('tue', 1), ('wed', 2)]

    Alternately, a dictionary of label-value pairs can be provided:

        >>> Numbers = EnumDict({'one': 1, 'two': 2, 'hundred' : 100, 'thousand' : 1000 } )

    To convert from one representation to another, just use normal dictionary retrieval, it
    works in either direction:

        >>> Weekdays[4]
        'fri'
        >>> Weekdays['fri']
        4

    If you need a particular representation, but don't know what you're starting from ( for
    example, a value that was passed as an argument ) you can use `EnumDict.key` or
    `EnumDict.value`:

        >>> Weekdays.value(3)
        3
        >>> Weekdays.value('thu')
        3
        >>> Weekdays.key(2)
        'wed'
        >>> Weekdays.key('wed')
        'wed'
    """

    def __init__(self, keys, **kwargs):
        """ Create an enumeration instance """

        if not keys:
            raise EnumEmptyError()

        if operator.isMappingType(keys):
            items = keys.items()
            if isinstance(items[0][0],int):
                byKey = dict( (k,v) for v,k in items )
            else:
                byKey = keys
        else:
            byKey = dict( (k,v) for v,k in enumerate( keys ) )
        super(EnumDict,self).__init__(byKey)

#        for key, value in byKey.items():
#            try:
#                super(EnumDict, self).__setattr__(key, value)
#            except TypeError, e:
#                raise EnumBadKeyError(key)
#
#        super(EnumDict, self).__setattr__('_reverse', {})
#        self.update(byKey)
#
#    def __setattr__(self, name, value):
#        raise EnumImmutableError(name)
#
#    def __delattr__(self, name):
#        raise EnumImmutableError(name)
#
#    def __setitem__(self, index, value):
#        raise EnumImmutableError(index)
#
#    def __delitem__(self, index):
#        raise EnumImmutableError(index)

    def __repr__(self):
        return "%s(%s)" % (self.__class__.__name__, super(EnumDict, self).__repr__())

    def value(self, key):
        """
        get an index value from a key. this method always returns an index. if a valid index is passed instead of a key, the index will
        be returned unchanged.  this is useful when you need an index, but are not certain whether you are starting with a key or an index.

            >>> units = EnumDict(['invalid', 'inches', 'feet', 'yards', 'miles', 'millimeters', 'centimeters', 'kilometers', 'meters'])
            >>> units.value('inches')
            1
            >>> units.value(3)
            3
            >>> units.value('hectares')
            Traceback (most recent call last):
              ...
            ValueError: invalid enumerator key: 'hectares'
            >>> units.value(10) #doctest: +ELLIPSIS
            Traceback (most recent call last):
              ...
            ValueError: invalid enumerator value: 10
        """
        if isinstance(key, int):
            # got a potential index : checking if it's valid
            if key in self.values():
                return key
            else:
                raise ValueError, "invalid enumerator value: %r" % key
        else:
            # got a key: retrieving index
            try:
                return dict.__getitem__(self, key)
            except KeyError:
                raise ValueError, "invalid enumerator key: %r" % key

    def key(self, index):
        """
        get a key value from an index. this method always returns a key. if a valid key is passed instead of an index, the key will
        be returned unchanged.  this is useful when you need a key, but are not certain whether you are starting with a key or an index.

            >>> units = EnumDict(['invalid', 'inches', 'feet', 'yards', 'miles', 'millimeters', 'centimeters', 'kilometers', 'meters'])
            >>> units.key(2)
            'feet'
            >>> units.key('inches')
            'inches'
            >>> units.key(10)  #doctest: +ELLIPSIS
            Traceback (most recent call last):
              ...
            ValueError: invalid enumerator value: 10
            >>> units.key('hectares')
            Traceback (most recent call last):
              ...
            ValueError: invalid enumerator key: 'hectares'
        """

        if isinstance(index, int):
            # got an index: retrieving key
            try:
                return self._reverse[index]
            except KeyError:
                raise ValueError( "invalid enumerator value: %r" % index )
        else:
            # got a potential key : checking if it's valid
            if index in dict.keys(self):
                return index
            else:
                raise ValueError( "invalid enumerator key: %r" % index)


    def values(self):
        "return a list of ordered integer values"
        return sorted(dict.values(self))


    def keys(self):
        "return a list of keys as strings ordered by their enumerator value"
        return [ self._reverse[v] for v in self.values() ]

########NEW FILE########
__FILENAME__ = BeautifulSoup
"""Beautiful Soup
Elixir and Tonic
"The Screen-Scraper's Friend"
http://www.crummy.com/software/BeautifulSoup/

Beautiful Soup parses a (possibly invalid) XML or HTML document into a
tree representation. It provides methods and Pythonic idioms that make
it easy to navigate, search, and modify the tree.

A well-formed XML/HTML document yields a well-formed data
structure. An ill-formed XML/HTML document yields a correspondingly
ill-formed data structure. If your document is only locally
well-formed, you can use this library to find and process the
well-formed part of it.

Beautiful Soup works with Python 2.2 and up. It has no external
dependencies, but you'll have more success at converting data to UTF-8
if you also install these three packages:

* chardet, for auto-detecting character encodings
  http://chardet.feedparser.org/
* cjkcodecs and iconv_codec, which add more encodings to the ones supported
  by stock Python.
  http://cjkpython.i18n.org/

Beautiful Soup defines classes for two main parsing strategies:

 * BeautifulStoneSoup, for parsing XML, SGML, or your domain-specific
   language that kind of looks like XML.

 * BeautifulSoup, for parsing run-of-the-mill HTML code, be it valid
   or invalid. This class has web browser-like heuristics for
   obtaining a sensible parse tree in the face of common HTML errors.

Beautiful Soup also defines a class (UnicodeDammit) for autodetecting
the encoding of an HTML or XML document, and converting it to
Unicode. Much of this code is taken from Mark Pilgrim's Universal Feed Parser.

For more than you ever wanted to know about Beautiful Soup, see the
documentation:
http://www.crummy.com/software/BeautifulSoup/documentation.html

Here, have some legalese:

Copyright (c) 2004-2008, Leonard Richardson

All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

  * Redistributions in binary form must reproduce the above
    copyright notice, this list of conditions and the following
    disclaimer in the documentation and/or other materials provided
    with the distribution.

  * Neither the name of the the Beautiful Soup Consortium and All
    Night Kosher Bakery nor the names of its contributors may be
    used to endorse or promote products derived from this software
    without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE, DAMMIT.

"""
from __future__ import generators

__author__ = "Leonard Richardson (leonardr@segfault.org)"
__version__ = "3.0.7a"
__copyright__ = "Copyright (c) 2004-2008 Leonard Richardson"
__license__ = "New-style BSD"

from sgmllib import SGMLParser, SGMLParseError
import codecs
import markupbase
import types
import re
import sgmllib
try:
  from htmlentitydefs import name2codepoint
except ImportError:
  name2codepoint = {}
try:
    set
except NameError:
    from sets import Set as set

#These hacks make Beautiful Soup able to parse XML with namespaces
sgmllib.tagfind = re.compile('[a-zA-Z][-_.:a-zA-Z0-9]*')
markupbase._declname_match = re.compile(r'[a-zA-Z][-_.:a-zA-Z0-9]*\s*').match

DEFAULT_OUTPUT_ENCODING = "utf-8"

# First, the classes that represent markup elements.

class PageElement:
    """Contains the navigational information for some part of the page
    (either a tag or a piece of text)"""

    def setup(self, parent=None, previous=None):
        """Sets up the initial relations between this element and
        other elements."""
        self.parent = parent
        self.previous = previous
        self.next = None
        self.previousSibling = None
        self.nextSibling = None
        if self.parent and self.parent.contents:
            self.previousSibling = self.parent.contents[-1]
            self.previousSibling.nextSibling = self

    def replaceWith(self, replaceWith):
        oldParent = self.parent
        myIndex = self.parent.contents.index(self)
        if hasattr(replaceWith, 'parent') and replaceWith.parent == self.parent:
            # We're replacing this element with one of its siblings.
            index = self.parent.contents.index(replaceWith)
            if index and index < myIndex:
                # Furthermore, it comes before this element. That
                # means that when we extract it, the index of this
                # element will change.
                myIndex = myIndex - 1
        self.extract()
        oldParent.insert(myIndex, replaceWith)

    def extract(self):
        """Destructively rips this element out of the tree."""
        if self.parent:
            try:
                self.parent.contents.remove(self)
            except ValueError:
                pass

        #Find the two elements that would be next to each other if
        #this element (and any children) hadn't been parsed. Connect
        #the two.
        lastChild = self._lastRecursiveChild()
        nextElement = lastChild.next

        if self.previous:
            self.previous.next = nextElement
        if nextElement:
            nextElement.previous = self.previous
        self.previous = None
        lastChild.next = None

        self.parent = None
        if self.previousSibling:
            self.previousSibling.nextSibling = self.nextSibling
        if self.nextSibling:
            self.nextSibling.previousSibling = self.previousSibling
        self.previousSibling = self.nextSibling = None
        return self

    def _lastRecursiveChild(self):
        "Finds the last element beneath this object to be parsed."
        lastChild = self
        while hasattr(lastChild, 'contents') and lastChild.contents:
            lastChild = lastChild.contents[-1]
        return lastChild

    def insert(self, position, newChild):
        if (isinstance(newChild, basestring)
            or isinstance(newChild, unicode)) \
            and not isinstance(newChild, NavigableString):
            newChild = NavigableString(newChild)

        position =  min(position, len(self.contents))
        if hasattr(newChild, 'parent') and newChild.parent != None:
            # We're 'inserting' an element that's already one
            # of this object's children.
            if newChild.parent == self:
                index = self.find(newChild)
                if index and index < position:
                    # Furthermore we're moving it further down the
                    # list of this object's children. That means that
                    # when we extract this element, our target index
                    # will jump down one.
                    position = position - 1
            newChild.extract()

        newChild.parent = self
        previousChild = None
        if position == 0:
            newChild.previousSibling = None
            newChild.previous = self
        else:
            previousChild = self.contents[position-1]
            newChild.previousSibling = previousChild
            newChild.previousSibling.nextSibling = newChild
            newChild.previous = previousChild._lastRecursiveChild()
        if newChild.previous:
            newChild.previous.next = newChild

        newChildsLastElement = newChild._lastRecursiveChild()

        if position >= len(self.contents):
            newChild.nextSibling = None

            parent = self
            parentsNextSibling = None
            while not parentsNextSibling:
                parentsNextSibling = parent.nextSibling
                parent = parent.parent
                if not parent: # This is the last element in the document.
                    break
            if parentsNextSibling:
                newChildsLastElement.next = parentsNextSibling
            else:
                newChildsLastElement.next = None
        else:
            nextChild = self.contents[position]
            newChild.nextSibling = nextChild
            if newChild.nextSibling:
                newChild.nextSibling.previousSibling = newChild
            newChildsLastElement.next = nextChild

        if newChildsLastElement.next:
            newChildsLastElement.next.previous = newChildsLastElement
        self.contents.insert(position, newChild)

    def append(self, tag):
        """Appends the given tag to the contents of this tag."""
        self.insert(len(self.contents), tag)

    def findNext(self, name=None, attrs={}, text=None, **kwargs):
        """Returns the first item that matches the given criteria and
        appears after this Tag in the document."""
        return self._findOne(self.findAllNext, name, attrs, text, **kwargs)

    def findAllNext(self, name=None, attrs={}, text=None, limit=None,
                    **kwargs):
        """Returns all items that match the given criteria and appear
        after this Tag in the document."""
        return self._findAll(name, attrs, text, limit, self.nextGenerator,
                             **kwargs)

    def findNextSibling(self, name=None, attrs={}, text=None, **kwargs):
        """Returns the closest sibling to this Tag that matches the
        given criteria and appears after this Tag in the document."""
        return self._findOne(self.findNextSiblings, name, attrs, text,
                             **kwargs)

    def findNextSiblings(self, name=None, attrs={}, text=None, limit=None,
                         **kwargs):
        """Returns the siblings of this Tag that match the given
        criteria and appear after this Tag in the document."""
        return self._findAll(name, attrs, text, limit,
                             self.nextSiblingGenerator, **kwargs)
    fetchNextSiblings = findNextSiblings # Compatibility with pre-3.x

    def findPrevious(self, name=None, attrs={}, text=None, **kwargs):
        """Returns the first item that matches the given criteria and
        appears before this Tag in the document."""
        return self._findOne(self.findAllPrevious, name, attrs, text, **kwargs)

    def findAllPrevious(self, name=None, attrs={}, text=None, limit=None,
                        **kwargs):
        """Returns all items that match the given criteria and appear
        before this Tag in the document."""
        return self._findAll(name, attrs, text, limit, self.previousGenerator,
                           **kwargs)
    fetchPrevious = findAllPrevious # Compatibility with pre-3.x

    def findPreviousSibling(self, name=None, attrs={}, text=None, **kwargs):
        """Returns the closest sibling to this Tag that matches the
        given criteria and appears before this Tag in the document."""
        return self._findOne(self.findPreviousSiblings, name, attrs, text,
                             **kwargs)

    def findPreviousSiblings(self, name=None, attrs={}, text=None,
                             limit=None, **kwargs):
        """Returns the siblings of this Tag that match the given
        criteria and appear before this Tag in the document."""
        return self._findAll(name, attrs, text, limit,
                             self.previousSiblingGenerator, **kwargs)
    fetchPreviousSiblings = findPreviousSiblings # Compatibility with pre-3.x

    def findParent(self, name=None, attrs={}, **kwargs):
        """Returns the closest parent of this Tag that matches the given
        criteria."""
        # NOTE: We can't use _findOne because findParents takes a different
        # set of arguments.
        r = None
        l = self.findParents(name, attrs, 1)
        if l:
            r = l[0]
        return r

    def findParents(self, name=None, attrs={}, limit=None, **kwargs):
        """Returns the parents of this Tag that match the given
        criteria."""

        return self._findAll(name, attrs, None, limit, self.parentGenerator,
                             **kwargs)
    fetchParents = findParents # Compatibility with pre-3.x

    #These methods do the real heavy lifting.

    def _findOne(self, method, name, attrs, text, **kwargs):
        r = None
        l = method(name, attrs, text, 1, **kwargs)
        if l:
            r = l[0]
        return r

    def _findAll(self, name, attrs, text, limit, generator, **kwargs):
        "Iterates over a generator looking for things that match."

        if isinstance(name, SoupStrainer):
            strainer = name
        else:
            # Build a SoupStrainer
            strainer = SoupStrainer(name, attrs, text, **kwargs)
        results = ResultSet(strainer)
        g = generator()
        while True:
            try:
                i = g.next()
            except StopIteration:
                break
            if i:
                found = strainer.search(i)
                if found:
                    results.append(found)
                    if limit and len(results) >= limit:
                        break
        return results

    #These Generators can be used to navigate starting from both
    #NavigableStrings and Tags.
    def nextGenerator(self):
        i = self
        while i:
            i = i.next
            yield i

    def nextSiblingGenerator(self):
        i = self
        while i:
            i = i.nextSibling
            yield i

    def previousGenerator(self):
        i = self
        while i:
            i = i.previous
            yield i

    def previousSiblingGenerator(self):
        i = self
        while i:
            i = i.previousSibling
            yield i

    def parentGenerator(self):
        i = self
        while i:
            i = i.parent
            yield i

    # Utility methods
    def substituteEncoding(self, str, encoding=None):
        encoding = encoding or "utf-8"
        return str.replace("%SOUP-ENCODING%", encoding)

    def toEncoding(self, s, encoding=None):
        """Encodes an object to a string in some encoding, or to Unicode.
        ."""
        if isinstance(s, unicode):
            if encoding:
                s = s.encode(encoding)
        elif isinstance(s, str):
            if encoding:
                s = s.encode(encoding)
            else:
                s = unicode(s)
        else:
            if encoding:
                s  = self.toEncoding(str(s), encoding)
            else:
                s = unicode(s)
        return s

class NavigableString(unicode, PageElement):

    def __new__(cls, value):
        """Create a new NavigableString.

        When unpickling a NavigableString, this method is called with
        the string in DEFAULT_OUTPUT_ENCODING. That encoding needs to be
        passed in to the superclass's __new__ or the superclass won't know
        how to handle non-ASCII characters.
        """
        if isinstance(value, unicode):
            return unicode.__new__(cls, value)
        return unicode.__new__(cls, value, DEFAULT_OUTPUT_ENCODING)

    def __getnewargs__(self):
        return (NavigableString.__str__(self),)

    def __getattr__(self, attr):
        """text.string gives you text. This is for backwards
        compatibility for Navigable*String, but for CData* it lets you
        get the string without the CData wrapper."""
        if attr == 'string':
            return self
        else:
            raise AttributeError, "'%s' object has no attribute '%s'" % (self.__class__.__name__, attr)

    def __unicode__(self):
        return str(self).decode(DEFAULT_OUTPUT_ENCODING)

    def __str__(self, encoding=DEFAULT_OUTPUT_ENCODING):
        if encoding:
            return self.encode(encoding)
        else:
            return self

class CData(NavigableString):

    def __str__(self, encoding=DEFAULT_OUTPUT_ENCODING):
        return "<![CDATA[%s]]>" % NavigableString.__str__(self, encoding)

class ProcessingInstruction(NavigableString):
    def __str__(self, encoding=DEFAULT_OUTPUT_ENCODING):
        output = self
        if "%SOUP-ENCODING%" in output:
            output = self.substituteEncoding(output, encoding)
        return "<?%s?>" % self.toEncoding(output, encoding)

class Comment(NavigableString):
    def __str__(self, encoding=DEFAULT_OUTPUT_ENCODING):
        return "<!--%s-->" % NavigableString.__str__(self, encoding)

class Declaration(NavigableString):
    def __str__(self, encoding=DEFAULT_OUTPUT_ENCODING):
        return "<!%s>" % NavigableString.__str__(self, encoding)

class Tag(PageElement):

    """Represents a found HTML tag with its attributes and contents."""

    def _invert(h):
        "Cheap function to invert a hash."
        i = {}
        for k,v in h.items():
            i[v] = k
        return i

    XML_ENTITIES_TO_SPECIAL_CHARS = { "apos" : "'",
                                      "quot" : '"',
                                      "amp" : "&",
                                      "lt" : "<",
                                      "gt" : ">" }

    XML_SPECIAL_CHARS_TO_ENTITIES = _invert(XML_ENTITIES_TO_SPECIAL_CHARS)

    def _convertEntities(self, match):
        """Used in a call to re.sub to replace HTML, XML, and numeric
        entities with the appropriate Unicode characters. If HTML
        entities are being converted, any unrecognized entities are
        escaped."""
        x = match.group(1)
        if self.convertHTMLEntities and x in name2codepoint:
            return unichr(name2codepoint[x])
        elif x in self.XML_ENTITIES_TO_SPECIAL_CHARS:
            if self.convertXMLEntities:
                return self.XML_ENTITIES_TO_SPECIAL_CHARS[x]
            else:
                return u'&%s;' % x
        elif len(x) > 0 and x[0] == '#':
            # Handle numeric entities
            if len(x) > 1 and x[1] == 'x':
                return unichr(int(x[2:], 16))
            else:
                return unichr(int(x[1:]))

        elif self.escapeUnrecognizedEntities:
            return u'&amp;%s;' % x
        else:
            return u'&%s;' % x

    def __init__(self, parser, name, attrs=None, parent=None,
                 previous=None):
        "Basic constructor."

        # We don't actually store the parser object: that lets extracted
        # chunks be garbage-collected
        self.parserClass = parser.__class__
        self.isSelfClosing = parser.isSelfClosingTag(name)
        self.name = name
        if attrs == None:
            attrs = []
        self.attrs = attrs
        self.contents = []
        self.setup(parent, previous)
        self.hidden = False
        self.containsSubstitutions = False
        self.convertHTMLEntities = parser.convertHTMLEntities
        self.convertXMLEntities = parser.convertXMLEntities
        self.escapeUnrecognizedEntities = parser.escapeUnrecognizedEntities

        # Convert any HTML, XML, or numeric entities in the attribute values.
        convert = lambda(k, val): (k,
                                   re.sub("&(#\d+|#x[0-9a-fA-F]+|\w+);",
                                          self._convertEntities,
                                          val))
        self.attrs = map(convert, self.attrs)

    def get(self, key, default=None):
        """Returns the value of the 'key' attribute for the tag, or
        the value given for 'default' if it doesn't have that
        attribute."""
        return self._getAttrMap().get(key, default)

    def has_key(self, key):
        return self._getAttrMap().has_key(key)

    def __getitem__(self, key):
        """tag[key] returns the value of the 'key' attribute for the tag,
        and throws an exception if it's not there."""
        return self._getAttrMap()[key]

    def __iter__(self):
        "Iterating over a tag iterates over its contents."
        return iter(self.contents)

    def __len__(self):
        "The length of a tag is the length of its list of contents."
        return len(self.contents)

    def __contains__(self, x):
        return x in self.contents

    def __nonzero__(self):
        "A tag is non-None even if it has no contents."
        return True

    def __setitem__(self, key, value):
        """Setting tag[key] sets the value of the 'key' attribute for the
        tag."""
        self._getAttrMap()
        self.attrMap[key] = value
        found = False
        for i in range(0, len(self.attrs)):
            if self.attrs[i][0] == key:
                self.attrs[i] = (key, value)
                found = True
        if not found:
            self.attrs.append((key, value))
        self._getAttrMap()[key] = value

    def __delitem__(self, key):
        "Deleting tag[key] deletes all 'key' attributes for the tag."
        for item in self.attrs:
            if item[0] == key:
                self.attrs.remove(item)
                #We don't break because bad HTML can define the same
                #attribute multiple times.
            self._getAttrMap()
            if self.attrMap.has_key(key):
                del self.attrMap[key]

    def __call__(self, *args, **kwargs):
        """Calling a tag like a function is the same as calling its
        findAll() method. Eg. tag('a') returns a list of all the A tags
        found within this tag."""
        return apply(self.findAll, args, kwargs)

    def __getattr__(self, tag):
        #print "Getattr %s.%s" % (self.__class__, tag)
        if len(tag) > 3 and tag.rfind('Tag') == len(tag)-3:
            return self.find(tag[:-3])
        elif tag.find('__') != 0:
            return self.find(tag)
        raise AttributeError, "'%s' object has no attribute '%s'" % (self.__class__, tag)

    def __eq__(self, other):
        """Returns true iff this tag has the same name, the same attributes,
        and the same contents (recursively) as the given tag.

        NOTE: right now this will return false if two tags have the
        same attributes in a different order. Should this be fixed?"""
        if not hasattr(other, 'name') or not hasattr(other, 'attrs') or not hasattr(other, 'contents') or self.name != other.name or self.attrs != other.attrs or len(self) != len(other):
            return False
        for i in range(0, len(self.contents)):
            if self.contents[i] != other.contents[i]:
                return False
        return True

    def __ne__(self, other):
        """Returns true iff this tag is not identical to the other tag,
        as defined in __eq__."""
        return not self == other

    def __repr__(self, encoding=DEFAULT_OUTPUT_ENCODING):
        """Renders this tag as a string."""
        return self.__str__(encoding)

    def __unicode__(self):
        return self.__str__(None)

    BARE_AMPERSAND_OR_BRACKET = re.compile("([<>]|"
                                           + "&(?!#\d+;|#x[0-9a-fA-F]+;|\w+;)"
                                           + ")")

    def _sub_entity(self, x):
        """Used with a regular expression to substitute the
        appropriate XML entity for an XML special character."""
        return "&" + self.XML_SPECIAL_CHARS_TO_ENTITIES[x.group(0)[0]] + ";"

    def __str__(self, encoding=DEFAULT_OUTPUT_ENCODING,
                prettyPrint=False, indentLevel=0):
        """Returns a string or Unicode representation of this tag and
        its contents. To get Unicode, pass None for encoding.

        NOTE: since Python's HTML parser consumes whitespace, this
        method is not certain to reproduce the whitespace present in
        the original string."""

        encodedName = self.toEncoding(self.name, encoding)

        attrs = []
        if self.attrs:
            for key, val in self.attrs:
                fmt = '%s="%s"'
                if isString(val):
                    if self.containsSubstitutions and '%SOUP-ENCODING%' in val:
                        val = self.substituteEncoding(val, encoding)

                    # The attribute value either:
                    #
                    # * Contains no embedded double quotes or single quotes.
                    #   No problem: we enclose it in double quotes.
                    # * Contains embedded single quotes. No problem:
                    #   double quotes work here too.
                    # * Contains embedded double quotes. No problem:
                    #   we enclose it in single quotes.
                    # * Embeds both single _and_ double quotes. This
                    #   can't happen naturally, but it can happen if
                    #   you modify an attribute value after parsing
                    #   the document. Now we have a bit of a
                    #   problem. We solve it by enclosing the
                    #   attribute in single quotes, and escaping any
                    #   embedded single quotes to XML entities.
                    if '"' in val:
                        fmt = "%s='%s'"
                        if "'" in val:
                            # TODO: replace with apos when
                            # appropriate.
                            val = val.replace("'", "&squot;")

                    # Now we're okay w/r/t quotes. But the attribute
                    # value might also contain angle brackets, or
                    # ampersands that aren't part of entities. We need
                    # to escape those to XML entities too.
                    val = self.BARE_AMPERSAND_OR_BRACKET.sub(self._sub_entity, val)

                attrs.append(fmt % (self.toEncoding(key, encoding),
                                    self.toEncoding(val, encoding)))
        close = ''
        closeTag = ''
        if self.isSelfClosing:
            close = ' /'
        else:
            closeTag = '</%s>' % encodedName

        indentTag, indentContents = 0, 0
        if prettyPrint:
            indentTag = indentLevel
            space = (' ' * (indentTag-1))
            indentContents = indentTag + 1
        contents = self.renderContents(encoding, prettyPrint, indentContents)
        if self.hidden:
            s = contents
        else:
            s = []
            attributeString = ''
            if attrs:
                attributeString = ' ' + ' '.join(attrs)
            if prettyPrint:
                s.append(space)
            s.append('<%s%s%s>' % (encodedName, attributeString, close))
            if prettyPrint:
                s.append("\n")
            s.append(contents)
            if prettyPrint and contents and contents[-1] != "\n":
                s.append("\n")
            if prettyPrint and closeTag:
                s.append(space)
            s.append(closeTag)
            if prettyPrint and closeTag and self.nextSibling:
                s.append("\n")
            s = ''.join(s)
        return s

    def decompose(self):
        """Recursively destroys the contents of this tree."""
        contents = [i for i in self.contents]
        for i in contents:
            if isinstance(i, Tag):
                i.decompose()
            else:
                i.extract()
        self.extract()

    def prettify(self, encoding=DEFAULT_OUTPUT_ENCODING):
        return self.__str__(encoding, True)

    def renderContents(self, encoding=DEFAULT_OUTPUT_ENCODING,
                       prettyPrint=False, indentLevel=0):
        """Renders the contents of this tag as a string in the given
        encoding. If encoding is None, returns a Unicode string.."""
        s=[]
        for c in self:
            text = None
            if isinstance(c, NavigableString):
                text = c.__str__(encoding)
            elif isinstance(c, Tag):
                s.append(c.__str__(encoding, prettyPrint, indentLevel))
            if text and prettyPrint:
                text = text.strip()
            if text:
                if prettyPrint:
                    s.append(" " * (indentLevel-1))
                s.append(text)
                if prettyPrint:
                    s.append("\n")
        return ''.join(s)

    #Soup methods

    def find(self, name=None, attrs={}, recursive=True, text=None,
             **kwargs):
        """Return only the first child of this Tag matching the given
        criteria."""
        r = None
        l = self.findAll(name, attrs, recursive, text, 1, **kwargs)
        if l:
            r = l[0]
        return r
    findChild = find

    def findAll(self, name=None, attrs={}, recursive=True, text=None,
                limit=None, **kwargs):
        """Extracts a list of Tag objects that match the given
        criteria.  You can specify the name of the Tag and any
        attributes you want the Tag to have.

        The value of a key-value pair in the 'attrs' map can be a
        string, a list of strings, a regular expression object, or a
        callable that takes a string and returns whether or not the
        string matches for some custom definition of 'matches'. The
        same is true of the tag name."""
        generator = self.recursiveChildGenerator
        if not recursive:
            generator = self.childGenerator
        return self._findAll(name, attrs, text, limit, generator, **kwargs)
    findChildren = findAll

    # Pre-3.x compatibility methods
    first = find
    fetch = findAll

    def fetchText(self, text=None, recursive=True, limit=None):
        return self.findAll(text=text, recursive=recursive, limit=limit)

    def firstText(self, text=None, recursive=True):
        return self.find(text=text, recursive=recursive)

    #Private methods

    def _getAttrMap(self):
        """Initializes a map representation of this tag's attributes,
        if not already initialized."""
        if not getattr(self, 'attrMap'):
            self.attrMap = {}
            for (key, value) in self.attrs:
                self.attrMap[key] = value
        return self.attrMap

    #Generator methods
    def childGenerator(self):
        for i in range(0, len(self.contents)):
            yield self.contents[i]
        raise StopIteration

    def recursiveChildGenerator(self):
        stack = [(self, 0)]
        while stack:
            tag, start = stack.pop()
            if isinstance(tag, Tag):
                for i in range(start, len(tag.contents)):
                    a = tag.contents[i]
                    yield a
                    if isinstance(a, Tag) and tag.contents:
                        if i < len(tag.contents) - 1:
                            stack.append((tag, i+1))
                        stack.append((a, 0))
                        break
        raise StopIteration

# Next, a couple classes to represent queries and their results.
class SoupStrainer:
    """Encapsulates a number of ways of matching a markup element (tag or
    text)."""

    def __init__(self, name=None, attrs={}, text=None, **kwargs):
        self.name = name
        if isString(attrs):
            kwargs['class'] = attrs
            attrs = None
        if kwargs:
            if attrs:
                attrs = attrs.copy()
                attrs.update(kwargs)
            else:
                attrs = kwargs
        self.attrs = attrs
        self.text = text

    def __str__(self):
        if self.text:
            return self.text
        else:
            return "%s|%s" % (self.name, self.attrs)

    def searchTag(self, markupName=None, markupAttrs={}):
        found = None
        markup = None
        if isinstance(markupName, Tag):
            markup = markupName
            markupAttrs = markup
        callFunctionWithTagData = callable(self.name) \
                                and not isinstance(markupName, Tag)

        if (not self.name) \
               or callFunctionWithTagData \
               or (markup and self._matches(markup, self.name)) \
               or (not markup and self._matches(markupName, self.name)):
            if callFunctionWithTagData:
                match = self.name(markupName, markupAttrs)
            else:
                match = True
                markupAttrMap = None
                for attr, matchAgainst in self.attrs.items():
                    if not markupAttrMap:
                         if hasattr(markupAttrs, 'get'):
                            markupAttrMap = markupAttrs
                         else:
                            markupAttrMap = {}
                            for k,v in markupAttrs:
                                markupAttrMap[k] = v
                    attrValue = markupAttrMap.get(attr)
                    if not self._matches(attrValue, matchAgainst):
                        match = False
                        break
            if match:
                if markup:
                    found = markup
                else:
                    found = markupName
        return found

    def search(self, markup):
        #print 'looking for %s in %s' % (self, markup)
        found = None
        # If given a list of items, scan it for a text element that
        # matches.
        if isList(markup) and not isinstance(markup, Tag):
            for element in markup:
                if isinstance(element, NavigableString) \
                       and self.search(element):
                    found = element
                    break
        # If it's a Tag, make sure its name or attributes match.
        # Don't bother with Tags if we're searching for text.
        elif isinstance(markup, Tag):
            if not self.text:
                found = self.searchTag(markup)
        # If it's text, make sure the text matches.
        elif isinstance(markup, NavigableString) or \
                 isString(markup):
            if self._matches(markup, self.text):
                found = markup
        else:
            raise Exception, "I don't know how to match against a %s" \
                  % markup.__class__
        return found

    def _matches(self, markup, matchAgainst):
        #print "Matching %s against %s" % (markup, matchAgainst)
        result = False
        if matchAgainst == True and type(matchAgainst) == types.BooleanType:
            result = markup != None
        elif callable(matchAgainst):
            result = matchAgainst(markup)
        else:
            #Custom match methods take the tag as an argument, but all
            #other ways of matching match the tag name as a string.
            if isinstance(markup, Tag):
                markup = markup.name
            if markup and not isString(markup):
                markup = unicode(markup)
            #Now we know that chunk is either a string, or None.
            if hasattr(matchAgainst, 'match'):
                # It's a regexp object.
                result = markup and matchAgainst.search(markup)
            elif isList(matchAgainst):
                result = markup in matchAgainst
            elif hasattr(matchAgainst, 'items'):
                result = markup.has_key(matchAgainst)
            elif matchAgainst and isString(markup):
                if isinstance(markup, unicode):
                    matchAgainst = unicode(matchAgainst)
                else:
                    matchAgainst = str(matchAgainst)

            if not result:
                result = matchAgainst == markup
        return result

class ResultSet(list):
    """A ResultSet is just a list that keeps track of the SoupStrainer
    that created it."""
    def __init__(self, source):
        list.__init__([])
        self.source = source

# Now, some helper functions.

def isList(l):
    """Convenience method that works with all 2.x versions of Python
    to determine whether or not something is listlike."""
    return hasattr(l, '__iter__') \
           or (type(l) in (types.ListType, types.TupleType))

def isString(s):
    """Convenience method that works with all 2.x versions of Python
    to determine whether or not something is stringlike."""
    try:
        return isinstance(s, unicode) or isinstance(s, basestring)
    except NameError:
        return isinstance(s, str)

def buildTagMap(default, *args):
    """Turns a list of maps, lists, or scalars into a single map.
    Used to build the SELF_CLOSING_TAGS, NESTABLE_TAGS, and
    NESTING_RESET_TAGS maps out of lists and partial maps."""
    built = {}
    for portion in args:
        if hasattr(portion, 'items'):
            #It's a map. Merge it.
            for k,v in portion.items():
                built[k] = v
        elif isList(portion):
            #It's a list. Map each item to the default.
            for k in portion:
                built[k] = default
        else:
            #It's a scalar. Map it to the default.
            built[portion] = default
    return built

# Now, the parser classes.

class BeautifulStoneSoup(Tag, SGMLParser):

    """This class contains the basic parser and search code. It defines
    a parser that knows nothing about tag behavior except for the
    following:

      You can't close a tag without closing all the tags it encloses.
      That is, "<foo><bar></foo>" actually means
      "<foo><bar></bar></foo>".

    [Another possible explanation is "<foo><bar /></foo>", but since
    this class defines no SELF_CLOSING_TAGS, it will never use that
    explanation.]

    This class is useful for parsing XML or made-up markup languages,
    or when BeautifulSoup makes an assumption counter to what you were
    expecting."""

    SELF_CLOSING_TAGS = {}
    NESTABLE_TAGS = {}
    RESET_NESTING_TAGS = {}
    QUOTE_TAGS = {}
    PRESERVE_WHITESPACE_TAGS = []

    MARKUP_MASSAGE = [(re.compile('(<[^<>]*)/>'),
                       lambda x: x.group(1) + ' />'),
                      (re.compile('<!\s+([^<>]*)>'),
                       lambda x: '<!' + x.group(1) + '>')
                      ]

    ROOT_TAG_NAME = u'[document]'

    HTML_ENTITIES = "html"
    XML_ENTITIES = "xml"
    XHTML_ENTITIES = "xhtml"
    # TODO: This only exists for backwards-compatibility
    ALL_ENTITIES = XHTML_ENTITIES

    # Used when determining whether a text node is all whitespace and
    # can be replaced with a single space. A text node that contains
    # fancy Unicode spaces (usually non-breaking) should be left
    # alone.
    STRIP_ASCII_SPACES = { 9: None, 10: None, 12: None, 13: None, 32: None, }

    def __init__(self, markup="", parseOnlyThese=None, fromEncoding=None,
                 markupMassage=True, smartQuotesTo=XML_ENTITIES,
                 convertEntities=None, selfClosingTags=None, isHTML=False):
        """The Soup object is initialized as the 'root tag', and the
        provided markup (which can be a string or a file-like object)
        is fed into the underlying parser.

        sgmllib will process most bad HTML, and the BeautifulSoup
        class has some tricks for dealing with some HTML that kills
        sgmllib, but Beautiful Soup can nonetheless choke or lose data
        if your data uses self-closing tags or declarations
        incorrectly.

        By default, Beautiful Soup uses regexes to sanitize input,
        avoiding the vast majority of these problems. If the problems
        don't apply to you, pass in False for markupMassage, and
        you'll get better performance.

        The default parser massage techniques fix the two most common
        instances of invalid HTML that choke sgmllib:

         <br/> (No space between name of closing tag and tag close)
         <! --Comment--> (Extraneous whitespace in declaration)

        You can pass in a custom list of (RE object, replace method)
        tuples to get Beautiful Soup to scrub your input the way you
        want."""

        self.parseOnlyThese = parseOnlyThese
        self.fromEncoding = fromEncoding
        self.smartQuotesTo = smartQuotesTo
        self.convertEntities = convertEntities
        # Set the rules for how we'll deal with the entities we
        # encounter
        if self.convertEntities:
            # It doesn't make sense to convert encoded characters to
            # entities even while you're converting entities to Unicode.
            # Just convert it all to Unicode.
            self.smartQuotesTo = None
            if convertEntities == self.HTML_ENTITIES:
                self.convertXMLEntities = False
                self.convertHTMLEntities = True
                self.escapeUnrecognizedEntities = True
            elif convertEntities == self.XHTML_ENTITIES:
                self.convertXMLEntities = True
                self.convertHTMLEntities = True
                self.escapeUnrecognizedEntities = False
            elif convertEntities == self.XML_ENTITIES:
                self.convertXMLEntities = True
                self.convertHTMLEntities = False
                self.escapeUnrecognizedEntities = False
        else:
            self.convertXMLEntities = False
            self.convertHTMLEntities = False
            self.escapeUnrecognizedEntities = False

        self.instanceSelfClosingTags = buildTagMap(None, selfClosingTags)
        SGMLParser.__init__(self)

        if hasattr(markup, 'read'):        # It's a file-type object.
            markup = markup.read()
        self.markup = markup
        self.markupMassage = markupMassage
        try:
            self._feed(isHTML=isHTML)
        except StopParsing:
            pass
        self.markup = None                 # The markup can now be GCed

    def convert_charref(self, name):
        """This method fixes a bug in Python's SGMLParser."""
        try:
            n = int(name)
        except ValueError:
            return
        if not 0 <= n <= 127 : # ASCII ends at 127, not 255
            return
        return self.convert_codepoint(n)

    def _feed(self, inDocumentEncoding=None, isHTML=False):
        # Convert the document to Unicode.
        markup = self.markup
        if isinstance(markup, unicode):
            if not hasattr(self, 'originalEncoding'):
                self.originalEncoding = None
        else:
            dammit = UnicodeDammit\
                     (markup, [self.fromEncoding, inDocumentEncoding],
                      smartQuotesTo=self.smartQuotesTo, isHTML=isHTML)
            markup = dammit.unicode
            self.originalEncoding = dammit.originalEncoding
            self.declaredHTMLEncoding = dammit.declaredHTMLEncoding
        if markup:
            if self.markupMassage:
                if not isList(self.markupMassage):
                    self.markupMassage = self.MARKUP_MASSAGE
                for fix, m in self.markupMassage:
                    markup = fix.sub(m, markup)
                # TODO: We get rid of markupMassage so that the
                # soup object can be deepcopied later on. Some
                # Python installations can't copy regexes. If anyone
                # was relying on the existence of markupMassage, this
                # might cause problems.
                del(self.markupMassage)
        self.reset()

        SGMLParser.feed(self, markup)
        # Close out any unfinished strings and close all the open tags.
        self.endData()
        while self.currentTag.name != self.ROOT_TAG_NAME:
            self.popTag()

    def __getattr__(self, methodName):
        """This method routes method call requests to either the SGMLParser
        superclass or the Tag superclass, depending on the method name."""
        #print "__getattr__ called on %s.%s" % (self.__class__, methodName)

        if methodName.find('start_') == 0 or methodName.find('end_') == 0 \
               or methodName.find('do_') == 0:
            return SGMLParser.__getattr__(self, methodName)
        elif methodName.find('__') != 0:
            return Tag.__getattr__(self, methodName)
        else:
            raise AttributeError

    def isSelfClosingTag(self, name):
        """Returns true iff the given string is the name of a
        self-closing tag according to this parser."""
        return self.SELF_CLOSING_TAGS.has_key(name) \
               or self.instanceSelfClosingTags.has_key(name)

    def reset(self):
        Tag.__init__(self, self, self.ROOT_TAG_NAME)
        self.hidden = 1
        SGMLParser.reset(self)
        self.currentData = []
        self.currentTag = None
        self.tagStack = []
        self.quoteStack = []
        self.pushTag(self)

    def popTag(self):
        tag = self.tagStack.pop()
        # Tags with just one string-owning child get the child as a
        # 'string' property, so that soup.tag.string is shorthand for
        # soup.tag.contents[0]
        if len(self.currentTag.contents) == 1 and \
           isinstance(self.currentTag.contents[0], NavigableString):
            self.currentTag.string = self.currentTag.contents[0]

        #print "Pop", tag.name
        if self.tagStack:
            self.currentTag = self.tagStack[-1]
        return self.currentTag

    def pushTag(self, tag):
        #print "Push", tag.name
        if self.currentTag:
            self.currentTag.contents.append(tag)
        self.tagStack.append(tag)
        self.currentTag = self.tagStack[-1]

    def endData(self, containerClass=NavigableString):
        if self.currentData:
            currentData = u''.join(self.currentData)
            if (currentData.translate(self.STRIP_ASCII_SPACES) == '' and
                not set([tag.name for tag in self.tagStack]).intersection(
                    self.PRESERVE_WHITESPACE_TAGS)):
                if '\n' in currentData:
                    currentData = '\n'
                else:
                    currentData = ' '
            self.currentData = []
            if self.parseOnlyThese and len(self.tagStack) <= 1 and \
                   (not self.parseOnlyThese.text or \
                    not self.parseOnlyThese.search(currentData)):
                return
            o = containerClass(currentData)
            o.setup(self.currentTag, self.previous)
            if self.previous:
                self.previous.next = o
            self.previous = o
            self.currentTag.contents.append(o)


    def _popToTag(self, name, inclusivePop=True):
        """Pops the tag stack up to and including the most recent
        instance of the given tag. If inclusivePop is false, pops the tag
        stack up to but *not* including the most recent instqance of
        the given tag."""
        #print "Popping to %s" % name
        if name == self.ROOT_TAG_NAME:
            return

        numPops = 0
        mostRecentTag = None
        for i in range(len(self.tagStack)-1, 0, -1):
            if name == self.tagStack[i].name:
                numPops = len(self.tagStack)-i
                break
        if not inclusivePop:
            numPops = numPops - 1

        for i in range(0, numPops):
            mostRecentTag = self.popTag()
        return mostRecentTag

    def _smartPop(self, name):

        """We need to pop up to the previous tag of this type, unless
        one of this tag's nesting reset triggers comes between this
        tag and the previous tag of this type, OR unless this tag is a
        generic nesting trigger and another generic nesting trigger
        comes between this tag and the previous tag of this type.

        Examples:
         <p>Foo<b>Bar *<p>* should pop to 'p', not 'b'.
         <p>Foo<table>Bar *<p>* should pop to 'table', not 'p'.
         <p>Foo<table><tr>Bar *<p>* should pop to 'tr', not 'p'.

         <li><ul><li> *<li>* should pop to 'ul', not the first 'li'.
         <tr><table><tr> *<tr>* should pop to 'table', not the first 'tr'
         <td><tr><td> *<td>* should pop to 'tr', not the first 'td'
        """

        nestingResetTriggers = self.NESTABLE_TAGS.get(name)
        isNestable = nestingResetTriggers != None
        isResetNesting = self.RESET_NESTING_TAGS.has_key(name)
        popTo = None
        inclusive = True
        for i in range(len(self.tagStack)-1, 0, -1):
            p = self.tagStack[i]
            if (not p or p.name == name) and not isNestable:
                #Non-nestable tags get popped to the top or to their
                #last occurance.
                popTo = name
                break
            if (nestingResetTriggers != None
                and p.name in nestingResetTriggers) \
                or (nestingResetTriggers == None and isResetNesting
                    and self.RESET_NESTING_TAGS.has_key(p.name)):

                #If we encounter one of the nesting reset triggers
                #peculiar to this tag, or we encounter another tag
                #that causes nesting to reset, pop up to but not
                #including that tag.
                popTo = p.name
                inclusive = False
                break
            p = p.parent
        if popTo:
            self._popToTag(popTo, inclusive)

    def unknown_starttag(self, name, attrs, selfClosing=0):
        #print "Start tag %s: %s" % (name, attrs)
        if self.quoteStack:
            #This is not a real tag.
            #print "<%s> is not real!" % name
            attrs = ''.join(map(lambda(x, y): ' %s="%s"' % (x, y), attrs))
            self.handle_data('<%s%s>' % (name, attrs))
            return
        self.endData()

        if not self.isSelfClosingTag(name) and not selfClosing:
            self._smartPop(name)

        if self.parseOnlyThese and len(self.tagStack) <= 1 \
               and (self.parseOnlyThese.text or not self.parseOnlyThese.searchTag(name, attrs)):
            return

        tag = Tag(self, name, attrs, self.currentTag, self.previous)
        if self.previous:
            self.previous.next = tag
        self.previous = tag
        self.pushTag(tag)
        if selfClosing or self.isSelfClosingTag(name):
            self.popTag()
        if name in self.QUOTE_TAGS:
            #print "Beginning quote (%s)" % name
            self.quoteStack.append(name)
            self.literal = 1
        return tag

    def unknown_endtag(self, name):
        #print "End tag %s" % name
        if self.quoteStack and self.quoteStack[-1] != name:
            #This is not a real end tag.
            #print "</%s> is not real!" % name
            self.handle_data('</%s>' % name)
            return
        self.endData()
        self._popToTag(name)
        if self.quoteStack and self.quoteStack[-1] == name:
            self.quoteStack.pop()
            self.literal = (len(self.quoteStack) > 0)

    def handle_data(self, data):
        self.currentData.append(data)

    def _toStringSubclass(self, text, subclass):
        """Adds a certain piece of text to the tree as a NavigableString
        subclass."""
        self.endData()
        self.handle_data(text)
        self.endData(subclass)

    def handle_pi(self, text):
        """Handle a processing instruction as a ProcessingInstruction
        object, possibly one with a %SOUP-ENCODING% slot into which an
        encoding will be plugged later."""
        if text[:3] == "xml":
            text = u"xml version='1.0' encoding='%SOUP-ENCODING%'"
        self._toStringSubclass(text, ProcessingInstruction)

    def handle_comment(self, text):
        "Handle comments as Comment objects."
        self._toStringSubclass(text, Comment)

    def handle_charref(self, ref):
        "Handle character references as data."
        if self.convertEntities:
            data = unichr(int(ref))
        else:
            data = '&#%s;' % ref
        self.handle_data(data)

    def handle_entityref(self, ref):
        """Handle entity references as data, possibly converting known
        HTML and/or XML entity references to the corresponding Unicode
        characters."""
        data = None
        if self.convertHTMLEntities:
            try:
                data = unichr(name2codepoint[ref])
            except KeyError:
                pass

        if not data and self.convertXMLEntities:
                data = self.XML_ENTITIES_TO_SPECIAL_CHARS.get(ref)

        if not data and self.convertHTMLEntities and \
            not self.XML_ENTITIES_TO_SPECIAL_CHARS.get(ref):
                # TODO: We've got a problem here. We're told this is
                # an entity reference, but it's not an XML entity
                # reference or an HTML entity reference. Nonetheless,
                # the logical thing to do is to pass it through as an
                # unrecognized entity reference.
                #
                # Except: when the input is "&carol;" this function
                # will be called with input "carol". When the input is
                # "AT&T", this function will be called with input
                # "T". We have no way of knowing whether a semicolon
                # was present originally, so we don't know whether
                # this is an unknown entity or just a misplaced
                # ampersand.
                #
                # The more common case is a misplaced ampersand, so I
                # escape the ampersand and omit the trailing semicolon.
                data = "&amp;%s" % ref
        if not data:
            # This case is different from the one above, because we
            # haven't already gone through a supposedly comprehensive
            # mapping of entities to Unicode characters. We might not
            # have gone through any mapping at all. So the chances are
            # very high that this is a real entity, and not a
            # misplaced ampersand.
            data = "&%s;" % ref
        self.handle_data(data)

    def handle_decl(self, data):
        "Handle DOCTYPEs and the like as Declaration objects."
        self._toStringSubclass(data, Declaration)

    def parse_declaration(self, i):
        """Treat a bogus SGML declaration as raw data. Treat a CDATA
        declaration as a CData object."""
        j = None
        if self.rawdata[i:i+9] == '<![CDATA[':
             k = self.rawdata.find(']]>', i)
             if k == -1:
                 k = len(self.rawdata)
             data = self.rawdata[i+9:k]
             j = k+3
             self._toStringSubclass(data, CData)
        else:
            try:
                j = SGMLParser.parse_declaration(self, i)
            except SGMLParseError:
                toHandle = self.rawdata[i:]
                self.handle_data(toHandle)
                j = i + len(toHandle)
        return j

class BeautifulSoup(BeautifulStoneSoup):

    """This parser knows the following facts about HTML:

    * Some tags have no closing tag and should be interpreted as being
      closed as soon as they are encountered.

    * The text inside some tags (ie. 'script') may contain tags which
      are not really part of the document and which should be parsed
      as text, not tags. If you want to parse the text as tags, you can
      always fetch it and parse it explicitly.

    * Tag nesting rules:

      Most tags can't be nested at all. For instance, the occurance of
      a <p> tag should implicitly close the previous <p> tag.

       <p>Para1<p>Para2
        should be transformed into:
       <p>Para1</p><p>Para2

      Some tags can be nested arbitrarily. For instance, the occurance
      of a <blockquote> tag should _not_ implicitly close the previous
      <blockquote> tag.

       Alice said: <blockquote>Bob said: <blockquote>Blah
        should NOT be transformed into:
       Alice said: <blockquote>Bob said: </blockquote><blockquote>Blah

      Some tags can be nested, but the nesting is reset by the
      interposition of other tags. For instance, a <tr> tag should
      implicitly close the previous <tr> tag within the same <table>,
      but not close a <tr> tag in another table.

       <table><tr>Blah<tr>Blah
        should be transformed into:
       <table><tr>Blah</tr><tr>Blah
        but,
       <tr>Blah<table><tr>Blah
        should NOT be transformed into
       <tr>Blah<table></tr><tr>Blah

    Differing assumptions about tag nesting rules are a major source
    of problems with the BeautifulSoup class. If BeautifulSoup is not
    treating as nestable a tag your page author treats as nestable,
    try ICantBelieveItsBeautifulSoup, MinimalSoup, or
    BeautifulStoneSoup before writing your own subclass."""

    def __init__(self, *args, **kwargs):
        if not kwargs.has_key('smartQuotesTo'):
            kwargs['smartQuotesTo'] = self.HTML_ENTITIES
        kwargs['isHTML'] = True
        BeautifulStoneSoup.__init__(self, *args, **kwargs)

    SELF_CLOSING_TAGS = buildTagMap(None,
                                    ['br' , 'hr', 'input', 'img', 'meta',
                                    'spacer', 'link', 'frame', 'base'])

    PRESERVE_WHITESPACE_TAGS = set(['pre', 'textarea'])

    QUOTE_TAGS = {'script' : None, 'textarea' : None}

    #According to the HTML standard, each of these inline tags can
    #contain another tag of the same type. Furthermore, it's common
    #to actually use these tags this way.
    NESTABLE_INLINE_TAGS = ['span', 'font', 'q', 'object', 'bdo', 'sub', 'sup',
                            'center']

    #According to the HTML standard, these block tags can contain
    #another tag of the same type. Furthermore, it's common
    #to actually use these tags this way.
    NESTABLE_BLOCK_TAGS = ['blockquote', 'div', 'fieldset', 'ins', 'del']

    #Lists can contain other lists, but there are restrictions.
    NESTABLE_LIST_TAGS = { 'ol' : [],
                           'ul' : [],
                           'li' : ['ul', 'ol'],
                           'dl' : [],
                           'dd' : ['dl'],
                           'dt' : ['dl'] }

    #Tables can contain other tables, but there are restrictions.
    NESTABLE_TABLE_TAGS = {'table' : [],
                           'tr' : ['table', 'tbody', 'tfoot', 'thead'],
                           'td' : ['tr'],
                           'th' : ['tr'],
                           'thead' : ['table'],
                           'tbody' : ['table'],
                           'tfoot' : ['table'],
                           }

    NON_NESTABLE_BLOCK_TAGS = ['address', 'form', 'p', 'pre']

    #If one of these tags is encountered, all tags up to the next tag of
    #this type are popped.
    RESET_NESTING_TAGS = buildTagMap(None, NESTABLE_BLOCK_TAGS, 'noscript',
                                     NON_NESTABLE_BLOCK_TAGS,
                                     NESTABLE_LIST_TAGS,
                                     NESTABLE_TABLE_TAGS)

    NESTABLE_TAGS = buildTagMap([], NESTABLE_INLINE_TAGS, NESTABLE_BLOCK_TAGS,
                                NESTABLE_LIST_TAGS, NESTABLE_TABLE_TAGS)

    # Used to detect the charset in a META tag; see start_meta
    CHARSET_RE = re.compile("((^|;)\s*charset=)([^;]*)", re.M)

    def start_meta(self, attrs):
        """Beautiful Soup can detect a charset included in a META tag,
        try to convert the document to that charset, and re-parse the
        document from the beginning."""
        httpEquiv = None
        contentType = None
        contentTypeIndex = None
        tagNeedsEncodingSubstitution = False

        for i in range(0, len(attrs)):
            key, value = attrs[i]
            key = key.lower()
            if key == 'http-equiv':
                httpEquiv = value
            elif key == 'content':
                contentType = value
                contentTypeIndex = i

        if httpEquiv and contentType: # It's an interesting meta tag.
            match = self.CHARSET_RE.search(contentType)
            if match:
                if (self.declaredHTMLEncoding is not None or
                    self.originalEncoding == self.fromEncoding):
                    # An HTML encoding was sniffed while converting
                    # the document to Unicode, or an HTML encoding was
                    # sniffed during a previous pass through the
                    # document, or an encoding was specified
                    # explicitly and it worked. Rewrite the meta tag.
                    def rewrite(match):
                        return match.group(1) + "%SOUP-ENCODING%"
                    newAttr = self.CHARSET_RE.sub(rewrite, contentType)
                    attrs[contentTypeIndex] = (attrs[contentTypeIndex][0],
                                               newAttr)
                    tagNeedsEncodingSubstitution = True
                else:
                    # This is our first pass through the document.
                    # Go through it again with the encoding information.
                    newCharset = match.group(3)
                    if newCharset and newCharset != self.originalEncoding:
                        self.declaredHTMLEncoding = newCharset
                        self._feed(self.declaredHTMLEncoding)
                        raise StopParsing
                    pass
        tag = self.unknown_starttag("meta", attrs)
        if tag and tagNeedsEncodingSubstitution:
            tag.containsSubstitutions = True

class StopParsing(Exception):
    pass

class ICantBelieveItsBeautifulSoup(BeautifulSoup):

    """The BeautifulSoup class is oriented towards skipping over
    common HTML errors like unclosed tags. However, sometimes it makes
    errors of its own. For instance, consider this fragment:

     <b>Foo<b>Bar</b></b>

    This is perfectly valid (if bizarre) HTML. However, the
    BeautifulSoup class will implicitly close the first b tag when it
    encounters the second 'b'. It will think the author wrote
    "<b>Foo<b>Bar", and didn't close the first 'b' tag, because
    there's no real-world reason to bold something that's already
    bold. When it encounters '</b></b>' it will close two more 'b'
    tags, for a grand total of three tags closed instead of two. This
    can throw off the rest of your document structure. The same is
    true of a number of other tags, listed below.

    It's much more common for someone to forget to close a 'b' tag
    than to actually use nested 'b' tags, and the BeautifulSoup class
    handles the common case. This class handles the not-co-common
    case: where you can't believe someone wrote what they did, but
    it's valid HTML and BeautifulSoup screwed up by assuming it
    wouldn't be."""

    I_CANT_BELIEVE_THEYRE_NESTABLE_INLINE_TAGS = \
     ['em', 'big', 'i', 'small', 'tt', 'abbr', 'acronym', 'strong',
      'cite', 'code', 'dfn', 'kbd', 'samp', 'strong', 'var', 'b',
      'big']

    I_CANT_BELIEVE_THEYRE_NESTABLE_BLOCK_TAGS = ['noscript']

    NESTABLE_TAGS = buildTagMap([], BeautifulSoup.NESTABLE_TAGS,
                                I_CANT_BELIEVE_THEYRE_NESTABLE_BLOCK_TAGS,
                                I_CANT_BELIEVE_THEYRE_NESTABLE_INLINE_TAGS)

class MinimalSoup(BeautifulSoup):
    """The MinimalSoup class is for parsing HTML that contains
    pathologically bad markup. It makes no assumptions about tag
    nesting, but it does know which tags are self-closing, that
    <script> tags contain Javascript and should not be parsed, that
    META tags may contain encoding information, and so on.

    This also makes it better for subclassing than BeautifulStoneSoup
    or BeautifulSoup."""

    RESET_NESTING_TAGS = buildTagMap('noscript')
    NESTABLE_TAGS = {}

class BeautifulSOAP(BeautifulStoneSoup):
    """This class will push a tag with only a single string child into
    the tag's parent as an attribute. The attribute's name is the tag
    name, and the value is the string child. An example should give
    the flavor of the change:

    <foo><bar>baz</bar></foo>
     =>
    <foo bar="baz"><bar>baz</bar></foo>

    You can then access fooTag['bar'] instead of fooTag.barTag.string.

    This is, of course, useful for scraping structures that tend to
    use subelements instead of attributes, such as SOAP messages. Note
    that it modifies its input, so don't print the modified version
    out.

    I'm not sure how many people really want to use this class; let me
    know if you do. Mainly I like the name."""

    def popTag(self):
        if len(self.tagStack) > 1:
            tag = self.tagStack[-1]
            parent = self.tagStack[-2]
            parent._getAttrMap()
            if (isinstance(tag, Tag) and len(tag.contents) == 1 and
                isinstance(tag.contents[0], NavigableString) and
                not parent.attrMap.has_key(tag.name)):
                parent[tag.name] = tag.contents[0]
        BeautifulStoneSoup.popTag(self)

#Enterprise class names! It has come to our attention that some people
#think the names of the Beautiful Soup parser classes are too silly
#and "unprofessional" for use in enterprise screen-scraping. We feel
#your pain! For such-minded folk, the Beautiful Soup Consortium And
#All-Night Kosher Bakery recommends renaming this file to
#"RobustParser.py" (or, in cases of extreme enterprisiness,
#"RobustParserBeanInterface.class") and using the following
#enterprise-friendly class aliases:
class RobustXMLParser(BeautifulStoneSoup):
    pass
class RobustHTMLParser(BeautifulSoup):
    pass
class RobustWackAssHTMLParser(ICantBelieveItsBeautifulSoup):
    pass
class RobustInsanelyWackAssHTMLParser(MinimalSoup):
    pass
class SimplifyingSOAPParser(BeautifulSOAP):
    pass

######################################################
#
# Bonus library: Unicode, Dammit
#
# This class forces XML data into a standard format (usually to UTF-8
# or Unicode).  It is heavily based on code from Mark Pilgrim's
# Universal Feed Parser. It does not rewrite the XML or HTML to
# reflect a new encoding: that happens in BeautifulStoneSoup.handle_pi
# (XML) and BeautifulSoup.start_meta (HTML).

# Autodetects character encodings.
# Download from http://chardet.feedparser.org/
try:
    import chardet
#    import chardet.constants
#    chardet.constants._debug = 1
except ImportError:
    chardet = None

# cjkcodecs and iconv_codec make Python know about more character encodings.
# Both are available from http://cjkpython.i18n.org/
# They're built in if you use Python 2.4.
try:
    import cjkcodecs.aliases
except ImportError:
    pass
try:
    import iconv_codec
except ImportError:
    pass

class UnicodeDammit:
    """A class for detecting the encoding of a *ML document and
    converting it to a Unicode string. If the source encoding is
    windows-1252, can replace MS smart quotes with their HTML or XML
    equivalents."""

    # This dictionary maps commonly seen values for "charset" in HTML
    # meta tags to the corresponding Python codec names. It only covers
    # values that aren't in Python's aliases and can't be determined
    # by the heuristics in find_codec.
    CHARSET_ALIASES = { "macintosh" : "mac-roman",
                        "x-sjis" : "shift-jis" }

    def __init__(self, markup, overrideEncodings=[],
                 smartQuotesTo='xml', isHTML=False):
        self.declaredHTMLEncoding = None
        self.markup, documentEncoding, sniffedEncoding = \
                     self._detectEncoding(markup, isHTML)
        self.smartQuotesTo = smartQuotesTo
        self.triedEncodings = []
        if markup == '' or isinstance(markup, unicode):
            self.originalEncoding = None
            self.unicode = unicode(markup)
            return

        u = None
        for proposedEncoding in overrideEncodings:
            u = self._convertFrom(proposedEncoding)
            if u: break
        if not u:
            for proposedEncoding in (documentEncoding, sniffedEncoding):
                u = self._convertFrom(proposedEncoding)
                if u: break

        # If no luck and we have auto-detection library, try that:
        if not u and chardet and not isinstance(self.markup, unicode):
            u = self._convertFrom(chardet.detect(self.markup)['encoding'])

        # As a last resort, try utf-8 and windows-1252:
        if not u:
            for proposed_encoding in ("utf-8", "windows-1252"):
                u = self._convertFrom(proposed_encoding)
                if u: break

        self.unicode = u
        if not u: self.originalEncoding = None

    def _subMSChar(self, orig):
        """Changes a MS smart quote character to an XML or HTML
        entity."""
        sub = self.MS_CHARS.get(orig)
        if type(sub) == types.TupleType:
            if self.smartQuotesTo == 'xml':
                sub = '&#x%s;' % sub[1]
            else:
                sub = '&%s;' % sub[0]
        return sub

    def _convertFrom(self, proposed):
        proposed = self.find_codec(proposed)
        if not proposed or proposed in self.triedEncodings:
            return None
        self.triedEncodings.append(proposed)
        markup = self.markup

        # Convert smart quotes to HTML if coming from an encoding
        # that might have them.
        if self.smartQuotesTo and proposed.lower() in("windows-1252",
                                                      "iso-8859-1",
                                                      "iso-8859-2"):
            markup = re.compile("([\x80-\x9f])").sub \
                     (lambda(x): self._subMSChar(x.group(1)),
                      markup)

        try:
            # print "Trying to convert document to %s" % proposed
            u = self._toUnicode(markup, proposed)
            self.markup = u
            self.originalEncoding = proposed
        except Exception, e:
            # print "That didn't work!"
            # print e
            return None
        #print "Correct encoding: %s" % proposed
        return self.markup

    def _toUnicode(self, data, encoding):
        '''Given a string and its encoding, decodes the string into Unicode.
        %encoding is a string recognized by encodings.aliases'''

        # strip Byte Order Mark (if present)
        if (len(data) >= 4) and (data[:2] == '\xfe\xff') \
               and (data[2:4] != '\x00\x00'):
            encoding = 'utf-16be'
            data = data[2:]
        elif (len(data) >= 4) and (data[:2] == '\xff\xfe') \
                 and (data[2:4] != '\x00\x00'):
            encoding = 'utf-16le'
            data = data[2:]
        elif data[:3] == '\xef\xbb\xbf':
            encoding = 'utf-8'
            data = data[3:]
        elif data[:4] == '\x00\x00\xfe\xff':
            encoding = 'utf-32be'
            data = data[4:]
        elif data[:4] == '\xff\xfe\x00\x00':
            encoding = 'utf-32le'
            data = data[4:]
        newdata = unicode(data, encoding)
        return newdata

    def _detectEncoding(self, xml_data, isHTML=False):
        """Given a document, tries to detect its XML encoding."""
        xml_encoding = sniffed_xml_encoding = None
        try:
            if xml_data[:4] == '\x4c\x6f\xa7\x94':
                # EBCDIC
                xml_data = self._ebcdic_to_ascii(xml_data)
            elif xml_data[:4] == '\x00\x3c\x00\x3f':
                # UTF-16BE
                sniffed_xml_encoding = 'utf-16be'
                xml_data = unicode(xml_data, 'utf-16be').encode('utf-8')
            elif (len(xml_data) >= 4) and (xml_data[:2] == '\xfe\xff') \
                     and (xml_data[2:4] != '\x00\x00'):
                # UTF-16BE with BOM
                sniffed_xml_encoding = 'utf-16be'
                xml_data = unicode(xml_data[2:], 'utf-16be').encode('utf-8')
            elif xml_data[:4] == '\x3c\x00\x3f\x00':
                # UTF-16LE
                sniffed_xml_encoding = 'utf-16le'
                xml_data = unicode(xml_data, 'utf-16le').encode('utf-8')
            elif (len(xml_data) >= 4) and (xml_data[:2] == '\xff\xfe') and \
                     (xml_data[2:4] != '\x00\x00'):
                # UTF-16LE with BOM
                sniffed_xml_encoding = 'utf-16le'
                xml_data = unicode(xml_data[2:], 'utf-16le').encode('utf-8')
            elif xml_data[:4] == '\x00\x00\x00\x3c':
                # UTF-32BE
                sniffed_xml_encoding = 'utf-32be'
                xml_data = unicode(xml_data, 'utf-32be').encode('utf-8')
            elif xml_data[:4] == '\x3c\x00\x00\x00':
                # UTF-32LE
                sniffed_xml_encoding = 'utf-32le'
                xml_data = unicode(xml_data, 'utf-32le').encode('utf-8')
            elif xml_data[:4] == '\x00\x00\xfe\xff':
                # UTF-32BE with BOM
                sniffed_xml_encoding = 'utf-32be'
                xml_data = unicode(xml_data[4:], 'utf-32be').encode('utf-8')
            elif xml_data[:4] == '\xff\xfe\x00\x00':
                # UTF-32LE with BOM
                sniffed_xml_encoding = 'utf-32le'
                xml_data = unicode(xml_data[4:], 'utf-32le').encode('utf-8')
            elif xml_data[:3] == '\xef\xbb\xbf':
                # UTF-8 with BOM
                sniffed_xml_encoding = 'utf-8'
                xml_data = unicode(xml_data[3:], 'utf-8').encode('utf-8')
            else:
                sniffed_xml_encoding = 'ascii'
                pass
        except:
            xml_encoding_match = None
        xml_encoding_match = re.compile(
            '^<\?.*encoding=[\'"](.*?)[\'"].*\?>').match(xml_data)
        if not xml_encoding_match and isHTML:
            regexp = re.compile('<\s*meta[^>]+charset=([^>]*?)[;\'">]', re.I)
            xml_encoding_match = regexp.search(xml_data)
        if xml_encoding_match is not None:
            xml_encoding = xml_encoding_match.groups()[0].lower()
            if isHTML:
                self.declaredHTMLEncoding = xml_encoding
            if sniffed_xml_encoding and \
               (xml_encoding in ('iso-10646-ucs-2', 'ucs-2', 'csunicode',
                                 'iso-10646-ucs-4', 'ucs-4', 'csucs4',
                                 'utf-16', 'utf-32', 'utf_16', 'utf_32',
                                 'utf16', 'u16')):
                xml_encoding = sniffed_xml_encoding
        return xml_data, xml_encoding, sniffed_xml_encoding


    def find_codec(self, charset):
        return self._codec(self.CHARSET_ALIASES.get(charset, charset)) \
               or (charset and self._codec(charset.replace("-", ""))) \
               or (charset and self._codec(charset.replace("-", "_"))) \
               or charset

    def _codec(self, charset):
        if not charset: return charset
        codec = None
        try:
            codecs.lookup(charset)
            codec = charset
        except (LookupError, ValueError):
            pass
        return codec

    EBCDIC_TO_ASCII_MAP = None
    def _ebcdic_to_ascii(self, s):
        c = self.__class__
        if not c.EBCDIC_TO_ASCII_MAP:
            emap = (0,1,2,3,156,9,134,127,151,141,142,11,12,13,14,15,
                    16,17,18,19,157,133,8,135,24,25,146,143,28,29,30,31,
                    128,129,130,131,132,10,23,27,136,137,138,139,140,5,6,7,
                    144,145,22,147,148,149,150,4,152,153,154,155,20,21,158,26,
                    32,160,161,162,163,164,165,166,167,168,91,46,60,40,43,33,
                    38,169,170,171,172,173,174,175,176,177,93,36,42,41,59,94,
                    45,47,178,179,180,181,182,183,184,185,124,44,37,95,62,63,
                    186,187,188,189,190,191,192,193,194,96,58,35,64,39,61,34,
                    195,97,98,99,100,101,102,103,104,105,196,197,198,199,200,
                    201,202,106,107,108,109,110,111,112,113,114,203,204,205,
                    206,207,208,209,126,115,116,117,118,119,120,121,122,210,
                    211,212,213,214,215,216,217,218,219,220,221,222,223,224,
                    225,226,227,228,229,230,231,123,65,66,67,68,69,70,71,72,
                    73,232,233,234,235,236,237,125,74,75,76,77,78,79,80,81,
                    82,238,239,240,241,242,243,92,159,83,84,85,86,87,88,89,
                    90,244,245,246,247,248,249,48,49,50,51,52,53,54,55,56,57,
                    250,251,252,253,254,255)
            import string
            c.EBCDIC_TO_ASCII_MAP = string.maketrans( \
            ''.join(map(chr, range(256))), ''.join(map(chr, emap)))
        return s.translate(c.EBCDIC_TO_ASCII_MAP)

    MS_CHARS = { '\x80' : ('euro', '20AC'),
                 '\x81' : ' ',
                 '\x82' : ('sbquo', '201A'),
                 '\x83' : ('fnof', '192'),
                 '\x84' : ('bdquo', '201E'),
                 '\x85' : ('hellip', '2026'),
                 '\x86' : ('dagger', '2020'),
                 '\x87' : ('Dagger', '2021'),
                 '\x88' : ('circ', '2C6'),
                 '\x89' : ('permil', '2030'),
                 '\x8A' : ('Scaron', '160'),
                 '\x8B' : ('lsaquo', '2039'),
                 '\x8C' : ('OElig', '152'),
                 '\x8D' : '?',
                 '\x8E' : ('#x17D', '17D'),
                 '\x8F' : '?',
                 '\x90' : '?',
                 '\x91' : ('lsquo', '2018'),
                 '\x92' : ('rsquo', '2019'),
                 '\x93' : ('ldquo', '201C'),
                 '\x94' : ('rdquo', '201D'),
                 '\x95' : ('bull', '2022'),
                 '\x96' : ('ndash', '2013'),
                 '\x97' : ('mdash', '2014'),
                 '\x98' : ('tilde', '2DC'),
                 '\x99' : ('trade', '2122'),
                 '\x9a' : ('scaron', '161'),
                 '\x9b' : ('rsaquo', '203A'),
                 '\x9c' : ('oelig', '153'),
                 '\x9d' : '?',
                 '\x9e' : ('#x17E', '17E'),
                 '\x9f' : ('Yuml', ''),}

#######################################################################


#By default, act as an HTML pretty-printer.
if __name__ == '__main__':
    import sys
    soup = BeautifulSoup(sys.stdin)
    print soup.prettify()

########NEW FILE########
__FILENAME__ = cpp
# -----------------------------------------------------------------------------
# cpp.py
#
# Author:  David Beazley (http://www.dabeaz.com)
# Copyright (C) 2007
# All rights reserved
#
# This module implements an ANSI-C style lexical preprocessor for PLY. 
# -----------------------------------------------------------------------------
from __future__ import generators

# -----------------------------------------------------------------------------
# Default preprocessor lexer definitions.   These tokens are enough to get
# a basic preprocessor working.   Other modules may import these if they want
# -----------------------------------------------------------------------------

tokens = (
   'CPP_ID','CPP_INTEGER', 'CPP_FLOAT', 'CPP_STRING', 'CPP_CHAR', 'CPP_WS', 'CPP_COMMENT', 'CPP_POUND','CPP_DPOUND'
)

literals = "+-*/%|&~^<>=!?()[]{}.,;:\\\'\""

# Whitespace
def t_CPP_WS(t):
    r'\s+'
    t.lexer.lineno += t.value.count("\n")
    return t

t_CPP_POUND = r'\#'
t_CPP_DPOUND = r'\#\#'

# Identifier
t_CPP_ID = r'[A-Za-z_][\w_]*'

# Integer literal
def CPP_INTEGER(t):
    r'(((((0x)|(0X))[0-9a-fA-F]+)|(\d+))([uU]|[lL]|[uU][lL]|[lL][uU])?)'
    return t

t_CPP_INTEGER = CPP_INTEGER

# Floating literal
t_CPP_FLOAT = r'((\d+)(\.\d+)(e(\+|-)?(\d+))? | (\d+)e(\+|-)?(\d+))([lL]|[fF])?'

# String literal
def t_CPP_STRING(t):
    r'\"([^\\\n]|(\\(.|\n)))*?\"'
    t.lexer.lineno += t.value.count("\n")
    return t

# Character constant 'c' or L'c'
def t_CPP_CHAR(t):
    r'(L)?\'([^\\\n]|(\\(.|\n)))*?\''
    t.lexer.lineno += t.value.count("\n")
    return t

# Comment
def t_CPP_COMMENT(t):
    r'(/\*(.|\n)*?\*/)|(//.*?\n)'
    t.lexer.lineno += t.value.count("\n")
    return t
    
def t_error(t):
    t.type = t.value[0]
    t.value = t.value[0]
    t.lexer.skip(1)
    return t

import re
import copy
import time
import os.path

# -----------------------------------------------------------------------------
# trigraph()
# 
# Given an input string, this function replaces all trigraph sequences. 
# The following mapping is used:
#
#     ??=    #
#     ??/    \
#     ??'    ^
#     ??(    [
#     ??)    ]
#     ??!    |
#     ??<    {
#     ??>    }
#     ??-    ~
# -----------------------------------------------------------------------------

_trigraph_pat = re.compile(r'''\?\?[=/\'\(\)\!<>\-]''')
_trigraph_rep = {
    '=':'#',
    '/':'\\',
    "'":'^',
    '(':'[',
    ')':']',
    '!':'|',
    '<':'{',
    '>':'}',
    '-':'~'
}

def trigraph(input):
    return _trigraph_pat.sub(lambda g: _trigraph_rep[g.group()[-1]],input)

# ------------------------------------------------------------------
# Macro object
#
# This object holds information about preprocessor macros
#
#    .name      - Macro name (string)
#    .value     - Macro value (a list of tokens)
#    .arglist   - List of argument names
#    .variadic  - Boolean indicating whether or not variadic macro
#    .vararg    - Name of the variadic parameter
#
# When a macro is created, the macro replacement token sequence is
# pre-scanned and used to create patch lists that are later used
# during macro expansion
# ------------------------------------------------------------------

class Macro(object):
    def __init__(self,name,value,arglist=None,variadic=False):
        self.name = name
        self.value = value
        self.arglist = arglist
        self.variadic = variadic
        if variadic:
            self.vararg = arglist[-1]
        self.source = None

# ------------------------------------------------------------------
# Preprocessor object
#
# Object representing a preprocessor.  Contains macro definitions,
# include directories, and other information
# ------------------------------------------------------------------

class Preprocessor(object):
    def __init__(self,lexer=None):
        if lexer is None:
            lexer = lex.lexer
        self.lexer = lexer
        self.macros = { }
        self.path = []
        self.temp_path = []

        # Probe the lexer for selected tokens
        self.lexprobe()

        tm = time.localtime()
        self.define("__DATE__ \"%s\"" % time.strftime("%b %d %Y",tm))
        self.define("__TIME__ \"%s\"" % time.strftime("%H:%M:%S",tm))
        self.parser = None

    # -----------------------------------------------------------------------------
    # tokenize()
    #
    # Utility function. Given a string of text, tokenize into a list of tokens
    # -----------------------------------------------------------------------------

    def tokenize(self,text):
        tokens = []
        self.lexer.input(text)
        while True:
            tok = self.lexer.token()
            if not tok: break
            tokens.append(tok)
        return tokens

    # ---------------------------------------------------------------------
    # error()
    #
    # Report a preprocessor error/warning of some kind
    # ----------------------------------------------------------------------

    def error(self,file,line,msg):
        print >>sys.stderr,"%s:%d %s" % (file,line,msg)

    # ----------------------------------------------------------------------
    # lexprobe()
    #
    # This method probes the preprocessor lexer object to discover
    # the token types of symbols that are important to the preprocessor.
    # If this works right, the preprocessor will simply "work"
    # with any suitable lexer regardless of how tokens have been named.
    # ----------------------------------------------------------------------

    def lexprobe(self):

        # Determine the token type for identifiers
        self.lexer.input("identifier")
        tok = self.lexer.token()
        if not tok or tok.value != "identifier":
            print "Couldn't determine identifier type"
        else:
            self.t_ID = tok.type

        # Determine the token type for integers
        self.lexer.input("12345")
        tok = self.lexer.token()
        if not tok or int(tok.value) != 12345:
            print "Couldn't determine integer type"
        else:
            self.t_INTEGER = tok.type
            self.t_INTEGER_TYPE = type(tok.value)

        # Determine the token type for strings enclosed in double quotes
        self.lexer.input("\"filename\"")
        tok = self.lexer.token()
        if not tok or tok.value != "\"filename\"":
            print "Couldn't determine string type"
        else:
            self.t_STRING = tok.type

        # Determine the token type for whitespace--if any
        self.lexer.input("  ")
        tok = self.lexer.token()
        if not tok or tok.value != "  ":
            self.t_SPACE = None
        else:
            self.t_SPACE = tok.type

        # Determine the token type for newlines
        self.lexer.input("\n")
        tok = self.lexer.token()
        if not tok or tok.value != "\n":
            self.t_NEWLINE = None
            print "Couldn't determine token for newlines"
        else:
            self.t_NEWLINE = tok.type

        self.t_WS = (self.t_SPACE, self.t_NEWLINE)

        # Check for other characters used by the preprocessor
        chars = [ '<','>','#','##','\\','(',')',',','.']
        for c in chars:
            self.lexer.input(c)
            tok = self.lexer.token()
            if not tok or tok.value != c:
                print "Unable to lex '%s' required for preprocessor" % c

    # ----------------------------------------------------------------------
    # add_path()
    #
    # Adds a search path to the preprocessor.  
    # ----------------------------------------------------------------------

    def add_path(self,path):
        self.path.append(path)

    # ----------------------------------------------------------------------
    # group_lines()
    #
    # Given an input string, this function splits it into lines.  Trailing whitespace
    # is removed.   Any line ending with \ is grouped with the next line.  This
    # function forms the lowest level of the preprocessor---grouping into text into
    # a line-by-line format.
    # ----------------------------------------------------------------------

    def group_lines(self,input):
        lex = self.lexer.clone()
        lines = [x.rstrip() for x in input.splitlines()]
        for i in xrange(len(lines)):
            j = i+1
            while lines[i].endswith('\\') and (j < len(lines)):
                lines[i] = lines[i][:-1]+lines[j]
                lines[j] = ""
                j += 1

        input = "\n".join(lines)
        lex.input(input)
        lex.lineno = 1

        current_line = []
        while True:
            tok = lex.token()
            if not tok:
                break
            current_line.append(tok)
            if tok.type in self.t_WS and '\n' in tok.value:
                yield current_line
                current_line = []

        if current_line:
            yield current_line

    # ----------------------------------------------------------------------
    # tokenstrip()
    # 
    # Remove leading/trailing whitespace tokens from a token list
    # ----------------------------------------------------------------------

    def tokenstrip(self,tokens):
        i = 0
        while i < len(tokens) and tokens[i].type in self.t_WS:
            i += 1
        del tokens[:i]
        i = len(tokens)-1
        while i >= 0 and tokens[i].type in self.t_WS:
            i -= 1
        del tokens[i+1:]
        return tokens


    # ----------------------------------------------------------------------
    # collect_args()
    #
    # Collects comma separated arguments from a list of tokens.   The arguments
    # must be enclosed in parenthesis.  Returns a tuple (tokencount,args,positions)
    # where tokencount is the number of tokens consumed, args is a list of arguments,
    # and positions is a list of integers containing the starting index of each
    # argument.  Each argument is represented by a list of tokens.
    #
    # When collecting arguments, leading and trailing whitespace is removed
    # from each argument.  
    #
    # This function properly handles nested parenthesis and commas---these do not
    # define new arguments.
    # ----------------------------------------------------------------------

    def collect_args(self,tokenlist):
        args = []
        positions = []
        current_arg = []
        nesting = 1
        tokenlen = len(tokenlist)
    
        # Search for the opening '('.
        i = 0
        while (i < tokenlen) and (tokenlist[i].type in self.t_WS):
            i += 1

        if (i < tokenlen) and (tokenlist[i].value == '('):
            positions.append(i+1)
        else:
            self.error(self.source,tokenlist[0].lineno,"Missing '(' in macro arguments")
            return 0, [], []

        i += 1

        while i < tokenlen:
            t = tokenlist[i]
            if t.value == '(':
                current_arg.append(t)
                nesting += 1
            elif t.value == ')':
                nesting -= 1
                if nesting == 0:
                    if current_arg:
                        args.append(self.tokenstrip(current_arg))
                        positions.append(i)
                    return i+1,args,positions
                current_arg.append(t)
            elif t.value == ',' and nesting == 1:
                args.append(self.tokenstrip(current_arg))
                positions.append(i+1)
                current_arg = []
            else:
                current_arg.append(t)
            i += 1
    
        # Missing end argument
        self.error(self.source,tokenlist[-1].lineno,"Missing ')' in macro arguments")
        return 0, [],[]

    # ----------------------------------------------------------------------
    # macro_prescan()
    #
    # Examine the macro value (token sequence) and identify patch points
    # This is used to speed up macro expansion later on---we'll know
    # right away where to apply patches to the value to form the expansion
    # ----------------------------------------------------------------------
    
    def macro_prescan(self,macro):
        macro.patch     = []             # Standard macro arguments 
        macro.str_patch = []             # String conversion expansion
        macro.var_comma_patch = []       # Variadic macro comma patch
        i = 0
        while i < len(macro.value):
            if macro.value[i].type == self.t_ID and macro.value[i].value in macro.arglist:
                argnum = macro.arglist.index(macro.value[i].value)
                # Conversion of argument to a string
                if i > 0 and macro.value[i-1].value == '#':
                    macro.value[i] = copy.copy(macro.value[i])
                    macro.value[i].type = self.t_STRING
                    del macro.value[i-1]
                    macro.str_patch.append((argnum,i-1))
                    continue
                # Concatenation
                elif (i > 0 and macro.value[i-1].value == '##'):
                    macro.patch.append(('c',argnum,i-1))
                    del macro.value[i-1]
                    continue
                elif ((i+1) < len(macro.value) and macro.value[i+1].value == '##'):
                    macro.patch.append(('c',argnum,i))
                    i += 1
                    continue
                # Standard expansion
                else:
                    macro.patch.append(('e',argnum,i))
            elif macro.value[i].value == '##':
                if macro.variadic and (i > 0) and (macro.value[i-1].value == ',') and \
                        ((i+1) < len(macro.value)) and (macro.value[i+1].type == self.t_ID) and \
                        (macro.value[i+1].value == macro.vararg):
                    macro.var_comma_patch.append(i-1)
            i += 1
        macro.patch.sort(key=lambda x: x[2],reverse=True)

    # ----------------------------------------------------------------------
    # macro_expand_args()
    #
    # Given a Macro and list of arguments (each a token list), this method
    # returns an expanded version of a macro.  The return value is a token sequence
    # representing the replacement macro tokens
    # ----------------------------------------------------------------------

    def macro_expand_args(self,macro,args):
        # Make a copy of the macro token sequence
        rep = [copy.copy(_x) for _x in macro.value]

        # Make string expansion patches.  These do not alter the length of the replacement sequence
        
        str_expansion = {}
        for argnum, i in macro.str_patch:
            if argnum not in str_expansion:
                str_expansion[argnum] = ('"%s"' % "".join([x.value for x in args[argnum]])).replace("\\","\\\\")
            rep[i] = copy.copy(rep[i])
            rep[i].value = str_expansion[argnum]

        # Make the variadic macro comma patch.  If the variadic macro argument is empty, we get rid
        comma_patch = False
        if macro.variadic and not args[-1]:
            for i in macro.var_comma_patch:
                rep[i] = None
                comma_patch = True

        # Make all other patches.   The order of these matters.  It is assumed that the patch list
        # has been sorted in reverse order of patch location since replacements will cause the
        # size of the replacement sequence to expand from the patch point.
        
        expanded = { }
        for ptype, argnum, i in macro.patch:
            # Concatenation.   Argument is left unexpanded
            if ptype == 'c':
                rep[i:i+1] = args[argnum]
            # Normal expansion.  Argument is macro expanded first
            elif ptype == 'e':
                if argnum not in expanded:
                    expanded[argnum] = self.expand_macros(args[argnum])
                rep[i:i+1] = expanded[argnum]

        # Get rid of removed comma if necessary
        if comma_patch:
            rep = [_i for _i in rep if _i]

        return rep


    # ----------------------------------------------------------------------
    # expand_macros()
    #
    # Given a list of tokens, this function performs macro expansion.
    # The expanded argument is a dictionary that contains macros already
    # expanded.  This is used to prevent infinite recursion.
    # ----------------------------------------------------------------------

    def expand_macros(self,tokens,expanded=None):
        if expanded is None:
            expanded = {}
        i = 0
        while i < len(tokens):
            t = tokens[i]
            if t.type == self.t_ID:
                if t.value in self.macros and t.value not in expanded:
                    # Yes, we found a macro match
                    expanded[t.value] = True
                    
                    m = self.macros[t.value]
                    if not m.arglist:
                        # A simple macro
                        ex = self.expand_macros([copy.copy(_x) for _x in m.value],expanded)
                        for e in ex:
                            e.lineno = t.lineno
                        tokens[i:i+1] = ex
                        i += len(ex)
                    else:
                        # A macro with arguments
                        j = i + 1
                        while j < len(tokens) and tokens[j].type in self.t_WS:
                            j += 1
                        if tokens[j].value == '(':
                            tokcount,args,positions = self.collect_args(tokens[j:])
                            if not m.variadic and len(args) !=  len(m.arglist):
                                self.error(self.source,t.lineno,"Macro %s requires %d arguments" % (t.value,len(m.arglist)))
                                i = j + tokcount
                            elif m.variadic and len(args) < len(m.arglist)-1:
                                if len(m.arglist) > 2:
                                    self.error(self.source,t.lineno,"Macro %s must have at least %d arguments" % (t.value, len(m.arglist)-1))
                                else:
                                    self.error(self.source,t.lineno,"Macro %s must have at least %d argument" % (t.value, len(m.arglist)-1))
                                i = j + tokcount
                            else:
                                if m.variadic:
                                    if len(args) == len(m.arglist)-1:
                                        args.append([])
                                    else:
                                        args[len(m.arglist)-1] = tokens[j+positions[len(m.arglist)-1]:j+tokcount-1]
                                        del args[len(m.arglist):]
                                        
                                # Get macro replacement text
                                rep = self.macro_expand_args(m,args)
                                rep = self.expand_macros(rep,expanded)
                                for r in rep:
                                    r.lineno = t.lineno
                                tokens[i:j+tokcount] = rep
                                i += len(rep)
                    del expanded[t.value]
                    continue
                elif t.value == '__LINE__':
                    t.type = self.t_INTEGER
                    t.value = self.t_INTEGER_TYPE(t.lineno)
                
            i += 1
        return tokens

    # ----------------------------------------------------------------------    
    # evalexpr()
    # 
    # Evaluate an expression token sequence for the purposes of evaluating
    # integral expressions.
    # ----------------------------------------------------------------------

    def evalexpr(self,tokens):
        # tokens = tokenize(line)
        # Search for defined macros
        i = 0
        while i < len(tokens):
            if tokens[i].type == self.t_ID and tokens[i].value == 'defined':
                j = i + 1
                needparen = False
                result = "0L"
                while j < len(tokens):
                    if tokens[j].type in self.t_WS:
                        j += 1
                        continue
                    elif tokens[j].type == self.t_ID:
                        if tokens[j].value in self.macros:
                            result = "1L"
                        else:
                            result = "0L"
                        if not needparen: break
                    elif tokens[j].value == '(':
                        needparen = True
                    elif tokens[j].value == ')':
                        break
                    else:
                        self.error(self.source,tokens[i].lineno,"Malformed defined()")
                    j += 1
                tokens[i].type = self.t_INTEGER
                tokens[i].value = self.t_INTEGER_TYPE(result)
                del tokens[i+1:j+1]
            i += 1
        tokens = self.expand_macros(tokens)
        for i,t in enumerate(tokens):
            if t.type == self.t_ID:
                tokens[i] = copy.copy(t)
                tokens[i].type = self.t_INTEGER
                tokens[i].value = self.t_INTEGER_TYPE("0L")
            elif t.type == self.t_INTEGER:
                tokens[i] = copy.copy(t)
                # Strip off any trailing suffixes
                tokens[i].value = str(tokens[i].value)
                while tokens[i].value[-1] not in "0123456789abcdefABCDEF":
                    tokens[i].value = tokens[i].value[:-1]
        
        expr = "".join([str(x.value) for x in tokens])
        expr = expr.replace("&&"," and ")
        expr = expr.replace("||"," or ")
        expr = expr.replace("!"," not ")
        try:
            result = eval(expr)
        except StandardError:
            self.error(self.source,tokens[0].lineno,"Couldn't evaluate expression")
            result = 0
        return result

    # ----------------------------------------------------------------------
    # parsegen()
    #
    # Parse an input string/
    # ----------------------------------------------------------------------
    def parsegen(self,input,source=None):

        # Replace trigraph sequences
        t = trigraph(input)
        lines = self.group_lines(t)

        if not source:
            source = ""
            
        self.define("__FILE__ \"%s\"" % source)

        self.source = source
        chunk = []
        enable = True
        iftrigger = False
        ifstack = []

        for x in lines:
            for i,tok in enumerate(x):
                if tok.type not in self.t_WS: break
            if tok.value == '#':
                # Preprocessor directive

                for tok in x:
                    if tok in self.t_WS and '\n' in tok.value:
                        chunk.append(tok)
                
                dirtokens = self.tokenstrip(x[i+1:])
                if dirtokens:
                    name = dirtokens[0].value
                    args = self.tokenstrip(dirtokens[1:])
                else:
                    name = ""
                    args = []
                
                if name == 'define':
                    if enable:
                        for tok in self.expand_macros(chunk):
                            yield tok
                        chunk = []
                        self.define(args)
                elif name == 'include':
                    if enable:
                        for tok in self.expand_macros(chunk):
                            yield tok
                        chunk = []
                        oldfile = self.macros['__FILE__']
                        for tok in self.include(args):
                            yield tok
                        self.macros['__FILE__'] = oldfile
                        self.source = source
                elif name == 'undef':
                    if enable:
                        for tok in self.expand_macros(chunk):
                            yield tok
                        chunk = []
                        self.undef(args)
                elif name == 'ifdef':
                    ifstack.append((enable,iftrigger))
                    if enable:
                        if not args[0].value in self.macros:
                            enable = False
                            iftrigger = False
                        else:
                            iftrigger = True
                elif name == 'ifndef':
                    ifstack.append((enable,iftrigger))
                    if enable:
                        if args[0].value in self.macros:
                            enable = False
                            iftrigger = False
                        else:
                            iftrigger = True
                elif name == 'if':
                    ifstack.append((enable,iftrigger))
                    if enable:
                        result = self.evalexpr(args)
                        if not result:
                            enable = False
                            iftrigger = False
                        else:
                            iftrigger = True
                elif name == 'elif':
                    if ifstack:
                        if ifstack[-1][0]:     # We only pay attention if outer "if" allows this
                            if enable:         # If already true, we flip enable False
                                enable = False
                            elif not iftrigger:   # If False, but not triggered yet, we'll check expression
                                result = self.evalexpr(args)
                                if result:
                                    enable  = True
                                    iftrigger = True
                    else:
                        self.error(self.source,dirtokens[0].lineno,"Misplaced #elif")
                        
                elif name == 'else':
                    if ifstack:
                        if ifstack[-1][0]:
                            if enable:
                                enable = False
                            elif not iftrigger:
                                enable = True
                                iftrigger = True
                    else:
                        self.error(self.source,dirtokens[0].lineno,"Misplaced #else")

                elif name == 'endif':
                    if ifstack:
                        enable,iftrigger = ifstack.pop()
                    else:
                        self.error(self.source,dirtokens[0].lineno,"Misplaced #endif")
                else:
                    # Unknown preprocessor directive
                    pass

            else:
                # Normal text
                if enable:
                    chunk.extend(x)

        for tok in self.expand_macros(chunk):
            yield tok
        chunk = []

    # ----------------------------------------------------------------------
    # include()
    #
    # Implementation of file-inclusion
    # ----------------------------------------------------------------------

    def include(self,tokens):
        # Try to extract the filename and then process an include file
        if not tokens:
            return
        if tokens:
            if tokens[0].value != '<' and tokens[0].type != self.t_STRING:
                tokens = self.expand_macros(tokens)

            if tokens[0].value == '<':
                # Include <...>
                i = 1
                while i < len(tokens):
                    if tokens[i].value == '>':
                        break
                    i += 1
                else:
                    print "Malformed #include <...>"
                    return
                filename = "".join([x.value for x in tokens[1:i]])
                path = self.path + [""] + self.temp_path
            elif tokens[0].type == self.t_STRING:
                filename = tokens[0].value[1:-1]
                path = self.temp_path + [""] + self.path
            else:
                print "Malformed #include statement"
                return
        for p in path:
            iname = os.path.join(p,filename)
            try:
                data = open(iname,"r").read()
                dname = os.path.dirname(iname)
                if dname:
                    self.temp_path.insert(0,dname)
                for tok in self.parsegen(data,filename):
                    yield tok
                if dname:
                    del self.temp_path[0]
                break
            except IOError,e:
                pass
        else:
            print "Couldn't find '%s'" % filename

    # ----------------------------------------------------------------------
    # define()
    #
    # Define a new macro
    # ----------------------------------------------------------------------

    def define(self,tokens):
        if isinstance(tokens,(str,unicode)):
            tokens = self.tokenize(tokens)

        linetok = tokens
        try:
            name = linetok[0]
            if len(linetok) > 1:
                mtype = linetok[1]
            else:
                mtype = None
            if not mtype:
                m = Macro(name.value,[])
                self.macros[name.value] = m
            elif mtype.type in self.t_WS:
                # A normal macro
                m = Macro(name.value,self.tokenstrip(linetok[2:]))
                self.macros[name.value] = m
            elif mtype.value == '(':
                # A macro with arguments
                tokcount, args, positions = self.collect_args(linetok[1:])
                variadic = False
                for a in args:
                    if variadic:
                        print "No more arguments may follow a variadic argument"
                        break
                    astr = "".join([str(_i.value) for _i in a])
                    if astr == "...":
                        variadic = True
                        a[0].type = self.t_ID
                        a[0].value = '__VA_ARGS__'
                        variadic = True
                        del a[1:]
                        continue
                    elif astr[-3:] == "..." and a[0].type == self.t_ID:
                        variadic = True
                        del a[1:]
                        # If, for some reason, "." is part of the identifier, strip off the name for the purposes
                        # of macro expansion
                        if a[0].value[-3:] == '...':
                            a[0].value = a[0].value[:-3]
                        continue
                    if len(a) > 1 or a[0].type != self.t_ID:
                        print "Invalid macro argument"
                        break
                else:
                    mvalue = self.tokenstrip(linetok[1+tokcount:])
                    i = 0
                    while i < len(mvalue):
                        if i+1 < len(mvalue):
                            if mvalue[i].type in self.t_WS and mvalue[i+1].value == '##':
                                del mvalue[i]
                                continue
                            elif mvalue[i].value == '##' and mvalue[i+1].type in self.t_WS:
                                del mvalue[i+1]
                        i += 1
                    m = Macro(name.value,mvalue,[x[0].value for x in args],variadic)
                    self.macro_prescan(m)
                    self.macros[name.value] = m
            else:
                print "Bad macro definition"
        except LookupError:
            print "Bad macro definition"

    # ----------------------------------------------------------------------
    # undef()
    #
    # Undefine a macro
    # ----------------------------------------------------------------------

    def undef(self,tokens):
        id = tokens[0].value
        try:
            del self.macros[id]
        except LookupError:
            pass

    # ----------------------------------------------------------------------
    # parse()
    #
    # Parse input text.
    # ----------------------------------------------------------------------
    def parse(self,input,source=None,ignore={}):
        self.ignore = ignore
        self.parser = self.parsegen(input,source)
        
    # ----------------------------------------------------------------------
    # token()
    #
    # Method to return individual tokens
    # ----------------------------------------------------------------------
    def token(self):
        try:
            while True:
                tok = self.parser.next()
                if tok.type not in self.ignore: return tok
        except StopIteration:
            self.parser = None
            return None

if __name__ == '__main__':
    import ply.lex as lex
    lexer = lex.lex()

    # Run a preprocessor
    import sys
    f = open(sys.argv[1])
    input = f.read()

    p = Preprocessor(lexer)
    p.parse(input,sys.argv[1])
    while True:
        tok = p.token()
        if not tok: break
        print p.source, tok




    







########NEW FILE########
__FILENAME__ = ctokens
# ----------------------------------------------------------------------
# ctokens.py
#
# Token specifications for symbols in ANSI C and C++.  This file is
# meant to be used as a library in other tokenizers.
# ----------------------------------------------------------------------

# Reserved words

tokens = [
    # Literals (identifier, integer constant, float constant, string constant, char const)
    'ID', 'TYPEID', 'ICONST', 'FCONST', 'SCONST', 'CCONST',

    # Operators (+,-,*,/,%,|,&,~,^,<<,>>, ||, &&, !, <, <=, >, >=, ==, !=)
    'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'MOD',
    'OR', 'AND', 'NOT', 'XOR', 'LSHIFT', 'RSHIFT',
    'LOR', 'LAND', 'LNOT',
    'LT', 'LE', 'GT', 'GE', 'EQ', 'NE',
    
    # Assignment (=, *=, /=, %=, +=, -=, <<=, >>=, &=, ^=, |=)
    'EQUALS', 'TIMESEQUAL', 'DIVEQUAL', 'MODEQUAL', 'PLUSEQUAL', 'MINUSEQUAL',
    'LSHIFTEQUAL','RSHIFTEQUAL', 'ANDEQUAL', 'XOREQUAL', 'OREQUAL',

    # Increment/decrement (++,--)
    'PLUSPLUS', 'MINUSMINUS',

    # Structure dereference (->)
    'ARROW',

    # Ternary operator (?)
    'TERNARY',
    
    # Delimeters ( ) [ ] { } , . ; :
    'LPAREN', 'RPAREN',
    'LBRACKET', 'RBRACKET',
    'LBRACE', 'RBRACE',
    'COMMA', 'PERIOD', 'SEMI', 'COLON',

    # Ellipsis (...)
    'ELLIPSIS',
]
    
# Operators
t_PLUS             = r'\+'
t_MINUS            = r'-'
t_TIMES            = r'\*'
t_DIVIDE           = r'/'
t_MODULO           = r'%'
t_OR               = r'\|'
t_AND              = r'&'
t_NOT              = r'~'
t_XOR              = r'\^'
t_LSHIFT           = r'<<'
t_RSHIFT           = r'>>'
t_LOR              = r'\|\|'
t_LAND             = r'&&'
t_LNOT             = r'!'
t_LT               = r'<'
t_GT               = r'>'
t_LE               = r'<='
t_GE               = r'>='
t_EQ               = r'=='
t_NE               = r'!='

# Assignment operators

t_EQUALS           = r'='
t_TIMESEQUAL       = r'\*='
t_DIVEQUAL         = r'/='
t_MODEQUAL         = r'%='
t_PLUSEQUAL        = r'\+='
t_MINUSEQUAL       = r'-='
t_LSHIFTEQUAL      = r'<<='
t_RSHIFTEQUAL      = r'>>='
t_ANDEQUAL         = r'&='
t_OREQUAL          = r'\|='
t_XOREQUAL         = r'^='

# Increment/decrement
t_INCREMENT        = r'\+\+'
t_DECREMENT        = r'--'

# ->
t_ARROW            = r'->'

# ?
t_TERNARY          = r'\?'

# Delimeters
t_LPAREN           = r'\('
t_RPAREN           = r'\)'
t_LBRACKET         = r'\['
t_RBRACKET         = r'\]'
t_LBRACE           = r'\{'
t_RBRACE           = r'\}'
t_COMMA            = r','
t_PERIOD           = r'\.'
t_SEMI             = r';'
t_COLON            = r':'
t_ELLIPSIS         = r'\.\.\.'

# Identifiers
t_ID = r'[A-Za-z_][A-Za-z0-9_]*'

# Integer literal
t_INTEGER = r'\d+([uU]|[lL]|[uU][lL]|[lL][uU])?'

# Floating literal
t_FLOAT = r'((\d+)(\.\d+)(e(\+|-)?(\d+))? | (\d+)e(\+|-)?(\d+))([lL]|[fF])?'

# String literal
t_STRING = r'\"([^\\\n]|(\\.))*?\"'

# Character constant 'c' or L'c'
t_CHARACTER = r'(L)?\'([^\\\n]|(\\.))*?\''

# Comment (C-Style)
def t_COMMENT(t):
    r'/\*(.|\n)*?\*/'
    t.lexer.lineno += t.value.count('\n')
    return t

# Comment (C++-Style)
def t_CPPCOMMENT(t):
    r'//.*\n'
    t.lexer.lineno += 1
    return t


    




########NEW FILE########
__FILENAME__ = lex
# -----------------------------------------------------------------------------
# ply: lex.py
#
# Copyright (C) 2001-2009,
# David M. Beazley (Dabeaz LLC)
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
# 
# * Redistributions of source code must retain the above copyright notice,
#   this list of conditions and the following disclaimer.  
# * Redistributions in binary form must reproduce the above copyright notice, 
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.  
# * Neither the name of the David Beazley or Dabeaz LLC may be used to
#   endorse or promote products derived from this software without
#  specific prior written permission. 
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
# -----------------------------------------------------------------------------

__version__    = "3.3"
__tabversion__ = "3.2"       # Version of table file used

import re, sys, types, copy, os

# This tuple contains known string types
try:
    # Python 2.6
    StringTypes = (types.StringType, types.UnicodeType)
except AttributeError:
    # Python 3.0
    StringTypes = (str, bytes)

# Extract the code attribute of a function. Different implementations
# are for Python 2/3 compatibility.

if sys.version_info[0] < 3:
    def func_code(f):
        return f.func_code
else:
    def func_code(f):
        return f.__code__

# This regular expression is used to match valid token names
_is_identifier = re.compile(r'^[a-zA-Z0-9_]+$')

# Exception thrown when invalid token encountered and no default error
# handler is defined.

class LexError(Exception):
    def __init__(self,message,s):
         self.args = (message,)
         self.text = s

# Token class.  This class is used to represent the tokens produced.
class LexToken(object):
    def __str__(self):
        return "LexToken(%s,%r,%d,%d)" % (self.type,self.value,self.lineno,self.lexpos)
    def __repr__(self):
        return str(self)

# This object is a stand-in for a logging object created by the 
# logging module.  

class PlyLogger(object):
    def __init__(self,f):
        self.f = f
    def critical(self,msg,*args,**kwargs):
        self.f.write((msg % args) + "\n")

    def warning(self,msg,*args,**kwargs):
        self.f.write("WARNING: "+ (msg % args) + "\n")

    def error(self,msg,*args,**kwargs):
        self.f.write("ERROR: " + (msg % args) + "\n")

    info = critical
    debug = critical

# Null logger is used when no output is generated. Does nothing.
class NullLogger(object):
    def __getattribute__(self,name):
        return self
    def __call__(self,*args,**kwargs):
        return self

# -----------------------------------------------------------------------------
#                        === Lexing Engine ===
#
# The following Lexer class implements the lexer runtime.   There are only
# a few public methods and attributes:
#
#    input()          -  Store a new string in the lexer
#    token()          -  Get the next token
#    clone()          -  Clone the lexer
#
#    lineno           -  Current line number
#    lexpos           -  Current position in the input string
# -----------------------------------------------------------------------------

class Lexer:
    def __init__(self):
        self.lexre = None             # Master regular expression. This is a list of
                                      # tuples (re,findex) where re is a compiled
                                      # regular expression and findex is a list
                                      # mapping regex group numbers to rules
        self.lexretext = None         # Current regular expression strings
        self.lexstatere = {}          # Dictionary mapping lexer states to master regexs
        self.lexstateretext = {}      # Dictionary mapping lexer states to regex strings
        self.lexstaterenames = {}     # Dictionary mapping lexer states to symbol names
        self.lexstate = "INITIAL"     # Current lexer state
        self.lexstatestack = []       # Stack of lexer states
        self.lexstateinfo = None      # State information
        self.lexstateignore = {}      # Dictionary of ignored characters for each state
        self.lexstateerrorf = {}      # Dictionary of error functions for each state
        self.lexreflags = 0           # Optional re compile flags
        self.lexdata = None           # Actual input data (as a string)
        self.lexpos = 0               # Current position in input text
        self.lexlen = 0               # Length of the input text
        self.lexerrorf = None         # Error rule (if any)
        self.lextokens = None         # List of valid tokens
        self.lexignore = ""           # Ignored characters
        self.lexliterals = ""         # Literal characters that can be passed through
        self.lexmodule = None         # Module
        self.lineno = 1               # Current line number
        self.lexoptimize = 0          # Optimized mode

    def clone(self,object=None):
        c = copy.copy(self)

        # If the object parameter has been supplied, it means we are attaching the
        # lexer to a new object.  In this case, we have to rebind all methods in
        # the lexstatere and lexstateerrorf tables.

        if object:
            newtab = { }
            for key, ritem in self.lexstatere.items():
                newre = []
                for cre, findex in ritem:
                     newfindex = []
                     for f in findex:
                         if not f or not f[0]:
                             newfindex.append(f)
                             continue
                         newfindex.append((getattr(object,f[0].__name__),f[1]))
                newre.append((cre,newfindex))
                newtab[key] = newre
            c.lexstatere = newtab
            c.lexstateerrorf = { }
            for key, ef in self.lexstateerrorf.items():
                c.lexstateerrorf[key] = getattr(object,ef.__name__)
            c.lexmodule = object
        return c

    # ------------------------------------------------------------
    # writetab() - Write lexer information to a table file
    # ------------------------------------------------------------
    def writetab(self,tabfile,outputdir=""):
        if isinstance(tabfile,types.ModuleType):
            return
        basetabfilename = tabfile.split(".")[-1]
        filename = os.path.join(outputdir,basetabfilename)+".py"
        tf = open(filename,"w")
        tf.write("# %s.py. This file automatically created by PLY (version %s). Don't edit!\n" % (tabfile,__version__))
        tf.write("_tabversion   = %s\n" % repr(__version__))
        tf.write("_lextokens    = %s\n" % repr(self.lextokens))
        tf.write("_lexreflags   = %s\n" % repr(self.lexreflags))
        tf.write("_lexliterals  = %s\n" % repr(self.lexliterals))
        tf.write("_lexstateinfo = %s\n" % repr(self.lexstateinfo))

        tabre = { }
        # Collect all functions in the initial state
        initial = self.lexstatere["INITIAL"]
        initialfuncs = []
        for part in initial:
            for f in part[1]:
                if f and f[0]:
                    initialfuncs.append(f)

        for key, lre in self.lexstatere.items():
             titem = []
             for i in range(len(lre)):
                  titem.append((self.lexstateretext[key][i],_funcs_to_names(lre[i][1],self.lexstaterenames[key][i])))
             tabre[key] = titem

        tf.write("_lexstatere   = %s\n" % repr(tabre))
        tf.write("_lexstateignore = %s\n" % repr(self.lexstateignore))

        taberr = { }
        for key, ef in self.lexstateerrorf.items():
             if ef:
                  taberr[key] = ef.__name__
             else:
                  taberr[key] = None
        tf.write("_lexstateerrorf = %s\n" % repr(taberr))
        tf.close()

    # ------------------------------------------------------------
    # readtab() - Read lexer information from a tab file
    # ------------------------------------------------------------
    def readtab(self,tabfile,fdict):
        if isinstance(tabfile,types.ModuleType):
            lextab = tabfile
        else:
            if sys.version_info[0] < 3:
                exec("import %s as lextab" % tabfile)
            else:
                env = { }
                exec("import %s as lextab" % tabfile, env,env)
                lextab = env['lextab']

        if getattr(lextab,"_tabversion","0.0") != __version__:
            raise ImportError("Inconsistent PLY version")

        self.lextokens      = lextab._lextokens
        self.lexreflags     = lextab._lexreflags
        self.lexliterals    = lextab._lexliterals
        self.lexstateinfo   = lextab._lexstateinfo
        self.lexstateignore = lextab._lexstateignore
        self.lexstatere     = { }
        self.lexstateretext = { }
        for key,lre in lextab._lexstatere.items():
             titem = []
             txtitem = []
             for i in range(len(lre)):
                  titem.append((re.compile(lre[i][0],lextab._lexreflags | re.VERBOSE),_names_to_funcs(lre[i][1],fdict)))
                  txtitem.append(lre[i][0])
             self.lexstatere[key] = titem
             self.lexstateretext[key] = txtitem
        self.lexstateerrorf = { }
        for key,ef in lextab._lexstateerrorf.items():
             self.lexstateerrorf[key] = fdict[ef]
        self.begin('INITIAL')

    # ------------------------------------------------------------
    # input() - Push a new string into the lexer
    # ------------------------------------------------------------
    def input(self,s):
        # Pull off the first character to see if s looks like a string
        c = s[:1]
        if not isinstance(c,StringTypes):
            raise ValueError("Expected a string")
        self.lexdata = s
        self.lexpos = 0
        self.lexlen = len(s)

    # ------------------------------------------------------------
    # begin() - Changes the lexing state
    # ------------------------------------------------------------
    def begin(self,state):
        if not state in self.lexstatere:
            raise ValueError("Undefined state")
        self.lexre = self.lexstatere[state]
        self.lexretext = self.lexstateretext[state]
        self.lexignore = self.lexstateignore.get(state,"")
        self.lexerrorf = self.lexstateerrorf.get(state,None)
        self.lexstate = state

    # ------------------------------------------------------------
    # push_state() - Changes the lexing state and saves old on stack
    # ------------------------------------------------------------
    def push_state(self,state):
        self.lexstatestack.append(self.lexstate)
        self.begin(state)

    # ------------------------------------------------------------
    # pop_state() - Restores the previous state
    # ------------------------------------------------------------
    def pop_state(self):
        self.begin(self.lexstatestack.pop())

    # ------------------------------------------------------------
    # current_state() - Returns the current lexing state
    # ------------------------------------------------------------
    def current_state(self):
        return self.lexstate

    # ------------------------------------------------------------
    # skip() - Skip ahead n characters
    # ------------------------------------------------------------
    def skip(self,n):
        self.lexpos += n

    # ------------------------------------------------------------
    # opttoken() - Return the next token from the Lexer
    #
    # Note: This function has been carefully implemented to be as fast
    # as possible.  Don't make changes unless you really know what
    # you are doing
    # ------------------------------------------------------------
    def token(self):
        # Make local copies of frequently referenced attributes
        lexpos    = self.lexpos
        lexlen    = self.lexlen
        lexignore = self.lexignore
        lexdata   = self.lexdata

        while lexpos < lexlen:
            # This code provides some short-circuit code for whitespace, tabs, and other ignored characters
            if lexdata[lexpos] in lexignore:
                lexpos += 1
                continue

            # Look for a regular expression match
            for lexre,lexindexfunc in self.lexre:
                m = lexre.match(lexdata,lexpos)
                if not m: continue

                # Create a token for return
                tok = LexToken()
                tok.value = m.group()
                tok.lineno = self.lineno
                tok.lexpos = lexpos

                i = m.lastindex
                func,tok.type = lexindexfunc[i]

                if not func:
                   # If no token type was set, it's an ignored token
                   if tok.type:
                      self.lexpos = m.end()
                      return tok
                   else:
                      lexpos = m.end()
                      break

                lexpos = m.end()

                # If token is processed by a function, call it

                tok.lexer = self      # Set additional attributes useful in token rules
                self.lexmatch = m
                self.lexpos = lexpos

                newtok = func(tok)

                # Every function must return a token, if nothing, we just move to next token
                if not newtok:
                    lexpos    = self.lexpos         # This is here in case user has updated lexpos.
                    lexignore = self.lexignore      # This is here in case there was a state change
                    break

                # Verify type of the token.  If not in the token map, raise an error
                if not self.lexoptimize:
                    if not newtok.type in self.lextokens:
                        raise LexError("%s:%d: Rule '%s' returned an unknown token type '%s'" % (
                            func_code(func).co_filename, func_code(func).co_firstlineno,
                            func.__name__, newtok.type),lexdata[lexpos:])

                return newtok
            else:
                # No match, see if in literals
                if lexdata[lexpos] in self.lexliterals:
                    tok = LexToken()
                    tok.value = lexdata[lexpos]
                    tok.lineno = self.lineno
                    tok.type = tok.value
                    tok.lexpos = lexpos
                    self.lexpos = lexpos + 1
                    return tok

                # No match. Call t_error() if defined.
                if self.lexerrorf:
                    tok = LexToken()
                    tok.value = self.lexdata[lexpos:]
                    tok.lineno = self.lineno
                    tok.type = "error"
                    tok.lexer = self
                    tok.lexpos = lexpos
                    self.lexpos = lexpos
                    newtok = self.lexerrorf(tok)
                    if lexpos == self.lexpos:
                        # Error method didn't change text position at all. This is an error.
                        raise LexError("Scanning error. Illegal character '%s'" % (lexdata[lexpos]), lexdata[lexpos:])
                    lexpos = self.lexpos
                    if not newtok: continue
                    return newtok

                self.lexpos = lexpos
                raise LexError("Illegal character '%s' at index %d" % (lexdata[lexpos],lexpos), lexdata[lexpos:])

        self.lexpos = lexpos + 1
        if self.lexdata is None:
             raise RuntimeError("No input string given with input()")
        return None

    # Iterator interface
    def __iter__(self):
        return self

    def next(self):
        t = self.token()
        if t is None:
            raise StopIteration
        return t

    __next__ = next

# -----------------------------------------------------------------------------
#                           ==== Lex Builder ===
#
# The functions and classes below are used to collect lexing information
# and build a Lexer object from it.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# get_caller_module_dict()
#
# This function returns a dictionary containing all of the symbols defined within
# a caller further down the call stack.  This is used to get the environment
# associated with the yacc() call if none was provided.
# -----------------------------------------------------------------------------

def get_caller_module_dict(levels):
    try:
        raise RuntimeError
    except RuntimeError:
        e,b,t = sys.exc_info()
        f = t.tb_frame
        while levels > 0:
            f = f.f_back                   
            levels -= 1
        ldict = f.f_globals.copy()
        if f.f_globals != f.f_locals:
            ldict.update(f.f_locals)

        return ldict

# -----------------------------------------------------------------------------
# _funcs_to_names()
#
# Given a list of regular expression functions, this converts it to a list
# suitable for output to a table file
# -----------------------------------------------------------------------------

def _funcs_to_names(funclist,namelist):
    result = []
    for f,name in zip(funclist,namelist):
         if f and f[0]:
             result.append((name, f[1]))
         else:
             result.append(f)
    return result

# -----------------------------------------------------------------------------
# _names_to_funcs()
#
# Given a list of regular expression function names, this converts it back to
# functions.
# -----------------------------------------------------------------------------

def _names_to_funcs(namelist,fdict):
     result = []
     for n in namelist:
          if n and n[0]:
              result.append((fdict[n[0]],n[1]))
          else:
              result.append(n)
     return result

# -----------------------------------------------------------------------------
# _form_master_re()
#
# This function takes a list of all of the regex components and attempts to
# form the master regular expression.  Given limitations in the Python re
# module, it may be necessary to break the master regex into separate expressions.
# -----------------------------------------------------------------------------

def _form_master_re(relist,reflags,ldict,toknames):
    if not relist: return []
    regex = "|".join(relist)
    try:
        lexre = re.compile(regex,re.VERBOSE | reflags)

        # Build the index to function map for the matching engine
        lexindexfunc = [ None ] * (max(lexre.groupindex.values())+1)
        lexindexnames = lexindexfunc[:]

        for f,i in lexre.groupindex.items():
            handle = ldict.get(f,None)
            if type(handle) in (types.FunctionType, types.MethodType):
                lexindexfunc[i] = (handle,toknames[f])
                lexindexnames[i] = f
            elif handle is not None:
                lexindexnames[i] = f
                if f.find("ignore_") > 0:
                    lexindexfunc[i] = (None,None)
                else:
                    lexindexfunc[i] = (None, toknames[f])
        
        return [(lexre,lexindexfunc)],[regex],[lexindexnames]
    except Exception:
        m = int(len(relist)/2)
        if m == 0: m = 1
        llist, lre, lnames = _form_master_re(relist[:m],reflags,ldict,toknames)
        rlist, rre, rnames = _form_master_re(relist[m:],reflags,ldict,toknames)
        return llist+rlist, lre+rre, lnames+rnames

# -----------------------------------------------------------------------------
# def _statetoken(s,names)
#
# Given a declaration name s of the form "t_" and a dictionary whose keys are
# state names, this function returns a tuple (states,tokenname) where states
# is a tuple of state names and tokenname is the name of the token.  For example,
# calling this with s = "t_foo_bar_SPAM" might return (('foo','bar'),'SPAM')
# -----------------------------------------------------------------------------

def _statetoken(s,names):
    nonstate = 1
    parts = s.split("_")
    for i in range(1,len(parts)):
         if not parts[i] in names and parts[i] != 'ANY': break
    if i > 1:
       states = tuple(parts[1:i])
    else:
       states = ('INITIAL',)

    if 'ANY' in states:
       states = tuple(names)

    tokenname = "_".join(parts[i:])
    return (states,tokenname)


# -----------------------------------------------------------------------------
# LexerReflect()
#
# This class represents information needed to build a lexer as extracted from a
# user's input file.
# -----------------------------------------------------------------------------
class LexerReflect(object):
    def __init__(self,ldict,log=None,reflags=0):
        self.ldict      = ldict
        self.error_func = None
        self.tokens     = []
        self.reflags    = reflags
        self.stateinfo  = { 'INITIAL' : 'inclusive'}
        self.files      = {}
        self.error      = 0

        if log is None:
            self.log = PlyLogger(sys.stderr)
        else:
            self.log = log

    # Get all of the basic information
    def get_all(self):
        self.get_tokens()
        self.get_literals()
        self.get_states()
        self.get_rules()
        
    # Validate all of the information
    def validate_all(self):
        self.validate_tokens()
        self.validate_literals()
        self.validate_rules()
        return self.error

    # Get the tokens map
    def get_tokens(self):
        tokens = self.ldict.get("tokens",None)
        if not tokens:
            self.log.error("No token list is defined")
            self.error = 1
            return

        if not isinstance(tokens,(list, tuple)):
            self.log.error("tokens must be a list or tuple")
            self.error = 1
            return
        
        if not tokens:
            self.log.error("tokens is empty")
            self.error = 1
            return

        self.tokens = tokens

    # Validate the tokens
    def validate_tokens(self):
        terminals = {}
        for n in self.tokens:
            if not _is_identifier.match(n):
                self.log.error("Bad token name '%s'",n)
                self.error = 1
            if n in terminals:
                self.log.warning("Token '%s' multiply defined", n)
            terminals[n] = 1

    # Get the literals specifier
    def get_literals(self):
        self.literals = self.ldict.get("literals","")

    # Validate literals
    def validate_literals(self):
        try:
            for c in self.literals:
                if not isinstance(c,StringTypes) or len(c) > 1:
                    self.log.error("Invalid literal %s. Must be a single character", repr(c))
                    self.error = 1
                    continue

        except TypeError:
            self.log.error("Invalid literals specification. literals must be a sequence of characters")
            self.error = 1

    def get_states(self):
        self.states = self.ldict.get("states",None)
        # Build statemap
        if self.states:
             if not isinstance(self.states,(tuple,list)):
                  self.log.error("states must be defined as a tuple or list")
                  self.error = 1
             else:
                  for s in self.states:
                        if not isinstance(s,tuple) or len(s) != 2:
                               self.log.error("Invalid state specifier %s. Must be a tuple (statename,'exclusive|inclusive')",repr(s))
                               self.error = 1
                               continue
                        name, statetype = s
                        if not isinstance(name,StringTypes):
                               self.log.error("State name %s must be a string", repr(name))
                               self.error = 1
                               continue
                        if not (statetype == 'inclusive' or statetype == 'exclusive'):
                               self.log.error("State type for state %s must be 'inclusive' or 'exclusive'",name)
                               self.error = 1
                               continue
                        if name in self.stateinfo:
                               self.log.error("State '%s' already defined",name)
                               self.error = 1
                               continue
                        self.stateinfo[name] = statetype

    # Get all of the symbols with a t_ prefix and sort them into various
    # categories (functions, strings, error functions, and ignore characters)

    def get_rules(self):
        tsymbols = [f for f in self.ldict if f[:2] == 't_' ]

        # Now build up a list of functions and a list of strings

        self.toknames = { }        # Mapping of symbols to token names
        self.funcsym =  { }        # Symbols defined as functions
        self.strsym =   { }        # Symbols defined as strings
        self.ignore   = { }        # Ignore strings by state
        self.errorf   = { }        # Error functions by state

        for s in self.stateinfo:
             self.funcsym[s] = []
             self.strsym[s] = []

        if len(tsymbols) == 0:
            self.log.error("No rules of the form t_rulename are defined")
            self.error = 1
            return

        for f in tsymbols:
            t = self.ldict[f]
            states, tokname = _statetoken(f,self.stateinfo)
            self.toknames[f] = tokname

            if hasattr(t,"__call__"):
                if tokname == 'error':
                    for s in states:
                        self.errorf[s] = t
                elif tokname == 'ignore':
                    line = func_code(t).co_firstlineno
                    file = func_code(t).co_filename
                    self.log.error("%s:%d: Rule '%s' must be defined as a string",file,line,t.__name__)
                    self.error = 1
                else:
                    for s in states: 
                        self.funcsym[s].append((f,t))
            elif isinstance(t, StringTypes):
                if tokname == 'ignore':
                    for s in states:
                        self.ignore[s] = t
                    if "\\" in t:
                        self.log.warning("%s contains a literal backslash '\\'",f)

                elif tokname == 'error':
                    self.log.error("Rule '%s' must be defined as a function", f)
                    self.error = 1
                else:
                    for s in states: 
                        self.strsym[s].append((f,t))
            else:
                self.log.error("%s not defined as a function or string", f)
                self.error = 1

        # Sort the functions by line number
        for f in self.funcsym.values():
            if sys.version_info[0] < 3:
                f.sort(lambda x,y: cmp(func_code(x[1]).co_firstlineno,func_code(y[1]).co_firstlineno))
            else:
                # Python 3.0
                f.sort(key=lambda x: func_code(x[1]).co_firstlineno)

        # Sort the strings by regular expression length
        for s in self.strsym.values():
            if sys.version_info[0] < 3:
                s.sort(lambda x,y: (len(x[1]) < len(y[1])) - (len(x[1]) > len(y[1])))
            else:
                # Python 3.0
                s.sort(key=lambda x: len(x[1]),reverse=True)

    # Validate all of the t_rules collected 
    def validate_rules(self):
        for state in self.stateinfo:
            # Validate all rules defined by functions

            

            for fname, f in self.funcsym[state]:
                line = func_code(f).co_firstlineno
                file = func_code(f).co_filename
                self.files[file] = 1

                tokname = self.toknames[fname]
                if isinstance(f, types.MethodType):
                    reqargs = 2
                else:
                    reqargs = 1
                nargs = func_code(f).co_argcount
                if nargs > reqargs:
                    self.log.error("%s:%d: Rule '%s' has too many arguments",file,line,f.__name__)
                    self.error = 1
                    continue

                if nargs < reqargs:
                    self.log.error("%s:%d: Rule '%s' requires an argument", file,line,f.__name__)
                    self.error = 1
                    continue

                if not f.__doc__:
                    self.log.error("%s:%d: No regular expression defined for rule '%s'",file,line,f.__name__)
                    self.error = 1
                    continue

                try:
                    c = re.compile("(?P<%s>%s)" % (fname,f.__doc__), re.VERBOSE | self.reflags)
                    if c.match(""):
                        self.log.error("%s:%d: Regular expression for rule '%s' matches empty string", file,line,f.__name__)
                        self.error = 1
                except re.error:
                    _etype, e, _etrace = sys.exc_info()
                    self.log.error("%s:%d: Invalid regular expression for rule '%s'. %s", file,line,f.__name__,e)
                    if '#' in f.__doc__:
                        self.log.error("%s:%d. Make sure '#' in rule '%s' is escaped with '\\#'",file,line, f.__name__)
                    self.error = 1

            # Validate all rules defined by strings
            for name,r in self.strsym[state]:
                tokname = self.toknames[name]
                if tokname == 'error':
                    self.log.error("Rule '%s' must be defined as a function", name)
                    self.error = 1
                    continue

                if not tokname in self.tokens and tokname.find("ignore_") < 0:
                    self.log.error("Rule '%s' defined for an unspecified token %s",name,tokname)
                    self.error = 1
                    continue

                try:
                    c = re.compile("(?P<%s>%s)" % (name,r),re.VERBOSE | self.reflags)
                    if (c.match("")):
                         self.log.error("Regular expression for rule '%s' matches empty string",name)
                         self.error = 1
                except re.error:
                    _etype, e, _etrace = sys.exc_info()
                    self.log.error("Invalid regular expression for rule '%s'. %s",name,e)
                    if '#' in r:
                         self.log.error("Make sure '#' in rule '%s' is escaped with '\\#'",name)
                    self.error = 1

            if not self.funcsym[state] and not self.strsym[state]:
                self.log.error("No rules defined for state '%s'",state)
                self.error = 1

            # Validate the error function
            efunc = self.errorf.get(state,None)
            if efunc:
                f = efunc
                line = func_code(f).co_firstlineno
                file = func_code(f).co_filename
                self.files[file] = 1

                if isinstance(f, types.MethodType):
                    reqargs = 2
                else:
                    reqargs = 1
                nargs = func_code(f).co_argcount
                if nargs > reqargs:
                    self.log.error("%s:%d: Rule '%s' has too many arguments",file,line,f.__name__)
                    self.error = 1

                if nargs < reqargs:
                    self.log.error("%s:%d: Rule '%s' requires an argument", file,line,f.__name__)
                    self.error = 1

        for f in self.files:
            self.validate_file(f)


    # -----------------------------------------------------------------------------
    # validate_file()
    #
    # This checks to see if there are duplicated t_rulename() functions or strings
    # in the parser input file.  This is done using a simple regular expression
    # match on each line in the given file.  
    # -----------------------------------------------------------------------------

    def validate_file(self,filename):
        import os.path
        base,ext = os.path.splitext(filename)
        if ext != '.py': return         # No idea what the file is. Return OK

        try:
            f = open(filename)
            lines = f.readlines()
            f.close()
        except IOError:
            return                      # Couldn't find the file.  Don't worry about it

        fre = re.compile(r'\s*def\s+(t_[a-zA-Z_0-9]*)\(')
        sre = re.compile(r'\s*(t_[a-zA-Z_0-9]*)\s*=')

        counthash = { }
        linen = 1
        for l in lines:
            m = fre.match(l)
            if not m:
                m = sre.match(l)
            if m:
                name = m.group(1)
                prev = counthash.get(name)
                if not prev:
                    counthash[name] = linen
                else:
                    self.log.error("%s:%d: Rule %s redefined. Previously defined on line %d",filename,linen,name,prev)
                    self.error = 1
            linen += 1
            
# -----------------------------------------------------------------------------
# lex(module)
#
# Build all of the regular expression rules from definitions in the supplied module
# -----------------------------------------------------------------------------
def lex(module=None,object=None,debug=0,optimize=0,lextab="lextab",reflags=0,nowarn=0,outputdir="", debuglog=None, errorlog=None):
    global lexer
    ldict = None
    stateinfo  = { 'INITIAL' : 'inclusive'}
    lexobj = Lexer()
    lexobj.lexoptimize = optimize
    global token,input

    if errorlog is None:
        errorlog = PlyLogger(sys.stderr)

    if debug:
        if debuglog is None:
            debuglog = PlyLogger(sys.stderr)

    # Get the module dictionary used for the lexer
    if object: module = object

    if module:
        _items = [(k,getattr(module,k)) for k in dir(module)]
        ldict = dict(_items)
    else:
        ldict = get_caller_module_dict(2)

    # Collect parser information from the dictionary
    linfo = LexerReflect(ldict,log=errorlog,reflags=reflags)
    linfo.get_all()
    if not optimize:
        if linfo.validate_all():
            raise SyntaxError("Can't build lexer")

    if optimize and lextab:
        try:
            lexobj.readtab(lextab,ldict)
            token = lexobj.token
            input = lexobj.input
            lexer = lexobj
            return lexobj

        except ImportError:
            pass

    # Dump some basic debugging information
    if debug:
        debuglog.info("lex: tokens   = %r", linfo.tokens)
        debuglog.info("lex: literals = %r", linfo.literals)
        debuglog.info("lex: states   = %r", linfo.stateinfo)

    # Build a dictionary of valid token names
    lexobj.lextokens = { }
    for n in linfo.tokens:
        lexobj.lextokens[n] = 1

    # Get literals specification
    if isinstance(linfo.literals,(list,tuple)):
        lexobj.lexliterals = type(linfo.literals[0])().join(linfo.literals)
    else:
        lexobj.lexliterals = linfo.literals

    # Get the stateinfo dictionary
    stateinfo = linfo.stateinfo

    regexs = { }
    # Build the master regular expressions
    for state in stateinfo:
        regex_list = []

        # Add rules defined by functions first
        for fname, f in linfo.funcsym[state]:
            line = func_code(f).co_firstlineno
            file = func_code(f).co_filename
            regex_list.append("(?P<%s>%s)" % (fname,f.__doc__))
            if debug:
                debuglog.info("lex: Adding rule %s -> '%s' (state '%s')",fname,f.__doc__, state)

        # Now add all of the simple rules
        for name,r in linfo.strsym[state]:
            regex_list.append("(?P<%s>%s)" % (name,r))
            if debug:
                debuglog.info("lex: Adding rule %s -> '%s' (state '%s')",name,r, state)

        regexs[state] = regex_list

    # Build the master regular expressions

    if debug:
        debuglog.info("lex: ==== MASTER REGEXS FOLLOW ====")

    for state in regexs:
        lexre, re_text, re_names = _form_master_re(regexs[state],reflags,ldict,linfo.toknames)
        lexobj.lexstatere[state] = lexre
        lexobj.lexstateretext[state] = re_text
        lexobj.lexstaterenames[state] = re_names
        if debug:
            for i in range(len(re_text)):
                debuglog.info("lex: state '%s' : regex[%d] = '%s'",state, i, re_text[i])

    # For inclusive states, we need to add the regular expressions from the INITIAL state
    for state,stype in stateinfo.items():
        if state != "INITIAL" and stype == 'inclusive':
             lexobj.lexstatere[state].extend(lexobj.lexstatere['INITIAL'])
             lexobj.lexstateretext[state].extend(lexobj.lexstateretext['INITIAL'])
             lexobj.lexstaterenames[state].extend(lexobj.lexstaterenames['INITIAL'])

    lexobj.lexstateinfo = stateinfo
    lexobj.lexre = lexobj.lexstatere["INITIAL"]
    lexobj.lexretext = lexobj.lexstateretext["INITIAL"]
    lexobj.lexreflags = reflags

    # Set up ignore variables
    lexobj.lexstateignore = linfo.ignore
    lexobj.lexignore = lexobj.lexstateignore.get("INITIAL","")

    # Set up error functions
    lexobj.lexstateerrorf = linfo.errorf
    lexobj.lexerrorf = linfo.errorf.get("INITIAL",None)
    if not lexobj.lexerrorf:
        errorlog.warning("No t_error rule is defined")

    # Check state information for ignore and error rules
    for s,stype in stateinfo.items():
        if stype == 'exclusive':
              if not s in linfo.errorf:
                   errorlog.warning("No error rule is defined for exclusive state '%s'", s)
              if not s in linfo.ignore and lexobj.lexignore:
                   errorlog.warning("No ignore rule is defined for exclusive state '%s'", s)
        elif stype == 'inclusive':
              if not s in linfo.errorf:
                   linfo.errorf[s] = linfo.errorf.get("INITIAL",None)
              if not s in linfo.ignore:
                   linfo.ignore[s] = linfo.ignore.get("INITIAL","")

    # Create global versions of the token() and input() functions
    token = lexobj.token
    input = lexobj.input
    lexer = lexobj

    # If in optimize mode, we write the lextab
    if lextab and optimize:
        lexobj.writetab(lextab,outputdir)

    return lexobj

# -----------------------------------------------------------------------------
# runmain()
#
# This runs the lexer as a main program
# -----------------------------------------------------------------------------

def runmain(lexer=None,data=None):
    if not data:
        try:
            filename = sys.argv[1]
            f = open(filename)
            data = f.read()
            f.close()
        except IndexError:
            sys.stdout.write("Reading from standard input (type EOF to end):\n")
            data = sys.stdin.read()

    if lexer:
        _input = lexer.input
    else:
        _input = input
    _input(data)
    if lexer:
        _token = lexer.token
    else:
        _token = token

    while 1:
        tok = _token()
        if not tok: break
        sys.stdout.write("(%s,%r,%d,%d)\n" % (tok.type, tok.value, tok.lineno,tok.lexpos))

# -----------------------------------------------------------------------------
# @TOKEN(regex)
#
# This decorator function can be used to set the regex expression on a function
# when its docstring might need to be set in an alternative way
# -----------------------------------------------------------------------------

def TOKEN(r):
    def set_doc(f):
        if hasattr(r,"__call__"):
            f.__doc__ = r.__doc__
        else:
            f.__doc__ = r
        return f
    return set_doc

# Alternative spelling of the TOKEN decorator
Token = TOKEN


########NEW FILE########
__FILENAME__ = yacc
# -----------------------------------------------------------------------------
# ply: yacc.py
#
# Copyright (C) 2001-2009,
# David M. Beazley (Dabeaz LLC)
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
# 
# * Redistributions of source code must retain the above copyright notice,
#   this list of conditions and the following disclaimer.  
# * Redistributions in binary form must reproduce the above copyright notice, 
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.  
# * Neither the name of the David Beazley or Dabeaz LLC may be used to
#   endorse or promote products derived from this software without
#  specific prior written permission. 
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
# -----------------------------------------------------------------------------
#
# This implements an LR parser that is constructed from grammar rules defined
# as Python functions. The grammer is specified by supplying the BNF inside
# Python documentation strings.  The inspiration for this technique was borrowed
# from John Aycock's Spark parsing system.  PLY might be viewed as cross between
# Spark and the GNU bison utility.
#
# The current implementation is only somewhat object-oriented. The
# LR parser itself is defined in terms of an object (which allows multiple
# parsers to co-exist).  However, most of the variables used during table
# construction are defined in terms of global variables.  Users shouldn't
# notice unless they are trying to define multiple parsers at the same
# time using threads (in which case they should have their head examined).
#
# This implementation supports both SLR and LALR(1) parsing.  LALR(1)
# support was originally implemented by Elias Ioup (ezioup@alumni.uchicago.edu),
# using the algorithm found in Aho, Sethi, and Ullman "Compilers: Principles,
# Techniques, and Tools" (The Dragon Book).  LALR(1) has since been replaced
# by the more efficient DeRemer and Pennello algorithm.
#
# :::::::: WARNING :::::::
#
# Construction of LR parsing tables is fairly complicated and expensive.
# To make this module run fast, a *LOT* of work has been put into
# optimization---often at the expensive of readability and what might
# consider to be good Python "coding style."   Modify the code at your
# own risk!
# ----------------------------------------------------------------------------

__version__    = "3.3"
__tabversion__ = "3.2"       # Table version

#-----------------------------------------------------------------------------
#                     === User configurable parameters ===
#
# Change these to modify the default behavior of yacc (if you wish)
#-----------------------------------------------------------------------------

yaccdebug   = 1                # Debugging mode.  If set, yacc generates a
                               # a 'parser.out' file in the current directory

debug_file  = 'parser.out'     # Default name of the debugging file
tab_module  = 'parsetab'       # Default name of the table module
default_lr  = 'LALR'           # Default LR table generation method

error_count = 3                # Number of symbols that must be shifted to leave recovery mode

yaccdevel   = 0                # Set to True if developing yacc.  This turns off optimized
                               # implementations of certain functions.

resultlimit = 40               # Size limit of results when running in debug mode.

pickle_protocol = 0            # Protocol to use when writing pickle files

import re, types, sys, os.path

# Compatibility function for python 2.6/3.0
if sys.version_info[0] < 3:
    def func_code(f):
        return f.func_code
else:
    def func_code(f):
        return f.__code__

# Compatibility
try:
    MAXINT = sys.maxint
except AttributeError:
    MAXINT = sys.maxsize

# Python 2.x/3.0 compatibility.
def load_ply_lex():
    if sys.version_info[0] < 3:
        import lex
    else:
        import ply.lex as lex
    return lex

# This object is a stand-in for a logging object created by the 
# logging module.   PLY will use this by default to create things
# such as the parser.out file.  If a user wants more detailed
# information, they can create their own logging object and pass
# it into PLY.

class PlyLogger(object):
    def __init__(self,f):
        self.f = f
    def debug(self,msg,*args,**kwargs):
        self.f.write((msg % args) + "\n")
    info     = debug

    def warning(self,msg,*args,**kwargs):
        self.f.write("WARNING: "+ (msg % args) + "\n")

    def error(self,msg,*args,**kwargs):
        self.f.write("ERROR: " + (msg % args) + "\n")

    critical = debug

# Null logger is used when no output is generated. Does nothing.
class NullLogger(object):
    def __getattribute__(self,name):
        return self
    def __call__(self,*args,**kwargs):
        return self
        
# Exception raised for yacc-related errors
class YaccError(Exception):   pass

# Format the result message that the parser produces when running in debug mode.
def format_result(r):
    repr_str = repr(r)
    if '\n' in repr_str: repr_str = repr(repr_str)
    if len(repr_str) > resultlimit:
        repr_str = repr_str[:resultlimit]+" ..."
    result = "<%s @ 0x%x> (%s)" % (type(r).__name__,id(r),repr_str)
    return result


# Format stack entries when the parser is running in debug mode
def format_stack_entry(r):
    repr_str = repr(r)
    if '\n' in repr_str: repr_str = repr(repr_str)
    if len(repr_str) < 16:
        return repr_str
    else:
        return "<%s @ 0x%x>" % (type(r).__name__,id(r))

#-----------------------------------------------------------------------------
#                        ===  LR Parsing Engine ===
#
# The following classes are used for the LR parser itself.  These are not
# used during table construction and are independent of the actual LR
# table generation algorithm
#-----------------------------------------------------------------------------

# This class is used to hold non-terminal grammar symbols during parsing.
# It normally has the following attributes set:
#        .type       = Grammar symbol type
#        .value      = Symbol value
#        .lineno     = Starting line number
#        .endlineno  = Ending line number (optional, set automatically)
#        .lexpos     = Starting lex position
#        .endlexpos  = Ending lex position (optional, set automatically)

class YaccSymbol:
    def __str__(self):    return self.type
    def __repr__(self):   return str(self)

# This class is a wrapper around the objects actually passed to each
# grammar rule.   Index lookup and assignment actually assign the
# .value attribute of the underlying YaccSymbol object.
# The lineno() method returns the line number of a given
# item (or 0 if not defined).   The linespan() method returns
# a tuple of (startline,endline) representing the range of lines
# for a symbol.  The lexspan() method returns a tuple (lexpos,endlexpos)
# representing the range of positional information for a symbol.

class YaccProduction:
    def __init__(self,s,stack=None):
        self.slice = s
        self.stack = stack
        self.lexer = None
        self.parser= None
    def __getitem__(self,n):
        if n >= 0: return self.slice[n].value
        else: return self.stack[n].value

    def __setitem__(self,n,v):
        self.slice[n].value = v

    def __getslice__(self,i,j):
        return [s.value for s in self.slice[i:j]]

    def __len__(self):
        return len(self.slice)

    def lineno(self,n):
        return getattr(self.slice[n],"lineno",0)

    def set_lineno(self,n,lineno):
        self.slice[n].lineno = lineno

    def linespan(self,n):
        startline = getattr(self.slice[n],"lineno",0)
        endline = getattr(self.slice[n],"endlineno",startline)
        return startline,endline

    def lexpos(self,n):
        return getattr(self.slice[n],"lexpos",0)

    def lexspan(self,n):
        startpos = getattr(self.slice[n],"lexpos",0)
        endpos = getattr(self.slice[n],"endlexpos",startpos)
        return startpos,endpos

    def error(self):
       raise SyntaxError


# -----------------------------------------------------------------------------
#                               == LRParser ==
#
# The LR Parsing engine.
# -----------------------------------------------------------------------------

class LRParser:
    def __init__(self,lrtab,errorf):
        self.productions = lrtab.lr_productions
        self.action      = lrtab.lr_action
        self.goto        = lrtab.lr_goto
        self.errorfunc   = errorf

    def errok(self):
        self.errorok     = 1

    def restart(self):
        del self.statestack[:]
        del self.symstack[:]
        sym = YaccSymbol()
        sym.type = '$end'
        self.symstack.append(sym)
        self.statestack.append(0)

    def parse(self,input=None,lexer=None,debug=0,tracking=0,tokenfunc=None):
        if debug or yaccdevel:
            if isinstance(debug,int):
                debug = PlyLogger(sys.stderr)
            return self.parsedebug(input,lexer,debug,tracking,tokenfunc)
        elif tracking:
            return self.parseopt(input,lexer,debug,tracking,tokenfunc)
        else:
            return self.parseopt_notrack(input,lexer,debug,tracking,tokenfunc)
        

    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    # parsedebug().
    #
    # This is the debugging enabled version of parse().  All changes made to the
    # parsing engine should be made here.   For the non-debugging version,
    # copy this code to a method parseopt() and delete all of the sections
    # enclosed in:
    #
    #      #--! DEBUG
    #      statements
    #      #--! DEBUG
    #
    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

    def parsedebug(self,input=None,lexer=None,debug=None,tracking=0,tokenfunc=None):
        lookahead = None                 # Current lookahead symbol
        lookaheadstack = [ ]             # Stack of lookahead symbols
        actions = self.action            # Local reference to action table (to avoid lookup on self.)
        goto    = self.goto              # Local reference to goto table (to avoid lookup on self.)
        prod    = self.productions       # Local reference to production list (to avoid lookup on self.)
        pslice  = YaccProduction(None)   # Production object passed to grammar rules
        errorcount = 0                   # Used during error recovery 

        # --! DEBUG
        debug.info("PLY: PARSE DEBUG START")
        # --! DEBUG

        # If no lexer was given, we will try to use the lex module
        if not lexer:
            lex = load_ply_lex()
            lexer = lex.lexer

        # Set up the lexer and parser objects on pslice
        pslice.lexer = lexer
        pslice.parser = self

        # If input was supplied, pass to lexer
        if input is not None:
            lexer.input(input)

        if tokenfunc is None:
           # Tokenize function
           get_token = lexer.token
        else:
           get_token = tokenfunc

        # Set up the state and symbol stacks

        statestack = [ ]                # Stack of parsing states
        self.statestack = statestack
        symstack   = [ ]                # Stack of grammar symbols
        self.symstack = symstack

        pslice.stack = symstack         # Put in the production
        errtoken   = None               # Err token

        # The start state is assumed to be (0,$end)

        statestack.append(0)
        sym = YaccSymbol()
        sym.type = "$end"
        symstack.append(sym)
        state = 0
        while 1:
            # Get the next symbol on the input.  If a lookahead symbol
            # is already set, we just use that. Otherwise, we'll pull
            # the next token off of the lookaheadstack or from the lexer

            # --! DEBUG
            debug.debug('')
            debug.debug('State  : %s', state)
            # --! DEBUG

            if not lookahead:
                if not lookaheadstack:
                    lookahead = get_token()     # Get the next token
                else:
                    lookahead = lookaheadstack.pop()
                if not lookahead:
                    lookahead = YaccSymbol()
                    lookahead.type = "$end"

            # --! DEBUG
            debug.debug('Stack  : %s',
                        ("%s . %s" % (" ".join([xx.type for xx in symstack][1:]), str(lookahead))).lstrip())
            # --! DEBUG

            # Check the action table
            ltype = lookahead.type
            t = actions[state].get(ltype)

            if t is not None:
                if t > 0:
                    # shift a symbol on the stack
                    statestack.append(t)
                    state = t
                    
                    # --! DEBUG
                    debug.debug("Action : Shift and goto state %s", t)
                    # --! DEBUG

                    symstack.append(lookahead)
                    lookahead = None

                    # Decrease error count on successful shift
                    if errorcount: errorcount -=1
                    continue

                if t < 0:
                    # reduce a symbol on the stack, emit a production
                    p = prod[-t]
                    pname = p.name
                    plen  = p.len

                    # Get production function
                    sym = YaccSymbol()
                    sym.type = pname       # Production name
                    sym.value = None

                    # --! DEBUG
                    if plen:
                        debug.info("Action : Reduce rule [%s] with %s and goto state %d", p.str, "["+",".join([format_stack_entry(_v.value) for _v in symstack[-plen:]])+"]",-t)
                    else:
                        debug.info("Action : Reduce rule [%s] with %s and goto state %d", p.str, [],-t)
                        
                    # --! DEBUG

                    if plen:
                        targ = symstack[-plen-1:]
                        targ[0] = sym

                        # --! TRACKING
                        if tracking:
                           t1 = targ[1]
                           sym.lineno = t1.lineno
                           sym.lexpos = t1.lexpos
                           t1 = targ[-1]
                           sym.endlineno = getattr(t1,"endlineno",t1.lineno)
                           sym.endlexpos = getattr(t1,"endlexpos",t1.lexpos)

                        # --! TRACKING

                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                        # The code enclosed in this section is duplicated 
                        # below as a performance optimization.  Make sure
                        # changes get made in both locations.

                        pslice.slice = targ
                        
                        try:
                            # Call the grammar rule with our special slice object
                            del symstack[-plen:]
                            del statestack[-plen:]
                            p.callable(pslice)
                            # --! DEBUG
                            debug.info("Result : %s", format_result(pslice[0]))
                            # --! DEBUG
                            symstack.append(sym)
                            state = goto[statestack[-1]][pname]
                            statestack.append(state)
                        except SyntaxError:
                            # If an error was set. Enter error recovery state
                            lookaheadstack.append(lookahead)
                            symstack.pop()
                            statestack.pop()
                            state = statestack[-1]
                            sym.type = 'error'
                            lookahead = sym
                            errorcount = error_count
                            self.errorok = 0
                        continue
                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    
                    else:

                        # --! TRACKING
                        if tracking:
                           sym.lineno = lexer.lineno
                           sym.lexpos = lexer.lexpos
                        # --! TRACKING

                        targ = [ sym ]

                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                        # The code enclosed in this section is duplicated 
                        # above as a performance optimization.  Make sure
                        # changes get made in both locations.

                        pslice.slice = targ

                        try:
                            # Call the grammar rule with our special slice object
                            p.callable(pslice)
                            # --! DEBUG
                            debug.info("Result : %s", format_result(pslice[0]))
                            # --! DEBUG
                            symstack.append(sym)
                            state = goto[statestack[-1]][pname]
                            statestack.append(state)
                        except SyntaxError:
                            # If an error was set. Enter error recovery state
                            lookaheadstack.append(lookahead)
                            symstack.pop()
                            statestack.pop()
                            state = statestack[-1]
                            sym.type = 'error'
                            lookahead = sym
                            errorcount = error_count
                            self.errorok = 0
                        continue
                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                if t == 0:
                    n = symstack[-1]
                    result = getattr(n,"value",None)
                    # --! DEBUG
                    debug.info("Done   : Returning %s", format_result(result))
                    debug.info("PLY: PARSE DEBUG END")
                    # --! DEBUG
                    return result

            if t == None:

                # --! DEBUG
                debug.error('Error  : %s',
                            ("%s . %s" % (" ".join([xx.type for xx in symstack][1:]), str(lookahead))).lstrip())
                # --! DEBUG

                # We have some kind of parsing error here.  To handle
                # this, we are going to push the current token onto
                # the tokenstack and replace it with an 'error' token.
                # If there are any synchronization rules, they may
                # catch it.
                #
                # In addition to pushing the error token, we call call
                # the user defined p_error() function if this is the
                # first syntax error.  This function is only called if
                # errorcount == 0.
                if errorcount == 0 or self.errorok:
                    errorcount = error_count
                    self.errorok = 0
                    errtoken = lookahead
                    if errtoken.type == "$end":
                        errtoken = None               # End of file!
                    if self.errorfunc:
                        global errok,token,restart
                        errok = self.errok        # Set some special functions available in error recovery
                        token = get_token
                        restart = self.restart
                        if errtoken and not hasattr(errtoken,'lexer'):
                            errtoken.lexer = lexer
                        tok = self.errorfunc(errtoken)
                        del errok, token, restart   # Delete special functions

                        if self.errorok:
                            # User must have done some kind of panic
                            # mode recovery on their own.  The
                            # returned token is the next lookahead
                            lookahead = tok
                            errtoken = None
                            continue
                    else:
                        if errtoken:
                            if hasattr(errtoken,"lineno"): lineno = lookahead.lineno
                            else: lineno = 0
                            if lineno:
                                sys.stderr.write("yacc: Syntax error at line %d, token=%s\n" % (lineno, errtoken.type))
                            else:
                                sys.stderr.write("yacc: Syntax error, token=%s" % errtoken.type)
                        else:
                            sys.stderr.write("yacc: Parse error in input. EOF\n")
                            return

                else:
                    errorcount = error_count

                # case 1:  the statestack only has 1 entry on it.  If we're in this state, the
                # entire parse has been rolled back and we're completely hosed.   The token is
                # discarded and we just keep going.

                if len(statestack) <= 1 and lookahead.type != "$end":
                    lookahead = None
                    errtoken = None
                    state = 0
                    # Nuke the pushback stack
                    del lookaheadstack[:]
                    continue

                # case 2: the statestack has a couple of entries on it, but we're
                # at the end of the file. nuke the top entry and generate an error token

                # Start nuking entries on the stack
                if lookahead.type == "$end":
                    # Whoa. We're really hosed here. Bail out
                    return

                if lookahead.type != 'error':
                    sym = symstack[-1]
                    if sym.type == 'error':
                        # Hmmm. Error is on top of stack, we'll just nuke input
                        # symbol and continue
                        lookahead = None
                        continue
                    t = YaccSymbol()
                    t.type = 'error'
                    if hasattr(lookahead,"lineno"):
                        t.lineno = lookahead.lineno
                    t.value = lookahead
                    lookaheadstack.append(lookahead)
                    lookahead = t
                else:
                    symstack.pop()
                    statestack.pop()
                    state = statestack[-1]       # Potential bug fix

                continue

            # Call an error function here
            raise RuntimeError("yacc: internal parser error!!!\n")

    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    # parseopt().
    #
    # Optimized version of parse() method.  DO NOT EDIT THIS CODE DIRECTLY.
    # Edit the debug version above, then copy any modifications to the method
    # below while removing #--! DEBUG sections.
    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


    def parseopt(self,input=None,lexer=None,debug=0,tracking=0,tokenfunc=None):
        lookahead = None                 # Current lookahead symbol
        lookaheadstack = [ ]             # Stack of lookahead symbols
        actions = self.action            # Local reference to action table (to avoid lookup on self.)
        goto    = self.goto              # Local reference to goto table (to avoid lookup on self.)
        prod    = self.productions       # Local reference to production list (to avoid lookup on self.)
        pslice  = YaccProduction(None)   # Production object passed to grammar rules
        errorcount = 0                   # Used during error recovery 

        # If no lexer was given, we will try to use the lex module
        if not lexer:
            lex = load_ply_lex()
            lexer = lex.lexer
        
        # Set up the lexer and parser objects on pslice
        pslice.lexer = lexer
        pslice.parser = self

        # If input was supplied, pass to lexer
        if input is not None:
            lexer.input(input)

        if tokenfunc is None:
           # Tokenize function
           get_token = lexer.token
        else:
           get_token = tokenfunc

        # Set up the state and symbol stacks

        statestack = [ ]                # Stack of parsing states
        self.statestack = statestack
        symstack   = [ ]                # Stack of grammar symbols
        self.symstack = symstack

        pslice.stack = symstack         # Put in the production
        errtoken   = None               # Err token

        # The start state is assumed to be (0,$end)

        statestack.append(0)
        sym = YaccSymbol()
        sym.type = '$end'
        symstack.append(sym)
        state = 0
        while 1:
            # Get the next symbol on the input.  If a lookahead symbol
            # is already set, we just use that. Otherwise, we'll pull
            # the next token off of the lookaheadstack or from the lexer

            if not lookahead:
                if not lookaheadstack:
                    lookahead = get_token()     # Get the next token
                else:
                    lookahead = lookaheadstack.pop()
                if not lookahead:
                    lookahead = YaccSymbol()
                    lookahead.type = '$end'

            # Check the action table
            ltype = lookahead.type
            t = actions[state].get(ltype)

            if t is not None:
                if t > 0:
                    # shift a symbol on the stack
                    statestack.append(t)
                    state = t

                    symstack.append(lookahead)
                    lookahead = None

                    # Decrease error count on successful shift
                    if errorcount: errorcount -=1
                    continue

                if t < 0:
                    # reduce a symbol on the stack, emit a production
                    p = prod[-t]
                    pname = p.name
                    plen  = p.len

                    # Get production function
                    sym = YaccSymbol()
                    sym.type = pname       # Production name
                    sym.value = None

                    if plen:
                        targ = symstack[-plen-1:]
                        targ[0] = sym

                        # --! TRACKING
                        if tracking:
                           t1 = targ[1]
                           sym.lineno = t1.lineno
                           sym.lexpos = t1.lexpos
                           t1 = targ[-1]
                           sym.endlineno = getattr(t1,"endlineno",t1.lineno)
                           sym.endlexpos = getattr(t1,"endlexpos",t1.lexpos)

                        # --! TRACKING

                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                        # The code enclosed in this section is duplicated 
                        # below as a performance optimization.  Make sure
                        # changes get made in both locations.

                        pslice.slice = targ
                        
                        try:
                            # Call the grammar rule with our special slice object
                            del symstack[-plen:]
                            del statestack[-plen:]
                            p.callable(pslice)
                            symstack.append(sym)
                            state = goto[statestack[-1]][pname]
                            statestack.append(state)
                        except SyntaxError:
                            # If an error was set. Enter error recovery state
                            lookaheadstack.append(lookahead)
                            symstack.pop()
                            statestack.pop()
                            state = statestack[-1]
                            sym.type = 'error'
                            lookahead = sym
                            errorcount = error_count
                            self.errorok = 0
                        continue
                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    
                    else:

                        # --! TRACKING
                        if tracking:
                           sym.lineno = lexer.lineno
                           sym.lexpos = lexer.lexpos
                        # --! TRACKING

                        targ = [ sym ]

                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                        # The code enclosed in this section is duplicated 
                        # above as a performance optimization.  Make sure
                        # changes get made in both locations.

                        pslice.slice = targ

                        try:
                            # Call the grammar rule with our special slice object
                            p.callable(pslice)
                            symstack.append(sym)
                            state = goto[statestack[-1]][pname]
                            statestack.append(state)
                        except SyntaxError:
                            # If an error was set. Enter error recovery state
                            lookaheadstack.append(lookahead)
                            symstack.pop()
                            statestack.pop()
                            state = statestack[-1]
                            sym.type = 'error'
                            lookahead = sym
                            errorcount = error_count
                            self.errorok = 0
                        continue
                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                if t == 0:
                    n = symstack[-1]
                    return getattr(n,"value",None)

            if t == None:

                # We have some kind of parsing error here.  To handle
                # this, we are going to push the current token onto
                # the tokenstack and replace it with an 'error' token.
                # If there are any synchronization rules, they may
                # catch it.
                #
                # In addition to pushing the error token, we call call
                # the user defined p_error() function if this is the
                # first syntax error.  This function is only called if
                # errorcount == 0.
                if errorcount == 0 or self.errorok:
                    errorcount = error_count
                    self.errorok = 0
                    errtoken = lookahead
                    if errtoken.type == '$end':
                        errtoken = None               # End of file!
                    if self.errorfunc:
                        global errok,token,restart
                        errok = self.errok        # Set some special functions available in error recovery
                        token = get_token
                        restart = self.restart
                        if errtoken and not hasattr(errtoken,'lexer'):
                            errtoken.lexer = lexer
                        tok = self.errorfunc(errtoken)
                        del errok, token, restart   # Delete special functions

                        if self.errorok:
                            # User must have done some kind of panic
                            # mode recovery on their own.  The
                            # returned token is the next lookahead
                            lookahead = tok
                            errtoken = None
                            continue
                    else:
                        if errtoken:
                            if hasattr(errtoken,"lineno"): lineno = lookahead.lineno
                            else: lineno = 0
                            if lineno:
                                sys.stderr.write("yacc: Syntax error at line %d, token=%s\n" % (lineno, errtoken.type))
                            else:
                                sys.stderr.write("yacc: Syntax error, token=%s" % errtoken.type)
                        else:
                            sys.stderr.write("yacc: Parse error in input. EOF\n")
                            return

                else:
                    errorcount = error_count

                # case 1:  the statestack only has 1 entry on it.  If we're in this state, the
                # entire parse has been rolled back and we're completely hosed.   The token is
                # discarded and we just keep going.

                if len(statestack) <= 1 and lookahead.type != '$end':
                    lookahead = None
                    errtoken = None
                    state = 0
                    # Nuke the pushback stack
                    del lookaheadstack[:]
                    continue

                # case 2: the statestack has a couple of entries on it, but we're
                # at the end of the file. nuke the top entry and generate an error token

                # Start nuking entries on the stack
                if lookahead.type == '$end':
                    # Whoa. We're really hosed here. Bail out
                    return

                if lookahead.type != 'error':
                    sym = symstack[-1]
                    if sym.type == 'error':
                        # Hmmm. Error is on top of stack, we'll just nuke input
                        # symbol and continue
                        lookahead = None
                        continue
                    t = YaccSymbol()
                    t.type = 'error'
                    if hasattr(lookahead,"lineno"):
                        t.lineno = lookahead.lineno
                    t.value = lookahead
                    lookaheadstack.append(lookahead)
                    lookahead = t
                else:
                    symstack.pop()
                    statestack.pop()
                    state = statestack[-1]       # Potential bug fix

                continue

            # Call an error function here
            raise RuntimeError("yacc: internal parser error!!!\n")

    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    # parseopt_notrack().
    #
    # Optimized version of parseopt() with line number tracking removed. 
    # DO NOT EDIT THIS CODE DIRECTLY. Copy the optimized version and remove
    # code in the #--! TRACKING sections
    # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

    def parseopt_notrack(self,input=None,lexer=None,debug=0,tracking=0,tokenfunc=None):
        lookahead = None                 # Current lookahead symbol
        lookaheadstack = [ ]             # Stack of lookahead symbols
        actions = self.action            # Local reference to action table (to avoid lookup on self.)
        goto    = self.goto              # Local reference to goto table (to avoid lookup on self.)
        prod    = self.productions       # Local reference to production list (to avoid lookup on self.)
        pslice  = YaccProduction(None)   # Production object passed to grammar rules
        errorcount = 0                   # Used during error recovery 

        # If no lexer was given, we will try to use the lex module
        if not lexer:
            lex = load_ply_lex()
            lexer = lex.lexer
        
        # Set up the lexer and parser objects on pslice
        pslice.lexer = lexer
        pslice.parser = self

        # If input was supplied, pass to lexer
        if input is not None:
            lexer.input(input)

        if tokenfunc is None:
           # Tokenize function
           get_token = lexer.token
        else:
           get_token = tokenfunc

        # Set up the state and symbol stacks

        statestack = [ ]                # Stack of parsing states
        self.statestack = statestack
        symstack   = [ ]                # Stack of grammar symbols
        self.symstack = symstack

        pslice.stack = symstack         # Put in the production
        errtoken   = None               # Err token

        # The start state is assumed to be (0,$end)

        statestack.append(0)
        sym = YaccSymbol()
        sym.type = '$end'
        symstack.append(sym)
        state = 0
        while 1:
            # Get the next symbol on the input.  If a lookahead symbol
            # is already set, we just use that. Otherwise, we'll pull
            # the next token off of the lookaheadstack or from the lexer

            if not lookahead:
                if not lookaheadstack:
                    lookahead = get_token()     # Get the next token
                else:
                    lookahead = lookaheadstack.pop()
                if not lookahead:
                    lookahead = YaccSymbol()
                    lookahead.type = '$end'

            # Check the action table
            ltype = lookahead.type
            t = actions[state].get(ltype)

            if t is not None:
                if t > 0:
                    # shift a symbol on the stack
                    statestack.append(t)
                    state = t

                    symstack.append(lookahead)
                    lookahead = None

                    # Decrease error count on successful shift
                    if errorcount: errorcount -=1
                    continue

                if t < 0:
                    # reduce a symbol on the stack, emit a production
                    p = prod[-t]
                    pname = p.name
                    plen  = p.len

                    # Get production function
                    sym = YaccSymbol()
                    sym.type = pname       # Production name
                    sym.value = None

                    if plen:
                        targ = symstack[-plen-1:]
                        targ[0] = sym

                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                        # The code enclosed in this section is duplicated 
                        # below as a performance optimization.  Make sure
                        # changes get made in both locations.

                        pslice.slice = targ
                        
                        try:
                            # Call the grammar rule with our special slice object
                            del symstack[-plen:]
                            del statestack[-plen:]
                            p.callable(pslice)
                            symstack.append(sym)
                            state = goto[statestack[-1]][pname]
                            statestack.append(state)
                        except SyntaxError:
                            # If an error was set. Enter error recovery state
                            lookaheadstack.append(lookahead)
                            symstack.pop()
                            statestack.pop()
                            state = statestack[-1]
                            sym.type = 'error'
                            lookahead = sym
                            errorcount = error_count
                            self.errorok = 0
                        continue
                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    
                    else:

                        targ = [ sym ]

                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                        # The code enclosed in this section is duplicated 
                        # above as a performance optimization.  Make sure
                        # changes get made in both locations.

                        pslice.slice = targ

                        try:
                            # Call the grammar rule with our special slice object
                            p.callable(pslice)
                            symstack.append(sym)
                            state = goto[statestack[-1]][pname]
                            statestack.append(state)
                        except SyntaxError:
                            # If an error was set. Enter error recovery state
                            lookaheadstack.append(lookahead)
                            symstack.pop()
                            statestack.pop()
                            state = statestack[-1]
                            sym.type = 'error'
                            lookahead = sym
                            errorcount = error_count
                            self.errorok = 0
                        continue
                        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                if t == 0:
                    n = symstack[-1]
                    return getattr(n,"value",None)

            if t == None:

                # We have some kind of parsing error here.  To handle
                # this, we are going to push the current token onto
                # the tokenstack and replace it with an 'error' token.
                # If there are any synchronization rules, they may
                # catch it.
                #
                # In addition to pushing the error token, we call call
                # the user defined p_error() function if this is the
                # first syntax error.  This function is only called if
                # errorcount == 0.
                if errorcount == 0 or self.errorok:
                    errorcount = error_count
                    self.errorok = 0
                    errtoken = lookahead
                    if errtoken.type == '$end':
                        errtoken = None               # End of file!
                    if self.errorfunc:
                        global errok,token,restart
                        errok = self.errok        # Set some special functions available in error recovery
                        token = get_token
                        restart = self.restart
                        if errtoken and not hasattr(errtoken,'lexer'):
                            errtoken.lexer = lexer
                        tok = self.errorfunc(errtoken)
                        del errok, token, restart   # Delete special functions

                        if self.errorok:
                            # User must have done some kind of panic
                            # mode recovery on their own.  The
                            # returned token is the next lookahead
                            lookahead = tok
                            errtoken = None
                            continue
                    else:
                        if errtoken:
                            if hasattr(errtoken,"lineno"): lineno = lookahead.lineno
                            else: lineno = 0
                            if lineno:
                                sys.stderr.write("yacc: Syntax error at line %d, token=%s\n" % (lineno, errtoken.type))
                            else:
                                sys.stderr.write("yacc: Syntax error, token=%s" % errtoken.type)
                        else:
                            sys.stderr.write("yacc: Parse error in input. EOF\n")
                            return

                else:
                    errorcount = error_count

                # case 1:  the statestack only has 1 entry on it.  If we're in this state, the
                # entire parse has been rolled back and we're completely hosed.   The token is
                # discarded and we just keep going.

                if len(statestack) <= 1 and lookahead.type != '$end':
                    lookahead = None
                    errtoken = None
                    state = 0
                    # Nuke the pushback stack
                    del lookaheadstack[:]
                    continue

                # case 2: the statestack has a couple of entries on it, but we're
                # at the end of the file. nuke the top entry and generate an error token

                # Start nuking entries on the stack
                if lookahead.type == '$end':
                    # Whoa. We're really hosed here. Bail out
                    return

                if lookahead.type != 'error':
                    sym = symstack[-1]
                    if sym.type == 'error':
                        # Hmmm. Error is on top of stack, we'll just nuke input
                        # symbol and continue
                        lookahead = None
                        continue
                    t = YaccSymbol()
                    t.type = 'error'
                    if hasattr(lookahead,"lineno"):
                        t.lineno = lookahead.lineno
                    t.value = lookahead
                    lookaheadstack.append(lookahead)
                    lookahead = t
                else:
                    symstack.pop()
                    statestack.pop()
                    state = statestack[-1]       # Potential bug fix

                continue

            # Call an error function here
            raise RuntimeError("yacc: internal parser error!!!\n")

# -----------------------------------------------------------------------------
#                          === Grammar Representation ===
#
# The following functions, classes, and variables are used to represent and
# manipulate the rules that make up a grammar. 
# -----------------------------------------------------------------------------

import re

# regex matching identifiers
_is_identifier = re.compile(r'^[a-zA-Z0-9_-]+$')

# -----------------------------------------------------------------------------
# class Production:
#
# This class stores the raw information about a single production or grammar rule.
# A grammar rule refers to a specification such as this:
#
#       expr : expr PLUS term 
#
# Here are the basic attributes defined on all productions
#
#       name     - Name of the production.  For example 'expr'
#       prod     - A list of symbols on the right side ['expr','PLUS','term']
#       prec     - Production precedence level
#       number   - Production number.
#       func     - Function that executes on reduce
#       file     - File where production function is defined
#       lineno   - Line number where production function is defined
#
# The following attributes are defined or optional.
#
#       len       - Length of the production (number of symbols on right hand side)
#       usyms     - Set of unique symbols found in the production
# -----------------------------------------------------------------------------

class Production(object):
    reduced = 0
    def __init__(self,number,name,prod,precedence=('right',0),func=None,file='',line=0):
        self.name     = name
        self.prod     = tuple(prod)
        self.number   = number
        self.func     = func
        self.callable = None
        self.file     = file
        self.line     = line
        self.prec     = precedence

        # Internal settings used during table construction
        
        self.len  = len(self.prod)   # Length of the production

        # Create a list of unique production symbols used in the production
        self.usyms = [ ]             
        for s in self.prod:
            if s not in self.usyms:
                self.usyms.append(s)

        # List of all LR items for the production
        self.lr_items = []
        self.lr_next = None

        # Create a string representation
        if self.prod:
            self.str = "%s -> %s" % (self.name," ".join(self.prod))
        else:
            self.str = "%s -> <empty>" % self.name

    def __str__(self):
        return self.str

    def __repr__(self):
        return "Production("+str(self)+")"

    def __len__(self):
        return len(self.prod)

    def __nonzero__(self):
        return 1

    def __getitem__(self,index):
        return self.prod[index]
            
    # Return the nth lr_item from the production (or None if at the end)
    def lr_item(self,n):
        if n > len(self.prod): return None
        p = LRItem(self,n)

        # Precompute the list of productions immediately following.  Hack. Remove later
        try:
            p.lr_after = Prodnames[p.prod[n+1]]
        except (IndexError,KeyError):
            p.lr_after = []
        try:
            p.lr_before = p.prod[n-1]
        except IndexError:
            p.lr_before = None

        return p
    
    # Bind the production function name to a callable
    def bind(self,pdict):
        if self.func:
            self.callable = pdict[self.func]

# This class serves as a minimal standin for Production objects when
# reading table data from files.   It only contains information
# actually used by the LR parsing engine, plus some additional
# debugging information.
class MiniProduction(object):
    def __init__(self,str,name,len,func,file,line):
        self.name     = name
        self.len      = len
        self.func     = func
        self.callable = None
        self.file     = file
        self.line     = line
        self.str      = str
    def __str__(self):
        return self.str
    def __repr__(self):
        return "MiniProduction(%s)" % self.str

    # Bind the production function name to a callable
    def bind(self,pdict):
        if self.func:
            self.callable = pdict[self.func]


# -----------------------------------------------------------------------------
# class LRItem
#
# This class represents a specific stage of parsing a production rule.  For
# example: 
#
#       expr : expr . PLUS term 
#
# In the above, the "." represents the current location of the parse.  Here
# basic attributes:
#
#       name       - Name of the production.  For example 'expr'
#       prod       - A list of symbols on the right side ['expr','.', 'PLUS','term']
#       number     - Production number.
#
#       lr_next      Next LR item. Example, if we are ' expr -> expr . PLUS term'
#                    then lr_next refers to 'expr -> expr PLUS . term'
#       lr_index   - LR item index (location of the ".") in the prod list.
#       lookaheads - LALR lookahead symbols for this item
#       len        - Length of the production (number of symbols on right hand side)
#       lr_after    - List of all productions that immediately follow
#       lr_before   - Grammar symbol immediately before
# -----------------------------------------------------------------------------

class LRItem(object):
    def __init__(self,p,n):
        self.name       = p.name
        self.prod       = list(p.prod)
        self.number     = p.number
        self.lr_index   = n
        self.lookaheads = { }
        self.prod.insert(n,".")
        self.prod       = tuple(self.prod)
        self.len        = len(self.prod)
        self.usyms      = p.usyms

    def __str__(self):
        if self.prod:
            s = "%s -> %s" % (self.name," ".join(self.prod))
        else:
            s = "%s -> <empty>" % self.name
        return s

    def __repr__(self):
        return "LRItem("+str(self)+")"

# -----------------------------------------------------------------------------
# rightmost_terminal()
#
# Return the rightmost terminal from a list of symbols.  Used in add_production()
# -----------------------------------------------------------------------------
def rightmost_terminal(symbols, terminals):
    i = len(symbols) - 1
    while i >= 0:
        if symbols[i] in terminals:
            return symbols[i]
        i -= 1
    return None

# -----------------------------------------------------------------------------
#                           === GRAMMAR CLASS ===
#
# The following class represents the contents of the specified grammar along
# with various computed properties such as first sets, follow sets, LR items, etc.
# This data is used for critical parts of the table generation process later.
# -----------------------------------------------------------------------------

class GrammarError(YaccError): pass

class Grammar(object):
    def __init__(self,terminals):
        self.Productions  = [None]  # A list of all of the productions.  The first
                                    # entry is always reserved for the purpose of
                                    # building an augmented grammar

        self.Prodnames    = { }     # A dictionary mapping the names of nonterminals to a list of all
                                    # productions of that nonterminal.

        self.Prodmap      = { }     # A dictionary that is only used to detect duplicate
                                    # productions.

        self.Terminals    = { }     # A dictionary mapping the names of terminal symbols to a
                                    # list of the rules where they are used.

        for term in terminals:
            self.Terminals[term] = []

        self.Terminals['error'] = []

        self.Nonterminals = { }     # A dictionary mapping names of nonterminals to a list
                                    # of rule numbers where they are used.

        self.First        = { }     # A dictionary of precomputed FIRST(x) symbols

        self.Follow       = { }     # A dictionary of precomputed FOLLOW(x) symbols

        self.Precedence   = { }     # Precedence rules for each terminal. Contains tuples of the
                                    # form ('right',level) or ('nonassoc', level) or ('left',level)

        self.UsedPrecedence = { }   # Precedence rules that were actually used by the grammer.
                                    # This is only used to provide error checking and to generate
                                    # a warning about unused precedence rules.

        self.Start = None           # Starting symbol for the grammar


    def __len__(self):
        return len(self.Productions)

    def __getitem__(self,index):
        return self.Productions[index]

    # -----------------------------------------------------------------------------
    # set_precedence()
    #
    # Sets the precedence for a given terminal. assoc is the associativity such as
    # 'left','right', or 'nonassoc'.  level is a numeric level.
    #
    # -----------------------------------------------------------------------------

    def set_precedence(self,term,assoc,level):
        assert self.Productions == [None],"Must call set_precedence() before add_production()"
        if term in self.Precedence:
            raise GrammarError("Precedence already specified for terminal '%s'" % term)
        if assoc not in ['left','right','nonassoc']:
            raise GrammarError("Associativity must be one of 'left','right', or 'nonassoc'")
        self.Precedence[term] = (assoc,level)
 
    # -----------------------------------------------------------------------------
    # add_production()
    #
    # Given an action function, this function assembles a production rule and
    # computes its precedence level.
    #
    # The production rule is supplied as a list of symbols.   For example,
    # a rule such as 'expr : expr PLUS term' has a production name of 'expr' and
    # symbols ['expr','PLUS','term'].
    #
    # Precedence is determined by the precedence of the right-most non-terminal
    # or the precedence of a terminal specified by %prec.
    #
    # A variety of error checks are performed to make sure production symbols
    # are valid and that %prec is used correctly.
    # -----------------------------------------------------------------------------

    def add_production(self,prodname,syms,func=None,file='',line=0):

        if prodname in self.Terminals:
            raise GrammarError("%s:%d: Illegal rule name '%s'. Already defined as a token" % (file,line,prodname))
        if prodname == 'error':
            raise GrammarError("%s:%d: Illegal rule name '%s'. error is a reserved word" % (file,line,prodname))
        if not _is_identifier.match(prodname):
            raise GrammarError("%s:%d: Illegal rule name '%s'" % (file,line,prodname))

        # Look for literal tokens 
        for n,s in enumerate(syms):
            if s[0] in "'\"":
                 try:
                     c = eval(s)
                     if (len(c) > 1):
                          raise GrammarError("%s:%d: Literal token %s in rule '%s' may only be a single character" % (file,line,s, prodname))
                     if not c in self.Terminals:
                          self.Terminals[c] = []
                     syms[n] = c
                     continue
                 except SyntaxError:
                     pass
            if not _is_identifier.match(s) and s != '%prec':
                raise GrammarError("%s:%d: Illegal name '%s' in rule '%s'" % (file,line,s, prodname))
        
        # Determine the precedence level
        if '%prec' in syms:
            if syms[-1] == '%prec':
                raise GrammarError("%s:%d: Syntax error. Nothing follows %%prec" % (file,line))
            if syms[-2] != '%prec':
                raise GrammarError("%s:%d: Syntax error. %%prec can only appear at the end of a grammar rule" % (file,line))
            precname = syms[-1]
            prodprec = self.Precedence.get(precname,None)
            if not prodprec:
                raise GrammarError("%s:%d: Nothing known about the precedence of '%s'" % (file,line,precname))
            else:
                self.UsedPrecedence[precname] = 1
            del syms[-2:]     # Drop %prec from the rule
        else:
            # If no %prec, precedence is determined by the rightmost terminal symbol
            precname = rightmost_terminal(syms,self.Terminals)
            prodprec = self.Precedence.get(precname,('right',0)) 
            
        # See if the rule is already in the rulemap
        map = "%s -> %s" % (prodname,syms)
        if map in self.Prodmap:
            m = self.Prodmap[map]
            raise GrammarError("%s:%d: Duplicate rule %s. " % (file,line, m) +
                               "Previous definition at %s:%d" % (m.file, m.line))

        # From this point on, everything is valid.  Create a new Production instance
        pnumber  = len(self.Productions)
        if not prodname in self.Nonterminals:
            self.Nonterminals[prodname] = [ ]

        # Add the production number to Terminals and Nonterminals
        for t in syms:
            if t in self.Terminals:
                self.Terminals[t].append(pnumber)
            else:
                if not t in self.Nonterminals:
                    self.Nonterminals[t] = [ ]
                self.Nonterminals[t].append(pnumber)

        # Create a production and add it to the list of productions
        p = Production(pnumber,prodname,syms,prodprec,func,file,line)
        self.Productions.append(p)
        self.Prodmap[map] = p

        # Add to the global productions list
        try:
            self.Prodnames[prodname].append(p)
        except KeyError:
            self.Prodnames[prodname] = [ p ]
        return 0

    # -----------------------------------------------------------------------------
    # set_start()
    #
    # Sets the starting symbol and creates the augmented grammar.  Production 
    # rule 0 is S' -> start where start is the start symbol.
    # -----------------------------------------------------------------------------

    def set_start(self,start=None):
        if not start:
            start = self.Productions[1].name
        if start not in self.Nonterminals:
            raise GrammarError("start symbol %s undefined" % start)
        self.Productions[0] = Production(0,"S'",[start])
        self.Nonterminals[start].append(0)
        self.Start = start

    # -----------------------------------------------------------------------------
    # find_unreachable()
    #
    # Find all of the nonterminal symbols that can't be reached from the starting
    # symbol.  Returns a list of nonterminals that can't be reached.
    # -----------------------------------------------------------------------------

    def find_unreachable(self):
        
        # Mark all symbols that are reachable from a symbol s
        def mark_reachable_from(s):
            if reachable[s]:
                # We've already reached symbol s.
                return
            reachable[s] = 1
            for p in self.Prodnames.get(s,[]):
                for r in p.prod:
                    mark_reachable_from(r)

        reachable   = { }
        for s in list(self.Terminals) + list(self.Nonterminals):
            reachable[s] = 0

        mark_reachable_from( self.Productions[0].prod[0] )

        return [s for s in list(self.Nonterminals)
                        if not reachable[s]]
    
    # -----------------------------------------------------------------------------
    # infinite_cycles()
    #
    # This function looks at the various parsing rules and tries to detect
    # infinite recursion cycles (grammar rules where there is no possible way
    # to derive a string of only terminals).
    # -----------------------------------------------------------------------------

    def infinite_cycles(self):
        terminates = {}

        # Terminals:
        for t in self.Terminals:
            terminates[t] = 1

        terminates['$end'] = 1

        # Nonterminals:

        # Initialize to false:
        for n in self.Nonterminals:
            terminates[n] = 0

        # Then propagate termination until no change:
        while 1:
            some_change = 0
            for (n,pl) in self.Prodnames.items():
                # Nonterminal n terminates iff any of its productions terminates.
                for p in pl:
                    # Production p terminates iff all of its rhs symbols terminate.
                    for s in p.prod:
                        if not terminates[s]:
                            # The symbol s does not terminate,
                            # so production p does not terminate.
                            p_terminates = 0
                            break
                    else:
                        # didn't break from the loop,
                        # so every symbol s terminates
                        # so production p terminates.
                        p_terminates = 1

                    if p_terminates:
                        # symbol n terminates!
                        if not terminates[n]:
                            terminates[n] = 1
                            some_change = 1
                        # Don't need to consider any more productions for this n.
                        break

            if not some_change:
                break

        infinite = []
        for (s,term) in terminates.items():
            if not term:
                if not s in self.Prodnames and not s in self.Terminals and s != 'error':
                    # s is used-but-not-defined, and we've already warned of that,
                    # so it would be overkill to say that it's also non-terminating.
                    pass
                else:
                    infinite.append(s)

        return infinite


    # -----------------------------------------------------------------------------
    # undefined_symbols()
    #
    # Find all symbols that were used the grammar, but not defined as tokens or
    # grammar rules.  Returns a list of tuples (sym, prod) where sym in the symbol
    # and prod is the production where the symbol was used. 
    # -----------------------------------------------------------------------------
    def undefined_symbols(self):
        result = []
        for p in self.Productions:
            if not p: continue

            for s in p.prod:
                if not s in self.Prodnames and not s in self.Terminals and s != 'error':
                    result.append((s,p))
        return result

    # -----------------------------------------------------------------------------
    # unused_terminals()
    #
    # Find all terminals that were defined, but not used by the grammar.  Returns
    # a list of all symbols.
    # -----------------------------------------------------------------------------
    def unused_terminals(self):
        unused_tok = []
        for s,v in self.Terminals.items():
            if s != 'error' and not v:
                unused_tok.append(s)

        return unused_tok

    # ------------------------------------------------------------------------------
    # unused_rules()
    #
    # Find all grammar rules that were defined,  but not used (maybe not reachable)
    # Returns a list of productions.
    # ------------------------------------------------------------------------------

    def unused_rules(self):
        unused_prod = []
        for s,v in self.Nonterminals.items():
            if not v:
                p = self.Prodnames[s][0]
                unused_prod.append(p)
        return unused_prod

    # -----------------------------------------------------------------------------
    # unused_precedence()
    #
    # Returns a list of tuples (term,precedence) corresponding to precedence
    # rules that were never used by the grammar.  term is the name of the terminal
    # on which precedence was applied and precedence is a string such as 'left' or
    # 'right' corresponding to the type of precedence. 
    # -----------------------------------------------------------------------------

    def unused_precedence(self):
        unused = []
        for termname in self.Precedence:
            if not (termname in self.Terminals or termname in self.UsedPrecedence):
                unused.append((termname,self.Precedence[termname][0]))
                
        return unused

    # -------------------------------------------------------------------------
    # _first()
    #
    # Compute the value of FIRST1(beta) where beta is a tuple of symbols.
    #
    # During execution of compute_first1, the result may be incomplete.
    # Afterward (e.g., when called from compute_follow()), it will be complete.
    # -------------------------------------------------------------------------
    def _first(self,beta):

        # We are computing First(x1,x2,x3,...,xn)
        result = [ ]
        for x in beta:
            x_produces_empty = 0

            # Add all the non-<empty> symbols of First[x] to the result.
            for f in self.First[x]:
                if f == '<empty>':
                    x_produces_empty = 1
                else:
                    if f not in result: result.append(f)

            if x_produces_empty:
                # We have to consider the next x in beta,
                # i.e. stay in the loop.
                pass
            else:
                # We don't have to consider any further symbols in beta.
                break
        else:
            # There was no 'break' from the loop,
            # so x_produces_empty was true for all x in beta,
            # so beta produces empty as well.
            result.append('<empty>')

        return result

    # -------------------------------------------------------------------------
    # compute_first()
    #
    # Compute the value of FIRST1(X) for all symbols
    # -------------------------------------------------------------------------
    def compute_first(self):
        if self.First:
            return self.First

        # Terminals:
        for t in self.Terminals:
            self.First[t] = [t]

        self.First['$end'] = ['$end']

        # Nonterminals:

        # Initialize to the empty set:
        for n in self.Nonterminals:
            self.First[n] = []

        # Then propagate symbols until no change:
        while 1:
            some_change = 0
            for n in self.Nonterminals:
                for p in self.Prodnames[n]:
                    for f in self._first(p.prod):
                        if f not in self.First[n]:
                            self.First[n].append( f )
                            some_change = 1
            if not some_change:
                break
        
        return self.First

    # ---------------------------------------------------------------------
    # compute_follow()
    #
    # Computes all of the follow sets for every non-terminal symbol.  The
    # follow set is the set of all symbols that might follow a given
    # non-terminal.  See the Dragon book, 2nd Ed. p. 189.
    # ---------------------------------------------------------------------
    def compute_follow(self,start=None):
        # If already computed, return the result
        if self.Follow:
            return self.Follow

        # If first sets not computed yet, do that first.
        if not self.First:
            self.compute_first()

        # Add '$end' to the follow list of the start symbol
        for k in self.Nonterminals:
            self.Follow[k] = [ ]

        if not start:
            start = self.Productions[1].name

        self.Follow[start] = [ '$end' ]

        while 1:
            didadd = 0
            for p in self.Productions[1:]:
                # Here is the production set
                for i in range(len(p.prod)):
                    B = p.prod[i]
                    if B in self.Nonterminals:
                        # Okay. We got a non-terminal in a production
                        fst = self._first(p.prod[i+1:])
                        hasempty = 0
                        for f in fst:
                            if f != '<empty>' and f not in self.Follow[B]:
                                self.Follow[B].append(f)
                                didadd = 1
                            if f == '<empty>':
                                hasempty = 1
                        if hasempty or i == (len(p.prod)-1):
                            # Add elements of follow(a) to follow(b)
                            for f in self.Follow[p.name]:
                                if f not in self.Follow[B]:
                                    self.Follow[B].append(f)
                                    didadd = 1
            if not didadd: break
        return self.Follow


    # -----------------------------------------------------------------------------
    # build_lritems()
    #
    # This function walks the list of productions and builds a complete set of the
    # LR items.  The LR items are stored in two ways:  First, they are uniquely
    # numbered and placed in the list _lritems.  Second, a linked list of LR items
    # is built for each production.  For example:
    #
    #   E -> E PLUS E
    #
    # Creates the list
    #
    #  [E -> . E PLUS E, E -> E . PLUS E, E -> E PLUS . E, E -> E PLUS E . ]
    # -----------------------------------------------------------------------------

    def build_lritems(self):
        for p in self.Productions:
            lastlri = p
            i = 0
            lr_items = []
            while 1:
                if i > len(p):
                    lri = None
                else:
                    lri = LRItem(p,i)
                    # Precompute the list of productions immediately following
                    try:
                        lri.lr_after = self.Prodnames[lri.prod[i+1]]
                    except (IndexError,KeyError):
                        lri.lr_after = []
                    try:
                        lri.lr_before = lri.prod[i-1]
                    except IndexError:
                        lri.lr_before = None

                lastlri.lr_next = lri
                if not lri: break
                lr_items.append(lri)
                lastlri = lri
                i += 1
            p.lr_items = lr_items

# -----------------------------------------------------------------------------
#                            == Class LRTable ==
#
# This basic class represents a basic table of LR parsing information.  
# Methods for generating the tables are not defined here.  They are defined
# in the derived class LRGeneratedTable.
# -----------------------------------------------------------------------------

class VersionError(YaccError): pass

class LRTable(object):
    def __init__(self):
        self.lr_action = None
        self.lr_goto = None
        self.lr_productions = None
        self.lr_method = None

    def read_table(self,module):
        if isinstance(module,types.ModuleType):
            parsetab = module
        else:
            if sys.version_info[0] < 3:
                exec("import %s as parsetab" % module)
            else:
                env = { }
                exec("import %s as parsetab" % module, env, env)
                parsetab = env['parsetab']

        if parsetab._tabversion != __tabversion__:
            raise VersionError("yacc table file version is out of date")

        self.lr_action = parsetab._lr_action
        self.lr_goto = parsetab._lr_goto

        self.lr_productions = []
        for p in parsetab._lr_productions:
            self.lr_productions.append(MiniProduction(*p))

        self.lr_method = parsetab._lr_method
        return parsetab._lr_signature

    def read_pickle(self,filename):
        try:
            import cPickle as pickle
        except ImportError:
            import pickle

        in_f = open(filename,"rb")

        tabversion = pickle.load(in_f)
        if tabversion != __tabversion__:
            raise VersionError("yacc table file version is out of date")
        self.lr_method = pickle.load(in_f)
        signature      = pickle.load(in_f)
        self.lr_action = pickle.load(in_f)
        self.lr_goto   = pickle.load(in_f)
        productions    = pickle.load(in_f)

        self.lr_productions = []
        for p in productions:
            self.lr_productions.append(MiniProduction(*p))

        in_f.close()
        return signature

    # Bind all production function names to callable objects in pdict
    def bind_callables(self,pdict):
        for p in self.lr_productions:
            p.bind(pdict)
    
# -----------------------------------------------------------------------------
#                           === LR Generator ===
#
# The following classes and functions are used to generate LR parsing tables on 
# a grammar.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# digraph()
# traverse()
#
# The following two functions are used to compute set valued functions
# of the form:
#
#     F(x) = F'(x) U U{F(y) | x R y}
#
# This is used to compute the values of Read() sets as well as FOLLOW sets
# in LALR(1) generation.
#
# Inputs:  X    - An input set
#          R    - A relation
#          FP   - Set-valued function
# ------------------------------------------------------------------------------

def digraph(X,R,FP):
    N = { }
    for x in X:
       N[x] = 0
    stack = []
    F = { }
    for x in X:
        if N[x] == 0: traverse(x,N,stack,F,X,R,FP)
    return F

def traverse(x,N,stack,F,X,R,FP):
    stack.append(x)
    d = len(stack)
    N[x] = d
    F[x] = FP(x)             # F(X) <- F'(x)

    rel = R(x)               # Get y's related to x
    for y in rel:
        if N[y] == 0:
             traverse(y,N,stack,F,X,R,FP)
        N[x] = min(N[x],N[y])
        for a in F.get(y,[]):
            if a not in F[x]: F[x].append(a)
    if N[x] == d:
       N[stack[-1]] = MAXINT
       F[stack[-1]] = F[x]
       element = stack.pop()
       while element != x:
           N[stack[-1]] = MAXINT
           F[stack[-1]] = F[x]
           element = stack.pop()

class LALRError(YaccError): pass

# -----------------------------------------------------------------------------
#                             == LRGeneratedTable ==
#
# This class implements the LR table generation algorithm.  There are no
# public methods except for write()
# -----------------------------------------------------------------------------

class LRGeneratedTable(LRTable):
    def __init__(self,grammar,method='LALR',log=None):
        if method not in ['SLR','LALR']:
            raise LALRError("Unsupported method %s" % method)

        self.grammar = grammar
        self.lr_method = method

        # Set up the logger
        if not log:
            log = NullLogger()
        self.log = log

        # Internal attributes
        self.lr_action     = {}        # Action table
        self.lr_goto       = {}        # Goto table
        self.lr_productions  = grammar.Productions    # Copy of grammar Production array
        self.lr_goto_cache = {}        # Cache of computed gotos
        self.lr0_cidhash   = {}        # Cache of closures

        self._add_count    = 0         # Internal counter used to detect cycles

        # Diagonistic information filled in by the table generator
        self.sr_conflict   = 0
        self.rr_conflict   = 0
        self.conflicts     = []        # List of conflicts

        self.sr_conflicts  = []
        self.rr_conflicts  = []

        # Build the tables
        self.grammar.build_lritems()
        self.grammar.compute_first()
        self.grammar.compute_follow()
        self.lr_parse_table()

    # Compute the LR(0) closure operation on I, where I is a set of LR(0) items.

    def lr0_closure(self,I):
        self._add_count += 1

        # Add everything in I to J
        J = I[:]
        didadd = 1
        while didadd:
            didadd = 0
            for j in J:
                for x in j.lr_after:
                    if getattr(x,"lr0_added",0) == self._add_count: continue
                    # Add B --> .G to J
                    J.append(x.lr_next)
                    x.lr0_added = self._add_count
                    didadd = 1

        return J

    # Compute the LR(0) goto function goto(I,X) where I is a set
    # of LR(0) items and X is a grammar symbol.   This function is written
    # in a way that guarantees uniqueness of the generated goto sets
    # (i.e. the same goto set will never be returned as two different Python
    # objects).  With uniqueness, we can later do fast set comparisons using
    # id(obj) instead of element-wise comparison.

    def lr0_goto(self,I,x):
        # First we look for a previously cached entry
        g = self.lr_goto_cache.get((id(I),x),None)
        if g: return g

        # Now we generate the goto set in a way that guarantees uniqueness
        # of the result

        s = self.lr_goto_cache.get(x,None)
        if not s:
            s = { }
            self.lr_goto_cache[x] = s

        gs = [ ]
        for p in I:
            n = p.lr_next
            if n and n.lr_before == x:
                s1 = s.get(id(n),None)
                if not s1:
                    s1 = { }
                    s[id(n)] = s1
                gs.append(n)
                s = s1
        g = s.get('$end',None)
        if not g:
            if gs:
                g = self.lr0_closure(gs)
                s['$end'] = g
            else:
                s['$end'] = gs
        self.lr_goto_cache[(id(I),x)] = g
        return g

    # Compute the LR(0) sets of item function
    def lr0_items(self):

        C = [ self.lr0_closure([self.grammar.Productions[0].lr_next]) ]
        i = 0
        for I in C:
            self.lr0_cidhash[id(I)] = i
            i += 1

        # Loop over the items in C and each grammar symbols
        i = 0
        while i < len(C):
            I = C[i]
            i += 1

            # Collect all of the symbols that could possibly be in the goto(I,X) sets
            asyms = { }
            for ii in I:
                for s in ii.usyms:
                    asyms[s] = None

            for x in asyms:
                g = self.lr0_goto(I,x)
                if not g:  continue
                if id(g) in self.lr0_cidhash: continue
                self.lr0_cidhash[id(g)] = len(C)
                C.append(g)

        return C

    # -----------------------------------------------------------------------------
    #                       ==== LALR(1) Parsing ====
    #
    # LALR(1) parsing is almost exactly the same as SLR except that instead of
    # relying upon Follow() sets when performing reductions, a more selective
    # lookahead set that incorporates the state of the LR(0) machine is utilized.
    # Thus, we mainly just have to focus on calculating the lookahead sets.
    #
    # The method used here is due to DeRemer and Pennelo (1982).
    #
    # DeRemer, F. L., and T. J. Pennelo: "Efficient Computation of LALR(1)
    #     Lookahead Sets", ACM Transactions on Programming Languages and Systems,
    #     Vol. 4, No. 4, Oct. 1982, pp. 615-649
    #
    # Further details can also be found in:
    #
    #  J. Tremblay and P. Sorenson, "The Theory and Practice of Compiler Writing",
    #      McGraw-Hill Book Company, (1985).
    #
    # -----------------------------------------------------------------------------

    # -----------------------------------------------------------------------------
    # compute_nullable_nonterminals()
    #
    # Creates a dictionary containing all of the non-terminals that might produce
    # an empty production.
    # -----------------------------------------------------------------------------

    def compute_nullable_nonterminals(self):
        nullable = {}
        num_nullable = 0
        while 1:
           for p in self.grammar.Productions[1:]:
               if p.len == 0:
                    nullable[p.name] = 1
                    continue
               for t in p.prod:
                    if not t in nullable: break
               else:
                    nullable[p.name] = 1
           if len(nullable) == num_nullable: break
           num_nullable = len(nullable)
        return nullable

    # -----------------------------------------------------------------------------
    # find_nonterminal_trans(C)
    #
    # Given a set of LR(0) items, this functions finds all of the non-terminal
    # transitions.    These are transitions in which a dot appears immediately before
    # a non-terminal.   Returns a list of tuples of the form (state,N) where state
    # is the state number and N is the nonterminal symbol.
    #
    # The input C is the set of LR(0) items.
    # -----------------------------------------------------------------------------

    def find_nonterminal_transitions(self,C):
         trans = []
         for state in range(len(C)):
             for p in C[state]:
                 if p.lr_index < p.len - 1:
                      t = (state,p.prod[p.lr_index+1])
                      if t[1] in self.grammar.Nonterminals:
                            if t not in trans: trans.append(t)
             state = state + 1
         return trans

    # -----------------------------------------------------------------------------
    # dr_relation()
    #
    # Computes the DR(p,A) relationships for non-terminal transitions.  The input
    # is a tuple (state,N) where state is a number and N is a nonterminal symbol.
    #
    # Returns a list of terminals.
    # -----------------------------------------------------------------------------

    def dr_relation(self,C,trans,nullable):
        dr_set = { }
        state,N = trans
        terms = []

        g = self.lr0_goto(C[state],N)
        for p in g:
           if p.lr_index < p.len - 1:
               a = p.prod[p.lr_index+1]
               if a in self.grammar.Terminals:
                   if a not in terms: terms.append(a)

        # This extra bit is to handle the start state
        if state == 0 and N == self.grammar.Productions[0].prod[0]:
           terms.append('$end')

        return terms

    # -----------------------------------------------------------------------------
    # reads_relation()
    #
    # Computes the READS() relation (p,A) READS (t,C).
    # -----------------------------------------------------------------------------

    def reads_relation(self,C, trans, empty):
        # Look for empty transitions
        rel = []
        state, N = trans

        g = self.lr0_goto(C[state],N)
        j = self.lr0_cidhash.get(id(g),-1)
        for p in g:
            if p.lr_index < p.len - 1:
                 a = p.prod[p.lr_index + 1]
                 if a in empty:
                      rel.append((j,a))

        return rel

    # -----------------------------------------------------------------------------
    # compute_lookback_includes()
    #
    # Determines the lookback and includes relations
    #
    # LOOKBACK:
    #
    # This relation is determined by running the LR(0) state machine forward.
    # For example, starting with a production "N : . A B C", we run it forward
    # to obtain "N : A B C ."   We then build a relationship between this final
    # state and the starting state.   These relationships are stored in a dictionary
    # lookdict.
    #
    # INCLUDES:
    #
    # Computes the INCLUDE() relation (p,A) INCLUDES (p',B).
    #
    # This relation is used to determine non-terminal transitions that occur
    # inside of other non-terminal transition states.   (p,A) INCLUDES (p', B)
    # if the following holds:
    #
    #       B -> LAT, where T -> epsilon and p' -L-> p
    #
    # L is essentially a prefix (which may be empty), T is a suffix that must be
    # able to derive an empty string.  State p' must lead to state p with the string L.
    #
    # -----------------------------------------------------------------------------

    def compute_lookback_includes(self,C,trans,nullable):

        lookdict = {}          # Dictionary of lookback relations
        includedict = {}       # Dictionary of include relations

        # Make a dictionary of non-terminal transitions
        dtrans = {}
        for t in trans:
            dtrans[t] = 1

        # Loop over all transitions and compute lookbacks and includes
        for state,N in trans:
            lookb = []
            includes = []
            for p in C[state]:
                if p.name != N: continue

                # Okay, we have a name match.  We now follow the production all the way
                # through the state machine until we get the . on the right hand side

                lr_index = p.lr_index
                j = state
                while lr_index < p.len - 1:
                     lr_index = lr_index + 1
                     t = p.prod[lr_index]

                     # Check to see if this symbol and state are a non-terminal transition
                     if (j,t) in dtrans:
                           # Yes.  Okay, there is some chance that this is an includes relation
                           # the only way to know for certain is whether the rest of the
                           # production derives empty

                           li = lr_index + 1
                           while li < p.len:
                                if p.prod[li] in self.grammar.Terminals: break      # No forget it
                                if not p.prod[li] in nullable: break
                                li = li + 1
                           else:
                                # Appears to be a relation between (j,t) and (state,N)
                                includes.append((j,t))

                     g = self.lr0_goto(C[j],t)               # Go to next set
                     j = self.lr0_cidhash.get(id(g),-1)     # Go to next state

                # When we get here, j is the final state, now we have to locate the production
                for r in C[j]:
                     if r.name != p.name: continue
                     if r.len != p.len:   continue
                     i = 0
                     # This look is comparing a production ". A B C" with "A B C ."
                     while i < r.lr_index:
                          if r.prod[i] != p.prod[i+1]: break
                          i = i + 1
                     else:
                          lookb.append((j,r))
            for i in includes:
                 if not i in includedict: includedict[i] = []
                 includedict[i].append((state,N))
            lookdict[(state,N)] = lookb

        return lookdict,includedict

    # -----------------------------------------------------------------------------
    # compute_read_sets()
    #
    # Given a set of LR(0) items, this function computes the read sets.
    #
    # Inputs:  C        =  Set of LR(0) items
    #          ntrans   = Set of nonterminal transitions
    #          nullable = Set of empty transitions
    #
    # Returns a set containing the read sets
    # -----------------------------------------------------------------------------

    def compute_read_sets(self,C, ntrans, nullable):
        FP = lambda x: self.dr_relation(C,x,nullable)
        R =  lambda x: self.reads_relation(C,x,nullable)
        F = digraph(ntrans,R,FP)
        return F

    # -----------------------------------------------------------------------------
    # compute_follow_sets()
    #
    # Given a set of LR(0) items, a set of non-terminal transitions, a readset,
    # and an include set, this function computes the follow sets
    #
    # Follow(p,A) = Read(p,A) U U {Follow(p',B) | (p,A) INCLUDES (p',B)}
    #
    # Inputs:
    #            ntrans     = Set of nonterminal transitions
    #            readsets   = Readset (previously computed)
    #            inclsets   = Include sets (previously computed)
    #
    # Returns a set containing the follow sets
    # -----------------------------------------------------------------------------

    def compute_follow_sets(self,ntrans,readsets,inclsets):
         FP = lambda x: readsets[x]
         R  = lambda x: inclsets.get(x,[])
         F = digraph(ntrans,R,FP)
         return F

    # -----------------------------------------------------------------------------
    # add_lookaheads()
    #
    # Attaches the lookahead symbols to grammar rules.
    #
    # Inputs:    lookbacks         -  Set of lookback relations
    #            followset         -  Computed follow set
    #
    # This function directly attaches the lookaheads to productions contained
    # in the lookbacks set
    # -----------------------------------------------------------------------------

    def add_lookaheads(self,lookbacks,followset):
        for trans,lb in lookbacks.items():
            # Loop over productions in lookback
            for state,p in lb:
                 if not state in p.lookaheads:
                      p.lookaheads[state] = []
                 f = followset.get(trans,[])
                 for a in f:
                      if a not in p.lookaheads[state]: p.lookaheads[state].append(a)

    # -----------------------------------------------------------------------------
    # add_lalr_lookaheads()
    #
    # This function does all of the work of adding lookahead information for use
    # with LALR parsing
    # -----------------------------------------------------------------------------

    def add_lalr_lookaheads(self,C):
        # Determine all of the nullable nonterminals
        nullable = self.compute_nullable_nonterminals()

        # Find all non-terminal transitions
        trans = self.find_nonterminal_transitions(C)

        # Compute read sets
        readsets = self.compute_read_sets(C,trans,nullable)

        # Compute lookback/includes relations
        lookd, included = self.compute_lookback_includes(C,trans,nullable)

        # Compute LALR FOLLOW sets
        followsets = self.compute_follow_sets(trans,readsets,included)

        # Add all of the lookaheads
        self.add_lookaheads(lookd,followsets)

    # -----------------------------------------------------------------------------
    # lr_parse_table()
    #
    # This function constructs the parse tables for SLR or LALR
    # -----------------------------------------------------------------------------
    def lr_parse_table(self):
        Productions = self.grammar.Productions
        Precedence  = self.grammar.Precedence
        goto   = self.lr_goto         # Goto array
        action = self.lr_action       # Action array
        log    = self.log             # Logger for output

        actionp = { }                 # Action production array (temporary)
        
        log.info("Parsing method: %s", self.lr_method)

        # Step 1: Construct C = { I0, I1, ... IN}, collection of LR(0) items
        # This determines the number of states

        C = self.lr0_items()

        if self.lr_method == 'LALR':
            self.add_lalr_lookaheads(C)

        # Build the parser table, state by state
        st = 0
        for I in C:
            # Loop over each production in I
            actlist = [ ]              # List of actions
            st_action  = { }
            st_actionp = { }
            st_goto    = { }
            log.info("")
            log.info("state %d", st)
            log.info("")
            for p in I:
                log.info("    (%d) %s", p.number, str(p))
            log.info("")

            for p in I:
                    if p.len == p.lr_index + 1:
                        if p.name == "S'":
                            # Start symbol. Accept!
                            st_action["$end"] = 0
                            st_actionp["$end"] = p
                        else:
                            # We are at the end of a production.  Reduce!
                            if self.lr_method == 'LALR':
                                laheads = p.lookaheads[st]
                            else:
                                laheads = self.grammar.Follow[p.name]
                            for a in laheads:
                                actlist.append((a,p,"reduce using rule %d (%s)" % (p.number,p)))
                                r = st_action.get(a,None)
                                if r is not None:
                                    # Whoa. Have a shift/reduce or reduce/reduce conflict
                                    if r > 0:
                                        # Need to decide on shift or reduce here
                                        # By default we favor shifting. Need to add
                                        # some precedence rules here.
                                        sprec,slevel = Productions[st_actionp[a].number].prec
                                        rprec,rlevel = Precedence.get(a,('right',0))
                                        if (slevel < rlevel) or ((slevel == rlevel) and (rprec == 'left')):
                                            # We really need to reduce here.
                                            st_action[a] = -p.number
                                            st_actionp[a] = p
                                            if not slevel and not rlevel:
                                                log.info("  ! shift/reduce conflict for %s resolved as reduce",a)
                                                self.sr_conflicts.append((st,a,'reduce'))
                                            Productions[p.number].reduced += 1
                                        elif (slevel == rlevel) and (rprec == 'nonassoc'):
                                            st_action[a] = None
                                        else:
                                            # Hmmm. Guess we'll keep the shift
                                            if not rlevel:
                                                log.info("  ! shift/reduce conflict for %s resolved as shift",a)
                                                self.sr_conflicts.append((st,a,'shift'))
                                    elif r < 0:
                                        # Reduce/reduce conflict.   In this case, we favor the rule
                                        # that was defined first in the grammar file
                                        oldp = Productions[-r]
                                        pp = Productions[p.number]
                                        if oldp.line > pp.line:
                                            st_action[a] = -p.number
                                            st_actionp[a] = p
                                            chosenp,rejectp = pp,oldp
                                            Productions[p.number].reduced += 1
                                            Productions[oldp.number].reduced -= 1
                                        else:
                                            chosenp,rejectp = oldp,pp
                                        self.rr_conflicts.append((st,chosenp,rejectp))
                                        log.info("  ! reduce/reduce conflict for %s resolved using rule %d (%s)", a,st_actionp[a].number, st_actionp[a])
                                    else:
                                        raise LALRError("Unknown conflict in state %d" % st)
                                else:
                                    st_action[a] = -p.number
                                    st_actionp[a] = p
                                    Productions[p.number].reduced += 1
                    else:
                        i = p.lr_index
                        a = p.prod[i+1]       # Get symbol right after the "."
                        if a in self.grammar.Terminals:
                            g = self.lr0_goto(I,a)
                            j = self.lr0_cidhash.get(id(g),-1)
                            if j >= 0:
                                # We are in a shift state
                                actlist.append((a,p,"shift and go to state %d" % j))
                                r = st_action.get(a,None)
                                if r is not None:
                                    # Whoa have a shift/reduce or shift/shift conflict
                                    if r > 0:
                                        if r != j:
                                            raise LALRError("Shift/shift conflict in state %d" % st)
                                    elif r < 0:
                                        # Do a precedence check.
                                        #   -  if precedence of reduce rule is higher, we reduce.
                                        #   -  if precedence of reduce is same and left assoc, we reduce.
                                        #   -  otherwise we shift
                                        rprec,rlevel = Productions[st_actionp[a].number].prec
                                        sprec,slevel = Precedence.get(a,('right',0))
                                        if (slevel > rlevel) or ((slevel == rlevel) and (rprec == 'right')):
                                            # We decide to shift here... highest precedence to shift
                                            Productions[st_actionp[a].number].reduced -= 1
                                            st_action[a] = j
                                            st_actionp[a] = p
                                            if not rlevel:
                                                log.info("  ! shift/reduce conflict for %s resolved as shift",a)
                                                self.sr_conflicts.append((st,a,'shift'))
                                        elif (slevel == rlevel) and (rprec == 'nonassoc'):
                                            st_action[a] = None
                                        else:
                                            # Hmmm. Guess we'll keep the reduce
                                            if not slevel and not rlevel:
                                                log.info("  ! shift/reduce conflict for %s resolved as reduce",a)
                                                self.sr_conflicts.append((st,a,'reduce'))

                                    else:
                                        raise LALRError("Unknown conflict in state %d" % st)
                                else:
                                    st_action[a] = j
                                    st_actionp[a] = p

            # Print the actions associated with each terminal
            _actprint = { }
            for a,p,m in actlist:
                if a in st_action:
                    if p is st_actionp[a]:
                        log.info("    %-15s %s",a,m)
                        _actprint[(a,m)] = 1
            log.info("")
            # Print the actions that were not used. (debugging)
            not_used = 0
            for a,p,m in actlist:
                if a in st_action:
                    if p is not st_actionp[a]:
                        if not (a,m) in _actprint:
                            log.debug("  ! %-15s [ %s ]",a,m)
                            not_used = 1
                            _actprint[(a,m)] = 1
            if not_used:
                log.debug("")

            # Construct the goto table for this state

            nkeys = { }
            for ii in I:
                for s in ii.usyms:
                    if s in self.grammar.Nonterminals:
                        nkeys[s] = None
            for n in nkeys:
                g = self.lr0_goto(I,n)
                j = self.lr0_cidhash.get(id(g),-1)
                if j >= 0:
                    st_goto[n] = j
                    log.info("    %-30s shift and go to state %d",n,j)

            action[st] = st_action
            actionp[st] = st_actionp
            goto[st] = st_goto
            st += 1


    # -----------------------------------------------------------------------------
    # write()
    #
    # This function writes the LR parsing tables to a file
    # -----------------------------------------------------------------------------

    def write_table(self,modulename,outputdir='',signature=""):
        basemodulename = modulename.split(".")[-1]
        filename = os.path.join(outputdir,basemodulename) + ".py"
        try:
            f = open(filename,"w")

            f.write("""
# %s
# This file is automatically generated. Do not edit.
_tabversion = %r

_lr_method = %r

_lr_signature = %r
    """ % (filename, __tabversion__, self.lr_method, signature))

            # Change smaller to 0 to go back to original tables
            smaller = 1

            # Factor out names to try and make smaller
            if smaller:
                items = { }

                for s,nd in self.lr_action.items():
                   for name,v in nd.items():
                      i = items.get(name)
                      if not i:
                         i = ([],[])
                         items[name] = i
                      i[0].append(s)
                      i[1].append(v)

                f.write("\n_lr_action_items = {")
                for k,v in items.items():
                    f.write("%r:([" % k)
                    for i in v[0]:
                        f.write("%r," % i)
                    f.write("],[")
                    for i in v[1]:
                        f.write("%r," % i)

                    f.write("]),")
                f.write("}\n")

                f.write("""
_lr_action = { }
for _k, _v in _lr_action_items.items():
   for _x,_y in zip(_v[0],_v[1]):
      if not _x in _lr_action:  _lr_action[_x] = { }
      _lr_action[_x][_k] = _y
del _lr_action_items
""")

            else:
                f.write("\n_lr_action = { ");
                for k,v in self.lr_action.items():
                    f.write("(%r,%r):%r," % (k[0],k[1],v))
                f.write("}\n");

            if smaller:
                # Factor out names to try and make smaller
                items = { }

                for s,nd in self.lr_goto.items():
                   for name,v in nd.items():
                      i = items.get(name)
                      if not i:
                         i = ([],[])
                         items[name] = i
                      i[0].append(s)
                      i[1].append(v)

                f.write("\n_lr_goto_items = {")
                for k,v in items.items():
                    f.write("%r:([" % k)
                    for i in v[0]:
                        f.write("%r," % i)
                    f.write("],[")
                    for i in v[1]:
                        f.write("%r," % i)

                    f.write("]),")
                f.write("}\n")

                f.write("""
_lr_goto = { }
for _k, _v in _lr_goto_items.items():
   for _x,_y in zip(_v[0],_v[1]):
       if not _x in _lr_goto: _lr_goto[_x] = { }
       _lr_goto[_x][_k] = _y
del _lr_goto_items
""")
            else:
                f.write("\n_lr_goto = { ");
                for k,v in self.lr_goto.items():
                    f.write("(%r,%r):%r," % (k[0],k[1],v))
                f.write("}\n");

            # Write production table
            f.write("_lr_productions = [\n")
            for p in self.lr_productions:
                if p.func:
                    f.write("  (%r,%r,%d,%r,%r,%d),\n" % (p.str,p.name, p.len, p.func,p.file,p.line))
                else:
                    f.write("  (%r,%r,%d,None,None,None),\n" % (str(p),p.name, p.len))
            f.write("]\n")
            f.close()

        except IOError:
            e = sys.exc_info()[1]
            sys.stderr.write("Unable to create '%s'\n" % filename)
            sys.stderr.write(str(e)+"\n")
            return


    # -----------------------------------------------------------------------------
    # pickle_table()
    #
    # This function pickles the LR parsing tables to a supplied file object
    # -----------------------------------------------------------------------------

    def pickle_table(self,filename,signature=""):
        try:
            import cPickle as pickle
        except ImportError:
            import pickle
        outf = open(filename,"wb")
        pickle.dump(__tabversion__,outf,pickle_protocol)
        pickle.dump(self.lr_method,outf,pickle_protocol)
        pickle.dump(signature,outf,pickle_protocol)
        pickle.dump(self.lr_action,outf,pickle_protocol)
        pickle.dump(self.lr_goto,outf,pickle_protocol)

        outp = []
        for p in self.lr_productions:
            if p.func:
                outp.append((p.str,p.name, p.len, p.func,p.file,p.line))
            else:
                outp.append((str(p),p.name,p.len,None,None,None))
        pickle.dump(outp,outf,pickle_protocol)
        outf.close()

# -----------------------------------------------------------------------------
#                            === INTROSPECTION ===
#
# The following functions and classes are used to implement the PLY
# introspection features followed by the yacc() function itself.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# get_caller_module_dict()
#
# This function returns a dictionary containing all of the symbols defined within
# a caller further down the call stack.  This is used to get the environment
# associated with the yacc() call if none was provided.
# -----------------------------------------------------------------------------

def get_caller_module_dict(levels):
    try:
        raise RuntimeError
    except RuntimeError:
        e,b,t = sys.exc_info()
        f = t.tb_frame
        while levels > 0:
            f = f.f_back                   
            levels -= 1
        ldict = f.f_globals.copy()
        if f.f_globals != f.f_locals:
            ldict.update(f.f_locals)

        return ldict

# -----------------------------------------------------------------------------
# parse_grammar()
#
# This takes a raw grammar rule string and parses it into production data
# -----------------------------------------------------------------------------
def parse_grammar(doc,file,line):
    grammar = []
    # Split the doc string into lines
    pstrings = doc.splitlines()
    lastp = None
    dline = line
    for ps in pstrings:
        dline += 1
        p = ps.split()
        if not p: continue
        try:
            if p[0] == '|':
                # This is a continuation of a previous rule
                if not lastp:
                    raise SyntaxError("%s:%d: Misplaced '|'" % (file,dline))
                prodname = lastp
                syms = p[1:]
            else:
                prodname = p[0]
                lastp = prodname
                syms   = p[2:]
                assign = p[1]
                if assign != ':' and assign != '::=':
                    raise SyntaxError("%s:%d: Syntax error. Expected ':'" % (file,dline))

            grammar.append((file,dline,prodname,syms))
        except SyntaxError:
            raise
        except Exception:
            raise SyntaxError("%s:%d: Syntax error in rule '%s'" % (file,dline,ps.strip()))

    return grammar

# -----------------------------------------------------------------------------
# ParserReflect()
#
# This class represents information extracted for building a parser including
# start symbol, error function, tokens, precedence list, action functions,
# etc.
# -----------------------------------------------------------------------------
class ParserReflect(object):
    def __init__(self,pdict,log=None):
        self.pdict      = pdict
        self.start      = None
        self.error_func = None
        self.tokens     = None
        self.files      = {}
        self.grammar    = []
        self.error      = 0

        if log is None:
            self.log = PlyLogger(sys.stderr)
        else:
            self.log = log

    # Get all of the basic information
    def get_all(self):
        self.get_start()
        self.get_error_func()
        self.get_tokens()
        self.get_precedence()
        self.get_pfunctions()
        
    # Validate all of the information
    def validate_all(self):
        self.validate_start()
        self.validate_error_func()
        self.validate_tokens()
        self.validate_precedence()
        self.validate_pfunctions()
        self.validate_files()
        return self.error

    # Compute a signature over the grammar
    def signature(self):
        try:
            from hashlib import md5
        except ImportError:
            from md5 import md5
        try:
            sig = md5()
            if self.start:
                sig.update(self.start.encode('latin-1'))
            if self.prec:
                sig.update("".join(["".join(p) for p in self.prec]).encode('latin-1'))
            if self.tokens:
                sig.update(" ".join(self.tokens).encode('latin-1'))
            for f in self.pfuncs:
                if f[3]:
                    sig.update(f[3].encode('latin-1'))
        except (TypeError,ValueError):
            pass
        return sig.digest()

    # -----------------------------------------------------------------------------
    # validate_file()
    #
    # This method checks to see if there are duplicated p_rulename() functions
    # in the parser module file.  Without this function, it is really easy for
    # users to make mistakes by cutting and pasting code fragments (and it's a real
    # bugger to try and figure out why the resulting parser doesn't work).  Therefore,
    # we just do a little regular expression pattern matching of def statements
    # to try and detect duplicates.
    # -----------------------------------------------------------------------------

    def validate_files(self):
        # Match def p_funcname(
        fre = re.compile(r'\s*def\s+(p_[a-zA-Z_0-9]*)\(')

        for filename in self.files.keys():
            base,ext = os.path.splitext(filename)
            if ext != '.py': return 1          # No idea. Assume it's okay.

            try:
                f = open(filename)
                lines = f.readlines()
                f.close()
            except IOError:
                continue

            counthash = { }
            for linen,l in enumerate(lines):
                linen += 1
                m = fre.match(l)
                if m:
                    name = m.group(1)
                    prev = counthash.get(name)
                    if not prev:
                        counthash[name] = linen
                    else:
                        self.log.warning("%s:%d: Function %s redefined. Previously defined on line %d", filename,linen,name,prev)

    # Get the start symbol
    def get_start(self):
        self.start = self.pdict.get('start')

    # Validate the start symbol
    def validate_start(self):
        if self.start is not None:
            if not isinstance(self.start,str):
                self.log.error("'start' must be a string")

    # Look for error handler
    def get_error_func(self):
        self.error_func = self.pdict.get('p_error')

    # Validate the error function
    def validate_error_func(self):
        if self.error_func:
            if isinstance(self.error_func,types.FunctionType):
                ismethod = 0
            elif isinstance(self.error_func, types.MethodType):
                ismethod = 1
            else:
                self.log.error("'p_error' defined, but is not a function or method")
                self.error = 1
                return

            eline = func_code(self.error_func).co_firstlineno
            efile = func_code(self.error_func).co_filename
            self.files[efile] = 1

            if (func_code(self.error_func).co_argcount != 1+ismethod):
                self.log.error("%s:%d: p_error() requires 1 argument",efile,eline)
                self.error = 1

    # Get the tokens map
    def get_tokens(self):
        tokens = self.pdict.get("tokens",None)
        if not tokens:
            self.log.error("No token list is defined")
            self.error = 1
            return

        if not isinstance(tokens,(list, tuple)):
            self.log.error("tokens must be a list or tuple")
            self.error = 1
            return
        
        if not tokens:
            self.log.error("tokens is empty")
            self.error = 1
            return

        self.tokens = tokens

    # Validate the tokens
    def validate_tokens(self):
        # Validate the tokens.
        if 'error' in self.tokens:
            self.log.error("Illegal token name 'error'. Is a reserved word")
            self.error = 1
            return

        terminals = {}
        for n in self.tokens:
            if n in terminals:
                self.log.warning("Token '%s' multiply defined", n)
            terminals[n] = 1

    # Get the precedence map (if any)
    def get_precedence(self):
        self.prec = self.pdict.get("precedence",None)

    # Validate and parse the precedence map
    def validate_precedence(self):
        preclist = []
        if self.prec:
            if not isinstance(self.prec,(list,tuple)):
                self.log.error("precedence must be a list or tuple")
                self.error = 1
                return
            for level,p in enumerate(self.prec):
                if not isinstance(p,(list,tuple)):
                    self.log.error("Bad precedence table")
                    self.error = 1
                    return

                if len(p) < 2:
                    self.log.error("Malformed precedence entry %s. Must be (assoc, term, ..., term)",p)
                    self.error = 1
                    return
                assoc = p[0]
                if not isinstance(assoc,str):
                    self.log.error("precedence associativity must be a string")
                    self.error = 1
                    return
                for term in p[1:]:
                    if not isinstance(term,str):
                        self.log.error("precedence items must be strings")
                        self.error = 1
                        return
                    preclist.append((term,assoc,level+1))
        self.preclist = preclist

    # Get all p_functions from the grammar
    def get_pfunctions(self):
        p_functions = []
        for name, item in self.pdict.items():
            if name[:2] != 'p_': continue
            if name == 'p_error': continue
            if isinstance(item,(types.FunctionType,types.MethodType)):
                line = func_code(item).co_firstlineno
                file = func_code(item).co_filename
                p_functions.append((line,file,name,item.__doc__))

        # Sort all of the actions by line number
        p_functions.sort()
        self.pfuncs = p_functions


    # Validate all of the p_functions
    def validate_pfunctions(self):
        grammar = []
        # Check for non-empty symbols
        if len(self.pfuncs) == 0:
            self.log.error("no rules of the form p_rulename are defined")
            self.error = 1
            return 
        
        for line, file, name, doc in self.pfuncs:
            func = self.pdict[name]
            if isinstance(func, types.MethodType):
                reqargs = 2
            else:
                reqargs = 1
            if func_code(func).co_argcount > reqargs:
                self.log.error("%s:%d: Rule '%s' has too many arguments",file,line,func.__name__)
                self.error = 1
            elif func_code(func).co_argcount < reqargs:
                self.log.error("%s:%d: Rule '%s' requires an argument",file,line,func.__name__)
                self.error = 1
            elif not func.__doc__:
                self.log.warning("%s:%d: No documentation string specified in function '%s' (ignored)",file,line,func.__name__)
            else:
                try:
                    parsed_g = parse_grammar(doc,file,line)
                    for g in parsed_g:
                        grammar.append((name, g))
                except SyntaxError:
                    e = sys.exc_info()[1]
                    self.log.error(str(e))
                    self.error = 1

                # Looks like a valid grammar rule
                # Mark the file in which defined.
                self.files[file] = 1

        # Secondary validation step that looks for p_ definitions that are not functions
        # or functions that look like they might be grammar rules.

        for n,v in self.pdict.items():
            if n[0:2] == 'p_' and isinstance(v, (types.FunctionType, types.MethodType)): continue
            if n[0:2] == 't_': continue
            if n[0:2] == 'p_' and n != 'p_error':
                self.log.warning("'%s' not defined as a function", n)
            if ((isinstance(v,types.FunctionType) and func_code(v).co_argcount == 1) or
                (isinstance(v,types.MethodType) and func_code(v).co_argcount == 2)):
                try:
                    doc = v.__doc__.split(" ")
                    if doc[1] == ':':
                        self.log.warning("%s:%d: Possible grammar rule '%s' defined without p_ prefix",
                                         func_code(v).co_filename, func_code(v).co_firstlineno,n)
                except Exception:
                    pass

        self.grammar = grammar

# -----------------------------------------------------------------------------
# yacc(module)
#
# Build a parser
# -----------------------------------------------------------------------------

def yacc(method='LALR', debug=yaccdebug, module=None, tabmodule=tab_module, start=None, 
         check_recursion=1, optimize=0, write_tables=1, debugfile=debug_file,outputdir='',
         debuglog=None, errorlog = None, picklefile=None):

    global parse                 # Reference to the parsing method of the last built parser

    # If pickling is enabled, table files are not created

    if picklefile:
        write_tables = 0

    if errorlog is None:
        errorlog = PlyLogger(sys.stderr)

    # Get the module dictionary used for the parser
    if module:
        _items = [(k,getattr(module,k)) for k in dir(module)]
        pdict = dict(_items)
    else:
        pdict = get_caller_module_dict(2)

    # Collect parser information from the dictionary
    pinfo = ParserReflect(pdict,log=errorlog)
    pinfo.get_all()

    if pinfo.error:
        raise YaccError("Unable to build parser")

    # Check signature against table files (if any)
    signature = pinfo.signature()

    # Read the tables
    try:
        lr = LRTable()
        if picklefile:
            read_signature = lr.read_pickle(picklefile)
        else:
            read_signature = lr.read_table(tabmodule)
        if optimize or (read_signature == signature):
            try:
                lr.bind_callables(pinfo.pdict)
                parser = LRParser(lr,pinfo.error_func)
                parse = parser.parse
                return parser
            except Exception:
                e = sys.exc_info()[1]
                errorlog.warning("There was a problem loading the table file: %s", repr(e))
    except VersionError:
        e = sys.exc_info()
        errorlog.warning(str(e))
    except Exception:
        pass

    if debuglog is None:
        if debug:
            debuglog = PlyLogger(open(debugfile,"w"))
        else:
            debuglog = NullLogger()

    debuglog.info("Created by PLY version %s (http://www.dabeaz.com/ply)", __version__)


    errors = 0

    # Validate the parser information
    if pinfo.validate_all():
        raise YaccError("Unable to build parser")
    
    if not pinfo.error_func:
        errorlog.warning("no p_error() function is defined")

    # Create a grammar object
    grammar = Grammar(pinfo.tokens)

    # Set precedence level for terminals
    for term, assoc, level in pinfo.preclist:
        try:
            grammar.set_precedence(term,assoc,level)
        except GrammarError:
            e = sys.exc_info()[1]
            errorlog.warning("%s",str(e))

    # Add productions to the grammar
    for funcname, gram in pinfo.grammar:
        file, line, prodname, syms = gram
        try:
            grammar.add_production(prodname,syms,funcname,file,line)
        except GrammarError:
            e = sys.exc_info()[1]
            errorlog.error("%s",str(e))
            errors = 1

    # Set the grammar start symbols
    try:
        if start is None:
            grammar.set_start(pinfo.start)
        else:
            grammar.set_start(start)
    except GrammarError:
        e = sys.exc_info()[1]
        errorlog.error(str(e))
        errors = 1

    if errors:
        raise YaccError("Unable to build parser")

    # Verify the grammar structure
    undefined_symbols = grammar.undefined_symbols()
    for sym, prod in undefined_symbols:
        errorlog.error("%s:%d: Symbol '%s' used, but not defined as a token or a rule",prod.file,prod.line,sym)
        errors = 1

    unused_terminals = grammar.unused_terminals()
    if unused_terminals:
        debuglog.info("")
        debuglog.info("Unused terminals:")
        debuglog.info("")
        for term in unused_terminals:
            errorlog.warning("Token '%s' defined, but not used", term)
            debuglog.info("    %s", term)

    # Print out all productions to the debug log
    if debug:
        debuglog.info("")
        debuglog.info("Grammar")
        debuglog.info("")
        for n,p in enumerate(grammar.Productions):
            debuglog.info("Rule %-5d %s", n, p)

    # Find unused non-terminals
    unused_rules = grammar.unused_rules()
    for prod in unused_rules:
        errorlog.warning("%s:%d: Rule '%s' defined, but not used", prod.file, prod.line, prod.name)

    if len(unused_terminals) == 1:
        errorlog.warning("There is 1 unused token")
    if len(unused_terminals) > 1:
        errorlog.warning("There are %d unused tokens", len(unused_terminals))

    if len(unused_rules) == 1:
        errorlog.warning("There is 1 unused rule")
    if len(unused_rules) > 1:
        errorlog.warning("There are %d unused rules", len(unused_rules))

    if debug:
        debuglog.info("")
        debuglog.info("Terminals, with rules where they appear")
        debuglog.info("")
        terms = list(grammar.Terminals)
        terms.sort()
        for term in terms:
            debuglog.info("%-20s : %s", term, " ".join([str(s) for s in grammar.Terminals[term]]))
        
        debuglog.info("")
        debuglog.info("Nonterminals, with rules where they appear")
        debuglog.info("")
        nonterms = list(grammar.Nonterminals)
        nonterms.sort()
        for nonterm in nonterms:
            debuglog.info("%-20s : %s", nonterm, " ".join([str(s) for s in grammar.Nonterminals[nonterm]]))
        debuglog.info("")

    if check_recursion:
        unreachable = grammar.find_unreachable()
        for u in unreachable:
            errorlog.warning("Symbol '%s' is unreachable",u)

        infinite = grammar.infinite_cycles()
        for inf in infinite:
            errorlog.error("Infinite recursion detected for symbol '%s'", inf)
            errors = 1
        
    unused_prec = grammar.unused_precedence()
    for term, assoc in unused_prec:
        errorlog.error("Precedence rule '%s' defined for unknown symbol '%s'", assoc, term)
        errors = 1

    if errors:
        raise YaccError("Unable to build parser")
    
    # Run the LRGeneratedTable on the grammar
    if debug:
        errorlog.debug("Generating %s tables", method)
            
    lr = LRGeneratedTable(grammar,method,debuglog)

    if debug:
        num_sr = len(lr.sr_conflicts)

        # Report shift/reduce and reduce/reduce conflicts
        if num_sr == 1:
            errorlog.warning("1 shift/reduce conflict")
        elif num_sr > 1:
            errorlog.warning("%d shift/reduce conflicts", num_sr)

        num_rr = len(lr.rr_conflicts)
        if num_rr == 1:
            errorlog.warning("1 reduce/reduce conflict")
        elif num_rr > 1:
            errorlog.warning("%d reduce/reduce conflicts", num_rr)

    # Write out conflicts to the output file
    if debug and (lr.sr_conflicts or lr.rr_conflicts):
        debuglog.warning("")
        debuglog.warning("Conflicts:")
        debuglog.warning("")

        for state, tok, resolution in lr.sr_conflicts:
            debuglog.warning("shift/reduce conflict for %s in state %d resolved as %s",  tok, state, resolution)
        
        already_reported = {}
        for state, rule, rejected in lr.rr_conflicts:
            if (state,id(rule),id(rejected)) in already_reported:
                continue
            debuglog.warning("reduce/reduce conflict in state %d resolved using rule (%s)", state, rule)
            debuglog.warning("rejected rule (%s) in state %d", rejected,state)
            errorlog.warning("reduce/reduce conflict in state %d resolved using rule (%s)", state, rule)
            errorlog.warning("rejected rule (%s) in state %d", rejected, state)
            already_reported[state,id(rule),id(rejected)] = 1
        
        warned_never = []
        for state, rule, rejected in lr.rr_conflicts:
            if not rejected.reduced and (rejected not in warned_never):
                debuglog.warning("Rule (%s) is never reduced", rejected)
                errorlog.warning("Rule (%s) is never reduced", rejected)
                warned_never.append(rejected)

    # Write the table file if requested
    if write_tables:
        lr.write_table(tabmodule,outputdir,signature)

    # Write a pickled version of the tables
    if picklefile:
        lr.pickle_table(picklefile,signature)

    # Build the parser
    lr.bind_callables(pinfo.pdict)
    parser = LRParser(lr,pinfo.error_func)

    parse = parser.parse
    return parser

########NEW FILE########
__FILENAME__ = mathutils
""" Defines useful math functions. """

from __builtin__ import round as _round
import math

# to be able to call conjugate, real and imag on all numericals

def conjugate(x):
    """ the conjugate part of x """
    if isinstance(x, complex) :
        return x.conjugate()
    else :
        return x

def real (x):
    """ the real part of x """
    if isinstance(x, complex) :
        return x.real
    else :
        return x

def imag (x):
    """ the imaginary part of x """
    if isinstance(x, complex) :
        return x.imag
    else :
        return type(x)(0)

# overload of built-in round fn to accept complex numbers
def round(value, ndigits=0) :
    """
    round(number[, ndigits]) -> float
    Round a number to a given precision in decimal digits (default 0 digits).
    This always returns a floating point number.  Precision may be negative.
    This builtin function was overloaded in mathutils to work on complex numbers,
    in that case rel and imaginary values are rounded separately

    """
    ndigits = int(ndigits)
    if isinstance(value, complex) :
        return complex(_round(value.real, ndigits), _round(value.imag, ndigits))
    else :
        return _round(value, ndigits)

# general remapping operations

def gamma (c, g):
    """
    Gamma color correction of c with a single scalar gamma value g

    :rtype: float
    """
    return c**g

def blend (a, b, weight=0.5):
    """
    blend(a, b[, weight=0.5]) :
    Blends values a and b according to normalized weight w,
    returns a for weight == 0.0 and b for weight = 1.0, a*(1.0-weight)+b*weight in between

    :rtype: float
    """
    return a*(1.0-weight)+b*weight

# TODO : modify these so that they accept iterable / element wise operations

def smoothmap(min, max, x):
    """Returns the value of a smooth remapping function.

    performs a smooth Hermite interpolation between 0 and 1 in the interval min to max,
    but does not clamp the range

    :rtype: float
    """
    x = float(x)
    x = float(x-min)/float(max-min)
    return x*x*(3.0-2.0*x)

def smoothstep(min, max, x):
    """Returns the value of a smooth step function.

    Returns 0 if x < min, 1 if x > max, and performs a smooth Hermite
    interpolation between 0 and 1 in the interval min to max.

    :rtype: float
    """
    if x<min:
        return 0.0
    if x>max:
        return 1.0
    return smoothmap(min, max, x)

def linmap(min, max, x):
    """Returns the value of a linear remapping function.

    performs a linear interpolation between 0 and 1 in the interval min to max,
    but does not clamp the range

    :rtype: float
    """
    return (float(x)-min)/(max-min)

def linstep(min, max, x):
    """Returns the value of a linear step function.

    Returns 0 if x < min, 1 if x > max, and performs a linear
    interpolation between 0 and 1 in the interval min to max.

    :rtype: float
    """
    if x<min:
        return 0.0
    if x>max:
        return 1.0
    return linmap(min, max, x)

# NOTE : x first seem more natural
def clamp(x=0.0, min=0.0, max=1.0) :
    """ Clamps the value x between min and max

    :rtype: float
    """
    # NOTE : in 2.5 can use 'caseTrue if condition else caseFalse'
    #realmin = min if min<max else max
    #realmax = max if min<max else min
    # orig C code :
    #    const double realmin=(min<max)?min:max;
    #    const double realmax=(min<max)?max:min;
    #    return ((x<realmin)?realmin:(x>realmax)?realmax:x);
    if min<max :
        realmin = min
        realmax = max
    else :
        realmin = max
        realmax = min
    if x<realmin :
        result = realmin
    elif x>realmax :
        result = realmax
    else :
        result = x
    return result

def setRange(x=0.0, oldmin=0.0, oldmax=1.0, newmin=0.0, newmax=1.0) :
    """ Resets x range from x linear interpolation of oldmin to oldmax to x linear interpolation from newmin to newmax

    :rtype: float
    """
    if oldmin<oldmax :
        realoldmin=oldmin
        realoldmax=oldmax
        realnewmin=newmin
        realnewmax=newmax
    elif oldmin>oldmax :
        realoldmin=oldmax
        realoldmax=oldmin
        realnewmin=newmax
        realnewmax=newmin
    else :
        return x
    if x<realoldmin :
        result = realnewmin
    elif x>realoldmax :
        result = realnewmax
    else :
        result = (realnewmin+(realnewmax-realnewmin)*(x-oldmin)/(oldmax-oldmin))
    return result

def hermiteInterp(x=0.0, y0=0.0, y1=1.0, s0=0.0, s1=0.0) :
    """ Hermite interpolation of x between points y0 and y1 of tangent slope s0 and s1

    :rtype: float
    """
    c = s0
    v = y0 - y1
    w = c + v
    x = w + v + s1
    b_neg = w + x
    return ((((x * x) - b_neg) * x + s0) * x + y0)

def hermite(x=0.0, v0=0.0, v1=0.0, s0=0.0, s1=0.0) :
    """
    As the MEL command : This command returns x point along on x hermite curve from the five given control arguments.
    The first two arguments are the start and end points of the curve, respectively.
    The next two arguments are the tangents of the curve at the start point and end point of the curve, respectively.
    The fifth argument, parameter, specifies the point on the hermite curve that is returned by this function.
    This parameter is the unitized distance along the curve from the start point to the end point.
    A parameter value of 0.0 corresponds to the start point and x parameter value of 1.0 corresponds to the end point of the curve.

    :rtype: float

    """

    if x<0.0 :
        res = v0
    elif x>1.0 :
        res = v1
    else :
        res = hermiteInterp(x, v0, v1, s0, s1)
    return res

########NEW FILE########
__FILENAME__ = namedtuple
""" Cookbook recipe 500261, Raymond Hettinger, planned for inclusion in 2.6 :
    http://docs.python.org/dev/library/collections.html#collections.namedtuple """
from operator import itemgetter as _itemgetter
from keyword import iskeyword as _iskeyword
import sys as _sys

__all__ = ['namedtuple']

def namedtuple(typename, field_names, docAppend="", verbose=False):
    """ Returns a new subclass of tuple with named fields.

    >>> Point = namedtuple('Point', 'x, y')
    >>> Point.__doc__                   # docstring for the new class
    'Point(x, y)'
    >>> p = Point(11, y=22)             # instantiate with positional args or keywords
    >>> p[0] + p[1]                     # indexable like a plain tuple
    33
    >>> x, y = p                        # unpack like a regular tuple
    >>> x, y
    (11, 22)
    >>> p.x + p.y                       # fields also accessible by name
    33
    >>> d = p._asdict()                 # convert to a dictionary
    >>> d['x']
    11
    >>> Point(**d)                      # convert from a dictionary
    Point(x=11, y=22)
    >>> p._replace(x=100)               # _replace() is like str.replace() but targets named fields
    Point(x=100, y=22)

    """

    docAppend = docAppend.encode('string_escape')

    # Parse and validate the field names.  Validation serves two purposes,
    # generating informative error messages and preventing template injection attacks.
    if isinstance(field_names, basestring):
        field_names = field_names.replace(',', ' ').split() # names separated by whitespace and/or commas
    field_names = tuple(field_names)
    for name in (typename,) + field_names:
        if not min(c.isalnum() or c=='_' for c in name):
            raise ValueError('Type names and field names can only contain alphanumeric characters and underscores: %r' % name)
        if _iskeyword(name):
            raise ValueError('Type names and field names cannot be a keyword: %r' % name)
        if name[0].isdigit():
            raise ValueError('Type names and field names cannot start with a number: %r' % name)
    seen_names = set()
    for name in field_names:
        if name.startswith('_'):
            raise ValueError('Field names cannot start with an underscore: %r' % name)
        if name in seen_names:
            raise ValueError('Encountered duplicate field name: %r' % name)
        seen_names.add(name)

    # Create and fill-in the class template
    # note in 2.6 collections use
    # def __getnewargs__(self):
    # return tuple(self)
    # instead of __reduce__ to provide unpickling capabilities

    numfields = len(field_names)
    argtxt = repr(field_names).replace("'", "")[1:-1]   # tuple repr without parens or quotes
    reprtxt = ', '.join('%s=%%r' % name for name in field_names)
    dicttxt = ', '.join('%r: t[%d]' % (name, pos) for pos, name in enumerate(field_names))
    template = '''class %(typename)s(tuple):
        '%(typename)s(%(argtxt)s)%(docAppend)s' \n
        __slots__ = () \n
        _fields = %(field_names)r \n
        def __new__(cls, %(argtxt)s):
            return tuple.__new__(cls, (%(argtxt)s)) \n
        @classmethod
        def _make(cls, iterable, new=tuple.__new__, len=len):
            'Make a new %(typename)s object from a sequence or iterable'
            result = new(cls, iterable)
            if len(result) != %(numfields)d:
                raise TypeError('Expected %(numfields)d arguments, got %%d' %% len(result))
            return result \n
        def __repr__(self):
            return '%(typename)s(%(reprtxt)s)' %% self \n
        def _asdict(t):
            'Return a new dict which maps field names to their values'
            return {%(dicttxt)s} \n
        def _replace(self, **kwds):
            'Return a new %(typename)s object replacing specified fields with new values'
            result = self._make(map(kwds.pop, %(field_names)r, self))
            if kwds:
                raise ValueError('Got unexpected field names: %%r' %% kwds.keys())
            return result \n
        def __reduce__(self) :
            return ( self.__class__, tuple(self) ) \n\n''' % locals()
    for i, name in enumerate(field_names):
        template += '        %s = property(itemgetter(%d))\n' % (name, i)
    if verbose:
        print template

    # Execute the template string in a temporary namespace
    namespace = dict(itemgetter=_itemgetter)
    try:
        exec template in namespace
    except SyntaxError, e:
        raise SyntaxError(e.message + ':\n' + template)
    result = namespace[typename]

    # For pickling to work, the __module__ variable needs to be set to the frame
    # where the named tuple is created.  Bypass this step in enviroments where
    # sys._getframe is not defined (Jython for example).
    if hasattr(_sys, '_getframe'):
        result.__module__ = _sys._getframe(1).f_globals['__name__']

    return result






if __name__ == '__main__':
    # verify that instances can be pickled
    from cPickle import loads, dumps
    Point = namedtuple('Point', 'x, y', True)
    p = Point(x=10, y=20)
    assert p == loads(dumps(p))

    # test and demonstrate ability to override methods
    class Point(namedtuple('Point', 'x y')):
        @property
        def hypot(self):
            return (self.x ** 2 + self.y ** 2) ** 0.5
        def __str__(self):
            return 'Point: x=%6.3f y=%6.3f hypot=%6.3f' % (self.x, self.y, self.hypot)

    for p in Point(3,4), Point(14,5), Point(9./7,6):
        print p

    class Point(namedtuple('Point', 'x y')):
        'Point class with optimized _make() and _replace() without error-checking'
        _make = classmethod(tuple.__new__)
        def _replace(self, _map=map, **kwds):
            return self._make(_map(kwds.get, ('x', 'y'), self))

    print Point(11, 22)._replace(x=100)

    import doctest
    TestResults = namedtuple('TestResults', 'failed attempted')
    print TestResults(*doctest.testmod())

########NEW FILE########
__FILENAME__ = nameparse
from objectParser import *

__all__ = [#'NameParseError', 'ParsingWarning',
           #'ProxyUni', 'NameParsed',
           'NamePart', 'NameAlphaPart', 'NameNumPart', 'NameGroup',
           'NameAlphaGroup', 'NameNumGroup', 'NameSep', 'MayaName', 'NamespaceSep', 'Namespace',
           'MayaShortName', 'DagPathSep', 'MayaNodePath', 'AttrSep', 'NameIndex', 'NameRangeIndex',
           'Component', 'Attribute', 'AttributePath', 'NodeAttribute', 'MayaObjectName',
           'getBasicPartList', 'parse']

# Parsers deriver from the Parser base class
# for Maya names parsing

# NOTE : order of declaration is important as yacc only considers
# lineno of function declaration to order the rules
# TODO : modify Yacc to take mro of class then relative line no or use decorators ?

# no parsed class for this, the Parsers and NameParsed class for each token (e.g. t_Alpha and --> Alpha, AlphaParser) will be created automatically anyway
class NameBaseParser(Parser):
    """ Base for name parser with common tokens """
    t_Alpha    = r'([a-z]+)|([A-Z]+[a-z]*)'
    t_Num   = r'[0-9]+'

    start = None

class NameAlphaPartParser(NameBaseParser):
    """ Parser for a name part starting with a letter """
    start = 'NameAlphaPart'

    def p_apart(self, p):
        '''NameAlphaPart : Alpha'''
        p[0] = NameAlphaPart(Token(p[1], type='Alpha', pos=p.lexpos(1)))

class NameNumPartParser(NameBaseParser):
    """ Parser for a name part starting with a number """
    start = 'NameNumPart'

    def p_npart(self, p):
        '''NameNumPart : Num'''
        p[0] = NameNumPart(Token(p[1], type='Num', pos=p.lexpos(1)))

class NamePartParser(NameAlphaPartParser, NameNumPartParser):
    """ Parser for a name part of either the NameAlphaPart or NameNumPart kind """
    start = 'NamePart'

    def p_part(self, p):
        '''NamePart : NameAlphaPart
                    | NameNumPart'''
        p[0] = NamePart(p[1])

class NameAlphaGroupParser(NameAlphaPartParser, NameNumPartParser):
    """
        A Parser for suitable groups for a name head : one or more name parts, the first part starting with a letter
        NameAlphaGroup = NameAlphaPart NamePart *
    """
    start = 'NameAlphaGroup'

    def p_agroup_concat(self, p):
        ''' NameAlphaGroup : NameAlphaGroup NameAlphaPart
                                |  NameAlphaGroup NameNumPart '''
        p[0] = p[1] + p[2]
    def p_agroup(self, p):
        ''' NameAlphaGroup : NameAlphaPart '''
        p[0] = NameAlphaGroup(p[1])

class NameNumGroupParser(NameAlphaPartParser, NameNumPartParser):
    """
        A Parser for suitable groups for a name body : one or more name parts, the first part starting with a number
        NameNumGroup = NameNumPart NamePart *
    """
    start = 'NameNumGroup'

    def p_ngroup_concat(self, p):
        ''' NameNumGroup : NameNumGroup NameAlphaPart
                                | NameNumGroup NameNumPart '''
        p[0] = p[1] + p[2]
    def p_ngroup(self, p):
        ''' NameNumGroup : NameNumPart '''
        p[0] = NameNumGroup(p[1])

class NameGroupParser(NameAlphaGroupParser, NameNumGroupParser):
    """
        A Parser for a name group of either the NameAlphaGroup or NameNumGroup kind
    """
    start = 'NameGroup'
    def p_group(self, p):
        ''' NameGroup : NameAlphaGroup
                        | NameNumGroup '''
        p[0] = NameGroup(p[1])

class NameSepParser(Parser):
    """ A Parser for the MayaName NameGroup separator : one or more underscores """
    t_Underscore  = r'_+'

    start = 'NameSep'
    def p_sep_concat(self, p):
        ''' NameSep : NameSep Underscore '''
        p[0] = p[1] + Token(p[1], type='Underscore', pos=p.lexpos(1))
    def p_sep(self, p):
        ''' NameSep : Underscore '''
        p[0] = NameSep(Token(p[1], type='Underscore', pos=p.lexpos(1)))

    # always lower precedence than parts we herit the parser from
    # TODO : gather precedence from base classes
    precedence = ( ('left', 'Underscore'),
                   ('right', ('Alpha', 'Num') ),
                 )

class MayaNameParser(NameSepParser, NameGroupParser):
    """
        A Parser for the most basic Maya Name : several name groups separated by one or more underscores,
        starting with an alphabetic part or one or more underscore, followed by zero or more NameGroup(s)
        separated by underscores
    """

    start = 'MayaName'

    def p_name_error(self, p):
        'MayaName : error'
        print "Syntax error in MayaName. Bad expression"

    # a atomic Maya name is in the form (_)*head(_group)*(_)*
    def p_name_concat(self, p):
        ''' MayaName : MayaName NameSep NameGroup
                        | MayaName NameSep '''
        if len(p) == 4 :
            p[0] = (p[1] + p[2]) + p[3]
        else :
            p[0] = p[1] + p[2]
    def p_name(self, p):
        ''' MayaName : NameSep NameGroup
                    | NameAlphaGroup '''
        if len(p) == 3 :
            p[0] = MayaName(p[1], p[2])
        else :
            p[0] = MayaName(p[1])

class NamespaceSepParser(Parser):
    """ A Parser for the Namespace separator """
    t_Colon  = r':'

    start = 'NamespaceSep'
    def p_nspace_sep(self, p):
        ''' NamespaceSep : Colon '''
        p[0] = NamespaceSep(Token(p[1], type='Colon', pos=p.lexpos(1)))

    precedence = ( ('left', 'Colon' ),
                   ('left', 'Underscore'),
                   ('right', 'Alpha', 'Num' ),
                   )

class NamespaceParser(NamespaceSepParser, MayaNameParser, EmptyParser):
    """ A Parser for Namespace, Maya namespaces names """

    start = 'Namespace'

    def p_nspace_concat(self, p):
        ''' Namespace : Namespace MayaName NamespaceSep '''
        p[0] = p[1] + Namespace(p[2], p[3])
    def p_nspace(self, p) :
        ''' Namespace : MayaName NamespaceSep
                    | NamespaceSep
                    | Empty '''
        if len(p) == 3 :
            p[0] = Namespace(p[1], p[2])
        else :
            p[0] = Namespace(p[1])

class MayaShortNameParser(NamespaceParser, MayaNameParser):
    """ A parser for MayaShortName, a short object name (without preceding path) with a possible preceding namespace """

    start = 'MayaShortName'

    def p_sname(self, p) :
        ''' MayaShortName : Namespace MayaName
                            | MayaName '''
        if len(p) == 3 :
            p[0] = MayaShortName(p[1], p[2])
        else :
            p[0] = MayaShortName(Namespace(pos=p.lexpos(1)), p[1])

class DagPathSepParser(Parser):
    """ A Parser for the DagPathSep separator """
    t_Pipe  = r'\|'

    start = 'DagPathSep'

    def p_dpath_sep(self, p):
        ''' DagPathSep : Pipe '''
        p[0] = DagPathSep(Token(p[1], type='Pipe', pos=p.lexpos(1)))

    precedence = ( ('left', 'Pipe'),
                   ('left', 'Colon'),
                   ('left', 'Underscore'),
                   ('left', 'Alpha', 'Num' ),
                 )

class MayaNodePathParser(DagPathSepParser, MayaShortNameParser):
    """ a Parser for Maya node name, an optional leading DagPathSep followed by one or more
        MayaShortName separated by DagPathSep """

    start = 'MayaNodePath'

    def p_node_concat(self, p) :
        ''' MayaNodePath : MayaNodePath DagPathSep MayaShortName '''
        p[0] = p[1] + MayaNodePath(p[2], p[3])
    def p_node(self, p) :
        ''' MayaNodePath : DagPathSep MayaShortName
                                | MayaShortName '''
        if len(p) == 3 :
            p[0] = MayaNodePath(p[1], p[2])
        else :
            p[0] = MayaNodePath(p[1])

class AttrSepParser(Parser):
    """ A Parser for the MayaAttributePath separator """
    t_Dot  = r'\.'

    start = 'AttrSep'
    def p_attr_sep(self, p):
        ''' AttrSep : Dot '''
        p[0] = AttrSep(Token(p[1], type='Dot', pos=p.lexpos(1)))

    precedence = ( ('left', 'Dot'),
                   ('left', 'Pipe'),
                   ('left', 'Colon'),
                   ('left', 'Underscore'),
                   ('left', 'Alpha', 'Num'),
                 )

class NameIndexParser(Parser):
    """ A Parser for attribute or component name indexes, in the form [<int number>] """
    t_Index  = r'\[(?:[0-9]+|-1)\]'

    start = 'NameIndex'
    def p_index(self, p):
        ''' NameIndex : Index '''
        p[0] = NameIndex(Token(p[1], type='Index', pos=p.lexpos(1)))

    precedence = ( ('left', 'Index'),
                   ('left', 'Dot'),
                   ('left', 'Pipe'),
                   ('left', 'Colon'),
                   ('left', 'Underscore'),
                   ('left', 'Alpha', 'Num'),
                 )

class NameRangeIndexParser(Parser):
    """ A Parser for an index specification for an attribute or a component index,
        in the form [<optional int number>:<optional int number>]
        Rule : NameIndex = r'\[[0-9]*:[0-9]*\]' """
    t_RangeIndex  = r'\[[0-9]*:[0-9]*\]'

    start = 'NameRangeIndex'
    def p_rindex(self, p):
        ''' NameRangeIndex : RangeIndex '''
        p[0] = NameIndex(Token(p[1], type='RangeIndex', pos=p.lexpos(1)))

    precedence = ( ('left', 'RangeIndex'),
                   ('left', 'Index'),
                   ('left', 'Dot'),
                   ('left', 'Pipe'),
                   ('left', 'Colon'),
                   ('left', 'Underscore'),
                   ('left', 'Alpha', 'Num'),
                 )

class SingleComponentNameParser(NameRangeIndexParser, NameIndexParser, MayaNameParser):
    """ A NameParsed for the reserved single indexed components names:
        vtx,
        Rule : NameIndex = r'\[[0-9]*:[0-9]*\]' """

class DoubleComponentNameParser(NameRangeIndexParser, NameIndexParser, MayaNameParser):
    pass

class TripleComponentNameParser(NameRangeIndexParser, NameIndexParser, MayaNameParser):
    pass

class ComponentNameParser(SingleComponentNameParser, DoubleComponentNameParser, TripleComponentNameParser):
    pass

# NOTE : call these attributes and the couple(node.attribute) a plug like in API ?

class NodeAttributeNameParser(NameIndexParser, MayaNameParser):
    """ Parser for a Attribute, the name of a Maya attribute on a Maya node, a MayaName with an optional NameIndex """

    start = 'Attribute'

    def p_nodeattr_error(self, p):
        'Attribute : error'
        print "Invalid node attribute name"
    def p_nodeattr(self, p):
        ''' Attribute : MayaName NameIndex
                                    | MayaName '''
        if len(p) == 3 :
            p[0] = Attribute(p[1], p[2])
        else :
            p[0] = Attribute(p[1])

class NodeAttributePathParser(AttrSepParser, NodeAttributeNameParser):
    """ Parser for a full path of a Maya attribute on a Maya node, as one or more AttrSep ('.') separated Attribute """

    start = 'AttributePath'

    def p_nodeattrpath_concat(self, p):
        ''' AttributePath : AttributePath AttrSep Attribute '''
        p[0] = AttributePath(p[1], p[2], p[3])
    def p_nodeattrpath(self, p):
        ''' AttributePath : Attribute '''
        p[0] = AttributePath(p[1])

class AttributeNameParser(NodeAttributePathParser, MayaNodePathParser):
    """ Parser for the name of a Maya attribute, a MayaNodePath followed by a AttrSep and a AttributePath """

    start = 'NodeAttribute'

    def p_attribute(self, p):
        ''' NodeAttribute : MayaNodePath AttrSep AttributePath'''
        p[0] = NodeAttribute(p[1], p[2], p[3])

# ComponentNameParser

class MayaObjectNameParser(AttributeNameParser):
    """ A Parser for an unspecified object name in Maya, can be a dag object name, a node name,
        an plug name, or a component name. """

    start = 'MayaObjectName'

    def p_mobject(self, p) :
        ''' MayaObjectName : MayaNodePath
                            | NodeAttribute '''
        p[0] = MayaObjectName(p[1])


class NameParsed(Parsed):

    def isNodeName(self):
        """ True if this dag path name is absolute (starts with '|') """
        return type(self) == MayaNodePath
    def isAttributeName(self):
        """ True if this object is specified including one or more dag parents """
        return type(self) == NodeAttribute
    def isComponentName(self):
        """ True if this object is specified as an absolute dag path (starting with '|') """
        return type(self) == Component

# NameParsed objects for Maya Names
# TODO : build _accepts from yacc rules directly

# Atomic Name element, an alphabetic or numeric word
class NamePart(NameParsed):
    """
    A name part of either the NameAlphaPart or NameNumPart kind

        Rule : NamePart = `NameAlphaPart` | `NameNumPart`

        Composed Of: `NameAlphaPart`, `NameNumPart`

        Component Of: `NameNumGroup`
    """
    _parser = NamePartParser
    _accepts = ('Alpha', 'Num')

    def isAlpha(self):
        return isinstance(self.sub[0], Alpha)
    def isNum(self):
        return isinstance(self.sub[0], Num)


class NameAlphaPart(NamePart):
    """
    A name part made of alphabetic letters

        Rule : NameAlphaPart = r'([a-z]+)|([A-Z]+[a-z]*)'

        Component Of: `NameNumGroup`, `NameAlphaGroup`
    """
    _parser = NameAlphaPartParser
    _accepts = ('Alpha', )

    def isAlpha(self):
        return True
    def isNum(self):
        return False

class NameNumPart(NamePart):
    """
    A name part made of numbers

        Rule : NameNumPart = r'[0-9]+'

    """
    _parser = NameNumPartParser
    _accepts = ('Num', )

    # to allow initialization from a single int
    def __new__(cls, *args, **kwargs):
        if len(args) == 1 and isinstance(args[0], int) :
            nargs = [Token(u"%s" % args[0], type='Num', pos=0)]
        else :
            nargs = list(args)
        return super(NameNumPart, cls).__new__(cls, *nargs, **kwargs)

    @ property
    def value(self) :
        return int(str(self))

    def isAlpha(self):
        return False
    def isNum(self):
        return True

# A Name group, all the consecutive parts between two underscores
class NameGroup(NameParsed):
    """
    A name group of either the NameAlphaGroup or NameNumGroup kind

        Rule : NameGroup = `NameAlphaGroup` | `NameNumGroup`

        Composed Of: `NameAlphaGroup`, `NameNumGroup`

        Component Of: `MayaName`
    """
    _parser = NameGroupParser
    _accepts = ('NameAlphaPart', 'NameNumPart', 'NamePart')

    def isNum(self):
        return self.parts[0].isNum()
    def isAlpha(self):
        return self.parts[0].isAlpha()

    @property
    def parts(self):
        """ All parts of that name group """
        return self.sub
    @property
    def first(self):
        """ First part of that name group """
        return self.parts[0]
    @property
    def last(self):
        """ Last part of that name group """
        return self.parts[-1]
    @property
    def tail(self):
        """ The tail (trailing numbers if any) of that name group """
        if self.last.isNum() :
            return (self.last)
    def nextName(self):
        tail = self.tail
        if tail is not None:
            padding = str(len(self.tail))
            formatStr = '%0' + padding + 'd'
            newval = formatStr % (tail.value+1)
            self.setSubItem(-1, newval )
    def prevName(self):
        tail = self.tail
        if tail is not None:
            padding = str(len(self.tail))
            formatStr = '%0' + padding + 'd'
            newval = formatStr % (tail.value-1)
            self.setSubItem(-1, newval )

class NameAlphaGroup(NameGroup):
    """
    A name group starting with an alphabetic part

        Rule : NameAlphaGroup  = `NameAlphaPart` `NamePart` *

        Composed Of: `NameAlphaPart`, `NamePart`

        Component Of: `NameNumGroup`
    """
    _parser = NameAlphaGroupParser
    _accepts = ('NameAlphaPart', 'NameNumPart', 'NamePart')

    def isNum(self):
        return False
    def isAlpha(self):
        return True

class NameNumGroup(NameGroup):
    """
    A name group starting with an alphabetic part

        Rule : NameAlphaGroup  = `NameAlphaPart` `NamePart` *

        Composed Of: `NameAlphaPart`, `NamePart`

        Component Of: `MayaName`
    """
    _parser = NameNumGroupParser
    _accepts = ('NameAlphaPart', 'NameNumPart', 'NamePart')

    def isNum(self):
        return True
    def isAlpha(self):
        return False

# separator for name groups
class NameSep(NameParsed):
    """
    the MayaName NameGroup separator : one or more underscores

        Rule : NameSep = r'_+'

        Component Of: `MayaName`
    """
    _parser = NameSepParser
    _accepts = ('Underscore',)

    @classmethod
    def default(cls):
        return Token('_', type='Underscore', pos=0)
    def reduced(self):
        """ Reduce multiple underscores to one """
        return NameSep()

# a short Maya name without namespaces or attributes
class MayaName(NameParsed):
    """
    The most basic Maya Name : several name groups separated by one or more underscores,
    starting with a NameHead or one or more underscore, followed by zero or more NameGroup

        Rule : MayaName = (`NameSep` * `NameAlphaGroup`) | (`NameSep` + `NameNumGroup`)  ( `NameSep` `NameGroup` ) * `NameSep` *

        Composed Of: `NameSep`, `NameAlphaGroup`, `NameNumGroup`, `NameGroup`

        Component Of: `Namespace`, `MayaShortName`, `Attribute`
    """

    _parser = MayaNameParser
    _accepts = ('NameAlphaGroup', 'NameNumGroup', 'NameGroup', 'NameSep')

    @property
    def parts(self):
        """ All groups of that name, including separators """
        return self.sub
    @property
    def groups(self):
        """ All groups of that Maya name, skipping separators """
        result = []
        for s in self.parts :
            if not isinstance(s, NameSep) :
                result.append(s)
        return tuple(result)
    @property
    def first(self):
        """ First group of that Maya name """
        if self.groups :
            return self.groups[0]
    @property
    def last(self):
        """ Last group of that Maya name """
        if self.groups :
            return self.groups[-1]
    @property
    def tail(self):
        """ The tail (trailing numbers if any) of that Maya Name """
        if self.groups :
            return self.groups[-1].tail
    def reduced(self):
        """ Reduces all separators in thet Maya Name to one underscore, eliminates head and tail separators if not needed """
        groups = self.groups
        result = []
        if groups :
            if groups[0].isNum() :
                result.append(NameSep())
            result.append(groups[0])
            for g in groups[1:] :
                result.append(NameSep())
                result.append(g)
            return self.__class__(*result)
        else :
            return self

#    def stripNum(self):
#        """Return the name of the node with trailing numbers stripped off. If no trailing numbers are found
#        the name will be returned unchanged."""
#        try:
#            return DependNode._numPartReg.split(self)[0]
#        except:
#            return unicode(self)

    def extractNum(self):
        """Return the trailing numbers of the node name. If no trailing numbers are found
        an error will be raised."""

        return self.tail

    def nextUniqueName(self):
        """Increment the trailing number of the object until a unique name is found"""
        name = self.shortName().nextName()
        while name.exists():
            name = name.nextName()
        return name

    def nextName(self):
        """Increment the trailing number of the object by 1"""
        try:
            self.last.nextName()
        except AttributeError:
            raise "could not find trailing numbers to increment"

    def prevName(self):
        """Decrement the trailing number of the object by 1"""
        try:
            self.last.prevName()
        except AttributeError:
            raise "could not find trailing numbers to decrement"

class NamespaceSep(NameParsed):
    """
    The Maya Namespace separator : the colon ':'

        Rule : NamespaceSep = r':'

        Component Of: `Namespace`
    """
    _parser = NamespaceSepParser
    _accepts = ('Colon',)

    @classmethod
    def default(cls):
        return Token(':', type='Colon', pos=0)

class Namespace(NameParsed):
    """
    A Maya namespace name, one or more MayaName separated by ':'

        Rule : Namespace = `NamespaceSep` ? (`MayaName` `NamespaceSep`) +

        Composed Of: `NamespaceSep`, `MayaName`

        Component Of: `MayaShortName`
    """
    _parser = NamespaceParser
    _accepts = ('NamespaceSep', 'MayaName', 'Empty')

    @classmethod
    def default(cls):
        return Empty()
    @property
    def parts(self):
        """ All parts of that namespace, including separators """
        return self.sub
    @property
    def spaces(self):
        """ All different individual namespaces in that Maya namespace, skipping separators """
        result = []
        for s in self.parts :
            if not isinstance(s, NamespaceSep) :
                result.append(s)
        return tuple(result)

    def setSpace(self, index, space):
        """Set the namespace at the given index"""
        count = 0
        for i, s in enumerate(self.sub) :
            if not isinstance(s, NamespaceSep) :
                if count == index:
                    self.setSubItem(i,space)
                    return
                count+=1
        raise IndexError, "This node has %s namespaces. The given index %s is out of range" % (len(self.spaces), index)

    def pop(self, index=0):
        """Remove an individual namespace (no separator). An index of 0 (default) is the shallowest (leftmost) in the list"""
        index*2
        sub = list(self.sub)
        # remove both MayaName and NamespaceSep
        res1 = str(sub.pop(index))
        res2 = sub.pop(index)
        self._sub = tuple(sub)
        if index < 0:
            return res2
        return res1

    def append(self, namespace):
        """Append a namespace. Can include separator and multiple namespaces. The new namespace will be the shallowest (leftmost) namespace."""
        if not namespace.endswith(':'): namespace += ':'
        newparts = list(Namespace(namespace).parts)
        sub = list(self.sub)
        self._sub = tuple( newparts +sub)

    @property
    def separator(self):
        return NamespaceSep()
    @property
    def path(self):
        """ All nested namespaces in that Maya namespace """
        if self.isAbsolute() :
            result = [self.__class__(self.separator, self.first)]
        else :
            result = [self.__class__(self.first)]
        for s in self.spaces[1:] :
            result.append(result[-1]+self.separator+s)
        return tuple(result)
    @property
    def space(self):
        """ Last namespace of the individual namespaces """
        return self.spaces[-1]
    @property
    def parents(self):
        """ All the nested namespaces names (full) in the namespace but the last, starting from last up """
        if len(self.path) > 1 :
            return tuple(reversed(self.path[:-1]))
        else :
            return ()
    @property
    def parent(self):
        """ All the individual namespaces in the namespace but the last, starting from last up, without separators """
        if self.parents :
            return self.parents[0]
    @property
    def first(self):
        """ First individual namespace of that namespace """
        try:
            return self.spaces[0]
        except :
            pass
    @property
    def last(self):
        """ Last individual namespace in that namespace """
        try:
            return self.spaces[-1]
        except :
            pass

    def isAbsolute(self):
        """ True if this namespace is an absolute namespace path (starts with ':') """
        if self.parts :
            return isinstance(self.parts[0], NamespaceSep)
        else :
            return False

class MayaShortName(NameParsed):
    """
    A short node name in Maya, a Maya name, possibly preceded by a Namespace

        Rule : MayaShortName = `Namespace` ? `MayaName`

        Composed Of: `Namespace`, `MayaName`

        Component Of: `MayaNodePath`
    """
    _parser = MayaShortNameParser
    _accepts = ('Namespace', 'MayaName')

    @property
    def parts(self):
        """ All parts of that namespace, including separators """
        return self.sub

    def getBaseName(self):
        "Get the short node name of the object"
        return self.sub[-1]
    def setBaseName(self, name):
        """Set the name of the object.  Should not include namespace"""
        return self.setSubItem(-1, name)
    basename = property( getBaseName, setBaseName, doc=""" The short node name without any namespace of the Maya short object name """ )

    def addPrefix(self, prefix):
        """Add a prefix to the node name. This must produce a valid maya name (no separators allowed)."""
        self.setBaseName( prefix + str(self.getBaseName()) )

    def addSuffix(self, suffix):
        """Add a suffix to the node name. This must produce a valid maya name (no separators allowed)."""
        self.setBaseName( str(self.getBaseName()) + suffix )

    def getBaseNamespace(self):
        "Get the namespace for the current node"
        # if isinstance(self.parts[0], Namespace) :
        #    return self.parts[0]
        return self.sub[0]

    def setNamespace(self, namespace):
        "Set the namespace. The provided namespace may be nested and should including a trailing colon unless it is empty."""
        self.setSubItem(0, namespace)
    namespace = property( getBaseNamespace, setNamespace, doc=""" The namespace name (full) of the Maya short object name """ )


    def isAbsoluteNamespace(self):
        """ True if this object is specified in an absolute namespace """
        if self.namespace :
            return self.namespace.isAbsolute()
        else :
            return False
#    @property
#    def groups(self):
#        """ All parts of that name group, skipping separators """
#        result = []
#        for s in self.parts :
#            if not isinstance(s, NameSep) :
#                result.append(s)
#        return tuple(result)
#    @property
#    def parts(self):
#        """ All parts of that maya short name, that is a possible namespace and node name """
#        return self.sub
    @property
    def first(self):
        """ All parts of that name group """
        return self.parts[0]
    @property
    def last(self):
        """ All parts of that name group """
        return self.parts[-1]

class DagPathSep(NameParsed):
    """
    The Maya long names separator : the pipe '|'

        Rule : DagPathSep = r'\|'

        Component Of: `MayaNodePath`
    """
    _parser = DagPathSepParser
    _accepts = ('Pipe',)

    @classmethod
    def default(cls):
        return Token('|', type='Pipe', pos=0)

class MayaNodePath(NameParsed):
    """
    A node name in Maya, one or more MayaShortName separated by DagPathSep, with an optional leading DagPathSep

        Rule : MayaNodePath = `DagPathSep` ? `MayaShortName` (`DagPathSep` `MayaShortName`) *

        Composed Of: `DagPathSep`, `MayaShortName`

        Component Of: `Component`, `NodeAttribute`

    Example
        >>> import pymel.util.nameparse as nameparse
        >>> obj = nameparse.parse( 'group1|pCube1|pCubeShape1' )
        >>> obj.setNamespace( 'foo:' )
        >>> print obj
        foo:group1|foo:pCube1|foo:pCubeShape1
        >>> print obj.parent
        foo:group1|foo:pCube1
        >>> print obj.node
        foo:pCubeShape1
        >>> print obj.node.basename
        pCubeShape1
        >>> print obj.node.namespace
        foo:

    """

#    class _parser(DagPathSepParser, MayaShortNameParser):
#        """ a Parser for Maya node name, an optional leading DagPathSep followed by one or more
#            MayaShortName separated by DagPathSep """
#
#        start = 'MayaNodePath'
#
#        def p_node_concat(self, p) :
#            ''' MayaNodePath : MayaNodePath DagPathSep MayaShortName '''
#            p[0] = p[1] + MayaNodePath(p[2], p[3])
#        def p_node(self, p) :
#            ''' MayaNodePath : DagPathSep MayaShortName
#                                    | MayaShortName '''
#            if len(p) == 3 :
#                p[0] = MayaNodePath(p[1], p[2])
#            else :
#                p[0] = MayaNodePath(p[1])

    _parser = MayaNodePathParser
    _accepts = ('DagPathSep', 'MayaShortName')

    @property
    def parts(self):
        """ All parts of that node name, including separators """
        return self.sub
    @property
    def nodes(self):
        """ All the short names in the dag path including the last, without separators """
        result = []
        for p in self.parts :
            if not isinstance(p, DagPathSep) :
                result.append(p)
        return tuple(result)

    def shortName(self):
        """ The last short name of the path """
        return self.nodes[-1]
    node = property( shortName )

    @property
    def separator(self):
        return DagPathSep()
    @property
    def nodePaths(self):
        """ All the long names in the dag path including the last"""
        if self.isAbsolute() :
            result = [self.__class__(self.separator, self.first)]
        else :
            result = [self.__class__(self.first)]
        for s in self.nodes[1:] :
            result.append(result[-1]+self.separator+s)
        return tuple(result)
    @property
    def parents(self):
        """ All the dags in the dag hierarchy above the last node, starting from last up """
        if len(self.nodes) > 1 :
            return tuple(reversed(self.nodePaths[:-1]))
        else :
            return ()
    @property
    def parent(self):
        """ Parent of the last node in the dag hierarchy """
        if self.parents :
            return self.parents[0]
    @property
    def first(self):
        """ First node name of that dag path name (root of the path) """
        return self.nodes[0]
    @property
    def root(self):
        """ First node name of that dag path name (root of the path) """
        return self.nodes[0]
    @property
    def last(self):
        """ Last node name of that dag path name (leaf of the path, equivalent to self.node) """
        return self.nodes[-1]

    def addPrefix(self, prefix):
        """Add a prefix to all nodes in the path. This must produce a valid maya name (no separators allowed)."""
        for node in self.nodes:
            node.setBaseName( prefix + str(node.getBaseName()) )

    def addSuffix(self, suffix):
        """Add a suffix to all nodes in the path. This must produce a valid maya name (no separators allowed)."""
        for node in self.nodes:
            node.setBaseName( str(node.getBaseName()) + suffix )

    def setNamespace(self, namespace):
        "Set the namespace for all nodes in this path. The provided namespace may be nested and should including a trailing colon unless it is empty."""
        for node in self.nodes:
            node.setNamespace(namespace)

    def addNamespace(self, namespace):
        "Append the namespace for all nodes in this path."""
        for node in self.nodes:
            node.namespace.append(namespace)

    def popNamespace(self, index=0):
        """Remove an individual namespace (no separator) from all nodes in this path. An index of 0 (default) is the shallowest (leftmost) in the list.
        Returns a tuple containing the namespace popped from each node in the path or None if the node had no namespaces."""
        result =[]
        for node in self.nodes:
            try:
                result.append( node.namespace.pop(index) )
            except IndexError:
                result.append( None )
        return tuple(result)

    def popNode(self,index=-1):
        """Remove a node from the end of the path"""
        result = []
        parts = list(self.sub)
        index *= 2
        if index < 0 or isinstance( parts[0], DagPathSep): index += 1

        if len(parts) <= 2:
            raise ValueError, "No more objects left to remove"
        result1 = parts.pop(index)
        result2 = parts.pop(index)
        self._sub = tuple(parts)
        return result1

    def addNode(self, node):
        """Add a node to the end of the path"""
        parts = list(self.sub)
        parts.extend( [ DagPathSep(), MayaShortName(node)] )
        self._sub = tuple(parts)

    def isShortName(self):
        """ True if this object node is specified as a short name (without a path) """
        return len(self.nodes) == 1
    def isDagName(self):
        """ True if this object is specified including one or more dag parents """
        return len(self.nodes) > 1
    def isLongName(self):
        """ True if this object is specified as an absolute dag path (starting with '|') """
        return isinstance(self.parts[0], DagPathSep)
    isAbsolute = isLongName

class AttrSep(NameParsed):
    """
    The Maya attribute separator : the dot '.'

        Rule : AttrSep = r'\.'

        Component Of: `Component`, `AttributePath`, `NodeAttribute`
    """
    _parser = DagPathSepParser
    _accepts = ('Dot',)

    @classmethod
    def default(cls):
        return Token('.', type='Dot', pos=0)

class NameIndex(NameParsed):
    """
    An index specification for an attribute or a component index, in the form [<int number>]

        Rule : NameIndex = r'\[[0-9]+\]'

        Component Of: `Attribute`
    """
    _parser = NameIndexParser
    _accepts = ('Index',)

    # to allow initialization from a single int
    def __new__(cls, *args, **kwargs):
        if len(args) == 1 and isinstance(args[0], int) :
            nargs = [Token(u"[%s]" % args[0], type='Index', pos=0)]
        else :
            nargs = list(args)
        return super(NameIndex, cls).__new__(cls, *nargs, **kwargs)

    @property
    def value(self):
        """ Index of that node attribute name """
        return int(self.strip("[]"))

class NameRangeIndex(NameParsed):
    """
    An index specification for an attribute or a component index, in the form::
        [<optional int number>:<optional int number>]

        Rule : NameIndex = r'\[[0-9]*:[0-9]*\]'


    """
    _parser = NameRangeIndexParser
    _accepts = ('RangeIndex',)

    @classmethod
    def default(cls):
        return Token(u"[:]", type='RangeIndex', pos=0)
    # to allow initialization from one or two int
    def __new__(cls, *args, **kwargs):
        if len(args) == 1 and isinstance(args[0], int) :
            nargs = [Token(u"[%s:]" % args[0], type='RangeIndex', pos=0)]
        elif len(args) == 2 and isinstance(args[0], int) and isinstance(args[1], int) :
            nargs[Token(u"[%s:%s]" % (args[0], args[1]), type='RangeIndex', pos=0)]
        else :
            nargs = list(args)
        return super(NameIndex, cls).__new__(cls, *nargs, **kwargs)

    @property
    def start(self):
        """ start of that component index range """
        return self.bounds[0]
    @property
    def end(self):
        """ end (inclusive) of that component index range """
        return self.bounds[1]
    @property
    def bounds(self):
        """ start and end bounds (inclusive) of that component index range """
        s =  self.strip("[]").split(":")
        r = [None, None]
        if s[0] :
            r[0] = int(s[0])
        if s[1] :
            r[1] = int(s[1])
        return tuple(r)
    @property
    def range(self):
        """ Python styled range (start and exclusive end) of that component index range """
        s =  self.strip("[]").split(":")
        r = [None, None]
        if s[0] :
            r[0] = int(s[0])
        if s[1] :
            r[1] = int(s[1]) + 1
        return tuple(r)

# components

#class NodeComponentName(NameParsed):
#    """ A Maya component name of any of the single, double or triple indexed kind """
#    _parser = NodeComponentNameParser
#    _accepts = ('MayaName', 'NameIndex', 'NameRangeIndex')
#
#class NodeSingleComponentName(Component):
#    _parser = NodeSingleComponentNameParser
#    _accepts = ('MayaName', 'NameIndex', 'NameRangeIndex')
#
#class NodeDoubleComponentName(Component):
#    _parser = NodeDoubleComponentNameParser
#    _accepts = ('MayaName', 'NameIndex', 'NameRangeIndex')
#
#class NodeTripleComponentName(Component):
#    _parser = NodeTripleComponentNameParser
#    _accepts = ('MayaName', 'NameIndex', 'NameRangeIndex')
#
#
class Component(NameParsed):
    """
    A Maya component name of any of the single, double or triple indexed kind

        Rule : Component = SingleComponentName | DoubleComponentName | TripleComponentName

        Component Of: `MayaObjectName`
    """
    _parser = ComponentNameParser
    _accepts = ('MayaNodePath', 'AttrSep', 'NodeComponentName')
#
#class SingleComponentName(Component):
#    """ A Maya single component name, in the form node name . component
#        Rule : SingleComponentName = MayaNodePath AttrSep NodeSingleComponentName """
#    _parser = SingleComponentNameParser
#    _accepts = ('MayaNodePath', 'AttrSep', 'NodeSingleComponentName')
#
#class DoubleComponentName(Component):
#    """ A Maya double component name, in the form node name . component
#        Rule : DoubleComponentName = MayaNodePath AttrSep NodeDoubleComponentName """
#    _parser = DoubleComponentNameParser
#    _accepts = ('MayaNodePath', 'AttrSep', 'NodeDoubleComponentName')
#
#class TripleComponentName(Component):
#    """ A Maya triple component name, in the form node name . component
#        Rule : TripleComponentName = MayaNodePath AttrSep NodeTripleComponentName """
#    _parser = TripleComponentNameParser
#    _accepts = ('MayaNodePath', 'AttrSep', 'NodeTripleComponentName')

# Decided to avoid the API denomination where attributes exist on nodes and a specific node+attribute association
# is called a plug as most scripting people are used to calling both attributes ?

class Attribute(NameParsed):
    """
    The name of a Maya attribute on a Maya node, a MayaName with an optional NameIndex

        Rule : Attribute = `MayaName` `NameIndex` ?

        Composed Of: `MayaName`, `NameIndex`

        Component Of: `AttributePath`
    """
    _parser = NodeAttributeNameParser
    _accepts = ('MayaName', 'NameIndex')

    @property
    def parts(self):
        """ All groups of that name, including separators """
        return self.sub
    @property
    def name(self):
        """ name(without index) of that node attribute name """
        return self.parts[0]
    @property
    def bracketedIndex(self):
        """ Index of that node attribute name """
        if len(self.parts) > 1 :
            return self.parts[-1]
    @property
    def index(self):
        """ Int value of the index of that node attribute name """
        if self.bracketedIndex :
            return self.bracketedIndex.value

    def isCompound(self): return False

class AttributePath(NameParsed):
    """
    The full path of a Maya attribute on a Maya node, as one or more AttrSep ('.') separated Attribute

        Rule : AttributePath = ( `Attribute` `AttrSep` ) * `Attribute`

        Composed Of: `Attribute`, `AttrSep`

        Component Of: `NodeAttribute`
    """



    _parser = NodeAttributePathParser
    _accepts = ('AttrSep', 'Attribute')

    @property
    def parts(self):
        """ All parts of that node attribute path name, including separators """
        return self.sub
    @property
    def attributes(self):
        """ All the node attribute names in that node attribute path, including the last, without separators """
        result = []
        for p in self.parts :
            if not isinstance(p, AttrSep) :
                result.append(p)
        return tuple(result)

    @property
    def separator(self):
        return AttrSep()
    @property
    def path(self):
        """ All nested namespaces in that Maya namespace """
        result = [self.__class__(self.separator, self.first)]
        for s in self.attributes[1:] :
            result.append(result[-1]+self.separator+s)
        return tuple(result)
    @property
    def parents(self):
        """ All the node attributes names (full) in the attribute path above the last node attribute name, starting from last up """
        if len(self.path) > 1 :
            return tuple(reversed(self.path[:-1]))
        else :
            return ()
    @property
    def parent(self):
        """ Parent of the last node attribute name in the path """
        if self.parents :
            return self.parents[0]
    @property
    def first(self):
        """ First node attribute name of that node attribute path (root of the path) """
        return self.attributes[0]
    @property
    def last(self):
        """ Last node attribute name of that node attribute path (leaf of the path, equivalent to self.attribute) """
        return self.attributes[-1]

    def isCompound(self):
        return len(self.attributes) > 1

class NodeAttribute(NameParsed):
    """
    The name of a Maya node and attribute (plug): a MayaNodePath followed by a AttrSep and a AttributePath

        Rule : NodeAttribute = `MayaNodePath` `AttrSep` `AttributePath`

        Composed Of: `MayaNodePath`, `AttrSep`, `AttributePath`

        Component Of: `MayaObjectName`


        >>> nodeAttr = NodeAttribute( 'persp|perspShape.focalLength' )
        >>> nodeAttr.attributes
        (Attribute('focalLength', 17),)
        >>> nodeAttr.nodePath
        MayaNodePath('persp|perspShape', 0)
        >>> nodeAttr.shortName()
        NodeAttribute('perspShape.focalLength', 0)
        >>>
        >>> nodeAttr2 = NodeAttribute( 'persp.translate.tx' )
        >>> nodeAttr2.attributes
        (Attribute('translate', 6), Attribute('tx', 16))

    """
    _parser = AttributeNameParser
    _accepts = ('MayaNodePath', 'AttrSep', 'AttributePath')

    @property
    def parts(self):
        """ All parts of that attribute name, including separators """
        return self.sub
#    @property
#    def groups(self):
#        """ All groups of that attribute name, ie a node name and a node attribute name """
#        return (self.parts[0], self.parts[2])
    @property
    def separator(self):
        return AttrSep()
    @property
    def nodePath(self):
        """The node part of the plug"""
        return self.parts[0]

    @property
    def attribute(self):
        """The attribute part of the plug"""
        attr = self.parts[2]
        if not attr.isCompound():
            return attr.last
        return attr

    def shortName(self):
        """Just the node and attribute without the full dag path. Returns a copy."""
        new = self.copy()
        for i in range( len(new.nodePath.nodes)-1 ):
            new.nodePath.popNode(0)
        return new

    @property
    def attributes(self):
        """ All the node attribute names in that node attribute path, including the last, without separators """
        attr = self.attribute
        if isinstance( attr, Attribute ):
            return (attr,)
        else:
            return self.attribute.attributes

    def popNode(self):
        """Remove a node from the end of the path, preserving any attributes (Ex. pCube1|pCubeShape1.width --> pCube1.width)."""
        self.nodePath.popNode()

#    @property
#    def first(self):
#        """ Equivalent to self.node """
#        return self.groups[0]
#    @property
#    def last(self):
#        """  Equivalent to self.attribute """
#        return self.groups[2]


# finally a generic catch-all
class MayaObjectName(NameParsed):
    """
    An object name in Maya, can be a dag object name, a node name,
    an plug name, a component name or a ui name

        Rule : MayaObjectName = `MayaNodePath` | `NodeAttribute` | `Component`

        Composed Of: `MayaNodePath`, `NodeAttribute`, `Component`
    """
    _parser = MayaObjectNameParser
    _accepts = ('MayaNodePath', 'NodeAttribute')

    @property
    def object(self):
        """ The actual Maya object name (node, attribute or component) it encapsulate """
        return self.sub[0]
    @property
    def type(self):
        """ What kind of Maya object is it, a node, an attribute or a component """
        return type(self.object)
    @property
    def parts(self):
        """ All parts of that object name, including separators """
        return self.object.parts

    @property
    def nodes(self):
        """ All the short names in the dag path including the last, without separators """
        return self.object.node.nodes

    @property
    def node(self):
        """ The full path of the node"""
        if self.isNodeName() :
            return self.object
        else :
            return self.object.node

    @property
    def attributes(self):
        """ All the node attribute names in that node attribute path, including the last, without separators """
        return self.object.attribute.attributes

    @property
    def attribute(self):
        """ The attribute (full) name for a NodeAttribute (node.attribute) name """
        if self.isAttributeName() :
            return self.object.attribute
    @property
    def component(self):
        """ The component name for a Component (node.component) name """
        if self.isComponentName() :
            return self.object.component

    def isNodeName(self):
        """ True if this dag path name is absolute (starts with '|') """
        return self.type == MayaNodePath
    def isAttributeName(self):
        """ True if this object is specified including one or more dag parents """
        return self.type == NodeAttribute
    def isComponentName(self):
        """ True if this object is specified as an absolute dag path (starting with '|') """
        return self.type == Component

# Empty special NameParsed class
class Empty(NameParsed):
    _parser = EmptyParser
    _accepts = ()

    @classmethod
    def default(cls):
        return ''


process()

#print "end of normal defs here"

# Current module
_thisModule = __import__(__name__, globals(), locals(), ['']) # last input must included for sub-modules to be imported correctly
#_thisModule = __import__(__name__)
#print "object _thisModule built"
#print _thisModule
#print dir(_thisModule)


#print "Module %s dynamically added %d Token classes" % (__file__, _addedTokenClasses)
#print dir(_thisModule)




def getBasicPartList( name ):
    """
    convenience function for breaking apart a maya object to the appropriate level for pymel name parsing

        >>> getBasicPartList('thing|foo:bar.attr[0].child')
        [MayaNodePath('thing|foo:bar', 0), MayaName('attr', 14), NameIndex('[0]', 18), MayaName('child', 22)]
    """
    partList = []
    def getParts( obj ):
        try:
            for i, x in enumerate(obj.parts):
                #print "part", i, repr(x)
                if isinstance( x, MayaNodePath) or isinstance( x, MayaName ) or isinstance( x, NameIndex ):
                    partList.append(x)
                else:
                    getParts(x)
        except AttributeError:
            #print "deadend", repr(obj)
            pass

    getParts( MayaObjectName(name) )
    return partList

def parse( name ):
    """main entry point for parsing a maya node name"""
    return MayaObjectName(name).object

# restrict visibility to NameParsed classes :
# __all__ = ParsedClasses().keys()
# print "nameparse.py exporting: ", __all__
#print "end here"
#print ParsedClasses()
#print ParserClasses()

# testing

def _decomposeGroup(name, ident=0):
    tab = "\t"*ident
    print tab+"group:%s (%r)" % (name, name)
    print tab+"[%s-%s] parts:" % (name.first, name.last), " ".join(name.parts)
    print tab+"tail:", name.tail
    print tab+"is ok for head:", name.isAlpha()

def _decomposeName(name, ident=0):
    tab = "\t"*ident
    print tab+"name: %s (%r)" % (name, name)
    print tab+"[%s-%s] parts: " % (name.parts[0], name.parts[-1]), " ".join(name.parts)
    print tab+"[%s-%s] groups: " % (name.first, name.last), " ".join(name.groups)
    print tab+"tail: ", name.tail
    print tab+"reduced: ", name.reduced()
    for group in name.groups :
        _decomposeGroup(group, ident=ident+1)

def _decomposeNamespace(name, ident=0):
    tab = "\t"*ident
    print tab+"namespace: %s (%r)" % (name, name)
    if name :
        print tab+"[%s-%s] parts: " % (name.parts[0], name.parts[-1]), " ".join(name.parts)
        print tab+"separator: %s" % name.separator
        print tab+"[%s-%s] name spaces:" % (name.first, name.last), " ".join(name.spaces)
        print tab+"space: ", name.space
        print tab+"parent: ", name.parent
        print tab+"path: ", " ".join(name.path)
        print tab+"parents: ", " ".join(name.parents)
        print tab+"is absolute:", name.isAbsolute()
        for space in name.spaces :
            _decomposeName(space, ident=ident+1)

def _decomposeShortName(name, ident=0):
    tab = "\t"*ident
    print tab+"short name: %s (%r)" % (name, name)
    print tab+"[%s-%s] parts: " % (name.first, name.last), " ".join(name.parts)
    print tab+"namespace: %s" % name.namespace
    print tab+"name: %s" % name.name
    print tab+"is absolute namespace: ", name.isAbsoluteNamespace()
    _decomposeNamespace(name.namespace, ident=ident+1)
    _decomposeName(name.name, ident=ident+1)

def _decomposeNodeName(name, ident=0) :
    tab = "\t"*ident
    print tab+"node name: %s (%r)" % (name, name)
    print tab+"[%s-%s] parts: " % (name.parts[0], name.parts[-1]), " ".join(name.parts)
    print tab+"separator: %s" % name.separator
    print tab+"[%s-%s] nodes: " % (name.first, name.last), " ".join(name.nodes)
    print tab+"node: ", name.node
    print tab+"parent: ", name.parent
    print tab+"path: ", " ".join(name.path)
    print tab+"parents: ", " ".join(name.parents)
    print tab+"is short name: ", name.isShortName()
    print tab+"is dag name: ", name.isDagName()
    print tab+"is long name: ", name.isLongName()
    for node in name.nodes :
        _decomposeShortName(node, ident=ident+1)

def _decomposeNodeAttributeName(name, ident=0) :
    tab = "\t"*ident
    print tab+"node attribute name: %s (%r)" % (name, name)
    print tab+"[%s-%s] parts: " % (name.parts[0], name.parts[-1]), " ".join(name.parts)
    print tab+"name: ", name.name
    print tab+"index: %s" % name.index
    print tab+"indexValue: %s" % name.indexValue
    _decomposeName(name.name, ident=ident+1)

def _decomposeNodeAttributePathName(name, ident=0) :
    tab = "\t"*ident
    print tab+"node attribute path name: %s (%r)" % (name, name)
    print tab+"[%s-%s] parts: " % (name.parts[0], name.parts[-1]), " ".join(name.parts)
    print tab+"separator: %s" % name.separator
    print tab+"[%s-%s] attributes: " % (name.first, name.last), " ".join(name.attributes)
    print tab+"attribute: ", name.attribute
    print tab+"parent: ", name.parent
    print tab+"path: ", " ".join(name.path)
    print tab+"parents: ", " ".join(name.parents)
    for attr in name.attributes :
        _decomposeNodeAttributeName(attr, ident=ident+1)


def _decomposeAttributeName(name, ident=0) :
    tab = "\t"*ident
    print tab+"attribute name: %s (%r)" % (name, name)
    print tab+"[%s-%s] parts: " % (name.parts[0], name.parts[-1]), " ".join(name.parts)
    print tab+"separator: %s" % name.separator
    print tab+"node: ", name.node
    print tab+"attribute: ", name.attribute
    _decomposeNodeName(name.node, ident=ident+1)
    _decomposeNodeAttributePathName(name.attribute, ident=ident+1)

def _decomposeObjectName(name, ident=0) :
    tab = "\t"*ident
    print tab+"That object name is a %s" % name.type.__name__
    print tab+"object: %s (%r)" % (name.object, name.object)
    print tab+"[%s-%s] parts: " % (name.parts[0], name.parts[-1]), " ".join(name.parts)

    print tab+"node: ", name.node
    print tab+"attribute (if any): ", name.attribute
    print tab+"component (if any): ", name.component

    if name.isNodeName() :
        _decomposeNodeName(name.object, ident=ident+1)
    elif name.isAttributeName() :
        _decomposeAttributeName(name.object, ident=ident+1)
    elif name.isComponentName() :
        _decomposeComponentName(name.object, ident=ident+1)
    else :
        raise ValueError, "type should be MayaNodePath, NodeAttribute or Component"

def _test (expr) :
    """ Tests the name parsing of the string argument expr and displays results """

    try:
        # name = MayaNodePath(expr)
        name = MayaObjectName(expr)
    except NameParseError, e:
        print "NameParseError:", e
        try :
            print "tokens"
            for t in name.tokens :
                print repr(t)
        except :
            pass
    else:
        print "="*80
        print "full name:%s (%r)" % (name, name)
        print "is valid:", name.isValid()
        _decomposeObjectName(name)
        print "="*80

def _itest ():
    """ Inerractive name parsing test, enter a name and see result decomposition """

    print "Interractive Name Parsing Test"
    while True:
        expr = raw_input("> ")
        if not expr: break
        _test(expr)





if __name__ == '__main__' :
    # test('SPACE:pre_someMaya12Name10_12')
    # interractive test for names parsing
    _itest()





########NEW FILE########
__FILENAME__ = objectParser
"""
.. classtree:: ProxyUni

.. dotgraph::

    main -> parse -> execute;
    main -> init;
    main -> cleanup;
    execute -> make_string;
    execute -> printf
    init -> make_string;
    main -> printf;
    execute -> compare;

"""

import re, inspect, sys, os, tempfile
import types
try:
    import external.ply.lex as lex
    import external.ply.yacc as yacc
except ImportError:
    import ply.lex as lex
    import ply.yacc as yacc

#from namedtuple import namedtuple
from common import capitalize, uncapitalize
import warnings
from arguments import *
from utilitytypes import *




# increase from 0 to 1 or 2 for more debug feedback
def verbose() :
    return 0

def currentfn() :
    try :
        return sys._getframe(1).f_code.co_name
    except :
        pass


class NameParseError(Exception):
    pass

class ParsingWarning(UserWarning):
    pass



ProxyUni = proxyClass( unicode, 'ProxyUni', module=__name__, dataFuncName='compileName', remove=['__getitem__', '__doc__']) # 2009 Beta 2.1 has issues with passing classes with __getitem__

# For parsed objects, Token or upper level constructs
class Parsed(ProxyUni):

    _parser = None
    _accepts = ()
    _name = None
    classes = {}

#class Parsed(unicode):
#
#    _parser = None
#    _accepts = ()

    @classmethod
    def accepts(cls, other) :
        """ Checks if this Parsed class can accept another object as a subpart without reparsing """
        if isinstance(other, Parsed) :
            for t in cls._accepts :
                if t == other.__class__.__name__ :
                    return True
        return False

    def compileName( self ):
        newname = u''
        partList = []
        def getParts( obj, newname ):
            try:
                for x in obj.parts:
                    #print repr(x)
                    newname = getParts(x, newname)
            except AttributeError:
                #print "DEAD", repr(obj)
                newname += unicode(obj._name)
            return newname
        self._name = getParts( self, newname )
        return self._name

    @classmethod
    def getParserClass(cls, parsername ):
        pass

    # init class attributes, all objects of a Parsed class share the same parser
    # TODO : check if it can be a problem with multithreading ? In that case we'll need a parser per instance
    @classmethod
    def classparserbuild(cls, **kwargs):
        """ Inits class Parser, all instances of a Parsed class share the same yacc parser object """

        clsname = cls.__name__
        try :
            # class declaration specifies a parser class
            parser = cls._parser
        except :
            # default rule
            parsername = cls.__name__+"Parser"
            parser = Parser.classes.get(parsername, None)
            cls._parser = parser
            warnings.warn ("could not read '_parser' for %s, building Parser name %s from Parsed class name %s" % (cls, parsername, clsname), UserWarning)

        if parser is not None :
            # if parser hasn't been built yet, build it
            if not isinstance(parser, Parser) :
                # parser is a class
                if inspect.isclass(parser) :
                    parsername = parser.__name__
                    if not issubclass (parser, Parser):
                        raise ValueError, "Parser %s specified in Parsed class %s is not a Parser class" % (parsername, cls.__name__)
                # parser is a string
                elif parser in Parser.classes :
                    parsername = parser
                    parser = Parser.classes[parsername]
                else :
                    raise ValueError, "Invalid Parser specification %r in Parsed class %s" % (parser, cls.__name__)

                # build class Parser, replace class _parser by the Parser instance object

                # print "Building parser instance of Parser %s for Parsed class: %s" % (parser, cls.__name__)
                # replace _parser attribute (which held a Parser class or classname) with parser class instance
                cls._parser = parser()
                cls._parser.build(**kwargs)
                # return cls._parser
        else :
            raise TypeError, "Parsed class %s does not define a parser, check declarations" % cls.__name__

    @classmethod
    def classparse(cls, data, **kwargs):
        clsname = cls.__name__
        data = unicode(data)
        debug = kwargs.get('debug', verbose())
        errmsg = ''
        # print "Calling parser %s with debug %s" % (cls.classparser(), debug)
        result = cls.classparser().parse(data, debug=debug)
        if cls.classparser().errorcount :
            # use error or warning ?
            errmsg = "cannot parse '%s' to a valid %s, %d parser errors" % (data, clsname, cls.classparser().errorcount)
            isValid = False
        elif not isinstance(result, cls) :
            # parse successful but returned a different class than exected
            errmsg = "parsing '%s' is valid, but as a %s Parsed object, and not as a %s Parsed object as it was parsed against" % (data, result.__class__.__name__, clsname)
            isValid = False
        elif not result == data :
            # should return a Parsed object with the same string value as the parsed string
            errmsg = "parsing '%s' raised no error, but the resulting name is %s is different from the nput string %s " % (result, data)
            isValid = False
        else :
            # parse successful
            isValid = True

        # check for error in parsing and correct and raise a warning or raise an error
        # TODO : corrections and error handling
        if not isValid :
            # can try to auto-correct some badly formed names
            raise NameParseError, errmsg

        # position is set to position of first found Parsed object
        if (result.sub) :
            result._pos = result.sub[0].pos
        else :
            result._pos = 0

        result._valid = True
        return result

    @classmethod
    def classparser(cls):
        """ parser object for that class """
        return cls._parser

    # instance methods

    def parse(self, data, **kwargs):
        return self.__class__.classparse(data, **kwargs)

    @property
    def parser(self):
        """ parser object for that class """
        return self.__class__.classparser()
    @property
    def tokens(self ):
        """ iterates self as leaf level lexed tokens """
        for i in expandArgs(self._sub) :
            if isinstance(i, Token) :
                yield i
    @property
    def sub(self):
        """ Internally stored parsing data for this Parsed object sub parts """
        return self._sub

    def setSubItem(self, index, value):
        """ Change the value of one of the Parsed sub parts.  The new value will first be parsed as the same
        type as it is replacing."""
        cls = self._sub[index].__class__
        sublist = list(self._sub)
        sublist[index] = cls(value)
        self._sub = tuple(sublist)

    @property
    def pos(self):
        """ position of that Parsed object """
        return self._pos
    def isValid(self):
        """ Validity """
        return self._valid

    def copy(self):
        """return an new independent copy of the parsed object"""
        return self.__class__(self._sub)

    def findType(self, type):
        res = []
        for x in self.sub:
            if isinstance(x,type):
                res.append( x )
            else:
                res += x.findType(type)
        return res

    def __new__(cls, *args, **kwargs):
        """ Creation of a Parsed object from a LexToken, other Parsed of compatible type or string,
            if a string is passed it will be parsed and checked for compatibility with this Parsed type """

        debug = kwargs.get('debug', verbose())
        # type checking
        data = None
        if args :
            if len(args) == 1:
                data = args[0]
            else :
                data = tuple(args)

        # some data (when initializing from single arg) can define the type of Parsed object to be created
        ptype = None
        if data is None :
            # only authorize Empty to be built without arguments
            ptype = 'Empty'
        elif isinstance(data, lex.LexToken) :
            ptype = kwargs.get('type', data.type)
        elif isinstance(data, Parsed) :
            ptype = data.__class__
        # can override type with the keyword 'type'
        ptype=kwargs.get('type', ptype)

        if (cls is Parsed or cls is Token) : #issubclass(cls, Token) ):
            if ptype is not None :
                if verbose():
                    print "__new__ called on Parsed/Token %s with type %r" % (cls.__name__, ptype)
                newcls = Parsed.classes.get(ptype, None)
                # can only specify an existing subclass of cls
                if newcls is None :
                    raise TypeError, "Type %s does not correspond to any existing Parsed sub-class (%s does not exist)" % (ptype, cls.__name__  )
                else :
                    clsname = newcls.__name__
                if not issubclass(newcls, cls) :
                    raise TypeError, "Type %s would create a class %s that is not a sub-class of the class %s that __new__ was called on" % (ptype, clsname, cls.__name__)
            else :
                raise TypeError, "Class %s is an abstract class and can't be created directly, you must specify a valid sub-type" % (cls.__name__)
        else :
            if verbose():
                print "__new__ called on explicit class %s" % (cls.__name__)
            clsname = cls.__name__
            newcls = cls

        # print "Creating new instance of Parsed class: %r" % newcls

        # process arguments and build, check arguments compatibility with that type
        pos = None
        sub = []
        valid = False
        value = data

        #if debug : print "VALUE1", value, repr(value)

        # special case for LexToken
        if isinstance(data, lex.LexToken) :
            if issubclass(newcls, Token) :
                # from a unique lex Token, do not check if also creating a Token
                sub = []
                pos = data.lexpos
                value = data.value
                valid = True
            else :
                # build a Token from it
                value = Token(data.value, ptype=data.type, pos=data.pos)

        if data is None :
            # Tokens can have default value to allow initialization without arguments
            try :
                value = newcls.default()
                valid = True
            except :
                valid = False
        elif isinstance(data, newcls) :
            #if debug : print "IS INSTANCE", data, repr(data)
            # from a similar class, copy it
            sub = data.sub
            pos = data.pos
            valid = data.isValid()
            value = unicode(data)
        elif newcls.accepts(data) :
            #if debug : print "ACCEPTS", data, repr(data)
            # from a compatible Parsed sub class, build the sub list from it
            sub.append(data)
            pos = data.pos
            valid = data.isValid()
            value = unicode(data)
        elif isSequence(data) and not isinstance(data, basestring):
            # building from sub parts, must be of the same type and in class _accepts
            # TODO : use yacc own rules for accepts
            if data :
                valid = True
                p = 0
                for arg in data :
                    # converts LexTokens directly
                    if isinstance(arg, lex.LexToken) :
                        a = Token(arg.value, ptype=arg.type, pos=data.pos)
                    else :
                        a = arg
                    # now check if it's a suitable sub-part or derived class
                    if isinstance(a, newcls) :
                        sub += a.sub
                    elif newcls.accepts(a) :
                        sub.append(a)
                    else :
                        valid = False
                        break
                value = u"".join(map(unicode, data))
                if valid :
                    pos = sub[0].pos
                else :
                    sub = []
            else :
                value = ''
        else :
            if debug : print "REPARSE", data, repr(data)
            # reparse unless it's a Token we already know the type of
            value = unicode(data)
            if issubclass(newcls, Token) and newcls is not Token :
                sub = []
                pos = 0
                valid = True
            else :
                valid = False

        # parse if necessary
        if valid :
            # print "No reparsing necessary for a resulting value %s (%r)" % (value, value)
            strvalue = unicode(value)
        elif isinstance(value, basestring) :
            if debug :
                print "%s: Will need to reparse value %r" % (clsname, value)
            newcls.classparserbuild(debug=debug)
            if debug : print "VALUE", value, type(value)
            result = newcls.classparse(value, debug=debug)
            if debug : print "RESULT", result, type(result), isinstance(result, newcls)
            if result is not None and isinstance(result, newcls) :
                strvalue = unicode(result)
                valid = result._valid
                sub = result._sub
                pos = result._pos
                if debug : print "SUB", sub
            else :
                strvalue = ''
                valid = False
        else :
            raise TypeError, "invalid argument(s) %r, cannot be parsed to create a Parsed object of type %s" % (value, clsname)

        if valid :
            # create a unicode object with appropriate string value
            newobj =  super(Parsed, cls).__new__(newcls)
            newobj._name = strvalue
            #if debug: print "NAME", newobj, type(newobj), sub#, inspect.getmro(newobj)
            # set instance attributes
            newobj._sub = tuple(sub)
            newobj._valid = valid
            # override for pos
            pos = kwargs.get('pos', pos)
            if pos is not None :
                pos += kwargs.get('offset', 0)

            if pos is None or (isinstance(pos, int) and pos>=0) :
                newobj._pos = pos
            else :
                raise ValueError, "A Parsed pos can only be None or an unsigned int, %r invalid" % pos

        return newobj

    def __add__(self, other):
        """ p1.__add__(p2) <==> p1+p2
            if p1 and p2 are of the same Parsed type, it's equivalent to reparsing str(p1) + str(p2)
            if p2 is an accepted sub part of p1, it adds it to the sub-parts
        """
        # The Parsed _accepts defines validity
        # TODO : use yacc own rules to check validity without a full reparse
        cls = self.__class__
        selfvalid = self.isValid()
        sublist = list(self.sub)
        value = unicode(self)
        # check other's type
        if isinstance(other, cls) :
            othervalid = other.isValid()
            sublist += other.sub
        elif self.accepts(other) :
            othervalid = other.isValid()
            sublist.append(other)
        elif isinstance(other, basestring) :
            othervalid = False
        else :
            raise TypeError, "cannot add %s and %s" % (type(self), type(other))

        if selfvalid and othervalid :
            # no reparse
            result = cls(*sublist)
        else :
            # reparse
            result = cls(unicode(self)+unicode(other))

        return result

    def __repr__(self):
        return u"%s('%s', %s)" % (self.__class__.__name__, self, self.pos)

# Parsers, all parser must derive from the Parser class

class Parser(object):
    """ Abstract Base class for all name parsers """
    classes = {}
    def __new__(cls, *args, **kwargs):
        # this class is an abstract base class for all Parser classes, cannot be built directly

        if cls is Parser :
            # type argument can be the name of a Parser class or an instance of the class
            ptype=kwargs.get('type', None)
            if ptype is None :
                raise TypeError, "must specify a Parser class"
            elif isinstance(ptype, Parser) and not ptype is Parser :
                parsercls = ptype
            elif ptype in Parser.classes :
                parsercls = Parser.classes[ptype]
            else :
                raise TypeError, "invalid Parser type: %s" % ptype
        else :
            # subclasses of Parser
            parsercls = cls

#        if 'tokensDict' in parsercls.__dict__ and 'rulesDict' in parsercls.__dict__:
#            rulesDict = parsercls.rulesDict
#            tokensDict = parsercls.tokensDict
#        else:

        reserved = []
#        #reserved = [ k for k,v in parsercls.tokensDict.items() if not k.startswith( 't_') ]
#        if hasattr( parsercls, '_reserved'):
#            for k, v in parsercls._reserved.items():
#                # reserved should be a map of reserved names (as used in the code to parse) to token names (as used in PLY).
#                # as such, we only care about the PLY names, ie. the values
#                reserved.append(v)

        rulesDict, tokensDict = Parser.getRulesAndTokens( parsercls )

        tokens = tokensDict.keys()
        rules = list(rulesDict.keys())
        # Sort them by line number of declaration as it's how the yacc builder works to order rules
        # TODO : some more explicit rule order handling (when precedence isn't an option) ?
        rules.sort(lambda x,y: cmp(rulesDict[x].func_code.co_firstlineno,rulesDict[y].func_code.co_firstlineno))
        # print "sorted rules:", [(r, parsercls.rulesDict[r].func_code.co_firstlineno) for r in rules]
        rules = tuple(rules)

        parsercls.tokens = tuple( tokens + list(set(reserved)) )
        parsercls.rules = rules

        #print "%s tokens %s" % ( parsercls, parsercls.tokens )
        # class must have a start attribute for __init__, start can be None though
        # must not inherit start as parsed would not parse own class new rules
        if not 'start' in parsercls.__dict__ :
            parsercls.start = None

        # TODO : same for precedence rules
        return super(Parser, cls).__new__(parsercls, *args, **kwargs)

    def __init__(self, *args, **kwargs):
        self.errorcount = 0
        self.lexer = None
        self.parser = None

    def t_error(self,t):
        warnings.warn ("illegal character in '%s' at %i: '%s'" % (t.lexer.lexdata, t.lexpos, t.value[0]), ParsingWarning, stacklevel=1)
        self.errorcount += 1
        t.lexer.skip(1)

    def p_error(self,p):
        print "error token", p
        if p is None :
            warnings.warn ("unexpected end of file", ParsingWarning, stacklevel=1)
        else :
            warnings.warn ("syntax error in '%s' at %i: '%s'" % (p.lexer.lexdata, p.lexpos, p.value), ParsingWarning, stacklevel=1)
        self.errorcount += 1

        # Just discard the token and tell the parser it's okay.
        # yacc.errok()
        #yacc.errok(). This resets the parser state so it doesn't think it's in error-recovery mode. This will prevent an error token from being generated and will reset the internal error counters so that the next syntax error will call p_error() again.
        #yacc.token(). This returns the next token on the input stream.
        #yacc.restart(). This discards the entire parsing stack and resets the parser to its initial state.

    @staticmethod
    def getRulesAndTokens( parsercls ):
        """
        build the tokens and precedence tuples from inherited declarations.
        gather tokens and rules definition from Parser class members (own and inherited)
        """

        tokensDict = {}
        rulesDict = {}
        for name, obj in inspect.getmembers(parsercls):
            if name.startswith('t_') and name != 't_error' :

                if isinstance(obj, basestring) :
                    v = obj
                elif inspect.isfunction(obj) or inspect.ismethod(obj) :
                    v = obj.__doc__
                else :
                    raise SyntaxError, "Token definition %s defines neither a string nor a function, unable to parse" % m[0]
                k = name[2:]
                tokensDict[k] = obj
            elif name.startswith('p_') and inspect.ismethod(obj) and name != 'p_error' :
                k = name[2:]
                rulesDict[k] = obj
#            elif name == '_reserved' and isinstance(obj,dict):
#                # reserved attribute holds a list of reserved token keywords.
#                # these should only exist on
#                print "FOUND reserved!"
#                for k,v in obj.items():
#                    tokensDict[v]=None

        return rulesDict, tokensDict

    def build(self,**kwargs):
        debug = kwargs.get('debug', verbose())
        start = kwargs.get('start', self.__class__.start)
        parserspath = kwargs.get('outputdir', tempfile.gettempdir() )
        if debug :
            print "nameparse parsers path", parserspath
        method = kwargs.get('method', 'LALR')
        if debug :
            print "Build for", self.__class__.__name__
            print "tokens:"
            for t in self.__class__.tokens :
                # t is not always in tokensDict, not sure if this is bad or not...
                #print "\t%s = %r" % (t, self.__class__.tokensDict[t])
                print "\t%s" % (t)
            print "rules:"
            for t in self.__class__.rules :
                # t is not always in rulesDict, not sure if this is bad or not...
                #print "\t%s = %r" % (t, self.__class__.rulesDict[t].__doc__)
                print "\t%s" % (t)
            print "start: %s" % start

        if self.lexer is None :
            lextab=self.__class__.__name__+"_lex"
            lkwargs = {'debug':debug, 'lextab':lextab }
            self.lexer = lex.lex(object=self, **lkwargs)
        if self.parser is None :
            tabmodule=self.__class__.__name__+"_yacc_"+start
            pkwargs = {'outputdir':parserspath, 'debug':debug, 'tabmodule':tabmodule, 'start':start, 'method':method }
            self.parser = yacc.yacc(module=self, **pkwargs)

    def parse(self, data, **kwargs):
        self.errorcount = 0
        return self.parser.parse(data, lexer=self.lexer, **kwargs)

class Token(Parsed):
    """ A class for token types, allows direct initialization from a string and type without checking
        to avoid unnecessary double parse of the string """
    pass



# token parser, can directly use re
class TokenParser(Parser):
    """ Abstract base class for Token parser """
    _pattern = None
    _type = None

    def build(self,**kwargs):
        pattern = kwargs.get('pattern', self.__class__._pattern)
        try :
            self.parser = re.compile(pattern)
        except :
            raise ValueError, "cannot build Token Parser from pattern %r. you must set the _pattern attribute to a valid regular expression" % pattern

    def parse(self, data, **kwargs):
        self.errorcount = 0
        if self.parser.match(data) is not None :
            return Token(data, type=self._type, pos=0)
        else :
            warnings.warn ("%s is not matching %s pattern %r" % (data, self.__class__.__name__, self._pattern))
            self.errorcount += 1

# special purpose empty parser
class EmptyTokenParser(Parser):

    def build(self,**kwargs):
        pass

    def parse(self, data, **kwargs):
        self.errorcount = 0
        if data :
            self.errorcount = 1
        else :
            return Empty()

# derived TokenParser classes will be built for every token definition detected in Parser classes in this module

class EmptyParser(Parser):
    """ Parser for the empty production """

    start = 'Empty'
    def p_empty(self, p) :
        'Empty : '
        pass

def isParsedClass (x) :
    try :
        return issubclass(x, Parsed)
    except :
        return False
def isParserClass (x) :
    try :
        return issubclass(x, Parser)
    except :
        return False

def _printClassTree(cls):
    def _printTree(data, level):
        if isinstance(data, tuple):
            level += 1
            for d in data:
                _printTree(d, level)
        else:
            print data

    print cls
    tree = inspect.getclasstree(cls)
    print tree
    _printTree( tree )


class autoparsed(type):
    """metaclass for dramatically reducing setup syntax for simple hierarchies"""
    def __new__(mcl, classname, bases, classdict):


        newcls = super(autoparsed, mcl).__new__(mcl, classname, bases, classdict)
        module = __import__( newcls.__module__, globals(), locals(), [''] )
        #print "autoparsed", newcls

        if issubclass(newcls, Parsed):
            # find the attribute _parser, which holds the parser class for this Parsed type
            parsercls = classdict.get('_parser',None)


            if isParserClass(parsercls) or ( parsercls is None and '_rules' in classdict):

                rules = classdict.get('_rules',None)
                if rules is not None:
                    # there's no parser, but there is a set of rules. use this to create a default parser
                    if not isIterable(rules):
                        raise TypeError, "_rules attribute must be an iterable list of string rules"

                    # first add the rules to the parserdict as attributes, these will be converted to methods, below
                    parserdict = {}
                    for i, rule in enumerate(rules):
                        attrname = 'p_%s_%02d' % ( classname, i+1)
                        parserdict[ attrname ] = rule
                else:
                    # parser already exists. use it, but use __dict__, not inherited info
                    parserdict = parsercls.__dict__

                # a dictionary of updates to be made to the parser
                updatedict = {}

                # automatically set the start attribute to the name of this class
                if 'start' not in parserdict:
                    updatedict['start'] = classname

                # gather up all the tokens and rules and store them separately
                tokensDict = {}
                rulesDict = {}
                reservedDict = {}
                accepts_set= set(classdict.get('_accepts', []) )

                classNameReg = re.compile('[a-zA-Z][a-zA-Z0-9]*')
                for name, obj in parserdict.items() :
                    # print "class %s has attribute %s" % (parsercls.__name__, m)

                    # RULES
                    if name.startswith('p_') :
                        shortname = name[2:]
                        # shorthand syntax: needs to be converted to a function
                        if isinstance(obj, basestring) :
                            v = obj
                            needsWrapping = True
                        # regular syntax: already a function
                        elif inspect.isfunction(obj) or inspect.ismethod(obj) :
                            v = inspect.getdoc(obj)
                            needsWrapping = False
                        else :
                            raise SyntaxError, "Token definition %s defines neither a string nor a function, unable to parse" % name

                        # process the docstring
                        accepts = []
                        colonSplit = [ x.strip() for x in v.split(':')]
                        if len(colonSplit) == 1:
                            v = classname + ' : ' + v
                            colonSplit = [classname, colonSplit[0] ]

                        if len(colonSplit) ==2 and colonSplit[0] != '':
                            pipeSplit = [ x.strip() for x in colonSplit[1].split('|') ]
                            for grp in pipeSplit:
                                # be sure to filter out ourselves
                                accepts += [ x for x in grp.split() if classNameReg.match(x) and x!=classname ]

                        # add the classes involved in the rules
                        accepts_set.update( accepts )

                        # create the function
                        if needsWrapping:
                            def p_func(self, p):
                                p[0] = newcls( *p[1:len(p)] )
                            p_func.__name__ = name
                            p_func.__doc__ = v
                            if verbose():
                                print "overwriting %s._parser.%s with yacc function: %r" % ( classname, name, v)
                            updatedict[name] = p_func
                            rulesDict[name] = p_func
    #                        k = m[0][2:]
    #                        if k in tokensDict :
    #                            warnings.warn("Token %s redefined in Parser %s" % (k, parser), UserWarning)
    #                        tokensDict[k] = v
                        else:
                            rulesDict[name] = obj

                    # TOKENS
                    elif name.startswith('t_') and name != 't_error' :
                        shortname = name[2:]
                        if isinstance(obj, basestring) :
                            v = obj
                        elif inspect.isfunction(obj) or inspect.ismethod(obj) :
                            v = obj.__doc__
                        else :
                            raise SyntaxError, "Token definition %s defines neither a string nor a function, unable to parse" % name
                        tokensDict[name] = obj

                if verbose():
                    print "%s accepts: %s" % (newcls.__name__, list(accepts_set) )

                # find bases
                bases = []
                for parsedname in accepts_set:
                    try:
                        parsedcls = getattr( module, parsedname )
                    except AttributeError:
                        warnings.warn("Could not find a Parsed class %s in module %s.  Assuming that it is an custom token." % (parsedname, module), UserWarning)
                        continue

                    try:
                        parser = parsedcls._parser
                    except AttributeError:
                        try:
                            parser = getattr( module, parsedname + 'Parser' )
                        except AttributeError:
                            raise SyntaxError, "Cannot find parser class for parsed class %s. It should be explicitly or automatically created as %s._parser or be named %sParser" % (parsedname, parsedname, parsedname )

                    assert isinstance(parser, Parser) or (inspect.isclass(parser) and issubclass(parser, Parser)), '%s._parser is not a subclass of Parser, it is %r' % ( parsedname, parser )

                    bases.append( parser )

                # some of our bases might be subclasses of other bases.  we want the smallest list of superclasses, so weed out
                # other classes that are directly dependent on other bases
                newbases = []
                for i in bases:
                    issuperclass = False
                    #parents = inspect.getmro(i)
                    for j in bases:
                        if i in inspect.getmro(j)[1:]:
                            issuperclass = True
                            break
                    if not issuperclass:
                        newbases.append(i)

                newbases = sorted( newbases, key=lambda x: len(inspect.getmro(x)), reverse=True)

                #print "%s bases" % newcls.__name__

                for base in newbases:
                    #print base
                    #print '\t', base.tokensDict
                    #print '\t', base.rulesDict
                    tokensDict.update( base.tokensDict )
                    rulesDict.update( base.rulesDict )
#                    if hasattr(base, '_reserved'):
#                        reservedDict.update( base._reserved )

                updatedict.update( tokensDict )
                updatedict.update( rulesDict )

                    #for i, parent in enumerate(inspect.getmro(base)):
                    #    print '\t'*i, parent
                #print inspect.getclasstree(bases)
#                    for base in newbases:
#                        _printClassTree( base )

                if rules is not None:
                    #time to make the parser
                    # we use the Rules in the 'accepts' list to determine the bases of this parser class

                    # TODO : filter out bases that are superclasses of other bases: we only need one set

                    parserName = classname + 'Parser'
                    #newbases = sorted( newbases, key = lambda x: x.__name__)


                    updatedict['tokensDict'] = tokensDict
                    updatedict['rulesDict'] = rulesDict
#                    updatedict['_reserved'] = reservedDict

                    parserdict.update( updatedict )

                    # create parser class
                    parsercls = type( parserName, (Parser,), parserdict )
                    parsercls.__module__ = module.__name__
                    setattr( newcls, '_parser', parsercls)
                else:
                    # update the existing parser
                    for k, v in updatedict.iteritems():
                        setattr( parsercls, k, v )

                setattr(newcls, '_accepts', tuple(accepts_set) )

            elif issubclass( newcls, Token ):
                # a token subclass defines its regex on the '_token' attr.
                # if this attr is defined, it causes a Parser class to be created for this token, along with
                # a rule, which is named after the class
                token = classdict.get('_token',None)
                if token is None:
                    raise TypeError, "Token classes that use the autoparsed metaclass must define a _token attribute"

                #print "automatically setting up token class for %s" % newcls.__name__

                tokenBasename = classname + '_Token'
                tokenName = 't_' + tokenBasename
                ruleName = 'p_' + tokenBasename
                parserName = classname + 'Parser'

                if hasattr(token, '__name__'):
                    #print "setting token name to %s" % tokenName
                    token.__name__ = tokenName

                parserdict = {}
                parserdict[tokenName] = token

                tokensDict = {tokenName:token}

#                if hasattr(newcls, '_reserved'):
#                    print "adding _reserved to %s" % parserName
#                    parserdict['_reserved'] = newcls._reserved

                parserdict['tokensDict'] = tokensDict


                # the rule is named after the class
                doc = '''%s : %s ''' % ( classname, tokenBasename )
                #class _parser( Parser ): pass

                def rule(self, p):
                    p[0] = newcls( p[1], pos=p.lexpos(1))
                rule.__name__ = ruleName
                rule.__doc__ = doc
                parserdict[ruleName] = rule
                parserdict['rulesDict'] = {ruleName:rule}

                # create the Parser class
                print "creating parser %s" % parserName
                parsercls = type( parserName, (Parser,), parserdict )
                parsercls.__module__ = module.__name__
                #setattr( _parser, tokenName, token )
                #setattr( _parser, ruleName, rule )
                setattr( newcls, '_parser', parsercls )


        return newcls

def _getTokenPatterns(parsercls):
    tokensDict={}
    for name, obj in parsercls.__dict__.items() :
        # print "class %s has attribute %s" % (parsercls.__name__, m)
        if name.startswith('t_') and name != 't_error' :
            # strip off 't_'
            k = name[2:]
            if isinstance(obj, basestring) :
                v = obj
            elif inspect.isfunction(obj) or inspect.ismethod(obj) :
                v = obj.__doc__
            else :
                raise SyntaxError, "Token definition %s defines neither a string nor a function, unable to parse" % name
            k = name[2:]
            if k in tokensDict :
                warnings.warn("Token %s redefined in Parser %s" % (k, parser), UserWarning)
            tokensDict[k] = v
    return tokensDict

# do it
#_addedTokenClasses =_createTokenClasses(debug=verbose())

# Build a dict of all existing Parser and Parsed classes in this module
#class Parsed.classes(dict) :
#    __metaclass__ =  metaStatic


#def parsedClasses(module):
#    return dict(inspect.getmembers(module, isParsedClass))
## Stores it at import so that the inspect method isn't recalled at each query
#Parsed.classes(Parsed.classes)

#class Parser.classes(dict) :
#    __metaclass__ =  metaStatic


Parsed.classes = {}
Parser.classes = {}

#def parserClasses(module):
#    return dict(inspect.getmembers(module, isParserClass))
## Stores it at import so that the inspect method isn't recalled at each query
#Parser.classes(Parser.classes)

def process(module=None):
    """cache out a dictionary of all Parsed and Parser classes, and create token classes"""
    if module:
        # User supplied a module object.
        if isinstance(module, types.ModuleType):
            module_dict = module.__dict__
#        elif isinstance(module, _INSTANCETYPE):
#            _items = [(k,getattr(module,k)) for k in dir(module)]
#            ldict = { }
#            for i in _items:
#                ldict[i[0]] = i[1]
        else:
            raise ValueError,"Expected a module"

    else:
        # No module given.  We might be able to get information from the caller.
        # Throw an exception and unwind the traceback to get the globals

        try:
            raise RuntimeError
        except RuntimeError:
            e,b,t = sys.exc_info()
            f = t.tb_frame
            f = f.f_back           # Walk out to our calling function
            module_dict = f.f_globals    # Grab its globals dictionary

    #_createTokenClasses(ldict, debug=verbose() )

    parserDict = {}
    parsedDict = {}
    tokensDict = {}

    # gather up all tokens, parsers, and parsed
    for name, obj in module_dict.iteritems():
        if isParserClass(obj):
            parserDict[name]=obj
            tokensDict.update( _getTokenPatterns(obj) )


        # find Parsers that are stored on Parsed classes as _parser
        elif isParsedClass(obj):
            parsedDict[name]=obj
            if hasattr(obj, '_parser'):
                if isParserClass(obj._parser):
                    tokensDict.update( _getTokenPatterns(obj._parser) )

    for token in tokensDict :
        pattern = tokensDict[token]
        parsedName = token
        parserName = token+"Parser"


        if verbose() :
            print "adding class %s for token %s of pattern r'%s'" % (parserName, token, pattern)

        class ThisTokenParser(TokenParser):
            """ Token Parser stub class """
        # set the Token Parser class attributes
        ThisTokenParser.__name__ = parserName
        #ThisTokenParser.__doc__ = "Parser for token %s=%r" % (token, pattern)
        ThisTokenParser.__module__ = __name__
        ThisTokenParser._pattern = pattern
        ThisTokenParser._type = token
        # add to the module
        module_dict[parserName] = ThisTokenParser
        parserDict[parserName] = ThisTokenParser

        if verbose() :
            print "adding class %s for token %s of pattern r'%s'" % (parsedName, token, pattern)

        class ThisToken(Token):
            """ Token stub class """
        # set the Token class attributes
        ThisToken.__name__ = parsedName
        # ThisToken.__doc__ = "Parser for token %s=%r" % (token, pattern)
        ThisToken.__module__ = __name__
        ThisToken._parser = ThisTokenParser
        # add to the module
        module_dict[parsedName] = ThisToken
        parsedDict[parsedName] = ThisToken


    Parser.classes = parserDict
    Parsed.classes = parsedDict



########NEW FILE########
__FILENAME__ = path
#
# Copyright (c) 2010 Mikhail Gusarov
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#

""" path.py - An object representing a path to a file or directory.

Original author:
 Jason Orendorff <jason.orendorff\x40gmail\x2ecom>

Current maintainer:
 Jason R. Coombs <jaraco@jaraco.com>

Contributors:
 Mikhail Gusarov <dottedmag@dottedmag.net>
 Marc Abramowitz <marc@marc-abramowitz.com>
 Jason R. Coombs <jaraco@jaraco.com>
 Jason Chu <jchu@xentac.net>
 Vojislav Stojkovic <vstojkovic@syntertainment.com>

Example::

    from path import path
    d = path('/home/guido/bin')
    for f in d.files('*.py'):
        f.chmod(0755)

path.py requires Python 2.5 or later.
"""

from __future__ import with_statement

import sys
import warnings
import os
import fnmatch
import glob
import shutil
import codecs
import hashlib
import errno
import tempfile
import functools
import operator
import re

try:
    import win32security
except ImportError:
    pass

try:
    import pwd
except ImportError:
    pass

try:
    import grp
except ImportError:
    pass

################################
# Monkey patchy python 3 support
try:
    basestring
except NameError:
    basestring = str

try:
    unicode
except NameError:
    unicode = str

try:
    getcwdu = os.getcwdu
except AttributeError:
    getcwdu = os.getcwd

if sys.version < '3':
    def u(x):
        return codecs.unicode_escape_decode(x)[0]
else:
    def u(x):
        return x

o777 = 511
o766 = 502
o666 = 438
o554 = 364
################################

__version__ = '5.0'
__all__ = ['path', 'CaseInsensitivePattern']


class TreeWalkWarning(Warning):
    pass


def simple_cache(func):
    """
    Save results for the 'using_module' classmethod.
    When Python 3.2 is available, use functools.lru_cache instead.
    """
    saved_results = {}

    def wrapper(cls, module):
        if module in saved_results:
            return saved_results[module]
        saved_results[module] = func(cls, module)
        return saved_results[module]
    return wrapper


class ClassProperty(property):
    def __get__(self, cls, owner):
        return self.fget.__get__(None, owner)()


class multimethod(object):
    """
    Acts like a classmethod when invoked from the class and like an
    instancemethod when invoked from the instance.
    """
    def __init__(self, func):
        self.func = func

    def __get__(self, instance, owner):
        return (
            functools.partial(self.func, owner) if instance is None
            else functools.partial(self.func, owner, instance)
        )


class path(unicode):
    """ Represents a filesystem path.

    For documentation on individual methods, consult their
    counterparts in os.path.
    """

    module = os.path
    """ The path module to use for path operations.

    .. seealso:: :mod:`os.path`
    """

    def __init__(self, other=''):
        if other is None:
            raise TypeError("Invalid initial value for path: None")

    @classmethod
    @simple_cache
    def using_module(cls, module):
        subclass_name = cls.__name__ + '_' + module.__name__
        bases = (cls,)
        ns = {'module': module}
        return type(subclass_name, bases, ns)

    @ClassProperty
    @classmethod
    def _next_class(cls):
        """
        What class should be used to construct new instances from this class
        """
        return cls

    # --- Special Python methods.

    def __repr__(self):
        return '%s(%s)' % (type(self).__name__, super(path, self).__repr__())

    # Adding a path and a string yields a path.
    def __add__(self, more):
        try:
            return self._next_class(super(path, self).__add__(more))
        except TypeError:  # Python bug
            return NotImplemented

    def __radd__(self, other):
        if not isinstance(other, basestring):
            return NotImplemented
        return self._next_class(other.__add__(self))

    # The / operator joins paths.
    def __div__(self, rel):
        """ fp.__div__(rel) == fp / rel == fp.joinpath(rel)

        Join two path components, adding a separator character if
        needed.

        .. seealso:: :func:`os.path.join`
        """
        return self._next_class(self.module.join(self, rel))

    # Make the / operator work even when true division is enabled.
    __truediv__ = __div__

    def __enter__(self):
        self._old_dir = self.getcwd()
        os.chdir(self)
        return self

    def __exit__(self, *_):
        os.chdir(self._old_dir)

    @classmethod
    def getcwd(cls):
        """ Return the current working directory as a path object.

        .. seealso:: :func:`os.getcwdu`
        """
        return cls(getcwdu())

    #
    # --- Operations on path strings.

    def abspath(self):
        """ .. seealso:: :func:`os.path.abspath` """
        return self._next_class(self.module.abspath(self))

    def normcase(self):
        """ .. seealso:: :func:`os.path.normcase` """
        return self._next_class(self.module.normcase(self))

    def normpath(self):
        """ .. seealso:: :func:`os.path.normpath` """
        return self._next_class(self.module.normpath(self))

    def realpath(self):
        """ .. seealso:: :func:`os.path.realpath` """
        return self._next_class(self.module.realpath(self))

    def expanduser(self):
        """ .. seealso:: :func:`os.path.expanduser` """
        return self._next_class(self.module.expanduser(self))

    def expandvars(self):
        """ .. seealso:: :func:`os.path.expandvars` """
        return self._next_class(self.module.expandvars(self))

    def dirname(self):
        """ .. seealso:: :attr:`parent`, :func:`os.path.dirname` """
        return self._next_class(self.module.dirname(self))

    def basename(self):
        """ .. seealso:: :attr:`name`, :func:`os.path.basename` """
        return self._next_class(self.module.basename(self))

    def expand(self):
        """ Clean up a filename by calling :meth:`expandvars()`,
        :meth:`expanduser()`, and :meth:`normpath()` on it.

        This is commonly everything needed to clean up a filename
        read from a configuration file, for example.
        """
        return self.expandvars().expanduser().normpath()

    @property
    def namebase(self):
        """ The same as :meth:`name`, but with one file extension stripped off.

        For example,
        ``path('/home/guido/python.tar.gz').name == 'python.tar.gz'``,
        but
        ``path('/home/guido/python.tar.gz').namebase == 'python.tar'``.
        """
        base, ext = self.module.splitext(self.name)
        return base

    @property
    def ext(self):
        """ The file extension, for example ``'.py'``. """
        f, ext = self.module.splitext(self)
        return ext

    @property
    def drive(self):
        """ The drive specifier, for example ``'C:'``.

        This is always empty on systems that don't use drive specifiers.
        """
        drive, r = self.module.splitdrive(self)
        return self._next_class(drive)

    parent = property(
        dirname, None, None,
        """ This path's parent directory, as a new path object.

        For example,
        ``path('/usr/local/lib/libpython.so').parent ==
        path('/usr/local/lib')``

        .. seealso:: :meth:`dirname`, :func:`os.path.dirname`
        """)

    name = property(
        basename, None, None,
        """ The name of this file or directory without the full path.

        For example,
        ``path('/usr/local/lib/libpython.so').name == 'libpython.so'``

        .. seealso:: :meth:`basename`, :func:`os.path.basename`
        """)

    def splitpath(self):
        """ p.splitpath() -> Return ``(p.parent, p.name)``.

        .. seealso:: :attr:`parent`, :attr:`name`, :func:`os.path.split`
        """
        parent, child = self.module.split(self)
        return self._next_class(parent), child

    def splitdrive(self):
        """ p.splitdrive() -> Return ``(p.drive, <the rest of p>)``.

        Split the drive specifier from this path.  If there is
        no drive specifier, p.drive is empty, so the return value
        is simply ``(path(''), p)``.  This is always the case on Unix.

        .. seealso:: :func:`os.path.splitdrive`
        """
        drive, rel = self.module.splitdrive(self)
        return self._next_class(drive), rel

    def splitext(self):
        """ p.splitext() -> Return ``(p.stripext(), p.ext)``.

        Split the filename extension from this path and return
        the two parts.  Either part may be empty.

        The extension is everything from ``'.'`` to the end of the
        last path segment.  This has the property that if
        ``(a, b) == p.splitext()``, then ``a + b == p``.

        .. seealso:: :func:`os.path.splitext`
        """
        filename, ext = self.module.splitext(self)
        return self._next_class(filename), ext

    def stripext(self):
        """ p.stripext() -> Remove one file extension from the path.

        For example, ``path('/home/guido/python.tar.gz').stripext()``
        returns ``path('/home/guido/python.tar')``.
        """
        return self.splitext()[0]

    def splitunc(self):
        """ .. seealso:: :func:`os.path.splitunc` """
        unc, rest = self.module.splitunc(self)
        return self._next_class(unc), rest

    @property
    def uncshare(self):
        """
        The UNC mount point for this path.
        This is empty for paths on local drives.
        """
        unc, r = self.module.splitunc(self)
        return self._next_class(unc)

    @multimethod
    def joinpath(cls, first, *others):
        """
        Join first to zero or more path components, adding a separator
        character (``first.module.sep``) if needed.  Returns a new instance of
        ``first._next_class``.

        .. seealso:: :func:`os.path.join`
        """
        if not isinstance(first, cls):
            first = cls(first)
        return first._next_class(first.module.join(first, *others))

    def splitall(self):
        r""" Return a list of the path components in this path.

        The first item in the list will be a path.  Its value will be
        either :data:`os.curdir`, :data:`os.pardir`, empty, or the root
        directory of this path (for example, ``'/'`` or ``'C:\\'``).  The
        other items in the list will be strings.

        ``path.path.joinpath(*result)`` will yield the original path.
        """
        parts = []
        loc = self
        while loc != os.curdir and loc != os.pardir:
            prev = loc
            loc, child = prev.splitpath()
            if loc == prev:
                break
            parts.append(child)
        parts.append(loc)
        parts.reverse()
        return parts

    def relpath(self, start='.'):
        """ Return this path as a relative path,
        based from `start`, which defaults to the current working directory.
        """
        cwd = self._next_class(start)
        return cwd.relpathto(self)

    def relpathto(self, dest):
        """ Return a relative path from `self` to `dest`.

        If there is no relative path from `self` to `dest`, for example if
        they reside on different drives in Windows, then this returns
        ``dest.abspath()``.
        """
        origin = self.abspath()
        dest = self._next_class(dest).abspath()

        orig_list = origin.normcase().splitall()
        # Don't normcase dest!  We want to preserve the case.
        dest_list = dest.splitall()

        if orig_list[0] != self.module.normcase(dest_list[0]):
            # Can't get here from there.
            return dest

        # Find the location where the two paths start to differ.
        i = 0
        for start_seg, dest_seg in zip(orig_list, dest_list):
            if start_seg != self.module.normcase(dest_seg):
                break
            i += 1

        # Now i is the point where the two paths diverge.
        # Need a certain number of "os.pardir"s to work up
        # from the origin to the point of divergence.
        segments = [os.pardir] * (len(orig_list) - i)
        # Need to add the diverging part of dest_list.
        segments += dest_list[i:]
        if len(segments) == 0:
            # If they happen to be identical, use os.curdir.
            relpath = os.curdir
        else:
            relpath = self.module.join(*segments)
        return self._next_class(relpath)

    # --- Listing, searching, walking, and matching

    def listdir(self, pattern=None, realpath=False):
        """ D.listdir() -> List of items in this directory.

        Use :meth:`files` or :meth:`dirs` instead if you want a listing
        of just files or just subdirectories.

        The elements of the list are path objects.

        With the optional `pattern` argument, this only lists
        items whose names match the given pattern. Pattern may be a glob-style
        string or a compiled regular expression pattern.

        .. seealso:: :meth:`files`, :meth:`dirs`, :meth:`match`
        """
        if pattern is None:
            pattern = '*'
        result = [
            self / child
            for child in os.listdir(self)
            if self._next_class(child).match(pattern)
        ]
        if realpath:
            result = [p.realpath() for p in result]
        return result

    def dirs(self, pattern=None, realpath=False):
        """ D.dirs() -> List of this directory's subdirectories.

        The elements of the list are path objects.
        This does not walk recursively into subdirectories
        (but see :meth:`walkdirs`).

        With the optional `pattern` argument, this only lists
        directories whose names match the given pattern.  For
        example, ``d.dirs('build-*')``.
        """
        result = [p for p in self.listdir(pattern) if p.isdir()]
        if realpath:
            # don't pass realpath to listdir to avoid wasting time resolving
            # filtered paths
            result = [p.realpath() for p in result]
        return result

    def files(self, pattern=None, realpath=False):
        """ D.files() -> List of the files in this directory.

        The elements of the list are path objects.
        This does not walk into subdirectories (see :meth:`walkfiles`).

        With the optional `pattern` argument, this only lists files
        whose names match the given pattern.  For example,
        ``d.files('*.pyc')``.
        """
        result = [p for p in self.listdir(pattern) if p.isfile()]
        if realpath:
            # don't pass realpath to listdir to avoid wasting time resolving
            # filtered paths
            result = [p.realpath() for p in result]
        return result

    def walk(self, pattern=None, errors='strict', realpath=False, regex=None):
        """ D.walk() -> iterator over files and subdirs, recursively.

        The iterator yields path objects naming each child item of
        this directory and its descendants.  This requires that
        D.isdir().

        This performs a depth-first traversal of the directory tree.
        Each directory is returned just before all its children.

        The `errors=` keyword argument controls behavior when an
        error occurs.  The default is 'strict', which causes an
        exception.  The other allowed values are 'warn', which
        reports the error via ``warnings.warn()``, and 'ignore'.
        """
        if errors not in ('strict', 'warn', 'ignore'):
            raise ValueError("invalid errors parameter")

        try:
            childList = self.listdir()
        except Exception:
            if errors == 'ignore':
                return
            elif errors == 'warn':
                warnings.warn(
                    "Unable to list directory '%s': %s"
                    % (self, sys.exc_info()[1]),
                    TreeWalkWarning)
                return
            else:
                raise

        if regex is not None:
            assert pattern is None, "Cannot provide both pattern and regex arguments"
            pattern = re.compile(regex)

        for child in childList:
            if pattern is None or child.match(pattern):
                if realpath:
                    yield child.realpath()
                else:
                    yield child
                try:
                    isdir = child.isdir()
                except Exception:
                    if errors == 'ignore':
                        isdir = False
                    elif errors == 'warn':
                        warnings.warn(
                            "Unable to access '%s': %s"
                            % (child, sys.exc_info()[1]),
                            TreeWalkWarning)
                        isdir = False
                    else:
                        raise

                if isdir:
                    for item in child.walk(pattern, errors, realpath):
                        yield item

    def walkdirs(self, pattern=None, errors='strict', realpath=False, regex=None):
        """ D.walkdirs() -> iterator over subdirs, recursively.

        With the optional `pattern` argument, this yields only
        directories whose names match the given pattern.  For
        example, ``mydir.walkdirs('*test')`` yields only directories
        with names ending in 'test'.

        The `errors=` keyword argument controls behavior when an
        error occurs.  The default is 'strict', which causes an
        exception.  The other allowed values are 'warn', which
        reports the error via ``warnings.warn()``, and 'ignore'.
        """
        if errors not in ('strict', 'warn', 'ignore'):
            raise ValueError("invalid errors parameter")

        try:
            dirs = self.dirs()
        except Exception:
            if errors == 'ignore':
                return
            elif errors == 'warn':
                warnings.warn(
                    "Unable to list directory '%s': %s"
                    % (self, sys.exc_info()[1]),
                    TreeWalkWarning)
                return
            else:
                raise

        if regex is not None:
            assert pattern is None, "Cannot provide both pattern and regex arguments"
            pattern = re.compile(regex)

        parent_realpath = None
        for child in dirs:
            if pattern is None or child.match(pattern):
                if child.islink():
                    if parent_realpath is None:
                        parent_realpath = self.realpath()
                    child_realpath = child.realpath()
                    # check for infinite recursion
                    if child_realpath == parent_realpath or parent_realpath.startswith(child_realpath + os.path.sep):
                        # print "skipping %s to prevent infinite recursion" % child
                        continue
                    else:
                        if realpath:
                            yield child_realpath
                        else:
                            yield child
                else:
                    if realpath:
                        yield child.realpath()
                    else:
                        yield child
                for subsubdir in child.walkdirs(pattern, errors, realpath):
                    yield subsubdir

    def walkfiles(self, pattern=None, errors='strict', realpath=False, regex=None):
        """ D.walkfiles() -> iterator over files in D, recursively.

        The optional argument, `pattern`, limits the results to files
        with names that match the pattern.  For example,
        ``mydir.walkfiles('*.tmp')`` yields only files with the .tmp
        extension.
        """
        if errors not in ('strict', 'warn', 'ignore'):
            raise ValueError("invalid errors parameter")

        try:
            childList = self.listdir()
        except Exception:
            if errors == 'ignore':
                return
            elif errors == 'warn':
                warnings.warn(
                    "Unable to list directory '%s': %s"
                    % (self, sys.exc_info()[1]),
                    TreeWalkWarning)
                return
            else:
                raise

        if regex is not None:
            assert pattern is None, "Cannot provide both pattern and regex arguments"
            pattern = re.compile(regex)

        for child in childList:
            try:
                isfile = child.isfile()
                isdir = not isfile and child.isdir()
            except:
                if errors == 'ignore':
                    continue
                elif errors == 'warn':
                    warnings.warn(
                        "Unable to access '%s': %s"
                        % (self, sys.exc_info()[1]),
                        TreeWalkWarning)
                    continue
                else:
                    raise

            if isfile:
                if pattern is None or child.match(pattern):
                    if realpath:
                        yield child.realpath()
                    else:
                        yield child
            elif isdir:
                for f in child.walkfiles(pattern, errors, realpath):
                    yield f

    def fnmatch(self, pattern, normcase=None):
        """ Return ``True`` if `self.name` matches the given pattern.

        pattern - A filename pattern with wildcards,
            for example ``'*.py'``. If the pattern contains a `normcase`
            attribute, it is applied to the name and path prior to comparison.

        normcase - (optional) A function used to normalize the pattern and
            filename before matching. Defaults to self.module which defaults
            to os.path.normcase.

        .. seealso:: :func:`fnmatch.fnmatch`
        """
        default_normcase = getattr(pattern, 'normcase', self.module.normcase)
        normcase = normcase or default_normcase
        name = normcase(self.name)
        pattern = normcase(pattern)
        return fnmatch.fnmatchcase(name, pattern)

    def regmatch(self, pattern, normcase=None):
        """ Return ``True`` if `self.name` matches the given pattern.

        pattern - A regex pattern compiled with :func:`re.compile`.
            If the pattern contains a `normcase`  attribute, it is applied to
            the name and path prior to comparison.

        normcase - (optional) A function used to normalize the
            filename before matching. Defaults to self.module which defaults
            to os.path.normcase.

        .. seealso:: :module:`re`
        """
        default_normcase = getattr(pattern, 'normcase', self.module.normcase)
        normcase = normcase or default_normcase
        name = normcase(self.name)
        return bool(pattern.match(name))

    def match(self, pattern, normcase=None):
        """ Return ``True`` if `self.name` matches the given pattern. Supports
        both glob strings and compiled regular expressions.

        pattern - A glob-style filename pattern with wildcards, or regex pattern
            compiled with :func:`re.compile`.
            If the pattern contains a `normcase`  attribute, it is applied to
            the name and path prior to comparison.

        normcase - (optional) A function used to normalize the pattern and
            filename before matching. Defaults to self.module which defaults
            to os.path.normcase.

        .. seealso:: :meth:`fnmatch` and :meth:`regmatch`
        """
        if isinstance(pattern, re._pattern_type):
            return self.regmatch(pattern, normcase)
        else:
            return self.fnmatch(pattern, normcase)

    def glob(self, pattern):
        """ Return a list of path objects that match the pattern.

        `pattern` - a path relative to this directory, with wildcards.

        For example, ``path('/users').glob('*/bin/*')`` returns a list
        of all the files users have in their bin directories.

        .. seealso:: :func:`glob.glob`
        """
        cls = self._next_class
        return [cls(s) for s in glob.glob(self / pattern)]

    #
    # --- Reading or writing an entire file at once.

    def open(self, *args, **kwargs):
        """ Open this file.  Return a file object.

        .. seealso:: :func:`python:open`
        """
        return open(self, *args, **kwargs)

    def bytes(self):
        """ Open this file, read all bytes, return them as a string. """
        with self.open('rb') as f:
            return f.read()

    def chunks(self, size, *args, **kwargs):
        """ Returns a generator yielding chunks of the file, so it can
            be read piece by piece with a simple for loop.

           Any argument you pass after `size` will be passed to `open()`.

           :example:

               >> for chunk in path("file.txt").chunks(8192):
               ..    print(chunk)

            This will read the file by chunks of 8192 bytes.
        """
        with open(self, *args, **kwargs) as f:
            while True:
                d = f.read(size)
                if not d:
                    break
                yield d

    def write_bytes(self, bytes, append=False):
        """ Open this file and write the given bytes to it.

        Default behavior is to overwrite any existing file.
        Call ``p.write_bytes(bytes, append=True)`` to append instead.
        """
        if append:
            mode = 'ab'
        else:
            mode = 'wb'
        with self.open(mode) as f:
            f.write(bytes)

    def text(self, encoding=None, errors='strict'):
        r""" Open this file, read it in, return the content as a string.

        This method uses ``'U'`` mode, so ``'\r\n'`` and ``'\r'`` are
        automatically translated to ``'\n'``.

        Optional arguments:
            `encoding` - The Unicode encoding (or character set) of
                the file.  If present, the content of the file is
                decoded and returned as a unicode object; otherwise
                it is returned as an 8-bit str.
            `errors` - How to handle Unicode errors; see :meth:`str.decode`
                for the options.  Default is 'strict'.

        .. seealso:: :meth:`lines`
        """
        if encoding is None:
            # 8-bit
            with self.open('U') as f:
                return f.read()
        else:
            # Unicode
            with codecs.open(self, 'r', encoding, errors) as f:
                # (Note - Can't use 'U' mode here, since codecs.open
                # doesn't support 'U' mode.)
                t = f.read()
            return (t.replace(u('\r\n'), u('\n'))
                     .replace(u('\r\x85'), u('\n'))
                     .replace(u('\r'), u('\n'))
                     .replace(u('\x85'), u('\n'))
                     .replace(u('\u2028'), u('\n')))

    def write_text(self, text, encoding=None, errors='strict',
                   linesep=os.linesep, append=False):
        r""" Write the given text to this file.

        The default behavior is to overwrite any existing file;
        to append instead, use the `append=True` keyword argument.

        There are two differences between :meth:`write_text` and
        :meth:`write_bytes`: newline handling and Unicode handling.
        See below.

        Parameters:

          `text` - str/unicode - The text to be written.

          `encoding` - str - The Unicode encoding that will be used.
              This is ignored if 'text' isn't a Unicode string.

          `errors` - str - How to handle Unicode encoding errors.
              Default is 'strict'.  See help(unicode.encode) for the
              options.  This is ignored if 'text' isn't a Unicode
              string.

          `linesep` - keyword argument - str/unicode - The sequence of
              characters to be used to mark end-of-line.  The default is
              :data:`os.linesep`.  You can also specify ``None``; this means to
              leave all newlines as they are in `text`.

          `append` - keyword argument - bool - Specifies what to do if
              the file already exists (``True``: append to the end of it;
              ``False``: overwrite it.)  The default is ``False``.


        --- Newline handling.

        write_text() converts all standard end-of-line sequences
        (``'\n'``, ``'\r'``, and ``'\r\n'``) to your platform's default
        end-of-line sequence (see :data:`os.linesep`; on Windows, for example,
        the end-of-line marker is ``'\r\n'``).

        If you don't like your platform's default, you can override it
        using the `linesep=` keyword argument.  If you specifically want
        write_text() to preserve the newlines as-is, use ``linesep=None``.

        This applies to Unicode text the same as to 8-bit text, except
        there are three additional standard Unicode end-of-line sequences:
        ``u'\x85'``, ``u'\r\x85'``, and ``u'\u2028'``.

        (This is slightly different from when you open a file for
        writing with ``fopen(filename, "w")`` in C or ``open(filename, 'w')``
        in Python.)


        --- Unicode

        If `text` isn't Unicode, then apart from newline handling, the
        bytes are written verbatim to the file.  The `encoding` and
        `errors` arguments are not used and must be omitted.

        If `text` is Unicode, it is first converted to bytes using the
        specified 'encoding' (or the default encoding if `encoding`
        isn't specified).  The `errors` argument applies only to this
        conversion.

        """
        if isinstance(text, unicode):
            if linesep is not None:
                # Convert all standard end-of-line sequences to
                # ordinary newline characters.
                text = (text.replace(u('\r\n'), u('\n'))
                            .replace(u('\r\x85'), u('\n'))
                            .replace(u('\r'), u('\n'))
                            .replace(u('\x85'), u('\n'))
                            .replace(u('\u2028'), u('\n')))
                text = text.replace(u('\n'), linesep)
            if encoding is None:
                encoding = sys.getdefaultencoding()
            bytes = text.encode(encoding, errors)
        else:
            # It is an error to specify an encoding if 'text' is
            # an 8-bit string.
            assert encoding is None

            if linesep is not None:
                text = (text.replace('\r\n', '\n')
                            .replace('\r', '\n'))
                bytes = text.replace('\n', linesep)

        self.write_bytes(bytes, append)

    def lines(self, encoding=None, errors='strict', retain=True):
        r""" Open this file, read all lines, return them in a list.

        Optional arguments:
            `encoding` - The Unicode encoding (or character set) of
                the file.  The default is None, meaning the content
                of the file is read as 8-bit characters and returned
                as a list of (non-Unicode) str objects.
            `errors` - How to handle Unicode errors; see help(str.decode)
                for the options.  Default is 'strict'
            `retain` - If true, retain newline characters; but all newline
                character combinations (``'\r'``, ``'\n'``, ``'\r\n'``) are
                translated to ``'\n'``.  If false, newline characters are
                stripped off.  Default is True.

        This uses ``'U'`` mode.

        .. seealso:: :meth:`text`
        """
        if encoding is None and retain:
            with self.open('U') as f:
                return f.readlines()
        else:
            return self.text(encoding, errors).splitlines(retain)

    def write_lines(self, lines, encoding=None, errors='strict',
                    linesep=os.linesep, append=False):
        r""" Write the given lines of text to this file.

        By default this overwrites any existing file at this path.

        This puts a platform-specific newline sequence on every line.
        See `linesep` below.

            `lines` - A list of strings.

            `encoding` - A Unicode encoding to use.  This applies only if
                `lines` contains any Unicode strings.

            `errors` - How to handle errors in Unicode encoding.  This
                also applies only to Unicode strings.

            linesep - The desired line-ending.  This line-ending is
                applied to every line.  If a line already has any
                standard line ending (``'\r'``, ``'\n'``, ``'\r\n'``,
                ``u'\x85'``, ``u'\r\x85'``, ``u'\u2028'``), that will
                be stripped off and this will be used instead.  The
                default is os.linesep, which is platform-dependent
                (``'\r\n'`` on Windows, ``'\n'`` on Unix, etc.).
                Specify ``None`` to write the lines as-is, like
                :meth:`file.writelines`.

        Use the keyword argument append=True to append lines to the
        file.  The default is to overwrite the file.  Warning:
        When you use this with Unicode data, if the encoding of the
        existing data in the file is different from the encoding
        you specify with the encoding= parameter, the result is
        mixed-encoding data, which can really confuse someone trying
        to read the file later.
        """
        if append:
            mode = 'ab'
        else:
            mode = 'wb'
        with self.open(mode) as f:
            for line in lines:
                isUnicode = isinstance(line, unicode)
                if linesep is not None:
                    # Strip off any existing line-end and add the
                    # specified linesep string.
                    if isUnicode:
                        if line[-2:] in (u('\r\n'), u('\x0d\x85')):
                            line = line[:-2]
                        elif line[-1:] in (u('\r'), u('\n'),
                                           u('\x85'), u('\u2028')):
                            line = line[:-1]
                    else:
                        if line[-2:] == '\r\n':
                            line = line[:-2]
                        elif line[-1:] in ('\r', '\n'):
                            line = line[:-1]
                    line += linesep
                if isUnicode:
                    if encoding is None:
                        encoding = sys.getdefaultencoding()
                    line = line.encode(encoding, errors)
                f.write(line)

    def read_md5(self):
        """ Calculate the md5 hash for this file.

        This reads through the entire file.

        .. seealso:: :meth:`read_hash`
        """
        return self.read_hash('md5')

    def _hash(self, hash_name):
        """ Returns a hash object for the file at the current path.

            `hash_name` should be a hash algo name such as 'md5' or 'sha1'
            that's available in the :mod:`hashlib` module.
        """
        m = hashlib.new(hash_name)
        for chunk in self.chunks(8192, mode="rb"):
            m.update(chunk)
        return m

    def read_hash(self, hash_name):
        """ Calculate given hash for this file.

        List of supported hashes can be obtained from :mod:`hashlib` package.
        This reads the entire file.

        .. seealso:: :meth:`hashlib.hash.digest`
        """
        return self._hash(hash_name).digest()

    def read_hexhash(self, hash_name):
        """ Calculate given hash for this file, returning hexdigest.

        List of supported hashes can be obtained from :mod:`hashlib` package.
        This reads the entire file.

        .. seealso:: :meth:`hashlib.hash.hexdigest`
        """
        return self._hash(hash_name).hexdigest()

    # --- Methods for querying the filesystem.
    # N.B. On some platforms, the os.path functions may be implemented in C
    # (e.g. isdir on Windows, Python 3.2.2), and compiled functions don't get
    # bound. Playing it safe and wrapping them all in method calls.

    def isabs(self):
        """ .. seealso:: :func:`os.path.isabs` """
        return self.module.isabs(self)

    def exists(self):
        """ .. seealso:: :func:`os.path.exists` """
        return self.module.exists(self)

    def isdir(self):
        """ .. seealso:: :func:`os.path.isdir` """
        return self.module.isdir(self)

    def isfile(self):
        """ .. seealso:: :func:`os.path.isfile` """
        return self.module.isfile(self)

    def islink(self):
        """ .. seealso:: :func:`os.path.islink` """
        return self.module.islink(self)

    def ismount(self):
        """ .. seealso:: :func:`os.path.ismount` """
        return self.module.ismount(self)

    def samefile(self, other):
        """ .. seealso:: :func:`os.path.samefile` """
        return self.module.samefile(self, other)

    def samepath(self, other):
        """Whether the other path represents the same path as this one.

        This will account for symbolic links, absolute/relative paths,
        case differences (if on a case-insensitive file system), and '..'
        usage (so paths such as A//B, A/./B and A/foo/../B will all compare equal).

        This will NOT account for hard links - use :meth:`samefile` for this, if
        available on your os.

        Essentially just compares the `self.canonicalpath()` to `other.canonicalpath()`
        """
        return self.canonicalpath() == self._next_class(other).canonicalpath()

    def canonicalpath(self):
        """Attempt to return a 'canonical' version of the path

        This will standardize for symbolic links, absolute/relative paths,
        case differences (if on a case-insensitive file system), and '..'
        usage (so paths such as A//B, A/./B and A/foo/../B will all compare equal).

        The intention is that string comparison of canonical paths will yield
        a reasonable guess as to whether two paths represent the same file.
        """
        return self.abspath().realpath().normpath().normcase()

    def truepath(self):
        """The absolute, real, normalized path.

        Shortcut for `.abspath().realpath().normpath()`

        Unlike canonicalpath, on case-sensitive filesystems, two different paths
        may refer the same file, and so should only be used in cases where a
        "normal" path from root is desired, but we wish to preserve case; in
        situations where comparison is desired, :meth:`canonicalpath` (or
        :meth:`samepath`) should be used.
        """
        return self.abspath().realpath().normpath()

    def getatime(self):
        """ .. seealso:: :attr:`atime`, :func:`os.path.getatime` """
        return self.module.getatime(self)

    atime = property(
        getatime, None, None,
        """ Last access time of the file.

        .. seealso:: :meth:`getatime`, :func:`os.path.getatime`
        """)

    def getmtime(self):
        """ .. seealso:: :attr:`mtime`, :func:`os.path.getmtime` """
        return self.module.getmtime(self)

    mtime = property(
        getmtime, None, None,
        """ Last-modified time of the file.

        .. seealso:: :meth:`getmtime`, :func:`os.path.getmtime`
        """)

    def getctime(self):
        """ .. seealso:: :attr:`ctime`, :func:`os.path.getctime` """
        return self.module.getctime(self)

    ctime = property(
        getctime, None, None,
        """ Creation time of the file.

        .. seealso:: :meth:`getctime`, :func:`os.path.getctime`
        """)

    def getsize(self):
        """ .. seealso:: :attr:`size`, :func:`os.path.getsize` """
        return self.module.getsize(self)

    size = property(
        getsize, None, None,
        """ Size of the file, in bytes.

        .. seealso:: :meth:`getsize`, :func:`os.path.getsize`
        """)

    if hasattr(os, 'access'):
        def access(self, mode):
            """ Return true if current user has access to this path.

            mode - One of the constants :data:`os.F_OK`, :data:`os.R_OK`,
            :data:`os.W_OK`, :data:`os.X_OK`

            .. seealso:: :func:`os.access`
            """
            return os.access(self, mode)

    def stat(self):
        """ Perform a ``stat()`` system call on this path.

        .. seealso:: :meth:`lstat`, :func:`os.stat`
        """
        return os.stat(self)

    def lstat(self):
        """ Like :meth:`stat`, but do not follow symbolic links.

        .. seealso:: :meth:`stat`, :func:`os.lstat`
        """
        return os.lstat(self)

    def __get_owner_windows(self):
        r"""
        Return the name of the owner of this file or directory. Follow
        symbolic links.

        Return a name of the form ``ur'DOMAIN\User Name'``; may be a group.

        .. seealso:: :attr:`owner`
        """
        desc = win32security.GetFileSecurity(
            self, win32security.OWNER_SECURITY_INFORMATION)
        sid = desc.GetSecurityDescriptorOwner()
        account, domain, typecode = win32security.LookupAccountSid(None, sid)
        return domain + u('\\') + account

    def __get_owner_unix(self):
        """
        Return the name of the owner of this file or directory. Follow
        symbolic links.

        .. seealso:: :attr:`owner`
        """
        st = self.stat()
        return pwd.getpwuid(st.st_uid).pw_name

    def __get_owner_not_implemented(self):
        raise NotImplementedError("Ownership not available on this platform.")

    if 'win32security' in globals():
        get_owner = __get_owner_windows
    elif 'pwd' in globals():
        get_owner = __get_owner_unix
    else:
        get_owner = __get_owner_not_implemented

    owner = property(
        get_owner, None, None,
        """ Name of the owner of this file or directory.

        .. seealso:: :meth:`get_owner`""")

    #
    # --- Modifying operations on files and directories

    def utime(self, times):
        """ Set the access and modified times of this file.

        .. seealso:: :func:`os.utime`
        """
        os.utime(self, times)
        return self

    def chmod(self, mode):
        """ .. seealso:: :func:`os.chmod` """
        os.chmod(self, mode)
        return self

    if hasattr(os, 'chown'):
        def chown(self, uid=-1, gid=-1):
            """ .. seealso:: :func:`os.chown` """
            os.chown(self, uid, gid)
            return self

    if "grp" in globals():
        def get_groupname(self):
            """
            Return the group name for this file or directory.

            .. seealso:: :meth:`chgrp`
            """
            return grp.getgrgid(self.stat().st_gid).gr_name

        groupname = property(
            get_groupname, None, None,
            """ The group name for this file or directory.

            .. seealso:: :meth:`get_groupname`""")

        def chgrp(self, group):
            """
            Utility for setting the group permissions of a file or folder.
            `group` can be the name as a string or an integer id.

            .. seealso:: :func:`os.chown`
            """
            if isinstance(group, basestring):
                group = grp.getgrnam(group).gr_gid
            os.chown(self, -1, group)

    if hasattr(os, 'statvfs'):
        def statvfs(self):
            """ Perform a ``statvfs()`` system call on this path.

            .. seealso:: :func:`os.statvfs`
            """
            return os.statvfs(self)

    if hasattr(os, 'pathconf'):
        def pathconf(self, name):
            """ .. seealso:: :func:`os.pathconf` """
            return os.pathconf(self, name)

    def rename(self, new):
        """ .. seealso:: :func:`os.rename` """
        os.rename(self, new)
        return self._next_class(new)

    def renames(self, new):
        """ .. seealso:: :func:`os.renames` """
        os.renames(self, new)
        return self._next_class(new)

    #
    # --- Create/delete operations on directories

    def mkdir(self, mode=o777):
        """ .. seealso:: :func:`os.mkdir` """
        os.mkdir(self, mode)
        return self

    def mkdir_p(self, mode=o777):
        """ Like :meth:`mkdir`, but does not raise an exception if the
        directory already exists. """
        try:
            self.mkdir(mode)
        except OSError:
            _, e, _ = sys.exc_info()
            if e.errno != errno.EEXIST:
                raise
        return self

    def makedirs(self, mode=o777):
        """ .. seealso:: :func:`os.makedirs` """
        os.makedirs(self, mode)
        return self

    def makedirs_p(self, mode=o777):
        """ Like :meth:`makedirs`, but does not raise an exception if the
        directory already exists. """
        try:
            self.makedirs(mode)
        except OSError:
            _, e, _ = sys.exc_info()
            if e.errno != errno.EEXIST:
                raise
        return self

    def rmdir(self):
        """ .. seealso:: :func:`os.rmdir` """
        os.rmdir(self)
        return self

    def rmdir_p(self):
        """ Like :meth:`rmdir`, but does not raise an exception if the
        directory is not empty or does not exist. """
        try:
            self.rmdir()
        except OSError:
            _, e, _ = sys.exc_info()
            if e.errno != errno.ENOTEMPTY and e.errno != errno.EEXIST:
                raise
        return self

    def removedirs(self):
        """ .. seealso:: :func:`os.removedirs` """
        os.removedirs(self)
        return self

    def removedirs_p(self):
        """ Like :meth:`removedirs`, but does not raise an exception if the
        directory is not empty or does not exist. """
        try:
            self.removedirs()
        except OSError:
            _, e, _ = sys.exc_info()
            if e.errno != errno.ENOTEMPTY and e.errno != errno.EEXIST:
                raise
        return self

    # --- Modifying operations on files

    def touch(self):
        """ Set the access/modified times of this file to the current time.
        Create the file if it does not exist.
        """
        fd = os.open(self, os.O_WRONLY | os.O_CREAT, o666)
        os.close(fd)
        os.utime(self, None)
        return self

    def remove(self):
        """ .. seealso:: :func:`os.remove` """
        os.remove(self)
        return self

    def remove_p(self):
        """ Like :meth:`remove`, but does not raise an exception if the
        file does not exist. """
        try:
            self.unlink()
        except OSError:
            _, e, _ = sys.exc_info()
            if e.errno != errno.ENOENT:
                raise
        return self

    def unlink(self):
        """ .. seealso:: :func:`os.unlink` """
        os.unlink(self)
        return self

    def unlink_p(self):
        """ Like :meth:`unlink`, but does not raise an exception if the
        file does not exist. """
        self.remove_p()
        return self

    # --- Links

    if hasattr(os, 'link'):
        def link(self, newpath):
            """ Create a hard link at `newpath`, pointing to this file.

            .. seealso:: :func:`os.link`
            """
            os.link(self, newpath)
            return self._next_class(newpath)

    if hasattr(os, 'symlink'):
        def symlink(self, newlink):
            """ Create a symbolic link at `newlink`, pointing here.

            .. seealso:: :func:`os.symlink`
            """
            os.symlink(self, newlink)
            return self._next_class(newlink)

    if hasattr(os, 'readlink'):
        def readlink(self):
            """ Return the path to which this symbolic link points.

            The result may be an absolute or a relative path.

            .. seealso:: :meth:`readlinkabs`, :func:`os.readlink`
            """
            return self._next_class(os.readlink(self))

        def readlinkabs(self):
            """ Return the path to which this symbolic link points.

            The result is always an absolute path.

            .. seealso:: :meth:`readlink`, :func:`os.readlink`
            """
            p = self.readlink()
            if p.isabs():
                return p
            else:
                return (self.parent / p).abspath()

    #
    # --- High-level functions from shutil

    copyfile = shutil.copyfile
    copymode = shutil.copymode
    copystat = shutil.copystat
    copy = shutil.copy
    copy2 = shutil.copy2
    copytree = shutil.copytree
    if hasattr(shutil, 'move'):
        move = shutil.move
    rmtree = shutil.rmtree

    def rmtree_p(self):
        """ Like :meth:`rmtree`, but does not raise an exception if the
        directory does not exist. """
        try:
            self.rmtree()
        except OSError:
            _, e, _ = sys.exc_info()
            if e.errno != errno.ENOENT:
                raise
        return self

    def chdir(self):
        """ .. seealso:: :func:`os.chdir` """
        os.chdir(self)

    cd = chdir

    #
    # --- Special stuff from os

    if hasattr(os, 'chroot'):
        def chroot(self):
            """ .. seealso:: :func:`os.chroot` """
            os.chroot(self)

    if hasattr(os, 'startfile'):
        def startfile(self):
            """ .. seealso:: :func:`os.startfile` """
            os.startfile(self)
            return self


class tempdir(path):
    """
    A temporary directory via tempfile.mkdtemp, and constructed with the
    same parameters that you can use as a context manager.

    Example:

        with tempdir() as d:
            # do stuff with the path object "d"

        # here the directory is deleted automatically

    .. seealso:: :func:`tempfile.mkdtemp`
    """

    @ClassProperty
    @classmethod
    def _next_class(cls):
        return path

    def __new__(cls, *args, **kwargs):
        dirname = tempfile.mkdtemp(*args, **kwargs)
        return super(tempdir, cls).__new__(cls, dirname)

    def __init__(self, *args, **kwargs):
        pass

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        if not exc_value:
            self.rmtree()


def _permission_mask(mode):
    """
    Convert a Unix chmod symbolic mode like 'ugo+rwx' to a function
    suitable for applying to a mask to affect that change.

    >>> mask = _permission_mask('ugo+rwx')
    >>> oct(mask(0554))
    '0777'

    >>> oct(_permission_mask('go-x')(0777))
    '0766'
    """
    parsed = re.match('(?P<who>[ugo]+)(?P<op>[-+])(?P<what>[rwx]+)$', mode)
    if not parsed:
        raise ValueError("Unrecognized symbolic mode", mode)
    spec_map = dict(r=4, w=2, x=1)
    spec = reduce(operator.or_, [spec_map[perm]
                  for perm in parsed.group('what')])
    # now apply spec to each in who
    shift_map = dict(u=6, g=3, o=0)
    mask = reduce(operator.or_, [spec << shift_map[subj]
                  for subj in parsed.group('who')])

    op = parsed.group('op')
    # if op is -, invert the mask
    if op == '-':
        mask ^= o777

    op_map = {'+': operator.or_, '-': operator.and_}
    return functools.partial(op_map[op], mask)


class CaseInsensitivePattern(unicode):
    """
    A string with a 'normcase' property, suitable for passing to
    :meth:`listdir`, :meth:`dirs`, :meth:`files`, :meth:`walk`,
    :meth:`walkdirs`, or :meth:`walkfiles` to match case-insensitive.

    For example, to get all files ending in .py, .Py, .pY, or .PY in the
    current directory::

        from path import path, CaseInsensitivePattern as ci
        path('.').files(ci('*.py'))
    """

    @property
    def normcase(self):
        return __import__('ntpath').normcase

# migrating to PEP8 compliance
Path = path

########NEW FILE########
__FILENAME__ = picklezip
import gzip
try:
    import cPickle as pickle
except:
    import pickle

__all__ = ['dump', 'load']

def dump(object, filename, protocol=-1):
    """
    Save an compressed pickle to disk.
    """
    file = gzip.GzipFile(filename, 'wb')
    try:
        pickle.dump(object, file, protocol)
    finally:
        file.close()


def _loads(filename):
    """
    Load a compressed pickle from disk to an upicklable string
    """
    file = gzip.GzipFile(filename, 'rb')
    try:
        buffer = ""
        while 1:
            data = file.read()
            if data == "":
                break
            buffer += data
        return buffer
    finally:
        file.close()

def load(filename):
    """
    Load a compressed pickle from disk
    """
    return pickle.loads(_loads(filename))

########NEW FILE########
__FILENAME__ = scanf
"""scanf.py: scanf-style input for Python.

Danny Yoo (dyoo@hkn.eecs.berkeley.edu)

The initial motivation for this module was based on a posting on
Python-tutor:

    http://mail.python.org/pipermail/tutor/2004-July/030480.html

I haven't been able to find a nice module to do scanf-style input.
Even the Library Reference recommends regular expressions as a
substitute:

    http://docs.python.org/lib/node109.html

But there appears to have been activity about this on python-list:

    http://aspn.activestate.com/ASPN/Mail/Message/python-list/785450


Still, let's see if we can get a close equivalent scanf() in place.
At the least, it'll be fun for me, and it might be useful for people
who are still recovering from C.  *grin*


Functions provided:

    scanf(formatString) -- formatted scanning across stdin

    sscanf(sourceString, formatString) -- formated scanning across strings

    fscanf(sourceFile, formatString) -- formated scanning across files


The behavior of this scanf() will be slightly different from that
defined in C, because, in truth, I'm a little lazy, and am not quite
sure if people will need all of scanf's features in typical Python
programming.


But let's first show what conversions this scanf() will support.
Format strings are of the following form:

    % [*] [width] [format]

where [*] and [width] are optional, and [format] is mandatory.  The
optional flags modify the format.

    *         suppresses variable capture.
    width     maximum character width.


We support the following scanf conversion formats (copied from K&R):

    d    decimal integer.

    i    integer.  The integer may be in octal (leading zero) or
         hexadecimal (leading 0x or 0X).  ## fixme

    o    octal integer (with or without leading zero).  ## fixme

    x    hexadecimal integer (with or without leading 0x or 0X)   ## fixme

    c    characters.  The next input characters (default 1) are
         placed at the indicated spot.  The normal skip over white space
         is suppressed; to read the next non-white space character, use
         %1s.

    s    character string (not quoted).

    f    floating-point number with optional sign and optional decimal point.

    %    literal %; no assignment is made.


Literal characters can appear in the scanf format string: they must
match the same characters in the input.

There is no guarantee of what happens if calls to scanf are mixed with
other input functions.  See the BUGS section below for details on this.


If the input doesn't conform to the format string, a FormatError is
raised.


Example format strings:

    "%d %d"         Two decimal integers.

    "%d.%d.%d.%d"   Four decimal integers, separated by literal periods.
                    The periods won't be captured.

    "hello %s"      Literally matches "hello" followed by any number of
                    spaces, followed by a captured word.


There's also an interface for calling the internal function bscanf()
that works on CharacterBuffer types, if in the future there is
something that supports getc() and ungetc() natively.  There's also an
undocumented compile() function that takes format strings and returns
a function that can scan through CharacterBuffers.  Ooops, I guess I
just documented it.  *grin*


######################################################################


BUGS and GOTCHAS:

One major problem that I'm running into is a lack of ungetc(); it
would be nice if there were such a function in Python, but I can't
find it.  I have to simulate it by using a CharacterBuffer object, but
it's not an ideal solution.

So at most, you may lose a single character to the internal buffers
maintained by this module if you use scanf().  The other two *scanf()
functions, thankfully, aren't effected by this problem, since I can
simulate ungetc() more accurately by using seek() in the other two
cases.

If you really need to get that buffered character back, you can grab
it through _STDIN.lastChar, though manually fiddling with this is not
recommended.

So use scanf() with the following caveat: unlike C's stdin(), this
version scanf() can't be interchanged with calls to other input
functions without some kind of weird side effect.  We keep a
one-character buffer into stdin, so at most you might lose one
character to the internal buffers.

fscanf() is only allowed to work on things that support both read(1)
and seek(1, -1), since then I can reliably do a ungetch-like thing.

scanf("%s") can be dangerous in a hostile environment, since it's very
possible for something to pass in a huge string without spaces.  So use
an explicit width instead if you can help it."""



import sys
import unittest
from string import whitespace as WHITESPACE
from string import digits as DIGITS


__all__ = ['scanf', 'sscanf', 'fscanf']
__version__ = '1.0'


class CharacterBuffer(object):
    """A CharacterBuffer allows us to get a character, and to "unget" a
    character.  Abstract class"""

    def getch(self):
        """Returns the next character.  If there are no more characters
        left in the stream, returns the empty string."""
        pass ## implement me!

    def ungetch(self, ch):
        """Tries to put back a character.  Can be called at most once
        between calls to getch()."""
        pass ## implement me!


    def scanCharacterSet(self, characterSet, maxChars=0):
        """Support function that scans across a buffer till we hit
        something outside the allowable characterSet."""
        return self.scanPredicate(lambda ch: ch in characterSet, maxChars)


    def scanPredicate(self, predicate, maxChars=0):
        """Support function that scans across a buffer till we hit
        something outside what's allowable by the predicate."""
        chars = []
        countChars = 0
        while True:
            if (maxChars != 0 and countChars >= maxChars):
                break
            ch = self.getch()
            if ch != '' and predicate(ch):
                chars.append(ch)
                countChars += 1
            else:
                self.ungetch(ch)
                break
        return ''.join(chars)



class CharacterBufferFromIterable(CharacterBuffer):
    """Implementation of CharacterBuffers for iterable things.
    We keep a 'lastChar' attribute to simulate ungetc()."""
    def __init__(self, iterable):
        self.iterator = iter(iterable)
        self.lastChar = ''

    def getch(self):
        if self.lastChar == '':
            try:
                return self.iterator.next()
            except StopIteration:
                return ''
        else:
            (ch, self.lastChar) = (self.lastChar, '')
            return ch

    def ungetch(self, ch):
        self.lastChar = ch


class CharacterBufferFromFile(CharacterBuffer):
    """Implementation of CharacterBuffers for files.  We use the native
    read(1) and seek() calls, so we don't have to do so much magic."""
    def __init__(self, myfile):
        self.myfile = myfile

    def getch(self):
        return self.myfile.read(1)

    def ungetch(self, ch):
        self.myfile.seek(- len(ch), 1)



def readiter(inputFile, *args):
    """Returns an iterator that calls read(*args) on the inputFile."""
    while True:
        ch = inputFile.read(*args)
        if ch:
            yield ch
        else:
            raise StopIteration


def isIterable(thing):
    """Returns true if 'thing' looks iterable."""
    try: iter(thing)
    except TypeError: return False
    return True


def isFileLike(thing):
    """Returns true if thing looks like a file."""
    if hasattr(thing, "read") and hasattr(thing, "seek"):
        try:
            thing.seek(1, 1)
            thing.seek(-1, 1)
            return True
        except IOError:
            pass
    return False


def makeCharBuffer(thing):
    """Try to coerse 'thing' into a CharacterBuffer.  'thing' can be
    an instance of:

        1.  CharacterBuffer
        2.  A file-like object,
        3.  An iterable.

    makeCharBuffer() will make guesses in that order.
    """
    if isinstance(thing, CharacterBuffer):
        return thing
    elif isFileLike(thing):
        ## this check must come before isIterable, since files
        ## provide a line-based iterator that we don't want to use.
        ## Plus we want to take advantage of file.seek()
        return CharacterBufferFromFile(thing)
    elif isIterable(thing):
        return CharacterBufferFromIterable(thing)
    else:
        raise ValueError, ("Can't coerse %r to CharacterBuffer" % thing)


class CappedBuffer(CharacterBuffer):
    """Implementation of a buffer that caps the number of bytes we can
    getch().  The cap may or may not include whitespace characters."""
    def __init__(self, buffer, width, ignoreWhitespace=False):
        self.buffer = buffer
        self.bytesRead = 0
        self.width = width
        self.ignoreWhitespace = ignoreWhitespace


    def getch(self):
        if self.bytesRead < self.width:
            nextChar = self.buffer.getch()
            if not self.isIgnoredChar(nextChar):
                self.bytesRead += len(nextChar)
            return nextChar
        else:
            return ''


    def isIgnoredChar(self, ch):
        return self.ignoreWhitespace and isWhitespaceChar(ch)


    def ungetch(self, ch):
        self.buffer.ungetch(ch)
        if not self.isIgnoredChar(ch):
            self.bytesRead -= len(ch)
        # make sure wacky things don't happen when ungetch()ing.
        assert self.bytesRead >= 0



class FormatError(ValueError):
    """A FormatError is raised if we run into errors while scanning
    for input."""
    pass

class IncompleteCaptureError(ValueError):
    """The *scanf() functions raise IncompleteCaptureError if a problem
    occurs doing scanning."""
    pass


try:
    """We keep a module-level STDIN CharacterBuffer, so that we can call
    scanf() several times and not lose characters between invocations."""
    _STDIN = CharacterBufferFromIterable(sys.stdin)


    def scanf(formatString):
        """scanf(formatString) -> tuple

    Scans standard input for formats specified in the formatString.  See
    module's docs for list of supported format characters."""
        return bscanf(_STDIN, formatString)

except: TypeError

def sscanf(inputString, formatString):
    """sscanf(inputString, formatString) -> tuple

Scans inputString for formats specified in the formatString.  See
module's docs for list of supported format characters."""
    return bscanf(CharacterBufferFromIterable(inputString), formatString)


def fscanf(inputFile, formatString):
    """fscanf(inputFile, formatString) -> tuple

Scans inputFile for formats specified in the formatString.  See
module's docs for list of supported format characters."""
    buffer = CharacterBufferFromFile(inputFile)
    return bscanf(buffer, formatString)


def bscanf(buffer, formatString):
    """fscanf(buffer, formatString) -> tuple

Scans a CharacterBuffer 'buffer' for formats specified in the
formatString.  See scanf module's docs for list of supported format
characters."""
    ## TODO: we may want to do some caching here of compiled formatStrings,
    ## similar to that of the 're' module.
    parser = compile(formatString)
    return parser(buffer)


def isWhitespaceChar(ch, _set=set(WHITESPACE)):
    """Returns true if the charcter looks like whitespace.
    We follow the definition of C's isspace() function.
    """
    return ch in _set


def handleWhitespace(buffer):
    """Scans for whitespace.  Returns all the whitespace it collects."""
    chars = []
    while True:
        ch = buffer.getch()
        if isWhitespaceChar(ch):
            chars.append(ch)
        else:
            buffer.ungetch(ch)
            break
    return ''.join(chars)


## We keep a few sets as module variables just to incur the cost of
## constructing them just once.
_PLUS_MINUS_SET = set("+-")
_DIGIT_SET = set(DIGITS)
_OCT_SET = set("01234567")
_HEX_SET = set("0123456789ABCDEFabcdef")

def handleDecimalInt(buffer, optional=False, allowLeadingWhitespace=True):
    """Tries to scan for an integer.  If 'optional' is set to False,
    returns None if an integer can't be successfully scanned."""
    if allowLeadingWhitespace:
        handleWhitespace(buffer)  ## eat leading spaces
    chars = []
    chars += buffer.scanCharacterSet(_PLUS_MINUS_SET, 1)
    chars += buffer.scanCharacterSet(_DIGIT_SET)
    try:
        return int(''.join(chars), 10)
    except ValueError:
        if optional:
            return None
        raise FormatError, ("invalid literal characters: %s" % ''.join(chars))


def handleOct(buffer):
    chars = []
    chars += buffer.scanCharacterSet(_PLUS_MINUS_SET)
    chars += buffer.scanCharacterSet(_OCT_SET)
    try:
        return int(''.join(chars), 8)
    except ValueError:
        raise FormatError, ("invalid literal characters: %s" % ''.join(chars))


def handleInt(buffer, base=0):
    chars = []
    chars += buffer.scanCharacterSet(_PLUS_MINUS_SET)
    chars += buffer.scanCharacterSet("0")
    if chars and chars[-1] == '0':
        chars += buffer.scanCharacterSet("xX")
    chars += buffer.scanCharacterSet(_HEX_SET)
    try:
        return int(''.join(chars), base)
    except ValueError:
        raise FormatError, ("invalid literal characters: %s" % ''.join(chars))


def handleHex(buffer):
    return handleInt(buffer, 16)


def handleFloat(buffer, allowLeadingWhitespace=True):
    if allowLeadingWhitespace:
        handleWhitespace(buffer) ## eat leading whitespace
    chars = []
    chars += buffer.scanCharacterSet(_PLUS_MINUS_SET)
    chars += buffer.scanCharacterSet(_DIGIT_SET)
    chars += buffer.scanCharacterSet(".")
    chars += buffer.scanCharacterSet(_DIGIT_SET)
    chars += buffer.scanCharacterSet("eE")
    chars += buffer.scanCharacterSet(_PLUS_MINUS_SET)
    chars += buffer.scanCharacterSet(_DIGIT_SET)
    try:
        return float(''.join(chars))
    except ValueError:
        raise FormatError, ("invalid literal characters: %s" % ''.join(chars))



def handleChars(buffer,
                allowLeadingWhitespace=False,
                isBadCharacter=lambda ch: False,
                optional=False):
    """Read as many characters are there are in the buffer."""
    if allowLeadingWhitespace:
        handleWhitespace(buffer)
    chars = []
    chars += buffer.scanPredicate(lambda ch: not isBadCharacter(ch))
    if chars:
        return ''.join(chars)
    else:
        if optional: return None
        raise FormatError, ("Empty buffer.")


def handleString(buffer, allowLeadingWhitespace=True):
    """Reading a string format is just an application of reading
    characters (skipping leading spaces, and reading up to space)."""
    return handleChars(buffer,
                       allowLeadingWhitespace=allowLeadingWhitespace,
                       isBadCharacter=isWhitespaceChar)


def makeHandleLiteral(literal):
    def f(buffer, optional=False):
        ch = buffer.getch()
        if ch == literal:
            return ch
        else:
            buffer.ungetch(ch)
            if optional: return None
            raise FormatError, ("%s != %s" % (literal, ch))
    return f


def makeWidthLimitedHandler(handler, width, ignoreWhitespace=False):
    """Constructs a Handler that caps the number of bytes that can be read
    from the byte buffer."""
    def f(buffer):
        return handler(CappedBuffer(buffer, width, ignoreWhitespace))
    return f


"""Just for kicks: handleChar is a handler for a single character."""
handleChar = makeWidthLimitedHandler(handleChars, 1, ignoreWhitespace=False)


def makeIgnoredHandler(handler):
    def f(buffer):
        handler(buffer)
        return None
    return f



class CompiledPattern:
    def __init__(self, handlers, formatString):
        self.handlers = handlers
        self.formatString = formatString

    def __call__(self, buffer):
        results = []
        try:
            for h in self.handlers:
                value = h(buffer)
                ## We use None as the sentinel value that ignored handlers
                ## will emit.
                if value is not None:
                    results.append(value)
            return tuple(results)
        except FormatError, e:
            raise IncompleteCaptureError, (e, tuple(results))

    def __repr__(self):
        return "compile(%r)" % self.formatString


def compile(formatString):
    """Given a format string, emits a new CompiledPattern that eats
    CharacterBuffers and returns captured values as a tuple.

    If there's a failure during scanning, raises IncompleteCaptureError,
    with args being a two-tuple of the FormatError, and the results that
    were captured before the error occurred.
    """
    handlers = []
    formatBuffer = CharacterBufferFromIterable(formatString)
    while True:
        ch = formatBuffer.getch()
        if ch == '': break
        if isWhitespaceChar(ch):
            handleWhitespace(formatBuffer)
            handlers.append(makeIgnoredHandler(handleWhitespace))
        elif ch == '%':
            handlers.append(_compileFormat(formatBuffer))
        else:
            handlers.append(makeIgnoredHandler(makeHandleLiteral(ch)))
    return CompiledPattern(handlers, formatString)


def _compileFormat(formatBuffer):
    def readOptionalSuppression():
        f = makeHandleLiteral("*")
        return f(formatBuffer, optional=True) == "*"

    def readOptionalWidth():
        return handleDecimalInt(formatBuffer,
                                optional=True,
                                allowLeadingWhitespace=False)

    def readFormat():
        return formatBuffer.getch()  ## Finally, read the format

    suppression = readOptionalSuppression()
    width = readOptionalWidth()
    formatCh = readFormat()
    handler = makeFormattedHandler(suppression, width, formatCh)
    if handler:
        return handler
    else:
        ## At this point, since we couldn't figure out the format, die loudly.
        raise FormatError, ("Invalid format character %s" % formatCh)



_FORMAT_HANDLERS = {'d': handleDecimalInt,
                    'i': handleInt,
                    'x': handleHex,
                    'o': handleOct,
                    's': handleString,
                    'f': handleFloat,
                    '%': makeIgnoredHandler(makeHandleLiteral('%'))
                    }


def makeFormattedHandler(suppression, width, formatCh):
    """Given suppression, width, and a formatType, returns a function
    that eats a buffer and returns that thing."""
    def applySuppression(handler):
        if suppression:
            return makeIgnoredHandler(handler)
        return handler
    def applyWidth(handler):
        if width != None:
            return makeWidthLimitedHandler(handler, width,
                                           ignoreWhitespace=True)
        return handler

    ## 'c' is a special case: it's the only handler that can't ignore
    ## whitespace.
    if formatCh == 'c':
        if width == None:
            return applySuppression(handleChar)
        else:
            return applySuppression(
                makeWidthLimitedHandler(handleChars, width,
                                        ignoreWhitespace=False))
    if formatCh in _FORMAT_HANDLERS:
        return applySuppression(applyWidth(_FORMAT_HANDLERS[formatCh]))
    else:
        return None




######################################################################
##
## Of course we have test cases.  *grin*
##

class ScanfTests(unittest.TestCase):
    def bufferFromString(self, s):
        return CharacterBufferFromIterable(s)


    def testBufferFromString(self):
        b = self.bufferFromString("hello")
        for letter in list('hello'):
            self.assertEquals(letter, b.getch())
        self.assertEquals('', b.getch())

    def testCharacterSetScanning(self):
        b = makeCharBuffer("+++-+++++1234")
        self.assertEquals("+++", b.scanCharacterSet(set("+")))
        self.assertEquals("", b.scanCharacterSet(set("+")))
        self.assertEquals("-", b.scanCharacterSet(set("-")))
        self.assertEquals("+", b.scanCharacterSet(set("+"), 1))

    def testPredicateScanning(self):
        b = makeCharBuffer("+++-+++++1234")
        self.assertEquals("+++", b.scanPredicate(lambda ch: ch == '+'))


    def testUngetch(self):
        b = self.bufferFromString("ong")
        b.ungetch('y')
        self.assertEquals('y', b.getch())
        self.assertEquals('o', b.getch())
        b.ungetch('u')
        self.assertEquals('u', b.getch())
        self.assertEquals('n', b.getch())
        self.assertEquals('g', b.getch())
        self.assertEquals('', b.getch())


    def testRepeatedGetchOnEmptyStreamIsOk(self):
        b = self.bufferFromString("")
        self.assertEquals('', b.getch())
        self.assertEquals('', b.getch())

    def testCappedBuffer(self):
        b = CappedBuffer(self.bufferFromString("supercalifragilisticexpialidocious"), 5)
        self.assertEquals("s", b.getch())
        self.assertEquals("u", b.getch())
        self.assertEquals("p", b.getch())
        self.assertEquals("e", b.getch())
        self.assertEquals("r", b.getch())
        self.assertEquals('', b.getch())
        self.assertEquals('', b.getch())
        b.ungetch('r')
        self.assertEquals("r", b.getch())
        self.assertEquals('' ,b.getch())


    def testWhitespaceScanning(self):
        b = self.bufferFromString("    42\n43")
        self.assertEquals("    ", handleWhitespace(b))
        self.assertEquals("", handleWhitespace(b))
        self.assertEquals("4", b.getch())


    def testDecimalDigitScanning(self):
        b = self.bufferFromString("42 43!44")
        self.assertEquals(42, handleDecimalInt(b))
        self.assertEquals(" ", handleWhitespace(b))
        self.assertEquals(43, handleDecimalInt(b))

        b2 = self.bufferFromString("-1-2+3-4");
        self.assertEquals(-1, handleDecimalInt(b2))
        self.assertEquals(-2, handleDecimalInt(b2))
        self.assertEquals(3, handleDecimalInt(b2))
        self.assertEquals(-4, handleDecimalInt(b2))
        self.assertRaises(FormatError, handleDecimalInt, b2)


    def testCharacter(self):
        b = self.bufferFromString("hi!")
        self.assertEquals("h", handleChar(b))
        self.assertEquals("i", handleChar(b))
        self.assertEquals("!", handleChar(b))
        self.assertRaises(FormatError, handleChar, b)


    def testString(self):
        b = self.bufferFromString("-42 + 1 equals -41")
        self.assertEquals("-42", handleString(b))
        handleWhitespace(b)
        self.assertEquals("+", handleString(b))
        handleWhitespace(b)
        self.assertEquals("1", handleString(b))
        handleWhitespace(b)
        self.assertEquals("equals", handleString(b))
        handleWhitespace(b)
        self.assertEquals("-41", handleString(b))


    def testIntegerScanning(self):
        self.assertEquals((42, 43),
                          sscanf("   42\n   43  ", "%d %d"))
        self.assertEquals((8,), sscanf("10", "%o"))
        self.assertEquals((8,), sscanf("010", "%o"))
        self.assertEquals((15,), sscanf("F", "%x"))
        self.assertEquals((15,), sscanf("f", "%x"))
        self.assertEquals((15,), sscanf("0xF", "%x"))
        self.assertEquals((15,), sscanf("0XF", "%x"))
        self.assertEquals((15,), sscanf("0Xf", "%x"))
        self.assertEquals((-1, -2, 3, -4), sscanf("-1-2+3-4", "%d%d%d%d"))



    def testWordScanning(self):
        self.assertEquals(("hello", "world"),
                          sscanf("   hello world", "%s %s"))


    def testSuppression(self):
        self.assertEquals((), sscanf(" hello world", "%*s %*s"))
        self.assertEquals(("happy",),
                          sscanf("hello happy world", "%*s %s %*s"))
        self.assertEquals((), sscanf("h", "%*c"))


    def testWidth(self):
        self.assertEquals(("00010",), sscanf("00010101010111", "%5c"))
        self.assertEquals(("xy",), sscanf("xyz", "%2s"))
        self.assertEquals(("xy",), sscanf("              xyz", "%2s"))
        self.assertEquals(("  ",), sscanf("              xyz", "%2c"))


    def testFscanf(self):
        import StringIO
        b = StringIO.StringIO("hello world")
        self.assertEquals(("hello", " ", "world"), fscanf(b, "%s%c%s"))
        ## Check that calling fscanf() twice doesn't
        ## drop the last character
        b2 = StringIO.StringIO("hello world")
        self.assertEquals(("hello",), fscanf(b2, "%s"))
        self.assertEquals((" ",), fscanf(b2, "%c"))
        self.assertEquals(("world",), fscanf(b2, "%s"))

    def testSkipLeadingSpaceOnScanning(self):
        """Ralph Heinkel reported a bug where floats weren't being
        parsed properly if there were leading whitespace for %f.
        This case checks that"""
        self.assertEquals((42.0,),
                          sscanf("    42.0", "%f"))


    def testFloats(self):
        self.assertEquals((3.14,
                           10.,
                           .001,
                           1e100,
                           3.14e-10,
                           0e0,), sscanf("""3.14
                           10.
                           .001
                           1e100
                           3.14e-10
                           0e0""", "%f %f %f %f %f %f"))


    def testMoreSimpleScanningExamples(self):
        self.assertEquals((192,168,1,1),
                          sscanf("192.168.1.1", "%d.%d.%d.%d"))
        self.assertEquals(("a", "b", "c"),
                          sscanf("  ab   c  ", "%1s%1s%s"))
        self.assertEquals(("hello", " ", "world"),
                          sscanf("hello world", "%s%c%s"))
        self.assertRaises(IncompleteCaptureError,
                          sscanf, "192.168.1.1", "%d %d %d %d")
        self.assertEquals(("danny",),
                          sscanf("hi danny", "hi %s"))
        self.assertEquals(("danny",),
                          sscanf("  hi danny", "  hi %s"))
        self.assertEquals(("a", "b", 3),
                          sscanf("ab3", "%c%c%d"))
        ## this case is weird, but it happens in C too!
        self.assertRaises(IncompleteCaptureError,
                          sscanf, "  hi danny", "hi %s")

        ## The example that's used in
        ## 'http://docs.python.org/lib/node109.html'
        self.assertEquals(("/usr/bin/sendmail", 0, 4),
                          sscanf("/usr/bin/sendmail - 0 errors, 4 warnings",
                                 "%s - %d errors, %d warnings"))

    def testErroneousFormats(self):
        self.assertRaises(FormatError, compile, "%")
        self.assertRaises(FormatError, compile, "% ")
        self.assertRaises(FormatError, compile, "%*")
        self.assertRaises(FormatError, compile, "%*z")
        self.assertRaises(FormatError, compile, "% d")
        self.assertRaises(FormatError, compile, "%* d")



if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = shell
import os, subprocess
from arguments import isIterable as _isIterable

__all__ = [ 'appendEnv', 'prependEnv', 'getEnv', 'getEnvs', 'putEnv', 'refreshEnviron', 'executableOutput', 'shellOutput' ]

# TODO : expand environment variables when testing if it already exists in the list
def appendEnv( env, value ):
    """append the value to the environment variable list ( separated by ':' on osx and linux and ';' on windows).
    skips if it already exists in the list"""
    sep = os.path.pathsep
    if env not in os.environ:
        #print "adding", env, value
        os.environ[env] = value
    else:
        splitEnv = os.environ[env].split(sep)
        if value not in splitEnv:
            splitEnv.append(value)
            #print "adding", env, value
            os.environ[env] = sep.join( splitEnv )
    # i believe os.putenv is triggered by modifying os.environ, so this should not be necessary ?
    #if put :
    #    os.putenv(env, os.environ[env])

def prependEnv( env, value ):
    """prepend the value to the environment variable list (separated by ':' on osx and linux and ';' on windows).
    skips if it already exists in the list"""
    sep = os.path.pathsep
    if env not in os.environ:
        #print "adding", env, value
        os.environ[env] = value
    else:
        splitEnv = os.environ[env].split(sep)
        if value not in splitEnv:
            splitEnv.insert(0,value)
            #print "adding", env, value
            os.environ[env] = sep.join( splitEnv )

def getEnv( env, default=None ):
    "get the value of an environment variable.  returns default (None) if the variable has not been previously set."
    return os.environ.get(env, default)

def getEnvs( env, default = None ):
    """
    get the value of an environment variable split into a list.  returns default ([]) if the variable has not been previously set.

    :rtype: list
    """
    try:
        return os.environ[env].split(os.path.pathsep)
    except KeyError:
        if default is None:
            return list()
        else:
            return default


def putEnv( env, value ):
    """set the value of an environment variable.  overwrites any pre-existing value for this variable. If value is a non-string
    iterable (aka a list or tuple), it will be joined into a string with the separator appropriate for the current system."""
    if _isIterable(value):
        value = os.path.pathsep.join(value)
    os.environ[env] = value

def refreshEnviron():
    """
    copy the shell environment into python's environment, as stored in os.environ
    """
    exclude = ['SHLVL']

    if os.name == 'posix':
        cmd = '/usr/bin/env'
    else:
        cmd = 'set'

    cmdOutput = shellOutput(cmd)
    #print "ENV", cmdOutput
    # use splitlines rather than split('\n') for better handling of different
    # newline characters on various os's
    for line in cmdOutput.splitlines():
        # need the check for '=' in line b/c on windows (and perhaps on other systems? orenouard?), an extra empty line may be appended
        if '=' in line:
            var, val = line.split('=', 1)  # split at most once, so that lines such as 'smiley==)' will work
            if not var.startswith('_') and var not in exclude:
                    os.environ[var] = val

def executableOutput(exeAndArgs, convertNewlines=True, stripTrailingNewline=True,
                     returnCode=False, input=None, **kwargs):
    """Will return the text output of running the given executable with the given arguments.

    This is just a convenience wrapper for subprocess.Popen, so the exeAndArgs argment
    should have the same format as the first argument to Popen: ie, either a single string
    giving the executable, or a list where the first element is the executable and the rest
    are arguments.

    :Parameters:
        convertNewlines : bool
            if True, will replace os-specific newlines (ie, \\r\\n on Windows) with
            the standard \\n newline

        stripTrailingNewline : bool
            if True, and the output from the executable contains a final newline,
            it is removed from the return value
            Note: the newline that is stripped is the one given by os.linesep, not \\n

        returnCode : bool
            if True, the return will be a tuple, (output, returnCode)

        input : string
            if non-none, a string that will be sent to the stdin of the executable

    kwargs are passed onto subprocess.Popen

    Note that if the keyword arg 'stdout' is supplied (and is something other than subprocess.PIPE),
    then the return will be empty - you must check the file object supplied as the stdout yourself.

    Also, 'stderr' is given the default value of subprocess.STDOUT, so that the return will be
    the combined output of stdout and stderr.

    Finally, since maya's python build doesn't support universal_newlines, this is always set to False -
    however, set convertNewlines to True for an equivalent result."""

    kwargs.setdefault('stdout', subprocess.PIPE)
    kwargs.setdefault('stderr', subprocess.STDOUT)

    if input:
        kwargs.setdefault('stdin', subprocess.PIPE)

    cmdProcess = subprocess.Popen(exeAndArgs, **kwargs)
    cmdOutput = cmdProcess.communicate(input=input)[0]

    if stripTrailingNewline and cmdOutput.endswith(os.linesep):
        cmdOutput = cmdOutput[:-len(os.linesep)]

    if convertNewlines:
        cmdOutput = cmdOutput.replace(os.linesep, '\n')
    if returnCode:
        return cmdOutput, cmdProcess.returncode
    return cmdOutput

def shellOutput(shellCommand, convertNewlines=True, stripTrailingNewline=True,
                returnCode=False, input=None, **kwargs):
    """Will return the text output of running a given shell command.

    :Parameters:
        convertNewlines : bool
            if True, will replace os-specific newlines (ie, \\r\\n on Windows) with
            the standard \\n newline

        stripTrailingNewline : bool
            if True, and the output from the executable contains a final newline,
            it is removed from the return value
            Note: the newline that is stripped is the one given by os.linesep, not \\n

        returnCode: bool
            if True, the return will be a tuple, (output, returnCode)

        input : string
            if non-none, a string that will be sent to the stdin of the executable

    With default arguments, behaves like commands.getoutput(shellCommand),
    except it works on windows as well.

    kwargs are passed onto subprocess.Popen

    Note that if the keyword arg 'stdout' is supplied (and is something other than subprocess.PIPE),
    then the return will be empty - you must check the file object supplied as the stdout yourself.

    Also, 'stderr' is given the default value of subprocess.STDOUT, so that the return will be
    the combined output of stdout and stderr.

    Finally, since maya's python build doesn't support universal_newlines, this is always set to False -
    however, set convertNewlines to True for an equivalent result."""

    # commands module not supported on windows... use subprocess
    kwargs['shell'] = True
    kwargs['convertNewlines'] = convertNewlines
    kwargs['stripTrailingNewline'] = stripTrailingNewline
    kwargs['returnCode'] = returnCode
    kwargs['input'] = input

    return executableOutput(shellCommand, **kwargs)

########NEW FILE########
__FILENAME__ = testing
import sys
import os
import types
import doctest
import modulefinder
import traceback
import inspect
from StringIO import StringIO
from unittest import *

import pymel.util
from warnings import warn

TEST_MAIN_FUNC_NAME = "test_main"
SUITE_FUNC_NAME = "suite"

def doctestFriendly(func):
    """
    Decorator which prepares maya to run doctests.
    """
    def prepForDoctest(*args, **kwargs):
        result = None
        if (sys.displayhook != sys.__displayhook__
            or sys.stdout != sys.__stdout__):
            save_displayhook = sys.displayhook
            # reset doctest.master, so we don't get spammed with
            # *** DocTestRunner.merge: '...' in both testers; summing outcomes.
            # messages...
            try:
                savedMaster = doctest.master
            except AttributeError:
                savedMaster = None

            # Note - for python 2.4 (ie, maya 8.5) compatability, can't use
            # try/except/raise - must separate
            try:
                sys.displayhook = sys.__displayhook__
                doctest.master = None
                try:
                    result = func(*args, **kwargs)
                except:
                    raise
            finally:
                sys.displayhook = save_displayhook
                doctest.master = savedMaster
        else:
            result = func(*args, **kwargs)
        return result
    return prepForDoctest

@doctestFriendly
def doctestobj(*args, **kwargs):
    """
    Wrapper for doctest.run_docstring_examples that works in maya gui.
    """
    return doctest.run_docstring_examples(*args, **kwargs)

@doctestFriendly
def doctestmod(*args, **kwargs):
    """
    Wrapper for doctest.testmod that works in maya gui.
    """
    return doctest.testmod(*args, **kwargs)

#def isDocTestable(path):
#    finder = moduleFinder.ModuleFinder()
#    finder.find_all_submodules(path)

class MayaTestRunner(TextTestRunner):
    def __init__(self, stream=sys.stdout, descriptions=True, verbosity=2):
        super(MayaTestRunner, self).__init__(stream=stream,
                                             descriptions=descriptions,
                                             verbosity=verbosity)

    @doctestFriendly
    def run(self, *args, **kwargs):
        super(MayaTestRunner, self).run(*args, **kwargs)

def addFuncToModule(func, module):
    if not hasattr(module, func.__name__):
        setattr(module, func.__name__, func)

def startsWithDoubleUnderscore(testcase):
    return testcase.__name__.startswith("__")

def setupUnittestModule(moduleName, suiteFuncName = SUITE_FUNC_NAME, testMainName=TEST_MAIN_FUNC_NAME,
                        filterTestCases=startsWithDoubleUnderscore):
    """
    Add basic unittest functions to the given module.

    Will add a 'suite' function that returns a suite object for the module,
    and a 'test_main' function which runs the suite.

    If a filterTestCases function is given, then this is applied to all objects in the module which
    inherit from TestCase, and if it returns true, removes them from the module dictionary,
    so that they are not automatically loaded.

    By default, it will filter all TestCases whose name starts with a double-underscore, ie
    '__AbstractTestCase'

    Will then call 'test_main' if moduleName == '__main__'
    """
    module = sys.modules[moduleName]
    def theSuite():
        return findTestCases(module)
    theSuite.__name__ = suiteFuncName

    def test_main():
        return MayaTestRunner().run(theSuite())
    test_main.__name__ = testMainName

    addFuncToModule(theSuite, module)
    addFuncToModule(test_main, module)

    for name in dir(module):
        obj = getattr(module, name)
        if (isinstance(obj, (type, types.ClassType)) and
            issubclass(obj, TestCase) and
            filterTestCases and
            filterTestCases(obj)):
            delattr(module, name)

    if moduleName == '__main__':
        test_main()

# Make this import / initialize pymel!
#class MayaTestRunner(TextTestRunner):
#    '''
#    Test runner for unittests that require maya.
#    '''
#
#    # For now, just calls standard TextTestRunner with different defaults
#    def __init__

class TestCaseExtended(TestCase):
    # Set this to True if you want to create a TestCase that you DON'T
    # want run (ie, an abstract class you wish to derive from, etc)
    DO_NOT_LOAD = False

    #def addTestFunc(self, function):
    def assertNoError(self, function, *args, **kwargs):
        try:
            function(*args, **kwargs)
        except:
            self.fail("Exception raised:\n%s" % traceback.format_exc())

    def assertIteration(self, iterable, expectedResults,
                        orderMatters=True,
                        onlyMembershipMatters=False):
        """
        Asserts that the iterable yields the expectedResults.

        'expectedResults' should be a sequence of items, where each item matches
        an item returned while iterating 'iterable'.

        If onlyMembershipMatters is True, then as long as the results of
        iterable are containined within expectedResults, and every member of
        expectedResults is returned by iterable at least once, the test will
        pass. (Ie, onlyMembershipMatters will override orderMatters.)

        If onlyMembershipMatters is False and orderMatters is True, then the
        items in expectedResults should match the order of items returned by the
        iterable.

        If onlyMembershipMatters is False and orderMatters is False, the
        assertion will pass as long as there is a one-to-one correspondence
        between the items of expectedResults and the items returned by
        iterable. Note that in this case, duplicate return values from the
        iterable will still need duplicate results in the expectedResults.

        Examples:

        # orderMatters=True, onlyMembershipMatters=False by default

        #################################################
        ## orderMatters=True, onlyMembershipMatters=False
        #################################################

        # will PASS
        assertIteration( "foo", ['f', 'o', 'o'])

        # will FAIL - last 'o' not present in expectedResults
        assertIteration( "foo", ['f', 'o'])

        # will FAIL - 'x' not present in iterable
        assertIteration( "foo", ['f', 'o', 'o', 'x'])

        # will FAIL - order incorrect
        assertIteration( "foo", ['o', 'f', 'o'])

        #################################################



        #################################################
        ## orderMatters=True, onlyMembershipMatters=True
        #################################################

        # will PASS - if onlyMembershipMatters, duplicate entries are ignored
        assertIteration( "foo", ['f', 'o', 'o'], onlyMemberShipMatters=True)

        #will PASS
        assertIteration( "foo", ['f', 'o'], onlyMemberShipMatters=True)

        #will FAIL - 'o' not present in expectedResults
        assertIteration( "foo", ['f'], onlyMemberShipMatters=True)

        # will FAIL - 'x' not present in iterable
        assertIteration( "foo", ['f', 'o', 'x'], onlyMemberShipMatters=True)

        # will PASS - order irrelevant
        assertIteration( "foo", ['o', 'f', 'o'], onlyMemberShipMatters=True)
        #################################################



        #################################################
        ## orderMatters=False, onlyMembershipMatters=False
        #################################################

        # will PASS
        assertIteration( "foo", ['f', 'o', 'o'], orderMatters=False)

        #will FAIL - second 'o' not in expectedResults
        assertIteration( "foo", ['f', 'o'], orderMatters=False)

        # will FAIL - 'x' not present in iterable
        assertIteration( "foo", ['f', 'o', 'o', 'x'], orderMatters=False))

        # will PASS - order irrelevant
        assertIteration( "foo", ['o', 'f', 'o'], orderMatters=False)
        #################################################
        """

        expectedResults = list(expectedResults)
        if onlyMembershipMatters:
            unmatchedResults = set(expectedResults)
        else:
            unmatchedResults = list(expectedResults)
        for item in iterable:
            notInExpectedResultsFormat = \
                "iterable '%s' contained item '%s', not found in %s '%s'"

            if onlyMembershipMatters:
                self.assertTrue(item in expectedResults,
                                notInExpectedResultsFormat % (iterable, item, "expectedResults", expectedResults))
            else:
                self.assertTrue(item in unmatchedResults,
                                notInExpectedResultsFormat % (iterable, item, "unmatched expectedResults", unmatchedResults))

                # should do above test even if orderMatters, since that way we will get a Fail (as opposed to an Error)
                # if len(unmatchedResults)==0
                if orderMatters:
                    self.assertEqual(item, unmatchedResults[0], "iterable returned '%s' when '%s' was expected" % (item, unmatchedResults[0]))
            if item in unmatchedResults:
                unmatchedResults.remove(item)

        message = "iterable '%s' did not contain expected item(s): %s" % (iterable, [str(x) for x in unmatchedResults])
        self.assertEqual(len(unmatchedResults), 0, message)

    def assertVectorsEqual(self, v1, v2, places=5):
        for p1, p2 in zip(v1, v2):
            try:
                self.assertAlmostEqual(p1, p2, places=places)
            except AssertionError:
                self.fail('%r not equal to %r to %s places' % (v1, v2, places))


# TODO: move to util.math?
def permutations(sequence, length=None):
    """Given a sequence, will return an iterator over the possible permutations.

    If length is 'None', the permutations will default to having the same length
    as the sequence; otherwise, the returned permtuations will have the given length.

    Note that every element in the sequence is considered unique, so that there may be
    'duplicate' permutations if there are duplicate elements in seq, ie:

    perumutations("aa") -> ['a', 'a'] and ['a', 'a']
    """

    if length is None:
        length = len(sequence)
    elif length < 0 or length > len(sequence):
        raise ValueError("Permutation length '%i' invalid for %s" % (length, sequence))

    if length==0: yield []

    else:
        for i in xrange(len(sequence)):
            for subpermutation in permutations(sequence[:i] + sequence[i+1:], length - 1):
                yield [sequence[i]] + subpermutation


def isOneToOne(dict):
    """
    Tests if the given dictionary is one to one (if dict[x]==dict[y], x==y)
    """
    return len(set(dict.itervalues())) == len(dict)

def isEquivalenceRelation(inputs, outputs, dict):
    """
    Tests if the given dictionary defines an equivalence relation from between inputs and outputs.

    Technically, tests if the dict is bijective: ie, one-to-one (if dict[x]==dict[y], x==y) and
    onto (for every y in outputs, exists an x such that dict[x] == y)
    """
    inputs = set(inputs)
    output = set(outputs)
    if len(inputs) == len(outputs) and \
        set(dict.iterkeys()) == inputs and \
        set(dict.itervalues()) == outputs:

        return True
    else:
        return False

class SuiteFromModule(TestSuite):
    def __init__(self, module, testImport=True):
        """
        Set testImport to True to have the suite automatically contain a test case that
        checks if we were able to find any tests in the given module.
        """
        super(SuiteFromModule, self).__init__()
        self._importError = None

        if isinstance(module, basestring):
            self.moduleName = module
            self.module = self._importTestModule()
        elif isinstance(module, types.ModuleType):
            self.moduleName = module.__name__
            self.module = module

        if self._importError is None and self.module:
            try:
                importedSuite = self._importSuite()
                if not importedSuite.countTestCases():
                    self._importError = "Imported suite (from %s.%s) had no test cases" % (self.module.__name__, self.suiteFuncName)
            except:
                self._importError = traceback.format_exc()

        if not self._importError:
            self.addTest(importedSuite)

        if testImport:
            self.addTest(self._makeImportTestCase())

    def _importTestModule(self):
        module = None
        try:
            module = __import__(self.moduleName)

            # if moduleName is 'package.module', __import__ returns package!
            packagePath = self.moduleName.split('.')
            for subModule in packagePath[1:]:
                module = getattr(module, subModule)
        except:
            self._importError = traceback.format_exc()
            module = None
        return module

    def _importSuite(self):
        return TestSuite()

    def _makeImportTestCase(suite_self):
        class TestSuiteImport(TestCaseExtended):
            def runTest(testCase_self):
                testCase_self.assertTrue(suite_self._importError is None, "Failed to create a test suite from module '%s':\n%s" % (suite_self.moduleName, suite_self._importError))
            runTest.__doc__ = """Try to create a %s from module '%s'""" % (suite_self.__class__.__name__, suite_self.moduleName)
        return TestSuiteImport()


class UnittestSuiteFromModule(SuiteFromModule):
    def __init__(self, moduleName, suiteFuncName=SUITE_FUNC_NAME, **kwargs):
        self.suiteFuncName = suiteFuncName
        super(UnittestSuiteFromModule, self).__init__(moduleName, **kwargs)

    def _importSuite(self):
        theSuite = None
        suiteFunc = getattr(self.module, self.suiteFuncName, None)
        if isinstance(suiteFunc, TestSuite):
            theSuite = suiteFunc
        elif callable(suiteFunc):
            theSuite = suiteFunc()

        if not theSuite:
            theSuite = findTestCases(self.module)
        if not theSuite:
            theSuite = TestSuite()
        return theSuite



class DoctestSuiteFromModule(SuiteFromModule):
    def __init__(self, moduleName, packageRecurse=False, alreadyRecursed = None, **kwargs):
        if alreadyRecursed is None:
            alreadyRecursed = []
        self.alreadyRecursed = alreadyRecursed
        self.packageRecurse = packageRecurse
        super(DoctestSuiteFromModule, self).__init__(moduleName, **kwargs)

    def _importSuite(self):
        theSuite = None

        if self.module not in self.alreadyRecursed:
            self.alreadyRecursed.append(self.module)
            try:
                theSuite = doctest.DocTestSuite(self.module)
            except ValueError:
                # will raise a value error if it found no tests...
                theSuite = None

            if self.packageRecurse:
                # if the module is a pacakge, for each directory in it's search path...
                for path in getattr(self.module, '__path__', []):

                    # ...add all submodules!
                    for name in os.listdir(path):
                        newPath = os.path.join(path, name)
                        basename, ext = os.path.splitext(name)
                        if ( (os.path.isfile(newPath) and ext in ('.py', '.pyo', '.pyc') and basename != '__init__')
                             or (os.path.isdir(newPath) and os.path.isfile(os.path.join(newPath, '__init__.py'))) ):
                            newModuleName = self.moduleName + "." + basename

                            newSuite = DoctestSuiteFromModule(newModuleName, testImport=False, packageRecurse=True, alreadyRecursed=self.alreadyRecursed)
                            if newSuite.countTestCases():
                                theSuite.addTest(newSuite)
        if not theSuite:
            theSuite = TestSuite()
        return theSuite

def setCompare(iter1, iter2):
    """
    Compares two groups of objects, returning the sets:
        onlyIn1, inBoth, onlyIn2
    """
    s1 = set(iter1)
    s2 = set(iter2)
    intersect = s1 & s2
    return s1 - intersect, intersect, s2 - intersect

def suite():
    theSuite = TestSuite()
    unittestMods = findUnittestModules()
    for testMod in unittestMods:
        theSuite.addTest(UnittestSuiteFromModule(testMod))
    doctests = DoctestSuiteFromModule('pymel', packageRecurse=True)
    if doctests.countTestCases():
        theSuite.addTest(doctests)
    return theSuite

########NEW FILE########
__FILENAME__ = trees
"""
A tree module that can wrap either pure python tree implementation or the networkx library if present

########################################################################
WARNING: this module may be removed in the future, or radically altered.
We do NOT recommend using it in external code...
########################################################################

>>> # Create a tree from nested sequences:
>>> myTree = Tree('a', ('ab', 'aa', 3, {}))
>>> print myTree
('a', ('ab', 'aa', '3', '{}'))
>>> print myTree.formatted()
+: a
|--: ab
|--: aa
|--: 3
\--: {}
>>> myTree.sort()
>>> print myTree.formatted()
+: a
|--: 3
|--: {}
|--: aa
\--: ab
>>>
>>> # Forests
>>> # -------
>>> # We can make a forest by passing in multiple args to the constructor
>>> myForest = Tree(1, 2, 3)
>>> for top in myForest.tops():
...     print top.value
...
1
2
3
>>> print myForest.formatted()
-: 1
<BLANKLINE>
-: 2
<BLANKLINE>
-: 3
"""
# Python implementation inspired from Gonzalo Rodrigues "Trees and more trees" in ASPN cookbook

#Import generators.
from __future__ import generators
# removed as it's 2.5 only
# import functools as ftools
from collections import *
import inspect
import warnings
import weakref as weak
from copy import *

#import logging
#_logger = logging.getLogger(__name__)
useNetworkx = False
networkxLoad = False
#if useNetworkx :
#    try :
#        import networkx.tree as nt
#        networkxLoad = True
#    except :
#        _logger.info("Library 'networkx' not present")
#        networkxLoad = False
#
#if networkxLoad :
#    _logger.info("Trees module will use networkx library")
#else :
#    _logger.info("Trees module will use pure python implementation")

#Utility

def isSequence(x):
    return type(x) is list or type(x) is tuple

def isTree(x):
    return (type(type(x)) is MetaTree)

def isImmutableTree(x):
    if isTree(x) :
        return x.__getattribute__('parent').fset is None
    else :
        return False

def isMutableTree(x):
    if isTree(x) :
        return x.__getattribute__('parent').fset is not None
    else :
        return False

# decorator to identify mutable methods (that are only valid for mutable trees)
def mutabletree(f) :
    f.mutabletree = True
    return f

# to create Tree classes
class MetaTree(type):
    """ This metaclass defines the type of all 'tree' classes """

    class PyTree :
        """Core methods for pure python trees implementation"""
        # these are the methods depending on implementation
        # a weak ref proxy of the parent/super (containing Tree) to allow faster parent lookup methods
        _pRef = None
        # the storage for value (top element of that tree)
        _value = None
        # the storage for subtrees, must be an iterable (and ordered if you want to have siblings order)
        # can be immutable or mutable
        _subtrees = None

        # Conversion to correct storage for subtrees
        def _toSubtree(cls, subtrees):
            """ Converts a list/tuple of subtrees to the appropriate date structure for that class
                Returns None for None or an empty list or tuple """
            if subtrees :
                return cls.TreeType(subtrees)
            else :
                return None
        _toSubtree = classmethod(_toSubtree)

        def __nonzero__(self) :
            try:
                return (self._value is not None or self._subtrees is not None)
            except :
                return False
        def isElement(self):
            if self :
                return (self._value is not None and self._subtrees is None)
            else :
                return False
        def hasChilds(self):
            if self :
                return (self._subtrees is not None)
            else :
                return False
        # by default only define get methods, set will be defined if the data type is mutable
        # and properties than can be either read only or read-write will be (re)defined accordingly at class creation
        # we always return trees / elements which value an be read from the value property

        # to be bound to properties
        def _get_value(self):
            return self._value
        # only for mutable
        @mutabletree
        def _set_value(self, value):
            if value is not None :
                self._value = value
        def _get_parent(self) :
            if self._pRef :
                # can remove
                if not self._pRef() is self :
                    return self._pRef()
                else :
                    raise RuntimeError, "Loop detected in tree %r on parent of %s", (self, self._get_value())
        # only for mutable
        @mutabletree
        def _set_parent(self, parent) :
            if parent is None :
                # unparenting
                if self._pRef is None :
                    return
                else :
                    oldparent = self._pRef()
                    # FIXME : we more or less assume it's a list here using remove instead of more generic iterable methods
                    oldparent._subtrees.remove(self)
                    # clean old parent subtrees if it dropped to 0
                    l = len(tuple(oldparent._subtrees))
                    if l == 0 :
                        oldparent._subtrees = None
                    elif l == 1 :
                        # if old parent was a forest and now has only only child, get rid of the None root
                        if oldparent._get_value() is None :
                            c = tuple(oldparent._subtrees)[0]
                            oldparent._set_value(c._get_value())
                            oldparent._subtrees = c._subtrees
                    # remove reference from self to old parent
                    self._pRef = None
            elif isinstance(parent, self.__class__) :
                if not parent is self :
                    # first unparent nicely if needed
                    if self._pRef is not None :
                        if self._pRef() is parent :
                            # what the fuss then ?
                            return
                        else :
                            # unparent
                            self._set_parent(None)
                    # then reparent as last child under 'parent'
                    # if self is actually a forest, we'll instead parent all childs of self
                    if self._get_value() is not None :
                        subs = [self]
                    elif self._subtrees is None :
                        subs = []
                    else :
                        subs = list(iter(self._subtrees))
                    for s in subs :
                        s._pRef = weak.ref(parent)
                        if parent._subtrees is None :
                            parent._subtrees = [s]
                        else :
                            # should not happen if the usual methods are used
                            for c in iter(parent._subtrees) :
                                if c is s :          # not == of course
                                    raise RuntimeError, "Self was already present in the childs of parent?"
                            parent._subtrees.append(s)
                    # now make self point to the new parent instead
                    if self._get_value() is None :
                        p = parent._get_parent()
                        self._pRef = weak.ref(p)
                        self._value = parent._value
                        self._subtrees = parent._subtrees
                else :
                    raise RuntimeError, "Setting self parent to itself would create a loop in tree %r" % self
            else :
                raise TypeError, "Can only reparent self to same type '%s' than self, not to '%s'" % (type(self), type(parent))
        def _get_next(self) :
            try :
                return self.siblings().next()
            except StopIteration:
                return None
        @mutabletree
        def _set_next(self, next) :
            parent = self._get_parent()
            if parent is not None :
                if parent._subtrees is not None :
                    l = len(tuple(parent._subtrees))
                    if l :
                        if next is None :
                            # nothing to do if self is unique child
                            if len(sseq) > 1  :
                                # FIXME : we more or less assume it's a list here using remove instead of more generic iterable method
                                try :
                                    parent._subtrees.remove(self)
                                except ValueError :
                                    raise RuntimeError, u"Invalid tree, parent of self '%s' does not have self in its subtrees" % self.value
                                parent._subtrees.append(self)
                        else :
                            if not isinstance(next, self.__class__) :
                                next = self.__class__(next)
                            # nothing to do if self == next
                            if self != next :
                                it = iter(parent._subtrees)
                                for s in it :
                                    if s == self :
                                        try :
                                            n = it.next()
                                        except StopIteration :
                                            n = iter(parent._subtrees).next()
                                        # nothing to do is next is already self's next
                                        if n != next :
                                            # FIXME : we more or less assume it's a list here using remove and insert instead of more generic iterable methods
                                            parent._subtrees.remove(self)
                                            try :
                                                j = parent._subtrees.index(next)
                                            except ValueError :
                                                raise ValueError, "Provided next element '%s' is not a sibling of self '%s'" % (next.value, self.value)
                                            parent._subtrees.insert(j, self)
                                # if self was not found, something is very wrong
                                raise RuntimeError, u"Invalid tree, parent of self '%s' does not have self in its subtrees" % self.value
                    else :
                        raise RuntimeError, u"Invalid tree, parent of self '%s' has an empty subtrees list" % self.value
                else :
                    raise RuntimeError, u"Invalid tree, parent of self '%s' has an empty subtrees list" % self.value
            raise ValueError, "Self has no parent, we can't change it's order in the list of its siblings, having none"
        # methods (for both mutable and immutable)
        def childs(self):
            """ Returns an iterator on all childs of self, or an empty iterator if self has no childs """
            if self._subtrees :
                return iter(self._subtrees)
            else :
                return iter(self.__class__.TreeType())
        def siblings (self):
            """ Returns an iterator on self siblings, not including self and starting with self next sibling,
                if self has no siblings (self has no parent or is unique child) then returns an empty iterator """
            parent = self._get_parent()
            if not parent :
                return iter(self.__class__.TreeType())
            else :
                cseq = tuple(parent.childs())
                for i in xrange(len(cseq)) :
                    if cseq[i] is self : # not ==
                        return iter(cseq[i+1:]+cseq[:i])
                # self should be in it's parents subtrees
                raise RuntimeError, u"Invalid tree, parent of %s does not have this subtree in its 'childs'" % self.value
        # Iterates as a nested tuple of values, the same format that can be passe back to init
        # that way if t is a Tree, Tree(list(t)) == Tree(tuple(t)) == t
        # use preorder, postorder, breadth for specific interations
        def __iter__(self):
            """Iterates first level of tree returning nested tuples for childs"""
            if self:
                if self.value :
                    yield self.value
                    childs = []
                    for subtree in self.childs() :
                        childs += list(subtree.__iter__())
                    if childs :
                        yield tuple(childs)
                else :
                    for subtree in self.childs():
                        for tree in subtree.__iter__():
                            yield tree
        #To allow pickling (will leave weak refs out and rebuild the object on unpickling from the preorder list of elements)
        def __reduce__(self):
            return (self.__class__, tuple(self) )
        # equivalence, __contains__
        # added equivalence test here
        def __eq__(self, other):
            """Checks for equality of two trees."""
            #Both trees not empty.
            if self and other:
                #Compare values.
                if self is other :
                    return True
                elif self.value != self.__class__(other).value:
                    return False
                elif len(self) != len(other) :
                    return False
                else :
                    return reduce(lambda x, y:x and y, map(lambda c1, c2:c1 == c2, self.childs(), other.childs()), True)
            #Both trees empty.
            elif not self and not other:
                return True
            else:
                return False
        def __ne__(self, other):
            return not self.__eq__(other)
        # compare using only top value (if compare is defined for value type) or all values ?
        def __contains__(self, element):
            """Returns True if element is in the tree, False otherwise."""
            if isTree(element) :
                for sub in self.breadth():
                    if element == sub:
                        return True
                return False
            else :
                for sub in self.breadth():
                    if element == sub.value:
                        return True
                return False
        # identity, not equivalence test
        def issubtree(self, other) :
            if isinstance(other, self.__class__) :
                parent = self
                while parent :
                    if parent is other :
                        return True
                    parent = parent.parent
            return False
        # get and __getitem
        # get the matching subtree to that subtree or element,
        # not that it can return a tuple if same element/subtree is present more than once in tree
        def __getitem__(self,value):
            """ Get a subtree from the Tree, given an element or value.
                Note that to be consistent with __getitem__ usual behavior, it will raise an exception
                it it doesn't find exactly one match (0 or more), method get will be more user friendly
                on non indexed trees.
                It's also possible to seek a path : a list of elements or values, it will limit the results
                to the subtrees that match the last item of the path, and whose parents match the path.
                A path can be relative, or absolute if starting with None as first item """
            result = self.get(value)
            l = len(result)
            if l==1 :
                return result[0]
            elif l == 0 :
                raise KeyError, "No  match for %s in Tree" % value
            else :
                raise KeyError, "More than one match for %s in Tree (%i found)" % (value, l)

        def get(self, value, default=tuple()):
            """ Identical to the __getitem__ method but will return a default value instead of raising KeyError
                if nor result is found """
            result = []
            # explore breadth first so that closest items are found faster
            if isTree(value) :
                # do a faster check in case value is a subtree of self
                if value.issubtree(self) :
                    return [value]
                # normal equivalence test
                for e in self.breadth() :
                    if value == e :
                        result.append(e)
            elif isSequence(value) :
                # we seek a path, a list of value that must be found in order,
                # if list starts with None it means it's an absolute path (starting at root)
                if value :
                    if value[0] is None :
                        result = [self]
                    else :
                        result += list(self.get(value[0]))
                    for p in value[1:] :
                        if result :
                            found = []
                            for t in result :
                                for c in t.childs() :
                                    if c.value == self.__class__(p).value :
                                        found.append(c)
                            result = found
                        else :
                            break
            else :
                for e in self.breadth() :
                    if value == e.value :
                        result.append(e)
            if not result :
                return default
            else :
                return tuple(result)
        # methods only for mutable : remove, __delitem__, add
        # remove
        @mutabletree
        def remove(self, element):
            """ Remove element from self, along with everything under it, will raise an exception if element is not in self """
            # TODO : only handle case where element is subtree of self here and let caller handle search for subtree from value
            self[element]._set_parent(None)
        # delete method
        @mutabletree
        def __delitem__(self, element) :
            try :
                sub = self[element]
            except :
                raise ValueError, "Tree does not contain element '%s'" % element
            sub._set_parent(None)
            del sub

        # methods only for mutable
        @mutabletree
        def add(self, element, parent=None, next=None):
            """ Add an element to self. parent and next element can be specified.
                Element will be added as a child of parent, parent can be any element or subtree of self:
                if parent is specified as a value there must exactly one match in self or an exception will be raised
                if parent is None, element will be added as a sibling of self's top node(s)
                if next is not none, element will be added before next in the childs of parent, else as a last childs """
            if not isinstance(element, self.__class__) :
                element = self.__class__(element)
            if parent is None :
                parent = self._get_parent()
                if parent is None :
                    value = self._get_value()
                    if value is not None :
                        # if self is not already a forest, make it one
                        subs = None
                        if self._subtrees is not None :
                            subs = list(iter(self._subtrees))
                        selfchild = self.__class__()
                        selfchild._pRef = weak.ref(self)
                        selfchild._set_value(value)
                        selfchild._subtrees = self.__class__._toSubtree(subs)
                        if subs :
                            for sub in subs :
                                sub._pRef = weak.ref(selfchild)
                        # must do manually
                        self._value = None
                        self._subtrees = self.__class__._toSubtree([selfchild])
                        # print self.debug()
                        # print selfchild.debug()
                    parent = self
            else :
                # parent must be actually a subtree of self, not a subtree of another tree that happens to be equal in value
                parent = self[parent]
            element._set_parent(parent)

        def __cmp__(self, other):
            return cmp(self.value, other.value)

        @mutabletree
        def sort(self, *args):
            if self and self._subtrees:
                for subTree in self._subtrees:
                    subTree.sort(*args)
                self._subtrees.sort(*args)

        # set and __setitem__

        # Changed to not allow sequences to follow each other, as it was too
        # ambiguous/confusing, and ikely not what the user intended - ie, if
        # we do:
        # >>> myTree = Tree(list1, list2)
        # ...chances are, I'm not going to want to have to check what the values are of
        # list1 in order to know where in the tree list2 will be placed.
        #
        # For instance, old init will do this:
        # >>> list1 = (1,2)
        # >>> list2 = (3,4)
        # >>> tree1 = Tree(list1, list2)
        # >>> print tree1.formatted()
        # +
        # |--1
        # \-+2
        #   |--3
        #   \--4
        # >>> list1 = (1,('a', 'b'))
        # >>> tree2 = Tree(list1, list2)
        # >>> print tree2.formatted()
        # +
        # |-+1
        # | |--a
        # | \--b
        # |--3
        # \--4
        #
        # Thus, the depth at which list2 is placed is dependant on list1.
        # Likely not what we want... therefore, lists may now only follow
        # non-list values - entering the previous examples will now result in an
        # error.
        # To create the same structures, you would do:
        # >>> tree1 = Tree(1, 2, (3,4))
        # >>> print tree1.formatted()
        # >>> tree2 = Tree(1, ('a','b'), 3, 4)
        # >>> print tree2.formatted()

        # init, this can be overriden in class definition
        def __init__(self, *args, **kwargs):
            """
            Initializer - non-sequences are values, sequeneces are children of previous value.

            The args represent tree nodes, where a node is specified by either another tree
            object, or a non sequence representing the value of that node, optionally followed
            by a sequence representing the children of that node.

            Values cannot be None, and when specifying the elements in a child sequence, they
            must fit the same rules for valid tree nodes given above.

            Invalid arguments (ie, two sequences following each other) will raise a ValueError.

            If there is only one node (ie, only one non-sequence arg, optionally followed by
            a list of children), then a tree is returned, with the single node as it's
            single root.

            If there are multiple nodes, then a forest is returned, with each node
            representing a root.

            For speed and ease of use, if there is only a single argument, and it is a sequence,
            it is the same as though we had unpacked the sequence:

            >>> list = (1,('a','b'))
            >>> Tree(list) == Tree(*list)
            True

            Now, some examples:

            >>> myTree = Tree()  # makes an empty tree
            >>> print myTree
            ()
            >>> myTree = Tree(1)
            >>> print repr(myTree) # different ways of stringifying...
            Tree(1)
            >>> myTree = Tree(1,('a','b'))  # make a tree with children
            >>> print myTree.formatted()
            +: 1
            |--: a
            \--: b
            >>> myTree = Tree(1,(2,'foo', ('bar',))) # tree with a subtree
            >>> myTree.view()
            +: 1
            |--: 2
            \-+: foo
              \--: bar
            >>> myForrest = Tree(1,2)   # make a forest
            >>> myForrest.view()        # view() is just shortcut for:
            ...                      # print treeInst.formatted()
            -: 1
            <BLANKLINE>
            -: 2
            >>> otherForrest = Tree('root1', myForrest, 'root4', ('kid1', 'kid2'))
            >>> otherForrest.view()
            -: root1
            <BLANKLINE>
            -: 1
            <BLANKLINE>
            -: 2
            <BLANKLINE>
            +: root4
            |--: kid1
            \--: kid2

            ...Note that a tree object, even if a forrest, will never be taken
            to represent the children of the previous arg - ie, the previous
            example did NOT result in:
            +: root1
            |--: 1
            \--: 2
            <BLANKLINE>
            +: root4
            |--: kid1
            \--: kid2

            This means that giving multiple forrest objects will effectively merge
            them into a larger forest:

            >>> forrest1 = Tree(1, 2)
            >>> forrest1.view()
            -: 1
            <BLANKLINE>
            -: 2
            >>> forrest2 = Tree('foo', 'bar')
            >>> forrest2.view()
            -: foo
            <BLANKLINE>
            -: bar
            >>> forrest3 = Tree(forrest1, forrest2)
            >>> forrest3.view()
            -: 1
            <BLANKLINE>
            -: 2
            <BLANKLINE>
            -: foo
            <BLANKLINE>
            -: bar

            Trying to give 2 sequences in a row results in a ValueError:

            >>> Tree('root1', (1,2), (3,4))
            Traceback (most recent call last):
              ...
            ValueError: Child sequence must immediately follow a non-sequence value when initializing a tree

            Similarly, trying to use 'None' as a tree value gives an error:
            >>> Tree(None, (1,2))
            Traceback (most recent call last):
              ...
            ValueError: None cannot be a tree element
            """
            # TODO: make it conform!
            parent = kwargs.get('parent', None)
            if parent is not None :
                pRef = weak.ref(parent)
            else :
                pRef = None

            if len(args) == 1 and isSequence(args[0]):
                args = args[0]

            roots = []
            previousWasValue = False
            for arg in args :
                isValue = False
                if isTree(arg) :
                    # we need to do a shallow copy if it's not the same tree type, or not already a subtree of self
                    if isinstance(arg, self.__class__) and arg.parent is self :
                        avalue = arg.value
                        if avalue :
                            roots += [arg]                                        # one item in childs : the subtree
                        else :
                            roots += [c for c in arg.childs()]                    # all childs of subtree in childs
                    else :
                        avalue = arg.value
                        if avalue :
                            roots += [self.__class__(avalue, tuple(c for c in arg.childs()), parent=self)]     # one item in childs : the subtree
                        else :
                            roots += [self.__class__(c, parent=self) for c in arg.childs()]                    # all childs of subtree in childs
                elif isSequence(arg) :
                    # we use sequences to encapsulate childs

                    # Check if the previous argument was a value,
                    # to see if this is a valid child list
                    if not previousWasValue:
                        raise ValueError('Child sequence must immediately follow a non-sequence value when initializing a tree')

                    childs = []
                    d = {'parent':self}
                    sub = self.__class__(*arg, **d)
                    if sub.value :
                        childs = [sub]
                    else :
                        childs = list(sub.childs())
                    # add resulting childs if any
                    if childs :
                        # parent to previous entry, childs are already self.__class__ copies
                        # coming from a sequence expansion
                        for c in childs :
                            c._pRef = weak.ref(roots[-1])
                        roots[-1]._subtrees = self.__class__._toSubtree(childs)
                elif arg is not None :
                    isValue = True
                    # argument at top level is a root
                    sub = self.__class__()
                    sub._pRef = pRef
                    sub._value = arg
                    roots.append(sub)

                else :
                    raise ValueError, "None cannot be a tree element"
                previousWasValue = isValue


            if not roots :
                self._pRef = None
                self._value = None
                self._subtrees = None
            elif len(roots) == 1 :
                # we don't need the None root if the tree is not a forest
                self._pRef = pRef
                self._value = roots[0]._value               # roots is filled with copies so not need to copy again
                self._subtrees = roots[0]._subtrees
            else :
                # more than one root, a None root as added on top
                self._pRef = pRef
                self._value = None
                self._subtrees = self.__class__._toSubtree(roots)
            # update the weak refs of childs to self
            for sub in self.childs() :
                sub._pRef = weak.ref(self)

    class IndexedPyTree :
        """ Additionnal methods for pure python indexed trees implementation, elements must have unique values
            or Tree class must define a key method that provides a unique key for each element """
        # To the PyTree methods an index that for each of the subtree elements (as keys)
        # keeps a weak references to the subtree
        _index = weak.WeakValueDictionary()

        # unique key based on top element value, by default just return element value
        # but can be overriden. For instance use long name instead of just short name for a a node
        # will allow to store a hierarchy of Maya nodes with duplicate names
        def _get_key(self):
            return self._value
        # key of an element relative to self, returns a tuple of keys for the whole path self-> element
        def elementKey(self, element):
            pass

        # _set_parent must update the index of the parent
        @mutabletree
        def _set_parent(self, parent) :
            oldparent = self.parent
            super(IndexedPyTree, self)._set_parent(parent)
            if parent != oldparent :
                oldparent._index.pop(self._get_key())
                for sub in self.preorder() :
                    parent._index[sub._get_key()] = sub
        # indexing will allow more efficient ways for the following methods than with non indexed trees
        # equivalence, __contains__
        # added equivalence test here
#        def __eq__(self, other):
#            """Checks for equality of two trees."""
#            #Both trees not empty.
#            if self and other:
#                #Compare values.
#                if self is other :
#                    return True
#                elif self.value != self.__class__(other).value:
#                    return False
#                elif len(self) != len(other) :
#                    return False
#                else :
#                    return reduce(lambda x, y:x and y, map(lambda c1, c2:c1 == c2, self.childs(), other.childs()), True)
#            #Both trees empty.
#            elif not self and not other:
#                return True
#            else:
#                return False
#        def __ne__(self, other):
#            return not self.__eq__(other)
#        # compare using only top value (if compare is defined for value type) or all values ?
#        def __contains__(self, element):
#            """Returns True if element is in the tree, False otherwise."""
#            if self :
#                if not isinstance(element, self.__class__) :
#                    element = self.__class__(element)
#                return self._index.has_key(element._get_key())
#            else :
#                return False
#        # identity, not equivalence test
#        def issubtree(self, other) :
#            if isinstance(other, self.__class__) :
#                key = self._get_key()
#                if other._index.has_key(key) :
#                    return other._index[key] is self
#            return False
        # get and __getitem
        # get the matching subtree to that subtree or element, will be redefined in the case of an indexed tree
        # not that it can return a tuple if same element/subtree is present more than once in tree
        def __getitem__(self,value):
            """ Get a subtree from the Tree, given an element or value.
                Note that to be consistent with __getitem__ usual behavior, it will raise an exception
                it it doesn't find exactly one match (0 or more), method get will be more user friendly
                on non indexed trees.
                It's also possible to seek a path : a list of elements or values, it will limit the results
                to the subtrees that match the last item of the path, and whose parents match the path.
                A path can be relative, or absolute if starting with None as first item """
            result = self.get(value)
            l = len(result)
            if l==1 :
                return result[0]
            elif l == 0 :
                raise KeyError, "No  match for %s in Tree" % value
            else :
                raise KeyError, "More than one match for %s in Tree (%i found)" % (value, l)

        def get(self, value, default=tuple()):
            """ Identical to the __getitem__ method but will return a default value instead of raising KeyError
                if nor result is found """
            result = []
            # use index for faster find
            if isTree(value) :
                # do a faster check in case value is a subtree of self
                if value.issubtree(self) :
                    return [value]
                # normal equivalence test
                for e in self.breadth() :
                    if value == e :
                        result.append(e)
            elif isSequence(value) :
                # we seek a path, a list of value that must be found in order,
                # if list starts with None it means it's an absolute path (starting at root)
                if value :
                    if value[0] is None :
                        result = [self]
                    else :
                        result += list(self.get(value[0]))
                    for p in value[1:] :
                        if result :
                            found = []
                            for t in result :
                                for c in t.childs() :
                                    if c.value == self.__class__(p).value :
                                        found.append(c)
                            result = found
                        else :
                            break
            else :
                for e in self.breadth() :
                    if value == e.value :
                        result.append(e)
            if not result :
                return default
            else :
                return tuple(result)



    class NxTree :
        """ Core methods for trees based on the networkx library, these trees are indexed by implementation (name of an element must be unique) """


    # now the methods for an immutable tree, not depending on implementation
    class ImTree :
        """The methods for an immutable Tree class."""

        # Iterators all returns trees/elements, use the value property to get value
        # note: inorder traversal could be defined for binary trees
        def preorder(self):
            """The standard preorder traversal iterator."""
            if self:
                yield self
                for subtree in self.childs():
                    for tree in subtree.preorder():
                        yield tree

        def postorder(self):
            """Postorder traversal of a tree."""
            if self:
                for subtree in self.childs():
                    for tree in subtree.postorder():
                        yield tree
                yield self

        def breadth(self):
            """Breadth first traversal of a tree."""
            if self:
                yield self
                deq = deque(x for x in self.childs())
                while deq :
                    arg = deq.popleft()
                    yield arg
                    for a in arg.childs() :
                        deq.append (a)

        def child (self, index=0):
            """ Returns nth child (by default first), is it exists """
            try :
                childs = [k for k in self.childs()]
                return childs[index]
            except :
                return None
        def parents (self):
            """Returns an iterator on path from element to top root, starting with first parent, empty iterator means self is root"""
            #parents = []
            #parent = self.parent
            #while parent :
            #    parents.append(parent)
            #    parent = parent.parent
            #return iter(parents)
            parent = self.parent
            while parent :
                yield parent
                parent = parent.parent
        def root (self):
            """ Root node of self, if self is a subtree, will travel up to top most node of containing tree """
            root = self
            parent = self.parent
            while parent :
                if parent.value :
                    root = parent
                parent = parent.parent
            return root
        def tops (self):
            """ Iterator on the top nodes of self, the subtrees that have no parent in self,
                will yield only self if self isn't a forest """
            if self.value :
                    yield self
            else :
                for c in self.childs() :
                    yield c
        def top (self, index=0):
            """ The nth top node of self (by default first) """
            try :
                tops = [k for k in self.tops()]
                return tops[index]
            except :
                return None
        def depth (self) :
            """Depth of self, the distance to self's root"""
            parents = self.parents()
            depth = 0
            for p in parents :
                depth += 1
            return depth
        def leaves(self):
            """ Get an iterator on all leaves under self """
            for elem in self.preorder() :
                if not elem.hasChilds() :
                    yield elem
        def level(self, dist=0):
            """ Get an iterator on all elements at the specified distance of self, negative distance means up, positive means down """
            deq = deque((self, 0))
            while deq :
                arg, level = deq.popleft()
                if level == dist :
                    yield arg
                elif level > dist :
                    if arg.parent :
                        deq.append((arg.parent, level-1))
                else :
                    for c in arg.childs() :
                        deq.append((c, level+1))

        # Comparison, contains, etc
        #Number of elements in the tree.
        def size(self):
            """Returns the number of elements (nodes) in the tree."""
            ret = 0
            for s in self.preorder():
                ret += 1
            return ret
        # use it for len(self)
        __len__ = size
        def height(self):
            """ Get maximum downward depth (distance from element to furthest leaf downwards of it) of the tree """
            max_depth=0
            deq = deque((self,0))
            while deq :
                arg, level = deq.popleft()
                if arg.value :
                    level += 1
                if not arg.isElement() :
                    for a in arg.childs() :
                        deq.append ((a, level))
                else :
                    if level > max_depth :
                        max_depth = level
            return max_depth

        # this can be redefined for trees where the uniqueness of the elements can allow a more efficient search
        def _pathIter (self, element, depth=0, found=None, down=False, up=False):
            # test if we have a hit
            if self == element :
                return ((self,), 0)
            # abort if a path of length 'found' that is not more than depth+! has been found,
            # as we will explore parent or childs of self, shortest path we can still
            # hope to find in this branch is of length depth+1
            if found is not None and not abs(found) > abs(depth) + 1 :
                return ((), None)
            # else keep searching
            seekup = None
            seekdown = None
            dirup = None
            dirdown = None
            if up and self.parent :
                p_path, dirup = self.parent._pathIter(element, up=True, depth=depth-1, found=found)
                if dirup is not None :
                    seekup = (self,)+p_path
                    dirup -= 1
                    found = dirup + depth
            # means if a match is found upwards and downwards at equal distance, the upwards match will be preferred
            if down and (found is None or abs(found) > abs(depth) + 1) :
                bestdirdown = None
                for c in self.childs() :
                    c_path, dirdown = c._pathIter(element, down=True, depth=depth+1, found=found)
                    if dirdown is not None :
                        c_path = (self,)+c_path
                        dirdown += 1
                        if not bestdirdown or dirdown < bestdirdown :
                            seekdown = c_path
                            bestdirdown = dirdown
                            found = dirdown + depth
                            # no need to check rest of childs now if found is just depth + 1
                            if not dirdown > 1 :
                                break
                # finally down distance is the best down distance found amongst childs
                dirdown = bestdirdown

            # retain shortest path and direction
            if dirup is not None and dirdown is not None:
                # for equal distance, prefer up
                if abs(dirup) <= abs(dirdown) :
                    path = seekup
                    direction = dirup
                else :
                    path = seekdown
                    direction = dirdown
            elif dirup is not None :
                # found only upwards
                path = seekup
                direction = dirup
            elif dirdown is not None :
                # found only downwards
                path = seekdown
                direction = dirdown
            else :
                # not found
                path = ()
                direction = None

            return (path, direction)

        # note it's not a true iterator as anyway we need to build handle lists to find shortest path first
        def path (self, element=None, **kwargs):
            """ Returns an iterator of the path to specified element if found, including starting element,
                empty iterator means no path found.
                For trees where duplicate values are allowed, shortest path to an element of this value is returned.
                element can be an ancestor or a descendant of self, if no element is specified, will return path from self's root to self
                up keyword set to True means it will search ascendants(parent and parents of parent) self for element, default is False
                down keyword set to True means it will search descendants(childs and childs of childs) of self for element, default is False
                If neither up nor down is specified, will search both directions
                order keyword defines in what order the path will be returned and can be set to 'top', 'bottom' or 'self', order by default is 'top'
                'top' means path will be returned from ancestor to descendant
                'bottom' means path will be returned from descendant to ancestor
                'self' means path will be returned from self to element """
            # By default returns path from self's root to self
            if element is None :
                path = (self,)+tuple(self.parents())
                direction = -len(path)
            else :
                if not isTree(element) :
                    element = self.__class__(element)
                up = kwargs.get("up", False)
                down = kwargs.get("down", False)
                if not (up or down) :
                    up = down = True
                path, direction = self._pathIter(element, depth=0, found=None, up=up, down=down)
            # in what order to return path
            # default : by hierarchy order, top to down, but can be returned start (self) to end (element)
            if direction is not None :
                order = kwargs.get("from", 'top')
                if order is 'top' :
                    if direction < 0 :
                        path = tuple(reversed(path))
                elif order is 'bottom' :
                    if direction > 0 :
                        path = tuple(reversed(path))
                elif order is 'self' :
                    path = tuple(path)
                else :
                   raise ValueError, "Unknown order '%s'" % order
            return iter(path)

        def dist (self, element, **kwargs):
            """ Returns distance from self to element, 0 means self==element, None if no path exists
                up keyword set to True means it will search ascendants(parent and parents of parent) self for element, default is False
                down keyword set to True means it will search descendants(childs and childs of childs) of self for element, default is False
                If neither up nor down is specified, will search both directions
                signed keyword set to true means returns negative distance when element is upwards self, positive when it's downwards """
            up = kwargs.get("up", False)
            down = kwargs.get("down", False)
            signed = kwargs.get("signed", False)
            if not (up or down) :
                up = down = True
            path,direction = self._pathIter (element, depth=0, found=None, down=down, up=up)
            if not signed :
                direction = abs(direction)
            return direction

         # TODO: make it match new __init__
        # - use [] for child lists, () for value/children pairs
        # make str, unicode, repr
        # str, unicode, represent
        def _strIter(self):
            res = ""
            value = self.value
            if value is not None:
                res = "'%s'" % str(value)
            temp = [sub._strIter() for sub in self.childs()]
            if temp :
                if res :
                    res += ", (%s)" % ", ".join(temp)
                else :
                    res = ", ".join(temp)
            return res

        # TODO: make it match new __init__
        # - use [] for child lists, () for value/children pairs
        def __str__(self):
            if self:
                return "(%s)" % (self._strIter())
            else:
                return "()"

        def _unicodeIter(self):
            res = u""
            value = self.value
            if value :
                res = u"'%s'" % unicode(value)
            temp = [sub._unicodeIter() for sub in self.childs()]
            if temp :
                if res :
                    res += u", (%s)" % u", ".join(temp)
                else :
                    res = u", ".join(temp)
            return res

        def __unicode__(self):
            if self:
                return u"(%s)" % (self._unicodeIter())
            else:
                return u"()"

        def _reprIter(self):
            res = ""
            value = self.value
            temp = [sub._strIter() for sub in self.childs()]
            if value :
                res = "%r" % value
            if temp :
                if res :
                    res += ", (%s)" % ", ".join(temp)
                else :
                    res = ", ".join(temp)
            return res

        def __repr__(self):
            if self:
                return "%s(%s)" % (self.__class__.__name__, self._reprIter())
            else:
                return "()"


        def formatted(self, returnList=False):
            """ Returns an indented string representation of the tree """
            # Changed print character from '>', so that doctest doesn't get
            # confused!
            # ...also made it a little prettier

            hasBranchChar = "|-"  # Ideally, would look like '+' with no left arm
            noBranchChar = "| "
            endBranchChar = "\-"  # Ideally, would look ike '+' with no left or bottom arm
            emptyBranchChar = "  "
            hasChildrenChar = "+: " # Ideally, would look like '+' with no top arm
            noChildrenChar = "-: "
            treeSep = ''
            lines = []
            if self :
                value = self.value

                children = tuple(self.childs())

                if value is not None:
                    if children:
                        valuePrefix = hasChildrenChar
                    else:
                        valuePrefix = noChildrenChar
                    lines.append(valuePrefix + str(value))

                for childNum, child in enumerate(children):
                    childLines = child.formatted(returnList=True)
                    if len(childLines)>0:
                        if value is None:
                            # we've got a forest - print all children 'as is'
                            childPrefix = grandChildPrefix = ""
                        elif childNum < (len(children) - 1):
                            # We've got a "middle" child - use 'hasBranchChar' and 'noBranchChar'
                            childPrefix = hasBranchChar
                            grandChildPrefix = noBranchChar
                        else:
                            # We've got an "end" child - use 'endBranchChar' and 'emptyBranchChar'
                            childPrefix = endBranchChar
                            grandChildPrefix = emptyBranchChar
                        lines.append(childPrefix + childLines[0])
                        for grandChild in childLines[1:]:
                            lines.append(grandChildPrefix + grandChild)
                    if value is None and childNum < (len(children) - 1):
                        # if we have a forest, add a treeSep between trees
                        lines.append(treeSep)

            if returnList:
                return lines
            else:
                return "\n".join(lines)

        def view(self):
            """
            Shortcut for print(self.formatted())
            """
            print(self.formatted())

        def debug(self, depth=0):
            """ Returns an detailed representation of the tree fro debug purposes"""
            if self :
                parent = self.parent
                pvalue = None
                if parent :
                    pvalue = parent.value
                next = self.next
                nvalue = None
                if next :
                    nvalue = next.value
                result = u">"*depth+u"r:%r<%i>" % (self.value, id(self))
                if parent :
                    result += ", p:%r<%i>" % (pvalue, id(parent))
                else :
                    result += ", p:None"
                if next :
                    result += ", n:%r<%i>" % (nvalue, id(next))
                else :
                    result += ", n:None"
                result += "\n"
                for a in self.childs() :
                    result += a.debug(depth+1)
                return result

        def copy(self, cls = None):
            """ Shallow copy of a tree.
                An extra class argument can be given to copy with a different
                (tree) class. No checks are made on the class. """
            if cls is None:
                cls = self.__class__
            if self:
                if self.value :
                    subtrees = (self.value,tuple(self.childs()))
                else :
                    subtrees = tuple(self.childs())
                return cls(*subtrees)
            else:
                return cls()

        # TODO : isParent (tree, other), isChild(tree, other), inter, union, substraction ?

    # now the methods for an mutable tree, not depending on implementation
    class MuTree :
        """Additionnal methods for a Mutable Tree class."""

        # Edit methods that are defined for mutable trees
        def __setitem__(self, element, value):
            pass


        def graft(self, element, parent=None, next=None):
            """ Attach element to self.
                If parent is secified, will be grafted as last child of parent (or before child 'next'),
                if parent is not in self, will raise an exception,
                if parent is None will be grafted at top level of self, besides any existing root(s).
                If next is specified, self will be grafted before next in the list of parent's childs,
                if next is not in parent's childs, will raise an exception,
                if next is None, self will be grafted as last child under parent. """
            self.add(element, parent, next)

        def prune(self, element) :
            """ Ungrafts element from self, with everything under it """
            element = self[element]
            self.remove(element)

        def pop(self, element) :
            """ Delete top node of self and reparent all it's subtrees under it's current parent.
                If self was a root all it's subtrees become separate trees of a forest under the 'None' root.
                self will now have the new parent as top node """
            element = self[element]
            parent = element.parent
            for c in element.childs() :
                self.graft(c, parent)
            self.remove(element)

        # TODO: reroot, in-place intersection, union, sub etc
        def reroot(self, element) :
            """ Reroot self so that element is self new top node """
            pass


    # class creation using the method of the above class to populate a new class depending on
    # class creation options (mutable, indexed, etc)
    def __new__(mcl, classname, bases, classdict):
        # Build a Tree class deriving from a base iterable class, base class must have methods __init__,  __iter__ and __nonzero__
        # by default use list
#        if not bases :
#            bases = (list, )
        # check if base meets requirement, either we derive from another Tree class or from the type that will be used for internal storage
        mutable = None
        indexed = None
        # check for keywords
        if classdict.has_key('mutable') :
            mutable = (classdict['mutable'] == True)
            del classdict['mutable']
        if classdict.has_key('indexed') :
            indexed = (classdict['indexed'] == True)
            del classdict['indexed']
        treeType = None
        # default storage types depending on type of tree
        if mutable :
            treeType = list
        else :
            treeType = tuple
        # check base classes
        newbases = []
        for base in bases :
            if type(base) == MetaTree :
                mubase = hasattr(base, 'add')
                inbase = hasattr(base, 'key')
                # Tree type is most complete type of all base classes
                if treeType == None or (not mutable and mubase) or (not indexed and inbase) :
                    treeType = base._TreeType
                    mutable = mubase
                    indexed = inbase
            # if we need to filter base classes ?
            newbases.append(base)

        # if we couldn't determine a tree type from keywords or base classes, raise an exception
        if not treeType :
            raise TypeError, "Tree classes must derive from another Tree class, or an iterable type that defines __init__, __iter__ and __nonzero__ at least"
        # store the type of iterable used to represent the class subtrees
        newbases = tuple(newbases)

        # build dictionnary for that class
        newdict = {}
        # methods depending on implementations
        coredict = {}
        # if networkx not present
        BaseCoreClass = []
        if not indexed :
            BaseCoreClass = [MetaTree.PyTree]
        else :
            # for indexed trees use networkx if present
            if networkxLoad :
                BaseCoreClass = [MetaTree.NxTree]
            else :
                BaseCoreClass = [MetaTree.PyTree, MetaTree.IndexedPyTree]
        # build core directory form the core base class methods
        for c in BaseCoreClass :
            for k in c.__dict__.keys() :
                # drawback of organising methods in "fake" classes is we get an unneeded entries, like __module__
                if k not in ('__module__') :
                    coredict[k] = c.__dict__[k]
        # use methods of core implementation that are relevant to this type of trees
        for k in coredict :
            m = coredict[k]
            if mutable or not hasattr(m, 'mutabletree') :
                newdict[k] = coredict[k]

        # set properties read only or read-write depending on the available methods
        newdict['value'] = property(newdict.get('_get_value', None), newdict.get('_set_value', None), None, """ Value of the top element of that tree """)
        newdict['parent'] = property(newdict.get('_get_parent', None), newdict.get('_set_parent', None), None, """ The parent tree of that tree, or None if tree isn't a subtree """)
        newdict['next'] = property(newdict.get('_get_next', None), newdict.get('_set_next', None), None, """ Next tree in the siblings order, or None is self doesn't have siblings """)
        if indexed :
            newdict['key'] = property(newdict.get('_get_key', None), newdict.get('_set_key', None), None, """ Unique key of the element for indexed trees """)

        # upper level methods, depending on type of tree
        # only restriction is you cannot override core methods
        basedict = dict(MetaTree.ImTree.__dict__)
        if mutable :
            # add the mutable methods
            mutabledict = dict(MetaTree.MuTree.__dict__)
            basedict.update(basedict, **mutabledict)

        # update with methods declared at class definition
        basedict.update(basedict, **classdict)
        # methods that must be defined here depending on the preceding

        # add  methods unless they clash with core methods
        for k in basedict :
            if k in newdict :
                if k == '__doc__' :
                    newdict[k] = newdict[k] + "\n" + basedict[k]
                else :
                    warnings.warn("Can't override core method or property %s in Trees (trying to create class '%s')" % (k, classname))
            else :
                newdict[k] = basedict[k]

        # set class tree type
        newdict['_TreeType'] = treeType
        # delegate rest of the work to type.__new__
        return super(MetaTree, mcl).__new__(mcl, classname, newbases, newdict)

    # will get called after __new__
#    def __init__(cls, name, bases, classdict) :
#        print cls
#        print name
#        print bases
#        print classdict


    #To get info on the kind of tree class that was created
    def __get_TreeType(cls):
        return cls._TreeType
    TreeType = property(__get_TreeType, None, None, "The type used for internal tree storage for that tree class.")

    def __repr__(cls):
        return "%s<TreeType:%r>" % (cls.__name__, cls.TreeType)

    def __str__(cls):
        return "%s<TreeType:%r>" % (cls.__name__, cls.TreeType)

    def __unicode__(cls):
        return u"%s<TreeType:%r>" % (cls.__name__, cls.TreeType)

# derive from one of these as needed
class FrozenTree(object):
    __metaclass__ =  MetaTree
    mutable = False
    indexed = False

class Tree(object):
    __metaclass__ =  MetaTree
    mutable = True
    indexed = False

class IndexedFrozenTree(object):
    __metaclass__ =  MetaTree
    mutable = False
    indexed = True

class IndexedTree(object):
    __metaclass__ =  MetaTree
    mutable = True
    indexed = True

def treeFromDict (arg):
    """
    This function will build a tree from the provided dictionnary of child:parent relations :
        where each key represent an element and each key value represent the parent of that element, allows to build Trees form
        cmp(a,b): returns True if a is a direct child of b, False else.
        All elements must be present in the dictionnary keys, with root elements having None as value/parent
    """
    if isinstance(arg, dict) :
        def isChildFn (a, b):
            return arg.get(a, None) == b
        s = set(arg.keys())
        for v in arg.values() :
            s.add(v)
        return treeFromChildLink (isChildFn, *s)
    else :
        raise ValueError ("%r is not a dictionnary" % arg)

def treeFromChildLink (isExactChildFn, *args):
    """
    This function will build a tree from the provided sequence and a comparison function in the form:
        cmp(a,b): returns True if a is a direct child of b, False else

        >>> lst = ['aab', 'aba', 'aa', 'bbb', 'ba', 'b', 'a', 'bb', 'ab', 'bab', 'bba']
        >>> def isDirectChild(s1, s2) :
        ...     return s1.startswith(s2) and len(s1)==len(s2)+1
        >>> a = treeFromChildLink (isDirectChild, *lst)
        >>> a.sort()
        >>> print a.formatted()
        +: a
        |-+: aa
        | \--: aab
        \-+: ab
          \--: aba
        <BLANKLINE>
        +: b
        |-+: ba
        | \--: bab
        \-+: bb
          |--: bba
          \--: bbb
        >>>
        >>> # A child cannot have more than one parent, if the isChild is ambiguous an exception will be raised
        >>>
        >>> def isChild(s1, s2) :
        ...     return s1.startswith(s2)
        >>> failedTree = treeFromChildLink (isChild, *lst)
        Traceback (most recent call last):
            ...
        ValueError: A child in Tree cannot have multiple parents, check the provided isChild(c, p) function: 'isChild'
    """
    deq = deque()
    for arg in args :
        deq.append(Tree(arg))
    lst = []
    it = 0
    while deq:
        it+=1
        #print "iteration %i deq= %s, lst= %s"% (it, deq, lst)
        c = deq.popleft()
        hasParent = False
        for p in list(deq)+lst :
            pars = filter(lambda x:isExactChildFn(c.top().value, x.value), p.preorder())
            for pr in pars :
                #print "%s is child of %s" % (c, pr)
                if not hasParent :
                    pr.graft(c, pr)
                    hasParent = True
                else :
                    # should only be one parent, break on first encountered
                    raise ValueError, "A child in Tree cannot have multiple parents, check the provided isChild(c, p) function: '%s'" % isExactChildFn.__name__
        # If it's a root we move it to final list
        if not hasParent :
            #print "%s has not parent, it goes to the list as root" % str(c)
            lst.append(c)

    # print "final list %s" % str(lst)
    return Tree(*lst)

def treeFromIsChild(isChildFn, *elements):
    """
    This function will build a tree from the provided sequence and a comparison function in the form:
        isChildFn(c,p): returns True if c is a child of p (direct or indirect), False otherwise

    The comparison function must satisfy the following conditions for all a, b, and c in the tree:
        isChildFn(a,a) == False
            (an object is not a child of itself)
        if isChildFn(a,b) AND isChildFn(b,c), then isChildFn(a,c)
            (indirect children are inherited)
        if isChildFn(a,b) AND isChildFn(a,c), then isChildFn(b,c) OR isChildFn(c,b) OR b==c
            (if a child has two distinct parents, then one must be the parent of the other)

    If any member of elements is itself a Tree, then it will be treated as a subtree (or subtrees, in the
    case of a forest) to be merged into the returned tree structure; for every root in such a subtree,
    the structure below the root will be unaltered, though the entire subtree itself may be parented to
    some other member of elements.

    >>> lst = ['aab', 'aba', 'aa', 'ba', 'bbb', 'a', 'b', 'bb', 'ab', 'bab', 'bba']
    >>> def isChild(s1, s2) :
    ...     return s1.startswith(s2)
    >>> a = treeFromIsChild (isChild, *lst)
    >>> a.sort()
    >>> print a.formatted()
    +: a
    |-+: aa
    | \--: aab
    \-+: ab
      \--: aba
    <BLANKLINE>
    +: b
    |-+: ba
    | \--: bab
    \-+: bb
      |--: bba
      \--: bbb
    """
    newTree = Tree()

    unordered = deque()

    # First, check for subtrees
    for element in elements:
        if isTree(element):
            for subTree in element.tops():
                newTree.add(subTree)
        else:
            unordered.append(element)

    # Then, go through unordered, making the subtrees rooted at each element
    while unordered:
        root = unordered.pop()
        children = deque()

        # iterate over a copy of unordered, since we're modifying it
        index = 0
        for val in deque(unordered):
            if isChildFn(val, root):
                children.append(val)
                del unordered[index]
            else:
                # Note that we only increment the index if we don't
                # delete an element... if we do delete an element,
                # our old index points at the next element already
                index += 1

        # Then check the subtrees, to see which are children of our root...
        for subTree in list(newTree.tops()):
            if isChildFn(subTree.value, root):
                children.append(subTree)
                newTree.remove(subTree)

        # ...then use recursion to make a new subTree with our new root
        newTree.add(root)
        newSubTree = newTree.top(-1)
        assert(newSubTree.value == root)
        #treeFromIsChild(isChildFn, *children).parent = newSubTree
        childForest = treeFromIsChild(isChildFn, *children)
        childForest.parent = newSubTree

    return newTree
#
#class DirTree(Tree):
#    """
#    A tree structure describing a directory hierarchy.
#    """
#    def __init__(self, dir=None):
#        """
#        Creates a DirTree rooted at the given directory
#
#        Can be initialized by passing in a single argument, which
#        if supplied, must be a path to a directory that exists
#        on the filesystem.
#
#        If the given directory does not exist on the filesystem,
#        a ValueError is raised.
#
#        >>> myDirTree = DirTree()
#        >>> myDirTree.value = 'root'
#        >>> myDirTree.add('foo')
#        >>> myDirTree.add('bar', parent='foo')
#        >>> myDirTree.add('other')
#        >>> myDirTree.view()
#        +: root
#        |-+: foo
#        | \--: bar
#        \--: other
#        """
#        if not os.path.isdir(dir):
#            raise ValueError("%s is not a valid directory" % dir)
#
#        super(DirTree, self).__init__()
#
#        if dir:
#            basename = ""
#            while not basename and dir:
#                dir, basename = os.path.split(dir)
#            self.value = basename
#            for entry in os.listdir(dir):
#                path = os.path.join(dir, entry)
#                if os.path.isdir(path):
#                    subTree = _pymelDirTree_recurse(path)
#                    self.add(subTree)
#
#    def dirPath(self, *args, **kwargs):
#        """
#        Returns a string representing the directory path from the root to this element.
#        """
#        dirs = [dir.value for dir in self.path()]
#        return os.path.join(dirs)

# unit test with doctest
if __name__ == '__main__' :
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = utilitytypes
"""
Defines common types and type related utilities:  Singleton, etc.
These types can be shared by other utils modules and imported into util main namespace for use by other pymel modules
"""

import inspect, types, operator, sys, warnings

class Singleton(type):
    """ Metaclass for Singleton classes.

        >>> class DictSingleton(dict) :
        ...    __metaclass__ = Singleton
        ...
        >>> DictSingleton({'A':1})
        {'A': 1}
        >>> a = DictSingleton()
        >>> a
        {'A': 1}
        >>> b = DictSingleton({'B':2})
        >>> a, b, DictSingleton()
        ({'B': 2}, {'B': 2}, {'B': 2})
        >>> a is b and a is DictSingleton()
        True

        >>> class StringSingleton(str) :
        ...    __metaclass__ = Singleton
        ...
        >>> StringSingleton("first")
        'first'
        >>> a = StringSingleton()
        >>> a
        'first'
        >>> b = StringSingleton("changed")
        >>> a, b, StringSingleton()
        ('first', 'first', 'first')
        >>> a is b and a is StringSingleton()
        True

        >>> class DictSingleton2(DictSingleton):
        ...     pass
        ...
        >>> DictSingleton2({'A':1})
        {'A': 1}
        >>> a = DictSingleton2()
        >>> a
        {'A': 1}
        >>> b = DictSingleton2({'B':2})
        >>> a, b, DictSingleton2()
        ({'B': 2}, {'B': 2}, {'B': 2})
        >>> a is b and a is DictSingleton2()
        True

    """
    def __new__(mcl, classname, bases, classdict):

        # newcls =  super(Singleton, mcl).__new__(mcl, classname, bases, classdict)

        # redefine __new__
        def __new__(cls, *p, **k):
            if '_the_instance' not in cls.__dict__:
                cls._the_instance = super(newcls, cls).__new__(cls, *p, **k)
            return cls._the_instance
        newdict = { '__new__': __new__}
        # define __init__ if it has not been defined in the class being created
        def __init__(self, *p, **k):
            cls = self.__class__
            if p :
                if hasattr(self, 'clear') :
                    self.clear()
                else :
                    super(newcls, self).__init__()
                super(newcls, self).__init__(*p, **k)
        if '__init__' not in classdict :
            newdict['__init__'] = __init__
        # Note: could have defined the __new__ method like it is done in Singleton but it's as easy to derive from it
        for k in classdict :
            if k in newdict :
                warnings.warn("Attribute %r is predefined in class %r of type %r and can't be overriden" % (k, classname, mcl.__name__))
            else :
                newdict[k] = classdict[k]

        newcls =  super(Singleton, mcl).__new__(mcl, classname, bases, newdict)

        return newcls

class metaStatic(Singleton) :
    """ A static (immutable) Singleton metaclass to quickly build classes
        holding predefined immutable dicts

        >>> class FrozenDictSingleton(dict) :
        ...    __metaclass__ = metaStatic
        ...
        >>> FrozenDictSingleton({'A':1})
        {'A': 1}
        >>> a = FrozenDictSingleton()
        >>> a
        {'A': 1}
        >>> b = FrozenDictSingleton()
        >>> a, b
        ({'A': 1}, {'A': 1})
        >>> a is b
        True

        >>> b = FrozenDictSingleton({'B':2})
        Traceback (most recent call last):
            ...
        TypeError: 'FrozenDictSingleton' object does not support redefinition

        >>> a['A']
        1
        >>> a['A'] = 2   #doctest: +ELLIPSIS
        Traceback (most recent call last):
            ...
        TypeError: '<class '...FrozenDictSingleton'>' object does not support item assignation

        >>> a.clear()
        Traceback (most recent call last):
            ...
        AttributeError: 'FrozenDictSingleton' object has no attribute 'clear'

        >>> a, b, FrozenDictSingleton()
        ({'A': 1}, {'A': 1}, {'A': 1})
        >>> a is b and a is FrozenDictSingleton()
        True

        >>> class StaticTest(FrozenDictSingleton):
        ...     pass
        ...
        >>> StaticTest({'A': 1})
        {'A': 1}
        >>> a = StaticTest()
        >>> a
        {'A': 1}
        >>> b = StaticTest()
        >>> a, b
        ({'A': 1}, {'A': 1})

        >>> class StaticTest2( StaticTest ):
        ...     pass
        ...
        >>> StaticTest2({'B': 2})
        {'B': 2}
        >>> a = StaticTest2()
        >>> a
        {'B': 2}
        >>> b = StaticTest2()
        >>> a, b
        ({'B': 2}, {'B': 2})

    """
    def __new__(mcl, classname, bases, classdict):
        """
        """
        # redefine __init__
        def __init__(self, *p, **k):
            cls = self.__class__
            # Can only create once)
            if p :
                # Can only init once
                if not self:
                    return super(newcls, self).__init__(*p, **k)
                else :
                    raise TypeError, "'"+classname+"' object does not support redefinition"
        newdict = { '__init__':__init__}
        # hide methods with might herit from a mutable base
        def __getattribute__(self, name):
            if name in newcls._hide :
                raise AttributeError, "'"+classname+"' object has no attribute '"+name+"'"
            else :
                return super(newcls, self).__getattribute__(name)
        newdict['__getattribute__'] = __getattribute__
        _hide = ('clear', 'update', 'pop', 'popitem', '__setitem__', '__delitem__', 'append', 'extend' )
        newdict['_hide'] = _hide
        # prevent item assignation or deletion
        def __setitem__(self, key, value) :
            raise TypeError, "'%s' object does not support item assignation" % (self.__class__)
        newdict['__setitem__'] = __setitem__
        def __delitem__(self, key):
            raise TypeError, "'%s' object does not support item deletion" % (self.__class__)
        newdict['__delitem__'] = __delitem__
        # Now add methods of the defined class, as long as it doesn't try to redefine
        # Note: could have defined the __new__ method like it is done in Singleton but it's as easy to derive from it
        for k in classdict :
            if k in newdict :
                warnings.warn("Attribute %r is predefined in class %r of type %r and can't be overriden" % (k, classname, mcl.__name__))
            else :
                newdict[k] = classdict[k]

        newcls = super(metaStatic, mcl).__new__(mcl, classname, bases, newdict)

        return newcls

try:
    from collections import defaultdict
except:
    class defaultdict(dict):
        def __init__(self, default_factory=None, *a, **kw):
            if (default_factory is not None and
                not hasattr(default_factory, '__call__')):
                raise TypeError('first argument must be callable')
            dict.__init__(self, *a, **kw)
            self.default_factory = default_factory
        def __getitem__(self, key):
            try:
                return dict.__getitem__(self, key)
            except KeyError:
                return self.__missing__(key)
        def __missing__(self, key):
            if self.default_factory is None:
                raise KeyError(key)
            self[key] = value = self.default_factory()
            return value
        def __reduce__(self):
            if self.default_factory is None:
                args = tuple()
            else:
                args = self.default_factory,
            return type(self), args, None, None, self.iteritems()
        def copy(self):
            return self.__copy__()
        def __copy__(self):
            return type(self)(self.default_factory, self)
        def __deepcopy__(self, memo):
            import copy
            return type(self)(self.default_factory,
                              copy.deepcopy(self.items()))

        def __repr__(self):
            return 'defaultdict(%s, %s)' % (self.default_factory,
                                            dict.__repr__(self))

class defaultlist(list):

    def __init__(self, default_factory, *args, **kwargs ):
        if (default_factory is not None and
            not hasattr(default_factory, '__call__')):
            raise TypeError('first argument must be callable')
        list.__init__(self,*args, **kwargs)
        self.default_factory = default_factory

    def __setitem__( self, index, item ):
        try:
            list.__setitem__(self, index, item)
        except IndexError:
            diff = index - len(self) - 1
            assert diff > 0
            self.extend( [self.default_factory() ] * diff + [item] )

    def __getitem__(self, index):
        try:
            return list.__getitem__(self, index)
        except IndexError:
            return self.default_factory()


class ModuleInterceptor(object):
    """
    This class is used to intercept an unset attribute of a module to perfrom a callback. The
    callback will only be performed if the attribute does not exist on the module. Any error raised
    in the callback will cause the original AttributeError to be raised.

        def cb( module, attr):
             if attr == 'this':
                 print "intercepted"
             else:
                 raise ValueError
        import sys
        sys.modules[__name__] = ModuleInterceptor(__name__, cb)
        intercepted

    The class does not work when imported into the main namespace.
    """
    def __init__(self, moduleName, callback):
        self.module = __import__( moduleName , globals(), locals(), [''] )
        self.callback = callback
    def __getattr__(self, attr):
        try:
            return getattr(self.module, attr)
        except AttributeError, msg:
            try:
                self.callback( self.module, attr)
            except:
                raise AttributeError, msg

# read only decorator
def readonly(f) :
    """ Marks a class member as protected, allowing metaProtected to prevent re-assignation on the classes it generates """
    f.__readonly__ = None
    return f

class metaReadOnlyAttr(type) :
    """ A metaclass to allow to define read-only class attributes, accessible either on the class or it's instances
        and protected against re-write or re-definition.
        Read only attributes are stored in the class '__readonly__' dictionary.
        Any attribute can be marked as read only by including its name in a tuple named '__readonly__' in the class
        definition. Alternatively methods can be marked as read only with the @readonly decorator and will then get
        added to the dictionary at class creation """

    def __setattr__(cls, name, value): #@NoSelf
        """ overload __setattr__ to forbid modification of read only class info """
        readonly = {}
        for c in inspect.getmro(cls) :
            if hasattr(c, '__readonly__') :
                readonly.update(c.__readonly__)
        if name in readonly :
            raise AttributeError, "attribute %s is a read only class attribute and cannot be modified on class %s" % (name, cls.__name__)
        else :
            super(metaReadOnlyAttr, cls).__setattr__(name, value)


    def __new__(mcl, classname, bases, classdict): #@NoSelf
        """ Create a new metaReadOnlyAttr class """

        # checks for protected members, in base classes on in class to be created
        readonly = {}
        # check for protected members in class definition
        if '__readonly__' in classdict :
            readonly.update(dict((a, None) for a in classdict['__readonly__']))
        for a in classdict :
            if hasattr(classdict[a], '__readonly__') :
                readonly[a] = None
        readonly['__readonly__'] = None
        classdict['__readonly__'] = readonly

        # the use of __slots__ protects instance attributes
#        slots = []
#        if '__slots__' in classdict :
#            slots = list(classdict['__slots__'])

        # create the new class
        newcls = super(metaReadOnlyAttr, mcl).__new__(mcl, classname, bases, classdict)

#        if hasattr(newcls, '__slots__') :
#            for s in newcls.__slots__ :
#                if s not in slots :
#                    slots.append(s)
#        type.__setattr__(newcls, '__slots__', slots)

        # unneeded through the use of __slots__
#        def __setattr__(self, name, value):
#            """ overload __setattr__ to forbid overloading of read only class info on a class instance """
#            try :
#                readonly = newcls.__readonly__
#            except :
#                readonly = {}
#            if name in readonly :
#                raise AttributeError, "attribute '%s' is a read only class attribute of class %s and cannot be overloaded on an instance of class %s" % (name, self.__class__.__name__, self.__class__.__name__)
#            else :
#                super(newcls, self).__setattr__(name, value)
#
#        type.__setattr__(newcls, '__setattr__', __setattr__)

        return newcls

NOT_PROXY_WRAPPED = ['__new__', '__getattribute__', '__getattr__', '__setattr__',
                     '__class__', '__weakref__', '__subclasshook__',
                     '__reduce_ex__', '__reduce__', '__dict__', '__sizeof__',
                     '__module__', '__init__', '__doc__']
def proxyClass( cls, classname, dataAttrName = None, dataFuncName=None,
                remove=(), makeDefaultInit = False, sourceIsImmutable=True,
                module=None ):
    """
    This function will generate a proxy class which keeps the internal data separate from the wrapped class. This
    is useful for emulating immutable types such as str and tuple, while using mutable data.  Be aware that changing data
    will break hashing.  not sure the best solution to this, but a good approach would be to subclass your proxy and implement
    a valid __hash__ method.

    :Parameters:
    cls : `type`
        The class to wrap
    classname : `string`
        The name to give the resulting proxy class
    dataAttrName : `string`
        The name of an attribute on which an instance of the wrapped class will
        be stored.
        Either dataAttrname or dataFuncName must be given, but not both.
    dataFuncName : `string`
        The name of an attribute on which reside a function, which takes no
        arguments, and when called, will return an instance of the wrapped
        class.
        Either dataAttrname or dataFuncName must be given, but not both.
    remove : `string` iterable
        An iterable of name of attributes which should NOT be wrapped.
        Note that certain attributes will never be wrapped - the list of
        such items is found in the NOT_PROXY_WRAPPED constant.
    makeDefaultInit : `bool`
        If True and dataAttrName is True, then a 'default' __init__ function
        will be created, which creates an instance of the wrapped class, and
        assigns it to the dataAttr. Defaults to False
        If dataAttrName is False, does nothing
    sourceIsImmutable : `bool`
        This parameter is included only for backwards compatibility - it is
        ignored.

    :rtype: `type`
    """

    assert not ( dataAttrName and dataFuncName ), 'Cannot use attribute and function for data storage. Choose one or the other.'

    if dataAttrName:
        class ProxyAttribute(object):
            def __init__(self, name):
                self.name = name

            def __get__(self, proxyInst, proxyClass):
                if proxyInst is None:
                    return getattr(cls, self.name)
                else:
                    return getattr(getattr(proxyInst, dataAttrName),
                                   self.name)

        def _methodWrapper( method ):
            def wrapper(self, *args, **kwargs):
                return method( getattr(self, dataAttrName), *args, **kwargs )

            wrapper.__doc__ = method.__doc__
            wrapper.__name__ = method.__name__
            return wrapper

    elif dataFuncName:
        class ProxyAttribute(object):
            def __init__(self, name):
                self.name = name

            def __get__(self, proxyInst, proxyClass):
                if proxyInst is None:
                    return getattr(cls, self.name)
                else:
                    return getattr(getattr(proxyInst, dataFuncName)(),
                                   self.name)

        def _methodWrapper( method ):
            #print method
            #@functools.wraps(f)
            def wrapper(self, *args, **kwargs):
                return method( getattr(self, dataFuncName)(), *args, **kwargs )

            wrapper.__doc__ = method.__doc__
            wrapper.__name__ = method.__name__
            return wrapper
    else:
        raise TypeError, 'Must specify either a dataAttrName or a dataFuncName'

    class Proxy(object):
        # make a default __init__ which sets the dataAttr...
        # if __init__ is in remove, or dataFuncName given,
        # user must supply own __init__, and set the dataAttr/dataFunc
        # themselves
        if makeDefaultInit and dataAttrName:
            def __init__(self, *args, **kwargs):
                # We may wrap __setattr__, so don't use 'our' __setattr__!
                object.__setattr__(self, dataAttrName, cls(*args, **kwargs))

        # For 'type' objects, you can't set the __doc__ outside of
        # the class definition, so do it here:
        if '__doc__' not in remove:
            __doc__ = cls.__doc__

    remove = set(remove)
    remove.update(NOT_PROXY_WRAPPED)
    #remove = [ '__init__', '__getattribute__', '__getattr__'] + remove
    for attrName, attrValue in inspect.getmembers(cls):
        if attrName not in remove:
            # We wrap methods using _methodWrapper, because if someone does
            #    unboundMethod = MyProxyClass.method
            # ...they should be able to call unboundMethod with an instance
            # of MyProxyClass as they expect (as opposed to an instance of
            # the wrapped class, which is what you would need to do if
            # we used ProxyAttribute)

            # ...the stuff with the cls.__dict__ is just to check
            # we don't have a classmethod - since it's a data descriptor,
            # we have to go through the class dict...
            if ((inspect.ismethoddescriptor(attrValue) or
                 inspect.ismethod(attrValue)) and
                not isinstance(cls.__dict__.get(attrName, None),
                               (classmethod, staticmethod))):
                try:
                    setattr(  Proxy, attrName, _methodWrapper(attrValue) )
                except AttributeError:
                    print "proxyClass: error adding proxy method %s.%s" % (classname, attrName)
            else:
                try:
                    setattr(  Proxy, attrName, ProxyAttribute(attrName) )
                except AttributeError:
                    print "proxyClass: error adding proxy attribute %s.%s" % (classname, attrName)

    Proxy.__name__ = classname
    if module is not None:
        Proxy.__module__ = module
    return Proxy


# Note - for backwards compatibility reasons, PyNodes still inherit from
# ProxyUnicode, even though we are now discouraging their use 'like strings',
# and ProxyUnicode itself has now had so many methods removed from it that
# it's no longer really a good proxy for unicode.

# NOTE: This may move back to core.general, depending on whether the __getitem__ bug was fixed in 2009, since we'll have to do a version switch there
#ProxyUnicode = proxyClass( unicode, 'ProxyUnicode', dataFuncName='name', remove=['__getitem__', 'translate']) # 2009 Beta 2.1 has issues with passing classes with __getitem__
ProxyUnicode = proxyClass( unicode, 'ProxyUnicode', module=__name__, dataFuncName='name',
            remove=[ '__doc__', '__getslice__', '__contains__',  '__len__',
            '__mod__', '__rmod__', '__mul__', '__rmod__', '__rmul__', # reserved for higher levels
            'expandtabs', 'translate', 'decode', 'encode', 'splitlines',
            'capitalize', 'swapcase', 'title',
            'isalnum', 'isalpha', 'isdigit', 'isspace', 'istitle',
            'zfill' ])

class universalmethod(object):
#    """
#    a decorator which is similar to builtin classmethod, but which leaves the method unmodified when called
#    as a normal instance method:
#        - when the wrapped method is called as a class method, the first argument will be the class.
#        - when the wrapped method is called as an instance method, the first argument will be the instance.
#
#        >>> import inspect
#        >>> class D(object):
#        ...    @universalmethod
#        ...    def f( obj ):
#        ...        if inspect.isclass(obj):
#        ...            print "doing something class related"
#        ...        else:
#        ...            print "doing something instance related"
#        ...
#        >>> D.f()
#        doing something class related
#        >>> d = D()
#        >>> d.f()
#        doing something instance related
#
#    """

    def __init__(self, f):
        self.f = f
        self.__doc__ = f.__doc__

    def __get__(self, instance, cls=None):
        if cls is None:
            cls = type(instance)
        if instance is None:
            instance = cls
        def newfunc(*args, **kwargs):
            return self.f(instance, *args, **kwargs)
        newfunc.__doc__ = self.__doc__
        return newfunc

def LazyLoadModule(name, contents):
    """
    :param name: name of the module
    :param contents: dictionary of initial module globals

    This function returns a special module type with one method `_addattr`.  The signature
    of this method is:

        _addattr(name, creator, *creatorArgs, **creatorKwargs)

    Attributes added with this method will not be created until the first time that
    they are accessed, at which point a callback function will be called to generate
    the attribute's value.

    :param name: name of the attribute to lazily add
    :param creator: a function that create the

    Example::

        import sys
        mod = LazyLoadModule(__name__, globals())
        mod._addattr( 'foo', str, 'bar' )
        sys.modules[__name__] = mod

    One caveat of this technique is that if a user imports everything from your
    lazy module ( .e.g from module import * ), it will cause all lazy attributes
    to be evaluated.

    Also, if any module-level expression needs to reference something that only
    exists in the LazyLoadModule, it will need to be stuck in after the creation of the
    LazyLoadModule.  Then, typically, after defining all functions/classes/etc
    which rely on the LazyLoadModule attributes, you will wish to update the
    LazyLoadModule with the newly-created functions - typically, this is done
    with the _updateLazyModule method.

    Finally, any functions which reference any LazyLoadModule-only attributes,
    whether they are defined after OR before the creation of the LazyLoadModule,
    will have to prefix it with a reference to the LazyLoadModule.

    Example::

        import sys

        def myFunc():
            # need to preface foo with 'lazyModule',
            # even though this function is defined before
            # the creation of the lazy module!
            print 'foo is:', lazyModule.foo

        mod = lazyLoadModule(__name__, globals())
        mod._addattr( 'foo', str, 'bar' )
        sys.modules[__name__] = mod

        # create a reference to the LazyLoadModule in this module's
        # global space
        lazyModule = sys.modules[__name__]

        # define something which relies on something in the lazy module
        fooExpanded = lazyModule.foo + '... now with MORE!'

        # update the lazyModule with our new additions (ie, fooExpanded)
        lazyModule._updateLazyModule(globals())
    """
    class _LazyLoadModule(types.ModuleType):
        class LazyLoader(object):
            """
            A data descriptor that delays instantiation of an object
            until it is first accessed.
            """
            def __init__(self, name, creator, *creatorArgs, **creatorKwargs):
                self.creator = creator
                self.args = creatorArgs
                self.kwargs = creatorKwargs
                self.name = name

            def __get__(self, obj, objtype):
                # In case the LazyLoader happens to get stored on more
                # than one object, cache the created object so the exact
                # same one will be returned
                if not hasattr(self, 'newobj'):
                    # use the callback to create the object that will replace us
                    self.newobj = self.creator(*self.args, **self.kwargs)
                    if isinstance(obj, types.ModuleType) and hasattr(self.newobj, '__module__'):
                        self.newobj.__module__ = obj.__name__
                #print "Lazy-loaded object:", self.name
                #delattr( obj.__class__, self.name) # should we overwrite with None?
                # overwrite ourselves with the newly created object
                setattr( obj, self.name, self.newobj)
                return self.newobj

        def __init__(self, name, contents):
            types.ModuleType.__init__(self, name)
            self.__dict__.update(contents)
            self._lazyGlobals = contents # globals of original module
            # add ourselves to sys.modules, overwriting the original module
            sys.modules[name] = self
            # the above line assigns a None value to all entries in the original globals.
            # luckily, we have a copy on this module we can use to restore it.
            self._lazyGlobals.update( self.__dict__ )
        @property
        def __all__(self):
            public = [ x for x in self.__dict__.keys() + self.__class__.__dict__.keys() if not x.startswith('_') ]
            return public

        @classmethod
        def _lazyModule_addAttr(cls, name, creator, *creatorArgs, **creatorKwargs):
            lazyObj = cls.LazyLoader(name, creator, *creatorArgs, **creatorKwargs)
            setattr( cls, name, lazyObj )
            return lazyObj

        def __setitem__(self, attr, args):
            """
            dynModule['attrName'] = ( callbackFunc, ( 'arg1', ), {} )
            """
            # args will either be a single callable, or will be a tuple of
            # ( callable, (args,), {kwargs} )
            if hasattr( args, '__call__'):
                callback = args
            elif isinstance( args, (tuple, list) ):
                if len(args) >= 1:
                    assert hasattr( args[0], '__call__' ), 'first argument must be callable'
                    callback = args[0]
                else:
                    raise ValueError, "must supply at least one argument"
                if len(args) >= 2:
                    assert hasattr( args[1], '__iter__'), 'second argument must be iterable'
                    cb_args = args[1]
                else:
                    cb_args = ()
                    cb_kwargs = {}
                if len(args) == 3:
                    assert operator.isMappingType(args[2]), 'third argument must be a mapping type'
                    cb_kwargs = args[2]
                else:
                    cb_kwargs = {}
                if len(args) > 3:
                    raise ValueError, "if args and kwargs are desired, they should be passed as a tuple and dictionary, respectively"
            else:
                raise ValueError, "the item must be set to a callable, or to a 3-tuple of (callable, (args,), {kwargs})"
            self._lazyModule_addAttr(attr, callback, *cb_args, **cb_kwargs)

        def __getitem__(self, attr):
            """
            return a LazyLoader without initializing it, or, if a LazyLoader does not exist with this name,
            a real object
            """
            try:
                return self.__class__.__dict__[attr]
            except KeyError:
                return self.__dict__[attr]

        # Sort of a cumbersome name, but we want to make sure it doesn't conflict with any
        # 'real' entries in the module
        def _lazyModule_update(self):
            """
            Used to update the contents of the LazyLoadModule with the contents of another dict.
            """
            # For debugging, print out a list of things in the _lazyGlobals that
            # AREN'T in __dict__
#            print "_lazyModule_update:"
#            print "only in dynamic module:", [x for x in
#                                              (set(self.__class__.__dict__) | set(self.__dict__))- set(self._lazyGlobals)
#                                              if not x.startswith('__')]
            self.__dict__.update(self._lazyGlobals)


    return _LazyLoadModule(name, contents)

# Note - since anything referencing attributes that only exist on the lazy module
# must be prefaced with a ref to the lazy module, if we are converting a pre-existing
# module to include LazyLoaded objects, we must manually go through and edit
# any references to those objects to have a 'lazyModule' prefix (or similar).
# To aid in this process, I recommend:
# 1. Uncommenting out the final print statement in _updateLazyModule
# 2. Grabbing the output of the print statement, throw it into a text editor with
#    regexp find/replace capabilities
# 3. You should have a python list of names.
#    Replace the initial and final bracket and quote - [' and '] - with opening
#    and closing parentheses - ( and )
#    Then find / replace all occurrences of:
#          ', '
#    with:
#          |
#    ...and you should be left with a regular expression you can use to find and replace
#   in your original code...
#   (you may also want to put (?<=\W) / (?=\W) in front / behind the regexp...)
#   Don't do the regexp find / replace on the source code blindly, though!
# ...also, when you make the call to _updateLazyModule that prints out the list of
# dynamic-module-only attributes, you should do it from a GUI maya - there are some objects
# that only exist in GUI-mode...

class LazyDocStringError(Exception): pass

class LazyDocString(types.StringType):
    """
    Set the __doc__ of an object to an object of this class in order to have
    a docstring that is dynamically generated when used.

    Due to restrictions of inheriting from StringType (which is necessary,
    as the 'help' function does a check to see if __doc__ is a string),
    the creator can only take a single object.

    Since the object initialization requires multiple parameters, the
    LazyDocString should be fed an sliceable-iterable on creation,
    of the following form:

        LazyDocString( [documentedObj, docGetter, arg1, arg2, ...] )

    documentedObj should be the object on which we are placing the docstring

    docGetter should be a function which is used to retrieve the 'real'
    docstring - it's args will be documentedObj and any extra args
    passed to the object on creation.

    Example Usage:

    >>> def getDocStringFromDict(obj):
    ...     returnVal = docStringDict[obj]
    ...     return returnVal
    >>>
    >>> # In order to alter the doc of a class, we need to use a metaclass
    >>> class TestMetaClass(type): pass
    >>>
    >>> class TestClass(object):
    ...     __metaclass__ = TestMetaClass
    ...
    ...     def aMethod(self):
    ...         pass
    ...
    ...     aMethod.__doc__ = LazyDocString( (aMethod, getDocStringFromDict, (aMethod,)) )
    >>>
    >>> TestClass.__doc__ = LazyDocString( (TestClass, getDocStringFromDict, (TestClass,)) )
    >>>
    >>>
    >>> docStringDict = {TestClass:'New Docs for PynodeClass!',
    ...                  TestClass.aMethod.im_func:'Method docs!'}
    >>>
    >>> TestClass.__doc__
    'New Docs for PynodeClass!'
    >>> TestClass.aMethod.__doc__
    'Method docs!'


    Note that new-style classes (ie, instances of 'type') and instancemethods
    can't have their __doc__ altered.

    In the case of classes, you can get around this by using a metaclass for
    the class whose docstring you wish to alter.

    In the case of instancemethods, just set the __doc__ on the function
    underlying the method (ie, myMethod.im_func). Note that if the __doc__
    for the method is set within the class definition itself, you will
    already automatically be modifying the underlying function.
    """

    def __init__(self, argList):
        if len(argList) < 2:
            raise LazyDocStringError('LazyDocString must be initialized with an iterable of the form: LazyDocString( [documentedObj, docGetter, arg1, arg2, ...] )')
        documentedObj = argList[0]
        docGetter = argList[1]
        if len(argList) > 2:
            args = argList[2]
            if len(argList) == 4:
                kwargs = argList[3]
            else:
                kwargs = {}
        else:
            args = ()
            kwargs = {}

        try:
            # put in a placeholder docstring, and check to make
            # sure we can change the __doc__ of this object!
            documentedObj.__doc__ = 'LazyDocString placeholder'
        except AttributeError:
            raise LazyDocStringError('cannot modify the docstring of %r objects' % documentedObj.__class__.__name__)
        self.documentedObj = documentedObj
        self.docGetter = docGetter
        self.args = args
        self.kwargs = kwargs

    def __str__(self):
        #print "creating docstrings", self.docGetter, self.args, self.kwargs
        self.documentedObj.__doc__ = self.docGetter(*self.args, **self.kwargs)
        return self.documentedObj.__doc__
    def __repr__(self):
        return repr(str(self))

for _name, _method in inspect.getmembers(types.StringType, inspect.isroutine):
    if _name.startswith('_'):
        continue

    def makeMethod(name):
        def LazyDocStringMethodWrapper(self, *args, **kwargs):
            return getattr(str(self), name)(*args, **kwargs)
        return LazyDocStringMethodWrapper
    setattr(LazyDocString, _name, makeMethod(_name) )

def addLazyDocString( object, creator, *creatorArgs, **creatorKwargs):
    """helper for LazyDocString.  Equivalent to :

        object.__doc__ = LazyDocString( (object, creator, creatorArgs, creatorKwargs) )
    """
    object.__doc__ = LazyDocString( (object, creator, creatorArgs, creatorKwargs) )

class TwoWayDict(dict):
    """
    A dictionary that can also map in reverse: value to key.

    >>> twd = TwoWayDict( {3:'foobar'} )
    >>> twd[3]
    'foobar'
    >>> twd.get_key('foobar')
    3

    Entries in both sets (keys and values) must be unique within that set, but
    not necessarily across the two sets - ie, you may have 12 as both a key and
    a value, but you may not have two keys which both map to 12 (or, as with a
    regular dict, two key entries for 12).

    If a key is updated to a new value, get_key for the old value will raise
    a KeyError:

    >>> twd = TwoWayDict( {3:'old'} )
    >>> twd[3] = 'new'
    >>> twd[3]
    'new'
    >>> twd.get_key('new')
    3
    >>> twd.get_key('old')
    Traceback (most recent call last):
        ...
    KeyError: 'old'

    Similarly, if a key is updated to an already-existing value, then the old key
    will be removed from the dictionary!

    >>> twd = TwoWayDict( {'oldKey':'aValue'} )
    >>> twd['newKey'] = 'aValue'
    >>> twd['newKey']
    'aValue'
    >>> twd.get_key('aValue')
    'newKey'
    >>> twd['oldKey']
    Traceback (most recent call last):
        ...
    KeyError: 'oldKey'

    If a group of values is fed to the TwoWayDict (either on initialization, or
    through 'update', etc) that is not consistent with these conditions, then the
    resulting dictionary is indeterminate; however, it is guaranteed to be a valid/
    uncorrupted TwoWayDict.
    (This is similar to how dict will allow, for instance, {1:'foo', 1:'bar'}).

    >>> twd = TwoWayDict( {1:'foo', 1:'bar'} )
    >>> # Is twd[1] 'foo' or 'bar'?? Nobody knows!
    >>> # ...however, one of these is guaranteed to raise an error...
    >>> twd.get_key('foo') + twd.get_key('bar')   #doctest: +IGNORE_EXCEPTION_DETAIL
    Traceback (most recent call last):
        ...
    KeyError: (either 'bar' or 'foo')
    >>> twd = TwoWayDict( {1:'foo', 2:'foo'} )
    >>> # Is twd.get_key('foo') 1 or 2? Nobody knows!
    >>> # ...however, one of these is guaranteed to raise an error...
    >>> twd[1] + twd[2]   #doctest: +IGNORE_EXCEPTION_DETAIL
    Traceback (most recent call last):
        ...
    KeyError: (either 1 or 2)

    Obviously, such shenannigans should be avoided - at some point in the future, this may
    cause an error to be raised...
    """

    def __init__(self, *args, **kwargs):
        dict.__init__(self)
        self._reverse = {}
        self.update(*args, **kwargs)

    def __setitem__(self, k, v):
        # Maintain the 1-1 mapping
        if dict.__contains__(self, k):
            del self._reverse[self[k]]
        if v in self._reverse:
            dict.__delitem__(self, self.get_key(v))
        dict.__setitem__(self, k, v)
        self._reverse[v] = k

    def has_value(self, v):
        return self._reverse.has_key(v)

    def __delitem__(self, k):
        del self._reverse[self[k]]
        dict.__delitem__(self, k)

    def clear(self):
        self._reverse.clear()
        dict.clear(self)

    def copy(self):
        return TwoWayDict(self)

    def pop(self, k):
        del self._reverse[self[k]]
        return self.pop(k)

    def popitem(self, **kws):
        raise NotImplementedError()

    def setdefault(self, **kws):
        raise NotImplementedError()

    def update(self, *args, **kwargs):
        if not (args or kwargs):
            return
        if len(args) > 1:
            raise TypeError('update expected at most 1 arguments, got %d' % len(args))
        # since args may be a couple different things, cast it to a dict to
        # simplify things...
        if args:
            tempDict = dict(args[0])
        else:
            tempDict = {}
        tempDict.update(kwargs)
        for key, val in tempDict.iteritems():
            self[key] = val

    def get_key(self, v):
        return self._reverse[v]

class EquivalencePairs(TwoWayDict):
    """
    A mapping object similar to a TwoWayDict, with the addition that indexing
    and '__contains__' can now be used with keys OR values:

    >>> eq = EquivalencePairs( {3:'foobar'} )
    >>> eq[3]
    'foobar'
    >>> eq['foobar']
    3
    >>> 3 in eq
    True
    >>> 'foobar' in eq
    True

    This is intended to be used where there is a clear distinction between
    keys and values, so there is little likelihood of the sets of keys
    and values intersecting.

    The dictionary has the same restrictions as a TwoWayDict, with the added restriction
    that an object must NOT appear in both the keys and values, unless it maps to itself.
    If a new item is set that would break this restriction, the old keys/values will be
    removed from the mapping to ensure these restrictions are met.

    >>> eq = EquivalencePairs( {1:'a', 2:'b', 3:'die'} )
    >>> eq['a']
    1
    >>> eq['b']
    2
    >>> eq[1]
    'a'
    >>> eq[2]
    'b'
    >>> del eq['die']
    >>> eq[3]
    Traceback (most recent call last):
        ...
    KeyError: 3
    >>> eq[2] = 1
    >>> eq[1]
    2
    >>> eq[2]
    1
    >>> eq['a']
    Traceback (most recent call last):
        ...
    KeyError: 'a'
    >>> eq['b']
    Traceback (most recent call last):
        ...
    KeyError: 'b'

    # Even though 2 is set as a VALUE, since it already
    # exists as a KEY, the 2:'b' mapping is removed,
    # so eq['b'] will be invalid...
    >>> eq = EquivalencePairs( {1:'a', 2:'b'} )
    >>> eq['new'] = 2
    >>> eq['new']
    2
    >>> eq[2]
    'new'
    >>> eq['b']
    Traceback (most recent call last):
        ...
    KeyError: 'b'

    # Similarly, if you set as a KEy something that
    # already exists as a value...
    >>> eq = EquivalencePairs( {1:'a', 2:'b'} )
    >>> eq['b'] = 3
    >>> eq['b']
    3
    >>> eq[3]
    'b'
    >>> eq[2]
    Traceback (most recent call last):
        ...
    KeyError: 2

    If a group of values is fed to the EquivalencePairs (either on initialization, or
    through 'update', etc) that is not consistent with it's restrictions, then the
    resulting dictionary is indeterminate; however, it is guaranteed to be a valid/
    uncorrupted TwoWayDict.

    (This is somewhat similar to the behavior of the dict object itself, which will allow
    a definition such as {1:2, 1:4} )

    Obviously, such shenannigans should be avoided - at some point in the future, this may
    even cause an error to be raised...

    Finally, note that a distinction between keys and values IS maintained, for compatibility
    with keys(), iter_values(), etc.
    """
    def __setitem__(self, k, v):
        if k in self:
            # this will check if k is in the keys OR values...
            del self[k]
        if v in self:
            del self[v]
        dict.__setitem__(self, k, v)
        self._reverse[v] = k

    def __delitem__(self, key):
        if dict.__contains__(self, key):
            super(EquivalencePairs, self).__delitem__(key)
        elif key in self._reverse:
            dict.__delitem__(self, self[key])
            del self._reverse[key]
        else:
            raise KeyError(key)

    def __getitem__(self, key):
        if dict.__contains__(self, key):
            return super(EquivalencePairs, self).__getitem__(key)
        elif key in self._reverse:
            return self._reverse[key]
        else:
            raise KeyError(key)

    def __contains__(self, key):
        return (dict.__contains__(self, key) or
                key in self._reverse)

    def get(self, key, d=None):
        try:
            return self.__getitem__(key)
        except KeyError:
            return d

def alias(origAttrName):
    """
    Returns a property which is simply an alias for another property.

    Acts simply to provide another name to reference the same
    underlying attribute; useful when subclassing, where a subclass
    might have a more descriptive name for an attribute that has the
    same function.

    The only purpose of this function is to produce more readable code.

    Example:

    >>> class GenericExporter(object):
    ...     def __init__(self, outFile):
    ...         self.outFile = outFile
    ...
    >>> class CowExporter(GenericExporter):
    ...     cowFile = alias('outFile')
    ...
    >>> CowExporter('bessie.cow').cowFile
    'bessie.cow'
    """
    def getter(self):
        return getattr(self, origAttrName)
    getter.__name__ = "get_" + origAttrName

    def setter(self, value):
        setattr(self, origAttrName, value)

    setter.__name__ = "set_" + origAttrName
    return property(getter, setter)

class propertycache(object):
    '''Class for creating properties where the value is initially calculated then stored.

    Intended for use as a descriptor, ie:

    class MyClass(object):
        @propertycache
        def aValue(self):
            return calcValue()
    c = MyClass()
    c.aValue

    '''
    def __init__(self, func):
        self.func = func
        self.name = func.__name__
    def __get__(self, ownerInstance, ownerCls=None):
        result = self.func(ownerInstance)
        setattr(ownerInstance, self.name, result)
        return result

# unit test with doctest
if __name__ == '__main__' :
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = versions
"""
Contains functions for easily comparing versions of Maya with the current running version.
Class for storing apiVersions, which are the best method for comparing versions. ::

    >>> from pymel import versions
    >>> if versions.current() >= versions.v2008:
    ...     print "The current version is later than Maya 2008"
    The current version is later than Maya 2008
"""

import re, struct
from maya.OpenMaya import MGlobal  as _MGlobal

def parseVersionStr(versionStr, extension=False):
    """
    >>> from pymel.all import *
    >>> versions.parseVersionStr('2008 Service Pack1 x64')
    '2008'
    >>> versions.parseVersionStr('2008 Service Pack1 x64', extension=True)
    '2008-x64'
    >>> versions.parseVersionStr('2008x64', extension=True)
    '2008-x64'
    >>> versions.parseVersionStr('8.5', extension=True)
    '8.5'
    >>> versions.parseVersionStr('2008 Extension 2')
    '2008'
    >>> versions.parseVersionStr('/Applications/Autodesk/maya2009/Maya.app/Contents', extension=True)
    '2009'
    >>> versions.parseVersionStr('C:\Program Files (x86)\Autodesk\Maya2008', extension=True)
    '2008'

    """
    if 'Preview' in versionStr:
        # Beta versions of Maya may use the format 'Preview Release nn x64', which
        # doesn't contain the actual Maya version. If we have one of those, we'll
        # make up the version from the API version. Not foolproof, but should work
        # in most cases.
        version = str(_MGlobal.apiVersion())[0:4]
        if extension and bitness() == 64:
            version += '-x64'
    else:
        # problem with service packs addition, must be able to match things such as :
        # '2008 Service Pack 1 x64', '2008x64', '2008', '8.5'

        # NOTE: we're using the same regular expression (parseVersionStr) to parse both the crazy human readable
        # maya versions as returned by about, and the maya location directory.  to handle both of these i'm afraid
        # the regular expression might be getting unwieldy

        ma = re.search("((?:maya)?(?P<base>[\d.]{3,})(?:(?:[ ].*[ ])|(?:-))?(?P<ext>x[\d.]+)?)", versionStr)
        version = ma.group('base')

        if extension and (ma.group('ext') is not None) :
            version += "-" + ma.group('ext')
    return version

def bitness():
    """
    The bitness of python running inside Maya as an int.
    """
    # NOTE: platform.architecture()[0] returns '64bit' on OSX 10.6 (Snow Leopard)
    # even when Maya is running in 32-bit mode. The struct technique
    # is more reliable.
    return struct.calcsize("P") * 8

_is64 = bitness() == 64
_current = _MGlobal.apiVersion()
_fullName = _MGlobal.mayaVersion()
_shortName = parseVersionStr(_fullName, extension=False)
_installName = _shortName + ('-x64' if _is64 else '')


v85           = 200700
v85_SP1       = 200701
v2008         = 200800
v2008_SP1     = 200806
v2008_EXT2    = 200806
v2009         = 200900
v2009_EXT1    = 200904
v2009_SP1A    = 200906
v2010         = 201000
v2011         = 201100
v2011_HOTFIX1 = 201101
v2011_HOTFIX2 = 201102
v2011_HOTFIX3 = 201103
v2011_SP1     = 201104
v2012         = 201200
v2012_HOTFIX1 = 201201
v2012_HOTFIX2 = 201202
v2012_HOTFIX3 = 201203
v2012_HOTFIX4 = 201204
v2012_SP1     = 201209
v2012_SAP1    = v2012_SP1
v2012_SP2     = 201217
v2012_SAP1SP1 = v2012_SP2
v2013         = 201300
v2014         = 201400
v2014_SP1     = 201402
v2014_SP2     = 201404
v2014_SP3     = 201406
v2014_EXT1    = 201450
v2014_EXT1SP1 = 201451
v2014_EXT1SP2 = 201459
v2015         = 201500

def current():
    return _current

def fullName():
    return _fullName

def installName():
    return _installName

def shortName():
    return _shortName

def is64bit():
    return _is64

def flavor():
    import maya.cmds
    try:
        return maya.cmds.about(product=1).split()[1]
    except AttributeError:
        raise RuntimeError, "This method cannot be used until maya is fully initialized"

def isUnlimited():
    return flavor() == 'Unlimited'


def isComplete():
    return flavor() == 'Complete'


def isRenderNode():
    return flavor() == 'Render'


def isEval():
    import maya.cmds
    try:
        return maya.cmds.about(evalVersion=1)
    except AttributeError:
        raise RuntimeError, "This method cannot be used until maya is fully initialized"


########NEW FILE########
__FILENAME__ = eclipseDebug
# Put in whatever code you want to use for an eclipse debug run here...


#mayapy -c "import pymel.core as pm; plug='stereoCamera'; pm.loadPlugin(plug) if not pm.pluginInfo(plug, loaded=1, q=1) else 'doNothing'; print '*******loaded******'; pm.unloadPlugin(plug, f=1); print '*****unloaded*******'"

import pymel.core as pm
node = pm.nt.Transform('persp')
attr = node.attr('translate')
attr.set( (1,2,3) )

########NEW FILE########
__FILENAME__ = pymel_test
#!/usr/bin/env mayapy

#nosetests --with-doctest -v pymel --exclude '(windows)|(tools)|(arrays)|(example1)'

#import doctest
from __future__ import with_statement

import sys, platform, os, shutil, time, inspect, tempfile, doctest, re

# tee class adapted from http://shallowsky.com/blog/programming/python-tee.html
class Tee(object):
    def __init__(self, _fd1, _fd2) :
        self.fd1 = _fd1
        self.fd2 = _fd2

    def __del__(self) :
        self.close()

    def close(self):
        for toClose in (self.fd1, self.fd2):
            if toClose not in (sys.stdout, sys.stderr,
                               sys.__stdout__, sys.__stderr__, None):
                toClose.close()
        self.fd1 = self.fd2 = None

    def write(self, text) :
        self.fd1.write(text)
        self.fd2.write(text)

    def flush(self) :
        self.fd1.flush()
        self.fd2.flush()

#stderrsav = sys.stderr
#outputlog = open(logfilename, "w")
#sys.stderr = tee(stderrsav, outputlog)

try:
    import nose
except ImportError, e:
    print "To run pymel's tests you must have nose installed: http://code.google.com/p/python-nose"
    raise e

# Get the 'new' version of unittest
if sys.version_info >= (2, 7, 0):
    import unittest
else:
    import unittest2 as unittest

import argparse

def getParser():
    testsDir = os.path.dirname(os.path.abspath(sys.argv[0]))
    pymelRoot = os.path.dirname( testsDir )

    parser = argparse.ArgumentParser(description='Run the pymel tests')
    parser.add_argument('extra_args', nargs='*', help='args to pass to nose or unit/unit2')
    parser.add_argument('--app-dir', help='''make the tests use the given dir as
        the MAYA_APP_DIR (ie, the base maya settings folder)''')
    #parser.add_argument('--test', help='''specific TestCase or test function to
        #run; if given, will be run using the "new" unittest"''')
    parser.add_argument('--tests-dir', help='''The directory that contains the test modules''',
        default=testsDir)
    parser.add_argument('--pymel-root', help='''The directory that contains the test modules''',
        default=pymelRoot)
    return parser

_PYTHON_DOT_NAME_RE = re.compile(r'[A-Za-z_][A-Za-z_0-9]*(\.[A-Za-z_][A-Za-z_0-9]*)+')

def isPythonDottedName(name):
    return bool(_PYTHON_DOT_NAME_RE.match(name))

def moduleObjNameSplit(moduleName):
    '''Returns the name split into the module part and the object name part
    '''
    import imp
    currentPath = None
    split = moduleName.split('.')
    moduleParts = []
    for name in split:
        try:
            currentPath = imp.find_module(name, currentPath)[1]
        except ImportError:
            break
        moduleParts.append(name)
    return '.'.join(moduleParts), '.'.join(split[len(moduleParts):])

def nose_test(argv, module=None, pymelDir=None):
    """
    Run pymel unittests / doctests
    """
    arg0 = argv[0]
    extraArgs = argv[1:]

    if pymelDir:
        os.chdir(pymelDir)

    os.environ['MAYA_PSEUDOTRANS_MODE']='5'
    os.environ['MAYA_PSEUDOTRANS_VALUE']=','

    noseKwArgs={}
    noseArgv = "dummyArg0 --with-doctest -vv".split()
    if module is None:
        #module = 'pymel' # if you don't set a module, nose will search the cwd
        excludes = r'''^windows
                    \Wall\.py$
                    ^tools
                    ^example1
                    ^testing
                    ^eclipseDebug
                    ^pmcmds
                    ^testPa
                    ^maya
                    ^maintenance
                    ^pymel_test
                    ^TestPymel
                    ^testPassContribution$'''.split()

        # default inGui to false - if we are in gui, we should be able to query
        # (definitively) that we are, but same may not be true from command line
        inGui = False
        try:
            import maya.cmds
            inGui = not maya.cmds.about(batch=1)
        except Exception: pass

        # if we're not in gui mode, disable the gui tests
        if not inGui:
            excludes.extend('^test_uitypes ^test_windows'.split())

        noseArgv += ['--exclude', '|'.join( [ '(%s)' % x for x in excludes ] )  ]

    if inspect.ismodule(module):
        noseKwArgs['module']=module
    elif module:
        noseArgv.append(module)
    if extraArgs is not None:
        noseArgv.extend(extraArgs)
    noseKwArgs['argv'] = noseArgv

    with DocTestPatcher():
        print "running nose:", noseKwArgs
        nose.main( **noseKwArgs)

def unit2_test(argv, **kwargs):
    # insert the verbose flag
    argv[1:1] = ['--verbose']

    kwargs['module'] = None
    kwargs['argv'] = argv

    if sys.version_info < (2, 7, 0):
        # if we try to specify a specific method, unittest2 checks to see if it
        # is an unbound method on a unittest2.TestCase; if it is on a
        # unittest.TestCase, it will not work; therefore, install unittest2 as
        # unittest
        sys.modules['unittest'] = sys.modules['unittest2']

    print "running unittest:", kwargs
    unittest.main(**kwargs)

class DocTestPatcher(object):
    """
    When finding docstrings from a module, DocTestFinder does a test to ensure that objects
    in the namespace are actually from that module. Unfortunately, our LazyLoadModule causes
    some problems with this.  Eventually, we may experiment with setting the LazyLoadModule
    and original module's dict's to be the same... for now, we use this class to override
    DocTestFinder._from_module to return the results we want.

    Also, the doctest will override the 'wantFile' setting for ANY .py file,
    even it it matches the 'exclude' - it does this so that it can search all
    python files for docs to add to the doctests.

    Unfortunately, if some modules are simply loaded, they can affect things -
    ie, if pymel.all is loaded, it will trigger the lazy-loading of all class
    objects, which will make our lazy-loading tests fail.

    To get around this, override the Doctest plugin object's wantFile to also
    exclude the 'excludes'.
    """
    def __enter__(self):
        self.set_from_module()
        self.set_wantFile()

    def set_from_module(self):
        self.orig_from_module = doctest.DocTestFinder.__dict__['_from_module']

        def _from_module(docTestFinder_self, module, object):
            """
            Return true if the given object is defined in the given
            module.
            """
            # We only have problems with functions...
            if inspect.isfunction(object):
                if 'LazyLoad' in module.__class__.__name__:
                    if module.__name__ == object.__module__:
                        return True
            return self.orig_from_module(docTestFinder_self, module, object)
        doctest.DocTestFinder._from_module = _from_module

    def set_wantFile(self):
        import nose
#        if nose.__versioninfo__ > (1,0,0):
#            self.orig_wantFile = None
#            return

        import nose.plugins.doctests
        self.orig_wantFile = nose.plugins.doctests.Doctest.__dict__['wantFile']

        def wantFile(self, file):
            """Override to select all modules and any file ending with
            configured doctest extension.
            """
            # Check if it's a desired file type
            if ( (file.endswith('.py') or (self.extension
                                           and anyp(file.endswith, self.extension)) )
                 # ...and that it isn't excluded
                 and (not self.conf.exclude
                      or not filter(None,
                                    [exc.search(file)
                                     for exc in self.conf.exclude]))):
                return True
            return None

        nose.plugins.doctests.Doctest.wantFile = wantFile

    def __exit__(self, *args, **kwargs):
        doctest.DocTestFinder._from_module = self.orig_from_module
        if self.orig_wantFile is not None:
            import nose.plugins.doctests
            nose.plugins.doctests.Doctest.wantFile = self.orig_wantFile

def main(argv):
    parser = getParser()
    parsed = parser.parse_args(argv[1:])

    if parsed.app_dir:
        if not os.path.exists(parsed.app_dir):
            os.makedirs(parsed.app_dir)
        os.environ['MAYA_APP_DIR'] = parsed.app_dir

    testsDir = parsed.tests_dir
    pymelRoot = parsed.pymel_root

    pypath = os.environ.get('PYTHONPATH', '').split(os.pathsep)
    # add the test dir to the python path - that way,
    # we can do 'pymel_test test_general' in order to run just the tests
    # in test_general
    sys.path.append(testsDir)
    pypath.append(testsDir)

    # ...and add this copy of pymel to the python path, highest priority,
    # to make sure it overrides any 'builtin' pymel/maya packages
    sys.path.insert(0, pymelRoot)
    pypath.insert(0, pymelRoot)

    os.environ['PYTHONPATH'] = os.pathsep.join(pypath)

    oldPath = os.getcwd()
    # make sure our cwd is the pymel project working directory
    os.chdir( pymelRoot )
    try:
        # Try to guess whether we were given an arg which is a TestCase or
        # test method/function, and if so, run new unittest (because it can
        # easily handle specific TestCase/method/function)... else run nose
        # (because it's what the test suite was originally set up to use)
        useNose = True
        if parsed.extra_args:
            name = parsed.extra_args[-1]
            if isPythonDottedName(name):
                modulePart, objPart = moduleObjNameSplit(name)
                if modulePart and objPart:
                    useNose = False

        argv = [argv[0]] + parsed.extra_args
        if useNose:
            nose_test(argv)
        else:
            unit2_test(argv)
    finally:
        os.chdir(oldPath)

if __name__ == '__main__':
    main(sys.argv)

########NEW FILE########
__FILENAME__ = TestPymel
#!/usr/bin/env mayapy

import unittest
import os
"""
This module is for integrating pymel tests into a larger unittest framework.
If you just wish to test pymel, use pymel_test instead.
"""

import sys
import inspect

gCantRun = False
try:
    import nose
except ImportError:
    gCantRun = True
    print('** nose module required for this test **')

if not gCantRun:
    thisDir = os.path.dirname(inspect.getsourcefile( lambda:None ))
    try:
        import pymel_test
    except ImportError:
        sys.path.append(thisDir)
        try:
            import pymel_test
        except ImportError:
            gCantRun = True
            import traceback
            print('** error importing pymel_test: **')
            traceback.print_exc()

if not gCantRun:
    class TestPymel(unittest.TestCase):
        pymelDir = os.path.dirname(thisDir)
        def testPymel(self):
           pymel_test.nose_test(pymelDir=self.pymelDir)

    if __name__ == '__main__':
        #from pymel import core
        suite = unittest.TestLoader().loadTestsFromTestCase(TestPymel)
        unittest.TextTestRunner(verbosity=2).run(suite)
########NEW FILE########
__FILENAME__ = test_animation
import sys
import unittest
import traceback

import maya.cmds as cmds

import pymel.core as pm
import pymel.util as util
import pymel.util.testing as testing

class TestConstraintVectorQuery(testing.TestCaseExtended):
    def setUp(self):
        cmds.file(new=1, f=1)

    def _doTestForConstraintType(self, constraintType):
        cmd = getattr(pm, constraintType)

        if constraintType == 'tangentConstraint':
            target = cmds.circle()[0]
        else:
            target = cmds.polyCube()[0]
        constrained = cmds.polyCube()[0]

        constr = cmd(target, constrained)
        print constr

        self.assertVectorsEqual(cmd(constr, q=1, worldUpVector=1), [0,1,0])
        self.assertVectorsEqual(constr.getWorldUpVector(), [0,1,0])

        self.assertVectorsEqual(cmd(constr, q=1, upVector=1), [0,1,0])
        self.assertVectorsEqual(constr.getUpVector(), [0,1,0])

        self.assertVectorsEqual(cmd(constr, q=1, aimVector=1), [1,0,0])
        self.assertVectorsEqual(constr.getAimVector(), [1,0,0])

    def test_aimConstraint(self):
        self._doTestForConstraintType('aimConstraint')

    def test_normalConstraint(self):
        self._doTestForConstraintType('normalConstraint')

    def test_tangentConstraint(self):
        self._doTestForConstraintType('tangentConstraint')

class TestTimeRange(testing.TestCaseExtended):
    def setUp(self):
        cmds.file(new=1, f=1)
        self.cube = cmds.polyCube()[0]
        for i in xrange(1,21,2):
            cmds.currentTime(i)
            pm.setAttr(self.cube + '.tx', i)
            pm.setKeyframe(self.cube + '.tx')

    def tearDown(self):
        cmds.delete(self.cube)

    @classmethod
    def addTest(cls, func, flag, val, expected):
        # define the test
        def test(self):
            kwargs = {'query':1, 'attribute':'tx', 'keyframeCount':1, flag:val}
            try:
                result = pm.keyframe(self.cube, **kwargs)
            except Exception:
                trace = traceback.format_exc()
                self.fail('Error executing keyframe for %s=%r:\n%s' % (flag, val, trace))
            self.assertEqual(result, expected,
                             "Wrong value for %s=%r - expected %r, got %r" % (flag, val, expected, result))

        # name the test...
        if isinstance(val, basestring):
            valPieces = val.split(':')
        elif isinstance(val, slice):
            valPieces = (val.start, val.stop)
        elif isinstance(val, (list, tuple)):
            valPieces = val
        else:
            valPieces = [val]
        valPieces = ["BLANK" if x == "" else x for x in valPieces]
        if len(valPieces) == 1:
            valName = '%s' % valPieces[0]
        else:
            valName = '%s_%s' % tuple(valPieces)
        valName = '%s_%s' % (type(val).__name__, valName)
        testName = 'test_%s_%s_%s' % (func.__name__, flag, valName)
        test.__name__ = testName

        # add the test to the class
        setattr(cls, testName, test)

    @classmethod
    def addKeyframeTimeTests(cls):
        for val, expected in [
                              ((4,),         0),
                              ((9,),         1),
                              ((None,),     10),
                              ((4,4),        0),
                              ((4,9),        3),
                              ((4,None),     8),
                              ((9,9),        1),
                              ((9,None),     6),
                              ((None,4),     2),
                              ((None,9),     5),
                              ((None,None), 10),

                              ([4,],         0),
                              ([9,],         1),
                              ([None,],     10),
                              ([4,4],        0),
                              ([4,9],        3),
                              ([4,None],     8),
                              ([9,9],        1),
                              ([9,None],     6),
                              ([None,4],     2),
                              ([None,9],     5),
                              ([None,None], 10),


                              ('4:4',        0),
                              ('4:9',        3),
                              ('4:',         8),
                              ('9:9',        1),
                              ('9:',         6),
                              (':4',         2),
                              (':9',         5),
                              (':',         10),

                              (slice(4),          2),
                              (slice(9),          5),
                              (slice(None),      10),
                              (slice(4,4),        0),
                              (slice(4,9),        3),
                              (slice(4,None),     8),
                              (slice(9,9),        1),
                              (slice(9,None),     6),
                              (slice(None,4),     2),
                              (slice(None,9),     5),
                              (slice(None,None), 10),

                              (4,            0),
                              (9,            1),
                             ]:
            cls.addTest(pm.keyframe, 'time', val, expected)
            cls.addTest(pm.keyframe, 't', val, expected)

    @classmethod
    def addKeyframeIndexTests(cls):
        for val, expected in [
                              ((2,),         1),
                              ((8,),         1),
                              ((10,),        0),
                              ((None,),     10),
                              ((10,10),      0),
                              ((2,2),        1),
                              ((2,8),        7),
                              ((2,None),     8),
                              ((8,8),        1),
                              ((8,None),     2),
                              ((None,2),     3),
                              ((None,8),     9),
                              ((None,None), 10),

                              ([2,],         1),
                              ([8,],         1),
                              ([None,],     10),
                              ([10,10],      0),
                              ([2,2],        1),
                              ([2,8],        7),
                              ([2,None],     8),
                              ([8,8],        1),
                              ([8,None],     2),
                              ([None,2],     3),
                              ([None,8],     9),
                              ([None,None], 10),


                              ('10:10',      0),
                              ('2:2',        1),
                              ('2:8',        7),
                              ('2:',         8),
                              ('8:8',        1),
                              ('8:',         2),
                              (':2',         3),
                              (':8',         9),
                              (':',         10),

                              (slice(2),          3),
                              (slice(8),          9),
                              (slice(None),      10),
                              (slice(2,2),        1),
                              (slice(2,8),        7),
                              (slice(2,None),     8),
                              (slice(8,8),        1),
                              (slice(8,None),     2),
                              (slice(None,2),     3),
                              (slice(None,8),     9),
                              (slice(None,None), 10),

                              (4,            1),
                              (9,            1),
                             ]:
            cls.addTest(pm.keyframe, 'index', val, expected)

TestTimeRange.addKeyframeTimeTests()
TestTimeRange.addKeyframeIndexTests()

class TestJoint(testing.TestCaseExtended):

    def setUp(self):
        cmds.file(new=1, f=1)

    def test_angleX(self):
        joint = pm.joint(angleX=31.5)
        self.assertEqual(pm.joint(joint, q=1, angleX=1), 31.5)
        pm.joint(joint, e=1, angleX=20.2)
        self.assertEqual(pm.joint(joint, q=1, angleX=1), 20.2)
        pm.delete(joint)

        joint = pm.joint(ax=31.5)
        self.assertEqual(pm.joint(joint, q=1, ax=1), 31.5)
        pm.joint(joint, e=1, ax=20.2)
        self.assertEqual(pm.joint(joint, q=1, ax=1), 20.2)
        pm.delete(joint)

    def test_angleY(self):
        joint = pm.joint(angleY=31.5)
        self.assertEqual(pm.joint(joint, q=1, angleY=1), 31.5)
        pm.joint(joint, e=1, angleY=20.2)
        self.assertEqual(pm.joint(joint, q=1, angleY=1), 20.2)
        pm.delete(joint)

        joint = pm.joint(ay=31.5)
        self.assertEqual(pm.joint(joint, q=1, ay=1), 31.5)
        pm.joint(joint, e=1, ay=20.2)
        self.assertEqual(pm.joint(joint, q=1, ay=1), 20.2)
        pm.delete(joint)

    def test_angleZ(self):
        joint = pm.joint(angleZ=31.5)
        self.assertEqual(pm.joint(joint, q=1, angleZ=1), 31.5)
        pm.joint(joint, e=1, angleZ=20.2)
        self.assertEqual(pm.joint(joint, q=1, angleZ=1), 20.2)
        pm.delete(joint)

        joint = pm.joint(az=31.5)
        self.assertEqual(pm.joint(joint, q=1, az=1), 31.5)
        pm.joint(joint, e=1, az=20.2)
        self.assertEqual(pm.joint(joint, q=1, az=1), 20.2)
        pm.delete(joint)

    def test_radius(self):
        joint = pm.joint(radius=31.5)
        self.assertEqual(pm.joint(joint, q=1, radius=1), 31.5)
        pm.joint(joint, e=1, radius=20.2)
        self.assertEqual(pm.joint(joint, q=1, radius=1), 20.2)
        pm.delete(joint)

        joint = pm.joint(rad=31.5)
        self.assertEqual(pm.joint(joint, q=1, rad=1), 31.5)
        pm.joint(joint, e=1, rad=20.2)
        self.assertEqual(pm.joint(joint, q=1, rad=1), 20.2)
        pm.delete(joint)

    def test_stiffnessX(self):
        joint = pm.joint(stiffnessX=31.5)
        self.assertEqual(pm.joint(joint, q=1, stiffnessX=1), 31.5)
        pm.joint(joint, e=1, stiffnessX=20.2)
        self.assertEqual(pm.joint(joint, q=1, stiffnessX=1), 20.2)
        pm.delete(joint)

        joint = pm.joint(stx=31.5)
        self.assertEqual(pm.joint(joint, q=1, stx=1), 31.5)
        pm.joint(joint, e=1, stx=20.2)
        self.assertEqual(pm.joint(joint, q=1, stx=1), 20.2)
        pm.delete(joint)

    def test_stiffnessY(self):
        joint = pm.joint(stiffnessY=31.5)
        self.assertEqual(pm.joint(joint, q=1, stiffnessY=1), 31.5)
        pm.joint(joint, e=1, stiffnessY=20.2)
        self.assertEqual(pm.joint(joint, q=1, stiffnessY=1), 20.2)
        pm.delete(joint)

        joint = pm.joint(sty=31.5)
        self.assertEqual(pm.joint(joint, q=1, sty=1), 31.5)
        pm.joint(joint, e=1, sty=20.2)
        self.assertEqual(pm.joint(joint, q=1, sty=1), 20.2)
        pm.delete(joint)

    def test_stiffnessZ(self):
        joint = pm.joint(stiffnessZ=31.5)
        self.assertEqual(pm.joint(joint, q=1, stiffnessZ=1), 31.5)
        pm.joint(joint, e=1, stiffnessZ=20.2)
        self.assertEqual(pm.joint(joint, q=1, stiffnessZ=1), 20.2)
        pm.delete(joint)

        joint = pm.joint(stz=31.5)
        self.assertEqual(pm.joint(joint, q=1, stz=1), 31.5)
        pm.joint(joint, e=1, stz=20.2)
        self.assertEqual(pm.joint(joint, q=1, stz=1), 20.2)
        pm.delete(joint)

########NEW FILE########
__FILENAME__ = test_api
import unittest
import pymel.api.allapi as api

class Test_toApiObject(unittest.TestCase):
    def test_multipleObjects(self):
        self.assertTrue(api.toApiObject('*') is None)
########NEW FILE########
__FILENAME__ = test_arguments
import unittest

import pymel.util.arguments as arguments

class testCase_mergeCascadingDicts(unittest.TestCase):
    def test_simpleAdd(self):
        orig = {1:'a'}
        arguments.mergeCascadingDicts( {2:'b'}, orig )
        self.assertEqual(orig, {1:'a',2:'b'})

    def test_subAdd(self):
        orig = {1:{'meat':'deinonychus'}}
        arguments.mergeCascadingDicts( {1:{'plants':'stegosaurus'}}, orig )
        self.assertEqual(orig, {1:{'plants':'stegosaurus', 'meat':'deinonychus'}})

    def test_simpleRemove(self):
        orig = {1:'a'}
        arguments.mergeCascadingDicts( {1:arguments.RemovedKey('old')}, orig )
        self.assertEqual(orig, {})

    def test_subRemove(self):
        orig = {1:{'plants':'stegosaurus'}}
        arguments.mergeCascadingDicts( {1:{'plants':arguments.RemovedKey('old')}}, orig )
        self.assertEqual(orig, {1:{}})

    def test_simpleUpdate(self):
        orig = {1:'a'}
        arguments.mergeCascadingDicts( {1:'b'}, orig )
        self.assertEqual(orig, {1:'b'})

    def test_subUpdate(self):
        orig = {1:{'meat':'deinonychus'}}
        arguments.mergeCascadingDicts( {1:{'meat':'trex'}}, orig )
        self.assertEqual(orig, {1:{'meat':'trex'}})

    def test_simpleListReplace(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:origList}
        arguments.mergeCascadingDicts( {1:{0:'samuel', 1:'jackson'}}, orig )
        self.assertEqual(orig, {1:{0:'samuel', 1:'jackson'}})
        self.assertTrue(origList is not orig[1])

    def test_subListReplace(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:{'a':origList}}
        arguments.mergeCascadingDicts( {1:{'a':{0:'samuel', 1:'jackson'}}}, orig )
        self.assertEqual(orig, {1:{'a':{0:'samuel', 1:'jackson'}}})
        self.assertTrue(origList is not orig[1]['a'])

    def test_simpleListUpdate(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:origList}
        arguments.mergeCascadingDicts( {1:{0:'samuel', 1:'jackson'}}, orig,
                                       allowDictToListMerging=True )
        self.assertEqual(orig, {1:['samuel', 'jackson', 'Fer']})
        self.assertTrue(origList is orig[1])

    def test_subListUpdate(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:{'a':origList}}
        arguments.mergeCascadingDicts( {1:{'a':{0:'samuel', 1:'jackson'}}}, orig,
                                       allowDictToListMerging=True )
        self.assertEqual(orig, {1:{'a':['samuel', 'jackson', 'Fer']}})
        self.assertTrue(origList is orig[1]['a'])

    def test_subListListUpdate(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:[origList, 'extra']}
        arguments.mergeCascadingDicts( {1:{0:{0:'samuel', 1:'jackson'}}}, orig,
                                       allowDictToListMerging=True )
        self.assertEqual(orig, {1:[['samuel', 'jackson', 'Fer'], 'extra']})
        self.assertTrue(origList is orig[1][0])

    def test_simpleListRemove(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:origList}
        arguments.mergeCascadingDicts( {1:{0:arguments.RemovedKey('old')}}, orig,
                                       allowDictToListMerging=True )
        self.assertEqual(orig, {1:['mother', 'Fer']})
        self.assertTrue(origList is orig[1])

class testCase_compareCascadingDicts(unittest.TestCase):
    def test_simpleAdd(self):
        orig = {1:'a'}
        new = {1:'a',2:'b'}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1]))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set([2]))
        self.assertEqual(diff, {2:'b'})
        arguments.mergeCascadingDicts( diff, orig )
        self.assertEqual(orig, new)

    def test_subAdd(self):
        orig = {1:{'meat':'deinonychus'}}
        new = {1:{'plants':'stegosaurus', 'meat':'deinonychus'}}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1]))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set())
        self.assertEqual(diff, {1:{'plants':'stegosaurus'}})
        arguments.mergeCascadingDicts( diff, orig )
        self.assertEqual(orig, new)

    def test_simpleRemove(self):
        orig = {1:'a'}
        new = {}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set())
        self.assertEqual(only1, set([1]))
        self.assertEqual(only2, set())
        self.assertEqual(diff, {1:arguments.RemovedKey('a')})
        arguments.mergeCascadingDicts( diff, orig )
        self.assertEqual(orig, new)

    def test_subRemove(self):
        orig = {1:{'plants':'stegosaurus'}}
        new = {1:{}}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1]))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set())
        self.assertEqual(diff, {1:{'plants':arguments.RemovedKey('stegosaurus')}})
        arguments.mergeCascadingDicts( diff, orig )
        self.assertEqual(orig, new)

    def test_simpleUpdate(self):
        orig = {1:'a'}
        new = {1:'b'}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1]))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set())
        self.assertEqual(diff, {1:'b'})
        arguments.mergeCascadingDicts( diff, orig )
        self.assertEqual(orig, new)

    def test_subUpdate(self):
        orig = {1:{'meat':'deinonychus'}}
        new = {1:{'meat':'trex'}}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1]))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set())
        self.assertEqual(diff, {1:{'meat':'trex'}})
        arguments.mergeCascadingDicts( diff, orig )
        self.assertEqual(orig, new)

    def test_simpleListReplace(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:origList, 'foo':'bar'}
        new = {1:{0:'samuel', 1:'jackson'}, 'foo':'bar'}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1, 'foo']))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set())
        print 'diff:', diff
        self.assertEqual(diff, {1:{0:'samuel', 1:'jackson', 2:arguments.RemovedKey('Fer')}})
        arguments.mergeCascadingDicts( diff, orig )
        self.assertEqual(orig, {1:{0:'samuel', 1:'jackson', 2:arguments.RemovedKey('Fer')}, 'foo':'bar'})
        self.assertTrue(origList is not orig[1])

    def test_subListReplace(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:{'a':origList}, 'foo':'bar'}
        new = {1:{'a':{0:'samuel', 1:'jackson'}}, 'foo':'bar'}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1, 'foo']))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set())
        self.assertEqual(diff, {1:{'a':{0:'samuel', 1:'jackson', 2:arguments.RemovedKey('Fer')}}})
        arguments.mergeCascadingDicts( diff, orig )
        self.assertEqual(orig, {1:{'a':{0:'samuel', 1:'jackson', 2:arguments.RemovedKey('Fer')}}, 'foo':'bar'})
        self.assertTrue(origList is not orig[1]['a'])

    def test_simpleListUpdate(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:origList}
        new = {1:['samuel', 'jackson', 'Fer']}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1]))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set())
        self.assertEqual(diff, {1:{0:'samuel', 1:'jackson'}})
        arguments.mergeCascadingDicts( diff, orig,
                                       allowDictToListMerging=True )
        self.assertEqual(orig, new)
        self.assertTrue(origList is orig[1])

    def test_subListUpdate(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:{'a':origList}}
        new = {1:{'a':['samuel', 'jackson', 'Fer']}}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1]))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set())
        self.assertEqual(diff, {1:{'a':{0:'samuel', 1:'jackson'}}})
        arguments.mergeCascadingDicts( diff, orig,
                                       allowDictToListMerging=True )
        self.assertEqual(orig, new)
        self.assertTrue(origList is orig[1]['a'])

    def test_subListListUpdate(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:[origList, 'extra']}
        new = {1:[['samuel', 'jackson', 'Fer'], 'extra']}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1]))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set())
        self.assertEqual(diff, {1:{0:{0:'samuel', 1:'jackson'}}})
        arguments.mergeCascadingDicts( diff, orig,
                                       allowDictToListMerging=True )
        self.assertEqual(orig, new)
        self.assertTrue(origList is orig[1][0])

    def test_simpleListRemove(self):
        origList = ['bad', 'mother', 'Fer']
        orig = {1:origList}
        new = {1:['bad', 'mother']}
        both, only1, only2, diff = arguments.compareCascadingDicts(orig, new)
        self.assertEqual(both, set([1]))
        self.assertEqual(only1, set())
        self.assertEqual(only2, set())
        self.assertEqual(diff, {1:{2:arguments.RemovedKey('Fer')}})
        arguments.mergeCascadingDicts( diff, orig,
                                       allowDictToListMerging=True )
        self.assertEqual(orig, new)
        self.assertTrue(origList is orig[1])

########NEW FILE########
__FILENAME__ = test_datatypes
#! /usr/autodesk/maya2008-x64/bin/mayapy

import sys, os, inspect, unittest
import pymel.core as pm

class test_PMTypes(unittest.TestCase):

    def setUp(self):
        self.eu = pm.datatypes.Vector(1,2,3)
        self.r = pm.datatypes.Point([0.25, 0.5, 1.0, 0.5])
        self.u = pm.datatypes.Vector()
        self.v = pm.datatypes.Vector()
        self.n = pm.datatypes.Vector()
        self.w = pm.datatypes.Vector()
        self.p = pm.datatypes.Point()
        self.q = pm.datatypes.Quaternion()
        self.m = pm.datatypes.Matrix()
        self.M = pm.api.MTransformationMatrix()
        self.V = pm.datatypes.VectorN()
        self.t = pm.api.MTransformationMatrix()


    def tearDown(self):
        pass

#############################################################
## MVector tests

    #def testMVector_dir(self):
    #    self.assertEqual(dir(self.u), dir(datatypes.Vector)) # currently errors - 'this' is not present in Vector

    def testMVector_attrs(self):
        self.assertEqual(self.u.shape, pm.datatypes.Vector.shape)
        self.assertEqual(self.u.ndim, pm.datatypes.Vector.ndim)
        self.assertEqual(self.u.size, pm.datatypes.Vector.size)
        self.u.assign(pm.datatypes.Vector(1, 2, 3))
        self.assertEqual(self.u.x, 1.0)
        self.assertEqual(self.u.y, 2.0)
        self.assertEqual(self.u.z, 3.0)

    def testMVector_instance(self):
        # The default class constructor. Creates a null vector.
        self.u = pm.datatypes.Vector()
        self.assertEqual(self.u, pm.datatypes.Vector())

        # The copy constructor. Create a new vector and initialize it to the same values as the given vector.
        self.u.assign(pm.datatypes.Vector(4, 5, 6))
        self.assertEqual(self.u, pm.datatypes.Vector([4.0, 5.0, 6.0]))

        # The copy constructor. Create a new vector and initialize it to the same values as the given vector.
        self.u = pm.datatypes.Vector(1, 2, 3)
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 2.0, 3.0]))

        # Class constructor. Initializes the vector with the explicit x, y and z values provided as arguments.
        self.u = pm.datatypes.Vector(x=1, y=2, z=3)
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 2.0, 3.0]))

        # Class constructor. Initializes the vector with the explicit x, y and z values provided in the given double array.
        self.u = pm.datatypes.Vector([1, 2], z=3)
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 2.0, 3.0]))

        # Class constructor. Initializes the vector with the explicit x, y and z values provided in the given double array.
        self.u[0:2] = [1,1]
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 1.0, 3.0]))

        # The index operator. If its argument is 0 it will return the x component of the vector. If its argument is 1 it will return the y component of the vector. Otherwise it will return the z component of the vector.
    def testMVector_indexOperatorAccess(self):
        self.assertEqual(self.eu(0), 1)
        self.assertEqual(self.eu(1), 2)
        self.assertEqual(self.eu(2), 3)
        self.assertEqual(self.eu(21), 3)

        self.assertEqual(self.eu[0], 1)
        self.assertEqual(self.eu[1], 2)
        self.assertEqual(self.eu[2], 3)

        # Vector from Point
    def testMVector_instanceFromPoint(self):
        self.u = pm.datatypes.Vector(pm.datatypes.Point(1, 2, 3))
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 2.0, 3.0]))

        # vector from API point
    def testMVector_instanceMPoint(self):
        self.u = pm.datatypes.Vector(pm.api.MPoint(1, 2, 3))
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 2.0, 3.0]))

        # Vector from VectorN
    def testMVector_instanceVectorN(self):
        self.u = pm.datatypes.Vector(pm.datatypes.VectorN(1, 2, 3))
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 2.0, 3.0]))

        # Vector from Single Float
    def testMVector_instance_from_singleFloat(self):
        self.u = pm.datatypes.Vector(1)
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 1.0, 1.0]))

        #
    def testMVector_instance_from_VectorOfLengthTwo(self):
        # Z defaults to 0.0
        self.u = pm.datatypes.Vector(1,2)
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 2.0, 0.0]))

    def testMVector_instanceVectorN2(self):
        self.u = pm.datatypes.Vector(pm.datatypes.VectorN(1, shape=(2,)))
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 1.0, 0.0]))

        # construct from Point, overriding individual axis values
    def testMVector_instancePoint2(self):
        self.u = pm.datatypes.Vector(pm.datatypes.Point(1, 2, 3, 1), y=20, z=30)
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 20.0, 30.0]))

        # assign value through index access
    def testMVector_indexAssign(self):
        self.u = pm.datatypes.Vector(1, 20, 30)
        self.u[0] = 10
        self.assertEqual(self.u, pm.datatypes.Vector([10.0, 20.0, 30.0]))

    def testMVector_IOBAssign(self):
        def IOBtest():
            self.u = pm.datatypes.Vector(pm.datatypes.VectorN(1, 2, 3, 4))
        self.failUnlessRaises(TypeError,IOBtest)  # fails with TypeError, was expecting ValueError

    def testMVector_in(self):
        self.assert_(1.0 in self.eu)

    def testMVector_list(self):
        self.assertEqual(list(self.eu),[1.0, 2.0, 3.0] )

    def testMVector_len(self):
        self.assertEquals(len(self.eu), 3)

    # Ensure that isInstance recognizes u, tests inheritance
    def testMVector_isInstances(self):
        self.assertTrue( isinstance(self.eu, pm.datatypes.VectorN))
        self.assertTrue( isinstance(self.u, pm.datatypes.Array))
        self.assertTrue( isinstance(self.u, pm.api.MVector))

    # Create Vector from api.MPoint
    def testMVector_instanceAPI(self):
        self.u = pm.datatypes.Vector(pm.api.MPoint(1, 2, 3))
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 2.0, 3.0]))

#    def testMVector_translateAPI(self):
#        self.u = datatypes.Vector(api.MPoint(1, 2, 3))
#        #self.M.setTranslation ( self.u, api.MSpace.kWorld )
#        self.u = Vector(self.M.getTranslation ( api.MSpace.kWorld ))
#        self.assertEqual(self.u, Vector([1.0, 2.0, 3.0]))

    def testMVector_Axis(self):
        self.u = pm.datatypes.Vector.xAxis
        self.v = pm.datatypes.Vector.yAxis
        self.assertEqual(self.u, pm.datatypes.Vector([1.0, 0.0, 0.0]))
        self.assertEqual(self.v, pm.datatypes.Vector([0.0, 1.0, 0.0]))

    def testMVector_crossProduct(self):
        self.u = pm.datatypes.Vector.xAxis
        self.v = pm.datatypes.Vector.yAxis
        self.n = self.u ^ self.v
        self.assertEqual(self.n, pm.datatypes.Vector([0.0, 0.0, 1.0]))
        self.n = self.u ^ pm.datatypes.VectorN(self.v)
        self.assertEqual(self.n, pm.datatypes.Vector([0.0, 0.0, 1.0]))
        self.n = self.u ^ [0, 1, 0]
        self.assertEqual(self.n, pm.datatypes.Vector([0.0, 0.0, 1.0]))

    def testMVector_dotProduct(self):
        self.n = pm.datatypes.Vector([1.0, 1.0, 1.0])
        self.n = self.n * 2
        self.assertEqual(self.n, pm.datatypes.Vector([2.0, 2.0, 2.0]))
        self.n = self.n * [0.5, 1.0, 2.0]
        self.assertEqual(self.n, pm.datatypes.Vector([1.0, 2.0, 4.0]))
        self.n = self.n * self.n
        self.assertEqual(self.n, 21)

    def testMVector_clamp(self):
        self.n = pm.datatypes.Vector([1.0, 3.0, 4.0])
        self.assertEqual((self.n.clamp(1.0, 2.0)),pm.datatypes.Vector([1.0, 2.0, 2.0]))

    def testMVector_neg(self):
        self.n = pm.datatypes.Vector([1.0, 3.0, 4.0])
        self.assertEqual(-self.n,pm.datatypes.Vector([-1.0, -3.0, -4.0]))

    def testMVector_add(self):
        self.u = pm.datatypes.Vector.xAxis
        self.v = pm.datatypes.Vector.yAxis
        self.w = self.u + self.v
        self.assertEqual(self.w,pm.datatypes.Vector([1.0, 1.0, 0.0]))

        self.u = pm.datatypes.Vector.xAxis
        self.assertEquals(self.u + 2,pm.datatypes.Vector([3.0, 2.0, 2.0]))
        self.assertEquals(2 + self.u,pm.datatypes.Vector([3.0, 2.0, 2.0]))
        self.assertEquals((self.u + [0.01, 0.01, 0.01]), pm.datatypes.Vector([1.01, 0.01, 0.01]))

    def testMVectorPoint_add(self):
        self.u = pm.datatypes.Vector.xAxis
        self.p = pm.datatypes.Point(1, 2, 3)

        self.q = self.u + self.p
        self.assertEqual(self.q, pm.datatypes.Point([2.0, 2.0, 3.0]))
        self.q = self.p + self.u
        self.assertEquals(self.q, pm.datatypes.Point([2.0, 2.0, 3.0]))

        self.assertEquals((self.q + self.p), pm.datatypes.Point([3.0, 4.0, 6.0]))
        self.assertEquals((self.p + self.q), pm.datatypes.Point([3.0, 4.0, 6.0]))
        self.assertEquals((self.p + self.u), pm.datatypes.Point([2.0, 2.0, 3.0]))

        self.assertEquals(pm.datatypes.VectorN(1, 2, 3, 4) + self.u, pm.datatypes.VectorN([2.0, 2.0, 3.0, 4])) # TODO want Point returned, rather than VectorN
        self.assertEquals([1, 2, 3] + self.u, pm.datatypes.Vector([2.0, 2.0, 3.0])) # TODO want Point returned, rather than Vector

    def testMVector_and_VectorN(self):
        self.u = pm.datatypes.Vector.xAxis
        self.w = self.u + pm.datatypes.VectorN(1, 2, 3, 4)
        self.assertEquals(self.w, pm.datatypes.VectorN([2.0, 2.0, 3.0, 4]))

    def testMVector_length(self):
        self.u = pm.datatypes.Vector(1, 2, 3)
        self.assertEquals(self.u, pm.datatypes.Vector([1.0, 2.0, 3.0]))
        self.assertAlmostEquals(self.u.length(), 3.74165738677 )
        self.assertAlmostEquals(pm.datatypes.Vector.length(self.u), 3.74165738677 )
        #self.assertAlmostEquals(datatypes.Vector.length([1,2,3]), 3.74165738677 )  # TODO :: TypeError: unbound method length() must be called with Vector instance as first argument (got list instance instead)
        self.assertAlmostEquals(pm.datatypes.length(pm.datatypes.VectorN(1,2,3)), 3.74165738677)
        self.assertAlmostEquals(pm.datatypes.VectorN(1,2,3).length(), 3.74165738677)
        self.assertAlmostEquals(pm.datatypes.VectorN.length(pm.datatypes.VectorN(1,2,3,4)), 5.47722557505)
        self.assertAlmostEquals(pm.datatypes.VectorN(1, 2, 3, 4).length(), 5.47722557505)
        self.assertEquals(pm.datatypes.length(1), 1.0)
        self.assertAlmostEquals(pm.datatypes.length([1,2]),2.2360679775)
        self.assertAlmostEquals(pm.datatypes.length([1,2,3]), 3.74165738677)
        self.assertAlmostEquals(pm.datatypes.length([1,2,3,4]), 5.47722557505)
        self.assertAlmostEquals(pm.datatypes.length([1,2,3,4], 0), 5.47722557505)
        self.assertAlmostEquals(pm.datatypes.length([1,2,3,4], (0,)), 5.47722557505)

        def AxisValTest(): # Axis must be value '0' for all Vectors
            pm.datatypes.length([1, 2, 3, 4], 1)
        self.failUnlessRaises(ValueError,AxisValTest)  # ValueError: axis 0 is the only valid axis for a VectorN, 1 invalid

    def testMVector_sqlength(self):
        self.u = pm.datatypes.Vector(1,2,3)
        self.assertEquals(self.u.sqlength(), 14.0)

    def testMVector_axis(self):
        self.u = pm.datatypes.Vector(1, 0, 0)
        self.v = pm.datatypes.Vector(0.707, 0, -0.707)
        self.assertEqual(pm.datatypes.axis(self.u, self.v), pm.datatypes.Vector([-0.0, 0.707, 0.0]))
        self.assertEqual(self.u.axis(self.v), pm.datatypes.Vector([-0.0, 0.707, 0.0]))
        self.assertEqual(pm.datatypes.axis(pm.datatypes.VectorN(self.u), pm.datatypes.VectorN(self.v)), pm.datatypes.VectorN([-0.0, 0.707, 0.0]))
        self.assertEqual(pm.datatypes.axis(pm.datatypes.VectorN(self.u), pm.datatypes.VectorN(self.v)), pm.datatypes.VectorN([-0.0, 0.707, 0.0]))
        first = pm.datatypes.axis(self.u, self.v, normalize=True)
        last = pm.datatypes.Vector([-0.0, 1.0, -0.0])
        self.assert_(first.isEquivalent(last))

        first = self.v.axis(self.u, normalize=True)
        last = pm.datatypes.Vector([-0.0, -1.0, 0.0])
        self.assert_(first.isEquivalent(last))

        first = pm.datatypes.axis(pm.datatypes.VectorN(self.u), pm.datatypes.VectorN(self.v), normalize=True)
        last = pm.datatypes.VectorN([-0.0, 1.0, 0.0])
        self.assert_(first.isEquivalent(last))

    def testMVector_angle(self):
        self.u = pm.datatypes.Vector(1, 0, 0)
        self.v = pm.datatypes.Vector(0.707, 0, -0.707)
        self.assertAlmostEquals(pm.datatypes.angle(self.u,self.v), 0.785398163397 )
        self.assertAlmostEquals(self.v.angle(self.u), 0.785398163397 )
        self.assertAlmostEquals(pm.datatypes.angle(pm.datatypes.VectorN(self.u),pm.datatypes.VectorN(self.v)),0.785398163397 )
        self.assertEquals(pm.datatypes.cotan(self.u, self.v), 1.0)

    def testMVector_angleRotateTo(self):
        self.u = pm.datatypes.Vector(1, 0, 0)
        self.v = pm.datatypes.Vector(0.707, 0, -0.707)

        first = self.u.rotateTo(self.v)
        last = pm.datatypes.Quaternion([-0.0, 0.382683432365, 0.0, 0.923879532511])
        self.assert_(first.isEquivalent(last))

    def testMVector_angleRotateBy(self):
        u = pm.datatypes.Vector(1, 0, 0)
        v = pm.datatypes.Vector(0.707, 0, -0.707)

        first = u.rotateBy(u.axis(v), u.angle(v))
        last = pm.datatypes.Vector([0.707106781187, 0.0, -0.707106781187])

        self.assert_(first.isEquivalent(last))

        q = pm.datatypes.Quaternion([-0.0, 0.382683432365, 0.0, 0.923879532511])

        first = u.rotateBy(q)
        last = pm.datatypes.Vector([0.707106781187, 0.0, -0.707106781187])
        self.assert_(first.isEquivalent(last))


    def testMVector_angleDistanceTo(self):
        self.u = pm.datatypes.Vector(1, 0, 0)
        self.v = pm.datatypes.Vector(0.707, 0, -0.707)
        self.assertAlmostEquals(self.u.distanceTo(self.v),0.765309087885)

    def testMVector_angleParallel(self):
        self.u = pm.datatypes.Vector(1, 0, 0)
        self.v = pm.datatypes.Vector(0.707, 0, -0.707)
        self.assertFalse(self.u.isParallel(self.v))
        self.assertTrue(self.u.isParallel(2*self.u))

    def testMVector_normal(self):
        self.u = pm.datatypes.Vector(1,2,3)
        first = self.u.normal()
        last = pm.datatypes.Vector([0.267261241912, 0.534522483825, 0.801783725737])
        self.assert_(first.isEquivalent(last))

    def testMVector_normalize(self):
        self.u = pm.datatypes.Vector(1,2,3)
        self.u.normalize()
        last = pm.datatypes.Vector([0.267261241912, 0.534522483825, 0.801783725737])
        self.assert_(self.u.isEquivalent(last))

    def testMVector_equality(self):
        self.u = pm.datatypes.Vector(1,2,3)
        self.w = self.u + pm.datatypes.VectorN(1, 2, 3, 4)
        self.assert_(self.u == self.u)
        self.assert_(self.u != self.w)
        self.assert_(self.u == pm.datatypes.Vector(1.0, 2.0, 3.0))
        #self.failIfEqual(self.u == [1.0, 2.0, 3.0])
        self.assert_(self.u != [1.0, 2.0, 3.0])
        self.assert_(self.u != pm.datatypes.Point(1.0, 2.0, 3.0))
        self.assertTrue(self.u.isEquivalent([1.0, 2.0, 3.0]))
        self.assertTrue(self.u.isEquivalent(pm.datatypes.Vector(1.0, 2.0, 3.0)))
        self.assertTrue(self.u.isEquivalent(pm.datatypes.Point(1.0, 2.0, 3.0)))
        #self.assertFalse(self.u.isEquivalent(self.w)) # TODO :: TypeError: super(type, obj): obj must be an instance or subtype of type
        #self.assertTrue(self.u.isEquivalent(self.w, 0.1)) # TODO :: TypeError: super(type, obj): obj must be an instance or subtype of type

    def testMVector_angleBlend(self):
        self.u = pm.datatypes.Vector(1, 0, 0)
        self.v = pm.datatypes.Vector(0.707, 0, -0.707)
        goop = pm.datatypes.Vector([0.8535, 0.0, -0.3535])
        self.assert_(self.u.blend(self.v).data.isEquivalent(goop.data))

#############################################################
## MPoint tests

    def testMPoint_hasAttr(self):
        self.assertTrue(hasattr(pm.datatypes.Point,'data'))

    def testMPoint_list(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.assertEquals(list(self.p),[1.0, 2.0, 3.0] )

    def testMPoint_len(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.assertEquals(len(self.p),3)

    def testMPoint_size(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.assertEquals(self.p.size,4)

    def testMPoint_indiceAccess(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.assertEquals(self.p.x, 1.0)
        self.assertEquals(self.p.y, 2.0)
        self.assertEquals(self.p.z, 3.0)
        self.assertEquals(self.p.w, 1.0)

        self.assertEquals(self.p[0], 1.0)
        self.assertEquals(self.p[1], 2.0)
        self.assertEquals(self.p[2], 3.0)
        self.assertEquals(self.p[3], 1.0)

    def testMPoint_get(self):
        self.p = pm.datatypes.Point(1,2,3)
        got = self.p.get()
        self.assert_(got == (1.0, 2.0, 3.0, 1.0))

    def testMPoint_distanceTo(self):
        self.q = pm.api.MPoint()
        self.p = pm.datatypes.Point(1,2,3)
        self.assertAlmostEquals(self.q.distanceTo(self.p), 3.74165738677)


    def testMPoint_NonCartesion_instance(self):
        # support for non cartesian points still there
        self.p = pm.datatypes.Point(1, 2, 3, 2)
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 2.0, 3.0, 2.0]))

        self.v = pm.datatypes.Vector(self.p)
        self.assertEquals(self.v, pm.datatypes.Vector([0.5, 1.0, 1.5]))

        self.V = pm.datatypes.VectorN(self.p)
        self.assertEquals(self.V,pm.datatypes.VectorN([1.0, 2.0, 3.0, 2.0]))

    def testMPoint_NonCartesion_list(self):
        self.p = pm.datatypes.Point(1, 2, 3, 2)
        self.assertEquals(list(self.p), [1.0, 2.0, 3.0, 2.0])

    def testMPoint_NonCartesion_len(self):
        self.p = pm.datatypes.Point(1, 2, 3, 2)
        self.assertEquals(len(self.p),4)

    def testMPoint_NonCartesion_size(self):
        self.p = pm.datatypes.Point(1, 2, 3, 2)
        self.assertEquals(self.p.size,4)

    def testMPoint_NonCartesion_indexLetterAccess(self):
        self.p = pm.datatypes.Point(1, 2, 3, 2)
        self.assertEquals(self.p.x, 1.0)
        self.assertEquals(self.p.y, 2.0)
        self.assertEquals(self.p.z, 3.0)
        self.assertEquals(self.p.w, 2.0)

        self.assertEquals(self.p[0], 1.0)
        self.assertEquals(self.p[1], 2.0)
        self.assertEquals(self.p[2], 3.0)
        self.assertEquals(self.p[3], 2.0)

    def testMPoint_NonCartesion_Get(self):
        got = ""
        self.p = pm.datatypes.Point(1, 2, 3, 2)
        got = self.p.get()
        self.assert_(got == (1.0, 2.0, 3.0, 2.0))


##############################################################

#        self.q = api.MPoint()
#        self.assertEquals(self.q.distanceTo(self.p), 1.87082869339)

##############################################################


        self.p = pm.datatypes.Point (pm.api.MPoint())
        self.assertEquals(self.p, pm.datatypes.Point([0.0, 0.0, 0.0]))

        self.p = pm.datatypes.Point(1)
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 1.0, 1.0]))

        self.p = pm.datatypes.Point(1, 2)
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 2.0, 0.0]))

        self.p = pm.datatypes.Point(1, 2, 3)
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 2.0, 3.0]))

        self.p = pm.datatypes.Point(pm.api.MPoint(1, 2, 3))
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 2.0, 3.0]))

        self.p = pm.datatypes.Point(pm.datatypes.VectorN(1,2))
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 2.0, 0.0]))

        self.p = pm.datatypes.Point(pm.datatypes.VectorN(1, 2, 3))
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 2.0, 3.0]))

    def testMPoint_instance(self):
        self.p = pm.datatypes.Point()
        self.assertEquals(self.p, pm.datatypes.Point([0.0, 0.0, 0.0]))
        self.assert_("<maya.OpenMaya.MPoint; proxy of <Swig Object of type 'MPoint *' at" in repr(self.p.data))

        self.p = pm.datatypes.Point(1,2,3)
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 2.0, 3.0]))

        self.v = pm.datatypes.Vector(self.p)
        self.assertNotEqual(self.p, self.v)
        self.assertTrue(self.p.isEquivalent(self.v))
        self.assertTrue(self.v.isEquivalent(self.p))
        self.assertEquals(self.v, pm.datatypes.Vector([1.0, 2.0, 3.0]))

        self.V = pm.datatypes.VectorN(self.p)
        self.assertEquals(self.V, pm.datatypes.VectorN([1.0, 2.0, 3.0, 1.0]))

        # Point from MVector
        self.p = pm.datatypes.Point(pm.api.MVector(1, 2, 3))
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 2.0, 3.0]))

        # Point from datatypes.VectorN
        self.p = pm.datatypes.Point(pm.datatypes.VectorN(1, 2, 3, 4))
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 2.0, 3.0, 4.0]))

        # Point from datatypes.Vector from Point
        self.p = pm.datatypes.Point(pm.datatypes.Vector(self.p))
        self.assertEquals(self.p, pm.datatypes.Point([0.25, 0.5, 0.75]))

        # VectorN from Point from VectorN
        self.p = pm.datatypes.Point(pm.datatypes.VectorN(1, 2, 3, 4))
            # notice the last minute, sneak conversion to VectorN.
        self.assertEquals(pm.datatypes.VectorN(self.p), pm.datatypes.VectorN([1.0, 2.0, 3.0, 4.0]))

        # Copy Constructor
        self.p = pm.datatypes.Point(self.p, w=1)
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 2.0, 3.0]))

        # datatypes.Vector from Point
        self.assertEquals(pm.datatypes.Vector(self.p), pm.datatypes.Vector([1.0, 2.0, 3.0])) # test Vector from Point

        # datatypes.VectorN from Point
        self.assertEquals(pm.datatypes.VectorN(self.p), pm.datatypes.VectorN([1.0, 2.0, 3.0, 1.0]))

        # origin test
        self.p = pm.datatypes.Point.origin
        self.assertEquals(self.p, pm.datatypes.Point([0.0, 0.0, 0.0]))

        # xAxis test
        self.p = pm.datatypes.Point.xAxis
        self.assertEquals(self.p, pm.datatypes.Point([1.0, 0.0, 0.0]))

        # yAxis test
        self.p = pm.datatypes.Point.yAxis
        self.assertEquals(self.p, pm.datatypes.Point([0.0, 1.0, 0.0]))

        # zAxis test
        self.p = pm.datatypes.Point.zAxis
        self.assertEquals(self.p, pm.datatypes.Point([0.0, 0.0, 1.0]))


    def testMPoint_add(self):
        self.p = pm.datatypes.Point(1, 2, 3, 1)
        self.assertEquals(self.p + 2, pm.datatypes.Point([3.0, 4.0, 5.0, 1.0]))
        self.assertEquals(2 + self.p, pm.datatypes.Point([3.0, 4.0, 5.0, 1.0]))

        #reset vals
        self.p = pm.datatypes.Point(1, 2, 3)

        # Point and Vector :: returns Point
        self.assertEquals(self.p + pm.datatypes.Vector([1, 2, 3]), pm.datatypes.Point([2.0, 4.0, 6.0]))

        # Point and Point :: returns Point
        self.assertEquals(self.p + pm.datatypes.Point([1, 2, 3]), pm.datatypes.Point([2.0, 4.0, 6.0]))

        # Point and list(3,) :: returns Point
        self.assertEquals(self.p + [1, 2, 3], pm.datatypes.Point([2.0, 4.0, 6.0]))

        # Point(3,) and Point(4,) :: returns Point
        self.assertEquals(self.p + pm.datatypes.Point([1, 2, 3, 1]), pm.datatypes.Point([2.0, 4.0, 6.0]))
        self.assertEquals(self.p + pm.datatypes.Point([1, 2, 3, 2]), pm.datatypes.Point([1.5, 3.0, 4.5]))

        # Vector and Point :: returns Point
        self.assertEquals((pm.datatypes.Vector([1, 2, 3]) + self.p), pm.datatypes.Point([2.0, 4.0, 6.0]))

        # Point and List(4,) :: returns Point
        self.assertEquals(self.p + [1, 2, 3, 2], pm.datatypes.Point([2.0, 4.0, 6.0, 3.0]))

        # Point(3,) and Point :: returns Point
        self.assertEquals((pm.datatypes.Point([1, 2, 3]) + self.p), pm.datatypes.Point([2.0, 4.0, 6.0]))

        # List and Point :: returns Point
        self.assertEquals(([1, 2, 3] + self.p), pm.datatypes.Point([2.0, 4.0, 6.0]))

        # TODO : returns Vector - expected Point([2.0, 4.0, 6.0])) :: if w=1, it returns type Vector,otherwise returns Point
        self.assertEquals(([1, 2, 3, 1] + self.p), pm.datatypes.Vector([2.0, 4.0, 6.0]))

        # not sure what ths chunk is testing for?
        #self.p = datatypes.Point(1, 2, 3)  # reset for all
        #self.assertEquasls((datatypes.Point([1,2,3]) + self.p), datatypes.Point([2.0, 4.0, 6.0]))
        #self.assertEquals([1,2,3,2] + self.p, datatypes.Point([2.0, 4.0, 6.0, 3.0]))
        #self.assertEquals((datatypes.Point([1, 2, 3, 2]) + self.p), datatypes.Point([1.5, 3.0, 4.5]))

    def testMPoint_operations(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.q = pm.datatypes.Point(0.25, 0.5, 1.0)

        # divide point by scalar
        self.assertEquals((self.p / 2),pm.datatypes.Point([0.5, 1.0, 1.5]))

        # multiply point by scalar
        self.assertEquals((self.p * 2),pm.datatypes.Point([2.0, 4.0, 6.0]))

        # add point by scalar
        self.assertEquals(self.q + 2,pm.datatypes.Point([2.25, 2.5, 3.0]))

        # divide point by scalar
        self.assertEquals(self.q / 2,pm.datatypes.Point([0.125, 0.25, 0.5]))

        # add point to point
        #self.assertEquals(self.p + self.q, datatypes.Point([1.25, 2.5, 4.0]))

        # subtract point from point :: successfully returns Vector instance
        self.assertEquals(self.p - self.q, pm.datatypes.Vector([0.75, 1.5, 2.0]))
        self.assertEquals(self.q - self.p, pm.datatypes.Vector([-0.75, -1.5, -2.0]))

        # subtract point from (point subtracted from point) :: nested/transitive subtraction
        self.assertEquals(self.p-(self.p - self.q), pm.datatypes.Point([0.25, 0.5, 1.0]))

        # Multiply Vectors from Points
        self.assertEquals(pm.datatypes.Vector(self.p) * pm.datatypes.Vector(self.q), 4.25)

        # Point multiplication
        self.assertEquals(self.p*self.q, 4.25)

        # divide point by point
        self.assertEquals(self.p / self.q, pm.datatypes.Vector([4.0, 4.0, 3.0])) # TODO : Original expected Point([4.0, 4.0, 3.0])

        # divide point by scalar
        self.assertEquals(self.p / 2, pm.datatypes.Point([0.5, 1.0, 1.5]))

        # multiply point by scalar
        self.assertEquals(self.p * 2, pm.datatypes.Point([2.0, 4.0, 6.0]))

    def testMPoint_cartesianize(self):
        locCop = pm.datatypes.Point(self.r)
        self.assertEquals(locCop.cartesian(),pm.datatypes.Point([0.5, 1.0, 2.0]))
        self.assertEquals(locCop.cartesianize(),pm.datatypes.Point([0.5, 1.0, 2.0]))

#    def testMPoint_deepcopy(self):
#        self.assertEquals(self.r, datatypes.Point([0.25, 0.5, 1.0, 0.5]))
#        self.assertEquals(self.r, self.qc)

    def testMPoint_rationalize(self):
        locCop = pm.datatypes.Point(self.r)
        self.assertEquals(locCop.rational(), pm.datatypes.Point([0.5, 1.0, 2.0, 0.5]))
        self.assertEquals(locCop.rationalize(), pm.datatypes.Point([0.5, 1.0, 2.0, 0.5])) # TODO :: currently returns Point([1.0, 2.0, 4.0, 0.5]

    def testMPoint_homegenize(self):
        locCop = pm.datatypes.Point(self.r)
        self.assertEquals(locCop.homogen(), pm.datatypes.Point([0.125, 0.25, 0.5, 0.5]))
        self.assertEquals(locCop.homogenize(), pm.datatypes.Point([0.125, 0.25, 0.5, 0.5])) # TODO :: homogen leaves self.r intact, returns homogenized

    def testMPoint_VectorFromCartesianizedPoint(self):
        locCop = pm.datatypes.Point(self.r)
        self.assertEquals(pm.datatypes.Vector(locCop.cartesian()), pm.datatypes.Vector([0.5, 1.0, 2.0])) #ignores 'w'

    def testMPoint_dividePointByScalar(self):
        self.assertEquals(self.r / 2, pm.datatypes.Point([0.125, 0.25, 0.5, 0.5]))

    def testMPoint_multPointByScalar(self):
        self.assertEquals(self.r * 2, pm.datatypes.Point([0.5, 1.0, 2.0, 0.5]))

    def testMPoint_addPointToScalar(self):
        self.assertEquals(self.r + 2, pm.datatypes.Point([2.5, 3.0, 4.0]))  # cartesianize is done by datatypes.Vector's add

    def testMPoint_VectorInst_addition(self):
        self.p = pm.datatypes.Point(1,2,3)
        #self.q = datatypes.Point(0.25, 0.5, 1.0)
        self.assertEquals((self.p + pm.datatypes.Vector(1, 2, 3)), pm.datatypes.Point([2.0, 4.0, 6.0]))
        self.assertEquals((self.r + pm.datatypes.Vector(1, 2, 3)), pm.datatypes.Point([1.5, 3.0, 5.0]))

    def testMPoint_cartesion_VectorInst_addition(self):
        self.assertEquals((self.r.cartesian() + pm.datatypes.Vector(1,2,3)), pm.datatypes.Point([1.5, 3.0, 5.0]))

    def testMPoint_subtractPointFromPoint(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.q = pm.datatypes.Point(0.25, 0.5, 1.0)
        self.assertEquals((self.p - self.r), pm.datatypes.Vector([0.5, 1.0, 1.0]))
        self.assertEquals((self.r - self.p), pm.datatypes.Vector([-0.5, -1.0, -1.0]))
        self.assertEquals(self.p - (self.p - self.r), pm.datatypes.Point([0.5, 1.0, 2.0]))

    def testMPoint_cartesian_subtraction(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.assertEquals((self.p-self.r.cartesian()), pm.datatypes.Vector([0.5, 1.0, 1.0]))

    def testMPoint_VectorMultiply_from_Points(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.assertEquals(pm.datatypes.Vector(self.p) * pm.datatypes.Vector(self.r), 8.5)

    def testMPoint_mult(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.assertEquals(self.p * self.r, 8.5)

 #   def testMPoint_dividePoints(self):  # TODO : need explicit homogenize as division not handled by api
 #       homoP = self.p.homogenize()
 #       homoQ = self.q.homogenize()
 #       self.assertEquals(homoP / homoQ, datatypes.Vector([2.0, 2.0, 1.5])) # used to be Point([4.0, 4.0, 3.0, 2.0])
        #  TODO : what do we want here ?

    def testMPoint_length(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.assertAlmostEquals(self.p.length(),3.74165738677)
        self.assertEquals(self.p[:1].length(), 1.0)
        self.assertEquals(pm.datatypes.length(self.p[:1]), 1.0)
        self.assertAlmostEquals(self.p[:2].length(), 2.2360679775)
        self.assertAlmostEquals(self.p[:3].length(), self.p.length())
        self.assertAlmostEquals(pm.datatypes.length(self.p),3.74165738677)


    def testMPoint_axis(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.q = pm.datatypes.Point(0.707, 0.0, -0.707)
        # returns Vector(- + -)
        self.assertEquals(pm.datatypes.axis(pm.datatypes.Point.origin, self.p, self.q), pm.datatypes.Vector([-1.414, 2.828, -1.414]))
        # returns Vector(- + -)
        self.assertEquals(pm.datatypes.Point.origin.axis(self.p, self.q), pm.datatypes.Vector([-1.414, 2.828, -1.414]))
        # returns Vector(+ - +)
        self.assertEquals(pm.datatypes.Point.origin.axis(self.q, self.p), pm.datatypes.Vector([1.414, -2.828, 1.414]))

    def testMPoint_angle(self): # TODO :: WONKY ass vals returned - do the math again
        self.p = pm.datatypes.Point(1,2,3)
        self.q = pm.datatypes.Point(0.707, 0.0, -0.707)
        self.assertAlmostEquals(pm.datatypes.angle(pm.datatypes.Point.origin, self.p, self.q), 1.9583930134500773)
        self.assertAlmostEquals(pm.datatypes.angle(pm.datatypes.Point.origin, self.q, self.p), 1.9583930134500773)

        self.assertAlmostEquals(pm.datatypes.angle(pm.datatypes.Point.origin, self.p, self.r), 0.13078263384791716)
        self.assertAlmostEquals(pm.datatypes.angle(pm.datatypes.Point.origin, self.r, self.p), 0.13078263384791716)

        self.assertAlmostEquals(pm.datatypes.Point.origin.angle(self.p, self.q), 1.9583930134500773)
        self.assertAlmostEquals(pm.datatypes.Point.origin.angle(self.p, self.r), 0.13078263384791716)
        # self.assertEquals(datatypes.cotan(datatypes.Point.origin, self.p, self.q), 1.0)

    def testMPoint_distance(self):
        self.q = pm.datatypes.Point(0.707, 0.0, -0.707)
        self.p = pm.datatypes.Point(1,2,3)
        self.assertAlmostEquals(self.p.distanceTo(self.q), 4.2222858737892199)

    def testMPoint_differenceLengthForDistance(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.q = pm.datatypes.Point(0.707, 0.0, -0.707)
        self.assertAlmostEquals((self.q-self.p).length(), 4.2222858737892199)

    def testMPoint_planar(self):
        self.p = pm.datatypes.Point(1,2,3)
        self.q = pm.datatypes.Point(0.707, 0.0, -0.707)
        self.assertTrue( pm.datatypes.planar( pm.datatypes.Point.origin, self.p, self.q ))
        #self.assertTrue( datatypes.planar( datatypes.Point.origin, self.p, self.q, self.r )) # TODO :: currently evaluates to false whenever you pass in mor than three args
        #self.assertFalse(datatypes.planar( datatypes.Point.origin, self.p, self.q, self.r + datatypes.Vector(0.0, 0.1, 0.0)))

    def testMPoint_center(self):
        locP = pm.datatypes.Point([1.0, 2.0, 3.0])
        locQ = pm.datatypes.Point([1.0, 2.0, 3.0, 1.0])
        first = pm.datatypes.center(pm.datatypes.Point.origin, locP, locP)
        last = pm.datatypes.Point([0.666666666667, 1.33333333333, 2.0])
        self.assert_(first, last) #TODO # Point([0.569, 0.0, -0.235666666667, 1.0])

    def testMPoint_bWeights(self):
        locP = pm.datatypes.Point([1.0, 2.0, 3.0])
        locQ = pm.datatypes.Point([1.0, 2.0, 3.0, 1.0])

        self.assertEquals(pm.datatypes.bWeights(self.r, pm.datatypes.Point.origin, locP, locQ), (0.0, 0.5, 0.5))
        self.assertEquals(pm.datatypes.bWeights((.5,0,0), (0,0,0),(1,0,0),(1,1,0),(0,1,0)), (.5, .5, 0, 0))

    def testMPoint_round(self):
        self.p = pm.datatypes.Point([0.33333, 0.66666, 1.333333, 0.33333])
        self.assertEquals(pm.datatypes.round(self.p, 3), pm.datatypes.Point([0.333, 0.667, 1.333, 0.333]) )


##################################################################
## MColor tests

    def testMColor_hasattr(self):
        self.assertTrue(hasattr(pm.datatypes.Color, 'data'))

    def testMColor_instance_hasattr(self):
        self.c = pm.datatypes.Color()
        self.assertTrue(hasattr(self.c, 'data'))

    def testMColor_instance(self):
        self.c = pm.datatypes.Color()
        self.assertEquals(self.c, pm.datatypes.Color([0.0, 0.0, 0.0, 1.0]))

        self.c = pm.datatypes.Color(pm.api.MColor())
        self.assertEquals(self.c, pm.datatypes.Color([0.0, 0.0, 0.0, 1.0])) # TODO - using api convention of single value would mean alpha
        # instead of datatypes.VectorN convention of filling all with value
        # which would yield # Color([0.5, 0.5, 0.5, 0.5]) instead
        # This would break coerce behavior for Color

        self.c = pm.datatypes.Color(0.5)
        self.assertEquals(self.c ,pm.datatypes.Color([0.5, 0.5, 0.5, 0.5]))

        self.c = pm.datatypes.Color(1, 1, 1)
        self.assertEquals(self.c , pm.datatypes.Color([1.0, 1.0, 1.0, 1.0]))

        self.c = pm.datatypes.Color(1, 0.5, 2, 0.5)
        self.assertEquals(self.c,pm.datatypes.Color([1.0, 0.5, 2.0, 0.5]))

        self.c = pm.datatypes.Color(128, quantize=255)
        self.assertEquals(self.c , pm.datatypes.Color([0.501960813999, 0.501960813999, 0.501960813999, 0.501960813999]))

        self.c = pm.datatypes.Color(255, 128, b=64, a=32, quantize=255)
        self.assertEquals(self.c , pm.datatypes.Color([1.0, 0.501960813999, 0.250980407, 0.1254902035]))

        self.c = pm.datatypes.Color(0, 65535, 65535, quantize=65535, mode='hsv')
        self.assertEquals(self.c , pm.datatypes.Color([1.0, 0.0, 0.0, 1.0]))

        self.c = pm.datatypes.Color(self.c, v=0.5, mode='hsv')
        self.assertEquals(self.c , pm.datatypes.Color([0.5, 0.0, 0.0, 1.0]))

    def testMColor_CopyConstructor(self):
        self.c = pm.datatypes.Color(pm.datatypes.Color.blue, v=0.5)
        self.assertEquals(self.c , pm.datatypes.Color([0.0, 0.0, 0.5, 1.0]))

    def testMColor_round(self):
        self.c = pm.datatypes.round(pm.datatypes.Color(255, 0, 255, g=128, quantize=255, mode='rgb'), 2)
        self.assertEquals(self.c , pm.datatypes.Color([1.0, 0.5, 1.0, 1.0]))

        self.c = pm.datatypes.round(pm.datatypes.Color(255, b=128, quantize=255, mode='rgb'), 2)
        self.assertEquals(self.c , pm.datatypes.Color([1.0, 1.0, 0.5, 1.0]))

    def testMColor_rgb(self):
        self.c = pm.datatypes.Color(0, 65535, 65535, quantize=65535, mode='hsv')
        self.assertEquals(self.c.rgb, (1.0, 0.0, 0.0))

    def testMColor_hsv(self):
        self.c = pm.datatypes.Color(0, 65535, 65535, quantize=65535, mode='hsv')
        self.assertEquals(self.c.hsv, (0.0, 1.0, 1.0))

        self.d = pm.datatypes.Color(self.c, v=0.5, mode='hsv')
        self.assertEquals(self.d.hsv,(0.0, 1.0, 0.5))

        self.c = pm.datatypes.Color(pm.datatypes.Color.blue, v=0.5)
        self.assertEquals(self.c.hsv,(0.66666666666666663, 1.0, 0.5))

    def testMColor_rgbIndex_access(self):
        self.c = pm.datatypes.Color(pm.datatypes.Color.blue, v=0.5)
        self.c.r = 1.0
        self.c.g = 2.0
        self.c.b = 3.0
        self.c.a = 0.5

        self.assertEquals(self.c , pm.datatypes.Color([1.0, 2.0, 3.0, 0.5]))
        self.assertEquals(self.c.hsv, (0.0, 0.0, 1.0))

    def testMColor_RGB_Constructor_Clamp(self):
        self.c = pm.datatypes.Color(1, 0.5, 2, 0.5).clamp()
        self.assertEquals(self.c, pm.datatypes.Color([1.0, 0.5, 1.0, 0.5]) )
        self.assertEquals(self.c.hsv, (0.83333333333333337, 0.5, 1.0))

    def testMColor_Copy_Constructor(self):
        self.c = pm.datatypes.Color(1, 0.5, 2, 0.5).clamp()
        self.d = pm.datatypes.Color(self.c,v=0.5)
        self.assertEquals(self.d, pm.datatypes.Color([0.5, 0.25, 0.5, 0.5]))
        self.assertEquals(self.d.hsv, (0.83333333333333337, 0.5, 0.5))

    def testMColor_RGB_Constructor(self):
        self.c = pm.datatypes.Color(0.0, 0.5, 1.0, 0.5)
        self.assertEquals(self.c, pm.datatypes.Color(0.0, 0.5, 1.0, 0.5))

    def testMColor_Gamma(self):
        self.c = pm.datatypes.Color(0.0, 0.5, 1.0, 0.5)
        self.d = self.c.gamma(2.0)
        self.assertEquals(self.d, pm.datatypes.Color([0.0, 0.25, 1.0, 0.5]))

    def testMColor_Blend(self):
        self.c = pm.datatypes.Color.red.blend(pm.datatypes.Color.blue, 0.5)
        self.assertEquals(self.c.hsv, (0.83333333333333337, 1.0, 0.5))

    def testMColor_HsvBlend(self):
        self.c = pm.datatypes.Color.red.hsvblend(pm.datatypes.Color.blue, 0.5)
        self.assertEquals(self.c.hsv, (0.83333333333333337, 1.0, 1.0))

    def testMColor_Over(self):
        self.c = pm.datatypes.Color(0.25, 0.5, 0.75, 0.5)
        self.d = pm.datatypes.Color.black
        self.assertEquals(self.c.over(self.d), pm.datatypes.Color([0.125, 0.25, 0.375, 1.0]) )
        self.assertEquals(self.d.over(self.c), pm.datatypes.Color([0.0, 0.0, 0.0, 0.5]))

    def testMColor_RGB_Constructor_Premult(self):
        self.c = pm.datatypes.Color(0.25, 0.5, 0.75, 0.5)
        self.assertEquals(self.c.premult(), pm.datatypes.Color([0.125, 0.25, 0.375, 1.0]))

    def testMColor_VectorInheritance(self):
        self.c = pm.datatypes.Color(0.25, 0.5, 1.0, 1.0)
        self.d = pm.datatypes.Color(2.0, 1.0, 0.5, 0.25)
        self.assertEquals(self.c, pm.datatypes.Color([0.25, 0.5, 1.0, 1.0]))
        self.assertEquals(self.d, pm.datatypes.Color([2.0, 1.0, 0.5, 0.25]))

        # Negative assignment
        self.assertEquals(-(self.c), pm.datatypes.Color([-0.25, -0.5, -1.0, 1.0]))

        # Multiply two colors
        self.e = self.c * self.d
        self.assertEquals(self.e, pm.datatypes.Color([0.5, 0.5, 0.5, 0.25]))

        # Addition with constant
        self.assertEquals((self.e + 2), pm.datatypes.Color([2.5, 2.5, 2.5, 0.25]))

        # Multiply by scalar float
        # (defined in api for colors and also multiplies alpha)
        self.assertEquals((self.e * 2.0), pm.datatypes.Color([1.0, 1.0, 1.0, 0.5]))

        # Divide by scalar float
        # TODO as is divide, that ignores alpha now for some reason
        self.assertEquals((self.e/2.0), pm.datatypes.Color([0.25, 0.25, 0.25, 0.25]))

        # Addition with Vector Instance
        self.assertEquals(self.e + pm.datatypes.Vector(1,2,3), pm.datatypes.Color([1.5, 2.5, 3.5, 0.25]))
        # TODO Come correct? Here, behaves like API.

        # Addition with self
        self.assertEquals((self.c + self.c), pm.datatypes.Color([0.5, 1.0, 2.0, 1.0]))
        # Addition with Color
        self.assertEquals((self.c + self.d), pm.datatypes.Color([2.25, 1.5, 1.5, 1.0]))
        # Subtraction with Color
        self.assertEquals((self.d - self.c), pm.datatypes.Color([1.75, 0.5, -0.5, 0.25]))
        #print "end tests Color" - TODO go through classes and make sure all methods are represented

#===============================================================================
# Euler Tests
#===============================================================================
    def testEuler_units(self):
        oldUnit = pm.datatypes.Angle.getUIUnit()
        try:
            pm.datatypes.Angle.setUIUnit('degrees')
            inDegrees = [10,20,30]
            eDeg = pm.datatypes.EulerRotation(inDegrees)
            self.assertEquals(eDeg, pm.datatypes.EulerRotation(inDegrees, unit='degrees'))
            eRad = pm.datatypes.EulerRotation(eDeg)
            eRad.unit = 'radians'
            self.assertEquals(eDeg, eRad)
            inRadians = [pm.datatypes.Angle(x, unit='degrees').asRadians() for x in inDegrees]
            eRad2 = pm.datatypes.EulerRotation(inRadians, unit='radians')
            self.assertEqual(eRad2, eDeg)
            self.assertNotEqual(eRad2.x, eDeg.x)
            self.assertEqual(list(eDeg), [pm.datatypes.Angle(x, unit='radians').asDegrees() for x in eRad2])
        finally:
            pm.datatypes.Angle.setUIUnit(oldUnit)

    def testEuler_rotationOrder(self):
        rot = pm.datatypes.EulerRotation(10,20,30, 'XYZ')
        self.assertEqual(rot.order, 'XYZ')
        rot.order = 'ZYX'
        self.assertEqual(rot.order, 'ZYX')
        other = pm.datatypes.EulerRotation(10,20,30, 'ZYX')
        self.assertEqual(other.order, 'ZYX')
        self.assertEqual(rot, pm.datatypes.EulerRotation(10,20,30, 'ZYX'))
        rot.assign( (6,7,8) )
        self.assertEqual(rot.order, 'ZYX')

    def testEuler_setItem(self):
        rot = pm.datatypes.EulerRotation(10,20,30, 'XYZ')
        self.assertAlmostEqual(rot.y, 20)
        rot.y = 50
        self.assertAlmostEqual(rot.y, 50)
        self.assertAlmostEqual(rot.z, 30)
        rot['z'] = 60
        self.assertAlmostEqual(rot.z, 60)
        self.assertAlmostEqual(rot.x, 10)
        rot[0] = 70
        self.assertAlmostEqual(rot.x, 70)


##################################################################
## MMatrix tests

    def testMatrix_Instance(self) :
        self.m = pm.datatypes.Matrix()
        self.assertEquals(self.m.shape, pm.datatypes.Matrix.shape)
        self.assertEquals(self.m.ndim,  pm.datatypes.Matrix.ndim)
        self.assertEquals(self.m.size,  pm.datatypes.Matrix.size)

    def testIdentityMatrix_IsInstance(self) :
        self.m = pm.datatypes.Matrix.identity
        self.assertTrue(isinstance(self.m, pm.datatypes.MatrixN))
        self.assertTrue(isinstance(self.m, pm.datatypes.Array))
        self.assertTrue(isinstance(self.m, pm.api.MMatrix))

    def testMatrix_False_Instances(self) :
        def Matrix_fromRange_Test():
            self.m = pm.datatypes.Matrix(range(20)) # TODO should fail
            self.m.formated()
        #   cannot initialize a Matrix of shape (4, 4) from list of 20,
        #   would cause truncation errors, use an explicit resize or trim"
        self.failUnlessRaises(TypeError, Matrix_fromRange_Test)

#        self.m = datatypes.Matrix()
#        def MatrixSetTest1():
#            self.m.shape = (4,4) # TODO should fail
#        def MatrixSetTest2():
#            self.m.shape = 2
#
#        self.failUnlessRaises(ValueError, MatrixSetTest1)
#        self.failUnlessRaises(ValueError, MatrixSetTest2)

    def testMatrix_formated(self) :
        self.m = pm.datatypes.Matrix()
        self.assertEquals(self.m.formated(), '[[1.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 0.0],\n [0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0]]')

    def testMatrix_IndexAccess(self) :
        self.m = pm.datatypes.Matrix()


        # Single Index
        self.assertEquals(self.m[0][0], 1.0)
        #self.assertEquals(self.m[0:0][0:2],[[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]) ## TODO :: WTF?
        # Multi Index
        self.assertEquals(self.m[1:2][0:1], pm.datatypes.MatrixN([[0.0, 1.0, 0.0, 0.0]]))

        # paren indice access
        self.assertEquals(self.m(0,0), 1.0)

    def testMMatrix_API_Calls(self) :
        # should be accepted directly by API methods
        self.n = pm.api.MMatrix()

        # SetToProduct # TODO returns MMatrix() ?
        self.m = self.n.setToProduct(self.m,self.m)
        self.assert_("<maya.OpenMaya.MMatrix; proxy of <Swig Object of type 'MMatrix *' at" in repr(self.m)) #TODO -

        # Make MAtrix instance from range()
        self.m = pm.datatypes.Matrix(range(16))
        self.assertEquals(self.m.formated(), '[[0.0, 1.0, 2.0, 3.0],\n [4.0, 5.0, 6.0, 7.0],\n [8.0, 9.0, 10.0, 11.0],\n [12.0, 13.0, 14.0, 15.0]]')

        # Make Matrix instance from Array from range()
        self.M = pm.datatypes.Array(range(16), shape=(8, 2))
        self.m = pm.datatypes.Matrix(self.M)
        self.assertEquals(self.m.formated(), '[[0.0, 1.0, 2.0, 3.0],\n [4.0, 5.0, 6.0, 7.0],\n [8.0, 9.0, 10.0, 11.0],\n [12.0, 13.0, 14.0, 15.0]]')

        # Make Matrix instance from MatrixN from range()
        self.M = pm.datatypes.MatrixN(range(9), shape=(3, 3))
        self.m = pm.datatypes.Matrix(self.M)
        self.assertEquals(self.m.formated(),'[[0.0, 1.0, 2.0, 0.0],\n [3.0, 4.0, 5.0, 0.0],\n [6.0, 7.0, 8.0, 0.0],\n [0.0, 0.0, 0.0, 1.0]]')

        # inherits from Array and MatrixN
        self.assertTrue(isinstance(self.m, pm.datatypes.MatrixN))
        self.assertTrue(isinstance(self.m, pm.datatypes.Array))

        # as well as _api_Matrix
        self.assertTrue(isinstance(self.m, pm.api.MMatrix))

        # create transformationmatrix and translate, yo :: TODO
        self.n = pm.api.MMatrix()
        self.m = self.n.setToProduct(self.m, self.m)
        self.t = pm.api.MTransformationMatrix()
        self.t.setTranslation(pm.datatypes.Vector(1,2,3), pm.api.MSpace.kWorld)
        self.m = pm.datatypes.Matrix(self.t)
        self.assertEquals(self.m.formated(), '[[1.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 0.0],\n [0.0, 0.0, 1.0, 0.0],\n [1.0, 2.0, 3.0, 1.0]]')

        self.m = pm.datatypes.Matrix(self.m, a30=10)
        self.assertEquals(self.m.formated(), '[[1.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 0.0],\n [0.0, 0.0, 1.0, 0.0],\n [10.0, 2.0, 3.0, 1.0]]')


    def testMatrix_Trimmed(self):
        self.m = pm.datatypes.Matrix.identity
        self.M = self.m.trimmed(shape=(3, 3))
        self.assertEquals(self.M.formated(),'[[1.0, 0.0, 0.0],\n [0.0, 1.0, 0.0],\n [0.0, 0.0, 1.0]]') # TODO goto the docs, tool

    def testMatrix_issingular(self):
        self.M = pm.datatypes.Matrix.identity
        self.M = self.m.trimmed(shape=(3,3))
        self.assertEquals(self.M, pm.datatypes.MatrixN([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]))

        def Matrix_badTrim_Test():
            self.m.trim(shape=(3,3)) # TODO should fail
        self.failUnlessRaises(TypeError, Matrix_badTrim_Test) # new shape (3, 3) should not be compatible with class Matrix

    def testMatrix_columnAccess(self):
        self.m = pm.datatypes.Matrix.identity
        self.assertEquals(self.m.ncol, 4)

        def Matrix_badRow():
            self.m.nrow = 3
        self.failUnlessRaises(TypeError, Matrix_badRow)

    def testMatrix_rowAccess(self):
        self.assertEquals(self.m.nrow, 4)

# for i in range(0,4):print m.col[i]

    def testMatrix_list(self):
        self.assertEquals(list(self.m.row), [pm.datatypes.Array([1.0, 0.0, 0.0, 0.0]), pm.datatypes.Array([0.0, 1.0, 0.0, 0.0]), pm.datatypes.Array([0.0, 0.0, 1.0, 0.0]), pm.datatypes.Array([0.0, 0.0, 0.0, 1.0])] )

        self.assertEquals(list(self.m.col), [pm.datatypes.Array([1.0, 0.0, 0.0, 0.0]), pm.datatypes.Array([0.0, 1.0, 0.0, 0.0]), pm.datatypes.Array([0.0, 0.0, 1.0, 0.0]), pm.datatypes.Array([0.0, 0.0, 0.0, 1.0])] )

    def testMMatrix_fromTrimmedMatrixN(self):
        self.m  = pm.datatypes.Matrix(pm.datatypes.MatrixN(range(9), shape=(3,3)).trimmed(shape=(4,4), value=10))
        self.assertEquals(self.m.formated(), '[[0.0, 1.0, 2.0, 10.0],\n [3.0, 4.0, 5.0, 10.0],\n [6.0, 7.0, 8.0, 10.0],\n [10.0, 10.0, 10.0, 10.0]]')

    def testMMatrix_getAccess(self):
        self.m = pm.datatypes.Matrix(pm.datatypes.MatrixN(range(9), shape=(3,3)).trimmed(shape=(4,4), value=10))
        self.assertEquals(self.m.get(), ((0.0, 1.0, 2.0, 10.0), (3.0, 4.0, 5.0, 10.0), (6.0, 7.0, 8.0, 10.0), (10.0, 10.0, 10.0, 10.0)))

    def testMMatrix_indexAccess(self):
        self.m = pm.datatypes.Matrix(pm.datatypes.MatrixN(range(9), shape=(3,3)).trimmed(shape=(4,4), value=10))
        self.assertEquals(self.m[0], pm.datatypes.Array([0.0, 1.0, 2.0, 10.0]))

        self.m[0] = 10
        self.assertEquals(self.m.formated(), '[[10.0, 10.0, 10.0, 10.0],\n [3.0, 4.0, 5.0, 10.0],\n [6.0, 7.0, 8.0, 10.0],\n [10.0, 10.0, 10.0, 10.0]]')

        # list
        self.assertTrue(10 in self.m)
        self.assertEquals(list(self.m), [pm.datatypes.Array([10.0, 10.0, 10.0, 10.0]), pm.datatypes.Array([3.0, 4.0, 5.0, 10.0]), pm.datatypes.Array([6.0, 7.0, 8.0, 10.0]), pm.datatypes.Array([10.0, 10.0, 10.0, 10.0])])

        # list flat
        self.assertEquals(list(self.m.flat), [10.0, 10.0, 10.0, 10.0, 3.0, 4.0, 5.0, 10.0, 6.0, 7.0, 8.0, 10.0, 10.0, 10.0, 10.0, 10.0])

    def testMMatrix_AxisAccess(self):
        self.u = pm.datatypes.Vector.xAxis
        self.v = pm.datatypes.Vector.yAxis
        self.assertEquals(self.v, pm.datatypes.Vector.yAxis)
        self.assertEquals(self.u, pm.datatypes.Vector.xAxis)

    def testMMatrix_rounded(self):
        ## TODO round(m, 2) returns
            #Traceback (most recent call last):
            #  File "<stdin>", line 1, in <module>
            #  File "/Volumes/luma/_globalSoft/python/thirdParty/pymel/util/mathutils.py", line 43, in round
            #    return _round(value, ndigits)
            #TypeError: a float is required

        # trans matrix : t: 1, 2, 3, r: 45, 90, 30, s: 0.5, 1.0, 2.0
        #self.m = datatypes.Matrix([0.0, 4.1633363423443383e-17, -0.5, 0.0, 0.25881904510252079, 0.96592582628906831, 1.3877787807814459e-16, 0.0, 1.9318516525781366, -0.51763809020504159, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0])
        #(round(self.m, 2).formated(),'[[0.0, 0.0, -0.5, 0.0],\n [0.26, 0.97, 0.0, 0.0],\n [1.93, -0.52, 0.0, 0.0],\n [1.0, 2.0, 3.0, 1.0]]' )
        pass

    def testMMatrix_operations(self):
        self.m = pm.datatypes.Matrix([[0.0, 4.16333634234e-17, -0.5, 0.0], [0.258819045103, 0.965925826289, 1.38777878078e-16, 0.0], [1.93185165258, -0.517638090205, 0.0, 0.0], [1.0, 2.0, 3.0, 1.0]])
        self.x = pm.datatypes.Vector.xAxis
        self.y = pm.datatypes.Vector.yAxis
        self.z = pm.datatypes.Vector.zAxis
        self.u = pm.datatypes.Vector(1, 2, 3)

        # start check
        self.assertEquals(self.u, pm.datatypes.Vector([1, 2, 3]))

        # multiply Matrix by Vector
        first = self.u * self.m
        last = pm.datatypes.Vector([6.31319304795, 0.378937381963, -0.5])
        self.assert_(first.isEquivalent(last))

        first = self.m * self.u
        last = pm.datatypes.Vector([-1.5, 2.19067069768, 0.896575472168])
        self.assert_(first.isEquivalent(last))

        #  multiply Matrix by Point
        self.p = pm.datatypes.Point(1,10,100,1)

        first = self.p * self.m
        last = pm.datatypes.Point([196.773355709, -40.1045507576, 2.5, 1.0])
        self.assert_(first.isEquivalent(last))

        first = self.m * self.p
        last = pm.datatypes.Point([-50.0, 9.91807730799, -3.24452924947, 321.0])
        self.assert_(first.isEquivalent(last))

        # multiplication by datatypes.VectorN:3
        first = pm.datatypes.VectorN([1, 2, 3])* self.m
        last = pm.datatypes.VectorN([6.31319304795, 0.378937381963, -0.5])
        #self.assert_(self.v.isEquivalent(last)) # AssertionError
        #self.assertEquals(first, last) # AssertionError: VectorN([6.31319304795, 0.378937381963, -0.5]) != VectorN([6.31319304795, 0.378937381963, -0.5])

        fd = first.data
        ld = last.data
        for i in range(0,2): # used assertAlmostEquals since we were getting some rounding errors for the list items after the eighth decimal
            self.assertAlmostEquals(fd[i], ld[i])

        # multiplication by datatypes.VectorN:5 Should fail, because
        # datatypes.Vector:5 and matrix:shape(4,4) are not able to conform for a 'VectorN * MatrixN' multiplication
        def VectorN_test():
            self.v = pm.datatypes.VectorN([1, 2, 3, 4, 5])* self.m
        self.failUnlessRaises(ValueError, VectorN_test)

        # element wise multiplication
        self.m = pm.datatypes.Matrix(range(1, 17))
        self.assertEquals(self.m.formated(), '[[1.0, 2.0, 3.0, 4.0],\n [5.0, 6.0, 7.0, 8.0],\n [9.0, 10.0, 11.0, 12.0],\n [13.0, 14.0, 15.0, 16.0]]')
        self.assertEquals(([1, 10, 100] * self.m), pm.datatypes.Matrix([[1.0, 20.0, 300.0, 0.0], [5.0, 60.0, 700.0, 0.0], [9.0, 100.0, 1100.0, 0.0], [13.0, 140.0, 1500.0, 0.0]]) )

        self.M = pm.datatypes.MatrixN(range(1, 21), shape=(4, 5))
        self.assertEquals(self.M.formated(), '[[1, 2, 3, 4, 5],\n [6, 7, 8, 9, 10],\n [11, 12, 13, 14, 15],\n [16, 17, 18, 19, 20]]')

        self.n = self.m * self.M
        self.assertEquals(self.n.formated(),'[[110.0, 120.0, 130.0, 140.0, 150.0],\n [246.0, 272.0, 298.0, 324.0, 350.0],\n [382.0, 424.0, 466.0, 508.0, 550.0],\n [518.0, 576.0, 634.0, 692.0, 750.0]]')

        # check class name
        self.assertEquals(pm.util.clsname(self.n), 'MatrixN')

        # multiply by integer - should return a Matrix
        self.n = (self.m * 2)
        self.assertEquals(self.n.formated(), '[[2.0, 4.0, 6.0, 8.0],\n [10.0, 12.0, 14.0, 16.0],\n [18.0, 20.0, 22.0, 24.0],\n [26.0, 28.0, 30.0, 32.0]]')
        # and then double-check class
        self.assertEquals(pm.util.clsname(self.n), 'Matrix')

        # multiply integer by matrix - should return a Matrix
        self.n = (2 * self.m)
        self.assertEquals(self.n.formated(), '[[2.0, 4.0, 6.0, 8.0],\n [10.0, 12.0, 14.0, 16.0],\n [18.0, 20.0, 22.0, 24.0],\n [26.0, 28.0, 30.0, 32.0]]')
        self.assertEquals(pm.util.clsname(self.n), 'Matrix')

        # add matrix to integer - should return a Matrix
        self.n = self.m + 2
        self.assertEquals(self.n.formated(),'[[3.0, 4.0, 5.0, 6.0],\n [7.0, 8.0, 9.0, 10.0],\n [11.0, 12.0, 13.0, 14.0],\n [15.0, 16.0, 17.0, 18.0]]')
        self.assertEquals(pm.util.clsname(self.n), 'Matrix')

         # add integer to matrix
        self.n = 2 + self.m
        self.assertEquals(self.n.formated(),'[[3.0, 4.0, 5.0, 6.0],\n [7.0, 8.0, 9.0, 10.0],\n [11.0, 12.0, 13.0, 14.0],\n [15.0, 16.0, 17.0, 18.0]]')
        self.assertEquals(pm.util.clsname(self.n), 'Matrix')

        def setToProduct_test():
            self.m.setToProduct(self.m, self.M)
        # cannot initialize a Matrix of shape (4, 4) from shape (4, 5) - truncation errors
        self.failUnlessRaises(TypeError, setToProduct_test)

        # isEquivalent() should evaluate as false
        self.assertFalse(self.m.isEquivalent(self.m * self.M))

        # trans matrix : t: 1, 2, 3, r: 45, 90, 30, s: 0.5, 1.0, 2.0
        self.m = pm.datatypes.Matrix([0.0, 4.1633363423443383e-17, -0.5, 0.0, 0.25881904510252079, 0.96592582628906831, 1.3877787807814459e-16, 0.0, 1.9318516525781366, -0.51763809020504159, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0])

        # round() matrix values # TODO round from chad
        #self.assertEquals(round(self.m, 2).formated(), '[[0.0, 0.0, -0.5, 0.0],\n [0.26, 0.97, 0.0, 0.0],\n [1.93, -0.52, 0.0, 0.0],\n [1.0, 2.0, 3.0, 1.0]]')

        # round() the transposed() the matrix # TODO round from chad
        #self.assertEquals(round(self.m.transpose(),2).formated(), '[[0.0, 0.26, 1.93, 1.0],\n [0.0, 0.97, -0.52, 2.0],\n [-0.5, 0.0, 0.0, 3.0],\n [0.0, 0.0, 0.0, 1.0]]')

        # issingular() - make sure (not) no inverse - yay, assertFalse!
        self.assertFalse(self.m.isSingular())

        # so lets check that inverse matrix# TODO round from chad
        #self.assertEquals(round(self.m.inverse(),2).formated(), '[[0.0, 0.26, 0.48, 0.0],\n [0.0, 0.97, -0.13, 0.0],\n [-2.0, 0.0, 0.0, 0.0],\n [6.0, -2.19, -0.22, 1.0]]')

        # adjoint() - should be the same as the inverse, as they are *almost the same thing # TODO round from chad
        #self.assertEquals(round(self.m.adjoint(),2).formated(), '[[0.0, 0.26, 0.48, 0.0],\n [0.0, 0.97, -0.13, 0.0],\n [-2.0, 0.0, -0.0, 0.0],\n [6.0, -2.19, -0.22, 1.0]]')

        # adjugate() - should be identical to the adoint matrix# TODO round from chad
        #self.assertEquals(round(self.m.adjugate(),2).formated(), '[[0.0, 0.26, 0.48, 0.0],\n [0.0, 0.97, -0.13, 0.0],\n [-2.0, 0.0, -0.0, 0.0],\n [6.0, -2.19, -0.22, 1.0]]')

        # homogenize()# TODO round from chad
        #self.assertEquals(round(self.m.homogenize(),2).formated(), '[[0.0, 0.0, -1.0, 0.0],\n [0.26, 0.97, 0.0, 0.0],\n [0.97, -0.26, -0.0, 0.0],\n [1.0, 2.0, 3.0, 1.0]]')

        # determinant()
        self.assertEquals(self.m.det(), 1.0)

        # determinant for this matrix:4x4
        self.assertEquals(self.m.det4x4(), 1.0)

        # determinant of the upper left 3x3 submatrix of this matrix instance
        self.assertEquals(self.m.det3x3(), 1.0)

        # TODO round from chad
        #self.assertEquals(round(m.weighted(0.5),2).formated(), '[[0.53, 0.0, -0.53, 0.0],\n [0.09, 0.99, 0.09, 0.0],\n [1.05, -0.2, 1.05, 0.0],\n [0.5, 1.0, 1.5, 1.0]]')

        # blend() # TODO round from chad
        #self.assertEquals(round(m.blend(Matrix.identity, 0.5),2).formated(), '[[0.53, 0.0, -0.53, 0.0],\n [0.09, 0.99, 0.09, 0.0],\n [1.05, -0.2, 1.05, 0.0],\n [0.5, 1.0, 1.5, 1.0]]')


##################################################################
## MTransformationMatrix tests


    def testMTransformationMatrix_QuatInstance(self) :
        q = pm.datatypes.Quaternion()
        self.assertEquals(q, pm.datatypes.Quaternion([0.0, 0.0, 0.0, 1.0]))

        q = pm.datatypes.Quaternion(1, 2, 3, 0.5)
        last = pm.datatypes.Quaternion([1.0, 2.0, 3.0, 0.5])
        self.assert_(q.isEquivalent(last))

        q = pm.datatypes.Quaternion(0.785, 0.785, 0.785, "XYZ", unit='radians')
        last = pm.datatypes.Quaternion([0.191357439088, 0.461717715523, 0.191357439088, 0.844737481223])
        self.assert_(q.isEquivalent(last))

    def testMTransformationMatrix_rotate(self):
        self.m = pm.datatypes.Matrix()
        self.q = pm.datatypes.Quaternion(1, 2, 3, 0.5)
        self.m.rotate = self.q
        last = pm.datatypes.Matrix([[-0.824561403509, 0.491228070175, 0.280701754386, 0.0], [0.0701754385965, -0.40350877193, 0.912280701754, 0.0], [0.561403508772, 0.771929824561, 0.298245614035, 0.0], [0.0, 0.0, 0.0, 1.0]])
        self.assert_(self.m.isEquivalent(last))

        self.t = pm.datatypes.Matrix()
        self.q = pm.datatypes.Quaternion(1, 2, 3, 0.5)
        self.t.rotate = self.q
        last = pm.datatypes.Matrix([[-0.824561403509, 0.491228070175, 0.280701754386, 0.0], [0.0701754385965, -0.40350877193, 0.912280701754, 0.0], [0.561403508772, 0.771929824561, 0.298245614035, 0.0], [0.0, 0.0, 0.0, 1.0]])
        self.assert_(self.t.isEquivalent(last))

    def testMTransformationMatrix_rotation(self):
        tm = pm.datatypes.TransformationMatrix()
        self.assertEqual(tm.getRotation(), pm.datatypes.EulerRotation(0,0,0) )
        tm.setRotation(90,0,0, 'XYZ')
        last = pm.datatypes.Matrix([[1,0,0,0], [0,0,1,0], [0,-1,0,0], [0,0,0,1]])
        self.assertTrue(tm.isEquivalent(last))
        self.assertEqual(tm.getRotation(), pm.datatypes.EulerRotation(90,0,0, 'XYZ'))
        tm.setRotation(10,20,30, 'XYZ')
        last = pm.dt.Matrix([[0.81379768134937369, 0.46984631039295421, -0.34202014332566871, 0.0,],
                   [-0.44096961052988248, 0.8825641192593856, 0.16317591116653482, 0.0,],
                   [0.37852230636979256, 0.018028311236297268, 0.92541657839832336, 0.0,],
                   [0.0, 0.0, 0.0, 1.0]])
        self.assertTrue(tm.isEquivalent(last))
        tm.setRotation(10,20,30, 'YZX')
        last = pm.dt.Matrix([0.81379768134937369,
                         0.52209946381304628,
                         -0.25523613325019773,
                         0.0,
                         -0.49999999999999994,
                         0.85286853195244317,
                         0.15038373318043533,
                         0.0,
                         0.29619813272602386,
                         0.0052361332501977423,
                         0.95511216570526569,
                         0.0,
                         0.0,
                         0.0,
                         0.0,
                         1.0])
        self.assertTrue(tm.isEquivalent(last))
        tm.setRotation(10,20,30, 'ZYX')
        last = pm.dt.Matrix([0.81379768134937369,
                         0.54383814248232565,
                         -0.2048741287028622,
                         0.0,
                         -0.46984631039295427,
                         0.82317294464550095,
                         0.31879577759716787,
                         0.0,
                         0.34202014332566871,
                         -0.16317591116653482,
                         0.92541657839832336,
                         0.0,
                         0.0,
                         0.0,
                         0.0,
                         1.0])
        self.assertTrue(tm.isEquivalent(last))

    def testMTransformationMatrix_rotateTo(self):
        self.t = pm.datatypes.TransformationMatrix()
        self.t.rotateTo([1, 2, 3, 0.5])
        last = pm.datatypes.Matrix([[-0.824561403509, 0.491228070175, 0.280701754386, 0.0], [0.0701754385965, -0.40350877193, 0.912280701754, 0.0], [0.561403508772, 0.771929824561, 0.298245614035, 0.0], [0.0, 0.0, 0.0, 1.0]])
        self.assert_(self.t.isEquivalent(last))

    def testMTransformationMatrix_formatted(self):
        self.m = pm.datatypes.TransformationMatrix()
        self.assertEquals(self.m.formated(), '[[1.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 0.0],\n [0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0]]')

    def testMTransformationMatrix_indiceAccess(self):
        self.m = pm.datatypes.TransformationMatrix()
        self.assertEquals(self.m[0, 0], 1.0)
        self.assertEquals(self.m[0:2, 0:3], pm.datatypes.MatrixN([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]))

    def testMTransformationMatrix_instanceEquality(self):
        self.m = pm.datatypes.TransformationMatrix()
        self.assertEquals(pm.datatypes.TransformationMatrix.shape, self.m.shape)
        self.assertEquals(pm.datatypes.TransformationMatrix.ndim, self.m.ndim)
        self.assertEquals(pm.datatypes.TransformationMatrix.size, self.m.size)

    def testMTransformationMatrix_inheritance(self):
        self.m = pm.datatypes.TransformationMatrix.identity
        self.assertTrue(isinstance(self.m, pm.datatypes.MatrixN))
        self.assertTrue(isinstance(self.m, pm.datatypes.Array)) # inherits from MatrixN --> Array

    def testMTransformationMatrix_API_instances(self):
        # as well as api.TransformationMatrix and api.Matrix
        self.m = pm.datatypes.TransformationMatrix.identity
        self.assertTrue(isinstance(self.m, pm.api.MTransformationMatrix))
        self.assertTrue(isinstance(self.m, pm.api.MMatrix))

    def testMTransformationMatrix_isEquivalent(self):
        self.n = pm.datatypes.TransformationMatrix.identity
        self.m = pm.datatypes.TransformationMatrix.identity

        self.assertTrue(self.m.isEquivalent(self.n))

        # Should Fail TODO :: does not currently fail
        def setShape_test1():
            self.m.shape = (4,4)
        def setShape_test2():
            self.m.shape = 2
        # these currently don't error out the way they should. TODO
        self.failUnlessRaises(TypeError, setShape_test1())
        self.failUnlessRaises(TypeError, setShape_test2())

        # setToProduct # TODO :: File "<stdin>", line 1, in <module> TypeError: in method 'MMatrix_setToProduct', argument 2 of type 'MMatrix const &'
        self.n = pm.api.MMatrix()
        #self.n = self.n.setToProduct(self.m, self.m)
        #self.assert_("<maya.OpenMaya.MMatrix; proxy of <Swig Object of type 'MMatrix *" in repr(self.n))

        # assign
        self.n = pm.api.MTransformationMatrix()
        self.n = self.n.assign(self.m)
        self.assert_("<maya.OpenMaya.MTransformationMatrix; proxy of <Swig Object of type 'MTransformationMatrix *" in repr(self.n))

        # rotation
        self.m = pm.datatypes.TransformationMatrix.identity
        self.m.rotation = pm.datatypes.Quaternion()
        self.assertEquals(self.m.formated(), '[[1.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 0.0],\n [0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0]]')

        # translations
        self.n = pm.datatypes.TransformationMatrix.identity
        self.n.translation = pm.datatypes.Vector(1, 2, 3)
        self.assertEquals(self.n.formated(), '[[1.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 0.0],\n [0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0]]')

        # identity multiplied by identity
        self.o = self.m * self.n
        self.assertEquals(self.o.formated(),'[[1.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 0.0],\n [0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0]]')

    def test_constants(self):
        # TODO : come up with a programatic way of finding constants
        s = """
        Vector.xAxis
        Vector.one
        Vector.zero
        Vector.yNegAxis
        Vector.zNegAxis
        Vector.xNegAxis
        Vector.zAxis
        Vector.yAxis
        FloatVector.xAxis
        FloatVector.one
        FloatVector.zero
        FloatVector.yNegAxis
        FloatVector.zNegAxis
        FloatVector.xNegAxis
        FloatVector.zAxis
        FloatVector.yAxis
        Point.origin
        Point.xAxis
        Point.yNegAxis
        Point.zero
        Point.zNegAxis
        Point.yAxis
        Point.zAxis
        Point.one
        Point.xNegAxis
        FloatPoint.origin
        FloatPoint.yNegAxis
        FloatPoint.yAxis
        FloatPoint.zNegAxis
        FloatPoint.xNegAxis
        FloatPoint.zAxis
        FloatPoint.xAxis
        FloatPoint.one
        FloatPoint.zero
        Color.xAxis
        Color.yNegAxis
        Color.zero
        Color.zNegAxis
        Color.yAxis
        Color.zAxis
        Color.one
        Color.xNegAxis
        FloatMatrix.identity
        TransformationMatrix.identity
        EulerRotation.identity
        Quaternion.identity
        """

        for x in s.split('\n'):
            x = x.strip()
            if x:
                c, at = x.split('.')
                val  = getattr( getattr( pm.datatypes, c ), at )

if __name__ == '__main__':
    unittest.main()
########NEW FILE########
__FILENAME__ = test_general
import sys, os, inspect, unittest
#from testingutils import setupUnittestModule
from pymel.core import *
import pymel.core as pm
import pymel.versions as versions
import pymel.internal.factories as factories
import pymel.internal.pmcmds as pmcmds
import pymel.core.datatypes as dt
import pymel.core.nodetypes as nt
import tempfile
#import pymel
#import maya.cmds as cmds

# Name mangling happens if we try to use __name inside a UnitTest class...
from maya.app.commands import __makeStubFunc as _makeStubFunc
#
#
#
#
#
#def testNodeCmds(verbose=False):
#
#    #emptyFunctions = []
#
#    for funcName in _internal.nodeCommandList:
#        _internal.testNodeCmd( funcName, _internal.cmdlist[funcName], verbose )
#
#    print "done"
#    #print emptyFunctions


# Todo - add missing attribute types (ie, message, boolean, datatype forms of
# double2, float3, etc

def _makeAllAttrTypes(nodeName):
    cmds.sphere(n=nodeName)

    attributeTypesToNames = {}
    dataTypesToNames = {}
    namesToType = {}

    def doAttrAdd(**kwargs):
        name = kwargs.get('ln', kwargs.get('longName'))
        dt = kwargs.get('dt', kwargs.get('dataType'))

        if dt is not None:
            dataTypesToNames.setdefault(dt, []).append(name)
            namesToType[name] = ('dt', dt)
        else:
            at = kwargs.get('at', kwargs.get('attributeType'))
            if at is None:
                at = 'double'
            attributeTypesToNames.setdefault(dt, []).append(name)
            namesToType[name] = ('at', at)
        cmds.addAttr(**kwargs)

    # compound numeric types
    doAttrAdd(ln='short2Attr',at='short2')
    doAttrAdd(ln='short2a',p='short2Attr',at='short')
    doAttrAdd(ln='short2b',p='short2Attr',at='short')

    doAttrAdd(ln='short3Attr',at='short3')
    doAttrAdd(ln='short3a',p='short3Attr',at='short')
    doAttrAdd(ln='short3b',p='short3Attr',at='short')
    doAttrAdd(ln='short3c',p='short3Attr',at='short')

    doAttrAdd(ln='long2Attr',at='long2')
    doAttrAdd(ln='long2a',p='long2Attr',at='long')
    doAttrAdd(ln='long2b',p='long2Attr',at='long')

    doAttrAdd(ln='long3Attr',at='long3')
    doAttrAdd(ln='long3a',p='long3Attr',at='long')
    doAttrAdd(ln='long3b',p='long3Attr',at='long')
    doAttrAdd(ln='long3c',p='long3Attr',at='long')

    doAttrAdd(ln='float2Attr',at='float2')
    doAttrAdd(ln='float2a',p='float2Attr',at="float")
    doAttrAdd(ln='float2b',p='float2Attr',at="float")

    doAttrAdd(ln='float3Attr',at='float3')
    doAttrAdd(ln='float3a',p='float3Attr',at="float")
    doAttrAdd(ln='float3b',p='float3Attr',at="float")
    doAttrAdd(ln='float3c',p='float3Attr',at="float")

    doAttrAdd(ln='double2Attr',at='double2')
    doAttrAdd(ln='double2a',p='double2Attr',at='double')
    doAttrAdd(ln='double2b',p='double2Attr',at='double')

    doAttrAdd(ln='double3Attr',at='double3')
    doAttrAdd(ln='double3a',p='double3Attr',at='double')
    doAttrAdd(ln='double3b',p='double3Attr',at='double')
    doAttrAdd(ln='double3c',p='double3Attr',at='double')

    # Array Attributes

    doAttrAdd(ln='Int32ArrayAttr',dt='Int32Array')
    doAttrAdd(ln='doubleArrayAttr',dt='doubleArray')
    doAttrAdd(ln='pointArrayAttr',dt='pointArray')
    doAttrAdd(ln='vectorArrayAttr',dt='vectorArray')

    doAttrAdd(ln='stringArrayAttr',dt='stringArray')
    doAttrAdd(ln='stringAttr',dt="string")

    # Matrix

    doAttrAdd(ln='matrixAttr',dt="matrix")

    # non numeric
    doAttrAdd(ln='sphereAttr',dt='sphere')
    doAttrAdd(ln='coneAttr',dt='cone')
    doAttrAdd(ln='meshAttr',dt='mesh')
    doAttrAdd(ln='latticeAttr',dt='lattice')
    doAttrAdd(ln='spectrumRGBAttr',dt='spectrumRGB')
    doAttrAdd(ln='reflectanceRGBAttr',dt='reflectanceRGB')
    doAttrAdd(ln='componentListAttr',dt='componentList')
    doAttrAdd(ln='attrAliasAttr',dt='attributeAlias')
    doAttrAdd(ln='curveAttr',dt='nurbsCurve')
    doAttrAdd(ln='surfaceAttr',dt='nurbsSurface')
    doAttrAdd(ln='trimFaceAttr',dt='nurbsTrimface')
    doAttrAdd(ln='polyFaceAttr',dt='polyFaces')

    return attributeTypesToNames, dataTypesToNames, namesToType

class testCase_mayaSetAttr(unittest.TestCase):
    """
    sanity check: make sure we know how to set and get attributes via maya's
    setAttr.  this serves mostly to document all the inconsistencies in setAttr
    so that we can sort them out in our own wrap.  it will also alert us to
    any changes that Autodesk makes.
    """

    def setUp(self):
        _makeAllAttrTypes('node')

    def test_short2(self):
        # compound
        cmds.setAttr( 'node.short2Attr', 1, 2 )
        assert cmds.getAttr( 'node.short2Attr' )        == [(1, 2)]

    def test_short3(self):
        cmds.setAttr( 'node.short3Attr', 1, 2, 3 )
        assert cmds.getAttr( 'node.short3Attr' )        == [(1, 2,3)]

    def test_long2(self):
        cmds.setAttr( 'node.long2Attr', 1, 2 )
        assert cmds.getAttr( 'node.long2Attr' )         == [(1, 2)]

    def test_long3(self):
        cmds.setAttr( 'node.long3Attr', 1, 2, 3 )
        assert cmds.getAttr( 'node.long3Attr' )         == [(1, 2,3)]

    def test_float2(self):
        cmds.setAttr( 'node.float2Attr', 1, 2 )
        assert cmds.getAttr( 'node.float2Attr' )        == [(1.0, 2.0)]

    def test_float(self):
        cmds.setAttr( 'node.float3Attr', 1, 2, 3 )
        assert cmds.getAttr( 'node.float3Attr' )        == [(1.0, 2.0, 3.0)]

    def test_double2(self):
        cmds.setAttr( 'node.double2Attr', 1, 2 )
        assert cmds.getAttr( 'node.double2Attr' )       == [(1.0, 2.0)]

    def test_double3(self):
        cmds.setAttr( 'node.double3Attr', 1, 2, 3 )
        assert cmds.getAttr( 'node.double3Attr' )       == [(1.0, 2.0, 3.0)]

    def test_int32Array(self):
        # array
        cmds.setAttr( 'node.Int32ArrayAttr', (1, 2, 3, 4), type='Int32Array' )
        assert cmds.getAttr( 'node.Int32ArrayAttr' ) == [1, 2, 3, 4]

    def test_doubleArray(self):
        cmds.setAttr( 'node.doubleArrayAttr', (1, 2, 3, 4), type='doubleArray' )
        assert cmds.getAttr( 'node.doubleArrayAttr' )   == [1.0, 2.0, 3.0, 4.0]

    def test_pointArray(self):
        if versions.current() < versions.v2011:
            # complex array
            cmds.setAttr( 'node.pointArrayAttr', 2, (1,2,3,4), "", (1,2,3,4), type='pointArray' )
            assert cmds.getAttr( 'node.pointArrayAttr' )    == [(1.0, 2.0, 3.0, 4.0), (1.0, 2.0, 3.0, 4.0)]
        else:
            cmds.setAttr( 'node.pointArrayAttr', 2, (1,2,3,4), (1,2,3,4), type='pointArray' )
            assert cmds.getAttr( 'node.pointArrayAttr' )    == [(1.0, 2.0, 3.0, 4.0), (1.0, 2.0, 3.0, 4.0)]

    def test_vectorArray(self):
        if versions.current() < versions.v2011:
            cmds.setAttr( 'node.vectorArrayAttr', 2, (1,2,3), "", (1,2,3), type='vectorArray' )
            assert cmds.getAttr( 'node.vectorArrayAttr' )   == [1.0, 2.0, 3.0, 1.0, 2.0, 3.0]
        else:
            cmds.setAttr( 'node.vectorArrayAttr', 2, (1,2,3), (1,2,3), type='vectorArray' )
            assert cmds.getAttr( 'node.vectorArrayAttr' )   == [(1.0, 2.0, 3.0), (1.0, 2.0, 3.0)]

    def test_stringArray(self):
        # string array
        cmds.setAttr( 'node.stringArrayAttr', 3, 'one', 'two', 'three', type='stringArray' )
        assert cmds.getAttr( 'node.stringArrayAttr' )   == [u'one', u'two', u'three']

    def test_string(self):
        cmds.setAttr( 'node.stringAttr', 'one', type='string' )
        assert cmds.getAttr( 'node.stringAttr' )        == u'one'

    if versions.current() >= versions.v2011:
        def test_matrix(self):
            # matrix
            # Fails in versions < 2011
            cmds.setAttr( 'node.matrixAttr', 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, type='matrix' )
            assert cmds.getAttr( 'node.matrixAttr' )   == [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]

    def test_sphere(self):
        # non-numeric: can't get
        cmds.setAttr( 'node.sphereAttr', 1.0, type='sphere' )
        #assert cmds.getAttr( 'node.sphereAttr' )        == 1.0

    def test_cone(self):
        cmds.setAttr( 'node.coneAttr', 45, 45, type='cone' )
        #assert cmds.getAttr( 'node.coneAttr' )        == 1.0

    def test_reflectanceRGB(self):
        cmds.setAttr( 'node.reflectanceRGBAttr', 1,1,1, type='reflectanceRGB' )
        #assert cmds.getAttr( 'node.reflectanceRGBAttr' )        == 1.0
        # TODO : finish non-numeric

def test_pymel_setAttr():

    _makeAllAttrTypes('node2')
    for data in [
        ('short2',  (1,2)),
        ('short3',  (1,2,3)),
        ('long2',   (1,2)),
        ('long3',   (1,2,3)),
        ('float2',  (1.0,2.0)),
        ('float3',  (1.0,2.0,3.0)),
        ('double2', (1.0,2.0)),
        ('double3', datatypes.Vector(1.0,2.0,3.0), [1,2,3] ),

        ('Int32Array', [1,2,3,4]),
        ('doubleArray', [1,2,3,4]),

        ('vectorArray', [datatypes.Vector([1,2,3]), datatypes.Vector([1,0,0])],
                        [[1,2,3], [1,0,0]] ),
        ('pointArray', [datatypes.Point([1,2,3]), datatypes.Point([2,4,6])],
                        [[1,2,3,1], [2,4,6,1]] ),

        ('stringArray', ['one', 'two', 'three']),
        ('string', 'one'),
        ('matrix', datatypes.Matrix(),
                        [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0] )]:
        typ = data[0]
        mainVal = data[1]

        for i, val in enumerate(data[1:]):
            def testSetAttr(*args):
                at = 'node2.' + typ + 'Attr'
                setAttr(at, val)
                newval = getAttr(at)
                assert newval == mainVal, "setAttr %s: returned value %r is not equal to input value %r" % (typ, newval, mainVal)

            testSetAttr.__name__ = 'test_setAttr_' + typ + '_' + str(i)
            testSetAttr.description = testSetAttr.__name__
            #print typ
            #testSetAttr()
            yield testSetAttr,

class testCase_mayaLockAttr(unittest.TestCase):

    def setUp(self):
        self.temp = os.path.join(tempfile.gettempdir(), 'referencesTest')
        if not os.path.isdir(self.temp):
            os.makedirs(self.temp)
        print "created temp dir: %s" % self.temp

        # Refs:
        #  sphere.ma
        #    (no refs)

        #  master.ma
        #    :sphere1 => sphere.ma
        #    :sphere2 => sphere.ma


        # create sphere file
        print "sphere file"
#        cmds.file(new=1, f=1)
        pm.newFile(f=1)
        sphere = pm.polySphere()[0]

        pm.addAttr(sphere, ln='zombieAttr1')
        pm.addAttr(sphere, ln='zombieAttr2')
        cmds.setAttr('%s.v' % sphere, lock=1)
        cmds.setAttr('%s.zombieAttr1' % sphere, lock=1)

        self.sphereFile = pm.saveAs( os.path.join( self.temp, 'sphere.ma' ), f=1 )

        print "master file"
        pm.newFile(f=1)
        self.sphereRef1 = pm.createReference( self.sphereFile, namespace='sphere1' )
        self.sphereRef2 = pm.createReference( self.sphereFile, namespace='sphere2' )
        self.sphere1 = pm.PyNode('sphere1:pSphere1')
        self.sphere2 = pm.PyNode('sphere2:pSphere1')
        self.sphere1.attr('translateY').set(2)
        self.sphere2.attr('translateY').set(4)

        self.cube = pm.polyCube()[0]
        pm.addAttr(self.cube, ln='zombieAttr1')
        pm.addAttr(self.cube, ln='zombieAttr2')
        cmds.setAttr('%s.v' % self.cube, lock=1)
        cmds.setAttr('%s.zombieAttr1' % self.cube, lock=1)

        self.masterFile = pm.saveAs(os.path.join(self.temp, 'master.ma'), f=1)

    def test_isLocked(self):
        nodes = [self.cube, self.sphere1, self.sphere2]
        attrs = ['v', 'zombieAttr1', 'zombieAttr2', 'rotateX']
        for node in nodes:
            for attr in attrs:
                pmAttr = getattr(node, attr)
                strAttr = '%s.%s' % (node, attr)
                self.assertEqual(pmAttr.isLocked(), cmds.getAttr(strAttr, lock=1))

    def test_lock(self):
        node = self.cube
        lockedAttrs = ['v', 'zombieAttr1']
        unlockedAttrs = ['zombieAttr2', 'rotateX']

        for attr in lockedAttrs:
            pmAttr = getattr(node, attr)
            strAttr = '%s.%s' % (node, attr)
            pmAttr.lock()
            self.assertTrue(cmds.getAttr(strAttr, lock=1))
            pmAttr.unlock()
            self.assertFalse(cmds.getAttr(strAttr, lock=1))
            pmAttr.lock()

        for attr in unlockedAttrs:
            pmAttr = getattr(node, attr)
            strAttr = '%s.%s' % (node, attr)
            pmAttr.unlock()
            self.assertFalse(cmds.getAttr(strAttr, lock=1))
            pmAttr.lock()
            self.assertTrue(cmds.getAttr(strAttr, lock=1))
            pmAttr.unlock()

    def test_lockRefs(self):
        nodes = [self.sphere1, self.sphere2]
        attrs = ['v', 'zombieAttr1', 'zombieAttr2', 'rotateX']
        for node in nodes:
            for attr in attrs:
                pmAttr = getattr(node, attr)
                lock = pmAttr.isLocked()

                # Check references
                self.assertRaises(AttributeError, pmAttr.lock, checkReference=True)
                self.assertEqual(pmAttr.isLocked(), lock)

                # Don't check references
                pmAttr.setLocked(not lock, checkReference=False)
                self.assertEqual(pmAttr.isLocked(), not lock)
                pmAttr.setLocked(lock, checkReference=False)

                # Don't check references (default)
                pmAttr.setLocked(not lock)
                self.assertEqual(pmAttr.isLocked(), not lock)
                pmAttr.setLocked(lock)

class testCase_enumAttr(unittest.TestCase):
    def setUp(self):
        self.node = cmds.createNode('transform')
        self.attrName = 'testEnum'
        self.attr = '%s.%s' % (self.node, self.attrName)
        cmds.addAttr(self.node, at='enum', longName=self.attrName,
                     enumName='First:Second:Third', keyable=True)

    def test_setString(self):
        print "self.attr:", self.attr
        setAttr(self.attr, 'Second')
        self.assertEqual(1, getAttr(self.attr))
        setAttr(self.attr, 'Third', asString=1)
        self.assertEqual(2, getAttr(self.attr))
        self.assertRaises(MayaAttributeEnumError, setAttr, self.attr, 'foo')

class testCase_nodesAndAttributes(unittest.TestCase):

    def setUp(self):
        self.sphere1, hist = polySphere()
        self.cube1, hist = polyCube()
        self.grp1 = group(self.sphere1, self.cube1)

        #duplicate
        self.grp2 = duplicate(self.grp1)[0]
        self.sphere2, self.cube2 = self.grp2.getChildren()

        #instance
        self.grp3 = instance(self.grp1)[0]
        self.sphere3, self.cube3 = self.grp3.getChildren()

        self.light = spotLight()

        currentTime( 1 )
        setKeyframe( self.light.intensity )
        currentTime( 10 )
        self.light.intensity.set(10)
        setKeyframe( self.light.intensity )
        currentTime( 1 )

        self.anim = self.light.intensity.inputs()[0]

        self.newobjs = []

        cmds.aliasAttr( 'myalias', self.sphere1.name() + '.scaleX' )

    def test_attribute_parent_equality(self):
        self.assertEqual( self.sphere2.t.tx.parent(), self.sphere2.t )

    def test_attribute_duplicate_inequality(self):
        self.assert_( self.sphere1.t != self.sphere2.t )

    def test_attribute_instance_equality(self):
        self.assertEqual( self.sphere1.t, self.sphere3.t )

    def test_attribute_cascading(self):
        self.sphere1.primaryVisibility.set(1)
        shape = self.sphere1.getShape()
        self.assertEqual( self.sphere1.primaryVisibility, shape.primaryVisibility )

    def test_attribute_aliases(self):
        fromPyNode = pm.PyNode(self.sphere1.name() + '.myalias')
        self.assertTrue( isinstance(fromPyNode, pm.Attribute ) )
        fromAttr = self.sphere1.attr('myalias')
        self.assertTrue( isinstance(fromAttr, pm.Attribute) )

        res1 = self.sphere1.listAttr(alias=1)
        res2 = self.sphere1.listAliases()
        self.assertEqual( res1[0], res2[0][1] )
        self.assertEqual(fromPyNode, res1[0])
        self.assertEqual(fromAttr, fromPyNode)

    def test_multi_compound_attribute_aliases(self):
        remap = pm.createNode('remapValue')
        attr = remap.attr('value')[0].value_Position
        attr.setAlias('alfred')

        fromPyNode = pm.PyNode(remap.name() + '.alfred')
        self.assertTrue( isinstance(fromPyNode, pm.Attribute ) )
        fromAttr = remap.attr('alfred')
        self.assertTrue( isinstance(fromAttr, pm.Attribute) )

        res1 = remap.listAttr(alias=1)
        res2 = remap.listAliases()
        self.assertEqual( res1[0], res2[0][1] )
        self.assertEqual(fromPyNode, res1[0])
        self.assertEqual(fromAttr, fromPyNode)

    def test_pmcmds_objectErrors(self):
        self.assertRaises( MayaAttributeError, setAttr, 'foo.bar', 0 )
        self.assertRaises( MayaAttributeError, getAttr, 'foo.bar' )
        self.assertRaises( MayaNodeError, listConnections, 'foobar' )

    def test05_dagNode_addParent(self):
        sphere = polySphere()[0]
        cube = polyCube()[0]
        torus = polyTorus()[0]
        sphere | cube | torus
        print torus.fullPath()

    #def test05_dagNode_getParent(self):
    def test06_instances(self):
        self.assert_( self.sphere1.isInstanced() )
        self.assert_( self.sphere1.isInstanceOf( self.sphere3 ) )

    def test_parentsAndChildren(self):
        shape = self.sphere1.getShape()
        self.assertEqual( shape, self.sphere1.childAtIndex(0) )
        shape.hasParent( self.sphere1 )
        self.assert_( shape.hasParent(self.sphere1) )
        self.assert_( self.sphere1.hasChild(shape) )

        self.sphere2 | self.grp1
        # Should now have grp2 | sphere2 | grp1 | cube1
        self.assertEqual(self.cube1.getParent(0), self.cube1)
        self.assertEqual(self.cube1.getParent(generations=1), self.grp1)
        self.assertEqual(self.cube1.getParent(2), self.sphere2)
        self.assertEqual(self.cube1.getParent(generations=3), self.grp2)
        self.assertEqual(self.cube1.getParent(-1), self.grp2)
        self.assertEqual(self.cube1.getParent(generations=-2), self.sphere2)
        self.assertEqual(self.cube1.getParent(-3), self.grp1)
        self.assertEqual(self.cube1.getParent(generations=-4), self.cube1)
        self.assertEqual(self.cube1.getParent(-5), None)
        self.assertEqual(self.cube1.getParent(generations=4), None)
        self.assertEqual(self.cube1.getParent(-63), None)
        self.assertEqual(self.cube1.getParent(generations=32), None)

    def test07_units(self):
        startLinear = currentUnit( q=1, linear=1)
        startAngular = currentUnit( q=1, angle=1)
        startTime = currentUnit( q=1, time=1)
        #cam = PyNode('persp')

        # change to units that differ from api internal units

        currentUnit(linear='meter')
        currentUnit(angle='deg')
        currentUnit(time='120fps')

        testPairs = [ ('persp.translate', 'getTranslation', 'setTranslation', datatypes.Vector([3.0,2.0,1.0]) ),  # Distance Vector
                      ('persp.shutterAngle' , 'getShutterAngle', 'setShutterAngle', 144.0 ),  # Angle
                      ('persp.verticalFilmAperture' , 'getVerticalFilmAperture', 'setVerticalFilmAperture', 2.0 ),  # Unitless
                      ('persp.focusDistance', 'getFocusDistance', 'setFocusDistance', 5.0 ),  # Distance
                      ('%s.penumbraAngle' % self.light, 'getPenumbra', 'setPenumbra', 5.0 ),  # Angle with renamed api method ( getPenumbraAngle --> getPenumbra )
                     ]
        print
        for attrName, getMethodName, setMethodName, realValue in testPairs:
            at = PyNode(attrName)
            node = at.node()
            getter = getattr( node, getMethodName )
            setter = getattr( node, setMethodName )

            print repr(at)
            print "Real Value:", repr(realValue)
            # set attribute using "safe" method
            at.set( realValue )
            # get attribute using wrapped api method
            gotValue = getter()
            print "Got Value:", repr(gotValue)
            # compare
            self.assertEqual( realValue, gotValue )

            # set using wrapped api method
            setter( realValue )
            # get attribute using "safe" method
            gotValue = at.get()
            # compare
            self.assertEqual( realValue, gotValue )


        self.assert_( self.anim.keyTimeValue[1].keyTime.get() == self.anim.getTime(1) )
        self.anim.setTime(1, 5.0)
        self.assert_( self.anim.keyTimeValue[1].keyTime.get() == self.anim.getTime(1) )
        # reset units
        currentUnit(linear=startLinear)
        currentUnit(angle=startAngular)
        currentUnit(time=startTime)

#    def test_components(self):
#        import pymel.examples.setVertexColor
#        pymel.examples.setVertexColor.doIt( self.sphere1 )
#
#    def test_examples(self):
#        import pymel.examples.example1
#        import pymel.examples.example2

    def test_classCreation(self):
        self.newobjs.append( nt.Joint() )
        self.newobjs.append( nt.Transform() )



    def test_transform_translation(self):
        SCENE.persp.setTranslation( [10,20,30], 'world')

        self.assert_( SCENE.persp.getTranslation( 'world' ) == datatypes.Vector([10.0, 20.0, 30.0]) )
        SCENE.persp.setTranslation( [1,2,3], 'world', relative=1)

        self.assert_( SCENE.persp.getTranslation( 'world' ) == datatypes.Vector([11.0, 22.0, 33.0]) )

        undo()
        self.assert_( SCENE.persp.getTranslation( 'world' ) == datatypes.Vector([10.0, 20.0, 30.0]) )

    def test_transform_scale(self):

        SCENE.persp.setScale( [10,20,30] )

        self.assert_( SCENE.persp.getScale() == [10.0, 20.0, 30.0] )
        SCENE.persp.setScale( [1,2,3], relative=1)

        self.assert_( SCENE.persp.getScale() == [10.0, 40.0, 90.0] )

        undo()
        self.assert_( SCENE.persp.getScale() == [10.0, 20.0, 30.0] )

    def test_transform_rotation(self):
        SCENE.persp.setRotation( [10,20,0], 'world')
        #print repr( SCENE.persp.getRotation( 'world' ) )
        self.assert_( SCENE.persp.getRotation( 'world' ).isEquivalent( datatypes.EulerRotation([10.0, 20.0, 0.0])) )
        SCENE.persp.setRotation( [0,90,0], 'world', relative=1)

        self.assert_( SCENE.persp.getRotation( 'world' ).isEquivalent( datatypes.EulerRotation([10.0, 110.0, 0.0])) )

        undo()
        self.assert_( SCENE.persp.getRotation( 'world' ).isEquivalent( datatypes.EulerRotation([10.0, 20.0, 00.0])) )

    def test_immutability(self):

        c1 = polyCube()[0]
        c2 = polyCube()[0]

        nodeHash1 = c1.__hash__()
        nodeHash2 = c2.__hash__()

        attrHash1 = c1.translate.__hash__()
        attrHash2 = c2.translate.__hash__()

        self.assert_ ( nodeHash1 != nodeHash2 )
        self.assert_ ( attrHash1 != attrHash2 )

        c1.rename( 'funfun' )
        c2.rename( 'yumyum' )

        self.assert_( nodeHash1 == c1.__hash__() )
        self.assert_( nodeHash2 == c2.__hash__() )
        self.assert_( attrHash1 == c1.translate.__hash__() )
        self.assert_( attrHash2 == c2.translate.__hash__() )

    def test_pynode_instantiation(self):
        plug = SCENE.persp.__apimfn__().findPlug('translateX')
        obj = SCENE.persp.__apimobject__()
        dag = SCENE.persp.__apimdagpath__()
        PyNode(obj).name()
        PyNode(plug).name()
        PyNode(dag).name()

    def test_muteAttr(self):
        self.sphere1.t.setKey()

        self.assertEqual(self.sphere1.tx.isMuted(), cmds.mute(str(self.sphere1.tx), q=1))
        self.sphere1.tx.mute()
        self.assertTrue(self.sphere1.tx.isMuted())
        self.assertEqual(self.sphere1.tx.isMuted(), cmds.mute(str(self.sphere1.tx), q=1))
        self.sphere1.tx.unmute()
        self.assertFalse(self.sphere1.tx.isMuted())
        self.assertEqual(self.sphere1.tx.isMuted(), cmds.mute(str(self.sphere1.tx), q=1))

        self.assertRaises(RuntimeError, self.sphere1.t.isMuted)
        self.sphere1.t.mute()
        for attr in self.sphere1.t.getChildren():
            self.assertTrue(attr.isMuted())
            self.assertEqual(attr.isMuted(), cmds.mute(str(attr), q=1))
        self.sphere1.t.unmute()
        for attr in self.sphere1.t.getChildren():
            self.assertFalse(attr.isMuted())
            self.assertEqual(attr.isMuted(), cmds.mute(str(attr), q=1))

    def tearDown(self):
        newFile(f=1)

class testCase_apiUndo(unittest.TestCase):

    def setUp(self):

        # reset all undo queues
        cmds.undoInfo(state=0)
        setAttr( 'persp.focalLength', 35 )
        setAttr( 'top.focalLength', 35 )
        factories.apiUndo.flushUndo()
        cmds.undoInfo(state=1)

    def test_undo(self):
        self.assert_( len(factories.apiUndo.undo_queue) == 0 )

        SCENE.top.setFocalLength(20)
        self.assert_( len(factories.apiUndo.undo_queue) == 1 )


        undoInfo(stateWithoutFlush=0)#--------------------------------

        SCENE.persp.setFocalLength(20)
        self.assert_( len(factories.apiUndo.undo_queue) == 1 )

        undoInfo(stateWithoutFlush=1)#--------------------------------

        undo() # undo top focal length back to 35

        self.assert_( SCENE.top.getFocalLength() == 35.0 )
        self.assert_( SCENE.persp.getFocalLength() == 20.0 )

        redo()

        self.assert_( SCENE.top.getFocalLength() == 20.0 )
        self.assert_( SCENE.persp.getFocalLength() == 20.0 )
        self.assert_( len(factories.apiUndo.undo_queue) == 1 )

        # clear maya's undo queue
        # we override undoInfo in system to flush the cache
        undoInfo( state=0)
        undoInfo( state=1)

        self.assert_( len(factories.apiUndo.undo_queue) == 0 )

        SCENE.top.setFocalLength(200)
        undo()

        self.assert_( SCENE.persp.getFocalLength() == 20.0 )
        self.assert_( SCENE.top.getFocalLength() == 20.0 )

        self.assert_( len(factories.apiUndo.undo_queue) == 0 )

#    def tearDown(self):
#
#        # reset all undo queues
#        cmds.undoInfo(state=0)
#        setAttr( 'persp.focalLength', 35 )
#        setAttr( 'top.focalLength', 35 )
#        factories.apiUndo.flushUndo()
#        cmds.undoInfo(state=1)

    def tearDown(self):
        # cleaning
        newFile(f=1)

class testCase_listHistory(unittest.TestCase):

    def setUp(self):
        self.sphere1, self.sphere1Maker = polySphere()
        self.sphere1Shape = self.sphere1.getShape()
        self.cube1 = polyCube()[0]
        self.cube1Shape = self.cube1.getShape()

        # Delete cube's construction history
        delete(self.cube1, ch=1)

        # Connect sphere up to cube
        self.sphere1Shape.outMesh >> self.cube1Shape.inMesh

        self.justSphereShape = set([self.sphere1Shape])
        self.justPolySphere = set([self.sphere1Maker])
        self.justCubeShape = set([self.cube1Shape])
        self.polySphereAndShape = self.justSphereShape | self.justPolySphere
        self.polySphereAndShapeAndCubeShape = self.polySphereAndShape | self.justCubeShape
        self.shapes = self.justSphereShape | self.justCubeShape

    def tearDown(self):
        # cleaning
        delete(self.sphere1)
        delete(self.cube1)

    def test_listHistory(self):
        hist = set(self.sphere1.listHistory())
        self.assertEqual(self.polySphereAndShape, hist)

        hist = set(self.cube1.listHistory())
        self.assertEqual(self.polySphereAndShapeAndCubeShape, hist)

    def test_listHistoryType(self):
        hist = set(self.sphere1.listHistory(type='dagNode'))
        self.assertEqual(self.justSphereShape, hist)

        hist = set(self.sphere1.listHistory(type='mesh'))
        self.assertEqual(self.justSphereShape, hist)

        hist = set(self.cube1.listHistory(type='dagNode'))
        self.assertEqual(self.shapes, hist)

        hist = set(self.cube1.listHistory(type='mesh'))
        self.assertEqual(self.shapes, hist)


    def test_listHistoryExactType(self):
        hist = set(self.sphere1.listHistory(exactType='dagNode'))
        self.assertEqual(set(), hist)

        hist = set(self.sphere1.listHistory(exactType='mesh'))
        self.assertEqual(self.justSphereShape, hist)

        hist = set(self.cube1.listHistory(exactType='dagNode'))
        self.assertEqual(set(), hist)

        hist = set(self.cube1.listHistory(exactType='mesh'))
        self.assertEqual(self.shapes, hist)

    def test_listFuture(self):
        fut = set(self.sphere1Maker.listFuture())
        self.assertEqual(self.polySphereAndShapeAndCubeShape, fut)

    def test_listFutureType(self):
        fut = set(self.sphere1Maker.listFuture(type='dagNode'))
        self.assertEqual(self.shapes, fut)

        fut = set(self.sphere1Maker.listFuture(type='mesh'))
        self.assertEqual(self.shapes, fut)

    def test_listFutureExactType(self):
        fut = set(self.sphere1Maker.listFuture(exactType='dagNode'))
        self.assertEqual(set(), fut)

        fut = set(self.sphere1Maker.listFuture(exactType='mesh'))
        self.assertEqual(self.shapes, fut)







#    def test_transform(self):
#        s, h = polySphere()
#        g = group(s)
#        s.setTranslation( [0,10,20] )
#        s.getTranslation(objectSpace=1)
#        # Result: [0.0, 10.0, 20.0] #
#        s.getTranslation('object')
#        # Result: [0.0, 10.0, 20.0] #
#        s.getTranslation(worldSpace=1)
#        # Result: [10.0, 10.0, 20.0] #
#        s.getTranslation('world')
#        # Result: [10.0, 10.0, 20.0] #

class testCase_duplicate(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)

    def test_duplicate(self):
        # make sure that we get proper dag nodes, even when the result will contain non-unique names
        group = cmds.group('persp')
        self.assert_( duplicate(group) )

        # ensure it works with depend nodes too
        dependNode = cmds.createNode('displayLayer')
        self.assert_( duplicate(dependNode) )

    def test_sameOrder(self):
        # Test when we have two nodes with similar names under the same parent,
        # that they're returned in the right order...

        # we create children under the nodes we will duplicate, just so that
        # we can identify which top-level-node is which...
        catParent = pm.createNode('transform', name='parent1')
        pm.createNode('transform', name='cat', parent=catParent)
        dogParent = pm.createNode('transform', name='parent2')
        pm.createNode('transform', name='dog', parent=dogParent)

        dupes = pm.duplicate(dogParent, catParent)

        parentRe = re.compile(r'^\|parent[0-9]$')
        self.assertTrue(parentRe.match(dupes[0].longName()))
        self.assertTrue(parentRe.match(dupes[1].longName()))
        self.assertEqual(dupes[0].getChildren()[0].nodeName(), 'dog')
        self.assertEqual(dupes[1].getChildren()[0].nodeName(), 'cat')

    def test_dupeParentAndChild(self):
        # Test that if one of the args to duplicate is a child of another arg,
        # that pymel can deal
        t1 = pm.nt.Transform(name='foobar')
        t2 = pm.nt.Transform(name='stuff', parent='foobar')
        dupes = pm.duplicate(t1, t2)
        self.assertEqual(dupes[0].longName(), '|foobar1')
        self.assertEqual(dupes[1].longName(), '|foobar1|stuff')
        self.assertEqual(dupes[0], dupes[1].getParent())

    def test_shapeSameName(self):
        # Test that if we dupe a transform that has a shape with an identical
        # name, that pymel can deal
        trans = pm.polySphere(name='Alfred')[0]
        shape = trans.getShape()
        shape.rename(trans.nodeName())
        dupes = pm.duplicate(trans)
        self.assertEqual(dupes[0].longName(), '|Alfred1')
        self.assertEqual(dupes[0].getShape().longName(), '|Alfred1|Alfred1')

    def test_underworld(self):
        camTrans, camShape = pm.camera()
        camTrans.rename('CamNewton')
        imageTrans, imageShape = pm.imagePlane(camera=camShape)
        imageTrans.rename('zeImage')

        self.assertEqual(imageShape.longName(),
                         '|CamNewton|CamNewtonShape->|zeImage|zeImageShape')

        dupes = pm.duplicate(imageTrans)
        self.assertEqual(dupes[0].longName(),
                         '|CamNewton|CamNewtonShape->|zeImage1')


class testCase_duplicateShape(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)
        self.poly = polyCube(name='singleShapePoly')[0]
        self.curve = circle(name='singleShapeCurve')[0]
        tempShapeTransform = polyCone()[0]
        self.subd = polyToSubdiv(tempShapeTransform,
                                 constructionHistory=False,
                                 name='singleShapeSubd')[0]
        delete(tempShapeTransform)
        #self.noShape = createNode('transform', name='noShapeTransform')

        #one transform, multiple shapes
        self.multiShape = polyCube(name='multiShape')[0]
        self.multiShape.getShape().rename('multiShapePolyShape')
        tempShapeTransform = polyToSubdiv(self.multiShape,
                                          constructionHistory=False,
                                          name='multiShapeSubd')[0]
        parent(tempShapeTransform.getShape(), self.multiShape, shape=True,
               addObject=True, relative=True)
        delete(tempShapeTransform)
        tempShapeTransform = circle(name='multiShapeCurve')[0]
        parent(tempShapeTransform.getShape(), self.multiShape, shape=True,
               addObject=True, relative=True)
        delete(tempShapeTransform)

    def tearDown(self):
        for node in (self.multiShape, self.poly, self.curve, self.subd):
            delete(node)

    def test_singleShapes(self):
        for shapeTransform in (self.poly, self.curve, self.subd):
            self.assertEqual(len(shapeTransform.getChildren(shapes=1)), 1)
            self.assertRaises(TypeError, duplicate, shapeTransform, addShape=True)
            self.assertEqual(len(shapeTransform.getChildren(shapes=1)), 1)
            origShape = shapeTransform.getShape()
            shapeDup = duplicate(origShape, addShape=True)
            self.assertEqual(len(shapeTransform.getChildren(shapes=1)), 2)
            self.assertEqual(len(shapeDup), 1)
            shapeDup = shapeDup[0]
            self.assertDupeShape(origShape, shapeDup)

    def test_multiShape(self):
        origShapes = self.multiShape.getChildren(shapes=1)
        oldNumChildren = len(origShapes)
        self.assertRaises(TypeError, duplicate, self.multiShape, addShape=True)
        self.assertEqual(len(self.multiShape.getChildren(shapes=1)),
                             oldNumChildren)
        for origShape in origShapes:
            shapeDup = duplicate(origShape, addShape=True)
            self.assertEqual(len(self.multiShape.getChildren(shapes=1)),
                             oldNumChildren + 1)
            oldNumChildren += 1
            self.assertEqual(len(shapeDup), 1)
            shapeDup = shapeDup[0]
            self.assertDupeShape(origShape, shapeDup)

    def assertDupeShape(self, origShape, shapeDup):
            self.assertTrue(shapeDup.__class__ == origShape.__class__)

            # As of Maya 2009, shapeCompare doesn't handle subdivs, and always
            #    returns 1 for curves
            if not isinstance(origShape, (nt.Subdiv, nt.NurbsCurve)):
                if shapeCompare(origShape, shapeDup) != 0:
                    self.fail("shapes do not compare equal: %r, %r)" %
                              (origShape, shapeDup))
            self.assertFalse(origShape.isInstanceOf(shapeDup))

class test_PyNodeWraps(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)

    def assertPyNode(self, obj, nodeType=PyNode):
        self.assert_(isinstance(obj, nodeType),
                     '%r was not a %s object' % (obj, nodeType.__name__))

    def assertPyNodes(self, objs, nodeType=PyNode):
        for obj in objs:
            self.assertPyNode(obj, nodeType)

    def test_addAttr_QParent(self):
        cmds.polyCube()
        cmds.addAttr( longName='sampson', numberOfChildren=5, attributeType='compound' )
        cmds.addAttr( longName='homeboy', attributeType='matrix', parent='sampson' )
        cmds.addAttr( longName='midge', attributeType='message', parent='sampson' )
        cmds.addAttr( longName='damien', attributeType='double', parent='sampson' )
        cmds.addAttr( longName='elizabeth', attributeType='double', parent='sampson' )
        cmds.addAttr( longName='sweetpea', attributeType='double', parent='sampson' )
        node = cmds.ls(sl=1)[0]
        self.assertPyNode(addAttr(node + '.sweetpea', q=1, parent=1), Attribute)

    def test_skinCluster_QGeometry(self):
        cube = cmds.polyCube()[0]
        j1 = cmds.joint(p=(0,0,-1))
        cmds.joint(p=(0,0,1))
        skin = pm.skinCluster(cube, j1)
        self.assertPyNodes(skin.getGeometry(), nt.DependNode)

    def test_addDynamic(self):
        # Create an emitter
        cmds.emitter( pos=(0, 0, 0), type='omni', r=100, sro=0, nuv=0, cye='none', cyi=1, spd=1, srn=0, nsp=1, tsp=0, mxd=0, mnd=0, dx=1, dy=0, dz=0, sp=0 )
        # Result: emitter1 #

        # Get the emitter to emit particles
        cmds.particle()
        # Result: particle2
        cmds.connectDynamic( 'particle1', em='emitter1' )

        # Create a particle to use as the source of the emitter
        cmds.particle( p=((6.0, 0, 7.0), (6.0, 0, 2.0)), c=1 )
        # Result: particle2

        # Use particle2 as a source of the emitter
        self.assertPyNodes(addDynamic( 'emitter1', 'particle2' ), PyNode)

    def test_addPP(self):
        cmds.emitter( n='myEmitter1' )
        cmds.particle( n='myParticle1' )
        cmds.connectDynamic( 'myParticle1', em='myEmitter1' )
        cmds.select( 'myParticle1' )
        cmds.emitter( n='myEmitter2' )
        cmds.particle( n='myParticle2' )
        cmds.connectDynamic( 'myParticle2', em='myEmitter2' )
        self.assertPyNodes(addPP( 'myEmitter2', atr='rate' ))

    def test_animLayer(self):
        self.assertEqual(animLayer(q=1, root=1), None)
        cmds.animLayer("layer1")
        rootLayer = animLayer(q=1, root=1)
        self.assertPyNode(rootLayer)
        self.assertEqual(animLayer(rootLayer, q=1, parent=1), None)
        self.assertPyNode(animLayer("layer1", q=1, parent=1))
        self.assertEqual(animLayer("layer1", q=1, children=1), [])
        self.assertPyNodes(animLayer(rootLayer, q=1, children=1))
        self.assertEqual(animLayer("layer1", q=1, attribute=1), [])
        self.assertEqual(animLayer("layer1", q=1,  blendNodes=1), [])
        cmds.animLayer("layer1", e=1, attribute=('persp.tx', 'persp.ry'))
        self.assertPyNodes(animLayer("layer1", q=1, attribute=1), Attribute)
        cmds.select('persp')
        self.assertPyNodes(animLayer(q=1, bestAnimLayer=1))
        self.assertEqual(animLayer("layer1", q=1,  animCurves=1), [])
        cmds.setKeyframe('persp', animLayer='layer1')
        self.assertPyNodes(animLayer("layer1", q=1,  animCurves=1))
        self.assertEqual(animLayer('layer1', q=1, bac=1), [])
        cmds.setKeyframe('persp', animLayer='BaseAnimation')
        self.assertPyNodes(animLayer('layer1', q=1, bac=1))
        self.assertPyNodes(animLayer("layer1", q=1,  blendNodes=1))
        self.assertEqual(animLayer("persp.tz", q=1,  bestLayer=1), None)
        self.assertPyNode(animLayer("persp.tx", q=1,  bestLayer=1))
        cmds.select('side')
        self.assertEqual(animLayer(q=1,  affectedLayers=1), [])
        cmds.select('persp')
        self.assertPyNodes(animLayer(q=1,  affectedLayers=1))

    def test_annotate(self):
        cmds.sphere( name='mySphere' )
        self.assertPyNode(annotate( 'mySphere', tx='my annotation text', p=(5, 6, 5) ))

    def test_arclen(self):
        circle(name='curve1')
        self.assertPyNode(arclen('curve1', ch=True))
        self.assertPyNode(arclen('curve1'), float)

    def test_arcLengthDimension(self):
        cmds.curve( d=3, p=((-9.3, 0, 3.2), (-4.2, 0, 5.0), (6.0, 0, 8.6), (2.1, 0, -1.9)), k=(0, 0, 0, 1, 2, 2));
        self.assertPyNode(arcLengthDimension( 'curveShape1.u[0.5]' ))

    def test_arrayMapper(self):
        particle( p=[(0, 0, 0), (3, 5, 6), (5, 6, 7), (9, 9, 9)] )
        self.assertPyNode(arrayMapper( target='particle1', destAttr='rampPosition', inputV='ageNormalized', type='ramp' ))

    if not cmds.about(batch=1):

        def test_art3dPaintCtx(self):
            polyCube()
            polyCube()
            select('pCube1', 'pCube2')
            from maya.mel import eval as mel
            mel("Art3dPaintTool")
            mel("art3dPaintAssignFileTextures color")
            self.assertPyNodes(art3dPaintCtx('art3dPaintContext', q=1, shn=1))
            self.assertPyNodes(art3dPaintCtx('art3dPaintContext', q=1, hnm=1))

        def test_artAttrCtx(self):
            polyCube()
            polyCube()
            select('pCube1', 'pCube2')
            if not cmds.artAttrCtx('artAttrCtx1', exists=1):
                cmds.artAttrCtx('artAttrCtx1')
            cmds.setToolTo('artAttrCtx1')
            self.assertPyNodes(artAttrCtx('artAttrCtx1', q=1, paintNodeArray=1))

for cmdName in ('''aimConstraint geometryConstraint normalConstraint
                   orientConstraint parentConstraint pointConstraint
                   pointOnPolyConstraint poleVectorConstraint
                   scaleConstraint tangentConstraint''').split():
    melCmd = getattr(cmds, cmdName, None)
    if not melCmd: continue
    pyCmd = globals()[cmdName]
    def constraintTest(self):
        cmds.polyCube(name='cube1')
        cmds.circle(name='circle1')
        constr = melCmd( 'circle1', 'cube1')[0]
        self.assertPyNodes(pyCmd(constr, q=1, targetList=1))
        self.assertPyNodes(pyCmd(constr, q=1, weightAliasList=1), Attribute)
        if 'worldUpObject' in factories.cmdlist[cmdName]['flags']:
            self.assertEqual(pyCmd(constr, q=1, worldUpObject=1), None)
            cmds.polySphere(name='sphere1')
            melCmd(constr, e=1, worldUpType='object', worldUpObject='sphere1')
            self.assertPyNode(pyCmd(constr, q=1, worldUpObject=1))
    testName = "test_" + cmdName
    constraintTest.__name__ = testName
    setattr(test_PyNodeWraps, testName, constraintTest)

    # Delete the function from the module level after we're done, so
    # nosetests won't find the "original" non-method function, and
    # try to run it as a test!
    del globals()['constraintTest']


class test_plugins(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)
        if cmds.pluginInfo('Fur', q=1, loaded=1):
            cmds.unloadPlugin('Fur')
            cmds.file(new=1, f=1)
        # Currently, PyNode classes for node types defined in 'default'
        # plugins are always created when pymel starts up, even if the plugin
        # wasn't loaded... so we need to make sure we delete 'FurGlobals' if it
        # was made
        if 'FurGlobals' in nt.__dict__:
            del nt.__dict__['FurGlobals']
        if 'FurGlobals' in nt.__class__.__dict__:
            delattr(nt.__class__, 'FurGlobals')
        # Also, 'unload' pymel.all if present - if it's there, it will cause
        # any new PyNodes to skip lazy loading
        sys.modules.pop('pymel.all', None)

    def test01_load(self):
        self.assert_( 'FurGlobals' not in nt.__dict__ )
        loadPlugin('Fur')
        self.assert_( 'FurGlobals' not in nt.__dict__ )
        # lazy loader exists
        self.assert_( 'FurGlobals' in nt.__class__.__dict__ )
        # after accessing, the lazy loader should generate the class
        nt.FurGlobals
        self.assert_( 'FurGlobals' in nt.__dict__ )

    def test02_unload(self):
        loadPlugin('Fur')
        unloadPlugin('Fur')
        self.assert_( 'FurGlobals' not in nt.__dict__ )
        # after accessing, the lazy loader should generate the class
        self.assertRaises(AttributeError, getattr, nt, 'FurGlobals')
        self.assert_( 'FurGlobals' not in nt.__dict__ )
        self.assert_( 'FurGlobals' not in nt.__class__.__dict__ )

class test_move(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)

    def test_relativeMove(self):
        cube = pm.polyCube()[0]
        pm.move(1,0,0, xyz=True, r=1)
        self.assertEqual(cube.getTranslation(), dt.Vector(1,0,0))
        pm.move(0,1,0, xyz=True, r=1)
        self.assertEqual(cube.getTranslation(), dt.Vector(1,1,0))
        pm.move(0,0,1, xyz=True, r=1)
        self.assertEqual(cube.getTranslation(), dt.Vector(1,1,1))

class test_parent(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)
        self.sphere = pm.polySphere()[0]
        self.cube = pm.polyCube()[0]
        self.cone = pm.polyCone()[0]

    def test_parent_world2obj(self):
        self.assertEqual(self.sphere.getParent(), None)
        pm.parent(self.sphere, self.cube)
        self.assertEqual(self.sphere.getParent(), self.cube)

    def test_parent_world2world_1(self):
        self.assertEqual(self.sphere.getParent(), None)
        pm.parent(self.sphere, None)
        self.assertEqual(self.sphere.getParent(), None)

    def test_parent_world2world_2(self):
        self.assertEqual(self.sphere.getParent(), None)
        pm.parent(self.sphere, w=1)
        self.assertEqual(self.sphere.getParent(), None)

    def test_parent_world2world_3(self):
        self.assertEqual(self.sphere.getParent(), None)
        pm.parent(self.sphere, world=True)
        self.assertEqual(self.sphere.getParent(), None)

    def test_parent_obj2obj(self):
        pm.parent(self.sphere, self.cube)
        self.assertEqual(self.sphere.getParent(), self.cube)
        pm.parent(self.sphere, self.cone)
        self.assertEqual(self.sphere.getParent(), self.cone)

    def test_parent_obj2sameObj(self):
        pm.parent(self.sphere, self.cube)
        self.assertEqual(self.sphere.getParent(), self.cube)
        pm.parent(self.sphere, self.cube)
        self.assertEqual(self.sphere.getParent(), self.cube)

    def test_parent_obj2world(self):
        pm.parent(self.sphere, self.cube)
        self.assertEqual(self.sphere.getParent(), self.cube)
        pm.parent(self.sphere, None)
        self.assertEqual(self.sphere.getParent(), None)

    def test_parent_multiWorld2obj(self):
        self.assertEqual(self.sphere.getParent(), None)
        self.assertEqual(self.cube.getParent(), None)
        pm.parent(self.sphere, self.cube, self.cone)
        self.assertEqual(self.sphere.getParent(), self.cone)
        self.assertEqual(self.cube.getParent(), self.cone)

    def test_parent_multiWorld2obj_sel(self):
        self.assertEqual(self.sphere.getParent(), None)
        self.assertEqual(self.cube.getParent(), None)
        pm.select(self.sphere, self.cube, self.cone)
        pm.parent()
        self.assertEqual(self.sphere.getParent(), self.cone)
        self.assertEqual(self.cube.getParent(), self.cone)


class test_lazyDocs(unittest.TestCase):
    # Test can't be reliably run if pymel.all is imported... re-stubbing
    # doesn't work
#    def test_stubMethodDocs(self):
#        origCmd = cmd = cmds.filter
#        try:
#            # if maya.cmds.filter has already been 'de-stubbed', re-stub it
#            if not cmd.__name__ == 'stubFunc':
#                # maya.cmds.dynamicLoad will fail if a library has already been
#                # loaded, so we could just feed in a dummy library..
#                cmd = _makeStubFunc('filter', 'Devices.dll')
#                cmds.filter = cmd
#            self.assertTrue('Creates or modifies a filter node' in
#                            pm.nt.Filter.__doc__)
#        finally:
#            if cmds.filter != origCmd:
#                cmds.filter = origCmd

    def test_getCmdName(self):
        cmd = cmds.filter
        if not cmd.__name__ == 'stubFunc':
            # maya.cmds.dynamicLoad will fail if a library has already been
            # loaded, so we could just feed in a dummy library..
            cmd = _makeStubFunc('filter', 'Devices.dll')
        self.assertEqual(pmcmds.getCmdName(cmd), 'filter')



class test_hasAttr(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        self.loc = pm.spaceLocator()

    def test_transformAttr(self):
        self.assertTrue(pm.hasAttr(self.loc, 'tx', checkShape=False))
        self.assertTrue(pm.hasAttr(self.loc, 'tx', checkShape=True))
        self.assertTrue(self.loc.hasAttr('tx', checkShape=False))
        self.assertTrue(self.loc.hasAttr('tx', checkShape=True))

    def test_shapeAttr(self):
        self.assertFalse(pm.hasAttr(self.loc, 'localPositionX', checkShape=False))
        self.assertTrue(pm.hasAttr(self.loc, 'localPositionX', checkShape=True))
        self.assertFalse(self.loc.hasAttr('localPositionX', checkShape=False))
        self.assertTrue(self.loc.hasAttr('localPositionX', checkShape=True))

    def test_badAttr(self):
        self.assertFalse(pm.hasAttr(self.loc, 'foobar', checkShape=False))
        self.assertFalse(pm.hasAttr(self.loc, 'foobar', checkShape=True))
        self.assertFalse(self.loc.hasAttr('foobar', checkShape=False))
        self.assertFalse(self.loc.hasAttr('foobar', checkShape=True))

class test_setEnums(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        self.loc = pm.spaceLocator()
        # if you don't specify enumName when the attribute is created, maya
        # doesn't think it's an enum when you try to set the enums later...
        self.loc.addAttr('testEnumAttr', attributeType='enum',
                         enumName='foo:bar')
        self.enumAttr = self.loc.attr('testEnumAttr')

    def test_string_noIndices(self):
        self.enumAttr.setEnums('first:second:third')
        self.assertEqual(self.enumAttr.getEnums(),
                         {'first':0, 'second':1, 'third':2})

    def test_string_allIndices(self):
        self.enumAttr.setEnums('giraffe=1:gazelle=5:lion=3')
        self.assertEqual(self.enumAttr.getEnums(),
                         {'giraffe':1, 'gazelle':5, 'lion':3})

    def test_string_partialIndices(self):
        self.enumAttr.setEnums('giraffe=1:gazelle=5:lion')
        self.assertEqual(self.enumAttr.getEnums(),
                         {'giraffe':1, 'gazelle':5, 'lion':6})

    def test_list_noIndices(self):
        self.enumAttr.setEnums(['giraffe', 'gazelle', 'lion'])
        self.assertEqual(self.enumAttr.getEnums(),
                         {'giraffe':0, 'gazelle':1, 'lion':2})

    def test_list_allIndices(self):
        self.enumAttr.setEnums(['giraffe=1', 'gazelle=5', 'lion=3'])
        self.assertEqual(self.enumAttr.getEnums(),
                         {'giraffe':1, 'gazelle':5, 'lion':3})

    def test_list_partialIndices(self):
        self.enumAttr.setEnums(['giraffe=1', 'gazelle=5', 'lion'])
        self.assertEqual(self.enumAttr.getEnums(),
                         {'giraffe':1, 'gazelle':5, 'lion':6})

    def test_dict(self):
        newEnums = {'giraffe':1, 'gazelle':5, 'lion':3}
        self.enumAttr.setEnums({'giraffe':1, 'gazelle':5, 'lion':3})
        self.assertEqual(self.enumAttr.getEnums(), newEnums)

class test_addAttr(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        self.loc = pm.spaceLocator()

    def test_enumName_string_noIndices(self):
        self.loc.addAttr('testEnumAttr', attributeType='enum',
                         enumName='first:second:third')
        self.assertEqual(self.loc.attr('testEnumAttr').getEnums(),
                         {'first':0, 'second':1, 'third':2})

    def test_enumName_string_allIndices(self):
        self.loc.addAttr('testEnumAttr', attributeType='enum',
                         enumName='giraffe=1:gazelle=5:lion=3')
        self.assertEqual(self.loc.attr('testEnumAttr').getEnums(),
                         {'giraffe':1, 'gazelle':5, 'lion':3})

    def test_enumName_string_partialIndices(self):
        self.loc.addAttr('testEnumAttr', attributeType='enum',
                         enumName='giraffe=1:gazelle=5:lion')
        self.assertEqual(self.loc.attr('testEnumAttr').getEnums(),
                         {'giraffe':1, 'gazelle':5, 'lion':6})

    def test_enumName_list_noIndices(self):
        self.loc.addAttr('testEnumAttr', attributeType='enum',
                         enumName=['giraffe', 'gazelle', 'lion'])
        self.assertEqual(self.loc.attr('testEnumAttr').getEnums(),
                         {'giraffe':0, 'gazelle':1, 'lion':2})

    def test_enumName_list_allIndices(self):
        self.loc.addAttr('testEnumAttr', attributeType='enum',
                         enumName=['giraffe=1', 'gazelle=5', 'lion=3'])
        self.assertEqual(self.loc.attr('testEnumAttr').getEnums(),
                         {'giraffe':1, 'gazelle':5, 'lion':3})

    def test_enumName_list_partialIndices(self):
        self.loc.addAttr('testEnumAttr', attributeType='enum',
                         enumName=['giraffe=1', 'gazelle=5', 'lion'])
        self.assertEqual(self.loc.attr('testEnumAttr').getEnums(),
                         {'giraffe':1, 'gazelle':5, 'lion':6})

    def test_enumName_dict(self):
        newEnums = {'giraffe':1, 'gazelle':5, 'lion':3}
        self.loc.addAttr('testEnumAttr', attributeType='enum',
                         enumName={'giraffe':1, 'gazelle':5, 'lion':3})
        self.assertEqual(self.loc.attr('testEnumAttr').getEnums(), newEnums)


class test_Attribute_iterDescendants(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        self.cube1 = pm.polyCube(ch=0)[0]
        self.cube2 = pm.polyCube(ch=0)[0]
        self.cube3 = pm.polyCube(ch=0)[0]
        self.blend = pm.blendShape(self.cube2, self.cube3, self.cube1)[0]

    def test_multi(self):
        results = sorted(x.name() for x in
                         self.blend.attr('weight').iterDescendants())
        expected = [u'blendShape1.weight[0]', u'blendShape1.weight[1]']
        self.assertEqual(results, expected)

        results = sorted(x.name() for x in
                         self.blend.attr('weight').iterDescendants(levels=1))
        self.assertEqual(results, expected)

        results = sorted(x.name() for x in
                         self.blend.attr('weight').iterDescendants(levels=2))
        self.assertEqual(results, expected)

        results = sorted(x.name() for x in
                         self.blend.attr('weight').iterDescendants(levels=0))
        self.assertEqual(results, [])

    def test_compound(self):
        results = sorted(x.name() for x in
                         self.blend.attr('baseOrigin').iterDescendants())
        expected = [u'blendShape1.baseOriginX',
                    u'blendShape1.baseOriginY',
                    u'blendShape1.baseOriginZ']
        self.assertEqual(results, expected)

        results = sorted(x.name() for x in
                         self.blend.attr('baseOrigin').iterDescendants(levels=1))
        self.assertEqual(results, expected)

        results = sorted(x.name() for x in
                         self.blend.attr('baseOrigin').iterDescendants(levels=2))
        self.assertEqual(results, expected)

        results = sorted(x.name() for x in
                         self.blend.attr('baseOrigin').iterDescendants(levels=0))
        self.assertEqual(results, [])


    def test_multiCompound(self):
        results = sorted(x.name() for x in
                         self.blend.attr('inputTarget').iterDescendants())
        expected = [u'blendShape1.inputTarget[0]',
            u'blendShape1.inputTarget[0].baseWeights',
            u'blendShape1.inputTarget[0].inputTargetGroup',
            u'blendShape1.inputTarget[0].inputTargetGroup[0]',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem[6000]',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem[6000].inputComponentsTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem[6000].inputGeomTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem[6000].inputPointsTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].normalizationId',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].targetWeights',
            u'blendShape1.inputTarget[0].inputTargetGroup[1]',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].inputTargetItem',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].inputTargetItem[6000]',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].inputTargetItem[6000].inputComponentsTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].inputTargetItem[6000].inputGeomTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].inputTargetItem[6000].inputPointsTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].normalizationId',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].targetWeights',
            u'blendShape1.inputTarget[0].normalizationGroup',
            u'blendShape1.inputTarget[0].paintTargetIndex',
            u'blendShape1.inputTarget[0].paintTargetWeights',
        ]
        self.assertEqual(results, expected)

        results = sorted(x.name() for x in
                         self.blend.attr('inputTarget').iterDescendants(levels=1))
        expected = [u'blendShape1.inputTarget[0]']
        self.assertEqual(results, expected)

        results = sorted(x.name() for x in
                         self.blend.attr('inputTarget').iterDescendants(levels=2))
        expected = [u'blendShape1.inputTarget[0]',
            u'blendShape1.inputTarget[0].baseWeights',
            u'blendShape1.inputTarget[0].inputTargetGroup',
            u'blendShape1.inputTarget[0].normalizationGroup',
            u'blendShape1.inputTarget[0].paintTargetIndex',
            u'blendShape1.inputTarget[0].paintTargetWeights',
        ]
        self.assertEqual(results, expected)

        results = sorted(x.name() for x in
                         self.blend.attr('inputTarget').iterDescendants(levels=0))
        self.assertEqual(results, [])

#suite = unittest.TestLoader().loadTestsFromTestCase(testCase_nodesAndAttributes)
#suite.addTest(unittest.TestLoader().loadTestsFromTestCase(testCase_listHistory))
#unittest.TextTestRunner(verbosity=2).run(suite)
#setupUnittestModule(__name__)


########NEW FILE########
__FILENAME__ = test_language
import unittest

import pymel.core.language as lang

# do this after pymel.core, so maya has initialized
from maya.mel import eval as meval
import maya.cmds as cmds


class testCase_pythonToMelCmd(unittest.TestCase):
    def test_bool_flag(self):
        self.assertEqual(lang.pythonToMelCmd('xform', rao=1).strip(),
                         'xform -rao')
        self.assertEqual(lang.pythonToMelCmd('connectAttr', force=1).strip(),
                         'connectAttr -force')

    def test_bool_arg(self):
        self.assertEqual(lang.pythonToMelCmd('connectAttr', lock=1).strip(),
                         'connectAttr -lock 1')

    def test_multi_arg(self):
        self.assertEqual(lang.pythonToMelCmd('xform', translation=(1,2,3)).strip(),
                         'xform -translation 1 2 3')

class testCase_MelGlobals(unittest.TestCase):
    def setUp(self):
        meval('''global proc int melGlobals_test_int_getter(int $inValue)
                {
                    return $inValue;
                }''')

        meval('''global proc string melGlobals_test_str_getter(string $inValue)
                {
                    return $inValue;
                }''')

        meval('''global proc int[] melGlobals_test_int_arr_getter(int $inValue[])
                {
                    return $inValue;
                }''')

        meval('''global proc string[] melGlobals_test_str_arr_getter(string $inValue[])
                {
                    return $inValue;
                }''')


    def test_set_int(self):
        meval('global int $melGlobals_test_set_int1')

        lang.melGlobals.set('melGlobals_test_set_int1', 37)
        self.assertEqual(meval('melGlobals_test_int_getter($melGlobals_test_set_int1)'),
                         37)
        lang.melGlobals.set('$melGlobals_test_set_int1', 47)
        self.assertEqual(meval('melGlobals_test_int_getter($melGlobals_test_set_int1)'),
                         47)
        lang.MelGlobals.set('melGlobals_test_set_int1', 57)
        self.assertEqual(meval('melGlobals_test_int_getter($melGlobals_test_set_int1)'),
                         57)
        lang.MelGlobals.set('$melGlobals_test_set_int1', 67)
        self.assertEqual(meval('melGlobals_test_int_getter($melGlobals_test_set_int1)'),
                         67)

    def test_set_int_arr(self):
        meval('global int $melGlobals_test_set_int_arr1[]')

        lang.melGlobals.set('melGlobals_test_set_int_arr1', [3, 4])
        self.assertEqual(meval('melGlobals_test_int_arr_getter($melGlobals_test_set_int_arr1)'),
                         [3, 4])
        lang.melGlobals.set('$melGlobals_test_set_int_arr1', [5, 6])
        self.assertEqual(meval('melGlobals_test_int_arr_getter($melGlobals_test_set_int_arr1)'),
                         [5, 6])
        lang.MelGlobals.set('melGlobals_test_set_int_arr1', [7, 8])
        self.assertEqual(meval('melGlobals_test_int_arr_getter($melGlobals_test_set_int_arr1)'),
                         [7, 8])
        lang.MelGlobals.set('$melGlobals_test_set_int_arr1', [9, 10])
        self.assertEqual(meval('melGlobals_test_int_arr_getter($melGlobals_test_set_int_arr1)'),
                         [9, 10])

    def test_set_str(self):
        meval('global string $melGlobals_test_set_str1')

        lang.melGlobals.set('melGlobals_test_set_str1', 'albatross')
        self.assertEqual(meval('melGlobals_test_str_getter($melGlobals_test_set_str1)'),
                         'albatross')
        lang.melGlobals.set('$melGlobals_test_set_str1', 'dinosaur')
        self.assertEqual(meval('melGlobals_test_str_getter($melGlobals_test_set_str1)'),
                         'dinosaur')

        lang.MelGlobals.set('melGlobals_test_set_str1', 'iguana')
        self.assertEqual(meval('melGlobals_test_str_getter($melGlobals_test_set_str1)'),
                         'iguana')
        lang.MelGlobals.set('$melGlobals_test_set_str1', 'parakeet')
        self.assertEqual(meval('melGlobals_test_str_getter($melGlobals_test_set_str1)'),
                         'parakeet')

    def test_set_str_arr(self):
        meval('global string $melGlobals_test_set_str_arr1[]')

        lang.melGlobals.set('melGlobals_test_set_str_arr1', ['albatross', 'macaroni'])
        self.assertEqual(meval('melGlobals_test_str_arr_getter($melGlobals_test_set_str_arr1)'),
                         ['albatross', 'macaroni'])
        lang.melGlobals.set('$melGlobals_test_set_str_arr1', ['dinosaur', 'pizza'])
        self.assertEqual(meval('melGlobals_test_str_arr_getter($melGlobals_test_set_str_arr1)'),
                         ['dinosaur', 'pizza'])

        lang.MelGlobals.set('melGlobals_test_set_str_arr1', ['iguana', 'lasagna'])
        self.assertEqual(meval('melGlobals_test_str_arr_getter($melGlobals_test_set_str_arr1)'),
                         ['iguana', 'lasagna'])
        lang.MelGlobals.set('$melGlobals_test_set_str_arr1', ['parakeet', 'dougnuts'])
        self.assertEqual(meval('melGlobals_test_str_arr_getter($melGlobals_test_set_str_arr1)'),
                         ['parakeet', 'dougnuts'])

    def test_setitem_int(self):
        meval('int $melGlobals_test_setitem_int1')

        lang.melGlobals['melGlobals_test_setitem_int1'] = 37
        self.assertEqual(meval('melGlobals_test_int_getter($melGlobals_test_setitem_int1)'),
                         37)
        lang.melGlobals['$melGlobals_test_setitem_int1'] = 47
        self.assertEqual(meval('melGlobals_test_int_getter($melGlobals_test_setitem_int1)'),
                         47)

    def test_setitem_str(self):
        meval('global string $melGlobals_test_setitem_str1')

        lang.melGlobals['melGlobals_test_setitem_str1'] = 'monkey'
        self.assertEqual(meval('melGlobals_test_str_getter($melGlobals_test_setitem_str1)'),
                         'monkey')
        lang.melGlobals['$melGlobals_test_setitem_str1'] = 'apple'
        self.assertEqual(meval('melGlobals_test_str_getter($melGlobals_test_setitem_str1)'),
                         'apple')

    def test_get_int(self):
        meval('global int $melGlobals_test_get_int1')

        meval('$melGlobals_test_get_int1 = 37')
        self.assertEqual(lang.melGlobals.get('melGlobals_test_get_int1'), 37)

        meval('$melGlobals_test_get_int1 = 47')
        self.assertEqual(lang.melGlobals.get('$melGlobals_test_get_int1'), 47)

        meval('$melGlobals_test_get_int1 = 57')
        self.assertEqual(lang.MelGlobals.get('melGlobals_test_get_int1'), 57)

        meval('$melGlobals_test_get_int1 = 67')
        self.assertEqual(lang.MelGlobals.get('$melGlobals_test_get_int1'), 67)

    def test_get_int_arr(self):
        meval('global int $melGlobals_test_get_int_arr1[]')

        meval('$melGlobals_test_get_int_arr1 = {1, 2}')
        self.assertEqual(lang.melGlobals.get('melGlobals_test_get_int_arr1'), [1, 2])

        meval('$melGlobals_test_get_int_arr1 = {3, 4}')
        self.assertEqual(lang.melGlobals.get('$melGlobals_test_get_int_arr1'), [3, 4])

        meval('$melGlobals_test_get_int_arr1 = {5, 6}')
        self.assertEqual(lang.MelGlobals.get('melGlobals_test_get_int_arr1'), [5, 6])

        meval('$melGlobals_test_get_int_arr1 = {7, 8}')
        self.assertEqual(lang.MelGlobals.get('$melGlobals_test_get_int_arr1'), [7, 8])

    def test_get_str(self):
        meval('global string $melGlobals_test_get_str1')

        meval('$melGlobals_test_get_str1 = "waldo"')
        self.assertEqual(lang.melGlobals.get('melGlobals_test_get_str1'), 'waldo')

        meval('$melGlobals_test_get_str1 = "marcy"')
        self.assertEqual(lang.melGlobals.get('$melGlobals_test_get_str1'), 'marcy')

        meval('$melGlobals_test_get_str1 = "may"')
        self.assertEqual(lang.MelGlobals.get('melGlobals_test_get_str1'), 'may')

        meval('$melGlobals_test_get_str1 = "marlene"')
        self.assertEqual(lang.MelGlobals.get('$melGlobals_test_get_str1'), 'marlene')

    def test_get_str_arr(self):
        meval('global string $melGlobals_test_get_str_arr1[]')

        meval('$melGlobals_test_get_str_arr1 = {"waldo", "funk"}')
        self.assertEqual(lang.melGlobals.get('melGlobals_test_get_str_arr1'), ["waldo", "funk"])

        meval('$melGlobals_test_get_str_arr1 = {"marcy", "jazz"}')
        self.assertEqual(lang.melGlobals.get('$melGlobals_test_get_str_arr1'), ["marcy", "jazz"])

        meval('$melGlobals_test_get_str_arr1 = {"may", "rock"}')
        self.assertEqual(lang.MelGlobals.get('melGlobals_test_get_str_arr1'), ["may", "rock"])

        meval('$melGlobals_test_get_str_arr1 = {"marlene", "trip-hop"}')
        self.assertEqual(lang.MelGlobals.get('$melGlobals_test_get_str_arr1'), ["marlene", "trip-hop"])

    def test_getitem_int(self):
        meval('global int $melGlobals_test_getitem_int1')

        meval('$melGlobals_test_getitem_int1 = 37')
        self.assertEqual(lang.melGlobals['melGlobals_test_getitem_int1'], 37)

        meval('$melGlobals_test_getitem_int1 = 47')
        self.assertEqual(lang.melGlobals['$melGlobals_test_getitem_int1'], 47)

    def test_getitem_str(self):
        meval('global string $melGlobals_test_getitem_str1')

        meval('$melGlobals_test_getitem_str1 = "waldo"')
        self.assertEqual(lang.melGlobals.get('melGlobals_test_getitem_str1'), 'waldo')

        meval('$melGlobals_test_getitem_str1 = "marcy"')
        self.assertEqual(lang.melGlobals.get('$melGlobals_test_getitem_str1'), 'marcy')

        meval('$melGlobals_test_getitem_str1 = "may"')
        self.assertEqual(lang.MelGlobals.get('melGlobals_test_getitem_str1'), 'may')

        meval('$melGlobals_test_getitem_str1 = "marlene"')
        self.assertEqual(lang.MelGlobals.get('$melGlobals_test_getitem_str1'), 'marlene')

    def test_initVar_int(self):
        self.assertRaises(RuntimeError, meval, 'print $melGlobals_test_initVar_int1')
        lang.melGlobals.initVar('int', 'melGlobals_test_initVar_int1')
        meval('print $melGlobals_test_initVar_int1')

        self.assertRaises(RuntimeError, meval, 'print $melGlobals_test_initVar_int2')
        lang.melGlobals.initVar('int', '$melGlobals_test_initVar_int2')
        meval('print $melGlobals_test_initVar_int2')

        self.assertRaises(RuntimeError, meval, 'print $melGlobals_test_initVar_int3')
        lang.MelGlobals.initVar('int', 'melGlobals_test_initVar_int3')
        meval('print $melGlobals_test_initVar_int3')

        self.assertRaises(RuntimeError, meval, 'print $melGlobals_test_initVar_int4')
        lang.MelGlobals.initVar('int', '$melGlobals_test_initVar_int4')
        meval('print $melGlobals_test_initVar_int4')

    def test_initVar_str(self):
        self.assertRaises(RuntimeError, meval, 'print $melGlobals_test_initVar_str1')
        lang.melGlobals.initVar('string', 'melGlobals_test_initVar_str1')
        meval('print $melGlobals_test_initVar_str1')

        self.assertRaises(RuntimeError, meval, 'print $melGlobals_test_initVar_str2')
        lang.melGlobals.initVar('string', '$melGlobals_test_initVar_str2')
        meval('print $melGlobals_test_initVar_str2')

        self.assertRaises(RuntimeError, meval, 'print $melGlobals_test_initVar_str3')
        lang.MelGlobals.initVar('string', 'melGlobals_test_initVar_str3')
        meval('print $melGlobals_test_initVar_str3')

        self.assertRaises(RuntimeError, meval, 'print $melGlobals_test_initVar_str4')
        lang.MelGlobals.initVar('string', '$melGlobals_test_initVar_str4')
        meval('print $melGlobals_test_initVar_str4')

    def test_getType_int(self):
        meval('global int $melGlobals_test_getType_int1')
        self.assertEqual(lang.melGlobals.getType('melGlobals_test_getType_int1'),
                         'int')

        meval('global int $melGlobals_test_getType_int2')
        self.assertEqual(lang.melGlobals.getType('$melGlobals_test_getType_int2'),
                         'int')

        meval('global int $melGlobals_test_getType_int3')
        self.assertEqual(lang.MelGlobals.getType('melGlobals_test_getType_int3'),
                         'int')

        meval('global int $melGlobals_test_getType_int4')
        self.assertEqual(lang.MelGlobals.getType('$melGlobals_test_getType_int4'),
                         'int')

    def test_getType_str(self):
        meval('global string $melGlobals_test_getType_str1')
        self.assertEqual(lang.melGlobals.getType('melGlobals_test_getType_str1'),
                         'string')

        meval('global string $melGlobals_test_getType_str2')
        self.assertEqual(lang.melGlobals.getType('$melGlobals_test_getType_str2'),
                         'string')

        meval('global string $melGlobals_test_getType_str3')
        self.assertEqual(lang.MelGlobals.getType('melGlobals_test_getType_str3'),
                         'string')

        meval('global string $melGlobals_test_getType_str4')
        self.assertEqual(lang.MelGlobals.getType('$melGlobals_test_getType_str4'),
                         'string')

    def test_keys(self):
        self.assertFalse('$melGlobals_test_keys_int1' in lang.melGlobals.keys())
        meval('global int $melGlobals_test_keys_int1')
        self.assertTrue('$melGlobals_test_keys_int1' in lang.melGlobals.keys())
        self.assertFalse('melGlobals_test_keys_int1' in lang.melGlobals.keys())

        self.assertFalse('$melGlobals_test_keys_int2' in lang.MelGlobals.keys())
        meval('global int $melGlobals_test_keys_int2')
        self.assertTrue('$melGlobals_test_keys_int2' in lang.MelGlobals.keys())
        self.assertFalse('melGlobals_test_keys_int2' in lang.MelGlobals.keys())

        self.assertFalse('$melGlobals_test_keys_str1' in lang.melGlobals.keys())
        meval('global string $melGlobals_test_keys_str1')
        self.assertTrue('$melGlobals_test_keys_str1' in lang.melGlobals.keys())
        self.assertFalse('melGlobals_test_keys_str1' in lang.melGlobals.keys())

        self.assertFalse('$melGlobals_test_keys_str2' in lang.MelGlobals.keys())
        meval('global string $melGlobals_test_keys_str2')
        self.assertTrue('$melGlobals_test_keys_str2' in lang.MelGlobals.keys())
        self.assertFalse('melGlobals_test_keys_str2' in lang.MelGlobals.keys())

    def test_noInit_set(self):
        self.assertRaises(TypeError, lang.melGlobals.set, 'melGlobals_test_nonexistant1', 37)
        self.assertRaises(TypeError, lang.melGlobals.set, 'melGlobals_test_nonexistant2', 'foo')

    def test_noInit_setitem(self):
        self.assertRaises(TypeError, lang.melGlobals.__setitem__, 'melGlobals_test_nonexistant3', 37)
        self.assertRaises(TypeError, lang.melGlobals.__setitem__, 'melGlobals_test_nonexistant4', 'foo')

    def test_noInit_get(self):
        self.assertRaises(KeyError, lang.melGlobals.get, 'melGlobals_test_nonexistant5')

    def test_noInit_getitem(self):
        self.assertRaises(KeyError, lang.melGlobals.__getitem__, 'melGlobals_test_nonexistant6')

    def test_noInit_getType(self):
        self.assertRaises(TypeError, lang.melGlobals.getType, 'melGlobals_test_nonexistant7')


class testCase_env(unittest.TestCase):
    def setUp(self):
        cmds.playbackOptions(animationStartTime=1)
        cmds.playbackOptions(minTime=4)
        cmds.playbackOptions(maxTime=10)
        cmds.playbackOptions(animationEndTime=24)

    def test_animStartTime_property(self):
        self.assertEqual(1, lang.env.animStartTime)
        lang.env.animStartTime = 2
        self.assertEqual(2, lang.env.animStartTime)

    def test_animStartTime_methods(self):
        self.assertEqual(1, lang.env.getAnimStartTime())
        lang.env.setAnimStartTime(3)
        self.assertEqual(3, lang.env.getAnimStartTime())

    def test_minTime_property(self):
        self.assertEqual(4, lang.env.minTime)
        lang.env.minTime = 5
        self.assertEqual(5, lang.env.minTime)

    def test_minTime_methods(self):
        self.assertEqual(4, lang.env.getMinTime())
        lang.env.setMinTime(6)
        self.assertEqual(6, lang.env.getMinTime())

    def test_maxTime_property(self):
        self.assertEqual(10, lang.env.maxTime)
        lang.env.maxTime = 11
        self.assertEqual(11, lang.env.maxTime)

    def test_maxTime_methods(self):
        self.assertEqual(10, lang.env.getMaxTime())
        lang.env.setMaxTime(12)
        self.assertEqual(12, lang.env.getMaxTime())

    def test_animEndTime_property(self):
        self.assertEqual(24, lang.env.animEndTime)
        lang.env.animEndTime = 22
        self.assertEqual(22, lang.env.animEndTime)

    def test_animEndTime_methods(self):
        self.assertEqual(24, lang.env.getAnimEndTime())
        lang.env.setAnimEndTime(23)
        self.assertEqual(23, lang.env.getAnimEndTime())

    def test_playbackTimes_property(self):
        self.assertEqual((1, 4, 10, 24), lang.env.playbackTimes)
        lang.env.playbackTimes = (2, 5, 11, 22)
        self.assertEqual((2, 5, 11, 22), lang.env.playbackTimes)

    def test_playbackTimes_methods(self):
        self.assertEqual((1, 4, 10, 24), lang.env.getPlaybackTimes())
        lang.env.setPlaybackTimes((3, 6, 12, 23))
        self.assertEqual((3, 6, 12, 23), lang.env.getPlaybackTimes())

########NEW FILE########
__FILENAME__ = test_mayaBugs
import sys
import os
import unittest
import maya.cmds as cmds
import maya.OpenMaya as om
import maya.OpenMayaAnim as oma
import maya.OpenMayaFX as omfx

import pymel.versions
from pymel.util.testing import TestCaseExtended

if not hasattr(cmds, 'about'):
    import maya.standalone
    maya.standalone.initialize()

#===============================================================================
# Current Bugs
#===============================================================================

# For CURRENT bugs, we PASS is the bug is still present, and FAIL if it goes
# away... this may be counter-intuitive, but it acts as an alert if a bug is
# fixed (so we can possibly get rid of yucky work-around code...)

# Bug report 378211
class TestConstraintAngleOffsetQuery(TestCaseExtended):
    def setUp(self):
        cmds.file(new=1, f=1)

    def runTest(self):
        for cmdName in ('aimConstraint', 'orientConstraint'):
            cube1 = cmds.polyCube()[0]
            cube2 = cmds.polyCube()[0]

            cmd = getattr(cmds, cmdName)
            constraint = cmd(cube1, cube2)[0]

            setVals = (12, 8, 7)
            cmd(constraint, e=1, offset=setVals)
            getVals = tuple(cmd(constraint, q=1, offset=1))

            # self.assertVectorsEqual(setVals, getVals)

            # check that things are BAD!
            try:
                self.assertVectorsEqual(setVals, getVals)
            except AssertionError:
                pass
            else:
                self.fail("TestConstraintAngleOffsetQuery was fixed! Huzzah!")

# Bug report 378192
class TestEmptyMFnNurbsCurve(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)

    def runTest(self):
        shapeStr = cmds.createNode('nurbsCurve', n="RigWorldShape")
        selList = om.MSelectionList()
        selList.add(shapeStr)
        node = om.MObject()
        selList.getDependNode(0, node)

        mnc = om.MFnNurbsCurve()
        self.assertTrue(mnc.hasObj(node))
#         try:
#             mnc.setObject(node)
#         except Exception:
#             self.fail("MFnNurbs curve doesn't work with empty curve object")

        # check that things are BAD!
        try:
            mnc.setObject(node)
        except Exception:
            pass
        else:
            self.fail("MFnNurbs curve now works with empty curve objects! Yay!")



# Bug report 344037
class TestSurfaceRangeDomain(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)

    def runTest(self):
        try:
            # create a nurbs sphere
            mySphere = cmds.sphere()[0]
            # a default sphere should have u/v
            # parameter ranges of 0:4/0:8

            # The following selections should
            # result in one of these:
            desiredResults = ('nurbsSphere1.u[2:3][0:8]',
                              'nurbsSphere1.u[2:3][*]',
                              'nurbsSphere1.u[2:3]',
                              'nurbsSphere1.uv[2:3][0:8]',
                              'nurbsSphere1.uv[2:3][*]',
                              'nurbsSphere1.uv[2:3]',
                              'nurbsSphere1.v[0:8][2:3]',
                              'nurbsSphere1.v[*][2:3]')


            # Passes
            cmds.select('nurbsSphere1.u[2:3][*]')
            self.assertTrue(cmds.ls(sl=1)[0] in desiredResults)

            # Passes
            cmds.select('nurbsSphere1.v[*][2:3]')
            self.assertTrue(cmds.ls(sl=1)[0] in desiredResults)

            # Fails! - returns 'nurbsSphere1.u[2:3][0:1]'
            cmds.select('nurbsSphere1.u[2:3]')
            self.assertTrue(cmds.ls(sl=1)[0] in desiredResults)

            # Fails! - returns 'nurbsSphere1.u[2:3][0:1]'
            cmds.select('nurbsSphere1.uv[2:3][*]')
            self.assertTrue(cmds.ls(sl=1)[0] in desiredResults)

            # The following selections should
            # result in one of these:
            desiredResults = ('nurbsSphere1.u[0:4][2:3]',
                              'nurbsSphere1.u[*][2:3]',
                              'nurbsSphere1.uv[0:4][2:3]',
                              'nurbsSphere1.uv[*][2:3]',
                              'nurbsSphere1.v[2:3][0:4]',
                              'nurbsSphere1.v[2:3][*]',
                              'nurbsSphere1.v[2:3]')

            # Passes
            cmds.select('nurbsSphere1.u[*][2:3]')
            self.assertTrue(cmds.ls(sl=1)[0] in desiredResults)

            # Passes
            cmds.select('nurbsSphere1.v[2:3][*]')
            self.assertTrue(cmds.ls(sl=1)[0] in desiredResults)

            # Fails! - returns 'nurbsSphereShape1.u[0:1][2:3]'
            cmds.select('nurbsSphere1.v[2:3]')
            self.assertTrue(cmds.ls(sl=1)[0] in desiredResults)

            # Fails! - returns 'nurbsSphereShape1.u[0:4][0:1]'
            cmds.select('nurbsSphere1.uv[*][2:3]')
            self.assertTrue(cmds.ls(sl=1)[0] in desiredResults)
        except AssertionError:
            pass
        else:
            # check that things are BAD!
            self.fail("Nurbs surface range domain bug fixed!")


# Bug report 345384

# This bug only seems to affect windows (or at least, Win x64 -
# haven't tried on 32-bit).
class TestMMatrixSetAttr(unittest.TestCase):
    def setUp(self):
        # pymel essentially fixes this bug by wrapping
        # the api's __setattr__... so undo this before testing
        if 'pymel.internal.factories' in sys.modules:
            factories = sys.modules['pymel.internal.factories']
            self.origSetAttr = factories.MetaMayaTypeWrapper._originalApiSetAttrs.get(om.MMatrix, None)
        else:
            self.origSetAttr = None
        if self.origSetAttr:
            self.fixedSetAttr = om.MMatrix.__setattr__
            om.MMatrix.__setattr__ = self.origSetAttr
        cmds.file(new=1, f=1)

    def runTest(self):
        # We expect it to fail on windows, and pass on other operating systems...
        shouldPass = os.name != 'nt'
        try:
            class MyClass1(object):
                def __init__(self):
                    self._bar = 'not set'

                def _setBar(self, val):
                    print "setting bar to:", val
                    self._bar = val
                def _getBar(self):
                    print "getting bar..."
                    return self._bar
                bar = property(_getBar, _setBar)

                # These two are just so we can trace what's going on...
                def __getattribute__(self, name):
                    # don't just use 'normal' repr, as that will
                    # call __getattribute__!
                    print "__getattribute__(%s, %r)" % (object.__repr__(self), name)
                    return super(MyClass1, self).__getattribute__(name)
                def __setattr__(self, name, val):
                    print "__setattr__(%r, %r, %r)" % (self, name, val)
                    return super(MyClass1, self).__setattr__(name, val)

            foo1 = MyClass1()
            # works like we expect...
            foo1.bar = 7
            print "foo1.bar:", foo1.bar
            self.assertTrue(foo1.bar == 7)


            class MyClass2(MyClass1, om.MMatrix): pass

            foo2 = MyClass2()
            foo2.bar = 7
            # Here, on windows, MMatrix's __setattr__ takes over, and
            # (after presumabably determining it didn't need to do
            # whatever special case thing it was designed to do)
            # instead of calling the super's __setattr__, which would
            # use the property, inserts it into the object's __dict__
            # manually
            print "foo2.bar:", foo2.bar
            self.assertTrue(foo2.bar == 7)
        except Exception:
            if shouldPass:
                raise
        else:
            if not shouldPass:
                self.fail("MMatrix setattr bug seems to have been fixed!")


    def tearDown(self):
        # Restore the 'fixed' __setattr__'s
        if self.origSetAttr:
            om.MMatrix.__setattr__ = self.fixedSetAttr

# Introduced in maya 2014
# Change request #: BSPR-12597
if pymel.versions.current() >= pymel.versions.v2014:
    class TestShapeParentInstance(unittest.TestCase):
        def setUp(self):
            cmds.file(new=1, f=1)

        def runTest(self):
            try:
                import maya.cmds as cmds

                def getShape(trans):
                    return cmds.listRelatives(trans, children=True, shapes=True)[0]

                cmds.file(new=1, f=1)
                shapeTransform = cmds.polyCube(name='singleShapePoly')[0]
                origShape = getShape(shapeTransform)
                dupeTransform1 = cmds.duplicate(origShape, parentOnly=1)[0]
                cmds.parent(origShape, dupeTransform1, shape=True, addObject=True, relative=True)
                dupeTransform2 = cmds.duplicate(dupeTransform1)[0]
                cmds.delete(dupeTransform1)
                dupeShape = getShape(dupeTransform2)

                # In maya 2014, this raises:
                # Error: Connection not made: 'singleShapePolyShape2.instObjGroups[1]' -> 'initialShadingGroup.dagSetMembers[2]'. Source is not connected.
                # Connection not made: 'singleShapePolyShape2.instObjGroups[1]' -> 'initialShadingGroup.dagSetMembers[2]'. Destination attribute must be writable.
                # Connection not made: 'singleShapePolyShape2.instObjGroups[1]' -> 'initialShadingGroup.dagSetMembers[2]'. Destination attribute must be writable.
                # Traceback (most recent call last):
                # File "<maya console>", line 13, in <module>
                # RuntimeError: Connection not made: 'singleShapePolyShape2.instObjGroups[1]' -> 'initialShadingGroup.dagSetMembers[2]'. Source is not connected.
                # Connection not made: 'singleShapePolyShape2.instObjGroups[1]' -> 'initialShadingGroup.dagSetMembers[2]'. Destination attribute must be writable.
                # Connection not made: 'singleShapePolyShape2.instObjGroups[1]' -> 'initialShadingGroup.dagSetMembers[2]'. Destination attribute must be writable. #

                cmds.parent(dupeShape, shapeTransform, shape=True, addObject=True, relative=True)
            except Exception:
                pass
            else:
                self.fail("ShapeParentInstance bug fixed!")


#===============================================================================
# Current bugs that will cause Maya to CRASH (and so are commented out!)
#===============================================================================

# This is commented out as it will cause a CRASH - uncomment out (or just
# copy/ paste the relevant code into the script editor) to test if it's still
# causing a crash...

# If you're copy / pasting into a script editor, in order for a crash to occur,
# all lines must be executed at once - if you execute one at a time, there will
# be no crash

# Also, I'm making the code in each of the test functions self-contained (ie,
# has all imports, etc) for easy copy-paste testing...

#class TestSubdivSelectCrash(unittest.TestCas):
#    def testCmds(self):
#        import maya.cmds as cmds
#        cmds.file(new=1, f=1)
#        polyCube = cmds.polyCube()[0]
#        subd = cmds.polyToSubdiv(polyCube)[0]
#        cmds.select(subd + '.sme[*][*]')
#
#    def testApi(self):
#        import maya.cmds as cmds
#        import maya.OpenMaya as om
#
#        polyCube = cmds.polyCube()[0]
#        subd = cmds.polyToSubdiv(polyCube)[0]
#        selList = om.MSelectionList()
#        selList.add(subd + '.sme[*][*]')



#===============================================================================
# FIXED (Former) Bugs
#===============================================================================

# Fixed in Maya 2009! yay!
class TestConstraintVectorQuery(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)

    def _doTestForConstraintType(self, constraintType):
        cmd = getattr(cmds, constraintType)

        if constraintType == 'tangentConstraint':
            target = cmds.circle()[0]
        else:
            target = cmds.polyCube()[0]
        constrained = cmds.polyCube()[0]

        constr = cmd(target, constrained)[0]

        self.assertEqual(cmd(constr, q=1, worldUpVector=1), [0,1,0])
        self.assertEqual(cmd(constr, q=1, upVector=1), [0,1,0])
        self.assertEqual(cmd(constr, q=1, aimVector=1), [1,0,0])

    def test_aimConstraint(self):
        self._doTestForConstraintType('aimConstraint')

    def test_normalConstraint(self):
        self._doTestForConstraintType('normalConstraint')

    def test_tangentConstraint(self):
        self._doTestForConstraintType('tangentConstraint')

# Fixed ! Yay!  (...though I've only check on win64...)
# (not sure when... was fixed by time of 2011 Hotfix 1 - api 201101,
# and still broken in 2009 SP1a - api 200906)
class TestMatrixSetAttr(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)
        res = cmds.sphere(n='node')
        cmds.addAttr(ln='matrixAttr',dt="matrix")

    def runTest(self):
        cmds.setAttr( 'node.matrixAttr', 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, type='matrix' )

# Bug report 345382
# Fixed ! Yay!  (...though I've only check on win64...)
# (not sure when... was fixed by time of 2011 Hotfix 1 - api 201101,
# and still broken in 2009 SP1a - api 200906)
class TestFluidMFnCreation(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)

    def runTest(self):
        fluid = cmds.createNode('fluidShape')
        selList = om.MSelectionList()
        selList.add(fluid)
        dag = om.MDagPath()
        selList.getDagPath(0, dag)
        omfx.MFnFluid(dag)

# nucleus node fixed in 2014
# symmetryConstraint fixed in 2015
class TestMFnCompatibility(unittest.TestCase):
    def setUp(self):
        cmds.file(new=1, f=1)

    def _assertInheritMFnConistency(self, nodeType, parentNodeType, mfnType):
        nodeInstName = cmds.createNode(nodeType)
        selList = om.MSelectionList()
        selList.add(nodeInstName)
        mobj = om.MObject()
        selList.getDependNode(0, mobj)

        self.assertTrue(parentNodeType in cmds.nodeType(nodeInstName, inherited=True))
        try:
            mfnType(mobj)
        except Exception, e:
            raise self.fail("Error creating %s even though %s inherits from %s: %s" %
                            (mfnType.__name__, nodeType, parentNodeType, e))

    def test_nucleus_MFnDagNode(self):
        self._assertInheritMFnConistency('nucleus', 'dagNode', om.MFnDagNode)

    def test_nucleus_MFnTransform(self):
        self._assertInheritMFnConistency('nucleus', 'transform', om.MFnTransform)

    def test_symmetryConstraint_test_nucleus_MFnDagNode(self):
        self._assertInheritMFnConistency('symmetryConstraint', 'dagNode', om.MFnDagNode)

    def test_symmetryConstraint_MFnTransform(self):
        self._assertInheritMFnConistency('symmetryConstraint', 'transform',
                                         om.MFnTransform)

    # These probably aren't strictly considered "bugs" by autodesk, though I
    # think they should be...
#    def test_hikHandle_MFnIkHandle(self):
#        self._assertInheritMFnConistency('hikHandle', 'ikHandle', oma.MFnIkHandle)
#
#    def test_jointFfd_MFnLatticeDeformer(self):
#        self._assertInheritMFnConistency('jointFfd', 'ffd', oma.MFnLatticeDeformer)
#
#    def test_transferAttributes_MFnWeightGeometryFilter(self):
#        self._assertInheritMFnConistency('transferAttributes', 'weightGeometryFilter', oma.MFnWeightGeometryFilter)
#
#    def test_transferAttributes_MFnGeometryFilter(self):
#        self._assertInheritMFnConistency('transferAttributes', 'geometryFilter', oma.MFnGeometryFilter)


# Fixed in 2014! yay!
class TestGroupUniqueness(unittest.TestCase):
    '''Test to check whether cmds.group returns a unique name
    '''
    def setUp(self):
        cmds.file(new=1, f=1)

    def runTest(self):
        cmds.select(cl=1)
        cmds.group(n='foo', empty=1)
        cmds.group(n='bar')
        cmds.select(cl=1)
        res = cmds.group(n='foo', empty=1)
        sameNames = cmds.ls(res)
        if len(sameNames) < 1:
            self.fail('cmds.group did not return a valid name')
        elif len(sameNames) > 1:
            self.fail('cmds.group did not return a unique name')



########NEW FILE########
__FILENAME__ = test_mayaIntegration
import os
import sys
import maya.utils
import traceback
import unittest
import re
import pymel.versions

import shutil
import string

thisFile = os.path.basename(__file__)

# don't want to bother matching on directories, because they can have
# relative paths, like '../myfile.py'
fileReStr = r'(?:(?:(?P<dir>[^\n]*?)(?P<file>[^\n/\\]*)\.pyc?)|(?P<special_file><maya console>|<string>))'
fileLineRe1 = re.compile(r'file %s line \d+' % fileReStr)
fileLineRe2 = re.compile(r'File "%s", line \d+' % fileReStr)

def replacePath(match):
    groups = match.groupdict()
    file = groups.get('file', '')
    if file:
        dir = groups.get('dir', '')
        if dir:
            dir = '<py_dir>/'
        path = '%s%s.py' % (dir, file)
    else:
        path = groups['special_file']
    return path

def fileLineReplacer1(match):
    return 'file %s line <lineno>' % replacePath(match)

def fileLineReplacer2(match):
    return 'File "%s", line <lineno>' % replacePath(match)


errorCodes = [
( 'shutil.move("this_does_not_exist.txt", "this_either.txt")',
(
"""IOError: [Errno 2] No such file or directory: 'this_does_not_exist.txt'""",
"""IOError: file <py_dir>/shutil.py line <lineno>: [Errno 2] No such file or directory: 'this_does_not_exist.txt'""",
"""[Errno 2] No such file or directory: 'this_does_not_exist.txt'
# Traceback (most recent call last):
#   File "<maya console>", line <lineno>, in <module>
#   File "<string>", line <lineno>, in <module>
#   File "<py_dir>/shutil.py", line <lineno>, in move
#     copy2(src, real_dst)
#   File "<py_dir>/shutil.py", line <lineno>, in copy2
#     copyfile(src, dst)
#   File "<py_dir>/shutil.py", line <lineno>, in copyfile
#     fsrc = open(src, 'rb')
# IOError: [Errno 2] No such file or directory: 'this_does_not_exist.txt'"""
    if sys.version_info[:2] < (2,7) else
"""[Errno 2] No such file or directory: 'this_does_not_exist.txt'
# Traceback (most recent call last):
#   File "<maya console>", line <lineno>, in <module>
#   File "<string>", line <lineno>, in <module>
#   File "<py_dir>/shutil.py", line <lineno>, in move
#     copy2(src, real_dst)
#   File "<py_dir>/shutil.py", line <lineno>, in copy2
#     copyfile(src, dst)
#   File "<py_dir>/shutil.py", line <lineno>, in copyfile
#     with open(src, 'rb') as fsrc:
# IOError: [Errno 2] No such file or directory: 'this_does_not_exist.txt'"""
)),

('foo : bar',
(
"""SyntaxError: invalid syntax""",
"""SyntaxError: file <maya console> line <lineno>: invalid syntax""",
"""invalid syntax
# Traceback (most recent call last):
#   File "<maya console>", line <lineno>, in <module>
#   File "<string>", line <lineno>
#     foo : bar
#         ^
# SyntaxError: invalid syntax"""
)),

("string.join(['one', 'two', 3])",
(
"""TypeError: sequence item 2: expected string, int found""",
"""TypeError: file <py_dir>/string.py line <lineno>: sequence item 2: expected string, int found""",
"""sequence item 2: expected string, int found
# Traceback (most recent call last):
#   File "<maya console>", line <lineno>, in <module>
#   File "<string>", line <lineno>, in <module>
#   File "<py_dir>/string.py", line <lineno>, in join
#     return sep.join(words)
# TypeError: sequence item 2: expected string, int found"""
)),
]


class TestMayaIntegration(unittest.TestCase):
    if pymel.versions.current() >= pymel.versions.v2011:
        import pymel.core
        def test_guiExceptionFormatting(self):
            for codeStr, messages in errorCodes:
                try:
                    eval(codeStr)
                except Exception, e:
                    type, value, traceback = sys.exc_info()
                    for level in range(3):
                        res = maya.utils.formatGuiException(type, value, traceback, level)
                        rawres = res
                        res = fileLineRe1.sub(fileLineReplacer1, res)
                        res = fileLineRe2.sub(fileLineReplacer2, res)
                        res = res.replace('test_guiExceptionFormatting', '<module>')
                        res = res.replace('<py_dir>/test_mayaIntegration.py', '<maya console>')
                        res = res.replace('#     eval(codeStr)\n', '')

                        expected = messages[level]
                        if res != expected:
                            print 'level: %d' % level
                            print '*' * 60
                            print "raw res:"
                            print rawres
                            print '*' * 60

                            print '*' * 60
                            print "res:"
                            print res
                            print '*' * 60

                            print '*' * 60
                            print "expected:"
                            print expected
                            print '*' * 60
                        self.assertEqual( res, expected )
                finally:
                    del traceback

########NEW FILE########
__FILENAME__ = test_mayautils
#import testingutils
import unittest
import pymel.internal.startup

class TestGetMayaVersion(unittest.TestCase):

    versions = ['6', '6.0', '7', '7.0', '8', '8.0', '8.5', '2008', '2009']
    extensions = [1, 2, 2008]
    servicePacks = [1, 2, 3009]
    bits = [32, 64, 1, 16]
    cuts = ['200802242349', '32', '200802242349-3040-2']

    def runTest(self):
        #testingutils.permutations([versions, extensions, servicePacks, bits, cuts])
        pass




########NEW FILE########
__FILENAME__ = test_mel2py
import unittest, sys

import maya.mel
import pymel.core

from pymel.tools.mel2py import mel2pyStr

class TestStrings(unittest.TestCase):
    def assertMelAndPyStringsEqual(self, melString, verbose=False):
        if verbose:
            print "Original mel string:"
            print melString

        #melCmd = '$tempStringVar = %s; print $tempStringVar; $tempStringVar = $tempStringVar;' % melString
        melCmd = '$tempStringVar = %s;' % melString
        strFromMMEval = maya.mel.eval(melCmd)

        if verbose:
            print "Decoded through maya.mel:"
            print strFromMMEval

        exec mel2pyStr(melCmd)
        strFromPy2Mel = tempStringVar

        if verbose:
            print "Decoded through py2mel:"
            print strFromPy2Mel

        self.assertEqual(strFromMMEval, strFromPy2Mel)

    def testBackslashQuoteStrings(self):
        melStrs = [r'''"\\"''',         # "\\" - mel string for: \
                   r'''"\""''',         # "\"" - mel string for: "
                   r'''"\"\""''',       # "\"\"" - mel string for: ""
                   r'''"\\\""''',       # "\\\"" - mel string for: \"
                   r'''"\"\\"''',       # "\"\\" - mel string for: "\
                   r'''"\\\\\""''',     # "\\\\\"" - mel string for: \\"
                   r'''"\\\\\\\""''']   # "\\\\\\\"" - mel string for: \\\"
        for melStr in melStrs:
            self.assertMelAndPyStringsEqual(melStr)

#testingutils.setupUnittestModule(__name__)


########NEW FILE########
__FILENAME__ = test_names
#import testingutils
import unittest
import pymel.core.other, pymel.core.system

class testCase_attribNameParsing(unittest.TestCase):
    def test_attribNameParents(self):
        parser = pymel.core.other.AttributeName("Cube1.multiComp[3].child.otherchild")
        self.assertEqual(parser.getParent(), "Cube1.multiComp[3].child")

        self.assertEqual(parser.getParent(0), parser)
        self.assertEqual(parser.getParent(generations=1), "Cube1.multiComp[3].child")
        self.assertEqual(parser.getParent(2), "Cube1.multiComp[3]")
        self.assertEqual(parser.getParent(generations=3), None)
        self.assertEqual(parser.getParent(-1), "Cube1.multiComp[3]")
        self.assertEqual(parser.getParent(generations=-2), "Cube1.multiComp[3].child")
        self.assertEqual(parser.getParent(-3), parser)
        self.assertEqual(parser.getParent(generations=-4), None)
        self.assertEqual(parser.getParent(-63), None)
        self.assertEqual(parser.getParent(generations=32), None)

class testCase_DagNameParsing(unittest.TestCase):
    def test_attribNameParents(self):
        parser = pymel.core.other.DagNodeName("NS1:TopLevel|Next|ns2:Third|Fourth")
        self.assertEqual(parser.getParent(), "NS1:TopLevel|Next|ns2:Third")

        self.assertEqual(parser.getParent(0), parser)
        self.assertEqual(parser.getParent(generations=1), "NS1:TopLevel|Next|ns2:Third")
        self.assertEqual(parser.getParent(2), "NS1:TopLevel|Next")
        self.assertEqual(parser.getParent(generations=3), "NS1:TopLevel")
        self.assertEqual(parser.getParent(generations=4), None)
        self.assertEqual(parser.getParent(-1), "NS1:TopLevel")
        self.assertEqual(parser.getParent(generations=-2), "NS1:TopLevel|Next")
        self.assertEqual(parser.getParent(-3), "NS1:TopLevel|Next|ns2:Third")
        self.assertEqual(parser.getParent(generations=-4), parser)
        self.assertEqual(parser.getParent(generations=-5), None)
        self.assertEqual(parser.getParent(-63), None)
        self.assertEqual(parser.getParent(generations=32), None)


#testingutils.setupUnittestModule(__name__)
########NEW FILE########
__FILENAME__ = test_nodetypes
import sys
import unittest
import itertools
import re
import platform
import inspect
import math

import maya.cmds as cmds
import pymel.core as pm
import pymel.api as api
from maintenance.pymelControlPanel import getClassHierarchy
import pymel.internal.factories as factories
import pymel.internal.apicache as apicache
import pymel.util.arrays as arrays

from pymel.util.testing import TestCaseExtended, setCompare

VERBOSE = False

class CrashError(Exception):
    """
    Raised to signal that doing something would have caused maya to crash.
    """
    pass


class testCase_attribs(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        self.sphere1, hist = pm.polySphere()

        class AttributeData(object):
            node = self.sphere1

            def __init__(self, name, **initArgs):
                self.name = name
                self.initArgs = initArgs

            def add(self):
                pm.addAttr(self.node, longName=self.name, **self.initArgs)

        self.newAttrs = [
                        AttributeData('angle', attributeType='doubleAngle'),
                        AttributeData('multiByte', multi=True, attributeType='byte'),
                        AttributeData('compound', attributeType='compound', numberOfChildren=3),
                        AttributeData('compound_multiFloat', attributeType='float', multi=True, parent='compound'),
                        AttributeData('compound_double', attributeType='double', parent='compound'),
                        AttributeData('compound_compound', attributeType='compound', numberOfChildren=2, parent='compound'),
                        AttributeData('compound_compound_matrix', attributeType='matrix', parent='compound_compound'),
                        AttributeData('compound_compound_long', attributeType='long', parent='compound_compound'),
                        AttributeData('multiCompound', attributeType='compound', multi=True, numberOfChildren=3),
                        AttributeData('multiCompound_string', dataType='string', parent='multiCompound'),
                        AttributeData('multiCompound_enum', attributeType='enum', parent='multiCompound'),
                        AttributeData('multiCompound_curve', dataType='nurbsCurve', parent='multiCompound'),
                        ]

        self.attrTypes = {}
        for attrData in self.newAttrs:
            attrType = attrData.initArgs.get('attributeType',attrData.initArgs.get('dataType'))
            if attrType == 'compound' or attrData.initArgs.get('multi'):
                attrType = 'TdataCompound'
            self.attrTypes[attrData.name] = attrType

        for attr in self.newAttrs:
            attr.add()

        self.newAttrs = dict([(newAttr.name, pm.Attribute(str(self.sphere1) + "." + newAttr.name)) for newAttr in self.newAttrs ])

        self.setIndices = (1, 3, 5, 12)
        for i in self.setIndices:
            self.newAttrs['multiByte'][i].set(1)

        self.setMultiElement = self.newAttrs['multiByte'][self.setIndices[0]]

        self.unsetMultiElement = self.newAttrs['multiByte'][200]

    def tearDown(self):
        pm.delete(self.sphere1)

    def test_newAttrsExists(self):
        for attrName, attr in self.newAttrs.iteritems():
#            print "Testing existence of:", attr.name()
            if attrName.startswith('multiCompound_'):
                self.assertFalse(attr.exists(), 'attr %r existed' % attr)
            else:
                self.assertTrue(attr.exists(), 'attr %r did not exist' % attr)

    def test_setMultiElementExists(self):
        attr = self.setMultiElement
        self.assertTrue(attr.exists(), '%s should exist' % attr)

    def test_unsetMultiElementExists(self):
        attr = self.unsetMultiElement
        self.assertFalse(attr.exists(), '%s should not exist' % attr)

    def test_setMultiCompoundElementExists(self):
        attr = self.newAttrs['multiCompound'][1].attr('multiCompound_string')
        attr.set('foo')
        self.assertTrue(attr.exists(), '%s should exist' % attr)

    def test_unsetMultiCompoundElementExists(self):
        attr = self.newAttrs['multiCompound'][1].attr('multiCompound_string')
        self.assertFalse(attr.exists())
        attr = self.newAttrs['multiCompound_string']
        self.assertFalse(attr.exists())

    def test_getParent(self):
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(), self.newAttrs['compound_compound'])

        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(0), self.newAttrs['compound_compound_long'])
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(generations=1), self.newAttrs['compound_compound'])
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(2), self.newAttrs['compound'])
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(generations=3), None)
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(-1), self.newAttrs['compound'])
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(generations=-2), self.newAttrs['compound_compound'])
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(-3), self.newAttrs['compound_compound_long'])
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(generations=-4), None)
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(-5), None)
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(generations=4), None)
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(-63), None)
        self.assertEqual(self.newAttrs['compound_compound_long'].getParent(generations=32), None)

        self.assertEqual(self.newAttrs['compound_compound_long'].getAllParents(),
                         [  self.newAttrs['compound_compound'],
                            self.newAttrs['compound'],
                         ])

        self.assertEqual(self.newAttrs['multiCompound_string'].getParent(generations=1).array(),
                         self.newAttrs['multiCompound'])
        self.assertEqual(self.newAttrs['multiCompound_string'].getParent(generations=2, arrays=True),
                         self.newAttrs['multiCompound'])
        self.assertEqual(self.newAttrs['multiCompound_string'].getParent(generations=-1, arrays=True),
                         self.newAttrs['multiCompound'])

        self.assertEqual(self.newAttrs['multiCompound_string'].getAllParents(),
                         [  self.newAttrs['multiCompound_string'].getParent(generations=1),
                         ])
        self.assertEqual(self.newAttrs['multiCompound_string'].getAllParents(arrays=True),
                         [  self.newAttrs['multiCompound_string'].getParent(generations=1),
                            self.newAttrs['multiCompound'],
                         ])

        self.assertEqual(self.newAttrs['multiByte'].getAllParents(), [])
        self.assertEqual(self.newAttrs['multiByte'].getAllParents(arrays=True), [])
        self.assertEqual(self.newAttrs['multiCompound'].getAllParents(), [])
        self.assertEqual(self.newAttrs['multiCompound'].getAllParents(arrays=True), [])
        self.assertEqual(self.newAttrs['multiCompound'].getAllParents(), [])
        self.assertEqual(self.newAttrs['multiCompound'].getAllParents(arrays=True), [])
        self.assertEqual(self.newAttrs['angle'].getAllParents(), [])
        self.assertEqual(self.newAttrs['angle'].getAllParents(arrays=True), [])

    def test_comparison(self):
        for attr in self.newAttrs.itervalues():
            self.assertEqual(attr, pm.PyNode(attr.name()))

    def test_comparisonOtherObject(self):
        self.assertNotEqual(self.newAttrs['compound'], self.sphere1)

    def test_add_delete(self):
        pm.PyNode('persp').addAttr('foo')
        self.assert_( pm.PyNode('persp').hasAttr('foo') )
        pm.PyNode('persp').deleteAttr('foo')
        self.assert_(  not pm.PyNode('persp').hasAttr('foo') )

    def test_elements(self):
        self.assertEqual(self.newAttrs['multiByte'].elements(), ['multiByte[%d]' % x for x in self.setIndices])
        self.assertEqual(self.newAttrs['multiCompound'].elements(), [])
        self.assertEqual(self.newAttrs['compound_multiFloat'].elements(), [])

    def test_iter(self):
        iterList = [x for x in self.newAttrs['multiByte']]
        expectedList = [self.newAttrs['multiByte'][i] for i in self.setIndices]
        self.assertEqual(iterList, expectedList)

    def test_iter_independence(self):
        iter1 = iter(self.newAttrs['multiByte'])
        iter2 = iter(self.newAttrs['multiByte'])
        zipped = zip(iter1, iter2)
        self.assertEqual(zipped, [ (self.newAttrs['multiByte'][i],
                                    self.newAttrs['multiByte'][i])
                                   for i in self.setIndices ])

    def test_settable(self):

        def testLockUnlock(attr, child=None):
            if child is None:
                attr.lock()
                self.assertFalse(attr.isSettable(), '%s was locked - should be unsettable' % attr)
                attr.unlock()
                self.assertTrue(attr.isSettable(), '%s was unlocked - should be settable' % attr)
            else:
                child.lock()
                self.assertFalse(child.isSettable(), '%s was locked - should be unsettable' % child)
                self.assertFalse(attr.isSettable(), '%s had locked child- should be unsettable' % attr)
                child.unlock()
                self.assertTrue(child.isSettable(), '%s was unlocked - should be settable' % attr)
                self.assertTrue(attr.isSettable(), '%s had unlocked child - should be settable' % attr)

        for attr in self.newAttrs.itervalues():
            if not attr.exists():
                continue

            testLockUnlock(attr)

            if attr.isMulti():
                child = attr[0]
                testLockUnlock(attr, child)
                if attr.isCompound():
                    multi_child = child.children()[0]
                    testLockUnlock(attr, child)
                    testLockUnlock(attr, multi_child)
            elif attr.isCompound():
                testLockUnlock(attr, attr.children()[0])

    def test_attr_type(self):
        for attrName, attrType in self.attrTypes.iteritems():
            self.assertEqual(self.newAttrs[attrName].type(), attrType)
        self.assertEqual(self.newAttrs['multiCompound'].numElements(), 0)
        self.assertEqual(self.newAttrs['multiByte'].numElements(), len(self.setIndices))

        # Try some non-dynamic attrs...
        self.assertEqual(self.sphere1.attr('translateX').type(), 'doubleLinear')
        self.assertEqual(self.sphere1.attr('translate').type(), 'double3')
        self.assertEqual(self.sphere1.attr('message').type(), 'message')

        # Try a more unusual attr type...
        circleMaker = pm.circle()[1]
        self.assertEqual(circleMaker.attr('outputCurve').type(), 'nurbsCurve')

class testCase_invertibles(unittest.TestCase):
    EXCEPTIONS = [
                  'MotionPath',   # setUEnd causes maya to crash
                  'OldBlindDataBase',
                  'TextureToGeom'
                 ]

    GETTER_SKIPS = [
                    # calling setAbsoluteChannelSettings([1,2,3]) will
                    # effectively set the number of channels to three, and
                    # calling setAbsoluteChannelSettings([0]) does not set it
                    # back to 1... and there doesn't seem to be a way to set it
                    # back to 1 channel... forgiving this because I'm assuming
                    # that the number of channels isn't "supposed" to change
                    ('AnimClip', 'getAbsoluteChannelSettings'),

                    # calling setExpression seems to trigger some sort of mel
                    # callback - if you check cmds.undoInfo(q=1, printQueue=1),
                    # it shows a call like:
                    #   expression -e -ae 0  -o ""  -a ""  -s "" expression1;
                    # ...that happens after the apiUndo.cmdCount increment

                    # Could wrap the adding of the apiUndo item and actual
                    # execution of the cmd into a single undo chunk, but I'm
                    # worried about unforeseen consequences... going to forgive,
                    # since it will undo correctly, it just takes one more
                    # undo than expected (which is often the case with mel
                    # callbacks...)
                    ('Expression', 'isAnimated'),
                   ]

    class GetTypedArgError(Exception): pass

    @classmethod
    def getTypedArg(cls, type):
        typeMap = {
            'bool' : True,
            'double' : 2.5, # min required for setFocalLength
            'double3' : ( 1.0, 2.0, 3.0),
            'MEulerRotation' : ( 1.0, 2.0, 3.0),
            'float': 2.5,
            'MFloatArray': [1.1, 2.2, 3.3],
            'MString': 'thingie',
            'float2': (.1, .2),
            'MPoint' : [1,2,3],
            'short': 1,
            'MColor' : [1,0,0],
            'MColorArray': ( [1.0,0.0,0.0], [0.0,1.0,0.0], [0.0,0.0,1.0] ),
            'MVector' : [1,0,0],
            'MVectorArray': ( [1.0,0.0,0.0], [0.0,1.0,0.0], [0.0,0.0,1.0] ),
            'int' : 1,
            'MIntArray': [1,2,3],
            'MSpace.Space' : 'world'
        }
        if '.' in type:
            return 1 # take a dumb guess at an enum
        else:
            try:
                return typeMap[type]
            except KeyError:
                raise cls.GetTypedArgError(type)

    @classmethod
    def setattrUnique(cls, name, obj):
        uniqueName = name
        i = 1
        while hasattr(cls, uniqueName):
            i += 1
            uniqueName = '%s%s' % (name, i)
        #print "%s.%s = %r" % (cls.__name__, uniqueName, obj)
        setattr(cls, uniqueName, obj)
        return uniqueName

    @classmethod
    def _getMethodAndArgTypes(cls, basePyClass, pyClassName, apiClassName,
                       classInfo, methodName):
        try:
            info = classInfo['methods'][methodName]
        except KeyError:
            return None
        try:
            methodName = info[0]['pymelName']
        except KeyError:
            pass

        methodName, data = factories._getApiOverrideNameAndData( pyClassName, methodName )
        try:
            overloadIndex = data['overloadIndex']
            info = info[overloadIndex]
        except (KeyError, TypeError):
            return None
        # test if this invertible has been broken in pymelControlPanel
        if not info.get('inverse', True):
            return None
        try:
            method = getattr( basePyClass, methodName )
        except AttributeError:
            return None
        inArgs = [ arg for arg in info['inArgs'] if arg not in info['defaults'] ]
        argTypes = [ str(info['types'][arg]) for arg in inArgs ]
        return method, argTypes

    @classmethod
    def addTests(cls):
        pyNodes = inspect.getmembers(pm.nodetypes,
                                     lambda x: inspect.isclass(x) and issubclass(x, pm.PyNode))

        realNodes = apicache._getRealMayaTypes(noPlugins=True)
        realPyNodes = [node for name, node in pyNodes if node.__melnode__ in realNodes]

        for pynode in realPyNodes:
            # for some reason, we sometimes return the same method twice...?
            # ensure we don't make 2 tests for it...
            methods = set()

            pynodeName = pynode.__name__
            if pynodeName in cls.EXCEPTIONS:
                continue

            for className, apiClassName in getClassHierarchy(pynodeName):
                if apiClassName not in factories.apiClassInfo:
                    continue

                #print className, apiClassName

                classInfo = factories.apiClassInfo[apiClassName]
                invertibles = classInfo['invertibles']
                #print invertibles

                for setMethod, getMethod in invertibles:
                    setMethodData = cls._getMethodAndArgTypes(pynode, className,
                                                              apiClassName,
                                                              classInfo,
                                                              setMethod)
                    if setMethodData is None:
                        continue
                    else:
                        setter, setArgTypes = setMethodData
                    if setter in methods:
                        continue
                    else:
                        methods.add(setter)

                    getter = None
                    if (pynodeName, getMethod) not in cls.GETTER_SKIPS:
                        getMethodData = cls._getMethodAndArgTypes(pynode, className,
                                                                  apiClassName,
                                                                  classInfo,
                                                                  getMethod)
                        if getMethodData:
                            getter, getArgTypes = getMethodData
                            if getArgTypes:
                                # if the getter requires args, don't bother testing
                                # it
                                getter = None

                    newTestMethod = cls.makeInvertTest(pynode, apiClassName,
                                                       setMethod, setter,
                                                       getter, setArgTypes)
                    cls.setattrUnique(newTestMethod.__name__, newTestMethod)

    @classmethod
    def makeInvertTest(cls, pynode, apiClassName, setMethod, setter, getter,
                       setArgTypes):
        def testInvert(self):
            print "testing %s.%s" % (pynode.__name__, setMethod)
            sys.stdout.flush()
            sys.stdout.flush()
            melnodeName = pynode.__melnode__
            if issubclass(pynode, pm.nt.GeometryShape):
                if pynode == pm.nt.Mesh :
                    obj = pm.polyCube()[0].getShape()
                    obj.createColorSet( 'thingie' )
                elif pynode == pm.nt.Subdiv:
                    obj = pm.polyToSubdiv( pm.polyCube()[0].getShape())[0].getShape()
                elif pynode == pm.nt.NurbsSurface:
                    obj = pm.sphere()[0].getShape()
                elif pynode == pm.nt.NurbsCurve:
                    obj = pm.circle()[0].getShape()
                else:
                    print "skipping shape", pynode
                    return
            else:
                #print "creating: %s" % melnodeName
                obj = pm.createNode( melnodeName )

            try:
                try:
                    if apiClassName == 'MFnMesh' and setMethod == 'setUVs':
                        args = [ [.1]*obj.numUVs(), [.2]*obj.numUVs() ]
                    elif apiClassName == 'MFnMesh' and setMethod == 'setColors':
                        args = [ [ [.5,.5,.5] ]*obj.numColors() ]
                    elif apiClassName == 'MFnMesh' and setMethod == 'setColor':
                        obj.setColors( [ [.5,.5,.5] ]*obj.numVertices() )
                        args = [ 1, [1,0,0] ]
                    elif apiClassName == 'MFnMesh' and setMethod in ['setFaceVertexColors', 'setVertexColors']:
                        obj.createColorSet(setMethod + '_ColorSet' )
                        args = [ ([1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]), [1, 2, 3] ]

                    elif apiClassName == 'MFnNurbsCurve' and setMethod == 'setKnot':
                        args = [ 6, 4.5 ]
                    else:
                        args = [ self.getTypedArg(typ) for typ in setArgTypes ]
                    #descr =  '%s.%s(%s)' % ( pynodeName, setMethod, ', '.join( [ repr(x) for x in args] ) )
                    args = [obj] + args

                    if getter:
                        oldVal = getter(obj)
                    setter( *args )
                    cmds.undo()
                    if getter:
                        newVal = getter(obj)

                        if isinstance(newVal, float):
                            self.assertAlmostEqual(oldVal, newVal, 12)
                        elif isinstance(newVal, (tuple, list, arrays.Array)):
                            if len(newVal) != len(oldVal):
                                self.fail('oldVal %r != to newVal %r - unequal lengths' % (oldVal, newVal))
                            for i in xrange(len(newVal)):
                                msg = 'index %d of oldVal %r not equal to newVal %r' % (i, oldVal, newVal)
                                if isinstance(newVal[i], float):
                                    self.assertAlmostEqual(oldVal[i], newVal[i],
                                                           places=12, msg=msg)
                                else:
                                    self.assertEqual(oldVal[i], newVal[i],
                                                     msg=msg)
                        else:
                            self.assertEqual(oldVal, newVal)
                except cls.GetTypedArgError:
                    pass
            finally:
                try:
                    pm.delete( obj )
                except:
                    pass
        testInvert.__name__ = 'test_%s_%s' % (pynode.__name__, setMethod)
        return testInvert

testCase_invertibles.addTests()

# TODO: add tests for slices
# test tricky / extended slices: ie, [:3], [:-1], [-3:-1], [5:1:-2], etc
# test multi-index slices, ie: [1:2, 5:9:2]
# Add tests for ranges of float parameters: ie, 'nurbsSphere1.v[5.657][3.1:4.2]'
# Add tests for double-indexed nurbs suface: 'nurbsSphere1.v[1.1:2.2][3.3:4.4]'
# check that indexing uses mel-style ranges (ie, inclusive)
# Continuous components with negative indices - ie, nurbsSurf[-3.3][-2]

class ComponentData(object):
    """
    Stores data handy for creating / testing a component.
    """
    def __init__(self, pymelType, nodeName, compName, indices, ranges,
                 melCompName=None,
                 pythonIndices=None, melIndices=None, neverUnindexed=False):
        self.pymelType = pymelType
        self.nodeName = nodeName
        self.compName = compName
        if melCompName is None:
            melCompName = compName
        self.melCompName = melCompName
        self.indices = indices
        self.ranges = ranges
        if isinstance(self.indices, (int, float, basestring)):
            self.indices = (self.indices,)
        if pythonIndices is None:
            pythonIndices = []
        if isinstance(pythonIndices, (int, float, basestring)):
            pythonIndices = [pythonIndices]
        self.pythonIndices = pythonIndices
        if melIndices is None:
            melIndices = []
        if isinstance(melIndices, (int, float, basestring)):
            melIndices = [melIndices]
        self.melIndices = melIndices
        self.neverUnindexed = neverUnindexed

        if indices:
            # just want the first one, since all we need in a component
            # mobject of the right type
            for x in self.melIndexedComps():
                compObjStr = x
                break
        else:
            compObjStr = self.melUnindexedComp()
        self._compObj = api.toApiObject(compObjStr)[1]


    def pyUnindexedComp(self):
        return self.nodeName + "." + self.compName

    def melUnindexedComp(self):
        return self.nodeName + "." + self.melCompName

    def _makeIndicesString(self, indexObj):
        return ''.join([('[%s]' % x) for x in indexObj.index])

    def pyIndexedComps(self):
        if not self.hasPyIndices():
            raise ValueError("no indices stored - %s" % self.pyUnindexedComp())
        else:
            # yield partial indices as well...
            for index in itertools.chain(self.indices, self.pythonIndices):
                if len(index.index):
                    for partialIndexLen in xrange(1, len(index.index)):
                        yield self.pyUnindexedComp() + self._makeIndicesString(IndexData(*index.index[:partialIndexLen]))
                yield self.pyUnindexedComp() + self._makeIndicesString(index)

    def melIndexedComps(self):
        if not self.hasMelIndices():
            raise ValueError("no indices stored - %s" % self.melUnindexedComp())
        else:
            for index in itertools.chain(self.indices, self.melIndices):
                yield self.melUnindexedComp() + self._makeIndicesString(index)

    def bothIndexedComps(self):
        """
        For indices which are same for mel/pymel, returns a pair (melComp, pyComp)
        if not self.hasMelIndices():
            raise ValueError("no indices stored - %s" % self.melUnindexedComp())
        else:
            for index in itertools.chain(self.indices, self.melIndices):
                yield self.melUnindexedComp() + self._makeIndicesString(index)
        """
        if not self.hasBothIndices():
            raise ValueError("no indices stored - %s" % self.melUnindexedComp())
        else:
            for index in self.indices:
                indiceString = self._makeIndicesString(index)
                yield (self.melUnindexedComp() + indiceString,
                       self.pyUnindexedComp() + indiceString)

    def hasPyIndices(self):
        return self.indices or self.pythonIndices

    def hasMelIndices(self):
        return self.indices or self.melIndices

    def hasBothIndices(self):
        return bool(self.indices)

    def typeEnum(self):
        return self._compObj.apiType()

    def typeName(self):
        return self._compObj.apiTypeStr()

class IndexData(object):
    def __init__(self, *index):
        self.index = index


def makeComponentCreationTests(evalStringCreator, funcName=None):
    """
    Outputs a function suitable for use as a unittest test that tests creation of components.

    For every ComponentData item in in self.compData, it will call
        'evalStringCreator(self, componentData)'
    evalStringCreator should output
        evalStrings
    where evalStrings is a list of strings, each of which when called like:
        eval(anEvalString)
    evaluates to a component.

    The function returns
        (successfulComps, failedComps)
    where each item of successfulComps is a successfully created component
    object, and each item of failedComps is the evalString that was not made.

    If any component cannot be created, the test will fail, and output a list of the components that
    could not be made in the fail message.
    """

    def test_makeComponents(self):
        successfulComps = []
        failedComps = []
        for componentData in self.compData.itervalues():
            evalStrings = evalStringCreator(self, componentData)
            for evalString in evalStrings:
                if VERBOSE:
                    print "trying to create:", evalString, "...",
                try:
                    self._pyCompFromString(evalString)
                except Exception:
                    if VERBOSE:
                        print "FAILED"
                    failedComps.append(evalString)
                else:
                    if VERBOSE:
                        print "ok"
                    successfulComps.append(evalString)
        if failedComps:
            self.fail('Could not create following components:\n   ' + '\n   '.join(failedComps))
    if funcName:
        test_makeComponents.__name__ = funcName
    return test_makeComponents

class MakeEvalStringCreator(object):
    """
    Used to transform a 'compString evalString creator' function to a
    a 'compData evalString creator' function.

    The generated 'compData evalString creator' is a function of the form:
       compDataEvalStringCreator(testCase, compDataObject)
    It takes a testCase_components object and a ComponentData object,
    and returns a list of strings, each of which can be fed as an argument
    to eval to generate a component.

    The input function, the 'compString evalString creator', is of the form:
        compStringEvalStringCreator(testCase, compString)
    It takes a testCase_components object and a component string, such as
       'myCube.vtx[1]'
    and returns a single string, which may be fed to eval to generate a
    component.

    melOrPymel determines whether mel-style or pymel-style syntax will be used.
    (in general, pymel-style indices are similar to mel-style, but can allow
    things such as [:-1].  Also, different component names may be used - for
    instance, the mel-syntax 'myNurbsSphere.v' will result in a v-isoparm,
    whereas PyNode('myNurbsSphere').v will give you the visibility attribute,
    so PyNode('myNurbsSphere').vIsoparm must be used. )

    If indexed is True, then the returned components will have an index. In this
    case, only compData which have associated index data (of the correct mel-or-
    pymel syntax type) will generate evalStrings.

    If indexed is False, then returned components will not have an index.
    In this case, alwaysMakeUnindexed will control whether given compData
    objects generate an evalString - if alwaysMakeUnindexed, all compData will
    be used, whereas as if it is false, only compData which have no index data
    for the given synatx will generate evalStrings.
    In addtion, if a ComponentData object has it's neverUnindexed property set
    to True, then no unindexed comp will be returned.
    """
    def __init__(self, melOrPymel, indexed=True, alwaysMakeUnindexed=False):
        self.melOrPymel = melOrPymel
        self.indexed = indexed
        self.alwaysMakeUnindexed = alwaysMakeUnindexed

    def __call__(self, evalStringCreator):
        def wrappedEvalStringCreator(testCase, compData):
            strings = []
            compDataStringFunc = None
            if self.indexed:
                if self.melOrPymel == 'mel':
                    if compData.hasMelIndices():
                        compDataStringFunc = compData.melIndexedComps
                elif self.melOrPymel == 'pymel':
                    if compData.hasPyIndices():
                        compDataStringFunc = compData.pyIndexedComps
                elif self.melOrPymel == 'both':
                    if compData.hasBothIndices():
                        compDataStringFunc = compData.bothIndexedComps
                if compDataStringFunc:
                    strings = [evalStringCreator(testCase, x)
                               for x in compDataStringFunc()]
            elif not compData.neverUnindexed:
                if self.melOrPymel == 'mel':
                    if self.alwaysMakeUnindexed or not compData.hasMelIndices():
                        compDataStringFunc = compData.melUnindexedComp
                elif self.melOrPymel == 'pymel':
                    if self.alwaysMakeUnindexed or not compData.hasPyIndices():
                        compDataStringFunc = compData.pyUnindexedComp
                if compDataStringFunc:
                    strings = [evalStringCreator(testCase, compDataStringFunc())]
            # get rid of any empty strings
            return [x for x in strings if x]
        return wrappedEvalStringCreator

def getEvalStringFunctions(theObj):
    returnDict = {}
    for propName in dir(theObj):
        evalStringId = '_evalStrings'
        if propName.endswith(evalStringId):
            returnDict[propName] = getattr(theObj, propName)
    return returnDict

class testCase_components(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)

        self.nodes = {}
        self.compData= {}


        self.nodes['cube'] = cmds.polyCube()[0]
        self.compData['meshVtx'] = ComponentData(pm.MeshVertex,
                                                 self.nodes['cube'], "vtx",
                                            [IndexData(2), IndexData('2:4')],
                                            [(0,7)],
                                            pythonIndices = [IndexData(':-1')])
        self.compData['meshEdge'] = ComponentData(pm.MeshEdge,
                                                  self.nodes['cube'], "e",
                                                  [IndexData(1)],
                                                  [(0,11)])
        #self.compData['meshEdge'] = ComponentData(self.nodes['cube'], "edge", 1)   # This just gets the plug, not a kEdgeComponent
        self.compData['meshFace'] = ComponentData(pm.MeshFace,
                                                  self.nodes['cube'], "f",
                                                  [IndexData(4)],
                                                  [(0,5)])
        self.compData['meshUV'] = ComponentData(pm.MeshUV,
                                                self.nodes['cube'], "map",
                                                [IndexData(3)],
                                                [(0,13)])
        self.compData['meshVtxFace'] = ComponentData(pm.MeshVertexFace,
                                                     self.nodes['cube'], "vtxFace",
                                                     [IndexData(3,0)],
                                                     [(0,7),(0,5)])
        self.compData['rotatePivot'] = ComponentData(pm.Pivot,
                                                     self.nodes['cube'],
                                                     "rotatePivot", [], [])

        self.nodes['subdBase'] = cmds.polyCube()[0]
        self.nodes['subd'] = cmds.polyToSubdiv(self.nodes['subdBase'])[0]
        self.compData['subdCV'] = ComponentData(pm.SubdVertex,
                                                self.nodes['subd'], "smp",
                                                [IndexData(0,2)], [])
        self.compData['subdEdge'] = ComponentData(pm.SubdEdge,
                                                  self.nodes['subd'], "sme",
                                                  [IndexData(256,1)], [])
        self.compData['subdFace'] = ComponentData(pm.SubdFace,
                                                  self.nodes['subd'], "smf",
                                                  [IndexData(256,0)], [])
        self.compData['subdUV'] = ComponentData(pm.SubdUV,
                                                self.nodes['subd'], "smm",
                                                [IndexData(10)], [])
        self.compData['scalePivot'] = ComponentData(pm.Pivot,
                                                    self.nodes['subd'],
                                                    "scalePivot", [], [])

        self.nodes['curve'] = cmds.circle()[0]
        self.compData['curveCV'] = ComponentData(pm.NurbsCurveCV,
                                                 self.nodes['curve'], "cv",
                                                 [IndexData(6)],
                                                 [(0,7)])
        self.compData['curvePt'] = ComponentData(pm.NurbsCurveParameter,
                                                 self.nodes['curve'], "u",
                                                 [IndexData(7.26580365007639)],
                                                 [(0,8)])
        self.compData['curveEP'] = ComponentData(pm.NurbsCurveEP,
                                                 self.nodes['curve'], "ep",
                                                 [IndexData(7)],
                                                 [(0,7)])
        self.compData['curveKnot'] = ComponentData(pm.NurbsCurveKnot,
                                                   self.nodes['curve'], "knot",
                                                   [IndexData(1)],
                                                   [(0,12)])

        self.nodes['sphere'] = cmds.sphere()[0]
        self.compData['nurbsCV'] = ComponentData(pm.NurbsSurfaceCV,
                                                 self.nodes['sphere'], "cv",
                                                 [IndexData(2,1)],
                                                 [(0,6),(0,7)],
                                                 pythonIndices = [IndexData('0:5:2', '1:4:3')])
        self.compData['nurbsIsoU'] = ComponentData(pm.NurbsSurfaceIsoparm,
                                                   self.nodes['sphere'], "u",
                                                   [IndexData(4),
                                                    IndexData(2.1,1.8)],
                                                   [(0,4),(0,8)],
                                                   neverUnindexed=True)
        self.compData['nurbsIsoV'] = ComponentData(pm.NurbsSurfaceIsoparm,
                                                   self.nodes['sphere'], "vIsoparm",
                                                   [IndexData(5.27974050577565),
                                                    IndexData(3,1.3)],
                                                   # Indice range given in u, v order,
                                                   # because comparison func will
                                                   # automatically flip indice
                                                   # order before using range
                                                   # info for 'v' isoparms
                                                   [(0,4),(0,8)],
                                                   melCompName="v",
                                                   neverUnindexed=True)
        self.compData['nurbsIsoUV'] = ComponentData(pm.NurbsSurfaceIsoparm,
                                                    self.nodes['sphere'], "uv",
                                                    [IndexData(1, 4.8)],
                                                   [(0,4),(0,8)],
                                                    neverUnindexed=True)
        self.compData['nurbsPatch'] = ComponentData(pm.NurbsSurfaceFace,
                                                    self.nodes['sphere'], "sf",
                                                    [IndexData(1,1)],
                                                    [(0,3),(0,7)])
        self.compData['nurbsEP'] = ComponentData(pm.NurbsSurfaceEP,
                                                 self.nodes['sphere'], "ep",
                                                 [IndexData(1,5)],
                                                 [(0,4),(0,7)])
        self.compData['nurbsKnot'] = ComponentData(pm.NurbsSurfaceKnot,
                                                   self.nodes['sphere'], "knot",
                                                   [IndexData(1,5)],
                                                   [(0,8),(0,12)])
        self.compData['nurbsRange'] = ComponentData(pm.NurbsSurfaceRange,
                                                    self.nodes['sphere'], "u",
                                                    [IndexData('2:3')],
                                                    [(0,4),(0,8)])

        self.latticeSize = (3,5,4)
        self.nodes['lattice'] = cmds.lattice(self.nodes['cube'],
                                             divisions=self.latticeSize)[1]
        self.compData['lattice'] = ComponentData(pm.LatticePoint,
                                                 self.nodes['lattice'], "pt",
                                                 [IndexData(0,1,0)],
                                                 [(0,2),(0,4),(0,3)])
        self.nodes['polySphere'] = cmds.polySphere()[0]

        self.nodes['negUSurf'] = cmds.surface(name='periodicSurf', du=3, dv=1,
                                              fu='periodic', fv='open',
                                              ku=range(-13, 0, 1), kv=(0, 1),
                                              pw=[(4, -4, 0, 1), (4, -4, -2.5, 1),
                                                  (5.5, 0, 0, 1), (5.5, 0, -2.5, 1),
                                                  (4, 4, 0, 1), (4, 4, -2.5, 1),
                                                  (0, 5.5, 0, 1), (0, 5.5, -2.5, 1),
                                                  (-4, 4, 0, 1), (-4, 4, -2.5, 1),
                                                  (-5.5, 0, 0, 1), (-5.5, 0, -2.5, 1),
                                                  (-4, -4, 0, 1), (-4, -4, -2.5, 1),
                                                  (0, -5.5, 0, 1), (0, -5.5, -2.5, 1),
                                                  (4, -4, 0, 1), (4, -4, -2.5, 1),
                                                  (5.5, 0, 0, 1), (5.5, 0, -2.5, 1),
                                                  (4, 4, 0, 1), (4, 4, -2.5, 1)] )
        self.compData['negNurbsIso'] = ComponentData(pm.NurbsSurfaceIsoparm,
                                                     self.nodes['negUSurf'], "uv",
                                                     [IndexData(-3.4, .5)],
                                                     [(-11,-3),(0,1)],
                                                     neverUnindexed=True)

        # Done in effort to prevent crash which happens after making a subd,
        # then adding any subd edges to an MSelectionList
        # see http://groups.google.com/group/python_inside_maya/browse_thread/thread/9415d03bac9e712b/0b94edb468fbe6bd
        cmds.refresh()
        import maya.utils
        maya.utils.processIdleEvents()
        # While the above works to prevent the crash in GUI mode,
        # unfortunately, I can't find anything that works in batch mode...
        # the following are various things I've tried...
        # Unfortunately, nothing is working so far...
#        cmds.refresh()
#        subdPyNode = pm.PyNode(self.nodes['subd']).getShape()
#        subdPyNode.__apimfn__().updateSubdSurface()

#        cmds.createNode('mesh')
#        cmds.undo()
#        edgeIt = api.MItSubdEdge(subdPyNode.__apimobject__())
#        while not edgeIt.isDone():
#            edgeIt.index()
#            edgeIt.next()

    def tearDown(self):
        for node in self.nodes.itervalues():
            if cmds.objExists(node):
                cmds.delete(node)
                #pass

    def test_allCompsRepresented(self):
        unableToCreate = ('kEdgeComponent',
                          'kDecayRegionCapComponent',
                          'kSetGroupComponent',
                          'kDynParticleSetComponent',
                          )
        compTypesDict = factories.getComponentTypes()
        flatCompTypes = set()
        for typesList in compTypesDict.itervalues():
            flatCompTypes.update(typesList)
        flatCompTypes = flatCompTypes - set([factories.apiTypesToApiEnums[x] for x in unableToCreate])

        notFoundCompTypes = set(flatCompTypes)
        for compDatum in self.compData.itervalues():
            testedType = compDatum.typeEnum()
            self.assert_(testedType in flatCompTypes)
            notFoundCompTypes.discard(testedType)

        if notFoundCompTypes:
            failMsg = "component types not tested:\n"
            for x in notFoundCompTypes:
                failMsg += "    " + factories.apiEnumsToApiTypes[x] + "\n"
            self.fail(failMsg)

    _indicesRe = re.compile( r'\[([^]]*)\]')

    @classmethod
    def _compStrSplit(cls, compStr):
        """
        Returns a tuple (nodeName, compName, indices).

        Indices will itself be a list.

        Example:
        >> testCase_components._compStrSplit('mySurf.uv[4][*]') # doctest: +SKIP
        ('mySurf', 'uv', ['4', '*'])
        """
        if '.' not in compStr:
            raise ValueError("compStr must be in 'nodeName.comp' form")
        nodeName, rest = compStr.split('.', 1)
        if not rest:
            compName = ''
            indices = []
        else:
            indices = cls._indicesRe.findall(rest)
            if not indices:
                compName = rest
            else:
                compName = rest.split('[', 1)[0]
        return nodeName, compName, indices

    @classmethod
    def _compStrJoin(cls, nodeName, compName, indices):
        """
        Inverse of _compStrSplit

        Given three items, nodeName, compName, indices, will
        return a component string representing that comp.

        Example:
        >> testCase_components._joinCompStr('mySurf', 'uv', ['4', '*']) # doctest: +SKIP
        'mySurf.uv[4][*]'
        """
        indicesStr = ''
        for indice in indices:
            indicesStr += '[%s]' % indice
        return '%s.%s%s' % (nodeName, compName, indicesStr)

    def _compStringsEqual(self, comp1, comp2, compData):
        # We assume that these comps have a '.' in them,
        # and that they've already been fed through
        # filterExpand, so myCube.vtx / myCubeShape.vtx
        # have been standardized
        if comp1==comp2:
            return True

        node1, comp1Name, indices1 = self._compStrSplit(comp1)
        node2, comp2Name, indices2 = self._compStrSplit(comp2)

        if node1 != node2:
            return False

        if not (comp1Name and comp2Name and
                indices1 and indices2):
            return False

        if comp1Name != comp2Name:
            # If the component names are not equal,
            # they're different components, unless
            # they're u/v/uv variants of each other...
            uvNames = ('u', 'v', 'uv')
            if (comp1Name not in uvNames or
                comp2Name not in uvNames):
                return False

        if comp1Name in ('vtxFace', 'smp', 'sme', 'smf'):
            # these types (really, any discrete component)
            # should be found
            # equal before we get here, by
            # filterExpand/setCompare -
            # so just fail these, as
            # the range information is hard to get
            return False

        # If one of them is v, we need to
        # flip the indices...
        if comp1Name == 'v':
            if len(indices1) == 0:
                pass
            elif len(indices1) == 1:
                indices1 = ['*', indices1[0]]
            elif len(indices1) == 2:
                indices1 = [indices1[1], indices1[0]]
            else:
                raise ValueError(comp1)
        if comp2Name == 'v':
            if len(indices2) == 0:
                pass
            elif len(indices2) == 1:
                indices2 = ['*', indices2[0]]
            elif len(indices2) == 2:
                indices2 = [indices2[1], indices2[0]]
            else:
                return ValueError(comp2)

        if len(indices1) < len(indices2):
            indices1 += (['*'] * (len(indices2) - len(indices1)))
        elif len(indices1) > len(indices2):
            indices2 += (['*'] * (len(indices1) - len(indices2)))

        if len(indices1) > len(compData.ranges):
            return False
        # it's ok if we have less indices than possible dimensions...

        for indice1, indice2, range in zip(indices1, indices2, compData.ranges):
            if indice1 == indice2:
                continue
            if (not self._isCompleteIndiceString(indice1, range) or
                not self._isCompleteIndiceString(indice2, range)):
                return False
        return True

    def _isCompleteIndiceString(self, indice, range):
        """
        Returns true if the given mel indice string would
        represent a 'complete' dimension for the given range.
        """
        if indice == '*':
            return True
        if indice.count(':') != 1:
            return False
        start, stop = indice.split(':')
        return float(start) == range[0] and float(stop) == range[1]

    def compsEqual(self, comp1, comp2, compData, failOnEmpty=True):
        """
        Compares two components for equality.

        The two args should either be pymel components objects, strings
        which can be selected, or a tuple or list of such objects.

        It will also return False if either component is empty, if failOnEmpty
        is True (default).
        """
        # First, make sure comp1, comp2 are both lists
        bothComps = [comp1, comp2]
        for i, comp in enumerate(bothComps):
            if isinstance(comp, (pm.Component, basestring)):
                bothComps[i] = [comp]
            else:
                # ensure it's a list, so we can modify it
                bothComps[i] = list(comp)

        # there's a bug where a comp such as:
        #   myNurbSurf.u[2]
        # will get converted to
        #   myNurbSurf.u[2][0:1]
        # when it should be
        #   myNurbSurf.u[2][0:8]
        # ...to get around it, use
        #  myNurbSurf.u[2][*]
        # See test_mayaBugs.TestSurfaceRangeDomain
        # for complete info on what will go wrong...
        if compData.pymelType in (pm.NurbsSurfaceRange, pm.NurbsSurfaceIsoparm):
            for compIterable in bothComps:
                for i, comp in enumerate(compIterable):
                    # Just worry about strings - the PyNodes
                    # are supposed to handle this bug themselves!
                    if isinstance(comp, basestring):
                        nodePart, compName, indices = self._compStrSplit(comp)
                        if compName == 'uv':
                            compPart = 'u'
                        if compName in ('u', 'v'):
                            if len(indices) < 2:
                                indices.append('*')
                        comp = self._compStrJoin(nodePart, compName, indices)
                    compIterable[i] = comp

        comp1, comp2 = bothComps



#        Comps are compared through first converting to strings
#        by selecting and using filterExpand, then by comparing the
#        the strings through string parsing.
#        This seems to be the only way to get comps such as
#        myNurbShape.v[3][0:4] and myNurb.v[3] (when the u range is 0-4,
#        and myNurbShape is the first shape of myNurb) to compare equal.


        # First, filter the results through filterExpand...
        if failOnEmpty:
            if not comp1: return False
            if not comp2: return False
        pm.select(comp1)
        comp1 = cmds.filterExpand(sm=tuple(x for x in xrange(74)))
        pm.select(comp2)
        comp2 = cmds.filterExpand(sm=tuple(x for x in xrange(74)))

        # first, filter out components whose strings are identical
        only1, both, only2 = setCompare(comp1, comp2)
        # Then, do pairwise comparison...
        # Make a copy of only1, as we'll be modifying it as we iterate
        # through...
        for comp1 in list(only1):
            for comp2 in only2:
                if self._compStringsEqual(comp1, comp2, compData):
                    only1.remove(comp1)
                    only2.remove(comp2)
                    break
            else:
                # we couldn't find a match for comp1 - fail!
                return False
        assert(not only1)
        # If only2 is now empty as well, success!
        return not only2

    def _pyCompFromString(self, compString):
        self._failIfWillMakeMayaCrash(compString)
        return eval(compString)

    # Need separate tests for PyNode / Component, b/c was bug where
    # Component('pCube1.vtx[3]') would actually return a Component
    # object, instead of a MeshVertex object, and fail, while
    # PyNode('pCube1.vtx[3]') would succeed

    def pyNodeMaker(self, compString):
        return 'pm.PyNode(%r)' % compString

    # cubeShape1.vtx[1] => PyNode('cubeShape1.vtx[1]')
    indexed_PyNode_evalStrings = MakeEvalStringCreator('mel', indexed=True)(pyNodeMaker)
    # cubeShape1.vtx[1] => PyNode('cubeShape1.vtx')
    unindexedComp_PyNode_evalStrings = MakeEvalStringCreator('mel', indexed=False)(pyNodeMaker)

    def componentMaker(self, compString):
        return 'pm.Component(%r)' % compString

    # cubeShape1.vtx[1] => Component('cubeShape1.vtx[1]')
    indexed_Component_evalStrings = MakeEvalStringCreator('mel', indexed=True)(componentMaker)
    # cubeShape1.vtx[1] => Component('cubeShape1.vtx')
    unindexedComp_Component_evalStrings = MakeEvalStringCreator('mel', indexed=False)(componentMaker)

    def object_evalStrings(self, compData):
        """
        ie, MeshVertexComponent('pCube1')
        """
        # Can't do Pivot('pCube1'), as we don't know whether we want scalePivot or rotatePivot
        if compData.pymelType == pm.Pivot:
            return []
        pymelClass = compData.pymelType
        return ['pm.%s(%r)' % (pymelClass.__name__, compData.nodeName)]

    def node_dot_comptypeMaker(self, compString):
        # node.scalePivot / node.rotatePivot returns the ATTRIBUTE,
        # so skip these.
        # (we can get the component by doing node.comp('scalePivot')
        if compString.endswith('Pivot'):
            return ''
        nodeName, compName = compString.split('.', 1)
        return 'pm.PyNode(%r).%s' % (nodeName, compName)

    # cubeShape1.vtx[1] => PyNode('cubeShape1').vtx[1]
    node_dot_comptypeIndex_evalStrings = MakeEvalStringCreator('pymel', indexed=True)(node_dot_comptypeMaker)
    # cubeShape1.vtx[1] => PyNode('cubeShape1').vtx
    node_dot_comptype_evalStrings = MakeEvalStringCreator('pymel', indexed=False, alwaysMakeUnindexed=True)(node_dot_comptypeMaker)

    # cubeShape1.vtx[1] => PyNode('cubeShape1').vtx
    @MakeEvalStringCreator('pymel', indexed=False, alwaysMakeUnindexed=True)
    def node_dot_compFunc_evalStrings(self, compString):
        nodeName, compName = compString.split('.', 1)
        return 'pm.PyNode(%r).comp(%r)' % (nodeName, compName)

    # cubeShape1.vtx[1] => PyNode('cubeShape1').vtx[1]
    @MakeEvalStringCreator('pymel', indexed=True)
    def node_dot_compFuncIndex_evalStrings(self, compString):
        nodeName, compNameAndIndex = compString.split('.', 1)
        indexSplit = compNameAndIndex.find('[')
        compName = compNameAndIndex[:indexSplit]
        indexString = compNameAndIndex[indexSplit:]
        return 'pm.PyNode(%r).comp(%r)%s' % (nodeName, compName, indexString)

    def test_objectComponentsClassEqual(self):
        successfulComps = []
        failedComps = []
        for componentData in self.compData.itervalues():
            for compString in self.object_evalStrings(componentData):
                try:
                    pymelObj = self._pyCompFromString(compString)
                except Exception:
                    failedComps.append(compString)
                else:
                    className = compString.split('(')[0]
                    pymelClass = eval(className)
                    if pymelObj.__class__ == pymelClass:
                        successfulComps.append(compString)
                    else:
                        failedComps.append(compString)
        if failedComps:
            self.fail('Following components wrong class (or not created):\n   ' + '\n   '.join(failedComps))

    def getComponentStrings(self, returnCompData=False, evalStringFuncs=None):
        """
        Return a list of all component strings made using this object's
        component data.

        If evalStringFuncs is given, it should be an iterable which returns
        evalString functions.

        Otherwise, the eval string function returned by
        getEvalStringFunctions(self.__class__).itervalues()
        will be used.

        If returnCompData is True, the returned list will be of tuples
            (evalString, compData)
        """
        if evalStringFuncs is None:
            evalStringFuncs = getEvalStringFunctions(self.__class__).values()
        componentStrings = set()
        for componentData in self.compData.itervalues():
            for evalStringFunc in evalStringFuncs:
                newStrings = evalStringFunc(self, componentData)
                if returnCompData:
                    newStrings = [(x, componentData) for x in newStrings]
                componentStrings.update(newStrings)
        return list(componentStrings)

    def test_componentSelection(self):
        failedCreation  = []
        failedSelections = []
        for compString in self.getComponentStrings():
            printedDone = False
            if VERBOSE:
                print compString, "-", "creating...",
            try:
                pymelObj = self._pyCompFromString(compString)
            except Exception:
                failedCreation.append(compString)
            else:
                if VERBOSE:
                    print "selecting...",
                try:
                    self._failIfWillMakeMayaCrash(pymelObj)
                    pm.select(pymelObj, r=1)
                except Exception:
#                        import traceback
#                        traceback.print_exc()
                    failedSelections.append(compString)
                if VERBOSE:
                    print "done!"
                    printedDone = True
            if VERBOSE and not printedDone:
                print "FAIL!!!"

        if failedCreation or failedSelections:
            failMsgs = []
            if failedCreation:
                failMsgs.append('Following components not created:\n   ' + '\n   '.join(failedCreation))
            if failedSelections:
                failMsgs.append('Following components unselectable:\n   ' + '\n   '.join(failedSelections))
            self.fail('\n\n'.join(failMsgs))

    def test_component_repr(self):
        failedCreation  = []
        failedRepr = []

        for compString in self.getComponentStrings():
            printedDone = False
            if VERBOSE:
                print compString, "-", "creating...",
            try:
                pymelObj = self._pyCompFromString(compString)
            except Exception:
                failedCreation.append(compString)
            else:
                if VERBOSE:
                    print "getting repr...",
                try:
                    self._failIfWillMakeMayaCrash(pymelObj)
                    repr(pymelObj)
                except Exception:
                    failedRepr.append(compString)
                else:
                    if VERBOSE:
                        print "done!"
                        printedDone = True
            if VERBOSE and not printedDone:
                print "FAIL!!!"

        if failedCreation or failedRepr:
            failMsgs = []
            if failedCreation:
                failMsgs.append('Following components not created:\n   ' + '\n   '.join(failedCreation))
            if failedRepr:
                failMsgs.append('Following components un-repr-able:\n   ' + '\n   '.join(failedRepr))
            self.fail('\n\n'.join(failMsgs))

    def test_componentIteration(self):
        failedCreation  = []
        failedIterations = []
        failedSelections = []
        iterationUnequal = []

        for compString,compData in self.getComponentStrings(returnCompData=True):
            printedDone = False
            if VERBOSE:
                print compString, "-", "creating...",
            try:
                pymelObj = self._pyCompFromString(compString)
            except Exception:
                failedCreation.append(compString)
            else:
                # only test iteration for discrete components!
                if not isinstance(pymelObj, pm.DiscreteComponent):
                    continue

                if VERBOSE:
                    print "iterating...",
                try:
                    self._failIfWillMakeMayaCrash(pymelObj)
                    iteration = [x for x in pymelObj]
                    iterationString = repr(iteration)
                except Exception:
#                        import traceback
#                        traceback.print_exc()
                    failedIterations.append(compString)
                else:
                    if VERBOSE:
                        print "comparing (using selection)...",
                    try:
                        pm.select(iteration)
                    except Exception:
                        failedSelections.append(iterationString)
                    else:
                        iterSel = pm.filterExpand(sm=(x for x in xrange(74)))
                        try:
                            pm.select(pymelObj)
                        except Exception:
                            failedSelections.append(compString)
                        else:
                            compSel = pm.filterExpand(sm=(x for x in xrange(74)))
                            if not self.compsEqual(iterSel, compSel, compData):
                                iterationUnequal.append(compString)
                            if VERBOSE:
                                print "done!"
                                printedDone = True
            if VERBOSE and not printedDone:
                print "FAIL!!!"

        if failedCreation or failedIterations or failedSelections or iterationUnequal:
            failMsgs = []
            if failedCreation:
                failMsgs.append('Following components not created:\n   ' + '\n   '.join(failedCreation))
            if failedIterations:
                failMsgs.append('Following components uniterable:\n   ' + '\n   '.join(failedIterations))
            if failedSelections:
                failMsgs.append('Following components unselectable:\n   ' + '\n   '.join(failedSelections))
            if iterationUnequal:
                failMsgs.append('Following components iteration not equal to orignal:\n   ' + '\n   '.join(iterationUnequal))
            self.fail('\n\n'.join(failMsgs))

    def test_componentTypes(self):
        def getCompAttrName(compString):
            dotSplit = compString.split('.')
            if len(dotSplit) > 1:
                return re.split(r'\W+', dotSplit[1])[0]

        failedCreation  = []
        failedComparisons = []
        for compString, compData in self.getComponentStrings(returnCompData=True):
            try:
                pymelObj = self._pyCompFromString(compString)
            except Exception:
                failedCreation.append(compString)
            else:
                if pymelObj.__class__ != compData.pymelType:
                        failedComparisons.append(compString +
                            ' - expected: %s got: %s' % (compData.pymelType,
                                                         pymelObj.__class__))

        if failedCreation or failedComparisons:
            failMsgs = []
            if failedCreation:
                failMsgs.append('Following components not created:\n   ' + '\n   '.join(failedCreation))
            if failedComparisons:
                failMsgs.append('Following components type wrong:\n   ' + '\n   '.join(failedComparisons))
            self.fail('\n\n'.join(failMsgs))

    # There's a bug - if you add x.sme[*][*] to an
    # MSelectionList immediately
    # after creating the component, without any idle events
    # run in between, Maya crashes...
    # In gui mode, we process idle events after creation,
    # but we can't do that in batch... so if we're
    # in batch, just fail x.sme[*][*]...

    # Even more fun - on osx, any comp such as x.sm*[256][*] crashes as well...
    def _failIfWillMakeMayaCrash(self, comp):
        try:
            if isinstance(comp, basestring):
#                if versions.current() >= versions.v2011:
#                    # In 2011, MFnNurbsSurface.getKnotDomain will make maya crash,
#                    # meaning any surf.u/v/uv.__getindex__ will crash
#                    nodeName, compName, indices = self._compStrSplit(comp)
#                    if re.match(r'''(?:(u|v|uv)(Isoparm)?|comp\(u?['"](u|v|uv)(Isoparm)?['"]\))$''', compName):
#                        raise CrashError
                if (platform.system() == 'Darwin' or
                    api.MGlobal.mayaState() in (api.MGlobal.kBatch,
                                              api.MGlobal.kLibraryApp)):
                    if ((comp.startswith('pm.SubdEdge') or
                         comp.endswith("comp(u'sme')") or
                         comp.endswith('.sme'))
                        and api.MGlobal.mayaState() in (api.MGlobal.kBatch,
                                                        api.MGlobal.kLibraryApp)):
                        raise CrashError
                    elif platform.system() == 'Darwin':
                        crashRe = re.compile(r".sm[pef]('\))?\[[0-9]+\]$")
                        if crashRe.search(comp):
                            raise CrashError
            elif isinstance(comp, pm.Component):
                # Check if we're in batch - in gui, we processed idle events after subd
                # creation, which for some reason, prevents the crash
                if api.MGlobal.mayaState() in (api.MGlobal.kBatch,
                                              api.MGlobal.kLibraryApp):
                    # In windows + linux, just selections of type .sme[*][*] - on OSX,
                    # it seems any .sm*[256][*] will crash it...
                    if platform.system() == 'Darwin':
                        if (isinstance(comp, (pm.SubdEdge, pm.SubdVertex, pm.SubdFace)) and
                            comp.currentDimension() in (0, 1)):
                            raise CrashError
                    elif (isinstance(comp, pm.SubdEdge) and
                          comp.currentDimension() == 0):
                        raise CrashError
        except CrashError, e:
            print "Auto-failing %r to avoid crash..." % comp
            raise

    def test_multiComponentName(self):
        compMobj = api.MFnSingleIndexedComponent().create(api.MFn.kMeshVertComponent)
        mfnComp = api.MFnSingleIndexedComponent(compMobj)
        mfnComp.addElement(0)
        mfnComp.addElement(1)
        mfnComp.addElement(2)
        mfnComp.addElement(5)
        mfnComp.addElement(7)
        mfnComp.addElement(9)
        mfnComp.addElement(11)
        myVerts = pm.MeshVertex(self.nodes['polySphere'], compMobj)
        self.assertEqual(str(myVerts), 'pSphere1.vtx[0:2,5:11:2]')

    def test_mixedPivot(self):
        pm.select(self.nodes['cube'] + '.rotatePivot', r=1)
        pm.select(self.nodes['cube'] + '.scalePivot', add=1)
        cubeName = self.nodes['cube']
        self.assertEqual(set(cmds.ls(sl=1)),
                         set(['%s.%s' % (cubeName, pivot) for pivot in ('rotatePivot', 'scalePivot')]))

    def test_mixedIsoparm(self):
        pm.select(self.nodes['sphere'] + '.u[1]', r=1)
        pm.select(self.nodes['sphere'] + '.v[0]', add=1)
        pm.select(self.nodes['sphere'] + '.uv[2][1]', add=1)
        nameAliases = set(x % self.nodes['sphere'] for x in [
                           # aliases for .u[1]
                           '%s.u[1]',
                           '%s.u[1][*]',
                           '%s.u[1][0:8]',
                           '%s.uv[1]',
                           '%s.uv[1][*]',
                           '%s.uv[1][0:8]',
                           # aliases for .v[0]
                           '%s.v[0]',
                           '%s.v[0][*]',
                           '%s.v[0][0:4]',
                           '%s.uv[*][0]',
                           '%s.uv[0:4][0]',
                           # aliases for .uv[2][1]
                           '%s.u[2][1]',
                           '%s.v[1][2]',
                           '%s.uv[2][1]'])
        selected = set(cmds.ls(sl=1))
        self.assertTrue(selected.issubset(nameAliases))

    def test_nurbsIsoPrintedRange(self):
        # Maya has a bug -running:
        #
        # import maya.cmds as cmds
        # cmds.sphere()
        # cmds.select('nurbsSphere1.uv[*][*]')
        # print cmds.ls(sl=1)
        # cmds.select('nurbsSphere1.u[*][*]')
        # print cmds.ls(sl=1)
        #
        # Gives two different results:
        # [u'nurbsSphere1.u[0:4][0:1]']
        # [u'nurbsSphere1.u[0:4][0:8]']
        sphereShape = pm.PyNode(self.nodes['sphere']).getShape().name()
        nameAliases = [x % sphereShape for x in [
                           '%s.u[*]',
                           '%s.u[*][*]',
                           '%s.u[0:4][0:8]',
                           '%s.uv[*]',
                           '%s.uv[*][*]',
                           '%s.uv[0:4][0:8]',
                           '%s.v[*]',
                           '%s.v[*][*]',
                           '%s.v[0:8][0:4]']]
        pynodeStr = str(pm.PyNode(self.nodes['sphere']).uv)
        self.assertTrue(pynodeStr in nameAliases,
                        '%s not equivalent to %s.uv[0:4][0:8]' % (pynodeStr,sphereShape))

    def test_meshVertConnnectedFaces(self):
        # For a standard cube, vert 3 should be connected to
        # faces 0,1,4
        desiredFaceStrings = ['%s.f[%d]' % (self.nodes['cube'], x) for x in (0,1,4)]
        connectedFaces = pm.PyNode(self.nodes['cube']).vtx[3].connectedFaces()
        self.assertTrue(self.compsEqual(desiredFaceStrings, connectedFaces, self.compData['meshFace']))

    def test_indiceChecking(self):
        # Check for a DiscreteComponent...
        cube = pm.PyNode(self.nodes['cube'])
        cube.vtx[2]
        cube.vtx[7]
        cube.vtx[-8]
        cube.vtx[-8:7]
        self.assertRaises(IndexError, cube.vtx.__getitem__, 8)
        self.assertRaises(IndexError, cube.vtx.__getitem__, slice(0,8))
        self.assertRaises(IndexError, cube.vtx.__getitem__, -9)
        self.assertRaises(IndexError, cube.vtx.__getitem__, slice(-9,7))
        self.assertRaises(IndexError, cube.vtx.__getitem__, 'foo')
        self.assertRaises(IndexError, cube.vtx.__getitem__, 5.2)
        self.assertRaises(IndexError, cube.vtx.__getitem__, slice(0,5.2))

        # Check for a ContinuousComponent...
        sphere = pm.PyNode(self.nodes['sphere'])
        self._failIfWillMakeMayaCrash('%s.u[2]' % sphere.name())
        sphere.u[2]
        sphere.u[4]
        sphere.u[0]
        sphere.u[0:4]
        self.assertRaises(IndexError, sphere.u.__getitem__, 4.1)
        self.assertRaises(IndexError, sphere.u.__getitem__, slice(0,5))
        self.assertRaises(IndexError, sphere.u.__getitem__, -2)
        self.assertRaises(IndexError, sphere.u.__getitem__, slice(-.1,4))
        self.assertRaises(IndexError, sphere.u.__getitem__, 'foo')
        self.assertRaises(IndexError, sphere.u.__getitem__, slice(0,'foo'))

    def test_melIndexing(self):
        melString = '%s.vtx[1:4]' % self.nodes['cube']
        self.assertTrue(self.compsEqual(melString, pm.PyNode(melString), self.compData['meshVtx']))


    # cubeShape1.vtx[1] => PyNode('cubeShape1').vtx[1]
    node_dot_comptypeIndex_evalStrings = MakeEvalStringCreator('pymel', indexed=True)(node_dot_comptypeMaker)

    def test_melPyMelCompsEqual(self):
        def pairedStrings(self, compStringPair):
            # The mel compString we don't need to alter...
            # For the PyNode, use PyNode('cubeShape1').vtx[1] syntax
            return (compStringPair[0], self.node_dot_comptypeMaker(compStringPair[1]))

        unindexedPairedStrings = MakeEvalStringCreator('both', indexed=False)(pairedStrings)
        indexedPairedStrings = MakeEvalStringCreator('both', indexed=True)(pairedStrings)
        failedCreation  = []
        failedDuringCompare = []
        failedComparison = []
        for componentData in self.compData.itervalues():
            evalStringPairs = itertools.chain(unindexedPairedStrings(self, componentData),
                                              indexedPairedStrings(self, componentData))
            for melString, pyString in evalStringPairs:
                printedDone = False
                if VERBOSE:
                    print melString, "/", pyString, "-", "creating...",
                try:
                    pymelObj = self._pyCompFromString(pyString)
                except Exception:
                    failedCreation.append(pyString)
                else:
                    if VERBOSE:
                        print "comparing...",
                    try:
                        areEqual = self.compsEqual(melString, pymelObj, componentData)
                    except Exception:
                        #raise
                        failedDuringCompare.append(str( (melString, pyString) ))
                    else:
                        if not areEqual:
                            failedComparison.append(str( (melString, pyString) ))
                        else:
                            if VERBOSE:
                                print "done!"
                            printedDone = True
                if not printedDone and VERBOSE:
                    print "FAIL!!!"

        if any( (failedCreation, failedDuringCompare, failedComparison) ):
            failMsgs = []
            if failedCreation:
                failMsgs.append('Following components not created:\n   ' + '\n   '.join(failedCreation))
            if failedDuringCompare:
                failMsgs.append('Following components had error during compare:\n   ' + '\n   '.join(failedDuringCompare))
            if failedComparison:
                failMsgs.append('Following components unequal:\n   ' + '\n   '.join(failedComparison))
            self.fail('\n\n'.join(failMsgs))

    def test_extendedSlices(self):
        failedComps = []
        def check(pynode, expectedStrings, compData):
            if not self.compsEqual(pynode, expectedStrings, compData):
                failedComps.append(repr(pynode) + '\n      not equal to:\n   ' + str(expectedStrings))

        pyCube = pm.PyNode('pCube1')
        check(pyCube.e[2:11:3],
              ('pCubeShape1.e[11]', 'pCubeShape1.e[8]',
               'pCubeShape1.e[5]', 'pCubeShape1.e[2]'),
              self.compData['meshEdge'])
        pySphere = pm.PyNode('nurbsSphere1')
        check(pySphere.cv[1:5:2][1:4:3],
              ('nurbsSphereShape1.cv[1][4]', 'nurbsSphereShape1.cv[1][1]',
               'nurbsSphereShape1.cv[3][4]', 'nurbsSphereShape1.cv[3][1]',
               'nurbsSphereShape1.cv[5][4]', 'nurbsSphereShape1.cv[5][1]'),
              self.compData['nurbsCV'])
        if failedComps:
            self.fail('Following components did not yield expected components:\n   ' + '\n   '.join(failedComps))

    def test_continuousCompRanges(self):
        failedComps = []
        def check(pynode, expectedStrings, compData):
            if not self.compsEqual(pynode, expectedStrings, compData):
                failedComps.append(repr(pynode) + '\n      not equal to:\n   ' + str(expectedStrings))

        check(self._pyCompFromString("pm.PyNode('nurbsSphere1').vIsoparm[5.54][1.1:3.4]"),
              'nurbsSphereShape1.u[1.1:3.4][5.54]',
              self.compData['nurbsIsoUV'])
        check(self._pyCompFromString("pm.PyNode('nurbsCircle1').u[2.8:6]"),
              'nurbsCircleShape1.u[2.8:6]',
              self.compData['curvePt'])
        if failedComps:
            self.fail('Following components did not yield expected components:\n   ' + '\n   '.join(failedComps))

    def test_negativeDiscreteIndices(self):
        failedComps = []
        def check(pynode, expectedStrings, compData):
            if not self.compsEqual(pynode, expectedStrings, compData):
                failedComps.append(repr(pynode) + '\n      not equal to:\n   ' + str(expectedStrings))

        pyCurve = pm.PyNode('nurbsCircle1')
        # Breaking into extra lines here just to make debugging easier
        pyCurveShape = pyCurve.getShape()
        knot = pyCurveShape.knot
        knotNeg3 = knot[-3]
        check(knotNeg3,
              'nurbsCircleShape1.knot[10]',
              self.compData['curveKnot'])
        pyLattice = pm.PyNode('ffd1Lattice')
        check(pyLattice.pt[-1][-5:-2][-2],
              ('ffd1LatticeShape.pt[2][0][2]',
               'ffd1LatticeShape.pt[2][1][2]',
               'ffd1LatticeShape.pt[2][2][2]'),
              self.compData['lattice'])
        if failedComps:
            self.fail('Following components did not yield expected components:\n   ' + '\n   '.join(failedComps))

    def test_negativeContinuousIndices(self):
        # For continous comps, these should behave just like positive ones...
        failedComps = []
        def check(pynode, expectedStrings, compData):
            if not self.compsEqual(pynode, expectedStrings, compData):
                failedComps.append(repr(pynode) + '\n      not equal to:\n   ' + str(expectedStrings))

        surf = pm.PyNode('surfaceShape1')
        check(surf.uv[-3.3][.5],
              'surfaceShape1.u[-3.3][.5]',
              self.compData['negNurbsIso'])
        check(surf.uv[-8:-5.1][0],
              'surfaceShape1.u[-8:-5.1][0]',
              self.compData['negNurbsIso'])

        if failedComps:
            self.fail('Following components did not yield expected components:\n   ' + '\n   '.join(failedComps))

    def test_multipleIterations(self):
        """
        Make sure that, on repeated iterations through a component, we get the same result.
        """
        comp = pm.PyNode(self.nodes['cube']).e[3:10]
        iter1 = [x for x in comp]
        iter2 = [x for x in comp]
        self.assertEqual(iter1, iter2)

    # Disabling this for now - such indicing wasn't possible in 0.9.x, either,
    # so while I'd like to get this working at some point, it's not necessary for now...
#    def test_multipleNoncontiguousIndices(self):
#        """
#        test things like .vtx[1,2,5:7]
#        """
#        failedComps = []
#        def check(pynode, expectedStrings, compData):
#            if not self.compsEqual(pynode, expectedStrings, compData):
#                failedComps.append(repr(pynode) + '\n      not equal to:\n   ' + str(expectedStrings))
#
#        cube = pm.PyNode('pCube1')
#        vtx = cube.vtx
#        check(vtx[1,2,5:7],
#              ('pCubeShape1.vtx[1]',
#               'pCubeShape1.vtx[2]',
#               'pCubeShape1.vtx[5]',
#               'pCubeShape1.vtx[6]',
#               'pCubeShape1.vtx[7]'),
#              self.compData['meshVtx'])
#
#        ffd = pm.PyNode('ffd1LatticeShape')
#        pt = ffd.pt
#        check(pt[0,1][1,2,4,][0,2],
#              ('ffd1LatticeShape.pt[0][1][0]',
#               'ffd1LatticeShape.pt[0][1][2]',
#               'ffd1LatticeShape.pt[0][2][0]',
#               'ffd1LatticeShape.pt[0][2][2]',
#               'ffd1LatticeShape.pt[0][4][0]',
#               'ffd1LatticeShape.pt[0][4][2]',
#               'ffd1LatticeShape.pt[1][1][0]',
#               'ffd1LatticeShape.pt[1][1][2]',
#               'ffd1LatticeShape.pt[1][2][0]',
#               'ffd1LatticeShape.pt[1][2][2]',
#               'ffd1LatticeShape.pt[1][4][0]',
#               'ffd1LatticeShape.pt[1][4][2]',
#               ),
#               self.compData['lattice'])
#
#        if failedComps:
#            self.fail('Following components did not yield expected components:\n   ' + '\n   '.join(failedComps))

    def test_totalSize_meshVtx(self):
        self.assertEqual(pm.PyNode(self.nodes['cube']).vtx.totalSize(), 8)
    def test_totalSize_meshEdge(self):
        self.assertEqual(pm.PyNode(self.nodes['cube']).edges.totalSize(), 12)
    def test_totalSize_meshFace(self):
        self.assertEqual(pm.PyNode(self.nodes['cube']).faces.totalSize(), 6)
    def test_totalSize_meshUV(self):
        # default cube uv layout is "t-shape" - so 14 uvs
        self.assertEqual(pm.PyNode(self.nodes['cube']).uvs.totalSize(), 14)
    def test_totalSize_meshVtxFace(self):
        self.assertEqual(pm.PyNode(self.nodes['cube']).vtxFace.totalSize(), 24)
    def test_totalSize_curveCV(self):
        self.assertEqual(pm.PyNode(self.nodes['curve']).cv.totalSize(), 8)
    def test_totalSize_curveEP(self):
        self.assertEqual(pm.PyNode(self.nodes['curve']).ep.totalSize(), 8)
    def test_totalSize_curveKnot(self):
        self.assertEqual(pm.PyNode(self.nodes['curve']).knots.totalSize(), 13)
    def test_totalSize_nurbsCV(self):
        self.assertEqual(pm.PyNode(self.nodes['sphere']).cv.totalSize(), 56)
    def test_totalSize_nurbsPatch(self):
        self.assertEqual(pm.PyNode(self.nodes['sphere']).faces.totalSize(), 32)
    def test_totalSize_nurbsEP(self):
        self.assertEqual(pm.PyNode(self.nodes['sphere']).ep.totalSize(), 40)
    def test_totalSize_nurbsKnot(self):
        self.assertEqual(pm.PyNode(self.nodes['sphere']).knots.totalSize(), 117)
    def test_totalSize_lattice(self):
        self.assertEqual(pm.PyNode(self.nodes['lattice']).pt.totalSize(),
                         self.latticeSize[0] * self.latticeSize[1] * self.latticeSize[2])

    def test_stringComp_indexing(self):
        comp = pm.PyNode('%s.vtx[*]' % self.nodes['cube'])
        compIndex = comp[2];
        self.assertEqual(compIndex.getPosition(), pm.dt.Point(-0.5, 0.5, 0.5))

    def test_listComp(self):
        nodeTypes = {'cube':pm.nt.Mesh,
                     'subd':pm.nt.Subdiv,
                     'curve':pm.nt.NurbsCurve,
                     'sphere':pm.nt.NurbsSurface,
                     'lattice':pm.nt.Lattice,
                    }

        def assertListCompForNodeClass(node, nodeClass):
            compNames = sorted(nodeClass._componentAttributes)
            compTypes = set()
            uniqueNames = []
            for compName in compNames:
                compType = nodeClass._componentAttributes[compName]
                if compType not in compTypes:
                    compTypes.add(compType)
                    uniqueNames.append(compName)
            self.assertEqual(node.listComp(names=True), compNames)
            comps = []
            for name in uniqueNames:
                comps.append(node.comp(name))
            self.assertEqual(node.listComp(), comps)


        for typeName, nodeClass in nodeTypes.iteritems():
            print typeName, nodeClass
            trans = pm.PyNode(self.nodes[typeName])
            assertListCompForNodeClass(trans, pm.nt.Transform)
            shape = trans.getShape()
            assertListCompForNodeClass(shape, nodeClass)


for propName, evalStringFunc in \
        getEvalStringFunctions(testCase_components).iteritems():
    evalStringId = '_evalStrings'
    if propName.endswith(evalStringId):
        baseName = propName[:-len(evalStringId)].capitalize()
        newFuncName = 'test_' + baseName + '_ComponentCreation'
        setattr(testCase_components, newFuncName,
            makeComponentCreationTests(evalStringFunc, funcName=newFuncName))

class testCase_DagNode(TestCaseExtended):
    def setUp(self):
        cmds.file(new=1, f=1)

    def test_getParent(self):
        tg1     = pm.createNode('transform', name='topGroup1')
        tg1c1   = pm.createNode('transform',    name='tg1_child1', parent='topGroup1')
        tg1c1g1 = pm.createNode('transform',        name='tg1_c1_grandkid1', parent='tg1_child1')
        tg1c1g2 = pm.createNode('transform',        name='tg1_c1_grandkid2', parent='tg1_child1')
        tg1c2   = pm.createNode('transform',    name='tg1_child2', parent='topGroup1')
        tg2     = pm.createNode('transform', name='topGroup2')
        tg2c2   = pm.createNode('transform',    name='tg2_child1', parent='topGroup2')
        # try some non-unique names
        tg3     = pm.createNode('transform', name='topGroup3')
        tg3c1   = pm.createNode('transform',    name='child1', parent='topGroup3')
        tg3c1c1 = pm.createNode('transform',        name='child1', parent='topGroup3|child1')
        tg4     = pm.createNode('transform', name='topGroup4')
        tg4c1   = pm.createNode('transform',    name='child1', parent='topGroup4')

        self.assertEqual(tg1c1g1.getParent(), tg1c1)

        self.assertEqual(tg1c1g1.getParent(0), tg1c1g1)
        self.assertEqual(tg1c1g1.getParent(generations=1), tg1c1)
        self.assertEqual(tg1c1g1.getParent(2), tg1)
        self.assertEqual(tg1c1g1.getParent(generations=3), None)
        self.assertEqual(tg1c1g1.getParent(-1), tg1)
        self.assertEqual(tg1c1g1.getParent(generations=-2), tg1c1)
        self.assertEqual(tg1c1g1.getParent(-3), tg1c1g1)
        self.assertEqual(tg1c1g1.getParent(generations=-4), None)
        self.assertEqual(tg1c1g1.getParent(-5), None)
        self.assertEqual(tg1c1g1.getParent(generations=4), None)
        self.assertEqual(tg1c1g1.getParent(-63), None)
        self.assertEqual(tg1c1g1.getParent(generations=32), None)

        self.assertEqual(tg1c1g1.getAllParents(), [tg1c1, tg1])

        self.assertEqual(tg3c1.getParent(generations=1), tg3)
        self.assertEqual(tg3c1c1.getParent(generations=2), tg3)
        self.assertEqual(tg3c1.getParent(generations=-1), tg3)

        self.assertEqual(tg3c1c1.getAllParents(), [tg3c1, tg3])
        self.assertEqual(tg3c1.getAllParents(), [tg3])
        self.assertEqual(tg3.getAllParents(), [])

    def test_isVisible(self):
        setA = []
        setB = []
        vis = [1,1,0,0,1,0,0,1]
        z = 0
        for x in range(8):
            setA.append(pm.createNode('transform', name='setA%d' % x))
            setB.append(pm.createNode('transform', name='setB%d' % x))

        for x in range(4):
            setA[x+4].setParent(setA[x])
            setB[x+4].setParent(setB[x])

        for x in range(8):
            setA[x].visibility.set(vis[x])
            setB[x].visibility.set(vis[x])

        for x in range(8):
            self.assertEqual(setA[x].isVisible(), setB[x].isVisible())
            self.assertEqual(setA[x].isVisible(), setB[x].isVisible(checkOverride=True))
            self.assertEqual(setA[x].isVisible(), setB[x].isVisible(checkOverride=False))

        for x in range(8):
            setB[x].overrideEnabled.set(1)
            self.assertEqual(setA[x].isVisible(), setB[x].isVisible())
            self.assertEqual(setA[x].isVisible(), setB[x].isVisible(checkOverride=True))
            self.assertEqual(setA[x].isVisible(), setB[x].isVisible(checkOverride=False))

        for x in range(8):
            setB[x].overrideVisibility.set(1)
            self.assertEqual(setA[x].isVisible(), setB[x].isVisible())
            self.assertEqual(setA[x].isVisible(), setB[x].isVisible(checkOverride=True))
            self.assertEqual(setA[x].isVisible(), setB[x].isVisible(checkOverride=False))

        for x in range(8):
            setB[x].overrideVisibility.set(0)
            self.assertFalse(setB[x].isVisible())

class testCase_transform(TestCaseExtended):
    def setUp(self):
        self.trans = pm.createNode('transform')
        self.trans.setRotationOrder('XYZ', False)

    def tearDown(self):
        pm.delete(self.trans)

    def test_setRotation(self):
        #Check dt.EulerRotation when angle unit differs
        oldUnit = pm.currentUnit(q=1, angle=1)
        try:
            pm.currentUnit(angle='degree')

            # Check dt.EulerRotation input
            euler = pm.dt.EulerRotation(10, 20, 30)
            self.trans.setRotation(euler)
            self.checkRotationsEqual(euler, self.trans.attr('rotate').get())

            # Check dt.Quaternion input
            euler = pm.dt.EulerRotation(5, 15, -16)
            quat = pm.dt.Quaternion(euler.asQuaternion())
            self.trans.setRotation(quat)
            self.checkRotationsEqual(euler, self.trans.attr('rotate').get())

            # Check api.MEulerRotation input
            angles = (10, 20, 30)
            euler = pm.api.MEulerRotation(*[math.radians(x) for x in angles])
            self.trans.setRotation(euler)
            self.checkRotationsEqual(angles, self.trans.attr('rotate').get())

            # Check api.MQuaternion input
            angles = (5, 15, -16)
            euler = pm.api.MEulerRotation(*[math.radians(x) for x in angles])
            quat = euler.asQuaternion()
            self.trans.setRotation(quat)
            self.checkRotationsEqual(angles, self.trans.attr('rotate').get())

            # Check list of size 3 input
            angles = (10, 20, 30)
            self.trans.setRotation(angles)
            self.checkRotationsEqual(angles, self.trans.attr('rotate').get())

            # Check list of size 4 input
            angles = (5, 15, -16)
            euler = pm.api.MEulerRotation(*[math.radians(x) for x in angles])
            quat = pm.dt.Quaternion(euler.asQuaternion())
            quatVals = list(quat)
            self.trans.setRotation(quatVals)
            self.checkRotationsEqual(angles, self.trans.attr('rotate').get())

            #Check dt.EulerRotation when euler rotation order non-standard
            origAngles = (10, 20, 30, 'YXZ')
            euler = pm.dt.EulerRotation(*origAngles)
            self.trans.setRotation(euler)
            euler.reorderIt('XYZ')
            self.checkRotationsEqual(euler, self.trans.attr('rotate').get())
            self.trans.setRotationOrder('YXZ', True)
            try:
                self.checkRotationsEqual(origAngles[:3], self.trans.attr('rotate').get())
            finally:
                self.trans.setRotationOrder('XYZ', False)

            #Check dt.EulerRotation when trans rotation order non-standard
            origAngles = (10, 20, 30, 'XYZ')
            euler = pm.dt.EulerRotation(*origAngles)
            self.trans.setRotationOrder('ZYX', False)
            try:
                self.trans.setRotation(euler)
                euler.reorderIt('ZYX')
                self.checkRotationsEqual(euler, self.trans.attr('rotate').get())
            finally:
                self.trans.setRotationOrder('XYZ', True)
            self.checkRotationsEqual(origAngles[:3], self.trans.attr('rotate').get())

            # Check dt.EulerRotation input with radian angles
            degAngles = (5, 15, -16)
            radAngles = [math.radians(x) for x in degAngles]
            euler = pm.dt.EulerRotation(*radAngles, unit='radians')
            self.trans.setRotation(euler)
            self.checkRotationsEqual(degAngles, self.trans.attr('rotate').get())
        finally:
            pm.currentUnit(angle=oldUnit)

    def checkRotationsEqual(self, rot1, rot2):
        if not len(rot1) == len(rot2):
            raise ValueError("rotation values must have same length: %r, %r" % (rot1, rot2))
        for i, (aVal, bVal) in enumerate(zip(rot1, rot2)):
            self.assertAlmostEqual(aVal, bVal,
                                   msg="component %i of rotations not equal (%s != %s)"
                                        % (i, aVal, bVal))

class testCase_nurbsSurface(TestCaseExtended):
    def setUp(self):
        self.negUSurf = pm.PyNode(pm.surface(name='periodicSurf', du=3, dv=1,
                                       fu='periodic', fv='open',
                                       ku=range(-13, 0, 1), kv=(0, 1),
                                       pw=[(4, -4, 0, 1), (4, -4, -2.5, 1),
                                           (5.5, 0, 0, 1), (5.5, 0, -2.5, 1),
                                           (4, 4, 0, 1), (4, 4, -2.5, 1),
                                           (0, 5.5, 0, 1), (0, 5.5, -2.5, 1),
                                           (-4, 4, 0, 1), (-4, 4, -2.5, 1),
                                           (-5.5, 0, 0, 1), (-5.5, 0, -2.5, 1),
                                           (-4, -4, 0, 1), (-4, -4, -2.5, 1),
                                           (0, -5.5, 0, 1), (0, -5.5, -2.5, 1),
                                           (4, -4, 0, 1), (4, -4, -2.5, 1),
                                           (5.5, 0, 0, 1), (5.5, 0, -2.5, 1),
                                           (4, 4, 0, 1), (4, 4, -2.5, 1)] ))

    def tearDown(self):
        pm.delete(self.negUSurf)

    def test_knotDomain(self):
        # Was a bug with this, due to automatic wrapping of api 'unsigned int &' args
        self.assertEqual(self.negUSurf.getKnotDomain(), (-11.0, -3.0, 0.0, 1.0))

class testCase_joint(TestCaseExtended):
    def setUp(self):
        pm.newFile(f=1)

#    def test_getAbsolute(self):
#        # Was a bug with this, due to handling of methods which needed casting AND unpacking
#        self.assertEqual(self.j.getAbsolute(), (4,5,6))

    def test_angleX(self):
        joint = pm.nt.Joint(angleX=31.5)
        self.assertEqual(joint.getAngleX(), 31.5)
        joint.setAngleX(20.2)
        self.assertEqual(joint.getAngleX(), 20.2)
        pm.delete(joint)

    def test_angleY(self):
        joint = pm.nt.Joint(angleY=31.5)
        self.assertEqual(joint.getAngleY(), 31.5)
        joint.setAngleY(20.2)
        self.assertEqual(joint.getAngleY(), 20.2)
        pm.delete(joint)

    def test_angleZ(self):
        joint = pm.nt.Joint(angleZ=31.5)
        self.assertEqual(joint.getAngleZ(), 31.5)
        joint.setAngleZ(20.2)
        self.assertEqual(joint.getAngleZ(), 20.2)
        pm.delete(joint)

    def test_radius(self):
        # Was a bug with this, due to handling of methods which needed unpacking (but not casting)
        joint = pm.nt.Joint(radius=31.5)
        self.assertEqual(joint.getRadius(), 31.5)
        joint.setRadius(20.2)
        self.assertEqual(joint.getRadius(), 20.2)
        pm.delete(joint)

    def test_stiffnessX(self):
        joint = pm.nt.Joint(stiffnessX=31.5)
        self.assertEqual(joint.getStiffnessX(), 31.5)
        joint.setStiffnessX(20.2)
        self.assertEqual(joint.getStiffnessX(), 20.2)
        pm.delete(joint)

    def test_stiffnessY(self):
        joint = pm.nt.Joint(stiffnessY=31.5)
        self.assertEqual(joint.getStiffnessY(), 31.5)
        joint.setStiffnessY(20.2)
        self.assertEqual(joint.getStiffnessY(), 20.2)
        pm.delete(joint)

    def test_stiffnessZ(self):
        joint = pm.nt.Joint(stiffnessZ=31.5)
        self.assertEqual(joint.getStiffnessZ(), 31.5)
        joint.setStiffnessZ(20.2)
        self.assertEqual(joint.getStiffnessZ(), 20.2)
        pm.delete(joint)


class testCase_sets(TestCaseExtended):
    def setUp(self):
        cmds.file(new=1, f=1)
        self.cube = pm.polyCube()[0]
        self.sphere = pm.sphere()[0]
        self.set = pm.sets()
    def assertSetSelect(self, setClass, *items):
        """
        Generator function which tests the given set type.
        It first selects the items, saves the list of the selected items, and makes a set
        from the selected items. Then it
            - selects the items in the set
            - calls set.members()
        and compares each of the results to the initial selection.
        """
        pm.select(items)
        initialSel = cmds.ls(sl=1)
        if issubclass(setClass, pm.nt.ObjectSet):
            mySet = pm.sets(initialSel)
        else:
            mySet = pm.nt.SelectionSet(initialSel)
        self.assertNoError(pm.select, mySet)
        self.assertIteration(initialSel, cmds.ls(sl=1),
                             orderMatters=False)
        if issubclass(setClass, pm.nt.ObjectSet):
            myList = mySet.members()
        else:
            myList = list(mySet)
        pm.select(myList)
        newSel = cmds.ls(sl=1)
        self.assertIteration(initialSel, newSel, orderMatters=False)

    def test_ObjectSet_singleObject(self):
        self.assertSetSelect(pm.nt.ObjectSet, self.cube)

    def test_ObjectSet_multiObject(self):
        self.assertSetSelect(pm.nt.ObjectSet, self.cube, self.sphere)

    def test_ObjectSet_vertices(self):
        self.assertSetSelect(pm.nt.ObjectSet, self.cube.vtx[1:3])

    def test_ObjectSet_mixedObjectsComponents(self):
        self.assertSetSelect(pm.nt.ObjectSet, self.cube.edges[4:6], self.sphere)

    def test_SelectionSet_singleObject(self):
        self.assertSetSelect(pm.nt.SelectionSet, self.cube)

    def test_SelectionSet_multiObject(self):
        self.assertSetSelect(pm.nt.SelectionSet, self.cube, self.sphere)

    def test_SelectionSet_vertices(self):
        self.assertSetSelect(pm.nt.SelectionSet, self.cube.vtx[1:3])

    def test_SelectionSet_mixedObjectsComponents(self):
        self.assertSetSelect(pm.nt.SelectionSet, self.cube.edges[4:6], self.sphere)

    def test_SelectionSet_nestedSets(self):
        self.assertSetSelect(pm.nt.SelectionSet, self.set)

    def test_ObjectSet_len(self):
        mySet = pm.sets(name='mySet', empty=True)
        self.assertEqual(len(mySet), 0)
        mySet.add('persp')
        self.assertEqual(len(mySet), 1)
        mySet.add('perspShape')
        self.assertEqual(len(mySet), 2)

    def test_SelectionSet_len(self):
        mySet = pm.nt.SelectionSet([])
        self.assertEqual(len(mySet), 0)
        mySet.add('persp')
        self.assertEqual(len(mySet), 1)
        mySet.add('perspShape')
        self.assertEqual(len(mySet), 2)



#class testCase_0_7_compatabilityMode(unittest.TestCase):
#    # Just used to define a value that we know won't be stored in
#    # 0_7_compatability mode...
#    class NOT_SET(object): pass
#
#    def setUp(self):
#        self.stored_0_7_compatability_mode = factories.pymel_options.get( '0_7_compatibility_mode', False)
#        factories.pymel_options['0_7_compatibility_mode'] = True
#
#    def tearDown(self):
#        if self.stored_0_7_compatability_mode == NOT_SET:
#            del factories.pymel_options['0_7_compatibility_mode']
#        else:
#            factories.pymel_options['0_7_compatibility_mode'] = self.stored_0_7_compatability_mode
#
#    def test_nonexistantPyNode(self):
#        # Will raise an error if not in 0_7_compatability_mode
#        pm.PyNode('I_Dont_Exist_3142341324')
#

class testCase_apiArgConversion(unittest.TestCase):
    def test_unsignedIntRef_out_args(self):
        # the MFnLattice.getDivisions uses
        # multiple unsigned int & 'out' arguments ... make sure
        # that we can call them / they were translated correctly!
        res = (3,4,5)
        latticeObj = pm.lattice(cmds.polyCube()[0], divisions=res)[1]
        self.assertEqual(latticeObj.getDivisions(), res)

    def test_float2Ref_out_arg(self):
        """
        Test api functions that have an output arg of type float2 &
        MFnMesh.getUvAtPoint's uvPoint arg is one such arg.
        """
        mesh = pm.polyCube()[0].getShape()
        self.assertEqual(mesh.getUVAtPoint([0,0,0], space='world'),
                         [0.49666666984558105, 0.125])

    def test_int2Ref_out_arg(self):
        """
        Test api functions that have an output arg of type int2 &
        MFnMesh.getEdgeVertices's vertexList arg is one such arg.
        """
        mesh = pm.polyCube()[0].getShape()
        self.assertEqual(mesh.getEdgeVertices(2), [4,5])

class testCase_Mesh(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        self.trans = pm.polyCube()[0]
        self.cube = self.trans.getShape()
        self.mesh = pm.createNode('mesh')

    def test_emptyMeshOps(self):
        mesh = self.mesh
        for comp in (mesh.vtx, mesh.faces, mesh.edges):
            self.assertEqual(len(comp), 0)
            self.assertEqual(bool(comp), False)
        self.assertEqual(mesh.numColorSets(), 0)
        self.assertEqual(mesh.numFaceVertices(), 0)
        self.assertEqual(mesh.numNormals(), 0)
        self.assertEqual(mesh.numUVSets(), 0)
        self.assertEqual(mesh.numUVs(), 0)
        self.assertEqual(mesh.numFaces(), 0)
        self.assertEqual(mesh.numVertices(), 0)
        self.assertEqual(mesh.numEdges(), 0)

    def test_setVertexColor(self):
        for i in range(8):
            color = pm.dt.Color(1.0* i/8.0,0.5,0.5,1)
            self.cube.setVertexColor(color, i)
        for i in range(8):
            color = pm.dt.Color(1.0* i/8.0,0.5,0.5,1)
            self.assertEqual(self.trans.vtx[i].getColor(), color)

class testCase_MeshVert(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        self.trans = pm.polyCube()[0]
        self.cube = self.trans.getShape()

    def test_setVertexColor(self):
        for i in range(8):
            color = pm.dt.Color(1.0* i/8.0,0.5,0.5,1)
            self.trans.vtx[i].setColor(color)
        for i in range(8):
            color = pm.dt.Color(1.0* i/8.0,0.5,0.5,1)
            self.assertEqual(self.cube.vtx[i].getColor(), color)

    def test_connections(self):
        self.assertTrue(self.cube.vtx[2].isConnectedTo(self.cube.vtx[3]))
        self.assertFalse(self.cube.vtx[2].isConnectedTo(self.cube.vtx[7]))

        self.assertTrue(self.cube.vtx[5].isConnectedTo(self.cube.e[7]))
        self.assertFalse(self.cube.vtx[5].isConnectedTo(self.cube.e[5]))

        self.assertTrue(self.cube.vtx[6].isConnectedTo(self.cube.f[5]))
        self.assertFalse(self.cube.vtx[6].isConnectedTo(self.cube.f[0]))

class testCase_MeshEdge(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        self.trans = pm.polyCube()[0]
        self.cube = self.trans.getShape()

    def test_connections(self):
        self.assertTrue(self.cube.e[7].isConnectedTo(self.cube.vtx[5]))
        self.assertFalse(self.cube.e[5].isConnectedTo(self.cube.vtx[5]))

        self.assertTrue(self.cube.e[2].isConnectedTo(self.cube.e[8]))
        self.assertFalse(self.cube.e[2].isConnectedTo(self.cube.e[5]))

        self.assertTrue(self.cube.e[1].isConnectedTo(self.cube.f[0]))
        self.assertFalse(self.cube.e[6].isConnectedTo(self.cube.f[2]))


class testCase_MeshFace(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        self.trans = pm.polyCube()[0]
        self.cube = self.trans.getShape()

    def test_connections(self):
        # Oddly enough, in a cube, all the verts 'connected' to the face
        # are the ones NOT contained in it, and all the ones that are
        # contained are considered not connected...
        self.assertTrue(self.cube.f[5].isConnectedTo(self.cube.vtx[7]))
        self.assertTrue(self.cube.f[0].isConnectedTo(self.cube.vtx[3]))

        self.assertTrue(self.cube.f[3].isConnectedTo(self.cube.e[5]))
        self.assertFalse(self.cube.f[4].isConnectedTo(self.cube.e[4]))

        self.assertTrue(self.cube.f[2].isConnectedTo(self.cube.f[1]))
        self.assertFalse(self.cube.f[5].isConnectedTo(self.cube.f[4]))

class testCase_ConstraintAngleOffsetQuery(TestCaseExtended):
    def setUp(self):
        pm.newFile(f=1)

    def runTest(self):
        for cmdName in ('aimConstraint', 'orientConstraint'):
            cube1 = pm.polyCube()[0]
            cube2 = pm.polyCube()[0]
            cube2.translate.set( (2,0,0) )
            cmd = getattr(pm, cmdName)
            constraint = cmd(cube1, cube2)

            setVals = (12, 8, 7)
            cmd(constraint, e=1, offset=setVals)
            getVals = tuple(cmd(constraint, q=1, offset=1))
            self.assertVectorsEqual(setVals, getVals)

class testCase_Container(TestCaseExtended):
    def setUp(self):
        pm.newFile(f=1)

    def testPublishedAttribute(self):
        c=pm.container( current=1 )
        g=pm.group( em=True )
        pm.container( c, e=True, publishAsParent=(g, 'yippee') )
        fromPyNode = pm.PyNode('container1.yippee')
        self.assertTrue( isinstance(fromPyNode, pm.Attribute))
        self.assertEqual( fromPyNode.name(), 'container1.canBeParent[0]' )
        fromAttr = c.attr('yippee')
        self.assertTrue( isinstance(fromAttr, pm.Attribute))
        self.assertEqual( fromAttr.name(), 'container1.canBeParent[0]' )
        self.assertEqual( fromPyNode, fromAttr )

    def testGetParentContainer(self):
        c1 = pm.container()
        self.assertEqual(c1.getParentContainer(), None)
        c2 = pm.container(addNode=c1)
        self.assertEqual(c2.getParentContainer(), None)
        self.assertEqual(c1.getParentContainer(), c2)

    def testGetRootTransform(self):
        t = pm.createNode('transform')
        c = pm.container(addNode=t)
        self.assertEqual(c.getRootTransform(), None)
        self.assertEqual(c.getPublishAsRoot(), None)
        c.setPublishAsRoot((t, True))
        self.assertEqual(c.getRootTransform(), t)
        self.assertEqual(c.getPublishAsRoot(), t)


class testCase_AnimCurve(TestCaseExtended):
    def setUp(self):
        pm.newFile(f=1)

    def testAddKeys(self):
        import maya.OpenMayaAnim as omAn
        import maya.OpenMaya as om

        # Test thanks to Mark Therrell, from issue 234

        pm.sphere()

        nodeAttr = 'nurbsSphere1.tx'
        times = [1, 2, 4, 7]
        values = [-1.444, 2.461, 7.544, 11.655]

        ## get the the MPlug of the node.attr using pymel (could use api, this way just to see it work)
        mplug = pm.PyNode(nodeAttr).__apimplug__()

        ## instantiate the MFnAnimaCurve function, get the curve type needed
        crvFnc = omAn.MFnAnimCurve()
        crvtype = crvFnc.timedAnimCurveTypeForPlug(mplug)

        ## make a curve on the attr using API
        ## how do i create the curve with pymel?? no docs on this??
        crv = crvFnc.create(mplug,crvtype)

        ## try to add keyframes to the curve using .addKeys function in Pymel
        name = om.MFnDependencyNode(crv).name()
        pyAnimCurve = pm.PyNode(name)
        pyAnimCurve.addKeys(times,values,'step','step',False)

        for time, val in zip(times, values):
            pm.currentTime(time)
            self.assertEqual(pm.getAttr(nodeAttr), val)

class testCase_rename(TestCaseExtended):
    def setUp(self):
        pm.newFile(f=1)

    def testBasicRename(self):
        sphere = pm.polySphere()[0]
        sphere.rename('firstName')
        self.assertEqual('firstName', sphere.nodeName())
        sphere.rename('newName')
        self.assertEqual('newName', sphere.nodeName())

    def testPreserveNamespace(self):
        sphere1 = pm.polySphere()[0]
        sphere2 = pm.polySphere()[0]
        pm.namespace(add="myNS")


        pm.namespace(set=":")
        # set to sphere1, myNS:sphere2
        sphere1.rename(':sphere1')
        sphere2.rename(':myNS:sphere2')
        self.assertEqual('sphere1', sphere1.nodeName())
        self.assertEqual('myNS:sphere2', sphere2.nodeName())
        # test w/o preserveNamespace, current NS == :
        sphere1.rename('sphere3', preserveNamespace=False)
        sphere2.rename('sphere4', preserveNamespace=False)
        self.assertEqual('sphere3', sphere1.nodeName())
        self.assertEqual('sphere4', sphere2.nodeName())

        pm.namespace(set=":myNS")
        # set to sphere1, myNS:sphere2
        sphere1.rename(':sphere1')
        sphere2.rename(':myNS:sphere2')
        self.assertEqual('sphere1', sphere1.nodeName())
        self.assertEqual('myNS:sphere2', sphere2.nodeName())
        # test w/o preserveNamespace, current NS == :myNS
        sphere1.rename('sphere3', preserveNamespace=False)
        sphere2.rename('sphere4', preserveNamespace=False)
        self.assertEqual('myNS:sphere3', sphere1.nodeName())
        self.assertEqual('myNS:sphere4', sphere2.nodeName())

        pm.namespace(set=":")
        # set to sphere1, myNS:sphere2
        sphere1.rename(':sphere1')
        sphere2.rename(':myNS:sphere2')
        self.assertEqual('sphere1', sphere1.nodeName())
        self.assertEqual('myNS:sphere2', sphere2.nodeName())
        # test w/ preserveNamespace, current NS == :
        sphere1.rename('sphere3', preserveNamespace=True)
        sphere2.rename('sphere4', preserveNamespace=True)
        self.assertEqual('sphere3', sphere1.nodeName())
        self.assertEqual('myNS:sphere4', sphere2.nodeName())

        pm.namespace(set=":myNS")
        # set to sphere1, myNS:sphere2
        sphere1.rename(':sphere1')
        sphere2.rename(':myNS:sphere2')
        self.assertEqual('sphere1', sphere1.nodeName())
        self.assertEqual('myNS:sphere2', sphere2.nodeName())
        # test w/ preserveNamespace, current NS == :myNS
        sphere1.rename('sphere3', preserveNamespace=True)
        sphere2.rename('sphere4', preserveNamespace=True)
        self.assertEqual('sphere3', sphere1.nodeName())
        self.assertEqual('myNS:sphere4', sphere2.nodeName())

class testCase_renderLayers(TestCaseExtended):
    def setUp(self):
        pm.newFile(f=1)
        self.cube = pm.polyCube()[0]
        self.sphere = pm.polySphere()[0]
        pm.select(None)
        self.layer = pm.createRenderLayer(name="diffuse")

    def test_add_single(self):
        self.assertEqual(self.layer.listMembers(), [])
        self.layer.addMembers(self.cube)
        self.assertEqual(self.layer.listMembers(), [self.cube])
        self.layer.addMembers(self.sphere)
        self.assertEqual(set(self.layer.listMembers()),
                         set([self.cube, self.sphere]))

    def test_add_multi(self):
        self.assertEqual(self.layer.listMembers(), [])
        self.layer.addMembers([self.cube, self.sphere])
        self.assertEqual(set(self.layer.listMembers()),
                         set([self.cube, self.sphere]))

    def test_remove_single(self):
        self.layer.addMembers([self.cube, self.sphere])
        self.assertEqual(set(self.layer.listMembers()),
                         set([self.cube, self.sphere]))
        self.layer.removeMembers(self.sphere)
        self.assertEqual(self.layer.listMembers(), [self.cube])
        self.layer.removeMembers(self.cube)
        self.assertEqual(self.layer.listMembers(), [])

    def test_remove_multi(self):
        self.layer.addMembers([self.cube, self.sphere])
        self.assertEqual(set(self.layer.listMembers()),
                         set([self.cube, self.sphere]))
        self.layer.removeMembers([self.sphere, self.cube])
        self.assertEqual(self.layer.listMembers(), [])

    def test_setCurrent(self):
        self.assertEqual(pm.nt.RenderLayer.defaultRenderLayer(),
                         pm.nt.RenderLayer.currentLayer())
        self.layer.setCurrent()
        self.assertEqual(self.layer, pm.nt.RenderLayer.currentLayer())

    def test_adjustments(self):
        widthAttr = pm.PyNode("defaultResolution.width")
        self.assertEqual(self.layer.listAdjustments(), [])
        self.layer.addAdjustments(widthAttr)
        self.assertEqual(self.layer.listAdjustments(), ["defaultResolution.width"])

        origVal = widthAttr.get()
        adjVal = origVal + 5

        self.layer.setCurrent()
        widthAttr.set(adjVal)
        self.assertEqual(widthAttr.get(), adjVal)
        pm.nt.RenderLayer.defaultRenderLayer().setCurrent()
        self.assertEqual(widthAttr.get(), origVal)
        self.layer.setCurrent()
        self.assertEqual(widthAttr.get(), adjVal)

        self.layer.removeAdjustments(widthAttr)
        self.assertEqual(self.layer.listAdjustments(), [])
        self.assertEqual(widthAttr.get(), origVal)
        pm.nt.RenderLayer.defaultRenderLayer().setCurrent()
        self.assertEqual(widthAttr.get(), origVal)

class testCase_Character(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        # First, create a character to hold the clips. The character will be
        # a 3-bone skeleton named "arm".
        #
        cmds.select(d=True)
        cmds.joint(p=(0, 0, 0))
        cmds.joint(p=(0, 4, 0))
        cmds.joint('joint1', e=True, zso=True, oj='xyz')
        cmds.joint(p=(0, 8, -1))
        cmds.joint('joint2', e=True, zso=True, oj='xyz')
        cmds.joint(p=(0, 9, -2))
        cmds.joint('joint3', e=True, zso=True, oj='xyz')
        cmds.select('joint1', 'joint2', 'joint3', r=True)
        self.char = pm.character(name='arm')

    def test_getClipScheduler(self):
        self.assertEqual(self.char.getClipScheduler(), None)

        # Create some animation for the character. For this example the animation will
        # be quite trivial.
        #
        cmds.select('joint3', r=True)
        cmds.currentTime(0)
        cmds.setKeyframe('joint3.rx')
        cmds.currentTime(10)
        cmds.setKeyframe('joint3.rx', v=90)
        cmds.currentTime(20)
        cmds.setKeyframe('joint3.rx', v=0)
        # Create a clip for the current animation named "handWave"
        #
        cmds.clip('arm', startTime=0, endTime=20, name='handWave')

        self.assertEqual(self.char.getClipScheduler(), 'armScheduler1')

class testCase_listAttr(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        self.cube1 = pm.polyCube(ch=0)[0]
        self.cube2 = pm.polyCube(ch=0)[0]
        self.cube3 = pm.polyCube(ch=0)[0]
        self.blend = pm.blendShape(self.cube2, self.cube3, self.cube1)[0]

    def test_standard(self):
        results = sorted(x.name() for x in self.blend.listAttr())
        expected = [u'blendShape1.attributeAliasList',
            u'blendShape1.baseOrigin',
            u'blendShape1.baseOriginX',
            u'blendShape1.baseOriginY',
            u'blendShape1.baseOriginZ',
            u'blendShape1.binMembership',
            u'blendShape1.caching',
            u'blendShape1.envelope',
            u'blendShape1.fchild1',
            u'blendShape1.fchild2',
            u'blendShape1.fchild3',
            u'blendShape1.function',
            u'blendShape1.icon',
            u'blendShape1.input',
            u'blendShape1.inputTarget',
            u'blendShape1.inputTarget[-1].baseWeights',
            u'blendShape1.inputTarget[-1].inputTargetGroup',
            u'blendShape1.inputTarget[-1].inputTargetGroup[-1].inputTargetItem',
            u'blendShape1.inputTarget[-1].inputTargetGroup[-1].inputTargetItem[-1].inputComponentsTarget',
            u'blendShape1.inputTarget[-1].inputTargetGroup[-1].inputTargetItem[-1].inputPointsTarget',
            u'blendShape1.inputTarget[-1].inputTargetGroup[-1].normalizationId',
            u'blendShape1.inputTarget[-1].inputTargetGroup[-1].targetWeights',
            u'blendShape1.inputTarget[-1].normalizationGroup',
            u'blendShape1.inputTarget[-1].normalizationGroup[-1].normalizationUseWeights',
            u'blendShape1.inputTarget[-1].normalizationGroup[-1].normalizationWeights',
            u'blendShape1.inputTarget[-1].paintTargetIndex',
            u'blendShape1.inputTarget[-1].paintTargetWeights',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem[0].inputGeomTarget',
            u'blendShape1.input[0].groupId',
            u'blendShape1.input[0].inputGeometry',
            u'blendShape1.isHistoricallyInteresting',
            u'blendShape1.map64BitIndices',
            u'blendShape1.message',
            u'blendShape1.nodeState',
            u'blendShape1.origin',
            u'blendShape1.outputGeometry',
            u'blendShape1.paintWeights',
            u'blendShape1.parallelBlender',
            u'blendShape1.supportNegativeWeights',
            u'blendShape1.targetOrigin',
            u'blendShape1.targetOriginX',
            u'blendShape1.targetOriginY',
            u'blendShape1.targetOriginZ',
            u'blendShape1.topologyCheck',
            u'blendShape1.useTargetCompWeights',
            u'blendShape1.weight',
        ]
        self.assertEqual(results, expected)

    def test_topLevel(self):
        results = sorted(x.name() for x in self.blend.listAttr(topLevel=True))
        expected = [u'blendShape1.attributeAliasList',
            u'blendShape1.baseOrigin',
            u'blendShape1.binMembership',
            u'blendShape1.caching',
            u'blendShape1.envelope',
            u'blendShape1.function',
            u'blendShape1.icon',
            u'blendShape1.input',
            u'blendShape1.inputTarget',
            u'blendShape1.isHistoricallyInteresting',
            u'blendShape1.map64BitIndices',
            u'blendShape1.message',
            u'blendShape1.nodeState',
            u'blendShape1.origin',
            u'blendShape1.outputGeometry',
            u'blendShape1.paintWeights',
            u'blendShape1.parallelBlender',
            u'blendShape1.supportNegativeWeights',
            u'blendShape1.targetOrigin',
            u'blendShape1.topologyCheck',
            u'blendShape1.useTargetCompWeights',
            u'blendShape1.weight',
        ]
        self.assertEqual(results, expected)

    def test_descendants(self):
        results = sorted(x.name() for x in self.blend.listAttr(descendants=True))
        expected = [u'blendShape1.attributeAliasList',
            u'blendShape1.baseOrigin',
            u'blendShape1.baseOriginX',
            u'blendShape1.baseOriginY',
            u'blendShape1.baseOriginZ',
            u'blendShape1.binMembership',
            u'blendShape1.caching',
            u'blendShape1.envelope',
            u'blendShape1.fchild1',
            u'blendShape1.fchild2',
            u'blendShape1.fchild3',
            u'blendShape1.function',
            u'blendShape1.icon',
            u'blendShape1.input',
            u'blendShape1.inputTarget',
            u'blendShape1.inputTarget[0]',
            u'blendShape1.inputTarget[0].baseWeights',
            u'blendShape1.inputTarget[0].inputTargetGroup',
            u'blendShape1.inputTarget[0].inputTargetGroup[0]',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem[6000]',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem[6000].inputComponentsTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem[6000].inputGeomTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].inputTargetItem[6000].inputPointsTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].normalizationId',
            u'blendShape1.inputTarget[0].inputTargetGroup[0].targetWeights',
            u'blendShape1.inputTarget[0].inputTargetGroup[1]',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].inputTargetItem',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].inputTargetItem[6000]',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].inputTargetItem[6000].inputComponentsTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].inputTargetItem[6000].inputGeomTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].inputTargetItem[6000].inputPointsTarget',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].normalizationId',
            u'blendShape1.inputTarget[0].inputTargetGroup[1].targetWeights',
            u'blendShape1.inputTarget[0].normalizationGroup',
            u'blendShape1.inputTarget[0].paintTargetIndex',
            u'blendShape1.inputTarget[0].paintTargetWeights',
            u'blendShape1.input[0]',
            u'blendShape1.input[0].groupId',
            u'blendShape1.input[0].inputGeometry',
            u'blendShape1.isHistoricallyInteresting',
            u'blendShape1.map64BitIndices',
            u'blendShape1.message',
            u'blendShape1.nodeState',
            u'blendShape1.origin',
            u'blendShape1.outputGeometry',
            u'blendShape1.outputGeometry[0]',
            u'blendShape1.paintWeights',
            u'blendShape1.parallelBlender',
            u'blendShape1.supportNegativeWeights',
            u'blendShape1.targetOrigin',
            u'blendShape1.targetOriginX',
            u'blendShape1.targetOriginY',
            u'blendShape1.targetOriginZ',
            u'blendShape1.topologyCheck',
            u'blendShape1.useTargetCompWeights',
            u'blendShape1.weight',
            u'blendShape1.weight[0]',
            u'blendShape1.weight[1]',
        ]
        self.assertEqual(results, expected)

#def test_units():
#    startLinear = currentUnit( q=1, linear=1)
#
#    #cam = pm.PyNode('persp')
#    # change units from default
#    currentUnit(linear='meter')
#
#    light = directionalLight()
#
#    testPairs = [ ('persp.translate', 'getTranslation', 'setTranslation', datatypes.Vector([3.0,2.0,1.0]) ),  # Distance datatypes.Vector
#                  ('persp.shutterAngle' , 'getShutterAngle', 'setShutterAngle', 144.0 ),  # Angle
#                  ('persp.verticalShake' , 'getVerticalShake', 'setVerticalShake', 1.0 ),  # Unitless
#                  ('persp.focusDistance', 'getFocusDistance', 'setFocusDistance', 5.0 ),  # Distance
#                  ('%s.penumbraAngle' % light, 'getPenumbra', 'setPenumbra', 5.0 ),  # Angle with renamed api method ( getPenumbraAngle --> getPenumbra )
#
#                 ]
#
#    for attrName, getMethodName, setMethodName, realValue in testPairs:
#        at = pm.PyNode(attrName)
#        node = at.node()
#        getter = getattr( node, getMethodName )
#        setter = getattr( node, setMethodName )
#
#
#        descr =  '%s / %s / %s' % ( attrName, getMethodName, setMethodName )
#
#        def checkUnits( *args ):
#            print repr(at)
#            print "Real Value:", repr(realValue)
#            # set attribute using "safe" method
#            at.set( realValue )
#            # get attribute using wrapped api method
#            gotValue = getter()
#            print "Got Value:", repr(gotValue)
#            # compare
#            self.assertEqual( realValue, gotValue )
#
#            # set using wrapped api method
#            setter( realValue )
#            # get attribute using "safe" method
#            gotValue = at.get()
#            # compare
#            self.assertEqual( realValue, gotValue )
#        checkUnits.description = descr
#        yield checkUnits
#
#    # reset units
#    currentUnit(linear=startLinear)
#    pm.delete( light )
#                    #print types

########NEW FILE########
__FILENAME__ = test_plogging
'''
Created on Oct 16, 2012

@author: paulm
'''
import os
import unittest
import logging

import pymel.internal.plogging as plogging
import pymel.core

class testCase_raiseLog(unittest.TestCase):
    DEFAULT_LOGGER = pymel.core._logger

    @classmethod
    def _makeTest(cls, logLvlName, errorLvlName, logger=None):
        logLvl = getattr(logging, logLvlName)
        errorLvl = getattr(logging, errorLvlName)

        if logger:
            funcType = 'method'
            func = logger.raiseLog
            args = []
        else:
            funcType = 'function'
            func =  plogging.raiseLog
            args = [cls.DEFAULT_LOGGER]
        msg = "attempting %s raiseLog %s (ERRORLEVEL set to %s):" % (logLvlName, funcType, errorLvlName)
        args.extend([logLvl, msg])

        def raiseLogTest(self):
            oldLvl = plogging.ERRORLEVEL
            plogging.ERRORLEVEL = errorLvl
            try:
                kwargs = {'errorClass':TypeError}
                if errorLvl <= logLvl:
                    # the errorLevel is lower than the level we're emitting, it should
                    # raise an error
                    self.assertRaises(RuntimeError, func, *args)
                    self.assertRaises(TypeError, func, *args, **kwargs)
                else:
                    # we should be able to run this without an error...
                    func(*args)
                    func(*args, **kwargs)
            finally:
                plogging.ERRORLEVEL = oldLvl
        raiseLogTest.__name__ = 'test_raiseLog_%s_emit_%s_err_%s' % (funcType, logLvlName, errorLvlName)
        return raiseLogTest


    @classmethod
    def addTests(cls):
        logLevelNames = ('DEBUG', 'INFO', 'WARNING', 'ERROR')
        for logLvlName in logLevelNames:
            for errorLvlName in logLevelNames:
                for logger in (None, cls.DEFAULT_LOGGER):
                    test = cls._makeTest(logLvlName, errorLvlName, logger=logger)
                    setattr(cls, test.__name__, test)
testCase_raiseLog.addTests()
########NEW FILE########
__FILENAME__ = test_pmcmds
#import unittest, sys
#
#import maya.cmds
#from testingutils import TestCaseExtended, setupUnittestModule
#import pymel.core.pmcmds as pmcmds
#
#class Mylist(object):
#    def __init__(self, list):
#        self.theList = list
#    def __iter__(self):
#        return self.theList.__iter__()
#    def __repr__(self):
#        return "Mylist(%s)" % repr(self.theList)
#
##class Mystring(object):
##    def __init__(self, inputString):
##        self.theString = str(inputString)
##    def __str__(self):
##        return self.theString
##    def __repr__(self):
##        return "Mystring(%s)" % repr(self.theString)
#
#
## If this is true, we will test that the maya cmds (not just the pymel commands!)
## fail / succeed when we expect them to... really, this is just informational
#testMayaCmds = False
#
## If this is true, (and testMayaCmd is True), then we will run tests
## to make sure that maya commands FAIL when we expect them to...
#testMayaFailures = True
#
#
#mayaTests_shouldPass = []
#mayaTests_shouldFail = []
#wrappedTests = []
#
#class TestWrappedCmds(TestCaseExtended):
#    def setUp(self):
#        import pymel
#        maya.cmds.file(f=True,new=True)
#        self.cubeTrans1, cubeShaper = pymel.polyCube()
#        self.cubeTrans2, cubeShaper = pymel.polyCube()
#        self.lists = {}
#        self.lists['transform'] = [self.cubeTrans1, self.cubeTrans2]
#        self.lists['attribute'] = [self.cubeTrans1.translateX, self.cubeTrans2.translateZ]
#        maya.cmds.connectAttr(str(self.cubeTrans1.scaleY), str(self.cubeTrans2.scaleZ))
#        self.lists['attribute2'] = [self.cubeTrans1.scaleY, self.cubeTrans2.scaleZ]
#
#
#    @classmethod
#    def addTestsForCmd(cls, cmdName, typeOfArgs,  \
#                       mayaFailsOnCustomStrings=False, mayaFailsOnCustomLists=False, \
#                       mayaFailsOnCustomStringsInNormalLists=False, \
#                       numOfArgs=None, canTakeListArg=False, extraArgs=None, extraKwArgs=None):
#        '''
#        cmdName - name of the command to test (ie, we will be testing maya.cmds.cmdName and pymel.cmdName)
#        typeOfArgs - the type of the non-keyword arguments for the command (ie, transform, attribute, etc)
#        args - extra non-keyword args to pass to the command
#
#        mayaFailsOnCustomStrings - if true, then maya.cmds.cmdName should fail when called with non-string objects,
#            and pymel.cmdName should handle it - test this
#        mayaFailsOnCustomLists -  if true, then maya.cmds.cmdName should fail when called with non-list sequences,
#            and pymel.cmdName should handle it - test this
#            Note - if BOTH mayaFailsOnCustomStrings and mayaFailsOnCustomLists are true, it will also test when
#            the command is fed a non-list sequence filled with non-string objects
#        mayaFailsOnCustomStringsInNormalLists - even if mayaFailsOnCustomStrings==True, then for some
#            reason, maya will generally SUCCEED on a customString in a normal list... change this to check that
#            maya FAILS in this case
#        canTakeListArg - if false, then the command will be fed multiple non-keyword args,
#            where each argument is a single object; if true, the command will ALSO be tested
#            with a single non-keyword argument, which is a sequence of objects (note that if
#            this is false, then the value of mayaFailsOnCustomLists is ignored)
#        numOfArgs - if numOfArgs is not None, then only feed in this many objects of the requested type
#            as non-keyword args to the command
#        extraArgs - other non-keyword args that will be passed into cmdName
#        extraKwArgs - other keyword args that will be passed into cmdName
#        '''
#
#        if extraArgs==None: extraArgs = []
#        if extraKwArgs==None: extraKwArgs = {}
##         print extraArgs
##         print extraKwArgs
#
#        mayaCmd = getattr(maya.cmds, cmdName)
#        wrappedCmd = getattr(pmcmds, cmdName)
#
#        # possible arg formats:
#        # 1. cmdName(arg1String, arg2String)
#        # 2. cmdName(arg1PyNode, arg2Pynode)
#        # 3. cmdName([arg1String, arg2String])
#        # 4. cmdname([arg1PyNode, arg2Pynode])
#        # 5. cmdname(Mylist([arg1String, arg2String]))
#        # 6. cmdname(Mylist([arg1PyNode, arg2Pynode]))
#
#        def addTestPair(mayaCmdWillFail=True, testPyNodes=False, useListArg=False, testCustomLists=False):
#            nameSuffixList = [typeOfArgs]
#            if testPyNodes:
#                nameSuffixList.append("PyNodes")
#            else:
#                nameSuffixList.append("normalStrings")
#            if useListArg:
#                nameSuffixList.append("in")
#                if testCustomLists:
#                    nameSuffixList.append("customList")
#                else:
#                    nameSuffixList.append("normalList")
#
#            def feedArgs(function):
#                '''Decorator used to feed in the appropriate args to the test function.'''
#                def methodWithAutomaticArgs(self):
#                    args = self.getArgs(typeOfArgs,
#                                        numOfArgs,
#                                        testPyNodes,
#                                        useListArg,
#                                        testCustomLists,
#                                        *extraArgs)
##                    print "self: %s" % self
##                    print "args: %s" % args
##                    print "kwargs: %s" % extraKwArgs
#                    return function(self, *args, **extraKwArgs)
#
#                methodWithAutomaticArgs.__name__ = function.__name__
#                methodWithAutomaticArgs.__doc__ = function.__doc__
#                return methodWithAutomaticArgs
#
#            if mayaCmdWillFail:
#                @feedArgs
#                def mayaTest(self, *args, **kwargs):
#                    '''maya.cmds.%s fails on %s'''
#                    self.assertRaises(TypeError, mayaCmd, *args, **kwargs)
#            else:
#                # if the maya command succeeds, no need to test the wrapped
#                @feedArgs
#                def mayaTest(self, *args, **kwargs):
#                    '''maya.cmds.%s handles %s'''
##                    print "%s(" % mayaCmd.__name__,
##                    print ", ".join([unicode(x) for x in args]),
##                    for key, val in kwargs: print "%s=%s," % (key,val),
##                    print ")"
#                    self.assertNoError(mayaCmd, *args, **kwargs)
#
#            @feedArgs
#            def wrappedTest(self, *args, **kwargs):
#                '''pymel.%s handles %s'''
##                print "%s(" % wrappedCmd.__name__,
##                print ", ".join([unicode(x) for x in args]),
##                for key, val in kwargs: print "%s=%s," % (key,val),
##                print ")"
#                self.assertNoError(wrappedCmd, *args, **kwargs)
#
#            for testMethod in (mayaTest, wrappedTest):
#                testMethod.__name__ = "_".join(["test", cmdName, testMethod.__name__, "on"] + nameSuffixList)
#                testMethod.__doc__ = testMethod.__doc__ % (cmdName, " ".join(nameSuffixList))
#                while(hasattr(cls, testMethod.__name__)):
#                    testMethod.__name__ += '1'
#                setattr(cls, testMethod.__name__, testMethod)
#
#            if mayaCmdWillFail:
#                mayaTests_shouldFail.append(mayaTest.__name__)
#            else:
#                mayaTests_shouldPass.append(mayaTest.__name__)
#            wrappedTests.append(wrappedTest.__name__)
#
#        # 1. cmdName(arg1String, arg2String)
#        addTestPair(mayaCmdWillFail=False)
#
#        # 2. cmdName(arg1PyNode, arg2Pynode)
#        addTestPair(mayaCmdWillFail=mayaFailsOnCustomStrings, testPyNodes=True)
#
#        if canTakeListArg:
#            # 3. cmdName([arg1String, arg2String])
#            addTestPair(mayaCmdWillFail=False, useListArg=True)
#
#            # 4. cmdname([arg1PyNode, arg2Pynode])
#            addTestPair(mayaCmdWillFail=mayaFailsOnCustomStringsInNormalLists,
#                        useListArg=True, testPyNodes=True)
#
#            # 5. cmdname(Mylist([arg1String, arg2String]))
#            addTestPair(mayaCmdWillFail=mayaFailsOnCustomLists,
#                        useListArg=True, testCustomLists=True)
#
#            # 6. cmdname(Mylist([arg1PyNode, arg2Pynode]))
#            addTestPair(mayaCmdWillFail=mayaFailsOnCustomLists,
#                        useListArg=True, testPyNodes=True, testCustomLists=True),
#
#
#    # Need to put this in separate method, b/c addTestsForCmd is a classmethod, and can't access
#    # self.lists directly
#    def getArgs(self, typeOfArgs, numOfArgs, testPyNodes, useListArg, testCustomLists, *args):
#        pynodeArgs =  self.lists[typeOfArgs]
#        if numOfArgs is not None:
#            while numOfArgs > len(pynodeArgs):
#                pynodeArgs = pynodeArgs + pynodeArgs
#            pynodeArgs = pynodeArgs[:numOfArgs]
#        stringArgs = [unicode(x) for x in pynodeArgs]
#
#        if testPyNodes:
#            testedArgs = pynodeArgs
#        else:
#            testedArgs = stringArgs
#
#        if useListArg:
#            if testCustomLists:
#                testedArgs = [Mylist(testedArgs)]
#            else:
#                testedArgs = [testedArgs]
#
##        print "testedArgs: %s" % testedArgs
#        return testedArgs + list(args)
#
## Reference:
##TestWrappedCmds.addTestsForCmd(cmdName, typeOfArgs,
##                       failsOnCustomStrings=False, failsOnCustomLists=False, \
##                       numOfArgs=None, canTakeListArg=False, *args, **kwargs)
#
## I don't really need the "absolute" here, was really just making sure extraKwArgs worked...
#TestWrappedCmds.addTestsForCmd('group', 'transform', mayaFailsOnCustomStrings=True, mayaFailsOnCustomLists=True, canTakeListArg=True, extraKwArgs={'absolute':1})
#TestWrappedCmds.addTestsForCmd('select', 'transform', mayaFailsOnCustomStrings=True, mayaFailsOnCustomLists=True, canTakeListArg=True)
#TestWrappedCmds.addTestsForCmd('connectAttr', 'attribute', mayaFailsOnCustomStrings=True, extraKwArgs={'force':1})
#TestWrappedCmds.addTestsForCmd('disconnectAttr', 'attribute2', mayaFailsOnCustomStrings=True)
#TestWrappedCmds.addTestsForCmd('listConnections', 'attribute2', mayaFailsOnCustomStrings=True,
#                               mayaFailsOnCustomLists=True, canTakeListArg=True)
#TestWrappedCmds.addTestsForCmd('getAttr', 'attribute', mayaFailsOnCustomStrings=True, numOfArgs=1)
#TestWrappedCmds.addTestsForCmd('setAttr', 'attribute', mayaFailsOnCustomStrings=True, numOfArgs=1, extraArgs=[3])
#TestWrappedCmds.addTestsForCmd('listAttr', 'transform', mayaFailsOnCustomStrings=True, mayaFailsOnCustomLists=True, canTakeListArg=True)
#TestWrappedCmds.addTestsForCmd('listAttr', 'attribute', mayaFailsOnCustomStrings=True, mayaFailsOnCustomLists=True, canTakeListArg=True)
#TestWrappedCmds.addTestsForCmd('attributeInfo', 'attribute', mayaFailsOnCustomStrings=True, mayaFailsOnCustomLists=True, canTakeListArg=True,
#                               extraKwArgs={'allAttributes':True})
#TestWrappedCmds.addTestsForCmd('listRelatives', 'transform', mayaFailsOnCustomStrings=True, mayaFailsOnCustomLists=True, canTakeListArg=True)
##TestWrappedCmds.addTestsForCmd('connectAttr', 'attribute', failsOnCustomStrings=True, failsOnCustomLists=True, canTakeListArg=True)
#
#mayaCmdsSuite_shouldPass = unittest.TestSuite()
#mayaCmdsSuite_shouldFail = unittest.TestSuite()
#wrappedCmdsSuite = unittest.TestSuite()
#
#for suite, testList in ( (mayaCmdsSuite_shouldPass, mayaTests_shouldPass),
#                         (mayaCmdsSuite_shouldFail, mayaTests_shouldFail),
#                         (wrappedCmdsSuite, wrappedTests) ):
#    for test in testList:
#        suite.addTest(TestWrappedCmds(test))
#
#mayaCmdsSuite = unittest.TestSuite()
#mayaCmdsSuite.addTests(mayaCmdsSuite_shouldPass)
#if testMayaFailures:
#    mayaCmdsSuite.addTests(mayaCmdsSuite_shouldFail)
#
#allSuite = unittest.TestSuite()
#allSuite.addTests( (mayaCmdsSuite, wrappedCmdsSuite) )
#
#def suite():
#    if testMayaCmds:
#        return allSuite
#    else:
#        return wrappedCmdsSuite
#
#def main():
#    unittest.TextTestRunner(stream=sys.stdout, verbosity=2).run(suite())
#
#setupUnittestModule(__name__)

########NEW FILE########
__FILENAME__ = test_py2mel
import unittest

import maya.mel as mel
import pymel.core as pm
import pymel.versions as versions

import pymel.tools.py2mel as py2mel

WRAPPED_CMDS = {}

class MyClassNoArgs(object):
    def noArgs(self):
        return "foo"

    def oneArg(self, arg1):
        return arg1 * 2

    def oneKwarg(self, kwarg1='default'):
        return kwarg1 * 2

    def oneArgOneKwarg(self, arg1, kwarg1='default'):
        return arg1 + kwarg1

    def oneArgTwoKwarg(self, arg1, kwarg1='ate', kwarg2='trex'):
        return '%s %s %s!' % (arg1, kwarg1, kwarg2)

class testCaseClassWrap(unittest.TestCase):
    def wrapClass(self, toWrap, cmdName, *args, **kwargs):
        global WRAPPED_CMDS
        if cmdName not in WRAPPED_CMDS:
            py2mel.py2melCmd(toWrap, commandName=cmdName, *args, **kwargs)
            WRAPPED_CMDS[cmdName] = toWrap
        elif WRAPPED_CMDS[cmdName] != toWrap:
            raise RuntimeError('error - already another command called %s' % cmdName)

    def assertMelError(self, cmd):
        # in maya 2014, a RuntimeError is raised... yay!
        if versions.current() >= versions.v2014:
            self.assertRaises(RuntimeError, mel.eval, cmd)
        else:
            # tried catch/catchQuiet, but they always return 0...
            self.assertEqual(mel.eval(cmd), None)

    def test_autoName(self):
        self.wrapClass(MyClassNoArgs, None)
        self.assertEqual(mel.eval('''MyClassNoArgs -noArgs'''), 'foo')

    def test_noArgs(self):
        self.wrapClass(MyClassNoArgs, 'myCls')
        self.assertEqual(mel.eval('''myCls -noArgs'''), 'foo')

    def test_oneArg(self):
        self.wrapClass(MyClassNoArgs, 'myCls')
        self.assertEqual(mel.eval('''myCls -oneArg stuff'''), 'stuffstuff')

    def test_oneKwarg(self):
        self.wrapClass(MyClassNoArgs, 'myCls')
        self.assertEqual(mel.eval('''myCls -oneKwarg goober'''), 'goobergoober')

    def test_oneKwarg_notEnoughArgsErr(self):
        self.wrapClass(MyClassNoArgs, 'myCls')
        self.assertMelError('''myCls -oneKwarg''')

    def test_oneArgOneKwarg(self):
        self.wrapClass(MyClassNoArgs, 'myCls')
        self.assertEqual(mel.eval('''myCls -oneArgOneKwarg stuff thing'''), 'stuffthing')

    def test_oneArgOneKwarg_notEnoughArgsErr(self):
        self.wrapClass(MyClassNoArgs, 'myCls')
        self.assertMelError('''myCls -oneArgOneKwarg''')
        self.assertMelError('''myCls -oneArgOneKwarg stuff''')

    def test_nameTooShort(self):
        class ShortFuncCls(object):
            def go(self):
                return 'Manitoba'
        self.wrapClass(ShortFuncCls, 'myShort')
        self.assertEqual(mel.eval('''myShort -goxx'''), 'Manitoba')
        self.assertEqual(mel.eval('''myShort -g'''), 'Manitoba')

    def test_excludeFlag(self):
        self.wrapClass(MyClassNoArgs, 'myCls2', excludeFlags=['oneKwarg'])
        self.assertEqual(mel.eval('''myCls2 -oneArg stuff'''), 'stuffstuff')
        self.assertMelError('''myCls2 -oneKwarg goober''')

    def test_excludeFlagArg(self):
        self.wrapClass(MyClassNoArgs, 'myCls3', excludeFlagArgs={'oneKwarg':['kwarg1']})
        self.assertEqual(mel.eval('''myCls3 -oneKwarg'''), 'defaultdefault')
        self.assertMelError('''myCls3 -oneKwarg goober''')

    def test_excludeFlagArg_orderChanged(self):
        self.wrapClass(MyClassNoArgs, 'myCls4', excludeFlagArgs={'oneArgTwoKwarg':['kwarg1']})
        self.assertMelError('''myCls4 -oneArgTwoKwarg foo''')
        self.assertEqual(mel.eval('''myCls4 -oneArgTwoKwarg "Little Bo PeeP" Batman'''), 'Little Bo PeeP ate Batman!')
        self.assertMelError('''myCls4 -oneArgTwoKwarg defenestrated You Spiderman''')

########NEW FILE########
__FILENAME__ = test_system
import os
import unittest
import tempfile
import shutil
import itertools
from pprint import pprint

import pymel.core as pm
import maya.cmds as cmds

class testCase_references(unittest.TestCase):

    def setUp(self):
        self.temp = os.path.join(tempfile.gettempdir(), 'referencesTest')
        if not os.path.isdir(self.temp):
            os.makedirs(self.temp)
        print "created temp dir: %s" % self.temp


        # Refs:
        #  sphere.ma
        #    (no refs)
        #  cube.ma
        #    :sphere => sphere.ma
        #  cone.ma
        #    :cubeInCone => cube.ma
        #      :cubeInCone:sphere => sphere.ma
        #  master.ma
        #    :sphere1 => sphere.ma
        #    :sphere2 => sphere.ma
        #    :cube1 => cube.ma
        #      :cube1:sphere => sphere.ma
        #    :cone1 => cone.ma
        #      :cone1:cubeInCone => cube.ma
        #        :cone1:cubeInCone:sphere => sphere.ma

        # create sphere file
        print "sphere file"
#        cmds.file(new=1, f=1)
        pm.newFile(f=1)
        sphere = pm.polySphere()
        # We will use this to test failed ref edits...
        pm.addAttr(sphere, ln='zombieAttr')
        self.sphereFile = pm.saveAs( os.path.join( self.temp, 'sphere.ma' ), f=1 )

        # create cube file
        print "cube file"
        pm.newFile(f=1)
        pm.polyCube()
        pm.createReference( self.sphereFile, namespace='sphere' )
        pm.PyNode('sphere:pSphere1').attr('translateX').set(2)
        self.cubeFile = pm.saveAs( os.path.join( self.temp, 'cube.ma' ), f=1 )

        # create cone file
        print "cone file"
        pm.newFile(f=1)
        pm.polyCone()
        pm.createReference( self.cubeFile, namespace='cubeInCone' )
        pm.PyNode('cubeInCone:pCube1').attr('translateZ').set(2)
        pm.PyNode('cubeInCone:sphere:pSphere1').attr('translateZ').set(2)
        self.coneFile = pm.saveAs( os.path.join( self.temp, 'cone.ma' ), f=1 )

        print "master file"
        pm.newFile(f=1)
        self.sphereRef1 = pm.createReference( self.sphereFile, namespace='sphere1' )
        pm.PyNode('sphere1:pSphere1').attr('translateY').set(2)
        self.sphereRef2 = pm.createReference( self.sphereFile, namespace='sphere2' )
        pm.PyNode('sphere2:pSphere1').attr('translateY').set(4)
        self.cubeRef1 = pm.createReference( self.cubeFile, namespace='cube1' )
        pm.PyNode('cube1:sphere:pSphere1').attr('translateY').set(6)
        pm.PyNode('cube1:pCube1').attr('translateY').set(6)
        self.coneRef1 = pm.createReference( self.coneFile, namespace='cone1' )
        self.masterFile = pm.saveAs(os.path.join(self.temp, 'master.ma'), f=1)

    def tearDown(self):
        pm.newFile(f=1)
        shutil.rmtree(self.temp, ignore_errors=True)

    def createFailedEdits(self):
        # Animate the zombieAttrs
        for transform in [x.getParent() for x in pm.ls(type='mesh')]:
            try:
                zombie = transform.attr('zombieAttr')
            except pm.MayaAttributeError:
                continue
            zombie.setKey(t=1, v=1)
            zombie.setKey(t=2, v=2)
            zombie.setKey(t=3, v=4)

        # want to create another successful edit, so we can tell just by number of edits
        # whether we got failed, successful, or both
        #   failed = 1
        #   successful = 2
        #   both = 3
        pm.setAttr(self.sphereRef1.namespace + ':pSphere1.rotate', (30,0,0))

        self.masterFile = pm.saveAs(os.path.join(self.temp, 'master.ma'), f=1)


        # deleting the attr should give some failed ref edits in the master...
        pm.openFile(self.sphereFile, f=1)
        pm.SCENE.pSphere1.zombieAttr.delete()
        pm.saveFile(f=1)

        pm.openFile(self.masterFile, f=1)
        self.sphereRef1 = pm.FileReference(namespace='sphere1')
        self.sphereRef2 = pm.FileReference(namespace='sphere2')
        self.cubeRef1 = pm.FileReference(namespace='cube1')
        self.coneRef1 = pm.FileReference(namespace='cone1')

    def test_iterRefs_depth(self):
        # Test that each subsequent ref is either a child of the previous ref,
        # or the sibling of of some ref higher in the stack'''
        refStack = []
        for ref in pm.iterReferences(recursive=True):
            splitNS = ref.fullNamespace.split(':')
            if len(splitNS) <= len(refStack):
                refStack = refStack[:len(splitNS) - 1]

            self.assertEqual(splitNS[:-1], refStack)
            refStack.append(ref.namespace)

    def test_iterRefs_breadth(self):
        # Test that each subsequent ref is has a recursive depth >= the
        # previous ref
        refDepth = 0
        for ref in pm.iterReferences(recursive=True, recurseType='breadth'):
            splitNS = ref.fullNamespace.split(':')
            thisDepth = len(splitNS)
            self.assertTrue(thisDepth >= refDepth)
            refDepth = thisDepth

    def test_basic_file_cmds(self):
        print "Exporting all", os.path.join( self.temp, 'all.ma' )
        expFile = pm.exportAll( os.path.join( self.temp, 'all.ma' ), preserveReferences=1, force=1)
        print "Importing"
        pm.importFile( expFile )
        print "Exporting all"
        pm.exportAll( os.path.join( self.temp, 'all.ma' ), preserveReferences=1, force=1)
        print "Exporting animation"
        pm.exportAnim( os.path.join( self.temp, 'anim.ma' ), force=1)
        pm.select(pm.SCENE.persp)
        print "Exporting selected animation"
        pm.exportSelectedAnim( os.path.join( self.temp, 'selAnim.ma' ), force=1)

    def test_file_reference(self):
        self.assert_( isinstance( self.sphereRef1, pm.FileReference ) )
        self.assert_( isinstance( self.sphereRef1.refNode, pm.PyNode ) )
        self.assert_( self.sphereRef1.namespace == 'sphere1' )
        self.assert_( self.sphereRef1.isLoaded() )
        self.sphereRef1.unload()
        self.assert_( self.sphereRef1.isDeferred() )
        self.sphereRef1.load()
        self.sphereRef1.exportAnim( os.path.join( self.temp, 'refAnim.ma' ), force=1 )
        pm.select( self.sphereRef1.nodes() )
        self.sphereRef1.exportSelectedAnim( os.path.join( self.temp, 'selRefAnim.ma' ), force=1 )
        self.sphereRef1.remove()
        self.sphereRef2.importContents()

    def test_file_reference_creation(self):
        for ref in pm.listReferences(recursive=True):
            self.assertEqual(ref, pm.FileReference(pm.PyNode(ref.refNode)))
            self.assertEqual(ref, pm.FileReference(str(ref.refNode)))
            self.assertEqual(ref, pm.FileReference(pm.Path(ref.withCopyNumber())))
            self.assertEqual(ref, pm.FileReference(str(ref.withCopyNumber())))
            self.assertEqual(ref, pm.FileReference(namespace=ref.fullNamespace))

    def test_failed_ref_edits(self):
        self.createFailedEdits()

        sphereRefs = [x for x in pm.listReferences(recursive=True)
                      if x.path.endswith('sphere.ma')]
        for ref in sphereRefs:
            print "testing failed ref edits on: %s" % ref
            self.assertEqual(1, len(pm.referenceQuery(ref,successfulEdits=False,failedEdits=True,es=True)))
            self.assertEqual(1, len(cmds.referenceQuery(str(ref.refNode), successfulEdits=False,failedEdits=True,es=True)))

    def test_import(self):
        ref = self.sphereRef1
        sphere = 'sphere1:pSphere1'
        self.assertTrue(pm.PyNode(sphere).isReferenced())
        ref.importContents()
        self.assertFalse(pm.PyNode(sphere).isReferenced())

    def test_import_remove_namespace(self):
        ref = self.sphereRef1
        nsSphere = 'sphere1:pSphere1'
        noNsSphere = 'pSphere1'
        self.assertTrue(pm.PyNode(nsSphere).isReferenced())
        self.assertFalse(pm.objExists(noNsSphere))
        ref.importContents(removeNamespace=True)
        self.assertFalse(pm.objExists(nsSphere))
        self.assertFalse(pm.PyNode(noNsSphere).isReferenced())

    def test_getReferenceEdits(self):
        def doTest(successfulEdits, failedEdits, force, expectedNum):
            self.setUp()
            self.createFailedEdits()

            # Should have 3 total, 2 successful, 1 failed
            refNode = str(self.sphereRef1.refNode)
            testKwargs = {'editStrings':True, 'onReferenceNode':refNode}

            testKwargs['successfulEdits'] = False
            testKwargs['failedEdits'] = True
            self.assertEqual(len(cmds.referenceQuery(refNode, **testKwargs)), 1)

            testKwargs['successfulEdits'] = True
            testKwargs['failedEdits'] = False
            self.assertEqual(len(cmds.referenceQuery(refNode, **testKwargs)), 2)

            testKwargs['successfulEdits'] = True
            testKwargs['failedEdits'] = True
            self.assertEqual(len(cmds.referenceQuery(refNode, **testKwargs)), 3)

            kwargs = {}
            if successfulEdits is not None:
                kwargs['successfulEdits'] = successfulEdits
            if failedEdits is not None:
                kwargs['failedEdits'] = failedEdits

            self.assertEqual(len(self.sphereRef1.getReferenceEdits(**kwargs)),
                             expectedNum)

        for force in (True, False):
            doTest(None, None, force, 3)    # should get all
            doTest(None, True, force, 1)    # should get failed
            doTest(None, False, force, 2)   # should get successful

            doTest(True, None, force, 2)    # should get successful
            doTest(True, True, force, 3)    # should get all
            doTest(True, False, force, 2)   # should get successful

            doTest(False, None, force, 1)   # should get failed
            doTest(False, True, force, 1)   # should get failed
            doTest(False, False, force, 0)  # should get none


    def test_removeReferenceEdits(self):
        def doTest(successfulEdits, failedEdits, force, expectedNum):
            self.setUp()
            self.createFailedEdits()

            # Should have 3 total, 2 successful, 1 failed
            refNode = str(self.sphereRef1.refNode)
            getKwargs = {'editStrings':True, 'onReferenceNode':refNode}

            getKwargs['successfulEdits'] = False
            getKwargs['failedEdits'] = True
            self.assertEqual(len(cmds.referenceQuery(refNode, **getKwargs)), 1)

            getKwargs['successfulEdits'] = True
            getKwargs['failedEdits'] = False
            self.assertEqual(len(cmds.referenceQuery(refNode, **getKwargs)), 2)

            getKwargs['successfulEdits'] = True
            getKwargs['failedEdits'] = True
            self.assertEqual(len(cmds.referenceQuery(refNode, **getKwargs)), 3)

            kwargs = {'removeEdits':True}
            if successfulEdits is not None:
                kwargs['successfulEdits'] = successfulEdits
            if failedEdits is not None:
                kwargs['failedEdits'] = failedEdits

            if force:
                kwargs['force'] = True
            else:
                self.sphereRef1.unload()

            self.sphereRef1.removeReferenceEdits(**kwargs)

            self.assertEqual(len(cmds.referenceQuery(refNode, **getKwargs)),
                             expectedNum)

        for force in (True, False):
            doTest(None, None, force, 0)    # should remove all
            doTest(None, True, force, 2)    # should remove failed
            doTest(None, False, force, 1)   # should remove successful

            doTest(True, None, force, 1)    # should remove successful
            doTest(True, True, force, 0)    # should remove all
            doTest(True, False, force, 1)   # should remove successful

            doTest(False, None, force, 2)   # should remove failed
            doTest(False, True, force, 2)   # should remove failed
            doTest(False, False, force, 3)  # should remove none

    def test_parent(self):
        self.assertEqual(pm.FileReference(namespace='sphere1').parent(), None)
        self.assertEqual(pm.FileReference(namespace='sphere2').parent(), None)
        self.assertEqual(pm.FileReference(namespace='cube1').parent(), None)
        self.assertEqual(pm.FileReference(namespace='cone1').parent(), None)

        self.assertEqual(pm.FileReference(namespace='cube1:sphere').parent(),
                         pm.FileReference(namespace='cube1'))
        self.assertEqual(pm.FileReference(namespace='cone1:cubeInCone').parent(),
                         pm.FileReference(namespace='cone1'))
        self.assertEqual(pm.FileReference(namespace='cone1:cubeInCone:sphere').parent(),
                         pm.FileReference(namespace='cone1:cubeInCone'))

    def test_listReferences(self):
        self.assertEqual(set(pm.listReferences()),
                         set([pm.FileReference(namespace='sphere1'),
                              pm.FileReference(namespace='sphere2'),
                              pm.FileReference(namespace='cube1'),
                              pm.FileReference(namespace='cone1'),
                             ]))

    def test_listReferences_recursive(self):
        self.assertEqual(set(pm.listReferences(recursive=True)),
                         set([pm.FileReference(namespace='sphere1'),
                              pm.FileReference(namespace='sphere2'),
                              pm.FileReference(namespace='cube1'),
                              pm.FileReference(namespace='cone1'),
                              pm.FileReference(namespace='cube1:sphere'),
                              pm.FileReference(namespace='cone1:cubeInCone'),
                              pm.FileReference(namespace='cone1:cubeInCone:sphere'),
                             ]))

    def _test_listReferences_options(self, expectedRefs, kwargs):
        for namespaces in (True, False):
            for refNodes in (True, False):
                for references in (True, False):
                    expected = set()
                    for ref in expectedRefs:
                        thisExpected = []
                        if namespaces:
                            thisExpected.append(ref.fullNamespace)
                        if refNodes:
                            thisExpected.append(ref.refNode)
                        if references:
                            thisExpected.append(ref)
                        if len(thisExpected) == 1:
                            thisExpected = thisExpected[0]
                        else:
                            thisExpected = tuple(thisExpected)
                        expected.add(thisExpected)
                    result = pm.listReferences(namespaces=namespaces,
                                               refNodes=refNodes,
                                               references=references,
                                               **kwargs)
                    self.assertEqual(set(result), expected)

    def test_listReferences_options(self):
        expectedRefs = set([pm.FileReference(namespace='sphere1'),
                            pm.FileReference(namespace='sphere2'),
                            pm.FileReference(namespace='cube1'),
                            pm.FileReference(namespace='cone1'),
                           ])
        self._test_listReferences_options(expectedRefs, {})

    def test_listReferences_options_recursive(self):
        expectedRefs = set([pm.FileReference(namespace='sphere1'),
                            pm.FileReference(namespace='sphere2'),
                            pm.FileReference(namespace='cube1'),
                            pm.FileReference(namespace='cone1'),
                            pm.FileReference(namespace='cube1:sphere'),
                            pm.FileReference(namespace='cone1:cubeInCone'),
                            pm.FileReference(namespace='cone1:cubeInCone:sphere'),
                           ])
        self._test_listReferences_options(expectedRefs, {'recursive':True})

    def test_listReferences_loaded_unloaded(self):
        def doTestForKwargPermutation(loaded, unloaded, expected):
            kwargs = {}
            if loaded is not None:
                kwargs['loaded'] = loaded
            if unloaded is not None:
                kwargs['unloaded'] = unloaded

            allRefs = pm.listReferences(recursive=True)

            if expected == 'all':
                expected = set(allRefs)
            elif expected == 'loaded':
                expected = set(x for x in allRefs if x.isLoaded())
            elif expected == 'unloaded':
                expected = set(x for x in allRefs if not x.isLoaded())
            elif expected == 'none':
                expected = set()
            else:
                raise ValueError(expected)

            result = set(pm.listReferences(recursive=True, **kwargs))
            self.assertEqual(result, expected)

            expected = set(x for x in expected if x.parent() is None)
            result = set(pm.listReferences(recursive=False, **kwargs))
            self.assertEqual(result, expected)

        def doTestForRefPermuation(loadedByNS):
            self.setUp()

            # Note that we always need to track by namespace... we cannot use
            # persistant FileReferences objects, since they are tied to
            # a reference node... and if a parent reference node is unloaded,
            # they may be come invalid

            for ns, loaded in loadedByNS.iteritems():
                if not loaded:
                    ref = pm.FileReference(namespace=ns)
                    if not loaded:
                        print "unloading: %r" % ns
                        ref.unload()

            pprint(loadedByNS)

            # All files should now be set up with the appropriate
            # loaded/unloaded refs... confirm
            for ns, loaded in loadedByNS.iteritems():
                try:
                    wasLoaded = pm.FileReference(namespace=ns).isLoaded()
                except RuntimeError:
                    wasLoaded = False
                self.assertEqual(loaded, wasLoaded)

            doTestForKwargPermutation(None, None, 'all')
            doTestForKwargPermutation(None, True, 'unloaded')
            doTestForKwargPermutation(None, False, 'loaded')

            doTestForKwargPermutation(True, None, 'loaded')
            doTestForKwargPermutation(True, True, 'all')
            doTestForKwargPermutation(True, False, 'loaded')

            doTestForKwargPermutation(False, None, 'unloaded')
            doTestForKwargPermutation(False, True, 'unloaded')
            doTestForKwargPermutation(False, False, 'none')

        def loadedRefPermutations(parentReference=None):
            '''Returns dicts mapping from namespaces to whether they are loaded
            or not

            Returns all possible such dicts, taking into account the fact that
            if a ref is unloaded, all it's subrefs will also be unloaded (and,
            in fact, won't even seem to exist)
            '''
            finalPermutations = []

            namespaces = pm.listReferences(parentReference=parentReference,
                                           namespaces=True,
                                           references=False)

            # now, get all the possible permutations for each sub-ref, assuming
            # that sub-ref is loaded

            subPermutationsByNS = {}
            for namespace in namespaces:
                subsForNS = loadedRefPermutations(parentReference=pm.FileReference(namespace=namespace))
                if subsForNS:
                    subPermutationsByNS[namespace] = subsForNS

            # Now get all loaded/unloaded permutations for top namespaces...
            for loadedVals in itertools.product((True, False),
                                                repeat=len(namespaces)):
                topByNamespace = dict(zip(namespaces, loadedVals))

                # then, find any sub-permutations for refs which are loaded
                possibleSubPermutations = []
                for ns, loaded in topByNamespace.iteritems():
                    if loaded and ns in subPermutationsByNS:
                        possibleSubPermutations.append(subPermutationsByNS[ns])

                # finally, if we iterate over all the products of all possible
                # sub-perms, and combine all the resulting dicts, we should
                # get all the final permutations...
                if possibleSubPermutations:
                    for subPermSelections in itertools.product(*possibleSubPermutations):
                        topCopy = dict(topByNamespace)
                        for subPermItem in subPermSelections:
                            topCopy.update(subPermItem)
                        finalPermutations.append(topCopy)
                else:
                    # there are no sub-permutations, just append the current
                    # permutation for top-level refs
                    finalPermutations.append(topByNamespace)
            return finalPermutations

        allPerms = loadedRefPermutations()
        # sanity check - should be 48 perms
        self.assertEqual(len(allPerms), 48)
        for loadedByNS in allPerms:
            doTestForRefPermuation(loadedByNS)

    def test_fullNamespace(self):
        # first, test that the namespaces are as expected, when all the ref
        # nodes are "normal" / unaltered

        expected = [
            (u'sphere1',
             pm.FileReference(u'/usr/tmp/referencesTest/sphere.ma',
                               refnode=u'sphere1RN')),
            (u'sphere2',
             pm.FileReference(u'/usr/tmp/referencesTest/sphere.ma{1}',
                              refnode=u'sphere2RN')),
            (u'cube1',
             pm.FileReference(u'/usr/tmp/referencesTest/cube.ma',
                              refnode=u'cube1RN')),
            (u'cube1:sphere',
             pm.FileReference(u'/usr/tmp/referencesTest/sphere.ma{2}',
                              refnode=u'cube1:sphereRN')),
            (u'cone1',
             pm.FileReference(u'/usr/tmp/referencesTest/cone.ma',
                              refnode=u'cone1RN')),
            (u'cone1:cubeInCone',
             pm.FileReference(u'/usr/tmp/referencesTest/cube.ma{1}',
                              refnode=u'cone1:cubeInConeRN')),
            (u'cone1:cubeInCone:sphere',
             pm.FileReference(u'/usr/tmp/referencesTest/sphere.ma{3}',
                              refnode=u'cone1:cubeInCone:sphereRN'))
        ]

        self.assertEqual(pm.listReferences(namespaces=1, recursive=1),
                         expected)

        self.assertEqual(self.coneRef1.namespace, 'cone1')
        self.assertEqual(self.coneRef1.fullNamespace, 'cone1')
        self.assertEqual(self.coneRef1.refNode.namespace(), '')

        cubeInConeRef = pm.FileReference(refnode='cone1:cubeInConeRN')
        self.assertEqual(cubeInConeRef.namespace, 'cubeInCone')
        self.assertEqual(cubeInConeRef.fullNamespace, 'cone1:cubeInCone')
        self.assertEqual(cubeInConeRef.refNode.namespace(), 'cone1:')

        sphereInCubeInConeRef = pm.FileReference(refnode='cone1:cubeInCone:sphereRN')
        self.assertEqual(sphereInCubeInConeRef.namespace, 'sphere')
        self.assertEqual(sphereInCubeInConeRef.fullNamespace,
                         'cone1:cubeInCone:sphere')
        self.assertEqual(sphereInCubeInConeRef.refNode.namespace(),
                         'cone1:cubeInCone:')

        # now, try changing the namespace of one of the refnodes...
        pm.Namespace.create('foobar')
        coneRefNode = self.coneRef1.refNode
        coneRefNode.unlock()
        coneRefNode.rename('foobar:%s' % coneRefNode)
        coneRefNode.lock()

        # now, make sure that results are as expected (ie, the namespace of the
        # reference itself should be UNCHANGED, even though the namespace of the
        # reference node has changed...
        self.assertEqual(pm.listReferences(namespaces=1, recursive=1),
                         expected)

        self.assertEqual(self.coneRef1.namespace, 'cone1')
        self.assertEqual(self.coneRef1.fullNamespace, 'cone1')
        self.assertEqual(self.coneRef1.refNode.namespace(), 'foobar:')

        self.assertEqual(cubeInConeRef.namespace, 'cubeInCone')
        self.assertEqual(cubeInConeRef.fullNamespace, 'cone1:cubeInCone')
        self.assertEqual(cubeInConeRef.refNode.namespace(), 'cone1:')

        self.assertEqual(sphereInCubeInConeRef.namespace, 'sphere')
        self.assertEqual(sphereInCubeInConeRef.fullNamespace,
                         'cone1:cubeInCone:sphere')
        self.assertEqual(sphereInCubeInConeRef.refNode.namespace(),
                         'cone1:cubeInCone:')

    def test_live_edits_returning_an_empty_list(self):
        """testing if the le=True or liveEdits=True with no reference edit will
        return an empty list
        """
        # create a new reference with no edits
        ref = pm.createReference(self.sphereFile, namespace='sphere')
        edits = pm.referenceQuery(ref, es=1, le=1)
        self.assertEqual(edits, [])

class testCase_fileInfo(unittest.TestCase):
    def setUp(self):
        pm.newFile(f=1)
        cmds.fileInfo('testKey', 'testValue')

    def test_get(self):
        default = "the default value!"
        self.assertEqual(pm.fileInfo.get('NoWayDoIExist', default), default)
        self.assertEqual(pm.fileInfo.get('NoWayDoIExist'), None)
        self.assertEqual(pm.fileInfo.get('testKey'), cmds.fileInfo('testKey', q=1)[0])

    def test_getitem(self):
        self.assertRaises(KeyError, lambda: pm.fileInfo['NoWayDoIExist'])
        self.assertEqual(pm.fileInfo['testKey'], cmds.fileInfo('testKey', q=1)[0])

class testCase_namespaces(unittest.TestCase):
    recurseAvailable= ( pm.versions.current() >= pm.versions.v2011 )

    def setUp(self):
        cmds.file(f=1, new=1)
        cmds.namespace( add='FOO' )
        cmds.namespace( add='BAR' )
        cmds.namespace( add='FRED' )
        cmds.namespace( add='BAR', parent=':FOO')
        cmds.namespace( add='CALVIN', parent=':FOO:BAR')
        cmds.sphere( n='FOO:sphere1' )
        cmds.sphere( n='FOO:sphere2' )
        cmds.sphere( n='BAR:sphere1' )
        cmds.sphere( n='FOO:BAR:sphere1' )

    def test_listNodes(self):
        self.assertEqual(set(pm.Namespace('FOO').listNodes()),
                         set([pm.PyNode('FOO:sphere1'),
                              pm.PyNode('FOO:sphere1Shape'),
                              pm.PyNode('FOO:sphere2'),
                              pm.PyNode('FOO:sphere2Shape'),
                              ]))

        if self.recurseAvailable:
            self.assertEqual( set(pm.Namespace('FOO').listNodes(recursive=False)),
                              set([pm.PyNode('FOO:sphere1'),
                                   pm.PyNode('FOO:sphere1Shape'),
                                   pm.PyNode('FOO:sphere2'),
                                   pm.PyNode('FOO:sphere2Shape'),
                                   ]))
            self.assertEqual( set(pm.Namespace('FOO').listNodes(recursive=True)),
                              set([pm.PyNode('FOO:sphere1'),
                                   pm.PyNode('FOO:sphere1Shape'),
                                   pm.PyNode('FOO:sphere2'),
                                   pm.PyNode('FOO:sphere2Shape'),
                                   pm.PyNode('FOO:BAR:sphere1'),
                                   pm.PyNode('FOO:BAR:sphere1Shape'),
                              ]))
    def test_listNamespaces(self):
        self.assertEqual(set(pm.Namespace('FOO').listNamespaces()),
                         set([pm.Namespace('FOO:BAR'),
                              ]))

        if self.recurseAvailable:
            self.assertEqual(set(pm.Namespace('FOO').listNamespaces(recursive=False)),
                             set([pm.Namespace('FOO:BAR'),
                                  ]))
            self.assertEqual(set(pm.Namespace('FOO').listNamespaces(recursive=True)),
                             set([pm.Namespace('FOO:BAR'),
                                  pm.Namespace('FOO:BAR:CALVIN')
                                  ]))

########NEW FILE########
__FILENAME__ = test_testingutils
import sys, unittest
import pymel.util.testing as testingutils

class TestAssertIteration(testingutils.TestCaseExtended):
    #################################################
    ## orderMatters=True, onlyMembershipMatters=False
    #################################################
    def test_defaults_01_exact(self):
        self.assertIteration( "foo", ['f', 'o', 'o'])

    def test_defaults_02_noRepeatedElements(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o'])

    def test_defaults_03_missingUniqueElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['o', 'o'])

    def test_defaults_04_missingNonUniqueElements(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f'])

    def test_defaults_05_extraUniqueElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'o', 'f'])

    def test_defaults_06_extraNonUniqueElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'o', 'o'])

    def test_defaults_07_extraNewElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'o', 'x'])

    def test_defaults_08_nonUniqueElementReplacedWithNewElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'x'])

    def test_defaults_09_nonUniqueElementReplacedWithUniqueElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'f'])

    def test_defaults_10_wrongOrder(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['o', 'f', 'o'])

    def test_defaults_11_noRepeatedElementsWrongOrder(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['o', 'f'])



    #################################################
    ## orderMatters=True, onlyMembershipMatters=True
    #################################################
    def test_onlyMembership_01_exact(self):
        self.assertIteration( "foo", ['f', 'o', 'o'], onlyMembershipMatters=True)

    def test_onlyMembership_02_noRepeatedElements(self):
        self.assertIteration("foo", ['f', 'o'], onlyMembershipMatters=True)

    def test_onlyMembership_03_missingUniqueElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['o', 'o'], onlyMembershipMatters=True)

    def test_onlyMembership_04_missingNonUniqueElements(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f'], onlyMembershipMatters=True)

    def test_onlyMembership_05_extraUniqueElement(self):
        self.assertIteration("foo", ['f', 'o', 'o', 'f'], onlyMembershipMatters=True)

    def test_onlyMembership_06_extraNonUniqueElement(self):
        self.assertIteration("foo", ['f', 'o', 'o', 'o'], onlyMembershipMatters=True)

    def test_onlyMembership_07_extraNewElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'o', 'x'], onlyMembershipMatters=True)

    def test_onlyMembership_08_nonUniqueElementReplacedWithNewElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'x'], onlyMembershipMatters=True)

    def test_onlyMembership_09_nonUniqueElementReplacedWithUniqueElement(self):
        self.assertIteration("foo", ['f', 'o', 'f'], onlyMembershipMatters=True)

    def test_onlyMembership_10_wrongOrder(self):
        self.assertIteration("foo", ['o', 'f', 'o'], onlyMembershipMatters=True)

    def test_onlyMembership_11_noRepeatedElementsWrongOrder(self):
        self.assertIteration("foo", ['o', 'f'], onlyMembershipMatters=True)



    #################################################
    ## orderMatters=False, onlyMembershipMatters=True
    #################################################
    def test_unorderedOnlyMembership_01_exact(self):
        self.assertIteration( "foo", ['f', 'o', 'o'], orderMatters=False, onlyMembershipMatters=True)

    def test_unorderedOnlyMembership_02_noRepeatedElements(self):
        self.assertIteration("foo", ['f', 'o'], orderMatters=False, onlyMembershipMatters=True)

    def test_unorderedOnlyMembership_03_missingUniqueElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['o', 'o'], orderMatters=False, onlyMembershipMatters=True)

    def test_unorderedOnlyMembership_04_missingNonUniqueElements(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f'], orderMatters=False, onlyMembershipMatters=True)

    def test_unorderedOnlyMembership_05_extraUniqueElement(self):
        self.assertIteration("foo", ['f', 'o', 'o', 'f'], orderMatters=False, onlyMembershipMatters=True)

    def test_unorderedOnlyMembership_06_extraNonUniqueElement(self):
        self.assertIteration("foo", ['f', 'o', 'o', 'o'], orderMatters=False, onlyMembershipMatters=True)

    def test_unorderedOnlyMembership_07_extraNewElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'o', 'x'], orderMatters=False, onlyMembershipMatters=True)

    def test_unorderedOnlyMembership_08_nonUniqueElementReplacedWithNewElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'x'], orderMatters=False, onlyMembershipMatters=True)

    def test_unorderedOnlyMembership_09_nonUniqueElementReplacedWithUniqueElement(self):
        self.assertIteration("foo", ['f', 'o', 'f'], orderMatters=False, onlyMembershipMatters=True)

    def test_unorderedOnlyMembership_10_wrongOrder(self):
        self.assertIteration("foo", ['o', 'f', 'o'], orderMatters=False, onlyMembershipMatters=True)

    def test_unorderedOnlyMembership_11_noRepeatedElementsWrongOrder(self):
        self.assertIteration("foo", ['o', 'f'], orderMatters=False, onlyMembershipMatters=True)



    #################################################
    ## orderMatters=False, onlyMembershipMatters=False
    #################################################
    def test_unordered_01_exact(self):
        self.assertIteration( "foo", ['f', 'o', 'o'], orderMatters=False)

    def test_unordered_02_noRepeatedElements(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o'], orderMatters=False)

    def test_unordered_03_missingUniqueElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['o', 'o'], orderMatters=False)

    def test_unordered_04_missingNonUniqueElements(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f'], orderMatters=False)

    def test_unordered_05_extraUniqueElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'o', 'f'], orderMatters=False)

    def test_unordered_06_extraNonUniqueElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'o', 'o'], orderMatters=False)

    def test_unordered_07_extraNewElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'o', 'x'], orderMatters=False)

    def test_unordered_08_nonUniqueElementReplacedWithNewElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'x'], orderMatters=False)

    def test_unordered_09_nonUniqueElementReplacedWithUniqueElement(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['f', 'o', 'f'], orderMatters=False)

    def test_unordered_10_wrongOrder(self):
        self.assertIteration("foo", ['o', 'f', 'o'], orderMatters=False)

    def test_unordered_11_noRepeatedElementsWrongOrder(self):
        self.assertRaises(self.failureException, self.assertIteration, "foo", ['o', 'f'], orderMatters=False)




class TestPermutations(testingutils.TestCaseExtended):

    def doPermuteTest(self, sequence, length, expectedResults):
        self.assertIteration(testingutils.permutations(sequence, length), expectedResults, orderMatters=False)

    def testEmptyStr(self):
        self.doPermuteTest("", None, [[]])

    def testEmptyList(self):
        self.doPermuteTest([], None, [[]])

    def testEmptyTuple(self):
        self.doPermuteTest(tuple(), None, [[]])

    def test1ElementList(self):
        """Test the permutation works on a list of length 1"""
        self.doPermuteTest([1], None, [[1]])

    def test2ElementList(self):
        """Test the permutation works on a list of length 2"""
        self.doPermuteTest([1, 2], None, [[2, 1], [1, 2]])

    def test3ElementList(self):
        """Test the permutation works on a list of length 3"""
        self.doPermuteTest([1, 2, 3], None,
                      [[1, 2, 3], [1, 3, 2],
                       [2, 1, 3], [2, 3, 1],
                       [3, 1, 2], [3, 2, 1]])

    def testRepeatedElements(self):
        """Test that repeated elements are handled correctly."""
        self.doPermuteTest("aa", None, [['a','a'],['a','a']])

    def testMisc(self):
        """Miscellaneous tests for validity."""
        testObj = object()
        argsAndExpectedResults = \
            (('bar', None,
              [['b', 'a', 'r'], ['b', 'r', 'a'],
               ['a', 'b', 'r'], ['a', 'r', 'b'],
               ['r', 'b', 'a'], ['r', 'a', 'b']]),
             ('bar', 3,
              [['b', 'a', 'r'], ['b', 'r', 'a'],
               ['a', 'b', 'r'], ['a', 'r', 'b'],
               ['r', 'b', 'a'], ['r', 'a', 'b']]),
             ('bar', 2,
              [['b', 'a'], ['b', 'r'],
               ['a', 'b'], ['a', 'r'],
               ['r', 'b'], ['r', 'a']]),
             ('bar', 1, [['b'], ['a'], ['r']]),
             ('bar', 0, [[]]),
             ('foo', None,
              [['f', 'o', 'o'], ['f', 'o', 'o'],
               ['o', 'f', 'o'], ['o', 'o', 'f'],
               ['o', 'f', 'o'], ['o', 'o', 'f']]),
             (['foo', 1, testObj, 'bar'], None,
              [['foo', 1, testObj, 'bar'], ['foo', 1, 'bar', testObj],
               ['foo', testObj, 1, 'bar'], ['foo', testObj, 'bar', 1],
               ['foo', 'bar', 1, testObj], ['foo', 'bar', testObj, 1],
               [1, 'foo', testObj, 'bar'], [1, 'foo', 'bar', testObj],
               [1, testObj, 'foo', 'bar'], [1, testObj, 'bar', 'foo'],
               [1, 'bar', 'foo', testObj], [1, 'bar', testObj, 'foo'],
               [testObj, 'foo', 1, 'bar'], [testObj, 'foo', 'bar', 1],
               [testObj, 1, 'foo', 'bar'], [testObj, 1, 'bar', 'foo'],
               [testObj, 'bar', 'foo', 1], [testObj, 'bar', 1, 'foo'],
               ['bar', 'foo', 1, testObj], ['bar', 'foo', testObj, 1],
               ['bar', 1, 'foo', testObj], ['bar', 1, testObj, 'foo'],
               ['bar', testObj, 'foo', 1], ['bar', testObj, 1, 'foo']]),
             ((2.6,), 1, [[2.6]]),
             (([], 3.8, 1, {}, 'fun', 'yeeha'), 2,
              [[[], 3.8], [[], 1], [[], {}], [[], 'fun'], [[], 'yeeha'],
               [3.8, []], [3.8, 1], [3.8, {}], [3.8, 'fun'], [3.8, 'yeeha'],
               [1, []], [1, 3.8], [1, {}], [1, 'fun'], [1, 'yeeha'],
               [{}, []], [{}, 3.8], [{}, 1], [{}, 'fun'], [{}, 'yeeha'],
               ['fun', []], ['fun', 3.8], ['fun', 1], ['fun', {}], ['fun', 'yeeha'],
               ['yeeha', []], ['yeeha', 3.8], ['yeeha', 1], ['yeeha', {}], ['yeeha', 'fun']]))
        for seq, length, results in argsAndExpectedResults:
            self.doPermuteTest(seq, length, results)

testCaseExtendedSuite = unittest.TestLoader().loadTestsFromTestCase(TestAssertIteration)
permutationsSuite = unittest.TestLoader().loadTestsFromTestCase(TestPermutations)

def suite():
    return unittest.TestSuite([testCaseExtendedSuite, permutationsSuite])



def test_main():
    unittest.TextTestRunner(stream=sys.stdout, verbosity=2).run(suite())

if __name__ == '__main__':
    test_main()





########NEW FILE########
__FILENAME__ = test_trees
from pymel.util.testing import TestCase, setupUnittestModule
import pymel.util.trees as trees

class testCase_typeTrees(TestCase):
    def setUp(self):
        self.types = ('dependNode', ('FurAttractors', ('FurCurveAttractors', 'FurDescription', 'FurGlobals'), 'abstractBaseCreate'))
        self.tree = trees.Tree( *(self.types) )
    def test01_parentMethod(self):
        """ Test the parent method on type tree """
        pass
    def tearDown(self):
        pass


# to be organised in nice unit tests :


#print dir(FrozenTree)
#print dir(Tree)
##print dir(IndexedFrozenTree)
##print dir(IndexedTree)
#a = Tree ('a', ('aa', 'ab'), 'b', ('ba', 'bb'))
#print a
#print list(a)
#print list(a.preorder())
#print str(a)
#print repr(a)
#print unicode(a)
#print a.formatted()
#print a.debug()
#t = Tree ('a', ('aa', 'ab'))
#print id(t)
#print t.debug()
#t.graft('b')
#print id(t)
#print t.debug()
#b = Tree ('a')
#print id(b)
#print b.debug()
#b.graft('b')
#print b.debug()
#b.graft('ab', 'a')
#print b.debug()
#aa = Tree ('aa', ('aaa', 'aab'))
#print id(aa)
#print aa.debug()
## FIXME : next doesn't work
#b.graft(aa, 'a', 'ab')
#print id(b)
#print id(aa), id(b['aa'])
#print b.debug()
#b.remove('ab')
#ab = FrozenTree('ab', ('aba', 'abb'))
#print id(ab)
#print ab.debug()
#b.graft(ab, 'a')
#print id(b)
#print id(ab), id(b['ab'])
#print b.debug()
#b.graft('c')
#print b.debug()
#b.remove('c')
#print b.debug()
#b.graft('c', 'b')
#print b.debug()
#b.graft(('ba', 'bb'), 'c')
#print b.debug()
## FIXME : pop not working yet
## b.pop('c')
#print b.debug()
#b.prune('a')
#print b.debug()
#b.graft(('a', ('aa', 'ab')), None, 'b')
#print b.debug()
#print list(b.tops())
#print b.top(0)
#print b.top(1)
##print isinstance(a, list)
##print issubclass(a.__class__, list)
#print id(a)
#print a.root()
#print id(a)
#print a.next
#print a.child(0)
#print a.child(0).next
#print a.formatted()
#print a.debug()
#b = a
#print b.debug()
#c = a.copy()
#print c.debug()
#print c.formatted()
#print a == b
#print a is b
#print a == c
#print a is c
#for k in a.breadth() :
#    print k.value
#for k in a :
#    print k.value
#for k in a.postorder() :
#    print k.value
#
#A = Tree ('a', ('aa', ('aaa', 'aab', 'aac'), 'ab', 'ac', ('aca', 'acb')), 'b', ('ba', 'bb'), 'c', ('ca', ('caa', 'cab', 'cac'), 'cb', ('cba', 'cbb'), 'cc', ('cca', 'ccb', 'ccc')))
#print id(A)
#for k in A :
#    print k.value
#for k in A.preorder() :
#    print k.value
#for k in A.postorder() :
#    print k.value
#for k in A.breadth() :
#    print k.value
#print b in a
#print c in a
#print a.child(0) in a
#print c.child(0) in a
#print c.child(0).value in a
#for k in A :
#    parentValues = [j.value for j in k.parents()]
#    root = k.root()
#    if root :
#        rootValue = root.value
#    else :
#        rootValue = None
#    print "%s: %s, %s" % (k.value, rootValue, parentValues)
#
#
#temp = Tree ('a', ('aa', 'ab'), 'b', ('ba', 'bb'))
#suba = temp['aa']
#print suba
#print suba.root()
#print temp
#print id(temp)
#print suba.root().parent
#print id(suba.root().parent)
##print a[a.child(0)]
##print a
##l = a['a']
##print l
##print a[('a', 'aa')]
#del (temp)
## print a
#print suba
#print suba.root()
#print suba.root().parent
#print id(suba.root().parent)
#d = Tree ('a', ('aa', 'ab'), 'b', ('aa', 'ab'))
#def getAsList(tree, value):
#    msg = ""
#    try :
#        tree[value]
#        print "Found exactly one match"
#    except :
#        msg =  "Not exactly one match"
#    f = tree.get(value, [])
#    if msg :
#        print msg+": %i found" % len(f)
#    for k in f:
#        print k, k.parent
#    return f
#getAsList(d, 'aa')
#getAsList(d,('b', 'ab'))
#getAsList(d,'xyz')
#getAsList(d,(None, 'aa'))
#getAsList(d,(None, d.child(0).child(0)))
#getAsList(d,(None, 'a', 'aa'))
#getAsList(d,('a', 'aa'))
#A = Tree ('a', ('aa', ('aaa', 'aab', 'aac'), 'ab', 'ac', ('aca', 'acb')), 'b', ('ba', 'bb'), 'c', ('ca', ('caa', 'cab', 'cac'), 'cb', ('cba', 'cbb'), 'cc', ('cca', 'ccb', 'ccc')))
#print list(A.path('aca'))
#for k in A.path('aca') :
#    print k.value
#for k in A['aca'].path(A) :
#    if k.value :
#        print k.value
#


#def getParent(c) :
#    res = cmds.listRelatives(c, parent=True)
#    if res :
#        return res[0]
#
#def isExactChildFn(c, p) :
#    """ a function to check if c is a direct child of p """
#    if (c is not None) and (p is not None) :
#        #print "checking if "+c+" is child of "+p
#        prt = getParent(c)
#        if prt is not None and p is not None :
#            return prt == p
#        elif prt is None and p is None :
#            return True
#        else :
#            return False
#    else :
#        return False
#
#def asOldHierarchy (*args) :
#    """returns a Tree containing the PyMel objects representing Maya nodes that were passed
#        as argument, or the current seleciton if no arguments are provided,
#        in a way that mimics the Maya scene hierarchy existing on these nodes.
#        Note that:
#        >>> cmds.file ("~/pymel/examples/skel.ma", f=True, typ="mayaAscii",o=True)
#        >>> File read in 0 seconds.
#        >>> u'~/pymel/examples/skel.ma'
#        >>> select ('FBX_Hips', replace=True, hierarchy=True)
#        >>> sel=ls(selection=True)
#        >>> skel=asHierarchy (sel)
#        >>> skel.find('FBX_Head')
#        >>> Tree(Joint('FBX_Head'), Tree(Joint('FBX_LeftEye')), Tree(Joint('FBX_RightEye')))
#        >>> skel.parent('FBX_Head')
#        >>> Joint('FBX_Neck1')
#        >>> util.expandArgs( skel ) == tuple(sel) and sel == [k for k in skel]
#        >>> True """
#
#    if len(args) == 0 :
#        nargs = cmds.ls( selection=True)
#    else :
#        args = util.expandArgs (*args)
#        # nargs = map(PyNode, args)
#    nargs = args
#    # print "Arguments: %s"+str(nargs)
#    result = oldTreeFromChildLink (isExactChildFn, *nargs)
#    # print "Result: %s"+str(result)
#    return result
#
#def asHierarchy (*args) :
#    """returns a Tree containing the PyMel objects representing Maya nodes that were passed
#        as argument, or the current seleciton if no arguments are provided,
#        in a way that mimics the Maya scene hierarchy existing on these nodes.
#        Note that:
#        >>> cmds.file ("~/pymel/examples/skel.ma", f=True, typ="mayaAscii",o=True)
#        >>> File read in 0 seconds.
#        >>> u'~/pymel/examples/skel.ma'
#        >>> select ('FBX_Hips', replace=True, hierarchy=True)
#        >>> sel=ls(selection=True)
#        >>> skel=asHierarchy (sel)
#        >>> skel.find('FBX_Head')
#        >>> Tree(Joint('FBX_Head'), Tree(Joint('FBX_LeftEye')), Tree(Joint('FBX_RightEye')))
#        >>> skel.parent('FBX_Head')
#        >>> Joint('FBX_Neck1')
#        >>> util.expandArgs( skel ) == tuple(sel) and sel == [k for k in skel]
#        >>> True """
#
#    if len(args) == 0 :
#        nargs = cmds.ls( selection=True)
#    else :
#        args = util.expandArgs (*args)
#        # nargs = map(PyNode, args)
#    nargs = args
#    # print "Arguments: %s"+str(nargs)
#    result = treeFromChildLink (isExactChildFn, *nargs)
#    # print "Result: %s"+str(result)
#    return result
#
#def asIndexedHierarchy (*args) :
#    """returns a Tree containing the PyMel objects representing Maya nodes that were passed
#        as argument, or the current seleciton if no arguments are provided,
#        in a way that mimics the Maya scene hierarchy existing on these nodes.
#        Note that:
#        >>> cmds.file ("~/pymel/examples/skel.ma", f=True, typ="mayaAscii",o=True)
#        >>> File read in 0 seconds.
#        >>> u'~/pymel/examples/skel.ma'
#        >>> select ('FBX_Hips', replace=True, hierarchy=True)
#        >>> sel=ls(selection=True)
#        >>> skel=asHierarchy (sel)
#        >>> skel.find('FBX_Head')
#        >>> Tree(Joint('FBX_Head'), Tree(Joint('FBX_LeftEye')), Tree(Joint('FBX_RightEye')))
#        >>> skel.parent('FBX_Head')
#        >>> Joint('FBX_Neck1')
#        >>> util.expandArgs( skel ) == tuple(sel) and sel == [k for k in skel]
#        >>> True """
#
#    if len(args) == 0 :
#        nargs = cmds.ls( selection=True)
#    else :
#        args = util.expandArgs (*args)
#        # nargs = map(PyNode, args)
#    nargs = args
#    # print "Arguments: %s"+str(nargs)
#    result = indexedTreeFromChildLink (isExactChildFn, *nargs)
#    # print "Result: %s"+str(result)
#    return result
#
#def asNetworkXHierarchy (*args) :
#    """returns a Tree containing the PyMel objects representing Maya nodes that were passed
#        as argument, or the current seleciton if no arguments are provided,
#        in a way that mimics the Maya scene hierarchy existing on these nodes.
#        Note that:
#        >>> cmds.file ("~/pymel/examples/skel.ma", f=True, typ="mayaAscii",o=True)
#        >>> File read in 0 seconds.
#        >>> u'~/pymel/examples/skel.ma'
#        >>> select ('FBX_Hips', replace=True, hierarchy=True)
#        >>> sel=ls(selection=True)
#        >>> skel=asHierarchy (sel)
#        >>> skel.find('FBX_Head')
#        >>> Tree(Joint('FBX_Head'), Tree(Joint('FBX_LeftEye')), Tree(Joint('FBX_RightEye')))
#        >>> skel.parent('FBX_Head')
#        >>> Joint('FBX_Neck1')
#        >>> util.expandArgs( skel ) == tuple(sel) and sel == [k for k in skel]
#        >>> True """
#
#    if len(args) == 0 :
#        nargs = cmds.ls( selection=True)
#    else :
#        args = util.expandArgs (*args)
#        # nargs = map(PyNode, args)
#    nargs = args
#    # print "Arguments: "+str(nargs)
#    result = networkXTreeFromChildLink (isExactChildFn, *nargs)
#    # print "Result: "+str(result)
#    return result
#
#
#
#def networkXTreeFromChildLink (isExactChildFn, *args):
#    """
#    This function will build a tree from the provided sequence and a comparison function in the form:
#        cmp(a,b): returns True if a is a direct child of b, False else
#    >>> lst = ['aab', 'aba', 'aa', 'bbb', 'ba', 'a', 'b', 'bb', 'ab', 'bab', 'bba']
#    >>> def isChild(s1, s2) :
#    >>>     return s1.startswith(s2) and len(s1)==len(s2)+1
#    >>> forest = treeFromChildLink (isChild, lst)
#    >>> for tree in forest :
#    >>>     print tree
#    A child cannot have more than one parent, if the isChild is ambiguous an exception will be raised
#    >>> def isChild(s1, s2) :
#    >>>     return s1.startswith(s2)
#    >>> forest = treeFromChildLink (isChild, lst)
#    """
#    deq = deque()
#    for arg in args :
#        t = nt.Tree()
#    t.add_node(arg)
#    t.root = arg
#    deq.append(t)
#    lst = []
#    it = 0
#    while deq:
#        it+=1
#        # print "iteration %i" % it
#        c = deq.popleft()
#    r = c.root
#        hasParent = False
#    fulllist = list(deq)+lst
#    sd = len(deq)
#    nextlist = []
#        for p in fulllist :
#        plist = []
#        for n in p.nodes_iter() :
#        # print "Is %s child of %s?" % (r, n)
#                if isExactChildFn(r, n) :
#                    plist.append(n)
#                    # print "%s is child of %s!" % (r, n)
#        for pr in plist :
#                if not hasParent :
#                    # print "graft %s on %s, under %s" % (r, p.root, pr)
#                    np = p.union_sub(c, v_from=p.root, v_to=c.root)
#            np.root = p.root
#            p = np
#                    hasParent = True
#                else :
#                    # should only be one parent, break on first encountered
#                    raise ValueError, "A child in Tree cannot have multiple parents, check the provided isChild(c, p) function: '%s'" % isExactChildFn.__name__
#            nextlist.append(p)
#    deq = deque(nextlist[:sd])
#    lst = nextlist[sd:]
#    # If it's a root we move it to final list
#        if not hasParent :
#            # print "%s has no parent, it goes to the list as root" % str(c.root)
#            lst.append(c)
#
#    # print "final list %s" % str(lst)
#    if len(lst) == 1 :
#        return lst[0]
#    else :
#        return tuple(lst)

setupUnittestModule(__name__)
########NEW FILE########
__FILENAME__ = test_uitypes
from __future__ import with_statement

import sys
import unittest
import maya.cmds as cmds
import pymel.core as pm
import pymel.core.uitypes as ui

if not hasattr(pm, 'currentMenuParent'):
    def currentMenuParent():
        return ui.PyUI(cmds.setParent(q=1, menu=1))
    pm.currentMenuParent = currentMenuParent


class TestWithStatement(unittest.TestCase):
    def setUp(self):
        cmds.setParent(None, menu=1)
        self.win = cmds.window()
    def tearDown(self):
        cmds.deleteUI(self.win, window=True)

    def test_classInit(self):
        with ui.FormLayout() as fl:
            self.assertEqual(pm.currentParent(), fl)
        self.assertEqual(pm.currentParent(), self.win)
        with ui.RowLayout() as rl:
            self.assertEqual(pm.currentParent(), rl)
        # Since there can only be one top-level layout,
        # what happens is that before creating the row layout, the
        # parent is set to the window; but that automatically gets translated
        # to mean the top-level layout for that window, which is the form
        # layout... so the row layout has it's parent set to the form
        # layout
        self.assertEqual(pm.currentParent(), fl)
        with ui.ColumnLayout() as cl:
            self.assertEqual(pm.currentParent(), cl)
        self.assertEqual(pm.currentParent(), fl)

    def test_cmdInit(self):
        with pm.formLayout() as fl:
            self.assertEqual(pm.currentParent(), fl)
        self.assertEqual(pm.currentParent(), self.win)
        with pm.rowLayout() as rl:
            self.assertEqual(pm.currentParent(), rl)
        # Since there can only be one top-level layout,
        # what happens is that before creating the row layout, the
        # parent is set to the window; but that automatically gets translated
        # to mean the top-level layout for that window, which is the form
        # layout... so the row layout has it's parent set to the form
        # layout
        self.assertEqual(pm.currentParent(), fl)
        with pm.columnLayout() as cl:
            self.assertEqual(pm.currentParent(), cl)
        self.assertEqual(pm.currentParent(), fl)

    def test_parentJump(self):
        cl = ui.ColumnLayout()
        rl1 = ui.RowLayout()
        with pm.rowLayout(parent=cl) as rl2:
            self.assertEqual(pm.currentParent(), rl2)
        self.assertEqual(pm.currentParent(), cl)

    def test_nested(self):
        with ui.ColumnLayout() as cl:
            self.assertEqual(pm.currentParent(), cl)
            with pm.rowLayout() as rl:
                self.assertEqual(pm.currentParent(), rl)
            self.assertEqual(pm.currentParent(), cl)
        self.assertEqual(pm.currentParent(), self.win)

    def test_nestedParentJump(self):
        with ui.ColumnLayout() as cl:
            self.assertEqual(pm.currentParent(), cl)
            with pm.rowLayout() as rl:
                self.assertEqual(pm.currentParent(), rl)
                with cl:
                    # set the parent BACK to the column layout
                    self.assertEqual(pm.currentParent(), cl)
                self.assertEqual(pm.currentParent(), rl)
            self.assertEqual(pm.currentParent(), cl)
        self.assertEqual(pm.currentParent(), self.win)

    def test_nestedMenu(self):
        self.assertEqual(pm.currentParent(), self.win)
        self.assertEqual(pm.currentMenuParent(), None)
        with ui.ColumnLayout() as cl:
            self.assertEqual(pm.currentParent(), cl)
            self.assertEqual(pm.currentMenuParent(), None)
            cmds.button()
            with pm.popupMenu() as m:
                self.assertEqual(pm.currentParent(), cl)
                self.assertEqual(pm.currentMenuParent(), m)
                with ui.MenuItem(subMenu=1) as sm:
                    self.assertEqual(pm.currentParent(), cl)
                    self.assertEqual(pm.currentMenuParent(), sm)
                self.assertEqual(pm.currentParent(), cl)
                self.assertEqual(pm.currentMenuParent(), m)
            self.assertEqual(pm.currentParent(), cl)
        self.assertEqual(pm.currentParent(), self.win)

    def test_rowGroupLayout(self):
        self.assertEqual(pm.currentParent(), self.win)
        self.assertEqual(pm.currentMenuParent(), None)
        with pm.textFieldButtonGrp( label='Label', text='Text', buttonLabel='Button' ) as tfbg:
            self.assertEqual(pm.currentParent(), tfbg)
            self.assertEqual(pm.currentMenuParent(), None)
            cmds.button()
            with pm.popupMenu() as m:
                self.assertEqual(pm.currentParent(), tfbg)
                self.assertEqual(pm.currentMenuParent(), m)
                with pm.menuItem(subMenu=1) as sm:
                    self.assertEqual(pm.currentParent(), tfbg)
                    self.assertEqual(pm.currentMenuParent(), sm)
                self.assertEqual(pm.currentParent(), tfbg)
                self.assertEqual(pm.currentMenuParent(), m)
            self.assertEqual(pm.currentParent(), tfbg)
        self.assertEqual(pm.currentParent(), self.win)

        fl = pm.formLayout()
        tfbg2 = pm.textFieldButtonGrp( label='Label', text='Text', buttonLabel='Button' )
        self.assertEqual(pm.currentParent(), fl)
        with pm.columnLayout() as cl:
            cmds.button()
            with pm.popupMenu() as m:
                self.assertEqual(pm.currentParent(), cl)
                self.assertEqual(pm.currentMenuParent(), m)
                with pm.menuItem(subMenu=1) as sm:
                    self.assertEqual(pm.currentParent(), cl)
                    self.assertEqual(pm.currentMenuParent(), sm)
                self.assertEqual(pm.currentParent(), cl)
                self.assertEqual(pm.currentMenuParent(), m)
            self.assertEqual(pm.currentParent(), cl)
        self.assertEqual(pm.currentParent(), fl)

    def test_optionMenuGrp(self):
        self.assertEqual(pm.currentParent(), self.win)
        self.assertEqual(pm.currentMenuParent(), None)
        with ui.ColumnLayout() as cl:
            self.assertEqual(pm.currentParent(), cl)
            self.assertEqual(pm.currentMenuParent(), None)
            cmds.button()
            with ui.OptionMenuGrp() as m:
                self.assertEqual(pm.currentParent(), m)
                self.assertEqual(pm.currentMenuParent(), m.menu())
            self.assertEqual(pm.currentParent(), cl)
        self.assertEqual(pm.currentParent(), self.win)

    def test_windowExit(self):
        self.assertEqual(pm.currentParent(), self.win)
        newWin = ui.Window()
        try:
            with newWin:
                self.assertEqual(pm.currentParent(), newWin)
                with pm.formLayout() as fl:
                    self.assertEqual(pm.currentParent(), fl)
                self.assertEqual(pm.currentParent(), newWin)
            self.assertTrue(pm.currentParent() in (None, newWin, fl))
        finally:
            pm.deleteUI(newWin, window=True)

        otherWin = ui.Window()
        # try NOT using with statement, to make sure the last newWin
        # statement's exit popped it off the stack correctly
        try:
            with pm.formLayout() as fl:
                self.assertEqual(pm.currentParent(), fl)
            self.assertEqual(pm.currentParent(), otherWin)
        finally:
            pm.deleteUI(otherWin, window=True)

class TestTextScrollList(unittest.TestCase):
    def setUp(self):
        cmds.setParent(None, menu=1)
        self.win = cmds.window()
    def tearDown(self):
        cmds.deleteUI(self.win, window=True)

    def test_selectItemEmptyList(self):
        with ui.Window(self.win):
            with pm.formLayout():
                tsl = pm.textScrollList()
                tsl.extend(['a','b','c'])
        # Make sure this is NOT None
        self.assertEqual(tsl.getSelectItem(), [])


if not pm.about(batch=1):
    for key, obj in globals().items():
        if isinstance(obj, unittest.TestCase):
            del globals()[key]
            obj.__name__ = '_canceledTest_' + obj.__name__

########NEW FILE########
__FILENAME__ = test_utilitytypes
from pymel.util.testing import TestCaseExtended, setupUnittestModule, TestCase
from pymel.util import utilitytypes

aDict = {'A':1, 'a':2}
bDict = {'B':3, 'b':4}

class BasicSingleton(object):
    __metaclass__ = utilitytypes.Singleton

class DictSingleton(dict) :
    __metaclass__ = utilitytypes.Singleton



class TestBasicSingleton(TestCaseExtended):
    # Override this attribute in derived classes!
    # Also, should use self.testClass (as
    # opposed to just 'testClass') in derived classes,
    # in case other classes derive from them...
    testClass = BasicSingleton

    def setUp(self):
        self.testClass = self.__class__.testClass

    def testSameInstance(self):
        self.assertTrue(self.testClass() is self.testClass())

class __AbstractTestDict(TestBasicSingleton):

    def testCanInitialize(self):
        self.testClass(aDict)
        self.assertEqual(aDict, dict(self.testClass()))

    def testReferencesEqual(self):
        oldRef = self.testClass(aDict)
        newRef = self.testClass()
        self.assertTrue( oldRef == newRef)

class TestDictSingleton(__AbstractTestDict):
    testClass = DictSingleton
    def setUp(self):
        super(TestDictSingleton, self).setUp()
        self.testClass().clear()

    def testInitializeResets(self):
        self.testClass(aDict)
        self.assertTrue(len(self.testClass())>0)
        self.testClass({})
        self.assertTrue(len(self.testClass())==0)

    def testSameInstanceAfterReinitializing(self):
        oldInst = self.testClass({'A':1})
        self.assertTrue(self.testClass({}) is oldInst)

    def testCanUpdate(self):
        self.testClass()['z'] = 3
        self.assertEqual(self.testClass()['z'], 3)
        self.testClass()['z'] = 12
        self.assertEqual(self.testClass()['z'], 12)

    def testNoClearOnUpdate(self):
        self.testClass()['a'] = "foobar"
        self.assertEqual(self.testClass()['a'], "foobar")
        self.testClass()['fuzzy'] = "bear"
        self.assertEqual(self.testClass()['a'], "foobar")

class TestFrozenDict(__AbstractTestDict):
    # In the case of static classes, need to create a new class
    # on each setup...

    def setUp(self):
        self._makeNewFrozenDictClass()

    def _makeNewFrozenDictClass(self, initialValue=None):
        class FrozenDict(dict):
            __metaclass__ = utilitytypes.metaStatic
        self.testClass = FrozenDict

    def _doInit(self, initialValue=None):
        if initialValue:
            return self.testClass(initialValue)
        else:
            return self.testClass()

    def _doAssignation(self, key, value):
        self.testClass()[key] = value

    def testNoReinitialization(self):
        self._doInit(aDict)
        self.assertRaises(TypeError, self._doInit, aDict)

    def testNoErrorIfNoArgs(self):
        self._doInit(aDict)
        self.assertNoError(self._doInit)
        self.assertNoError(self._doInit)

    def testNoAssignation(self):
        self.assertRaises(TypeError, self._doAssignation, 'A', 3)

    def testHidden(self):
        shouldBeHidden = ('clear', 'update', 'pop', 'popitem', '__setitem__', '__delitem__', 'append', 'extend' )
        for hidden in shouldBeHidden:
            self.assertFalse(hasattr(self.testClass(), hidden))

class TestEquivalencePairs(TestCaseExtended):
    def testInitPairs(self):
        ep = utilitytypes.EquivalencePairs( ((1,'foo'), (2,'bar')) )
        self.assertEqual(ep[1], 'foo')
        self.assertEqual(ep[2], 'bar')
        self.assertEqual(ep['foo'], 1)
        self.assertEqual(ep['bar'], 2)

    def testInitDict(self):
        ep = utilitytypes.EquivalencePairs( {1:'foo', 2:'bar'} )
        self.assertEqual(ep[1], 'foo')
        self.assertEqual(ep[2], 'bar')
        self.assertEqual(ep['foo'], 1)
        self.assertEqual(ep['bar'], 2)

    def testInitEquivPairs(self):
        otherEp = utilitytypes.EquivalencePairs( {1:'foo', 2:'bar'} )
        ep = utilitytypes.EquivalencePairs(otherEp)
        self.assertEqual(ep[1], 'foo')
        self.assertEqual(ep[2], 'bar')
        self.assertEqual(ep['foo'], 1)
        self.assertEqual(ep['bar'], 2)

    def testOverwritePairs(self):
        ep = utilitytypes.EquivalencePairs({1:'a', 2:'b'})
        self.assertEqual(ep[1], 'a')
        self.assertEqual(ep[2], 'b')
        self.assertEqual(ep['a'], 1)
        self.assertEqual(ep['b'], 2)
        ep[1] = 2
        self.assertRaises(KeyError, self._getIndex, ep, 'a')
        self.assertRaises(KeyError, self._getIndex, ep, 'b')
        self.assertEqual(ep[1], 2)
        self.assertEqual(ep[2], 1)

    def _getIndex(self, indexableObj, index):
        return indexableObj[index]

class TestProxyClass(TestCase):
    class MyClass(object):
        "MyClass's doc string!"
        data = 3.14

        def __init__(self, id):
            self.id = id

        @classmethod
        def clsMeth(cls):
            return cls

        @staticmethod
        def statMeth():
            return 'static'

        def instMeth(self):
            return (self, self.id)

    def test_wrapData(self):
        Wrapped = utilitytypes.proxyClass(self.MyClass, 'Wrapped',
                                          dataAttrName='_data', makeDefaultInit=True)
        self.assertEqual(Wrapped.data, self.MyClass.data)
        self.assertEqual(Wrapped('foo').data, self.MyClass('foo').data)

    def test_classMethod(self):
        Wrapped = utilitytypes.proxyClass(self.MyClass, 'Wrapped',
                                          dataAttrName='_data', makeDefaultInit=True)
        self.assertEqual(Wrapped.clsMeth(), self.MyClass.clsMeth())

    def test_staticMethod(self):
        Wrapped = utilitytypes.proxyClass(self.MyClass, 'Wrapped',
                                          dataAttrName='_data', makeDefaultInit=True)
        self.assertEqual(Wrapped.statMeth(), self.MyClass.statMeth())

    def test_instMethod(self):
        Wrapped = utilitytypes.proxyClass(self.MyClass, 'Wrapped',
                                          dataAttrName='_data', makeDefaultInit=True)
        wrappedResult = Wrapped('bar').instMeth()
        myClassResult = self.MyClass('bar').instMeth()
        self.assertEqual(wrappedResult[0].__class__, myClassResult[0].__class__)
        self.assertEqual(wrappedResult[1], myClassResult[1])

    def test_docString(self):
        Wrapped = utilitytypes.proxyClass(self.MyClass, 'Wrapped',
                                          dataAttrName='_data', makeDefaultInit=True)
        self.assertEqual(Wrapped.__doc__, self.MyClass.__doc__)

    def test_immutable(self):

        Wrapped = utilitytypes.proxyClass(''.__class__, 'Wrapped',
                                          dataAttrName='_data', makeDefaultInit=True)
        self.assertEqual(Wrapped('Fun times were had by all')[3:7],
                         'Fun times were had by all'[3:7])


    def test_unboundMethod(self):
        """
        We should be able to do MyProxyClass.wrappedMethod(myProxyClassInst)
        """
        Wrapped = utilitytypes.proxyClass(self.MyClass, 'Wrapped',
                                          dataAttrName='_data', makeDefaultInit=True)
        wrapInst = Wrapped('bar')
        wrappedResult = Wrapped.instMeth(wrapInst)
        myClassResult = self.MyClass('bar').instMeth()
        self.assertEqual(wrappedResult[0].__class__, myClassResult[0].__class__)
        self.assertEqual(wrappedResult[1], myClassResult[1])

    def test_unboundMethodDescriptor(self):
        """
        Some built-in types have fun things called method descriptors...
        ...they're like methods, but not!
        """
        Wrapped = utilitytypes.proxyClass(''.__class__, 'Wrapped',
                                          dataAttrName='_data', makeDefaultInit=True)
        theString = 'Fun times were had by all!'
        wrapInst = Wrapped(theString)
        self.assertEqual(Wrapped.__len__(wrapInst), len(theString))

setupUnittestModule(__name__)

########NEW FILE########
__FILENAME__ = test_util_common
'''
Created on Oct 16, 2012

@author: paulm
'''

# used to have tests for util.isClassRunningStack, but it turned out
# inspect.stack() could cause crashes in some cases...

########NEW FILE########
__FILENAME__ = test_windows
import sys
import unittest
import maya.cmds as cmds
import pymel.core as pm
import pymel.core.uitypes as ui
import pymel.core.windows as windows

class TestMenu(unittest.TestCase):
    def setUp(self):
        cmds.setParent(None, menu=1)
        self.win = cmds.window()
    def tearDown(self):
        cmds.deleteUI(self.win, window=True)

    def testOptionMenuAsMenu(self):
        cmds.formLayout()
        om = ui.OptionMenu('someOptionMenu', create=True)
        cmds.menuItem( label='Yellow' )
        self.assertEqual(windows.menu(om, q=1, numberOfItems=1), 1)
        self.assertEqual(windows.menu(om.name(), q=1, numberOfItems=1), 1)
        self.assertEqual(windows.menu(om.shortName(), q=1, numberOfItems=1), 1)
        ui.Menu(om)
        ui.Menu(om.name())
        ui.Menu(om.shortName())

if not pm.about(batch=1):
    for key, obj in globals().items():
        if isinstance(obj, unittest.TestCase):
            del globals()[key]
            obj.__name__ = '_canceledTest_' + obj.__name__

########NEW FILE########
