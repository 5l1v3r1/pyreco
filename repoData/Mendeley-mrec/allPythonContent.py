__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# mrec documentation build configuration file, created by
# sphinx-quickstart on Fri Aug 30 16:35:35 2013.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('.'))
sys.path.insert(0, os.path.abspath('..'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.pngmath', 'sphinx.ext.autosummary', 'numpydoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'mrec'
copyright = u'2013, Mendeley Ltd.'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
import pkg_resources
try:
    release = pkg_resources.get_distribution('mrec').version
except pkg_resources.DistributionNotFound:
    print 'To build the documentation, The distribution information of mrec'
    print 'has to be available.  Either install the package into your'
    print 'development environment or run "python setup.py develop" to setup'
    print 'the metadata.'
    sys.exit(1)
del pkg_resources
version = '.'.join(release.split('.')[:2])

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'sphinxdoc'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'mrecdoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'mrec.tex', u'mrec Documentation',
   u'Mark Levy, Mendeley Ltd.', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'mrec', u'mrec Documentation',
     [u'Mark Levy, Mendeley Ltd.'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'mrec', u'mrec Documentation',
   u'Mark Levy, Mendeley Ltd.', 'mrec', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = base_recommender
try:
    import cPickle as pickle
except ImportError:
    import pickle
import numpy as np
from scipy.sparse import csr_matrix

class BaseRecommender(object):
    """
    Minimal interface to be implemented by recommenders, along with
    some helper methods. A concrete recommender must implement the
    recommend_items() method and should provide its own implementation
    of __str__() so that it can be identified when printing results.

    Notes
    =====
    In most cases you should inherit from either
    `mrec.mf.recommender.MatrixFactorizationRecommender` or
    `mrec.item_similarity.recommender.ItemSimilarityRecommender`
    and *not* directly from this class.

    These provide more efficient implementations of save(), load()
    and the batch methods to recommend items.
    """

    def recommend_items(self,dataset,u,max_items=10,return_scores=True,item_features=None):
        """
        Recommend new items for a user.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        u : int
            Index of user for which to make recommendations.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        item_features : array_like, shape = [num_items, num_features]
            Optionally supply features for each item in the dataset.

        Returns
        =======
        recs : list
            List of (idx,score) pairs if return_scores is True, else
            just a list of idxs.
        """
        raise NotImplementedError('you must implement recommend_items()')

    def fit(self,train,item_features=None):
        """
        Train on supplied data. In general you will want to
        implement this rather than computing recommendations on
        the fly.

        Parameters
        ==========
        train : scipy.sparse.csr_matrix or mrec.sparse.fast_sparse_matrix, shape = [num_users, num_items]
            User-item matrix.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, required by some recommenders.
        """
        raise NotImplementedError('you should implement fit()')

    def save(self,filepath):
        """
        Serialize model to file.

        Parameters
        ==========
        filepath : str
            Filepath to write to, which must have the '.npz' suffix.

        Notes
        =====
        Internally numpy.savez may be used to serialize the model and
        this would add the '.npz' suffix to the supplied filepath if
        it were not already present, which would most likely cause errors
        in client code.
        """
        if not filepath.endswith('.npz'):
            raise ValueError('invalid filepath {0}, must have ".npz" suffix'.format(filepath))

        archive = self._create_archive()
        if archive:
            np.savez(filepath,**archive)
        else:
            pickle.dump(self,open(filepath,'w'))

    def _create_archive(self):
        """
        Optionally return a dict of fields to be serialized
        in a numpy archive: this lets you store arrays efficiently
        by separating them from the model itself.

        Returns
        =======
        archive : dict
            Fields to serialize, must include the model itself
            under the key 'model'.
        """
        pass

    @staticmethod
    def load(filepath):
        """
        Load a recommender model from file after it has been serialized with
        save().

        Parameters
        ==========
        filepath : str
            The filepath to read from.
        """
        r = np.load(filepath)
        if isinstance(r,BaseRecommender):
            model = r
        else:
            model = np.loads(str(r['model']))
            model._load_archive(r)  # restore any fields serialized separately
        return model

    def _load_archive(archive):
        """
        Load fields from a numpy archive.

        Notes
        =====
        This is called by the static load() method and should be used
        to restore the fields returned by _create_archive().
        """
        pass

    @staticmethod
    def read_recommender_description(filepath):
        """
        Read a recommender model description from file after it has
        been saved by save(), without loading any additional
        associated data into memory.

        Parameters
        ==========
        filepath : str
            The filepath to read from.
        """
        r = np.load(filepath,mmap_mode='r')
        if isinstance(r,BaseRecommender):
            model = r
        else:
            model = np.loads(str(r['model']))
        return str(model)

    def __str__(self):
        if hasattr(self,'description'):
            return self.description
        return 'unspecified recommender: you should set self.description or implement __str__()'

    def batch_recommend_items(self,
                              dataset,
                              max_items=10,
                              return_scores=True,
                              show_progress=False,
                              item_features=None):
        """
        Recommend new items for all users in the training dataset.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        show_progress: bool
            If true print something to stdout to show progress.
        item_features : array_like, shape = [num_items, num_features]
            Optionally supply features for each item in the dataset.

        Returns
        =======
        recs : list of lists
            Each entry is a list of (idx,score) pairs if return_scores is True,
            else just a list of idxs.

        Notes
        =====
        This provides a default implementation, you will be able to optimize
        this for most recommenders.
        """
        recs = []
        for u in xrange(self.num_users):
            if show_progress and u%1000 == 0:
               print u,'..',
            recs.append(self.recommend_items(dataset,u,max_items,return_scores))
        if show_progress:
            print
        return recs

    def range_recommend_items(self,
                              dataset,
                              user_start,
                              user_end,
                              max_items=10,
                              return_scores=True,
                              item_features=None):
        """
        Recommend new items for a range of users in the training dataset.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        user_start : int
            Index of first user in the range to recommend.
        user_end : int
            Index one beyond last user in the range to recommend.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        item_features : array_like, shape = [num_items, num_features]
            Optionally supply features for each item in the dataset.

        Returns
        =======
        recs : list of lists
            Each entry is a list of (idx,score) pairs if return_scores is True,
            else just a list of idxs.

        Notes
        =====
        This provides a default implementation, you will be able to optimize
        this for most recommenders.
        """
        return [self.recommend_items(dataset,u,max_items,return_scores) for u in xrange(user_start,user_end)]

    def _zero_known_item_scores(self,r,train):
        """
        Helper function to set predicted scores/ratings for training items
        to zero or less, to avoid recommending already known items.

        Parameters
        ==========
        r : numpy.ndarray or scipy.sparse.csr_matrix
            Predicted scores/ratings.
        train : scipy.sparse.csr_matrix
            The training user-item matrix, which can include zero-valued entries.

        Returns
        =======
        r_safe : scipy.sparse.csr_matrix
            r_safe is equal to r except that r[u,i] <= 0 for all u,i with entries
            in train.
        """
        col = train.indices
        if isinstance(r,csr_matrix):
            max_score = r.data.max()
        else:
            max_score = r.max()
        data = max_score * np.ones(col.shape)
        # build up the row (user) indices
        # - we can't just use row,col = train.nonzero() as this eliminates
        #   u,i for which train[u,i] has been explicitly set to zero
        row = np.zeros(col.shape)
        for u in xrange(train.shape[0]):
            start,end = train.indptr[u],train.indptr[u+1]
            if end > start:
                row[start:end] = u
        return r - csr_matrix((data,(row,col)),shape=r.shape)


########NEW FILE########
__FILENAME__ = metrics
"""
Metrics to evaluate recommendations:
* with hit rate, following e.g. Karypis lab SLIM and FISM papers
* with prec@k and MRR
"""

import numpy as np
from scipy import stats
from collections import defaultdict

# classes to access known items for each test user

class get_known_items_from_dict(object):

    def __init__(self,data):
        self.data = data

    def __call__(self,u):
        return self.data[u]

class get_known_items_from_csr_matrix(object):

    def __init__(self,data):
        self.data = data

    def __call__(self,u):
        return self.data[u].indices

class get_known_items_from_thresholded_csr_matrix(object):

    def __init__(self,data,min_value):
        self.data = data
        self.min_value = min_value

    def __call__(self,u):
        items = self.data[u].toarray().flatten()
        items[items<self.min_value] = 0
        return items.nonzero()

# methods to refit a model to a new training dataset

def retrain_recommender(model,dataset):
    model.fit(dataset)

# methods for metric computation itself

def run_evaluation(models,retrain,get_split,num_runs,evaluation_func):
    """
    This is the main entry point to run an evaluation.

    Supply functions to retrain model, to get a new split of data on
    each run, to get known items from the test set, and to compute the
    metrics you want:
    - retrain(model,dataset) should retrain model
    - get_split() should return train_data,test_users,test_data
    - evaluation_func(model,users,test) should return a dict of metrics
    A number of suitable functions are already available in the module.
    """
    metrics = [defaultdict(list) for m in models]
    for _ in xrange(num_runs):
        train,users,test = get_split()
        for i,model in enumerate(models):
            retrain(model,train)
            run_metrics = evaluation_func(model,train,users,test)
            for m,val in run_metrics.iteritems():
                print m,val
                metrics[i][m].append(val)
    return metrics

def generate_metrics(get_known_items,compute_metrics):
    def evaluation_func(model,train,users,test):
        return evaluate(model,train,users,get_known_items(test),compute_metrics)
    return evaluation_func

def sort_metrics_by_name(names):
    # group by name and number in "@n"
    prefix2val = defaultdict(list)
    for name in names:
        parts = name.split('@')
        name = parts[0]
        if len(parts) > 1:
            val = int(parts[1])
            prefix2val[name].append(val)
        else:
            prefix2val[name] = []
    for name,vals in prefix2val.iteritems():
        prefix2val[name] = sorted(vals)
    ret = []
    for name,vals in sorted(prefix2val.iteritems()):
        if vals:
            for val in vals:
                ret.append('{0}@{1}'.format(name,val))
        else:
            ret.append(name)
    return ret

def print_report(models,metrics):
    """
    Call this to print out the metrics returned by run_evaluation().
    """
    for model,results in zip(models,metrics):
        print model
        if hasattr(model,'similarity_matrix'):
            nnz = model.similarity_matrix.nnz
            num_items = model.similarity_matrix.shape[0]
            density = float(model.similarity_matrix.nnz)/num_items**2
            print 'similarity matrix nnz = {0} (density {1:.3f})'.format(nnz,density)
        for m in sort_metrics_by_name(results.keys()):
            vals = results[m]
            print '{0}{1:.4f} +/- {2:.4f}'.format(m.ljust(15),np.mean(vals),stats.sem(vals,ddof=0))

def evaluate(model,train,users,get_known_items,compute_metrics):
    avg_metrics = defaultdict(float)
    count = 0
    for u in users:
        recommended = [r for r,_ in model.recommend_items(train,u,max_items=20)]
        metrics = compute_metrics(recommended,get_known_items(u))
        if metrics:
            for m,val in metrics.iteritems():
                avg_metrics[m] += val
            count += 1
    for m in avg_metrics:
        avg_metrics[m] /= float(count)
    return avg_metrics

# collections of metrics

def compute_main_metrics(recommended,known):
    if not known:
        return None
    return {'prec@5':prec(recommended,known,5),
            'prec@10':prec(recommended,known,10),
            'prec@15':prec(recommended,known,15),
            'prec@20':prec(recommended,known,20),
            'mrr':rr(recommended,known)}

def compute_hit_rate(recommended,known):
    if not known:
        return None
    return {'hit rate@10':hit_rate(recommended,known,10)}

# individual metrics

def prec(predicted,true,k,ignore_missing=False):
    """
    Compute precision@k.

    Parameters
    ==========
    predicted : array like
        Predicted items.
    true : array like
        True items.
    k : int
        Measure precision@k.
    ignore_missing : boolean (default: False)
        If True then measure precision only up to rank len(predicted)
        even if this is less than k, otherwise assume that the missing
        predictions were all incorrect

    Returns
    =======
    prec@k : float
        Precision at k.
    """
    if len(predicted) == 0:
        return 0
    correct = len(set(predicted[:k]).intersection(set(true)))
    num_predicted = k
    if len(predicted) < k and ignore_missing:
        num_predicted = len(predicted)
    return float(correct)/num_predicted

def hit_rate(predicted,true,k):
    """
    Compute hit rate i.e. recall@k assume a single test item.

    Parameters
    ==========
    predicted : array like
        Predicted items.
    true : array like
        Containing the single true test item.
    k : int
        Measure hit rate@k.

    Returns
    =======
    hitrate : int
        1 if true is amongst predicted, 0 if not.
    """
    if len(true) != 1:
        raise ValueError('can only evaluate hit rate for exactly 1 true item')
    return int(true[0] in predicted[:k])

def rr(predicted,true):
    """
    Compute Reciprocal Rank.

    Parameters
    ==========
    predicted : array like
        Predicted items.
    true : array like
        True items.

    Returns
    =======
    rr : float
        Reciprocal of rank at which first true item is found in predicted.

    Notes
    =====
    We'll under report this as our predictions are truncated.
    """
    for i,x in enumerate(predicted):
        if x in true:
            return 1.0/(i+1)
    return 0

########NEW FILE########
__FILENAME__ = preprocessing
import random

class TSVParser(object):
    """
    Parses tsv input: user, item, score.

    Parameters
    ----------
    thresh : float (default: 0)
        Set scores below this to zero.
    binarize : bool (default: False)
        If True, set all non-zero scores to 1.
    """

    def __init__(self,thresh=0,binarize=False,delimiter='\t'):
        self.thresh = thresh
        self.binarize = binarize
        self.delimiter = delimiter

    def parse(self,line):
        parts = line.strip().split(self.delimiter)
        user,item,count = parts[:3]
        val = float(count)
        if val >= self.thresh:
            if self.binarize:
                val = 1
        else:
            val = 0
        return int(user),(int(item),val)

class SplitCreator(object):
    """
    Split ratings for a user randomly into train
    and test groups.  Only items with positive scores
    will be included in the test group.

    Parameters
    ----------
    test_size : float
        If test_size >= 1 this specifies the absolute number
        of items to put in the test group; if test_size < 1
        then this specifies the test proportion.
    normalize : bool (default: False)
        If True, scale training scores for each user to have unit norm.
    discard_zeros : bool (default: False)
        If True then discard items with zero scores, if
        False then retain them in the training group.This
        should normally be False as such items have been seen
        (if not liked) and so the training set should include
        them so that it can be used to determine which items
        are actually novel at recommendation time.
    sample_before_thresholding : bool (default: False)
        If True then consider any item seen by the user for
        inclusion in the test group, even though only items
        with positive scrore will be selected. If the input
        includes items with zero scores this means that the
        test set may be smaller than the requested size for
        some users, even though they have apparently seen
        enough items.
    """

    def __init__(self,test_size,normalize=False,discard_zeros=False,sample_before_thresholding=False):
        self.test_size = test_size
        self.normalize = normalize
        self.discard_zeros = discard_zeros
        self.sample_before_thresholding = sample_before_thresholding

    def handle(self,vals):
        if self.sample_before_thresholding:
            train,test = self.split(vals)
        else:
            train,test = self.stratified_split(vals)
        train = [(v,c) for v,c in train if not self.discard_zeros or c > 0]
        test = [(v,c) for v,c in test if c > 0]
        if self.normalize:
            norm = sum(c*c for v,c in train)**0.5
            if norm > 0:
                train = [(v,c/norm) for v,c in train]
        return train,test

    def pos_neg_vals(self,vals):
        vals = list(vals)
        pos = [(v,c) for v,c in vals if c > 0]
        neg = [(v,0) for v,c in vals if c == 0]
        return pos,neg

    def split(self,vals):
        random.shuffle(vals)
        num_train = self.num_train(vals)
        return vals[:num_train],vals[num_train:]

    def stratified_split(self,vals):
        pos,neg = self.pos_neg_vals(vals)
        random.shuffle(pos)
        train = pos[:self.num_train(pos)]
        if not self.discard_zeros:
            random.shuffle(neg)
            train.extend(neg[:self.num_train(neg)])
            random.shuffle(train)
        test = pos[self.num_train(pos):]
        return train,test

    def num_train(self,vals):
        if self.test_size >= 1:
            return len(vals)-self.test_size
        return int(len(vals)*(1.0-self.test_size))

########NEW FILE########
__FILENAME__ = test_metrics
from sklearn.utils.testing import assert_equal
from sklearn.utils.testing import assert_raises

from mrec.evaluation import metrics

def test_sort_metrics_by_name():
    names = ['recall@10','z-score','auc','recall@5']
    expected = ['auc','recall@5','recall@10','z-score']
    assert_equal(expected,metrics.sort_metrics_by_name(names))

def test_prec():
    true = [2,8,6,4]
    predicted = [6,5,8,7]
    expected = [1,0.5,2./3.,0.5]
    for k in xrange(1,5):
        assert_equal(metrics.prec([],true,k),0)
        assert_equal(metrics.prec(true,true,k),1)
        assert_equal(metrics.prec(predicted,true,k),expected[k-1])
    assert_equal(metrics.prec(true,true,5),0.8)
    assert_equal(metrics.prec(true,true,5,ignore_missing=True),1)
    assert_equal(metrics.prec(predicted,true,5),0.4)
    assert_equal(metrics.prec(predicted,true,5,ignore_missing=True),expected[3])

def test_hit_rate():
    predicted = [6,5,8,7]
    for true in [[],[2,8]]:
        for k in xrange(1,5):
            with assert_raises(ValueError):
                metrics.hit_rate(predicted,true,k)
    true = [5]
    expected = [0,1,1,1]
    for k in xrange(1,5):
        assert_equal(metrics.hit_rate(predicted,true,k),expected[k-1])

def test_rr():
    true = [2,8,6,4]
    predicted = [5,7,6,8]
    expected = [0,0,1./3.,1./3.]
    for k in xrange(1,5):
        assert_equal(metrics.rr(predicted[:k],true),expected[k-1])

########NEW FILE########
__FILENAME__ = convert
"""
Convert sparse matrix from one file format to another.
"""

import os
import subprocess

def tsv2mtx(infile,outfile):
    num_users,num_items,nnz = 0,0,0
    for line in open(infile):
        u,i,v = line.strip().split()
        u = int(u)
        i = int(i)
        if u > num_users:
            num_users = u
        if i > num_items:
            num_items = i
        nnz += 1
    headerfile = outfile+'.header'
    with open(headerfile,'w') as header:
        print >>header,'%%MatrixMarket matrix coordinate real general'
        print >>header,'{0} {1} {2}'.format(num_users,num_items,nnz)
    subprocess.check_call(['cat',headerfile,infile],stdout=open(outfile,'w'))
    subprocess.check_call(['rm',headerfile])

def main():
    from optparse import OptionParser

    from mrec import load_sparse_matrix, save_sparse_matrix

    parser = OptionParser()
    parser.add_option('--input_format',dest='input_format',help='format of input dataset tsv | csv | mm (matrixmarket) | csr (scipy.sparse.csr_matrix) | fsm (mrec.sparse.fast_sparse_matrix)')
    parser.add_option('--input',dest='input',help='filepath to input')
    parser.add_option('--output_format',dest='output_format',help='format of output dataset(s) tsv | csv | mm (matrixmarket) | csr (scipy.sparse.csr_matrix) | fsm (mrec.sparse.fast_sparse_matrix)')
    parser.add_option('--output',dest='output',help='filepath for output')

    (opts,args) = parser.parse_args()
    if not opts.input or not opts.output or not opts.input_format or not opts.output_format:
        parser.print_help()
        raise SystemExit

    if opts.output_format == opts.input_format:
        raise SystemExit('input and output format are the same, not doing anything')

    if opts.input_format == 'tsv' and opts.output_format == 'mm':
        # we can do this without loading the data
        tsv2mtx(opts.input,opts.output)
    else:
        data = load_sparse_matrix(opts.input_format,opts.input)
        save_sparse_matrix(data,opts.output_format,opts.output)

if __name__ == '__main__':
    main()


########NEW FILE########
__FILENAME__ = evaluate
"""
Evaluate precomputed recommendations for one or more training/test sets.
Test and recommendation files must following naming conventions relative
to the training filepaths.
"""

def main():

    import os
    import logging
    import glob
    from optparse import OptionParser
    from collections import defaultdict

    from mrec import load_sparse_matrix
    from mrec.evaluation.metrics import compute_main_metrics, compute_hit_rate
    from mrec.evaluation import Evaluator
    from mrec.evaluation.metrics import print_report
    from filename_conventions import get_testfile, get_recsfile

    logging.basicConfig(level=logging.INFO,format='[%(asctime)s] %(levelname)s: %(message)s')

    parser = OptionParser()
    parser.add_option('--input_format',dest='input_format',help='format of training dataset(s) tsv | csv | mm (matrixmarket) | fsm (fast_sparse_matrix)')
    parser.add_option('--test_input_format',dest='test_input_format',default='npz',help='format of test dataset(s) tsv | csv | mm (matrixmarket) | npz (numpy binary)  (default: %default)')
    parser.add_option('--train',dest='train',help='glob specifying path(s) to training dataset(s) IMPORTANT: must be in quotes if it includes the * wildcard')
    parser.add_option('--recsdir',dest='recsdir',help='directory containing tsv files of precomputed recommendations')
    parser.add_option('--metrics',dest='metrics',default='main',help='which set of metrics to compute, main|hitrate (default: %default)')
    parser.add_option('--description',dest='description',help='description of model which generated the recommendations')
    metrics_funcs = {'main':compute_main_metrics,
                     'hitrate':compute_hit_rate}

    (opts,args) = parser.parse_args()
    if not opts.input_format or not opts.train or not opts.recsdir \
            or opts.metrics not in metrics_funcs:
        parser.print_help()
        raise SystemExit

    opts.train = os.path.abspath(os.path.expanduser(opts.train))
    opts.recsdir = os.path.abspath(os.path.expanduser(opts.recsdir))

    evaluator = Evaluator(metrics_funcs[opts.metrics],max_items=20)

    trainfiles = glob.glob(opts.train)

    all_metrics = defaultdict(list)
    for trainfile in trainfiles:
        logging.info('processing {0}...'.format(trainfile))
        testfile = get_testfile(trainfile)
        recsfile = get_recsfile(trainfile,opts.recsdir)
        testdata = load_sparse_matrix(opts.test_input_format,testfile).tocsr()
        cum_metrics,count = evaluator.process(testdata,recsfile,0,testdata.shape[0])
        if cum_metrics is not None:
            for m in cum_metrics:
                all_metrics[m].append(float(cum_metrics[m])/count)

    print_report([opts.description],[all_metrics])

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = factors
"""
Postprocess externally computed user/item factors so we can make
and evaluation recommendations with mrec scripts.
"""

def main():

    import os
    import logging
    import subprocess
    from optparse import OptionParser
    import numpy as np
    from scipy.io import mmread

    from mrec import save_recommender
    from mrec.mf.recommender import MatrixFactorizationRecommender
    from filename_conventions import get_modelfile

    logging.basicConfig(level=logging.INFO,format='[%(asctime)s] %(levelname)s: %(message)s')

    parser = OptionParser()
    parser.add_option('--factor_format',dest='factor_format',help='format of factor files tsv | mm (matrixmarket) | npy (numpy array)')
    parser.add_option('--user_factors',dest='user_factors',help='user factors filepath')
    parser.add_option('--item_factors',dest='item_factors',help='item factors filepath')
    parser.add_option('--train',dest='train',help='filepath to training data, just used to apply naming convention to output model saved here')
    parser.add_option('--outdir',dest='outdir',help='directory for output')
    parser.add_option('--description',dest='description',help='optional description of how factors were computed, will be saved with model so it can be output with evaluation results')

    (opts,args) = parser.parse_args()
    if not opts.factor_format or not opts.user_factors or not opts.item_factors \
            or not opts.outdir:
        parser.print_help()
        raise SystemExit

    model = MatrixFactorizationRecommender()

    logging.info('loading factors...')

    if opts.factor_format == 'npy':
        model.U = np.load(opts.user_factors)
        model.V = np.load(opts.item_factors)
    elif opts.factor_format == 'mm':
        model.U = mmread(opts.user_factors)
        model.V = mmread(opts.item_factors)
    elif opts.factor_format == 'tsv':
        model.U = np.loadtxt(opts.user_factors)
        model.V = np.loadtxt(opts.item_factors)
    else:
        raise ValueError('unknown factor format: {0}'.format(factor_format))

    if opts.description:
        model.description = opts.description

    logging.info('saving model...')

    logging.info('creating output directory {0}...'.format(opts.outdir))
    subprocess.check_call(['mkdir','-p',opts.outdir])

    modelfile = get_modelfile(opts.train,opts.outdir)
    save_recommender(model,modelfile)

    logging.info('done')

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = filename_conventions
"""
File naming conventions:

* training files must contain 'train' in their filename.
* the corresponding test files must have the same filepaths,
  but with 'test' in place of 'train' in their filenames.
* models, similarity matrices and recommendations will be
  written to filenames based on the training file.
"""

import os

def get_testfile(trainfile):
    filename = os.path.basename(trainfile)
    return os.path.join(os.path.dirname(trainfile),filename.replace('train','test'))

def get_simsdir(trainfile,outdir):
    filename = os.path.basename(trainfile)
    return os.path.join(outdir,'{0}-sims'.format(filename))

def get_recsdir(trainfile,outdir):
    filename = os.path.basename(trainfile)
    return os.path.join(outdir,'{0}-recs'.format(filename))

def get_modelsdir(trainfile,outdir):
    filename = os.path.basename(trainfile)
    return os.path.join(outdir,'{0}-models'.format(filename))

def get_factorsdir(trainfile,outdir):
    filename = os.path.basename(trainfile)
    return os.path.join(outdir,'{0}-factors'.format(filename))

def get_simsfile(trainfile,outdir):
    filename = os.path.basename(trainfile)
    return os.path.join(outdir,'{0}.sims.tsv'.format(filename))

def get_recsfile(trainfile,outdir):
    filename = os.path.basename(trainfile)
    return os.path.join(outdir,'{0}.recs.tsv'.format(filename))

def get_modelfile(trainfile,outdir):
    filename = os.path.basename(trainfile)
    return os.path.join(outdir,'{0}.model.npz'.format(filename))

def get_sortedfile(infile,outdir):
    filename = os.path.basename(infile)
    return os.path.join(outdir,'{0}.sorted'.format(filename))

def get_splitfile(infile,outdir,split_type,i):
    filename = os.path.basename(infile)
    return os.path.join(outdir,'{0}.{1}.{2}'.format(filename,split_type,i))

########NEW FILE########
__FILENAME__ = predict
"""
Make and evaluate recommendations in parallel on an ipython cluster,
using models that have previously been trained and saved to file.
We assume a shared filesystem (as you'll have when running locally
or on an AWS cluster fired up with StarCluster) to avoid passing
data between the controller and the worker engines, as this can
cause OOM issues for the controller.

You can specify multiple training sets / models and separate
recommendations will be output and evaluated for each of them: this
makes it easy to run a cross-validated evaluation.
"""

import math
import glob
import re
import os
import subprocess
from shutil import rmtree
import logging
from collections import defaultdict

from mrec import load_sparse_matrix, read_recommender_description, load_recommender
from mrec.parallel import predict
from mrec.mf.recommender import MatrixFactorizationRecommender
from mrec.item_similarity.recommender import ItemSimilarityRecommender

from filename_conventions import *

ONE_MB = 2**20

def process(view,opts,modelfile,trainfile,testfile,featurefile,outdir,evaluator):

    recsdir = get_recsdir(trainfile,opts.outdir)
    logging.info('creating recs directory {0}...'.format(recsdir))
    subprocess.check_call(['mkdir','-p',recsdir])

    done = []
    if not opts.overwrite:
        logging.info('checking for existing output recs...')
        done.extend(find_done(recsdir))
        if done:
            logging.info('found {0} output files'.format(len(done)))

    logging.info('creating tasks...')
    tasks = create_tasks(modelfile,
                         opts.input_format,
                         trainfile,
                         opts.test_input_format,
                         testfile,
                         opts.item_feature_format,
                         featurefile,
                         recsdir,
                         opts.mb_per_task,
                         done,
                         evaluator)

    logging.info('running in parallel across ipython engines...')
    results = []
    results.append(view.map_async(predict.run,tasks,retries=2))

    # wait for tasks to complete
    processed = [r.get() for r in results]

    logging.info('checking output files...')
    done = find_done(recsdir)
    remaining = len(tasks) - len(done)

    if remaining == 0:
        logging.info('SUCCESS: all tasks completed')
        logging.info('concatenating {0} partial output files...'.format(len(done)))
        paths = [os.path.join(recsdir,'recs.{0}-{1}.tsv'.format(start,end)) for start,end in done]
        cmd = ['cat']+paths
        recsfile = get_recsfile(trainfile,outdir)
        subprocess.check_call(cmd,stdout=open(recsfile,'w'))
        logging.info('removing partial output files...')
        rmtree(recsdir)
        logging.info('done')

        # aggregate metrics from each task
        avg_metrics = defaultdict(float)
        tot_count = 0
        for results in processed:
            for cum_metrics,count in results:
                for m,val in cum_metrics.iteritems():
                    avg_metrics[m] += val
                tot_count += count
        for m in avg_metrics:
            avg_metrics[m] /= float(tot_count)
    else:
        logging.error('FAILED: {0}/{1} tasks did not complete successfully'.format(remaining,len(tasks)))
        logging.error('try rerunning the command to retry the remaining tasks')
        avg_metrics = None

    return read_recommender_description(modelfile),avg_metrics

def create_tasks(modelfile,
                 input_format,
                 trainfile,
                 test_input_format,
                 testfile,
                 item_feature_format,
                 featurefile,
                 outdir,
                 mb_per_task,
                 done,
                 evaluator):
    users_per_task,num_users = estimate_users_per_task(mb_per_task,input_format,trainfile,modelfile)
    tasks = []
    for start in xrange(0,num_users,users_per_task):
        end = min(num_users,start+users_per_task)
        generate = (start,end) not in done
        tasks.append((modelfile,input_format,trainfile,test_input_format,testfile,item_feature_format,featurefile,outdir,start,end,evaluator,generate))
    logging.info('created {0} tasks, {1} users per task'.format(len(tasks),users_per_task))
    return tasks

def estimate_users_per_task(mb_per_task,input_format,trainfile,modelfile):
    num_users,num_items,nnz = get_dataset_size(input_format,trainfile)
    logging.info('loading model to get size...')
    model = load_recommender(modelfile)
    # we load the training and test data on every task
    # - let's guess that worst case the test data will be the same size
    required_mb_per_task = 2*(nnz*16)/ONE_MB
    if isinstance(model,MatrixFactorizationRecommender):
        # we have to load the factors on every task
        required_mb_per_task += ((model.U.size+model.V.size)*16)/ONE_MB
        if mb_per_task > required_mb_per_task:
            # remaining mem usage is dominated by computed scores:
            users_per_task = ((mb_per_task-required_mb_per_task)*ONE_MB) / (num_items*16)
    elif isinstance(model,ItemSimilarityRecommender):
        # we have to load the similarity matrix on every task
        required_mb_per_task += (model.similarity_matrix.nnz*16)/ONE_MB
        if mb_per_task > required_mb_per_task:
            # estimate additional usage from avg items per user and sims per item
            items_per_user = nnz / num_users
            sims_per_item = model.similarity_matrix.nnz / num_items
            users_per_task = ((mb_per_task-required_mb_per_task)*ONE_MB) / (items_per_user*sims_per_item*16)
    else:
        # assume nothing else to load
        users_per_task = num_users

    if mb_per_task <= required_mb_per_task:
        raise RuntimeError('requires at least {0}MB per task, increase --mb_per_task if you can'.format(required_mb_per_task))

    return users_per_task,num_users

def get_dataset_size(input_format,datafile):
    logging.info('loading dataset to get size...')
    dataset = load_sparse_matrix(input_format,datafile)
    return dataset.shape[0],dataset.shape[1],dataset.nnz

def find_done(outdir):
    success_files = glob.glob(os.path.join(outdir,'*.SUCCESS'))
    r = re.compile('.*?([0-9]+)-([0-9]+)\.SUCCESS$')
    done = []
    for path in success_files:
        m = r.match(path)
        start = int(m.group(1))
        end = int(m.group(2))
        done.append((start,end))
    return done

def main():

    import os
    from optparse import OptionParser
    from IPython.parallel import Client

    from mrec.evaluation.metrics import compute_main_metrics, compute_hit_rate
    from mrec.evaluation import Evaluator
    from mrec import load_recommender
    from mrec.evaluation.metrics import print_report

    logging.basicConfig(level=logging.INFO,format='[%(asctime)s] %(levelname)s: %(message)s')

    parser = OptionParser()
    parser.add_option('--mb_per_task',dest='mb_per_task',type='int',default=None,help='approximate memory limit per task in MB, so total memory usage is num_engines * mb_per_task (default: share all available RAM across engines)')
    parser.add_option('--input_format',dest='input_format',help='format of training dataset(s) tsv | csv | mm (matrixmarket) | fsm (fast_sparse_matrix)')
    parser.add_option('--test_input_format',dest='test_input_format',default='npz',help='format of test dataset(s) tsv | csv | mm (matrixmarket) | npz (numpy binary)  (default: %default)')
    parser.add_option('--train',dest='train',help='glob specifying path(s) to training dataset(s) IMPORTANT: must be in quotes if it includes the * wildcard')
    parser.add_option('--modeldir',dest='modeldir',help='directory containing trained models')
    parser.add_option('--outdir',dest='outdir',help='directory for output files')
    parser.add_option('--metrics',dest='metrics',default='main',help='which set of metrics to compute, main|hitrate (default: %default)')
    parser.add_option('--item_feature_format',dest='item_feature_format',help='format of item features tsv | csv | mm (matrixmarket) | npz (numpy arrays)')
    parser.add_option('--item_features',dest='item_features',help='path to sparse item features in tsv format (item_id,feature_id,val)')
    parser.add_option('--overwrite',dest='overwrite',action='store_true',default=False,help='overwrite existing files in outdir (default: %default)')
    parser.add_option('--packer',dest='packer',default='json',help='packer for IPython.parallel (default: %default)')
    parser.add_option('--add_module_paths',dest='add_module_paths',help='optional comma-separated list of paths to append to pythonpath (useful if you need to import uninstalled modules to IPython engines on a cluster)')

    metrics_funcs = {'main':compute_main_metrics,
                     'hitrate':compute_hit_rate}

    (opts,args) = parser.parse_args()
    if not opts.input_format or not opts.train or not opts.outdir \
            or not opts.modeldir or opts.metrics not in metrics_funcs:
        parser.print_help()
        raise SystemExit

    opts.train = os.path.abspath(os.path.expanduser(opts.train))
    opts.modeldir = os.path.abspath(os.path.expanduser(opts.modeldir))
    opts.outdir = os.path.abspath(os.path.expanduser(opts.outdir))

    # create an ipython client
    c = Client(packer=opts.packer)
    view = c.load_balanced_view()
    if opts.mb_per_task is None:
        import psutil
        num_engines = len(view)
        opts.mb_per_task = psutil.virtual_memory().available/ONE_MB/(num_engines+1)  # don't take *all* the memory

    if opts.add_module_paths:
        c[:].execute('import sys')
        for path in opts.add_module_paths.split(','):
            logging.info('adding {0} to pythonpath on all engines'.format(path))
            c[:].execute("sys.path.append('{0}')".format(path))

    evaluator = Evaluator(metrics_funcs[opts.metrics],max_items=20)

    trainfiles = glob.glob(opts.train)

    descriptions = set()
    all_metrics = defaultdict(list)
    for trainfile in trainfiles:
        logging.info('processing {0}...'.format(trainfile))
        modelfile = get_modelfile(trainfile,opts.modeldir)
        testfile = get_testfile(trainfile)
        description,metrics = process(view,opts,modelfile,trainfile,testfile,opts.item_features,opts.outdir,evaluator)
        descriptions.add(description)
        if metrics is not None:
            for m in metrics:
                all_metrics[m].append(metrics[m])

    description = ' AND '.join(descriptions)
    if len(descriptions) > 1:
        logging.warn('You are aggregating metrics from different models! {}'.format(description))

    print_report([description],[all_metrics])

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = prepare
class Processor(object):

    def __init__(self,splitter,parser,min_items_per_user,preprocess=None):
        self.splitter = splitter
        self.parser = parser
        self.min_items_per_user = min_items_per_user
        self.preprocess = preprocess

    def output(self,user,vals,outfile):
        for v,c in vals:
            print >>outfile,'{0}\t{1}\t{2}'.format(user,v,c)

    def handle(self,user,vals):
        if len(vals) >= self.min_items_per_user:
            if self.preprocess is not None:
                vals = self.preprocess(vals)
            train,test = self.splitter.handle(vals)
            self.output(user,train,self.train_out)
            self.output(user,test,self.test_out)
        else:
            self.too_few_items += 1

    def create_split(self,infile,train_out,test_out):
        self.train_out = train_out
        self.test_out = test_out
        self.too_few_items = 0
        last_user = None
        vals = []
        for line in infile:
            user,val = self.parser.parse(line)
            if user != last_user:
                if last_user is not None:
                    self.handle(last_user,vals)
                last_user = user
                vals = []
            vals.append(val)
        self.handle(last_user,vals)

    def get_too_few_items(self):
        return self.too_few_items

def main():
    import os
    import logging
    import subprocess
    from optparse import OptionParser

    from mrec.evaluation.preprocessing import TSVParser, SplitCreator
    from filename_conventions import get_sortedfile, get_splitfile

    logging.basicConfig(level=logging.INFO,format='[%(asctime)s] %(levelname)s: %(message)s')

    parser = OptionParser()
    parser.add_option('--dataset',dest='dataset',help='path to input dataset in tsv format')
    parser.add_option('--delimiter',dest='delimiter',default='\t',help='input delimiter (default: tab)')
    parser.add_option('--outdir',dest='outdir',help='directory for output files')
    parser.add_option('--num_splits',dest='num_splits',type='int',default=5,help='number of train/test splits to create (default: %default)')
    parser.add_option('--min_items_per_user',dest='min_items_per_user',type='int',default=10,help='skip users with less than this number of ratings (default: %default)')
    parser.add_option('--binarize',dest='binarize',action='store_true',default=False,help='binarize ratings')
    parser.add_option('--normalize',dest='normalize',action='store_true',help='scale training ratings to unit norm')
    parser.add_option('--rating_thresh',dest='rating_thresh',type='float',default=0,help='treat ratings below this as zero (default: %default)')
    parser.add_option('--test_size',dest='test_size',type='float',default=0.5,help='target number of test items for each user, if test_size >= 1 treat as an absolute number, otherwise treat as a fraction of the total items (default: %default)')
    parser.add_option('--discard_zeros',dest='discard_zeros',action='store_true',help='discard zero training ratings after thresholding (not recommended, incompatible with using training items to guarantee that recommendations are novel)')
    parser.add_option('--sample_before_thresholding',dest='sample_before_thresholding',action='store_true',help='choose test items before thresholding ratings (not recommended, test items below threshold will then be discarded)')

    (opts,args) = parser.parse_args()
    if not opts.dataset or not opts.outdir:
        parser.print_help()
        raise SystemExit

    opts.dataset = os.path.abspath(opts.dataset)
    opts.outdir = os.path.abspath(opts.outdir)

    logging.info('sorting input data...')
    infile = get_sortedfile(opts.dataset,opts.outdir)
    subprocess.check_call(['mkdir','-p',opts.outdir])
    subprocess.check_call(['sort','-k1','-n',opts.dataset],stdout=open(infile,'w'))

    parser = TSVParser(thresh=opts.rating_thresh,binarize=opts.binarize,delimiter=opts.delimiter)
    splitter = SplitCreator(test_size=opts.test_size,normalize=opts.normalize,discard_zeros=opts.discard_zeros,
                            sample_before_thresholding=opts.sample_before_thresholding)
    processor = Processor(splitter,parser,opts.min_items_per_user)

    for i in xrange(opts.num_splits):
        trainfile = get_splitfile(opts.dataset,opts.outdir,'train',i)
        testfile = get_splitfile(opts.dataset,opts.outdir,'test',i)

        logging.info('creating split {0}: {1} {2}'.format(i,trainfile,testfile))
        processor.create_split(open(infile),open(trainfile,'w'),open(testfile,'w'))

        too_few_items = processor.get_too_few_items()
        if (too_few_items):
            logging.info('skipped {0} users with less than {1} ratings'.format(too_few_items,opts.min_items_per_user))

    logging.info('cleaning up...')
    subprocess.check_call(['rm',infile])
    logging.info('done')

if __name__ == '__main__':
    main()


########NEW FILE########
__FILENAME__ = train
"""
Train an item similarity model in parallel on an ipython cluster.
We assume a shared filesystem (as you'll have when running locally
or on an AWS cluster fired up with StarCluster) to avoid passing
data between the controller and the worker engines, as this can
cause OOM issues for the controller.

You can specify multiple training sets and the model will learn a
separate similarity matrix for each input dataset: this makes it
easy to generate data for cross-validated evaluation.
"""

from filename_conventions import *

def main():

    import os
    import logging
    import glob
    import subprocess
    from optparse import OptionParser
    from IPython.parallel import Client

    from mrec import load_fast_sparse_matrix, save_recommender
    from mrec.item_similarity.slim import SLIM
    from mrec.item_similarity.knn import CosineKNNRecommender, DotProductKNNRecommender
    from mrec.mf.wrmf import WRMFRecommender
    from mrec.mf.warp import WARPMFRecommender
    from mrec.mf.warp2 import WARP2MFRecommender
    from mrec.popularity import ItemPopularityRecommender
    from mrec.parallel.item_similarity import ItemSimilarityRunner
    from mrec.parallel.wrmf import WRMFRunner
    from mrec.parallel.warp import WARPMFRunner

    logging.basicConfig(level=logging.INFO,format='[%(asctime)s] %(levelname)s: %(message)s')

    parser = OptionParser()
    parser.add_option('-n','--num_engines',dest='num_engines',type='int',default=0,help='number of IPython engines to use')
    parser.add_option('--input_format',dest='input_format',help='format of training dataset(s) tsv | csv | mm (matrixmarket) | fsm (fast_sparse_matrix)')
    parser.add_option('--train',dest='train',help='glob specifying path(s) to training dataset(s) IMPORTANT: must be in quotes if it includes the * wildcard')
    parser.add_option('--outdir',dest='outdir',help='directory for output files')
    parser.add_option('--overwrite',dest='overwrite',action='store_true',help='overwrite existing files in outdir')
    parser.add_option('--model',dest='model',default='slim',help='type of model to train: slim | knn | wrmf | warp | popularity (default: %default)')
    parser.add_option('--max_sims',dest='max_sims',type='int',default=100,help='max similar items to output for each training item (default: %default)')
    parser.add_option('--learner',dest='learner',default='sgd',help='underlying learner for SLIM learner: sgd | elasticnet | fs_sgd (default: %default)')
    parser.add_option('--l1_reg',dest='l1_reg',type='float',default=0.001,help='l1 regularization constant (default: %default)')
    parser.add_option('--l2_reg',dest='l2_reg',type='float',default=0.0001,help='l2 regularization constant (default: %default)')
    parser.add_option('--metric',dest='metric',default='cosine',help='metric for knn recommender: cosine | dot (default: %default)')
    parser.add_option('--num_factors',dest='num_factors',type='int',default=80,help='number of latent factors (default: %default)')
    parser.add_option('--alpha',dest='alpha',type='float',default=1.0,help='wrmf confidence constant (default: %default)')
    parser.add_option('--lbda',dest='lbda',type='float',default=0.015,help='wrmf regularization constant (default: %default)')
    parser.add_option('--als_iters',dest='als_iters',type='int',default=15,help='number of als iterations (default: %default)')
    parser.add_option('--gamma',dest='gamma',type='float',default=0.01,help='warp learning rate (default: %default)')
    parser.add_option('--C',dest='C',type='float',default=100.0,help='warp regularization constant (default: %default)')
    parser.add_option('--item_feature_format',dest='item_feature_format',help='format of item features tsv | csv | mm (matrixmarket) | npz (numpy arrays)')
    parser.add_option('--item_features',dest='item_features',help='path to sparse item features in tsv format (item_id,feature_id,val)')
    parser.add_option('--popularity_method',dest='popularity_method',default='count',help='how to compute popularity for baseline recommender: count | sum | avg | thresh (default: %default)')
    parser.add_option('--popularity_thresh',dest='popularity_thresh',type='float',default=0,help='ignore scores below this when computing popularity for baseline recommender (default: %default)')
    parser.add_option('--packer',dest='packer',default='json',help='packer for IPython.parallel (default: %default)')
    parser.add_option('--add_module_paths',dest='add_module_paths',help='optional comma-separated list of paths to append to pythonpath (useful if you need to import uninstalled modules to IPython engines on a cluster)')

    (opts,args) = parser.parse_args()
    if not opts.input_format or not opts.train or not opts.outdir or not opts.num_engines:
        parser.print_help()
        raise SystemExit

    opts.train = os.path.abspath(os.path.expanduser(opts.train))
    opts.outdir = os.path.abspath(os.path.expanduser(opts.outdir))

    trainfiles = glob.glob(opts.train)

    if opts.model == 'popularity':
        # special case, don't need to run in parallel
        subprocess.check_call(['mkdir','-p',opts.outdir])
        for trainfile in trainfiles:
            logging.info('processing {0}...'.format(trainfile))
            model = ItemPopularityRecommender(method=opts.popularity_method,thresh=opts.popularity_thresh)
            dataset = load_fast_sparse_matrix(opts.input_format,trainfile)
            model.fit(dataset)
            modelfile = get_modelfile(trainfile,opts.outdir)
            save_recommender(model,modelfile)
        logging.info('done')
        return

    # create an ipython client
    c = Client(packer=opts.packer)
    view = c.load_balanced_view()

    if opts.add_module_paths:
        c[:].execute('import sys')
        for path in opts.add_module_paths.split(','):
            logging.info('adding {0} to pythonpath on all engines'.format(path))
            c[:].execute("sys.path.append('{0}')".format(path))

    if opts.model == 'slim':
        if opts.learner == 'fs_sgd':
            num_selected_features = 2 * opts.max_sims  # preselect this many candidate similar items
            model = SLIM(l1_reg=opts.l1_reg,l2_reg=opts.l2_reg,model=opts.learner,num_selected_features=num_selected_features)
        else:
            model = SLIM(l1_reg=opts.l1_reg,l2_reg=opts.l2_reg,model=opts.learner)
    elif opts.model == 'knn':
        if opts.metric == 'cosine':
            model = CosineKNNRecommender(k=opts.max_sims)
        elif opts.metric == 'dot':
            model = DotProductKNNRecommender(k=opts.max_sims)
        else:
            parser.print_help()
            raise SystemExit('unknown metric: {0}'.format(opts.metric))
    elif opts.model == 'wrmf':
        model = WRMFRecommender(d=opts.num_factors,alpha=opts.alpha,lbda=opts.lbda,num_iters=opts.als_iters)
    elif opts.model == 'warp':
        num_factors_per_engine = max(opts.num_factors/opts.num_engines,1)
        if opts.item_features:
            model = WARP2MFRecommender(d=num_factors_per_engine,gamma=opts.gamma,C=opts.C)
        else:
            model = WARPMFRecommender(d=num_factors_per_engine,gamma=opts.gamma,C=opts.C)
    else:
        parser.print_help()
        raise SystemExit('unknown model type: {0}'.format(opts.model))

    for trainfile in trainfiles:
        logging.info('processing {0}...'.format(trainfile))
        modelfile = get_modelfile(trainfile,opts.outdir)
        if opts.model == 'wrmf':
            runner = WRMFRunner()
            factorsdir = get_factorsdir(trainfile,opts.outdir)
            runner.run(view,model,opts.input_format,trainfile,opts.num_engines,factorsdir,modelfile)
        elif opts.model == 'warp':
            runner = WARPMFRunner()
            modelsdir = get_modelsdir(trainfile,opts.outdir)
            runner.run(view,model,opts.input_format,trainfile,opts.item_feature_format,opts.item_features,opts.num_engines,modelsdir,opts.overwrite,modelfile)
        else:
            runner = ItemSimilarityRunner()
            simsdir = get_simsdir(trainfile,opts.outdir)
            simsfile = get_simsfile(trainfile,opts.outdir)
            runner.run(view,model,opts.input_format,trainfile,opts.num_engines,simsdir,opts.overwrite,opts.max_sims,simsfile,modelfile)

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = tune_slim
"""
Try to find a sensible range for regularization
constants for SLIM by looking at model sparsity.
"""

import random
from math import log10
import logging
from operator import itemgetter
from optparse import OptionParser
try:
    from sklearn.grid_search import ParameterGrid
except ImportError:
    from sklearn.grid_search import IterGrid as ParameterGrid
from IPython.parallel import Client

from mrec import load_fast_sparse_matrix

def estimate_sparsity(task):
    from mrec.item_similarity.slim import SLIM
    args,dataset,min_nnz,sample_items = task
    model = SLIM(**args)
    tot_nnz = 0
    tot_neg = 0
    below_min_nnz = 0

    for i in sample_items:
        w = model.compute_similarities(dataset,i)
        nnz = sum(w>0)
        tot_nnz += nnz
        if nnz < min_nnz:
            below_min_nnz += 1
        tot_neg += sum(w<0)

    num_samples = len(sample_items)
    avg_nnz = float(tot_nnz)/num_samples
    too_few_sims = float(below_min_nnz)/num_samples
    avg_neg = float(tot_neg)/num_samples
    return args,avg_nnz,too_few_sims,avg_neg

def pow_range(small,big):
    return [10**v for v in xrange(int(log10(small)),int(log10(big))+1)]

def main():
    parser = OptionParser()
    parser.add_option('-d','--dataset',dest='dataset',help='path to dataset')
    parser.add_option('--input_format',dest='input_format',help='format of training dataset(s) tsv | csv | mm (matrixmarket) | fsm (fast_sparse_matrix)')
    parser.add_option('--l1_min',dest='l1_min',type='float',help='min l1 constant to try (expected to be a power of 10)')
    parser.add_option('--l1_max',dest='l1_max',type='float',help='max l1 constant to try (expected to be a power of 10)')
    parser.add_option('--l2_min',dest='l2_min',type='float',help='min l2 constant to try (expected to be a power of 10)')
    parser.add_option('--l2_max',dest='l2_max',type='float',help='max l2 constant to try (expected to be a power of 10)')
    parser.add_option('--max_sims',dest='max_sims',type='int',default=2000,help='max desired number of positive item similarity weights (default: %default)')
    parser.add_option('--min_sims',dest='min_sims',type='int',default=15,help='min desired number of positive item similarity weights (default: %default)')
    parser.add_option('--max_sparse',dest='max_sparse',type='float',default=0.01,help='max allowable proportion of items with less than min_sims positive similarity weights (default: %default)')
    parser.add_option('--num_samples',dest='num_samples',type='int',default=100,help='number of sample items to evaluate for each regularization setting')
    parser.add_option('--packer',dest='packer',default='json',help='packer for IPython.parallel (default: %default)')
    parser.add_option('--add_module_paths',dest='add_module_paths',help='comma-separated list of paths to append to pythonpath to enable import of uninstalled modules')

    (opts,args) = parser.parse_args()
    if not opts.dataset or not opts.input_format or not opts.l1_min or not opts.l1_max or not opts.l2_min or not opts.l2_max:
        parser.print_help()
        raise SystemExit

    logging.basicConfig(level=logging.INFO,format='[%(asctime)s] %(levelname)s: %(message)s')

    dataset = load_fast_sparse_matrix(opts.input_format,opts.dataset)

    params = {'l1_reg':pow_range(opts.l1_min,opts.l1_max),
              'l2_reg':pow_range(opts.l2_min,opts.l2_max)}
    num_items = dataset.shape[1]
    sample_items = random.sample(xrange(num_items),opts.num_samples)

    logging.info('preparing tasks for a grid search of these values:')
    logging.info(params)
    tasks = [(args,dataset,opts.min_sims,sample_items) for args in ParameterGrid(params)]

    c = Client(packer=opts.packer)
    view = c.load_balanced_view()

    if opts.add_module_paths:
        c[:].execute('import sys')
        for path in opts.add_module_paths.split(','):
            logging.info('adding {0} to pythonpath on all engines'.format(path))
            c[:].execute("sys.path.append('{0}')".format(path))

    logging.info('running {0} tasks in parallel...'.format(len(tasks)))
    results = view.map(estimate_sparsity,tasks,ordered=False)

    candidates = [(args,nsims,nsparse,nneg) for args,nsims,nsparse,nneg in results if nsims <= opts.max_sims and nsparse <= opts.max_sparse]

    if candidates:
        best = min(candidates,key=itemgetter(1))

        print 'best parameter setting: {0}'.format(best[0])
        print 'mean # positive similarity weights per item = {0:.3}'.format(best[1])
        print 'proportion of items with fewer than {0} positive similarity weights = {1:.3}'.format(opts.min_sims,best[2])
        print 'mean # negative similarity weights per item = {0:.3}'.format(best[3])
    else:
        print 'no parameter settings satisfied the conditions, try increasing --min_sims, --max_sims or --max_sparse'

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = knn
"""
Brute-force k-nearest neighbour recommenders
intended to provide evaluation baselines.
"""

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from recommender import ItemSimilarityRecommender

class KNNRecommender(ItemSimilarityRecommender):
    """
    Abstract base class for k-nn recommenders.  You must supply an
    implementation of the compute_all_similarities() method.

    Parameters
    ==========
    k : int
        The number of nearest neighbouring items to retain
    """

    def __init__(self,k):
        self.k = k

    def compute_similarities(self,dataset,j):
        A = dataset.X
        a = dataset.fast_get_col(j)
        d = self.compute_all_similarities(A,a)
        d[j] = 0  # zero out self-similarity
        # now zero out similarities for all but top-k items
        nn = d.argsort()[-1:-1-self.k:-1]
        w = np.zeros(A.shape[1])
        w[nn] = d[nn]
        return w

    def compute_all_similarities(self,A,a):
        """
        Compute similarity scores between item vector a
        and all the rows of A.

        Parameters
        ==========
        A : scipy.sparse.csr_matrix
            Matrix of item vectors.
        a : array_like
            The item vector to be compared to each row of A.

        Returns
        =======
        similarities : numpy.ndarray
            Vector of similarity scores.
        """
        pass

class DotProductKNNRecommender(KNNRecommender):
    """
    Similarity between two items is their dot product
    (i.e. cooccurrence count if input data is binary).
    """

    def compute_all_similarities(self,A,a):
        return A.T.dot(a).toarray().flatten()

    def __str__(self):
        return 'DotProductKNNRecommender(k={0})'.format(self.k)

class CosineKNNRecommender(KNNRecommender):
    """
    Similarity between two items is their cosine distance.
    """

    def compute_all_similarities(self,A,a):
        return cosine_similarity(A.T,a.T).flatten()

    def __str__(self):
        return 'CosineKNNRecommender(k={0})'.format(self.k)

if __name__ == '__main__':

    # use knn models like this:

    import random
    import StringIO
    from mrec import load_fast_sparse_matrix

    random.seed(0)

    print 'loading test data...'
    data = """\
%%MatrixMarket matrix coordinate real general
3 5 9
1	1	1
1	2	1
1	3	1
1	4	1
2	2	1
2	3	1
2	5	1
3	3	1
3	4	1
"""
    print data
    dataset = load_fast_sparse_matrix('mm',StringIO.StringIO(data))
    num_users,num_items = dataset.shape

    model = CosineKNNRecommender(k=2)

    num_samples = 2

    def output(i,j,val):
        # convert back to 1-indexed
        print '{0}\t{1}\t{2:.3f}'.format(i+1,j+1,val)

    print 'computing some item similarities...'
    print 'item\tsim\tweight'
    # if we want we can compute these individually without calling fit()
    for i in random.sample(xrange(num_items),num_samples):
        for j,weight in model.get_similar_items(i,max_similar_items=2,dataset=dataset):
            output(i,j,weight)

    print 'learning entire similarity matrix...'
    # more usually we just call train() on the entire dataset
    model = CosineKNNRecommender(k=2)
    model.fit(dataset)
    print 'making some recommendations...'
    print 'user\trec\tscore'
    for u in random.sample(xrange(num_users),num_samples):
        for i,score in model.recommend_items(dataset.X,u,max_items=10):
            output(u,i,score)

    print 'making batch recommendations...'
    recs = model.batch_recommend_items(dataset.X)
    for u in xrange(num_users):
        for i,score in recs[u]:
            output(u,i,score)

    print 'making range recommendations...'
    for start,end in [(0,2),(2,3)]:
        recs = model.range_recommend_items(dataset.X,start,end)
        for u in xrange(start,end):
            for i,score in recs[u-start]:
                output(u,i,score)

########NEW FILE########
__FILENAME__ = precomputed
"""
Make recommendations from a precomputed item similarity matrix.
"""

from recommender import ItemSimilarityRecommender

class PrecomputedItemSimilarityRecommender(ItemSimilarityRecommender):
    """
    Wrapper class to make recommendations using a precomputed item similarity matrix.

    Parameters
    ==========
    description : str
        Printable name for this recommender.
    similarity_matrix : array_like(num_items,num_items)
        The precomputed item similarity matrix.
    """


    def __init__(self,description,similarity_matrix):
        self.description = description
        self.set_similarity_matrix(similarity_matrix)

    def set_similarity_matrix(self,similarity_matrix):
        self.similarity_matrix = similarity_matrix

    def compute_similarities(self,j):
        return self.similarity_matrix[j,:]

    def fit(self,dataset,item_features=None):
        pass

    def __str__(self):
        return self.description

########NEW FILE########
__FILENAME__ = recommender
"""
Base class for item similarity recommenders.
"""

try:
    import cPickle as pickle
except ImportError:
    import pickle
import numpy as np
from itertools import izip
from operator import itemgetter
from scipy.sparse import csr_matrix, coo_matrix

from ..sparse import fast_sparse_matrix
from ..base_recommender import BaseRecommender

class ItemSimilarityRecommender(BaseRecommender):
    """
    Abstract base class for recommenders that generate recommendations
    from an item similarity matrix.  To implement a recommender you just
    need to supply the compute_similarities() method.
    """

    def fit(self,dataset,item_features=None):
        """
        Learn the complete similarity matrix from a user-item matrix.

        Parameters
        ==========
        dataset : scipy sparse matrix or mrec.sparse.fast_sparse_matrix, shape = [num_users, num_items]
            The matrix of user-item counts, row i holds the counts for
            the i-th user.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, ignored here.
        """
        if not isinstance(dataset,fast_sparse_matrix):
            dataset = fast_sparse_matrix(dataset)
        num_users,num_items = dataset.shape
        # build up a sparse similarity matrix
        data = []
        row = []
        col = []
        for j in xrange(num_items):
            w = self.compute_similarities(dataset,j)
            for k,v in enumerate(w):
                if v != 0:
                    data.append(v)
                    row.append(j)
                    col.append(k)
        idx = np.array([row,col],dtype='int32')
        self.similarity_matrix = csr_matrix((data,idx),(num_items,num_items))

    def _create_archive(self):
        """
        Return fields to be serialized in a numpy archive.

        Returns
        =======
        archive : dict
            Fields to serialize, includes the model itself
            under the key 'model'.
        """
        # pickle the model without its similarity matrix
        # and use numpy to save the similarity matrix efficiently
        tmp = self.similarity_matrix
        self.similarity_matrix = None
        m = pickle.dumps(self)
        self.similarity_matrix = tmp
        if isinstance(self.similarity_matrix,np.ndarray):
            archive = {'mat':self.similarity_matrix,'model':m}
        elif isinstance(self.similarity_matrix,csr_matrix):
            d = self.similarity_matrix.tocoo(copy=False)
            archive = {'row':d.row,'col':d.col,'data':d.data,'shape':d.shape,'model':m}
        else:
            # similarity matrix has unexpected type
            archive = None
        return archive

    def _load_archive(self,archive):
        """
        Load fields from a numpy archive.
        """
        if 'mat' in archive.files:
            self.similarity_matrix = archive['mat']
        elif 'row' in archive.files:
            data = archive['data']
            row = archive['row']
            col = archive['col']
            shape = archive['shape']
            self.similarity_matrix = coo_matrix((data,(row,col)),shape=shape).tocsr()
        else:
            raise IOError('unexpected serialization format, cannot find similarity matrix')

    def load_similarity_matrix(self,filepath,num_items,offset=1):
        """
        Load a precomputed similarity matrix from tsv.

        Parameters
        ==========
        filepath : str
            Filepath to tsv file holding externally computed similarity matrix.
        num_items : int
            Total number of items (might exceed highest ID in a sparse similarity matrix).
        offset : int
            Item index offset i.e. 1 if indices in file are 1-indexed.
        """
        y = np.loadtxt(filepath)
        row = y[:,0]
        col = y[:,1]
        data = y[:,2]
        idx = np.array([row,col],dtype='int32')-offset
        self.similarity_matrix = csr_matrix((data,idx),(num_items,num_items))

    def compute_similarities(self,dataset,j):
        """
        Compute pairwise similarity scores between the j-th item and
        every item in the dataset.

        Parameters
        ==========
        j : int
            Index of item for which to compute similarity scores.
        dataset : mrec.sparse.fast_sparse_matrix
            The user-item matrix.

        Returns
        =======
        similarities : numpy.ndarray
            Vector of similarity scores.
        """
        pass

    def get_similar_items(self,j,max_similar_items=30,dataset=None):
        """
        Get the most similar items to a supplied item.

        Parameters
        ==========
        j : int
            Index of item for which to get similar items.
        max_similar_items : int
            Maximum number of similar items to return.
        dataset : mrec.sparse.fast_sparse_matrix
            The user-item matrix. Not required if you've already called fit()
            to learn the similarity matrix.

        Returns
        =======
        sims : list
            Sorted list of similar items, best first.  Each entry is
            a tuple of the form (i,score).
        """
        if hasattr(self,'similarity_matrix') and self.similarity_matrix is not None:
            w = zip(self.similarity_matrix[j].indices,self.similarity_matrix[j].data)
            sims = sorted(w,key=itemgetter(1),reverse=True)[:max_similar_items]
            sims = [(i,f) for i,f in sims if f > 0]
        else:
            w = self.compute_similarities(dataset,j)
            sims = [(i,w[i]) for i in w.argsort()[-1:-max_similar_items-1:-1] if w[i] > 0]
        return sims

    def recommend_items(self,dataset,u,max_items=10,return_scores=True,item_features=None):
        """
        Recommend new items for a user.  Assumes you've already called
        fit() to learn the similarity matrix.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        u : int
            Index of user for which to make recommendations.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, ignored here.

        Returns
        =======
        recs : list
            List of (idx,score) pairs if return_scores is True, else
            just a list of idxs.
        """
        try:
            r = (self.similarity_matrix * dataset[u].T).toarray().flatten()
        except AttributeError:
            raise AttributeError('you must call fit() before trying to recommend items')
        known_items = set(dataset[u].indices)
        recs = []
        for i in r.argsort()[::-1]:
            if i not in known_items:
                if return_scores:
                    recs.append((i,r[i]))
                else:
                    recs.append(i)
                if len(recs) >= max_items:
                    break
        return recs

    def batch_recommend_items(self,
                              dataset,
                              max_items=10,
                              return_scores=True,
                              show_progress=False,
                              item_features=None):
        """
        Recommend new items for all users in the training dataset.  Assumes
        you've already called fit() to learn the similarity matrix.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        show_progress: bool
            If true print something to stdout to show progress.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, ignored here.

        Returns
        =======
        recs : list of lists
            Each entry is a list of (idx,score) pairs if return_scores is True,
            else just a list of idxs.
        """
        try:
            r = dataset * self.similarity_matrix.T
        except AttributeError:
            raise AttributeError('you must call fit() before trying to recommend items')
        return self._get_recommendations_from_predictions(r,dataset,0,r.shape[0],max_items,return_scores,show_progress)

    def range_recommend_items(self,
                              dataset,
                              user_start,
                              user_end,
                              max_items=10,
                              return_scores=True,
                              item_features=None):
        """
        Recommend new items for a range of users in the training dataset.
        Assumes you've already called fit() to learn the similarity matrix.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        user_start : int
            Index of first user in the range to recommend.
        user_end : int
            Index one beyond last user in the range to recommend.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, ignored here.

        Returns
        =======
        recs : list of lists
            Each entry is a list of (idx,score) pairs if return_scores is True,
            else just a list of idxs.
        """
        try:
            r = dataset[user_start:user_end,:] * self.similarity_matrix.T
        except AttributeError:
            raise AttributeError('you must call fit() before trying to recommend items')
        return self._get_recommendations_from_predictions(r,dataset,user_start,user_end,max_items,return_scores)

    def _get_recommendations_from_predictions(self,r,dataset,user_start,user_end,max_items,return_scores=True,show_progress=False):
        """
        Select recommendations given predicted scores/ratings.

        Parameters
        ==========
        r : scipy.sparse.csr_matrix
            Predicted scores/ratings for candidate items for users in supplied range.
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        user_start : int
            Index of first user in the range to recommend.
        user_end : int
            Index one beyond last user in the range to recommend.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        show_progress: bool
            If true print something to stdout to show progress.

        Returns
        =======
        recs : list of lists
            Each entry is a list of (idx,score) pairs if return_scores is True,
            else just a list of idxs.
        """
        r = self._zero_known_item_scores(r,dataset[user_start:user_end,:])
        recs = [[] for u in xrange(user_start,user_end)]
        for u in xrange(user_start,user_end):
            ux = u - user_start
            if show_progress and ux%1000 == 0:
               print ux,'..',
            ru = r[ux,:]
            if return_scores:
                recs[ux] = [(i,v) for v,i in sorted(izip(ru.data,ru.indices),reverse=True) if v > 0][:max_items]
            else:
                recs[ux] = [i for v,i in sorted(izip(ru.data,ru.indices),reverse=True) if v > 0][:max_items]
        if show_progress:
            print
        return recs

########NEW FILE########
__FILENAME__ = slim
"""
Train a Sparse Linear Methods (SLIM) item similarity model using various
methods for sparse regression.

See:
    Efficient Top-N Recommendation by Linear Regression,
    M. Levy and K. Jack, LSRS workshop at RecSys 2013.

    SLIM: Sparse linear methods for top-n recommender systems,
    X. Ning and G. Karypis, ICDM 2011.
    http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf
"""

from sklearn.linear_model import SGDRegressor, ElasticNet
from sklearn.preprocessing import binarize
import sklearn
import numpy as np

from recommender import ItemSimilarityRecommender


def parse_version(version_string):
    if '-' in version_string:
        version_string = version_string.split('-', 1)[0]
    return tuple(map(int, version_string.split('.')))


class NNFeatureSelectingSGDRegressor(object):
    """
    Wraps nearest-neighbour feature selection and regression in a single model.
    """

    def __init__(self,model,k):
        self.model = model
        self.k = k

    def fit(self,A,a):
        # find k-NN by brute force
        d = A.T.dot(a).flatten()  # distance = dot product
        nn = d.argsort()[-1:-1-self.k:-1]
        # fit the model to selected features only
        self.model.fit(A[:,nn],a)
        # set our weights for the selected "features" i.e. items
        self.coef_ = np.zeros(A.shape[1])
        self.coef_[nn] = self.model.coef_

    def __str__(self):
        return 'NN-feature selecting {0}'.format(self.model)

class SLIM(ItemSimilarityRecommender):
    """
    Parameters
    ==========

    l1_reg : float
        L1 regularisation constant.
    l2_reg : float
        L2 regularisation constant.
    fit_intercept : bool
        Whether to fit a constant term.
    ignore_negative_weights : bool
        If true discard any computed negative similarity weights.
    num_selected_features : int
        The number of "features" (i.e. most similar items) to retain when using feature selection.
    model : string
        The underlying model to use: sgd, elasticnet, fs_sgd.
        :sgd: SGDRegressor with elasticnet penalty
        :elasticnet: ElasticNet
        :fs_sgd: NNFeatureSelectingSGDRegressor
    """
    def __init__(self,
                 l1_reg=0.001,
                 l2_reg=0.0001,
                 fit_intercept=False,
                 ignore_negative_weights=False,
                 num_selected_features=200,
                 model='sgd'):
        alpha = l1_reg+l2_reg
        l1_ratio = l1_reg/alpha
        if parse_version(sklearn.__version__) <= (0, 14, 1):
            # Backward compat: in old versions of scikit-learn l1_ratio had
            # the opposite sign...
            l1_ratio = (1 - l1_ratio)
        if model == 'sgd':
            self.model = SGDRegressor(penalty='elasticnet',fit_intercept=fit_intercept,alpha=alpha,l1_ratio=l1_ratio)
        elif model == 'elasticnet':
            self.model = ElasticNet(alpha=alpha,l1_ratio=l1_ratio,positive=True,fit_intercept=fit_intercept,copy_X=False)
        elif model == 'fs_sgd':
            m = SGDRegressor(penalty='elasticnet',fit_intercept=fit_intercept,alpha=alpha,l1_ratio=l1_ratio)
            self.model = NNFeatureSelectingSGDRegressor(m,num_selected_features)
        else:
            raise SystemExit('unknown model type: {0}'.format(model))
        self.ignore_negative_weights = ignore_negative_weights

    def compute_similarities(self,dataset,j):
        """Compute item similarity weights for item j."""
        # zero out the j-th column of the input so we get w[j] = 0
        a = dataset.fast_get_col(j)
        dataset.fast_update_col(j,np.zeros(a.nnz))
        self.model.fit(dataset.X,a.toarray().ravel())
        # reinstate the j-th column
        dataset.fast_update_col(j,a.data)
        w = self.model.coef_
        if self.ignore_negative_weights:
            w[w<0] = 0
        return w

    def compute_similarities_from_vec(self,dataset,a):
        """Compute item similarity weights for out-of-dataset item vector."""
        self.model.fit(dataset.X,a)
        return self.model.coef_

    def __str__(self):
        if self.ignore_negative_weights:
            return 'SLIM({0} ignoring negative weights)'.format(self.model)
        else:
            return 'SLIM({0})'.format(self.model)

if __name__ == '__main__':

    # use SLIM like this:

    import random
    import StringIO
    from mrec import load_fast_sparse_matrix

    random.seed(0)

    print 'loading test data...'
    data = """\
%%MatrixMarket matrix coordinate real general
3 5 9
1	1	1
1	2	1
1	3	1
1	4	1
2	2	1
2	3	1
2	5	1
3	3	1
3	4	1
"""
    print data
    dataset = load_fast_sparse_matrix('mm',StringIO.StringIO(data))
    num_users,num_items = dataset.shape

    model = SLIM()

    num_samples = 2

    def output(i,j,val):
        # convert back to 1-indexed
        print '{0}\t{1}\t{2:.3f}'.format(i+1,j+1,val)

    print 'computing some item similarities...'
    print 'item\tsim\tweight'
    # if we want we can compute these individually without calling fit()
    for i in random.sample(xrange(num_items),num_samples):
        for j,weight in model.get_similar_items(i,max_similar_items=10,dataset=dataset):
            output(i,j,weight)

    print 'learning entire similarity matrix...'
    # usually we'll call train() on the entire dataset
    model = SLIM()
    model.fit(dataset)
    print 'making some recommendations...'
    print 'user\trec\tscore'
    for u in random.sample(xrange(num_users),num_samples):
        for i,score in model.recommend_items(dataset.X,u,max_items=10):
            output(u,i,score)

    print 'making batch recommendations...'
    recs = model.batch_recommend_items(dataset.X)
    for u in xrange(num_users):
        for i,score in recs[u]:
            output(u,i,score)

    print 'making range recommendations...'
    for start,end in [(0,2),(2,3)]:
        recs = model.range_recommend_items(dataset.X,start,end)
        for u in xrange(start,end):
            for i,score in recs[u-start]:
                output(u,i,score)

########NEW FILE########
__FILENAME__ = climf
"""
CLiMF Collaborative Less-is-More Filtering, a variant of latent factor CF
which optimises a lower bound of the smoothed reciprocal rank of "relevant"
items in ranked recommendation lists.  The intention is to promote diversity
as well as accuracy in the recommendations.  The method assumes binary
relevance data, as for example in friendship or follow relationships.

CLiMF: Learning to Maximize Reciprocal Rank with Collaborative Less-is-More Filtering
Yue Shi, Martha Larson, Alexandros Karatzoglou, Nuria Oliver, Linas Baltrunas, Alan Hanjalic
ACM RecSys 2012
"""

from math import exp, log
import random
import numpy as np

from mrec.mf.recommender import MatrixFactorizationRecommender


# TODO: cythonize most of this...


def g(x):
    """sigmoid function"""
    return 1/(1+exp(-x))

def dg(x):
    """derivative of sigmoid function"""
    return exp(x)/(1+exp(x))**2

class CLiMFRecommender(MatrixFactorizationRecommender):

    def __init__(self,d,lbda=0.01,gamma=0.01,max_iters=25):
        self.d = d
        self.lbda = lbda
        self.gamma = gamma
        self.max_iters = max_iters

    def fit(self,data):
        self.U = 0.01*np.random.random_sample((data.shape[0],self.d))
        self.V = 0.01*np.random.random_sample((data.shape[1],self.d))
        # TODO: create a validation set

        for iter in xrange(self.max_iters):
            print 'iteration {0}:'.format(iter+1)
            print 'objective = {0:.4f}'.format(self.objective(data))
            self.update(data)
            # TODO: compute MRR on validation set, terminate if appropriate

    def precompute_f(self,data,i):
        """
        precompute f[j] = <U[i],V[j]>

        params:
          data: scipy csr sparse matrix containing user->(item,count)
          U   : user factors
          V   : item factors
          i   : item of interest

        returns:
          dot products <U[i],V[j]> for all j in data[i]
        """
        items = data[i].indices
        f = dict((j,np.dot(self.U[i],self.V[j])) for j in items)
        return f

    def objective(self,data):
        """
        compute objective function F(U,V)

        params:
          data: scipy csr sparse matrix containing user->(item,count)
          U   : user factors
          V   : item factors
          lbda: regularization constant lambda
        returns:
          current value of F(U,V)
        """
        F = -0.5*self.lbda*(np.sum(self.U*self.U)+np.sum(self.V*self.V))
        for i in xrange(len(self.U)):
            f = self.precompute_f(data,i)
            for j in f:
                F += log(g(f[j]))
                for k in f:
                    F += log(1-g(f[k]-f[j]))
        return F

    def update(self,data):
        """
        update user/item factors using stochastic gradient ascent

        params:
          data : scipy csr sparse matrix containing user->(item,count)
          U    : user factors
          V    : item factors
          lbda : regularization constant lambda
          gamma: learning rate
        """
        for i in xrange(len(self.U)):
            dU = -self.lbda*self.U[i]
            f = self.precompute_f(data,i)
            for j in f:
                dV = g(-f[j])-self.lbda*self.V[j]
                for k in f:
                    dV += dg(f[j]-f[k])*(1/(1-g(f[k]-f[j]))-1/(1-g(f[j]-f[k])))*self.U[i]
                self.V[j] += self.gamma*dV
                dU += g(-f[j])*self.V[j]
                for k in f:
                    dU += (self.V[j]-self.V[k])*dg(f[k]-f[j])/(1-g(f[k]-f[j]))
            self.U[i] += self.gamma*dU

    def compute_mrr(self,data,test_users=None):
        """
        compute average Mean Reciprocal Rank of data according to factors

        params:
          data      : scipy csr sparse matrix containing user->(item,count)
          U         : user factors
          V         : item factors
          test_users: optional subset of users over which to compute MRR

        returns:
          the mean MRR over all users in data
        """
        mrr = []
        if test_users is None:
            test_users = range(len(self.U))
        for ix,i in enumerate(test_users):
            items = set(data[i].indices)
            if not items:
                continue
            predictions = np.sum(np.tile(self.U[i],(len(self.V),1))*self.V,axis=1)
            found = False
            for rank,item in enumerate(np.argsort(predictions)[::-1]):
                if item in items:
                    mrr.append(1.0/(rank+1))
                    found = True
                    break
            if not found:
                print 'fail, no relevant items predicted for test user {0}'.format(i+1)
                print 'known items: {0}'.format(items)
        assert(len(mrr) == len(test_users))
        return np.mean(mrr)

def main():
    import sys
    from mrec import load_sparse_matrix, save_recommender
    from mrec.mf.climf import CLiMFRecommender

    file_format = sys.argv[1]
    filepath = sys.argv[2]
    outfile = sys.argv[3]

    # load training set as scipy sparse matrix
    train = load_sparse_matrix(file_format,filepath)

    model = CLiMFRecommender(d=5)
    model.fit(train)

    save_recommender(model,outfile)

if __name__ == '__main__':
    import cProfile
    cProfile.run('main()')

########NEW FILE########
__FILENAME__ = evaluate
def retrain_recommender(model,dataset):
    model.fit(dataset.X)

if __name__ == '__main__':

    try:
        from sklearn.grid_search import ParameterGrid
    except ImportError:
        from sklearn.grid_search import IterGrid as ParameterGrid
    from optparse import OptionParser
    from warp import WARPMFRecommender

    from mrec.evaluation.metrics import *

    parser = OptionParser()
    parser.add_option('-m','--main_split_dir',dest='main_split_dir',help='directory containing 50/50 splits for main evaluation')
    parser.add_option('-l','--loo_split_dir',dest='loo_split_dir',help='directory containing LOO splits for hit rate evaluation')
    parser.add_option('-n','--num_splits',dest='num_splits',type='int',default=5,help='number of splits in each directory (default: %default)')

    (opts,args) = parser.parse_args()
    if not (opts.main_split_dir or opts.loo_split_dir) or not opts.num_splits:
        parser.print_help()
        raise SystemExit

    print 'doing a grid search for regularization parameters...'
    params = {'d':[100],'gamma':[0.01],'C':[100],'max_iter':[100000],'validation_iters':[500]}
    models = [WARPMFRecommender(**a) for a in ParameterGrid(params)]

    for train in glob:
        # get test
        # load em both up
        # put them into something that returns train,test.keys(),test in a generator()
        # test is a dict id->[id,id,...]

    if opts.main_split_dir:
        generate_main_metrics = generate_metrics(get_known_items_from_dict,compute_main_metrics)
        main_metrics = run_evaluation(models,
                                      retrain_recommender,
                                      load_splits(opts.main_split_dir,opts.num_splits),
                                      opts.num_splits,
                                      generate_main_metrics)
        print_report(models,main_metrics)

    if opts.loo_split_dir:
        generate_hit_rate = generate_metrics(get_known_items_from_dict,compute_hit_rate)
        hit_rate_metrics = run_evaluation(models,
                                          retrain_recommender,
                                          load_splits(opts.loo_split_dir,opts.num_splits),
                                          opts.num_splits,
                                          generate_hit_rate)
        print_report(models,hit_rate_metrics)

########NEW FILE########
__FILENAME__ = warp
import numpy as np
import random
from itertools import izip

from mrec.evaluation import metrics

from warp_fast import warp_sample, apply_updates

class WARPBatchUpdate(object):
    """Collection of arrays to hold a batch of WARP sgd updates."""

    def __init__(self,batch_size,d):
        self.u = np.zeros(batch_size,dtype='int32')
        self.dU = np.zeros((batch_size,d),order='F')
        self.v_pos = np.zeros(batch_size,dtype='int32')
        self.dV_pos = np.zeros((batch_size,d))
        self.v_neg = np.zeros(batch_size,dtype='int32')
        self.dV_neg = np.zeros((batch_size,d))

    def clear(self):
        pass

    def set_update(self,ix,update):
        u,v_pos,v_neg,dU,dV_pos,dV_neg = update
        self.u[ix] = u
        self.dU[ix] = dU
        self.v_pos[ix] = v_pos
        self.dV_pos[ix] = dV_pos
        self.v_neg[ix] = v_neg
        self.dV_neg[ix] = dV_neg

class WARPDecomposition(object):
    """
    Matrix embedding optimizing the WARP loss.

    Parameters
    ==========
    num_rows : int
        Number of rows in the full matrix.
    num_cols : int
        Number of columns in the full matrix.
    d : int
        The embedding dimension for the decomposition.
    """

    def __init__(self,num_rows,num_cols,d):
        # initialize factors to small random values
        self.U = d**-0.5*np.random.random_sample((num_rows,d))
        self.V = d**-0.5*np.random.random_sample((num_cols,d))
        # ensure memory layout avoids extra allocation in dot product
        self.U = np.asfortranarray(self.U)

    def compute_gradient_step(self,u,i,j,L):
        """
        Compute a gradient step from results of sampling.

        Parameters
        ==========
        u : int
            The sampled row.
        i : int
            The sampled positive column.
        j : int
            The sampled violating negative column i.e. U[u].V[j] is currently
            too large compared to U[u].V[i]
        L : int
            The number of trials required to find a violating negative column.

        Returns
        =======
        u : int
            As input.
        i : int
            As input.
        j : int
            As input.
        dU : numpy.ndarray
            Gradient step for U[u].
        dV_pos : numpy.ndarray
            Gradient step for V[i].
        dV_neg : numpy.ndarray
            Gradient step for V[j].
        """
        dU = L*(self.V[i]-self.V[j])
        dV_pos = L*self.U[u]
        dV_neg = -L*self.U[u]
        return u,i,j,dU,dV_pos,dV_neg

    def apply_updates(self,updates,gamma,C):
        # delegate to cython implementation
        apply_updates(self.U,updates.u,updates.dU,gamma,C)
        apply_updates(self.V,updates.v_pos,updates.dV_pos,gamma,C)
        apply_updates(self.V,updates.v_neg,updates.dV_neg,gamma,C)

    def reconstruct(self,rows):
        if rows is None:
            U = self.U
        else:
            U = np.asfortranarray(self.U[rows,:])
        return U.dot(self.V.T)

class WARP(object):
    """
    Learn low-dimensional embedding optimizing the WARP loss.

    Parameters
    ==========
    d : int
        Embedding dimension.
    gamma : float
        Learning rate.
    C : float
        Regularization constant.
    max_iters : int
        Maximum number of SGD updates.
    validation_iters : int
        Number of SGD updates between checks for stopping condition.
    batch_size : int
        Mini batch size for SGD updates.
    positive_thresh: float
        Training entries below this are treated as zero.
    max_trials : int
        Number of attempts allowed to find a violating negative example during
        training updates. This means that in practice we optimize for ranks 1
        to max_trials-1.

    Attributes
    ==========
    U_ : numpy.ndarray
        Row factors.
    V_ : numpy.ndarray
        Column factors.
    """

    def __init__(self,
                 d,
                 gamma,
                 C,
                 max_iters,
                 validation_iters,
                 batch_size=10,
                 positive_thresh=0.00001,
                 max_trials=50):
        self.d = d
        self.gamma = gamma
        self.C = C
        self.max_iters = max_iters
        self.validation_iters = validation_iters
        self.batch_size = batch_size
        self.positive_thresh = positive_thresh
        self.max_trials = max_trials

    def __str__(self):
        return 'WARP(d={0},gamma={1},C={2},max_iters={3},validation_iters={4},batch_size={5},positive_thresh={6},max_trials={7})'.format(self.d,self.gamma,self.C,self.max_iters,self.validation_iters,self.batch_size,self.positive_thresh,self.max_trials)

    def fit(self,train,validation=None):
        """
        Learn factors from training set. The dot product of the factors
        reconstructs the training matrix approximately, minimizing the
        WARP ranking loss relative to the original data.

        Parameters
        ==========
        train : scipy.sparse.csr_matrix
            Training matrix to be factorized.
        validation : dict or int
            Validation set to control early stopping, based on precision@30.
            The dict should have the form row->[cols] where the values in cols
            are those we expected to be highly ranked in the reconstruction of
            row. If an int is supplied then instead we evaluate precision
            against the training data for the first validation rows.

        Returns
        =======
        self : object
            This model itself.
        """
        num_rows,num_cols = train.shape
        decomposition = WARPDecomposition(num_rows,num_cols,self.d)
        updates = WARPBatchUpdate(self.batch_size,self.d)
        self.precompute_warp_loss(num_cols)

        self._fit(decomposition,updates,train,validation)

        self.U_ = decomposition.U
        self.V_ = decomposition.V

        return self

    def _fit(self,decomposition,updates,train,validation):
        precs = []
        tot_trials = 0
        for it in xrange(self.max_iters):
            if it % self.validation_iters == 0:
                print 'tot_trials',tot_trials
                tot_trials = 0
                prec = self.estimate_precision(decomposition,train,validation)
                precs.append(prec)
                print '{0}: validation precision = {1:.3f}'.format(it,precs[-1])
                if len(precs) > 3 and precs[-1] < precs[-2] and precs[-2] < precs[-3]:
                    print 'validation precision got worse twice, terminating'
                    break
            tot_trials += self.compute_updates(train,decomposition,updates)
            decomposition.apply_updates(updates,self.gamma,self.C)

    def precompute_warp_loss(self,num_cols):
        """
        Precompute WARP loss for each possible rank:

            L(i) = \sum_{0,i}{1/(i+1)}
        """
        assert(num_cols>1)
        self.warp_loss = np.ones(num_cols)
        for i in xrange(1,num_cols):
            self.warp_loss[i] = self.warp_loss[i-1]+1.0/(i+1)

    def compute_updates(self,train,decomposition,updates):
        updates.clear()
        tot_trials = 0
        for ix in xrange(self.batch_size):
            u,i,j,N,trials = self.sample(train,decomposition)
            tot_trials += trials
            L = self.estimate_warp_loss(train,u,N)
            updates.set_update(ix,decomposition.compute_gradient_step(u,i,j,L))
        return tot_trials

    def sample(self,train,decomposition):
        # delegate to cython implementation
        return warp_sample(decomposition.U,
                           decomposition.V,
                           train.data,
                           train.indices,
                           train.indptr,
                           self.positive_thresh,
                           self.max_trials)

    def estimate_warp_loss(self,train,u,N):
        num_cols = train.shape[1]
        nnz = train.indptr[u+1]-train.indptr[u]
        estimated_rank = (num_cols-nnz-1)/N
        return self.warp_loss[estimated_rank]

    def estimate_precision(self,decomposition,train,validation,k=30):
        """
        Compute prec@k for a sample of training rows.

        Parameters
        ==========
        decomposition : WARPDecomposition
            The current decomposition.
        train : scipy.sparse.csr_matrix
            The training data.
        k : int
            Measure precision@k.
        validation : dict or int
            Validation set over which we compute precision. Either supply
            a dict of row -> list of hidden cols, or an integer n, in which
            case we simply evaluate against the training data for the first
            n rows.

        Returns
        =======
        prec : float
            Precision@k computed over a sample of the training rows.

        Notes
        =====
        At the moment this will underestimate the precision of real
        recommendations because we do not exclude training cols with zero
        ratings from the top-k predictions evaluated.
        """
        if isinstance(validation,dict):
            have_validation_set = True
            rows = validation.keys()
        elif isinstance(validation,(int,long)):
            have_validation_set = False
            rows = range(validation)
        else:
            raise ValueError('validation must be dict or int')

        r = decomposition.reconstruct(rows)
        prec = 0
        for u,ru in izip(rows,r):
            predicted = ru.argsort()[::-1][:k]
            if have_validation_set:
                actual = validation[u]
            else:
                actual = train[u].indices[train[u].data > 0]
            prec += metrics.prec(predicted,actual,k)
        return float(prec)/len(rows)


########NEW FILE########
__FILENAME__ = warp2
import numpy as np
import scipy
import random

from warp import WARPBatchUpdate, WARPDecomposition, WARP
from warp_fast import warp2_sample

class WARP2BatchUpdate(WARPBatchUpdate):
    """Collection of arrays to hold a batch of sgd updates."""

    def __init__(self,batch_size,num_features,d):
        WARPBatchUpdate.__init__(self,batch_size,d)
        self.dW = np.zeros((num_features,d))

    def clear(self):
        self.dW[:] = 0

    def set_update(self,ix,update):
        u,v_pos,v_neg,dU,dV_pos,dV_neg,dW = update
        WARPBatchUpdate.set_update(self,ix,(u,v_pos,v_neg,dU,dV_pos,dV_neg))
        self.dW += dW

class WARP2Decomposition(WARPDecomposition):
    """
    Joint matrix and feature embedding optimizing the WARP loss.

    Parameters
    ==========
    num_rows : int
        Number of rows in the full matrix.
    num_cols : int
        Number of columns in the full matrix.
    X : array_like, shape = [num_cols, num_features]
        Features describing each column in the matrix.
    d : int
        The embedding dimension.
    """

    def __init__(self,num_rows,num_cols,X,d):
        WARPDecomposition.__init__(self,num_rows,num_cols,d)
        # W holds latent factors for each item feature
        self.W = d**-0.5*np.random.random_sample((X.shape[1],d))
        self.X = X
        self.is_sparse = isinstance(X,scipy.sparse.csr_matrix)

    def compute_gradient_step(self,u,i,j,L):
        """
        Compute a gradient step from results of sampling.

        Parameters
        ==========
        u : int
            The sampled row.
        i : int
            The sampled positive column.
        j : int
            The sampled violating negative column i.e. U[u].V[j] is currently
            too large compared to U[u].V[i]
        L : int
            The number of trials required to find a violating negative column.

        Returns
        =======
        u : int
            As input.
        i : int
            As input.
        j : int
            As input.
        dU : numpy.ndarray
            Gradient step for U[u].
        dV_pos : numpy.ndarray
            Gradient step for V[i].
        dV_neg : numpy.ndarray
            Gradient step for V[j].
        dW : numpy.ndarray
            Gradient step for W.
        """
        dU = L*(self.V[i]-self.V[j])
        dV_pos = L*self.U[u]
        dV_neg = -L*self.U[u]
        dx = self.X[i]-self.X[j]
        if not self.is_sparse:
            dx = np.atleast_2d(dx)
        dW = L*dx.T.dot(np.atleast_2d(self.U[u]))
        return u,i,j,dU,dV_pos,dV_neg,dW

    def apply_updates(self,updates,gamma,C):
        WARPDecomposition.apply_updates(self,updates,gamma,C)
        self.apply_matrix_update(self.W,updates.dW,gamma,C)

    def apply_matrix_update(self,W,dW,gamma,C):
        W += gamma*dW
        # ensure that ||W_k|| < C for all k
        p = np.sum(np.abs(W)**2,axis=-1)**0.5/C
        p[p<1] = 1
        W /= p[:,np.newaxis]

    def reconstruct(self,rows):
        if rows is None:
            U = self.U
        else:
            U = np.asfortranarray(self.U[rows,:])
        return U.dot(self.V.T + self.X.dot(self.W).T)

class WARP2(WARP):
    """
    Learn low-dimensional embedding optimizing the WARP loss.

    Parameters
    ==========
    d : int
        Embedding dimension.
    gamma : float
        Learning rate.
    C : float
        Regularization constant.
    max_iters : int
        Maximum number of SGD updates.
    validation_iters : int
        Number of SGD updates between checks for stopping condition.
    batch_size : int
        Mini batch size for SGD updates.
    positive_thresh: float
        Training entries below this are treated as zero.
    max_trials : int
        Number of attempts allowed to find a violating negative example during
        training updates. This means that in practice we optimize for ranks 1
        to max_trials-1.

    Attributes
    ==========
    U_ : numpy.ndarray
        Row factors.
    V_ : numpy.ndarray
        Column factors.
    W_ : numpy.ndarray
        Item feature factors.
    """

    def fit(self,train,X,validation=None):
        """
        Learn embedding from training set. A suitable dot product of the
        factors reconstructs the training matrix approximately, minimizing
        the WARP ranking loss relative to the original data.

        Parameters
        ==========
        train : scipy.sparse.csr_matrix
            Training matrix to be factorized.
        X : array_like, shape = [num_cols, num_features]
            Item features.
        validation : dict or int
            Validation set to control early stopping, based on precision@30.
            The dict should have the form row->[cols] where the values in cols
            are those we expected to be highly ranked in the reconstruction of
            row. If an int is supplied then instead we evaluate precision
            against the training data for the first validation rows.

        Returns
        =======
        self : object
            This model itself.
        """
        num_rows,num_cols = train.shape
        decomposition = WARP2Decomposition(num_rows,num_cols,X,self.d)
        updates = WARP2BatchUpdate(self.batch_size,X.shape[1],self.d)
        self.precompute_warp_loss(num_cols)

        self._fit(decomposition,updates,train,validation)

        self.U_ = decomposition.U
        self.V_ = decomposition.V
        self.W_ = decomposition.W

        return self

    def sample(self,train,decomposition):
        # delegate to cython implementation
        return warp2_sample(decomposition.U,
                            decomposition.V,
                            decomposition.W,
                            decomposition.X,
                            train.data,
                            train.indices,
                            train.indptr,
                            self.positive_thresh,
                            self.max_trials)


########NEW FILE########
__FILENAME__ = recommender
"""
Base class for recommenders that work
by matrix factorization.
"""

try:
    import cPickle as pickle
except ImportError:
    import pickle
import numpy as np
from itertools import izip
from scipy.sparse import csr_matrix

from mrec.base_recommender import BaseRecommender

class MatrixFactorizationRecommender(BaseRecommender):
    """
    Base class for matrix factorization recommenders.
    """

    def _create_archive(self):
        """
        Return fields to be serialized in a numpy archive.

        Returns
        =======
        archive : dict
            Fields to serialize, includes the model itself
            under the key 'model'.
        """
        # pickle the model without its factors
        # then use numpy to save the factors efficiently
        tmp = (self.U,self.V)
        self.U = self.V = None
        m = pickle.dumps(self)
        self.U,self.V = tmp
        return {'model':m,'U':self.U,'V':self.V}

    def _load_archive(self,archive):
        """
        Load fields from a numpy archive.
        """
        self.U = archive['U']
        self.V = archive['V']

    def __str__(self):
        if hasattr(self,'description'):
            return self.description
        return 'MatrixFactorizationRecommender'

    def fit(self,train):
        """
        Learn user and item factors from training dataset.

        Parameters
        ==========
        train : scipy sparse matrix
          The user-item matrix.
        """
        pass

    def load_factors(self,user_factor_filepath,item_factor_filepath,fmt):
        """
        Load precomputed user and item factors from file.

        Parameters
        ==========
        user_factor_filepath : str
            Filepath to tsv file holding externally computed user factors. Can be
            TSV, Matrix Market or numpy array serialized with numpy.save().
        item_factor_filepath : str
            Filepath to TSV file holding externally computed item factors. Can be
            TSV, Matrix Market or numpy array serialized with numpy.save().
        fmt : str: npy, mm or tsv
            File format: numpy array, Matrix Market or TSV.  Each line of TSV input
            should contain all of the factors for a single user or item.
        """
        if fmt == 'npy':
            self.U = np.load(user_factor_filepath)
            self.V = np.load(item_factor_filepath)
        elif fmt == 'mm':
            self.U = mmread(user_factor_filepath)
            self.V = mmread(item_factor_filepath)
        elif fmt == 'tsv':
            self.U = np.loadtxt(user_factor_filepath)
            self.V = np.loadtxt(item_factor_filepath)
        else:
            raise ValueError('unknown input format {0}'.format(fmt))
        # ensure that memory layout avoids extra allocation in dot product
        self.U = np.asfortranarray(self.U)

    def recommend_items(self,dataset,u,max_items=10,return_scores=True,item_features=None):
        """
        Recommend up to max_items most highly recommended items for user u.
        Assumes you've already called fit() to learn the factors.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        u : int
            Index of user for which to make recommendations.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        item_features : array_like, shape = [num_items, num_features]
            Features for each item in the dataset.

        Returns
        =======
        recs : list
            List of (idx,score) pairs if return_scores is True, else
            just a list of idxs.
        """
        r = self.predict_ratings(u,item_features=item_features)
        return self._get_recommendations_from_predictions(r,dataset,u,u+1,max_items,return_scores)[0]

    def predict_ratings(self,users=None,item_features=None):
        """
        Predict ratings/scores for all items for supplied users.
        Assumes you've already called fit() to learn the factors.

        Only call this if you really want predictions for all items.
        To get the top-k recommended items for each user you should
        call one of the recommend_items() instead.

        Parameters
        ==========
        users : int or array-like
            Index or indices of users for which to make predictions.
        item_features : array_like, shape = [num_items, num_features]
            Features for each item in the dataset, ignored here.

        Returns
        =======
        predictions : numpy.ndarray, shape = [len(users), num_items]
            Predicted ratings for all items for each supplied user.
        """
        if isinstance(users,int):
            users = [users]

        if users is None:
            U = self.U
        else:
            U = np.asfortranarray(self.U[users,:])
        return U.dot(self.V.T)

    def batch_recommend_items(self,
                              dataset,
                              max_items=10,
                              return_scores=True,
                              show_progress=False,
                              item_features=None):
        """
        Recommend new items for all users in the training dataset.  Assumes
        you've already called fit() to learn the similarity matrix.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        show_progress: bool
            If true print something to stdout to show progress.
        item_features : array_like, shape = [num_items, num_features]
            Features for each item in the dataset.

        Returns
        =======
        recs : list of lists
            Each entry is a list of (idx,score) pairs if return_scores is True,
            else just a list of idxs.
        """
        r = self.predict_ratings(item_features=item_features)
        return self._get_recommendations_from_predictions(r,dataset,0,r.shape[0],max_items,return_scores,show_progress)

    def range_recommend_items(self,
                              dataset,
                              user_start,
                              user_end,
                              max_items=10,
                              return_scores=True,
                              item_features=None):
        """
        Recommend new items for a range of users in the training dataset.
        Assumes you've already called fit() to learn the similarity matrix.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        user_start : int
            Index of first user in the range to recommend.
        user_end : int
            Index one beyond last user in the range to recommend.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        item_features : array_like, shape = [num_items, num_features]
            Features for each item in the dataset.

        Returns
        =======
        recs : list of lists
            Each entry is a list of (idx,score) pairs if return_scores is True,
            else just a list of idxs.
        """
        r = self.predict_ratings(xrange(user_start,user_end),item_features=item_features)
        return self._get_recommendations_from_predictions(r,dataset,user_start,user_end,max_items,return_scores)

    def _get_recommendations_from_predictions(self,
                                              r,
                                              dataset,
                                              user_start,
                                              user_end,
                                              max_items,
                                              return_scores=True,
                                              show_progress=False):
        """
        Select recommendations given predicted scores/ratings.

        Parameters
        ==========
        r : numpy.ndarray
            Predicted scores/ratings for all items for users in supplied range.
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        user_start : int
            Index of first user in the range to recommend.
        user_end : int
            Index one beyond last user in the range to recommend.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        show_progress: bool
            If true print something to stdout to show progress.

        Returns
        =======
        recs : list of lists
            Each entry is a list of (idx,score) pairs if return_scores is True,
            else just a list of idxs.
        """
        r = np.array(self._zero_known_item_scores(r,dataset[user_start:user_end,:]))
        recs = [[] for u in xrange(user_start,user_end)]
        for u in xrange(user_start,user_end):
            ux = u - user_start
            if show_progress and ux%1000 == 0:
               print ux,'..',
            ru = r[ux]
            if return_scores:
                recs[ux] = [(i,ru[i]) for i in ru.argsort()[::-1] if ru[i] > 0][:max_items]
            else:
                recs[ux] = [i for i in ru.argsort()[::-1] if ru[i] > 0][:max_items]
        if show_progress:
            print
        return recs

########NEW FILE########
__FILENAME__ = warp
import numpy as np
import random

from mrec.evaluation import metrics

from recommender import MatrixFactorizationRecommender
from model.warp import WARP

class WARPMFRecommender(MatrixFactorizationRecommender):
    """
    Learn matrix factorization optimizing the WARP loss.

    Parameters
    ==========
    d : int
        Dimensionality of factors.
    gamma : float
        Learning rate.
    C : float
        Regularization constant.
    batch_size : int
        Mini batch size for SGD updates.
    positive_thresh: float
        Consider an item to be "positive" i.e. liked if its rating is at least this.
    max_trials : int
        Number of attempts allowed to find a violating negative example during updates.
        In practice it means that we optimize for ranks 1 to max_trials-1.
    """

    def __init__(self,d,gamma,C,batch_size=10,positive_thresh=0.00001,max_trials=50):
        self.d = d
        self.gamma = gamma
        self.C = C
        self.batch_size = batch_size
        self.positive_thresh = positive_thresh
        self.max_trials = max_trials

    def fit(self,train,item_features=None):
        """
        Learn factors from training set.

        Parameters
        ==========
        train : scipy.sparse.csr_matrix
            User-item matrix.
        item_features : array_like, shape = [num_items, num_features]
            Features for each item in the dataset, ignored here.
        """
        max_iters,validation_iters,validation = self.create_validation_set(train)
        model = WARP(self.d,self.gamma,self.C,max_iters,validation_iters,self.batch_size,self.positive_thresh,self.max_trials)
        self.description = 'WARPMF({0})'.format(model)
        model.fit(train,validation)

        self.U = model.U_
        self.V = model.V_

    def create_validation_set(self,train):
        """
        Hide and return half of the known items for a sample of users,
        and estimate the number of sgd iterations to run.

        Parameters
        ==========
        train : scipy.sparse.csr_matrix
            User-item matrix.

        Returns
        =======
        max_iters : int
            Total number of sgd iterations to run.
        validation_iters : int
            Check progress after this many iterations.
        validation : dict
            Validation set.
        """
        # use 1% of users for validation, with a floor
        num_users = train.shape[0]
        num_validation_users = max(num_users/100,100)
        # ensure reasonable expected number of updates per validation user
        validation_iters = 100*num_users/num_validation_users
        # and reasonable number of validation cycles
        max_iters = 30*validation_iters

        print num_validation_users,'validation users'
        print validation_iters,'validation iters'
        print max_iters,'max_iters'

        validation = dict()
        for u in xrange(num_validation_users):
            positive = np.where(train[u].data > 0)[0]
            hidden = random.sample(positive,positive.shape[0]/2)
            if hidden:
                train[u].data[hidden] = 0
                validation[u] = train[u].indices[hidden]

        return max_iters,validation_iters,validation

def main():
    import sys
    from mrec import load_sparse_matrix, save_recommender
    from mrec.sparse import fast_sparse_matrix

    file_format = sys.argv[1]
    filepath = sys.argv[2]
    outfile = sys.argv[3]

    # load training set as scipy sparse matrix
    train = load_sparse_matrix(file_format,filepath)

    model = WARPMFRecommender(d=100,gamma=0.01,C=100.0,batch_size=10)
    model.fit(train)

    save_recommender(model,outfile)

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = warp2
import numpy as np

from warp import WARPMFRecommender
from model.warp2 import WARP2

class WARP2MFRecommender(WARPMFRecommender):
    """
    Learn matrix factorization optimizing the WARP loss
    with item features as well as user-item training data.

    Parameters
    ==========
    d : int
        Dimensionality of factors.
    gamma : float
        Learning rate.
    C : float
        Regularization constant.
    batch_size : int
        Mini batch size for SGD updates.
    positive_thresh: float
        Consider an item to be "positive" i.e. liked if its rating is at least this.
    max_trials : int
        Number of attempts allowed to find a violating negative example during updates.
        In practice it means that we optimize for ranks 1 to max_trials-1.
    """

    def __str__(self):
        return 'WARP2MF(d={0},gamma={1},C={2})'.format(self.d,self.gamma,self.C)

    def fit(self,train,item_features=None):
        """
        Learn factors from training set and item features.

        Parameters
        ==========
        train : scipy.sparse.csr_matrix
            User-item matrix.
        item_features : array_like, shape = [num_items, num_features]
            Features for each item in the dataset.
        """
        max_iters,validation_iters,validation = self.create_validation_set(train)
        model = WARP2(self.d,self.gamma,self.C,max_iters,validation_iters,self.batch_size,self.positive_thresh,self.max_trials)
        self.description = 'WARP2MF({0})'.format(model)
        model.fit(train,item_features,validation)

        self.U = model.U_
        self.V = model.V_
        self.W = model.W_

    def predict_ratings(self,users=None,item_features=None):
        """
        Predict ratings/scores for all items for supplied users.
        Assumes you've already called fit() to learn the factors.

        Only call this if you really want predictions for all items.
        To get the top-k recommended items for each user you should
        call one of the recommend_items() instead.

        Parameters
        ==========
        users : int or array-like
            Index or indices of users for which to make predictions.
        item_features : array_like, shape = [num_items, num_features]
            Features for each item in the dataset.

        Returns
        =======
        predictions : numpy.ndarray, shape = [len(users), num_items]
            Predicted ratings for all items for each supplied user.
        """
        if isinstance(users,int):
            users = [users]

        if users is None:
            U = self.U
        else:
            U = np.asfortranarray(self.U[users,:])
        return U.dot(self.V.T + item_features.dot(self.W).T)

def main(file_format,filepath,feature_format,feature_file,outfile):
    from mrec import load_sparse_matrix, save_recommender
    from mrec.sparse import fast_sparse_matrix

    # load training set
    train = load_sparse_matrix(file_format,filepath)
    # load item features, assume they are tsv: item_id,feature_id,val
    X = load_sparse_matrix(feature_format,feature_file).toarray()
    # strip features for any trailing items that don't appear in training set
    num_items = train.shape[1]
    X = X[:num_items,:]

    model = WARP2MFRecommender(d=100,gamma=0.01,C=100.0,batch_size=10)
    model.fit(train,X)

    save_recommender(model,outfile)

if __name__ == '__main__':
    import sys
    file_format = sys.argv[1]
    filepath = sys.argv[2]
    feature_format = sys.argv[3]
    feature_file = sys.argv[4]
    outfile = sys.argv[5]

    main(file_format,filepath,feature_format,feature_file,outfile)

########NEW FILE########
__FILENAME__ = wrmf
"""
Weighted Regularize Matrix Factorization by alternating least squares.

See:
Y. Hu, Y. Koren and C. Volinsky, Collaborative filtering for implicit feedback datasets, ICDM 2008.
http://research.yahoo.net/files/HuKorenVolinsky-ICDM08.pdf
R. Pan et al., One-class collaborative filtering, ICDM 2008.
http://www.hpl.hp.com/techreports/2008/HPL-2008-48R1.pdf
"""

import numpy as np
from scipy.sparse import csr_matrix

from mrec.sparse import fast_sparse_matrix
from mrec.mf.recommender import MatrixFactorizationRecommender

class WRMFRecommender(MatrixFactorizationRecommender):
    """
    Parameters
    ==========
    d : int
        Number of latent factors.
    alpha : float
        Confidence weight, confidence c = 1 + alpha*r where r is the observed "rating".
    lbda : float
        Regularization constant.
    num_iters : int
        Number of iterations of alternating least squares.
    """

    def __init__(self,d,alpha=1,lbda=0.015,num_iters=15):
        self.d = d
        self.alpha = alpha
        self.lbda = lbda
        self.num_iters = num_iters

    def __str__(self):
        return 'WRMFRecommender (d={0},alpha={1},lambda={2},num_iters={3})'.format(self.d,self.alpha,self.lbda,self.num_iters)

    def init_factors(self,num_factors,assign_values=True):
        if assign_values:
            return self.d**-0.5*np.random.random_sample((num_factors,self.d))
        return np.empty((num_factors,self.d))

    def fit(self,train,item_features=None):
        """
        Learn factors from training set. User and item factors are
        fitted alternately.

        Parameters
        ==========
        train : scipy.sparse.csr_matrix or mrec.sparse.fast_sparse_matrix
            User-item matrix.
        item_features : array_like, shape = [num_items, num_features]
            Features for each item in the dataset, ignored here.
        """
        if type(train) == csr_matrix:
            train = fast_sparse_matrix(train)

        num_users,num_items = train.shape

        self.U = self.init_factors(num_users,False)  # don't need values, will compute them
        self.V = self.init_factors(num_items)
        for it in xrange(self.num_iters):
            print 'iteration',it
            # fit user factors
            VV = self.V.T.dot(self.V)
            for u in xrange(num_users):
                # get (positive i.e. non-zero scored) items for user
                indices = train.X[u].nonzero()[1]
                if indices.size:
                    self.U[u,:] = self.update(indices,self.V,VV)
                else:
                    self.U[u,:] = np.zeros(self.d)
            # fit item factors
            UU = self.U.T.dot(self.U)
            for i in xrange(num_items):
                indices = train.fast_get_col(i).nonzero()[0]
                if indices.size:
                    self.V[i,:] = self.update(indices,self.U,UU)
                else:
                    self.V[i,:] = np.zeros(self.d)

    def update(self,indices,H,HH):
        """
        Update latent factors for a single user or item.
        """
        Hix = H[indices,:]
        M = HH + self.alpha*Hix.T.dot(Hix) + np.diag(self.lbda*np.ones(self.d))
        return np.dot(np.linalg.inv(M),(1+self.alpha)*Hix.sum(axis=0))

def main():
    import sys
    from mrec import load_sparse_matrix, save_recommender
    from mrec.sparse import fast_sparse_matrix
    from mrec.mf.wrmf import WRMFRecommender

    file_format = sys.argv[1]
    filepath = sys.argv[2]
    outfile = sys.argv[3]

    # load training set as scipy sparse matrix
    train = load_sparse_matrix(file_format,filepath)

    model = WRMFRecommender(d=5)
    model.fit(train)

    save_recommender(model,outfile)

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = evaluate
"""
Evaluation task to run on an ipython engine.
"""

def run(task):

    # import modules required by engine
    import numpy as np
    from scipy.sparse import coo_matrix
    from collections import defaultdict

    from mrec import load_sparse_matrix

    input_format,testfile,recsfile,start,end,evaluator = task

    # load the test data
    testdata = load_sparse_matrix(input_format,testfile)

    return evaluator.process(testdata,recsfile,start,end)

########NEW FILE########
__FILENAME__ = item_similarity
import math
import glob
import re
import os
import subprocess
from shutil import rmtree
import logging

from mrec import load_sparse_matrix, save_recommender

class ItemSimilarityRunner(object):

    def run(self,view,model,input_format,trainfile,num_engines,simsdir,overwrite,max_sims,simsfile,modelfile):

        logging.info('finding number of items...')
        dataset = load_sparse_matrix(input_format,trainfile)
        num_users,num_items = dataset.shape
        del dataset
        logging.info('%d users and %d items', num_users, num_items)

        logging.info('creating sims directory {0}...'.format(simsdir))
        subprocess.check_call(['mkdir','-p',simsdir])

        done = []
        if not overwrite:
            logging.info('checking for existing output sims...')
            done.extend(self.find_done(simsdir))
            if done:
                logging.info('found {0} output files'.format(len(done)))

        logging.info('creating tasks...')
        tasks = self.create_tasks(model,input_format,trainfile,simsdir,num_items,num_engines,max_sims,done)

        if num_engines > 0:
            logging.info('running %d tasks in parallel across ipython'
                         ' engines...', len(tasks))
            async_job = view.map_async(process,tasks,retries=2)
            # wait for tasks to complete
            results = async_job.get()
        else:
            # Sequential run to make it easier for debugging
            logging.info('training similarity model sequentially')
            results = [process(task) for task in tasks]

        logging.info('checking output files...')
        done = self.find_done(simsdir)
        remaining = len(tasks) - len(done)
        if remaining == 0:
            logging.info('SUCCESS: all tasks completed')
            logging.info('concatenating {0} partial output files...'.format(len(done)))
            paths = [os.path.join(simsdir,'sims.{0}-{1}.tsv'.format(start,end)) for start,end in done]
            cmd = ['cat']+paths
            subprocess.check_call(cmd,stdout=open(simsfile,'w'))
            logging.info('removing partial output files...')
            rmtree(simsdir)
            logging.info('loading %d items in %s model from %s',
                         num_items, type(model).__name__, simsfile)
            model.load_similarity_matrix(simsfile,num_items)
            save_recommender(model,modelfile)
            logging.info('done')
        else:
            logging.error('FAILED: {0}/{1} tasks did not complete successfully'.format(remaining,len(tasks)))
            logging.error('try rerunning the command to retry the remaining tasks')

    def find_done(self,outdir):
        success_files = glob.glob(os.path.join(outdir,'*.SUCCESS'))
        r = re.compile('.*?([0-9]+)-([0-9]+)\.SUCCESS$')
        done = []
        for path in success_files:
            m = r.match(path)
            start = int(m.group(1))
            end = int(m.group(2))
            done.append((start,end))
        return done

    def create_tasks(self,model,input_format,trainfile,outdir,num_items,num_engines,max_similar_items,done):
        if num_engines == 0:
            # special marker for sequential run
            num_engines = 1
        items_per_engine = int(math.ceil(float(num_items)/num_engines))
        tasks = []
        for start in xrange(0,num_items,items_per_engine):
            end = min(num_items,start+items_per_engine)
            if (start,end) not in done:
                tasks.append((model,input_format,trainfile,outdir,start,end,max_similar_items))
        return tasks

def process(task):
    """
    Training task to run on an ipython engine.
    """

    # import modules required by engine
    import os
    import subprocess
    from mrec import load_fast_sparse_matrix

    model,input_format,trainfile,outdir,start,end,max_similar_items = task

    # initialise the model
    dataset = load_fast_sparse_matrix(input_format,trainfile)
    if hasattr(model,'similarity_matrix'):
        # clear out any existing similarity matrix to trigger recomputation of
        # the item-item similarities from the users' ratings.
        model.similarity_matrix = None

    # write sims directly to file as we compute them
    outfile = os.path.join(outdir,'sims.{0}-{1}.tsv'.format(start,end))
    out = open(outfile,'w')
    for j in xrange(start,end):
        w = model.get_similar_items(j,max_similar_items=max_similar_items,dataset=dataset)
        for k,v in w:
            print >>out,'{0}\t{1}\t{2}'.format(j+1,k+1,v)  # write as 1-indexed
    out.close()

    # record success
    cmd = ['touch',os.path.join(outdir,'{0}-{1}.SUCCESS'.format(start,end))]
    subprocess.check_call(cmd)

    # return the range that we've processed
    return start,end

########NEW FILE########
__FILENAME__ = predict
"""
Prediction task to run on an ipython engine.
"""

def run(task):

    # import modules required by engine
    import os
    import subprocess
    import numpy as np
    from scipy.sparse import coo_matrix

    from mrec import load_sparse_matrix, load_recommender
    from mrec.evaluation import Evaluator

    modelfile,input_format,trainfile,test_input_format,testfile,feature_format,featurefile,outdir,start,end,evaluator,generate = task

    # initialise the model
    model = load_recommender(modelfile)

    outfile = os.path.join(outdir,'recs.{0}-{1}.tsv'.format(start,end))

    if generate:
        # generate recommendations for our batch of users
        dataset = load_sparse_matrix(input_format,trainfile)
        out = open(outfile,'w')
        if featurefile is not None:
            # currently runs much faster if features are loaded as a dense matrix
            item_features = load_sparse_matrix(feature_format,featurefile).toarray()
            # strip features for any trailing items that don't appear in training set
            num_items = dataset.shape[1]
            item_features = item_features[:num_items,:]
            recs = model.range_recommend_items(dataset,start,end,max_items=20,return_scores=True,item_features=item_features)
        else:
            recs = model.range_recommend_items(dataset,start,end,max_items=20,return_scores=True)
        for u,items in zip(xrange(start,end),recs):
            for i,w in items:
                print >>out,'{0}\t{1}\t{2}'.format(u+1,i+1,w)  # write as 1-indexed
        out.close()

        # record success
        cmd = ['touch',os.path.join(outdir,'{0}-{1}.SUCCESS'.format(start,end))]
        subprocess.check_call(cmd)

    # load the test data
    testdata = load_sparse_matrix(test_input_format,testfile).tocsr()

    # return evaluation metrics
    return evaluator.process(testdata,outfile,start,end)

########NEW FILE########
__FILENAME__ = warp
import glob
import re
import os
import subprocess
from shutil import rmtree
import logging
import numpy as np

from mrec import save_recommender, load_recommender

class WARPMFRunner(object):

    def run(self,
            view,
            model,
            input_format,
            trainfile,
            feature_format,
            featurefile,
            num_engines,
            workdir,
            overwrite,
            modelfile):

        logging.info('creating models directory {0}...'.format(workdir))
        subprocess.check_call(['mkdir','-p',workdir])

        done = []
        if not overwrite:
            logging.info('checking for existing output models...')
            done.extend(self.find_done(workdir))
            if done:
                logging.info('found {0} output files'.format(len(done)))

        logging.info('creating tasks...')
        tasks = self.create_tasks(model,
                                  input_format,
                                  trainfile,
                                  feature_format,
                                  featurefile,
                                  workdir,
                                  num_engines,
                                  done)

        if tasks:
            logging.info('running in parallel across ipython engines...')
            async_job = view.map_async(process,tasks,retries=2)

            # wait for tasks to complete
            results = async_job.get()

            logging.info('checking output files...')
            done = self.find_done(workdir)
            remaining = len(tasks) - len(done)
        else:
            remaining = 0

        if remaining == 0:
            logging.info('SUCCESS: all tasks completed')
            logging.info('concatenating {0} models...'.format(len(done)))
            for ix in sorted(done):
                partial_model = load_recommender(self.get_modelfile(ix,workdir))
                if ix == 0:
                    model = partial_model
                else:
                    # concatenate factors
                    model.d += partial_model.d
                    model.U = np.hstack((model.U,partial_model.U))
                    model.V = np.hstack((model.V,partial_model.V))
                    if hasattr(model,'W'):
                        model.W = np.hstack((model.W,partial_model.W))
            save_recommender(model,modelfile)
            logging.info('removing partial output files...')
            rmtree(workdir)
            logging.info('done')
        else:
            logging.error('FAILED: {0}/{1} tasks did not complete successfully'.format(remaining,len(tasks)))
            logging.error('try rerunning the command to retry the remaining tasks')

    def create_tasks(self,
                     model,
                     input_format,
                     trainfile,
                     feature_format,
                     featurefile,
                     outdir,
                     num_engines,
                     done):
        tasks = []
        for ix in xrange(num_engines):
            if ix not in done:
                outfile = self.get_modelfile(ix,outdir)
                tasks.append((model,input_format,trainfile,feature_format,featurefile,outfile,ix,num_engines))
        return tasks

    def find_done(self,outdir):
        success_files = glob.glob(os.path.join(outdir,'*.SUCCESS'))
        r = re.compile('.*?([0-9]+)\.model\.npz\.SUCCESS$')
        done = []
        for path in success_files:
            m = r.match(path)
            ix = int(m.group(1))
            done.append(ix)
        return done

    def get_modelfile(self,ix,workdir):
        return os.path.join(workdir,'{0}.model.npz'.format(ix))

def process(task):
    """
    Training task to run on an ipython engine.
    """

    # import modules required by engine
    import os
    import subprocess
    from mrec import load_sparse_matrix, save_recommender

    model,input_format,trainfile,feature_format,featurefile,outfile,offset,step = task

    dataset = load_sparse_matrix(input_format,trainfile)
    if featurefile is not None:
        # currently runs much faster if features are loaded as a dense matrix
        item_features = load_sparse_matrix(feature_format,featurefile).toarray()
        # strip features for any trailing items that don't appear in training set
        num_items = dataset.shape[1]
        item_features = item_features[:num_items,:]
        model.fit(dataset,item_features=item_features)
    else:
        model.fit(dataset)
    save_recommender(model,outfile)

    # record success
    cmd = ['touch','{0}.SUCCESS'.format(outfile)]
    subprocess.check_call(cmd)

    # return the offset for the samples that we've learned from
    return offset

########NEW FILE########
__FILENAME__ = wrmf
import glob
import logging
import os
import subprocess
from shutil import rmtree
import math
import numpy as np

from mrec import load_sparse_matrix, save_recommender

def get_user_indices(data,u):
    # get (positive i.e. non-zero scored) items for user
    return data.X[u].nonzero()[1]

def get_item_indices(data,i):
    # get users for item
    return data.fast_get_col(i).nonzero()[0]

def get_factor_files(workdir,factor_type):
    # return partial factor files in sorted order so they can simply be stacked
    factor_files = glob.glob(os.path.join(workdir,'{0}.*.npy'.format(factor_type)))
    return sorted(factor_files,key=lambda x: int(x[:-4][x[:-4].rfind('.')+1:]))

def get_user_factor_files(workdir):
    return get_factor_files(workdir,'U')

def get_item_factor_files(workdir):
    return get_factor_files(workdir,'V')

def init_item_factors(model,data):
    num_users,num_items = data.shape
    return model.init_factors(num_items)

class WRMFRunner(object):

    def run(self,view,model,input_format,trainfile,num_engines,workdir,modelfile):
        logging.info('creating factors directory {0}'.format(workdir))
        subprocess.check_call(['mkdir','-p',workdir])

        logging.info('getting data size')
        data = load_sparse_matrix(input_format,trainfile)
        num_users,num_items = data.shape
        del data

        for it in xrange(model.num_iters):
            logging.info('iteration {0}'.format(it))
            tasks = self.create_tasks(num_users,num_engines,model,input_format,trainfile,workdir,'U',get_user_indices,get_item_factor_files,init_item_factors)
            self.run_tasks(view,tasks)
            tasks = self.create_tasks(num_items,num_engines,model,input_format,trainfile,workdir,'V',get_item_indices,get_user_factor_files,None)  # won't need to initialize user factors
            self.run_tasks(view,tasks)

        model.U = np.vstack([np.load(f) for f in get_user_factor_files(workdir)])
        model.V = np.vstack([np.load(f) for f in get_item_factor_files(workdir)])

        save_recommender(model,modelfile)

        logging.info('removing partial output files')
        rmtree(workdir)
        logging.info('done')

    def run_tasks(self,view,tasks):
        async_job = view.map_async(compute_factors,tasks,retries=2)
        # wait for tasks to complete
        result = async_job.get()

    def create_tasks(self,num_factors,num_engines,model,input_format,trainfile,workdir,factor_type,get_indices,get_fixed_factor_files,init_fixed_factors):
        factors_per_engine = int(math.ceil(float(num_factors)/num_engines))
        tasks = []
        for start in xrange(0,num_factors,factors_per_engine):
            end = min(num_factors,start+factors_per_engine)
            fixed_factor_files = get_fixed_factor_files(workdir)
            tasks.append((model,input_format,trainfile,factor_type,get_indices,init_fixed_factors,fixed_factor_files,start,end,workdir))
        return tasks

def compute_factors(task):
    """
    WRMF update method to run on an IPython engine.
    This reads from file and writes back to file,
    only filepaths and an empty model need to be passed.
    """

    # import modules needed on engine
    import os
    import numpy as np
    from mrec import load_fast_sparse_matrix

    model,input_format,trainfile,factor_type,get_indices,init_fixed_factors,fixed_factor_files,start,end,workdir = task

    data = load_fast_sparse_matrix(input_format,trainfile)

    if fixed_factor_files:
        H = np.vstack([np.load(f) for f in fixed_factor_files])
    else:
        H = init_fixed_factors(model,data)

    HH = H.T.dot(H)
    W = np.zeros(((end-start),model.d))
    for j in xrange(start,end):
        indices = get_indices(data,j)
        if indices.size:
            W[j-start,:] = model.update(indices,H,HH)

    np.save(os.path.join(workdir,'{0}.{1}.npy'.format(factor_type,start)),W)

    return start,end

########NEW FILE########
__FILENAME__ = popularity
"""
Trivial unpersonalized item popularity recommender
intended to provide a baseline for evaluations.
"""

import numpy as np

from base_recommender import BaseRecommender
from sparse import fast_sparse_matrix

class ItemPopularityRecommender(BaseRecommender):
    """
    Create an unpersonalized item popularity recommender, useful
    to provide a baseline for comparison with a "real" one.

    Parameters
    ----------

    method : 'count', 'sum', 'avg' or 'thresh' (default: 'count')
        How to calculate the popularity of an item based on its ratings
        from all users:
        count - popularity is its total number of ratings of any value
        sum - popularity is the sum of its ratings
        avg - popularity is its mean rating
        thresh - popularity is its number of ratings higher than thresh
    thresh : float, optional
        The threshold used by the 'thresh' method of calculating item
        popularity.
    """

    def __init__(self,method='count',thresh=0):
        self.description = 'ItemPop'
        if method not in ['count','sum','avg','thresh']:
            raise ValueError('invalid value for method parameter')
        self.method = method
        self.thresh = thresh

    def fit(self,dataset,item_features=None):
        """
        Compute the most popular items using the method specified
        in the constructor.

        Parameters
        ----------
        dataset : scipy sparse matrix or mrec.sparse.fast_sparse_matrix
            The user-item matrix.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, ignored here.
        """
        if isinstance(dataset,fast_sparse_matrix):
            d = dataset.X.tocsc()
        else:
            d = dataset.tocsc()
        if self.method == 'count':
            # count the total number of ratings for each item
            popularity = [(d[:,i].nnz,i) for i in xrange(d.shape[1])]
        elif self.method == 'sum':
            # find the sum of the ratings for each item
            popularity = [(d[:,i].sum(),i) for i in xrange(d.shape[1])]
        elif self.method == 'avg':
            # find the mean rating for each item
            popularity = [(d[:,i].mean(),i) for i in xrange(d.shape[1])]
        elif self.method == 'thresh':
            # count the number of ratings above thresh for each item
            popularity = [(sum(d[:,i].data>self.thresh),i) for i in xrange(d.shape[1])]
        popularity.sort(reverse=True)
        self.pop_items = [(i,c) for (c,i) in popularity]

    def recommend_items(self,dataset,u,max_items=10,return_scores=True,item_features=None):
        """
        Recommend new items for a user.  Assumes you've already called
        fit().

        Parameters
        ----------
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        u : int
            Index of user for which to make recommendations (for
            compatibility with other recommenders).
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, ignored here.

        Returns
        -------
        recs : list
            List of (idx,score) pairs if return_scores is True, else
            just a list of idxs.
        """
        known_items = set(dataset[u].indices)
        recs = []
        for i,c in self.pop_items:
            if i not in known_items:
                if return_scores:
                    recs.append((i,c))
                else:
                    recs.append(i)
                if len(recs) >= max_items:
                    break
        return recs

    def __str__(self):
        return self.description

########NEW FILE########
__FILENAME__ = reranking_recommender
"""
Recommender that gets candidates using an item similarity model
and then reranks them using a matrix factorization model.
"""

try:
    import cPickle as pickle
except ImportError:
    import pickle
import numpy as np

from base_recommender import BaseRecommender

class RerankingRecommender(BaseRecommender):
    """
    A secondary recommender that combines an item similarity
    model and a matrix factorization one. The item similarity
    model is used to select candidate items for each user which
    are then reranked based on their latent factors.

    Parameters
    ==========
    item_similarity_recommender : mrec.item_similarity.recommender.ItemSimilarityRecommender
        The model used to select candidates.
    mf_recommender : mrec.mf.recommender.MatrixFactorizationRecommender
        The model used to rerank them.
    num_candidates : int (default: 100)
        The number of candidate items drawn from the first model for each user.
    """

    def __init__(self,item_similarity_recommender,mf_recommender,num_candidates=100):
        self.item_similarity_recommender = item_similarity_recommender
        self.mf_recommender = mf_recommender
        self.num_candidates = num_candidates
        self.description = 'RerankingRecommender({0},{1})'.format(self.item_similarity_recommender,self.mf_recommender)

    def _create_archive(self):
        archive = self.item_similarity_recommender._create_archive()
        archive['item_similarity_model'] = archive['model']
        archive.update(self.mf_recommender._create_archive())
        archive['mf_model'] = archive['model']
        tmp = self.item_similarity_recommender,self.mf_recommender
        self.item_similarity_model = self.mf_recommender = None
        m = pickle.dumps(self)
        self.item_similarity_model,self.mf_recommender = tmp
        archive['model'] = m
        return archive

    def _load_archive(self,archive):
        self.item_similarity_recommender = np.loads(str(archive['item_similarity_model']))
        self.item_similarity_recommender._load_archive(archive)
        self.mf_recommender = np.loads(str(archive['mf_model']))
        self.mf_recommender._load_archive(archive)

    def fit(self,train,item_features=None):
        """
        Fit both models to the training data.

        Parameters
        ==========
        train : scipy.sparse.csr_matrix, shape = [num_users, num_items]
            The training user-item matrix.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, required by some recommenders.

        Notes
        =====
        You are not obliged to call this, alternatively you can pass
        ready trained models to the RerankingRecommender constructor.
        """
        self.item_similarity_recommender.fit(train,item_features)
        self.mf_recommender.fit(train,item_features)

    def rerank(self,u,candidates,max_items,return_scores):
        """
        Use latent factors to rerank candidate recommended items for a user
        and return the highest scoring.

        Parameters
        ==========
        u : int
            Index of user for which to make recommendations.
        candidates : array like
            List of candidate item indices.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.

        Returns
        =======
        recs : list
            List of (idx,score) pairs if return_scores is True, else
            just a list of idxs.
        """
        r = self.mf_recommender.U[u].dot(self.mf_recommender.V[candidates].T)
        reranked = r.argsort()[:-1-max_items:-1]
        if return_scores:
            recs = [(candidates[i],r[i]) for i in reranked]
        else:
            recs = [candidates[i] for i in reranked]
        return recs

    def recommend_items(self,dataset,u,max_items=10,return_scores=True,item_features=None):
        """
        Recommend new items for a user.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        u : int
            Index of user for which to make recommendations.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, required by some recommenders.

        Returns
        =======
        recs : list
            List of (idx,score) pairs if return_scores is True, else
            just a list of idxs.
        """
        candidates = self.item_similarity_recommender.recommend_items(dataset,u,self.num_candidates,return_scores=False)
        return self.rerank(u,candidates,max_items,return_scores=return_scores)

    def batch_recommend_items(self,
                              dataset,
                              max_items=10,
                              return_scores=True,
                              item_features=None):
        """
        Recommend new items for all users in the training dataset.  Assumes
        you've already called fit() to learn the similarity matrix.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        show_progress: bool
            If true print something to stdout to show progress.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, required by some recommenders.

        Returns
        =======
        recs : list of lists
            Each entry is a list of (idx,score) pairs if return_scores is True,
            else just a list of idxs.
        """
        recs = self.item_similarity_recommender.batch_recommend_items(dataset,self.num_candidates,return_scores=False,item_features=item_features)
        for u,candidates in enumerate(recs):
            recs[u] = self.rerank(u,candidates,max_items,return_scores=return_scores)
        return recs

    def range_recommend_items(self,
                              dataset,
                              user_start,
                              user_end,
                              max_items=10,
                              return_scores=True,
                              item_features=None):
        """
        Recommend new items for a range of users in the training dataset.
        Assumes you've already called fit() to learn the similarity matrix.

        Parameters
        ==========
        dataset : scipy.sparse.csr_matrix
            User-item matrix containing known items.
        user_start : int
            Index of first user in the range to recommend.
        user_end : int
            Index one beyond last user in the range to recommend.
        max_items : int
            Maximum number of recommended items to return.
        return_scores : bool
            If true return a score along with each recommended item.
        item_features : array_like, shape = [num_items, num_features]
            Features for items in training set, required by some recommenders.

        Returns
        =======
        recs : list of lists
            Each entry is a list of (idx,score) pairs if return_scores is True,
            else just a list of idxs.
        """
        recs = self.item_similarity_recommender.range_recommend_items(dataset,user_start,user_end,self.num_candidates,return_scores=False,item_features=item_features)
        for u,candidates in enumerate(recs):
            recs[u] = self.rerank(user_start+u,candidates,max_items,return_scores=return_scores)
        return recs

def main():
    import sys
    from mrec import load_sparse_matrix, save_recommender
    from mrec.sparse import fast_sparse_matrix
    from mrec.item_similarity.knn import CosineKNNRecommender
    from mrec.mf.warp import WARPMFRecommender
    from mrec.reranking_recommender import RerankingRecommender

    file_format = sys.argv[1]
    filepath = sys.argv[2]
    outfile = sys.argv[3]

    # load training set as scipy sparse matrix
    train = load_sparse_matrix(file_format,filepath)

    item_sim_model = CosineKNNRecommender(k=100)
    mf_model = WARPMFRecommender(d=80,gamma=0.01,C=100.0,max_iters=25000,validation_iters=1000,batch_size=10)
    recommender = RerankingRecommender(item_sim_model,mf_model,num_candidates=100)

    recommender.fit(train)

    save_recommender(recommender,outfile)

if __name__ == '__main__':
    main()


########NEW FILE########
__FILENAME__ = sparse
"""
Sparse data structures and convenience methods to load sparse matrices from file.
"""

import random
import numpy as np
from scipy.sparse import csr_matrix, coo_matrix
from scipy.io import mmread

def loadtxt(filepath,comments='#',delimiter=None,skiprows=0,usecols=None,index_offset=1):
    """
    Load a scipy sparse matrix from simply formatted data such as TSV, handles
    similar input to numpy.loadtxt().

    Parameters
    ----------
    filepath : file or str
        File containing simply formatted row,col,val sparse matrix data.
    comments : str, optional
        The character used to indicate the start of a comment (default: #).
    delimiter : str, optional
        The string used to separate values. By default, this is any whitespace.
    skiprows : int, optional
        Skip the first skiprows lines; default: 0.
    usecols : sequence, optional
        Which columns to read, with 0 being the first. For example, usecols = (1,4,5)
        will extract the 2nd, 5th and 6th columns. The default, None, results in all
        columns being read.
    index_offset : int, optional
        Offset applied to the row and col indices in the input data (default: 1).
        The default offset is chosen so that 1-indexed data on file results in a
        fast_sparse_matrix holding 0-indexed matrices.

    Returns
    -------
    mat : scipy.sparse.csr_matrix
        The sparse matrix.
    """
    d = np.loadtxt(filepath,comments=comments,delimiter=delimiter,skiprows=skiprows,usecols=usecols)
    if d.shape[1] < 3:
        raise ValueError('invalid number of columns in input')
    row = d[:,0]-index_offset
    col = d[:,1]-index_offset
    data = d[:,2]
    shape = (max(row)+1,max(col)+1)
    return csr_matrix((data,(row,col)),shape=shape)

def savez(d,file):
    """
    Save a sparse matrix to file in numpy binary format.

    Parameters
    ----------
    d : scipy.sparse.coo_matrix
        The sparse matrix to save.
    file : str or file
        Either the file name (string) or an open file (file-like object)
        where the matrix will be saved. If file is a string, the ``.npz``
        extension will be appended to the file name if it is not already there.
    """
    np.savez(file,row=d.row,col=d.col,data=d.data,shape=d.shape)

def loadz(file):
    """
    Load a sparse matrix saved to file with savez.

    Parameters
    ----------
    file : str
        The open file or filepath to read from.

    Returns
    -------
    mat : scipy.sparse.coo_matrix
        The sparse matrix.
    """
    y = np.load(file)
    return coo_matrix((y['data'],(y['row'],y['col'])),shape=y['shape'])

class fast_sparse_matrix(object):
    """
    Adds fast columnar reads and updates to
    a scipy.sparse.csr_matrix, at the cost
    of keeping a csc_matrix of equal size as
    a column-wise index into the same raw data.
    It is updateable in the sense that you can
    change the values of all the existing non-
    zero entries in a given column.  Trying to
    set other entries will result in an error.

    For other functionality you are expected to
    call methods on the underlying csr_matrix:

    >>> fsm = fast_sparse_matrix(data) # data is a csr_matrix
    >>> col = fsm.fast_get_col(2)      # get a column quickly
    >>> row = fsm.X[1]                 # get a row as usual
    """
    def __init__(self,X,col_view=None):
        """
        Create a fast_sparse_matrix from a csr_matrix X. Note
        that X is not copied and its values will be modified by
        any subsequent call to fast_update_col().

        Parameters
        ----------

        X : scipy sparse matrix
            The sparse matrix to wrap.
        col_view : scipy.csc_matrix, optional
            The corresponding index matrix to provide fast columnar access,
            created if not supplied here.
        """
        self.X = X.tocsr()
        if col_view is not None:
            self.col_view = col_view
        else:
            # create the columnar index matrix
            ind = self.X.copy()
            ind.data = np.arange(self.X.nnz)
            self.col_view = ind.tocsc()

    @property
    def shape(self):
        """
        Return the shape of the underlying matrix.
        """
        return self.X.shape

    def fast_get_col(self,j):
        """
        Return column j of the underlying matrix.

        Parameters
        ----------
        j : int
            Index of column to get.

        Returns
        -------
        col : scipy.sparse.csc_matrix
            Copy of column j of the matrix.
        """
        col = self.col_view[:,j].copy()
        col.data = self.X.data[col.data]
        return col

    def fast_update_col(self,j,vals):
        """
        Update values of existing non-zeros in column
        of the underlying matrix.

        Parameters
        ----------
        j : int
            Index of the column to update.
        vals : array like
            The new values to be assigned, must satisfy
            len(vals) == X[:,j].nnz i.e. this method can
            only change the value of existing non-zero entries
            of column j, it cannot add new ones.
        """
        dataptr = self.col_view[:,j].data
        self.X.data[dataptr] = vals

    def ensure_sparse_cols(self,max_density,remove_lowest=True):
        """
        Ensure that no column of the matrix excess the specified
        density, setting excess entries to zero where necessary.

        This can be useful to avoid popularity bias in collaborative
        filtering, by pruning the number of users for popular items:

        >>> num_users,num_items = train.shape
        >>> f = fast_sparse_matrix(train)
        >>> f.ensure_sparse_cols(max_density=0.01)

        Now any item in train has non-zero ratings from at most 1% of users.

        Parameters
        ----------
        max_density : float
            The highest allowable column-wise density. A value of one
            or more is treated as an absolute limit on the number of
            non-zero entries in a column, while a value of less than
            one is treated as a density i.e. a proportion of the overall
            number of rows.
        remove_lowest : boolean (default: True)
            If true then excess entries to be set to zero in a column are
            chosen lowest first, otherwise they are selected randomly.
        """
        if max_density >= 1:
            max_nnz = int(max_density)
        else:
            max_nnz = int(max_density*self.shape[0])
        for j in xrange(self.shape[1]):
            col = self.fast_get_col(j)
            excess = col.nnz - max_nnz
            if excess > 0:
                if remove_lowest:
                    zero_entries = np.argsort(col.data)[:excess]
                else:
                    zero_entries = random.sample(xrange(col.nnz),excess)
                col.data[zero_entries] = 0
                self.fast_update_col(j,col.data)

    def save(self,filepath):
        """
        Save to file as arrays in numpy binary format.

        Parameters
        ----------
        filepath : str
            The filepath to write to.
        """
        d = self.X.tocoo(copy=False)
        v = self.col_view.tocoo(copy=False)
        np.savez(filepath,row=d.row,col=d.col,data=d.data,shape=d.shape,
                 v_row=v.row,v_col=v.col,v_data=v.data,v_shape=v.shape)

    @staticmethod
    def load(filepath):
        """
        Load a fast_sparse_matrix from file written by fast_sparse_matrix.save().

        Parameters
        ----------
        filepath : str
            The filepath to load.
        """
        y = np.load(filepath,mmap_mode='r')
        X = coo_matrix((y['data'],(y['row'],y['col'])),shape=y['shape'])
        col_view = coo_matrix((y['v_data'],(y['v_row'],y['v_col'])),shape=y['v_shape'])
        return fast_sparse_matrix(X,col_view.tocsc())

    @staticmethod
    def loadtxt(filepath,comments='#',delimiter=None,skiprows=0,usecols=None,index_offset=1):
        """
        Create a fast_sparse_matrix from simply formatted data such as TSV, handles
        similar input to numpy.loadtxt().

        Parameters
        ----------
        filepath : file or str
            File containing simply formatted row,col,val sparse matrix data.
        comments : str, optional
            The character used to indicate the start of a comment (default: #).
        delimiter : str, optional
            The string used to separate values. By default, this is any whitespace.
        skiprows : int, optional
            Skip the first skiprows lines; default: 0.
        usecols : sequence, optional
            Which columns to read, with 0 being the first. For example, usecols = (1,4,5)
            will extract the 2nd, 5th and 6th columns. The default, None, results in all
            columns being read.
        index_offset : int, optional
            Offset applied to the row and col indices in the input data (default: 1).
            The default offset is chosen so that 1-indexed data on file results in a
            fast_sparse_matrix holding 0-indexed matrices.

        Returns
        -------
        mat : mrec.sparse.fast_sparse_matrix
            A fast_sparse_matrix holding the data in the file.
        """
        X = loadtxt(filepath,comments=comments,delimiter=delimiter,skiprows=skiprows,usecols=usecols)
        return fast_sparse_matrix(X)

    @staticmethod
    def loadmm(filepath):
        """
        Create a fast_sparse_matrix from matrixmarket data.

        Parameters
        ----------
        filepath : file or str
            The matrixmarket file to read.

        Returns
        -------
        mat : mrec.sparse.fast_sparse_matrix
            A fast_sparse_matrix holding the data in the file.
        """
        X = mmread(filepath)
        return fast_sparse_matrix(X)


########NEW FILE########
__FILENAME__ = testing
import random
import numpy as np
from scipy.sparse import coo_matrix
from sklearn.utils.testing import assert_array_equal

def get_random_coo_matrix(rows=3,cols=10,nnz=20):
    row_col = random.sample(xrange(rows*cols),nnz)  # ensure <row,col> are unique
    row = [i // cols for i in row_col]
    col = [i % cols for i in row_col]
    data = np.random.randint(0,nnz*5,nnz)
    return coo_matrix((data,(row,col)),shape=(rows,cols))

def assert_sparse_matrix_equal(X,Y):
    expected = X.toarray()
    actual = Y.toarray()
    # it's possible that we had trailing empty columns in X
    # - there's no way we can know about these sometimes e.g.
    # when reading back from file
    expected = expected[:actual.shape[0],:actual.shape[1]]
    assert_array_equal(expected,actual)


########NEW FILE########
__FILENAME__ = test_base_recommender
try:
    import cPickle as pickle
except ImportError:
    import pickle
import tempfile
import os
import numpy as np
from nose.tools import assert_less_equal
from sklearn.utils.testing import assert_raises
from sklearn.utils.testing import assert_equal
from sklearn.utils.testing import assert_array_equal

from mrec.testing import get_random_coo_matrix

from mrec.base_recommender import BaseRecommender

class MyRecommender(BaseRecommender):
    def __init__(self):
        self.foo = np.ndarray(range(10))
        self.description = 'my recommender'
    def _create_archive(self):
        tmp = self.foo
        self.foo = None
        m = pickle.dumps(self)
        self.foo = tmp
        return {'model':m,'foo':self.foo}
    def _load_archive(self,archive):
        self.foo = archive['foo']

def save_load(r):
    f,path = tempfile.mkstemp(suffix='.npz')
    r.save(path)
    return BaseRecommender.load(path)

def check_read_description(r):
    f,path = tempfile.mkstemp(suffix='.npz')
    r.save(path)
    d = BaseRecommender.read_recommender_description(path)
    assert_equal(str(r),d)

def test_save_filepath_condition():
    r = BaseRecommender()
    invalid_filepath = 'no suffix'
    assert_raises(ValueError,r.save,invalid_filepath)

def test_save_load():
    r = save_load(BaseRecommender())
    assert_equal(type(r),BaseRecommender)
    r = MyRecommender()
    r2 = save_load(r)
    assert_equal(type(r2),type(r))
    assert_array_equal(r2.foo,r.foo)
    assert_equal(r2.description,r.description)

def test_read_recommender_description():
    check_read_description(BaseRecommender())
    check_read_description(MyRecommender())

def test_zero_known_item_scores():
    train = get_random_coo_matrix().tocsr()
    predictions = np.random.random_sample(train.shape)
    r = BaseRecommender()
    safe = r._zero_known_item_scores(predictions,train)
    num_users,num_items = predictions.shape
    for u in xrange(num_users):
        for i in xrange(num_items):
            if i in train[u].indices:
                assert_less_equal(safe[u,i],0)
            else:
                assert_equal(safe[u,i],predictions[u,i])

########NEW FILE########
__FILENAME__ = test_mrec
import tempfile
import os

from mrec.testing import get_random_coo_matrix
from mrec.testing import assert_sparse_matrix_equal

from mrec import load_sparse_matrix
from mrec import save_sparse_matrix

def test_save_load_sparse_matrix():
    X = get_random_coo_matrix()
    for fmt in ['tsv','csv','npz','mm','fsm']:
        if fmt == 'mm':
            suffix = '.mtx'
        elif fmt == 'npz' or fmt == 'fsm':
            suffix = '.npz'
        else:
            suffix = ''
        f,path = tempfile.mkstemp(suffix=suffix)
        save_sparse_matrix(X,fmt,path)
        Y = load_sparse_matrix(fmt,path)
        assert_sparse_matrix_equal(X,Y)
        os.remove(path)

########NEW FILE########
__FILENAME__ = test_sparse
import tempfile
import os
from sklearn.utils.testing import assert_equal
from sklearn.utils.testing import assert_array_equal

from mrec.testing import get_random_coo_matrix
from mrec.testing import assert_sparse_matrix_equal

from mrec.sparse import loadtxt
from mrec.sparse import savez
from mrec.sparse import loadz
from mrec.sparse import fast_sparse_matrix

def test_loadtxt():
    X = get_random_coo_matrix()
    f,path = tempfile.mkstemp(suffix='.npz')
    with open(path,'w') as f:
        for i,j,v in zip(X.row,X.col,X.data):
            print >>f,'{0}\t{1}\t{2}'.format(i+1,j+1,v)
    Y = loadtxt(path)
    os.remove(path)
    assert_sparse_matrix_equal(X,Y)

def test_savez_loadz():
    m = get_random_coo_matrix()
    f,path = tempfile.mkstemp(suffix='.npz')
    savez(m,path)
    n = loadz(path)
    os.remove(path)
    assert_array_equal(n.toarray(),m.toarray())

def test_init_fast_sparse_matrix():
    X = get_random_coo_matrix()
    Y = X.tocsr()
    Z = X.tocsc()
    for M in [X,Y,Z]:
        m = fast_sparse_matrix(M)
        assert_array_equal(m.X.toarray(),M.toarray())
        assert_equal(m.shape,M.shape)

def test_fast_get_col():
    X = get_random_coo_matrix().tocsc()
    m = fast_sparse_matrix(X)
    rows,cols = X.shape
    for j in xrange(cols):
        assert_array_equal(m.fast_get_col(j).toarray(),X[:,j].toarray())

def test_fast_update_col():
    X = get_random_coo_matrix().tocsc()
    m = fast_sparse_matrix(X)
    cols = X.shape[1]
    for j in xrange(cols):
        vals = m.fast_get_col(j).data
        if (vals==0).all():
            continue
        vals[vals!=0] += 1
        m.fast_update_col(j,vals)
        expected = X[:,j].toarray()
        for i in xrange(expected.shape[0]):
            if expected[i] != 0:
                expected[i] += 1
        assert_array_equal(m.fast_get_col(j).toarray(),expected)

def test_save_load():
    """Save to file as arrays in numpy binary format."""
    X = get_random_coo_matrix()
    m = fast_sparse_matrix(X)
    f,path = tempfile.mkstemp(suffix='.npz')
    m.save(path)
    n = fast_sparse_matrix.load(path)
    os.remove(path)
    assert_equal(m.shape,n.shape)
    assert_array_equal(m.X.toarray(),n.X.toarray())
    assert_array_equal(m.col_view.toarray(),n.col_view.toarray())


########NEW FILE########
