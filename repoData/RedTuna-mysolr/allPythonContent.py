__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# mysolr documentation build configuration file, created by
# sphinx-quickstart on Wed Aug 31 09:39:29 2011.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('..'))
import mysolr
from mysolr import __version__

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'mysolr'
copyright = u'2011-2012, Rubén Abad, Miguel Olivares'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = __version__
# The full version, including alpha/beta/rc tags.
release = version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'flask_theme_support.FlaskyStyle'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
html_sidebars = {
    'index':    ['sidebarintro.html', 'sourcelink.html', 'searchbox.html'],
    '**':       ['sidebarlogo.html', 'localtoc.html', 'relations.html',
                 'sourcelink.html', 'searchbox.html']
}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
html_show_sourcelink = False

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
html_show_sphinx = False

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'mysolrdoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'mysolr.tex', u'mysolr Documentation',
   u'Rubén Abad, Miguel Olivares', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'mysolr', u'mysolr Documentation',
     [u'Rubén Abad, Miguel Olivares'], 1)
]

sys.path.append(os.path.abspath('_themes'))
html_theme_path = ['_themes']
html_theme = 'mysolr'

########NEW FILE########
__FILENAME__ = flask_theme_support
# flasky extensions.  flasky pygments style based on tango style
from pygments.style import Style
from pygments.token import Keyword, Name, Comment, String, Error, \
     Number, Operator, Generic, Whitespace, Punctuation, Other, Literal


class FlaskyStyle(Style):
    background_color = "#f8f8f8"
    default_style = ""

    styles = {
        # No corresponding class for the following:
        #Text:                     "", # class:  ''
        Whitespace:                "underline #f8f8f8",      # class: 'w'
        Error:                     "#a40000 border:#ef2929", # class: 'err'
        Other:                     "#000000",                # class 'x'

        Comment:                   "italic #8f5902", # class: 'c'
        Comment.Preproc:           "noitalic",       # class: 'cp'

        Keyword:                   "bold #004461",   # class: 'k'
        Keyword.Constant:          "bold #004461",   # class: 'kc'
        Keyword.Declaration:       "bold #004461",   # class: 'kd'
        Keyword.Namespace:         "bold #004461",   # class: 'kn'
        Keyword.Pseudo:            "bold #004461",   # class: 'kp'
        Keyword.Reserved:          "bold #004461",   # class: 'kr'
        Keyword.Type:              "bold #004461",   # class: 'kt'

        Operator:                  "#582800",   # class: 'o'
        Operator.Word:             "bold #004461",   # class: 'ow' - like keywords

        Punctuation:               "bold #000000",   # class: 'p'

        # because special names such as Name.Class, Name.Function, etc.
        # are not recognized as such later in the parsing, we choose them
        # to look the same as ordinary variables.
        Name:                      "#000000",        # class: 'n'
        Name.Attribute:            "#c4a000",        # class: 'na' - to be revised
        Name.Builtin:              "#004461",        # class: 'nb'
        Name.Builtin.Pseudo:       "#3465a4",        # class: 'bp'
        Name.Class:                "#000000",        # class: 'nc' - to be revised
        Name.Constant:             "#000000",        # class: 'no' - to be revised
        Name.Decorator:            "#888",           # class: 'nd' - to be revised
        Name.Entity:               "#ce5c00",        # class: 'ni'
        Name.Exception:            "bold #cc0000",   # class: 'ne'
        Name.Function:             "#000000",        # class: 'nf'
        Name.Property:             "#000000",        # class: 'py'
        Name.Label:                "#f57900",        # class: 'nl'
        Name.Namespace:            "#000000",        # class: 'nn' - to be revised
        Name.Other:                "#000000",        # class: 'nx'
        Name.Tag:                  "bold #004461",   # class: 'nt' - like a keyword
        Name.Variable:             "#000000",        # class: 'nv' - to be revised
        Name.Variable.Class:       "#000000",        # class: 'vc' - to be revised
        Name.Variable.Global:      "#000000",        # class: 'vg' - to be revised
        Name.Variable.Instance:    "#000000",        # class: 'vi' - to be revised

        Number:                    "#990000",        # class: 'm'

        Literal:                   "#000000",        # class: 'l'
        Literal.Date:              "#000000",        # class: 'ld'

        String:                    "#4e9a06",        # class: 's'
        String.Backtick:           "#4e9a06",        # class: 'sb'
        String.Char:               "#4e9a06",        # class: 'sc'
        String.Doc:                "italic #8f5902", # class: 'sd' - like a comment
        String.Double:             "#4e9a06",        # class: 's2'
        String.Escape:             "#4e9a06",        # class: 'se'
        String.Heredoc:            "#4e9a06",        # class: 'sh'
        String.Interpol:           "#4e9a06",        # class: 'si'
        String.Other:              "#4e9a06",        # class: 'sx'
        String.Regex:              "#4e9a06",        # class: 'sr'
        String.Single:             "#4e9a06",        # class: 's1'
        String.Symbol:             "#4e9a06",        # class: 'ss'

        Generic:                   "#000000",        # class: 'g'
        Generic.Deleted:           "#a40000",        # class: 'gd'
        Generic.Emph:              "italic #000000", # class: 'ge'
        Generic.Error:             "#ef2929",        # class: 'gr'
        Generic.Heading:           "bold #000080",   # class: 'gh'
        Generic.Inserted:          "#00A000",        # class: 'gi'
        Generic.Output:            "#888",           # class: 'go'
        Generic.Prompt:            "#745334",        # class: 'gp'
        Generic.Strong:            "bold #000000",   # class: 'gs'
        Generic.Subheading:        "bold #800080",   # class: 'gu'
        Generic.Traceback:         "bold #a40000",   # class: 'gt'
    }

########NEW FILE########
__FILENAME__ = flask_theme_support
# flasky extensions.  flasky pygments style based on tango style
from pygments.style import Style
from pygments.token import Keyword, Name, Comment, String, Error, \
     Number, Operator, Generic, Whitespace, Punctuation, Other, Literal


class FlaskyStyle(Style):
    background_color = "#f8f8f8"
    default_style = ""

    styles = {
        # No corresponding class for the following:
        #Text:                     "", # class:  ''
        Whitespace:                "underline #f8f8f8",      # class: 'w'
        Error:                     "#a40000 border:#ef2929", # class: 'err'
        Other:                     "#000000",                # class 'x'

        Comment:                   "italic #8f5902", # class: 'c'
        Comment.Preproc:           "noitalic",       # class: 'cp'

        Keyword:                   "bold #004461",   # class: 'k'
        Keyword.Constant:          "bold #004461",   # class: 'kc'
        Keyword.Declaration:       "bold #004461",   # class: 'kd'
        Keyword.Namespace:         "bold #004461",   # class: 'kn'
        Keyword.Pseudo:            "bold #004461",   # class: 'kp'
        Keyword.Reserved:          "bold #004461",   # class: 'kr'
        Keyword.Type:              "bold #004461",   # class: 'kt'

        Operator:                  "#582800",   # class: 'o'
        Operator.Word:             "bold #004461",   # class: 'ow' - like keywords

        Punctuation:               "bold #000000",   # class: 'p'

        # because special names such as Name.Class, Name.Function, etc.
        # are not recognized as such later in the parsing, we choose them
        # to look the same as ordinary variables.
        Name:                      "#000000",        # class: 'n'
        Name.Attribute:            "#c4a000",        # class: 'na' - to be revised
        Name.Builtin:              "#004461",        # class: 'nb'
        Name.Builtin.Pseudo:       "#3465a4",        # class: 'bp'
        Name.Class:                "#000000",        # class: 'nc' - to be revised
        Name.Constant:             "#000000",        # class: 'no' - to be revised
        Name.Decorator:            "#888",           # class: 'nd' - to be revised
        Name.Entity:               "#ce5c00",        # class: 'ni'
        Name.Exception:            "bold #cc0000",   # class: 'ne'
        Name.Function:             "#000000",        # class: 'nf'
        Name.Property:             "#000000",        # class: 'py'
        Name.Label:                "#f57900",        # class: 'nl'
        Name.Namespace:            "#000000",        # class: 'nn' - to be revised
        Name.Other:                "#000000",        # class: 'nx'
        Name.Tag:                  "bold #004461",   # class: 'nt' - like a keyword
        Name.Variable:             "#000000",        # class: 'nv' - to be revised
        Name.Variable.Class:       "#000000",        # class: 'vc' - to be revised
        Name.Variable.Global:      "#000000",        # class: 'vg' - to be revised
        Name.Variable.Instance:    "#000000",        # class: 'vi' - to be revised

        Number:                    "#990000",        # class: 'm'

        Literal:                   "#000000",        # class: 'l'
        Literal.Date:              "#000000",        # class: 'ld'

        String:                    "#4e9a06",        # class: 's'
        String.Backtick:           "#4e9a06",        # class: 'sb'
        String.Char:               "#4e9a06",        # class: 'sc'
        String.Doc:                "italic #8f5902", # class: 'sd' - like a comment
        String.Double:             "#4e9a06",        # class: 's2'
        String.Escape:             "#4e9a06",        # class: 'se'
        String.Heredoc:            "#4e9a06",        # class: 'sh'
        String.Interpol:           "#4e9a06",        # class: 'si'
        String.Other:              "#4e9a06",        # class: 'sx'
        String.Regex:              "#4e9a06",        # class: 'sr'
        String.Single:             "#4e9a06",        # class: 's1'
        String.Symbol:             "#4e9a06",        # class: 'ss'

        Generic:                   "#000000",        # class: 'g'
        Generic.Deleted:           "#a40000",        # class: 'gd'
        Generic.Emph:              "italic #000000", # class: 'ge'
        Generic.Error:             "#ef2929",        # class: 'gr'
        Generic.Heading:           "bold #000080",   # class: 'gh'
        Generic.Inserted:          "#00A000",        # class: 'gi'
        Generic.Output:            "#888",           # class: 'go'
        Generic.Prompt:            "#745334",        # class: 'gp'
        Generic.Strong:            "bold #000000",   # class: 'gs'
        Generic.Subheading:        "bold #800080",   # class: 'gu'
        Generic.Traceback:         "bold #a40000",   # class: 'gt'
    }

########NEW FILE########
__FILENAME__ = compat
# -*- coding: utf-8 -*-
"""
    mysolr.compat
    ~~~~~~~~~~~~~~

    Resolve compatibility between python 2.X and 3.X

"""

import sys
import anyjson

if sys.version_info >= (3, ):
    from urllib.parse import urljoin
elif sys.version_info >= (2, ):
    from urlparse import urljoin

def parse_response(content):
    return anyjson.loads(content.decode('utf-8'))

def compat_args(query):
    for (key, value) in query.items():
        if isinstance(value, bool):
            query[key] = str(value).lower()


def get_basestring():
    return str if sys.version_info[0] == 3  else basestring
########NEW FILE########
__FILENAME__ = mysolr
# -*- coding: utf-8 -*-
"""
mysolr.mysolr
~~~~~~~~~~~~~

This module impliments the mysolr Solr class, providing an easy access to
operate with a Solr server.

>>> from mysolr import Solr
>>> solr = Solr('http://myserver:8080/solr')
>>> query = {'q':'*:*', 'rows': 0, 'start': 0, 'facet': 'true', 
             'facet.field': 'province'}
>>> query_response = solr.search(**query)

"""
from .response import SolrResponse
from .compat import urljoin, compat_args, get_basestring
from xml.sax.saxutils import escape

import json
import requests

class Solr(object):
    """Acts as an easy-to-use interface to Solr."""

    def __init__(self, base_url='http://localhost:8080/solr/',
                 make_request=requests, use_get=False, version=None):
        """ Initializes a Solr object. Solr URL is a needed parameter.

        :param base_url: Url to solr index
        :param make_request: 
        :param use_get: Use get instead of post when searching. Useful if you
                        cache GET requests
        :param version: first number of the solr version. i.e. 4 if solr 
                        version is 4.0.0 If you set to none this parameter
                        a request to admin/system will be done at init time
                        in order to guess the version.
        """
        self.base_url = base_url if base_url.endswith('/') else '%s/' % base_url
        self.make_request = make_request
        self.use_get = use_get
        self.version = version
        if not version:
            self.version = self.get_version()
        assert(self.version in (1, 3, 4))

    def search(self, resource='select', **kwargs):
        """Queries Solr with the given kwargs and returns a SolrResponse
        object.

        :param resource: Request dispatcher. 'select' by default.
        :param **kwargs: Dictionary containing any of the available Solr query
                         parameters described in
                         http://wiki.apache.org/solr/CommonQueryParameters.
                         'q' is a mandatory parameter.

        """
        query = build_request(kwargs)
        url = urljoin(self.base_url, resource)
        if self.use_get:
            http_response = self.make_request.get(url, params=query)
        else:
            http_response = self.make_request.post(url, data=query)

        solr_response = SolrResponse(http_response)
        return solr_response

    def search_cursor(self, resource='select', **kwargs):
        """ """
        query = build_request(kwargs)
        cursor = Cursor(urljoin(self.base_url, resource), query,
                        self.make_request, self.use_get)

        return cursor
    
    def async_search(self, queries, size=10, resource='select'):
        """ Asynchronous search using async module from requests. 

        :param queries:  List of queries. Each query is a dictionary containing
                         any of the available Solr query parameters described in
                         http://wiki.apache.org/solr/CommonQueryParameters.
                         'q' is a mandatory parameter.
        :param size:     Size of threadpool
        :param resource: Request dispatcher. 'select' by default.
        """
        try:
            import grequests
        except:
            raise RuntimeError('grequests is required for Solr.async_search.')

        url = urljoin(self.base_url, resource)
        queries = map(build_request, queries)
        rs = (grequests.post(url, data=query) for query in queries)
        responses = grequests.map(rs, size=size)
        return [SolrResponse(http_response) for http_response in responses]


    def update(self, documents, input_type='json', commit=True):
        """Sends an update/add message to add the array of hashes(documents) to
        Solr.

        :param documents: A list of solr-compatible documents to index. You
                          should use unicode strings for text/string fields.
        :param input_type: The format which documents are sent. Remember that
                           json is not supported until version 3.
        :param commit: If True, sends a commit message after the operation is
                       executed.

        """
        assert input_type in ['xml', 'json']

        if input_type == 'xml':
            http_response = self._post_xml(_get_add_xml(documents))
        else:
            http_response = self._post_json(json.dumps(documents))
        if commit:
            self.commit()
        
        return SolrResponse(http_response)

    def delete_by_key(self, identifier, commit=True):
        """Sends an ID delete message to Solr.

        :param commit: If True, sends a commit message after the operation is
                       executed.

        """
        xml = '<delete><id>%s</id></delete>' % (identifier)
        http_response = self._post_xml(xml)
        if commit:
            self.commit()
        return SolrResponse(http_response)

    def delete_by_query(self, query, commit=True):
        """Sends a query delete message to Solr.

        :param commit: If True, sends a commit message after the operation is
                       executed.

        """
        xml = '<delete><query>%s</query></delete>' % (query)
        http_response = self._post_xml(xml)
        if commit:
            self.commit()
        return SolrResponse(http_response)

    def commit(self, wait_flush=True,
               wait_searcher=True, expunge_deletes=False):
        """Sends a commit message to Solr.

        :param wait_flush: Block until index changes are flushed to disk
                           (default is True).
        :param wait_searcher: Block until a new searcher is opened and
                              registered as the main query searcher, making the
                              changes visible (default is True).
        :param expunge_deletes: Merge segments with deletes away (default is 
                                False)

        """
        xml = '<commit '
        if self.version < 4:
            xml += 'waitFlush="%s" ' % str(wait_flush).lower()
        xml += 'waitSearcher="%s" ' % str(wait_searcher).lower()
        xml += 'expungeDeletes="%s" ' % str(expunge_deletes).lower()
        xml += '/>'

        http_response = self._post_xml(xml)
        return SolrResponse(http_response)

    def optimize(self, wait_flush=True, wait_searcher=True, max_segments=1):
        """Sends an optimize message to Solr.

        :param wait_flush: Block until index changes are flushed to disk
                           (default is True)
        :param wait_searcher: Block until a new searcher is opened and
                              registered as the main query searcher, making the
                              changes visible (default is True)
        :param max_segments: Optimizes down to at most this number of segments
                             (default is 1)

        """
        xml = '<optimize '
        if self.version < 4:
            xml += 'waitFlush="%s" ' % str(wait_flush).lower()
        xml += 'waitSearcher="%s" ' % str(wait_searcher).lower()
        xml += 'maxSegments="%s" ' % max_segments
        xml += '/>'

        http_response = self._post_xml(xml)
        return SolrResponse(http_response)

    def rollback(self):
        """Sends a rollback message to Solr server."""
        xml = '<rollback />'
        http_response = self._post_xml(xml)
        return SolrResponse(http_response)

    def ping(self):
        """ Ping call to solr server. """
        url = urljoin(self.base_url, 'admin/ping')
        http_response = self.make_request.get(url, params={'wt': 'json'})
        return SolrResponse(http_response)

    def is_up(self):
        """Check if a Solr server is up using ping call"""
        try:
            solr_response = self.ping()
        except:
            return False
        return solr_response.status == 200 and solr_response.solr_status == 0

    def schema(self):
        return self._get_file('schema.xml')

    def solrconfig(self):
        return self._get_file('solrconfig.xml')

    def get_system_info(self):
        """ Gets solr system status. """
        url = urljoin(self.base_url, 'admin/system')
        params = {'wt': 'json'}
        http_response = self.make_request.get(url, params=params)
        return SolrResponse(http_response)

    def get_version(self):
        system_info = self.get_system_info()
        version = system_info.raw_content['lucene']['solr-spec-version']
        return int(version[0])

    def more_like_this(self, resource='mlt', text=None, **kwargs):
        """Implements convenient access to Solr MoreLikeThis functionality  

        Please, visit http://wiki.apache.org/solr/MoreLikeThis to learn more
        about MLT configuration and common parameters.

        There are two ways of using MLT in Solr:

        Using a previously configured RequestHandler
            You normally specify a query and the first matching document for 
            that query is used to retrieve similar documents.
            You can however specify a text instead of a query, and similar
            documents to the text will be returned.
            You must configure a MLT RequestHandler in your solrconfig.xml in
            order to get advantage of this functionality.
            Note that this method has a default resource name with value "mlt",
            but if your RequestHandler has a different name you must specify it
            when calling the more_like_this method.

        Using the MLT Search Component:
            The resulting documents in this case will be those that match the
            regular query, but the SolrResponse will have a "mlt" section where
            similar documents for each result document will be given.

        :param resource: Request dispatcher. 'ml' by default.
        :param text: Text to use for similar documents retrieval. None by
                     default.
        :param **kwargs: Dictionary containing any of the available Solr query
                         parameters described in
                         http://wiki.apache.org/solr/CommonQueryParameters
                         or MoreLikeThis Common parameters described in
                         http://wiki.apache.org/solr/MoreLikeThis.
                         'q' is a mandatory parameter in all cases except
                         when using a MLT RequestHandler with a Text parameter.
    
        """
        if text is not None: #RequestHandler with Content-Streamed Text
            #we dont call build_query because 'q' is NOT mandatory in this case
            kwargs['wt'] = 'json'
            headers = {'Content-type': 'text/json'}
            url = urljoin(self.base_url, resource)
            http_response = self.make_request.post(url, params=kwargs,
                                                   data=text,
                                                   headers=headers)
            solr_response = SolrResponse(http_response)
            return solr_response
        else:
            return self.search(resource=resource, **kwargs)

    def _post_xml(self, xml):
        """ Sends the xml to Solr server.

        :param xml: XML document to be posted.
        """
        url = urljoin(self.base_url, 'update')
        xml_data = xml.encode('utf-8')
        headers = {
            'Content-type': 'text/xml; charset=utf-8',
            'Content-Length': "%s" % len(xml_data)
        }
        http_response = self.make_request.post(url, data=xml_data,
                                               headers=headers)
        return http_response

    def _post_json(self, json_doc):
        """ Sends the json to Solr server.

        :param json_doc: JSON document to be posted.
        """
        url = urljoin(self.base_url, 'update/json')
        json_data = json_doc.encode('utf-8')
        headers = {
            'Content-type': 'application/json; charset=utf-8',
            'Content-Length': "%s" % len(json_data)
        }
        http_response = self.make_request.post(url, data=json_data,
                                               headers=headers)
        return http_response

    def _get_file(self, filename):
        """Retrieves config files of the current index."""
        url = urljoin(self.base_url, 'admin/file')
        params = {
            'contentType': 'text/xml;charset=utf-8',
            'file' : filename
        }
        http_response = self.make_request.get(url, params=params)
        return http_response.content


class Cursor(object):
    """ Implements the concept of cursor in relational databases """
    def __init__(self, url, query, make_request=requests, use_get=False):
        """ Cursor initialization """
        self.url = url
        self.query = query
        self.make_request = make_request
        self.use_get = use_get

    def fetch(self, rows=None):
        """ Generator method that grabs all the documents in bulk sets of 
        'rows' documents

        :param rows: number of rows for each request
        """
        if rows:
            self.query['rows'] = rows

        if 'rows' not in self.query:
            self.query['rows'] = 10

        self.query['start'] = 0

        end = False
        docs_retrieved = 0
        while not end:
            if self.use_get:
                http_response = self.make_request.get(self.url,
                                                      params=self.query)
            else:
                http_response = self.make_request.post(self.url,
                                                       data=self.query)
            solr_response = SolrResponse(http_response)
            yield solr_response
            total_results = solr_response.total_results
            docs_retrieved += len(solr_response.documents)
            end = docs_retrieved == total_results
            self.query['start'] += self.query['rows']


def _get_add_xml(array_of_hash, overwrite=True):
    """ Creates add XML message to send to Solr based on the array of hashes
    (documents) provided.

    :param overwrite: Newer documents will replace previously added documents
                      with the same uniqueKey (default is True)

    """
    xml = '<add overwrite="%s">' % ('true' if overwrite else 'false')
    for doc_hash in array_of_hash:
        doc = '<doc>'
        for key, value in doc_hash.items():
            if isinstance(value, list):
                for v in value:
                    if isinstance(v, get_basestring()):
                        v = escape(v)
                    doc += '<field name="%s">%s</field>' % (key, v)
            else:
                if isinstance(value, get_basestring()):
                    value = escape(value)
                doc += '<field name="%s">%s</field>' % (key, value)
        doc += '</doc>'
        xml += doc
    xml += '</add>'
    return xml


def  build_request(query):
    """ Check solr query and put convenient format """
    assert 'q' in query
    compat_args(query)
    query['wt'] = 'json'
    return query

########NEW FILE########
__FILENAME__ = response
# -*- coding: utf-8 -*-
"""
mysolr.response
~~~~~~~~~~~~~

This module implements a class that encapsulate Http responses obtained from Solr.
mysolr.SolrResponse is a generic Solr Response, from any of the GET/POST methods
supported by mysolr. For example, performing a ping against a Solr instance will
return an object of class mysolr.SolrResponse.
Performing a search will also return a mysolr.SolrResponse object, but in this
case, the response will contain additional fields only relevant when working 
with search results.

Because mysolr uses requests library for all the Http machinery, a mysolr.SolrResponse
can be created from a more generic requests.Response.
"""

from .compat import parse_response
import requests
import json
import re
try:
    from collections import OrderedDict
except ImportError:
    from ordereddict import OrderedDict

class SolrResponse(object):
    """Parse solr response and make it accesible."""
    def __init__(self, http_response=None):
        """ Initializes a SolrResponse object.

        If a requests.Response is provided as an argument, some  of its attributes
        (headers, content, url and status_code) will be incorporated to the current 
        SolrResponse object.

        :param http_response: `requests.Response` object

        """
        self.headers = None
        self.url = None
        self.status = 0
        self.raw_content = None
        if http_response is not None:
            self.headers = http_response.headers
            self.raw_content = http_response.content
            self.url = http_response.url
            self.status = http_response.status_code

        self.parse_content()

    def parse_content(self):
        """Tries to parse the raw content to know if its a structured results 
        response or an unstructured HTML page (usually resulting from an error)

        """
        if self.raw_content:
            try:
                self.raw_content = parse_response(self.raw_content)
            except:
                self.raw_content = None

            #Solr responded with a Structured Results Response
            if self.raw_content is not None:
                #: Response status from solr responseHeader.
                self.solr_status = self.raw_content['responseHeader']['status']
                #: Query time.
                self.qtime = self.raw_content['responseHeader']['QTime']
                self.total_results = None
                self.start = None
                self.documents = None
                if 'response' in self.raw_content:
                    #: Number of results.
                    self.total_results = self.raw_content['response']['numFound']
                    #: Offset.
                    self.start = self.raw_content['response']['start']
                    #: Documents list.
                    self.documents = self.raw_content['response']['docs']
                #: Facets parsed as a OrderedDict (Order matters).
                self.facets = None
                if 'facet_counts' in self.raw_content:
                    self.facets = self.parse_facets(self.raw_content['facet_counts'])
                #: Shorcut to stats resuts
                self.stats = None
                if 'stats' in self.raw_content:
                    self.stats = self.raw_content['stats']['stats_fields']
                #: Spellcheck result parsed into a more readable object.
                self.spellcheck = None
                if 'spellcheck' in self.raw_content:
                    suggestions = self.raw_content['spellcheck']['suggestions']
                    self.spellcheck = self.parse_spellcheck(suggestions)
                #: Shorcut to highlighting result
                self.highlighting = None
                if 'highlighting' in self.raw_content:
                    self.highlighting = self.raw_content['highlighting']
                self.mlt = None
                if 'moreLikeThis' in self.raw_content:
                    self.mlt = self.raw_content['moreLikeThis']
                self.message = None
            #Solr responded with a unstructured HTML Body Response
            else:
                #try to extract error message from html body if any:
                self.message = self.extract_errmessage()

    def __repr__(self):
        return '<SolrResponse status=%d>' % self.status 

    def parse_facets(self, solr_facets):
        """ Parse facets."""
        result = {}
        for facet_type, facets in solr_facets.items():
            facet_type_dict = {}
            for name, facet in facets.items():
                if isinstance(facet, list):
                    parsed = [tuple(facet[i:i+2]) for i in range(0, len(facet), 2)]
                    facet_type_dict[name] = OrderedDict(parsed)
                elif isinstance(facet, dict):
                    facet_type_dict[name] = OrderedDict(facet)
                elif isinstance(facet, int):
                    facet_type_dict[name] = facet
            result[facet_type] = facet_type_dict
        return result


    def parse_spellcheck(self, solr_suggestions):
        """ Parse spellcheck result into a more readable format. """
        result = {}
        suggestions = {}

        for i in range(0, len(solr_suggestions), 2):
            key = solr_suggestions[i]
            value = solr_suggestions[i+1]
            if isinstance(value, dict):
                # it's a suggestion
                suggestions[key] = value
            else:
                # it's information about spellchecking result
                result[key] = value

        result['suggestions'] = suggestions
        return result

    def extract_errmessage(self):
        """Tries to extract an error message from a SolrResponse body content.
        
        Useful for error identification (e.g.: indexation errors)
        """
        message = None
        try:
            message = re.findall('<u>([^<]*)</u>', str(self.raw_content))[-1]
        except Exception as e:
            pass
        return message


########NEW FILE########
__FILENAME__ = test_highlighting_query_result
# -*- coding: utf-8 -*-
import unittest


from mysolr import SolrResponse
from os.path import join, dirname
import requests
import json
import sys

class HighlightingQueryResultTestCase(unittest.TestCase):
    """ """

    def setUp(self):
        mock_file = join(dirname(__file__), 'mocks/highlightingquery')
        with open(mock_file) as f:
            raw_content = None
            if sys.version_info[0] == 3:
                raw_content = f.read().encode('utf-8')
            else:
                raw_content = f.read()
            self.response = SolrResponse()
            self.response.raw_content = raw_content
            self.response.status = 200
            self.response.parse_content()

    def tearDown(self):
        pass

    def test_query(self):
        self.assertNotEqual(self.response.highlighting, None)


if __name__ == '__main__':
    unittest.main()
########NEW FILE########
__FILENAME__ = test_query
# -*- coding: utf-8 -*-
import os
import time
import unittest
from mysolr import Solr


class QueryResultTestCase(unittest.TestCase):

    def setUp(self):
        self.solr = Solr(os.getenv('SOLR_URL'))

    def test_search(self):
        response = self.solr.search(q='*:*')
        self.assertEqual(response.status, 200)
        self.assertEqual(response.total_results, 4)
        self.assertEqual(len(response.documents), 4)

    def test_search_cursor(self):
        cursor = self.solr.search_cursor(q='*:*')
        i = 0
        for response in cursor.fetch(1):
            self.assertEqual(response.status, 200)
            i += 1
        self.assertEqual(i, 4)

        cursor = self.solr.search_cursor(q='*:*')
        i = 0
        for response in cursor.fetch(4):
            self.assertEqual(response.status, 200)
            i += 1
        self.assertEqual(i, 1)

    def test_commit(self):
        response = self.solr.commit()
        self.assertEqual(response.status, 200)

    def test_optimize(self):
        response = self.solr.optimize()
        self.assertEqual(response.status, 200)

    def test_ping(self):
        response = self.solr.ping()
        self.assertEqual(response.status, 200)

    def test_is_up(self):
        response = self.solr.is_up()
        self.assertEqual(response, True)

    def test_update_delete(self):
        # Get total results
        response = self.solr.search(q='*:*')
        self.assertEqual(response.status, 200)
        total_results = response.total_results
        # Post one document using json
        documents = [{'id' : 1}]
        response = self.solr.update(documents, input_type='json')
        self.assertEqual(response.status, 200)
        # Post anoter document using xml
        documents = [{'id' : 2}]
        response = self.solr.update(documents, input_type='xml')
        self.assertEqual(response.status, 200)
        # Compare total results
        response = self.solr.search(q='*:*')
        self.assertEqual(response.status, 200)
        self.assertEqual(response.total_results, total_results + 2)

        # Now delete the two document posted above
        query = 'id:1'
        key = 2
        response = self.solr.delete_by_query(query)
        self.assertEqual(response.status, 200)
        response = self.solr.delete_by_key(key)
        self.assertEqual(response.status, 200)
        response = self.solr.search(q='*:*')
        self.assertEqual(response.status, 200)
        self.assertEqual(response.total_results, total_results)

    def tearDown(self):
        pass

    def test_query(self):
        pass

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_query_result
#!/usr/bin/python
# -*- coding: utf-8 -*-

import unittest
from mysolr import SolrResponse
from os.path import join, dirname
import requests
import sys
import json

class QueryResultTestCase(unittest.TestCase):

    def setUp(self):
        mock_file = join(dirname(__file__), 'mocks/query')
        with open(mock_file) as f:
            raw_content = None
            if sys.version_info[0] == 3:
                raw_content = f.read().encode('utf-8')
            else:
                raw_content = f.read()
            self.solr_response = SolrResponse()
            self.solr_response.raw_content = raw_content
            self.solr_response.status = 200
            self.solr_response.parse_content()

    def tearDown(self):
        pass

    def test_raw_content(self):
        self.assertNotEqual(self.solr_response.raw_content, None)

    def test_status(self):
        self.assertNotEqual(self.solr_response.solr_status, None)
        self.assertEqual(self.solr_response.solr_status, 0)

    def test_qtime(self):
        self.assertNotEqual(self.solr_response.qtime, None)
        self.assertEqual(self.solr_response.qtime, 101)

    def test_total_results(self):
        self.assertNotEqual(self.solr_response.total_results, None)
        self.assertEqual(self.solr_response.total_results, 2)

    def test_start(self):
        self.assertNotEqual(self.solr_response.start, None)
        self.assertEqual(self.solr_response.start, 0)

    def test_documents(self):
        self.assertNotEqual(self.solr_response.documents, None)
        self.assertEqual(len(self.solr_response.documents), 2)

    def test_facets(self):
        self.assertNotEqual(self.solr_response.facets, None)

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_spell_query_result
# -*- coding: utf-8 -*-
import unittest


from mysolr import SolrResponse
from os.path import join, dirname
import requests
import sys
import json


class SpellQueryResultTestCase(unittest.TestCase):
    """ """

    def setUp(self):
        mock_file = join(dirname(__file__), 'mocks/spellquery')
        with open(mock_file) as f:
            raw_content = None
            if sys.version_info[0] == 3:
                raw_content = f.read().encode('utf-8')
            else:
                raw_content = f.read()
            self.response = SolrResponse()
            self.response.raw_content = raw_content
            self.response.status = 200
            self.response.parse_content()

    def tearDown(self):
        pass

    def test_query(self):
        self.assertNotEqual(self.response.spellcheck, None)


if __name__ == '__main__':
    unittest.main()
########NEW FILE########
__FILENAME__ = test_stats_query_result
# -*- coding: utf-8 -*-
import unittest


from mysolr import SolrResponse
from os.path import join, dirname
import requests
import sys
import json


class StatsQueryResultTestCase(unittest.TestCase):
    """ """

    def setUp(self):
        mock_file = join(dirname(__file__), 'mocks/statsquery')
        with open(mock_file) as f:
            raw_content = None
            if sys.version_info[0] == 3:
                raw_content = f.read().encode('utf-8')
            else:
                raw_content = f.read()
            self.response = SolrResponse()
            self.response.raw_content = raw_content
            self.response.status = 200
            self.response.parse_content()

    def tearDown(self):
        pass

    def test_query(self):
        self.assertNotEqual(self.response.stats, None)


if __name__ == '__main__':
    unittest.main()
########NEW FILE########
