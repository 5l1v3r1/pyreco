Should contain three files

1. class2go-validator.pem - this is the organization's secret key,
   generated by Opscode

2. USERNAME.pem - this is the user's secret key, generated by Opscode.

3. knife.rb - configuration for the knife command line utility.
   Needs to contain the symmetric key for the Class2Go's AWS account 
   (c2gops)

Creating SSL certificates is a common task done in web application infrastructures, so a rake task is provided to generate certificates.  These certificates are stored here by the ssl_cert task.  

Configure the values used in the SSL certificate by modifying `config/rake.rb`.

To generate a certificate set for a new monitoring server, for example:

    rake ssl_cert FQDN=monitoring.example.com

Once the certificates are generated, copy them into the cookbook(s) where you want to use them.

    cp certificates/monitoring.example.com.* cookbooks/COOKBOOK/files/default

In the recipe for that cookbook, create a `cookbook_file` resource to configure a resource that puts them in place on the destination server.

    cookbook_file '/etc/apache2/ssl/monitoring.example.com.pem'
      owner 'root'
      group 'root'
      mode 0600
    end

## v1.1.4:

* [COOK-599] - don't break folder permissions if chef-server recipe is present

## v1.1.2:

* [COOK-1039] - support mac_os_x_server

## v1.1.0:

* [COOK-909] - trigger upstart on correct event
* [COOK-795] - add windows support with winsw
* [COOK-798] - added recipe to run chef-client as a cron job
* [COOK-986] - don't delete the validation.pem if chef-server recipe
  is detected

## v1.0.4:

* [COOK-670] - Added Solaris service-installation support for chef-client cookbook.
* [COOK-781] - chef-client service recipe fails with chef 0.9.x

## v1.0.2:

* [CHEF-2491] init scripts should implement reload

## v1.0.0:

* [COOK-204] chef::client pid template doesn't match package expectations
* [COOK-491] service config/defaults should not be pulled from Chef gem
* [COOK-525] Tell bluepill to daemonize chef-client command
* [COOK-554] Typo in backup_path
* [COOK-609] chef-client cookbook fails if init_type is set to upstart and chef is installed from deb
* [COOK-635] Allow configuration of path to chef-client binary in init script

Description
===========

This cookbook is used to configure a system as a Chef Client.

Requirements
============

Chef 0.9.12 or higher is required.

Platforms
---------

The following platforms are supported by this cookbook, meaning that the recipes run on these platforms without error.

* Debian
* Ubuntu
* Red Hat
* CentOS
* Fedora
* SUSE distributions (OpenSUSE, SLES, etc)
* ArchLinux
* FreeBSD
* Mac OS X
* Mac OS X Server

Opscode Cookbooks
-----------------

Other cookbooks can be used with this cookbook but they are not explicitly required. The default settings in this cookbook do not require their use. The other cookbooks (on community.opsocde.com) are:

* bluepill
* daemontools
* runit

See __USAGE__ below.

Attributes
==========

* `node["chef_client"]["interval"]` - Sets `Chef::Config[:interval]` via command-line option for number of seconds between chef-client daemon runs. Default 1800.
* `node["chef_client"]["splay"]` - Sets `Chef::Config[:splay]` via command-line option for a random amount of seconds to add to interval. Default 20.
* `node["chef_client"]["log_dir"]` - Sets directory used in `Chef::Config[:log_location]` via command-line option to a location where chef-client should log output. Default "/var/log/chef".
* `node["chef_client"]["conf_dir"]` - Sets directory used via command-line option to a location where chef-client search for the client config file . Default "/etc/chef".
* `node["chef_client"]["bin"]` - Sets the full path to the `chef-client` binary.  Mainly used to set a specific path if multiple versions of chef-client exist on a system or the bin has been installed in a non-sane path. Default "/usr/bin/chef-client"
* `node["chef_client"]["server_url"]` - Sets `Chef::Config[:chef_server_url]` in the config file to the Chef Server URI. Default "http://localhost:4000". See __USAGE__.
* `node["chef_client"]["validation_client_name"]` - Sets `Chef::Config[:validation_client_name]` in the config file to the name of the validation client. Default "chef-validator". See __USAGE__.
* `node["chef_client"]["init_style"]` - Sets up the client service based on the style of init system to use. Default is based on platform and falls back to "none". See __USAGE__.
* `node["chef_client"]["run_path"]` - Directory location where chef-client should write the PID file. Default based on platform, falls back to "/var/run".
* `node["chef_client"]["cache_path"]` - Directory location for `Chef::Config[:file_cache_path]` where chef-client will cache various files. Default is based on platform, falls back to "/var/chef/cache".
* `node["chef_client"]["backup_path"]` - Directory location for `Chef::Config[:file_backup_path]` where chef-client will backup templates and cookbook files. Default is based on platform, falls back to "/var/chef/backup".
* node["chef_client"]["cron"]["minute"] - The hour that chef-client will run as a cron task, only applicable if the you set "cron" as the "init_style"
* node["chef_client"]["cron"]["hour"] - The hour that chef-client will run as a cron task, only applicable if the you set "cron" as the "init_style"
* node["chef_client"]["load_gems"] - Hash of gems to load into chef via the client.rb file


Recipes
=======

This section describes the recipes in the cookbook and how to use them in your environment.

config
------

Sets up the `/etc/chef/client.rb` config file from a template and reloads the configuration for the current chef-client run.

service
-------

Use this recipe on systems that should have a `chef-client` daemon running, such as when Knife bootstrap was used to install Chef on a new system.

This recipe sets up the `chef-client` service depending on the `init_style` attribute (see above). The following init styles are supported:

* init - uses the init script included in the chef gem, supported on debian and redhat family distributions.
* upstart - uses the upstart job included in the chef gem, supported on ubuntu.
* arch - uses the init script included in this cookbook for ArchLinux, supported on arch.
* runit - sets up the service under runit, supported on ubuntu, debian and gentoo.
* bluepill - sets up the service under bluepill. As bluepill is a pure ruby process monitor, this should work on any platform.
* daemontools -sets up the service under daemontools, supported on debian, ubuntu and arch
* bsd - prints a message about how to update BSD systems to enable the chef-client service, supported on Free/OpenBSD and OSX.

default
-------

Includes the `chef-client::service` recipe by default.

delete_validation
-----------------

Use this recipe to delete the validation certificate (default `/etc/chef/validation.pem`) when using a `chef-client` after the client has been validated and authorized to connect to the server.

Beware if using this on your Chef Server. First copy the validation.pem certificate file to another location, such as your knife configuration directory (`~/.chef`) or [Chef Repository](http://wiki.opscode.com/display/chef/Chef+Repository).

cron
----

Use this recipe to run chef-client as a cron job rather than as a
service. The cron job runs after random delay that is between 0 and 90
seconds to ensure that the chef-clients don't attempt to connect to
the chef-server at the exact same time. You should set
node["chef_client"]["init_style"] = "none" when you use this mode but
it is not required.



USAGE
=====

Create a `base` role that will represent the base configuration for any system that includes managing aspects of the chef-client. Add recipes to the run list of the role, customize the attributes, and apply the role to nodes. For example, the following role (Ruby DSL) will set the init style to `init`, delete the validation certificate (as the client would already be authenticated) and set up the chef-client as a service using the init style.

    name "base"
    description "Base role applied to all nodes"
    override_attributes(
      "chef_client" => {
        "init_style" => "init"
      }
    )
    run_list(
      "recipe[chef-client::delete_validation]",
      "recipe[chef-client::config]",
      "recipe[chef-client::service]"
    )

The `chef-client::config` recipe is only required with init style `init` (default setting for the attribute on debian/redhat family platforms, because the init script doesn't include the `pid_file` option which is set in the config.

The default Chef Server will be `http://localhost:4000` which is the `Chef::Config[:chef_server_url]` default value. To use the config recipe with the Opscode Platform, for example, add the following to the `override_attributes`

    override_attributes(
      "chef_client" => {
        "server_url" => "https://api.opscode.com/organizations/ORGNAME",
        "validation_client_name" => "ORGNAME-validator"
      }
    )

Where ORGNAME is your Opscode Platform organization name. Be sure to add these attributes to the role if modifying per the section below.

You can also set all of the `Chef::Config` http proxy related settings.  By default Chef will not use a proxy.

    override_attributes(
      "chef_client" => {
        "http_proxy" => "http://proxy.vmware.com:3128",
        "https_proxy" => "http://proxy.vmware.com:3128",
        "http_proxy_user" => "my_username",
        "http_proxy_pass" => "Awe_some_Pass_Word!",
        "no_proxy" => "*.vmware.com,10.*"
      }
    )

Alternate Init Styles
---------------------

The alternate init styles available are:

* runit
* bluepill
* daemontools
* none -- should be specified if you are running chef-client as cron job

For usage, see below.

# Runit

To use runit, download the cookbook from the cookbook site.

    knife cookbook site vendor runit -d

Change the `init_style` to runit in the base role and add the runit recipe to the role's run list:

    name "base"
    description "Base role applied to all nodes"
    override_attributes(
      "chef_client" => {
        "init_style" => "runit"
      }
    )
    run_list(
      "recipe[chef-client::delete_validation]",
      "recipe[runit]",
      "recipe[chef-client]"
    )

The `chef-client` recipe will create the chef-client service configured with runit. The runit run script will be located in `/etc/sv/chef-client/run`. The output log will be in the runit service directory, `/etc/sv/chef-client/log/main/current`.

# Bluepill

To use bluepill, download the cookbook from the cookbook site.

    knife cookbook site vendor bluepill -d

Change the `init_style` to runit in the base role and add the bluepill recipe to the role's run list:

    name "base"
    description "Base role applied to all nodes"
    override_attributes(
      "chef_client" => {
        "init_style" => "bluepill"
      }
    )
    run_list(
      "recipe[chef-client::delete_validation]",
      "recipe[bluepill]",
      "recipe[chef-client]"
    )

The `chef-client` recipe will create the chef-client service configured with bluepill. The bluepill "pill" will be located in `/etc/bluepill/chef-client.pill`. The output log will be to client.log file in the `node["chef_client"]["log_dir"]` location, `/var/log/chef/client` by default.

# Daemontools

To use daemontools, download the cookbook from the cookbook site.

    knife cookbook site vendor daemontools -d

Change the `init_style` to runit in the base role and add the daemontools recipe to the role's run list:

    name "base"
    description "Base role applied to all nodes"
    override_attributes(
      "chef_client" => {
        "init_style" => "daemontools"
      }
    )
    run_list(
      "recipe[chef-client::delete_validation]",
      "recipe[daemontools]",
      "recipe[chef-client]"
    )

The `chef-client` recipe will create the chef-cilent service configured under daemontools. It uses the same sv run scripts as the runit recipe. The run script will be located in `/etc/sv/chef-client/run`. The output log will be in the daemontools service directory, `/etc/sv/chef-client/log/main/current`.

Templates
=========

chef-client.pill.erb
--------------------

Bluepill configuration for the chef-client service.

client.rb.erb
-------------

Configuration for the client, lands in directory specified by `node["chef_client"]["conf_dir"]` (`/etc/chef/client.rb` by default).

`sv-chef-client-*run.erb`
-------------------------

Runit and Daemontools run script for chef-client service and logs.

Logs will be located in the `node["chef_client"]["log_dir"]`.

License and Author
==================

Author:: Joshua Timberman (<joshua@opscode.com>)
Author:: Seth Chisamore (<schisamo@opscode.com>)
Copyright:: 2010-2011, Opscode, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and

Description
===========

Requirements
============

Attributes
==========

Usage
=====


# CHANGELOG for class2go-apache-restart

This file is used to list changes made in each version of class2go-apache-restart.

## 0.1.0:

* Initial release of class2go-apache-restart

- - - 
Check the [Markdown Syntax Guide](http://daringfireball.net/projects/markdown/syntax) for help with Markdown.

The [Github Flavored Markdown page](http://github.github.com/github-flavored-markdown/) describes the differences between markdown on github and standard markdown.

Description
===========

Requirements
============

Attributes
==========

Usage
=====


Just does an apt-get update

Description
===========

Requirements
============

Attributes
==========

Usage
=====


Description
===========

Requirements
============

Attributes
==========

Usage
=====



Description
===========

Requirements
============

Attributes
==========

Usage
=====


Description
===========

Requirements
============

Attributes
==========

Usage
=====


class2go-database-setup Cookbook
================================

call "manage.py createcachetable grader_cache"

Description
===========

Requirements
============

Attributes
==========

Usage
=====


Description
===========

Requirements
============

Attributes
==========

Usage
=====


Description
===========

Requirements
============

Attributes
==========

Usage
=====


Description
===========

Requirements
============

Attributes
==========

Usage
=====


Description
===========

Requirements
============

Attributes
==========

Usage
=====


django-storages Patch: s3boto_response_header_issue70.patch
===========================================================

We need to apply this patch to the s3boto.py file to allow for the
specification of response headers for S3 file URLs. This feature
then allows us to generate S3 URL download links that will start
download upon user click, rather than opening the file in a different
window. The patch simply adds a response_headers argument to the
url method of the S3BotoStorage class, and the associated boto
generate_url call (which already supports response_headers).

The patch contents have been copied into the recipe file.  So 
if this is being modified, make sure to also update 
    class2go-python/recipes/default.rb


Top apply the patch manually...
------------------
See instructions [here][1].
  [1]: https://github.com/Stanford-Online/class2go/issues/70#issuecomment-7840569

Description
===========

Requirements
============

Attributes
==========

Usage
=====


Description
===========

Requirements
============

Attributes
==========

Usage
=====


We distribute ffmpeg ourselves since we need a version linked with the libx264 codec.
Compiled on Ubuntu 12.4 LTS machine, rough instructions like this:


git clone git://git.videolan.org/x264.git
cd x264
./configure --enable-static --prefix=/usr/local
make && make install


git clone git://git.videolan.org/ffmpeg.git 
cd ffmpeg
./configure --enable-libx264 --enable-gpl --prefix=/usr/local
make 



To install on a mac, use "brew install ffmpeg"

## v1.0.0:

* [COOK-852] - Support "pkg" in addition to "mpkg" package types

## v0.7.0:

* [COOK-854] - use `cp -R` instead of `cp -r`
* [COOK-855] - specify a file or directory to check for prior install

## v0.6.0:

* option to install software that is an .mpkg inside a .dmg
* ignore failure on chmod in case mode is already set, or is root owned

Description
===========

Lightweight resource and provider to install OS X applications (.app) from dmg files.

Requirements
============

## Platform:

* Mac OS X

Resources and Providers
=======================

dmg\_package
------------

This resource will install a DMG "Package". It will retrieve the DMG from a remote URL, mount it using OS X's `hdid`, copy the application (.app directory) to the specified destination (/Applications), and detach the image using `hdiutil`. The dmg file will be stored in the `Chef::Config[:file_cache_path]`. If you want to install an application that has already been downloaded (not using the `source` parameter), copy it to the appropriate location. You can find out what directory this is with the following command on the node to run chef:

    knife exec -E 'p Chef::Config[:file_cache_path]' -c /etc/chef/client.rb

Optionally, the LWRP can install an "mpkg" or "pkg" package using installer(8).

# Actions:

* :install - Installs the application.

# Parameter attributes:

* `app` - This is the name of the application used by default for the /Volumes directory and the .app directory copied to /Applications.
* `source` - remote URL for the dmg to download if specified. Default is nil.
* `destination` - directory to copy the .app into. Default is /Applications.
* `checksum` - sha256 checksum of the dmg to download. Default is nil.
* `type` - type of package, "app", "pkg" or "mpkg". Default is "app". When using "pkg" or "mpkg", the destination must be /Applications.
* `volumes_dir` - Directory under /Volumes where the dmg is mounted. Not all dmgs are mounted into a /Volumes location matching the name of the dmg. If not specified, this will use the name attribute.
* `package_id` - Package id registered with pkgutil when a pkg or mpkg is installed
* `dmg_name` - Specify the name of the dmg if it is not the same as `app`, or if the name has spaces.
* `dmg_passphrase` - Specify a passphrase to use to unencrypt the dmg while mounting.
* `accept_eula` - Specify whether to accept the EULA.  Certain dmgs require acceptance of EULA before mounting.  Can be true or false, defaults to false.

Usage Examples
==============

Install `/Applications/Tunnelblick.app` from the primary download site.

    dmg_package "Tunnelblick" do
      source "http://tunnelblick.googlecode.com/files/Tunnelblick_3.1.2.dmg"
      checksum "a3fae60b6833175f32df20c90cd3a3603a"
      action :install
    end

Install Google Chrome. Uses the `dmg_name` because the application name has spaces. Installs in `/Applications/Google Chrome.app`.

    dmg_package "Google Chrome" do
      dmg_name "googlechrome"
      source "https://dl-ssl.google.com/chrome/mac/stable/GGRM/googlechrome.dmg"
      checksum "7daa2dc5c46d9bfb14f1d7ff4b33884325e5e63e694810adc58f14795165c91a"
      action :install
    end

Install Dropbox. Uses `volumes_dir` because the mounted directory is different than the name of the application directory. Installs in `/Applications/Dropbox.app`.

    dmg_package "Dropbox" do
      volumes_dir "Dropbox Installer"
      source "http://www.dropbox.com/download?plat=mac"
      checksum "b4ea620ca22b0517b75753283ceb82326aca8bc3c86212fbf725de6446a96a13"
      action :install
    end

Install MacIrssi to `~/Applications` from the local file downloaded to the cache path into an Applications directory in the current user's home directory. Chef should run as a non-root user for this.

    directory "#{ENV['HOME']}/Applications"

    dmg_package "MacIrssi" do
      destination "#{ENV['HOME']}/Applications"
      action :install
    end

Install Virtualbox to `/Applications` from the .mpkg:

    dmg_package "Virtualbox" do
      source "http://dlc.sun.com.edgesuite.net/virtualbox/4.0.8/VirtualBox-4.0.8-71778-OSX.dmg"
      type "mpkg"
    end

Install pgAdmin to `/Applications` and automatically accept the EULA:

    dmg_package "pgAdmin3" do
      source "http://wwwmaster.postgresql.org/redir/198/h/pgadmin3/release/v1.12.3/osx/pgadmin3-1.12.3.dmg"
      checksum "9435f79d5b52d0febeddfad392adf82db9df159196f496c1ab139a6957242ce9"
      accept_eula true
    end

Install Pivotal Tracker to `/Applications` using a password-protected dmg:

    dmg_package "Pivotal Tracker" do
      volumes_dir "tracker"
      source "http://cheffiles.pivotallabs.com/fluid_tracker.dmg"
      dmg_passphrase  "xyz"
    end

Install Silverlight, with idempotence check based on pkgutil:

    dmg_package "Silerlight" do
      source "http://silverlight.dlservice.microsoft.com/download/D/C/2/DC2D5838-9138-4D25-AA92-52F61F7C51E6/runtime/Silverlight.dmg"
      type "pkg"
      checksum "6d4a0ad4552d9815531463eb3f467fb8cf4bffcc"
      package_id "com.microsoft.installSilverlightPlugin"
    end

To do
=====

A few things remain outstanding to make this cookbook "1.0" quality.

* support downloading a .dmg.zip and unzipping it
* specify a local .dmg already downloaded in another location (like ~/Downloads)

Some things that would be nice to have at some point.

* use hdiutil to mount/attach the disk image
* automatically detect the `volumes_dir` where the image is attached
* be able to automatically accept license agreements

License and Author
==================

* Copyright 2011, Joshua Timberman <cookbooks@housepub.org>

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

gdata Patch: ytservice_file_len.patch
=====================================

We need to apply this patch to the youtube/service.py file in order
for video uploads to youtube to work. The patch modifies one line in
the function InsertVideoEntry which accesses the content length of
the uploaded file using the wrong attribute len, to use the correct
attribute size.	  

The updated gdata package with the patched file gdata-2.0.17-c2g.tar.gz
is what the recipe uses.

To apply the patch manually...
-------------------
Go to your python packages to your gdata/youtube directory. This is
where the service.py we are patching is located. The path will look
like /path/to/site-packages/gdata/youtube/

Once you are in this directory, run the following command, supplying
your patch's location:  
sudo patch < /path/to/ytservice_file_len.patch

You can reverse the patch by running the same command with the -R
option:  
sudo patch -R < /path/to/ytservice_file_len.patch

Your patch should now be applied to allow YouTube uploads to work.

Description
===========

Install the Google client for Google Data.  We copy version 2.0.17 in here for good measure.  For more info, see the project page at [http://code.google.com/p/gdata-python-client/].


## v1.0.0:

* [COOK-1152] - Add support for Mac OS X
* [COOK-1112] - Add support for Windows

## v0.10.0:

* [COOK-853] - Git client installation on CentOS

## v0.9.0:

* Current public release.

Description
===========

Installs git and optionally sets up a git server as a daemon under runit.

Requirements
============

## Platform:

* Debian/Ubuntu
* ArchLinux

## Cookbooks:

* runit

Usage
=====

This cookbook primarily installs git core packages. It can also be
used to serve git repositories.

    include_recipe "git::server"

This creates the directory /srv/git and starts a git daemon, exporting
all repositories found. Repositories need to be added manually, but
will be available once they are created.

License and Author
==================

Author:: Joshua Timberman (<joshua@opscode.com>)

Copyright:: 2009, Opscode, Inc

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

This directory contains the cookbooks used to configure systems in your infrastructure with Chef.

Knife needs to be configured to know where the cookbooks are located with the `cookbook_path` setting. If this is not set, then several cookbook operations will fail to work properly.

    cookbook_path ["./cookbooks"]

This setting tells knife to look for the cookbooks directory in the present working directory. This means the knife cookbook subcommands need to be run in the `chef-repo` directory itself. To make sure that the cookbooks can be found elsewhere inside the repository, use an absolute path. This is a Ruby file, so something like the following can be used:

    current_dir = File.dirname(__FILE__)
    cookbook_path ["#{current_dir}/../cookbooks"]

Which will set `current_dir` to the location of the knife.rb file itself (e.g. `~/chef-repo/.chef/knife.rb`).

Configure knife to use your preferred copyright holder, email contact and license. Add the following lines to `.chef/knife.rb`.

    cookbook_copyright "Example, Com."
    cookbook_email     "cookbooks@example.com"
    cookbook_license   "apachev2"

Supported values for `cookbook_license` are "apachev2", "mit","gplv2","gplv3",  or "none". These settings are used to prefill comments in the default recipe, and the corresponding values in the metadata.rb. You are free to change the the comments in those files.

Create new cookbooks in this directory with Knife.

    knife cookbook create COOKBOOK

This will create all the cookbook directory components. You don't need to use them all, and can delete the ones you don't need. It also creates a README file, metadata.rb and default recipe.

You can also download cookbooks directly from the Opscode Cookbook Site. There are two subcommands to help with this depending on what your preference is.

The first and recommended method is to use a vendor branch if you're using Git. This is automatically handled with Knife.

    knife cookbook site install COOKBOOK

This will:

* Download the cookbook tarball from cookbooks.opscode.com.
* Ensure its on the git master branch.
* Checks for an existing vendor branch, and creates if it doesn't.
* Checks out the vendor branch (chef-vendor-COOKBOOK).
* Removes the existing (old) version.
* Untars the cookbook tarball it downloaded in the first step.
* Adds the cookbook files to the git index and commits.
* Creates a tag for the version downloaded.
* Checks out the master branch again.
* Merges the cookbook into master.
* Repeats the above for all the cookbooks dependencies, downloading them from the community site

The last step will ensure that any local changes or modifications you have made to the cookbook are preserved, so you can keep your changes through upstream updates.

If you're not using Git, use the site download subcommand to download the tarball.

    knife cookbook site download COOKBOOK

This creates the COOKBOOK.tar.gz from in the current directory (e.g., `~/chef-repo`). We recommend following a workflow similar to the above for your version control tool.

## v0.15.0:

* [COOK-1008] - Added parameters for names of different templates in runit

Description
===========

Installs runit and provides `runit_service` definition for managing new
services under runit.

This cookbook does not use runit to replace system init, nor are there
plans to do so.

For more information about runit:

* http://smarden.org/runit/

Requirements
============

## Platform:

* Debian/Ubuntu
* Gentoo

Attributes
==========

See `attributes/default.rb` for defaults.

* `node['runit']['sv_bin']` - Full path to the `sv` binary.
* `node['runit']['chpst_bin']` - Full path to the `chpst` binary.
* `node['runit']['service_dir']` - Full path to the default "services"
  directory where enabled services are linked.
* `node['runit']['sv_dir']` - Full path to the directory where the
  service lives, which gets linked to `service_dir`.

Recipes
=======

default
-------

Installs and sets up runit on the system. Assumes a package
installation, so native package must exist. This recipe will make sure
that the runsvdir process gets started, ensures that inittab is
updated with the SV entry. The package will be preseeded on
ubuntu/debian signal init, otherwise the appropriate action is chosen
to notify the runsvdir command.

Older versions of Ubuntu (<= 10.04) are supported, but support may be
removed in a future version.

Definitions
===========

The definition in this cookbook will be deprecated by an LWRP in a
future version. See __Roadmap__.

runit\_service
--------------

This definition includes `recipe[runit]` to ensure it is installed
first. As LWRPs cannot use `include_recipe`, this will not be
available in future versions, so runit will need to be in a role or
node run list.

Sets up a new service to be managed and supervised by runit. It will
be created in the `node['runit']['sv_dir']` unless otherwise specified
in the `directory` parameter (see below).

### Parameters:

* `name` - Name of the service. This will be used in the template file
  names (see __Usage__), as well as the name of the service resource
  created in the definition.
* `directory` - the directory where the service's configuration and
  scripts should be located. Default is `node['runit']['sv_dir']`.
* `only_if` - unused, will be removed in a future version (won't be
  present in lwrp). Default is false.
* `finish_script` - if true, a finish script should be created.
  Default is false. For more information see: [Description of runsv](http://smarden.org/runit/runsv.8.html).
* `control` - Array of signals to create a control directory with
  control scripts (e.g., `sv-SERVICE-control-SIGNAL.erb`, where
  SERVICE is the name parameter for the service name, and SIGNAL is
  the Unix signal to send. Default is an empty array. For more
  information see:
  [Customize Control](http://smarden.org/runit/runsv.8.html)
* `run_restart` - if true, the service resource will subscribe to
  changes to the run script and restart itself when it is modified.
  Default is true.
* `active_directory` - used for user-specific services. Default is
  `node['runit']['service_dir']`.
* `owner` - userid of the owner for the service's files, and should be
  used in the run template with chpst to ensure the service runs as
  that user. Default is root.
* `group` - groupid of the group for the service's files, and should
  be used in the run template with chpst to ensure the service runs as
  that group. Default is root.
* `template_name` - specify an alternate name for the templates
  instead of basing them on the name parameter. Default is the name parameter.
* `log_template_name` - specify an alternate name for the runit log template
  instead of basing them on the template_name parameter. Default is the
  template_name parameter.
* `control_template_names` - specify alternate names for runit control signal
  templates instead of basing them on the template_name parameter. Default
  is the template_name parameter.
* `finish_script_template_name` - specify an altername for the finish script
  template. Default is the template_name parameter
* `start_command` - The command used to start the service in
  conjunction with the `sv` command and the `service_dir` name.
  Default is `start`.
* `stop_command` - The command used to stop the service in conjunction
  with the `sv` command and the `service_dir` name. Default is `stop`.
* `restart_command` - The command used to restart the service in
  conjunction with the `sv` command and the `service_dir` name.  You
  may need to modify this to send an alternate signal to restart the
  service depending on the nature of the process. Default is `restart`
* `status_command` - The command used to check status for the service in
  conjunction with the `sv` command and the `service_dir` name. This
  is used by chef when checking the current resource state in managing
  the service. Default is `status`.
* `options` - a Hash of variables to pass into the run and log/run
  templates with the template resource `variables` parameter.
  Available inside the template(s) as `@options`. Default is an empty Hash.
* `env` -

### Examples:

Create templates for `sv-myservice-run.erb` and
`sv-myservice-log-run.erb` that have the commands for starting
myservice and its logger.

    runit_service "myservice"

See __Usage__ for expanded examples.

Resources/Providers
===================

None yet. See __Roadmap__.

Usage
=====

To get runit installed on supported platforms, use `recipe[runit]`.
Once it is installed, use the `runit_service` definition to set up
services to be managed by runit. Do note that once
[CHEF-154](http://tickets.opscode.com/browse/CHEF-154) is implemented,
some of the usage/implementation here will change. In order to use the
`runit_service` definition, two templates must be created for the
service, `cookbook_name/templates/default/sv-SERVICE-run.erb` and
`cookbook_name/templates/default/sv-SERVICE-log-run.erb`. Replace
`SERVICE` with the name of the service you're managing. For more usage,
see __Examples__.

Examples
--------

We'll set up `chef-client` to run as a service under runit, such as is
done in the `chef-client` cookbook. This example will be more simple
than in that cookbook. First, create the required run template,
`chef-client/templates/default/sv-chef-client-run.erb`.

    #!/bin/sh
    exec 2>&1
    exec /usr/bin/env chef-client -i 1800 -s 30

Then create the required log/run template,
`chef-client/templates/default/sv-chef-client-run.erb`.

    #!/bin/sh
    exec svlogd -tt ./main

__Note__ This will cause output of the running process to go to
`/etc/sv/chef-client/log/main/current`.

Finally, set up the service in the `chef-client` recipe with:

    runit_service "chef-client"

Next, let's set up memcached with some additional options. First, the
`memcached/templates/default/sv-memcached-run.erb` template:

    #!/bin/sh
    exec 2>&1
    exec chpst -u <%= @options[:user] %> /usr/bin/memcached -v -m <%= @options[:memory] %> -p <%= @options[:port] %>

Note that the script uses chpst (which comes with runit) to set the
user option, then starts memcached on the specified memory and port
(see below).

The log/run template,
`memcached/templates/default/sv-memcached-log-run.erb`:

    #!/bin/sh
    exec svlogd -tt ./main

Finally, the `runit_service` in our recipe:

    runit_service "memcached" do
      options({
        :memory => node[:memcached][:memory],
        :port => node[:memcached][:port],
        :user => node[:memcached][:user]}.merge(params)
      )
    end

This is where the user, port and memory options used in the run
template are used.

License and Author
==================

Author:: Adam Jacob <adam@opscode.com>
Author:: Joshua Timberman <joshua@opscode.com>

Copyright:: 2008-2011, Opscode, Inc

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

Description
===========

Requirements
============

Attributes
==========

Usage
=====


Description
===========

Requirements
============

Attributes
==========

Usage
=====


# CHANGELOG for shib

This file is used to list changes made in each version of shib.

## 0.1.0:

* Initial release of shib

- - - 
Check the [Markdown Syntax Guide](http://daringfireball.net/projects/markdown/syntax) for help with Markdown.

The [Github Flavored Markdown page](http://github.github.com/github-flavored-markdown/) describes the differences between markdown on github and standard markdown.

Description
===========

Requirements
============

Attributes
==========

Usage
=====


## v0.6.2:

* Updated README to remove git diff artifacts.

## v0.6.0:

* Default action for the yum_repository LWRP is now add.
* [COOK-1227] - clear Chefs internal cache after adding new yum repo
* [COOK-1262] - yum::epel should enable existing repo on Amazon Linux
* [COOK-1272], [COOK-1302] - update RPM file for CentOS / RHEL 6
* [COOK-1330] - update cookbook documentation on excludes for yum
* [COOK-1346] - retry remote_file for EPEL in case we get an FTP mirror


## v0.5.2:

* [COOK-825] - epel and ius `remote_file` should notify the `rpm_package` to install

## v0.5.0:

* [COOK-675] - add recipe for handling EPEL repository
* [COOK-722] - add recipe for handling IUS repository

## v.0.1.2:

* Remove yum update in default recipe, that doesn't update caches, it updates packages installed.

# Description

Configures various YUM components on Red Hat-like systems.  Includes
LWRP for managing repositories and their GPG keys.

Based on the work done by Eric Wolfe and Charles Duffy on the
[yumrepo](https://github.com/atomic-penguin/cookbook-yumrepo) cookbook.

# Requirements

RedHat Enterprise Linux 5, and 6 distributions within this platform family.

# Attributes

* `yum['exclude']`
    - An array containing a list of packages to exclude from updates or
      installs.  Wildcards and shell globs are supported.
    - Defaults to an empty exclude list.

* `yum['installonlypkgs']`
    - An array containing a list of packages which should only be
      installed, never updated.
    - Defaults to an empty install-only list.

* `yum['epel_release']`
    - Set the epel release version based on `node['platform_version']`.
    - Defaults to the most current release of EPEL, based on the major
      version of your platform release.

* `yum['ius_release']`
    - Set the IUS release to install.
    - Defaults to the current release of the IUS repo.

# Recipes

## default

The default recipe does nothing.

## yum

Manages the configuration of the `/etc/yum.conf` via attributes.  See
the aforementioned Array attributes `yum['exclude']` and
`yum['installonlypkgs']`.

## epel

Installs the EPEL repository via RPM. Uses the `yum['epel_release']`
attribute to select the right version of the repository package to
install. Also uses the node's platform version (as an integer) for the
major release of EL.

On Amazon Linux, the built-in EPEL repository is activated using
`yum-config-manager --quiet --enable epel`. This ignores the
`node['yum']['epel_release']` attribute in favor of the version
configured in the Amazon Linux AMI.

## ius

Installs the [IUS Community repositories](http://iuscommunity.org/Repos)
via RPM. Uses the `node['yum']['ius_release']` attribute to select the
right versino of the package to install.

The IUS repository requires EPEL, and includes `yum::epel` as a
dependency.

# Resources/Providers

## key

This LWRP handles importing GPG keys for YUM repositories. Keys can be
imported by the `url` parameter or placed in `/etc/pki/rpm-gpg/` by a
recipe and then installed with the LWRP without passing the URL.

### Actions

- :add: installs the GPG key into `/etc/pki/rpm-gpg/`
- :remove: removes the GPG key from `/etc/pki/rpm-gpg/`

#### Attribute Parameters

- key: name attribute. The name of the GPG key to install.
- url: if the key needs to be downloaded, the URL providing the download.

#### Example

``` ruby
# add the Zenoss GPG key
yum_key "RPM-GPG-KEY-zenoss" do
  url "http://dev.zenoss.com/yum/RPM-GPG-KEY-zenoss"
  action :add
end
    
# remove Zenoss GPG key
yum_key "RPM-GPG-KEY-zenoss" do
  action :remove
end
```

### repository

This LWRP provides an easy way to manage additional YUM repositories.
GPG keys can be managed with the `key` LWRP.  The LWRP automatically
updates the package management cache upon the first run, when a new
repo is added.

#### Actions

- :add: creates a repository file and builds the repository listing
- :remove: removes the repository file

#### Attribute Parameters

- repo_name: name attribute. The name of the channel to discover
- description. The description of the repository
- url: The URL providing the packages
- mirrorlist: Default is `false`,  if `true` the `url` is considered a list of mirrors
- key: Optional, the name of the GPG key file installed by the `key` LWRP.

- enabled: Default is `1`, set to `0` if the repository is disabled.
- type: Optional, alternate type of repository
- failovermethod: Optional, failovermethod
- bootstrapurl: Optional, bootstrapurl

### Example

``` ruby
# add the Zenoss repository
yum_repository "zenoss" do
  name "Zenoss Stable repo"
  url "http://dev.zenoss.com/yum/stable/"
  key "RPM-GPG-KEY-zenoss"
  action :add
end
    
# remove Zenoss repo
yum_repository "zenoss" do
  action :remove
end
```

# Usage

Put `recipe[yum::yum]` in the run list to ensure yum is configured
correctly for your environment within your Chef run.

Use the `yum::epel` recipe to enable EPEL, or the `yum::ius` recipe to
enable IUS, per __Recipes__ section above.

You can manage GPG keys either with cookbook_file in a recipe if you
want to package it with a cookbook or use the `url` parameter of the
`key` LWRP.

# License and Author

Author:: Eric G. Wolfe
Author:: Matt Ray (<matt@opscode.com>)
Author:: Joshua Timberman (<joshua@opscode.com>)

Copyright:: 2010 Tippr Inc.
Copyright:: 2011 Eric G. Wolfe
Copyright:: 2011 Opscode, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

Data Bags
---------

This directory contains directories of the various data bags you create for your infrastructure. Each subdirectory corresponds to a data bag on the Chef Server, and contains JSON files of the items that go in the bag.

First, create a directory for the data bag.

    mkdir data_bags/BAG

Then create the JSON files for items that will go into that bag.

    $EDITOR data_bags/BAG/ITEM.json

The JSON for the ITEM must contain a key named "id" with a value equal to "ITEM". For example,

    {
      "id": "foo"
    }

Next, create the data bag on the Chef Server.

    knife data bag create BAG

Then upload the items in the data bag's directory to the Chef Server.

    knife data bag from file BAG ITEM.json


Encrypted Data Bags
-------------------

Added in Chef 0.10, encrypted data bags allow you to encrypt the contents of your data bags. The content of attributes will no longer be searchable. To use encrypted data bags, first you must have or create a secret key.

    openssl rand -base64 512 > secret_key

You may use this secret_key to add items to a data bag during a create.

    knife data bag create --secret-file secret_key passwords mysql

You may also use it when adding ITEMs from files,

    knife data bag create passwords
    knife data bag from file passwords data_bags/passwords/mysql.json --secret-file secret_key

The JSON for the ITEM must contain a key named "id" with a value equal to "ITEM" and the contents will be encrypted when uploaded. For example,

    {
      "id": "mysql",
      "password": "abc123"
    }

Without the secret_key, the contents are encrypted.

    knife data bag show passwords mysql
    id:        mysql
    password:  2I0XUUve1TXEojEyeGsjhw==

Use the secret_key to view the contents.

    knife data bag show passwords mysql --secret-file secret_key
    id:        mysql
    password:  abc123


Class2Go Environments file.  This is where we store anything
configuration bits.

Because we store our secrets in these files, we can't check them
into GitHub.

    DO NOT CHECK IN THE ENVIRONMENT FILES
    THEY HAVE OUR SECRET GOODIES IN THEM!

They must be stored out of band.  For information how to get these
files set up correctly, read the [Software Release Process] [reldoc]
doc in our Google Docs shared folder (actually, in the ops subfolder).

    [reldoc]: https://docs.google.com/document/d/1Ij5dR9E-cUhxOJlOcrWfv_kiXpIfgNOzSYLm79UCOjg/edit#

To get you started, look at the example environment files are checked
in here: ```example-stage.rb``` and ```example-prod.rb```.


Overview
========

Chef repository for managing Class2Go staging and production.


Repository Directories
======================

This repository contains several directories, and each directory contains a README file that describes what it is for in greater detail, and how to use it for managing your systems with Chef.

* `certificates/` - SSL certificates generated by `rake ssl_cert` live here.
* `config/` - Contains the Rake configuration file, `rake.rb`.
* `cookbooks/` - Cookbooks you download or create.
* `data_bags/` - Store data bags and items in .json in the repository.
* `roles/` - Store roles in .rb or .json in the repository.


Rake Tasks
==========

The repository contains a `Rakefile` that includes tasks that are installed with the Chef libraries. To view the tasks available with in the repository with a brief description, run `rake -T`.

The default task (`default`) is run when executing `rake` with no arguments. It will call the task `test_cookbooks`.

The following tasks are not directly replaced by knife sub-commands.

* `bundle_cookbook[cookbook]` - Creates cookbook tarballs in the `pkgs/` dir.
* `install` - Calls `update`, `roles` and `upload_cookbooks` Rake tasks.
* `ssl_cert` - Create self-signed SSL certificates in `certificates/` dir.
* `update` - Update the repository from source control server, understands git and svn.

The following tasks duplicate functionality from knife and may be removed in a future version of Chef.

* `metadata` - replaced by `knife cookbook metadata -a`.
* `new_cookbook` - replaced by `knife cookbook create`.
* `role[role_name]` - replaced by `knife role from file`.
* `roles` - iterates over the roles and uploads with `knife role from file`.
* `test_cookbooks` - replaced by `knife cookbook test -a`.
* `test_cookbook[cookbook]` - replaced by `knife cookbook test COOKBOOK`.
* `upload_cookbooks` - replaced by `knife cookbook upload -a`.
* `upload_cookbook[cookbook]` - replaced by `knife cookbook upload COOKBOOK`.

Configuration
=============

The repository uses two configuration files.

* config/rake.rb
* .chef/knife.rb

The first, `config/rake.rb` configures the Rakefile in two sections.

* Constants used in the `ssl_cert` task for creating the certificates.
* Constants that set the directory locations used in various tasks.

If you use the `ssl_cert` task, change the values in the `config/rake.rb` file appropriately. These values were also used in the `new_cookbook` task, but that task is replaced by the `knife cookbook create` command which can be configured below.

The second config file, `.chef/knife.rb` is a repository specific configuration file for knife. If you're using the Opscode Platform, you can download one for your organization from the management console. If you're using the Open Source Chef Server, you can generate a new one with `knife configure`. For more information about configuring Knife, see the Knife documentation.

http://help.opscode.com/faqs/chefbasics/knife

Next Steps
==========

Read the README file in each of the subdirectories for more information about what goes in those directories.

Create roles here, in either the Role Ruby DSL (.rb) or JSON (.json) files. To install roles on the server, use knife.

For example, create `roles/base_example.rb`:

    name "base_example"
    description "Example base role applied to all nodes."
    # List of recipes and roles to apply. Requires Chef 0.8, earlier versions use 'recipes()'.
    #run_list()
    # Attributes applied if the node doesn't have it set already.
    #default_attributes()
    # Attributes applied no matter what the node has set already.
    #override_attributes()

Then upload it to the Chef Server:
    
    knife role from file roles/base_example.rb

Place to put project docs.

Edit CSS Style plug-in notes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Unlike WYSIWYG editor functionality that operates only on the selected text,
typically by inserting new HTML elements with the specified styles.
This plug-in operates on the HTML blocks surrounding the selected text.
No new HTML elements are created.

This plug-in only operates on the surrounding blocks and not the nearest
parent node.  This means that if a block encapsulates a node,
e.g <p><span>text</span></p>, then only the styles in the block are
recognized, not those in the span.

When selecting text that includes multiple blocks at the same level (peers),
this plug-in accumulates the specified styles in all of the surrounding blocks
and populates the dialogue checkboxes accordingly.  There is no differentiation
between styles set in all the blocks versus styles set in some of the blocks.

When the [Update] or [Apply] buttons are pressed, the styles selected in the
checkboxes are applied to all blocks that surround the selected text.

Simple Smileys is a set of 49 clean, free as in freedom, Public Domain smileys.
For more packages or older versions, visit http://simplesmileys.org

This is an evolution from the tool originally written by Kelvin Do
for generating a set of thumbnails from a video for navigation.  It
has evolved from a command line tool to a celery-dispatched service.

Requires
- PIL
- ffmpeg



Requirements
------------
PDFKit has a number of system-level dependencies to work correctly:
 - wkhtmltopdf
 - libicu
 - an xserver

On a Debian-family Linux such as Ubuntu, the easiest way to get these is to run 
  sudo apt-get install wkhtmltopdf xvfb libicu-dev libicu48

Running
-------
To run successfully, wkhtmltopdf needs a running X server. If you're already
running Linux on your desktop, congratulations. If not, you'll need to start
one. In a headless environment like AWS, the easiest way to get an X server
is with xvfb.

The following is not guaranteed to work, but has been tested to run ok on
Ubuntu 12.04 AWS images as of March 2013:

    Xvfb :0 -fp /usr/share/X11/fonts/misc -screen 0 1280x1024x24 
    export DISPLAY=:0.0
    ./manage.py issue_certificate_multi <course_handle> <no_certs_file> <certification_conditions_file>

The important idea is that the DISPLAY variable should point to the display
handle of a running X instance before you invoke manage.py.

This directory is left over from early in the project and isn't being maintained.

Class2Go 
========

[![Build Status](https://travis-ci.org/Stanford-Online/class2go.png?branch=master)](https://travis-ci.org/Stanford-Online/class2go)

Class2Go is Stanford's internal open-source platform for on-line
education. A team of eight built the first version over Summer 2012.
Class2Go launched Fall 2012 and since then we've hosted several
"massive open online courses" (MOOC's) and on-campus classes.  The
big MOOC's we hosted were [Computer Networking][net] and [Solar
Cells, Fuel Cells, and Batteries][sol] in Fall 2012, and [Introduction
to Databases][db] in Winter 2013.
  [net]: http://networking.class.stanford.edu/
  [sol]: http://solar.class.stanford.edu/
  [db]: http://db.class2go.stanford.edu/

**On April 3rd [we announced][ann-s] that Class2Go is merging with
the edX platform.  The Stanford Online engineering team is now
working on the edX code base with the goal of standing up our own
instance and using it for Stanford MOOC's, on-campus classes,
distance learners, and educational research.  EdX will be released
under the AGPL open-source license by June 1st.**

**The Class2Go project is in maintenance mode.  For more information, 
see the [announcement][ann-f] on the Class2Go Forum.**
  [ann-s]: http://news.stanford.edu/news/2013/april/edx-collaborate-platform-030313.html
  [ann-f]: https://groups.google.com/forum/?fromgroups=#!topic/class2go-users/lPGL4R74HPE

----------------------------------------------------------------

Class2Go was built to be an open platform for learning and research.
Professors have access to the classes' data to learn how their
students learn. We will facilitate experiments.  For example, we
intend this to be the best plaform for running A/B/N tests to measure
the impact of different teaching methods on student outcomes, or
to build interesting features to try out new ways of presenting
material or grading exercises.  We believe an open source platform
is the best way to do this.

For community support of c2g users, we have a Google group at
https://groups.google.com/forum/#!forum/class2go-users.

If you are interested in reaching the team email us at 
<c2g-contact@class.stanford.edu>.

If you are interested in evaluating the Class2Go platform, you can explore Class2Go
through two courses we have created. The [Introduction to Class2Go][howto] 
course highlights the major features of the platform and includes guides 
for adding content to a Class2Go course and templates for creating problem sets, 
exams, or surveys. 
  [howto]: http://class2go.stanford.edu/class2go/howto/

The [Class2Go Sandbox][sandbox] course allows access to the administrator 
features of the Class2Go platform. You are welcome to access this course 
to test adding and updating course materials through the admin interface. 
The public login (username: class2go, password: class2go) gives access to 
both courses.
  [sandbox]: http://class2gosandbox.com/sandbox/C2G

Philosophy 
----------

There are some principles that have guided our project:

* **Open**. The platform is open source to make it easier for users
    (faculty members) to give us feedback on what we are doing.
    We would love to have others use the platform.  We are working
    with others who are interested in using Class2Go for on-line
    education: universities, private schools, even NGO's.

* **Portable**. Valuable course content shouldn't be tied to any
    one platform. Documents are already portable; the videos are
    outside our system (on YouTube) and the assets themselves can
    be repurposed as faculty see fit.  

* **Interoperable**. We don't want to build or maintain more than we
    have to. See the section below for a list of all the shoulders
    we are standing on.


Key Features
------------

To bring this to life we've built a system. Here are some of its
important distinguishing features.

* **Video and Problem Set Management**. Professors (and TA's) can
    upload assets to S3; videos are then uploaded to YouTube.

* **Exercises**. We support two kinds of exercises: formative, for
    learning and encouraging engagement; and summative, for assessment,
    like quizzes and tests.  Students can attempt each formative
    problems many times as they want without penalty, but may be
    penalized for multiple submissions in summative sets. In both
    types of problem sets, feedback is available immediately so
    students can learn along the way.

* **Content Management**. We have built a simple content management
    system where course information (videos, static pages, problem
    sets) can be created, reviewed, and then published. One important
    ability is an automatic live date, so a professor (or, most
    likely, their TA) doesn't have to click a button at midnight to
    publish a problem set.

* **Frame Extraction**. We have a simple tool for extracting frames
    from a video (using ```ffmpeg```) and differencing them to find 
    key frames.  The thumbnails of these frames are used as an index
    to the video for navigation. It's called the Kelvinator after
    its first author, Kelvin Do.

* **Reporting**. We have a set of ad-hoc and scheduled reports so
    teachers can get feedback and adjust.


Leveraging Others
-----------------

Thanks to all the projects we are relying on to make this work. Some are
commercial, some open source. But a ton of good stuff.

* [YouTube] [yt] and [Popcorn.js] [pop] for video
* [Piazza] [pz] for forums
* [MySQL] [mys] is our database
* The massive [Python] [p] [Django] [dj] ecosystem: eg. South, Registration
* [Amazon AWS] [a] suite for hosting (EC2, S3, RDS, Route53, IAM)
* Chef from [Opscode] [oc] for configuration management
* [Github] [gh] for source code management and issues

  [yt]:   http://www.youtube.com/
  [pop]:  http://www.popcornjs.org/
  [pz]:   http://www.piazza.com/
  [mys]:  http://www.mysql.org/
  [p]:    http://www.python.org/
  [dj]:   http://www.djangoproject.com/
  [a]:    http://aws.amazon.com/
  [oc]:   http://www.opscode.com/
  [gh]:   http://www.github.com/


Contributing
------------

We welcome others contributing to Class2Go.  Begin by checking out
our source from here and using README_SETUP.md to get a development
environment set up.  There are also some docs available on the
Project Wiki on GitHub.

Before sending unsolicited pull requests it is often best to discuss your
intentions with the core dev team. Send us mail: <c2g-contact@class.stanford.edu>.

If you want to get an idea of the kinds of things to do on the project,
check out our
<a href="https://github.com/Stanford-Online/class2go/issues?state=open">issue list on GitHub</a>.  
We keep it here for all to see.  Feel free to comment on bugs and make 
suggestions.  If you want to fix a bug, go ahead and fork, fix, test, and 
send a pull request.


Using Class2Go Yourself
-----------------------

We intend for other colleges, universities, and even private
organizations to be able to stand up their own instance of Class2Go
to host their own courses.  Unfortunately, the tooling and instructions
for this aren't turnkey just yet.  We also need to do some development
to make it less Stanford-specific.  Maybe you can help with that?

If you're interested, your first step, just like other contributions,
is to stand up a development environment on your own machine and try
it out.  We have people who got this demo-sized Class2Go up and running
pretty quickly on their local machine.

Send us mail at <c2g-contact@class.stanford.edu> and we can give
you an idea what would be involved.

If you are interested in evaluating the Class2Go platform before trying to stand 
up your own instance, you can explore Class2Go through two courses 
we have created. The [Introduction to Class2Go][howto] course highlights the major 
features of the platform and includes guides for adding content to a Class2Go course 
and templates for creating problem sets, exams, or surveys. 
[howto]: http://class2go.stanford.edu/class2go/howto/

The [Class2Go Sandbox][sandbox] course allows access to the administrator features 
of the Class2Go platform. You are welcome to access this course to test adding and 
updating course materials through the admin interface. The public login 
(username: class2go, password: class2go) gives access to both courses.
[sandbox]: http://class2go.stanford.edu/sandbox/C2G/


License
-------

Copyright 2012 Stanford University

Licensed under the Apache License, Version 2.0 (the "License"); 
you may not use this file except in compliance with the License. 
You may obtain a copy of the License at 

<http://www.apache.org/licenses/LICENSE-2.0>

Unless required by applicable law or agreed to in writing, software 
distributed under the License is distributed on an "AS IS" BASIS, 
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
See the License for the specific language governing permissions and 
limitations under the License.


Setting up Your Class2Go Dev Environment
========================================

These instructions should help you get started setting up a dev
environment.  You should be able to do most of your development on
your laptop by running a local database (mysqld) and storing files
locally instead of in S3.

The majority of our dev team uses Macs, so the Mac instructions are
generally the most up to date.  But we do have some developers who
have had windows or Ubuntu Linux as their day-to-day dev machines, so
we know it works.

If you have suggestions how to improve these notes, please improve
them and send us a pull request!

* [Mac OS X](#mac)
* [Windows](#windows)
* [Linux](#linux)
* [Configuring Django](#config)
* [Generating Test Data](#testdata)

It is a big step to go from a dev instance to a full-on deployed
cloud instance.  Instructions for that are forthcoming.

<a name="mac"></a>
For Mac
-------------

General Instructions:

* Set up command line tools (`clang`, `make`, etc.)
* Set up Homebrew, a package manager for Mac
* Set up MySQL
* Set up Python
* Set up Python's virtual env
* Set up Django
* Set up test suite

For Mac OS-X Lion: Instructions mainly taken from
http://www.tlswebsolutions.com/mac-os-x-lion-setting-up-django-pip-virtualenv-and-homebrew/

Some people don't have their normal user set up with write permissions
for all these commands that modify the environment (`brew`,
`easy_install`, `pip`).  For all of those you should plan on running
your own `sudo` prefix for these.

1. Install XCode from the Apple App Store Version 4.5 or later

1. Within XCode, add the command line tools: Preferences -> Download ->
"Command Line Tools" -> Install button

1. Install Homebrew:

        /usr/bin/ruby -e "$(curl -fsSkL http://raw.github.com/mxcl/homebrew/go)"

1. Check out your `PATH` to see if `/usr/local/bin` comes before
`/usr/bin`:

        echo $PATH

    If not, open up your shell's login script (`~/.bashrc` for bash),
and add the following line to it:

        export PATH=/usr/local/bin:$PATH

    Make sure to source the login script once you're finished so that
your new `PATH` is loaded:

        source ~/.bashrc

1. Install MySQL
    1. Download MySQL [here](dev.mysql.com/downloads/mysql)
    1. Look for the DMG of the latest 64-bit version
    1. Install the mysql-5.x-osx10.x-x86_64.pkg
    1. Install the MySQLStartupItem.pkg
    1. Install the MySQL.prefpane
        1. Start MySQL Server
        1. Check Automatically Start on startup

    1. Edit your shell's login script:

            vim ~/.bashrc

    1. ...and add the following:

            export PATH=/usr/local/mysql/bin:$PATH
            export DYLD_LIBRARY_PATH=/usr/local/mysql/lib:$DYLD_LIBRARY_PATH

    1. Once done, source your login script so that it takes effect:

            source ~/.bashrc

1. [Optional] Install Sequel Pro:
    
    www.sequelpro.com

1. Set up a user account and database in MySQL:

        create database class2go;
        grant all on class2go.* to class2go@'localhost' identified by 'class2gopw';
        grant all on class2go.* to class2go@'127.0.0.1' identified by 'class2gopw';

    [NB:] Remember these values, especially if you change them from these
defaults, as you'll use them later when setting up Django.

1. Install Python (we are expecting 2.7.x):

        brew install readline sqlite gdbm

1. If you plan on running in a virtual environment, then you probably
want to instally your own python.  But if not, then you already have
python on your machine (in `/usr/bin/python`), in which case you *shouldn't*
install another copy of python (in `/usr/local/bin/python`).
But if you want to do it with:

        brew install python --universal --framework

1. Install pip, a python package manager (this command may need `sudo`):

        easy_install pip

1. Install python's virtual env (this command may also need `sudo`):

        pip install virtualenv

1. Install virtualenvwrapper (`sudo` this too if necessary):

        pip install virtualenvwrapper

    1. Verify installation location of virtualenv and virtualenvwrapper:

            ls /usr/local/bin/

    1. Edit login script:

            vim .bashrc

    1. ...and add the following:

            # virtualenv setup -- use Distribute by default
            export VIRTUALENV_DISTRIBUTE=true

            # virtualenvwrapper setup (feel free to change project directories)
            export WORKON_HOME=~/class2go-venv
            export PROJECT_HOME=~/class2go-projects
            export VIRTUALENVWRAPPER_VIRTUALENV_ARGS='--no-site-packages'
            export VIRTUALENVWRAPPER_VIRTUALENV=`which virtualenv`
            source /usr/local/bin/virtualenvwrapper.sh

    1. Source login script so env vars take effect:

            source ~/.bashrc
    [NB:] Sourcing should auto-create your virtual environment base dir)

    1. Check out new virtual base directory:

            ls class2go-venv/

    1. Make sure `PROJECT_HOME` is defined

            echo $PROJECT_HOME

    1. Make new project directory:

            mkdir -p $PROJECT_HOME

    1. Issue command to set up new project subdirectory and link it to virtual env:

            mkproject class2go

    1. Clone this repository, or move a copy, into your `PROJECT_HOME` directory:

            git clone git@github.com:Stanford-Online/class2go.git $PROJECT_HOME/class2go

1. Make sure that you're in the root project directory. Do this whenever
you want to work on the project so that the virtual environment gets set
up properly:

        workon class2go

1. Install all the dependencies with this command:

        pip install -r requirements.txt

    [Optional] And subsequently all of the optional dependencies with this command:
 
        pip install -r suggested_requirements.txt

    [NB:] If you aren't using pip or want to install packages manually, just open the
    requirements files and run the local equivalent of

        pip install <packagename>

    for each package listed therein.

1. [Optional] If you want mass-emailing to work, install 'lynx' command-line utility:

        brew install lynx

1. [Optional] Install chrome for Selenium testing

        # chromedriver - list of options available here:
        # https://code.google.com/p/chromedriver/downloads/list
        curl -O http://chromedriver.googlecode.com/files/chromedriver_mac_23.0.1240.0.zip
        unzip chromedriver_mac_23.0.1240.0.zip
        # move onto your path
        sudo mv ./chromedriver /usr/local/bin/
        # install Chrome -- download from https://www.google.com/intl/en/chrome/browser/

    [NB:] If instead you wish to use Firefox, you can use the default Selenium Firefox
    driver by setting the environment variable C2G_SELENIUM_WEBDRIVER=firefox. For
    Flash tests to pass, you will have to have the Flash player plugin installed.

1. [Optional] Install dependencies to run Selenium tests "headless"

        # TODO: Figure out how to run headless on Mac OSX (see Linux section for starters)

1. Head into the main folder of the project:

        cd main

1. Set up default folders for logs, the celery SQLite DB, and other
stuff:

        mkdir cache-default
        mkdir logs
        mkdir sqlite3
        mkdir static

1. In the `main/` folder, make a copy of `database_example.py` to
`database.py`
and edit the `DATABASES` strings as follows substituting proper values
(remember those MySQL values from above??):

        DATABASES = {
            'default': {
                'ENGINE': 'django.db.backends.mysql',
                'NAME': 'class2go',
                'USER': 'class2go',
                'PASSWORD': 'class2gopw',
                'HOST': '',
                'PORT': '',
            },
            'celery': {
                'ENGINE': 'django.db.backends.sqlite3',
                'NAME': 'sqlite3/celerydb.sqlite',
            },
        }

1. Setup initial db from the main folder

        ./manage.py syncdb  ######## answer no to the superuser question for now
        ./manage.py migrate
        ./manage.py syncdb --database=celery
        ./manage.py migrate --database=celery

    At this point you should be able to look at the django database in
    your local mysql and see a bunch of c2g_* tables. Now you should create the super user

        ./manage.py createsuperuser

    Yay. :)

1. From the main folder, run server on whatever port you want (default
is 8000 if you omit 8100):

        ./manage.py runserver 8100

1. Visit [localhost:8100](localhost:8100) in your web browser and confirm that you get a C2G page.


<a name="windows"></a>
For Windows
----------------

[NB] While we try to keep these instructions up to date, the majority of the
developers working on Class2Go are using MacOS or Linux. You may have the 
best luck if you follow the directions in one of those sections in parallel 
with the directions here.

Eclipse Users and/or WAMP users:

The following versions seem to be compatible:

- Python: 2.7.3
- Eclipse for PHP: Helios (http://download.eclipse.org/releases/helios)
- PyDev plugin for Eclipse: 2.5.0 (http://pydev.org/updates)
- Egit plugin for Eclipse: (http://download.eclipse.org/egit/updates)
- WAMPServer: 2.1


Steps:

2. Install Eclipse

2. Install Egit and configure it to the github repos (https://github.com/Stanford-Online/class2go)
    For this you would need someone to set you up with access to this repos.
    Note, when configuring the Remote Push Url you'll need to add ".git" on the end:
    (git clone https://github.com/Stanford-Online/class2go.git)

**Requirements**

2. Prereqs:
	If you do not have the following, install them:
		python 2.7
		django
		easy_install
		pip
		python image library (pip install PIL)
        django_storages
        boto
        lynx (for mass mailing)

2. Install South, the database schema migration tool: (this will be inside the virtualenv)
    easy_install South

2. Install the other libraries listed in the requirements.txt and suggested_requirements.txt

2. Create a database called c2g (for example).

2. Copy database.example.py to database.py.

2. In database.py, append 'mysql' to ENGINE, and enter the name of the database you created in step 1, and the credentials of an authorized user of the database (user 'root' and empty password may work on MySQL unless you specified otherwise during the MySQL setup)

2. Make sure you're in the src/class2go/main directory (wherever that is for you)

2. 'python manage.py syncdb' followed by 'python manage.py migrate' to create the required database tables and make sure the schema is up to date.You will be asked to create your admin account on the way. Skip it. You will later be able to create a user and promote it to admin manually using your DBMS client.

        ./manage.py syncdb  ######## answer no to the superuser question for now
        ./manage.py migrate
        ./manage.py syncdb --database=celery
        ./manage.py migrate --database=celery

At this point you should be able to look at the django database in your local mysql and see a bunch of c2g_* tables. Now you should create the super user

    ./manage.py createsuperuser

Yay. :)

2. XX -- 'python manage.py collectstatic' to copy all static files to the directory specified in settings.py.

2. 'python manage.py runserver xxxx' to run a dev server on port number xxxx. Example: xxxx = 8000

2. Visit localhost:xxxx in your web browser and confirm that you get a C2G page.




<a name="linux"></a>
For Linux
-----------------

This assumes you have mysql and python installed.  These instructions
also include info for virtualenvwrapper, which contains useful tools
for virtualenv. virtualenvwrapper can also be installed for Mac (and
probably Windows too).  If you will be using the Firefox driver for
Selenium web tests, make sure you have the Flash plugin installed. If you 
wish to install the Chrome driver, instructions for doing so can be found
below.

3. Create the database (perhaps with different username and password):

        sudo mysql mysql
        create database c2g;
        CREATE USER 'c2g_username'@'localhost' IDENTIFIED BY 'c2g_passwd';
        GRANT ALL PRIVILEGES ON c2g . * TO 'c2g_username'@'localhost';
        FLUSH PRIVILEGES;

3. Install pip:

        sudo apt-get install python-pip

3. Install virtualenv:

        sudo pip install virtualenv

3. Install virtualenvwrapper:

        sudo pip install virtualenvwrapper

3. Verify installation location of virtualenv and virtualenvwrapper:

        ls /usr/local/bin/

3. Check out your PATH to see if /usr/local/bin comes before /usr/bin:

        echo $PATH
    (If not, add `export PATH=/usr/local/bin:$PATH` to your .bashrc)

3. Edit login script:

        vim .bashrc

3. ...and add the following:

        # virtualenv setup -- use Distribute by default
        export VIRTUALENV_DISTRIBUTE=true

        # virtualenvwrapper setup
        export WORKON_HOME=~/DevEnvs
        export PROJECT_HOME=~/DevProjects
        export VIRTUALENVWRAPPER_VIRTUALENV_ARGS='--no-site-packages'
        export VIRTUALENVWRAPPER_VIRTUALENV=`which virtualenv`
        source /usr/local/bin/virtualenvwrapper.sh

3. Source login script so env vars take effect:

        source ~/.bashrc
    (Sourcing should auto-create your virtual environment base dir)

3. Check out new virtual base directory:

        ls DevEnvs/

3. Make sure PROJECT_HOME is defined

        echo $PROJECT_HOME

3. Make new project directory:

        mkdir -p $PROJECT_HOME

3. Issue command to set up new project subdirectory and link it to virtual env:

        mkproject class2go

3. Once inside virtual env/project directory, install django:

        pip install django

3. Clone class2go repo from github:

        git clone https://github.com/Stanford-Online/class2go.git .

3. Check out where your mysql is installed, make sure mysql_config exists in the dir:

        ls `which mysql`

3. Need to install mysql_config if it's not there:

        sudo apt-get install libmysqlclient-dev

3. Might need some extra python developer stuff:

        sudo apt-get install python-dev

3. Install all the dependencies with this command:

    pip install -r requirements.txt

And subsequently all of the optional dependencies with this command:
 
    pip install -r suggested_requirements.txt

If you aren't using pip or want to install packages manually, just open the
requirements files and run the local equivalent of 

        pip install <packagename>

for each package listed therein.

3. [Optional] If you want mass-email sending to work, install the 'lynx' package:

    sudo apt-get install lynx-cur

3. [Nota Bene] [Optional] Install chrome for Selenium testing

        # chromedriver - list of options available here:
        # https://code.google.com/p/chromedriver/downloads/list
        curl -O http://chromedriver.googlecode.com/files/chromedriver_linux32_23.0.1240.0.zip
        unzip chromedriver_linux32_23.0.1240.0.zip
        # move onto your path
        sudo mv ./chromedriver /usr/local/bin/
        # install Chrome -- download from https://www.google.com/intl/en/chrome/browser/

[NB:] If instead you wish to use firefox, you can use the default Selenium firefox
driver by setting the environment variable C2G_SELENIUM_WEBDRIVER=firefox. For 
flash tests to pass, you will have to have the flash player installed. On recent 
64-bit Ubuntus, this comes from 'flashplugin-installer'

3. [Optional] Install dependenices to run selenium tests "headless"

        pip install pyvirtualdisplay
        sudo apt-get install xvfb xserver-xephyr

Note that to use this, you will have to set the environment variable C2G_HEADLESS_TESTS=1.

3. [Optional] Install wkhtmltopdf for statement generation. xhtmltopdf can be
   used, but it has poor CSS support. For nice CSS support, you can use
   embedded webkit with wkhtmltopdf, and drive it with the python-pdfkit library:

        sudo apt-get install wkhtmltopdf xvfb libicu48 libicu-dev

Note that this pulls in number of dependencies. It's generally not recommended
to install all of this anywhere it's not strictly needed. You will also require
the suggested python-pdfkit library from pypi.

3. Go to "main" dir and copy over database settings file:

        cd main
        cp database_example.py database.py

3. Edit file and add db name, username and password (see mac instructions)

        vim database.py

3. Run syncdb to create database tables

        ./manage.py syncdb  ######## answer no to the superuser question for now
    Might need to issue "syncdb" command a couple times if there are errors. The
    first time, it will ask you for username and password for the database

3. Migrate user stuff over:

        ./manage.py migrate

Now you should create the super user

        ./manage.py createsuperuser

Yay. :)


3. Update settings file and change STATIC\_ROOT to "static/":

        vim settings.py

3. Make sure directory exists, or create it:

        mkdir static

3. Run collectstatic to copy stuff into your dir:

        ./manage.py collectstatic

3. Run server on whatever port you want:

        python manage.py runserver 8100


When you want to start working on your project, just do the following:

        # this should change to the correct virtualenv and cd you to project dir
        workon class2go
        python ./manage.py runserver 8100


<a name="config"></a>
Configuring Django
------------------

The "main" dir is where the django project lives.  You will spend
most of your time in there.  All the runtime application source is
under main, and the manage.py script is the interface to runtime
command line tools.

We partition our django project settings into two settings files:

* **settings.py** - Most of the project settings are in here.  This
    should be familiar to any django dev.

* **database.py** - Anything that should *not* be checked in, i.e.
    secret keys or local configuration, should be in the database.py
    file.  Upon setting up your project one of the first things you
    have to do is create your own database.py.  There is an example
    file to get you started, database_example.py.



<a name="testdata"></a>
Generating Test Data
-----------------------

1. Some schema mods were made so run: manage.py migrate

2. Take a look in c2g/views.py as there are some parameters that
    affect which data gets created. Note, if you choose the delete\_current\_data
    option it will delete your current django users so you'll have to
    recreate those users if you want.

3. To run the script that populates the data do "manage.py help db_populate" first.
    This will tell you where to setup the params for the test data.

A helper script for this exists at main/repave\_dev\_database.sh.  It
drops/recreates your dev database and then does the syncdb / migrate
/ db_populate steps so you end up with a clean database.  It requires
a ~/.my.cnf file to know what database to talk to.

1. On a prod machine: 
    echo "select date(date_joined), count(*) from auth_user group by 1;" | ~/class2go/main/manage.py dbshell

2. Copy/paste into the file on your machine
    ./users_by_day.dat

3. Run this command:
    cat plot_users.conf | gnuplot

4. Total?
    cat users_by_day.dat | awk '{x += $2} END {print x}'

The chart will be in class2go_users.png

