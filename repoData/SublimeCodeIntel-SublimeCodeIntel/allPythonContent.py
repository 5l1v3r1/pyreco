__FILENAME__ = cElementTree
import sys
import struct

VERSION = sys.version_info[:2]
PLATFORM = sys.platform
ARCH = 'x%d' % (struct.calcsize('P') * 8)

if VERSION >= (3, 3):
    from iElementTree import *
    from iElementTree import _patched_for_komodo_
elif VERSION >= (2, 6):
    platform = None

    try:
        from _local_arch.cElementTree import *
        platform = "Local arch"
    except ImportError:
        if PLATFORM == 'darwin':
            from _macosx_universal_py26.cElementTree import *
            platform = "MacOS X Universal"
        elif PLATFORM.startswith('linux'):
            if ARCH == 'x64':
                from _linux_libcpp6_x86_64_py26.cElementTree import *
                platform = "Linux 64 bits"
            elif ARCH == 'x32':
                from _linux_libcpp6_x86_py26.cElementTree import *
                platform = "Linux 32 bits"
        elif PLATFORM.startswith('win'):
            if ARCH == 'x64':
                from _win64_py26.cElementTree import *
                platform = "Windows 64 bits"
            elif ARCH == 'x32':
                from _win32_py26.cElementTree import *
                platform = "Windows 32 bits"

    if not platform:
        raise ImportError("Could not find a suitable cElementTree binary for your platform and architecture.")

########NEW FILE########
__FILENAME__ = big5freq
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
# 
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
# 
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# Big5 frequency table
# by Taiwan's Mandarin Promotion Council 
# <http://www.edu.tw:81/mandr/>
# 
# 128  --> 0.42261
# 256  --> 0.57851
# 512  --> 0.74851
# 1024 --> 0.89384
# 2048 --> 0.97583
# 
# Ideal Distribution Ratio = 0.74851/(1-0.74851) =2.98
# Random Distribution Ration = 512/(5401-512)=0.105
# 
# Typical Distribution Ratio about 25% of Ideal one, still much higher than RDR

BIG5_TYPICAL_DISTRIBUTION_RATIO = 0.75

#Char to FreqOrder table
BIG5_TABLE_SIZE = 5376

Big5CharToFreqOrder = ( \
   1,1801,1506, 255,1431, 198,   9,  82,   6,5008, 177, 202,3681,1256,2821, 110, #   16
3814,  33,3274, 261,  76,  44,2114,  16,2946,2187,1176, 659,3971,  26,3451,2653, #   32
1198,3972,3350,4202, 410,2215, 302, 590, 361,1964,   8, 204,  58,4510,5009,1932, #   48
  63,5010,5011, 317,1614,  75, 222, 159,4203,2417,1480,5012,3555,3091, 224,2822, #   64
3682,   3,  10,3973,1471,  29,2787,1135,2866,1940, 873, 130,3275,1123, 312,5013, #   80
4511,2052, 507, 252, 682,5014, 142,1915, 124, 206,2947,  34,3556,3204,  64, 604, #   96
5015,2501,1977,1978, 155,1991, 645, 641,1606,5016,3452, 337,  72, 406,5017,  80, #  112
 630, 238,3205,1509, 263, 939,1092,2654, 756,1440,1094,3453, 449,  69,2987, 591, #  128
 179,2096, 471, 115,2035,1844,  60,  50,2988, 134, 806,1869, 734,2036,3454, 180, #  144
 995,1607, 156, 537,2907, 688,5018, 319,1305, 779,2145, 514,2379, 298,4512, 359, #  160
2502,  90,2716,1338, 663,  11, 906,1099,2553,  20,2441, 182, 532,1716,5019, 732, #  176
1376,4204,1311,1420,3206,  25,2317,1056, 113, 399, 382,1950, 242,3455,2474, 529, #  192
3276, 475,1447,3683,5020, 117,  21, 656, 810,1297,2300,2334,3557,5021, 126,4205, #  208
 706, 456, 150, 613,4513,  71,1118,2037,4206, 145,3092,  85, 835, 486,2115,1246, #  224
1426, 428, 727,1285,1015, 800, 106, 623, 303,1281,5022,2128,2359, 347,3815, 221, #  240
3558,3135,5023,1956,1153,4207,  83, 296,1199,3093, 192, 624,  93,5024, 822,1898, #  256
2823,3136, 795,2065, 991,1554,1542,1592,  27,  43,2867, 859, 139,1456, 860,4514, #  272
 437, 712,3974, 164,2397,3137, 695, 211,3037,2097, 195,3975,1608,3559,3560,3684, #  288
3976, 234, 811,2989,2098,3977,2233,1441,3561,1615,2380, 668,2077,1638, 305, 228, #  304
1664,4515, 467, 415,5025, 262,2099,1593, 239, 108, 300, 200,1033, 512,1247,2078, #  320
5026,5027,2176,3207,3685,2682, 593, 845,1062,3277,  88,1723,2038,3978,1951, 212, #  336
 266, 152, 149, 468,1899,4208,4516,  77, 187,5028,3038,  37,   5,2990,5029,3979, #  352
5030,5031,  39,2524,4517,2908,3208,2079,  55, 148,  74,4518, 545, 483,1474,1029, #  368
1665, 217,1870,1531,3138,1104,2655,4209,  24, 172,3562, 900,3980,3563,3564,4519, #  384
  32,1408,2824,1312, 329, 487,2360,2251,2717, 784,2683,   4,3039,3351,1427,1789, #  400
 188, 109, 499,5032,3686,1717,1790, 888,1217,3040,4520,5033,3565,5034,3352,1520, #  416
3687,3981, 196,1034, 775,5035,5036, 929,1816, 249, 439,  38,5037,1063,5038, 794, #  432
3982,1435,2301,  46, 178,3278,2066,5039,2381,5040, 214,1709,4521, 804,  35, 707, #  448
 324,3688,1601,2554, 140, 459,4210,5041,5042,1365, 839, 272, 978,2262,2580,3456, #  464
2129,1363,3689,1423, 697, 100,3094,  48,  70,1231, 495,3139,2196,5043,1294,5044, #  480
2080, 462, 586,1042,3279, 853, 256, 988, 185,2382,3457,1698, 434,1084,5045,3458, #  496
 314,2625,2788,4522,2335,2336, 569,2285, 637,1817,2525, 757,1162,1879,1616,3459, #  512
 287,1577,2116, 768,4523,1671,2868,3566,2526,1321,3816, 909,2418,5046,4211, 933, #  528
3817,4212,2053,2361,1222,4524, 765,2419,1322, 786,4525,5047,1920,1462,1677,2909, #  544
1699,5048,4526,1424,2442,3140,3690,2600,3353,1775,1941,3460,3983,4213, 309,1369, #  560
1130,2825, 364,2234,1653,1299,3984,3567,3985,3986,2656, 525,1085,3041, 902,2001, #  576
1475, 964,4527, 421,1845,1415,1057,2286, 940,1364,3141, 376,4528,4529,1381,   7, #  592
2527, 983,2383, 336,1710,2684,1846, 321,3461, 559,1131,3042,2752,1809,1132,1313, #  608
 265,1481,1858,5049, 352,1203,2826,3280, 167,1089, 420,2827, 776, 792,1724,3568, #  624
4214,2443,3281,5050,4215,5051, 446, 229, 333,2753, 901,3818,1200,1557,4530,2657, #  640
1921, 395,2754,2685,3819,4216,1836, 125, 916,3209,2626,4531,5052,5053,3820,5054, #  656
5055,5056,4532,3142,3691,1133,2555,1757,3462,1510,2318,1409,3569,5057,2146, 438, #  672
2601,2910,2384,3354,1068, 958,3043, 461, 311,2869,2686,4217,1916,3210,4218,1979, #  688
 383, 750,2755,2627,4219, 274, 539, 385,1278,1442,5058,1154,1965, 384, 561, 210, #  704
  98,1295,2556,3570,5059,1711,2420,1482,3463,3987,2911,1257, 129,5060,3821, 642, #  720
 523,2789,2790,2658,5061, 141,2235,1333,  68, 176, 441, 876, 907,4220, 603,2602, #  736
 710, 171,3464, 404, 549,  18,3143,2398,1410,3692,1666,5062,3571,4533,2912,4534, #  752
5063,2991, 368,5064, 146, 366,  99, 871,3693,1543, 748, 807,1586,1185,  22,2263, #  768
 379,3822,3211,5065,3212, 505,1942,2628,1992,1382,2319,5066, 380,2362, 218, 702, #  784
1818,1248,3465,3044,3572,3355,3282,5067,2992,3694, 930,3283,3823,5068,  59,5069, #  800
 585, 601,4221, 497,3466,1112,1314,4535,1802,5070,1223,1472,2177,5071, 749,1837, #  816
 690,1900,3824,1773,3988,1476, 429,1043,1791,2236,2117, 917,4222, 447,1086,1629, #  832
5072, 556,5073,5074,2021,1654, 844,1090, 105, 550, 966,1758,2828,1008,1783, 686, #  848
1095,5075,2287, 793,1602,5076,3573,2603,4536,4223,2948,2302,4537,3825, 980,2503, #  864
 544, 353, 527,4538, 908,2687,2913,5077, 381,2629,1943,1348,5078,1341,1252, 560, #  880
3095,5079,3467,2870,5080,2054, 973, 886,2081, 143,4539,5081,5082, 157,3989, 496, #  896
4224,  57, 840, 540,2039,4540,4541,3468,2118,1445, 970,2264,1748,1966,2082,4225, #  912
3144,1234,1776,3284,2829,3695, 773,1206,2130,1066,2040,1326,3990,1738,1725,4226, #  928
 279,3145,  51,1544,2604, 423,1578,2131,2067, 173,4542,1880,5083,5084,1583, 264, #  944
 610,3696,4543,2444, 280, 154,5085,5086,5087,1739, 338,1282,3096, 693,2871,1411, #  960
1074,3826,2445,5088,4544,5089,5090,1240, 952,2399,5091,2914,1538,2688, 685,1483, #  976
4227,2475,1436, 953,4228,2055,4545, 671,2400,  79,4229,2446,3285, 608, 567,2689, #  992
3469,4230,4231,1691, 393,1261,1792,2401,5092,4546,5093,5094,5095,5096,1383,1672, # 1008
3827,3213,1464, 522,1119, 661,1150, 216, 675,4547,3991,1432,3574, 609,4548,2690, # 1024
2402,5097,5098,5099,4232,3045,   0,5100,2476, 315, 231,2447, 301,3356,4549,2385, # 1040
5101, 233,4233,3697,1819,4550,4551,5102,  96,1777,1315,2083,5103, 257,5104,1810, # 1056
3698,2718,1139,1820,4234,2022,1124,2164,2791,1778,2659,5105,3097, 363,1655,3214, # 1072
5106,2993,5107,5108,5109,3992,1567,3993, 718, 103,3215, 849,1443, 341,3357,2949, # 1088
1484,5110,1712, 127,  67, 339,4235,2403, 679,1412, 821,5111,5112, 834, 738, 351, # 1104
2994,2147, 846, 235,1497,1881, 418,1993,3828,2719, 186,1100,2148,2756,3575,1545, # 1120
1355,2950,2872,1377, 583,3994,4236,2581,2995,5113,1298,3699,1078,2557,3700,2363, # 1136
  78,3829,3830, 267,1289,2100,2002,1594,4237, 348, 369,1274,2197,2178,1838,4552, # 1152
1821,2830,3701,2757,2288,2003,4553,2951,2758, 144,3358, 882,4554,3995,2759,3470, # 1168
4555,2915,5114,4238,1726, 320,5115,3996,3046, 788,2996,5116,2831,1774,1327,2873, # 1184
3997,2832,5117,1306,4556,2004,1700,3831,3576,2364,2660, 787,2023, 506, 824,3702, # 1200
 534, 323,4557,1044,3359,2024,1901, 946,3471,5118,1779,1500,1678,5119,1882,4558, # 1216
 165, 243,4559,3703,2528, 123, 683,4239, 764,4560,  36,3998,1793, 589,2916, 816, # 1232
 626,1667,3047,2237,1639,1555,1622,3832,3999,5120,4000,2874,1370,1228,1933, 891, # 1248
2084,2917, 304,4240,5121, 292,2997,2720,3577, 691,2101,4241,1115,4561, 118, 662, # 1264
5122, 611,1156, 854,2386,1316,2875,   2, 386, 515,2918,5123,5124,3286, 868,2238, # 1280
1486, 855,2661, 785,2216,3048,5125,1040,3216,3578,5126,3146, 448,5127,1525,5128, # 1296
2165,4562,5129,3833,5130,4242,2833,3579,3147, 503, 818,4001,3148,1568, 814, 676, # 1312
1444, 306,1749,5131,3834,1416,1030, 197,1428, 805,2834,1501,4563,5132,5133,5134, # 1328
1994,5135,4564,5136,5137,2198,  13,2792,3704,2998,3149,1229,1917,5138,3835,2132, # 1344
5139,4243,4565,2404,3580,5140,2217,1511,1727,1120,5141,5142, 646,3836,2448, 307, # 1360
5143,5144,1595,3217,5145,5146,5147,3705,1113,1356,4002,1465,2529,2530,5148, 519, # 1376
5149, 128,2133,  92,2289,1980,5150,4003,1512, 342,3150,2199,5151,2793,2218,1981, # 1392
3360,4244, 290,1656,1317, 789, 827,2365,5152,3837,4566, 562, 581,4004,5153, 401, # 1408
4567,2252,  94,4568,5154,1399,2794,5155,1463,2025,4569,3218,1944,5156, 828,1105, # 1424
4245,1262,1394,5157,4246, 605,4570,5158,1784,2876,5159,2835, 819,2102, 578,2200, # 1440
2952,5160,1502, 436,3287,4247,3288,2836,4005,2919,3472,3473,5161,2721,2320,5162, # 1456
5163,2337,2068,  23,4571, 193, 826,3838,2103, 699,1630,4248,3098, 390,1794,1064, # 1472
3581,5164,1579,3099,3100,1400,5165,4249,1839,1640,2877,5166,4572,4573, 137,4250, # 1488
 598,3101,1967, 780, 104, 974,2953,5167, 278, 899, 253, 402, 572, 504, 493,1339, # 1504
5168,4006,1275,4574,2582,2558,5169,3706,3049,3102,2253, 565,1334,2722, 863,  41, # 1520
5170,5171,4575,5172,1657,2338,  19, 463,2760,4251, 606,5173,2999,3289,1087,2085, # 1536
1323,2662,3000,5174,1631,1623,1750,4252,2691,5175,2878, 791,2723,2663,2339, 232, # 1552
2421,5176,3001,1498,5177,2664,2630, 755,1366,3707,3290,3151,2026,1609, 119,1918, # 1568
3474, 862,1026,4253,5178,4007,3839,4576,4008,4577,2265,1952,2477,5179,1125, 817, # 1584
4254,4255,4009,1513,1766,2041,1487,4256,3050,3291,2837,3840,3152,5180,5181,1507, # 1600
5182,2692, 733,  40,1632,1106,2879, 345,4257, 841,2531, 230,4578,3002,1847,3292, # 1616
3475,5183,1263, 986,3476,5184, 735, 879, 254,1137, 857, 622,1300,1180,1388,1562, # 1632
4010,4011,2954, 967,2761,2665,1349, 592,2134,1692,3361,3003,1995,4258,1679,4012, # 1648
1902,2188,5185, 739,3708,2724,1296,1290,5186,4259,2201,2202,1922,1563,2605,2559, # 1664
1871,2762,3004,5187, 435,5188, 343,1108, 596,  17,1751,4579,2239,3477,3709,5189, # 1680
4580, 294,3582,2955,1693, 477, 979, 281,2042,3583, 643,2043,3710,2631,2795,2266, # 1696
1031,2340,2135,2303,3584,4581, 367,1249,2560,5190,3585,5191,4582,1283,3362,2005, # 1712
 240,1762,3363,4583,4584, 836,1069,3153, 474,5192,2149,2532, 268,3586,5193,3219, # 1728
1521,1284,5194,1658,1546,4260,5195,3587,3588,5196,4261,3364,2693,1685,4262, 961, # 1744
1673,2632, 190,2006,2203,3841,4585,4586,5197, 570,2504,3711,1490,5198,4587,2633, # 1760
3293,1957,4588, 584,1514, 396,1045,1945,5199,4589,1968,2449,5200,5201,4590,4013, # 1776
 619,5202,3154,3294, 215,2007,2796,2561,3220,4591,3221,4592, 763,4263,3842,4593, # 1792
5203,5204,1958,1767,2956,3365,3712,1174, 452,1477,4594,3366,3155,5205,2838,1253, # 1808
2387,2189,1091,2290,4264, 492,5206, 638,1169,1825,2136,1752,4014, 648, 926,1021, # 1824
1324,4595, 520,4596, 997, 847,1007, 892,4597,3843,2267,1872,3713,2405,1785,4598, # 1840
1953,2957,3103,3222,1728,4265,2044,3714,4599,2008,1701,3156,1551,  30,2268,4266, # 1856
5207,2027,4600,3589,5208, 501,5209,4267, 594,3478,2166,1822,3590,3479,3591,3223, # 1872
 829,2839,4268,5210,1680,3157,1225,4269,5211,3295,4601,4270,3158,2341,5212,4602, # 1888
4271,5213,4015,4016,5214,1848,2388,2606,3367,5215,4603, 374,4017, 652,4272,4273, # 1904
 375,1140, 798,5216,5217,5218,2366,4604,2269, 546,1659, 138,3051,2450,4605,5219, # 1920
2254, 612,1849, 910, 796,3844,1740,1371, 825,3845,3846,5220,2920,2562,5221, 692, # 1936
 444,3052,2634, 801,4606,4274,5222,1491, 244,1053,3053,4275,4276, 340,5223,4018, # 1952
1041,3005, 293,1168,  87,1357,5224,1539, 959,5225,2240, 721, 694,4277,3847, 219, # 1968
1478, 644,1417,3368,2666,1413,1401,1335,1389,4019,5226,5227,3006,2367,3159,1826, # 1984
 730,1515, 184,2840,  66,4607,5228,1660,2958, 246,3369, 378,1457, 226,3480, 975, # 2000
4020,2959,1264,3592, 674, 696,5229, 163,5230,1141,2422,2167, 713,3593,3370,4608, # 2016
4021,5231,5232,1186,  15,5233,1079,1070,5234,1522,3224,3594, 276,1050,2725, 758, # 2032
1126, 653,2960,3296,5235,2342, 889,3595,4022,3104,3007, 903,1250,4609,4023,3481, # 2048
3596,1342,1681,1718, 766,3297, 286,  89,2961,3715,5236,1713,5237,2607,3371,3008, # 2064
5238,2962,2219,3225,2880,5239,4610,2505,2533, 181, 387,1075,4024, 731,2190,3372, # 2080
5240,3298, 310, 313,3482,2304, 770,4278,  54,3054, 189,4611,3105,3848,4025,5241, # 2096
1230,1617,1850, 355,3597,4279,4612,3373, 111,4280,3716,1350,3160,3483,3055,4281, # 2112
2150,3299,3598,5242,2797,4026,4027,3009, 722,2009,5243,1071, 247,1207,2343,2478, # 2128
1378,4613,2010, 864,1437,1214,4614, 373,3849,1142,2220, 667,4615, 442,2763,2563, # 2144
3850,4028,1969,4282,3300,1840, 837, 170,1107, 934,1336,1883,5244,5245,2119,4283, # 2160
2841, 743,1569,5246,4616,4284, 582,2389,1418,3484,5247,1803,5248, 357,1395,1729, # 2176
3717,3301,2423,1564,2241,5249,3106,3851,1633,4617,1114,2086,4285,1532,5250, 482, # 2192
2451,4618,5251,5252,1492, 833,1466,5253,2726,3599,1641,2842,5254,1526,1272,3718, # 2208
4286,1686,1795, 416,2564,1903,1954,1804,5255,3852,2798,3853,1159,2321,5256,2881, # 2224
4619,1610,1584,3056,2424,2764, 443,3302,1163,3161,5257,5258,4029,5259,4287,2506, # 2240
3057,4620,4030,3162,2104,1647,3600,2011,1873,4288,5260,4289, 431,3485,5261, 250, # 2256
  97,  81,4290,5262,1648,1851,1558, 160, 848,5263, 866, 740,1694,5264,2204,2843, # 2272
3226,4291,4621,3719,1687, 950,2479, 426, 469,3227,3720,3721,4031,5265,5266,1188, # 2288
 424,1996, 861,3601,4292,3854,2205,2694, 168,1235,3602,4293,5267,2087,1674,4622, # 2304
3374,3303, 220,2565,1009,5268,3855, 670,3010, 332,1208, 717,5269,5270,3603,2452, # 2320
4032,3375,5271, 513,5272,1209,2882,3376,3163,4623,1080,5273,5274,5275,5276,2534, # 2336
3722,3604, 815,1587,4033,4034,5277,3605,3486,3856,1254,4624,1328,3058,1390,4035, # 2352
1741,4036,3857,4037,5278, 236,3858,2453,3304,5279,5280,3723,3859,1273,3860,4625, # 2368
5281, 308,5282,4626, 245,4627,1852,2480,1307,2583, 430, 715,2137,2454,5283, 270, # 2384
 199,2883,4038,5284,3606,2727,1753, 761,1754, 725,1661,1841,4628,3487,3724,5285, # 2400
5286, 587,  14,3305, 227,2608, 326, 480,2270, 943,2765,3607, 291, 650,1884,5287, # 2416
1702,1226, 102,1547,  62,3488, 904,4629,3489,1164,4294,5288,5289,1224,1548,2766, # 2432
 391, 498,1493,5290,1386,1419,5291,2056,1177,4630, 813, 880,1081,2368, 566,1145, # 2448
4631,2291,1001,1035,2566,2609,2242, 394,1286,5292,5293,2069,5294,  86,1494,1730, # 2464
4039, 491,1588, 745, 897,2963, 843,3377,4040,2767,2884,3306,1768, 998,2221,2070, # 2480
 397,1827,1195,1970,3725,3011,3378, 284,5295,3861,2507,2138,2120,1904,5296,4041, # 2496
2151,4042,4295,1036,3490,1905, 114,2567,4296, 209,1527,5297,5298,2964,2844,2635, # 2512
2390,2728,3164, 812,2568,5299,3307,5300,1559, 737,1885,3726,1210, 885,  28,2695, # 2528
3608,3862,5301,4297,1004,1780,4632,5302, 346,1982,2222,2696,4633,3863,1742, 797, # 2544
1642,4043,1934,1072,1384,2152, 896,4044,3308,3727,3228,2885,3609,5303,2569,1959, # 2560
4634,2455,1786,5304,5305,5306,4045,4298,1005,1308,3728,4299,2729,4635,4636,1528, # 2576
2610, 161,1178,4300,1983, 987,4637,1101,4301, 631,4046,1157,3229,2425,1343,1241, # 2592
1016,2243,2570, 372, 877,2344,2508,1160, 555,1935, 911,4047,5307, 466,1170, 169, # 2608
1051,2921,2697,3729,2481,3012,1182,2012,2571,1251,2636,5308, 992,2345,3491,1540, # 2624
2730,1201,2071,2406,1997,2482,5309,4638, 528,1923,2191,1503,1874,1570,2369,3379, # 2640
3309,5310, 557,1073,5311,1828,3492,2088,2271,3165,3059,3107, 767,3108,2799,4639, # 2656
1006,4302,4640,2346,1267,2179,3730,3230, 778,4048,3231,2731,1597,2667,5312,4641, # 2672
5313,3493,5314,5315,5316,3310,2698,1433,3311, 131,  95,1504,4049, 723,4303,3166, # 2688
1842,3610,2768,2192,4050,2028,2105,3731,5317,3013,4051,1218,5318,3380,3232,4052, # 2704
4304,2584, 248,1634,3864, 912,5319,2845,3732,3060,3865, 654,  53,5320,3014,5321, # 2720
1688,4642, 777,3494,1032,4053,1425,5322, 191, 820,2121,2846, 971,4643, 931,3233, # 2736
 135, 664, 783,3866,1998, 772,2922,1936,4054,3867,4644,2923,3234, 282,2732, 640, # 2752
1372,3495,1127, 922, 325,3381,5323,5324, 711,2045,5325,5326,4055,2223,2800,1937, # 2768
4056,3382,2224,2255,3868,2305,5327,4645,3869,1258,3312,4057,3235,2139,2965,4058, # 2784
4059,5328,2225, 258,3236,4646, 101,1227,5329,3313,1755,5330,1391,3314,5331,2924, # 2800
2057, 893,5332,5333,5334,1402,4305,2347,5335,5336,3237,3611,5337,5338, 878,1325, # 2816
1781,2801,4647, 259,1385,2585, 744,1183,2272,4648,5339,4060,2509,5340, 684,1024, # 2832
4306,5341, 472,3612,3496,1165,3315,4061,4062, 322,2153, 881, 455,1695,1152,1340, # 2848
 660, 554,2154,4649,1058,4650,4307, 830,1065,3383,4063,4651,1924,5342,1703,1919, # 2864
5343, 932,2273, 122,5344,4652, 947, 677,5345,3870,2637, 297,1906,1925,2274,4653, # 2880
2322,3316,5346,5347,4308,5348,4309,  84,4310, 112, 989,5349, 547,1059,4064, 701, # 2896
3613,1019,5350,4311,5351,3497, 942, 639, 457,2306,2456, 993,2966, 407, 851, 494, # 2912
4654,3384, 927,5352,1237,5353,2426,3385, 573,4312, 680, 921,2925,1279,1875, 285, # 2928
 790,1448,1984, 719,2168,5354,5355,4655,4065,4066,1649,5356,1541, 563,5357,1077, # 2944
5358,3386,3061,3498, 511,3015,4067,4068,3733,4069,1268,2572,3387,3238,4656,4657, # 2960
5359, 535,1048,1276,1189,2926,2029,3167,1438,1373,2847,2967,1134,2013,5360,4313, # 2976
1238,2586,3109,1259,5361, 700,5362,2968,3168,3734,4314,5363,4315,1146,1876,1907, # 2992
4658,2611,4070, 781,2427, 132,1589, 203, 147, 273,2802,2407, 898,1787,2155,4071, # 3008
4072,5364,3871,2803,5365,5366,4659,4660,5367,3239,5368,1635,3872, 965,5369,1805, # 3024
2699,1516,3614,1121,1082,1329,3317,4073,1449,3873,  65,1128,2848,2927,2769,1590, # 3040
3874,5370,5371,  12,2668,  45, 976,2587,3169,4661, 517,2535,1013,1037,3240,5372, # 3056
3875,2849,5373,3876,5374,3499,5375,2612, 614,1999,2323,3877,3110,2733,2638,5376, # 3072
2588,4316, 599,1269,5377,1811,3735,5378,2700,3111, 759,1060, 489,1806,3388,3318, # 3088
1358,5379,5380,2391,1387,1215,2639,2256, 490,5381,5382,4317,1759,2392,2348,5383, # 3104
4662,3878,1908,4074,2640,1807,3241,4663,3500,3319,2770,2349, 874,5384,5385,3501, # 3120
3736,1859,  91,2928,3737,3062,3879,4664,5386,3170,4075,2669,5387,3502,1202,1403, # 3136
3880,2969,2536,1517,2510,4665,3503,2511,5388,4666,5389,2701,1886,1495,1731,4076, # 3152
2370,4667,5390,2030,5391,5392,4077,2702,1216, 237,2589,4318,2324,4078,3881,4668, # 3168
4669,2703,3615,3504, 445,4670,5393,5394,5395,5396,2771,  61,4079,3738,1823,4080, # 3184
5397, 687,2046, 935, 925, 405,2670, 703,1096,1860,2734,4671,4081,1877,1367,2704, # 3200
3389, 918,2106,1782,2483, 334,3320,1611,1093,4672, 564,3171,3505,3739,3390, 945, # 3216
2641,2058,4673,5398,1926, 872,4319,5399,3506,2705,3112, 349,4320,3740,4082,4674, # 3232
3882,4321,3741,2156,4083,4675,4676,4322,4677,2408,2047, 782,4084, 400, 251,4323, # 3248
1624,5400,5401, 277,3742, 299,1265, 476,1191,3883,2122,4324,4325,1109, 205,5402, # 3264
2590,1000,2157,3616,1861,5403,5404,5405,4678,5406,4679,2573, 107,2484,2158,4085, # 3280
3507,3172,5407,1533, 541,1301, 158, 753,4326,2886,3617,5408,1696, 370,1088,4327, # 3296
4680,3618, 579, 327, 440, 162,2244, 269,1938,1374,3508, 968,3063,  56,1396,3113, # 3312
2107,3321,3391,5409,1927,2159,4681,3016,5410,3619,5411,5412,3743,4682,2485,5413, # 3328
2804,5414,1650,4683,5415,2613,5416,5417,4086,2671,3392,1149,3393,4087,3884,4088, # 3344
5418,1076,  49,5419, 951,3242,3322,3323, 450,2850, 920,5420,1812,2805,2371,4328, # 3360
1909,1138,2372,3885,3509,5421,3243,4684,1910,1147,1518,2428,4685,3886,5422,4686, # 3376
2393,2614, 260,1796,3244,5423,5424,3887,3324, 708,5425,3620,1704,5426,3621,1351, # 3392
1618,3394,3017,1887, 944,4329,3395,4330,3064,3396,4331,5427,3744, 422, 413,1714, # 3408
3325, 500,2059,2350,4332,2486,5428,1344,1911, 954,5429,1668,5430,5431,4089,2409, # 3424
4333,3622,3888,4334,5432,2307,1318,2512,3114, 133,3115,2887,4687, 629,  31,2851, # 3440
2706,3889,4688, 850, 949,4689,4090,2970,1732,2089,4335,1496,1853,5433,4091, 620, # 3456
3245, 981,1242,3745,3397,1619,3746,1643,3326,2140,2457,1971,1719,3510,2169,5434, # 3472
3246,5435,5436,3398,1829,5437,1277,4690,1565,2048,5438,1636,3623,3116,5439, 869, # 3488
2852, 655,3890,3891,3117,4092,3018,3892,1310,3624,4691,5440,5441,5442,1733, 558, # 3504
4692,3747, 335,1549,3065,1756,4336,3748,1946,3511,1830,1291,1192, 470,2735,2108, # 3520
2806, 913,1054,4093,5443,1027,5444,3066,4094,4693, 982,2672,3399,3173,3512,3247, # 3536
3248,1947,2807,5445, 571,4694,5446,1831,5447,3625,2591,1523,2429,5448,2090, 984, # 3552
4695,3749,1960,5449,3750, 852, 923,2808,3513,3751, 969,1519, 999,2049,2325,1705, # 3568
5450,3118, 615,1662, 151, 597,4095,2410,2326,1049, 275,4696,3752,4337, 568,3753, # 3584
3626,2487,4338,3754,5451,2430,2275, 409,3249,5452,1566,2888,3514,1002, 769,2853, # 3600
 194,2091,3174,3755,2226,3327,4339, 628,1505,5453,5454,1763,2180,3019,4096, 521, # 3616
1161,2592,1788,2206,2411,4697,4097,1625,4340,4341, 412,  42,3119, 464,5455,2642, # 3632
4698,3400,1760,1571,2889,3515,2537,1219,2207,3893,2643,2141,2373,4699,4700,3328, # 3648
1651,3401,3627,5456,5457,3628,2488,3516,5458,3756,5459,5460,2276,2092, 460,5461, # 3664
4701,5462,3020, 962, 588,3629, 289,3250,2644,1116,  52,5463,3067,1797,5464,5465, # 3680
5466,1467,5467,1598,1143,3757,4342,1985,1734,1067,4702,1280,3402, 465,4703,1572, # 3696
 510,5468,1928,2245,1813,1644,3630,5469,4704,3758,5470,5471,2673,1573,1534,5472, # 3712
5473, 536,1808,1761,3517,3894,3175,2645,5474,5475,5476,4705,3518,2929,1912,2809, # 3728
5477,3329,1122, 377,3251,5478, 360,5479,5480,4343,1529, 551,5481,2060,3759,1769, # 3744
2431,5482,2930,4344,3330,3120,2327,2109,2031,4706,1404, 136,1468,1479, 672,1171, # 3760
3252,2308, 271,3176,5483,2772,5484,2050, 678,2736, 865,1948,4707,5485,2014,4098, # 3776
2971,5486,2737,2227,1397,3068,3760,4708,4709,1735,2931,3403,3631,5487,3895, 509, # 3792
2854,2458,2890,3896,5488,5489,3177,3178,4710,4345,2538,4711,2309,1166,1010, 552, # 3808
 681,1888,5490,5491,2972,2973,4099,1287,1596,1862,3179, 358, 453, 736, 175, 478, # 3824
1117, 905,1167,1097,5492,1854,1530,5493,1706,5494,2181,3519,2292,3761,3520,3632, # 3840
4346,2093,4347,5495,3404,1193,2489,4348,1458,2193,2208,1863,1889,1421,3331,2932, # 3856
3069,2182,3521, 595,2123,5496,4100,5497,5498,4349,1707,2646, 223,3762,1359, 751, # 3872
3121, 183,3522,5499,2810,3021, 419,2374, 633, 704,3897,2394, 241,5500,5501,5502, # 3888
 838,3022,3763,2277,2773,2459,3898,1939,2051,4101,1309,3122,2246,1181,5503,1136, # 3904
2209,3899,2375,1446,4350,2310,4712,5504,5505,4351,1055,2615, 484,3764,5506,4102, # 3920
 625,4352,2278,3405,1499,4353,4103,5507,4104,4354,3253,2279,2280,3523,5508,5509, # 3936
2774, 808,2616,3765,3406,4105,4355,3123,2539, 526,3407,3900,4356, 955,5510,1620, # 3952
4357,2647,2432,5511,1429,3766,1669,1832, 994, 928,5512,3633,1260,5513,5514,5515, # 3968
1949,2293, 741,2933,1626,4358,2738,2460, 867,1184, 362,3408,1392,5516,5517,4106, # 3984
4359,1770,1736,3254,2934,4713,4714,1929,2707,1459,1158,5518,3070,3409,2891,1292, # 4000
1930,2513,2855,3767,1986,1187,2072,2015,2617,4360,5519,2574,2514,2170,3768,2490, # 4016
3332,5520,3769,4715,5521,5522, 666,1003,3023,1022,3634,4361,5523,4716,1814,2257, # 4032
 574,3901,1603, 295,1535, 705,3902,4362, 283, 858, 417,5524,5525,3255,4717,4718, # 4048
3071,1220,1890,1046,2281,2461,4107,1393,1599, 689,2575, 388,4363,5526,2491, 802, # 4064
5527,2811,3903,2061,1405,2258,5528,4719,3904,2110,1052,1345,3256,1585,5529, 809, # 4080
5530,5531,5532, 575,2739,3524, 956,1552,1469,1144,2328,5533,2329,1560,2462,3635, # 4096
3257,4108, 616,2210,4364,3180,2183,2294,5534,1833,5535,3525,4720,5536,1319,3770, # 4112
3771,1211,3636,1023,3258,1293,2812,5537,5538,5539,3905, 607,2311,3906, 762,2892, # 4128
1439,4365,1360,4721,1485,3072,5540,4722,1038,4366,1450,2062,2648,4367,1379,4723, # 4144
2593,5541,5542,4368,1352,1414,2330,2935,1172,5543,5544,3907,3908,4724,1798,1451, # 4160
5545,5546,5547,5548,2936,4109,4110,2492,2351, 411,4111,4112,3637,3333,3124,4725, # 4176
1561,2674,1452,4113,1375,5549,5550,  47,2974, 316,5551,1406,1591,2937,3181,5552, # 4192
1025,2142,3125,3182, 354,2740, 884,2228,4369,2412, 508,3772, 726,3638, 996,2433, # 4208
3639, 729,5553, 392,2194,1453,4114,4726,3773,5554,5555,2463,3640,2618,1675,2813, # 4224
 919,2352,2975,2353,1270,4727,4115,  73,5556,5557, 647,5558,3259,2856,2259,1550, # 4240
1346,3024,5559,1332, 883,3526,5560,5561,5562,5563,3334,2775,5564,1212, 831,1347, # 4256
4370,4728,2331,3909,1864,3073, 720,3910,4729,4730,3911,5565,4371,5566,5567,4731, # 4272
5568,5569,1799,4732,3774,2619,4733,3641,1645,2376,4734,5570,2938, 669,2211,2675, # 4288
2434,5571,2893,5572,5573,1028,3260,5574,4372,2413,5575,2260,1353,5576,5577,4735, # 4304
3183, 518,5578,4116,5579,4373,1961,5580,2143,4374,5581,5582,3025,2354,2355,3912, # 4320
 516,1834,1454,4117,2708,4375,4736,2229,2620,1972,1129,3642,5583,2776,5584,2976, # 4336
1422, 577,1470,3026,1524,3410,5585,5586, 432,4376,3074,3527,5587,2594,1455,2515, # 4352
2230,1973,1175,5588,1020,2741,4118,3528,4737,5589,2742,5590,1743,1361,3075,3529, # 4368
2649,4119,4377,4738,2295, 895, 924,4378,2171, 331,2247,3076, 166,1627,3077,1098, # 4384
5591,1232,2894,2231,3411,4739, 657, 403,1196,2377, 542,3775,3412,1600,4379,3530, # 4400
5592,4740,2777,3261, 576, 530,1362,4741,4742,2540,2676,3776,4120,5593, 842,3913, # 4416
5594,2814,2032,1014,4121, 213,2709,3413, 665, 621,4380,5595,3777,2939,2435,5596, # 4432
2436,3335,3643,3414,4743,4381,2541,4382,4744,3644,1682,4383,3531,1380,5597, 724, # 4448
2282, 600,1670,5598,1337,1233,4745,3126,2248,5599,1621,4746,5600, 651,4384,5601, # 4464
1612,4385,2621,5602,2857,5603,2743,2312,3078,5604, 716,2464,3079, 174,1255,2710, # 4480
4122,3645, 548,1320,1398, 728,4123,1574,5605,1891,1197,3080,4124,5606,3081,3082, # 4496
3778,3646,3779, 747,5607, 635,4386,4747,5608,5609,5610,4387,5611,5612,4748,5613, # 4512
3415,4749,2437, 451,5614,3780,2542,2073,4388,2744,4389,4125,5615,1764,4750,5616, # 4528
4390, 350,4751,2283,2395,2493,5617,4391,4126,2249,1434,4127, 488,4752, 458,4392, # 4544
4128,3781, 771,1330,2396,3914,2576,3184,2160,2414,1553,2677,3185,4393,5618,2494, # 4560
2895,2622,1720,2711,4394,3416,4753,5619,2543,4395,5620,3262,4396,2778,5621,2016, # 4576
2745,5622,1155,1017,3782,3915,5623,3336,2313, 201,1865,4397,1430,5624,4129,5625, # 4592
5626,5627,5628,5629,4398,1604,5630, 414,1866, 371,2595,4754,4755,3532,2017,3127, # 4608
4756,1708, 960,4399, 887, 389,2172,1536,1663,1721,5631,2232,4130,2356,2940,1580, # 4624
5632,5633,1744,4757,2544,4758,4759,5634,4760,5635,2074,5636,4761,3647,3417,2896, # 4640
4400,5637,4401,2650,3418,2815, 673,2712,2465, 709,3533,4131,3648,4402,5638,1148, # 4656
 502, 634,5639,5640,1204,4762,3649,1575,4763,2623,3783,5641,3784,3128, 948,3263, # 4672
 121,1745,3916,1110,5642,4403,3083,2516,3027,4132,3785,1151,1771,3917,1488,4133, # 4688
1987,5643,2438,3534,5644,5645,2094,5646,4404,3918,1213,1407,2816, 531,2746,2545, # 4704
3264,1011,1537,4764,2779,4405,3129,1061,5647,3786,3787,1867,2897,5648,2018, 120, # 4720
4406,4407,2063,3650,3265,2314,3919,2678,3419,1955,4765,4134,5649,3535,1047,2713, # 4736
1266,5650,1368,4766,2858, 649,3420,3920,2546,2747,1102,2859,2679,5651,5652,2000, # 4752
5653,1111,3651,2977,5654,2495,3921,3652,2817,1855,3421,3788,5655,5656,3422,2415, # 4768
2898,3337,3266,3653,5657,2577,5658,3654,2818,4135,1460, 856,5659,3655,5660,2899, # 4784
2978,5661,2900,3922,5662,4408, 632,2517, 875,3923,1697,3924,2296,5663,5664,4767, # 4800
3028,1239, 580,4768,4409,5665, 914, 936,2075,1190,4136,1039,2124,5666,5667,5668, # 4816
5669,3423,1473,5670,1354,4410,3925,4769,2173,3084,4137, 915,3338,4411,4412,3339, # 4832
1605,1835,5671,2748, 398,3656,4413,3926,4138, 328,1913,2860,4139,3927,1331,4414, # 4848
3029, 937,4415,5672,3657,4140,4141,3424,2161,4770,3425, 524, 742, 538,3085,1012, # 4864
5673,5674,3928,2466,5675, 658,1103, 225,3929,5676,5677,4771,5678,4772,5679,3267, # 4880
1243,5680,4142, 963,2250,4773,5681,2714,3658,3186,5682,5683,2596,2332,5684,4774, # 4896
5685,5686,5687,3536, 957,3426,2547,2033,1931,2941,2467, 870,2019,3659,1746,2780, # 4912
2781,2439,2468,5688,3930,5689,3789,3130,3790,3537,3427,3791,5690,1179,3086,5691, # 4928
3187,2378,4416,3792,2548,3188,3131,2749,4143,5692,3428,1556,2549,2297, 977,2901, # 4944
2034,4144,1205,3429,5693,1765,3430,3189,2125,1271, 714,1689,4775,3538,5694,2333, # 4960
3931, 533,4417,3660,2184, 617,5695,2469,3340,3539,2315,5696,5697,3190,5698,5699, # 4976
3932,1988, 618, 427,2651,3540,3431,5700,5701,1244,1690,5702,2819,4418,4776,5703, # 4992
3541,4777,5704,2284,1576, 473,3661,4419,3432, 972,5705,3662,5706,3087,5707,5708, # 5008
4778,4779,5709,3793,4145,4146,5710, 153,4780, 356,5711,1892,2902,4420,2144, 408, # 5024
 803,2357,5712,3933,5713,4421,1646,2578,2518,4781,4782,3934,5714,3935,4422,5715, # 5040
2416,3433, 752,5716,5717,1962,3341,2979,5718, 746,3030,2470,4783,4423,3794, 698, # 5056
4784,1893,4424,3663,2550,4785,3664,3936,5719,3191,3434,5720,1824,1302,4147,2715, # 5072
3937,1974,4425,5721,4426,3192, 823,1303,1288,1236,2861,3542,4148,3435, 774,3938, # 5088
5722,1581,4786,1304,2862,3939,4787,5723,2440,2162,1083,3268,4427,4149,4428, 344, # 5104
1173, 288,2316, 454,1683,5724,5725,1461,4788,4150,2597,5726,5727,4789, 985, 894, # 5120
5728,3436,3193,5729,1914,2942,3795,1989,5730,2111,1975,5731,4151,5732,2579,1194, # 5136
 425,5733,4790,3194,1245,3796,4429,5734,5735,2863,5736, 636,4791,1856,3940, 760, # 5152
1800,5737,4430,2212,1508,4792,4152,1894,1684,2298,5738,5739,4793,4431,4432,2213, # 5168
 479,5740,5741, 832,5742,4153,2496,5743,2980,2497,3797, 990,3132, 627,1815,2652, # 5184
4433,1582,4434,2126,2112,3543,4794,5744, 799,4435,3195,5745,4795,2113,1737,3031, # 5200
1018, 543, 754,4436,3342,1676,4796,4797,4154,4798,1489,5746,3544,5747,2624,2903, # 5216
4155,5748,5749,2981,5750,5751,5752,5753,3196,4799,4800,2185,1722,5754,3269,3270, # 5232
1843,3665,1715, 481, 365,1976,1857,5755,5756,1963,2498,4801,5757,2127,3666,3271, # 5248
 433,1895,2064,2076,5758, 602,2750,5759,5760,5761,5762,5763,3032,1628,3437,5764, # 5264
3197,4802,4156,2904,4803,2519,5765,2551,2782,5766,5767,5768,3343,4804,2905,5769, # 5280
4805,5770,2864,4806,4807,1221,2982,4157,2520,5771,5772,5773,1868,1990,5774,5775, # 5296
5776,1896,5777,5778,4808,1897,4158, 318,5779,2095,4159,4437,5780,5781, 485,5782, # 5312
 938,3941, 553,2680, 116,5783,3942,3667,5784,3545,2681,2783,3438,3344,2820,5785, # 5328
3668,2943,4160,1747,2944,2983,5786,5787, 207,5788,4809,5789,4810,2521,5790,3033, # 5344
 890,3669,3943,5791,1878,3798,3439,5792,2186,2358,3440,1652,5793,5794,5795, 941, # 5360
2299, 208,3546,4161,2020, 330,4438,3944,2906,2499,3799,4439,4811,5796,5797,5798, # 5376  #last 512
#Everything below is of no interest for detection purpose
2522,1613,4812,5799,3345,3945,2523,5800,4162,5801,1637,4163,2471,4813,3946,5802, # 5392
2500,3034,3800,5803,5804,2195,4814,5805,2163,5806,5807,5808,5809,5810,5811,5812, # 5408
5813,5814,5815,5816,5817,5818,5819,5820,5821,5822,5823,5824,5825,5826,5827,5828, # 5424
5829,5830,5831,5832,5833,5834,5835,5836,5837,5838,5839,5840,5841,5842,5843,5844, # 5440
5845,5846,5847,5848,5849,5850,5851,5852,5853,5854,5855,5856,5857,5858,5859,5860, # 5456
5861,5862,5863,5864,5865,5866,5867,5868,5869,5870,5871,5872,5873,5874,5875,5876, # 5472
5877,5878,5879,5880,5881,5882,5883,5884,5885,5886,5887,5888,5889,5890,5891,5892, # 5488
5893,5894,5895,5896,5897,5898,5899,5900,5901,5902,5903,5904,5905,5906,5907,5908, # 5504
5909,5910,5911,5912,5913,5914,5915,5916,5917,5918,5919,5920,5921,5922,5923,5924, # 5520
5925,5926,5927,5928,5929,5930,5931,5932,5933,5934,5935,5936,5937,5938,5939,5940, # 5536
5941,5942,5943,5944,5945,5946,5947,5948,5949,5950,5951,5952,5953,5954,5955,5956, # 5552
5957,5958,5959,5960,5961,5962,5963,5964,5965,5966,5967,5968,5969,5970,5971,5972, # 5568
5973,5974,5975,5976,5977,5978,5979,5980,5981,5982,5983,5984,5985,5986,5987,5988, # 5584
5989,5990,5991,5992,5993,5994,5995,5996,5997,5998,5999,6000,6001,6002,6003,6004, # 5600
6005,6006,6007,6008,6009,6010,6011,6012,6013,6014,6015,6016,6017,6018,6019,6020, # 5616
6021,6022,6023,6024,6025,6026,6027,6028,6029,6030,6031,6032,6033,6034,6035,6036, # 5632
6037,6038,6039,6040,6041,6042,6043,6044,6045,6046,6047,6048,6049,6050,6051,6052, # 5648
6053,6054,6055,6056,6057,6058,6059,6060,6061,6062,6063,6064,6065,6066,6067,6068, # 5664
6069,6070,6071,6072,6073,6074,6075,6076,6077,6078,6079,6080,6081,6082,6083,6084, # 5680
6085,6086,6087,6088,6089,6090,6091,6092,6093,6094,6095,6096,6097,6098,6099,6100, # 5696
6101,6102,6103,6104,6105,6106,6107,6108,6109,6110,6111,6112,6113,6114,6115,6116, # 5712
6117,6118,6119,6120,6121,6122,6123,6124,6125,6126,6127,6128,6129,6130,6131,6132, # 5728
6133,6134,6135,6136,6137,6138,6139,6140,6141,6142,6143,6144,6145,6146,6147,6148, # 5744
6149,6150,6151,6152,6153,6154,6155,6156,6157,6158,6159,6160,6161,6162,6163,6164, # 5760
6165,6166,6167,6168,6169,6170,6171,6172,6173,6174,6175,6176,6177,6178,6179,6180, # 5776
6181,6182,6183,6184,6185,6186,6187,6188,6189,6190,6191,6192,6193,6194,6195,6196, # 5792
6197,6198,6199,6200,6201,6202,6203,6204,6205,6206,6207,6208,6209,6210,6211,6212, # 5808
6213,6214,6215,6216,6217,6218,6219,6220,6221,6222,6223,3670,6224,6225,6226,6227, # 5824
6228,6229,6230,6231,6232,6233,6234,6235,6236,6237,6238,6239,6240,6241,6242,6243, # 5840
6244,6245,6246,6247,6248,6249,6250,6251,6252,6253,6254,6255,6256,6257,6258,6259, # 5856
6260,6261,6262,6263,6264,6265,6266,6267,6268,6269,6270,6271,6272,6273,6274,6275, # 5872
6276,6277,6278,6279,6280,6281,6282,6283,6284,6285,4815,6286,6287,6288,6289,6290, # 5888
6291,6292,4816,6293,6294,6295,6296,6297,6298,6299,6300,6301,6302,6303,6304,6305, # 5904
6306,6307,6308,6309,6310,6311,4817,4818,6312,6313,6314,6315,6316,6317,6318,4819, # 5920
6319,6320,6321,6322,6323,6324,6325,6326,6327,6328,6329,6330,6331,6332,6333,6334, # 5936
6335,6336,6337,4820,6338,6339,6340,6341,6342,6343,6344,6345,6346,6347,6348,6349, # 5952
6350,6351,6352,6353,6354,6355,6356,6357,6358,6359,6360,6361,6362,6363,6364,6365, # 5968
6366,6367,6368,6369,6370,6371,6372,6373,6374,6375,6376,6377,6378,6379,6380,6381, # 5984
6382,6383,6384,6385,6386,6387,6388,6389,6390,6391,6392,6393,6394,6395,6396,6397, # 6000
6398,6399,6400,6401,6402,6403,6404,6405,6406,6407,6408,6409,6410,3441,6411,6412, # 6016
6413,6414,6415,6416,6417,6418,6419,6420,6421,6422,6423,6424,6425,4440,6426,6427, # 6032
6428,6429,6430,6431,6432,6433,6434,6435,6436,6437,6438,6439,6440,6441,6442,6443, # 6048
6444,6445,6446,6447,6448,6449,6450,6451,6452,6453,6454,4821,6455,6456,6457,6458, # 6064
6459,6460,6461,6462,6463,6464,6465,6466,6467,6468,6469,6470,6471,6472,6473,6474, # 6080
6475,6476,6477,3947,3948,6478,6479,6480,6481,3272,4441,6482,6483,6484,6485,4442, # 6096
6486,6487,6488,6489,6490,6491,6492,6493,6494,6495,6496,4822,6497,6498,6499,6500, # 6112
6501,6502,6503,6504,6505,6506,6507,6508,6509,6510,6511,6512,6513,6514,6515,6516, # 6128
6517,6518,6519,6520,6521,6522,6523,6524,6525,6526,6527,6528,6529,6530,6531,6532, # 6144
6533,6534,6535,6536,6537,6538,6539,6540,6541,6542,6543,6544,6545,6546,6547,6548, # 6160
6549,6550,6551,6552,6553,6554,6555,6556,2784,6557,4823,6558,6559,6560,6561,6562, # 6176
6563,6564,6565,6566,6567,6568,6569,3949,6570,6571,6572,4824,6573,6574,6575,6576, # 6192
6577,6578,6579,6580,6581,6582,6583,4825,6584,6585,6586,3950,2785,6587,6588,6589, # 6208
6590,6591,6592,6593,6594,6595,6596,6597,6598,6599,6600,6601,6602,6603,6604,6605, # 6224
6606,6607,6608,6609,6610,6611,6612,4826,6613,6614,6615,4827,6616,6617,6618,6619, # 6240
6620,6621,6622,6623,6624,6625,4164,6626,6627,6628,6629,6630,6631,6632,6633,6634, # 6256
3547,6635,4828,6636,6637,6638,6639,6640,6641,6642,3951,2984,6643,6644,6645,6646, # 6272
6647,6648,6649,4165,6650,4829,6651,6652,4830,6653,6654,6655,6656,6657,6658,6659, # 6288
6660,6661,6662,4831,6663,6664,6665,6666,6667,6668,6669,6670,6671,4166,6672,4832, # 6304
3952,6673,6674,6675,6676,4833,6677,6678,6679,4167,6680,6681,6682,3198,6683,6684, # 6320
6685,6686,6687,6688,6689,6690,6691,6692,6693,6694,6695,6696,6697,4834,6698,6699, # 6336
6700,6701,6702,6703,6704,6705,6706,6707,6708,6709,6710,6711,6712,6713,6714,6715, # 6352
6716,6717,6718,6719,6720,6721,6722,6723,6724,6725,6726,6727,6728,6729,6730,6731, # 6368
6732,6733,6734,4443,6735,6736,6737,6738,6739,6740,6741,6742,6743,6744,6745,4444, # 6384
6746,6747,6748,6749,6750,6751,6752,6753,6754,6755,6756,6757,6758,6759,6760,6761, # 6400
6762,6763,6764,6765,6766,6767,6768,6769,6770,6771,6772,6773,6774,6775,6776,6777, # 6416
6778,6779,6780,6781,4168,6782,6783,3442,6784,6785,6786,6787,6788,6789,6790,6791, # 6432
4169,6792,6793,6794,6795,6796,6797,6798,6799,6800,6801,6802,6803,6804,6805,6806, # 6448
6807,6808,6809,6810,6811,4835,6812,6813,6814,4445,6815,6816,4446,6817,6818,6819, # 6464
6820,6821,6822,6823,6824,6825,6826,6827,6828,6829,6830,6831,6832,6833,6834,6835, # 6480
3548,6836,6837,6838,6839,6840,6841,6842,6843,6844,6845,6846,4836,6847,6848,6849, # 6496
6850,6851,6852,6853,6854,3953,6855,6856,6857,6858,6859,6860,6861,6862,6863,6864, # 6512
6865,6866,6867,6868,6869,6870,6871,6872,6873,6874,6875,6876,6877,3199,6878,6879, # 6528
6880,6881,6882,4447,6883,6884,6885,6886,6887,6888,6889,6890,6891,6892,6893,6894, # 6544
6895,6896,6897,6898,6899,6900,6901,6902,6903,6904,4170,6905,6906,6907,6908,6909, # 6560
6910,6911,6912,6913,6914,6915,6916,6917,6918,6919,6920,6921,6922,6923,6924,6925, # 6576
6926,6927,4837,6928,6929,6930,6931,6932,6933,6934,6935,6936,3346,6937,6938,4838, # 6592
6939,6940,6941,4448,6942,6943,6944,6945,6946,4449,6947,6948,6949,6950,6951,6952, # 6608
6953,6954,6955,6956,6957,6958,6959,6960,6961,6962,6963,6964,6965,6966,6967,6968, # 6624
6969,6970,6971,6972,6973,6974,6975,6976,6977,6978,6979,6980,6981,6982,6983,6984, # 6640
6985,6986,6987,6988,6989,6990,6991,6992,6993,6994,3671,6995,6996,6997,6998,4839, # 6656
6999,7000,7001,7002,3549,7003,7004,7005,7006,7007,7008,7009,7010,7011,7012,7013, # 6672
7014,7015,7016,7017,7018,7019,7020,7021,7022,7023,7024,7025,7026,7027,7028,7029, # 6688
7030,4840,7031,7032,7033,7034,7035,7036,7037,7038,4841,7039,7040,7041,7042,7043, # 6704
7044,7045,7046,7047,7048,7049,7050,7051,7052,7053,7054,7055,7056,7057,7058,7059, # 6720
7060,7061,7062,7063,7064,7065,7066,7067,7068,7069,7070,2985,7071,7072,7073,7074, # 6736
7075,7076,7077,7078,7079,7080,4842,7081,7082,7083,7084,7085,7086,7087,7088,7089, # 6752
7090,7091,7092,7093,7094,7095,7096,7097,7098,7099,7100,7101,7102,7103,7104,7105, # 6768
7106,7107,7108,7109,7110,7111,7112,7113,7114,7115,7116,7117,7118,4450,7119,7120, # 6784
7121,7122,7123,7124,7125,7126,7127,7128,7129,7130,7131,7132,7133,7134,7135,7136, # 6800
7137,7138,7139,7140,7141,7142,7143,4843,7144,7145,7146,7147,7148,7149,7150,7151, # 6816
7152,7153,7154,7155,7156,7157,7158,7159,7160,7161,7162,7163,7164,7165,7166,7167, # 6832
7168,7169,7170,7171,7172,7173,7174,7175,7176,7177,7178,7179,7180,7181,7182,7183, # 6848
7184,7185,7186,7187,7188,4171,4172,7189,7190,7191,7192,7193,7194,7195,7196,7197, # 6864
7198,7199,7200,7201,7202,7203,7204,7205,7206,7207,7208,7209,7210,7211,7212,7213, # 6880
7214,7215,7216,7217,7218,7219,7220,7221,7222,7223,7224,7225,7226,7227,7228,7229, # 6896
7230,7231,7232,7233,7234,7235,7236,7237,7238,7239,7240,7241,7242,7243,7244,7245, # 6912
7246,7247,7248,7249,7250,7251,7252,7253,7254,7255,7256,7257,7258,7259,7260,7261, # 6928
7262,7263,7264,7265,7266,7267,7268,7269,7270,7271,7272,7273,7274,7275,7276,7277, # 6944
7278,7279,7280,7281,7282,7283,7284,7285,7286,7287,7288,7289,7290,7291,7292,7293, # 6960
7294,7295,7296,4844,7297,7298,7299,7300,7301,7302,7303,7304,7305,7306,7307,7308, # 6976
7309,7310,7311,7312,7313,7314,7315,7316,4451,7317,7318,7319,7320,7321,7322,7323, # 6992
7324,7325,7326,7327,7328,7329,7330,7331,7332,7333,7334,7335,7336,7337,7338,7339, # 7008
7340,7341,7342,7343,7344,7345,7346,7347,7348,7349,7350,7351,7352,7353,4173,7354, # 7024
7355,4845,7356,7357,7358,7359,7360,7361,7362,7363,7364,7365,7366,7367,7368,7369, # 7040
7370,7371,7372,7373,7374,7375,7376,7377,7378,7379,7380,7381,7382,7383,7384,7385, # 7056
7386,7387,7388,4846,7389,7390,7391,7392,7393,7394,7395,7396,7397,7398,7399,7400, # 7072
7401,7402,7403,7404,7405,3672,7406,7407,7408,7409,7410,7411,7412,7413,7414,7415, # 7088
7416,7417,7418,7419,7420,7421,7422,7423,7424,7425,7426,7427,7428,7429,7430,7431, # 7104
7432,7433,7434,7435,7436,7437,7438,7439,7440,7441,7442,7443,7444,7445,7446,7447, # 7120
7448,7449,7450,7451,7452,7453,4452,7454,3200,7455,7456,7457,7458,7459,7460,7461, # 7136
7462,7463,7464,7465,7466,7467,7468,7469,7470,7471,7472,7473,7474,4847,7475,7476, # 7152
7477,3133,7478,7479,7480,7481,7482,7483,7484,7485,7486,7487,7488,7489,7490,7491, # 7168
7492,7493,7494,7495,7496,7497,7498,7499,7500,7501,7502,3347,7503,7504,7505,7506, # 7184
7507,7508,7509,7510,7511,7512,7513,7514,7515,7516,7517,7518,7519,7520,7521,4848, # 7200
7522,7523,7524,7525,7526,7527,7528,7529,7530,7531,7532,7533,7534,7535,7536,7537, # 7216
7538,7539,7540,7541,7542,7543,7544,7545,7546,7547,7548,7549,3801,4849,7550,7551, # 7232
7552,7553,7554,7555,7556,7557,7558,7559,7560,7561,7562,7563,7564,7565,7566,7567, # 7248
7568,7569,3035,7570,7571,7572,7573,7574,7575,7576,7577,7578,7579,7580,7581,7582, # 7264
7583,7584,7585,7586,7587,7588,7589,7590,7591,7592,7593,7594,7595,7596,7597,7598, # 7280
7599,7600,7601,7602,7603,7604,7605,7606,7607,7608,7609,7610,7611,7612,7613,7614, # 7296
7615,7616,4850,7617,7618,3802,7619,7620,7621,7622,7623,7624,7625,7626,7627,7628, # 7312
7629,7630,7631,7632,4851,7633,7634,7635,7636,7637,7638,7639,7640,7641,7642,7643, # 7328
7644,7645,7646,7647,7648,7649,7650,7651,7652,7653,7654,7655,7656,7657,7658,7659, # 7344
7660,7661,7662,7663,7664,7665,7666,7667,7668,7669,7670,4453,7671,7672,7673,7674, # 7360
7675,7676,7677,7678,7679,7680,7681,7682,7683,7684,7685,7686,7687,7688,7689,7690, # 7376
7691,7692,7693,7694,7695,7696,7697,3443,7698,7699,7700,7701,7702,4454,7703,7704, # 7392
7705,7706,7707,7708,7709,7710,7711,7712,7713,2472,7714,7715,7716,7717,7718,7719, # 7408
7720,7721,7722,7723,7724,7725,7726,7727,7728,7729,7730,7731,3954,7732,7733,7734, # 7424
7735,7736,7737,7738,7739,7740,7741,7742,7743,7744,7745,7746,7747,7748,7749,7750, # 7440
3134,7751,7752,4852,7753,7754,7755,4853,7756,7757,7758,7759,7760,4174,7761,7762, # 7456
7763,7764,7765,7766,7767,7768,7769,7770,7771,7772,7773,7774,7775,7776,7777,7778, # 7472
7779,7780,7781,7782,7783,7784,7785,7786,7787,7788,7789,7790,7791,7792,7793,7794, # 7488
7795,7796,7797,7798,7799,7800,7801,7802,7803,7804,7805,4854,7806,7807,7808,7809, # 7504
7810,7811,7812,7813,7814,7815,7816,7817,7818,7819,7820,7821,7822,7823,7824,7825, # 7520
4855,7826,7827,7828,7829,7830,7831,7832,7833,7834,7835,7836,7837,7838,7839,7840, # 7536
7841,7842,7843,7844,7845,7846,7847,3955,7848,7849,7850,7851,7852,7853,7854,7855, # 7552
7856,7857,7858,7859,7860,3444,7861,7862,7863,7864,7865,7866,7867,7868,7869,7870, # 7568
7871,7872,7873,7874,7875,7876,7877,7878,7879,7880,7881,7882,7883,7884,7885,7886, # 7584
7887,7888,7889,7890,7891,4175,7892,7893,7894,7895,7896,4856,4857,7897,7898,7899, # 7600
7900,2598,7901,7902,7903,7904,7905,7906,7907,7908,4455,7909,7910,7911,7912,7913, # 7616
7914,3201,7915,7916,7917,7918,7919,7920,7921,4858,7922,7923,7924,7925,7926,7927, # 7632
7928,7929,7930,7931,7932,7933,7934,7935,7936,7937,7938,7939,7940,7941,7942,7943, # 7648
7944,7945,7946,7947,7948,7949,7950,7951,7952,7953,7954,7955,7956,7957,7958,7959, # 7664
7960,7961,7962,7963,7964,7965,7966,7967,7968,7969,7970,7971,7972,7973,7974,7975, # 7680
7976,7977,7978,7979,7980,7981,4859,7982,7983,7984,7985,7986,7987,7988,7989,7990, # 7696
7991,7992,7993,7994,7995,7996,4860,7997,7998,7999,8000,8001,8002,8003,8004,8005, # 7712
8006,8007,8008,8009,8010,8011,8012,8013,8014,8015,8016,4176,8017,8018,8019,8020, # 7728
8021,8022,8023,4861,8024,8025,8026,8027,8028,8029,8030,8031,8032,8033,8034,8035, # 7744
8036,4862,4456,8037,8038,8039,8040,4863,8041,8042,8043,8044,8045,8046,8047,8048, # 7760
8049,8050,8051,8052,8053,8054,8055,8056,8057,8058,8059,8060,8061,8062,8063,8064, # 7776
8065,8066,8067,8068,8069,8070,8071,8072,8073,8074,8075,8076,8077,8078,8079,8080, # 7792
8081,8082,8083,8084,8085,8086,8087,8088,8089,8090,8091,8092,8093,8094,8095,8096, # 7808
8097,8098,8099,4864,4177,8100,8101,8102,8103,8104,8105,8106,8107,8108,8109,8110, # 7824
8111,8112,8113,8114,8115,8116,8117,8118,8119,8120,4178,8121,8122,8123,8124,8125, # 7840
8126,8127,8128,8129,8130,8131,8132,8133,8134,8135,8136,8137,8138,8139,8140,8141, # 7856
8142,8143,8144,8145,4865,4866,8146,8147,8148,8149,8150,8151,8152,8153,8154,8155, # 7872
8156,8157,8158,8159,8160,8161,8162,8163,8164,8165,4179,8166,8167,8168,8169,8170, # 7888
8171,8172,8173,8174,8175,8176,8177,8178,8179,8180,8181,4457,8182,8183,8184,8185, # 7904
8186,8187,8188,8189,8190,8191,8192,8193,8194,8195,8196,8197,8198,8199,8200,8201, # 7920
8202,8203,8204,8205,8206,8207,8208,8209,8210,8211,8212,8213,8214,8215,8216,8217, # 7936
8218,8219,8220,8221,8222,8223,8224,8225,8226,8227,8228,8229,8230,8231,8232,8233, # 7952
8234,8235,8236,8237,8238,8239,8240,8241,8242,8243,8244,8245,8246,8247,8248,8249, # 7968
8250,8251,8252,8253,8254,8255,8256,3445,8257,8258,8259,8260,8261,8262,4458,8263, # 7984
8264,8265,8266,8267,8268,8269,8270,8271,8272,4459,8273,8274,8275,8276,3550,8277, # 8000
8278,8279,8280,8281,8282,8283,8284,8285,8286,8287,8288,8289,4460,8290,8291,8292, # 8016
8293,8294,8295,8296,8297,8298,8299,8300,8301,8302,8303,8304,8305,8306,8307,4867, # 8032
8308,8309,8310,8311,8312,3551,8313,8314,8315,8316,8317,8318,8319,8320,8321,8322, # 8048
8323,8324,8325,8326,4868,8327,8328,8329,8330,8331,8332,8333,8334,8335,8336,8337, # 8064
8338,8339,8340,8341,8342,8343,8344,8345,8346,8347,8348,8349,8350,8351,8352,8353, # 8080
8354,8355,8356,8357,8358,8359,8360,8361,8362,8363,4869,4461,8364,8365,8366,8367, # 8096
8368,8369,8370,4870,8371,8372,8373,8374,8375,8376,8377,8378,8379,8380,8381,8382, # 8112
8383,8384,8385,8386,8387,8388,8389,8390,8391,8392,8393,8394,8395,8396,8397,8398, # 8128
8399,8400,8401,8402,8403,8404,8405,8406,8407,8408,8409,8410,4871,8411,8412,8413, # 8144
8414,8415,8416,8417,8418,8419,8420,8421,8422,4462,8423,8424,8425,8426,8427,8428, # 8160
8429,8430,8431,8432,8433,2986,8434,8435,8436,8437,8438,8439,8440,8441,8442,8443, # 8176
8444,8445,8446,8447,8448,8449,8450,8451,8452,8453,8454,8455,8456,8457,8458,8459, # 8192
8460,8461,8462,8463,8464,8465,8466,8467,8468,8469,8470,8471,8472,8473,8474,8475, # 8208
8476,8477,8478,4180,8479,8480,8481,8482,8483,8484,8485,8486,8487,8488,8489,8490, # 8224
8491,8492,8493,8494,8495,8496,8497,8498,8499,8500,8501,8502,8503,8504,8505,8506, # 8240
8507,8508,8509,8510,8511,8512,8513,8514,8515,8516,8517,8518,8519,8520,8521,8522, # 8256
8523,8524,8525,8526,8527,8528,8529,8530,8531,8532,8533,8534,8535,8536,8537,8538, # 8272
8539,8540,8541,8542,8543,8544,8545,8546,8547,8548,8549,8550,8551,8552,8553,8554, # 8288
8555,8556,8557,8558,8559,8560,8561,8562,8563,8564,4872,8565,8566,8567,8568,8569, # 8304
8570,8571,8572,8573,4873,8574,8575,8576,8577,8578,8579,8580,8581,8582,8583,8584, # 8320
8585,8586,8587,8588,8589,8590,8591,8592,8593,8594,8595,8596,8597,8598,8599,8600, # 8336
8601,8602,8603,8604,8605,3803,8606,8607,8608,8609,8610,8611,8612,8613,4874,3804, # 8352
8614,8615,8616,8617,8618,8619,8620,8621,3956,8622,8623,8624,8625,8626,8627,8628, # 8368
8629,8630,8631,8632,8633,8634,8635,8636,8637,8638,2865,8639,8640,8641,8642,8643, # 8384
8644,8645,8646,8647,8648,8649,8650,8651,8652,8653,8654,8655,8656,4463,8657,8658, # 8400
8659,4875,4876,8660,8661,8662,8663,8664,8665,8666,8667,8668,8669,8670,8671,8672, # 8416
8673,8674,8675,8676,8677,8678,8679,8680,8681,4464,8682,8683,8684,8685,8686,8687, # 8432
8688,8689,8690,8691,8692,8693,8694,8695,8696,8697,8698,8699,8700,8701,8702,8703, # 8448
8704,8705,8706,8707,8708,8709,2261,8710,8711,8712,8713,8714,8715,8716,8717,8718, # 8464
8719,8720,8721,8722,8723,8724,8725,8726,8727,8728,8729,8730,8731,8732,8733,4181, # 8480
8734,8735,8736,8737,8738,8739,8740,8741,8742,8743,8744,8745,8746,8747,8748,8749, # 8496
8750,8751,8752,8753,8754,8755,8756,8757,8758,8759,8760,8761,8762,8763,4877,8764, # 8512
8765,8766,8767,8768,8769,8770,8771,8772,8773,8774,8775,8776,8777,8778,8779,8780, # 8528
8781,8782,8783,8784,8785,8786,8787,8788,4878,8789,4879,8790,8791,8792,4880,8793, # 8544
8794,8795,8796,8797,8798,8799,8800,8801,4881,8802,8803,8804,8805,8806,8807,8808, # 8560
8809,8810,8811,8812,8813,8814,8815,3957,8816,8817,8818,8819,8820,8821,8822,8823, # 8576
8824,8825,8826,8827,8828,8829,8830,8831,8832,8833,8834,8835,8836,8837,8838,8839, # 8592
8840,8841,8842,8843,8844,8845,8846,8847,4882,8848,8849,8850,8851,8852,8853,8854, # 8608
8855,8856,8857,8858,8859,8860,8861,8862,8863,8864,8865,8866,8867,8868,8869,8870, # 8624
8871,8872,8873,8874,8875,8876,8877,8878,8879,8880,8881,8882,8883,8884,3202,8885, # 8640
8886,8887,8888,8889,8890,8891,8892,8893,8894,8895,8896,8897,8898,8899,8900,8901, # 8656
8902,8903,8904,8905,8906,8907,8908,8909,8910,8911,8912,8913,8914,8915,8916,8917, # 8672
8918,8919,8920,8921,8922,8923,8924,4465,8925,8926,8927,8928,8929,8930,8931,8932, # 8688
4883,8933,8934,8935,8936,8937,8938,8939,8940,8941,8942,8943,2214,8944,8945,8946, # 8704
8947,8948,8949,8950,8951,8952,8953,8954,8955,8956,8957,8958,8959,8960,8961,8962, # 8720
8963,8964,8965,4884,8966,8967,8968,8969,8970,8971,8972,8973,8974,8975,8976,8977, # 8736
8978,8979,8980,8981,8982,8983,8984,8985,8986,8987,8988,8989,8990,8991,8992,4885, # 8752
8993,8994,8995,8996,8997,8998,8999,9000,9001,9002,9003,9004,9005,9006,9007,9008, # 8768
9009,9010,9011,9012,9013,9014,9015,9016,9017,9018,9019,9020,9021,4182,9022,9023, # 8784
9024,9025,9026,9027,9028,9029,9030,9031,9032,9033,9034,9035,9036,9037,9038,9039, # 8800
9040,9041,9042,9043,9044,9045,9046,9047,9048,9049,9050,9051,9052,9053,9054,9055, # 8816
9056,9057,9058,9059,9060,9061,9062,9063,4886,9064,9065,9066,9067,9068,9069,4887, # 8832
9070,9071,9072,9073,9074,9075,9076,9077,9078,9079,9080,9081,9082,9083,9084,9085, # 8848
9086,9087,9088,9089,9090,9091,9092,9093,9094,9095,9096,9097,9098,9099,9100,9101, # 8864
9102,9103,9104,9105,9106,9107,9108,9109,9110,9111,9112,9113,9114,9115,9116,9117, # 8880
9118,9119,9120,9121,9122,9123,9124,9125,9126,9127,9128,9129,9130,9131,9132,9133, # 8896
9134,9135,9136,9137,9138,9139,9140,9141,3958,9142,9143,9144,9145,9146,9147,9148, # 8912
9149,9150,9151,4888,9152,9153,9154,9155,9156,9157,9158,9159,9160,9161,9162,9163, # 8928
9164,9165,9166,9167,9168,9169,9170,9171,9172,9173,9174,9175,4889,9176,9177,9178, # 8944
9179,9180,9181,9182,9183,9184,9185,9186,9187,9188,9189,9190,9191,9192,9193,9194, # 8960
9195,9196,9197,9198,9199,9200,9201,9202,9203,4890,9204,9205,9206,9207,9208,9209, # 8976
9210,9211,9212,9213,9214,9215,9216,9217,9218,9219,9220,9221,9222,4466,9223,9224, # 8992
9225,9226,9227,9228,9229,9230,9231,9232,9233,9234,9235,9236,9237,9238,9239,9240, # 9008
9241,9242,9243,9244,9245,4891,9246,9247,9248,9249,9250,9251,9252,9253,9254,9255, # 9024
9256,9257,4892,9258,9259,9260,9261,4893,4894,9262,9263,9264,9265,9266,9267,9268, # 9040
9269,9270,9271,9272,9273,4467,9274,9275,9276,9277,9278,9279,9280,9281,9282,9283, # 9056
9284,9285,3673,9286,9287,9288,9289,9290,9291,9292,9293,9294,9295,9296,9297,9298, # 9072
9299,9300,9301,9302,9303,9304,9305,9306,9307,9308,9309,9310,9311,9312,9313,9314, # 9088
9315,9316,9317,9318,9319,9320,9321,9322,4895,9323,9324,9325,9326,9327,9328,9329, # 9104
9330,9331,9332,9333,9334,9335,9336,9337,9338,9339,9340,9341,9342,9343,9344,9345, # 9120
9346,9347,4468,9348,9349,9350,9351,9352,9353,9354,9355,9356,9357,9358,9359,9360, # 9136
9361,9362,9363,9364,9365,9366,9367,9368,9369,9370,9371,9372,9373,4896,9374,4469, # 9152
9375,9376,9377,9378,9379,4897,9380,9381,9382,9383,9384,9385,9386,9387,9388,9389, # 9168
9390,9391,9392,9393,9394,9395,9396,9397,9398,9399,9400,9401,9402,9403,9404,9405, # 9184
9406,4470,9407,2751,9408,9409,3674,3552,9410,9411,9412,9413,9414,9415,9416,9417, # 9200
9418,9419,9420,9421,4898,9422,9423,9424,9425,9426,9427,9428,9429,3959,9430,9431, # 9216
9432,9433,9434,9435,9436,4471,9437,9438,9439,9440,9441,9442,9443,9444,9445,9446, # 9232
9447,9448,9449,9450,3348,9451,9452,9453,9454,9455,9456,9457,9458,9459,9460,9461, # 9248
9462,9463,9464,9465,9466,9467,9468,9469,9470,9471,9472,4899,9473,9474,9475,9476, # 9264
9477,4900,9478,9479,9480,9481,9482,9483,9484,9485,9486,9487,9488,3349,9489,9490, # 9280
9491,9492,9493,9494,9495,9496,9497,9498,9499,9500,9501,9502,9503,9504,9505,9506, # 9296
9507,9508,9509,9510,9511,9512,9513,9514,9515,9516,9517,9518,9519,9520,4901,9521, # 9312
9522,9523,9524,9525,9526,4902,9527,9528,9529,9530,9531,9532,9533,9534,9535,9536, # 9328
9537,9538,9539,9540,9541,9542,9543,9544,9545,9546,9547,9548,9549,9550,9551,9552, # 9344
9553,9554,9555,9556,9557,9558,9559,9560,9561,9562,9563,9564,9565,9566,9567,9568, # 9360
9569,9570,9571,9572,9573,9574,9575,9576,9577,9578,9579,9580,9581,9582,9583,9584, # 9376
3805,9585,9586,9587,9588,9589,9590,9591,9592,9593,9594,9595,9596,9597,9598,9599, # 9392
9600,9601,9602,4903,9603,9604,9605,9606,9607,4904,9608,9609,9610,9611,9612,9613, # 9408
9614,4905,9615,9616,9617,9618,9619,9620,9621,9622,9623,9624,9625,9626,9627,9628, # 9424
9629,9630,9631,9632,4906,9633,9634,9635,9636,9637,9638,9639,9640,9641,9642,9643, # 9440
4907,9644,9645,9646,9647,9648,9649,9650,9651,9652,9653,9654,9655,9656,9657,9658, # 9456
9659,9660,9661,9662,9663,9664,9665,9666,9667,9668,9669,9670,9671,9672,4183,9673, # 9472
9674,9675,9676,9677,4908,9678,9679,9680,9681,4909,9682,9683,9684,9685,9686,9687, # 9488
9688,9689,9690,4910,9691,9692,9693,3675,9694,9695,9696,2945,9697,9698,9699,9700, # 9504
9701,9702,9703,9704,9705,4911,9706,9707,9708,9709,9710,9711,9712,9713,9714,9715, # 9520
9716,9717,9718,9719,9720,9721,9722,9723,9724,9725,9726,9727,9728,9729,9730,9731, # 9536
9732,9733,9734,9735,4912,9736,9737,9738,9739,9740,4913,9741,9742,9743,9744,9745, # 9552
9746,9747,9748,9749,9750,9751,9752,9753,9754,9755,9756,9757,9758,4914,9759,9760, # 9568
9761,9762,9763,9764,9765,9766,9767,9768,9769,9770,9771,9772,9773,9774,9775,9776, # 9584
9777,9778,9779,9780,9781,9782,4915,9783,9784,9785,9786,9787,9788,9789,9790,9791, # 9600
9792,9793,4916,9794,9795,9796,9797,9798,9799,9800,9801,9802,9803,9804,9805,9806, # 9616
9807,9808,9809,9810,9811,9812,9813,9814,9815,9816,9817,9818,9819,9820,9821,9822, # 9632
9823,9824,9825,9826,9827,9828,9829,9830,9831,9832,9833,9834,9835,9836,9837,9838, # 9648
9839,9840,9841,9842,9843,9844,9845,9846,9847,9848,9849,9850,9851,9852,9853,9854, # 9664
9855,9856,9857,9858,9859,9860,9861,9862,9863,9864,9865,9866,9867,9868,4917,9869, # 9680
9870,9871,9872,9873,9874,9875,9876,9877,9878,9879,9880,9881,9882,9883,9884,9885, # 9696
9886,9887,9888,9889,9890,9891,9892,4472,9893,9894,9895,9896,9897,3806,9898,9899, # 9712
9900,9901,9902,9903,9904,9905,9906,9907,9908,9909,9910,9911,9912,9913,9914,4918, # 9728
9915,9916,9917,4919,9918,9919,9920,9921,4184,9922,9923,9924,9925,9926,9927,9928, # 9744
9929,9930,9931,9932,9933,9934,9935,9936,9937,9938,9939,9940,9941,9942,9943,9944, # 9760
9945,9946,4920,9947,9948,9949,9950,9951,9952,9953,9954,9955,4185,9956,9957,9958, # 9776
9959,9960,9961,9962,9963,9964,9965,4921,9966,9967,9968,4473,9969,9970,9971,9972, # 9792
9973,9974,9975,9976,9977,4474,9978,9979,9980,9981,9982,9983,9984,9985,9986,9987, # 9808
9988,9989,9990,9991,9992,9993,9994,9995,9996,9997,9998,9999,10000,10001,10002,10003, # 9824
10004,10005,10006,10007,10008,10009,10010,10011,10012,10013,10014,10015,10016,10017,10018,10019, # 9840
10020,10021,4922,10022,4923,10023,10024,10025,10026,10027,10028,10029,10030,10031,10032,10033, # 9856
10034,10035,10036,10037,10038,10039,10040,10041,10042,10043,10044,10045,10046,10047,10048,4924, # 9872
10049,10050,10051,10052,10053,10054,10055,10056,10057,10058,10059,10060,10061,10062,10063,10064, # 9888
10065,10066,10067,10068,10069,10070,10071,10072,10073,10074,10075,10076,10077,10078,10079,10080, # 9904
10081,10082,10083,10084,10085,10086,10087,4475,10088,10089,10090,10091,10092,10093,10094,10095, # 9920
10096,10097,4476,10098,10099,10100,10101,10102,10103,10104,10105,10106,10107,10108,10109,10110, # 9936
10111,2174,10112,10113,10114,10115,10116,10117,10118,10119,10120,10121,10122,10123,10124,10125, # 9952
10126,10127,10128,10129,10130,10131,10132,10133,10134,10135,10136,10137,10138,10139,10140,3807, # 9968
4186,4925,10141,10142,10143,10144,10145,10146,10147,4477,4187,10148,10149,10150,10151,10152, # 9984
10153,4188,10154,10155,10156,10157,10158,10159,10160,10161,4926,10162,10163,10164,10165,10166, #10000
10167,10168,10169,10170,10171,10172,10173,10174,10175,10176,10177,10178,10179,10180,10181,10182, #10016
10183,10184,10185,10186,10187,10188,10189,10190,10191,10192,3203,10193,10194,10195,10196,10197, #10032
10198,10199,10200,4478,10201,10202,10203,10204,4479,10205,10206,10207,10208,10209,10210,10211, #10048
10212,10213,10214,10215,10216,10217,10218,10219,10220,10221,10222,10223,10224,10225,10226,10227, #10064
10228,10229,10230,10231,10232,10233,10234,4927,10235,10236,10237,10238,10239,10240,10241,10242, #10080
10243,10244,10245,10246,10247,10248,10249,10250,10251,10252,10253,10254,10255,10256,10257,10258, #10096
10259,10260,10261,10262,10263,10264,10265,10266,10267,10268,10269,10270,10271,10272,10273,4480, #10112
4928,4929,10274,10275,10276,10277,10278,10279,10280,10281,10282,10283,10284,10285,10286,10287, #10128
10288,10289,10290,10291,10292,10293,10294,10295,10296,10297,10298,10299,10300,10301,10302,10303, #10144
10304,10305,10306,10307,10308,10309,10310,10311,10312,10313,10314,10315,10316,10317,10318,10319, #10160
10320,10321,10322,10323,10324,10325,10326,10327,10328,10329,10330,10331,10332,10333,10334,4930, #10176
10335,10336,10337,10338,10339,10340,10341,10342,4931,10343,10344,10345,10346,10347,10348,10349, #10192
10350,10351,10352,10353,10354,10355,3088,10356,2786,10357,10358,10359,10360,4189,10361,10362, #10208
10363,10364,10365,10366,10367,10368,10369,10370,10371,10372,10373,10374,10375,4932,10376,10377, #10224
10378,10379,10380,10381,10382,10383,10384,10385,10386,10387,10388,10389,10390,10391,10392,4933, #10240
10393,10394,10395,4934,10396,10397,10398,10399,10400,10401,10402,10403,10404,10405,10406,10407, #10256
10408,10409,10410,10411,10412,3446,10413,10414,10415,10416,10417,10418,10419,10420,10421,10422, #10272
10423,4935,10424,10425,10426,10427,10428,10429,10430,4936,10431,10432,10433,10434,10435,10436, #10288
10437,10438,10439,10440,10441,10442,10443,4937,10444,10445,10446,10447,4481,10448,10449,10450, #10304
10451,10452,10453,10454,10455,10456,10457,10458,10459,10460,10461,10462,10463,10464,10465,10466, #10320
10467,10468,10469,10470,10471,10472,10473,10474,10475,10476,10477,10478,10479,10480,10481,10482, #10336
10483,10484,10485,10486,10487,10488,10489,10490,10491,10492,10493,10494,10495,10496,10497,10498, #10352
10499,10500,10501,10502,10503,10504,10505,4938,10506,10507,10508,10509,10510,2552,10511,10512, #10368
10513,10514,10515,10516,3447,10517,10518,10519,10520,10521,10522,10523,10524,10525,10526,10527, #10384
10528,10529,10530,10531,10532,10533,10534,10535,10536,10537,10538,10539,10540,10541,10542,10543, #10400
4482,10544,4939,10545,10546,10547,10548,10549,10550,10551,10552,10553,10554,10555,10556,10557, #10416
10558,10559,10560,10561,10562,10563,10564,10565,10566,10567,3676,4483,10568,10569,10570,10571, #10432
10572,3448,10573,10574,10575,10576,10577,10578,10579,10580,10581,10582,10583,10584,10585,10586, #10448
10587,10588,10589,10590,10591,10592,10593,10594,10595,10596,10597,10598,10599,10600,10601,10602, #10464
10603,10604,10605,10606,10607,10608,10609,10610,10611,10612,10613,10614,10615,10616,10617,10618, #10480
10619,10620,10621,10622,10623,10624,10625,10626,10627,4484,10628,10629,10630,10631,10632,4940, #10496
10633,10634,10635,10636,10637,10638,10639,10640,10641,10642,10643,10644,10645,10646,10647,10648, #10512
10649,10650,10651,10652,10653,10654,10655,10656,4941,10657,10658,10659,2599,10660,10661,10662, #10528
10663,10664,10665,10666,3089,10667,10668,10669,10670,10671,10672,10673,10674,10675,10676,10677, #10544
10678,10679,10680,4942,10681,10682,10683,10684,10685,10686,10687,10688,10689,10690,10691,10692, #10560
10693,10694,10695,10696,10697,4485,10698,10699,10700,10701,10702,10703,10704,4943,10705,3677, #10576
10706,10707,10708,10709,10710,10711,10712,4944,10713,10714,10715,10716,10717,10718,10719,10720, #10592
10721,10722,10723,10724,10725,10726,10727,10728,4945,10729,10730,10731,10732,10733,10734,10735, #10608
10736,10737,10738,10739,10740,10741,10742,10743,10744,10745,10746,10747,10748,10749,10750,10751, #10624
10752,10753,10754,10755,10756,10757,10758,10759,10760,10761,4946,10762,10763,10764,10765,10766, #10640
10767,4947,4948,10768,10769,10770,10771,10772,10773,10774,10775,10776,10777,10778,10779,10780, #10656
10781,10782,10783,10784,10785,10786,10787,10788,10789,10790,10791,10792,10793,10794,10795,10796, #10672
10797,10798,10799,10800,10801,10802,10803,10804,10805,10806,10807,10808,10809,10810,10811,10812, #10688
10813,10814,10815,10816,10817,10818,10819,10820,10821,10822,10823,10824,10825,10826,10827,10828, #10704
10829,10830,10831,10832,10833,10834,10835,10836,10837,10838,10839,10840,10841,10842,10843,10844, #10720
10845,10846,10847,10848,10849,10850,10851,10852,10853,10854,10855,10856,10857,10858,10859,10860, #10736
10861,10862,10863,10864,10865,10866,10867,10868,10869,10870,10871,10872,10873,10874,10875,10876, #10752
10877,10878,4486,10879,10880,10881,10882,10883,10884,10885,4949,10886,10887,10888,10889,10890, #10768
10891,10892,10893,10894,10895,10896,10897,10898,10899,10900,10901,10902,10903,10904,10905,10906, #10784
10907,10908,10909,10910,10911,10912,10913,10914,10915,10916,10917,10918,10919,4487,10920,10921, #10800
10922,10923,10924,10925,10926,10927,10928,10929,10930,10931,10932,4950,10933,10934,10935,10936, #10816
10937,10938,10939,10940,10941,10942,10943,10944,10945,10946,10947,10948,10949,4488,10950,10951, #10832
10952,10953,10954,10955,10956,10957,10958,10959,4190,10960,10961,10962,10963,10964,10965,10966, #10848
10967,10968,10969,10970,10971,10972,10973,10974,10975,10976,10977,10978,10979,10980,10981,10982, #10864
10983,10984,10985,10986,10987,10988,10989,10990,10991,10992,10993,10994,10995,10996,10997,10998, #10880
10999,11000,11001,11002,11003,11004,11005,11006,3960,11007,11008,11009,11010,11011,11012,11013, #10896
11014,11015,11016,11017,11018,11019,11020,11021,11022,11023,11024,11025,11026,11027,11028,11029, #10912
11030,11031,11032,4951,11033,11034,11035,11036,11037,11038,11039,11040,11041,11042,11043,11044, #10928
11045,11046,11047,4489,11048,11049,11050,11051,4952,11052,11053,11054,11055,11056,11057,11058, #10944
4953,11059,11060,11061,11062,11063,11064,11065,11066,11067,11068,11069,11070,11071,4954,11072, #10960
11073,11074,11075,11076,11077,11078,11079,11080,11081,11082,11083,11084,11085,11086,11087,11088, #10976
11089,11090,11091,11092,11093,11094,11095,11096,11097,11098,11099,11100,11101,11102,11103,11104, #10992
11105,11106,11107,11108,11109,11110,11111,11112,11113,11114,11115,3808,11116,11117,11118,11119, #11008
11120,11121,11122,11123,11124,11125,11126,11127,11128,11129,11130,11131,11132,11133,11134,4955, #11024
11135,11136,11137,11138,11139,11140,11141,11142,11143,11144,11145,11146,11147,11148,11149,11150, #11040
11151,11152,11153,11154,11155,11156,11157,11158,11159,11160,11161,4956,11162,11163,11164,11165, #11056
11166,11167,11168,11169,11170,11171,11172,11173,11174,11175,11176,11177,11178,11179,11180,4957, #11072
11181,11182,11183,11184,11185,11186,4958,11187,11188,11189,11190,11191,11192,11193,11194,11195, #11088
11196,11197,11198,11199,11200,3678,11201,11202,11203,11204,11205,11206,4191,11207,11208,11209, #11104
11210,11211,11212,11213,11214,11215,11216,11217,11218,11219,11220,11221,11222,11223,11224,11225, #11120
11226,11227,11228,11229,11230,11231,11232,11233,11234,11235,11236,11237,11238,11239,11240,11241, #11136
11242,11243,11244,11245,11246,11247,11248,11249,11250,11251,4959,11252,11253,11254,11255,11256, #11152
11257,11258,11259,11260,11261,11262,11263,11264,11265,11266,11267,11268,11269,11270,11271,11272, #11168
11273,11274,11275,11276,11277,11278,11279,11280,11281,11282,11283,11284,11285,11286,11287,11288, #11184
11289,11290,11291,11292,11293,11294,11295,11296,11297,11298,11299,11300,11301,11302,11303,11304, #11200
11305,11306,11307,11308,11309,11310,11311,11312,11313,11314,3679,11315,11316,11317,11318,4490, #11216
11319,11320,11321,11322,11323,11324,11325,11326,11327,11328,11329,11330,11331,11332,11333,11334, #11232
11335,11336,11337,11338,11339,11340,11341,11342,11343,11344,11345,11346,11347,4960,11348,11349, #11248
11350,11351,11352,11353,11354,11355,11356,11357,11358,11359,11360,11361,11362,11363,11364,11365, #11264
11366,11367,11368,11369,11370,11371,11372,11373,11374,11375,11376,11377,3961,4961,11378,11379, #11280
11380,11381,11382,11383,11384,11385,11386,11387,11388,11389,11390,11391,11392,11393,11394,11395, #11296
11396,11397,4192,11398,11399,11400,11401,11402,11403,11404,11405,11406,11407,11408,11409,11410, #11312
11411,4962,11412,11413,11414,11415,11416,11417,11418,11419,11420,11421,11422,11423,11424,11425, #11328
11426,11427,11428,11429,11430,11431,11432,11433,11434,11435,11436,11437,11438,11439,11440,11441, #11344
11442,11443,11444,11445,11446,11447,11448,11449,11450,11451,11452,11453,11454,11455,11456,11457, #11360
11458,11459,11460,11461,11462,11463,11464,11465,11466,11467,11468,11469,4963,11470,11471,4491, #11376
11472,11473,11474,11475,4964,11476,11477,11478,11479,11480,11481,11482,11483,11484,11485,11486, #11392
11487,11488,11489,11490,11491,11492,4965,11493,11494,11495,11496,11497,11498,11499,11500,11501, #11408
11502,11503,11504,11505,11506,11507,11508,11509,11510,11511,11512,11513,11514,11515,11516,11517, #11424
11518,11519,11520,11521,11522,11523,11524,11525,11526,11527,11528,11529,3962,11530,11531,11532, #11440
11533,11534,11535,11536,11537,11538,11539,11540,11541,11542,11543,11544,11545,11546,11547,11548, #11456
11549,11550,11551,11552,11553,11554,11555,11556,11557,11558,11559,11560,11561,11562,11563,11564, #11472
4193,4194,11565,11566,11567,11568,11569,11570,11571,11572,11573,11574,11575,11576,11577,11578, #11488
11579,11580,11581,11582,11583,11584,11585,11586,11587,11588,11589,11590,11591,4966,4195,11592, #11504
11593,11594,11595,11596,11597,11598,11599,11600,11601,11602,11603,11604,3090,11605,11606,11607, #11520
11608,11609,11610,4967,11611,11612,11613,11614,11615,11616,11617,11618,11619,11620,11621,11622, #11536
11623,11624,11625,11626,11627,11628,11629,11630,11631,11632,11633,11634,11635,11636,11637,11638, #11552
11639,11640,11641,11642,11643,11644,11645,11646,11647,11648,11649,11650,11651,11652,11653,11654, #11568
11655,11656,11657,11658,11659,11660,11661,11662,11663,11664,11665,11666,11667,11668,11669,11670, #11584
11671,11672,11673,11674,4968,11675,11676,11677,11678,11679,11680,11681,11682,11683,11684,11685, #11600
11686,11687,11688,11689,11690,11691,11692,11693,3809,11694,11695,11696,11697,11698,11699,11700, #11616
11701,11702,11703,11704,11705,11706,11707,11708,11709,11710,11711,11712,11713,11714,11715,11716, #11632
11717,11718,3553,11719,11720,11721,11722,11723,11724,11725,11726,11727,11728,11729,11730,4969, #11648
11731,11732,11733,11734,11735,11736,11737,11738,11739,11740,4492,11741,11742,11743,11744,11745, #11664
11746,11747,11748,11749,11750,11751,11752,4970,11753,11754,11755,11756,11757,11758,11759,11760, #11680
11761,11762,11763,11764,11765,11766,11767,11768,11769,11770,11771,11772,11773,11774,11775,11776, #11696
11777,11778,11779,11780,11781,11782,11783,11784,11785,11786,11787,11788,11789,11790,4971,11791, #11712
11792,11793,11794,11795,11796,11797,4972,11798,11799,11800,11801,11802,11803,11804,11805,11806, #11728
11807,11808,11809,11810,4973,11811,11812,11813,11814,11815,11816,11817,11818,11819,11820,11821, #11744
11822,11823,11824,11825,11826,11827,11828,11829,11830,11831,11832,11833,11834,3680,3810,11835, #11760
11836,4974,11837,11838,11839,11840,11841,11842,11843,11844,11845,11846,11847,11848,11849,11850, #11776
11851,11852,11853,11854,11855,11856,11857,11858,11859,11860,11861,11862,11863,11864,11865,11866, #11792
11867,11868,11869,11870,11871,11872,11873,11874,11875,11876,11877,11878,11879,11880,11881,11882, #11808
11883,11884,4493,11885,11886,11887,11888,11889,11890,11891,11892,11893,11894,11895,11896,11897, #11824
11898,11899,11900,11901,11902,11903,11904,11905,11906,11907,11908,11909,11910,11911,11912,11913, #11840
11914,11915,4975,11916,11917,11918,11919,11920,11921,11922,11923,11924,11925,11926,11927,11928, #11856
11929,11930,11931,11932,11933,11934,11935,11936,11937,11938,11939,11940,11941,11942,11943,11944, #11872
11945,11946,11947,11948,11949,4976,11950,11951,11952,11953,11954,11955,11956,11957,11958,11959, #11888
11960,11961,11962,11963,11964,11965,11966,11967,11968,11969,11970,11971,11972,11973,11974,11975, #11904
11976,11977,11978,11979,11980,11981,11982,11983,11984,11985,11986,11987,4196,11988,11989,11990, #11920
11991,11992,4977,11993,11994,11995,11996,11997,11998,11999,12000,12001,12002,12003,12004,12005, #11936
12006,12007,12008,12009,12010,12011,12012,12013,12014,12015,12016,12017,12018,12019,12020,12021, #11952
12022,12023,12024,12025,12026,12027,12028,12029,12030,12031,12032,12033,12034,12035,12036,12037, #11968
12038,12039,12040,12041,12042,12043,12044,12045,12046,12047,12048,12049,12050,12051,12052,12053, #11984
12054,12055,12056,12057,12058,12059,12060,12061,4978,12062,12063,12064,12065,12066,12067,12068, #12000
12069,12070,12071,12072,12073,12074,12075,12076,12077,12078,12079,12080,12081,12082,12083,12084, #12016
12085,12086,12087,12088,12089,12090,12091,12092,12093,12094,12095,12096,12097,12098,12099,12100, #12032
12101,12102,12103,12104,12105,12106,12107,12108,12109,12110,12111,12112,12113,12114,12115,12116, #12048
12117,12118,12119,12120,12121,12122,12123,4979,12124,12125,12126,12127,12128,4197,12129,12130, #12064
12131,12132,12133,12134,12135,12136,12137,12138,12139,12140,12141,12142,12143,12144,12145,12146, #12080
12147,12148,12149,12150,12151,12152,12153,12154,4980,12155,12156,12157,12158,12159,12160,4494, #12096
12161,12162,12163,12164,3811,12165,12166,12167,12168,12169,4495,12170,12171,4496,12172,12173, #12112
12174,12175,12176,3812,12177,12178,12179,12180,12181,12182,12183,12184,12185,12186,12187,12188, #12128
12189,12190,12191,12192,12193,12194,12195,12196,12197,12198,12199,12200,12201,12202,12203,12204, #12144
12205,12206,12207,12208,12209,12210,12211,12212,12213,12214,12215,12216,12217,12218,12219,12220, #12160
12221,4981,12222,12223,12224,12225,12226,12227,12228,12229,12230,12231,12232,12233,12234,12235, #12176
4982,12236,12237,12238,12239,12240,12241,12242,12243,12244,12245,4983,12246,12247,12248,12249, #12192
4984,12250,12251,12252,12253,12254,12255,12256,12257,12258,12259,12260,12261,12262,12263,12264, #12208
4985,12265,4497,12266,12267,12268,12269,12270,12271,12272,12273,12274,12275,12276,12277,12278, #12224
12279,12280,12281,12282,12283,12284,12285,12286,12287,4986,12288,12289,12290,12291,12292,12293, #12240
12294,12295,12296,2473,12297,12298,12299,12300,12301,12302,12303,12304,12305,12306,12307,12308, #12256
12309,12310,12311,12312,12313,12314,12315,12316,12317,12318,12319,3963,12320,12321,12322,12323, #12272
12324,12325,12326,12327,12328,12329,12330,12331,12332,4987,12333,12334,12335,12336,12337,12338, #12288
12339,12340,12341,12342,12343,12344,12345,12346,12347,12348,12349,12350,12351,12352,12353,12354, #12304
12355,12356,12357,12358,12359,3964,12360,12361,12362,12363,12364,12365,12366,12367,12368,12369, #12320
12370,3965,12371,12372,12373,12374,12375,12376,12377,12378,12379,12380,12381,12382,12383,12384, #12336
12385,12386,12387,12388,12389,12390,12391,12392,12393,12394,12395,12396,12397,12398,12399,12400, #12352
12401,12402,12403,12404,12405,12406,12407,12408,4988,12409,12410,12411,12412,12413,12414,12415, #12368
12416,12417,12418,12419,12420,12421,12422,12423,12424,12425,12426,12427,12428,12429,12430,12431, #12384
12432,12433,12434,12435,12436,12437,12438,3554,12439,12440,12441,12442,12443,12444,12445,12446, #12400
12447,12448,12449,12450,12451,12452,12453,12454,12455,12456,12457,12458,12459,12460,12461,12462, #12416
12463,12464,4989,12465,12466,12467,12468,12469,12470,12471,12472,12473,12474,12475,12476,12477, #12432
12478,12479,12480,4990,12481,12482,12483,12484,12485,12486,12487,12488,12489,4498,12490,12491, #12448
12492,12493,12494,12495,12496,12497,12498,12499,12500,12501,12502,12503,12504,12505,12506,12507, #12464
12508,12509,12510,12511,12512,12513,12514,12515,12516,12517,12518,12519,12520,12521,12522,12523, #12480
12524,12525,12526,12527,12528,12529,12530,12531,12532,12533,12534,12535,12536,12537,12538,12539, #12496
12540,12541,12542,12543,12544,12545,12546,12547,12548,12549,12550,12551,4991,12552,12553,12554, #12512
12555,12556,12557,12558,12559,12560,12561,12562,12563,12564,12565,12566,12567,12568,12569,12570, #12528
12571,12572,12573,12574,12575,12576,12577,12578,3036,12579,12580,12581,12582,12583,3966,12584, #12544
12585,12586,12587,12588,12589,12590,12591,12592,12593,12594,12595,12596,12597,12598,12599,12600, #12560
12601,12602,12603,12604,12605,12606,12607,12608,12609,12610,12611,12612,12613,12614,12615,12616, #12576
12617,12618,12619,12620,12621,12622,12623,12624,12625,12626,12627,12628,12629,12630,12631,12632, #12592
12633,12634,12635,12636,12637,12638,12639,12640,12641,12642,12643,12644,12645,12646,4499,12647, #12608
12648,12649,12650,12651,12652,12653,12654,12655,12656,12657,12658,12659,12660,12661,12662,12663, #12624
12664,12665,12666,12667,12668,12669,12670,12671,12672,12673,12674,12675,12676,12677,12678,12679, #12640
12680,12681,12682,12683,12684,12685,12686,12687,12688,12689,12690,12691,12692,12693,12694,12695, #12656
12696,12697,12698,4992,12699,12700,12701,12702,12703,12704,12705,12706,12707,12708,12709,12710, #12672
12711,12712,12713,12714,12715,12716,12717,12718,12719,12720,12721,12722,12723,12724,12725,12726, #12688
12727,12728,12729,12730,12731,12732,12733,12734,12735,12736,12737,12738,12739,12740,12741,12742, #12704
12743,12744,12745,12746,12747,12748,12749,12750,12751,12752,12753,12754,12755,12756,12757,12758, #12720
12759,12760,12761,12762,12763,12764,12765,12766,12767,12768,12769,12770,12771,12772,12773,12774, #12736
12775,12776,12777,12778,4993,2175,12779,12780,12781,12782,12783,12784,12785,12786,4500,12787, #12752
12788,12789,12790,12791,12792,12793,12794,12795,12796,12797,12798,12799,12800,12801,12802,12803, #12768
12804,12805,12806,12807,12808,12809,12810,12811,12812,12813,12814,12815,12816,12817,12818,12819, #12784
12820,12821,12822,12823,12824,12825,12826,4198,3967,12827,12828,12829,12830,12831,12832,12833, #12800
12834,12835,12836,12837,12838,12839,12840,12841,12842,12843,12844,12845,12846,12847,12848,12849, #12816
12850,12851,12852,12853,12854,12855,12856,12857,12858,12859,12860,12861,4199,12862,12863,12864, #12832
12865,12866,12867,12868,12869,12870,12871,12872,12873,12874,12875,12876,12877,12878,12879,12880, #12848
12881,12882,12883,12884,12885,12886,12887,4501,12888,12889,12890,12891,12892,12893,12894,12895, #12864
12896,12897,12898,12899,12900,12901,12902,12903,12904,12905,12906,12907,12908,12909,12910,12911, #12880
12912,4994,12913,12914,12915,12916,12917,12918,12919,12920,12921,12922,12923,12924,12925,12926, #12896
12927,12928,12929,12930,12931,12932,12933,12934,12935,12936,12937,12938,12939,12940,12941,12942, #12912
12943,12944,12945,12946,12947,12948,12949,12950,12951,12952,12953,12954,12955,12956,1772,12957, #12928
12958,12959,12960,12961,12962,12963,12964,12965,12966,12967,12968,12969,12970,12971,12972,12973, #12944
12974,12975,12976,12977,12978,12979,12980,12981,12982,12983,12984,12985,12986,12987,12988,12989, #12960
12990,12991,12992,12993,12994,12995,12996,12997,4502,12998,4503,12999,13000,13001,13002,13003, #12976
4504,13004,13005,13006,13007,13008,13009,13010,13011,13012,13013,13014,13015,13016,13017,13018, #12992
13019,13020,13021,13022,13023,13024,13025,13026,13027,13028,13029,3449,13030,13031,13032,13033, #13008
13034,13035,13036,13037,13038,13039,13040,13041,13042,13043,13044,13045,13046,13047,13048,13049, #13024
13050,13051,13052,13053,13054,13055,13056,13057,13058,13059,13060,13061,13062,13063,13064,13065, #13040
13066,13067,13068,13069,13070,13071,13072,13073,13074,13075,13076,13077,13078,13079,13080,13081, #13056
13082,13083,13084,13085,13086,13087,13088,13089,13090,13091,13092,13093,13094,13095,13096,13097, #13072
13098,13099,13100,13101,13102,13103,13104,13105,13106,13107,13108,13109,13110,13111,13112,13113, #13088
13114,13115,13116,13117,13118,3968,13119,4995,13120,13121,13122,13123,13124,13125,13126,13127, #13104
4505,13128,13129,13130,13131,13132,13133,13134,4996,4506,13135,13136,13137,13138,13139,4997, #13120
13140,13141,13142,13143,13144,13145,13146,13147,13148,13149,13150,13151,13152,13153,13154,13155, #13136
13156,13157,13158,13159,4998,13160,13161,13162,13163,13164,13165,13166,13167,13168,13169,13170, #13152
13171,13172,13173,13174,13175,13176,4999,13177,13178,13179,13180,13181,13182,13183,13184,13185, #13168
13186,13187,13188,13189,13190,13191,13192,13193,13194,13195,13196,13197,13198,13199,13200,13201, #13184
13202,13203,13204,13205,13206,5000,13207,13208,13209,13210,13211,13212,13213,13214,13215,13216, #13200
13217,13218,13219,13220,13221,13222,13223,13224,13225,13226,13227,4200,5001,13228,13229,13230, #13216
13231,13232,13233,13234,13235,13236,13237,13238,13239,13240,3969,13241,13242,13243,13244,3970, #13232
13245,13246,13247,13248,13249,13250,13251,13252,13253,13254,13255,13256,13257,13258,13259,13260, #13248
13261,13262,13263,13264,13265,13266,13267,13268,3450,13269,13270,13271,13272,13273,13274,13275, #13264
13276,5002,13277,13278,13279,13280,13281,13282,13283,13284,13285,13286,13287,13288,13289,13290, #13280
13291,13292,13293,13294,13295,13296,13297,13298,13299,13300,13301,13302,3813,13303,13304,13305, #13296
13306,13307,13308,13309,13310,13311,13312,13313,13314,13315,13316,13317,13318,13319,13320,13321, #13312
13322,13323,13324,13325,13326,13327,13328,4507,13329,13330,13331,13332,13333,13334,13335,13336, #13328
13337,13338,13339,13340,13341,5003,13342,13343,13344,13345,13346,13347,13348,13349,13350,13351, #13344
13352,13353,13354,13355,13356,13357,13358,13359,13360,13361,13362,13363,13364,13365,13366,13367, #13360
5004,13368,13369,13370,13371,13372,13373,13374,13375,13376,13377,13378,13379,13380,13381,13382, #13376
13383,13384,13385,13386,13387,13388,13389,13390,13391,13392,13393,13394,13395,13396,13397,13398, #13392
13399,13400,13401,13402,13403,13404,13405,13406,13407,13408,13409,13410,13411,13412,13413,13414, #13408
13415,13416,13417,13418,13419,13420,13421,13422,13423,13424,13425,13426,13427,13428,13429,13430, #13424
13431,13432,4508,13433,13434,13435,4201,13436,13437,13438,13439,13440,13441,13442,13443,13444, #13440
13445,13446,13447,13448,13449,13450,13451,13452,13453,13454,13455,13456,13457,5005,13458,13459, #13456
13460,13461,13462,13463,13464,13465,13466,13467,13468,13469,13470,4509,13471,13472,13473,13474, #13472
13475,13476,13477,13478,13479,13480,13481,13482,13483,13484,13485,13486,13487,13488,13489,13490, #13488
13491,13492,13493,13494,13495,13496,13497,13498,13499,13500,13501,13502,13503,13504,13505,13506, #13504
13507,13508,13509,13510,13511,13512,13513,13514,13515,13516,13517,13518,13519,13520,13521,13522, #13520
13523,13524,13525,13526,13527,13528,13529,13530,13531,13532,13533,13534,13535,13536,13537,13538, #13536
13539,13540,13541,13542,13543,13544,13545,13546,13547,13548,13549,13550,13551,13552,13553,13554, #13552
13555,13556,13557,13558,13559,13560,13561,13562,13563,13564,13565,13566,13567,13568,13569,13570, #13568
13571,13572,13573,13574,13575,13576,13577,13578,13579,13580,13581,13582,13583,13584,13585,13586, #13584
13587,13588,13589,13590,13591,13592,13593,13594,13595,13596,13597,13598,13599,13600,13601,13602, #13600
13603,13604,13605,13606,13607,13608,13609,13610,13611,13612,13613,13614,13615,13616,13617,13618, #13616
13619,13620,13621,13622,13623,13624,13625,13626,13627,13628,13629,13630,13631,13632,13633,13634, #13632
13635,13636,13637,13638,13639,13640,13641,13642,5006,13643,13644,13645,13646,13647,13648,13649, #13648
13650,13651,5007,13652,13653,13654,13655,13656,13657,13658,13659,13660,13661,13662,13663,13664, #13664
13665,13666,13667,13668,13669,13670,13671,13672,13673,13674,13675,13676,13677,13678,13679,13680, #13680
13681,13682,13683,13684,13685,13686,13687,13688,13689,13690,13691,13692,13693,13694,13695,13696, #13696
13697,13698,13699,13700,13701,13702,13703,13704,13705,13706,13707,13708,13709,13710,13711,13712, #13712
13713,13714,13715,13716,13717,13718,13719,13720,13721,13722,13723,13724,13725,13726,13727,13728, #13728
13729,13730,13731,13732,13733,13734,13735,13736,13737,13738,13739,13740,13741,13742,13743,13744, #13744
13745,13746,13747,13748,13749,13750,13751,13752,13753,13754,13755,13756,13757,13758,13759,13760, #13760
13761,13762,13763,13764,13765,13766,13767,13768,13769,13770,13771,13772,13773,13774,3273,13775, #13776
13776,13777,13778,13779,13780,13781,13782,13783,13784,13785,13786,13787,13788,13789,13790,13791, #13792
13792,13793,13794,13795,13796,13797,13798,13799,13800,13801,13802,13803,13804,13805,13806,13807, #13808
13808,13809,13810,13811,13812,13813,13814,13815,13816,13817,13818,13819,13820,13821,13822,13823, #13824
13824,13825,13826,13827,13828,13829,13830,13831,13832,13833,13834,13835,13836,13837,13838,13839, #13840
13840,13841,13842,13843,13844,13845,13846,13847,13848,13849,13850,13851,13852,13853,13854,13855, #13856
13856,13857,13858,13859,13860,13861,13862,13863,13864,13865,13866,13867,13868,13869,13870,13871, #13872
13872,13873,13874,13875,13876,13877,13878,13879,13880,13881,13882,13883,13884,13885,13886,13887, #13888
13888,13889,13890,13891,13892,13893,13894,13895,13896,13897,13898,13899,13900,13901,13902,13903, #13904
13904,13905,13906,13907,13908,13909,13910,13911,13912,13913,13914,13915,13916,13917,13918,13919, #13920
13920,13921,13922,13923,13924,13925,13926,13927,13928,13929,13930,13931,13932,13933,13934,13935, #13936
13936,13937,13938,13939,13940,13941,13942,13943,13944,13945,13946,13947,13948,13949,13950,13951, #13952
13952,13953,13954,13955,13956,13957,13958,13959,13960,13961,13962,13963,13964,13965,13966,13967, #13968
13968,13969,13970,13971,13972) #13973

########NEW FILE########
__FILENAME__ = big5prober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
# 
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
# 
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from mbcharsetprober import MultiByteCharSetProber
from codingstatemachine import CodingStateMachine
from chardistribution import Big5DistributionAnalysis
from mbcssm import Big5SMModel

class Big5Prober(MultiByteCharSetProber):
    def __init__(self):
        MultiByteCharSetProber.__init__(self)
        self._mCodingSM = CodingStateMachine(Big5SMModel)
        self._mDistributionAnalyzer = Big5DistributionAnalysis()
        self.reset()

    def get_charset_name(self):
        return "Big5"

########NEW FILE########
__FILENAME__ = chardistribution
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
# 
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
# 
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants
from euctwfreq import EUCTWCharToFreqOrder, EUCTW_TABLE_SIZE, EUCTW_TYPICAL_DISTRIBUTION_RATIO
from euckrfreq import EUCKRCharToFreqOrder, EUCKR_TABLE_SIZE, EUCKR_TYPICAL_DISTRIBUTION_RATIO
from gb2312freq import GB2312CharToFreqOrder, GB2312_TABLE_SIZE, GB2312_TYPICAL_DISTRIBUTION_RATIO
from big5freq import Big5CharToFreqOrder, BIG5_TABLE_SIZE, BIG5_TYPICAL_DISTRIBUTION_RATIO
from jisfreq import JISCharToFreqOrder, JIS_TABLE_SIZE, JIS_TYPICAL_DISTRIBUTION_RATIO

ENOUGH_DATA_THRESHOLD = 1024
SURE_YES = 0.99
SURE_NO = 0.01

class CharDistributionAnalysis:
    def __init__(self):
        self._mCharToFreqOrder = None # Mapping table to get frequency order from char order (get from GetOrder())
        self._mTableSize = None # Size of above table
        self._mTypicalDistributionRatio = None # This is a constant value which varies from language to language, used in calculating confidence.  See http://www.mozilla.org/projects/intl/UniversalCharsetDetection.html for further detail.
        self.reset()
        
    def reset(self):
        """reset analyser, clear any state"""
        self._mDone = constants.False # If this flag is set to constants.True, detection is done and conclusion has been made
        self._mTotalChars = 0 # Total characters encountered
        self._mFreqChars = 0 # The number of characters whose frequency order is less than 512

    def feed(self, aStr, aCharLen):
        """feed a character with known length"""
        if aCharLen == 2:
            # we only care about 2-bytes character in our distribution analysis
            order = self.get_order(aStr)
        else:
            order = -1
        if order >= 0:
            self._mTotalChars += 1
            # order is valid
            if order < self._mTableSize:
                if 512 > self._mCharToFreqOrder[order]:
                    self._mFreqChars += 1

    def get_confidence(self):
        """return confidence based on existing data"""
        # if we didn't receive any character in our consideration range, return negative answer
        if self._mTotalChars <= 0:
            return SURE_NO

        if self._mTotalChars != self._mFreqChars:
            r = self._mFreqChars / ((self._mTotalChars - self._mFreqChars) * self._mTypicalDistributionRatio)
            if r < SURE_YES:
                return r

        # normalize confidence (we don't want to be 100% sure)
        return SURE_YES

    def got_enough_data(self):
        # It is not necessary to receive all data to draw conclusion. For charset detection,
        # certain amount of data is enough
        return self._mTotalChars > ENOUGH_DATA_THRESHOLD

    def get_order(self, aStr):
        # We do not handle characters based on the original encoding string, but 
        # convert this encoding string to a number, here called order.
        # This allows multiple encodings of a language to share one frequency table.
        return -1
    
class EUCTWDistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        CharDistributionAnalysis.__init__(self)
        self._mCharToFreqOrder = EUCTWCharToFreqOrder
        self._mTableSize = EUCTW_TABLE_SIZE
        self._mTypicalDistributionRatio = EUCTW_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, aStr):
        # for euc-TW encoding, we are interested 
        #   first  byte range: 0xc4 -- 0xfe
        #   second byte range: 0xa1 -- 0xfe
        # no validation needed here. State machine has done that
        if aStr[0] >= '\xC4':
            return 94 * (ord(aStr[0]) - 0xC4) + ord(aStr[1]) - 0xA1
        else:
            return -1

class EUCKRDistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        CharDistributionAnalysis.__init__(self)
        self._mCharToFreqOrder = EUCKRCharToFreqOrder
        self._mTableSize = EUCKR_TABLE_SIZE
        self._mTypicalDistributionRatio = EUCKR_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, aStr):
        # for euc-KR encoding, we are interested 
        #   first  byte range: 0xb0 -- 0xfe
        #   second byte range: 0xa1 -- 0xfe
        # no validation needed here. State machine has done that
        if aStr[0] >= '\xB0':
            return 94 * (ord(aStr[0]) - 0xB0) + ord(aStr[1]) - 0xA1
        else:
            return -1;

class GB2312DistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        CharDistributionAnalysis.__init__(self)
        self._mCharToFreqOrder = GB2312CharToFreqOrder
        self._mTableSize = GB2312_TABLE_SIZE
        self._mTypicalDistributionRatio = GB2312_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, aStr):
        # for GB2312 encoding, we are interested 
        #  first  byte range: 0xb0 -- 0xfe
        #  second byte range: 0xa1 -- 0xfe
        # no validation needed here. State machine has done that
        if (aStr[0] >= '\xB0') and (aStr[1] >= '\xA1'):
            return 94 * (ord(aStr[0]) - 0xB0) + ord(aStr[1]) - 0xA1
        else:
            return -1;

class Big5DistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        CharDistributionAnalysis.__init__(self)
        self._mCharToFreqOrder = Big5CharToFreqOrder
        self._mTableSize = BIG5_TABLE_SIZE
        self._mTypicalDistributionRatio = BIG5_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, aStr):
        # for big5 encoding, we are interested 
        #   first  byte range: 0xa4 -- 0xfe
        #   second byte range: 0x40 -- 0x7e , 0xa1 -- 0xfe
        # no validation needed here. State machine has done that
        if aStr[0] >= '\xA4':
            if aStr[1] >= '\xA1':
                return 157 * (ord(aStr[0]) - 0xA4) + ord(aStr[1]) - 0xA1 + 63
            else:
                return 157 * (ord(aStr[0]) - 0xA4) + ord(aStr[1]) - 0x40
        else:
            return -1

class SJISDistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        CharDistributionAnalysis.__init__(self)
        self._mCharToFreqOrder = JISCharToFreqOrder
        self._mTableSize = JIS_TABLE_SIZE
        self._mTypicalDistributionRatio = JIS_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, aStr):
        # for sjis encoding, we are interested 
        #   first  byte range: 0x81 -- 0x9f , 0xe0 -- 0xfe
        #   second byte range: 0x40 -- 0x7e,  0x81 -- oxfe
        # no validation needed here. State machine has done that
        if (aStr[0] >= '\x81') and (aStr[0] <= '\x9F'):
            order = 188 * (ord(aStr[0]) - 0x81)
        elif (aStr[0] >= '\xE0') and (aStr[0] <= '\xEF'):
            order = 188 * (ord(aStr[0]) - 0xE0 + 31)
        else:
            return -1;
        order = order + ord(aStr[1]) - 0x40
        if aStr[1] > '\x7F':
            order =- 1
        return order

class EUCJPDistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        CharDistributionAnalysis.__init__(self)
        self._mCharToFreqOrder = JISCharToFreqOrder
        self._mTableSize = JIS_TABLE_SIZE
        self._mTypicalDistributionRatio = JIS_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, aStr):
        # for euc-JP encoding, we are interested 
        #   first  byte range: 0xa0 -- 0xfe
        #   second byte range: 0xa1 -- 0xfe
        # no validation needed here. State machine has done that
        if aStr[0] >= '\xA0':
            return 94 * (ord(aStr[0]) - 0xA1) + ord(aStr[1]) - 0xa1
        else:
            return -1

########NEW FILE########
__FILENAME__ = charsetgroupprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
# 
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
# 
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants, sys
from charsetprober import CharSetProber

class CharSetGroupProber(CharSetProber):
    def __init__(self):
        CharSetProber.__init__(self)
        self._mActiveNum = 0
        self._mProbers = []
        self._mBestGuessProber = None
        
    def reset(self):
        CharSetProber.reset(self)
        self._mActiveNum = 0
        for prober in self._mProbers:
            if prober:
                prober.reset()
                prober.active = constants.True
                self._mActiveNum += 1
        self._mBestGuessProber = None

    def get_charset_name(self):
        if not self._mBestGuessProber:
            self.get_confidence()
            if not self._mBestGuessProber: return None
#                self._mBestGuessProber = self._mProbers[0]
        return self._mBestGuessProber.get_charset_name()

    def feed(self, aBuf):
        for prober in self._mProbers:
            if not prober: continue
            if not prober.active: continue
            st = prober.feed(aBuf)
            if not st: continue
            if st == constants.eFoundIt:
                self._mBestGuessProber = prober
                return self.get_state()
            elif st == constants.eNotMe:
                prober.active = constants.False
                self._mActiveNum -= 1
                if self._mActiveNum <= 0:
                    self._mState = constants.eNotMe
                    return self.get_state()
        return self.get_state()

    def get_confidence(self):
        st = self.get_state()
        if st == constants.eFoundIt:
            return 0.99
        elif st == constants.eNotMe:
            return 0.01
        bestConf = 0.0
        self._mBestGuessProber = None
        for prober in self._mProbers:
            if not prober: continue
            if not prober.active:
                if constants._debug:
                    sys.stderr.write(prober.get_charset_name() + ' not active\n')
                continue
            cf = prober.get_confidence()
            if constants._debug:
                sys.stderr.write('%s confidence = %s\n' % (prober.get_charset_name(), cf))
            if bestConf < cf:
                bestConf = cf
                self._mBestGuessProber = prober
        if not self._mBestGuessProber: return 0.0
        return bestConf
#        else:
#            self._mBestGuessProber = self._mProbers[0]
#            return self._mBestGuessProber.get_confidence()

########NEW FILE########
__FILENAME__ = charsetprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
# 
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
# 
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants, re

class CharSetProber:
    def __init__(self):
        pass
        
    def reset(self):
        self._mState = constants.eDetecting
    
    def get_charset_name(self):
        return None

    def feed(self, aBuf):
        pass

    def get_state(self):
        return self._mState

    def get_confidence(self):
        return 0.0

    def filter_high_bit_only(self, aBuf):
        aBuf = re.sub(r'([\x00-\x7F])+', ' ', aBuf)
        return aBuf
    
    def filter_without_english_letters(self, aBuf):
        aBuf = re.sub(r'([A-Za-z])+', ' ', aBuf)
        return aBuf
        
    def filter_with_english_letters(self, aBuf):
        # TODO
        return aBuf

########NEW FILE########
__FILENAME__ = codingstatemachine
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from constants import eStart, eError, eItsMe

class CodingStateMachine:
    def __init__(self, sm):
        self._mModel = sm
        self._mCurrentBytePos = 0
        self._mCurrentCharLen = 0
        self.reset()

    def reset(self):
        self._mCurrentState = eStart

    def next_state(self, c):
        # for each byte we get its class
        # if it is first byte, we also get byte length
        try:
            byteCls = self._mModel['classTable'][ord(c)]
        except IndexError:
            return eError
        if self._mCurrentState == eStart:
            self._mCurrentBytePos = 0
            self._mCurrentCharLen = self._mModel['charLenTable'][byteCls]
        # from byte's class and stateTable, we get its next state
        self._mCurrentState = self._mModel['stateTable'][self._mCurrentState * self._mModel['classFactor'] + byteCls]
        self._mCurrentBytePos += 1
        return self._mCurrentState

    def get_current_charlen(self):
        return self._mCurrentCharLen

    def get_coding_state_machine(self):
        return self._mModel['name']

########NEW FILE########
__FILENAME__ = constants
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

_debug = 0

eDetecting = 0
eFoundIt = 1
eNotMe = 2

eStart = 0
eError = 1
eItsMe = 2

SHORTCUT_THRESHOLD = 0.95

import __builtin__
if not hasattr(__builtin__, 'False'):
    False = 0
    True = 1
else:
    False = __builtin__.False
    True = __builtin__.True

########NEW FILE########
__FILENAME__ = escprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants, sys
from escsm import HZSMModel, ISO2022CNSMModel, ISO2022JPSMModel, ISO2022KRSMModel
from charsetprober import CharSetProber
from codingstatemachine import CodingStateMachine

class EscCharSetProber(CharSetProber):
    def __init__(self):
        CharSetProber.__init__(self)
        self._mCodingSM = [ \
            CodingStateMachine(HZSMModel),
            CodingStateMachine(ISO2022CNSMModel),
            CodingStateMachine(ISO2022JPSMModel),
            CodingStateMachine(ISO2022KRSMModel)
            ]
        self.reset()

    def reset(self):
        CharSetProber.reset(self)
        for codingSM in self._mCodingSM:
            if not codingSM: continue
            codingSM.active = constants.True
            codingSM.reset()
        self._mActiveSM = len(self._mCodingSM)
        self._mDetectedCharset = None

    def get_charset_name(self):
        return self._mDetectedCharset

    def get_confidence(self):
        if self._mDetectedCharset:
            return 0.99
        else:
            return 0.00

    def feed(self, aBuf):
        for c in aBuf:
            for codingSM in self._mCodingSM:
                if not codingSM: continue
                if not codingSM.active: continue
                codingState = codingSM.next_state(c)
                if codingState == constants.eError:
                    codingSM.active = constants.False
                    self._mActiveSM -= 1
                    if self._mActiveSM <= 0:
                        self._mState = constants.eNotMe
                        return self.get_state()
                elif codingState == constants.eItsMe:
                    self._mState = constants.eFoundIt
                    self._mDetectedCharset = codingSM.get_coding_state_machine()
                    return self.get_state()
                
        return self.get_state()

########NEW FILE########
__FILENAME__ = escsm
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from constants import eStart, eError, eItsMe

HZ_cls = ( \
1,0,0,0,0,0,0,0,  # 00 - 07 
0,0,0,0,0,0,0,0,  # 08 - 0f 
0,0,0,0,0,0,0,0,  # 10 - 17 
0,0,0,1,0,0,0,0,  # 18 - 1f 
0,0,0,0,0,0,0,0,  # 20 - 27 
0,0,0,0,0,0,0,0,  # 28 - 2f 
0,0,0,0,0,0,0,0,  # 30 - 37 
0,0,0,0,0,0,0,0,  # 38 - 3f 
0,0,0,0,0,0,0,0,  # 40 - 47 
0,0,0,0,0,0,0,0,  # 48 - 4f 
0,0,0,0,0,0,0,0,  # 50 - 57 
0,0,0,0,0,0,0,0,  # 58 - 5f 
0,0,0,0,0,0,0,0,  # 60 - 67 
0,0,0,0,0,0,0,0,  # 68 - 6f 
0,0,0,0,0,0,0,0,  # 70 - 77 
0,0,0,4,0,5,2,0,  # 78 - 7f 
1,1,1,1,1,1,1,1,  # 80 - 87 
1,1,1,1,1,1,1,1,  # 88 - 8f 
1,1,1,1,1,1,1,1,  # 90 - 97 
1,1,1,1,1,1,1,1,  # 98 - 9f 
1,1,1,1,1,1,1,1,  # a0 - a7 
1,1,1,1,1,1,1,1,  # a8 - af 
1,1,1,1,1,1,1,1,  # b0 - b7 
1,1,1,1,1,1,1,1,  # b8 - bf 
1,1,1,1,1,1,1,1,  # c0 - c7 
1,1,1,1,1,1,1,1,  # c8 - cf 
1,1,1,1,1,1,1,1,  # d0 - d7 
1,1,1,1,1,1,1,1,  # d8 - df 
1,1,1,1,1,1,1,1,  # e0 - e7 
1,1,1,1,1,1,1,1,  # e8 - ef 
1,1,1,1,1,1,1,1,  # f0 - f7 
1,1,1,1,1,1,1,1,  # f8 - ff 
)

HZ_st = ( \
eStart,eError,     3,eStart,eStart,eStart,eError,eError,# 00-07 
eError,eError,eError,eError,eItsMe,eItsMe,eItsMe,eItsMe,# 08-0f 
eItsMe,eItsMe,eError,eError,eStart,eStart,     4,eError,# 10-17 
     5,eError,     6,eError,     5,     5,     4,eError,# 18-1f 
     4,eError,     4,     4,     4,eError,     4,eError,# 20-27 
     4,eItsMe,eStart,eStart,eStart,eStart,eStart,eStart,# 28-2f 
)

HZCharLenTable = (0, 0, 0, 0, 0, 0)

HZSMModel = {'classTable': HZ_cls,
             'classFactor': 6,
             'stateTable': HZ_st,
             'charLenTable': HZCharLenTable,
             'name': "HZ-GB-2312"}

ISO2022CN_cls = ( \
2,0,0,0,0,0,0,0,  # 00 - 07 
0,0,0,0,0,0,0,0,  # 08 - 0f 
0,0,0,0,0,0,0,0,  # 10 - 17 
0,0,0,1,0,0,0,0,  # 18 - 1f 
0,0,0,0,0,0,0,0,  # 20 - 27 
0,3,0,0,0,0,0,0,  # 28 - 2f 
0,0,0,0,0,0,0,0,  # 30 - 37 
0,0,0,0,0,0,0,0,  # 38 - 3f 
0,0,0,4,0,0,0,0,  # 40 - 47 
0,0,0,0,0,0,0,0,  # 48 - 4f 
0,0,0,0,0,0,0,0,  # 50 - 57 
0,0,0,0,0,0,0,0,  # 58 - 5f 
0,0,0,0,0,0,0,0,  # 60 - 67 
0,0,0,0,0,0,0,0,  # 68 - 6f 
0,0,0,0,0,0,0,0,  # 70 - 77 
0,0,0,0,0,0,0,0,  # 78 - 7f 
2,2,2,2,2,2,2,2,  # 80 - 87 
2,2,2,2,2,2,2,2,  # 88 - 8f 
2,2,2,2,2,2,2,2,  # 90 - 97 
2,2,2,2,2,2,2,2,  # 98 - 9f 
2,2,2,2,2,2,2,2,  # a0 - a7 
2,2,2,2,2,2,2,2,  # a8 - af 
2,2,2,2,2,2,2,2,  # b0 - b7 
2,2,2,2,2,2,2,2,  # b8 - bf 
2,2,2,2,2,2,2,2,  # c0 - c7 
2,2,2,2,2,2,2,2,  # c8 - cf 
2,2,2,2,2,2,2,2,  # d0 - d7 
2,2,2,2,2,2,2,2,  # d8 - df 
2,2,2,2,2,2,2,2,  # e0 - e7 
2,2,2,2,2,2,2,2,  # e8 - ef 
2,2,2,2,2,2,2,2,  # f0 - f7 
2,2,2,2,2,2,2,2,  # f8 - ff 
)

ISO2022CN_st = ( \
eStart,     3,eError,eStart,eStart,eStart,eStart,eStart,# 00-07 
eStart,eError,eError,eError,eError,eError,eError,eError,# 08-0f 
eError,eError,eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,# 10-17 
eItsMe,eItsMe,eItsMe,eError,eError,eError,     4,eError,# 18-1f 
eError,eError,eError,eItsMe,eError,eError,eError,eError,# 20-27 
     5,     6,eError,eError,eError,eError,eError,eError,# 28-2f 
eError,eError,eError,eItsMe,eError,eError,eError,eError,# 30-37 
eError,eError,eError,eError,eError,eItsMe,eError,eStart,# 38-3f 
)

ISO2022CNCharLenTable = (0, 0, 0, 0, 0, 0, 0, 0, 0)

ISO2022CNSMModel = {'classTable': ISO2022CN_cls,
                    'classFactor': 9,
                    'stateTable': ISO2022CN_st,
                    'charLenTable': ISO2022CNCharLenTable,
                    'name': "ISO-2022-CN"}

ISO2022JP_cls = ( \
2,0,0,0,0,0,0,0,  # 00 - 07 
0,0,0,0,0,0,2,2,  # 08 - 0f 
0,0,0,0,0,0,0,0,  # 10 - 17 
0,0,0,1,0,0,0,0,  # 18 - 1f 
0,0,0,0,7,0,0,0,  # 20 - 27 
3,0,0,0,0,0,0,0,  # 28 - 2f 
0,0,0,0,0,0,0,0,  # 30 - 37 
0,0,0,0,0,0,0,0,  # 38 - 3f 
6,0,4,0,8,0,0,0,  # 40 - 47 
0,9,5,0,0,0,0,0,  # 48 - 4f 
0,0,0,0,0,0,0,0,  # 50 - 57 
0,0,0,0,0,0,0,0,  # 58 - 5f 
0,0,0,0,0,0,0,0,  # 60 - 67 
0,0,0,0,0,0,0,0,  # 68 - 6f 
0,0,0,0,0,0,0,0,  # 70 - 77 
0,0,0,0,0,0,0,0,  # 78 - 7f 
2,2,2,2,2,2,2,2,  # 80 - 87 
2,2,2,2,2,2,2,2,  # 88 - 8f 
2,2,2,2,2,2,2,2,  # 90 - 97 
2,2,2,2,2,2,2,2,  # 98 - 9f 
2,2,2,2,2,2,2,2,  # a0 - a7 
2,2,2,2,2,2,2,2,  # a8 - af 
2,2,2,2,2,2,2,2,  # b0 - b7 
2,2,2,2,2,2,2,2,  # b8 - bf 
2,2,2,2,2,2,2,2,  # c0 - c7 
2,2,2,2,2,2,2,2,  # c8 - cf 
2,2,2,2,2,2,2,2,  # d0 - d7 
2,2,2,2,2,2,2,2,  # d8 - df 
2,2,2,2,2,2,2,2,  # e0 - e7 
2,2,2,2,2,2,2,2,  # e8 - ef 
2,2,2,2,2,2,2,2,  # f0 - f7 
2,2,2,2,2,2,2,2,  # f8 - ff 
)

ISO2022JP_st = ( \
eStart,     3,eError,eStart,eStart,eStart,eStart,eStart,# 00-07 
eStart,eStart,eError,eError,eError,eError,eError,eError,# 08-0f 
eError,eError,eError,eError,eItsMe,eItsMe,eItsMe,eItsMe,# 10-17 
eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eError,eError,# 18-1f 
eError,     5,eError,eError,eError,     4,eError,eError,# 20-27 
eError,eError,eError,     6,eItsMe,eError,eItsMe,eError,# 28-2f 
eError,eError,eError,eError,eError,eError,eItsMe,eItsMe,# 30-37 
eError,eError,eError,eItsMe,eError,eError,eError,eError,# 38-3f 
eError,eError,eError,eError,eItsMe,eError,eStart,eStart,# 40-47 
)

ISO2022JPCharLenTable = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0)

ISO2022JPSMModel = {'classTable': ISO2022JP_cls,
                    'classFactor': 10,
                    'stateTable': ISO2022JP_st,
                    'charLenTable': ISO2022JPCharLenTable,
                    'name': "ISO-2022-JP"}

ISO2022KR_cls = ( \
2,0,0,0,0,0,0,0,  # 00 - 07 
0,0,0,0,0,0,0,0,  # 08 - 0f 
0,0,0,0,0,0,0,0,  # 10 - 17 
0,0,0,1,0,0,0,0,  # 18 - 1f 
0,0,0,0,3,0,0,0,  # 20 - 27 
0,4,0,0,0,0,0,0,  # 28 - 2f 
0,0,0,0,0,0,0,0,  # 30 - 37 
0,0,0,0,0,0,0,0,  # 38 - 3f 
0,0,0,5,0,0,0,0,  # 40 - 47 
0,0,0,0,0,0,0,0,  # 48 - 4f 
0,0,0,0,0,0,0,0,  # 50 - 57 
0,0,0,0,0,0,0,0,  # 58 - 5f 
0,0,0,0,0,0,0,0,  # 60 - 67 
0,0,0,0,0,0,0,0,  # 68 - 6f 
0,0,0,0,0,0,0,0,  # 70 - 77 
0,0,0,0,0,0,0,0,  # 78 - 7f 
2,2,2,2,2,2,2,2,  # 80 - 87 
2,2,2,2,2,2,2,2,  # 88 - 8f 
2,2,2,2,2,2,2,2,  # 90 - 97 
2,2,2,2,2,2,2,2,  # 98 - 9f 
2,2,2,2,2,2,2,2,  # a0 - a7 
2,2,2,2,2,2,2,2,  # a8 - af 
2,2,2,2,2,2,2,2,  # b0 - b7 
2,2,2,2,2,2,2,2,  # b8 - bf 
2,2,2,2,2,2,2,2,  # c0 - c7 
2,2,2,2,2,2,2,2,  # c8 - cf 
2,2,2,2,2,2,2,2,  # d0 - d7 
2,2,2,2,2,2,2,2,  # d8 - df 
2,2,2,2,2,2,2,2,  # e0 - e7 
2,2,2,2,2,2,2,2,  # e8 - ef 
2,2,2,2,2,2,2,2,  # f0 - f7 
2,2,2,2,2,2,2,2,  # f8 - ff 
)

ISO2022KR_st = ( \
eStart,     3,eError,eStart,eStart,eStart,eError,eError,# 00-07 
eError,eError,eError,eError,eItsMe,eItsMe,eItsMe,eItsMe,# 08-0f 
eItsMe,eItsMe,eError,eError,eError,     4,eError,eError,# 10-17 
eError,eError,eError,eError,     5,eError,eError,eError,# 18-1f 
eError,eError,eError,eItsMe,eStart,eStart,eStart,eStart,# 20-27 
)

ISO2022KRCharLenTable = (0, 0, 0, 0, 0, 0)

ISO2022KRSMModel = {'classTable': ISO2022KR_cls,
                    'classFactor': 6,
                    'stateTable': ISO2022KR_st,
                    'charLenTable': ISO2022KRCharLenTable,
                    'name': "ISO-2022-KR"}

########NEW FILE########
__FILENAME__ = eucjpprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants, sys
from constants import eStart, eError, eItsMe
from mbcharsetprober import MultiByteCharSetProber
from codingstatemachine import CodingStateMachine
from chardistribution import EUCJPDistributionAnalysis
from jpcntx import EUCJPContextAnalysis
from mbcssm import EUCJPSMModel

class EUCJPProber(MultiByteCharSetProber):
    def __init__(self):
        MultiByteCharSetProber.__init__(self)
        self._mCodingSM = CodingStateMachine(EUCJPSMModel)
        self._mDistributionAnalyzer = EUCJPDistributionAnalysis()
        self._mContextAnalyzer = EUCJPContextAnalysis()
        self.reset()

    def reset(self):
        MultiByteCharSetProber.reset(self)
        self._mContextAnalyzer.reset()
        
    def get_charset_name(self):
        return "EUC-JP"

    def feed(self, aBuf):
        aLen = len(aBuf)
        for i in range(0, aLen):
            codingState = self._mCodingSM.next_state(aBuf[i])
            if codingState == eError:
                if constants._debug:
                    sys.stderr.write(self.get_charset_name() + ' prober hit error at byte ' + str(i) + '\n')
                self._mState = constants.eNotMe
                break
            elif codingState == eItsMe:
                self._mState = constants.eFoundIt
                break
            elif codingState == eStart:
                charLen = self._mCodingSM.get_current_charlen()
                if i == 0:
                    self._mLastChar[1] = aBuf[0]
                    self._mContextAnalyzer.feed(self._mLastChar, charLen)
                    self._mDistributionAnalyzer.feed(self._mLastChar, charLen)
                else:
                    self._mContextAnalyzer.feed(aBuf[i-1:i+1], charLen)
                    self._mDistributionAnalyzer.feed(aBuf[i-1:i+1], charLen)
                    
        self._mLastChar[0] = aBuf[aLen - 1]
        
        if self.get_state() == constants.eDetecting:
            if self._mContextAnalyzer.got_enough_data() and \
                   (self.get_confidence() > constants.SHORTCUT_THRESHOLD):
                self._mState = constants.eFoundIt

        return self.get_state()

    def get_confidence(self):
        contxtCf = self._mContextAnalyzer.get_confidence()
        distribCf = self._mDistributionAnalyzer.get_confidence()
        return max(contxtCf, distribCf)

########NEW FILE########
__FILENAME__ = euckrfreq
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# Sampling from about 20M text materials include literature and computer technology

# 128  --> 0.79
# 256  --> 0.92
# 512  --> 0.986
# 1024 --> 0.99944
# 2048 --> 0.99999
#
# Idea Distribution Ratio = 0.98653 / (1-0.98653) = 73.24
# Random Distribution Ration = 512 / (2350-512) = 0.279.
# 
# Typical Distribution Ratio  

EUCKR_TYPICAL_DISTRIBUTION_RATIO = 6.0

EUCKR_TABLE_SIZE = 2352

# Char to FreqOrder table , 
EUCKRCharToFreqOrder = ( \
  13, 130, 120,1396, 481,1719,1720, 328, 609, 212,1721, 707, 400, 299,1722,  87,
1397,1723, 104, 536,1117,1203,1724,1267, 685,1268, 508,1725,1726,1727,1728,1398,
1399,1729,1730,1731, 141, 621, 326,1057, 368,1732, 267, 488,  20,1733,1269,1734,
 945,1400,1735,  47, 904,1270,1736,1737, 773, 248,1738, 409, 313, 786, 429,1739,
 116, 987, 813,1401, 683,  75,1204, 145,1740,1741,1742,1743,  16, 847, 667, 622,
 708,1744,1745,1746, 966, 787, 304, 129,1747,  60, 820, 123, 676,1748,1749,1750,
1751, 617,1752, 626,1753,1754,1755,1756, 653,1757,1758,1759,1760,1761,1762, 856,
 344,1763,1764,1765,1766,  89, 401, 418, 806, 905, 848,1767,1768,1769, 946,1205,
 709,1770,1118,1771, 241,1772,1773,1774,1271,1775, 569,1776, 999,1777,1778,1779,
1780, 337, 751,1058,  28, 628, 254,1781, 177, 906, 270, 349, 891,1079,1782,  19,
1783, 379,1784, 315,1785, 629, 754,1402, 559,1786, 636, 203,1206,1787, 710, 567,
1788, 935, 814,1789,1790,1207, 766, 528,1791,1792,1208,1793,1794,1795,1796,1797,
1403,1798,1799, 533,1059,1404,1405,1156,1406, 936, 884,1080,1800, 351,1801,1802,
1803,1804,1805, 801,1806,1807,1808,1119,1809,1157, 714, 474,1407,1810, 298, 899,
 885,1811,1120, 802,1158,1812, 892,1813,1814,1408, 659,1815,1816,1121,1817,1818,
1819,1820,1821,1822, 319,1823, 594, 545,1824, 815, 937,1209,1825,1826, 573,1409,
1022,1827,1210,1828,1829,1830,1831,1832,1833, 556, 722, 807,1122,1060,1834, 697,
1835, 900, 557, 715,1836,1410, 540,1411, 752,1159, 294, 597,1211, 976, 803, 770,
1412,1837,1838,  39, 794,1413, 358,1839, 371, 925,1840, 453, 661, 788, 531, 723,
 544,1023,1081, 869,  91,1841, 392, 430, 790, 602,1414, 677,1082, 457,1415,1416,
1842,1843, 475, 327,1024,1417, 795, 121,1844, 733, 403,1418,1845,1846,1847, 300,
 119, 711,1212, 627,1848,1272, 207,1849,1850, 796,1213, 382,1851, 519,1852,1083,
 893,1853,1854,1855, 367, 809, 487, 671,1856, 663,1857,1858, 956, 471, 306, 857,
1859,1860,1160,1084,1861,1862,1863,1864,1865,1061,1866,1867,1868,1869,1870,1871,
 282,  96, 574,1872, 502,1085,1873,1214,1874, 907,1875,1876, 827, 977,1419,1420,
1421, 268,1877,1422,1878,1879,1880, 308,1881,   2, 537,1882,1883,1215,1884,1885,
 127, 791,1886,1273,1423,1887,  34, 336, 404, 643,1888, 571, 654, 894, 840,1889,
   0, 886,1274, 122, 575, 260, 908, 938,1890,1275, 410, 316,1891,1892, 100,1893,
1894,1123,  48,1161,1124,1025,1895, 633, 901,1276,1896,1897, 115, 816,1898, 317,
1899, 694,1900, 909, 734,1424, 572, 866,1425, 691,  85, 524,1010, 543, 394, 841,
1901,1902,1903,1026,1904,1905,1906,1907,1908,1909,  30, 451, 651, 988, 310,1910,
1911,1426, 810,1216,  93,1912,1913,1277,1217,1914, 858, 759,  45,  58, 181, 610,
 269,1915,1916, 131,1062, 551, 443,1000, 821,1427, 957, 895,1086,1917,1918, 375,
1919, 359,1920, 687,1921, 822,1922, 293,1923,1924,  40, 662, 118, 692,  29, 939,
 887, 640, 482, 174,1925,  69,1162, 728,1428, 910,1926,1278,1218,1279, 386, 870,
 217, 854,1163, 823,1927,1928,1929,1930, 834,1931,  78,1932, 859,1933,1063,1934,
1935,1936,1937, 438,1164, 208, 595,1938,1939,1940,1941,1219,1125,1942, 280, 888,
1429,1430,1220,1431,1943,1944,1945,1946,1947,1280, 150, 510,1432,1948,1949,1950,
1951,1952,1953,1954,1011,1087,1955,1433,1043,1956, 881,1957, 614, 958,1064,1065,
1221,1958, 638,1001, 860, 967, 896,1434, 989, 492, 553,1281,1165,1959,1282,1002,
1283,1222,1960,1961,1962,1963,  36, 383, 228, 753, 247, 454,1964, 876, 678,1965,
1966,1284, 126, 464, 490, 835, 136, 672, 529, 940,1088,1435, 473,1967,1968, 467,
  50, 390, 227, 587, 279, 378, 598, 792, 968, 240, 151, 160, 849, 882,1126,1285,
 639,1044, 133, 140, 288, 360, 811, 563,1027, 561, 142, 523,1969,1970,1971,   7,
 103, 296, 439, 407, 506, 634, 990,1972,1973,1974,1975, 645,1976,1977,1978,1979,
1980,1981, 236,1982,1436,1983,1984,1089, 192, 828, 618, 518,1166, 333,1127,1985,
 818,1223,1986,1987,1988,1989,1990,1991,1992,1993, 342,1128,1286, 746, 842,1994,
1995, 560, 223,1287,  98,   8, 189, 650, 978,1288,1996,1437,1997,  17, 345, 250,
 423, 277, 234, 512, 226,  97, 289,  42, 167,1998, 201,1999,2000, 843, 836, 824,
 532, 338, 783,1090, 182, 576, 436,1438,1439, 527, 500,2001, 947, 889,2002,2003,
2004,2005, 262, 600, 314, 447,2006, 547,2007, 693, 738,1129,2008,  71,1440, 745,
 619, 688,2009, 829,2010,2011, 147,2012,  33, 948,2013,2014,  74, 224,2015,  61,
 191, 918, 399, 637,2016,1028,1130, 257, 902,2017,2018,2019,2020,2021,2022,2023,
2024,2025,2026, 837,2027,2028,2029,2030, 179, 874, 591,  52, 724, 246,2031,2032,
2033,2034,1167, 969,2035,1289, 630, 605, 911,1091,1168,2036,2037,2038,1441, 912,
2039, 623,2040,2041, 253,1169,1290,2042,1442, 146, 620, 611, 577, 433,2043,1224,
 719,1170, 959, 440, 437, 534,  84, 388, 480,1131, 159, 220, 198, 679,2044,1012,
 819,1066,1443, 113,1225, 194, 318,1003,1029,2045,2046,2047,2048,1067,2049,2050,
2051,2052,2053,  59, 913, 112,2054, 632,2055, 455, 144, 739,1291,2056, 273, 681,
 499,2057, 448,2058,2059, 760,2060,2061, 970, 384, 169, 245,1132,2062,2063, 414,
1444,2064,2065,  41, 235,2066, 157, 252, 877, 568, 919, 789, 580,2067, 725,2068,
2069,1292,2070,2071,1445,2072,1446,2073,2074,  55, 588,  66,1447, 271,1092,2075,
1226,2076, 960,1013, 372,2077,2078,2079,2080,2081,1293,2082,2083,2084,2085, 850,
2086,2087,2088,2089,2090, 186,2091,1068, 180,2092,2093,2094, 109,1227, 522, 606,
2095, 867,1448,1093, 991,1171, 926, 353,1133,2096, 581,2097,2098,2099,1294,1449,
1450,2100, 596,1172,1014,1228,2101,1451,1295,1173,1229,2102,2103,1296,1134,1452,
 949,1135,2104,2105,1094,1453,1454,1455,2106,1095,2107,2108,2109,2110,2111,2112,
2113,2114,2115,2116,2117, 804,2118,2119,1230,1231, 805,1456, 405,1136,2120,2121,
2122,2123,2124, 720, 701,1297, 992,1457, 927,1004,2125,2126,2127,2128,2129,2130,
  22, 417,2131, 303,2132, 385,2133, 971, 520, 513,2134,1174,  73,1096, 231, 274,
 962,1458, 673,2135,1459,2136, 152,1137,2137,2138,2139,2140,1005,1138,1460,1139,
2141,2142,2143,2144,  11, 374, 844,2145, 154,1232,  46,1461,2146, 838, 830, 721,
1233, 106,2147,  90, 428, 462, 578, 566,1175, 352,2148,2149, 538,1234, 124,1298,
2150,1462, 761, 565,2151, 686,2152, 649,2153,  72, 173,2154, 460, 415,2155,1463,
2156,1235, 305,2157,2158,2159,2160,2161,2162, 579,2163,2164,2165,2166,2167, 747,
2168,2169,2170,2171,1464, 669,2172,2173,2174,2175,2176,1465,2177,  23, 530, 285,
2178, 335, 729,2179, 397,2180,2181,2182,1030,2183,2184, 698,2185,2186, 325,2187,
2188, 369,2189, 799,1097,1015, 348,2190,1069, 680,2191, 851,1466,2192,2193,  10,
2194, 613, 424,2195, 979, 108, 449, 589,  27, 172,  81,1031,  80, 774, 281, 350,
1032, 525, 301, 582,1176,2196, 674,1045,2197,2198,1467, 730, 762,2199,2200,2201,
2202,1468,2203, 993,2204,2205, 266,1070, 963,1140,2206,2207,2208, 664,1098, 972,
2209,2210,2211,1177,1469,1470, 871,2212,2213,2214,2215,2216,1471,2217,2218,2219,
2220,2221,2222,2223,2224,2225,2226,2227,1472,1236,2228,2229,2230,2231,2232,2233,
2234,2235,1299,2236,2237, 200,2238, 477, 373,2239,2240, 731, 825, 777,2241,2242,
2243, 521, 486, 548,2244,2245,2246,1473,1300,  53, 549, 137, 875,  76, 158,2247,
1301,1474, 469, 396,1016, 278, 712,2248, 321, 442, 503, 767, 744, 941,1237,1178,
1475,2249,  82, 178,1141,1179, 973,2250,1302,2251, 297,2252,2253, 570,2254,2255,
2256,  18, 450, 206,2257, 290, 292,1142,2258, 511, 162,  99, 346, 164, 735,2259,
1476,1477,   4, 554, 343, 798,1099,2260,1100,2261,  43, 171,1303, 139, 215,2262,
2263, 717, 775,2264,1033, 322, 216,2265, 831,2266, 149,2267,1304,2268,2269, 702,
1238, 135, 845, 347, 309,2270, 484,2271, 878, 655, 238,1006,1478,2272,  67,2273,
 295,2274,2275, 461,2276, 478, 942, 412,2277,1034,2278,2279,2280, 265,2281, 541,
2282,2283,2284,2285,2286,  70, 852,1071,2287,2288,2289,2290,  21,  56, 509, 117,
 432,2291,2292, 331, 980, 552,1101, 148, 284, 105, 393,1180,1239, 755,2293, 187,
2294,1046,1479,2295, 340,2296,  63,1047, 230,2297,2298,1305, 763,1306, 101, 800,
 808, 494,2299,2300,2301, 903,2302,  37,1072,  14,   5,2303,  79, 675,2304, 312,
2305,2306,2307,2308,2309,1480,   6,1307,2310,2311,2312,   1, 470,  35,  24, 229,
2313, 695, 210,  86, 778,  15, 784, 592, 779,  32,  77, 855, 964,2314, 259,2315,
 501, 380,2316,2317,  83, 981, 153, 689,1308,1481,1482,1483,2318,2319, 716,1484,
2320,2321,2322,2323,2324,2325,1485,2326,2327, 128,  57,  68, 261,1048, 211, 170,
1240,  31,2328,  51, 435, 742,2329,2330,2331, 635,2332, 264, 456,2333,2334,2335,
 425,2336,1486, 143, 507, 263, 943,2337, 363, 920,1487, 256,1488,1102, 243, 601,
1489,2338,2339,2340,2341,2342,2343,2344, 861,2345,2346,2347,2348,2349,2350, 395,
2351,1490,1491,  62, 535, 166, 225,2352,2353, 668, 419,1241, 138, 604, 928,2354,
1181,2355,1492,1493,2356,2357,2358,1143,2359, 696,2360, 387, 307,1309, 682, 476,
2361,2362, 332,  12, 222, 156,2363, 232,2364, 641, 276, 656, 517,1494,1495,1035,
 416, 736,1496,2365,1017, 586,2366,2367,2368,1497,2369, 242,2370,2371,2372,1498,
2373, 965, 713,2374,2375,2376,2377, 740, 982,1499, 944,1500,1007,2378,2379,1310,
1501,2380,2381,2382, 785, 329,2383,2384,1502,2385,2386,2387, 932,2388,1503,2389,
2390,2391,2392,1242,2393,2394,2395,2396,2397, 994, 950,2398,2399,2400,2401,1504,
1311,2402,2403,2404,2405,1049, 749,2406,2407, 853, 718,1144,1312,2408,1182,1505,
2409,2410, 255, 516, 479, 564, 550, 214,1506,1507,1313, 413, 239, 444, 339,1145,
1036,1508,1509,1314,1037,1510,1315,2411,1511,2412,2413,2414, 176, 703, 497, 624,
 593, 921, 302,2415, 341, 165,1103,1512,2416,1513,2417,2418,2419, 376,2420, 700,
2421,2422,2423, 258, 768,1316,2424,1183,2425, 995, 608,2426,2427,2428,2429, 221,
2430,2431,2432,2433,2434,2435,2436,2437, 195, 323, 726, 188, 897, 983,1317, 377,
 644,1050, 879,2438, 452,2439,2440,2441,2442,2443,2444, 914,2445,2446,2447,2448,
 915, 489,2449,1514,1184,2450,2451, 515,  64, 427, 495,2452, 583,2453, 483, 485,
1038, 562, 213,1515, 748, 666,2454,2455,2456,2457, 334,2458, 780, 996,1008, 705,
1243,2459,2460,2461,2462,2463, 114,2464, 493,1146, 366, 163,1516, 961,1104,2465,
 291,2466,1318,1105,2467,1517, 365,2468, 355, 951,1244,2469,1319,2470, 631,2471,
2472, 218,1320, 364, 320, 756,1518,1519,1321,1520,1322,2473,2474,2475,2476, 997,
2477,2478,2479,2480, 665,1185,2481, 916,1521,2482,2483,2484, 584, 684,2485,2486,
 797,2487,1051,1186,2488,2489,2490,1522,2491,2492, 370,2493,1039,1187,  65,2494,
 434, 205, 463,1188,2495, 125, 812, 391, 402, 826, 699, 286, 398, 155, 781, 771,
 585,2496, 590, 505,1073,2497, 599, 244, 219, 917,1018, 952, 646,1523,2498,1323,
2499,2500,  49, 984, 354, 741,2501, 625,2502,1324,2503,1019, 190, 357, 757, 491,
  95, 782, 868,2504,2505,2506,2507,2508,2509, 134,1524,1074, 422,1525, 898,2510,
 161,2511,2512,2513,2514, 769,2515,1526,2516,2517, 411,1325,2518, 472,1527,2519,
2520,2521,2522,2523,2524, 985,2525,2526,2527,2528,2529,2530, 764,2531,1245,2532,
2533,  25, 204, 311,2534, 496,2535,1052,2536,2537,2538,2539,2540,2541,2542, 199,
 704, 504, 468, 758, 657,1528, 196,  44, 839,1246, 272, 750,2543, 765, 862,2544,
2545,1326,2546, 132, 615, 933,2547, 732,2548,2549,2550,1189,1529,2551, 283,1247,
1053, 607, 929,2552,2553,2554, 930, 183, 872, 616,1040,1147,2555,1148,1020, 441,
 249,1075,2556,2557,2558, 466, 743,2559,2560,2561,  92, 514, 426, 420, 526,2562,
2563,2564,2565,2566,2567,2568, 185,2569,2570,2571,2572, 776,1530, 658,2573, 362,
2574, 361, 922,1076, 793,2575,2576,2577,2578,2579,2580,1531, 251,2581,2582,2583,
2584,1532,  54, 612, 237,1327,2585,2586, 275, 408, 647, 111,2587,1533,1106, 465,
   3, 458,   9,  38,2588, 107, 110, 890, 209,  26, 737, 498,2589,1534,2590, 431,
 202,  88,1535, 356, 287,1107, 660,1149,2591, 381,1536, 986,1150, 445,1248,1151,
 974,2592,2593, 846,2594, 446, 953, 184,1249,1250, 727,2595, 923, 193, 883,2596,
2597,2598, 102, 324, 539, 817,2599, 421,1041,2600, 832,2601,  94, 175, 197, 406,
2602, 459,2603,2604,2605,2606,2607, 330, 555,2608,2609,2610, 706,1108, 389,2611,
2612,2613,2614, 233,2615, 833, 558, 931, 954,1251,2616,2617,1537, 546,2618,2619,
1009,2620,2621,2622,1538, 690,1328,2623, 955,2624,1539,2625,2626, 772,2627,2628,
2629,2630,2631, 924, 648, 863, 603,2632,2633, 934,1540, 864, 865,2634, 642,1042,
 670,1190,2635,2636,2637,2638, 168,2639, 652, 873, 542,1054,1541,2640,2641,2642,  # 512, 256
#Everything below is of no interest for detection purpose
2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,
2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,
2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,
2691,2692,2693,2694,2695,2696,2697,2698,2699,1542, 880,2700,2701,2702,2703,2704,
2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,
2721,2722,2723,2724,2725,1543,2726,2727,2728,2729,2730,2731,2732,1544,2733,2734,
2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,
2751,2752,2753,2754,1545,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,
2766,1546,2767,1547,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,
2780,2781,2782,2783,2784,2785,2786,1548,2787,2788,2789,1109,2790,2791,2792,2793,
2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,
2810,2811,2812,1329,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,
2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,
2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,
1549,2857,2858,2859,2860,1550,2861,2862,1551,2863,2864,2865,2866,2867,2868,2869,
2870,2871,2872,2873,2874,1110,1330,2875,2876,2877,2878,2879,2880,2881,2882,2883,
2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,
2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,
2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,1331,
2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,1552,2944,2945,
2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,
2962,2963,2964,1252,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,
2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,
2993,2994,2995,2996,2997,2998,2999,3000,3001,3002,3003,3004,3005,3006,3007,3008,
3009,3010,3011,3012,1553,3013,3014,3015,3016,3017,1554,3018,1332,3019,3020,3021,
3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3033,3034,3035,3036,3037,
3038,3039,3040,3041,3042,3043,3044,3045,3046,3047,3048,3049,3050,1555,3051,3052,
3053,1556,1557,3054,3055,3056,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,
3067,1558,3068,3069,3070,3071,3072,3073,3074,3075,3076,1559,3077,3078,3079,3080,
3081,3082,3083,1253,3084,3085,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,
3096,3097,3098,3099,3100,3101,3102,3103,3104,3105,3106,3107,3108,1152,3109,3110,
3111,3112,3113,1560,3114,3115,3116,3117,1111,3118,3119,3120,3121,3122,3123,3124,
3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3135,3136,3137,3138,3139,3140,
3141,3142,3143,3144,3145,3146,3147,3148,3149,3150,3151,3152,3153,3154,3155,3156,
3157,3158,3159,3160,3161,3162,3163,3164,3165,3166,3167,3168,3169,3170,3171,3172,
3173,3174,3175,3176,1333,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,
3188,3189,1561,3190,3191,1334,3192,3193,3194,3195,3196,3197,3198,3199,3200,3201,
3202,3203,3204,3205,3206,3207,3208,3209,3210,3211,3212,3213,3214,3215,3216,3217,
3218,3219,3220,3221,3222,3223,3224,3225,3226,3227,3228,3229,3230,3231,3232,3233,
3234,1562,3235,3236,3237,3238,3239,3240,3241,3242,3243,3244,3245,3246,3247,3248,
3249,3250,3251,3252,3253,3254,3255,3256,3257,3258,3259,3260,3261,3262,3263,3264,
3265,3266,3267,3268,3269,3270,3271,3272,3273,3274,3275,3276,3277,1563,3278,3279,
3280,3281,3282,3283,3284,3285,3286,3287,3288,3289,3290,3291,3292,3293,3294,3295,
3296,3297,3298,3299,3300,3301,3302,3303,3304,3305,3306,3307,3308,3309,3310,3311,
3312,3313,3314,3315,3316,3317,3318,3319,3320,3321,3322,3323,3324,3325,3326,3327,
3328,3329,3330,3331,3332,3333,3334,3335,3336,3337,3338,3339,3340,3341,3342,3343,
3344,3345,3346,3347,3348,3349,3350,3351,3352,3353,3354,3355,3356,3357,3358,3359,
3360,3361,3362,3363,3364,1335,3365,3366,3367,3368,3369,3370,3371,3372,3373,3374,
3375,3376,3377,3378,3379,3380,3381,3382,3383,3384,3385,3386,3387,1336,3388,3389,
3390,3391,3392,3393,3394,3395,3396,3397,3398,3399,3400,3401,3402,3403,3404,3405,
3406,3407,3408,3409,3410,3411,3412,3413,3414,1337,3415,3416,3417,3418,3419,1338,
3420,3421,3422,1564,1565,3423,3424,3425,3426,3427,3428,3429,3430,3431,1254,3432,
3433,3434,1339,3435,3436,3437,3438,3439,1566,3440,3441,3442,3443,3444,3445,3446,
3447,3448,3449,3450,3451,3452,3453,3454,1255,3455,3456,3457,3458,3459,1567,1191,
3460,1568,1569,3461,3462,3463,1570,3464,3465,3466,3467,3468,1571,3469,3470,3471,
3472,3473,1572,3474,3475,3476,3477,3478,3479,3480,3481,3482,3483,3484,3485,3486,
1340,3487,3488,3489,3490,3491,3492,1021,3493,3494,3495,3496,3497,3498,1573,3499,
1341,3500,3501,3502,3503,3504,3505,3506,3507,3508,3509,3510,3511,1342,3512,3513,
3514,3515,3516,1574,1343,3517,3518,3519,1575,3520,1576,3521,3522,3523,3524,3525,
3526,3527,3528,3529,3530,3531,3532,3533,3534,3535,3536,3537,3538,3539,3540,3541,
3542,3543,3544,3545,3546,3547,3548,3549,3550,3551,3552,3553,3554,3555,3556,3557,
3558,3559,3560,3561,3562,3563,3564,3565,3566,3567,3568,3569,3570,3571,3572,3573,
3574,3575,3576,3577,3578,3579,3580,1577,3581,3582,1578,3583,3584,3585,3586,3587,
3588,3589,3590,3591,3592,3593,3594,3595,3596,3597,3598,3599,3600,3601,3602,3603,
3604,1579,3605,3606,3607,3608,3609,3610,3611,3612,3613,3614,3615,3616,3617,3618,
3619,3620,3621,3622,3623,3624,3625,3626,3627,3628,3629,1580,3630,3631,1581,3632,
3633,3634,3635,3636,3637,3638,3639,3640,3641,3642,3643,3644,3645,3646,3647,3648,
3649,3650,3651,3652,3653,3654,3655,3656,1582,3657,3658,3659,3660,3661,3662,3663,
3664,3665,3666,3667,3668,3669,3670,3671,3672,3673,3674,3675,3676,3677,3678,3679,
3680,3681,3682,3683,3684,3685,3686,3687,3688,3689,3690,3691,3692,3693,3694,3695,
3696,3697,3698,3699,3700,1192,3701,3702,3703,3704,1256,3705,3706,3707,3708,1583,
1257,3709,3710,3711,3712,3713,3714,3715,3716,1584,3717,3718,3719,3720,3721,3722,
3723,3724,3725,3726,3727,3728,3729,3730,3731,3732,3733,3734,3735,3736,3737,3738,
3739,3740,3741,3742,3743,3744,3745,1344,3746,3747,3748,3749,3750,3751,3752,3753,
3754,3755,3756,1585,3757,3758,3759,3760,3761,3762,3763,3764,3765,3766,1586,3767,
3768,3769,3770,3771,3772,3773,3774,3775,3776,3777,3778,1345,3779,3780,3781,3782,
3783,3784,3785,3786,3787,3788,3789,3790,3791,3792,3793,3794,3795,1346,1587,3796,
3797,1588,3798,3799,3800,3801,3802,3803,3804,3805,3806,1347,3807,3808,3809,3810,
3811,1589,3812,3813,3814,3815,3816,3817,3818,3819,3820,3821,1590,3822,3823,1591,
1348,3824,3825,3826,3827,3828,3829,3830,1592,3831,3832,1593,3833,3834,3835,3836,
3837,3838,3839,3840,3841,3842,3843,3844,1349,3845,3846,3847,3848,3849,3850,3851,
3852,3853,3854,3855,3856,3857,3858,1594,3859,3860,3861,3862,3863,3864,3865,3866,
3867,3868,3869,1595,3870,3871,3872,3873,1596,3874,3875,3876,3877,3878,3879,3880,
3881,3882,3883,3884,3885,3886,1597,3887,3888,3889,3890,3891,3892,3893,3894,3895,
1598,3896,3897,3898,1599,1600,3899,1350,3900,1351,3901,3902,1352,3903,3904,3905,
3906,3907,3908,3909,3910,3911,3912,3913,3914,3915,3916,3917,3918,3919,3920,3921,
3922,3923,3924,1258,3925,3926,3927,3928,3929,3930,3931,1193,3932,1601,3933,3934,
3935,3936,3937,3938,3939,3940,3941,3942,3943,1602,3944,3945,3946,3947,3948,1603,
3949,3950,3951,3952,3953,3954,3955,3956,3957,3958,3959,3960,3961,3962,3963,3964,
3965,1604,3966,3967,3968,3969,3970,3971,3972,3973,3974,3975,3976,3977,1353,3978,
3979,3980,3981,3982,3983,3984,3985,3986,3987,3988,3989,3990,3991,1354,3992,3993,
3994,3995,3996,3997,3998,3999,4000,4001,4002,4003,4004,4005,4006,4007,4008,4009,
4010,4011,4012,4013,4014,4015,4016,4017,4018,4019,4020,4021,4022,4023,1355,4024,
4025,4026,4027,4028,4029,4030,4031,4032,4033,4034,4035,4036,4037,4038,4039,4040,
1605,4041,4042,4043,4044,4045,4046,4047,4048,4049,4050,4051,4052,4053,4054,4055,
4056,4057,4058,4059,4060,1606,4061,4062,4063,4064,1607,4065,4066,4067,4068,4069,
4070,4071,4072,4073,4074,4075,4076,1194,4077,4078,1608,4079,4080,4081,4082,4083,
4084,4085,4086,4087,1609,4088,4089,4090,4091,4092,4093,4094,4095,4096,4097,4098,
4099,4100,4101,4102,4103,4104,4105,4106,4107,4108,1259,4109,4110,4111,4112,4113,
4114,4115,4116,4117,4118,4119,4120,4121,4122,4123,4124,1195,4125,4126,4127,1610,
4128,4129,4130,4131,4132,4133,4134,4135,4136,4137,1356,4138,4139,4140,4141,4142,
4143,4144,1611,4145,4146,4147,4148,4149,4150,4151,4152,4153,4154,4155,4156,4157,
4158,4159,4160,4161,4162,4163,4164,4165,4166,4167,4168,4169,4170,4171,4172,4173,
4174,4175,4176,4177,4178,4179,4180,4181,4182,4183,4184,4185,4186,4187,4188,4189,
4190,4191,4192,4193,4194,4195,4196,4197,4198,4199,4200,4201,4202,4203,4204,4205,
4206,4207,4208,4209,4210,4211,4212,4213,4214,4215,4216,4217,4218,4219,1612,4220,
4221,4222,4223,4224,4225,4226,4227,1357,4228,1613,4229,4230,4231,4232,4233,4234,
4235,4236,4237,4238,4239,4240,4241,4242,4243,1614,4244,4245,4246,4247,4248,4249,
4250,4251,4252,4253,4254,4255,4256,4257,4258,4259,4260,4261,4262,4263,4264,4265,
4266,4267,4268,4269,4270,1196,1358,4271,4272,4273,4274,4275,4276,4277,4278,4279,
4280,4281,4282,4283,4284,4285,4286,4287,1615,4288,4289,4290,4291,4292,4293,4294,
4295,4296,4297,4298,4299,4300,4301,4302,4303,4304,4305,4306,4307,4308,4309,4310,
4311,4312,4313,4314,4315,4316,4317,4318,4319,4320,4321,4322,4323,4324,4325,4326,
4327,4328,4329,4330,4331,4332,4333,4334,1616,4335,4336,4337,4338,4339,4340,4341,
4342,4343,4344,4345,4346,4347,4348,4349,4350,4351,4352,4353,4354,4355,4356,4357,
4358,4359,4360,1617,4361,4362,4363,4364,4365,1618,4366,4367,4368,4369,4370,4371,
4372,4373,4374,4375,4376,4377,4378,4379,4380,4381,4382,4383,4384,4385,4386,4387,
4388,4389,4390,4391,4392,4393,4394,4395,4396,4397,4398,4399,4400,4401,4402,4403,
4404,4405,4406,4407,4408,4409,4410,4411,4412,4413,4414,4415,4416,1619,4417,4418,
4419,4420,4421,4422,4423,4424,4425,1112,4426,4427,4428,4429,4430,1620,4431,4432,
4433,4434,4435,4436,4437,4438,4439,4440,4441,4442,1260,1261,4443,4444,4445,4446,
4447,4448,4449,4450,4451,4452,4453,4454,4455,1359,4456,4457,4458,4459,4460,4461,
4462,4463,4464,4465,1621,4466,4467,4468,4469,4470,4471,4472,4473,4474,4475,4476,
4477,4478,4479,4480,4481,4482,4483,4484,4485,4486,4487,4488,4489,1055,4490,4491,
4492,4493,4494,4495,4496,4497,4498,4499,4500,4501,4502,4503,4504,4505,4506,4507,
4508,4509,4510,4511,4512,4513,4514,4515,4516,4517,4518,1622,4519,4520,4521,1623,
4522,4523,4524,4525,4526,4527,4528,4529,4530,4531,4532,4533,4534,4535,1360,4536,
4537,4538,4539,4540,4541,4542,4543, 975,4544,4545,4546,4547,4548,4549,4550,4551,
4552,4553,4554,4555,4556,4557,4558,4559,4560,4561,4562,4563,4564,4565,4566,4567,
4568,4569,4570,4571,1624,4572,4573,4574,4575,4576,1625,4577,4578,4579,4580,4581,
4582,4583,4584,1626,4585,4586,4587,4588,4589,4590,4591,4592,4593,4594,4595,1627,
4596,4597,4598,4599,4600,4601,4602,4603,4604,4605,4606,4607,4608,4609,4610,4611,
4612,4613,4614,4615,1628,4616,4617,4618,4619,4620,4621,4622,4623,4624,4625,4626,
4627,4628,4629,4630,4631,4632,4633,4634,4635,4636,4637,4638,4639,4640,4641,4642,
4643,4644,4645,4646,4647,4648,4649,1361,4650,4651,4652,4653,4654,4655,4656,4657,
4658,4659,4660,4661,1362,4662,4663,4664,4665,4666,4667,4668,4669,4670,4671,4672,
4673,4674,4675,4676,4677,4678,4679,4680,4681,4682,1629,4683,4684,4685,4686,4687,
1630,4688,4689,4690,4691,1153,4692,4693,4694,1113,4695,4696,4697,4698,4699,4700,
4701,4702,4703,4704,4705,4706,4707,4708,4709,4710,4711,1197,4712,4713,4714,4715,
4716,4717,4718,4719,4720,4721,4722,4723,4724,4725,4726,4727,4728,4729,4730,4731,
4732,4733,4734,4735,1631,4736,1632,4737,4738,4739,4740,4741,4742,4743,4744,1633,
4745,4746,4747,4748,4749,1262,4750,4751,4752,4753,4754,1363,4755,4756,4757,4758,
4759,4760,4761,4762,4763,4764,4765,4766,4767,4768,1634,4769,4770,4771,4772,4773,
4774,4775,4776,4777,4778,1635,4779,4780,4781,4782,4783,4784,4785,4786,4787,4788,
4789,1636,4790,4791,4792,4793,4794,4795,4796,4797,4798,4799,4800,4801,4802,4803,
4804,4805,4806,1637,4807,4808,4809,1638,4810,4811,4812,4813,4814,4815,4816,4817,
4818,1639,4819,4820,4821,4822,4823,4824,4825,4826,4827,4828,4829,4830,4831,4832,
4833,1077,4834,4835,4836,4837,4838,4839,4840,4841,4842,4843,4844,4845,4846,4847,
4848,4849,4850,4851,4852,4853,4854,4855,4856,4857,4858,4859,4860,4861,4862,4863,
4864,4865,4866,4867,4868,4869,4870,4871,4872,4873,4874,4875,4876,4877,4878,4879,
4880,4881,4882,4883,1640,4884,4885,1641,4886,4887,4888,4889,4890,4891,4892,4893,
4894,4895,4896,4897,4898,4899,4900,4901,4902,4903,4904,4905,4906,4907,4908,4909,
4910,4911,1642,4912,4913,4914,1364,4915,4916,4917,4918,4919,4920,4921,4922,4923,
4924,4925,4926,4927,4928,4929,4930,4931,1643,4932,4933,4934,4935,4936,4937,4938,
4939,4940,4941,4942,4943,4944,4945,4946,4947,4948,4949,4950,4951,4952,4953,4954,
4955,4956,4957,4958,4959,4960,4961,4962,4963,4964,4965,4966,4967,4968,4969,4970,
4971,4972,4973,4974,4975,4976,4977,4978,4979,4980,1644,4981,4982,4983,4984,1645,
4985,4986,1646,4987,4988,4989,4990,4991,4992,4993,4994,4995,4996,4997,4998,4999,
5000,5001,5002,5003,5004,5005,1647,5006,1648,5007,5008,5009,5010,5011,5012,1078,
5013,5014,5015,5016,5017,5018,5019,5020,5021,5022,5023,5024,5025,5026,5027,5028,
1365,5029,5030,5031,5032,5033,5034,5035,5036,5037,5038,5039,1649,5040,5041,5042,
5043,5044,5045,1366,5046,5047,5048,5049,5050,5051,5052,5053,5054,5055,1650,5056,
5057,5058,5059,5060,5061,5062,5063,5064,5065,5066,5067,5068,5069,5070,5071,5072,
5073,5074,5075,5076,5077,1651,5078,5079,5080,5081,5082,5083,5084,5085,5086,5087,
5088,5089,5090,5091,5092,5093,5094,5095,5096,5097,5098,5099,5100,5101,5102,5103,
5104,5105,5106,5107,5108,5109,5110,1652,5111,5112,5113,5114,5115,5116,5117,5118,
1367,5119,5120,5121,5122,5123,5124,5125,5126,5127,5128,5129,1653,5130,5131,5132,
5133,5134,5135,5136,5137,5138,5139,5140,5141,5142,5143,5144,5145,5146,5147,5148,
5149,1368,5150,1654,5151,1369,5152,5153,5154,5155,5156,5157,5158,5159,5160,5161,
5162,5163,5164,5165,5166,5167,5168,5169,5170,5171,5172,5173,5174,5175,5176,5177,
5178,1370,5179,5180,5181,5182,5183,5184,5185,5186,5187,5188,5189,5190,5191,5192,
5193,5194,5195,5196,5197,5198,1655,5199,5200,5201,5202,1656,5203,5204,5205,5206,
1371,5207,1372,5208,5209,5210,5211,1373,5212,5213,1374,5214,5215,5216,5217,5218,
5219,5220,5221,5222,5223,5224,5225,5226,5227,5228,5229,5230,5231,5232,5233,5234,
5235,5236,5237,5238,5239,5240,5241,5242,5243,5244,5245,5246,5247,1657,5248,5249,
5250,5251,1658,1263,5252,5253,5254,5255,5256,1375,5257,5258,5259,5260,5261,5262,
5263,5264,5265,5266,5267,5268,5269,5270,5271,5272,5273,5274,5275,5276,5277,5278,
5279,5280,5281,5282,5283,1659,5284,5285,5286,5287,5288,5289,5290,5291,5292,5293,
5294,5295,5296,5297,5298,5299,5300,1660,5301,5302,5303,5304,5305,5306,5307,5308,
5309,5310,5311,5312,5313,5314,5315,5316,5317,5318,5319,5320,5321,1376,5322,5323,
5324,5325,5326,5327,5328,5329,5330,5331,5332,5333,1198,5334,5335,5336,5337,5338,
5339,5340,5341,5342,5343,1661,5344,5345,5346,5347,5348,5349,5350,5351,5352,5353,
5354,5355,5356,5357,5358,5359,5360,5361,5362,5363,5364,5365,5366,5367,5368,5369,
5370,5371,5372,5373,5374,5375,5376,5377,5378,5379,5380,5381,5382,5383,5384,5385,
5386,5387,5388,5389,5390,5391,5392,5393,5394,5395,5396,5397,5398,1264,5399,5400,
5401,5402,5403,5404,5405,5406,5407,5408,5409,5410,5411,5412,1662,5413,5414,5415,
5416,1663,5417,5418,5419,5420,5421,5422,5423,5424,5425,5426,5427,5428,5429,5430,
5431,5432,5433,5434,5435,5436,5437,5438,1664,5439,5440,5441,5442,5443,5444,5445,
5446,5447,5448,5449,5450,5451,5452,5453,5454,5455,5456,5457,5458,5459,5460,5461,
5462,5463,5464,5465,5466,5467,5468,5469,5470,5471,5472,5473,5474,5475,5476,5477,
5478,1154,5479,5480,5481,5482,5483,5484,5485,1665,5486,5487,5488,5489,5490,5491,
5492,5493,5494,5495,5496,5497,5498,5499,5500,5501,5502,5503,5504,5505,5506,5507,
5508,5509,5510,5511,5512,5513,5514,5515,5516,5517,5518,5519,5520,5521,5522,5523,
5524,5525,5526,5527,5528,5529,5530,5531,5532,5533,5534,5535,5536,5537,5538,5539,
5540,5541,5542,5543,5544,5545,5546,5547,5548,1377,5549,5550,5551,5552,5553,5554,
5555,5556,5557,5558,5559,5560,5561,5562,5563,5564,5565,5566,5567,5568,5569,5570,
1114,5571,5572,5573,5574,5575,5576,5577,5578,5579,5580,5581,5582,5583,5584,5585,
5586,5587,5588,5589,5590,5591,5592,1378,5593,5594,5595,5596,5597,5598,5599,5600,
5601,5602,5603,5604,5605,5606,5607,5608,5609,5610,5611,5612,5613,5614,1379,5615,
5616,5617,5618,5619,5620,5621,5622,5623,5624,5625,5626,5627,5628,5629,5630,5631,
5632,5633,5634,1380,5635,5636,5637,5638,5639,5640,5641,5642,5643,5644,5645,5646,
5647,5648,5649,1381,1056,5650,5651,5652,5653,5654,5655,5656,5657,5658,5659,5660,
1666,5661,5662,5663,5664,5665,5666,5667,5668,1667,5669,1668,5670,5671,5672,5673,
5674,5675,5676,5677,5678,1155,5679,5680,5681,5682,5683,5684,5685,5686,5687,5688,
5689,5690,5691,5692,5693,5694,5695,5696,5697,5698,1669,5699,5700,5701,5702,5703,
5704,5705,1670,5706,5707,5708,5709,5710,1671,5711,5712,5713,5714,1382,5715,5716,
5717,5718,5719,5720,5721,5722,5723,5724,5725,1672,5726,5727,1673,1674,5728,5729,
5730,5731,5732,5733,5734,5735,5736,1675,5737,5738,5739,5740,5741,5742,5743,5744,
1676,5745,5746,5747,5748,5749,5750,5751,1383,5752,5753,5754,5755,5756,5757,5758,
5759,5760,5761,5762,5763,5764,5765,5766,5767,5768,1677,5769,5770,5771,5772,5773,
1678,5774,5775,5776, 998,5777,5778,5779,5780,5781,5782,5783,5784,5785,1384,5786,
5787,5788,5789,5790,5791,5792,5793,5794,5795,5796,5797,5798,5799,5800,1679,5801,
5802,5803,1115,1116,5804,5805,5806,5807,5808,5809,5810,5811,5812,5813,5814,5815,
5816,5817,5818,5819,5820,5821,5822,5823,5824,5825,5826,5827,5828,5829,5830,5831,
5832,5833,5834,5835,5836,5837,5838,5839,5840,5841,5842,5843,5844,5845,5846,5847,
5848,5849,5850,5851,5852,5853,5854,5855,1680,5856,5857,5858,5859,5860,5861,5862,
5863,5864,1681,5865,5866,5867,1682,5868,5869,5870,5871,5872,5873,5874,5875,5876,
5877,5878,5879,1683,5880,1684,5881,5882,5883,5884,1685,5885,5886,5887,5888,5889,
5890,5891,5892,5893,5894,5895,5896,5897,5898,5899,5900,5901,5902,5903,5904,5905,
5906,5907,1686,5908,5909,5910,5911,5912,5913,5914,5915,5916,5917,5918,5919,5920,
5921,5922,5923,5924,5925,5926,5927,5928,5929,5930,5931,5932,5933,5934,5935,1687,
5936,5937,5938,5939,5940,5941,5942,5943,5944,5945,5946,5947,5948,5949,5950,5951,
5952,1688,1689,5953,1199,5954,5955,5956,5957,5958,5959,5960,5961,1690,5962,5963,
5964,5965,5966,5967,5968,5969,5970,5971,5972,5973,5974,5975,5976,5977,5978,5979,
5980,5981,1385,5982,1386,5983,5984,5985,5986,5987,5988,5989,5990,5991,5992,5993,
5994,5995,5996,5997,5998,5999,6000,6001,6002,6003,6004,6005,6006,6007,6008,6009,
6010,6011,6012,6013,6014,6015,6016,6017,6018,6019,6020,6021,6022,6023,6024,6025,
6026,6027,1265,6028,6029,1691,6030,6031,6032,6033,6034,6035,6036,6037,6038,6039,
6040,6041,6042,6043,6044,6045,6046,6047,6048,6049,6050,6051,6052,6053,6054,6055,
6056,6057,6058,6059,6060,6061,6062,6063,6064,6065,6066,6067,6068,6069,6070,6071,
6072,6073,6074,6075,6076,6077,6078,6079,6080,6081,6082,6083,6084,1692,6085,6086,
6087,6088,6089,6090,6091,6092,6093,6094,6095,6096,6097,6098,6099,6100,6101,6102,
6103,6104,6105,6106,6107,6108,6109,6110,6111,6112,6113,6114,6115,6116,6117,6118,
6119,6120,6121,6122,6123,6124,6125,6126,6127,6128,6129,6130,6131,1693,6132,6133,
6134,6135,6136,1694,6137,6138,6139,6140,6141,1695,6142,6143,6144,6145,6146,6147,
6148,6149,6150,6151,6152,6153,6154,6155,6156,6157,6158,6159,6160,6161,6162,6163,
6164,6165,6166,6167,6168,6169,6170,6171,6172,6173,6174,6175,6176,6177,6178,6179,
6180,6181,6182,6183,6184,6185,1696,6186,6187,6188,6189,6190,6191,6192,6193,6194,
6195,6196,6197,6198,6199,6200,6201,6202,6203,6204,6205,6206,6207,6208,6209,6210,
6211,6212,6213,6214,6215,6216,6217,6218,6219,1697,6220,6221,6222,6223,6224,6225,
6226,6227,6228,6229,6230,6231,6232,6233,6234,6235,6236,6237,6238,6239,6240,6241,
6242,6243,6244,6245,6246,6247,6248,6249,6250,6251,6252,6253,1698,6254,6255,6256,
6257,6258,6259,6260,6261,6262,6263,1200,6264,6265,6266,6267,6268,6269,6270,6271,  #1024
6272,6273,6274,6275,6276,6277,6278,6279,6280,6281,6282,6283,6284,6285,6286,6287,
6288,6289,6290,6291,6292,6293,6294,6295,6296,6297,6298,6299,6300,6301,6302,1699,
6303,6304,1700,6305,6306,6307,6308,6309,6310,6311,6312,6313,6314,6315,6316,6317,
6318,6319,6320,6321,6322,6323,6324,6325,6326,6327,6328,6329,6330,6331,6332,6333,
6334,6335,6336,6337,6338,6339,1701,6340,6341,6342,6343,6344,1387,6345,6346,6347,
6348,6349,6350,6351,6352,6353,6354,6355,6356,6357,6358,6359,6360,6361,6362,6363,
6364,6365,6366,6367,6368,6369,6370,6371,6372,6373,6374,6375,6376,6377,6378,6379,
6380,6381,6382,6383,6384,6385,6386,6387,6388,6389,6390,6391,6392,6393,6394,6395,
6396,6397,6398,6399,6400,6401,6402,6403,6404,6405,6406,6407,6408,6409,6410,6411,
6412,6413,1702,6414,6415,6416,6417,6418,6419,6420,6421,6422,1703,6423,6424,6425,
6426,6427,6428,6429,6430,6431,6432,6433,6434,6435,6436,6437,6438,1704,6439,6440,
6441,6442,6443,6444,6445,6446,6447,6448,6449,6450,6451,6452,6453,6454,6455,6456,
6457,6458,6459,6460,6461,6462,6463,6464,6465,6466,6467,6468,6469,6470,6471,6472,
6473,6474,6475,6476,6477,6478,6479,6480,6481,6482,6483,6484,6485,6486,6487,6488,
6489,6490,6491,6492,6493,6494,6495,6496,6497,6498,6499,6500,6501,6502,6503,1266,
6504,6505,6506,6507,6508,6509,6510,6511,6512,6513,6514,6515,6516,6517,6518,6519,
6520,6521,6522,6523,6524,6525,6526,6527,6528,6529,6530,6531,6532,6533,6534,6535,
6536,6537,6538,6539,6540,6541,6542,6543,6544,6545,6546,6547,6548,6549,6550,6551,
1705,1706,6552,6553,6554,6555,6556,6557,6558,6559,6560,6561,6562,6563,6564,6565,
6566,6567,6568,6569,6570,6571,6572,6573,6574,6575,6576,6577,6578,6579,6580,6581,
6582,6583,6584,6585,6586,6587,6588,6589,6590,6591,6592,6593,6594,6595,6596,6597,
6598,6599,6600,6601,6602,6603,6604,6605,6606,6607,6608,6609,6610,6611,6612,6613,
6614,6615,6616,6617,6618,6619,6620,6621,6622,6623,6624,6625,6626,6627,6628,6629,
6630,6631,6632,6633,6634,6635,6636,6637,1388,6638,6639,6640,6641,6642,6643,6644,
1707,6645,6646,6647,6648,6649,6650,6651,6652,6653,6654,6655,6656,6657,6658,6659,
6660,6661,6662,6663,1708,6664,6665,6666,6667,6668,6669,6670,6671,6672,6673,6674,
1201,6675,6676,6677,6678,6679,6680,6681,6682,6683,6684,6685,6686,6687,6688,6689,
6690,6691,6692,6693,6694,6695,6696,6697,6698,6699,6700,6701,6702,6703,6704,6705,
6706,6707,6708,6709,6710,6711,6712,6713,6714,6715,6716,6717,6718,6719,6720,6721,
6722,6723,6724,6725,1389,6726,6727,6728,6729,6730,6731,6732,6733,6734,6735,6736,
1390,1709,6737,6738,6739,6740,6741,6742,1710,6743,6744,6745,6746,1391,6747,6748,
6749,6750,6751,6752,6753,6754,6755,6756,6757,1392,6758,6759,6760,6761,6762,6763,
6764,6765,6766,6767,6768,6769,6770,6771,6772,6773,6774,6775,6776,6777,6778,6779,
6780,1202,6781,6782,6783,6784,6785,6786,6787,6788,6789,6790,6791,6792,6793,6794,
6795,6796,6797,6798,6799,6800,6801,6802,6803,6804,6805,6806,6807,6808,6809,1711,
6810,6811,6812,6813,6814,6815,6816,6817,6818,6819,6820,6821,6822,6823,6824,6825,
6826,6827,6828,6829,6830,6831,6832,6833,6834,6835,6836,1393,6837,6838,6839,6840,
6841,6842,6843,6844,6845,6846,6847,6848,6849,6850,6851,6852,6853,6854,6855,6856,
6857,6858,6859,6860,6861,6862,6863,6864,6865,6866,6867,6868,6869,6870,6871,6872,
6873,6874,6875,6876,6877,6878,6879,6880,6881,6882,6883,6884,6885,6886,6887,6888,
6889,6890,6891,6892,6893,6894,6895,6896,6897,6898,6899,6900,6901,6902,1712,6903,
6904,6905,6906,6907,6908,6909,6910,1713,6911,6912,6913,6914,6915,6916,6917,6918,
6919,6920,6921,6922,6923,6924,6925,6926,6927,6928,6929,6930,6931,6932,6933,6934,
6935,6936,6937,6938,6939,6940,6941,6942,6943,6944,6945,6946,6947,6948,6949,6950,
6951,6952,6953,6954,6955,6956,6957,6958,6959,6960,6961,6962,6963,6964,6965,6966,
6967,6968,6969,6970,6971,6972,6973,6974,1714,6975,6976,6977,6978,6979,6980,6981,
6982,6983,6984,6985,6986,6987,6988,1394,6989,6990,6991,6992,6993,6994,6995,6996,
6997,6998,6999,7000,1715,7001,7002,7003,7004,7005,7006,7007,7008,7009,7010,7011,
7012,7013,7014,7015,7016,7017,7018,7019,7020,7021,7022,7023,7024,7025,7026,7027,
7028,1716,7029,7030,7031,7032,7033,7034,7035,7036,7037,7038,7039,7040,7041,7042,
7043,7044,7045,7046,7047,7048,7049,7050,7051,7052,7053,7054,7055,7056,7057,7058,
7059,7060,7061,7062,7063,7064,7065,7066,7067,7068,7069,7070,7071,7072,7073,7074,
7075,7076,7077,7078,7079,7080,7081,7082,7083,7084,7085,7086,7087,7088,7089,7090,
7091,7092,7093,7094,7095,7096,7097,7098,7099,7100,7101,7102,7103,7104,7105,7106,
7107,7108,7109,7110,7111,7112,7113,7114,7115,7116,7117,7118,7119,7120,7121,7122,
7123,7124,7125,7126,7127,7128,7129,7130,7131,7132,7133,7134,7135,7136,7137,7138,
7139,7140,7141,7142,7143,7144,7145,7146,7147,7148,7149,7150,7151,7152,7153,7154,
7155,7156,7157,7158,7159,7160,7161,7162,7163,7164,7165,7166,7167,7168,7169,7170,
7171,7172,7173,7174,7175,7176,7177,7178,7179,7180,7181,7182,7183,7184,7185,7186,
7187,7188,7189,7190,7191,7192,7193,7194,7195,7196,7197,7198,7199,7200,7201,7202,
7203,7204,7205,7206,7207,1395,7208,7209,7210,7211,7212,7213,1717,7214,7215,7216,
7217,7218,7219,7220,7221,7222,7223,7224,7225,7226,7227,7228,7229,7230,7231,7232,
7233,7234,7235,7236,7237,7238,7239,7240,7241,7242,7243,7244,7245,7246,7247,7248,
7249,7250,7251,7252,7253,7254,7255,7256,7257,7258,7259,7260,7261,7262,7263,7264,
7265,7266,7267,7268,7269,7270,7271,7272,7273,7274,7275,7276,7277,7278,7279,7280,
7281,7282,7283,7284,7285,7286,7287,7288,7289,7290,7291,7292,7293,7294,7295,7296,
7297,7298,7299,7300,7301,7302,7303,7304,7305,7306,7307,7308,7309,7310,7311,7312,
7313,1718,7314,7315,7316,7317,7318,7319,7320,7321,7322,7323,7324,7325,7326,7327,
7328,7329,7330,7331,7332,7333,7334,7335,7336,7337,7338,7339,7340,7341,7342,7343,
7344,7345,7346,7347,7348,7349,7350,7351,7352,7353,7354,7355,7356,7357,7358,7359,
7360,7361,7362,7363,7364,7365,7366,7367,7368,7369,7370,7371,7372,7373,7374,7375,
7376,7377,7378,7379,7380,7381,7382,7383,7384,7385,7386,7387,7388,7389,7390,7391,
7392,7393,7394,7395,7396,7397,7398,7399,7400,7401,7402,7403,7404,7405,7406,7407,
7408,7409,7410,7411,7412,7413,7414,7415,7416,7417,7418,7419,7420,7421,7422,7423,
7424,7425,7426,7427,7428,7429,7430,7431,7432,7433,7434,7435,7436,7437,7438,7439,
7440,7441,7442,7443,7444,7445,7446,7447,7448,7449,7450,7451,7452,7453,7454,7455,
7456,7457,7458,7459,7460,7461,7462,7463,7464,7465,7466,7467,7468,7469,7470,7471,
7472,7473,7474,7475,7476,7477,7478,7479,7480,7481,7482,7483,7484,7485,7486,7487,
7488,7489,7490,7491,7492,7493,7494,7495,7496,7497,7498,7499,7500,7501,7502,7503,
7504,7505,7506,7507,7508,7509,7510,7511,7512,7513,7514,7515,7516,7517,7518,7519,
7520,7521,7522,7523,7524,7525,7526,7527,7528,7529,7530,7531,7532,7533,7534,7535,
7536,7537,7538,7539,7540,7541,7542,7543,7544,7545,7546,7547,7548,7549,7550,7551,
7552,7553,7554,7555,7556,7557,7558,7559,7560,7561,7562,7563,7564,7565,7566,7567,
7568,7569,7570,7571,7572,7573,7574,7575,7576,7577,7578,7579,7580,7581,7582,7583,
7584,7585,7586,7587,7588,7589,7590,7591,7592,7593,7594,7595,7596,7597,7598,7599,
7600,7601,7602,7603,7604,7605,7606,7607,7608,7609,7610,7611,7612,7613,7614,7615,
7616,7617,7618,7619,7620,7621,7622,7623,7624,7625,7626,7627,7628,7629,7630,7631,
7632,7633,7634,7635,7636,7637,7638,7639,7640,7641,7642,7643,7644,7645,7646,7647,
7648,7649,7650,7651,7652,7653,7654,7655,7656,7657,7658,7659,7660,7661,7662,7663,
7664,7665,7666,7667,7668,7669,7670,7671,7672,7673,7674,7675,7676,7677,7678,7679,
7680,7681,7682,7683,7684,7685,7686,7687,7688,7689,7690,7691,7692,7693,7694,7695,
7696,7697,7698,7699,7700,7701,7702,7703,7704,7705,7706,7707,7708,7709,7710,7711,
7712,7713,7714,7715,7716,7717,7718,7719,7720,7721,7722,7723,7724,7725,7726,7727,
7728,7729,7730,7731,7732,7733,7734,7735,7736,7737,7738,7739,7740,7741,7742,7743,
7744,7745,7746,7747,7748,7749,7750,7751,7752,7753,7754,7755,7756,7757,7758,7759,
7760,7761,7762,7763,7764,7765,7766,7767,7768,7769,7770,7771,7772,7773,7774,7775,
7776,7777,7778,7779,7780,7781,7782,7783,7784,7785,7786,7787,7788,7789,7790,7791,
7792,7793,7794,7795,7796,7797,7798,7799,7800,7801,7802,7803,7804,7805,7806,7807,
7808,7809,7810,7811,7812,7813,7814,7815,7816,7817,7818,7819,7820,7821,7822,7823,
7824,7825,7826,7827,7828,7829,7830,7831,7832,7833,7834,7835,7836,7837,7838,7839,
7840,7841,7842,7843,7844,7845,7846,7847,7848,7849,7850,7851,7852,7853,7854,7855,
7856,7857,7858,7859,7860,7861,7862,7863,7864,7865,7866,7867,7868,7869,7870,7871,
7872,7873,7874,7875,7876,7877,7878,7879,7880,7881,7882,7883,7884,7885,7886,7887,
7888,7889,7890,7891,7892,7893,7894,7895,7896,7897,7898,7899,7900,7901,7902,7903,
7904,7905,7906,7907,7908,7909,7910,7911,7912,7913,7914,7915,7916,7917,7918,7919,
7920,7921,7922,7923,7924,7925,7926,7927,7928,7929,7930,7931,7932,7933,7934,7935,
7936,7937,7938,7939,7940,7941,7942,7943,7944,7945,7946,7947,7948,7949,7950,7951,
7952,7953,7954,7955,7956,7957,7958,7959,7960,7961,7962,7963,7964,7965,7966,7967,
7968,7969,7970,7971,7972,7973,7974,7975,7976,7977,7978,7979,7980,7981,7982,7983,
7984,7985,7986,7987,7988,7989,7990,7991,7992,7993,7994,7995,7996,7997,7998,7999,
8000,8001,8002,8003,8004,8005,8006,8007,8008,8009,8010,8011,8012,8013,8014,8015,
8016,8017,8018,8019,8020,8021,8022,8023,8024,8025,8026,8027,8028,8029,8030,8031,
8032,8033,8034,8035,8036,8037,8038,8039,8040,8041,8042,8043,8044,8045,8046,8047,
8048,8049,8050,8051,8052,8053,8054,8055,8056,8057,8058,8059,8060,8061,8062,8063,
8064,8065,8066,8067,8068,8069,8070,8071,8072,8073,8074,8075,8076,8077,8078,8079,
8080,8081,8082,8083,8084,8085,8086,8087,8088,8089,8090,8091,8092,8093,8094,8095,
8096,8097,8098,8099,8100,8101,8102,8103,8104,8105,8106,8107,8108,8109,8110,8111,
8112,8113,8114,8115,8116,8117,8118,8119,8120,8121,8122,8123,8124,8125,8126,8127,
8128,8129,8130,8131,8132,8133,8134,8135,8136,8137,8138,8139,8140,8141,8142,8143,
8144,8145,8146,8147,8148,8149,8150,8151,8152,8153,8154,8155,8156,8157,8158,8159,
8160,8161,8162,8163,8164,8165,8166,8167,8168,8169,8170,8171,8172,8173,8174,8175,
8176,8177,8178,8179,8180,8181,8182,8183,8184,8185,8186,8187,8188,8189,8190,8191,
8192,8193,8194,8195,8196,8197,8198,8199,8200,8201,8202,8203,8204,8205,8206,8207,
8208,8209,8210,8211,8212,8213,8214,8215,8216,8217,8218,8219,8220,8221,8222,8223,
8224,8225,8226,8227,8228,8229,8230,8231,8232,8233,8234,8235,8236,8237,8238,8239,
8240,8241,8242,8243,8244,8245,8246,8247,8248,8249,8250,8251,8252,8253,8254,8255,
8256,8257,8258,8259,8260,8261,8262,8263,8264,8265,8266,8267,8268,8269,8270,8271,
8272,8273,8274,8275,8276,8277,8278,8279,8280,8281,8282,8283,8284,8285,8286,8287,
8288,8289,8290,8291,8292,8293,8294,8295,8296,8297,8298,8299,8300,8301,8302,8303,
8304,8305,8306,8307,8308,8309,8310,8311,8312,8313,8314,8315,8316,8317,8318,8319,
8320,8321,8322,8323,8324,8325,8326,8327,8328,8329,8330,8331,8332,8333,8334,8335,
8336,8337,8338,8339,8340,8341,8342,8343,8344,8345,8346,8347,8348,8349,8350,8351,
8352,8353,8354,8355,8356,8357,8358,8359,8360,8361,8362,8363,8364,8365,8366,8367,
8368,8369,8370,8371,8372,8373,8374,8375,8376,8377,8378,8379,8380,8381,8382,8383,
8384,8385,8386,8387,8388,8389,8390,8391,8392,8393,8394,8395,8396,8397,8398,8399,
8400,8401,8402,8403,8404,8405,8406,8407,8408,8409,8410,8411,8412,8413,8414,8415,
8416,8417,8418,8419,8420,8421,8422,8423,8424,8425,8426,8427,8428,8429,8430,8431,
8432,8433,8434,8435,8436,8437,8438,8439,8440,8441,8442,8443,8444,8445,8446,8447,
8448,8449,8450,8451,8452,8453,8454,8455,8456,8457,8458,8459,8460,8461,8462,8463,
8464,8465,8466,8467,8468,8469,8470,8471,8472,8473,8474,8475,8476,8477,8478,8479,
8480,8481,8482,8483,8484,8485,8486,8487,8488,8489,8490,8491,8492,8493,8494,8495,
8496,8497,8498,8499,8500,8501,8502,8503,8504,8505,8506,8507,8508,8509,8510,8511,
8512,8513,8514,8515,8516,8517,8518,8519,8520,8521,8522,8523,8524,8525,8526,8527,
8528,8529,8530,8531,8532,8533,8534,8535,8536,8537,8538,8539,8540,8541,8542,8543,
8544,8545,8546,8547,8548,8549,8550,8551,8552,8553,8554,8555,8556,8557,8558,8559,
8560,8561,8562,8563,8564,8565,8566,8567,8568,8569,8570,8571,8572,8573,8574,8575,
8576,8577,8578,8579,8580,8581,8582,8583,8584,8585,8586,8587,8588,8589,8590,8591,
8592,8593,8594,8595,8596,8597,8598,8599,8600,8601,8602,8603,8604,8605,8606,8607,
8608,8609,8610,8611,8612,8613,8614,8615,8616,8617,8618,8619,8620,8621,8622,8623,
8624,8625,8626,8627,8628,8629,8630,8631,8632,8633,8634,8635,8636,8637,8638,8639,
8640,8641,8642,8643,8644,8645,8646,8647,8648,8649,8650,8651,8652,8653,8654,8655,
8656,8657,8658,8659,8660,8661,8662,8663,8664,8665,8666,8667,8668,8669,8670,8671,
8672,8673,8674,8675,8676,8677,8678,8679,8680,8681,8682,8683,8684,8685,8686,8687,
8688,8689,8690,8691,8692,8693,8694,8695,8696,8697,8698,8699,8700,8701,8702,8703,
8704,8705,8706,8707,8708,8709,8710,8711,8712,8713,8714,8715,8716,8717,8718,8719,
8720,8721,8722,8723,8724,8725,8726,8727,8728,8729,8730,8731,8732,8733,8734,8735,
8736,8737,8738,8739,8740,8741)

########NEW FILE########
__FILENAME__ = euckrprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from mbcharsetprober import MultiByteCharSetProber
from codingstatemachine import CodingStateMachine
from chardistribution import EUCKRDistributionAnalysis
from mbcssm import EUCKRSMModel

class EUCKRProber(MultiByteCharSetProber):
    def __init__(self):
        MultiByteCharSetProber.__init__(self)
        self._mCodingSM = CodingStateMachine(EUCKRSMModel)
        self._mDistributionAnalyzer = EUCKRDistributionAnalysis()
        self.reset()

    def get_charset_name(self):
        return "EUC-KR"

########NEW FILE########
__FILENAME__ = euctwfreq
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# EUCTW frequency table
# Converted from big5 work 
# by Taiwan's Mandarin Promotion Council 
# <http:#www.edu.tw:81/mandr/>

# 128  --> 0.42261
# 256  --> 0.57851
# 512  --> 0.74851
# 1024 --> 0.89384
# 2048 --> 0.97583
#
# Idea Distribution Ratio = 0.74851/(1-0.74851) =2.98
# Random Distribution Ration = 512/(5401-512)=0.105
# 
# Typical Distribution Ratio about 25% of Ideal one, still much higher than RDR

EUCTW_TYPICAL_DISTRIBUTION_RATIO = 0.75

# Char to FreqOrder table , 
EUCTW_TABLE_SIZE = 8102

EUCTWCharToFreqOrder = ( \
   1,1800,1506, 255,1431, 198,   9,  82,   6,7310, 177, 202,3615,1256,2808, 110, # 2742
3735,  33,3241, 261,  76,  44,2113,  16,2931,2184,1176, 659,3868,  26,3404,2643, # 2758
1198,3869,3313,4060, 410,2211, 302, 590, 361,1963,   8, 204,  58,4296,7311,1931, # 2774
  63,7312,7313, 317,1614,  75, 222, 159,4061,2412,1480,7314,3500,3068, 224,2809, # 2790
3616,   3,  10,3870,1471,  29,2774,1135,2852,1939, 873, 130,3242,1123, 312,7315, # 2806
4297,2051, 507, 252, 682,7316, 142,1914, 124, 206,2932,  34,3501,3173,  64, 604, # 2822
7317,2494,1976,1977, 155,1990, 645, 641,1606,7318,3405, 337,  72, 406,7319,  80, # 2838
 630, 238,3174,1509, 263, 939,1092,2644, 756,1440,1094,3406, 449,  69,2969, 591, # 2854
 179,2095, 471, 115,2034,1843,  60,  50,2970, 134, 806,1868, 734,2035,3407, 180, # 2870
 995,1607, 156, 537,2893, 688,7320, 319,1305, 779,2144, 514,2374, 298,4298, 359, # 2886
2495,  90,2707,1338, 663,  11, 906,1099,2545,  20,2436, 182, 532,1716,7321, 732, # 2902
1376,4062,1311,1420,3175,  25,2312,1056, 113, 399, 382,1949, 242,3408,2467, 529, # 2918
3243, 475,1447,3617,7322, 117,  21, 656, 810,1297,2295,2329,3502,7323, 126,4063, # 2934
 706, 456, 150, 613,4299,  71,1118,2036,4064, 145,3069,  85, 835, 486,2114,1246, # 2950
1426, 428, 727,1285,1015, 800, 106, 623, 303,1281,7324,2127,2354, 347,3736, 221, # 2966
3503,3110,7325,1955,1153,4065,  83, 296,1199,3070, 192, 624,  93,7326, 822,1897, # 2982
2810,3111, 795,2064, 991,1554,1542,1592,  27,  43,2853, 859, 139,1456, 860,4300, # 2998
 437, 712,3871, 164,2392,3112, 695, 211,3017,2096, 195,3872,1608,3504,3505,3618, # 3014
3873, 234, 811,2971,2097,3874,2229,1441,3506,1615,2375, 668,2076,1638, 305, 228, # 3030
1664,4301, 467, 415,7327, 262,2098,1593, 239, 108, 300, 200,1033, 512,1247,2077, # 3046
7328,7329,2173,3176,3619,2673, 593, 845,1062,3244,  88,1723,2037,3875,1950, 212, # 3062
 266, 152, 149, 468,1898,4066,4302,  77, 187,7330,3018,  37,   5,2972,7331,3876, # 3078
7332,7333,  39,2517,4303,2894,3177,2078,  55, 148,  74,4304, 545, 483,1474,1029, # 3094
1665, 217,1869,1531,3113,1104,2645,4067,  24, 172,3507, 900,3877,3508,3509,4305, # 3110
  32,1408,2811,1312, 329, 487,2355,2247,2708, 784,2674,   4,3019,3314,1427,1788, # 3126
 188, 109, 499,7334,3620,1717,1789, 888,1217,3020,4306,7335,3510,7336,3315,1520, # 3142
3621,3878, 196,1034, 775,7337,7338, 929,1815, 249, 439,  38,7339,1063,7340, 794, # 3158
3879,1435,2296,  46, 178,3245,2065,7341,2376,7342, 214,1709,4307, 804,  35, 707, # 3174
 324,3622,1601,2546, 140, 459,4068,7343,7344,1365, 839, 272, 978,2257,2572,3409, # 3190
2128,1363,3623,1423, 697, 100,3071,  48,  70,1231, 495,3114,2193,7345,1294,7346, # 3206
2079, 462, 586,1042,3246, 853, 256, 988, 185,2377,3410,1698, 434,1084,7347,3411, # 3222
 314,2615,2775,4308,2330,2331, 569,2280, 637,1816,2518, 757,1162,1878,1616,3412, # 3238
 287,1577,2115, 768,4309,1671,2854,3511,2519,1321,3737, 909,2413,7348,4069, 933, # 3254
3738,7349,2052,2356,1222,4310, 765,2414,1322, 786,4311,7350,1919,1462,1677,2895, # 3270
1699,7351,4312,1424,2437,3115,3624,2590,3316,1774,1940,3413,3880,4070, 309,1369, # 3286
1130,2812, 364,2230,1653,1299,3881,3512,3882,3883,2646, 525,1085,3021, 902,2000, # 3302
1475, 964,4313, 421,1844,1415,1057,2281, 940,1364,3116, 376,4314,4315,1381,   7, # 3318
2520, 983,2378, 336,1710,2675,1845, 321,3414, 559,1131,3022,2742,1808,1132,1313, # 3334
 265,1481,1857,7352, 352,1203,2813,3247, 167,1089, 420,2814, 776, 792,1724,3513, # 3350
4071,2438,3248,7353,4072,7354, 446, 229, 333,2743, 901,3739,1200,1557,4316,2647, # 3366
1920, 395,2744,2676,3740,4073,1835, 125, 916,3178,2616,4317,7355,7356,3741,7357, # 3382
7358,7359,4318,3117,3625,1133,2547,1757,3415,1510,2313,1409,3514,7360,2145, 438, # 3398
2591,2896,2379,3317,1068, 958,3023, 461, 311,2855,2677,4074,1915,3179,4075,1978, # 3414
 383, 750,2745,2617,4076, 274, 539, 385,1278,1442,7361,1154,1964, 384, 561, 210, # 3430
  98,1295,2548,3515,7362,1711,2415,1482,3416,3884,2897,1257, 129,7363,3742, 642, # 3446
 523,2776,2777,2648,7364, 141,2231,1333,  68, 176, 441, 876, 907,4077, 603,2592, # 3462
 710, 171,3417, 404, 549,  18,3118,2393,1410,3626,1666,7365,3516,4319,2898,4320, # 3478
7366,2973, 368,7367, 146, 366,  99, 871,3627,1543, 748, 807,1586,1185,  22,2258, # 3494
 379,3743,3180,7368,3181, 505,1941,2618,1991,1382,2314,7369, 380,2357, 218, 702, # 3510
1817,1248,3418,3024,3517,3318,3249,7370,2974,3628, 930,3250,3744,7371,  59,7372, # 3526
 585, 601,4078, 497,3419,1112,1314,4321,1801,7373,1223,1472,2174,7374, 749,1836, # 3542
 690,1899,3745,1772,3885,1476, 429,1043,1790,2232,2116, 917,4079, 447,1086,1629, # 3558
7375, 556,7376,7377,2020,1654, 844,1090, 105, 550, 966,1758,2815,1008,1782, 686, # 3574
1095,7378,2282, 793,1602,7379,3518,2593,4322,4080,2933,2297,4323,3746, 980,2496, # 3590
 544, 353, 527,4324, 908,2678,2899,7380, 381,2619,1942,1348,7381,1341,1252, 560, # 3606
3072,7382,3420,2856,7383,2053, 973, 886,2080, 143,4325,7384,7385, 157,3886, 496, # 3622
4081,  57, 840, 540,2038,4326,4327,3421,2117,1445, 970,2259,1748,1965,2081,4082, # 3638
3119,1234,1775,3251,2816,3629, 773,1206,2129,1066,2039,1326,3887,1738,1725,4083, # 3654
 279,3120,  51,1544,2594, 423,1578,2130,2066, 173,4328,1879,7386,7387,1583, 264, # 3670
 610,3630,4329,2439, 280, 154,7388,7389,7390,1739, 338,1282,3073, 693,2857,1411, # 3686
1074,3747,2440,7391,4330,7392,7393,1240, 952,2394,7394,2900,1538,2679, 685,1483, # 3702
4084,2468,1436, 953,4085,2054,4331, 671,2395,  79,4086,2441,3252, 608, 567,2680, # 3718
3422,4087,4088,1691, 393,1261,1791,2396,7395,4332,7396,7397,7398,7399,1383,1672, # 3734
3748,3182,1464, 522,1119, 661,1150, 216, 675,4333,3888,1432,3519, 609,4334,2681, # 3750
2397,7400,7401,7402,4089,3025,   0,7403,2469, 315, 231,2442, 301,3319,4335,2380, # 3766
7404, 233,4090,3631,1818,4336,4337,7405,  96,1776,1315,2082,7406, 257,7407,1809, # 3782
3632,2709,1139,1819,4091,2021,1124,2163,2778,1777,2649,7408,3074, 363,1655,3183, # 3798
7409,2975,7410,7411,7412,3889,1567,3890, 718, 103,3184, 849,1443, 341,3320,2934, # 3814
1484,7413,1712, 127,  67, 339,4092,2398, 679,1412, 821,7414,7415, 834, 738, 351, # 3830
2976,2146, 846, 235,1497,1880, 418,1992,3749,2710, 186,1100,2147,2746,3520,1545, # 3846
1355,2935,2858,1377, 583,3891,4093,2573,2977,7416,1298,3633,1078,2549,3634,2358, # 3862
  78,3750,3751, 267,1289,2099,2001,1594,4094, 348, 369,1274,2194,2175,1837,4338, # 3878
1820,2817,3635,2747,2283,2002,4339,2936,2748, 144,3321, 882,4340,3892,2749,3423, # 3894
4341,2901,7417,4095,1726, 320,7418,3893,3026, 788,2978,7419,2818,1773,1327,2859, # 3910
3894,2819,7420,1306,4342,2003,1700,3752,3521,2359,2650, 787,2022, 506, 824,3636, # 3926
 534, 323,4343,1044,3322,2023,1900, 946,3424,7421,1778,1500,1678,7422,1881,4344, # 3942
 165, 243,4345,3637,2521, 123, 683,4096, 764,4346,  36,3895,1792, 589,2902, 816, # 3958
 626,1667,3027,2233,1639,1555,1622,3753,3896,7423,3897,2860,1370,1228,1932, 891, # 3974
2083,2903, 304,4097,7424, 292,2979,2711,3522, 691,2100,4098,1115,4347, 118, 662, # 3990
7425, 611,1156, 854,2381,1316,2861,   2, 386, 515,2904,7426,7427,3253, 868,2234, # 4006
1486, 855,2651, 785,2212,3028,7428,1040,3185,3523,7429,3121, 448,7430,1525,7431, # 4022
2164,4348,7432,3754,7433,4099,2820,3524,3122, 503, 818,3898,3123,1568, 814, 676, # 4038
1444, 306,1749,7434,3755,1416,1030, 197,1428, 805,2821,1501,4349,7435,7436,7437, # 4054
1993,7438,4350,7439,7440,2195,  13,2779,3638,2980,3124,1229,1916,7441,3756,2131, # 4070
7442,4100,4351,2399,3525,7443,2213,1511,1727,1120,7444,7445, 646,3757,2443, 307, # 4086
7446,7447,1595,3186,7448,7449,7450,3639,1113,1356,3899,1465,2522,2523,7451, 519, # 4102
7452, 128,2132,  92,2284,1979,7453,3900,1512, 342,3125,2196,7454,2780,2214,1980, # 4118
3323,7455, 290,1656,1317, 789, 827,2360,7456,3758,4352, 562, 581,3901,7457, 401, # 4134
4353,2248,  94,4354,1399,2781,7458,1463,2024,4355,3187,1943,7459, 828,1105,4101, # 4150
1262,1394,7460,4102, 605,4356,7461,1783,2862,7462,2822, 819,2101, 578,2197,2937, # 4166
7463,1502, 436,3254,4103,3255,2823,3902,2905,3425,3426,7464,2712,2315,7465,7466, # 4182
2332,2067,  23,4357, 193, 826,3759,2102, 699,1630,4104,3075, 390,1793,1064,3526, # 4198
7467,1579,3076,3077,1400,7468,4105,1838,1640,2863,7469,4358,4359, 137,4106, 598, # 4214
3078,1966, 780, 104, 974,2938,7470, 278, 899, 253, 402, 572, 504, 493,1339,7471, # 4230
3903,1275,4360,2574,2550,7472,3640,3029,3079,2249, 565,1334,2713, 863,  41,7473, # 4246
7474,4361,7475,1657,2333,  19, 463,2750,4107, 606,7476,2981,3256,1087,2084,1323, # 4262
2652,2982,7477,1631,1623,1750,4108,2682,7478,2864, 791,2714,2653,2334, 232,2416, # 4278
7479,2983,1498,7480,2654,2620, 755,1366,3641,3257,3126,2025,1609, 119,1917,3427, # 4294
 862,1026,4109,7481,3904,3760,4362,3905,4363,2260,1951,2470,7482,1125, 817,4110, # 4310
4111,3906,1513,1766,2040,1487,4112,3030,3258,2824,3761,3127,7483,7484,1507,7485, # 4326
2683, 733,  40,1632,1106,2865, 345,4113, 841,2524, 230,4364,2984,1846,3259,3428, # 4342
7486,1263, 986,3429,7487, 735, 879, 254,1137, 857, 622,1300,1180,1388,1562,3907, # 4358
3908,2939, 967,2751,2655,1349, 592,2133,1692,3324,2985,1994,4114,1679,3909,1901, # 4374
2185,7488, 739,3642,2715,1296,1290,7489,4115,2198,2199,1921,1563,2595,2551,1870, # 4390
2752,2986,7490, 435,7491, 343,1108, 596,  17,1751,4365,2235,3430,3643,7492,4366, # 4406
 294,3527,2940,1693, 477, 979, 281,2041,3528, 643,2042,3644,2621,2782,2261,1031, # 4422
2335,2134,2298,3529,4367, 367,1249,2552,7493,3530,7494,4368,1283,3325,2004, 240, # 4438
1762,3326,4369,4370, 836,1069,3128, 474,7495,2148,2525, 268,3531,7496,3188,1521, # 4454
1284,7497,1658,1546,4116,7498,3532,3533,7499,4117,3327,2684,1685,4118, 961,1673, # 4470
2622, 190,2005,2200,3762,4371,4372,7500, 570,2497,3645,1490,7501,4373,2623,3260, # 4486
1956,4374, 584,1514, 396,1045,1944,7502,4375,1967,2444,7503,7504,4376,3910, 619, # 4502
7505,3129,3261, 215,2006,2783,2553,3189,4377,3190,4378, 763,4119,3763,4379,7506, # 4518
7507,1957,1767,2941,3328,3646,1174, 452,1477,4380,3329,3130,7508,2825,1253,2382, # 4534
2186,1091,2285,4120, 492,7509, 638,1169,1824,2135,1752,3911, 648, 926,1021,1324, # 4550
4381, 520,4382, 997, 847,1007, 892,4383,3764,2262,1871,3647,7510,2400,1784,4384, # 4566
1952,2942,3080,3191,1728,4121,2043,3648,4385,2007,1701,3131,1551,  30,2263,4122, # 4582
7511,2026,4386,3534,7512, 501,7513,4123, 594,3431,2165,1821,3535,3432,3536,3192, # 4598
 829,2826,4124,7514,1680,3132,1225,4125,7515,3262,4387,4126,3133,2336,7516,4388, # 4614
4127,7517,3912,3913,7518,1847,2383,2596,3330,7519,4389, 374,3914, 652,4128,4129, # 4630
 375,1140, 798,7520,7521,7522,2361,4390,2264, 546,1659, 138,3031,2445,4391,7523, # 4646
2250, 612,1848, 910, 796,3765,1740,1371, 825,3766,3767,7524,2906,2554,7525, 692, # 4662
 444,3032,2624, 801,4392,4130,7526,1491, 244,1053,3033,4131,4132, 340,7527,3915, # 4678
1041,2987, 293,1168,  87,1357,7528,1539, 959,7529,2236, 721, 694,4133,3768, 219, # 4694
1478, 644,1417,3331,2656,1413,1401,1335,1389,3916,7530,7531,2988,2362,3134,1825, # 4710
 730,1515, 184,2827,  66,4393,7532,1660,2943, 246,3332, 378,1457, 226,3433, 975, # 4726
3917,2944,1264,3537, 674, 696,7533, 163,7534,1141,2417,2166, 713,3538,3333,4394, # 4742
3918,7535,7536,1186,  15,7537,1079,1070,7538,1522,3193,3539, 276,1050,2716, 758, # 4758
1126, 653,2945,3263,7539,2337, 889,3540,3919,3081,2989, 903,1250,4395,3920,3434, # 4774
3541,1342,1681,1718, 766,3264, 286,  89,2946,3649,7540,1713,7541,2597,3334,2990, # 4790
7542,2947,2215,3194,2866,7543,4396,2498,2526, 181, 387,1075,3921, 731,2187,3335, # 4806
7544,3265, 310, 313,3435,2299, 770,4134,  54,3034, 189,4397,3082,3769,3922,7545, # 4822
1230,1617,1849, 355,3542,4135,4398,3336, 111,4136,3650,1350,3135,3436,3035,4137, # 4838
2149,3266,3543,7546,2784,3923,3924,2991, 722,2008,7547,1071, 247,1207,2338,2471, # 4854
1378,4399,2009, 864,1437,1214,4400, 373,3770,1142,2216, 667,4401, 442,2753,2555, # 4870
3771,3925,1968,4138,3267,1839, 837, 170,1107, 934,1336,1882,7548,7549,2118,4139, # 4886
2828, 743,1569,7550,4402,4140, 582,2384,1418,3437,7551,1802,7552, 357,1395,1729, # 4902
3651,3268,2418,1564,2237,7553,3083,3772,1633,4403,1114,2085,4141,1532,7554, 482, # 4918
2446,4404,7555,7556,1492, 833,1466,7557,2717,3544,1641,2829,7558,1526,1272,3652, # 4934
4142,1686,1794, 416,2556,1902,1953,1803,7559,3773,2785,3774,1159,2316,7560,2867, # 4950
4405,1610,1584,3036,2419,2754, 443,3269,1163,3136,7561,7562,3926,7563,4143,2499, # 4966
3037,4406,3927,3137,2103,1647,3545,2010,1872,4144,7564,4145, 431,3438,7565, 250, # 4982
  97,  81,4146,7566,1648,1850,1558, 160, 848,7567, 866, 740,1694,7568,2201,2830, # 4998
3195,4147,4407,3653,1687, 950,2472, 426, 469,3196,3654,3655,3928,7569,7570,1188, # 5014
 424,1995, 861,3546,4148,3775,2202,2685, 168,1235,3547,4149,7571,2086,1674,4408, # 5030
3337,3270, 220,2557,1009,7572,3776, 670,2992, 332,1208, 717,7573,7574,3548,2447, # 5046
3929,3338,7575, 513,7576,1209,2868,3339,3138,4409,1080,7577,7578,7579,7580,2527, # 5062
3656,3549, 815,1587,3930,3931,7581,3550,3439,3777,1254,4410,1328,3038,1390,3932, # 5078
1741,3933,3778,3934,7582, 236,3779,2448,3271,7583,7584,3657,3780,1273,3781,4411, # 5094
7585, 308,7586,4412, 245,4413,1851,2473,1307,2575, 430, 715,2136,2449,7587, 270, # 5110
 199,2869,3935,7588,3551,2718,1753, 761,1754, 725,1661,1840,4414,3440,3658,7589, # 5126
7590, 587,  14,3272, 227,2598, 326, 480,2265, 943,2755,3552, 291, 650,1883,7591, # 5142
1702,1226, 102,1547,  62,3441, 904,4415,3442,1164,4150,7592,7593,1224,1548,2756, # 5158
 391, 498,1493,7594,1386,1419,7595,2055,1177,4416, 813, 880,1081,2363, 566,1145, # 5174
4417,2286,1001,1035,2558,2599,2238, 394,1286,7596,7597,2068,7598,  86,1494,1730, # 5190
3936, 491,1588, 745, 897,2948, 843,3340,3937,2757,2870,3273,1768, 998,2217,2069, # 5206
 397,1826,1195,1969,3659,2993,3341, 284,7599,3782,2500,2137,2119,1903,7600,3938, # 5222
2150,3939,4151,1036,3443,1904, 114,2559,4152, 209,1527,7601,7602,2949,2831,2625, # 5238
2385,2719,3139, 812,2560,7603,3274,7604,1559, 737,1884,3660,1210, 885,  28,2686, # 5254
3553,3783,7605,4153,1004,1779,4418,7606, 346,1981,2218,2687,4419,3784,1742, 797, # 5270
1642,3940,1933,1072,1384,2151, 896,3941,3275,3661,3197,2871,3554,7607,2561,1958, # 5286
4420,2450,1785,7608,7609,7610,3942,4154,1005,1308,3662,4155,2720,4421,4422,1528, # 5302
2600, 161,1178,4156,1982, 987,4423,1101,4157, 631,3943,1157,3198,2420,1343,1241, # 5318
1016,2239,2562, 372, 877,2339,2501,1160, 555,1934, 911,3944,7611, 466,1170, 169, # 5334
1051,2907,2688,3663,2474,2994,1182,2011,2563,1251,2626,7612, 992,2340,3444,1540, # 5350
2721,1201,2070,2401,1996,2475,7613,4424, 528,1922,2188,1503,1873,1570,2364,3342, # 5366
3276,7614, 557,1073,7615,1827,3445,2087,2266,3140,3039,3084, 767,3085,2786,4425, # 5382
1006,4158,4426,2341,1267,2176,3664,3199, 778,3945,3200,2722,1597,2657,7616,4427, # 5398
7617,3446,7618,7619,7620,3277,2689,1433,3278, 131,  95,1504,3946, 723,4159,3141, # 5414
1841,3555,2758,2189,3947,2027,2104,3665,7621,2995,3948,1218,7622,3343,3201,3949, # 5430
4160,2576, 248,1634,3785, 912,7623,2832,3666,3040,3786, 654,  53,7624,2996,7625, # 5446
1688,4428, 777,3447,1032,3950,1425,7626, 191, 820,2120,2833, 971,4429, 931,3202, # 5462
 135, 664, 783,3787,1997, 772,2908,1935,3951,3788,4430,2909,3203, 282,2723, 640, # 5478
1372,3448,1127, 922, 325,3344,7627,7628, 711,2044,7629,7630,3952,2219,2787,1936, # 5494
3953,3345,2220,2251,3789,2300,7631,4431,3790,1258,3279,3954,3204,2138,2950,3955, # 5510
3956,7632,2221, 258,3205,4432, 101,1227,7633,3280,1755,7634,1391,3281,7635,2910, # 5526
2056, 893,7636,7637,7638,1402,4161,2342,7639,7640,3206,3556,7641,7642, 878,1325, # 5542
1780,2788,4433, 259,1385,2577, 744,1183,2267,4434,7643,3957,2502,7644, 684,1024, # 5558
4162,7645, 472,3557,3449,1165,3282,3958,3959, 322,2152, 881, 455,1695,1152,1340, # 5574
 660, 554,2153,4435,1058,4436,4163, 830,1065,3346,3960,4437,1923,7646,1703,1918, # 5590
7647, 932,2268, 122,7648,4438, 947, 677,7649,3791,2627, 297,1905,1924,2269,4439, # 5606
2317,3283,7650,7651,4164,7652,4165,  84,4166, 112, 989,7653, 547,1059,3961, 701, # 5622
3558,1019,7654,4167,7655,3450, 942, 639, 457,2301,2451, 993,2951, 407, 851, 494, # 5638
4440,3347, 927,7656,1237,7657,2421,3348, 573,4168, 680, 921,2911,1279,1874, 285, # 5654
 790,1448,1983, 719,2167,7658,7659,4441,3962,3963,1649,7660,1541, 563,7661,1077, # 5670
7662,3349,3041,3451, 511,2997,3964,3965,3667,3966,1268,2564,3350,3207,4442,4443, # 5686
7663, 535,1048,1276,1189,2912,2028,3142,1438,1373,2834,2952,1134,2012,7664,4169, # 5702
1238,2578,3086,1259,7665, 700,7666,2953,3143,3668,4170,7667,4171,1146,1875,1906, # 5718
4444,2601,3967, 781,2422, 132,1589, 203, 147, 273,2789,2402, 898,1786,2154,3968, # 5734
3969,7668,3792,2790,7669,7670,4445,4446,7671,3208,7672,1635,3793, 965,7673,1804, # 5750
2690,1516,3559,1121,1082,1329,3284,3970,1449,3794,  65,1128,2835,2913,2759,1590, # 5766
3795,7674,7675,  12,2658,  45, 976,2579,3144,4447, 517,2528,1013,1037,3209,7676, # 5782
3796,2836,7677,3797,7678,3452,7679,2602, 614,1998,2318,3798,3087,2724,2628,7680, # 5798
2580,4172, 599,1269,7681,1810,3669,7682,2691,3088, 759,1060, 489,1805,3351,3285, # 5814
1358,7683,7684,2386,1387,1215,2629,2252, 490,7685,7686,4173,1759,2387,2343,7687, # 5830
4448,3799,1907,3971,2630,1806,3210,4449,3453,3286,2760,2344, 874,7688,7689,3454, # 5846
3670,1858,  91,2914,3671,3042,3800,4450,7690,3145,3972,2659,7691,3455,1202,1403, # 5862
3801,2954,2529,1517,2503,4451,3456,2504,7692,4452,7693,2692,1885,1495,1731,3973, # 5878
2365,4453,7694,2029,7695,7696,3974,2693,1216, 237,2581,4174,2319,3975,3802,4454, # 5894
4455,2694,3560,3457, 445,4456,7697,7698,7699,7700,2761,  61,3976,3672,1822,3977, # 5910
7701, 687,2045, 935, 925, 405,2660, 703,1096,1859,2725,4457,3978,1876,1367,2695, # 5926
3352, 918,2105,1781,2476, 334,3287,1611,1093,4458, 564,3146,3458,3673,3353, 945, # 5942
2631,2057,4459,7702,1925, 872,4175,7703,3459,2696,3089, 349,4176,3674,3979,4460, # 5958
3803,4177,3675,2155,3980,4461,4462,4178,4463,2403,2046, 782,3981, 400, 251,4179, # 5974
1624,7704,7705, 277,3676, 299,1265, 476,1191,3804,2121,4180,4181,1109, 205,7706, # 5990
2582,1000,2156,3561,1860,7707,7708,7709,4464,7710,4465,2565, 107,2477,2157,3982, # 6006
3460,3147,7711,1533, 541,1301, 158, 753,4182,2872,3562,7712,1696, 370,1088,4183, # 6022
4466,3563, 579, 327, 440, 162,2240, 269,1937,1374,3461, 968,3043,  56,1396,3090, # 6038
2106,3288,3354,7713,1926,2158,4467,2998,7714,3564,7715,7716,3677,4468,2478,7717, # 6054
2791,7718,1650,4469,7719,2603,7720,7721,3983,2661,3355,1149,3356,3984,3805,3985, # 6070
7722,1076,  49,7723, 951,3211,3289,3290, 450,2837, 920,7724,1811,2792,2366,4184, # 6086
1908,1138,2367,3806,3462,7725,3212,4470,1909,1147,1518,2423,4471,3807,7726,4472, # 6102
2388,2604, 260,1795,3213,7727,7728,3808,3291, 708,7729,3565,1704,7730,3566,1351, # 6118
1618,3357,2999,1886, 944,4185,3358,4186,3044,3359,4187,7731,3678, 422, 413,1714, # 6134
3292, 500,2058,2345,4188,2479,7732,1344,1910, 954,7733,1668,7734,7735,3986,2404, # 6150
4189,3567,3809,4190,7736,2302,1318,2505,3091, 133,3092,2873,4473, 629,  31,2838, # 6166
2697,3810,4474, 850, 949,4475,3987,2955,1732,2088,4191,1496,1852,7737,3988, 620, # 6182
3214, 981,1242,3679,3360,1619,3680,1643,3293,2139,2452,1970,1719,3463,2168,7738, # 6198
3215,7739,7740,3361,1828,7741,1277,4476,1565,2047,7742,1636,3568,3093,7743, 869, # 6214
2839, 655,3811,3812,3094,3989,3000,3813,1310,3569,4477,7744,7745,7746,1733, 558, # 6230
4478,3681, 335,1549,3045,1756,4192,3682,1945,3464,1829,1291,1192, 470,2726,2107, # 6246
2793, 913,1054,3990,7747,1027,7748,3046,3991,4479, 982,2662,3362,3148,3465,3216, # 6262
3217,1946,2794,7749, 571,4480,7750,1830,7751,3570,2583,1523,2424,7752,2089, 984, # 6278
4481,3683,1959,7753,3684, 852, 923,2795,3466,3685, 969,1519, 999,2048,2320,1705, # 6294
7754,3095, 615,1662, 151, 597,3992,2405,2321,1049, 275,4482,3686,4193, 568,3687, # 6310
3571,2480,4194,3688,7755,2425,2270, 409,3218,7756,1566,2874,3467,1002, 769,2840, # 6326
 194,2090,3149,3689,2222,3294,4195, 628,1505,7757,7758,1763,2177,3001,3993, 521, # 6342
1161,2584,1787,2203,2406,4483,3994,1625,4196,4197, 412,  42,3096, 464,7759,2632, # 6358
4484,3363,1760,1571,2875,3468,2530,1219,2204,3814,2633,2140,2368,4485,4486,3295, # 6374
1651,3364,3572,7760,7761,3573,2481,3469,7762,3690,7763,7764,2271,2091, 460,7765, # 6390
4487,7766,3002, 962, 588,3574, 289,3219,2634,1116,  52,7767,3047,1796,7768,7769, # 6406
7770,1467,7771,1598,1143,3691,4198,1984,1734,1067,4488,1280,3365, 465,4489,1572, # 6422
 510,7772,1927,2241,1812,1644,3575,7773,4490,3692,7774,7775,2663,1573,1534,7776, # 6438
7777,4199, 536,1807,1761,3470,3815,3150,2635,7778,7779,7780,4491,3471,2915,1911, # 6454
2796,7781,3296,1122, 377,3220,7782, 360,7783,7784,4200,1529, 551,7785,2059,3693, # 6470
1769,2426,7786,2916,4201,3297,3097,2322,2108,2030,4492,1404, 136,1468,1479, 672, # 6486
1171,3221,2303, 271,3151,7787,2762,7788,2049, 678,2727, 865,1947,4493,7789,2013, # 6502
3995,2956,7790,2728,2223,1397,3048,3694,4494,4495,1735,2917,3366,3576,7791,3816, # 6518
 509,2841,2453,2876,3817,7792,7793,3152,3153,4496,4202,2531,4497,2304,1166,1010, # 6534
 552, 681,1887,7794,7795,2957,2958,3996,1287,1596,1861,3154, 358, 453, 736, 175, # 6550
 478,1117, 905,1167,1097,7796,1853,1530,7797,1706,7798,2178,3472,2287,3695,3473, # 6566
3577,4203,2092,4204,7799,3367,1193,2482,4205,1458,2190,2205,1862,1888,1421,3298, # 6582
2918,3049,2179,3474, 595,2122,7800,3997,7801,7802,4206,1707,2636, 223,3696,1359, # 6598
 751,3098, 183,3475,7803,2797,3003, 419,2369, 633, 704,3818,2389, 241,7804,7805, # 6614
7806, 838,3004,3697,2272,2763,2454,3819,1938,2050,3998,1309,3099,2242,1181,7807, # 6630
1136,2206,3820,2370,1446,4207,2305,4498,7808,7809,4208,1055,2605, 484,3698,7810, # 6646
3999, 625,4209,2273,3368,1499,4210,4000,7811,4001,4211,3222,2274,2275,3476,7812, # 6662
7813,2764, 808,2606,3699,3369,4002,4212,3100,2532, 526,3370,3821,4213, 955,7814, # 6678
1620,4214,2637,2427,7815,1429,3700,1669,1831, 994, 928,7816,3578,1260,7817,7818, # 6694
7819,1948,2288, 741,2919,1626,4215,2729,2455, 867,1184, 362,3371,1392,7820,7821, # 6710
4003,4216,1770,1736,3223,2920,4499,4500,1928,2698,1459,1158,7822,3050,3372,2877, # 6726
1292,1929,2506,2842,3701,1985,1187,2071,2014,2607,4217,7823,2566,2507,2169,3702, # 6742
2483,3299,7824,3703,4501,7825,7826, 666,1003,3005,1022,3579,4218,7827,4502,1813, # 6758
2253, 574,3822,1603, 295,1535, 705,3823,4219, 283, 858, 417,7828,7829,3224,4503, # 6774
4504,3051,1220,1889,1046,2276,2456,4004,1393,1599, 689,2567, 388,4220,7830,2484, # 6790
 802,7831,2798,3824,2060,1405,2254,7832,4505,3825,2109,1052,1345,3225,1585,7833, # 6806
 809,7834,7835,7836, 575,2730,3477, 956,1552,1469,1144,2323,7837,2324,1560,2457, # 6822
3580,3226,4005, 616,2207,3155,2180,2289,7838,1832,7839,3478,4506,7840,1319,3704, # 6838
3705,1211,3581,1023,3227,1293,2799,7841,7842,7843,3826, 607,2306,3827, 762,2878, # 6854
1439,4221,1360,7844,1485,3052,7845,4507,1038,4222,1450,2061,2638,4223,1379,4508, # 6870
2585,7846,7847,4224,1352,1414,2325,2921,1172,7848,7849,3828,3829,7850,1797,1451, # 6886
7851,7852,7853,7854,2922,4006,4007,2485,2346, 411,4008,4009,3582,3300,3101,4509, # 6902
1561,2664,1452,4010,1375,7855,7856,  47,2959, 316,7857,1406,1591,2923,3156,7858, # 6918
1025,2141,3102,3157, 354,2731, 884,2224,4225,2407, 508,3706, 726,3583, 996,2428, # 6934
3584, 729,7859, 392,2191,1453,4011,4510,3707,7860,7861,2458,3585,2608,1675,2800, # 6950
 919,2347,2960,2348,1270,4511,4012,  73,7862,7863, 647,7864,3228,2843,2255,1550, # 6966
1346,3006,7865,1332, 883,3479,7866,7867,7868,7869,3301,2765,7870,1212, 831,1347, # 6982
4226,4512,2326,3830,1863,3053, 720,3831,4513,4514,3832,7871,4227,7872,7873,4515, # 6998
7874,7875,1798,4516,3708,2609,4517,3586,1645,2371,7876,7877,2924, 669,2208,2665, # 7014
2429,7878,2879,7879,7880,1028,3229,7881,4228,2408,7882,2256,1353,7883,7884,4518, # 7030
3158, 518,7885,4013,7886,4229,1960,7887,2142,4230,7888,7889,3007,2349,2350,3833, # 7046
 516,1833,1454,4014,2699,4231,4519,2225,2610,1971,1129,3587,7890,2766,7891,2961, # 7062
1422, 577,1470,3008,1524,3373,7892,7893, 432,4232,3054,3480,7894,2586,1455,2508, # 7078
2226,1972,1175,7895,1020,2732,4015,3481,4520,7896,2733,7897,1743,1361,3055,3482, # 7094
2639,4016,4233,4521,2290, 895, 924,4234,2170, 331,2243,3056, 166,1627,3057,1098, # 7110
7898,1232,2880,2227,3374,4522, 657, 403,1196,2372, 542,3709,3375,1600,4235,3483, # 7126
7899,4523,2767,3230, 576, 530,1362,7900,4524,2533,2666,3710,4017,7901, 842,3834, # 7142
7902,2801,2031,1014,4018, 213,2700,3376, 665, 621,4236,7903,3711,2925,2430,7904, # 7158
2431,3302,3588,3377,7905,4237,2534,4238,4525,3589,1682,4239,3484,1380,7906, 724, # 7174
2277, 600,1670,7907,1337,1233,4526,3103,2244,7908,1621,4527,7909, 651,4240,7910, # 7190
1612,4241,2611,7911,2844,7912,2734,2307,3058,7913, 716,2459,3059, 174,1255,2701, # 7206
4019,3590, 548,1320,1398, 728,4020,1574,7914,1890,1197,3060,4021,7915,3061,3062, # 7222
3712,3591,3713, 747,7916, 635,4242,4528,7917,7918,7919,4243,7920,7921,4529,7922, # 7238
3378,4530,2432, 451,7923,3714,2535,2072,4244,2735,4245,4022,7924,1764,4531,7925, # 7254
4246, 350,7926,2278,2390,2486,7927,4247,4023,2245,1434,4024, 488,4532, 458,4248, # 7270
4025,3715, 771,1330,2391,3835,2568,3159,2159,2409,1553,2667,3160,4249,7928,2487, # 7286
2881,2612,1720,2702,4250,3379,4533,7929,2536,4251,7930,3231,4252,2768,7931,2015, # 7302
2736,7932,1155,1017,3716,3836,7933,3303,2308, 201,1864,4253,1430,7934,4026,7935, # 7318
7936,7937,7938,7939,4254,1604,7940, 414,1865, 371,2587,4534,4535,3485,2016,3104, # 7334
4536,1708, 960,4255, 887, 389,2171,1536,1663,1721,7941,2228,4027,2351,2926,1580, # 7350
7942,7943,7944,1744,7945,2537,4537,4538,7946,4539,7947,2073,7948,7949,3592,3380, # 7366
2882,4256,7950,4257,2640,3381,2802, 673,2703,2460, 709,3486,4028,3593,4258,7951, # 7382
1148, 502, 634,7952,7953,1204,4540,3594,1575,4541,2613,3717,7954,3718,3105, 948, # 7398
3232, 121,1745,3837,1110,7955,4259,3063,2509,3009,4029,3719,1151,1771,3838,1488, # 7414
4030,1986,7956,2433,3487,7957,7958,2093,7959,4260,3839,1213,1407,2803, 531,2737, # 7430
2538,3233,1011,1537,7960,2769,4261,3106,1061,7961,3720,3721,1866,2883,7962,2017, # 7446
 120,4262,4263,2062,3595,3234,2309,3840,2668,3382,1954,4542,7963,7964,3488,1047, # 7462
2704,1266,7965,1368,4543,2845, 649,3383,3841,2539,2738,1102,2846,2669,7966,7967, # 7478
1999,7968,1111,3596,2962,7969,2488,3842,3597,2804,1854,3384,3722,7970,7971,3385, # 7494
2410,2884,3304,3235,3598,7972,2569,7973,3599,2805,4031,1460, 856,7974,3600,7975, # 7510
2885,2963,7976,2886,3843,7977,4264, 632,2510, 875,3844,1697,3845,2291,7978,7979, # 7526
4544,3010,1239, 580,4545,4265,7980, 914, 936,2074,1190,4032,1039,2123,7981,7982, # 7542
7983,3386,1473,7984,1354,4266,3846,7985,2172,3064,4033, 915,3305,4267,4268,3306, # 7558
1605,1834,7986,2739, 398,3601,4269,3847,4034, 328,1912,2847,4035,3848,1331,4270, # 7574
3011, 937,4271,7987,3602,4036,4037,3387,2160,4546,3388, 524, 742, 538,3065,1012, # 7590
7988,7989,3849,2461,7990, 658,1103, 225,3850,7991,7992,4547,7993,4548,7994,3236, # 7606
1243,7995,4038, 963,2246,4549,7996,2705,3603,3161,7997,7998,2588,2327,7999,4550, # 7622
8000,8001,8002,3489,3307, 957,3389,2540,2032,1930,2927,2462, 870,2018,3604,1746, # 7638
2770,2771,2434,2463,8003,3851,8004,3723,3107,3724,3490,3390,3725,8005,1179,3066, # 7654
8006,3162,2373,4272,3726,2541,3163,3108,2740,4039,8007,3391,1556,2542,2292, 977, # 7670
2887,2033,4040,1205,3392,8008,1765,3393,3164,2124,1271,1689, 714,4551,3491,8009, # 7686
2328,3852, 533,4273,3605,2181, 617,8010,2464,3308,3492,2310,8011,8012,3165,8013, # 7702
8014,3853,1987, 618, 427,2641,3493,3394,8015,8016,1244,1690,8017,2806,4274,4552, # 7718
8018,3494,8019,8020,2279,1576, 473,3606,4275,3395, 972,8021,3607,8022,3067,8023, # 7734
8024,4553,4554,8025,3727,4041,4042,8026, 153,4555, 356,8027,1891,2888,4276,2143, # 7750
 408, 803,2352,8028,3854,8029,4277,1646,2570,2511,4556,4557,3855,8030,3856,4278, # 7766
8031,2411,3396, 752,8032,8033,1961,2964,8034, 746,3012,2465,8035,4279,3728, 698, # 7782
4558,1892,4280,3608,2543,4559,3609,3857,8036,3166,3397,8037,1823,1302,4043,2706, # 7798
3858,1973,4281,8038,4282,3167, 823,1303,1288,1236,2848,3495,4044,3398, 774,3859, # 7814
8039,1581,4560,1304,2849,3860,4561,8040,2435,2161,1083,3237,4283,4045,4284, 344, # 7830
1173, 288,2311, 454,1683,8041,8042,1461,4562,4046,2589,8043,8044,4563, 985, 894, # 7846
8045,3399,3168,8046,1913,2928,3729,1988,8047,2110,1974,8048,4047,8049,2571,1194, # 7862
 425,8050,4564,3169,1245,3730,4285,8051,8052,2850,8053, 636,4565,1855,3861, 760, # 7878
1799,8054,4286,2209,1508,4566,4048,1893,1684,2293,8055,8056,8057,4287,4288,2210, # 7894
 479,8058,8059, 832,8060,4049,2489,8061,2965,2490,3731, 990,3109, 627,1814,2642, # 7910
4289,1582,4290,2125,2111,3496,4567,8062, 799,4291,3170,8063,4568,2112,1737,3013, # 7926
1018, 543, 754,4292,3309,1676,4569,4570,4050,8064,1489,8065,3497,8066,2614,2889, # 7942
4051,8067,8068,2966,8069,8070,8071,8072,3171,4571,4572,2182,1722,8073,3238,3239, # 7958
1842,3610,1715, 481, 365,1975,1856,8074,8075,1962,2491,4573,8076,2126,3611,3240, # 7974
 433,1894,2063,2075,8077, 602,2741,8078,8079,8080,8081,8082,3014,1628,3400,8083, # 7990
3172,4574,4052,2890,4575,2512,8084,2544,2772,8085,8086,8087,3310,4576,2891,8088, # 8006
4577,8089,2851,4578,4579,1221,2967,4053,2513,8090,8091,8092,1867,1989,8093,8094, # 8022
8095,1895,8096,8097,4580,1896,4054, 318,8098,2094,4055,4293,8099,8100, 485,8101, # 8038
 938,3862, 553,2670, 116,8102,3863,3612,8103,3498,2671,2773,3401,3311,2807,8104, # 8054
3613,2929,4056,1747,2930,2968,8105,8106, 207,8107,8108,2672,4581,2514,8109,3015, # 8070
 890,3614,3864,8110,1877,3732,3402,8111,2183,2353,3403,1652,8112,8113,8114, 941, # 8086
2294, 208,3499,4057,2019, 330,4294,3865,2892,2492,3733,4295,8115,8116,8117,8118, # 8102
#Everything below is of no interest for detection purpose
2515,1613,4582,8119,3312,3866,2516,8120,4058,8121,1637,4059,2466,4583,3867,8122, # 8118
2493,3016,3734,8123,8124,2192,8125,8126,2162,8127,8128,8129,8130,8131,8132,8133, # 8134
8134,8135,8136,8137,8138,8139,8140,8141,8142,8143,8144,8145,8146,8147,8148,8149, # 8150
8150,8151,8152,8153,8154,8155,8156,8157,8158,8159,8160,8161,8162,8163,8164,8165, # 8166
8166,8167,8168,8169,8170,8171,8172,8173,8174,8175,8176,8177,8178,8179,8180,8181, # 8182
8182,8183,8184,8185,8186,8187,8188,8189,8190,8191,8192,8193,8194,8195,8196,8197, # 8198
8198,8199,8200,8201,8202,8203,8204,8205,8206,8207,8208,8209,8210,8211,8212,8213, # 8214
8214,8215,8216,8217,8218,8219,8220,8221,8222,8223,8224,8225,8226,8227,8228,8229, # 8230
8230,8231,8232,8233,8234,8235,8236,8237,8238,8239,8240,8241,8242,8243,8244,8245, # 8246
8246,8247,8248,8249,8250,8251,8252,8253,8254,8255,8256,8257,8258,8259,8260,8261, # 8262
8262,8263,8264,8265,8266,8267,8268,8269,8270,8271,8272,8273,8274,8275,8276,8277, # 8278
8278,8279,8280,8281,8282,8283,8284,8285,8286,8287,8288,8289,8290,8291,8292,8293, # 8294
8294,8295,8296,8297,8298,8299,8300,8301,8302,8303,8304,8305,8306,8307,8308,8309, # 8310
8310,8311,8312,8313,8314,8315,8316,8317,8318,8319,8320,8321,8322,8323,8324,8325, # 8326
8326,8327,8328,8329,8330,8331,8332,8333,8334,8335,8336,8337,8338,8339,8340,8341, # 8342
8342,8343,8344,8345,8346,8347,8348,8349,8350,8351,8352,8353,8354,8355,8356,8357, # 8358
8358,8359,8360,8361,8362,8363,8364,8365,8366,8367,8368,8369,8370,8371,8372,8373, # 8374
8374,8375,8376,8377,8378,8379,8380,8381,8382,8383,8384,8385,8386,8387,8388,8389, # 8390
8390,8391,8392,8393,8394,8395,8396,8397,8398,8399,8400,8401,8402,8403,8404,8405, # 8406
8406,8407,8408,8409,8410,8411,8412,8413,8414,8415,8416,8417,8418,8419,8420,8421, # 8422
8422,8423,8424,8425,8426,8427,8428,8429,8430,8431,8432,8433,8434,8435,8436,8437, # 8438
8438,8439,8440,8441,8442,8443,8444,8445,8446,8447,8448,8449,8450,8451,8452,8453, # 8454
8454,8455,8456,8457,8458,8459,8460,8461,8462,8463,8464,8465,8466,8467,8468,8469, # 8470
8470,8471,8472,8473,8474,8475,8476,8477,8478,8479,8480,8481,8482,8483,8484,8485, # 8486
8486,8487,8488,8489,8490,8491,8492,8493,8494,8495,8496,8497,8498,8499,8500,8501, # 8502
8502,8503,8504,8505,8506,8507,8508,8509,8510,8511,8512,8513,8514,8515,8516,8517, # 8518
8518,8519,8520,8521,8522,8523,8524,8525,8526,8527,8528,8529,8530,8531,8532,8533, # 8534
8534,8535,8536,8537,8538,8539,8540,8541,8542,8543,8544,8545,8546,8547,8548,8549, # 8550
8550,8551,8552,8553,8554,8555,8556,8557,8558,8559,8560,8561,8562,8563,8564,8565, # 8566
8566,8567,8568,8569,8570,8571,8572,8573,8574,8575,8576,8577,8578,8579,8580,8581, # 8582
8582,8583,8584,8585,8586,8587,8588,8589,8590,8591,8592,8593,8594,8595,8596,8597, # 8598
8598,8599,8600,8601,8602,8603,8604,8605,8606,8607,8608,8609,8610,8611,8612,8613, # 8614
8614,8615,8616,8617,8618,8619,8620,8621,8622,8623,8624,8625,8626,8627,8628,8629, # 8630
8630,8631,8632,8633,8634,8635,8636,8637,8638,8639,8640,8641,8642,8643,8644,8645, # 8646
8646,8647,8648,8649,8650,8651,8652,8653,8654,8655,8656,8657,8658,8659,8660,8661, # 8662
8662,8663,8664,8665,8666,8667,8668,8669,8670,8671,8672,8673,8674,8675,8676,8677, # 8678
8678,8679,8680,8681,8682,8683,8684,8685,8686,8687,8688,8689,8690,8691,8692,8693, # 8694
8694,8695,8696,8697,8698,8699,8700,8701,8702,8703,8704,8705,8706,8707,8708,8709, # 8710
8710,8711,8712,8713,8714,8715,8716,8717,8718,8719,8720,8721,8722,8723,8724,8725, # 8726
8726,8727,8728,8729,8730,8731,8732,8733,8734,8735,8736,8737,8738,8739,8740,8741) # 8742

########NEW FILE########
__FILENAME__ = euctwprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from mbcharsetprober import MultiByteCharSetProber
from codingstatemachine import CodingStateMachine
from chardistribution import EUCTWDistributionAnalysis
from mbcssm import EUCTWSMModel

class EUCTWProber(MultiByteCharSetProber):
    def __init__(self):
        MultiByteCharSetProber.__init__(self)
        self._mCodingSM = CodingStateMachine(EUCTWSMModel)
        self._mDistributionAnalyzer = EUCTWDistributionAnalysis()
        self.reset()

    def get_charset_name(self):
        return "EUC-TW"

########NEW FILE########
__FILENAME__ = gb2312freq
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# GB2312 most frequently used character table
#
# Char to FreqOrder table , from hz6763

# 512  --> 0.79  -- 0.79
# 1024 --> 0.92  -- 0.13
# 2048 --> 0.98  -- 0.06
# 6768 --> 1.00  -- 0.02
#
# Ideal Distribution Ratio = 0.79135/(1-0.79135) = 3.79
# Random Distribution Ration = 512 / (3755 - 512) = 0.157
# 
# Typical Distribution Ratio about 25% of Ideal one, still much higher that RDR

GB2312_TYPICAL_DISTRIBUTION_RATIO = 0.9

GB2312_TABLE_SIZE = 3760

GB2312CharToFreqOrder = ( \
1671, 749,1443,2364,3924,3807,2330,3921,1704,3463,2691,1511,1515, 572,3191,2205,
2361, 224,2558, 479,1711, 963,3162, 440,4060,1905,2966,2947,3580,2647,3961,3842,
2204, 869,4207, 970,2678,5626,2944,2956,1479,4048, 514,3595, 588,1346,2820,3409,
 249,4088,1746,1873,2047,1774, 581,1813, 358,1174,3590,1014,1561,4844,2245, 670,
1636,3112, 889,1286, 953, 556,2327,3060,1290,3141, 613, 185,3477,1367, 850,3820,
1715,2428,2642,2303,2732,3041,2562,2648,3566,3946,1349, 388,3098,2091,1360,3585,
 152,1687,1539, 738,1559,  59,1232,2925,2267,1388,1249,1741,1679,2960, 151,1566,
1125,1352,4271, 924,4296, 385,3166,4459, 310,1245,2850,  70,3285,2729,3534,3575,
2398,3298,3466,1960,2265, 217,3647, 864,1909,2084,4401,2773,1010,3269,5152, 853,
3051,3121,1244,4251,1895, 364,1499,1540,2313,1180,3655,2268, 562, 715,2417,3061,
 544, 336,3768,2380,1752,4075, 950, 280,2425,4382, 183,2759,3272, 333,4297,2155,
1688,2356,1444,1039,4540, 736,1177,3349,2443,2368,2144,2225, 565, 196,1482,3406,
 927,1335,4147, 692, 878,1311,1653,3911,3622,1378,4200,1840,2969,3149,2126,1816,
2534,1546,2393,2760, 737,2494,  13, 447, 245,2747,  38,2765,2129,2589,1079, 606,
 360, 471,3755,2890, 404, 848, 699,1785,1236, 370,2221,1023,3746,2074,2026,2023,
2388,1581,2119, 812,1141,3091,2536,1519, 804,2053, 406,1596,1090, 784, 548,4414,
1806,2264,2936,1100, 343,4114,5096, 622,3358, 743,3668,1510,1626,5020,3567,2513,
3195,4115,5627,2489,2991,  24,2065,2697,1087,2719,  48,1634, 315,  68, 985,2052,
 198,2239,1347,1107,1439, 597,2366,2172, 871,3307, 919,2487,2790,1867, 236,2570,
1413,3794, 906,3365,3381,1701,1982,1818,1524,2924,1205, 616,2586,2072,2004, 575,
 253,3099,  32,1365,1182, 197,1714,2454,1201, 554,3388,3224,2748, 756,2587, 250,
2567,1507,1517,3529,1922,2761,2337,3416,1961,1677,2452,2238,3153, 615, 911,1506,
1474,2495,1265,1906,2749,3756,3280,2161, 898,2714,1759,3450,2243,2444, 563,  26,
3286,2266,3769,3344,2707,3677, 611,1402, 531,1028,2871,4548,1375, 261,2948, 835,
1190,4134, 353, 840,2684,1900,3082,1435,2109,1207,1674, 329,1872,2781,4055,2686,
2104, 608,3318,2423,2957,2768,1108,3739,3512,3271,3985,2203,1771,3520,1418,2054,
1681,1153, 225,1627,2929, 162,2050,2511,3687,1954, 124,1859,2431,1684,3032,2894,
 585,4805,3969,2869,2704,2088,2032,2095,3656,2635,4362,2209, 256, 518,2042,2105,
3777,3657, 643,2298,1148,1779, 190, 989,3544, 414,  11,2135,2063,2979,1471, 403,
3678, 126, 770,1563, 671,2499,3216,2877, 600,1179, 307,2805,4937,1268,1297,2694,
 252,4032,1448,1494,1331,1394, 127,2256, 222,1647,1035,1481,3056,1915,1048, 873,
3651, 210,  33,1608,2516, 200,1520, 415, 102,   0,3389,1287, 817,  91,3299,2940,
 836,1814, 549,2197,1396,1669,2987,3582,2297,2848,4528,1070, 687,  20,1819, 121,
1552,1364,1461,1968,2617,3540,2824,2083, 177, 948,4938,2291, 110,4549,2066, 648,
3359,1755,2110,2114,4642,4845,1693,3937,3308,1257,1869,2123, 208,1804,3159,2992,
2531,2549,3361,2418,1350,2347,2800,2568,1291,2036,2680,  72, 842,1990, 212,1233,
1154,1586,  75,2027,3410,4900,1823,1337,2710,2676, 728,2810,1522,3026,4995, 157,
 755,1050,4022, 710, 785,1936,2194,2085,1406,2777,2400, 150,1250,4049,1206, 807,
1910, 534, 529,3309,1721,1660, 274,  39,2827, 661,2670,1578, 925,3248,3815,1094,
4278,4901,4252,  41,1150,3747,2572,2227,4501,3658,4902,3813,3357,3617,2884,2258,
 887, 538,4187,3199,1294,2439,3042,2329,2343,2497,1255, 107, 543,1527, 521,3478,
3568, 194,5062,  15, 961,3870,1241,1192,2664,  66,5215,3260,2111,1295,1127,2152,
3805,4135, 901,1164,1976, 398,1278, 530,1460, 748, 904,1054,1966,1426,  53,2909,
 509, 523,2279,1534, 536,1019, 239,1685, 460,2353, 673,1065,2401,3600,4298,2272,
1272,2363, 284,1753,3679,4064,1695,  81, 815,2677,2757,2731,1386, 859, 500,4221,
2190,2566, 757,1006,2519,2068,1166,1455, 337,2654,3203,1863,1682,1914,3025,1252,
1409,1366, 847, 714,2834,2038,3209, 964,2970,1901, 885,2553,1078,1756,3049, 301,
1572,3326, 688,2130,1996,2429,1805,1648,2930,3421,2750,3652,3088, 262,1158,1254,
 389,1641,1812, 526,1719, 923,2073,1073,1902, 468, 489,4625,1140, 857,2375,3070,
3319,2863, 380, 116,1328,2693,1161,2244, 273,1212,1884,2769,3011,1775,1142, 461,
3066,1200,2147,2212, 790, 702,2695,4222,1601,1058, 434,2338,5153,3640,  67,2360,
4099,2502, 618,3472,1329, 416,1132, 830,2782,1807,2653,3211,3510,1662, 192,2124,
 296,3979,1739,1611,3684,  23, 118, 324, 446,1239,1225, 293,2520,3814,3795,2535,
3116,  17,1074, 467,2692,2201, 387,2922,  45,1326,3055,1645,3659,2817, 958, 243,
1903,2320,1339,2825,1784,3289, 356, 576, 865,2315,2381,3377,3916,1088,3122,1713,
1655, 935, 628,4689,1034,1327, 441, 800, 720, 894,1979,2183,1528,5289,2702,1071,
4046,3572,2399,1571,3281,  79, 761,1103, 327, 134, 758,1899,1371,1615, 879, 442,
 215,2605,2579, 173,2048,2485,1057,2975,3317,1097,2253,3801,4263,1403,1650,2946,
 814,4968,3487,1548,2644,1567,1285,   2, 295,2636,  97, 946,3576, 832, 141,4257,
3273, 760,3821,3521,3156,2607, 949,1024,1733,1516,1803,1920,2125,2283,2665,3180,
1501,2064,3560,2171,1592, 803,3518,1416, 732,3897,4258,1363,1362,2458, 119,1427,
 602,1525,2608,1605,1639,3175, 694,3064,  10, 465,  76,2000,4846,4208, 444,3781,
1619,3353,2206,1273,3796, 740,2483, 320,1723,2377,3660,2619,1359,1137,1762,1724,
2345,2842,1850,1862, 912, 821,1866, 612,2625,1735,2573,3369,1093, 844,  89, 937,
 930,1424,3564,2413,2972,1004,3046,3019,2011, 711,3171,1452,4178, 428, 801,1943,
 432, 445,2811, 206,4136,1472, 730, 349,  73, 397,2802,2547, 998,1637,1167, 789,
 396,3217, 154,1218, 716,1120,1780,2819,4826,1931,3334,3762,2139,1215,2627, 552,
3664,3628,3232,1405,2383,3111,1356,2652,3577,3320,3101,1703, 640,1045,1370,1246,
4996, 371,1575,2436,1621,2210, 984,4033,1734,2638,  16,4529, 663,2755,3255,1451,
3917,2257,1253,1955,2234,1263,2951, 214,1229, 617, 485, 359,1831,1969, 473,2310,
 750,2058, 165,  80,2864,2419, 361,4344,2416,2479,1134, 796,3726,1266,2943, 860,
2715, 938, 390,2734,1313,1384, 248, 202, 877,1064,2854, 522,3907, 279,1602, 297,
2357, 395,3740, 137,2075, 944,4089,2584,1267,3802,  62,1533,2285, 178, 176, 780,
2440, 201,3707, 590, 478,1560,4354,2117,1075,  30,  74,4643,4004,1635,1441,2745,
 776,2596, 238,1077,1692,1912,2844, 605, 499,1742,3947, 241,3053, 980,1749, 936,
2640,4511,2582, 515,1543,2162,5322,2892,2993, 890,2148,1924, 665,1827,3581,1032,
 968,3163, 339,1044,1896, 270, 583,1791,1720,4367,1194,3488,3669,  43,2523,1657,
 163,2167, 290,1209,1622,3378, 550, 634,2508,2510, 695,2634,2384,2512,1476,1414,
 220,1469,2341,2138,2852,3183,2900,4939,2865,3502,1211,3680, 854,3227,1299,2976,
3172, 186,2998,1459, 443,1067,3251,1495, 321,1932,3054, 909, 753,1410,1828, 436,
2441,1119,1587,3164,2186,1258, 227, 231,1425,1890,3200,3942, 247, 959, 725,5254,
2741, 577,2158,2079, 929, 120, 174, 838,2813, 591,1115, 417,2024,  40,3240,1536,
1037, 291,4151,2354, 632,1298,2406,2500,3535,1825,1846,3451, 205,1171, 345,4238,
  18,1163, 811, 685,2208,1217, 425,1312,1508,1175,4308,2552,1033, 587,1381,3059,
2984,3482, 340,1316,4023,3972, 792,3176, 519, 777,4690, 918, 933,4130,2981,3741,
  90,3360,2911,2200,5184,4550, 609,3079,2030, 272,3379,2736, 363,3881,1130,1447,
 286, 779, 357,1169,3350,3137,1630,1220,2687,2391, 747,1277,3688,2618,2682,2601,
1156,3196,5290,4034,3102,1689,3596,3128, 874, 219,2783, 798, 508,1843,2461, 269,
1658,1776,1392,1913,2983,3287,2866,2159,2372, 829,4076,  46,4253,2873,1889,1894,
 915,1834,1631,2181,2318, 298, 664,2818,3555,2735, 954,3228,3117, 527,3511,2173,
 681,2712,3033,2247,2346,3467,1652, 155,2164,3382, 113,1994, 450, 899, 494, 994,
1237,2958,1875,2336,1926,3727, 545,1577,1550, 633,3473, 204,1305,3072,2410,1956,
2471, 707,2134, 841,2195,2196,2663,3843,1026,4940, 990,3252,4997, 368,1092, 437,
3212,3258,1933,1829, 675,2977,2893, 412, 943,3723,4644,3294,3283,2230,2373,5154,
2389,2241,2661,2323,1404,2524, 593, 787, 677,3008,1275,2059, 438,2709,2609,2240,
2269,2246,1446,  36,1568,1373,3892,1574,2301,1456,3962, 693,2276,5216,2035,1143,
2720,1919,1797,1811,2763,4137,2597,1830,1699,1488,1198,2090, 424,1694, 312,3634,
3390,4179,3335,2252,1214, 561,1059,3243,2295,2561, 975,5155,2321,2751,3772, 472,
1537,3282,3398,1047,2077,2348,2878,1323,3340,3076, 690,2906,  51, 369, 170,3541,
1060,2187,2688,3670,2541,1083,1683, 928,3918, 459, 109,4427, 599,3744,4286, 143,
2101,2730,2490,  82,1588,3036,2121, 281,1860, 477,4035,1238,2812,3020,2716,3312,
1530,2188,2055,1317, 843, 636,1808,1173,3495, 649, 181,1002, 147,3641,1159,2414,
3750,2289,2795, 813,3123,2610,1136,4368,   5,3391,4541,2174, 420, 429,1728, 754,
1228,2115,2219, 347,2223,2733, 735,1518,3003,2355,3134,1764,3948,3329,1888,2424,
1001,1234,1972,3321,3363,1672,1021,1450,1584, 226, 765, 655,2526,3404,3244,2302,
3665, 731, 594,2184, 319,1576, 621, 658,2656,4299,2099,3864,1279,2071,2598,2739,
 795,3086,3699,3908,1707,2352,2402,1382,3136,2475,1465,4847,3496,3865,1085,3004,
2591,1084, 213,2287,1963,3565,2250, 822, 793,4574,3187,1772,1789,3050, 595,1484,
1959,2770,1080,2650, 456, 422,2996, 940,3322,4328,4345,3092,2742, 965,2784, 739,
4124, 952,1358,2498,2949,2565, 332,2698,2378, 660,2260,2473,4194,3856,2919, 535,
1260,2651,1208,1428,1300,1949,1303,2942, 433,2455,2450,1251,1946, 614,1269, 641,
1306,1810,2737,3078,2912, 564,2365,1419,1415,1497,4460,2367,2185,1379,3005,1307,
3218,2175,1897,3063, 682,1157,4040,4005,1712,1160,1941,1399, 394, 402,2952,1573,
1151,2986,2404, 862, 299,2033,1489,3006, 346, 171,2886,3401,1726,2932, 168,2533,
  47,2507,1030,3735,1145,3370,1395,1318,1579,3609,4560,2857,4116,1457,2529,1965,
 504,1036,2690,2988,2405, 745,5871, 849,2397,2056,3081, 863,2359,3857,2096,  99,
1397,1769,2300,4428,1643,3455,1978,1757,3718,1440,  35,4879,3742,1296,4228,2280,
 160,5063,1599,2013, 166, 520,3479,1646,3345,3012, 490,1937,1545,1264,2182,2505,
1096,1188,1369,1436,2421,1667,2792,2460,1270,2122, 727,3167,2143, 806,1706,1012,
1800,3037, 960,2218,1882, 805, 139,2456,1139,1521, 851,1052,3093,3089, 342,2039,
 744,5097,1468,1502,1585,2087, 223, 939, 326,2140,2577, 892,2481,1623,4077, 982,
3708, 135,2131,  87,2503,3114,2326,1106, 876,1616, 547,2997,2831,2093,3441,4530,
4314,   9,3256,4229,4148, 659,1462,1986,1710,2046,2913,2231,4090,4880,5255,3392,
3274,1368,3689,4645,1477, 705,3384,3635,1068,1529,2941,1458,3782,1509, 100,1656,
2548, 718,2339, 408,1590,2780,3548,1838,4117,3719,1345,3530, 717,3442,2778,3220,
2898,1892,4590,3614,3371,2043,1998,1224,3483, 891, 635, 584,2559,3355, 733,1766,
1729,1172,3789,1891,2307, 781,2982,2271,1957,1580,5773,2633,2005,4195,3097,1535,
3213,1189,1934,5693,3262, 586,3118,1324,1598, 517,1564,2217,1868,1893,4445,3728,
2703,3139,1526,1787,1992,3882,2875,1549,1199,1056,2224,1904,2711,5098,4287, 338,
1993,3129,3489,2689,1809,2815,1997, 957,1855,3898,2550,3275,3057,1105,1319, 627,
1505,1911,1883,3526, 698,3629,3456,1833,1431, 746,  77,1261,2017,2296,1977,1885,
 125,1334,1600, 525,1798,1109,2222,1470,1945, 559,2236,1186,3443,2476,1929,1411,
2411,3135,1777,3372,2621,1841,1613,3229, 668,1430,1839,2643,2916, 195,1989,2671,
2358,1387, 629,3205,2293,5256,4439, 123,1310, 888,1879,4300,3021,3605,1003,1162,
3192,2910,2010, 140,2395,2859,  55,1082,2012,2901, 662, 419,2081,1438, 680,2774,
4654,3912,1620,1731,1625,5035,4065,2328, 512,1344, 802,5443,2163,2311,2537, 524,
3399,  98,1155,2103,1918,2606,3925,2816,1393,2465,1504,3773,2177,3963,1478,4346,
 180,1113,4655,3461,2028,1698, 833,2696,1235,1322,1594,4408,3623,3013,3225,2040,
3022, 541,2881, 607,3632,2029,1665,1219, 639,1385,1686,1099,2803,3231,1938,3188,
2858, 427, 676,2772,1168,2025, 454,3253,2486,3556, 230,1950, 580, 791,1991,1280,
1086,1974,2034, 630, 257,3338,2788,4903,1017,  86,4790, 966,2789,1995,1696,1131,
 259,3095,4188,1308, 179,1463,5257, 289,4107,1248,  42,3413,1725,2288, 896,1947,
 774,4474,4254, 604,3430,4264, 392,2514,2588, 452, 237,1408,3018, 988,4531,1970,
3034,3310, 540,2370,1562,1288,2990, 502,4765,1147,   4,1853,2708, 207, 294,2814,
4078,2902,2509, 684,  34,3105,3532,2551, 644, 709,2801,2344, 573,1727,3573,3557,
2021,1081,3100,4315,2100,3681, 199,2263,1837,2385, 146,3484,1195,2776,3949, 997,
1939,3973,1008,1091,1202,1962,1847,1149,4209,5444,1076, 493, 117,5400,2521, 972,
1490,2934,1796,4542,2374,1512,2933,2657, 413,2888,1135,2762,2314,2156,1355,2369,
 766,2007,2527,2170,3124,2491,2593,2632,4757,2437, 234,3125,3591,1898,1750,1376,
1942,3468,3138, 570,2127,2145,3276,4131, 962, 132,1445,4196,  19, 941,3624,3480,
3366,1973,1374,4461,3431,2629, 283,2415,2275, 808,2887,3620,2112,2563,1353,3610,
 955,1089,3103,1053,  96,  88,4097, 823,3808,1583, 399, 292,4091,3313, 421,1128,
 642,4006, 903,2539,1877,2082, 596,  29,4066,1790, 722,2157, 130, 995,1569, 769,
1485, 464, 513,2213, 288,1923,1101,2453,4316, 133, 486,2445,  50, 625, 487,2207,
  57, 423, 481,2962, 159,3729,1558, 491, 303, 482, 501, 240,2837, 112,3648,2392,
1783, 362,   8,3433,3422, 610,2793,3277,1390,1284,1654,  21,3823, 734, 367, 623,
 193, 287, 374,1009,1483, 816, 476, 313,2255,2340,1262,2150,2899,1146,2581, 782,
2116,1659,2018,1880, 255,3586,3314,1110,2867,2137,2564, 986,2767,5185,2006, 650,
 158, 926, 762, 881,3157,2717,2362,3587, 306,3690,3245,1542,3077,2427,1691,2478,
2118,2985,3490,2438, 539,2305, 983, 129,1754, 355,4201,2386, 827,2923, 104,1773,
2838,2771, 411,2905,3919, 376, 767, 122,1114, 828,2422,1817,3506, 266,3460,1007,
1609,4998, 945,2612,4429,2274, 726,1247,1964,2914,2199,2070,4002,4108, 657,3323,
1422, 579, 455,2764,4737,1222,2895,1670, 824,1223,1487,2525, 558, 861,3080, 598,
2659,2515,1967, 752,2583,2376,2214,4180, 977, 704,2464,4999,2622,4109,1210,2961,
 819,1541, 142,2284,  44, 418, 457,1126,3730,4347,4626,1644,1876,3671,1864, 302,
1063,5694, 624, 723,1984,3745,1314,1676,2488,1610,1449,3558,3569,2166,2098, 409,
1011,2325,3704,2306, 818,1732,1383,1824,1844,3757, 999,2705,3497,1216,1423,2683,
2426,2954,2501,2726,2229,1475,2554,5064,1971,1794,1666,2014,1343, 783, 724, 191,
2434,1354,2220,5065,1763,2752,2472,4152, 131, 175,2885,3434,  92,1466,4920,2616,
3871,3872,3866, 128,1551,1632, 669,1854,3682,4691,4125,1230, 188,2973,3290,1302,
1213, 560,3266, 917, 763,3909,3249,1760, 868,1958, 764,1782,2097, 145,2277,3774,
4462,  64,1491,3062, 971,2132,3606,2442, 221,1226,1617, 218, 323,1185,3207,3147,
 571, 619,1473,1005,1744,2281, 449,1887,2396,3685, 275, 375,3816,1743,3844,3731,
 845,1983,2350,4210,1377, 773, 967,3499,3052,3743,2725,4007,1697,1022,3943,1464,
3264,2855,2722,1952,1029,2839,2467,  84,4383,2215, 820,1391,2015,2448,3672, 377,
1948,2168, 797,2545,3536,2578,2645,  94,2874,1678, 405,1259,3071, 771, 546,1315,
 470,1243,3083, 895,2468, 981, 969,2037, 846,4181, 653,1276,2928,  14,2594, 557,
3007,2474, 156, 902,1338,1740,2574, 537,2518, 973,2282,2216,2433,1928, 138,2903,
1293,2631,1612, 646,3457, 839,2935, 111, 496,2191,2847, 589,3186, 149,3994,2060,
4031,2641,4067,3145,1870,  37,3597,2136,1025,2051,3009,3383,3549,1121,1016,3261,
1301, 251,2446,2599,2153, 872,3246, 637, 334,3705, 831, 884, 921,3065,3140,4092,
2198,1944, 246,2964, 108,2045,1152,1921,2308,1031, 203,3173,4170,1907,3890, 810,
1401,2003,1690, 506, 647,1242,2828,1761,1649,3208,2249,1589,3709,2931,5156,1708,
 498, 666,2613, 834,3817,1231, 184,2851,1124, 883,3197,2261,3710,1765,1553,2658,
1178,2639,2351,  93,1193, 942,2538,2141,4402, 235,1821, 870,1591,2192,1709,1871,
3341,1618,4126,2595,2334, 603, 651,  69, 701, 268,2662,3411,2555,1380,1606, 503,
 448, 254,2371,2646, 574,1187,2309,1770, 322,2235,1292,1801, 305, 566,1133, 229,
2067,2057, 706, 167, 483,2002,2672,3295,1820,3561,3067, 316, 378,2746,3452,1112,
 136,1981, 507,1651,2917,1117, 285,4591, 182,2580,3522,1304, 335,3303,1835,2504,
1795,1792,2248, 674,1018,2106,2449,1857,2292,2845, 976,3047,1781,2600,2727,1389,
1281,  52,3152, 153, 265,3950, 672,3485,3951,4463, 430,1183, 365, 278,2169,  27,
1407,1336,2304, 209,1340,1730,2202,1852,2403,2883, 979,1737,1062, 631,2829,2542,
3876,2592, 825,2086,2226,3048,3625, 352,1417,3724, 542, 991, 431,1351,3938,1861,
2294, 826,1361,2927,3142,3503,1738, 463,2462,2723, 582,1916,1595,2808, 400,3845,
3891,2868,3621,2254,  58,2492,1123, 910,2160,2614,1372,1603,1196,1072,3385,1700,
3267,1980, 696, 480,2430, 920, 799,1570,2920,1951,2041,4047,2540,1321,4223,2469,
3562,2228,1271,2602, 401,2833,3351,2575,5157, 907,2312,1256, 410, 263,3507,1582,
 996, 678,1849,2316,1480, 908,3545,2237, 703,2322, 667,1826,2849,1531,2604,2999,
2407,3146,2151,2630,1786,3711, 469,3542, 497,3899,2409, 858, 837,4446,3393,1274,
 786, 620,1845,2001,3311, 484, 308,3367,1204,1815,3691,2332,1532,2557,1842,2020,
2724,1927,2333,4440, 567,  22,1673,2728,4475,1987,1858,1144,1597, 101,1832,3601,
  12, 974,3783,4391, 951,1412,   1,3720, 453,4608,4041, 528,1041,1027,3230,2628,
1129, 875,1051,3291,1203,2262,1069,2860,2799,2149,2615,3278, 144,1758,3040,  31,
 475,1680, 366,2685,3184, 311,1642,4008,2466,5036,1593,1493,2809, 216,1420,1668,
 233, 304,2128,3284, 232,1429,1768,1040,2008,3407,2740,2967,2543, 242,2133, 778,
1565,2022,2620, 505,2189,2756,1098,2273, 372,1614, 708, 553,2846,2094,2278, 169,
3626,2835,4161, 228,2674,3165, 809,1454,1309, 466,1705,1095, 900,3423, 880,2667,
3751,5258,2317,3109,2571,4317,2766,1503,1342, 866,4447,1118,  63,2076, 314,1881,
1348,1061, 172, 978,3515,1747, 532, 511,3970,   6, 601, 905,2699,3300,1751, 276,
1467,3725,2668,  65,4239,2544,2779,2556,1604, 578,2451,1802, 992,2331,2624,1320,
3446, 713,1513,1013, 103,2786,2447,1661, 886,1702, 916, 654,3574,2031,1556, 751,
2178,2821,2179,1498,1538,2176, 271, 914,2251,2080,1325, 638,1953,2937,3877,2432,
2754,  95,3265,1716, 260,1227,4083, 775, 106,1357,3254, 426,1607, 555,2480, 772,
1985, 244,2546, 474, 495,1046,2611,1851,2061,  71,2089,1675,2590, 742,3758,2843,
3222,1433, 267,2180,2576,2826,2233,2092,3913,2435, 956,1745,3075, 856,2113,1116,
 451,   3,1988,2896,1398, 993,2463,1878,2049,1341,2718,2721,2870,2108, 712,2904,
4363,2753,2324, 277,2872,2349,2649, 384, 987, 435, 691,3000, 922, 164,3939, 652,
1500,1184,4153,2482,3373,2165,4848,2335,3775,3508,3154,2806,2830,1554,2102,1664,
2530,1434,2408, 893,1547,2623,3447,2832,2242,2532,3169,2856,3223,2078,  49,3770,
3469, 462, 318, 656,2259,3250,3069, 679,1629,2758, 344,1138,1104,3120,1836,1283,
3115,2154,1437,4448, 934, 759,1999, 794,2862,1038, 533,2560,1722,2342, 855,2626,
1197,1663,4476,3127,  85,4240,2528,  25,1111,1181,3673, 407,3470,4561,2679,2713,
 768,1925,2841,3986,1544,1165, 932, 373,1240,2146,1930,2673, 721,4766, 354,4333,
 391,2963, 187,  61,3364,1442,1102, 330,1940,1767, 341,3809,4118, 393,2496,2062,
2211, 105, 331, 300, 439, 913,1332, 626, 379,3304,1557, 328, 689,3952, 309,1555,
 931, 317,2517,3027, 325, 569, 686,2107,3084,  60,1042,1333,2794, 264,3177,4014,
1628, 258,3712,   7,4464,1176,1043,1778, 683, 114,1975,  78,1492, 383,1886, 510,
 386, 645,5291,2891,2069,3305,4138,3867,2939,2603,2493,1935,1066,1848,3588,1015,
1282,1289,4609, 697,1453,3044,2666,3611,1856,2412,  54, 719,1330, 568,3778,2459,
1748, 788, 492, 551,1191,1000, 488,3394,3763, 282,1799, 348,2016,1523,3155,2390,
1049, 382,2019,1788,1170, 729,2968,3523, 897,3926,2785,2938,3292, 350,2319,3238,
1718,1717,2655,3453,3143,4465, 161,2889,2980,2009,1421,  56,1908,1640,2387,2232,
1917,1874,2477,4921, 148,  83,3438, 592,4245,2882,1822,1055, 741, 115,1496,1624,
 381,1638,4592,1020, 516,3214, 458, 947,4575,1432, 211,1514,2926,1865,2142, 189,
 852,1221,1400,1486, 882,2299,4036, 351,  28,1122, 700,6479,6480,6481,6482,6483,  # last 512
#Everything below is of no interest for detection purpose
5508,6484,3900,3414,3974,4441,4024,3537,4037,5628,5099,3633,6485,3148,6486,3636,
5509,3257,5510,5973,5445,5872,4941,4403,3174,4627,5873,6276,2286,4230,5446,5874,
5122,6102,6103,4162,5447,5123,5323,4849,6277,3980,3851,5066,4246,5774,5067,6278,
3001,2807,5695,3346,5775,5974,5158,5448,6487,5975,5976,5776,3598,6279,5696,4806,
4211,4154,6280,6488,6489,6490,6281,4212,5037,3374,4171,6491,4562,4807,4722,4827,
5977,6104,4532,4079,5159,5324,5160,4404,3858,5359,5875,3975,4288,4610,3486,4512,
5325,3893,5360,6282,6283,5560,2522,4231,5978,5186,5449,2569,3878,6284,5401,3578,
4415,6285,4656,5124,5979,2506,4247,4449,3219,3417,4334,4969,4329,6492,4576,4828,
4172,4416,4829,5402,6286,3927,3852,5361,4369,4830,4477,4867,5876,4173,6493,6105,
4657,6287,6106,5877,5450,6494,4155,4868,5451,3700,5629,4384,6288,6289,5878,3189,
4881,6107,6290,6495,4513,6496,4692,4515,4723,5100,3356,6497,6291,3810,4080,5561,
3570,4430,5980,6498,4355,5697,6499,4724,6108,6109,3764,4050,5038,5879,4093,3226,
6292,5068,5217,4693,3342,5630,3504,4831,4377,4466,4309,5698,4431,5777,6293,5778,
4272,3706,6110,5326,3752,4676,5327,4273,5403,4767,5631,6500,5699,5880,3475,5039,
6294,5562,5125,4348,4301,4482,4068,5126,4593,5700,3380,3462,5981,5563,3824,5404,
4970,5511,3825,4738,6295,6501,5452,4516,6111,5881,5564,6502,6296,5982,6503,4213,
4163,3454,6504,6112,4009,4450,6113,4658,6297,6114,3035,6505,6115,3995,4904,4739,
4563,4942,4110,5040,3661,3928,5362,3674,6506,5292,3612,4791,5565,4149,5983,5328,
5259,5021,4725,4577,4564,4517,4364,6298,5405,4578,5260,4594,4156,4157,5453,3592,
3491,6507,5127,5512,4709,4922,5984,5701,4726,4289,6508,4015,6116,5128,4628,3424,
4241,5779,6299,4905,6509,6510,5454,5702,5780,6300,4365,4923,3971,6511,5161,3270,
3158,5985,4100, 867,5129,5703,6117,5363,3695,3301,5513,4467,6118,6512,5455,4232,
4242,4629,6513,3959,4478,6514,5514,5329,5986,4850,5162,5566,3846,4694,6119,5456,
4869,5781,3779,6301,5704,5987,5515,4710,6302,5882,6120,4392,5364,5705,6515,6121,
6516,6517,3736,5988,5457,5989,4695,2457,5883,4551,5782,6303,6304,6305,5130,4971,
6122,5163,6123,4870,3263,5365,3150,4871,6518,6306,5783,5069,5706,3513,3498,4409,
5330,5632,5366,5458,5459,3991,5990,4502,3324,5991,5784,3696,4518,5633,4119,6519,
4630,5634,4417,5707,4832,5992,3418,6124,5993,5567,4768,5218,6520,4595,3458,5367,
6125,5635,6126,4202,6521,4740,4924,6307,3981,4069,4385,6308,3883,2675,4051,3834,
4302,4483,5568,5994,4972,4101,5368,6309,5164,5884,3922,6127,6522,6523,5261,5460,
5187,4164,5219,3538,5516,4111,3524,5995,6310,6311,5369,3181,3386,2484,5188,3464,
5569,3627,5708,6524,5406,5165,4677,4492,6312,4872,4851,5885,4468,5996,6313,5709,
5710,6128,2470,5886,6314,5293,4882,5785,3325,5461,5101,6129,5711,5786,6525,4906,
6526,6527,4418,5887,5712,4808,2907,3701,5713,5888,6528,3765,5636,5331,6529,6530,
3593,5889,3637,4943,3692,5714,5787,4925,6315,6130,5462,4405,6131,6132,6316,5262,
6531,6532,5715,3859,5716,5070,4696,5102,3929,5788,3987,4792,5997,6533,6534,3920,
4809,5000,5998,6535,2974,5370,6317,5189,5263,5717,3826,6536,3953,5001,4883,3190,
5463,5890,4973,5999,4741,6133,6134,3607,5570,6000,4711,3362,3630,4552,5041,6318,
6001,2950,2953,5637,4646,5371,4944,6002,2044,4120,3429,6319,6537,5103,4833,6538,
6539,4884,4647,3884,6003,6004,4758,3835,5220,5789,4565,5407,6540,6135,5294,4697,
4852,6320,6321,3206,4907,6541,6322,4945,6542,6136,6543,6323,6005,4631,3519,6544,
5891,6545,5464,3784,5221,6546,5571,4659,6547,6324,6137,5190,6548,3853,6549,4016,
4834,3954,6138,5332,3827,4017,3210,3546,4469,5408,5718,3505,4648,5790,5131,5638,
5791,5465,4727,4318,6325,6326,5792,4553,4010,4698,3439,4974,3638,4335,3085,6006,
5104,5042,5166,5892,5572,6327,4356,4519,5222,5573,5333,5793,5043,6550,5639,5071,
4503,6328,6139,6551,6140,3914,3901,5372,6007,5640,4728,4793,3976,3836,4885,6552,
4127,6553,4451,4102,5002,6554,3686,5105,6555,5191,5072,5295,4611,5794,5296,6556,
5893,5264,5894,4975,5466,5265,4699,4976,4370,4056,3492,5044,4886,6557,5795,4432,
4769,4357,5467,3940,4660,4290,6141,4484,4770,4661,3992,6329,4025,4662,5022,4632,
4835,4070,5297,4663,4596,5574,5132,5409,5895,6142,4504,5192,4664,5796,5896,3885,
5575,5797,5023,4810,5798,3732,5223,4712,5298,4084,5334,5468,6143,4052,4053,4336,
4977,4794,6558,5335,4908,5576,5224,4233,5024,4128,5469,5225,4873,6008,5045,4729,
4742,4633,3675,4597,6559,5897,5133,5577,5003,5641,5719,6330,6560,3017,2382,3854,
4406,4811,6331,4393,3964,4946,6561,2420,3722,6562,4926,4378,3247,1736,4442,6332,
5134,6333,5226,3996,2918,5470,4319,4003,4598,4743,4744,4485,3785,3902,5167,5004,
5373,4394,5898,6144,4874,1793,3997,6334,4085,4214,5106,5642,4909,5799,6009,4419,
4189,3330,5899,4165,4420,5299,5720,5227,3347,6145,4081,6335,2876,3930,6146,3293,
3786,3910,3998,5900,5300,5578,2840,6563,5901,5579,6147,3531,5374,6564,6565,5580,
4759,5375,6566,6148,3559,5643,6336,6010,5517,6337,6338,5721,5902,3873,6011,6339,
6567,5518,3868,3649,5722,6568,4771,4947,6569,6149,4812,6570,2853,5471,6340,6341,
5644,4795,6342,6012,5723,6343,5724,6013,4349,6344,3160,6150,5193,4599,4514,4493,
5168,4320,6345,4927,3666,4745,5169,5903,5005,4928,6346,5725,6014,4730,4203,5046,
4948,3395,5170,6015,4150,6016,5726,5519,6347,5047,3550,6151,6348,4197,4310,5904,
6571,5581,2965,6152,4978,3960,4291,5135,6572,5301,5727,4129,4026,5905,4853,5728,
5472,6153,6349,4533,2700,4505,5336,4678,3583,5073,2994,4486,3043,4554,5520,6350,
6017,5800,4487,6351,3931,4103,5376,6352,4011,4321,4311,4190,5136,6018,3988,3233,
4350,5906,5645,4198,6573,5107,3432,4191,3435,5582,6574,4139,5410,6353,5411,3944,
5583,5074,3198,6575,6354,4358,6576,5302,4600,5584,5194,5412,6577,6578,5585,5413,
5303,4248,5414,3879,4433,6579,4479,5025,4854,5415,6355,4760,4772,3683,2978,4700,
3797,4452,3965,3932,3721,4910,5801,6580,5195,3551,5907,3221,3471,3029,6019,3999,
5908,5909,5266,5267,3444,3023,3828,3170,4796,5646,4979,4259,6356,5647,5337,3694,
6357,5648,5338,4520,4322,5802,3031,3759,4071,6020,5586,4836,4386,5048,6581,3571,
4679,4174,4949,6154,4813,3787,3402,3822,3958,3215,3552,5268,4387,3933,4950,4359,
6021,5910,5075,3579,6358,4234,4566,5521,6359,3613,5049,6022,5911,3375,3702,3178,
4911,5339,4521,6582,6583,4395,3087,3811,5377,6023,6360,6155,4027,5171,5649,4421,
4249,2804,6584,2270,6585,4000,4235,3045,6156,5137,5729,4140,4312,3886,6361,4330,
6157,4215,6158,3500,3676,4929,4331,3713,4930,5912,4265,3776,3368,5587,4470,4855,
3038,4980,3631,6159,6160,4132,4680,6161,6362,3923,4379,5588,4255,6586,4121,6587,
6363,4649,6364,3288,4773,4774,6162,6024,6365,3543,6588,4274,3107,3737,5050,5803,
4797,4522,5589,5051,5730,3714,4887,5378,4001,4523,6163,5026,5522,4701,4175,2791,
3760,6589,5473,4224,4133,3847,4814,4815,4775,3259,5416,6590,2738,6164,6025,5304,
3733,5076,5650,4816,5590,6591,6165,6592,3934,5269,6593,3396,5340,6594,5804,3445,
3602,4042,4488,5731,5732,3525,5591,4601,5196,6166,6026,5172,3642,4612,3202,4506,
4798,6366,3818,5108,4303,5138,5139,4776,3332,4304,2915,3415,4434,5077,5109,4856,
2879,5305,4817,6595,5913,3104,3144,3903,4634,5341,3133,5110,5651,5805,6167,4057,
5592,2945,4371,5593,6596,3474,4182,6367,6597,6168,4507,4279,6598,2822,6599,4777,
4713,5594,3829,6169,3887,5417,6170,3653,5474,6368,4216,2971,5228,3790,4579,6369,
5733,6600,6601,4951,4746,4555,6602,5418,5475,6027,3400,4665,5806,6171,4799,6028,
5052,6172,3343,4800,4747,5006,6370,4556,4217,5476,4396,5229,5379,5477,3839,5914,
5652,5807,4714,3068,4635,5808,6173,5342,4192,5078,5419,5523,5734,6174,4557,6175,
4602,6371,6176,6603,5809,6372,5735,4260,3869,5111,5230,6029,5112,6177,3126,4681,
5524,5915,2706,3563,4748,3130,6178,4018,5525,6604,6605,5478,4012,4837,6606,4534,
4193,5810,4857,3615,5479,6030,4082,3697,3539,4086,5270,3662,4508,4931,5916,4912,
5811,5027,3888,6607,4397,3527,3302,3798,2775,2921,2637,3966,4122,4388,4028,4054,
1633,4858,5079,3024,5007,3982,3412,5736,6608,3426,3236,5595,3030,6179,3427,3336,
3279,3110,6373,3874,3039,5080,5917,5140,4489,3119,6374,5812,3405,4494,6031,4666,
4141,6180,4166,6032,5813,4981,6609,5081,4422,4982,4112,3915,5653,3296,3983,6375,
4266,4410,5654,6610,6181,3436,5082,6611,5380,6033,3819,5596,4535,5231,5306,5113,
6612,4952,5918,4275,3113,6613,6376,6182,6183,5814,3073,4731,4838,5008,3831,6614,
4888,3090,3848,4280,5526,5232,3014,5655,5009,5737,5420,5527,6615,5815,5343,5173,
5381,4818,6616,3151,4953,6617,5738,2796,3204,4360,2989,4281,5739,5174,5421,5197,
3132,5141,3849,5142,5528,5083,3799,3904,4839,5480,2880,4495,3448,6377,6184,5271,
5919,3771,3193,6034,6035,5920,5010,6036,5597,6037,6378,6038,3106,5422,6618,5423,
5424,4142,6619,4889,5084,4890,4313,5740,6620,3437,5175,5307,5816,4199,5198,5529,
5817,5199,5656,4913,5028,5344,3850,6185,2955,5272,5011,5818,4567,4580,5029,5921,
3616,5233,6621,6622,6186,4176,6039,6379,6380,3352,5200,5273,2908,5598,5234,3837,
5308,6623,6624,5819,4496,4323,5309,5201,6625,6626,4983,3194,3838,4167,5530,5922,
5274,6381,6382,3860,3861,5599,3333,4292,4509,6383,3553,5481,5820,5531,4778,6187,
3955,3956,4324,4389,4218,3945,4325,3397,2681,5923,4779,5085,4019,5482,4891,5382,
5383,6040,4682,3425,5275,4094,6627,5310,3015,5483,5657,4398,5924,3168,4819,6628,
5925,6629,5532,4932,4613,6041,6630,4636,6384,4780,4204,5658,4423,5821,3989,4683,
5822,6385,4954,6631,5345,6188,5425,5012,5384,3894,6386,4490,4104,6632,5741,5053,
6633,5823,5926,5659,5660,5927,6634,5235,5742,5824,4840,4933,4820,6387,4859,5928,
4955,6388,4143,3584,5825,5346,5013,6635,5661,6389,5014,5484,5743,4337,5176,5662,
6390,2836,6391,3268,6392,6636,6042,5236,6637,4158,6638,5744,5663,4471,5347,3663,
4123,5143,4293,3895,6639,6640,5311,5929,5826,3800,6189,6393,6190,5664,5348,3554,
3594,4749,4603,6641,5385,4801,6043,5827,4183,6642,5312,5426,4761,6394,5665,6191,
4715,2669,6643,6644,5533,3185,5427,5086,5930,5931,5386,6192,6044,6645,4781,4013,
5745,4282,4435,5534,4390,4267,6045,5746,4984,6046,2743,6193,3501,4087,5485,5932,
5428,4184,4095,5747,4061,5054,3058,3862,5933,5600,6646,5144,3618,6395,3131,5055,
5313,6396,4650,4956,3855,6194,3896,5202,4985,4029,4225,6195,6647,5828,5486,5829,
3589,3002,6648,6397,4782,5276,6649,6196,6650,4105,3803,4043,5237,5830,6398,4096,
3643,6399,3528,6651,4453,3315,4637,6652,3984,6197,5535,3182,3339,6653,3096,2660,
6400,6654,3449,5934,4250,4236,6047,6401,5831,6655,5487,3753,4062,5832,6198,6199,
6656,3766,6657,3403,4667,6048,6658,4338,2897,5833,3880,2797,3780,4326,6659,5748,
5015,6660,5387,4351,5601,4411,6661,3654,4424,5935,4339,4072,5277,4568,5536,6402,
6662,5238,6663,5349,5203,6200,5204,6201,5145,4536,5016,5056,4762,5834,4399,4957,
6202,6403,5666,5749,6664,4340,6665,5936,5177,5667,6666,6667,3459,4668,6404,6668,
6669,4543,6203,6670,4276,6405,4480,5537,6671,4614,5205,5668,6672,3348,2193,4763,
6406,6204,5937,5602,4177,5669,3419,6673,4020,6205,4443,4569,5388,3715,3639,6407,
6049,4058,6206,6674,5938,4544,6050,4185,4294,4841,4651,4615,5488,6207,6408,6051,
5178,3241,3509,5835,6208,4958,5836,4341,5489,5278,6209,2823,5538,5350,5206,5429,
6675,4638,4875,4073,3516,4684,4914,4860,5939,5603,5389,6052,5057,3237,5490,3791,
6676,6409,6677,4821,4915,4106,5351,5058,4243,5539,4244,5604,4842,4916,5239,3028,
3716,5837,5114,5605,5390,5940,5430,6210,4332,6678,5540,4732,3667,3840,6053,4305,
3408,5670,5541,6410,2744,5240,5750,6679,3234,5606,6680,5607,5671,3608,4283,4159,
4400,5352,4783,6681,6411,6682,4491,4802,6211,6412,5941,6413,6414,5542,5751,6683,
4669,3734,5942,6684,6415,5943,5059,3328,4670,4144,4268,6685,6686,6687,6688,4372,
3603,6689,5944,5491,4373,3440,6416,5543,4784,4822,5608,3792,4616,5838,5672,3514,
5391,6417,4892,6690,4639,6691,6054,5673,5839,6055,6692,6056,5392,6212,4038,5544,
5674,4497,6057,6693,5840,4284,5675,4021,4545,5609,6418,4454,6419,6213,4113,4472,
5314,3738,5087,5279,4074,5610,4959,4063,3179,4750,6058,6420,6214,3476,4498,4716,
5431,4960,4685,6215,5241,6694,6421,6216,6695,5841,5945,6422,3748,5946,5179,3905,
5752,5545,5947,4374,6217,4455,6423,4412,6218,4803,5353,6696,3832,5280,6219,4327,
4702,6220,6221,6059,4652,5432,6424,3749,4751,6425,5753,4986,5393,4917,5948,5030,
5754,4861,4733,6426,4703,6697,6222,4671,5949,4546,4961,5180,6223,5031,3316,5281,
6698,4862,4295,4934,5207,3644,6427,5842,5950,6428,6429,4570,5843,5282,6430,6224,
5088,3239,6060,6699,5844,5755,6061,6431,2701,5546,6432,5115,5676,4039,3993,3327,
4752,4425,5315,6433,3941,6434,5677,4617,4604,3074,4581,6225,5433,6435,6226,6062,
4823,5756,5116,6227,3717,5678,4717,5845,6436,5679,5846,6063,5847,6064,3977,3354,
6437,3863,5117,6228,5547,5394,4499,4524,6229,4605,6230,4306,4500,6700,5951,6065,
3693,5952,5089,4366,4918,6701,6231,5548,6232,6702,6438,4704,5434,6703,6704,5953,
4168,6705,5680,3420,6706,5242,4407,6066,3812,5757,5090,5954,4672,4525,3481,5681,
4618,5395,5354,5316,5955,6439,4962,6707,4526,6440,3465,4673,6067,6441,5682,6708,
5435,5492,5758,5683,4619,4571,4674,4804,4893,4686,5493,4753,6233,6068,4269,6442,
6234,5032,4705,5146,5243,5208,5848,6235,6443,4963,5033,4640,4226,6236,5849,3387,
6444,6445,4436,4437,5850,4843,5494,4785,4894,6709,4361,6710,5091,5956,3331,6237,
4987,5549,6069,6711,4342,3517,4473,5317,6070,6712,6071,4706,6446,5017,5355,6713,
6714,4988,5436,6447,4734,5759,6715,4735,4547,4456,4754,6448,5851,6449,6450,3547,
5852,5318,6451,6452,5092,4205,6716,6238,4620,4219,5611,6239,6072,4481,5760,5957,
5958,4059,6240,6453,4227,4537,6241,5761,4030,4186,5244,5209,3761,4457,4876,3337,
5495,5181,6242,5959,5319,5612,5684,5853,3493,5854,6073,4169,5613,5147,4895,6074,
5210,6717,5182,6718,3830,6243,2798,3841,6075,6244,5855,5614,3604,4606,5496,5685,
5118,5356,6719,6454,5960,5357,5961,6720,4145,3935,4621,5119,5962,4261,6721,6455,
4786,5963,4375,4582,6245,6246,6247,6076,5437,4877,5856,3376,4380,6248,4160,6722,
5148,6456,5211,6457,6723,4718,6458,6724,6249,5358,4044,3297,6459,6250,5857,5615,
5497,5245,6460,5498,6725,6251,6252,5550,3793,5499,2959,5396,6461,6462,4572,5093,
5500,5964,3806,4146,6463,4426,5762,5858,6077,6253,4755,3967,4220,5965,6254,4989,
5501,6464,4352,6726,6078,4764,2290,5246,3906,5438,5283,3767,4964,2861,5763,5094,
6255,6256,4622,5616,5859,5860,4707,6727,4285,4708,4824,5617,6257,5551,4787,5212,
4965,4935,4687,6465,6728,6466,5686,6079,3494,4413,2995,5247,5966,5618,6729,5967,
5764,5765,5687,5502,6730,6731,6080,5397,6467,4990,6258,6732,4538,5060,5619,6733,
4719,5688,5439,5018,5149,5284,5503,6734,6081,4607,6259,5120,3645,5861,4583,6260,
4584,4675,5620,4098,5440,6261,4863,2379,3306,4585,5552,5689,4586,5285,6735,4864,
6736,5286,6082,6737,4623,3010,4788,4381,4558,5621,4587,4896,3698,3161,5248,4353,
4045,6262,3754,5183,4588,6738,6263,6739,6740,5622,3936,6741,6468,6742,6264,5095,
6469,4991,5968,6743,4992,6744,6083,4897,6745,4256,5766,4307,3108,3968,4444,5287,
3889,4343,6084,4510,6085,4559,6086,4898,5969,6746,5623,5061,4919,5249,5250,5504,
5441,6265,5320,4878,3242,5862,5251,3428,6087,6747,4237,5624,5442,6266,5553,4539,
6748,2585,3533,5398,4262,6088,5150,4736,4438,6089,6267,5505,4966,6749,6268,6750,
6269,5288,5554,3650,6090,6091,4624,6092,5690,6751,5863,4270,5691,4277,5555,5864,
6752,5692,4720,4865,6470,5151,4688,4825,6753,3094,6754,6471,3235,4653,6755,5213,
5399,6756,3201,4589,5865,4967,6472,5866,6473,5019,3016,6757,5321,4756,3957,4573,
6093,4993,5767,4721,6474,6758,5625,6759,4458,6475,6270,6760,5556,4994,5214,5252,
6271,3875,5768,6094,5034,5506,4376,5769,6761,2120,6476,5253,5770,6762,5771,5970,
3990,5971,5557,5558,5772,6477,6095,2787,4641,5972,5121,6096,6097,6272,6763,3703,
5867,5507,6273,4206,6274,4789,6098,6764,3619,3646,3833,3804,2394,3788,4936,3978,
4866,4899,6099,6100,5559,6478,6765,3599,5868,6101,5869,5870,6275,6766,4527,6767)


########NEW FILE########
__FILENAME__ = gb2312prober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from mbcharsetprober import MultiByteCharSetProber
from codingstatemachine import CodingStateMachine
from chardistribution import GB2312DistributionAnalysis
from mbcssm import GB2312SMModel

class GB2312Prober(MultiByteCharSetProber):
    def __init__(self):
        MultiByteCharSetProber.__init__(self)
        self._mCodingSM = CodingStateMachine(GB2312SMModel)
        self._mDistributionAnalyzer = GB2312DistributionAnalysis()
        self.reset()

    def get_charset_name(self):
        return "GB2312"

########NEW FILE########
__FILENAME__ = hebrewprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
#          Shy Shalom
# Portions created by the Initial Developer are Copyright (C) 2005
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from charsetprober import CharSetProber
import constants

# This prober doesn't actually recognize a language or a charset.
# It is a helper prober for the use of the Hebrew model probers

### General ideas of the Hebrew charset recognition ###
#
# Four main charsets exist in Hebrew:
# "ISO-8859-8" - Visual Hebrew
# "windows-1255" - Logical Hebrew 
# "ISO-8859-8-I" - Logical Hebrew
# "x-mac-hebrew" - ?? Logical Hebrew ??
#
# Both "ISO" charsets use a completely identical set of code points, whereas
# "windows-1255" and "x-mac-hebrew" are two different proper supersets of 
# these code points. windows-1255 defines additional characters in the range
# 0x80-0x9F as some misc punctuation marks as well as some Hebrew-specific 
# diacritics and additional 'Yiddish' ligature letters in the range 0xc0-0xd6.
# x-mac-hebrew defines similar additional code points but with a different 
# mapping.
#
# As far as an average Hebrew text with no diacritics is concerned, all four 
# charsets are identical with respect to code points. Meaning that for the 
# main Hebrew alphabet, all four map the same values to all 27 Hebrew letters 
# (including final letters).
#
# The dominant difference between these charsets is their directionality.
# "Visual" directionality means that the text is ordered as if the renderer is
# not aware of a BIDI rendering algorithm. The renderer sees the text and 
# draws it from left to right. The text itself when ordered naturally is read 
# backwards. A buffer of Visual Hebrew generally looks like so:
# "[last word of first line spelled backwards] [whole line ordered backwards
# and spelled backwards] [first word of first line spelled backwards] 
# [end of line] [last word of second line] ... etc' "
# adding punctuation marks, numbers and English text to visual text is
# naturally also "visual" and from left to right.
# 
# "Logical" directionality means the text is ordered "naturally" according to
# the order it is read. It is the responsibility of the renderer to display 
# the text from right to left. A BIDI algorithm is used to place general 
# punctuation marks, numbers and English text in the text.
#
# Texts in x-mac-hebrew are almost impossible to find on the Internet. From 
# what little evidence I could find, it seems that its general directionality
# is Logical.
#
# To sum up all of the above, the Hebrew probing mechanism knows about two
# charsets:
# Visual Hebrew - "ISO-8859-8" - backwards text - Words and sentences are
#    backwards while line order is natural. For charset recognition purposes
#    the line order is unimportant (In fact, for this implementation, even 
#    word order is unimportant).
# Logical Hebrew - "windows-1255" - normal, naturally ordered text.
#
# "ISO-8859-8-I" is a subset of windows-1255 and doesn't need to be 
#    specifically identified.
# "x-mac-hebrew" is also identified as windows-1255. A text in x-mac-hebrew
#    that contain special punctuation marks or diacritics is displayed with
#    some unconverted characters showing as question marks. This problem might
#    be corrected using another model prober for x-mac-hebrew. Due to the fact
#    that x-mac-hebrew texts are so rare, writing another model prober isn't 
#    worth the effort and performance hit.
#
#### The Prober ####
#
# The prober is divided between two SBCharSetProbers and a HebrewProber,
# all of which are managed, created, fed data, inquired and deleted by the
# SBCSGroupProber. The two SBCharSetProbers identify that the text is in
# fact some kind of Hebrew, Logical or Visual. The final decision about which
# one is it is made by the HebrewProber by combining final-letter scores
# with the scores of the two SBCharSetProbers to produce a final answer.
#
# The SBCSGroupProber is responsible for stripping the original text of HTML
# tags, English characters, numbers, low-ASCII punctuation characters, spaces
# and new lines. It reduces any sequence of such characters to a single space.
# The buffer fed to each prober in the SBCS group prober is pure text in
# high-ASCII.
# The two SBCharSetProbers (model probers) share the same language model:
# Win1255Model.
# The first SBCharSetProber uses the model normally as any other
# SBCharSetProber does, to recognize windows-1255, upon which this model was
# built. The second SBCharSetProber is told to make the pair-of-letter
# lookup in the language model backwards. This in practice exactly simulates
# a visual Hebrew model using the windows-1255 logical Hebrew model.
#
# The HebrewProber is not using any language model. All it does is look for
# final-letter evidence suggesting the text is either logical Hebrew or visual
# Hebrew. Disjointed from the model probers, the results of the HebrewProber
# alone are meaningless. HebrewProber always returns 0.00 as confidence
# since it never identifies a charset by itself. Instead, the pointer to the
# HebrewProber is passed to the model probers as a helper "Name Prober".
# When the Group prober receives a positive identification from any prober,
# it asks for the name of the charset identified. If the prober queried is a
# Hebrew model prober, the model prober forwards the call to the
# HebrewProber to make the final decision. In the HebrewProber, the
# decision is made according to the final-letters scores maintained and Both
# model probers scores. The answer is returned in the form of the name of the
# charset identified, either "windows-1255" or "ISO-8859-8".

# windows-1255 / ISO-8859-8 code points of interest
FINAL_KAF = '\xea'
NORMAL_KAF = '\xeb'
FINAL_MEM = '\xed'
NORMAL_MEM = '\xee'
FINAL_NUN = '\xef'
NORMAL_NUN = '\xf0'
FINAL_PE = '\xf3'
NORMAL_PE = '\xf4'
FINAL_TSADI = '\xf5'
NORMAL_TSADI = '\xf6'

# Minimum Visual vs Logical final letter score difference.
# If the difference is below this, don't rely solely on the final letter score distance.
MIN_FINAL_CHAR_DISTANCE = 5

# Minimum Visual vs Logical model score difference.
# If the difference is below this, don't rely at all on the model score distance.
MIN_MODEL_DISTANCE = 0.01

VISUAL_HEBREW_NAME = "ISO-8859-8"
LOGICAL_HEBREW_NAME = "windows-1255"

class HebrewProber(CharSetProber):
    def __init__(self):
        CharSetProber.__init__(self)
        self._mLogicalProber = None
        self._mVisualProber = None
        self.reset()

    def reset(self):
        self._mFinalCharLogicalScore = 0
        self._mFinalCharVisualScore = 0
        # The two last characters seen in the previous buffer,
        # mPrev and mBeforePrev are initialized to space in order to simulate a word 
        # delimiter at the beginning of the data
        self._mPrev = ' '
        self._mBeforePrev = ' '
        # These probers are owned by the group prober.
        
    def set_model_probers(self, logicalProber, visualProber):
        self._mLogicalProber = logicalProber
        self._mVisualProber = visualProber

    def is_final(self, c):
        return c in [FINAL_KAF, FINAL_MEM, FINAL_NUN, FINAL_PE, FINAL_TSADI]

    def is_non_final(self, c):
        # The normal Tsadi is not a good Non-Final letter due to words like 
        # 'lechotet' (to chat) containing an apostrophe after the tsadi. This 
        # apostrophe is converted to a space in FilterWithoutEnglishLetters causing 
        # the Non-Final tsadi to appear at an end of a word even though this is not 
        # the case in the original text.
        # The letters Pe and Kaf rarely display a related behavior of not being a 
        # good Non-Final letter. Words like 'Pop', 'Winamp' and 'Mubarak' for 
        # example legally end with a Non-Final Pe or Kaf. However, the benefit of 
        # these letters as Non-Final letters outweighs the damage since these words 
        # are quite rare.
        return c in [NORMAL_KAF, NORMAL_MEM, NORMAL_NUN, NORMAL_PE]
    
    def feed(self, aBuf):
        # Final letter analysis for logical-visual decision.
        # Look for evidence that the received buffer is either logical Hebrew or 
        # visual Hebrew.
        # The following cases are checked:
        # 1) A word longer than 1 letter, ending with a final letter. This is an 
        #    indication that the text is laid out "naturally" since the final letter 
        #    really appears at the end. +1 for logical score.
        # 2) A word longer than 1 letter, ending with a Non-Final letter. In normal
        #    Hebrew, words ending with Kaf, Mem, Nun, Pe or Tsadi, should not end with
        #    the Non-Final form of that letter. Exceptions to this rule are mentioned
        #    above in isNonFinal(). This is an indication that the text is laid out
        #    backwards. +1 for visual score
        # 3) A word longer than 1 letter, starting with a final letter. Final letters 
        #    should not appear at the beginning of a word. This is an indication that 
        #    the text is laid out backwards. +1 for visual score.
        # 
        # The visual score and logical score are accumulated throughout the text and 
        # are finally checked against each other in GetCharSetName().
        # No checking for final letters in the middle of words is done since that case
        # is not an indication for either Logical or Visual text.
        # 
        # We automatically filter out all 7-bit characters (replace them with spaces)
        # so the word boundary detection works properly. [MAP]

        if self.get_state() == constants.eNotMe:
            # Both model probers say it's not them. No reason to continue.
            return constants.eNotMe

        aBuf = self.filter_high_bit_only(aBuf)
        
        for cur in aBuf:
            if cur == ' ':
                # We stand on a space - a word just ended
                if self._mBeforePrev != ' ':
                    # next-to-last char was not a space so self._mPrev is not a 1 letter word
                    if self.is_final(self._mPrev):
                        # case (1) [-2:not space][-1:final letter][cur:space]
                        self._mFinalCharLogicalScore += 1
                    elif self.is_non_final(self._mPrev):
                        # case (2) [-2:not space][-1:Non-Final letter][cur:space]
                        self._mFinalCharVisualScore += 1
            else:
                # Not standing on a space
                if (self._mBeforePrev == ' ') and (self.is_final(self._mPrev)) and (cur != ' '):
                    # case (3) [-2:space][-1:final letter][cur:not space]
                    self._mFinalCharVisualScore += 1
            self._mBeforePrev = self._mPrev
            self._mPrev = cur

        # Forever detecting, till the end or until both model probers return eNotMe (handled above)
        return constants.eDetecting

    def get_charset_name(self):
        # Make the decision: is it Logical or Visual?
        # If the final letter score distance is dominant enough, rely on it.
        finalsub = self._mFinalCharLogicalScore - self._mFinalCharVisualScore
        if finalsub >= MIN_FINAL_CHAR_DISTANCE:
            return LOGICAL_HEBREW_NAME
        if finalsub <= -MIN_FINAL_CHAR_DISTANCE:
            return VISUAL_HEBREW_NAME

        # It's not dominant enough, try to rely on the model scores instead.
        modelsub = self._mLogicalProber.get_confidence() - self._mVisualProber.get_confidence()
        if modelsub > MIN_MODEL_DISTANCE:
            return LOGICAL_HEBREW_NAME
        if modelsub < -MIN_MODEL_DISTANCE:
            return VISUAL_HEBREW_NAME

        # Still no good, back to final letter distance, maybe it'll save the day.
        if finalsub < 0.0:
            return VISUAL_HEBREW_NAME

        # (finalsub > 0 - Logical) or (don't know what to do) default to Logical.
        return LOGICAL_HEBREW_NAME

    def get_state(self):
        # Remain active as long as any of the model probers are active.
        if (self._mLogicalProber.get_state() == constants.eNotMe) and \
           (self._mVisualProber.get_state() == constants.eNotMe):
            return constants.eNotMe
        return constants.eDetecting

########NEW FILE########
__FILENAME__ = jisfreq
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# Sampling from about 20M text materials include literature and computer technology
#
# Japanese frequency table, applied to both S-JIS and EUC-JP
# They are sorted in order. 

# 128  --> 0.77094
# 256  --> 0.85710
# 512  --> 0.92635
# 1024 --> 0.97130
# 2048 --> 0.99431
#
# Ideal Distribution Ratio = 0.92635 / (1-0.92635) = 12.58
# Random Distribution Ration = 512 / (2965+62+83+86-512) = 0.191
# 
# Typical Distribution Ratio, 25% of IDR 

JIS_TYPICAL_DISTRIBUTION_RATIO = 3.0

# Char to FreqOrder table , 
JIS_TABLE_SIZE = 4368

JISCharToFreqOrder = ( \
  40,   1,   6, 182, 152, 180, 295,2127, 285, 381,3295,4304,3068,4606,3165,3510, #   16
3511,1822,2785,4607,1193,2226,5070,4608, 171,2996,1247,  18, 179,5071, 856,1661, #   32
1262,5072, 619, 127,3431,3512,3230,1899,1700, 232, 228,1294,1298, 284, 283,2041, #   48
2042,1061,1062,  48,  49,  44,  45, 433, 434,1040,1041, 996, 787,2997,1255,4305, #   64
2108,4609,1684,1648,5073,5074,5075,5076,5077,5078,3687,5079,4610,5080,3927,3928, #   80
5081,3296,3432, 290,2285,1471,2187,5082,2580,2825,1303,2140,1739,1445,2691,3375, #   96
1691,3297,4306,4307,4611, 452,3376,1182,2713,3688,3069,4308,5083,5084,5085,5086, #  112
5087,5088,5089,5090,5091,5092,5093,5094,5095,5096,5097,5098,5099,5100,5101,5102, #  128
5103,5104,5105,5106,5107,5108,5109,5110,5111,5112,4097,5113,5114,5115,5116,5117, #  144
5118,5119,5120,5121,5122,5123,5124,5125,5126,5127,5128,5129,5130,5131,5132,5133, #  160
5134,5135,5136,5137,5138,5139,5140,5141,5142,5143,5144,5145,5146,5147,5148,5149, #  176
5150,5151,5152,4612,5153,5154,5155,5156,5157,5158,5159,5160,5161,5162,5163,5164, #  192
5165,5166,5167,5168,5169,5170,5171,5172,5173,5174,5175,1472, 598, 618, 820,1205, #  208
1309,1412,1858,1307,1692,5176,5177,5178,5179,5180,5181,5182,1142,1452,1234,1172, #  224
1875,2043,2149,1793,1382,2973, 925,2404,1067,1241, 960,1377,2935,1491, 919,1217, #  240
1865,2030,1406,1499,2749,4098,5183,5184,5185,5186,5187,5188,2561,4099,3117,1804, #  256
2049,3689,4309,3513,1663,5189,3166,3118,3298,1587,1561,3433,5190,3119,1625,2998, #  272
3299,4613,1766,3690,2786,4614,5191,5192,5193,5194,2161,  26,3377,   2,3929,  20, #  288
3691,  47,4100,  50,  17,  16,  35, 268,  27, 243,  42, 155,  24, 154,  29, 184, #  304
   4,  91,  14,  92,  53, 396,  33, 289,   9,  37,  64, 620,  21,  39, 321,   5, #  320
  12,  11,  52,  13,   3, 208, 138,   0,   7,  60, 526, 141, 151,1069, 181, 275, #  336
1591,  83, 132,1475, 126, 331, 829,  15,  69, 160,  59,  22, 157,  55,1079, 312, #  352
 109,  38,  23,  25,  10,  19,  79,5195,  61, 382,1124,   8,  30,5196,5197,5198, #  368
5199,5200,5201,5202,5203,5204,5205,5206,  89,  62,  74,  34,2416, 112, 139, 196, #  384
 271, 149,  84, 607, 131, 765,  46,  88, 153, 683,  76, 874, 101, 258,  57,  80, #  400
  32, 364, 121,1508, 169,1547,  68, 235, 145,2999,  41, 360,3027,  70,  63,  31, #  416
  43, 259, 262,1383,  99, 533, 194,  66,  93, 846, 217, 192,  56, 106,  58, 565, #  432
 280, 272, 311, 256, 146,  82, 308,  71, 100, 128, 214, 655, 110, 261, 104,1140, #  448
  54,  51,  36,  87,  67,3070, 185,2618,2936,2020,  28,1066,2390,2059,5207,5208, #  464
5209,5210,5211,5212,5213,5214,5215,5216,4615,5217,5218,5219,5220,5221,5222,5223, #  480
5224,5225,5226,5227,5228,5229,5230,5231,5232,5233,5234,5235,5236,3514,5237,5238, #  496
5239,5240,5241,5242,5243,5244,2297,2031,4616,4310,3692,5245,3071,5246,3598,5247, #  512
4617,3231,3515,5248,4101,4311,4618,3808,4312,4102,5249,4103,4104,3599,5250,5251, #  528
5252,5253,5254,5255,5256,5257,5258,5259,5260,5261,5262,5263,5264,5265,5266,5267, #  544
5268,5269,5270,5271,5272,5273,5274,5275,5276,5277,5278,5279,5280,5281,5282,5283, #  560
5284,5285,5286,5287,5288,5289,5290,5291,5292,5293,5294,5295,5296,5297,5298,5299, #  576
5300,5301,5302,5303,5304,5305,5306,5307,5308,5309,5310,5311,5312,5313,5314,5315, #  592
5316,5317,5318,5319,5320,5321,5322,5323,5324,5325,5326,5327,5328,5329,5330,5331, #  608
5332,5333,5334,5335,5336,5337,5338,5339,5340,5341,5342,5343,5344,5345,5346,5347, #  624
5348,5349,5350,5351,5352,5353,5354,5355,5356,5357,5358,5359,5360,5361,5362,5363, #  640
5364,5365,5366,5367,5368,5369,5370,5371,5372,5373,5374,5375,5376,5377,5378,5379, #  656
5380,5381, 363, 642,2787,2878,2788,2789,2316,3232,2317,3434,2011, 165,1942,3930, #  672
3931,3932,3933,5382,4619,5383,4620,5384,5385,5386,5387,5388,5389,5390,5391,5392, #  688
5393,5394,5395,5396,5397,5398,5399,5400,5401,5402,5403,5404,5405,5406,5407,5408, #  704
5409,5410,5411,5412,5413,5414,5415,5416,5417,5418,5419,5420,5421,5422,5423,5424, #  720
5425,5426,5427,5428,5429,5430,5431,5432,5433,5434,5435,5436,5437,5438,5439,5440, #  736
5441,5442,5443,5444,5445,5446,5447,5448,5449,5450,5451,5452,5453,5454,5455,5456, #  752
5457,5458,5459,5460,5461,5462,5463,5464,5465,5466,5467,5468,5469,5470,5471,5472, #  768
5473,5474,5475,5476,5477,5478,5479,5480,5481,5482,5483,5484,5485,5486,5487,5488, #  784
5489,5490,5491,5492,5493,5494,5495,5496,5497,5498,5499,5500,5501,5502,5503,5504, #  800
5505,5506,5507,5508,5509,5510,5511,5512,5513,5514,5515,5516,5517,5518,5519,5520, #  816
5521,5522,5523,5524,5525,5526,5527,5528,5529,5530,5531,5532,5533,5534,5535,5536, #  832
5537,5538,5539,5540,5541,5542,5543,5544,5545,5546,5547,5548,5549,5550,5551,5552, #  848
5553,5554,5555,5556,5557,5558,5559,5560,5561,5562,5563,5564,5565,5566,5567,5568, #  864
5569,5570,5571,5572,5573,5574,5575,5576,5577,5578,5579,5580,5581,5582,5583,5584, #  880
5585,5586,5587,5588,5589,5590,5591,5592,5593,5594,5595,5596,5597,5598,5599,5600, #  896
5601,5602,5603,5604,5605,5606,5607,5608,5609,5610,5611,5612,5613,5614,5615,5616, #  912
5617,5618,5619,5620,5621,5622,5623,5624,5625,5626,5627,5628,5629,5630,5631,5632, #  928
5633,5634,5635,5636,5637,5638,5639,5640,5641,5642,5643,5644,5645,5646,5647,5648, #  944
5649,5650,5651,5652,5653,5654,5655,5656,5657,5658,5659,5660,5661,5662,5663,5664, #  960
5665,5666,5667,5668,5669,5670,5671,5672,5673,5674,5675,5676,5677,5678,5679,5680, #  976
5681,5682,5683,5684,5685,5686,5687,5688,5689,5690,5691,5692,5693,5694,5695,5696, #  992
5697,5698,5699,5700,5701,5702,5703,5704,5705,5706,5707,5708,5709,5710,5711,5712, # 1008
5713,5714,5715,5716,5717,5718,5719,5720,5721,5722,5723,5724,5725,5726,5727,5728, # 1024
5729,5730,5731,5732,5733,5734,5735,5736,5737,5738,5739,5740,5741,5742,5743,5744, # 1040
5745,5746,5747,5748,5749,5750,5751,5752,5753,5754,5755,5756,5757,5758,5759,5760, # 1056
5761,5762,5763,5764,5765,5766,5767,5768,5769,5770,5771,5772,5773,5774,5775,5776, # 1072
5777,5778,5779,5780,5781,5782,5783,5784,5785,5786,5787,5788,5789,5790,5791,5792, # 1088
5793,5794,5795,5796,5797,5798,5799,5800,5801,5802,5803,5804,5805,5806,5807,5808, # 1104
5809,5810,5811,5812,5813,5814,5815,5816,5817,5818,5819,5820,5821,5822,5823,5824, # 1120
5825,5826,5827,5828,5829,5830,5831,5832,5833,5834,5835,5836,5837,5838,5839,5840, # 1136
5841,5842,5843,5844,5845,5846,5847,5848,5849,5850,5851,5852,5853,5854,5855,5856, # 1152
5857,5858,5859,5860,5861,5862,5863,5864,5865,5866,5867,5868,5869,5870,5871,5872, # 1168
5873,5874,5875,5876,5877,5878,5879,5880,5881,5882,5883,5884,5885,5886,5887,5888, # 1184
5889,5890,5891,5892,5893,5894,5895,5896,5897,5898,5899,5900,5901,5902,5903,5904, # 1200
5905,5906,5907,5908,5909,5910,5911,5912,5913,5914,5915,5916,5917,5918,5919,5920, # 1216
5921,5922,5923,5924,5925,5926,5927,5928,5929,5930,5931,5932,5933,5934,5935,5936, # 1232
5937,5938,5939,5940,5941,5942,5943,5944,5945,5946,5947,5948,5949,5950,5951,5952, # 1248
5953,5954,5955,5956,5957,5958,5959,5960,5961,5962,5963,5964,5965,5966,5967,5968, # 1264
5969,5970,5971,5972,5973,5974,5975,5976,5977,5978,5979,5980,5981,5982,5983,5984, # 1280
5985,5986,5987,5988,5989,5990,5991,5992,5993,5994,5995,5996,5997,5998,5999,6000, # 1296
6001,6002,6003,6004,6005,6006,6007,6008,6009,6010,6011,6012,6013,6014,6015,6016, # 1312
6017,6018,6019,6020,6021,6022,6023,6024,6025,6026,6027,6028,6029,6030,6031,6032, # 1328
6033,6034,6035,6036,6037,6038,6039,6040,6041,6042,6043,6044,6045,6046,6047,6048, # 1344
6049,6050,6051,6052,6053,6054,6055,6056,6057,6058,6059,6060,6061,6062,6063,6064, # 1360
6065,6066,6067,6068,6069,6070,6071,6072,6073,6074,6075,6076,6077,6078,6079,6080, # 1376
6081,6082,6083,6084,6085,6086,6087,6088,6089,6090,6091,6092,6093,6094,6095,6096, # 1392
6097,6098,6099,6100,6101,6102,6103,6104,6105,6106,6107,6108,6109,6110,6111,6112, # 1408
6113,6114,2044,2060,4621, 997,1235, 473,1186,4622, 920,3378,6115,6116, 379,1108, # 1424
4313,2657,2735,3934,6117,3809, 636,3233, 573,1026,3693,3435,2974,3300,2298,4105, # 1440
 854,2937,2463, 393,2581,2417, 539, 752,1280,2750,2480, 140,1161, 440, 708,1569, # 1456
 665,2497,1746,1291,1523,3000, 164,1603, 847,1331, 537,1997, 486, 508,1693,2418, # 1472
1970,2227, 878,1220, 299,1030, 969, 652,2751, 624,1137,3301,2619,  65,3302,2045, # 1488
1761,1859,3120,1930,3694,3516, 663,1767, 852, 835,3695, 269, 767,2826,2339,1305, # 1504
 896,1150, 770,1616,6118, 506,1502,2075,1012,2519, 775,2520,2975,2340,2938,4314, # 1520
3028,2086,1224,1943,2286,6119,3072,4315,2240,1273,1987,3935,1557, 175, 597, 985, # 1536
3517,2419,2521,1416,3029, 585, 938,1931,1007,1052,1932,1685,6120,3379,4316,4623, # 1552
 804, 599,3121,1333,2128,2539,1159,1554,2032,3810, 687,2033,2904, 952, 675,1467, # 1568
3436,6121,2241,1096,1786,2440,1543,1924, 980,1813,2228, 781,2692,1879, 728,1918, # 1584
3696,4624, 548,1950,4625,1809,1088,1356,3303,2522,1944, 502, 972, 373, 513,2827, # 1600
 586,2377,2391,1003,1976,1631,6122,2464,1084, 648,1776,4626,2141, 324, 962,2012, # 1616
2177,2076,1384, 742,2178,1448,1173,1810, 222, 102, 301, 445, 125,2420, 662,2498, # 1632
 277, 200,1476,1165,1068, 224,2562,1378,1446, 450,1880, 659, 791, 582,4627,2939, # 1648
3936,1516,1274, 555,2099,3697,1020,1389,1526,3380,1762,1723,1787,2229, 412,2114, # 1664
1900,2392,3518, 512,2597, 427,1925,2341,3122,1653,1686,2465,2499, 697, 330, 273, # 1680
 380,2162, 951, 832, 780, 991,1301,3073, 965,2270,3519, 668,2523,2636,1286, 535, # 1696
1407, 518, 671, 957,2658,2378, 267, 611,2197,3030,6123, 248,2299, 967,1799,2356, # 1712
 850,1418,3437,1876,1256,1480,2828,1718,6124,6125,1755,1664,2405,6126,4628,2879, # 1728
2829, 499,2179, 676,4629, 557,2329,2214,2090, 325,3234, 464, 811,3001, 992,2342, # 1744
2481,1232,1469, 303,2242, 466,1070,2163, 603,1777,2091,4630,2752,4631,2714, 322, # 1760
2659,1964,1768, 481,2188,1463,2330,2857,3600,2092,3031,2421,4632,2318,2070,1849, # 1776
2598,4633,1302,2254,1668,1701,2422,3811,2905,3032,3123,2046,4106,1763,1694,4634, # 1792
1604, 943,1724,1454, 917, 868,2215,1169,2940, 552,1145,1800,1228,1823,1955, 316, # 1808
1080,2510, 361,1807,2830,4107,2660,3381,1346,1423,1134,4108,6127, 541,1263,1229, # 1824
1148,2540, 545, 465,1833,2880,3438,1901,3074,2482, 816,3937, 713,1788,2500, 122, # 1840
1575, 195,1451,2501,1111,6128, 859, 374,1225,2243,2483,4317, 390,1033,3439,3075, # 1856
2524,1687, 266, 793,1440,2599, 946, 779, 802, 507, 897,1081, 528,2189,1292, 711, # 1872
1866,1725,1167,1640, 753, 398,2661,1053, 246, 348,4318, 137,1024,3440,1600,2077, # 1888
2129, 825,4319, 698, 238, 521, 187,2300,1157,2423,1641,1605,1464,1610,1097,2541, # 1904
1260,1436, 759,2255,1814,2150, 705,3235, 409,2563,3304, 561,3033,2005,2564, 726, # 1920
1956,2343,3698,4109, 949,3812,3813,3520,1669, 653,1379,2525, 881,2198, 632,2256, # 1936
1027, 778,1074, 733,1957, 514,1481,2466, 554,2180, 702,3938,1606,1017,1398,6129, # 1952
1380,3521, 921, 993,1313, 594, 449,1489,1617,1166, 768,1426,1360, 495,1794,3601, # 1968
1177,3602,1170,4320,2344, 476, 425,3167,4635,3168,1424, 401,2662,1171,3382,1998, # 1984
1089,4110, 477,3169, 474,6130,1909, 596,2831,1842, 494, 693,1051,1028,1207,3076, # 2000
 606,2115, 727,2790,1473,1115, 743,3522, 630, 805,1532,4321,2021, 366,1057, 838, # 2016
 684,1114,2142,4322,2050,1492,1892,1808,2271,3814,2424,1971,1447,1373,3305,1090, # 2032
1536,3939,3523,3306,1455,2199, 336, 369,2331,1035, 584,2393, 902, 718,2600,6131, # 2048
2753, 463,2151,1149,1611,2467, 715,1308,3124,1268, 343,1413,3236,1517,1347,2663, # 2064
2093,3940,2022,1131,1553,2100,2941,1427,3441,2942,1323,2484,6132,1980, 872,2368, # 2080
2441,2943, 320,2369,2116,1082, 679,1933,3941,2791,3815, 625,1143,2023, 422,2200, # 2096
3816,6133, 730,1695, 356,2257,1626,2301,2858,2637,1627,1778, 937, 883,2906,2693, # 2112
3002,1769,1086, 400,1063,1325,3307,2792,4111,3077, 456,2345,1046, 747,6134,1524, # 2128
 884,1094,3383,1474,2164,1059, 974,1688,2181,2258,1047, 345,1665,1187, 358, 875, # 2144
3170, 305, 660,3524,2190,1334,1135,3171,1540,1649,2542,1527, 927, 968,2793, 885, # 2160
1972,1850, 482, 500,2638,1218,1109,1085,2543,1654,2034, 876,  78,2287,1482,1277, # 2176
 861,1675,1083,1779, 724,2754, 454, 397,1132,1612,2332, 893, 672,1237, 257,2259, # 2192
2370, 135,3384, 337,2244, 547, 352, 340, 709,2485,1400, 788,1138,2511, 540, 772, # 2208
1682,2260,2272,2544,2013,1843,1902,4636,1999,1562,2288,4637,2201,1403,1533, 407, # 2224
 576,3308,1254,2071, 978,3385, 170, 136,1201,3125,2664,3172,2394, 213, 912, 873, # 2240
3603,1713,2202, 699,3604,3699, 813,3442, 493, 531,1054, 468,2907,1483, 304, 281, # 2256
4112,1726,1252,2094, 339,2319,2130,2639, 756,1563,2944, 748, 571,2976,1588,2425, # 2272
2715,1851,1460,2426,1528,1392,1973,3237, 288,3309, 685,3386, 296, 892,2716,2216, # 2288
1570,2245, 722,1747,2217, 905,3238,1103,6135,1893,1441,1965, 251,1805,2371,3700, # 2304
2601,1919,1078,  75,2182,1509,1592,1270,2640,4638,2152,6136,3310,3817, 524, 706, # 2320
1075, 292,3818,1756,2602, 317,  98,3173,3605,3525,1844,2218,3819,2502, 814, 567, # 2336
 385,2908,1534,6137, 534,1642,3239, 797,6138,1670,1529, 953,4323, 188,1071, 538, # 2352
 178, 729,3240,2109,1226,1374,2000,2357,2977, 731,2468,1116,2014,2051,6139,1261, # 2368
1593, 803,2859,2736,3443, 556, 682, 823,1541,6140,1369,2289,1706,2794, 845, 462, # 2384
2603,2665,1361, 387, 162,2358,1740, 739,1770,1720,1304,1401,3241,1049, 627,1571, # 2400
2427,3526,1877,3942,1852,1500, 431,1910,1503, 677, 297,2795, 286,1433,1038,1198, # 2416
2290,1133,1596,4113,4639,2469,1510,1484,3943,6141,2442, 108, 712,4640,2372, 866, # 2432
3701,2755,3242,1348, 834,1945,1408,3527,2395,3243,1811, 824, 994,1179,2110,1548, # 2448
1453, 790,3003, 690,4324,4325,2832,2909,3820,1860,3821, 225,1748, 310, 346,1780, # 2464
2470, 821,1993,2717,2796, 828, 877,3528,2860,2471,1702,2165,2910,2486,1789, 453, # 2480
 359,2291,1676,  73,1164,1461,1127,3311, 421, 604, 314,1037, 589, 116,2487, 737, # 2496
 837,1180, 111, 244, 735,6142,2261,1861,1362, 986, 523, 418, 581,2666,3822, 103, # 2512
 855, 503,1414,1867,2488,1091, 657,1597, 979, 605,1316,4641,1021,2443,2078,2001, # 2528
1209,  96, 587,2166,1032, 260,1072,2153, 173,  94, 226,3244, 819,2006,4642,4114, # 2544
2203, 231,1744, 782,  97,2667, 786,3387, 887, 391, 442,2219,4326,1425,6143,2694, # 2560
 633,1544,1202, 483,2015, 592,2052,1958,2472,1655, 419, 129,4327,3444,3312,1714, # 2576
1257,3078,4328,1518,1098, 865,1310,1019,1885,1512,1734, 469,2444, 148, 773, 436, # 2592
1815,1868,1128,1055,4329,1245,2756,3445,2154,1934,1039,4643, 579,1238, 932,2320, # 2608
 353, 205, 801, 115,2428, 944,2321,1881, 399,2565,1211, 678, 766,3944, 335,2101, # 2624
1459,1781,1402,3945,2737,2131,1010, 844, 981,1326,1013, 550,1816,1545,2620,1335, # 2640
1008, 371,2881, 936,1419,1613,3529,1456,1395,2273,1834,2604,1317,2738,2503, 416, # 2656
1643,4330, 806,1126, 229, 591,3946,1314,1981,1576,1837,1666, 347,1790, 977,3313, # 2672
 764,2861,1853, 688,2429,1920,1462,  77, 595, 415,2002,3034, 798,1192,4115,6144, # 2688
2978,4331,3035,2695,2582,2072,2566, 430,2430,1727, 842,1396,3947,3702, 613, 377, # 2704
 278, 236,1417,3388,3314,3174, 757,1869, 107,3530,6145,1194, 623,2262, 207,1253, # 2720
2167,3446,3948, 492,1117,1935, 536,1838,2757,1246,4332, 696,2095,2406,1393,1572, # 2736
3175,1782, 583, 190, 253,1390,2230, 830,3126,3389, 934,3245,1703,1749,2979,1870, # 2752
2545,1656,2204, 869,2346,4116,3176,1817, 496,1764,4644, 942,1504, 404,1903,1122, # 2768
1580,3606,2945,1022, 515, 372,1735, 955,2431,3036,6146,2797,1110,2302,2798, 617, # 2784
6147, 441, 762,1771,3447,3607,3608,1904, 840,3037,  86, 939,1385, 572,1370,2445, # 2800
1336, 114,3703, 898, 294, 203,3315, 703,1583,2274, 429, 961,4333,1854,1951,3390, # 2816
2373,3704,4334,1318,1381, 966,1911,2322,1006,1155, 309, 989, 458,2718,1795,1372, # 2832
1203, 252,1689,1363,3177, 517,1936, 168,1490, 562, 193,3823,1042,4117,1835, 551, # 2848
 470,4645, 395, 489,3448,1871,1465,2583,2641, 417,1493, 279,1295, 511,1236,1119, # 2864
  72,1231,1982,1812,3004, 871,1564, 984,3449,1667,2696,2096,4646,2347,2833,1673, # 2880
3609, 695,3246,2668, 807,1183,4647, 890, 388,2333,1801,1457,2911,1765,1477,1031, # 2896
3316,3317,1278,3391,2799,2292,2526, 163,3450,4335,2669,1404,1802,6148,2323,2407, # 2912
1584,1728,1494,1824,1269, 298, 909,3318,1034,1632, 375, 776,1683,2061, 291, 210, # 2928
1123, 809,1249,1002,2642,3038, 206,1011,2132, 144, 975, 882,1565, 342, 667, 754, # 2944
1442,2143,1299,2303,2062, 447, 626,2205,1221,2739,2912,1144,1214,2206,2584, 760, # 2960
1715, 614, 950,1281,2670,2621, 810, 577,1287,2546,4648, 242,2168, 250,2643, 691, # 2976
 123,2644, 647, 313,1029, 689,1357,2946,1650, 216, 771,1339,1306, 808,2063, 549, # 2992
 913,1371,2913,2914,6149,1466,1092,1174,1196,1311,2605,2396,1783,1796,3079, 406, # 3008
2671,2117,3949,4649, 487,1825,2220,6150,2915, 448,2348,1073,6151,2397,1707, 130, # 3024
 900,1598, 329, 176,1959,2527,1620,6152,2275,4336,3319,1983,2191,3705,3610,2155, # 3040
3706,1912,1513,1614,6153,1988, 646, 392,2304,1589,3320,3039,1826,1239,1352,1340, # 3056
2916, 505,2567,1709,1437,2408,2547, 906,6154,2672, 384,1458,1594,1100,1329, 710, # 3072
 423,3531,2064,2231,2622,1989,2673,1087,1882, 333, 841,3005,1296,2882,2379, 580, # 3088
1937,1827,1293,2585, 601, 574, 249,1772,4118,2079,1120, 645, 901,1176,1690, 795, # 3104
2207, 478,1434, 516,1190,1530, 761,2080, 930,1264, 355, 435,1552, 644,1791, 987, # 3120
 220,1364,1163,1121,1538, 306,2169,1327,1222, 546,2645, 218, 241, 610,1704,3321, # 3136
1984,1839,1966,2528, 451,6155,2586,3707,2568, 907,3178, 254,2947, 186,1845,4650, # 3152
 745, 432,1757, 428,1633, 888,2246,2221,2489,3611,2118,1258,1265, 956,3127,1784, # 3168
4337,2490, 319, 510, 119, 457,3612, 274,2035,2007,4651,1409,3128, 970,2758, 590, # 3184
2800, 661,2247,4652,2008,3950,1420,1549,3080,3322,3951,1651,1375,2111, 485,2491, # 3200
1429,1156,6156,2548,2183,1495, 831,1840,2529,2446, 501,1657, 307,1894,3247,1341, # 3216
 666, 899,2156,1539,2549,1559, 886, 349,2208,3081,2305,1736,3824,2170,2759,1014, # 3232
1913,1386, 542,1397,2948, 490, 368, 716, 362, 159, 282,2569,1129,1658,1288,1750, # 3248
2674, 276, 649,2016, 751,1496, 658,1818,1284,1862,2209,2087,2512,3451, 622,2834, # 3264
 376, 117,1060,2053,1208,1721,1101,1443, 247,1250,3179,1792,3952,2760,2398,3953, # 3280
6157,2144,3708, 446,2432,1151,2570,3452,2447,2761,2835,1210,2448,3082, 424,2222, # 3296
1251,2449,2119,2836, 504,1581,4338, 602, 817, 857,3825,2349,2306, 357,3826,1470, # 3312
1883,2883, 255, 958, 929,2917,3248, 302,4653,1050,1271,1751,2307,1952,1430,2697, # 3328
2719,2359, 354,3180, 777, 158,2036,4339,1659,4340,4654,2308,2949,2248,1146,2232, # 3344
3532,2720,1696,2623,3827,6158,3129,1550,2698,1485,1297,1428, 637, 931,2721,2145, # 3360
 914,2550,2587,  81,2450, 612, 827,2646,1242,4655,1118,2884, 472,1855,3181,3533, # 3376
3534, 569,1353,2699,1244,1758,2588,4119,2009,2762,2171,3709,1312,1531,6159,1152, # 3392
1938, 134,1830, 471,3710,2276,1112,1535,3323,3453,3535, 982,1337,2950, 488, 826, # 3408
 674,1058,1628,4120,2017, 522,2399, 211, 568,1367,3454, 350, 293,1872,1139,3249, # 3424
1399,1946,3006,1300,2360,3324, 588, 736,6160,2606, 744, 669,3536,3828,6161,1358, # 3440
 199, 723, 848, 933, 851,1939,1505,1514,1338,1618,1831,4656,1634,3613, 443,2740, # 3456
3829, 717,1947, 491,1914,6162,2551,1542,4121,1025,6163,1099,1223, 198,3040,2722, # 3472
 370, 410,1905,2589, 998,1248,3182,2380, 519,1449,4122,1710, 947, 928,1153,4341, # 3488
2277, 344,2624,1511, 615, 105, 161,1212,1076,1960,3130,2054,1926,1175,1906,2473, # 3504
 414,1873,2801,6164,2309, 315,1319,3325, 318,2018,2146,2157, 963, 631, 223,4342, # 3520
4343,2675, 479,3711,1197,2625,3712,2676,2361,6165,4344,4123,6166,2451,3183,1886, # 3536
2184,1674,1330,1711,1635,1506, 799, 219,3250,3083,3954,1677,3713,3326,2081,3614, # 3552
1652,2073,4657,1147,3041,1752, 643,1961, 147,1974,3955,6167,1716,2037, 918,3007, # 3568
1994, 120,1537, 118, 609,3184,4345, 740,3455,1219, 332,1615,3830,6168,1621,2980, # 3584
1582, 783, 212, 553,2350,3714,1349,2433,2082,4124, 889,6169,2310,1275,1410, 973, # 3600
 166,1320,3456,1797,1215,3185,2885,1846,2590,2763,4658, 629, 822,3008, 763, 940, # 3616
1990,2862, 439,2409,1566,1240,1622, 926,1282,1907,2764, 654,2210,1607, 327,1130, # 3632
3956,1678,1623,6170,2434,2192, 686, 608,3831,3715, 903,3957,3042,6171,2741,1522, # 3648
1915,1105,1555,2552,1359, 323,3251,4346,3457, 738,1354,2553,2311,2334,1828,2003, # 3664
3832,1753,2351,1227,6172,1887,4125,1478,6173,2410,1874,1712,1847, 520,1204,2607, # 3680
 264,4659, 836,2677,2102, 600,4660,3833,2278,3084,6174,4347,3615,1342, 640, 532, # 3696
 543,2608,1888,2400,2591,1009,4348,1497, 341,1737,3616,2723,1394, 529,3252,1321, # 3712
 983,4661,1515,2120, 971,2592, 924, 287,1662,3186,4349,2700,4350,1519, 908,1948, # 3728
2452, 156, 796,1629,1486,2223,2055, 694,4126,1259,1036,3392,1213,2249,2742,1889, # 3744
1230,3958,1015, 910, 408, 559,3617,4662, 746, 725, 935,4663,3959,3009,1289, 563, # 3760
 867,4664,3960,1567,2981,2038,2626, 988,2263,2381,4351, 143,2374, 704,1895,6175, # 3776
1188,3716,2088, 673,3085,2362,4352, 484,1608,1921,2765,2918, 215, 904,3618,3537, # 3792
 894, 509, 976,3043,2701,3961,4353,2837,2982, 498,6176,6177,1102,3538,1332,3393, # 3808
1487,1636,1637, 233, 245,3962, 383, 650, 995,3044, 460,1520,1206,2352, 749,3327, # 3824
 530, 700, 389,1438,1560,1773,3963,2264, 719,2951,2724,3834, 870,1832,1644,1000, # 3840
 839,2474,3717, 197,1630,3394, 365,2886,3964,1285,2133, 734, 922, 818,1106, 732, # 3856
 480,2083,1774,3458, 923,2279,1350, 221,3086,  85,2233,2234,3835,1585,3010,2147, # 3872
1387,1705,2382,1619,2475, 133, 239,2802,1991,1016,2084,2383, 411,2838,1113, 651, # 3888
1985,1160,3328, 990,1863,3087,1048,1276,2647, 265,2627,1599,3253,2056, 150, 638, # 3904
2019, 656, 853, 326,1479, 680,1439,4354,1001,1759, 413,3459,3395,2492,1431, 459, # 3920
4355,1125,3329,2265,1953,1450,2065,2863, 849, 351,2678,3131,3254,3255,1104,1577, # 3936
 227,1351,1645,2453,2193,1421,2887, 812,2121, 634,  95,2435, 201,2312,4665,1646, # 3952
1671,2743,1601,2554,2702,2648,2280,1315,1366,2089,3132,1573,3718,3965,1729,1189, # 3968
 328,2679,1077,1940,1136, 558,1283, 964,1195, 621,2074,1199,1743,3460,3619,1896, # 3984
1916,1890,3836,2952,1154,2112,1064, 862, 378,3011,2066,2113,2803,1568,2839,6178, # 4000
3088,2919,1941,1660,2004,1992,2194, 142, 707,1590,1708,1624,1922,1023,1836,1233, # 4016
1004,2313, 789, 741,3620,6179,1609,2411,1200,4127,3719,3720,4666,2057,3721, 593, # 4032
2840, 367,2920,1878,6180,3461,1521, 628,1168, 692,2211,2649, 300, 720,2067,2571, # 4048
2953,3396, 959,2504,3966,3539,3462,1977, 701,6181, 954,1043, 800, 681, 183,3722, # 4064
1803,1730,3540,4128,2103, 815,2314, 174, 467, 230,2454,1093,2134, 755,3541,3397, # 4080
1141,1162,6182,1738,2039, 270,3256,2513,1005,1647,2185,3837, 858,1679,1897,1719, # 4096
2954,2324,1806, 402, 670, 167,4129,1498,2158,2104, 750,6183, 915, 189,1680,1551, # 4112
 455,4356,1501,2455, 405,1095,2955, 338,1586,1266,1819, 570, 641,1324, 237,1556, # 4128
2650,1388,3723,6184,1368,2384,1343,1978,3089,2436, 879,3724, 792,1191, 758,3012, # 4144
1411,2135,1322,4357, 240,4667,1848,3725,1574,6185, 420,3045,1546,1391, 714,4358, # 4160
1967, 941,1864, 863, 664, 426, 560,1731,2680,1785,2864,1949,2363, 403,3330,1415, # 4176
1279,2136,1697,2335, 204, 721,2097,3838,  90,6186,2085,2505, 191,3967, 124,2148, # 4192
1376,1798,1178,1107,1898,1405, 860,4359,1243,1272,2375,2983,1558,2456,1638, 113, # 4208
3621, 578,1923,2609, 880, 386,4130, 784,2186,2266,1422,2956,2172,1722, 497, 263, # 4224
2514,1267,2412,2610, 177,2703,3542, 774,1927,1344, 616,1432,1595,1018, 172,4360, # 4240
2325, 911,4361, 438,1468,3622, 794,3968,2024,2173,1681,1829,2957, 945, 895,3090, # 4256
 575,2212,2476, 475,2401,2681, 785,2744,1745,2293,2555,1975,3133,2865, 394,4668, # 4272
3839, 635,4131, 639, 202,1507,2195,2766,1345,1435,2572,3726,1908,1184,1181,2457, # 4288
3727,3134,4362, 843,2611, 437, 916,4669, 234, 769,1884,3046,3047,3623, 833,6187, # 4304
1639,2250,2402,1355,1185,2010,2047, 999, 525,1732,1290,1488,2612, 948,1578,3728, # 4320
2413,2477,1216,2725,2159, 334,3840,1328,3624,2921,1525,4132, 564,1056, 891,4363, # 4336
1444,1698,2385,2251,3729,1365,2281,2235,1717,6188, 864,3841,2515, 444, 527,2767, # 4352
2922,3625, 544, 461,6189, 566, 209,2437,3398,2098,1065,2068,3331,3626,3257,2137, # 4368  #last 512
#Everything below is of no interest for detection purpose
2138,2122,3730,2888,1995,1820,1044,6190,6191,6192,6193,6194,6195,6196,6197,6198, # 4384
6199,6200,6201,6202,6203,6204,6205,4670,6206,6207,6208,6209,6210,6211,6212,6213, # 4400
6214,6215,6216,6217,6218,6219,6220,6221,6222,6223,6224,6225,6226,6227,6228,6229, # 4416
6230,6231,6232,6233,6234,6235,6236,6237,3187,6238,6239,3969,6240,6241,6242,6243, # 4432
6244,4671,6245,6246,4672,6247,6248,4133,6249,6250,4364,6251,2923,2556,2613,4673, # 4448
4365,3970,6252,6253,6254,6255,4674,6256,6257,6258,2768,2353,4366,4675,4676,3188, # 4464
4367,3463,6259,4134,4677,4678,6260,2267,6261,3842,3332,4368,3543,6262,6263,6264, # 4480
3013,1954,1928,4135,4679,6265,6266,2478,3091,6267,4680,4369,6268,6269,1699,6270, # 4496
3544,4136,4681,6271,4137,6272,4370,2804,6273,6274,2593,3971,3972,4682,6275,2236, # 4512
4683,6276,6277,4684,6278,6279,4138,3973,4685,6280,6281,3258,6282,6283,6284,6285, # 4528
3974,4686,2841,3975,6286,6287,3545,6288,6289,4139,4687,4140,6290,4141,6291,4142, # 4544
6292,6293,3333,6294,6295,6296,4371,6297,3399,6298,6299,4372,3976,6300,6301,6302, # 4560
4373,6303,6304,3843,3731,6305,4688,4374,6306,6307,3259,2294,6308,3732,2530,4143, # 4576
6309,4689,6310,6311,6312,3048,6313,6314,4690,3733,2237,6315,6316,2282,3334,6317, # 4592
6318,3844,6319,6320,4691,6321,3400,4692,6322,4693,6323,3049,6324,4375,6325,3977, # 4608
6326,6327,6328,3546,6329,4694,3335,6330,4695,4696,6331,6332,6333,6334,4376,3978, # 4624
6335,4697,3979,4144,6336,3980,4698,6337,6338,6339,6340,6341,4699,4700,4701,6342, # 4640
6343,4702,6344,6345,4703,6346,6347,4704,6348,4705,4706,3135,6349,4707,6350,4708, # 4656
6351,4377,6352,4709,3734,4145,6353,2506,4710,3189,6354,3050,4711,3981,6355,3547, # 4672
3014,4146,4378,3735,2651,3845,3260,3136,2224,1986,6356,3401,6357,4712,2594,3627, # 4688
3137,2573,3736,3982,4713,3628,4714,4715,2682,3629,4716,6358,3630,4379,3631,6359, # 4704
6360,6361,3983,6362,6363,6364,6365,4147,3846,4717,6366,6367,3737,2842,6368,4718, # 4720
2628,6369,3261,6370,2386,6371,6372,3738,3984,4719,3464,4720,3402,6373,2924,3336, # 4736
4148,2866,6374,2805,3262,4380,2704,2069,2531,3138,2806,2984,6375,2769,6376,4721, # 4752
4722,3403,6377,6378,3548,6379,6380,2705,3092,1979,4149,2629,3337,2889,6381,3338, # 4768
4150,2557,3339,4381,6382,3190,3263,3739,6383,4151,4723,4152,2558,2574,3404,3191, # 4784
6384,6385,4153,6386,4724,4382,6387,6388,4383,6389,6390,4154,6391,4725,3985,6392, # 4800
3847,4155,6393,6394,6395,6396,6397,3465,6398,4384,6399,6400,6401,6402,6403,6404, # 4816
4156,6405,6406,6407,6408,2123,6409,6410,2326,3192,4726,6411,6412,6413,6414,4385, # 4832
4157,6415,6416,4158,6417,3093,3848,6418,3986,6419,6420,3849,6421,6422,6423,4159, # 4848
6424,6425,4160,6426,3740,6427,6428,6429,6430,3987,6431,4727,6432,2238,6433,6434, # 4864
4386,3988,6435,6436,3632,6437,6438,2843,6439,6440,6441,6442,3633,6443,2958,6444, # 4880
6445,3466,6446,2364,4387,3850,6447,4388,2959,3340,6448,3851,6449,4728,6450,6451, # 4896
3264,4729,6452,3193,6453,4389,4390,2706,3341,4730,6454,3139,6455,3194,6456,3051, # 4912
2124,3852,1602,4391,4161,3853,1158,3854,4162,3989,4392,3990,4731,4732,4393,2040, # 4928
4163,4394,3265,6457,2807,3467,3855,6458,6459,6460,3991,3468,4733,4734,6461,3140, # 4944
2960,6462,4735,6463,6464,6465,6466,4736,4737,4738,4739,6467,6468,4164,2403,3856, # 4960
6469,6470,2770,2844,6471,4740,6472,6473,6474,6475,6476,6477,6478,3195,6479,4741, # 4976
4395,6480,2867,6481,4742,2808,6482,2493,4165,6483,6484,6485,6486,2295,4743,6487, # 4992
6488,6489,3634,6490,6491,6492,6493,6494,6495,6496,2985,4744,6497,6498,4745,6499, # 5008
6500,2925,3141,4166,6501,6502,4746,6503,6504,4747,6505,6506,6507,2890,6508,6509, # 5024
6510,6511,6512,6513,6514,6515,6516,6517,6518,6519,3469,4167,6520,6521,6522,4748, # 5040
4396,3741,4397,4749,4398,3342,2125,4750,6523,4751,4752,4753,3052,6524,2961,4168, # 5056
6525,4754,6526,4755,4399,2926,4169,6527,3857,6528,4400,4170,6529,4171,6530,6531, # 5072
2595,6532,6533,6534,6535,3635,6536,6537,6538,6539,6540,6541,6542,4756,6543,6544, # 5088
6545,6546,6547,6548,4401,6549,6550,6551,6552,4402,3405,4757,4403,6553,6554,6555, # 5104
4172,3742,6556,6557,6558,3992,3636,6559,6560,3053,2726,6561,3549,4173,3054,4404, # 5120
6562,6563,3993,4405,3266,3550,2809,4406,6564,6565,6566,4758,4759,6567,3743,6568, # 5136
4760,3744,4761,3470,6569,6570,6571,4407,6572,3745,4174,6573,4175,2810,4176,3196, # 5152
4762,6574,4177,6575,6576,2494,2891,3551,6577,6578,3471,6579,4408,6580,3015,3197, # 5168
6581,3343,2532,3994,3858,6582,3094,3406,4409,6583,2892,4178,4763,4410,3016,4411, # 5184
6584,3995,3142,3017,2683,6585,4179,6586,6587,4764,4412,6588,6589,4413,6590,2986, # 5200
6591,2962,3552,6592,2963,3472,6593,6594,4180,4765,6595,6596,2225,3267,4414,6597, # 5216
3407,3637,4766,6598,6599,3198,6600,4415,6601,3859,3199,6602,3473,4767,2811,4416, # 5232
1856,3268,3200,2575,3996,3997,3201,4417,6603,3095,2927,6604,3143,6605,2268,6606, # 5248
3998,3860,3096,2771,6607,6608,3638,2495,4768,6609,3861,6610,3269,2745,4769,4181, # 5264
3553,6611,2845,3270,6612,6613,6614,3862,6615,6616,4770,4771,6617,3474,3999,4418, # 5280
4419,6618,3639,3344,6619,4772,4182,6620,2126,6621,6622,6623,4420,4773,6624,3018, # 5296
6625,4774,3554,6626,4183,2025,3746,6627,4184,2707,6628,4421,4422,3097,1775,4185, # 5312
3555,6629,6630,2868,6631,6632,4423,6633,6634,4424,2414,2533,2928,6635,4186,2387, # 5328
6636,4775,6637,4187,6638,1891,4425,3202,3203,6639,6640,4776,6641,3345,6642,6643, # 5344
3640,6644,3475,3346,3641,4000,6645,3144,6646,3098,2812,4188,3642,3204,6647,3863, # 5360
3476,6648,3864,6649,4426,4001,6650,6651,6652,2576,6653,4189,4777,6654,6655,6656, # 5376
2846,6657,3477,3205,4002,6658,4003,6659,3347,2252,6660,6661,6662,4778,6663,6664, # 5392
6665,6666,6667,6668,6669,4779,4780,2048,6670,3478,3099,6671,3556,3747,4004,6672, # 5408
6673,6674,3145,4005,3748,6675,6676,6677,6678,6679,3408,6680,6681,6682,6683,3206, # 5424
3207,6684,6685,4781,4427,6686,4782,4783,4784,6687,6688,6689,4190,6690,6691,3479, # 5440
6692,2746,6693,4428,6694,6695,6696,6697,6698,6699,4785,6700,6701,3208,2727,6702, # 5456
3146,6703,6704,3409,2196,6705,4429,6706,6707,6708,2534,1996,6709,6710,6711,2747, # 5472
6712,6713,6714,4786,3643,6715,4430,4431,6716,3557,6717,4432,4433,6718,6719,6720, # 5488
6721,3749,6722,4006,4787,6723,6724,3644,4788,4434,6725,6726,4789,2772,6727,6728, # 5504
6729,6730,6731,2708,3865,2813,4435,6732,6733,4790,4791,3480,6734,6735,6736,6737, # 5520
4436,3348,6738,3410,4007,6739,6740,4008,6741,6742,4792,3411,4191,6743,6744,6745, # 5536
6746,6747,3866,6748,3750,6749,6750,6751,6752,6753,6754,6755,3867,6756,4009,6757, # 5552
4793,4794,6758,2814,2987,6759,6760,6761,4437,6762,6763,6764,6765,3645,6766,6767, # 5568
3481,4192,6768,3751,6769,6770,2174,6771,3868,3752,6772,6773,6774,4193,4795,4438, # 5584
3558,4796,4439,6775,4797,6776,6777,4798,6778,4799,3559,4800,6779,6780,6781,3482, # 5600
6782,2893,6783,6784,4194,4801,4010,6785,6786,4440,6787,4011,6788,6789,6790,6791, # 5616
6792,6793,4802,6794,6795,6796,4012,6797,6798,6799,6800,3349,4803,3483,6801,4804, # 5632
4195,6802,4013,6803,6804,4196,6805,4014,4015,6806,2847,3271,2848,6807,3484,6808, # 5648
6809,6810,4441,6811,4442,4197,4443,3272,4805,6812,3412,4016,1579,6813,6814,4017, # 5664
6815,3869,6816,2964,6817,4806,6818,6819,4018,3646,6820,6821,4807,4019,4020,6822, # 5680
6823,3560,6824,6825,4021,4444,6826,4198,6827,6828,4445,6829,6830,4199,4808,6831, # 5696
6832,6833,3870,3019,2458,6834,3753,3413,3350,6835,4809,3871,4810,3561,4446,6836, # 5712
6837,4447,4811,4812,6838,2459,4448,6839,4449,6840,6841,4022,3872,6842,4813,4814, # 5728
6843,6844,4815,4200,4201,4202,6845,4023,6846,6847,4450,3562,3873,6848,6849,4816, # 5744
4817,6850,4451,4818,2139,6851,3563,6852,6853,3351,6854,6855,3352,4024,2709,3414, # 5760
4203,4452,6856,4204,6857,6858,3874,3875,6859,6860,4819,6861,6862,6863,6864,4453, # 5776
3647,6865,6866,4820,6867,6868,6869,6870,4454,6871,2869,6872,6873,4821,6874,3754, # 5792
6875,4822,4205,6876,6877,6878,3648,4206,4455,6879,4823,6880,4824,3876,6881,3055, # 5808
4207,6882,3415,6883,6884,6885,4208,4209,6886,4210,3353,6887,3354,3564,3209,3485, # 5824
2652,6888,2728,6889,3210,3755,6890,4025,4456,6891,4825,6892,6893,6894,6895,4211, # 5840
6896,6897,6898,4826,6899,6900,4212,6901,4827,6902,2773,3565,6903,4828,6904,6905, # 5856
6906,6907,3649,3650,6908,2849,3566,6909,3567,3100,6910,6911,6912,6913,6914,6915, # 5872
4026,6916,3355,4829,3056,4457,3756,6917,3651,6918,4213,3652,2870,6919,4458,6920, # 5888
2438,6921,6922,3757,2774,4830,6923,3356,4831,4832,6924,4833,4459,3653,2507,6925, # 5904
4834,2535,6926,6927,3273,4027,3147,6928,3568,6929,6930,6931,4460,6932,3877,4461, # 5920
2729,3654,6933,6934,6935,6936,2175,4835,2630,4214,4028,4462,4836,4215,6937,3148, # 5936
4216,4463,4837,4838,4217,6938,6939,2850,4839,6940,4464,6941,6942,6943,4840,6944, # 5952
4218,3274,4465,6945,6946,2710,6947,4841,4466,6948,6949,2894,6950,6951,4842,6952, # 5968
4219,3057,2871,6953,6954,6955,6956,4467,6957,2711,6958,6959,6960,3275,3101,4843, # 5984
6961,3357,3569,6962,4844,6963,6964,4468,4845,3570,6965,3102,4846,3758,6966,4847, # 6000
3878,4848,4849,4029,6967,2929,3879,4850,4851,6968,6969,1733,6970,4220,6971,6972, # 6016
6973,6974,6975,6976,4852,6977,6978,6979,6980,6981,6982,3759,6983,6984,6985,3486, # 6032
3487,6986,3488,3416,6987,6988,6989,6990,6991,6992,6993,6994,6995,6996,6997,4853, # 6048
6998,6999,4030,7000,7001,3211,7002,7003,4221,7004,7005,3571,4031,7006,3572,7007, # 6064
2614,4854,2577,7008,7009,2965,3655,3656,4855,2775,3489,3880,4222,4856,3881,4032, # 6080
3882,3657,2730,3490,4857,7010,3149,7011,4469,4858,2496,3491,4859,2283,7012,7013, # 6096
7014,2365,4860,4470,7015,7016,3760,7017,7018,4223,1917,7019,7020,7021,4471,7022, # 6112
2776,4472,7023,7024,7025,7026,4033,7027,3573,4224,4861,4034,4862,7028,7029,1929, # 6128
3883,4035,7030,4473,3058,7031,2536,3761,3884,7032,4036,7033,2966,2895,1968,4474, # 6144
3276,4225,3417,3492,4226,2105,7034,7035,1754,2596,3762,4227,4863,4475,3763,4864, # 6160
3764,2615,2777,3103,3765,3658,3418,4865,2296,3766,2815,7036,7037,7038,3574,2872, # 6176
3277,4476,7039,4037,4477,7040,7041,4038,7042,7043,7044,7045,7046,7047,2537,7048, # 6192
7049,7050,7051,7052,7053,7054,4478,7055,7056,3767,3659,4228,3575,7057,7058,4229, # 6208
7059,7060,7061,3660,7062,3212,7063,3885,4039,2460,7064,7065,7066,7067,7068,7069, # 6224
7070,7071,7072,7073,7074,4866,3768,4867,7075,7076,7077,7078,4868,3358,3278,2653, # 6240
7079,7080,4479,3886,7081,7082,4869,7083,7084,7085,7086,7087,7088,2538,7089,7090, # 6256
7091,4040,3150,3769,4870,4041,2896,3359,4230,2930,7092,3279,7093,2967,4480,3213, # 6272
4481,3661,7094,7095,7096,7097,7098,7099,7100,7101,7102,2461,3770,7103,7104,4231, # 6288
3151,7105,7106,7107,4042,3662,7108,7109,4871,3663,4872,4043,3059,7110,7111,7112, # 6304
3493,2988,7113,4873,7114,7115,7116,3771,4874,7117,7118,4232,4875,7119,3576,2336, # 6320
4876,7120,4233,3419,4044,4877,4878,4482,4483,4879,4484,4234,7121,3772,4880,1045, # 6336
3280,3664,4881,4882,7122,7123,7124,7125,4883,7126,2778,7127,4485,4486,7128,4884, # 6352
3214,3887,7129,7130,3215,7131,4885,4045,7132,7133,4046,7134,7135,7136,7137,7138, # 6368
7139,7140,7141,7142,7143,4235,7144,4886,7145,7146,7147,4887,7148,7149,7150,4487, # 6384
4047,4488,7151,7152,4888,4048,2989,3888,7153,3665,7154,4049,7155,7156,7157,7158, # 6400
7159,7160,2931,4889,4890,4489,7161,2631,3889,4236,2779,7162,7163,4891,7164,3060, # 6416
7165,1672,4892,7166,4893,4237,3281,4894,7167,7168,3666,7169,3494,7170,7171,4050, # 6432
7172,7173,3104,3360,3420,4490,4051,2684,4052,7174,4053,7175,7176,7177,2253,4054, # 6448
7178,7179,4895,7180,3152,3890,3153,4491,3216,7181,7182,7183,2968,4238,4492,4055, # 6464
7184,2990,7185,2479,7186,7187,4493,7188,7189,7190,7191,7192,4896,7193,4897,2969, # 6480
4494,4898,7194,3495,7195,7196,4899,4495,7197,3105,2731,7198,4900,7199,7200,7201, # 6496
4056,7202,3361,7203,7204,4496,4901,4902,7205,4497,7206,7207,2315,4903,7208,4904, # 6512
7209,4905,2851,7210,7211,3577,7212,3578,4906,7213,4057,3667,4907,7214,4058,2354, # 6528
3891,2376,3217,3773,7215,7216,7217,7218,7219,4498,7220,4908,3282,2685,7221,3496, # 6544
4909,2632,3154,4910,7222,2337,7223,4911,7224,7225,7226,4912,4913,3283,4239,4499, # 6560
7227,2816,7228,7229,7230,7231,7232,7233,7234,4914,4500,4501,7235,7236,7237,2686, # 6576
7238,4915,7239,2897,4502,7240,4503,7241,2516,7242,4504,3362,3218,7243,7244,7245, # 6592
4916,7246,7247,4505,3363,7248,7249,7250,7251,3774,4506,7252,7253,4917,7254,7255, # 6608
3284,2991,4918,4919,3219,3892,4920,3106,3497,4921,7256,7257,7258,4922,7259,4923, # 6624
3364,4507,4508,4059,7260,4240,3498,7261,7262,4924,7263,2992,3893,4060,3220,7264, # 6640
7265,7266,7267,7268,7269,4509,3775,7270,2817,7271,4061,4925,4510,3776,7272,4241, # 6656
4511,3285,7273,7274,3499,7275,7276,7277,4062,4512,4926,7278,3107,3894,7279,7280, # 6672
4927,7281,4513,7282,7283,3668,7284,7285,4242,4514,4243,7286,2058,4515,4928,4929, # 6688
4516,7287,3286,4244,7288,4517,7289,7290,7291,3669,7292,7293,4930,4931,4932,2355, # 6704
4933,7294,2633,4518,7295,4245,7296,7297,4519,7298,7299,4520,4521,4934,7300,4246, # 6720
4522,7301,7302,7303,3579,7304,4247,4935,7305,4936,7306,7307,7308,7309,3777,7310, # 6736
4523,7311,7312,7313,4248,3580,7314,4524,3778,4249,7315,3581,7316,3287,7317,3221, # 6752
7318,4937,7319,7320,7321,7322,7323,7324,4938,4939,7325,4525,7326,7327,7328,4063, # 6768
7329,7330,4940,7331,7332,4941,7333,4526,7334,3500,2780,1741,4942,2026,1742,7335, # 6784
7336,3582,4527,2388,7337,7338,7339,4528,7340,4250,4943,7341,7342,7343,4944,7344, # 6800
7345,7346,3020,7347,4945,7348,7349,7350,7351,3895,7352,3896,4064,3897,7353,7354, # 6816
7355,4251,7356,7357,3898,7358,3779,7359,3780,3288,7360,7361,4529,7362,4946,4530, # 6832
2027,7363,3899,4531,4947,3222,3583,7364,4948,7365,7366,7367,7368,4949,3501,4950, # 6848
3781,4951,4532,7369,2517,4952,4252,4953,3155,7370,4954,4955,4253,2518,4533,7371, # 6864
7372,2712,4254,7373,7374,7375,3670,4956,3671,7376,2389,3502,4065,7377,2338,7378, # 6880
7379,7380,7381,3061,7382,4957,7383,7384,7385,7386,4958,4534,7387,7388,2993,7389, # 6896
3062,7390,4959,7391,7392,7393,4960,3108,4961,7394,4535,7395,4962,3421,4536,7396, # 6912
4963,7397,4964,1857,7398,4965,7399,7400,2176,3584,4966,7401,7402,3422,4537,3900, # 6928
3585,7403,3782,7404,2852,7405,7406,7407,4538,3783,2654,3423,4967,4539,7408,3784, # 6944
3586,2853,4540,4541,7409,3901,7410,3902,7411,7412,3785,3109,2327,3903,7413,7414, # 6960
2970,4066,2932,7415,7416,7417,3904,3672,3424,7418,4542,4543,4544,7419,4968,7420, # 6976
7421,4255,7422,7423,7424,7425,7426,4067,7427,3673,3365,4545,7428,3110,2559,3674, # 6992
7429,7430,3156,7431,7432,3503,7433,3425,4546,7434,3063,2873,7435,3223,4969,4547, # 7008
4548,2898,4256,4068,7436,4069,3587,3786,2933,3787,4257,4970,4971,3788,7437,4972, # 7024
3064,7438,4549,7439,7440,7441,7442,7443,4973,3905,7444,2874,7445,7446,7447,7448, # 7040
3021,7449,4550,3906,3588,4974,7450,7451,3789,3675,7452,2578,7453,4070,7454,7455, # 7056
7456,4258,3676,7457,4975,7458,4976,4259,3790,3504,2634,4977,3677,4551,4260,7459, # 7072
7460,7461,7462,3907,4261,4978,7463,7464,7465,7466,4979,4980,7467,7468,2213,4262, # 7088
7469,7470,7471,3678,4981,7472,2439,7473,4263,3224,3289,7474,3908,2415,4982,7475, # 7104
4264,7476,4983,2655,7477,7478,2732,4552,2854,2875,7479,7480,4265,7481,4553,4984, # 7120
7482,7483,4266,7484,3679,3366,3680,2818,2781,2782,3367,3589,4554,3065,7485,4071, # 7136
2899,7486,7487,3157,2462,4072,4555,4073,4985,4986,3111,4267,2687,3368,4556,4074, # 7152
3791,4268,7488,3909,2783,7489,2656,1962,3158,4557,4987,1963,3159,3160,7490,3112, # 7168
4988,4989,3022,4990,4991,3792,2855,7491,7492,2971,4558,7493,7494,4992,7495,7496, # 7184
7497,7498,4993,7499,3426,4559,4994,7500,3681,4560,4269,4270,3910,7501,4075,4995, # 7200
4271,7502,7503,4076,7504,4996,7505,3225,4997,4272,4077,2819,3023,7506,7507,2733, # 7216
4561,7508,4562,7509,3369,3793,7510,3590,2508,7511,7512,4273,3113,2994,2616,7513, # 7232
7514,7515,7516,7517,7518,2820,3911,4078,2748,7519,7520,4563,4998,7521,7522,7523, # 7248
7524,4999,4274,7525,4564,3682,2239,4079,4565,7526,7527,7528,7529,5000,7530,7531, # 7264
5001,4275,3794,7532,7533,7534,3066,5002,4566,3161,7535,7536,4080,7537,3162,7538, # 7280
7539,4567,7540,7541,7542,7543,7544,7545,5003,7546,4568,7547,7548,7549,7550,7551, # 7296
7552,7553,7554,7555,7556,5004,7557,7558,7559,5005,7560,3795,7561,4569,7562,7563, # 7312
7564,2821,3796,4276,4277,4081,7565,2876,7566,5006,7567,7568,2900,7569,3797,3912, # 7328
7570,7571,7572,4278,7573,7574,7575,5007,7576,7577,5008,7578,7579,4279,2934,7580, # 7344
7581,5009,7582,4570,7583,4280,7584,7585,7586,4571,4572,3913,7587,4573,3505,7588, # 7360
5010,7589,7590,7591,7592,3798,4574,7593,7594,5011,7595,4281,7596,7597,7598,4282, # 7376
5012,7599,7600,5013,3163,7601,5014,7602,3914,7603,7604,2734,4575,4576,4577,7605, # 7392
7606,7607,7608,7609,3506,5015,4578,7610,4082,7611,2822,2901,2579,3683,3024,4579, # 7408
3507,7612,4580,7613,3226,3799,5016,7614,7615,7616,7617,7618,7619,7620,2995,3290, # 7424
7621,4083,7622,5017,7623,7624,7625,7626,7627,4581,3915,7628,3291,7629,5018,7630, # 7440
7631,7632,7633,4084,7634,7635,3427,3800,7636,7637,4582,7638,5019,4583,5020,7639, # 7456
3916,7640,3801,5021,4584,4283,7641,7642,3428,3591,2269,7643,2617,7644,4585,3592, # 7472
7645,4586,2902,7646,7647,3227,5022,7648,4587,7649,4284,7650,7651,7652,4588,2284, # 7488
7653,5023,7654,7655,7656,4589,5024,3802,7657,7658,5025,3508,4590,7659,7660,7661, # 7504
1969,5026,7662,7663,3684,1821,2688,7664,2028,2509,4285,7665,2823,1841,7666,2689, # 7520
3114,7667,3917,4085,2160,5027,5028,2972,7668,5029,7669,7670,7671,3593,4086,7672, # 7536
4591,4087,5030,3803,7673,7674,7675,7676,7677,7678,7679,4286,2366,4592,4593,3067, # 7552
2328,7680,7681,4594,3594,3918,2029,4287,7682,5031,3919,3370,4288,4595,2856,7683, # 7568
3509,7684,7685,5032,5033,7686,7687,3804,2784,7688,7689,7690,7691,3371,7692,7693, # 7584
2877,5034,7694,7695,3920,4289,4088,7696,7697,7698,5035,7699,5036,4290,5037,5038, # 7600
5039,7700,7701,7702,5040,5041,3228,7703,1760,7704,5042,3229,4596,2106,4089,7705, # 7616
4597,2824,5043,2107,3372,7706,4291,4090,5044,7707,4091,7708,5045,3025,3805,4598, # 7632
4292,4293,4294,3373,7709,4599,7710,5046,7711,7712,5047,5048,3806,7713,7714,7715, # 7648
5049,7716,7717,7718,7719,4600,5050,7720,7721,7722,5051,7723,4295,3429,7724,7725, # 7664
7726,7727,3921,7728,3292,5052,4092,7729,7730,7731,7732,7733,7734,7735,5053,5054, # 7680
7736,7737,7738,7739,3922,3685,7740,7741,7742,7743,2635,5055,7744,5056,4601,7745, # 7696
7746,2560,7747,7748,7749,7750,3923,7751,7752,7753,7754,7755,4296,2903,7756,7757, # 7712
7758,7759,7760,3924,7761,5057,4297,7762,7763,5058,4298,7764,4093,7765,7766,5059, # 7728
3925,7767,7768,7769,7770,7771,7772,7773,7774,7775,7776,3595,7777,4299,5060,4094, # 7744
7778,3293,5061,7779,7780,4300,7781,7782,4602,7783,3596,7784,7785,3430,2367,7786, # 7760
3164,5062,5063,4301,7787,7788,4095,5064,5065,7789,3374,3115,7790,7791,7792,7793, # 7776
7794,7795,7796,3597,4603,7797,7798,3686,3116,3807,5066,7799,7800,5067,7801,7802, # 7792
4604,4302,5068,4303,4096,7803,7804,3294,7805,7806,5069,4605,2690,7807,3026,7808, # 7808
7809,7810,7811,7812,7813,7814,7815,7816,7817,7818,7819,7820,7821,7822,7823,7824, # 7824
7825,7826,7827,7828,7829,7830,7831,7832,7833,7834,7835,7836,7837,7838,7839,7840, # 7840
7841,7842,7843,7844,7845,7846,7847,7848,7849,7850,7851,7852,7853,7854,7855,7856, # 7856
7857,7858,7859,7860,7861,7862,7863,7864,7865,7866,7867,7868,7869,7870,7871,7872, # 7872
7873,7874,7875,7876,7877,7878,7879,7880,7881,7882,7883,7884,7885,7886,7887,7888, # 7888
7889,7890,7891,7892,7893,7894,7895,7896,7897,7898,7899,7900,7901,7902,7903,7904, # 7904
7905,7906,7907,7908,7909,7910,7911,7912,7913,7914,7915,7916,7917,7918,7919,7920, # 7920
7921,7922,7923,7924,3926,7925,7926,7927,7928,7929,7930,7931,7932,7933,7934,7935, # 7936
7936,7937,7938,7939,7940,7941,7942,7943,7944,7945,7946,7947,7948,7949,7950,7951, # 7952
7952,7953,7954,7955,7956,7957,7958,7959,7960,7961,7962,7963,7964,7965,7966,7967, # 7968
7968,7969,7970,7971,7972,7973,7974,7975,7976,7977,7978,7979,7980,7981,7982,7983, # 7984
7984,7985,7986,7987,7988,7989,7990,7991,7992,7993,7994,7995,7996,7997,7998,7999, # 8000
8000,8001,8002,8003,8004,8005,8006,8007,8008,8009,8010,8011,8012,8013,8014,8015, # 8016
8016,8017,8018,8019,8020,8021,8022,8023,8024,8025,8026,8027,8028,8029,8030,8031, # 8032
8032,8033,8034,8035,8036,8037,8038,8039,8040,8041,8042,8043,8044,8045,8046,8047, # 8048
8048,8049,8050,8051,8052,8053,8054,8055,8056,8057,8058,8059,8060,8061,8062,8063, # 8064
8064,8065,8066,8067,8068,8069,8070,8071,8072,8073,8074,8075,8076,8077,8078,8079, # 8080
8080,8081,8082,8083,8084,8085,8086,8087,8088,8089,8090,8091,8092,8093,8094,8095, # 8096
8096,8097,8098,8099,8100,8101,8102,8103,8104,8105,8106,8107,8108,8109,8110,8111, # 8112
8112,8113,8114,8115,8116,8117,8118,8119,8120,8121,8122,8123,8124,8125,8126,8127, # 8128
8128,8129,8130,8131,8132,8133,8134,8135,8136,8137,8138,8139,8140,8141,8142,8143, # 8144
8144,8145,8146,8147,8148,8149,8150,8151,8152,8153,8154,8155,8156,8157,8158,8159, # 8160
8160,8161,8162,8163,8164,8165,8166,8167,8168,8169,8170,8171,8172,8173,8174,8175, # 8176
8176,8177,8178,8179,8180,8181,8182,8183,8184,8185,8186,8187,8188,8189,8190,8191, # 8192
8192,8193,8194,8195,8196,8197,8198,8199,8200,8201,8202,8203,8204,8205,8206,8207, # 8208
8208,8209,8210,8211,8212,8213,8214,8215,8216,8217,8218,8219,8220,8221,8222,8223, # 8224
8224,8225,8226,8227,8228,8229,8230,8231,8232,8233,8234,8235,8236,8237,8238,8239, # 8240
8240,8241,8242,8243,8244,8245,8246,8247,8248,8249,8250,8251,8252,8253,8254,8255, # 8256
8256,8257,8258,8259,8260,8261,8262,8263,8264,8265,8266,8267,8268,8269,8270,8271) # 8272

########NEW FILE########
__FILENAME__ = jpcntx
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants

NUM_OF_CATEGORY = 6
DONT_KNOW = -1
ENOUGH_REL_THRESHOLD = 100
MAX_REL_THRESHOLD = 1000
MINIMUM_DATA_THRESHOLD = 4

# This is hiragana 2-char sequence table, the number in each cell represents its frequency category
jp2CharContext = ( \
(0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1),
(2,4,0,4,0,3,0,4,0,3,4,4,4,2,4,3,3,4,3,2,3,3,4,2,3,3,3,2,4,1,4,3,3,1,5,4,3,4,3,4,3,5,3,0,3,5,4,2,0,3,1,0,3,3,0,3,3,0,1,1,0,4,3,0,3,3,0,4,0,2,0,3,5,5,5,5,4,0,4,1,0,3,4),
(0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2),
(0,4,0,5,0,5,0,4,0,4,5,4,4,3,5,3,5,1,5,3,4,3,4,4,3,4,3,3,4,3,5,4,4,3,5,5,3,5,5,5,3,5,5,3,4,5,5,3,1,3,2,0,3,4,0,4,2,0,4,2,1,5,3,2,3,5,0,4,0,2,0,5,4,4,5,4,5,0,4,0,0,4,4),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,3,0,4,0,3,0,3,0,4,5,4,3,3,3,3,4,3,5,4,4,3,5,4,4,3,4,3,4,4,4,4,5,3,4,4,3,4,5,5,4,5,5,1,4,5,4,3,0,3,3,1,3,3,0,4,4,0,3,3,1,5,3,3,3,5,0,4,0,3,0,4,4,3,4,3,3,0,4,1,1,3,4),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,4,0,3,0,3,0,4,0,3,4,4,3,2,2,1,2,1,3,1,3,3,3,3,3,4,3,1,3,3,5,3,3,0,4,3,0,5,4,3,3,5,4,4,3,4,4,5,0,1,2,0,1,2,0,2,2,0,1,0,0,5,2,2,1,4,0,3,0,1,0,4,4,3,5,4,3,0,2,1,0,4,3),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,3,0,5,0,4,0,2,1,4,4,2,4,1,4,2,4,2,4,3,3,3,4,3,3,3,3,1,4,2,3,3,3,1,4,4,1,1,1,4,3,3,2,0,2,4,3,2,0,3,3,0,3,1,1,0,0,0,3,3,0,4,2,2,3,4,0,4,0,3,0,4,4,5,3,4,4,0,3,0,0,1,4),
(1,4,0,4,0,4,0,4,0,3,5,4,4,3,4,3,5,4,3,3,4,3,5,4,4,4,4,3,4,2,4,3,3,1,5,4,3,2,4,5,4,5,5,4,4,5,4,4,0,3,2,2,3,3,0,4,3,1,3,2,1,4,3,3,4,5,0,3,0,2,0,4,5,5,4,5,4,0,4,0,0,5,4),
(0,5,0,5,0,4,0,3,0,4,4,3,4,3,3,3,4,0,4,4,4,3,4,3,4,3,3,1,4,2,4,3,4,0,5,4,1,4,5,4,4,5,3,2,4,3,4,3,2,4,1,3,3,3,2,3,2,0,4,3,3,4,3,3,3,4,0,4,0,3,0,4,5,4,4,4,3,0,4,1,0,1,3),
(0,3,1,4,0,3,0,2,0,3,4,4,3,1,4,2,3,3,4,3,4,3,4,3,4,4,3,2,3,1,5,4,4,1,4,4,3,5,4,4,3,5,5,4,3,4,4,3,1,2,3,1,2,2,0,3,2,0,3,1,0,5,3,3,3,4,3,3,3,3,4,4,4,4,5,4,2,0,3,3,2,4,3),
(0,2,0,3,0,1,0,1,0,0,3,2,0,0,2,0,1,0,2,1,3,3,3,1,2,3,1,0,1,0,4,2,1,1,3,3,0,4,3,3,1,4,3,3,0,3,3,2,0,0,0,0,1,0,0,2,0,0,0,0,0,4,1,0,2,3,2,2,2,1,3,3,3,4,4,3,2,0,3,1,0,3,3),
(0,4,0,4,0,3,0,3,0,4,4,4,3,3,3,3,3,3,4,3,4,2,4,3,4,3,3,2,4,3,4,5,4,1,4,5,3,5,4,5,3,5,4,0,3,5,5,3,1,3,3,2,2,3,0,3,4,1,3,3,2,4,3,3,3,4,0,4,0,3,0,4,5,4,4,5,3,0,4,1,0,3,4),
(0,2,0,3,0,3,0,0,0,2,2,2,1,0,1,0,0,0,3,0,3,0,3,0,1,3,1,0,3,1,3,3,3,1,3,3,3,0,1,3,1,3,4,0,0,3,1,1,0,3,2,0,0,0,0,1,3,0,1,0,0,3,3,2,0,3,0,0,0,0,0,3,4,3,4,3,3,0,3,0,0,2,3),
(2,3,0,3,0,2,0,1,0,3,3,4,3,1,3,1,1,1,3,1,4,3,4,3,3,3,0,0,3,1,5,4,3,1,4,3,2,5,5,4,4,4,4,3,3,4,4,4,0,2,1,1,3,2,0,1,2,0,0,1,0,4,1,3,3,3,0,3,0,1,0,4,4,4,5,5,3,0,2,0,0,4,4),
(0,2,0,1,0,3,1,3,0,2,3,3,3,0,3,1,0,0,3,0,3,2,3,1,3,2,1,1,0,0,4,2,1,0,2,3,1,4,3,2,0,4,4,3,1,3,1,3,0,1,0,0,1,0,0,0,1,0,0,0,0,4,1,1,1,2,0,3,0,0,0,3,4,2,4,3,2,0,1,0,0,3,3),
(0,1,0,4,0,5,0,4,0,2,4,4,2,3,3,2,3,3,5,3,3,3,4,3,4,2,3,0,4,3,3,3,4,1,4,3,2,1,5,5,3,4,5,1,3,5,4,2,0,3,3,0,1,3,0,4,2,0,1,3,1,4,3,3,3,3,0,3,0,1,0,3,4,4,4,5,5,0,3,0,1,4,5),
(0,2,0,3,0,3,0,0,0,2,3,1,3,0,4,0,1,1,3,0,3,4,3,2,3,1,0,3,3,2,3,1,3,0,2,3,0,2,1,4,1,2,2,0,0,3,3,0,0,2,0,0,0,1,0,0,0,0,2,2,0,3,2,1,3,3,0,2,0,2,0,0,3,3,1,2,4,0,3,0,2,2,3),
(2,4,0,5,0,4,0,4,0,2,4,4,4,3,4,3,3,3,1,2,4,3,4,3,4,4,5,0,3,3,3,3,2,0,4,3,1,4,3,4,1,4,4,3,3,4,4,3,1,2,3,0,4,2,0,4,1,0,3,3,0,4,3,3,3,4,0,4,0,2,0,3,5,3,4,5,2,0,3,0,0,4,5),
(0,3,0,4,0,1,0,1,0,1,3,2,2,1,3,0,3,0,2,0,2,0,3,0,2,0,0,0,1,0,1,1,0,0,3,1,0,0,0,4,0,3,1,0,2,1,3,0,0,0,0,0,0,3,0,0,0,0,0,0,0,4,2,2,3,1,0,3,0,0,0,1,4,4,4,3,0,0,4,0,0,1,4),
(1,4,1,5,0,3,0,3,0,4,5,4,4,3,5,3,3,4,4,3,4,1,3,3,3,3,2,1,4,1,5,4,3,1,4,4,3,5,4,4,3,5,4,3,3,4,4,4,0,3,3,1,2,3,0,3,1,0,3,3,0,5,4,4,4,4,4,4,3,3,5,4,4,3,3,5,4,0,3,2,0,4,4),
(0,2,0,3,0,1,0,0,0,1,3,3,3,2,4,1,3,0,3,1,3,0,2,2,1,1,0,0,2,0,4,3,1,0,4,3,0,4,4,4,1,4,3,1,1,3,3,1,0,2,0,0,1,3,0,0,0,0,2,0,0,4,3,2,4,3,5,4,3,3,3,4,3,3,4,3,3,0,2,1,0,3,3),
(0,2,0,4,0,3,0,2,0,2,5,5,3,4,4,4,4,1,4,3,3,0,4,3,4,3,1,3,3,2,4,3,0,3,4,3,0,3,4,4,2,4,4,0,4,5,3,3,2,2,1,1,1,2,0,1,5,0,3,3,2,4,3,3,3,4,0,3,0,2,0,4,4,3,5,5,0,0,3,0,2,3,3),
(0,3,0,4,0,3,0,1,0,3,4,3,3,1,3,3,3,0,3,1,3,0,4,3,3,1,1,0,3,0,3,3,0,0,4,4,0,1,5,4,3,3,5,0,3,3,4,3,0,2,0,1,1,1,0,1,3,0,1,2,1,3,3,2,3,3,0,3,0,1,0,1,3,3,4,4,1,0,1,2,2,1,3),
(0,1,0,4,0,4,0,3,0,1,3,3,3,2,3,1,1,0,3,0,3,3,4,3,2,4,2,0,1,0,4,3,2,0,4,3,0,5,3,3,2,4,4,4,3,3,3,4,0,1,3,0,0,1,0,0,1,0,0,0,0,4,2,3,3,3,0,3,0,0,0,4,4,4,5,3,2,0,3,3,0,3,5),
(0,2,0,3,0,0,0,3,0,1,3,0,2,0,0,0,1,0,3,1,1,3,3,0,0,3,0,0,3,0,2,3,1,0,3,1,0,3,3,2,0,4,2,2,0,2,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,2,1,2,0,1,0,1,0,0,0,1,3,1,2,0,0,0,1,0,0,1,4),
(0,3,0,3,0,5,0,1,0,2,4,3,1,3,3,2,1,1,5,2,1,0,5,1,2,0,0,0,3,3,2,2,3,2,4,3,0,0,3,3,1,3,3,0,2,5,3,4,0,3,3,0,1,2,0,2,2,0,3,2,0,2,2,3,3,3,0,2,0,1,0,3,4,4,2,5,4,0,3,0,0,3,5),
(0,3,0,3,0,3,0,1,0,3,3,3,3,0,3,0,2,0,2,1,1,0,2,0,1,0,0,0,2,1,0,0,1,0,3,2,0,0,3,3,1,2,3,1,0,3,3,0,0,1,0,0,0,0,0,2,0,0,0,0,0,2,3,1,2,3,0,3,0,1,0,3,2,1,0,4,3,0,1,1,0,3,3),
(0,4,0,5,0,3,0,3,0,4,5,5,4,3,5,3,4,3,5,3,3,2,5,3,4,4,4,3,4,3,4,5,5,3,4,4,3,4,4,5,4,4,4,3,4,5,5,4,2,3,4,2,3,4,0,3,3,1,4,3,2,4,3,3,5,5,0,3,0,3,0,5,5,5,5,4,4,0,4,0,1,4,4),
(0,4,0,4,0,3,0,3,0,3,5,4,4,2,3,2,5,1,3,2,5,1,4,2,3,2,3,3,4,3,3,3,3,2,5,4,1,3,3,5,3,4,4,0,4,4,3,1,1,3,1,0,2,3,0,2,3,0,3,0,0,4,3,1,3,4,0,3,0,2,0,4,4,4,3,4,5,0,4,0,0,3,4),
(0,3,0,3,0,3,1,2,0,3,4,4,3,3,3,0,2,2,4,3,3,1,3,3,3,1,1,0,3,1,4,3,2,3,4,4,2,4,4,4,3,4,4,3,2,4,4,3,1,3,3,1,3,3,0,4,1,0,2,2,1,4,3,2,3,3,5,4,3,3,5,4,4,3,3,0,4,0,3,2,2,4,4),
(0,2,0,1,0,0,0,0,0,1,2,1,3,0,0,0,0,0,2,0,1,2,1,0,0,1,0,0,0,0,3,0,0,1,0,1,1,3,1,0,0,0,1,1,0,1,1,0,0,0,0,0,2,0,0,0,0,0,0,0,0,1,1,2,2,0,3,4,0,0,0,1,1,0,0,1,0,0,0,0,0,1,1),
(0,1,0,0,0,1,0,0,0,0,4,0,4,1,4,0,3,0,4,0,3,0,4,0,3,0,3,0,4,1,5,1,4,0,0,3,0,5,0,5,2,0,1,0,0,0,2,1,4,0,1,3,0,0,3,0,0,3,1,1,4,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0),
(1,4,0,5,0,3,0,2,0,3,5,4,4,3,4,3,5,3,4,3,3,0,4,3,3,3,3,3,3,2,4,4,3,1,3,4,4,5,4,4,3,4,4,1,3,5,4,3,3,3,1,2,2,3,3,1,3,1,3,3,3,5,3,3,4,5,0,3,0,3,0,3,4,3,4,4,3,0,3,0,2,4,3),
(0,1,0,4,0,0,0,0,0,1,4,0,4,1,4,2,4,0,3,0,1,0,1,0,0,0,0,0,2,0,3,1,1,1,0,3,0,0,0,1,2,1,0,0,1,1,1,1,0,1,0,0,0,1,0,0,3,0,0,0,0,3,2,0,2,2,0,1,0,0,0,2,3,2,3,3,0,0,0,0,2,1,0),
(0,5,1,5,0,3,0,3,0,5,4,4,5,1,5,3,3,0,4,3,4,3,5,3,4,3,3,2,4,3,4,3,3,0,3,3,1,4,4,3,4,4,4,3,4,5,5,3,2,3,1,1,3,3,1,3,1,1,3,3,2,4,5,3,3,5,0,4,0,3,0,4,4,3,5,3,3,0,3,4,0,4,3),
(0,5,0,5,0,3,0,2,0,4,4,3,5,2,4,3,3,3,4,4,4,3,5,3,5,3,3,1,4,0,4,3,3,0,3,3,0,4,4,4,4,5,4,3,3,5,5,3,2,3,1,2,3,2,0,1,0,0,3,2,2,4,4,3,1,5,0,4,0,3,0,4,3,1,3,2,1,0,3,3,0,3,3),
(0,4,0,5,0,5,0,4,0,4,5,5,5,3,4,3,3,2,5,4,4,3,5,3,5,3,4,0,4,3,4,4,3,2,4,4,3,4,5,4,4,5,5,0,3,5,5,4,1,3,3,2,3,3,1,3,1,0,4,3,1,4,4,3,4,5,0,4,0,2,0,4,3,4,4,3,3,0,4,0,0,5,5),
(0,4,0,4,0,5,0,1,1,3,3,4,4,3,4,1,3,0,5,1,3,0,3,1,3,1,1,0,3,0,3,3,4,0,4,3,0,4,4,4,3,4,4,0,3,5,4,1,0,3,0,0,2,3,0,3,1,0,3,1,0,3,2,1,3,5,0,3,0,1,0,3,2,3,3,4,4,0,2,2,0,4,4),
(2,4,0,5,0,4,0,3,0,4,5,5,4,3,5,3,5,3,5,3,5,2,5,3,4,3,3,4,3,4,5,3,2,1,5,4,3,2,3,4,5,3,4,1,2,5,4,3,0,3,3,0,3,2,0,2,3,0,4,1,0,3,4,3,3,5,0,3,0,1,0,4,5,5,5,4,3,0,4,2,0,3,5),
(0,5,0,4,0,4,0,2,0,5,4,3,4,3,4,3,3,3,4,3,4,2,5,3,5,3,4,1,4,3,4,4,4,0,3,5,0,4,4,4,4,5,3,1,3,4,5,3,3,3,3,3,3,3,0,2,2,0,3,3,2,4,3,3,3,5,3,4,1,3,3,5,3,2,0,0,0,0,4,3,1,3,3),
(0,1,0,3,0,3,0,1,0,1,3,3,3,2,3,3,3,0,3,0,0,0,3,1,3,0,0,0,2,2,2,3,0,0,3,2,0,1,2,4,1,3,3,0,0,3,3,3,0,1,0,0,2,1,0,0,3,0,3,1,0,3,0,0,1,3,0,2,0,1,0,3,3,1,3,3,0,0,1,1,0,3,3),
(0,2,0,3,0,2,1,4,0,2,2,3,1,1,3,1,1,0,2,0,3,1,2,3,1,3,0,0,1,0,4,3,2,3,3,3,1,4,2,3,3,3,3,1,0,3,1,4,0,1,1,0,1,2,0,1,1,0,1,1,0,3,1,3,2,2,0,1,0,0,0,2,3,3,3,1,0,0,0,0,0,2,3),
(0,5,0,4,0,5,0,2,0,4,5,5,3,3,4,3,3,1,5,4,4,2,4,4,4,3,4,2,4,3,5,5,4,3,3,4,3,3,5,5,4,5,5,1,3,4,5,3,1,4,3,1,3,3,0,3,3,1,4,3,1,4,5,3,3,5,0,4,0,3,0,5,3,3,1,4,3,0,4,0,1,5,3),
(0,5,0,5,0,4,0,2,0,4,4,3,4,3,3,3,3,3,5,4,4,4,4,4,4,5,3,3,5,2,4,4,4,3,4,4,3,3,4,4,5,5,3,3,4,3,4,3,3,4,3,3,3,3,1,2,2,1,4,3,3,5,4,4,3,4,0,4,0,3,0,4,4,4,4,4,1,0,4,2,0,2,4),
(0,4,0,4,0,3,0,1,0,3,5,2,3,0,3,0,2,1,4,2,3,3,4,1,4,3,3,2,4,1,3,3,3,0,3,3,0,0,3,3,3,5,3,3,3,3,3,2,0,2,0,0,2,0,0,2,0,0,1,0,0,3,1,2,2,3,0,3,0,2,0,4,4,3,3,4,1,0,3,0,0,2,4),
(0,0,0,4,0,0,0,0,0,0,1,0,1,0,2,0,0,0,0,0,1,0,2,0,1,0,0,0,0,0,3,1,3,0,3,2,0,0,0,1,0,3,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,4,0,2,0,0,0,0,0,0,2),
(0,2,1,3,0,2,0,2,0,3,3,3,3,1,3,1,3,3,3,3,3,3,4,2,2,1,2,1,4,0,4,3,1,3,3,3,2,4,3,5,4,3,3,3,3,3,3,3,0,1,3,0,2,0,0,1,0,0,1,0,0,4,2,0,2,3,0,3,3,0,3,3,4,2,3,1,4,0,1,2,0,2,3),
(0,3,0,3,0,1,0,3,0,2,3,3,3,0,3,1,2,0,3,3,2,3,3,2,3,2,3,1,3,0,4,3,2,0,3,3,1,4,3,3,2,3,4,3,1,3,3,1,1,0,1,1,0,1,0,1,0,1,0,0,0,4,1,1,0,3,0,3,1,0,2,3,3,3,3,3,1,0,0,2,0,3,3),
(0,0,0,0,0,0,0,0,0,0,3,0,2,0,3,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,3,0,3,0,3,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,2,0,2,3,0,0,0,0,0,0,0,0,3),
(0,2,0,3,1,3,0,3,0,2,3,3,3,1,3,1,3,1,3,1,3,3,3,1,3,0,2,3,1,1,4,3,3,2,3,3,1,2,2,4,1,3,3,0,1,4,2,3,0,1,3,0,3,0,0,1,3,0,2,0,0,3,3,2,1,3,0,3,0,2,0,3,4,4,4,3,1,0,3,0,0,3,3),
(0,2,0,1,0,2,0,0,0,1,3,2,2,1,3,0,1,1,3,0,3,2,3,1,2,0,2,0,1,1,3,3,3,0,3,3,1,1,2,3,2,3,3,1,2,3,2,0,0,1,0,0,0,0,0,0,3,0,1,0,0,2,1,2,1,3,0,3,0,0,0,3,4,4,4,3,2,0,2,0,0,2,4),
(0,0,0,1,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,2,2,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,3,1,0,0,0,0,0,0,0,3),
(0,3,0,3,0,2,0,3,0,3,3,3,2,3,2,2,2,0,3,1,3,3,3,2,3,3,0,0,3,0,3,2,2,0,2,3,1,4,3,4,3,3,2,3,1,5,4,4,0,3,1,2,1,3,0,3,1,1,2,0,2,3,1,3,1,3,0,3,0,1,0,3,3,4,4,2,1,0,2,1,0,2,4),
(0,1,0,3,0,1,0,2,0,1,4,2,5,1,4,0,2,0,2,1,3,1,4,0,2,1,0,0,2,1,4,1,1,0,3,3,0,5,1,3,2,3,3,1,0,3,2,3,0,1,0,0,0,0,0,0,1,0,0,0,0,4,0,1,0,3,0,2,0,1,0,3,3,3,4,3,3,0,0,0,0,2,3),
(0,0,0,1,0,0,0,0,0,0,2,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,0,0,1,0,0,0,0,0,3),
(0,1,0,3,0,4,0,3,0,2,4,3,1,0,3,2,2,1,3,1,2,2,3,1,1,1,2,1,3,0,1,2,0,1,3,2,1,3,0,5,5,1,0,0,1,3,2,1,0,3,0,0,1,0,0,0,0,0,3,4,0,1,1,1,3,2,0,2,0,1,0,2,3,3,1,2,3,0,1,0,1,0,4),
(0,0,0,1,0,3,0,3,0,2,2,1,0,0,4,0,3,0,3,1,3,0,3,0,3,0,1,0,3,0,3,1,3,0,3,3,0,0,1,2,1,1,1,0,1,2,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,2,2,1,2,0,0,2,0,0,0,0,2,3,3,3,3,0,0,0,0,1,4),
(0,0,0,3,0,3,0,0,0,0,3,1,1,0,3,0,1,0,2,0,1,0,0,0,0,0,0,0,1,0,3,0,2,0,2,3,0,0,2,2,3,1,2,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,2,0,0,0,0,2,3),
(2,4,0,5,0,5,0,4,0,3,4,3,3,3,4,3,3,3,4,3,4,4,5,4,5,5,5,2,3,0,5,5,4,1,5,4,3,1,5,4,3,4,4,3,3,4,3,3,0,3,2,0,2,3,0,3,0,0,3,3,0,5,3,2,3,3,0,3,0,3,0,3,4,5,4,5,3,0,4,3,0,3,4),
(0,3,0,3,0,3,0,3,0,3,3,4,3,2,3,2,3,0,4,3,3,3,3,3,3,3,3,0,3,2,4,3,3,1,3,4,3,4,4,4,3,4,4,3,2,4,4,1,0,2,0,0,1,1,0,2,0,0,3,1,0,5,3,2,1,3,0,3,0,1,2,4,3,2,4,3,3,0,3,2,0,4,4),
(0,3,0,3,0,1,0,0,0,1,4,3,3,2,3,1,3,1,4,2,3,2,4,2,3,4,3,0,2,2,3,3,3,0,3,3,3,0,3,4,1,3,3,0,3,4,3,3,0,1,1,0,1,0,0,0,4,0,3,0,0,3,1,2,1,3,0,4,0,1,0,4,3,3,4,3,3,0,2,0,0,3,3),
(0,3,0,4,0,1,0,3,0,3,4,3,3,0,3,3,3,1,3,1,3,3,4,3,3,3,0,0,3,1,5,3,3,1,3,3,2,5,4,3,3,4,5,3,2,5,3,4,0,1,0,0,0,0,0,2,0,0,1,1,0,4,2,2,1,3,0,3,0,2,0,4,4,3,5,3,2,0,1,1,0,3,4),
(0,5,0,4,0,5,0,2,0,4,4,3,3,2,3,3,3,1,4,3,4,1,5,3,4,3,4,0,4,2,4,3,4,1,5,4,0,4,4,4,4,5,4,1,3,5,4,2,1,4,1,1,3,2,0,3,1,0,3,2,1,4,3,3,3,4,0,4,0,3,0,4,4,4,3,3,3,0,4,2,0,3,4),
(1,4,0,4,0,3,0,1,0,3,3,3,1,1,3,3,2,2,3,3,1,0,3,2,2,1,2,0,3,1,2,1,2,0,3,2,0,2,2,3,3,4,3,0,3,3,1,2,0,1,1,3,1,2,0,0,3,0,1,1,0,3,2,2,3,3,0,3,0,0,0,2,3,3,4,3,3,0,1,0,0,1,4),
(0,4,0,4,0,4,0,0,0,3,4,4,3,1,4,2,3,2,3,3,3,1,4,3,4,0,3,0,4,2,3,3,2,2,5,4,2,1,3,4,3,4,3,1,3,3,4,2,0,2,1,0,3,3,0,0,2,0,3,1,0,4,4,3,4,3,0,4,0,1,0,2,4,4,4,4,4,0,3,2,0,3,3),
(0,0,0,1,0,4,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,3,2,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,2),
(0,2,0,3,0,4,0,4,0,1,3,3,3,0,4,0,2,1,2,1,1,1,2,0,3,1,1,0,1,0,3,1,0,0,3,3,2,0,1,1,0,0,0,0,0,1,0,2,0,2,2,0,3,1,0,0,1,0,1,1,0,1,2,0,3,0,0,0,0,1,0,0,3,3,4,3,1,0,1,0,3,0,2),
(0,0,0,3,0,5,0,0,0,0,1,0,2,0,3,1,0,1,3,0,0,0,2,0,0,0,1,0,0,0,1,1,0,0,4,0,0,0,2,3,0,1,4,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,1,0,0,0,0,0,0,0,2,0,0,3,0,0,0,0,0,3),
(0,2,0,5,0,5,0,1,0,2,4,3,3,2,5,1,3,2,3,3,3,0,4,1,2,0,3,0,4,0,2,2,1,1,5,3,0,0,1,4,2,3,2,0,3,3,3,2,0,2,4,1,1,2,0,1,1,0,3,1,0,1,3,1,2,3,0,2,0,0,0,1,3,5,4,4,4,0,3,0,0,1,3),
(0,4,0,5,0,4,0,4,0,4,5,4,3,3,4,3,3,3,4,3,4,4,5,3,4,5,4,2,4,2,3,4,3,1,4,4,1,3,5,4,4,5,5,4,4,5,5,5,2,3,3,1,4,3,1,3,3,0,3,3,1,4,3,4,4,4,0,3,0,4,0,3,3,4,4,5,0,0,4,3,0,4,5),
(0,4,0,4,0,3,0,3,0,3,4,4,4,3,3,2,4,3,4,3,4,3,5,3,4,3,2,1,4,2,4,4,3,1,3,4,2,4,5,5,3,4,5,4,1,5,4,3,0,3,2,2,3,2,1,3,1,0,3,3,3,5,3,3,3,5,4,4,2,3,3,4,3,3,3,2,1,0,3,2,1,4,3),
(0,4,0,5,0,4,0,3,0,3,5,5,3,2,4,3,4,0,5,4,4,1,4,4,4,3,3,3,4,3,5,5,2,3,3,4,1,2,5,5,3,5,5,2,3,5,5,4,0,3,2,0,3,3,1,1,5,1,4,1,0,4,3,2,3,5,0,4,0,3,0,5,4,3,4,3,0,0,4,1,0,4,4),
(1,3,0,4,0,2,0,2,0,2,5,5,3,3,3,3,3,0,4,2,3,4,4,4,3,4,0,0,3,4,5,4,3,3,3,3,2,5,5,4,5,5,5,4,3,5,5,5,1,3,1,0,1,0,0,3,2,0,4,2,0,5,2,3,2,4,1,3,0,3,0,4,5,4,5,4,3,0,4,2,0,5,4),
(0,3,0,4,0,5,0,3,0,3,4,4,3,2,3,2,3,3,3,3,3,2,4,3,3,2,2,0,3,3,3,3,3,1,3,3,3,0,4,4,3,4,4,1,1,4,4,2,0,3,1,0,1,1,0,4,1,0,2,3,1,3,3,1,3,4,0,3,0,1,0,3,1,3,0,0,1,0,2,0,0,4,4),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,3,0,3,0,2,0,3,0,1,5,4,3,3,3,1,4,2,1,2,3,4,4,2,4,4,5,0,3,1,4,3,4,0,4,3,3,3,2,3,2,5,3,4,3,2,2,3,0,0,3,0,2,1,0,1,2,0,0,0,0,2,1,1,3,1,0,2,0,4,0,3,4,4,4,5,2,0,2,0,0,1,3),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,1,1,0,0,1,1,0,0,0,4,2,1,1,0,1,0,3,2,0,0,3,1,1,1,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,1,0,0,0,2,0,0,0,1,4,0,4,2,1,0,0,0,0,0,1),
(0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,3,1,0,0,0,2,0,2,1,0,0,1,2,1,0,1,1,0,0,3,0,0,0,0,0,0,0,0,0,0,0,1,3,1,0,0,0,0,0,1,0,0,2,1,0,0,0,0,0,0,0,0,2),
(0,4,0,4,0,4,0,3,0,4,4,3,4,2,4,3,2,0,4,4,4,3,5,3,5,3,3,2,4,2,4,3,4,3,1,4,0,2,3,4,4,4,3,3,3,4,4,4,3,4,1,3,4,3,2,1,2,1,3,3,3,4,4,3,3,5,0,4,0,3,0,4,3,3,3,2,1,0,3,0,0,3,3),
(0,4,0,3,0,3,0,3,0,3,5,5,3,3,3,3,4,3,4,3,3,3,4,4,4,3,3,3,3,4,3,5,3,3,1,3,2,4,5,5,5,5,4,3,4,5,5,3,2,2,3,3,3,3,2,3,3,1,2,3,2,4,3,3,3,4,0,4,0,2,0,4,3,2,2,1,2,0,3,0,0,4,1),
)

class JapaneseContextAnalysis:
    def __init__(self):
        self.reset()

    def reset(self):
        self._mTotalRel = 0 # total sequence received
        self._mRelSample = [0] * NUM_OF_CATEGORY # category counters, each interger counts sequence in its category
        self._mNeedToSkipCharNum = 0 # if last byte in current buffer is not the last byte of a character, we need to know how many bytes to skip in next buffer
        self._mLastCharOrder = -1 # The order of previous char
        self._mDone = constants.False # If this flag is set to constants.True, detection is done and conclusion has been made

    def feed(self, aBuf, aLen):
        if self._mDone: return

        # The buffer we got is byte oriented, and a character may span in more than one
        # buffers. In case the last one or two byte in last buffer is not complete, we
        # record how many byte needed to complete that character and skip these bytes here.
        # We can choose to record those bytes as well and analyse the character once it
        # is complete, but since a character will not make much difference, by simply skipping
        # this character will simply our logic and improve performance.
        i = self._mNeedToSkipCharNum
        while i < aLen:
            order, charLen = self.get_order(aBuf[i:i+2])
            i += charLen
            if i > aLen:
                self._mNeedToSkipCharNum = i - aLen
                self._mLastCharOrder = -1
            else:
                if (order != -1) and (self._mLastCharOrder != -1):
                    self._mTotalRel += 1
                    if self._mTotalRel > MAX_REL_THRESHOLD:
                        self._mDone = constants.True
                        break
                    self._mRelSample[jp2CharContext[self._mLastCharOrder][order]] += 1
                self._mLastCharOrder = order

    def got_enough_data(self):
        return self._mTotalRel > ENOUGH_REL_THRESHOLD

    def get_confidence(self):
        # This is just one way to calculate confidence. It works well for me.
        if self._mTotalRel > MINIMUM_DATA_THRESHOLD:
            return (self._mTotalRel - self._mRelSample[0]) / self._mTotalRel
        else:
            return DONT_KNOW

    def get_order(self, aStr):
        return -1, 1

class SJISContextAnalysis(JapaneseContextAnalysis):
    def get_order(self, aStr):
        if not aStr: return -1, 1
        # find out current char's byte length
        try:
            if ((aStr[0] >= '\x81') and (aStr[0] <= '\x9F')) or \
               ((aStr[0] >= '\xE0') and (aStr[0] <= '\xFC')):
                charLen = 2
            else:
                charLen = 1
        except UnicodeDecodeError:
            return -1, 1

        # return its order if it is hiragana
        if len(aStr) > 1:
            if (aStr[0] == '\202') and \
               (aStr[1] >= '\x9F') and \
               (aStr[1] <= '\xF1'):
                return ord(aStr[1]) - 0x9F, charLen

        return -1, charLen

class EUCJPContextAnalysis(JapaneseContextAnalysis):
    def get_order(self, aStr):
        if not aStr: return -1, 1
        # find out current char's byte length
        try:
            if (aStr[0] == '\x8E') or \
               ((aStr[0] >= '\xA1') and (aStr[0] <= '\xFE')):
                charLen = 2
            elif aStr[0] == '\x8F':
                charLen = 3
            else:
                charLen = 1
        except UnicodeDecodeError:
            return -1, 1

        # return its order if it is hiragana
        if len(aStr) > 1:
            if (aStr[0] == '\xA4') and \
               (aStr[1] >= '\xA1') and \
               (aStr[1] <= '\xF3'):
                return ord(aStr[1]) - 0xA1, charLen

        return -1, charLen

########NEW FILE########
__FILENAME__ = langbulgarianmodel
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants

# 255: Control characters that usually does not exist in any text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9

# Character Mapping Table:
# this table is modified base on win1251BulgarianCharToOrderMap, so 
# only number <64 is sure valid

Latin5_BulgarianCharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253, 77, 90, 99,100, 72,109,107,101, 79,185, 81,102, 76, 94, 82,  # 40
110,186,108, 91, 74,119, 84, 96,111,187,115,253,253,253,253,253,  # 50
253, 65, 69, 70, 66, 63, 68,112,103, 92,194,104, 95, 86, 87, 71,  # 60
116,195, 85, 93, 97,113,196,197,198,199,200,253,253,253,253,253,  # 70
194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,  # 80
210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,  # 90
 81,226,227,228,229,230,105,231,232,233,234,235,236, 45,237,238,  # a0
 31, 32, 35, 43, 37, 44, 55, 47, 40, 59, 33, 46, 38, 36, 41, 30,  # b0
 39, 28, 34, 51, 48, 49, 53, 50, 54, 57, 61,239, 67,240, 60, 56,  # c0
  1, 18,  9, 20, 11,  3, 23, 15,  2, 26, 12, 10, 14,  6,  4, 13,  # d0
  7,  8,  5, 19, 29, 25, 22, 21, 27, 24, 17, 75, 52,241, 42, 16,  # e0
 62,242,243,244, 58,245, 98,246,247,248,249,250,251, 91,252,253,  # f0
)

win1251BulgarianCharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253, 77, 90, 99,100, 72,109,107,101, 79,185, 81,102, 76, 94, 82,  # 40
110,186,108, 91, 74,119, 84, 96,111,187,115,253,253,253,253,253,  # 50
253, 65, 69, 70, 66, 63, 68,112,103, 92,194,104, 95, 86, 87, 71,  # 60
116,195, 85, 93, 97,113,196,197,198,199,200,253,253,253,253,253,  # 70
206,207,208,209,210,211,212,213,120,214,215,216,217,218,219,220,  # 80
221, 78, 64, 83,121, 98,117,105,222,223,224,225,226,227,228,229,  # 90
 88,230,231,232,233,122, 89,106,234,235,236,237,238, 45,239,240,  # a0
 73, 80,118,114,241,242,243,244,245, 62, 58,246,247,248,249,250,  # b0
 31, 32, 35, 43, 37, 44, 55, 47, 40, 59, 33, 46, 38, 36, 41, 30,  # c0
 39, 28, 34, 51, 48, 49, 53, 50, 54, 57, 61,251, 67,252, 60, 56,  # d0
  1, 18,  9, 20, 11,  3, 23, 15,  2, 26, 12, 10, 14,  6,  4, 13,  # e0
  7,  8,  5, 19, 29, 25, 22, 21, 27, 24, 17, 75, 52,253, 42, 16,  # f0
)

# Model Table: 
# total sequences: 100%
# first 512 sequences: 96.9392%
# first 1024 sequences:3.0618%
# rest  sequences:     0.2992%
# negative sequences:  0.0020% 
BulgarianLangModel = ( \
0,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,3,3,3,3,3,3,3,3,2,3,3,3,3,3,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,0,3,3,3,2,2,3,2,2,1,2,2,
3,1,3,3,2,3,3,3,3,3,3,3,3,3,3,3,3,0,3,3,3,3,3,3,3,3,3,3,0,3,0,1,
0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,3,2,3,3,3,3,3,3,3,3,0,3,1,0,
0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
3,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,1,3,2,3,3,3,3,3,3,3,3,0,3,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,2,3,3,2,3,3,3,3,3,3,3,3,3,3,3,3,1,3,2,3,3,3,3,3,3,3,3,0,3,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,3,2,3,2,2,1,3,3,3,3,2,2,2,1,1,2,0,1,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,3,3,2,3,2,2,3,3,1,1,2,3,3,2,3,3,3,3,2,1,2,0,2,0,3,0,0,
0,0,0,0,0,0,0,1,0,0,2,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,3,3,1,3,3,3,3,3,2,3,2,3,3,3,3,3,2,3,3,1,3,0,3,0,2,0,0,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,3,3,3,1,3,3,2,3,3,3,1,3,3,2,3,2,2,2,0,0,2,0,2,0,2,0,0,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,3,3,3,3,0,3,3,3,2,2,3,3,3,1,2,2,3,2,1,1,2,0,2,0,0,0,0,
1,0,0,0,0,0,0,0,0,0,2,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,3,3,2,3,3,1,2,3,2,2,2,3,3,3,3,3,2,2,3,1,2,0,2,1,2,0,0,
0,0,0,0,0,0,0,0,0,0,3,0,0,1,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,1,3,3,3,3,3,2,3,3,3,2,3,3,2,3,2,2,2,3,1,2,0,1,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,3,3,3,3,3,3,1,1,1,2,2,1,3,1,3,2,2,3,0,0,1,0,1,0,1,0,0,
0,0,0,1,0,0,0,0,1,0,2,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,2,2,3,2,2,3,1,2,1,1,1,2,3,1,3,1,2,2,0,1,1,1,1,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,1,3,2,2,3,3,1,2,3,1,1,3,3,3,3,1,2,2,1,1,1,0,2,0,2,0,1,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,1,2,2,3,3,3,2,2,1,1,2,0,2,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,
3,0,1,2,1,3,3,2,3,3,3,3,3,2,3,2,1,0,3,1,2,1,2,1,2,3,2,1,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,1,1,2,3,3,3,3,3,3,3,3,3,3,3,3,0,0,3,1,3,3,2,3,3,2,2,2,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,3,3,3,3,0,3,3,3,3,3,2,1,1,2,1,3,3,0,3,1,1,1,1,3,2,0,1,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,
3,3,2,2,2,3,3,3,3,3,3,3,3,3,3,3,1,1,3,1,3,3,2,3,2,2,2,3,0,2,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,2,3,3,2,2,3,2,1,1,1,1,1,3,1,3,1,1,0,0,0,1,0,0,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,2,3,2,0,3,2,0,3,0,2,0,0,2,1,3,1,0,0,1,0,0,0,1,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,2,1,1,1,1,2,1,1,2,1,1,1,2,2,1,2,1,1,1,0,1,1,0,1,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,2,1,3,1,1,2,1,3,2,1,1,0,1,2,3,2,1,1,1,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,3,3,3,3,2,2,1,0,1,0,0,1,0,0,0,2,1,0,3,0,0,1,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,2,3,2,3,3,1,3,2,1,1,1,2,1,1,2,1,3,0,1,0,0,0,1,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,1,1,2,2,3,3,2,3,2,2,2,3,1,2,2,1,1,2,1,1,2,2,0,1,1,0,1,0,2,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,2,1,3,1,0,2,2,1,3,2,1,0,0,2,0,2,0,1,0,0,0,0,0,0,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,3,1,2,0,2,3,1,2,3,2,0,1,3,1,2,1,1,1,0,0,1,0,0,2,2,2,3,
2,2,2,2,1,2,1,1,2,2,1,1,2,0,1,1,1,0,0,1,1,0,0,1,1,0,0,0,1,1,0,1,
3,3,3,3,3,2,1,2,2,1,2,0,2,0,1,0,1,2,1,2,1,1,0,0,0,1,0,1,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,1,
3,3,2,3,3,1,1,3,1,0,3,2,1,0,0,0,1,2,0,2,0,1,0,0,0,1,0,1,2,1,2,2,
1,1,1,1,1,1,1,2,2,2,1,1,1,1,1,1,1,0,1,2,1,1,1,0,0,0,0,0,1,1,0,0,
3,1,0,1,0,2,3,2,2,2,3,2,2,2,2,2,1,0,2,1,2,1,1,1,0,1,2,1,2,2,2,1,
1,1,2,2,2,2,1,2,1,1,0,1,2,1,2,2,2,1,1,1,0,1,1,1,1,2,0,1,0,0,0,0,
2,3,2,3,3,0,0,2,1,0,2,1,0,0,0,0,2,3,0,2,0,0,0,0,0,1,0,0,2,0,1,2,
2,1,2,1,2,2,1,1,1,2,1,1,1,0,1,2,2,1,1,1,1,1,0,1,1,1,0,0,1,2,0,0,
3,3,2,2,3,0,2,3,1,1,2,0,0,0,1,0,0,2,0,2,0,0,0,1,0,1,0,1,2,0,2,2,
1,1,1,1,2,1,0,1,2,2,2,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,0,1,1,0,0,
2,3,2,3,3,0,0,3,0,1,1,0,1,0,0,0,2,2,1,2,0,0,0,0,0,0,0,0,2,0,1,2,
2,2,1,1,1,1,1,2,2,2,1,0,2,0,1,0,1,0,0,1,0,1,0,0,1,0,0,0,0,1,0,0,
3,3,3,3,2,2,2,2,2,0,2,1,1,1,1,2,1,2,1,1,0,2,0,1,0,1,0,0,2,0,1,2,
1,1,1,1,1,1,1,2,2,1,1,0,2,0,1,0,2,0,0,1,1,1,0,0,2,0,0,0,1,1,0,0,
2,3,3,3,3,1,0,0,0,0,0,0,0,0,0,0,2,0,0,1,1,0,0,0,0,0,0,1,2,0,1,2,
2,2,2,1,1,2,1,1,2,2,2,1,2,0,1,1,1,1,1,1,0,1,1,1,1,0,0,1,1,1,0,0,
2,3,3,3,3,0,2,2,0,2,1,0,0,0,1,1,1,2,0,2,0,0,0,3,0,0,0,0,2,0,2,2,
1,1,1,2,1,2,1,1,2,2,2,1,2,0,1,1,1,0,1,1,1,1,0,2,1,0,0,0,1,1,0,0,
2,3,3,3,3,0,2,1,0,0,2,0,0,0,0,0,1,2,0,2,0,0,0,0,0,0,0,0,2,0,1,2,
1,1,1,2,1,1,1,1,2,2,2,0,1,0,1,1,1,0,0,1,1,1,0,0,1,0,0,0,0,1,0,0,
3,3,2,2,3,0,1,0,1,0,0,0,0,0,0,0,1,1,0,3,0,0,0,0,0,0,0,0,1,0,2,2,
1,1,1,1,1,2,1,1,2,2,1,2,2,1,0,1,1,1,1,1,0,1,0,0,1,0,0,0,1,1,0,0,
3,1,0,1,0,2,2,2,2,3,2,1,1,1,2,3,0,0,1,0,2,1,1,0,1,1,1,1,2,1,1,1,
1,2,2,1,2,1,2,2,1,1,0,1,2,1,2,2,1,1,1,0,0,1,1,1,2,1,0,1,0,0,0,0,
2,1,0,1,0,3,1,2,2,2,2,1,2,2,1,1,1,0,2,1,2,2,1,1,2,1,1,0,2,1,1,1,
1,2,2,2,2,2,2,2,1,2,0,1,1,0,2,1,1,1,1,1,0,0,1,1,1,1,0,1,0,0,0,0,
2,1,1,1,1,2,2,2,2,1,2,2,2,1,2,2,1,1,2,1,2,3,2,2,1,1,1,1,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,2,2,3,2,0,1,2,0,1,2,1,1,0,1,0,1,2,1,2,0,0,0,1,1,0,0,0,1,0,0,2,
1,1,0,0,1,1,0,1,1,1,1,0,2,0,1,1,1,0,0,1,1,0,0,0,0,1,0,0,0,1,0,0,
2,0,0,0,0,1,2,2,2,2,2,2,2,1,2,1,1,1,1,1,1,1,0,1,1,1,1,1,2,1,1,1,
1,2,2,2,2,1,1,2,1,2,1,1,1,0,2,1,2,1,1,1,0,2,1,1,1,1,0,1,0,0,0,0,
3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,
1,1,0,1,0,1,1,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,2,2,3,2,0,0,0,0,1,0,0,0,0,0,0,1,1,0,2,0,0,0,0,0,0,0,0,1,0,1,2,
1,1,1,1,1,1,0,0,2,2,2,2,2,0,1,1,0,1,1,1,1,1,0,0,1,0,0,0,1,1,0,1,
2,3,1,2,1,0,1,1,0,2,2,2,0,0,1,0,0,1,1,1,1,0,0,0,0,0,0,0,1,0,1,2,
1,1,1,1,2,1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,0,1,0,0,1,0,0,0,0,1,0,0,
2,2,2,2,2,0,0,2,0,0,2,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,2,0,2,2,
1,1,1,1,1,0,0,1,2,1,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,
1,2,2,2,2,0,0,2,0,1,1,0,0,0,1,0,0,2,0,2,0,0,0,0,0,0,0,0,0,0,1,1,
0,0,0,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,
1,2,2,3,2,0,0,1,0,0,1,0,0,0,0,0,0,1,0,2,0,0,0,1,0,0,0,0,0,0,0,2,
1,1,0,0,1,0,0,0,1,1,0,0,1,0,1,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,
2,1,2,2,2,1,2,1,2,2,1,1,2,1,1,1,0,1,1,1,1,2,0,1,0,1,1,1,1,0,1,1,
1,1,2,1,1,1,1,1,1,0,0,1,2,1,1,1,1,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,
1,0,0,1,3,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,2,2,2,1,0,0,1,0,2,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,0,0,0,2,0,0,1,
0,2,0,1,0,0,1,1,2,0,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,
1,2,2,2,2,0,1,1,0,2,1,0,1,1,1,0,0,1,0,2,0,1,0,0,0,0,0,0,0,0,0,1,
0,1,0,0,1,0,0,0,1,1,0,0,1,0,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,
2,2,2,2,2,0,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,
0,1,0,1,1,1,0,0,1,1,1,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,
2,0,1,0,0,1,2,1,1,1,1,1,1,2,2,1,0,0,1,0,1,0,0,0,0,1,1,1,1,0,0,0,
1,1,2,1,1,1,1,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,2,1,2,1,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,
0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,0,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,
0,1,1,0,1,1,1,0,0,1,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,
1,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,2,0,0,2,0,1,0,0,1,0,0,1,
1,1,0,0,1,1,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,
1,1,1,1,1,1,1,2,0,0,0,0,0,0,2,1,0,1,1,0,0,1,1,1,0,1,0,0,0,0,0,0,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,0,1,1,1,1,1,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
)

Latin5BulgarianModel = { \
  'charToOrderMap': Latin5_BulgarianCharToOrderMap,
  'precedenceMatrix': BulgarianLangModel,
  'mTypicalPositiveRatio': 0.969392,
  'keepEnglishLetter': constants.False,
  'charsetName': "ISO-8859-5"
}

Win1251BulgarianModel = { \
  'charToOrderMap': win1251BulgarianCharToOrderMap,
  'precedenceMatrix': BulgarianLangModel,
  'mTypicalPositiveRatio': 0.969392,
  'keepEnglishLetter': constants.False,
  'charsetName': "windows-1251"
}

########NEW FILE########
__FILENAME__ = langcyrillicmodel
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants

# KOI8-R language model
# Character Mapping Table:
KOI8R_CharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253,142,143,144,145,146,147,148,149,150,151,152, 74,153, 75,154,  # 40
155,156,157,158,159,160,161,162,163,164,165,253,253,253,253,253,  # 50
253, 71,172, 66,173, 65,174, 76,175, 64,176,177, 77, 72,178, 69,  # 60
 67,179, 78, 73,180,181, 79,182,183,184,185,253,253,253,253,253,  # 70
191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,  # 80
207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,  # 90
223,224,225, 68,226,227,228,229,230,231,232,233,234,235,236,237,  # a0
238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,  # b0
 27,  3, 21, 28, 13,  2, 39, 19, 26,  4, 23, 11,  8, 12,  5,  1,  # c0
 15, 16,  9,  7,  6, 14, 24, 10, 17, 18, 20, 25, 30, 29, 22, 54,  # d0
 59, 37, 44, 58, 41, 48, 53, 46, 55, 42, 60, 36, 49, 38, 31, 34,  # e0
 35, 43, 45, 32, 40, 52, 56, 33, 61, 62, 51, 57, 47, 63, 50, 70,  # f0
)

win1251_CharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253,142,143,144,145,146,147,148,149,150,151,152, 74,153, 75,154,  # 40
155,156,157,158,159,160,161,162,163,164,165,253,253,253,253,253,  # 50
253, 71,172, 66,173, 65,174, 76,175, 64,176,177, 77, 72,178, 69,  # 60
 67,179, 78, 73,180,181, 79,182,183,184,185,253,253,253,253,253,  # 70
191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,
207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,
223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,
239,240,241,242,243,244,245,246, 68,247,248,249,250,251,252,253,
 37, 44, 33, 46, 41, 48, 56, 51, 42, 60, 36, 49, 38, 31, 34, 35,
 45, 32, 40, 52, 53, 55, 58, 50, 57, 63, 70, 62, 61, 47, 59, 43,
  3, 21, 10, 19, 13,  2, 24, 20,  4, 23, 11,  8, 12,  5,  1, 15,
  9,  7,  6, 14, 39, 26, 28, 22, 25, 29, 54, 18, 17, 30, 27, 16,
)

latin5_CharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253,142,143,144,145,146,147,148,149,150,151,152, 74,153, 75,154,  # 40
155,156,157,158,159,160,161,162,163,164,165,253,253,253,253,253,  # 50
253, 71,172, 66,173, 65,174, 76,175, 64,176,177, 77, 72,178, 69,  # 60
 67,179, 78, 73,180,181, 79,182,183,184,185,253,253,253,253,253,  # 70
191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,
207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,
223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,
 37, 44, 33, 46, 41, 48, 56, 51, 42, 60, 36, 49, 38, 31, 34, 35,
 45, 32, 40, 52, 53, 55, 58, 50, 57, 63, 70, 62, 61, 47, 59, 43,
  3, 21, 10, 19, 13,  2, 24, 20,  4, 23, 11,  8, 12,  5,  1, 15,
  9,  7,  6, 14, 39, 26, 28, 22, 25, 29, 54, 18, 17, 30, 27, 16,
239, 68,240,241,242,243,244,245,246,247,248,249,250,251,252,255,
)

macCyrillic_CharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253,142,143,144,145,146,147,148,149,150,151,152, 74,153, 75,154,  # 40
155,156,157,158,159,160,161,162,163,164,165,253,253,253,253,253,  # 50
253, 71,172, 66,173, 65,174, 76,175, 64,176,177, 77, 72,178, 69,  # 60
 67,179, 78, 73,180,181, 79,182,183,184,185,253,253,253,253,253,  # 70
 37, 44, 33, 46, 41, 48, 56, 51, 42, 60, 36, 49, 38, 31, 34, 35,
 45, 32, 40, 52, 53, 55, 58, 50, 57, 63, 70, 62, 61, 47, 59, 43,
191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,
207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,
223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,
239,240,241,242,243,244,245,246,247,248,249,250,251,252, 68, 16,
  3, 21, 10, 19, 13,  2, 24, 20,  4, 23, 11,  8, 12,  5,  1, 15,
  9,  7,  6, 14, 39, 26, 28, 22, 25, 29, 54, 18, 17, 30, 27,255,
)

IBM855_CharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253,142,143,144,145,146,147,148,149,150,151,152, 74,153, 75,154,  # 40
155,156,157,158,159,160,161,162,163,164,165,253,253,253,253,253,  # 50
253, 71,172, 66,173, 65,174, 76,175, 64,176,177, 77, 72,178, 69,  # 60
 67,179, 78, 73,180,181, 79,182,183,184,185,253,253,253,253,253,  # 70
191,192,193,194, 68,195,196,197,198,199,200,201,202,203,204,205,
206,207,208,209,210,211,212,213,214,215,216,217, 27, 59, 54, 70,
  3, 37, 21, 44, 28, 58, 13, 41,  2, 48, 39, 53, 19, 46,218,219,
220,221,222,223,224, 26, 55,  4, 42,225,226,227,228, 23, 60,229,
230,231,232,233,234,235, 11, 36,236,237,238,239,240,241,242,243,
  8, 49, 12, 38,  5, 31,  1, 34, 15,244,245,246,247, 35, 16,248,
 43,  9, 45,  7, 32,  6, 40, 14, 52, 24, 56, 10, 33, 17, 61,249,
250, 18, 62, 20, 51, 25, 57, 30, 47, 29, 63, 22, 50,251,252,255,
)

IBM866_CharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253,142,143,144,145,146,147,148,149,150,151,152, 74,153, 75,154,  # 40
155,156,157,158,159,160,161,162,163,164,165,253,253,253,253,253,  # 50
253, 71,172, 66,173, 65,174, 76,175, 64,176,177, 77, 72,178, 69,  # 60
 67,179, 78, 73,180,181, 79,182,183,184,185,253,253,253,253,253,  # 70
 37, 44, 33, 46, 41, 48, 56, 51, 42, 60, 36, 49, 38, 31, 34, 35,
 45, 32, 40, 52, 53, 55, 58, 50, 57, 63, 70, 62, 61, 47, 59, 43,
  3, 21, 10, 19, 13,  2, 24, 20,  4, 23, 11,  8, 12,  5,  1, 15,
191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,
207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,
223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,
  9,  7,  6, 14, 39, 26, 28, 22, 25, 29, 54, 18, 17, 30, 27, 16,
239, 68,240,241,242,243,244,245,246,247,248,249,250,251,252,255,
)

# Model Table: 
# total sequences: 100%
# first 512 sequences: 97.6601%
# first 1024 sequences: 2.3389%
# rest  sequences:      0.1237%
# negative sequences:   0.0009% 
RussianLangModel = ( \
0,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,1,1,3,3,3,3,1,3,3,3,2,3,2,3,3,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,0,3,2,2,2,2,2,0,0,2,
3,3,3,2,3,3,3,3,3,3,3,3,3,3,2,3,3,0,0,3,3,3,3,3,3,3,3,3,2,3,2,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,2,2,3,3,3,3,3,3,3,3,3,2,3,3,0,0,3,3,3,3,3,3,3,3,2,3,3,1,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,2,3,2,3,3,3,3,3,3,3,3,3,3,3,3,3,0,0,3,3,3,3,3,3,3,3,3,3,3,2,1,
0,0,0,0,0,0,0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,3,3,0,0,3,3,3,3,3,3,3,3,3,3,3,2,1,
0,0,0,0,0,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,2,2,2,3,1,3,3,1,3,3,3,3,2,2,3,0,2,2,2,3,3,2,1,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,2,3,3,3,3,3,2,2,3,2,3,3,3,2,1,2,2,0,1,2,2,2,2,2,2,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,3,0,2,2,3,3,2,1,2,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,1,0,0,2,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,2,3,3,1,2,3,2,2,3,2,3,3,3,3,2,2,3,0,3,2,2,3,1,1,1,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,2,2,3,3,3,3,3,2,3,3,3,3,2,2,2,0,3,3,3,2,2,2,2,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,2,3,2,3,3,3,3,3,3,2,3,2,2,0,1,3,2,1,2,2,1,0,
0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,3,2,1,1,3,0,1,1,1,1,2,1,1,0,2,2,2,1,2,0,1,0,
0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,2,3,3,2,2,2,2,1,3,2,3,2,3,2,1,2,2,0,1,1,2,1,2,1,2,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,3,3,2,2,3,2,3,3,3,2,2,2,2,0,2,2,2,2,3,1,1,0,
0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,
3,2,3,2,2,3,3,3,3,3,3,3,3,3,1,3,2,0,0,3,3,3,3,2,3,3,3,3,2,3,2,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,3,3,3,3,3,2,2,3,3,0,2,1,0,3,2,3,2,3,0,0,1,2,0,0,1,0,1,2,1,1,0,
0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,3,0,2,3,3,3,3,2,3,3,3,3,1,2,2,0,0,2,3,2,2,2,3,2,3,2,2,3,0,0,
0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,2,3,0,2,3,2,3,0,1,2,3,3,2,0,2,3,0,0,2,3,2,2,0,1,3,1,3,2,2,1,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,1,3,0,2,3,3,3,3,3,3,3,3,2,1,3,2,0,0,2,2,3,3,3,2,3,3,0,2,2,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,2,2,3,3,2,2,2,3,3,0,0,1,1,1,1,1,2,0,0,1,1,1,1,0,1,0,
0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,2,2,3,3,3,3,3,3,3,0,3,2,3,3,2,3,2,0,2,1,0,1,1,0,1,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,2,3,3,3,2,2,2,2,3,1,3,2,3,1,1,2,1,0,2,2,2,2,1,3,1,0,
0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,
2,2,3,3,3,3,3,1,2,2,1,3,1,0,3,0,0,3,0,0,0,1,1,0,1,2,1,0,0,0,0,0,
0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,2,2,1,1,3,3,3,2,2,1,2,2,3,1,1,2,0,0,2,2,1,3,0,0,2,1,1,2,1,1,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,2,3,3,3,3,1,2,2,2,1,2,1,3,3,1,1,2,1,2,1,2,2,0,2,0,0,1,1,0,1,0,
0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,3,3,3,3,3,2,1,3,2,2,3,2,0,3,2,0,3,0,1,0,1,1,0,0,1,1,1,1,0,1,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,2,3,3,3,2,2,2,3,3,1,2,1,2,1,0,1,0,1,1,0,1,0,0,2,1,1,1,0,1,0,
0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,
3,1,1,2,1,2,3,3,2,2,1,2,2,3,0,2,1,0,0,2,2,3,2,1,2,2,2,2,2,3,1,0,
0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,1,1,0,1,1,2,2,1,1,3,0,0,1,3,1,1,1,0,0,0,1,0,1,1,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,1,3,3,3,2,0,0,0,2,1,0,1,0,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,0,1,0,0,2,3,2,2,2,1,2,2,2,1,2,1,0,0,1,1,1,0,2,0,1,1,1,0,0,1,1,
1,0,0,0,0,0,1,2,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,
2,3,3,3,3,0,0,0,0,1,0,0,0,0,3,0,1,2,1,0,0,0,0,0,0,0,1,1,0,0,1,1,
1,0,1,0,1,2,0,0,1,1,2,1,0,1,1,1,1,0,1,1,1,1,0,1,0,0,1,0,0,1,1,0,
2,2,3,2,2,2,3,1,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,0,1,0,1,1,1,0,2,1,
1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,0,1,1,1,0,1,1,0,
3,3,3,2,2,2,2,3,2,2,1,1,2,2,2,2,1,1,3,1,2,1,2,0,0,1,1,0,1,0,2,1,
1,1,1,1,1,2,1,0,1,1,1,1,0,1,0,0,1,1,0,0,1,0,1,0,0,1,0,0,0,1,1,0,
2,0,0,1,0,3,2,2,2,2,1,2,1,2,1,2,0,0,0,2,1,2,2,1,1,2,2,0,1,1,0,2,
1,1,1,1,1,0,1,1,1,2,1,1,1,2,1,0,1,2,1,1,1,1,0,1,1,1,0,0,1,0,0,1,
1,3,2,2,2,1,1,1,2,3,0,0,0,0,2,0,2,2,1,0,0,0,0,0,0,1,0,0,0,0,1,1,
1,0,1,1,0,1,0,1,1,0,1,1,0,2,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,1,1,0,
2,3,2,3,2,1,2,2,2,2,1,0,0,0,2,0,0,1,1,0,0,0,0,0,0,0,1,1,0,0,2,1,
1,1,2,1,0,2,0,0,1,0,1,0,0,1,0,0,1,1,0,1,1,0,0,0,0,0,1,0,0,0,0,0,
3,0,0,1,0,2,2,2,3,2,2,2,2,2,2,2,0,0,0,2,1,2,1,1,1,2,2,0,0,0,1,2,
1,1,1,1,1,0,1,2,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,1,
2,3,2,3,3,2,0,1,1,1,0,0,1,0,2,0,1,1,3,1,0,0,0,0,0,0,0,1,0,0,2,1,
1,1,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,1,0,0,1,1,0,1,0,0,0,0,0,0,1,0,
2,3,3,3,3,1,2,2,2,2,0,1,1,0,2,1,1,1,2,1,0,1,1,0,0,1,0,1,0,0,2,0,
0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,3,3,3,2,0,0,1,1,2,2,1,0,0,2,0,1,1,3,0,0,1,0,0,0,0,0,1,0,1,2,1,
1,1,2,0,1,1,1,0,1,0,1,1,0,1,0,1,1,1,1,0,1,0,0,0,0,0,0,1,0,1,1,0,
1,3,2,3,2,1,0,0,2,2,2,0,1,0,2,0,1,1,1,0,1,0,0,0,3,0,1,1,0,0,2,1,
1,1,1,0,1,1,0,0,0,0,1,1,0,1,0,0,2,1,1,0,1,0,0,0,1,0,1,0,0,1,1,0,
3,1,2,1,1,2,2,2,2,2,2,1,2,2,1,1,0,0,0,2,2,2,0,0,0,1,2,1,0,1,0,1,
2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,2,1,1,1,0,1,0,1,1,0,1,1,1,0,0,1,
3,0,0,0,0,2,0,1,1,1,1,1,1,1,0,1,0,0,0,1,1,1,0,1,0,1,1,0,0,1,0,1,
1,1,0,0,1,0,0,0,1,0,1,1,0,0,1,0,1,0,1,0,0,0,0,1,0,0,0,1,0,0,0,1,
1,3,3,2,2,0,0,0,2,2,0,0,0,1,2,0,1,1,2,0,0,0,0,0,0,0,0,1,0,0,2,1,
0,1,1,0,0,1,1,0,0,0,1,1,0,1,1,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,1,0,
2,3,2,3,2,0,0,0,0,1,1,0,0,0,2,0,2,0,2,0,0,0,0,0,1,0,0,1,0,0,1,1,
1,1,2,0,1,2,1,0,1,1,2,1,1,1,1,1,2,1,1,0,1,0,0,1,1,1,1,1,0,1,1,0,
1,3,2,2,2,1,0,0,2,2,1,0,1,2,2,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,1,1,
0,0,1,1,0,1,1,0,0,1,1,0,1,1,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,
1,0,0,1,0,2,3,1,2,2,2,2,2,2,1,1,0,0,0,1,0,1,0,2,1,1,1,0,0,0,0,1,
1,1,0,1,1,0,1,1,1,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,
2,0,2,0,0,1,0,3,2,1,2,1,2,2,0,1,0,0,0,2,1,0,0,2,1,1,1,1,0,2,0,2,
2,1,1,1,1,1,1,1,1,1,1,1,1,2,1,0,1,1,1,1,0,0,0,1,1,1,1,0,1,0,0,1,
1,2,2,2,2,1,0,0,1,0,0,0,0,0,2,0,1,1,1,1,0,0,0,0,1,0,1,2,0,0,2,0,
1,0,1,1,1,2,1,0,1,0,1,1,0,0,1,0,1,1,1,0,1,0,0,0,1,0,0,1,0,1,1,0,
2,1,2,2,2,0,3,0,1,1,0,0,0,0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
0,0,0,1,1,1,0,0,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,
1,2,2,3,2,2,0,0,1,1,2,0,1,2,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,
0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,1,1,0,0,1,0,0,0,0,0,0,0,0,1,1,0,
2,2,1,1,2,1,2,2,2,2,2,1,2,2,0,1,0,0,0,1,2,2,2,1,2,1,1,1,1,1,2,1,
1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,0,0,0,0,1,1,1,0,1,1,0,0,1,
1,2,2,2,2,0,1,0,2,2,0,0,0,0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,2,0,
0,0,1,0,0,1,0,0,0,0,1,0,1,1,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,
0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,2,2,2,2,0,0,0,2,2,2,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
0,1,1,0,0,1,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,2,2,2,2,0,0,0,0,1,0,0,1,1,2,0,0,0,0,1,0,1,0,0,1,0,0,2,0,0,0,1,
0,0,1,0,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,
1,2,2,2,1,1,2,0,2,1,1,1,1,0,2,2,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,1,
0,0,1,0,1,1,0,0,0,0,1,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,
1,0,2,1,2,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,
0,0,1,0,1,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,
1,0,0,0,0,2,0,1,2,1,0,1,1,1,0,1,0,0,0,1,0,1,0,0,1,0,1,0,0,0,0,1,
0,0,0,0,0,1,0,0,1,1,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,
2,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
1,0,0,0,1,0,0,0,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
1,1,1,0,1,0,1,0,0,1,1,1,1,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,
1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
1,1,0,1,1,0,1,0,1,0,0,0,0,1,1,0,1,1,0,0,0,0,0,1,0,1,1,0,1,0,0,0,
0,1,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,
)

Koi8rModel = { \
  'charToOrderMap': KOI8R_CharToOrderMap,
  'precedenceMatrix': RussianLangModel,
  'mTypicalPositiveRatio': 0.976601,
  'keepEnglishLetter': constants.False,
  'charsetName': "KOI8-R"
}

Win1251CyrillicModel = { \
  'charToOrderMap': win1251_CharToOrderMap,
  'precedenceMatrix': RussianLangModel,
  'mTypicalPositiveRatio': 0.976601,
  'keepEnglishLetter': constants.False,
  'charsetName': "windows-1251"
}

Latin5CyrillicModel = { \
  'charToOrderMap': latin5_CharToOrderMap,
  'precedenceMatrix': RussianLangModel,
  'mTypicalPositiveRatio': 0.976601,
  'keepEnglishLetter': constants.False,
  'charsetName': "ISO-8859-5"
}

MacCyrillicModel = { \
  'charToOrderMap': macCyrillic_CharToOrderMap,
  'precedenceMatrix': RussianLangModel,
  'mTypicalPositiveRatio': 0.976601,
  'keepEnglishLetter': constants.False,
  'charsetName': "MacCyrillic"
};

Ibm866Model = { \
  'charToOrderMap': IBM866_CharToOrderMap,
  'precedenceMatrix': RussianLangModel,
  'mTypicalPositiveRatio': 0.976601,
  'keepEnglishLetter': constants.False,
  'charsetName': "IBM866"
}

Ibm855Model = { \
  'charToOrderMap': IBM855_CharToOrderMap,
  'precedenceMatrix': RussianLangModel,
  'mTypicalPositiveRatio': 0.976601,
  'keepEnglishLetter': constants.False,
  'charsetName': "IBM855"
}

########NEW FILE########
__FILENAME__ = langgreekmodel
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants

# 255: Control characters that usually does not exist in any text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9

# Character Mapping Table:
Latin7_CharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253, 82,100,104, 94, 98,101,116,102,111,187,117, 92, 88,113, 85,  # 40
 79,118,105, 83, 67,114,119, 95, 99,109,188,253,253,253,253,253,  # 50
253, 72, 70, 80, 81, 60, 96, 93, 89, 68,120, 97, 77, 86, 69, 55,  # 60
 78,115, 65, 66, 58, 76,106,103, 87,107,112,253,253,253,253,253,  # 70
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 80
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 90
253,233, 90,253,253,253,253,253,253,253,253,253,253, 74,253,253,  # a0
253,253,253,253,247,248, 61, 36, 46, 71, 73,253, 54,253,108,123,  # b0
110, 31, 51, 43, 41, 34, 91, 40, 52, 47, 44, 53, 38, 49, 59, 39,  # c0
 35, 48,250, 37, 33, 45, 56, 50, 84, 57,120,121, 17, 18, 22, 15,  # d0
124,  1, 29, 20, 21,  3, 32, 13, 25,  5, 11, 16, 10,  6, 30,  4,  # e0
  9,  8, 14,  7,  2, 12, 28, 23, 42, 24, 64, 75, 19, 26, 27,253,  # f0
)

win1253_CharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253, 82,100,104, 94, 98,101,116,102,111,187,117, 92, 88,113, 85,  # 40
 79,118,105, 83, 67,114,119, 95, 99,109,188,253,253,253,253,253,  # 50
253, 72, 70, 80, 81, 60, 96, 93, 89, 68,120, 97, 77, 86, 69, 55,  # 60
 78,115, 65, 66, 58, 76,106,103, 87,107,112,253,253,253,253,253,  # 70
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 80
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 90
253,233, 61,253,253,253,253,253,253,253,253,253,253, 74,253,253,  # a0
253,253,253,253,247,253,253, 36, 46, 71, 73,253, 54,253,108,123,  # b0
110, 31, 51, 43, 41, 34, 91, 40, 52, 47, 44, 53, 38, 49, 59, 39,  # c0
 35, 48,250, 37, 33, 45, 56, 50, 84, 57,120,121, 17, 18, 22, 15,  # d0
124,  1, 29, 20, 21,  3, 32, 13, 25,  5, 11, 16, 10,  6, 30,  4,  # e0
  9,  8, 14,  7,  2, 12, 28, 23, 42, 24, 64, 75, 19, 26, 27,253,  # f0
)

# Model Table: 
# total sequences: 100%
# first 512 sequences: 98.2851%
# first 1024 sequences:1.7001%
# rest  sequences:     0.0359%
# negative sequences:  0.0148% 
GreekLangModel = ( \
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,3,2,2,3,3,3,3,3,3,3,3,1,3,3,3,0,2,2,3,3,0,3,0,3,2,0,3,3,3,0,
3,0,0,0,2,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,3,0,3,3,0,3,2,3,3,0,3,2,3,3,3,0,0,3,0,3,0,3,3,2,0,0,0,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,
0,2,3,2,2,3,3,3,3,3,3,3,3,0,3,3,3,3,0,2,3,3,0,3,3,3,3,2,3,3,3,0,
2,0,0,0,2,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,2,3,3,2,3,3,3,3,3,3,3,3,3,3,3,3,0,2,1,3,3,3,3,2,3,3,2,3,3,2,0,
0,0,0,0,2,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,0,3,3,3,3,3,3,0,3,3,0,3,3,3,3,3,3,3,3,3,3,0,3,2,3,3,0,
2,0,1,0,2,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
0,3,3,3,3,3,2,3,0,0,0,0,3,3,0,3,1,3,3,3,0,3,3,0,3,3,3,3,0,0,0,0,
2,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,3,0,3,0,3,3,3,3,3,0,3,2,2,2,3,0,2,3,3,3,3,3,2,3,3,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,3,3,2,2,2,3,3,3,3,0,3,1,3,3,3,3,2,3,3,3,3,3,3,3,2,2,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,3,2,0,3,0,0,0,3,3,2,3,3,3,3,3,0,0,3,2,3,0,2,3,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,0,3,3,3,3,0,0,3,3,0,2,3,0,3,0,3,3,3,0,0,3,0,3,0,2,2,3,3,0,0,
0,0,1,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,3,2,0,3,2,3,3,3,3,0,3,3,3,3,3,0,3,3,2,3,2,3,3,2,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,2,3,2,3,3,3,3,3,3,0,2,3,2,3,2,2,2,3,2,3,3,2,3,0,2,2,2,3,0,
2,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,3,0,0,0,3,3,3,2,3,3,0,0,3,0,3,0,0,0,3,2,0,3,0,3,0,0,2,0,2,0,
0,0,0,0,2,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,0,3,3,3,3,3,3,0,3,3,0,3,0,0,0,3,3,0,3,3,3,0,0,1,2,3,0,
3,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,3,2,0,0,3,2,2,3,3,0,3,3,3,3,3,2,1,3,0,3,2,3,3,2,1,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,3,3,0,2,3,3,3,3,3,3,0,0,3,0,3,0,0,0,3,3,0,3,2,3,0,0,3,3,3,0,
3,0,0,0,2,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,0,3,3,3,3,3,3,0,0,3,0,3,0,0,0,3,2,0,3,2,3,0,0,3,2,3,0,
2,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,3,1,2,2,3,3,3,3,3,3,0,2,3,0,3,0,0,0,3,3,0,3,0,2,0,0,2,3,1,0,
2,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,0,3,3,3,3,0,3,0,3,3,2,3,0,3,3,3,3,3,3,0,3,3,3,0,2,3,0,0,3,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,0,3,3,3,0,0,3,0,0,0,3,3,0,3,0,2,3,3,0,0,3,0,3,0,3,3,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,3,0,0,0,3,3,3,3,3,3,0,0,3,0,2,0,0,0,3,3,0,3,0,3,0,0,2,0,2,0,
0,0,0,0,1,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,3,3,0,3,0,2,0,3,2,0,3,2,3,2,3,0,0,3,2,3,2,3,3,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,3,0,0,2,3,3,3,3,3,0,0,0,3,0,2,1,0,0,3,2,2,2,0,3,0,0,2,2,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,0,3,3,3,2,0,3,0,3,0,3,3,0,2,1,2,3,3,0,0,3,0,3,0,3,3,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,2,3,3,3,0,3,3,3,3,3,3,0,2,3,0,3,0,0,0,2,1,0,2,2,3,0,0,2,2,2,0,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,3,0,0,2,3,3,3,2,3,0,0,1,3,0,2,0,0,0,0,3,0,1,0,2,0,0,1,1,1,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,3,1,0,3,0,0,0,3,2,0,3,2,3,3,3,0,0,3,0,3,2,2,2,1,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,0,3,3,3,0,0,3,0,0,0,0,2,0,2,3,3,2,2,2,2,3,0,2,0,2,2,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,3,3,3,2,0,0,0,0,0,0,2,3,0,2,0,2,3,2,0,0,3,0,3,0,3,1,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,3,2,3,3,2,2,3,0,2,0,3,0,0,0,2,0,0,0,0,1,2,0,2,0,2,0,
0,2,0,2,0,2,2,0,0,1,0,2,2,2,0,2,2,2,0,2,2,2,0,0,2,0,0,1,0,0,0,0,
0,2,0,3,3,2,0,0,0,0,0,0,1,3,0,2,0,2,2,2,0,0,2,0,3,0,0,2,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,0,2,3,2,0,2,2,0,2,0,2,2,0,2,0,2,2,2,0,0,0,0,0,0,2,3,0,0,0,2,
0,1,2,0,0,0,0,2,2,0,0,0,2,1,0,2,2,0,0,0,0,0,0,1,0,2,0,0,0,0,0,0,
0,0,2,1,0,2,3,2,2,3,2,3,2,0,0,3,3,3,0,0,3,2,0,0,0,1,1,0,2,0,2,2,
0,2,0,2,0,2,2,0,0,2,0,2,2,2,0,2,2,2,2,0,0,2,0,0,0,2,0,1,0,0,0,0,
0,3,0,3,3,2,2,0,3,0,0,0,2,2,0,2,2,2,1,2,0,0,1,2,2,0,0,3,0,0,0,2,
0,1,2,0,0,0,1,2,0,0,0,0,0,0,0,2,2,0,1,0,0,2,0,0,0,2,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,2,3,3,2,2,0,0,0,2,0,2,3,3,0,2,0,0,0,0,0,0,2,2,2,0,2,2,0,2,0,2,
0,2,2,0,0,2,2,2,2,1,0,0,2,2,0,2,0,0,2,0,0,0,0,0,0,2,0,0,0,0,0,0,
0,2,0,3,2,3,0,0,0,3,0,0,2,2,0,2,0,2,2,2,0,0,2,0,0,0,0,0,0,0,0,2,
0,0,2,2,0,0,2,2,2,0,0,0,0,0,0,2,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,2,0,0,3,2,0,2,2,2,2,2,0,0,0,2,0,0,0,0,2,0,1,0,0,2,0,1,0,0,0,
0,2,2,2,0,2,2,0,1,2,0,2,2,2,0,2,2,2,2,1,2,2,0,0,2,0,0,0,0,0,0,0,
0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
0,2,0,2,0,2,2,0,0,0,0,1,2,1,0,0,2,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,3,2,3,0,0,2,0,0,0,2,2,0,2,0,0,0,1,0,0,2,0,2,0,2,2,0,0,0,0,
0,0,2,0,0,0,0,2,2,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,
0,2,2,3,2,2,0,0,0,0,0,0,1,3,0,2,0,2,2,0,0,0,1,0,2,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,2,0,2,0,3,2,0,2,0,0,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
0,0,2,0,0,0,0,1,1,0,0,2,1,2,0,2,2,0,1,0,0,1,0,0,0,2,0,0,0,0,0,0,
0,3,0,2,2,2,0,0,2,0,0,0,2,0,0,0,2,3,0,2,0,0,0,0,0,0,2,2,0,0,0,2,
0,1,2,0,0,0,1,2,2,1,0,0,0,2,0,0,2,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,2,1,2,0,2,2,0,2,0,0,2,0,0,0,0,1,2,1,0,2,1,0,0,0,0,0,0,0,0,0,0,
0,0,2,0,0,0,3,1,2,2,0,2,0,0,0,0,2,0,0,0,2,0,0,3,0,0,0,0,2,2,2,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,2,1,0,2,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,1,0,0,0,0,0,0,2,
0,2,2,0,0,2,2,2,2,2,0,1,2,0,0,0,2,2,0,1,0,2,0,0,2,2,0,0,0,0,0,0,
0,0,0,0,1,0,0,0,0,0,0,0,3,0,0,2,0,0,0,0,0,0,0,0,2,0,2,0,0,0,0,2,
0,1,2,0,0,0,0,2,2,1,0,1,0,1,0,2,2,2,1,0,0,0,0,0,0,1,0,0,0,0,0,0,
0,2,0,1,2,0,0,0,0,0,0,0,0,0,0,2,0,0,2,2,0,0,0,0,1,0,0,0,0,0,0,2,
0,2,2,0,0,0,0,2,2,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,2,0,0,2,0,0,0,
0,2,2,2,2,0,0,0,3,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,2,0,0,0,0,0,0,1,
0,0,2,0,0,0,0,1,2,0,0,0,0,0,0,2,2,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,
0,2,0,2,2,2,0,0,2,0,0,0,0,0,0,0,2,2,2,0,0,0,2,0,0,0,0,0,0,0,0,2,
0,0,1,0,0,0,0,2,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,
0,3,0,2,0,0,0,0,0,0,0,0,2,0,0,0,0,0,2,0,0,0,0,0,0,0,2,0,0,0,0,2,
0,0,2,0,0,0,0,2,2,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,2,0,2,2,1,0,0,0,0,0,0,2,0,0,2,0,2,2,2,0,0,0,0,0,0,2,0,0,0,0,2,
0,0,2,0,0,2,0,2,2,0,0,0,0,2,0,2,0,0,0,0,0,2,0,0,0,2,0,0,0,0,0,0,
0,0,3,0,0,0,2,2,0,2,2,0,0,0,0,0,2,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,2,0,0,0,0,0,
0,2,2,2,2,2,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,
0,0,0,0,0,0,0,2,1,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,2,2,0,0,0,0,0,2,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
0,2,0,0,0,2,0,0,0,0,0,1,0,0,0,0,2,2,0,0,0,1,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,2,0,0,0,
0,2,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,2,0,2,0,0,0,
0,0,0,0,0,0,0,0,2,1,0,0,0,0,0,0,2,0,0,0,1,2,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
)

Latin7GreekModel = { \
  'charToOrderMap': Latin7_CharToOrderMap,
  'precedenceMatrix': GreekLangModel,
  'mTypicalPositiveRatio': 0.982851,
  'keepEnglishLetter': constants.False,
  'charsetName': "ISO-8859-7"
}

Win1253GreekModel = { \
  'charToOrderMap': win1253_CharToOrderMap,
  'precedenceMatrix': GreekLangModel,
  'mTypicalPositiveRatio': 0.982851,
  'keepEnglishLetter': constants.False,
  'charsetName': "windows-1253"
}

########NEW FILE########
__FILENAME__ = langhebrewmodel
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
#          Simon Montagu
# Portions created by the Initial Developer are Copyright (C) 2005
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#   Shoshannah Forbes - original C code (?)
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants

# 255: Control characters that usually does not exist in any text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9

# Windows-1255 language model
# Character Mapping Table:
win1255_CharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253, 69, 91, 79, 80, 92, 89, 97, 90, 68,111,112, 82, 73, 95, 85,  # 40
 78,121, 86, 71, 67,102,107, 84,114,103,115,253,253,253,253,253,  # 50
253, 50, 74, 60, 61, 42, 76, 70, 64, 53,105, 93, 56, 65, 54, 49,  # 60
 66,110, 51, 43, 44, 63, 81, 77, 98, 75,108,253,253,253,253,253,  # 70
124,202,203,204,205, 40, 58,206,207,208,209,210,211,212,213,214,
215, 83, 52, 47, 46, 72, 32, 94,216,113,217,109,218,219,220,221,
 34,116,222,118,100,223,224,117,119,104,125,225,226, 87, 99,227,
106,122,123,228, 55,229,230,101,231,232,120,233, 48, 39, 57,234,
 30, 59, 41, 88, 33, 37, 36, 31, 29, 35,235, 62, 28,236,126,237,
238, 38, 45,239,240,241,242,243,127,244,245,246,247,248,249,250,
  9,  8, 20, 16,  3,  2, 24, 14, 22,  1, 25, 15,  4, 11,  6, 23,
 12, 19, 13, 26, 18, 27, 21, 17,  7, 10,  5,251,252,128, 96,253,
)

# Model Table: 
# total sequences: 100%
# first 512 sequences: 98.4004%
# first 1024 sequences: 1.5981%
# rest  sequences:      0.087%
# negative sequences:   0.0015% 
HebrewLangModel = ( \
0,3,3,3,3,3,3,3,3,3,3,2,3,3,3,3,3,3,3,3,3,3,3,2,3,2,1,2,0,1,0,0,
3,0,3,1,0,0,1,3,2,0,1,1,2,0,2,2,2,1,1,1,1,2,1,1,1,2,0,0,2,2,0,1,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,
1,2,1,2,1,2,0,0,2,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,
1,2,1,3,1,1,0,0,2,0,0,0,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,1,0,1,2,2,1,3,
1,2,1,1,2,2,0,0,2,2,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,1,0,1,1,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,3,3,2,2,2,2,3,2,
1,2,1,2,2,2,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,3,3,2,3,2,2,3,2,2,2,1,2,2,2,2,
1,2,1,1,2,2,0,1,2,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,0,2,2,2,2,2,
0,2,0,2,2,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,3,0,2,2,2,
0,2,1,2,2,2,0,0,2,1,0,0,0,0,1,0,1,0,0,0,0,0,0,2,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,2,3,3,3,3,3,3,3,3,3,3,3,3,3,2,1,2,3,2,2,2,
1,2,1,2,2,2,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,1,0,
3,3,3,3,3,3,3,3,3,2,3,3,3,2,3,3,3,3,3,3,3,3,3,3,3,3,3,1,0,2,0,2,
0,2,1,2,2,2,0,0,1,2,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,2,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,3,2,3,2,2,3,2,1,2,1,1,1,
0,1,1,1,1,1,3,0,1,0,0,0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,0,0,1,0,0,1,0,0,0,0,
0,0,1,0,0,0,0,0,2,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,
0,2,0,1,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,2,3,3,3,2,1,2,3,3,2,3,3,3,3,2,3,2,1,2,0,2,1,2,
0,2,0,2,2,2,0,0,1,2,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,
3,3,3,3,3,3,3,3,3,2,3,3,3,1,2,2,3,3,2,3,2,3,2,2,3,1,2,2,0,2,2,2,
0,2,1,2,2,2,0,0,1,2,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,1,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,2,3,3,3,2,3,3,2,2,2,3,3,3,3,1,3,2,2,2,
0,2,0,1,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,3,3,3,2,3,2,2,2,1,2,2,0,2,2,2,2,
0,2,0,2,2,2,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,2,3,3,3,1,3,2,3,3,2,3,3,2,2,1,2,2,2,2,2,2,
0,2,1,2,1,2,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,2,3,2,3,3,2,3,3,3,3,2,3,2,3,3,3,3,3,2,2,2,2,2,2,2,1,
0,2,0,1,2,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,2,1,2,3,3,3,3,3,3,3,2,3,2,3,2,1,2,3,0,2,1,2,2,
0,2,1,1,2,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,2,0,
3,3,3,3,3,3,3,3,3,2,3,3,3,3,2,1,3,1,2,2,2,1,2,3,3,1,2,1,2,2,2,2,
0,1,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,2,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,0,2,3,3,3,1,3,3,3,1,2,2,2,2,1,1,2,2,2,2,2,2,
0,2,0,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,2,3,3,3,2,2,3,3,3,2,1,2,3,2,3,2,2,2,2,1,2,1,1,1,2,2,
0,2,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,1,0,0,0,0,0,
1,0,1,0,0,0,0,0,2,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,2,3,3,2,3,1,2,2,2,2,3,2,3,1,1,2,2,1,2,2,1,1,0,2,2,2,2,
0,1,0,1,2,2,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,
3,0,0,1,1,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,2,0,
0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,1,0,1,0,1,1,0,1,1,0,0,0,1,1,0,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,
0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,0,0,1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
3,2,2,1,2,2,2,2,2,2,2,1,2,2,1,2,2,1,1,1,1,1,1,1,1,2,1,1,0,3,3,3,
0,3,0,2,2,2,2,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,2,2,1,2,2,2,1,1,1,2,0,1,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,0,0,0,0,0,
0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,3,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,2,1,0,2,1,0,
0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,
0,3,1,1,2,2,2,2,2,1,2,2,2,1,1,2,2,2,2,2,2,2,1,2,2,1,0,1,1,1,1,0,
0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,2,1,1,1,1,2,1,1,2,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,0,0,0,0,
0,0,2,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,1,0,0,0,0,0,0,1,0,0,
2,1,1,2,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,2,1,2,1,2,1,1,1,1,0,0,0,0,
0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,2,1,2,2,2,2,2,2,2,2,2,2,1,2,1,2,1,1,2,1,1,1,2,1,2,1,2,0,1,0,1,
0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,3,1,2,2,2,1,2,2,2,2,2,2,2,2,1,2,1,1,1,1,1,1,2,1,2,1,1,0,1,0,1,
0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,1,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,
0,2,0,1,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
3,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,1,1,1,1,1,1,1,0,1,1,0,1,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,2,0,1,1,1,0,1,0,0,0,1,1,0,1,1,0,0,0,0,0,1,1,0,0,
0,1,1,1,2,1,2,2,2,0,2,0,2,0,1,1,2,1,1,1,1,2,1,0,1,1,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,0,1,0,0,0,0,0,1,0,1,2,2,0,1,0,0,1,1,2,2,1,2,0,2,0,0,0,1,2,0,1,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,2,0,2,1,2,0,2,0,0,1,1,1,1,1,1,0,1,0,0,0,1,0,0,1,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,1,0,0,0,0,0,1,0,2,1,1,0,1,0,0,1,1,1,2,2,0,0,1,0,0,0,1,0,0,1,
1,1,2,1,0,1,1,1,0,1,0,1,1,1,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,2,2,1,
0,2,0,1,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,1,0,0,1,0,1,1,1,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,1,1,1,1,1,1,1,1,2,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,1,1,1,0,1,1,0,1,0,0,0,1,1,0,1,
2,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,1,0,1,1,1,0,1,0,0,1,1,2,1,1,2,0,1,0,0,0,1,1,0,1,
1,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,1,0,1,1,2,0,1,0,0,0,0,2,1,1,2,0,2,0,0,0,1,1,0,1,
1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,1,0,2,1,1,0,1,0,0,2,2,1,2,1,1,0,1,0,0,0,1,1,0,1,
2,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,1,2,2,0,0,0,0,0,1,1,0,1,0,0,1,0,0,0,0,1,0,1,
1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,1,2,2,0,0,0,0,2,1,1,1,0,2,1,1,0,0,0,2,1,0,1,
1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,1,0,1,1,2,0,1,0,0,1,1,0,2,1,1,0,1,0,0,0,1,1,0,1,
2,2,1,1,1,0,1,1,0,1,1,0,1,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,1,0,2,1,1,0,1,0,0,1,1,0,1,2,1,0,2,0,0,0,1,1,0,1,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,
0,1,0,0,2,0,2,1,1,0,1,0,1,0,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,1,0,1,1,2,0,1,0,0,1,1,1,0,1,0,0,1,0,0,0,1,0,0,1,
1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,0,0,0,0,0,0,0,1,0,1,1,0,0,1,0,0,2,1,1,1,1,1,0,1,0,0,0,0,1,0,1,
0,1,1,1,2,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,1,2,1,0,0,0,0,0,1,1,1,1,1,0,1,0,0,0,1,1,0,0,
)

Win1255HebrewModel = { \
  'charToOrderMap': win1255_CharToOrderMap,
  'precedenceMatrix': HebrewLangModel,
  'mTypicalPositiveRatio': 0.984004,
  'keepEnglishLetter': constants.False,
  'charsetName': "windows-1255"
}

########NEW FILE########
__FILENAME__ = langhungarianmodel
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants

# 255: Control characters that usually does not exist in any text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9

# Character Mapping Table:
Latin2_HungarianCharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253, 28, 40, 54, 45, 32, 50, 49, 38, 39, 53, 36, 41, 34, 35, 47,
 46, 71, 43, 33, 37, 57, 48, 64, 68, 55, 52,253,253,253,253,253,
253,  2, 18, 26, 17,  1, 27, 12, 20,  9, 22,  7,  6, 13,  4,  8,
 23, 67, 10,  5,  3, 21, 19, 65, 62, 16, 11,253,253,253,253,253,
159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,
175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,
191,192,193,194,195,196,197, 75,198,199,200,201,202,203,204,205,
 79,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,
221, 51, 81,222, 78,223,224,225,226, 44,227,228,229, 61,230,231,
232,233,234, 58,235, 66, 59,236,237,238, 60, 69, 63,239,240,241,
 82, 14, 74,242, 70, 80,243, 72,244, 15, 83, 77, 84, 30, 76, 85,
245,246,247, 25, 73, 42, 24,248,249,250, 31, 56, 29,251,252,253,
)

win1250HungarianCharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253, 28, 40, 54, 45, 32, 50, 49, 38, 39, 53, 36, 41, 34, 35, 47,
 46, 72, 43, 33, 37, 57, 48, 64, 68, 55, 52,253,253,253,253,253,
253,  2, 18, 26, 17,  1, 27, 12, 20,  9, 22,  7,  6, 13,  4,  8,
 23, 67, 10,  5,  3, 21, 19, 65, 62, 16, 11,253,253,253,253,253,
161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,
177,178,179,180, 78,181, 69,182,183,184,185,186,187,188,189,190,
191,192,193,194,195,196,197, 76,198,199,200,201,202,203,204,205,
 81,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,
221, 51, 83,222, 80,223,224,225,226, 44,227,228,229, 61,230,231,
232,233,234, 58,235, 66, 59,236,237,238, 60, 70, 63,239,240,241,
 84, 14, 75,242, 71, 82,243, 73,244, 15, 85, 79, 86, 30, 77, 87,
245,246,247, 25, 74, 42, 24,248,249,250, 31, 56, 29,251,252,253,
)

# Model Table: 
# total sequences: 100%
# first 512 sequences: 94.7368%
# first 1024 sequences:5.2623%
# rest  sequences:     0.8894%
# negative sequences:  0.0009% 
HungarianLangModel = ( \
0,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,1,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,
3,3,3,3,3,3,3,3,3,3,2,3,3,3,3,3,3,3,3,2,2,3,3,1,1,2,2,2,2,2,1,2,
3,2,2,3,3,3,3,3,2,3,3,3,3,3,3,1,2,3,3,3,3,2,3,3,1,1,3,3,0,1,1,1,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,
3,2,1,3,3,3,3,3,2,3,3,3,3,3,1,1,2,3,3,3,3,3,3,3,1,1,3,2,0,1,1,1,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,1,1,2,3,3,3,1,3,3,3,3,3,1,3,3,2,2,0,3,2,3,
0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,
3,3,3,3,3,3,2,3,3,3,2,3,3,2,3,3,3,3,3,2,3,3,2,2,3,2,3,2,0,3,2,2,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,
3,3,3,3,3,3,2,3,3,3,3,3,2,3,3,3,1,2,3,2,2,3,1,2,3,3,2,2,0,3,3,3,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,2,2,3,3,3,3,3,3,2,3,3,3,3,2,3,3,3,3,0,2,3,2,
0,0,0,1,1,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,3,3,3,1,1,1,3,3,2,1,3,2,2,3,2,1,3,2,2,1,0,3,3,1,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,2,2,3,3,3,3,3,1,2,3,3,3,3,1,2,1,3,3,3,3,2,2,3,1,1,3,2,0,1,1,1,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,2,2,3,3,3,3,3,2,1,3,3,3,3,3,2,2,1,3,3,3,0,1,1,2,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,
3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,3,3,3,2,3,3,2,3,3,3,2,0,3,2,3,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,1,0,
3,3,3,3,3,3,2,3,3,3,2,3,2,3,3,3,1,3,2,2,2,3,1,1,3,3,1,1,0,3,3,2,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,2,3,3,3,2,3,2,3,3,3,2,3,3,3,3,3,1,2,3,2,2,0,2,2,2,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,3,3,2,2,2,3,1,3,3,2,2,1,3,3,3,1,1,3,1,2,3,2,3,2,2,2,1,0,2,2,2,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,
3,1,1,3,3,3,3,3,1,2,3,3,3,3,1,2,1,3,3,3,2,2,3,2,1,0,3,2,0,1,1,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,1,1,3,3,3,3,3,1,2,3,3,3,3,1,1,0,3,3,3,3,0,2,3,0,0,2,1,0,1,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,2,2,3,3,2,2,2,2,3,3,0,1,2,3,2,3,2,2,3,2,1,2,0,2,2,2,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,
3,3,3,3,3,3,1,2,3,3,3,2,1,2,3,3,2,2,2,3,2,3,3,1,3,3,1,1,0,2,3,2,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,3,3,1,2,2,2,2,3,3,3,1,1,1,3,3,1,1,3,1,1,3,2,1,2,3,1,1,0,2,2,2,
0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,3,3,2,1,2,1,1,3,3,1,1,1,1,3,3,1,1,2,2,1,2,1,1,2,2,1,1,0,2,2,1,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,3,3,1,1,2,1,1,3,3,1,0,1,1,3,3,2,0,1,1,2,3,1,0,2,2,1,0,0,1,3,2,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,2,1,3,3,3,3,3,1,2,3,2,3,3,2,1,1,3,2,3,2,1,2,2,0,1,2,1,0,0,1,1,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
3,3,3,3,2,2,2,2,3,1,2,2,1,1,3,3,0,3,2,1,2,3,2,1,3,3,1,1,0,2,1,3,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,3,3,2,2,2,3,2,3,3,3,2,1,1,3,3,1,1,1,2,2,3,2,3,2,2,2,1,0,2,2,1,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
1,0,0,3,3,3,3,3,0,0,3,3,2,3,0,0,0,2,3,3,1,0,1,2,0,0,1,1,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,1,2,3,3,3,3,3,1,2,3,3,2,2,1,1,0,3,3,2,2,1,2,2,1,0,2,2,0,1,1,1,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,2,2,1,3,1,2,3,3,2,2,1,1,2,2,1,1,1,1,3,2,1,1,1,1,2,1,0,1,2,1,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,
2,3,3,1,1,1,1,1,3,3,3,0,1,1,3,3,1,1,1,1,1,2,2,0,3,1,1,2,0,2,1,1,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
3,1,0,1,2,1,2,2,0,1,2,3,1,2,0,0,0,2,1,1,1,1,1,2,0,0,1,1,0,0,0,0,
1,2,1,2,2,2,1,2,1,2,0,2,0,2,2,1,1,2,1,1,2,1,1,1,0,1,0,0,0,1,1,0,
1,1,1,2,3,2,3,3,0,1,2,2,3,1,0,1,0,2,1,2,2,0,1,1,0,0,1,1,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,0,0,3,3,2,2,1,0,0,3,2,3,2,0,0,0,1,1,3,0,0,1,1,0,0,2,1,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,1,1,2,2,3,3,1,0,1,3,2,3,1,1,1,0,1,1,1,1,1,3,1,0,0,2,2,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,1,1,1,2,2,2,1,0,1,2,3,3,2,0,0,0,2,1,1,1,2,1,1,1,0,1,1,1,0,0,0,
1,2,2,2,2,2,1,1,1,2,0,2,1,1,1,1,1,2,1,1,1,1,1,1,0,1,1,1,0,0,1,1,
3,2,2,1,0,0,1,1,2,2,0,3,0,1,2,1,1,0,0,1,1,1,0,1,1,1,1,0,2,1,1,1,
2,2,1,1,1,2,1,2,1,1,1,1,1,1,1,2,1,1,1,2,3,1,1,1,1,1,1,1,1,1,0,1,
2,3,3,0,1,0,0,0,3,3,1,0,0,1,2,2,1,0,0,0,0,2,0,0,1,1,1,0,2,1,1,1,
2,1,1,1,1,1,1,2,1,1,0,1,1,0,1,1,1,0,1,2,1,1,0,1,1,1,1,1,1,1,0,1,
2,3,3,0,1,0,0,0,2,2,0,0,0,0,1,2,2,0,0,0,0,1,0,0,1,1,0,0,2,0,1,0,
2,1,1,1,1,2,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,2,0,1,1,1,1,1,0,1,
3,2,2,0,1,0,1,0,2,3,2,0,0,1,2,2,1,0,0,1,1,1,0,0,2,1,0,1,2,2,1,1,
2,1,1,1,1,1,1,2,1,1,1,1,1,1,0,2,1,0,1,1,0,1,1,1,0,1,1,2,1,1,0,1,
2,2,2,0,0,1,0,0,2,2,1,1,0,0,2,1,1,0,0,0,1,2,0,0,2,1,0,0,2,1,1,1,
2,1,1,1,1,2,1,2,1,1,1,2,2,1,1,2,1,1,1,2,1,1,1,1,1,1,1,1,1,1,0,1,
1,2,3,0,0,0,1,0,3,2,1,0,0,1,2,1,1,0,0,0,0,2,1,0,1,1,0,0,2,1,2,1,
1,1,0,0,0,1,0,1,1,1,1,1,2,0,0,1,0,0,0,2,0,0,1,1,1,1,1,1,1,1,0,1,
3,0,0,2,1,2,2,1,0,0,2,1,2,2,0,0,0,2,1,1,1,0,1,1,0,0,1,1,2,0,0,0,
1,2,1,2,2,1,1,2,1,2,0,1,1,1,1,1,1,1,1,1,2,1,1,0,0,1,1,1,1,0,0,1,
1,3,2,0,0,0,1,0,2,2,2,0,0,0,2,2,1,0,0,0,0,3,1,1,1,1,0,0,2,1,1,1,
2,1,0,1,1,1,0,1,1,1,1,1,1,1,0,2,1,0,0,1,0,1,1,0,1,1,1,1,1,1,0,1,
2,3,2,0,0,0,1,0,2,2,0,0,0,0,2,1,1,0,0,0,0,2,1,0,1,1,0,0,2,1,1,0,
2,1,1,1,1,2,1,2,1,2,0,1,1,1,0,2,1,1,1,2,1,1,1,1,0,1,1,1,1,1,0,1,
3,1,1,2,2,2,3,2,1,1,2,2,1,1,0,1,0,2,2,1,1,1,1,1,0,0,1,1,0,1,1,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,2,2,0,0,0,0,0,2,2,0,0,0,0,2,2,1,0,0,0,1,1,0,0,1,2,0,0,2,1,1,1,
2,2,1,1,1,2,1,2,1,1,0,1,1,1,1,2,1,1,1,2,1,1,1,1,0,1,2,1,1,1,0,1,
1,0,0,1,2,3,2,1,0,0,2,0,1,1,0,0,0,1,1,1,1,0,1,1,0,0,1,0,0,0,0,0,
1,2,1,2,1,2,1,1,1,2,0,2,1,1,1,0,1,2,0,0,1,1,1,0,0,0,0,0,0,0,0,0,
2,3,2,0,0,0,0,0,1,1,2,1,0,0,1,1,1,0,0,0,0,2,0,0,1,1,0,0,2,1,1,1,
2,1,1,1,1,1,1,2,1,0,1,1,1,1,0,2,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,
1,2,2,0,1,1,1,0,2,2,2,0,0,0,3,2,1,0,0,0,1,1,0,0,1,1,0,1,1,1,0,0,
1,1,0,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,2,1,1,1,0,0,1,1,1,0,1,0,1,
2,1,0,2,1,1,2,2,1,1,2,1,1,1,0,0,0,1,1,0,1,1,1,1,0,0,1,1,1,0,0,0,
1,2,2,2,2,2,1,1,1,2,0,2,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,1,0,
1,2,3,0,0,0,1,0,2,2,0,0,0,0,2,2,0,0,0,0,0,1,0,0,1,0,0,0,2,0,1,0,
2,1,1,1,1,1,0,2,0,0,0,1,2,1,1,1,1,0,1,2,0,1,0,1,0,1,1,1,0,1,0,1,
2,2,2,0,0,0,1,0,2,1,2,0,0,0,1,1,2,0,0,0,0,1,0,0,1,1,0,0,2,1,0,1,
2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,0,1,1,1,1,1,0,1,
1,2,2,0,0,0,1,0,2,2,2,0,0,0,1,1,0,0,0,0,0,1,1,0,2,0,0,1,1,1,0,1,
1,0,1,1,1,1,1,1,0,1,1,1,1,0,0,1,0,0,1,1,0,1,0,1,1,1,1,1,0,0,0,1,
1,0,0,1,0,1,2,1,0,0,1,1,1,2,0,0,0,1,1,0,1,0,1,1,0,0,1,0,0,0,0,0,
0,2,1,2,1,1,1,1,1,2,0,2,0,1,1,0,1,2,1,0,1,1,1,0,0,0,0,0,0,1,0,0,
2,1,1,0,1,2,0,0,1,1,1,0,0,0,1,1,0,0,0,0,0,1,0,0,1,0,0,0,2,1,0,1,
2,2,1,1,1,1,1,2,1,1,0,1,1,1,1,2,1,1,1,2,1,1,0,1,0,1,1,1,1,1,0,1,
1,2,2,0,0,0,0,0,1,1,0,0,0,0,2,1,0,0,0,0,0,2,0,0,2,2,0,0,2,0,0,1,
2,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,0,0,0,1,1,1,1,0,0,1,1,1,1,0,0,1,
1,1,2,0,0,3,1,0,2,1,1,1,0,0,1,1,1,0,0,0,1,1,0,0,0,1,0,0,1,0,1,0,
1,2,1,0,1,1,1,2,1,1,0,1,1,1,1,1,0,0,0,1,1,1,1,1,0,1,0,0,0,1,0,0,
2,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,2,0,0,0,
2,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,2,1,1,0,0,1,1,1,1,1,0,1,
2,1,1,1,2,1,1,1,0,1,1,2,1,0,0,0,0,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,1,0,1,1,1,1,1,0,0,1,1,2,1,0,0,0,1,1,0,0,0,1,1,0,0,1,0,1,0,0,0,
1,2,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,0,1,0,0,
2,0,0,0,1,1,1,1,0,0,1,1,0,0,0,0,0,1,1,1,2,0,0,1,0,0,1,0,1,0,0,0,
0,1,1,1,1,1,1,1,1,2,0,1,1,1,1,0,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,
1,0,0,1,1,1,1,1,0,0,2,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,
0,1,1,1,1,1,1,0,1,1,0,1,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,
1,0,0,1,1,1,0,0,0,0,1,0,2,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,
0,1,1,1,1,1,0,0,1,1,0,1,0,1,0,0,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,
0,0,0,1,0,0,0,0,0,0,1,1,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,1,1,1,0,1,0,0,1,1,0,1,0,1,1,0,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,
2,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,0,0,1,0,1,0,1,1,1,0,0,1,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,0,0,1,1,1,1,0,0,0,1,1,1,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,
0,1,1,1,1,1,1,0,1,1,0,1,0,1,0,0,1,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,
)

Latin2HungarianModel = { \
  'charToOrderMap': Latin2_HungarianCharToOrderMap,
  'precedenceMatrix': HungarianLangModel,
  'mTypicalPositiveRatio': 0.947368,
  'keepEnglishLetter': constants.True,
  'charsetName': "ISO-8859-2"
}

Win1250HungarianModel = { \
  'charToOrderMap': win1250HungarianCharToOrderMap,
  'precedenceMatrix': HungarianLangModel,
  'mTypicalPositiveRatio': 0.947368,
  'keepEnglishLetter': constants.True,
  'charsetName': "windows-1250"
}

########NEW FILE########
__FILENAME__ = langthaimodel
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants

# 255: Control characters that usually does not exist in any text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9

# The following result for thai was collected from a limited sample (1M). 

# Character Mapping Table:
TIS620CharToOrderMap = ( \
255,255,255,255,255,255,255,255,255,255,254,255,255,254,255,255,  # 00
255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,  # 10
253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,253,  # 20
252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,  # 30
253,182,106,107,100,183,184,185,101, 94,186,187,108,109,110,111,  # 40
188,189,190, 89, 95,112,113,191,192,193,194,253,253,253,253,253,  # 50
253, 64, 72, 73,114, 74,115,116,102, 81,201,117, 90,103, 78, 82,  # 60
 96,202, 91, 79, 84,104,105, 97, 98, 92,203,253,253,253,253,253,  # 70
209,210,211,212,213, 88,214,215,216,217,218,219,220,118,221,222,
223,224, 99, 85, 83,225,226,227,228,229,230,231,232,233,234,235,
236,  5, 30,237, 24,238, 75,  8, 26, 52, 34, 51,119, 47, 58, 57,
 49, 53, 55, 43, 20, 19, 44, 14, 48,  3, 17, 25, 39, 62, 31, 54,
 45,  9, 16,  2, 61, 15,239, 12, 42, 46, 18, 21, 76,  4, 66, 63,
 22, 10,  1, 36, 23, 13, 40, 27, 32, 35, 86,240,241,242,243,244,
 11, 28, 41, 29, 33,245, 50, 37,  6,  7, 67, 77, 38, 93,246,247,
 68, 56, 59, 65, 69, 60, 70, 80, 71, 87,248,249,250,251,252,253,
)

# Model Table: 
# total sequences: 100%
# first 512 sequences: 92.6386%
# first 1024 sequences:7.3177%
# rest  sequences:     1.0230%
# negative sequences:  0.0436% 
ThaiLangModel = ( \
0,1,3,3,3,3,0,0,3,3,0,3,3,0,3,3,3,3,3,3,3,3,0,0,3,3,3,0,3,3,3,3,
0,3,3,0,0,0,1,3,0,3,3,2,3,3,0,1,2,3,3,3,3,0,2,0,2,0,0,3,2,1,2,2,
3,0,3,3,2,3,0,0,3,3,0,3,3,0,3,3,3,3,3,3,3,3,3,0,3,2,3,0,2,2,2,3,
0,2,3,0,0,0,0,1,0,1,2,3,1,1,3,2,2,0,1,1,0,0,1,0,0,0,0,0,0,0,1,1,
3,3,3,2,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,3,3,2,3,2,3,3,2,2,2,
3,1,2,3,0,3,3,2,2,1,2,3,3,1,2,0,1,3,0,1,0,0,1,0,0,0,0,0,0,0,1,1,
3,3,2,2,3,3,3,3,1,2,3,3,3,3,3,2,2,2,2,3,3,2,2,3,3,2,2,3,2,3,2,2,
3,3,1,2,3,1,2,2,3,3,1,0,2,1,0,0,3,1,2,1,0,0,1,0,0,0,0,0,0,1,0,1,
3,3,3,3,3,3,2,2,3,3,3,3,2,3,2,2,3,3,2,2,3,2,2,2,2,1,1,3,1,2,1,1,
3,2,1,0,2,1,0,1,0,1,1,0,1,1,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,
3,3,3,2,3,2,3,3,2,2,3,2,3,3,2,3,1,1,2,3,2,2,2,3,2,2,2,2,2,1,2,1,
2,2,1,1,3,3,2,1,0,1,2,2,0,1,3,0,0,0,1,1,0,0,0,0,0,2,3,0,0,2,1,1,
3,3,2,3,3,2,0,0,3,3,0,3,3,0,2,2,3,1,2,2,1,1,1,0,2,2,2,0,2,2,1,1,
0,2,1,0,2,0,0,2,0,1,0,0,1,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,0,
3,3,2,3,3,2,0,0,3,3,0,2,3,0,2,1,2,2,2,2,1,2,0,0,2,2,2,0,2,2,1,1,
0,2,1,0,2,0,0,2,0,1,1,0,1,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,
3,3,2,3,2,3,2,0,2,2,1,3,2,1,3,2,1,2,3,2,2,3,0,2,3,2,2,1,2,2,2,2,
1,2,2,0,0,0,0,2,0,1,2,0,1,1,1,0,1,0,3,1,1,0,0,0,0,0,0,0,0,0,1,0,
3,3,2,3,3,2,3,2,2,2,3,2,2,3,2,2,1,2,3,2,2,3,1,3,2,2,2,3,2,2,2,3,
3,2,1,3,0,1,1,1,0,2,1,1,1,1,1,0,1,0,1,1,0,0,0,0,0,0,0,0,0,2,0,0,
1,0,0,3,0,3,3,3,3,3,0,0,3,0,2,2,3,3,3,3,3,0,0,0,1,1,3,0,0,0,0,2,
0,0,1,0,0,0,0,0,0,0,2,3,0,0,0,3,0,2,0,0,0,0,0,3,0,0,0,0,0,0,0,0,
2,0,3,3,3,3,0,0,2,3,0,0,3,0,3,3,2,3,3,3,3,3,0,0,3,3,3,0,0,0,3,3,
0,0,3,0,0,0,0,2,0,0,2,1,1,3,0,0,1,0,0,2,3,0,1,0,0,0,0,0,0,0,1,0,
3,3,3,3,2,3,3,3,3,3,3,3,1,2,1,3,3,2,2,1,2,2,2,3,1,1,2,0,2,1,2,1,
2,2,1,0,0,0,1,1,0,1,0,1,1,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,
3,0,2,1,2,3,3,3,0,2,0,2,2,0,2,1,3,2,2,1,2,1,0,0,2,2,1,0,2,1,2,2,
0,1,1,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,2,1,3,3,1,1,3,0,2,3,1,1,3,2,1,1,2,0,2,2,3,2,1,1,1,1,1,2,
3,0,0,1,3,1,2,1,2,0,3,0,0,0,1,0,3,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,
3,3,1,1,3,2,3,3,3,1,3,2,1,3,2,1,3,2,2,2,2,1,3,3,1,2,1,3,1,2,3,0,
2,1,1,3,2,2,2,1,2,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,
3,3,2,3,2,3,3,2,3,2,3,2,3,3,2,1,0,3,2,2,2,1,2,2,2,1,2,2,1,2,1,1,
2,2,2,3,0,1,3,1,1,1,1,0,1,1,0,2,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,2,3,2,2,1,1,3,2,3,2,3,2,0,3,2,2,1,2,0,2,2,2,1,2,2,2,2,1,
3,2,1,2,2,1,0,2,0,1,0,0,1,1,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,1,
3,3,3,3,3,2,3,1,2,3,3,2,2,3,0,1,1,2,0,3,3,2,2,3,0,1,1,3,0,0,0,0,
3,1,0,3,3,0,2,0,2,1,0,0,3,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,2,3,2,3,3,0,1,3,1,1,2,1,2,1,1,3,1,1,0,2,3,1,1,1,1,1,1,1,1,
3,1,1,2,2,2,2,1,1,1,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
3,2,2,1,1,2,1,3,3,2,3,2,2,3,2,2,3,1,2,2,1,2,0,3,2,1,2,2,2,2,2,1,
3,2,1,2,2,2,1,1,1,1,0,0,1,1,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,3,3,3,3,1,3,3,0,2,1,0,3,2,0,0,3,1,0,1,1,0,1,0,0,0,0,0,1,
1,0,0,1,0,3,2,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,2,2,2,3,0,0,1,3,0,3,2,0,3,2,2,3,3,3,3,3,1,0,2,2,2,0,2,2,1,2,
0,2,3,0,0,0,0,1,0,1,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
3,0,2,3,1,3,3,2,3,3,0,3,3,0,3,2,2,3,2,3,3,3,0,0,2,2,3,0,1,1,1,3,
0,0,3,0,0,0,2,2,0,1,3,0,1,2,2,2,3,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,
3,2,3,3,2,0,3,3,2,2,3,1,3,2,1,3,2,0,1,2,2,0,2,3,2,1,0,3,0,0,0,0,
3,0,0,2,3,1,3,0,0,3,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,1,3,2,2,2,1,2,0,1,3,1,1,3,1,3,0,0,2,1,1,1,1,2,1,1,1,0,2,1,0,1,
1,2,0,0,0,3,1,1,0,0,0,0,1,0,1,0,0,1,0,1,0,0,0,0,0,3,1,0,0,0,1,0,
3,3,3,3,2,2,2,2,2,1,3,1,1,1,2,0,1,1,2,1,2,1,3,2,0,0,3,1,1,1,1,1,
3,1,0,2,3,0,0,0,3,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,2,3,0,3,3,0,2,0,0,0,0,0,0,0,3,0,0,1,0,0,0,0,0,0,0,0,0,0,0,
0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,2,3,1,3,0,0,1,2,0,0,2,0,3,3,2,3,3,3,2,3,0,0,2,2,2,0,0,0,2,2,
0,0,1,0,0,0,0,3,0,0,0,0,2,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,
0,0,0,3,0,2,0,0,0,0,0,0,0,0,0,0,1,2,3,1,3,3,0,0,1,0,3,0,0,0,0,0,
0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,1,2,3,1,2,3,1,0,3,0,2,2,1,0,2,1,1,2,0,1,0,0,1,1,1,1,0,1,0,0,
1,0,0,0,0,1,1,0,3,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,3,3,2,1,0,1,1,1,3,1,2,2,2,2,2,2,1,1,1,1,0,3,1,0,1,3,1,1,1,1,
1,1,0,2,0,1,3,1,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,2,0,1,
3,0,2,2,1,3,3,2,3,3,0,1,1,0,2,2,1,2,1,3,3,1,0,0,3,2,0,0,0,0,2,1,
0,1,0,0,0,0,1,2,0,1,1,3,1,1,2,2,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
0,0,3,0,0,1,0,0,0,3,0,0,3,0,3,1,0,1,1,1,3,2,0,0,0,3,0,0,0,0,2,0,
0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,2,0,0,0,0,0,0,0,0,0,
3,3,1,3,2,1,3,3,1,2,2,0,1,2,1,0,1,2,0,0,0,0,0,3,0,0,0,3,0,0,0,0,
3,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,1,2,0,3,3,3,2,2,0,1,1,0,1,3,0,0,0,2,2,0,0,0,0,3,1,0,1,0,0,0,
0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,2,3,1,2,0,0,2,1,0,3,1,0,1,2,0,1,1,1,1,3,0,0,3,1,1,0,2,2,1,1,
0,2,0,0,0,0,0,1,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,0,3,1,2,0,0,2,2,0,1,2,0,1,0,1,3,1,2,1,0,0,0,2,0,3,0,0,0,1,0,
0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,1,1,2,2,0,0,0,2,0,2,1,0,1,1,0,1,1,1,2,1,0,0,1,1,1,0,2,1,1,1,
0,1,1,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,
0,0,0,2,0,1,3,1,1,1,1,0,0,0,0,3,2,0,1,0,0,0,1,2,0,0,0,1,0,0,0,0,
0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,3,3,3,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,0,2,3,2,2,0,0,0,1,0,0,0,0,2,3,2,1,2,2,3,0,0,0,2,3,1,0,0,0,1,1,
0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,
3,3,2,2,0,1,0,0,0,0,2,0,2,0,1,0,0,0,1,1,0,0,0,2,1,0,1,0,1,1,0,0,
0,1,0,2,0,0,1,0,3,0,1,0,0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,1,0,0,1,0,0,0,0,0,1,1,2,0,0,0,0,1,0,0,1,3,1,0,0,0,0,1,1,0,0,
0,1,0,0,0,0,3,0,0,0,0,0,0,3,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,
3,3,1,1,1,1,2,3,0,0,2,1,1,1,1,1,0,2,1,1,0,0,0,2,1,0,1,2,1,1,0,1,
2,1,0,3,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,3,1,0,0,0,0,0,0,0,3,0,0,0,3,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,1,
0,0,0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,3,2,0,0,0,0,0,0,1,2,1,0,1,1,0,2,0,0,1,0,0,2,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,2,0,0,0,1,3,0,1,0,0,0,2,0,0,0,0,0,0,0,1,2,0,0,0,0,0,
3,3,0,0,1,1,2,0,0,1,2,1,0,1,1,1,0,1,1,0,0,2,1,1,0,1,0,0,1,1,1,0,
0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,2,2,1,0,0,0,0,1,0,0,0,0,3,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,
2,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,3,0,0,1,1,0,0,0,2,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
1,1,0,1,2,0,1,2,0,0,1,1,0,2,0,1,0,0,1,0,0,0,0,1,0,0,0,2,0,0,0,0,
1,0,0,1,0,1,1,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,1,0,0,0,0,0,0,0,1,1,0,1,1,0,2,1,3,0,0,0,0,1,1,0,0,0,0,0,0,0,3,
1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,0,1,0,1,0,0,2,0,0,2,0,0,1,1,2,0,0,1,1,0,0,0,1,0,0,0,1,1,0,0,0,
1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,
1,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,1,1,0,0,0,
2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,0,0,0,0,2,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,3,0,0,0,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,1,0,0,0,0,
1,0,0,0,0,0,0,0,0,1,0,0,0,0,2,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,1,1,0,0,2,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
)

TIS620ThaiModel = { \
  'charToOrderMap': TIS620CharToOrderMap,
  'precedenceMatrix': ThaiLangModel,
  'mTypicalPositiveRatio': 0.926386,
  'keepEnglishLetter': constants.False,
  'charsetName': "TIS-620"
}

########NEW FILE########
__FILENAME__ = latin1prober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from charsetprober import CharSetProber
import constants
import operator

FREQ_CAT_NUM = 4

UDF = 0 # undefined
OTH = 1 # other
ASC = 2 # ascii capital letter
ASS = 3 # ascii small letter
ACV = 4 # accent capital vowel
ACO = 5 # accent capital other
ASV = 6 # accent small vowel
ASO = 7 # accent small other
CLASS_NUM = 8 # total classes

Latin1_CharToClass = ( \
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 00 - 07
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 08 - 0F
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 10 - 17
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 18 - 1F
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 20 - 27
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 28 - 2F
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 30 - 37
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 38 - 3F
  OTH, ASC, ASC, ASC, ASC, ASC, ASC, ASC,   # 40 - 47
  ASC, ASC, ASC, ASC, ASC, ASC, ASC, ASC,   # 48 - 4F
  ASC, ASC, ASC, ASC, ASC, ASC, ASC, ASC,   # 50 - 57
  ASC, ASC, ASC, OTH, OTH, OTH, OTH, OTH,   # 58 - 5F
  OTH, ASS, ASS, ASS, ASS, ASS, ASS, ASS,   # 60 - 67
  ASS, ASS, ASS, ASS, ASS, ASS, ASS, ASS,   # 68 - 6F
  ASS, ASS, ASS, ASS, ASS, ASS, ASS, ASS,   # 70 - 77
  ASS, ASS, ASS, OTH, OTH, OTH, OTH, OTH,   # 78 - 7F
  OTH, UDF, OTH, ASO, OTH, OTH, OTH, OTH,   # 80 - 87
  OTH, OTH, ACO, OTH, ACO, UDF, ACO, UDF,   # 88 - 8F
  UDF, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 90 - 97
  OTH, OTH, ASO, OTH, ASO, UDF, ASO, ACO,   # 98 - 9F
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # A0 - A7
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # A8 - AF
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # B0 - B7
  OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # B8 - BF
  ACV, ACV, ACV, ACV, ACV, ACV, ACO, ACO,   # C0 - C7
  ACV, ACV, ACV, ACV, ACV, ACV, ACV, ACV,   # C8 - CF
  ACO, ACO, ACV, ACV, ACV, ACV, ACV, OTH,   # D0 - D7
  ACV, ACV, ACV, ACV, ACV, ACO, ACO, ACO,   # D8 - DF
  ASV, ASV, ASV, ASV, ASV, ASV, ASO, ASO,   # E0 - E7
  ASV, ASV, ASV, ASV, ASV, ASV, ASV, ASV,   # E8 - EF
  ASO, ASO, ASV, ASV, ASV, ASV, ASV, OTH,   # F0 - F7
  ASV, ASV, ASV, ASV, ASV, ASO, ASO, ASO,   # F8 - FF
)

# 0 : illegal
# 1 : very unlikely
# 2 : normal
# 3 : very likely
Latin1ClassModel = ( \
# UDF OTH ASC ASS ACV ACO ASV ASO
   0,  0,  0,  0,  0,  0,  0,  0,  # UDF
   0,  3,  3,  3,  3,  3,  3,  3,  # OTH
   0,  3,  3,  3,  3,  3,  3,  3,  # ASC
   0,  3,  3,  3,  1,  1,  3,  3,  # ASS
   0,  3,  3,  3,  1,  2,  1,  2,  # ACV
   0,  3,  3,  3,  3,  3,  3,  3,  # ACO
   0,  3,  1,  3,  1,  1,  1,  3,  # ASV
   0,  3,  1,  3,  1,  1,  3,  3,  # ASO
)

class Latin1Prober(CharSetProber):
    def __init__(self):
        CharSetProber.__init__(self)
        self.reset()

    def reset(self):
        self._mLastCharClass = OTH
        self._mFreqCounter = [0] * FREQ_CAT_NUM
        CharSetProber.reset(self)

    def get_charset_name(self):
        return "windows-1252"

    def feed(self, aBuf):
        aBuf = self.filter_with_english_letters(aBuf)
        for c in aBuf:
            try:
                charClass = Latin1_CharToClass[ord(c)]
            except IndexError:
                return constants.eError
            freq = Latin1ClassModel[(self._mLastCharClass * CLASS_NUM) + charClass]
            if freq == 0:
                self._mState = constants.eNotMe
                break
            self._mFreqCounter[freq] += 1
            self._mLastCharClass = charClass

        return self.get_state()

    def get_confidence(self):
        if self.get_state() == constants.eNotMe:
            return 0.01

        total = reduce(operator.add, self._mFreqCounter)
        if total < 0.01:
            confidence = 0.0
        else:
            confidence = (self._mFreqCounter[3] / total) - (self._mFreqCounter[1] * 20.0 / total)
        if confidence < 0.0:
            confidence = 0.0
        # lower the confidence of latin1 so that other more accurate detector
        # can take priority.
        confidence = confidence * 0.5
        return confidence

########NEW FILE########
__FILENAME__ = mbcharsetprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#   Proofpoint, Inc.
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants, sys
from constants import eStart, eError, eItsMe
from charsetprober import CharSetProber

class MultiByteCharSetProber(CharSetProber):
    def __init__(self):
        CharSetProber.__init__(self)
        self._mDistributionAnalyzer = None
        self._mCodingSM = None
        self._mLastChar = ['\x00', '\x00']

    def reset(self):
        CharSetProber.reset(self)
        if self._mCodingSM:
            self._mCodingSM.reset()
        if self._mDistributionAnalyzer:
            self._mDistributionAnalyzer.reset()
        self._mLastChar = ['\x00', '\x00']

    def get_charset_name(self):
        pass

    def feed(self, aBuf):
        aLen = len(aBuf)
        for i in range(0, aLen):
            codingState = self._mCodingSM.next_state(aBuf[i])
            if codingState == eError:
                if constants._debug:
                    sys.stderr.write(self.get_charset_name() + ' prober hit error at byte ' + str(i) + '\n')
                self._mState = constants.eNotMe
                break
            elif codingState == eItsMe:
                self._mState = constants.eFoundIt
                break
            elif codingState == eStart:
                charLen = self._mCodingSM.get_current_charlen()
                if i == 0:
                    self._mLastChar[1] = aBuf[0]
                    self._mDistributionAnalyzer.feed(self._mLastChar, charLen)
                else:
                    self._mDistributionAnalyzer.feed(aBuf[i-1:i+1], charLen)
                    
        self._mLastChar[0] = aBuf[aLen - 1]
        
        if self.get_state() == constants.eDetecting:
            if self._mDistributionAnalyzer.got_enough_data() and \
               (self.get_confidence() > constants.SHORTCUT_THRESHOLD):
                self._mState = constants.eFoundIt

        return self.get_state()

    def get_confidence(self):
        return self._mDistributionAnalyzer.get_confidence()

########NEW FILE########
__FILENAME__ = mbcsgroupprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#   Proofpoint, Inc.
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from charsetgroupprober import CharSetGroupProber
from utf8prober import UTF8Prober
from sjisprober import SJISProber
from eucjpprober import EUCJPProber
from gb2312prober import GB2312Prober
from euckrprober import EUCKRProber
from big5prober import Big5Prober
from euctwprober import EUCTWProber

class MBCSGroupProber(CharSetGroupProber):
    def __init__(self):
        CharSetGroupProber.__init__(self)
        self._mProbers = [ \
            UTF8Prober(),
            SJISProber(),
            EUCJPProber(),
            GB2312Prober(),
            EUCKRProber(),
            Big5Prober(),
            EUCTWProber()]
        self.reset()

########NEW FILE########
__FILENAME__ = mbcssm
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from constants import eStart, eError, eItsMe

# BIG5 

BIG5_cls = ( \
    1,1,1,1,1,1,1,1,  # 00 - 07    #allow 0x00 as legal value
    1,1,1,1,1,1,0,0,  # 08 - 0f 
    1,1,1,1,1,1,1,1,  # 10 - 17 
    1,1,1,0,1,1,1,1,  # 18 - 1f 
    1,1,1,1,1,1,1,1,  # 20 - 27 
    1,1,1,1,1,1,1,1,  # 28 - 2f 
    1,1,1,1,1,1,1,1,  # 30 - 37 
    1,1,1,1,1,1,1,1,  # 38 - 3f 
    2,2,2,2,2,2,2,2,  # 40 - 47 
    2,2,2,2,2,2,2,2,  # 48 - 4f 
    2,2,2,2,2,2,2,2,  # 50 - 57 
    2,2,2,2,2,2,2,2,  # 58 - 5f 
    2,2,2,2,2,2,2,2,  # 60 - 67 
    2,2,2,2,2,2,2,2,  # 68 - 6f 
    2,2,2,2,2,2,2,2,  # 70 - 77 
    2,2,2,2,2,2,2,1,  # 78 - 7f 
    4,4,4,4,4,4,4,4,  # 80 - 87 
    4,4,4,4,4,4,4,4,  # 88 - 8f 
    4,4,4,4,4,4,4,4,  # 90 - 97 
    4,4,4,4,4,4,4,4,  # 98 - 9f 
    4,3,3,3,3,3,3,3,  # a0 - a7 
    3,3,3,3,3,3,3,3,  # a8 - af 
    3,3,3,3,3,3,3,3,  # b0 - b7 
    3,3,3,3,3,3,3,3,  # b8 - bf 
    3,3,3,3,3,3,3,3,  # c0 - c7 
    3,3,3,3,3,3,3,3,  # c8 - cf 
    3,3,3,3,3,3,3,3,  # d0 - d7 
    3,3,3,3,3,3,3,3,  # d8 - df 
    3,3,3,3,3,3,3,3,  # e0 - e7 
    3,3,3,3,3,3,3,3,  # e8 - ef 
    3,3,3,3,3,3,3,3,  # f0 - f7 
    3,3,3,3,3,3,3,0)  # f8 - ff 

BIG5_st = ( \
    eError,eStart,eStart,     3,eError,eError,eError,eError,#00-07 
    eError,eError,eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eError,#08-0f 
    eError,eStart,eStart,eStart,eStart,eStart,eStart,eStart)#10-17 

Big5CharLenTable = (0, 1, 1, 2, 0)

Big5SMModel = {'classTable': BIG5_cls,
               'classFactor': 5,
               'stateTable': BIG5_st,
               'charLenTable': Big5CharLenTable,
               'name': 'Big5'}

# EUC-JP

EUCJP_cls = ( \
    4,4,4,4,4,4,4,4,  # 00 - 07 
    4,4,4,4,4,4,5,5,  # 08 - 0f 
    4,4,4,4,4,4,4,4,  # 10 - 17 
    4,4,4,5,4,4,4,4,  # 18 - 1f 
    4,4,4,4,4,4,4,4,  # 20 - 27 
    4,4,4,4,4,4,4,4,  # 28 - 2f 
    4,4,4,4,4,4,4,4,  # 30 - 37 
    4,4,4,4,4,4,4,4,  # 38 - 3f 
    4,4,4,4,4,4,4,4,  # 40 - 47 
    4,4,4,4,4,4,4,4,  # 48 - 4f 
    4,4,4,4,4,4,4,4,  # 50 - 57 
    4,4,4,4,4,4,4,4,  # 58 - 5f 
    4,4,4,4,4,4,4,4,  # 60 - 67 
    4,4,4,4,4,4,4,4,  # 68 - 6f 
    4,4,4,4,4,4,4,4,  # 70 - 77 
    4,4,4,4,4,4,4,4,  # 78 - 7f 
    5,5,5,5,5,5,5,5,  # 80 - 87 
    5,5,5,5,5,5,1,3,  # 88 - 8f 
    5,5,5,5,5,5,5,5,  # 90 - 97 
    5,5,5,5,5,5,5,5,  # 98 - 9f 
    5,2,2,2,2,2,2,2,  # a0 - a7 
    2,2,2,2,2,2,2,2,  # a8 - af 
    2,2,2,2,2,2,2,2,  # b0 - b7 
    2,2,2,2,2,2,2,2,  # b8 - bf 
    2,2,2,2,2,2,2,2,  # c0 - c7 
    2,2,2,2,2,2,2,2,  # c8 - cf 
    2,2,2,2,2,2,2,2,  # d0 - d7 
    2,2,2,2,2,2,2,2,  # d8 - df 
    0,0,0,0,0,0,0,0,  # e0 - e7 
    0,0,0,0,0,0,0,0,  # e8 - ef 
    0,0,0,0,0,0,0,0,  # f0 - f7 
    0,0,0,0,0,0,0,5)  # f8 - ff 

EUCJP_st = ( \
          3,     4,     3,     5,eStart,eError,eError,eError,#00-07 
     eError,eError,eError,eError,eItsMe,eItsMe,eItsMe,eItsMe,#08-0f 
     eItsMe,eItsMe,eStart,eError,eStart,eError,eError,eError,#10-17 
     eError,eError,eStart,eError,eError,eError,     3,eError,#18-1f 
          3,eError,eError,eError,eStart,eStart,eStart,eStart)#20-27 

EUCJPCharLenTable = (2, 2, 2, 3, 1, 0)

EUCJPSMModel = {'classTable': EUCJP_cls,
                'classFactor': 6,
                'stateTable': EUCJP_st,
                'charLenTable': EUCJPCharLenTable,
                'name': 'EUC-JP'}

# EUC-KR

EUCKR_cls  = ( \
    1,1,1,1,1,1,1,1,  # 00 - 07 
    1,1,1,1,1,1,0,0,  # 08 - 0f 
    1,1,1,1,1,1,1,1,  # 10 - 17 
    1,1,1,0,1,1,1,1,  # 18 - 1f 
    1,1,1,1,1,1,1,1,  # 20 - 27 
    1,1,1,1,1,1,1,1,  # 28 - 2f 
    1,1,1,1,1,1,1,1,  # 30 - 37 
    1,1,1,1,1,1,1,1,  # 38 - 3f 
    1,1,1,1,1,1,1,1,  # 40 - 47 
    1,1,1,1,1,1,1,1,  # 48 - 4f 
    1,1,1,1,1,1,1,1,  # 50 - 57 
    1,1,1,1,1,1,1,1,  # 58 - 5f 
    1,1,1,1,1,1,1,1,  # 60 - 67 
    1,1,1,1,1,1,1,1,  # 68 - 6f 
    1,1,1,1,1,1,1,1,  # 70 - 77 
    1,1,1,1,1,1,1,1,  # 78 - 7f 
    0,0,0,0,0,0,0,0,  # 80 - 87 
    0,0,0,0,0,0,0,0,  # 88 - 8f 
    0,0,0,0,0,0,0,0,  # 90 - 97 
    0,0,0,0,0,0,0,0,  # 98 - 9f 
    0,2,2,2,2,2,2,2,  # a0 - a7 
    2,2,2,2,2,3,3,3,  # a8 - af 
    2,2,2,2,2,2,2,2,  # b0 - b7 
    2,2,2,2,2,2,2,2,  # b8 - bf 
    2,2,2,2,2,2,2,2,  # c0 - c7 
    2,3,2,2,2,2,2,2,  # c8 - cf 
    2,2,2,2,2,2,2,2,  # d0 - d7 
    2,2,2,2,2,2,2,2,  # d8 - df 
    2,2,2,2,2,2,2,2,  # e0 - e7 
    2,2,2,2,2,2,2,2,  # e8 - ef 
    2,2,2,2,2,2,2,2,  # f0 - f7 
    2,2,2,2,2,2,2,0)  # f8 - ff 

EUCKR_st = (
    eError,eStart,     3,eError,eError,eError,eError,eError,#00-07 
    eItsMe,eItsMe,eItsMe,eItsMe,eError,eError,eStart,eStart)#08-0f 

EUCKRCharLenTable = (0, 1, 2, 0)

EUCKRSMModel = {'classTable': EUCKR_cls,
                'classFactor': 4,
                'stateTable': EUCKR_st,
                'charLenTable': EUCKRCharLenTable,
                'name': 'EUC-KR'}

# EUC-TW

EUCTW_cls = ( \
    2,2,2,2,2,2,2,2,  # 00 - 07 
    2,2,2,2,2,2,0,0,  # 08 - 0f 
    2,2,2,2,2,2,2,2,  # 10 - 17 
    2,2,2,0,2,2,2,2,  # 18 - 1f 
    2,2,2,2,2,2,2,2,  # 20 - 27 
    2,2,2,2,2,2,2,2,  # 28 - 2f 
    2,2,2,2,2,2,2,2,  # 30 - 37 
    2,2,2,2,2,2,2,2,  # 38 - 3f 
    2,2,2,2,2,2,2,2,  # 40 - 47 
    2,2,2,2,2,2,2,2,  # 48 - 4f 
    2,2,2,2,2,2,2,2,  # 50 - 57 
    2,2,2,2,2,2,2,2,  # 58 - 5f 
    2,2,2,2,2,2,2,2,  # 60 - 67 
    2,2,2,2,2,2,2,2,  # 68 - 6f 
    2,2,2,2,2,2,2,2,  # 70 - 77 
    2,2,2,2,2,2,2,2,  # 78 - 7f 
    0,0,0,0,0,0,0,0,  # 80 - 87 
    0,0,0,0,0,0,6,0,  # 88 - 8f 
    0,0,0,0,0,0,0,0,  # 90 - 97 
    0,0,0,0,0,0,0,0,  # 98 - 9f 
    0,3,4,4,4,4,4,4,  # a0 - a7 
    5,5,1,1,1,1,1,1,  # a8 - af 
    1,1,1,1,1,1,1,1,  # b0 - b7 
    1,1,1,1,1,1,1,1,  # b8 - bf 
    1,1,3,1,3,3,3,3,  # c0 - c7 
    3,3,3,3,3,3,3,3,  # c8 - cf 
    3,3,3,3,3,3,3,3,  # d0 - d7 
    3,3,3,3,3,3,3,3,  # d8 - df 
    3,3,3,3,3,3,3,3,  # e0 - e7 
    3,3,3,3,3,3,3,3,  # e8 - ef 
    3,3,3,3,3,3,3,3,  # f0 - f7 
    3,3,3,3,3,3,3,0)  # f8 - ff 

EUCTW_st = ( \
    eError,eError,eStart,     3,     3,     3,     4,eError,#00-07 
    eError,eError,eError,eError,eError,eError,eItsMe,eItsMe,#08-0f 
    eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eError,eStart,eError,#10-17 
    eStart,eStart,eStart,eError,eError,eError,eError,eError,#18-1f 
         5,eError,eError,eError,eStart,eError,eStart,eStart,#20-27 
    eStart,eError,eStart,eStart,eStart,eStart,eStart,eStart)#28-2f 

EUCTWCharLenTable = (0, 0, 1, 2, 2, 2, 3)

EUCTWSMModel = {'classTable': EUCTW_cls,
                'classFactor': 7,
                'stateTable': EUCTW_st,
                'charLenTable': EUCTWCharLenTable,
                'name': 'x-euc-tw'}

# GB2312

GB2312_cls = ( \
    1,1,1,1,1,1,1,1,  # 00 - 07 
    1,1,1,1,1,1,0,0,  # 08 - 0f 
    1,1,1,1,1,1,1,1,  # 10 - 17 
    1,1,1,0,1,1,1,1,  # 18 - 1f 
    1,1,1,1,1,1,1,1,  # 20 - 27 
    1,1,1,1,1,1,1,1,  # 28 - 2f 
    3,3,3,3,3,3,3,3,  # 30 - 37 
    3,3,1,1,1,1,1,1,  # 38 - 3f 
    2,2,2,2,2,2,2,2,  # 40 - 47 
    2,2,2,2,2,2,2,2,  # 48 - 4f 
    2,2,2,2,2,2,2,2,  # 50 - 57 
    2,2,2,2,2,2,2,2,  # 58 - 5f 
    2,2,2,2,2,2,2,2,  # 60 - 67 
    2,2,2,2,2,2,2,2,  # 68 - 6f 
    2,2,2,2,2,2,2,2,  # 70 - 77 
    2,2,2,2,2,2,2,4,  # 78 - 7f 
    5,6,6,6,6,6,6,6,  # 80 - 87 
    6,6,6,6,6,6,6,6,  # 88 - 8f 
    6,6,6,6,6,6,6,6,  # 90 - 97 
    6,6,6,6,6,6,6,6,  # 98 - 9f 
    6,6,6,6,6,6,6,6,  # a0 - a7 
    6,6,6,6,6,6,6,6,  # a8 - af 
    6,6,6,6,6,6,6,6,  # b0 - b7 
    6,6,6,6,6,6,6,6,  # b8 - bf 
    6,6,6,6,6,6,6,6,  # c0 - c7 
    6,6,6,6,6,6,6,6,  # c8 - cf 
    6,6,6,6,6,6,6,6,  # d0 - d7 
    6,6,6,6,6,6,6,6,  # d8 - df 
    6,6,6,6,6,6,6,6,  # e0 - e7 
    6,6,6,6,6,6,6,6,  # e8 - ef 
    6,6,6,6,6,6,6,6,  # f0 - f7 
    6,6,6,6,6,6,6,0)  # f8 - ff 

GB2312_st = ( \
    eError,eStart,eStart,eStart,eStart,eStart,     3,eError,#00-07 
    eError,eError,eError,eError,eError,eError,eItsMe,eItsMe,#08-0f 
    eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eError,eError,eStart,#10-17 
         4,eError,eStart,eStart,eError,eError,eError,eError,#18-1f 
    eError,eError,     5,eError,eError,eError,eItsMe,eError,#20-27 
    eError,eError,eStart,eStart,eStart,eStart,eStart,eStart)#28-2f 

# To be accurate, the length of class 6 can be either 2 or 4. 
# But it is not necessary to discriminate between the two since 
# it is used for frequency analysis only, and we are validing 
# each code range there as well. So it is safe to set it to be 
# 2 here. 
GB2312CharLenTable = (0, 1, 1, 1, 1, 1, 2)

GB2312SMModel = {'classTable': GB2312_cls,
                  'classFactor': 7,
                  'stateTable': GB2312_st,
                  'charLenTable': GB2312CharLenTable,
                  'name': 'GB2312'}

# Shift_JIS

SJIS_cls = ( \
    1,1,1,1,1,1,1,1,  # 00 - 07 
    1,1,1,1,1,1,0,0,  # 08 - 0f 
    1,1,1,1,1,1,1,1,  # 10 - 17 
    1,1,1,0,1,1,1,1,  # 18 - 1f 
    1,1,1,1,1,1,1,1,  # 20 - 27 
    1,1,1,1,1,1,1,1,  # 28 - 2f 
    1,1,1,1,1,1,1,1,  # 30 - 37 
    1,1,1,1,1,1,1,1,  # 38 - 3f 
    2,2,2,2,2,2,2,2,  # 40 - 47 
    2,2,2,2,2,2,2,2,  # 48 - 4f 
    2,2,2,2,2,2,2,2,  # 50 - 57 
    2,2,2,2,2,2,2,2,  # 58 - 5f 
    2,2,2,2,2,2,2,2,  # 60 - 67 
    2,2,2,2,2,2,2,2,  # 68 - 6f 
    2,2,2,2,2,2,2,2,  # 70 - 77 
    2,2,2,2,2,2,2,1,  # 78 - 7f 
    3,3,3,3,3,3,3,3,  # 80 - 87 
    3,3,3,3,3,3,3,3,  # 88 - 8f 
    3,3,3,3,3,3,3,3,  # 90 - 97 
    3,3,3,3,3,3,3,3,  # 98 - 9f 
    #0xa0 is illegal in sjis encoding, but some pages does 
    #contain such byte. We need to be more error forgiven.
    2,2,2,2,2,2,2,2,  # a0 - a7     
    2,2,2,2,2,2,2,2,  # a8 - af 
    2,2,2,2,2,2,2,2,  # b0 - b7 
    2,2,2,2,2,2,2,2,  # b8 - bf 
    2,2,2,2,2,2,2,2,  # c0 - c7 
    2,2,2,2,2,2,2,2,  # c8 - cf 
    2,2,2,2,2,2,2,2,  # d0 - d7 
    2,2,2,2,2,2,2,2,  # d8 - df 
    3,3,3,3,3,3,3,3,  # e0 - e7 
    3,3,3,3,3,4,4,4,  # e8 - ef 
    4,4,4,4,4,4,4,4,  # f0 - f7 
    4,4,4,4,4,0,0,0)  # f8 - ff 

SJIS_st = ( \
    eError,eStart,eStart,     3,eError,eError,eError,eError,#00-07 
    eError,eError,eError,eError,eItsMe,eItsMe,eItsMe,eItsMe,#08-0f 
    eItsMe,eItsMe,eError,eError,eStart,eStart,eStart,eStart)#10-17 

SJISCharLenTable = (0, 1, 1, 2, 0, 0)

SJISSMModel = {'classTable': SJIS_cls,
               'classFactor': 6,
               'stateTable': SJIS_st,
               'charLenTable': SJISCharLenTable,
               'name': 'Shift_JIS'}

# UCS2-BE

UCS2BE_cls = ( \
    0,0,0,0,0,0,0,0,  # 00 - 07 
    0,0,1,0,0,2,0,0,  # 08 - 0f 
    0,0,0,0,0,0,0,0,  # 10 - 17 
    0,0,0,3,0,0,0,0,  # 18 - 1f 
    0,0,0,0,0,0,0,0,  # 20 - 27 
    0,3,3,3,3,3,0,0,  # 28 - 2f 
    0,0,0,0,0,0,0,0,  # 30 - 37 
    0,0,0,0,0,0,0,0,  # 38 - 3f 
    0,0,0,0,0,0,0,0,  # 40 - 47 
    0,0,0,0,0,0,0,0,  # 48 - 4f 
    0,0,0,0,0,0,0,0,  # 50 - 57 
    0,0,0,0,0,0,0,0,  # 58 - 5f 
    0,0,0,0,0,0,0,0,  # 60 - 67 
    0,0,0,0,0,0,0,0,  # 68 - 6f 
    0,0,0,0,0,0,0,0,  # 70 - 77 
    0,0,0,0,0,0,0,0,  # 78 - 7f 
    0,0,0,0,0,0,0,0,  # 80 - 87 
    0,0,0,0,0,0,0,0,  # 88 - 8f 
    0,0,0,0,0,0,0,0,  # 90 - 97 
    0,0,0,0,0,0,0,0,  # 98 - 9f 
    0,0,0,0,0,0,0,0,  # a0 - a7 
    0,0,0,0,0,0,0,0,  # a8 - af 
    0,0,0,0,0,0,0,0,  # b0 - b7 
    0,0,0,0,0,0,0,0,  # b8 - bf 
    0,0,0,0,0,0,0,0,  # c0 - c7 
    0,0,0,0,0,0,0,0,  # c8 - cf 
    0,0,0,0,0,0,0,0,  # d0 - d7 
    0,0,0,0,0,0,0,0,  # d8 - df 
    0,0,0,0,0,0,0,0,  # e0 - e7 
    0,0,0,0,0,0,0,0,  # e8 - ef 
    0,0,0,0,0,0,0,0,  # f0 - f7 
    0,0,0,0,0,0,4,5)  # f8 - ff 

UCS2BE_st  = ( \
          5,     7,     7,eError,     4,     3,eError,eError,#00-07 
     eError,eError,eError,eError,eItsMe,eItsMe,eItsMe,eItsMe,#08-0f 
     eItsMe,eItsMe,     6,     6,     6,     6,eError,eError,#10-17 
          6,     6,     6,     6,     6,eItsMe,     6,     6,#18-1f 
          6,     6,     6,     6,     5,     7,     7,eError,#20-27 
          5,     8,     6,     6,eError,     6,     6,     6,#28-2f 
          6,     6,     6,     6,eError,eError,eStart,eStart)#30-37 

UCS2BECharLenTable = (2, 2, 2, 0, 2, 2)

UCS2BESMModel = {'classTable': UCS2BE_cls,
                 'classFactor': 6,
                 'stateTable': UCS2BE_st,
                 'charLenTable': UCS2BECharLenTable,
                 'name': 'UTF-16BE'}

# UCS2-LE

UCS2LE_cls = ( \
    0,0,0,0,0,0,0,0,  # 00 - 07 
    0,0,1,0,0,2,0,0,  # 08 - 0f 
    0,0,0,0,0,0,0,0,  # 10 - 17 
    0,0,0,3,0,0,0,0,  # 18 - 1f 
    0,0,0,0,0,0,0,0,  # 20 - 27 
    0,3,3,3,3,3,0,0,  # 28 - 2f 
    0,0,0,0,0,0,0,0,  # 30 - 37 
    0,0,0,0,0,0,0,0,  # 38 - 3f 
    0,0,0,0,0,0,0,0,  # 40 - 47 
    0,0,0,0,0,0,0,0,  # 48 - 4f 
    0,0,0,0,0,0,0,0,  # 50 - 57 
    0,0,0,0,0,0,0,0,  # 58 - 5f 
    0,0,0,0,0,0,0,0,  # 60 - 67 
    0,0,0,0,0,0,0,0,  # 68 - 6f 
    0,0,0,0,0,0,0,0,  # 70 - 77 
    0,0,0,0,0,0,0,0,  # 78 - 7f 
    0,0,0,0,0,0,0,0,  # 80 - 87 
    0,0,0,0,0,0,0,0,  # 88 - 8f 
    0,0,0,0,0,0,0,0,  # 90 - 97 
    0,0,0,0,0,0,0,0,  # 98 - 9f 
    0,0,0,0,0,0,0,0,  # a0 - a7 
    0,0,0,0,0,0,0,0,  # a8 - af 
    0,0,0,0,0,0,0,0,  # b0 - b7 
    0,0,0,0,0,0,0,0,  # b8 - bf 
    0,0,0,0,0,0,0,0,  # c0 - c7 
    0,0,0,0,0,0,0,0,  # c8 - cf 
    0,0,0,0,0,0,0,0,  # d0 - d7 
    0,0,0,0,0,0,0,0,  # d8 - df 
    0,0,0,0,0,0,0,0,  # e0 - e7 
    0,0,0,0,0,0,0,0,  # e8 - ef 
    0,0,0,0,0,0,0,0,  # f0 - f7 
    0,0,0,0,0,0,4,5)  # f8 - ff 

UCS2LE_st = ( \
          6,     6,     7,     6,     4,     3,eError,eError,#00-07 
     eError,eError,eError,eError,eItsMe,eItsMe,eItsMe,eItsMe,#08-0f 
     eItsMe,eItsMe,     5,     5,     5,eError,eItsMe,eError,#10-17 
          5,     5,     5,eError,     5,eError,     6,     6,#18-1f 
          7,     6,     8,     8,     5,     5,     5,eError,#20-27 
          5,     5,     5,eError,eError,eError,     5,     5,#28-2f 
          5,     5,     5,eError,     5,eError,eStart,eStart)#30-37 

UCS2LECharLenTable = (2, 2, 2, 2, 2, 2)

UCS2LESMModel = {'classTable': UCS2LE_cls,
                 'classFactor': 6,
                 'stateTable': UCS2LE_st,
                 'charLenTable': UCS2LECharLenTable,
                 'name': 'UTF-16LE'}

# UTF-8

UTF8_cls = ( \
    1,1,1,1,1,1,1,1,  # 00 - 07  #allow 0x00 as a legal value
    1,1,1,1,1,1,0,0,  # 08 - 0f 
    1,1,1,1,1,1,1,1,  # 10 - 17 
    1,1,1,0,1,1,1,1,  # 18 - 1f 
    1,1,1,1,1,1,1,1,  # 20 - 27 
    1,1,1,1,1,1,1,1,  # 28 - 2f 
    1,1,1,1,1,1,1,1,  # 30 - 37 
    1,1,1,1,1,1,1,1,  # 38 - 3f 
    1,1,1,1,1,1,1,1,  # 40 - 47 
    1,1,1,1,1,1,1,1,  # 48 - 4f 
    1,1,1,1,1,1,1,1,  # 50 - 57 
    1,1,1,1,1,1,1,1,  # 58 - 5f 
    1,1,1,1,1,1,1,1,  # 60 - 67 
    1,1,1,1,1,1,1,1,  # 68 - 6f 
    1,1,1,1,1,1,1,1,  # 70 - 77 
    1,1,1,1,1,1,1,1,  # 78 - 7f 
    2,2,2,2,3,3,3,3,  # 80 - 87 
    4,4,4,4,4,4,4,4,  # 88 - 8f 
    4,4,4,4,4,4,4,4,  # 90 - 97 
    4,4,4,4,4,4,4,4,  # 98 - 9f 
    5,5,5,5,5,5,5,5,  # a0 - a7 
    5,5,5,5,5,5,5,5,  # a8 - af 
    5,5,5,5,5,5,5,5,  # b0 - b7 
    5,5,5,5,5,5,5,5,  # b8 - bf 
    0,0,6,6,6,6,6,6,  # c0 - c7 
    6,6,6,6,6,6,6,6,  # c8 - cf 
    6,6,6,6,6,6,6,6,  # d0 - d7 
    6,6,6,6,6,6,6,6,  # d8 - df 
    7,8,8,8,8,8,8,8,  # e0 - e7 
    8,8,8,8,8,9,8,8,  # e8 - ef 
    10,11,11,11,11,11,11,11,  # f0 - f7 
    12,13,13,13,14,15,0,0)   # f8 - ff 

UTF8_st = ( \
    eError,eStart,eError,eError,eError,eError,     12,   10,#00-07 
         9,     11,     8,     7,     6,     5,     4,    3,#08-0f 
    eError,eError,eError,eError,eError,eError,eError,eError,#10-17 
    eError,eError,eError,eError,eError,eError,eError,eError,#18-1f 
    eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,#20-27 
    eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,eItsMe,#28-2f 
    eError,eError,     5,     5,     5,     5,eError,eError,#30-37 
    eError,eError,eError,eError,eError,eError,eError,eError,#38-3f 
    eError,eError,eError,     5,     5,     5,eError,eError,#40-47 
    eError,eError,eError,eError,eError,eError,eError,eError,#48-4f 
    eError,eError,     7,     7,     7,     7,eError,eError,#50-57 
    eError,eError,eError,eError,eError,eError,eError,eError,#58-5f 
    eError,eError,eError,eError,     7,     7,eError,eError,#60-67 
    eError,eError,eError,eError,eError,eError,eError,eError,#68-6f 
    eError,eError,     9,     9,     9,     9,eError,eError,#70-77 
    eError,eError,eError,eError,eError,eError,eError,eError,#78-7f 
    eError,eError,eError,eError,eError,     9,eError,eError,#80-87 
    eError,eError,eError,eError,eError,eError,eError,eError,#88-8f 
    eError,eError,    12,    12,    12,    12,eError,eError,#90-97 
    eError,eError,eError,eError,eError,eError,eError,eError,#98-9f 
    eError,eError,eError,eError,eError,    12,eError,eError,#a0-a7 
    eError,eError,eError,eError,eError,eError,eError,eError,#a8-af 
    eError,eError,    12,    12,    12,eError,eError,eError,#b0-b7 
    eError,eError,eError,eError,eError,eError,eError,eError,#b8-bf 
    eError,eError,eStart,eStart,eStart,eStart,eError,eError,#c0-c7 
    eError,eError,eError,eError,eError,eError,eError,eError)#c8-cf 

UTF8CharLenTable = (0, 1, 0, 0, 0, 0, 2, 3, 3, 3, 4, 4, 5, 5, 6, 6)

UTF8SMModel = {'classTable': UTF8_cls,
               'classFactor': 16,
               'stateTable': UTF8_st,
               'charLenTable': UTF8CharLenTable,
               'name': 'UTF-8'}

########NEW FILE########
__FILENAME__ = sbcharsetprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants, sys
from charsetprober import CharSetProber

SAMPLE_SIZE = 64
SB_ENOUGH_REL_THRESHOLD = 1024
POSITIVE_SHORTCUT_THRESHOLD = 0.95
NEGATIVE_SHORTCUT_THRESHOLD = 0.05
SYMBOL_CAT_ORDER = 250
NUMBER_OF_SEQ_CAT = 4
POSITIVE_CAT = NUMBER_OF_SEQ_CAT - 1
#NEGATIVE_CAT = 0

class SingleByteCharSetProber(CharSetProber):
    def __init__(self, model, reversed=constants.False, nameProber=None):
        CharSetProber.__init__(self)
        self._mModel = model
        self._mReversed = reversed # TRUE if we need to reverse every pair in the model lookup
        self._mNameProber = nameProber # Optional auxiliary prober for name decision
        self.reset()

    def reset(self):
        CharSetProber.reset(self)
        self._mLastOrder = 255 # char order of last character
        self._mSeqCounters = [0] * NUMBER_OF_SEQ_CAT
        self._mTotalSeqs = 0
        self._mTotalChar = 0
        self._mFreqChar = 0 # characters that fall in our sampling range

    def get_charset_name(self):
        if self._mNameProber:
            return self._mNameProber.get_charset_name()
        else:
            return self._mModel['charsetName']

    def feed(self, aBuf):
        if not self._mModel['keepEnglishLetter']:
            aBuf = self.filter_without_english_letters(aBuf)
        aLen = len(aBuf)
        if not aLen:
            return self.get_state()
        for c in aBuf:
            try:
                order = self._mModel['charToOrderMap'][ord(c)]
            except IndexError:
                return constants.eError
            if order < SYMBOL_CAT_ORDER:
                self._mTotalChar += 1
            if order < SAMPLE_SIZE:
                self._mFreqChar += 1
                if self._mLastOrder < SAMPLE_SIZE:
                    self._mTotalSeqs += 1
                    if not self._mReversed:
                        self._mSeqCounters[self._mModel['precedenceMatrix'][(self._mLastOrder * SAMPLE_SIZE) + order]] += 1
                    else: # reverse the order of the letters in the lookup
                        self._mSeqCounters[self._mModel['precedenceMatrix'][(order * SAMPLE_SIZE) + self._mLastOrder]] += 1
            self._mLastOrder = order

        if self.get_state() == constants.eDetecting:
            if self._mTotalSeqs > SB_ENOUGH_REL_THRESHOLD:
                cf = self.get_confidence()
                if cf > POSITIVE_SHORTCUT_THRESHOLD:
                    if constants._debug:
                        sys.stderr.write('%s confidence = %s, we have a winner\n' % (self._mModel['charsetName'], cf))
                    self._mState = constants.eFoundIt
                elif cf < NEGATIVE_SHORTCUT_THRESHOLD:
                    if constants._debug:
                        sys.stderr.write('%s confidence = %s, below negative shortcut threshhold %s\n' % (self._mModel['charsetName'], cf, NEGATIVE_SHORTCUT_THRESHOLD))
                    self._mState = constants.eNotMe

        return self.get_state()

    def get_confidence(self):
        r = 0.01
        if self._mTotalSeqs > 0:
#            print self._mSeqCounters[POSITIVE_CAT], self._mTotalSeqs, self._mModel['mTypicalPositiveRatio']
            r = (1.0 * self._mSeqCounters[POSITIVE_CAT]) / self._mTotalSeqs / self._mModel['mTypicalPositiveRatio']
#            print r, self._mFreqChar, self._mTotalChar
            r = r * self._mFreqChar / self._mTotalChar
            if r >= 1.0:
                r = 0.99
        return r

########NEW FILE########
__FILENAME__ = sbcsgroupprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants, sys
from charsetgroupprober import CharSetGroupProber
from sbcharsetprober import SingleByteCharSetProber
from langcyrillicmodel import Win1251CyrillicModel, Koi8rModel, Latin5CyrillicModel, MacCyrillicModel, Ibm866Model, Ibm855Model
from langgreekmodel import Latin7GreekModel, Win1253GreekModel
from langbulgarianmodel import Latin5BulgarianModel, Win1251BulgarianModel
from langhungarianmodel import Latin2HungarianModel, Win1250HungarianModel
from langthaimodel import TIS620ThaiModel
from langhebrewmodel import Win1255HebrewModel
from hebrewprober import HebrewProber

class SBCSGroupProber(CharSetGroupProber):
    def __init__(self):
        CharSetGroupProber.__init__(self)
        self._mProbers = [ \
            SingleByteCharSetProber(Win1251CyrillicModel),
            SingleByteCharSetProber(Koi8rModel),
            SingleByteCharSetProber(Latin5CyrillicModel),
            SingleByteCharSetProber(MacCyrillicModel),
            SingleByteCharSetProber(Ibm866Model),
            SingleByteCharSetProber(Ibm855Model),
            SingleByteCharSetProber(Latin7GreekModel),
            SingleByteCharSetProber(Win1253GreekModel),
            SingleByteCharSetProber(Latin5BulgarianModel),
            SingleByteCharSetProber(Win1251BulgarianModel),
            SingleByteCharSetProber(Latin2HungarianModel),
            SingleByteCharSetProber(Win1250HungarianModel),
            SingleByteCharSetProber(TIS620ThaiModel),
            ]
        hebrewProber = HebrewProber()
        logicalHebrewProber = SingleByteCharSetProber(Win1255HebrewModel, constants.False, hebrewProber)
        visualHebrewProber = SingleByteCharSetProber(Win1255HebrewModel, constants.True, hebrewProber)
        hebrewProber.set_model_probers(logicalHebrewProber, visualHebrewProber)
        self._mProbers.extend([hebrewProber, logicalHebrewProber, visualHebrewProber])

        self.reset()

########NEW FILE########
__FILENAME__ = sjisprober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from mbcharsetprober import MultiByteCharSetProber
from codingstatemachine import CodingStateMachine
from chardistribution import SJISDistributionAnalysis
from jpcntx import SJISContextAnalysis
from mbcssm import SJISSMModel
import constants, sys
from constants import eStart, eError, eItsMe

class SJISProber(MultiByteCharSetProber):
    def __init__(self):
        MultiByteCharSetProber.__init__(self)
        self._mCodingSM = CodingStateMachine(SJISSMModel)
        self._mDistributionAnalyzer = SJISDistributionAnalysis()
        self._mContextAnalyzer = SJISContextAnalysis()
        self.reset()

    def reset(self):
        MultiByteCharSetProber.reset(self)
        self._mContextAnalyzer.reset()

    def get_charset_name(self):
        return "SHIFT_JIS"

    def feed(self, aBuf):
        aLen = len(aBuf)
        for i in range(0, aLen):
            codingState = self._mCodingSM.next_state(aBuf[i])
            if codingState == eError:
                if constants._debug:
                    sys.stderr.write(self.get_charset_name() + ' prober hit error at byte ' + str(i) + '\n')
                self._mState = constants.eNotMe
                break
            elif codingState == eItsMe:
                self._mState = constants.eFoundIt
                break
            elif codingState == eStart:
                charLen = self._mCodingSM.get_current_charlen()
                if i == 0:
                    self._mLastChar[1] = aBuf[0]
                    self._mContextAnalyzer.feed(self._mLastChar[2 - charLen :], charLen)
                    self._mDistributionAnalyzer.feed(self._mLastChar, charLen)
                else:
                    self._mContextAnalyzer.feed(aBuf[i + 1 - charLen : i + 3 - charLen], charLen)
                    self._mDistributionAnalyzer.feed(aBuf[i - 1 : i + 1], charLen)

        self._mLastChar[0] = aBuf[aLen - 1]

        if self.get_state() == constants.eDetecting:
            if self._mContextAnalyzer.got_enough_data() and \
                   (self.get_confidence() > constants.SHORTCUT_THRESHOLD):
                self._mState = constants.eFoundIt

        return self.get_state()

    def get_confidence(self):
        contxtCf = self._mContextAnalyzer.get_confidence()
        distribCf = self._mDistributionAnalyzer.get_confidence()
        return max(contxtCf, distribCf)

########NEW FILE########
__FILENAME__ = universaldetector
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants, sys
from latin1prober import Latin1Prober # windows-1252
from mbcsgroupprober import MBCSGroupProber # multi-byte character sets
from sbcsgroupprober import SBCSGroupProber # single-byte character sets
from escprober import EscCharSetProber # ISO-2122, etc.
import re
import logging

logger = logging.getLogger(__name__)

MINIMUM_THRESHOLD = 0.20
ePureAscii = 0
eEscAscii = 1
eHighbyte = 2

class UniversalDetector:
    def __init__(self):
        self._highBitDetector = re.compile(r'[\x80-\xFF]')
        self._escDetector = re.compile(r'(\033|~{)')
        self._mEscCharSetProber = None
        self._mCharSetProbers = []
        self.reset()

    def reset(self):
        self.result = {'encoding': None, 'confidence': 0.0}
        self.done = constants.False
        self._mStart = constants.True
        self._mGotData = constants.False
        self._mInputState = ePureAscii
        self._mLastChar = ''
        if self._mEscCharSetProber:
            self._mEscCharSetProber.reset()
        for prober in self._mCharSetProbers:
            prober.reset()

    def feed(self, aBuf):
        if self.done: return

        charmap = (
            # EF BB BF  UTF-8 with BOM
            ('\xEF\xBB\xBF', {'encoding': "UTF-8", 'confidence': 1.0}),
            # FF FE 00 00  UTF-32, little-endian BOM
            ('\xFF\xFE\x00\x00', {'encoding': "UTF-32LE", 'confidence': 1.0}),
            # 00 00 FE FF  UTF-32, big-endian BOM
            ('\x00\x00\xFE\xFF', {'encoding': "UTF-32BE", 'confidence': 1.0}),
            # FE FF 00 00  UCS-4, unusual octet order BOM (3412)
            ('\xFE\xFF\x00\x00', {'encoding': "X-ISO-10646-UCS-4-3412", 'confidence': 1.0}),
            # 00 00 FF FE  UCS-4, unusual octet order BOM (2143)
            ('\x00\x00\xFF\xFE', {'encoding': "X-ISO-10646-UCS-4-2143", 'confidence': 1.0}),
            # FF FE  UTF-16, little endian BOM
            ('\xFF\xFE', {'encoding': "UTF-16LE", 'confidence': 1.0}),
            # FE FF  UTF-16, big endian BOM
            ('\xFE\xFF', {'encoding': "UTF-16BE", 'confidence': 1.0}),
        )

        aLen = len(aBuf)
        if not aLen: return

        if not self._mGotData:
            # If the data starts with BOM, we know it is UTF
            for chunk, result in charmap:
                if aBuf[:len(chunk)] == chunk:
                    self.result = result
                    break

        self._mGotData = constants.True
        if self.result['encoding'] and (self.result['confidence'] > 0.0):
            self.done = constants.True
            return

        if self._mInputState == ePureAscii:
            if self._highBitDetector.search(aBuf):
                self._mInputState = eHighbyte
            elif (self._mInputState == ePureAscii) and self._escDetector.search(self._mLastChar + aBuf):
                self._mInputState = eEscAscii

        self._mLastChar = aBuf[-1]

        if self._mInputState == eEscAscii:
            if not self._mEscCharSetProber:
                self._mEscCharSetProber = EscCharSetProber()
            if self._mEscCharSetProber.feed(aBuf) == constants.eFoundIt:
                self.result = {'encoding': self._mEscCharSetProber.get_charset_name(),
                               'confidence': self._mEscCharSetProber.get_confidence()}
                self.done = constants.True
        elif self._mInputState == eHighbyte:
            if not self._mCharSetProbers:
                self._mCharSetProbers = [MBCSGroupProber(), SBCSGroupProber(), Latin1Prober()]
            for prober in self._mCharSetProbers:
                try:
                    if prober.feed(aBuf) == constants.eFoundIt:
                        self.result = {'encoding': prober.get_charset_name(),
                                       'confidence': prober.get_confidence()}
                        self.done = constants.True
                        break
                except (UnicodeDecodeError, UnicodeEncodeError), e:
                    logger.exception(e)

    def close(self):
        if self.done: return
        if not self._mGotData:
            if constants._debug:
                sys.stderr.write('no data received!\n')
            return
        self.done = constants.True

        if self._mInputState == ePureAscii:
            self.result = {'encoding': 'ascii', 'confidence': 1.0}
            return self.result

        if self._mInputState == eHighbyte:
            proberConfidence = None
            maxProberConfidence = 0.0
            maxProber = None
            for prober in self._mCharSetProbers:
                if not prober: continue
                proberConfidence = prober.get_confidence()
                if proberConfidence > maxProberConfidence:
                    maxProberConfidence = proberConfidence
                    maxProber = prober
            if maxProber and (maxProberConfidence > MINIMUM_THRESHOLD):
                self.result = {'encoding': maxProber.get_charset_name(),
                               'confidence': maxProber.get_confidence()}
                return self.result

        if constants._debug:
            sys.stderr.write('no probers hit minimum threshhold\n')
            for prober in self._mCharSetProbers[0].mProbers:
                if not prober: continue
                sys.stderr.write('%s confidence = %s\n' % \
                                 (prober.get_charset_name(), \
                                  prober.get_confidence()))

########NEW FILE########
__FILENAME__ = utf8prober
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import constants, sys
from constants import eStart, eError, eItsMe
from charsetprober import CharSetProber
from codingstatemachine import CodingStateMachine
from mbcssm import UTF8SMModel

ONE_CHAR_PROB = 0.5

class UTF8Prober(CharSetProber):
    def __init__(self):
        CharSetProber.__init__(self)
        self._mCodingSM = CodingStateMachine(UTF8SMModel)
        self.reset()

    def reset(self):
        CharSetProber.reset(self)
        self._mCodingSM.reset()
        self._mNumOfMBChar = 0

    def get_charset_name(self):
        return "utf-8"

    def feed(self, aBuf):
        for c in aBuf:
            codingState = self._mCodingSM.next_state(c)
            if codingState == eError:
                self._mState = constants.eNotMe
                break
            elif codingState == eItsMe:
                self._mState = constants.eFoundIt
                break
            elif codingState == eStart:
                if self._mCodingSM.get_current_charlen() >= 2:
                    self._mNumOfMBChar += 1

        if self.get_state() == constants.eDetecting:
            if self.get_confidence() > constants.SHORTCUT_THRESHOLD:
                self._mState = constants.eFoundIt

        return self.get_state()

    def get_confidence(self):
        unlike = 0.99
        if self._mNumOfMBChar < 6:
            for i in range(0, self._mNumOfMBChar):
                unlike = unlike * ONE_CHAR_PROB
            return 1.0 - unlike
        else:
            return unlike

########NEW FILE########
__FILENAME__ = ciElementTree
import sys
import struct

VERSION = sys.version_info[:2]
PLATFORM = sys.platform
ARCH = 'x%d' % (struct.calcsize('P') * 8)

if VERSION >= (3, 3):
    from iElementTree import *
    from iElementTree import _patched_for_komodo_
elif VERSION >= (2, 6):
	platform = None

	try:
	    from _local_arch.ciElementTree import *
	    platform = "Local arch"
	except ImportError:
	    if PLATFORM == 'darwin':
	        from _macosx_universal_py26.ciElementTree import *
	        platform = "MacOS X Universal"
	    elif PLATFORM.startswith('linux'):
	        if ARCH == 'x64':
	            from _linux_libcpp6_x86_64_py26.ciElementTree import *
	            platform = "Linux 64 bits"
	        elif ARCH == 'x32':
	            from _linux_libcpp6_x86_py26.ciElementTree import *
	            platform = "Linux 32 bits"
	    elif PLATFORM.startswith('win'):
	        if ARCH == 'x64':
	            from _win64_py26.ciElementTree import *
	            platform = "Windows 64 bits"
	        elif ARCH == 'x32':
	            from _win32_py26.ciElementTree import *
	            platform = "Windows 32 bits"

	if not platform:
	    raise ImportError("Could not find a suitable ciElementTree binary for your platform and architecture.")

########NEW FILE########
__FILENAME__ = accessor
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****


"""The Accessor interface (and implementations) for accessing scintilla
lexer-based styled buffers.
"""

import bisect
import threading

from SilverCity import ScintillaConstants

from codeintel2.common import *
from codeintel2 import util

if _xpcom_:
    from xpcom import components
    from xpcom.client import WeakReference
    from xpcom import COMException


class Accessor(object):
    """Virtual base class for a lexed text accessor. This defines an API
    with which lexed text data (the text content, styling info, etc.) is
    accessed by trigger/completion/etc. handling. Actual instances will
    be one of the subclasses.
    """
    def char_at_pos(self, pos):
        raise VirtualMethodError()

    def style_at_pos(self, pos):
        raise VirtualMethodError()

    def line_and_col_at_pos(self, pos):
        raise VirtualMethodError()

    def gen_char_and_style_back(self, start, stop):
        """Generate (char, style) tuples backward from start to stop
        a la range(start, stop, -1) -- i.e. exclusive at 'stop' index.

        For SciMozAccessor this can be implemented more efficiently than
        the naive usage of char_at_pos()/style_at_pos().
        """
        raise VirtualMethodError()

    def gen_char_and_style(self, start, stop):
        """Generate (char, style) tuples forward from start to stop
        a la range(start, stop) -- i.e. exclusive at 'stop' index.

        For SciMozAccessor this can be implemented more efficiently than
        the naive usage of char_at_pos()/style_at_pos().
        """
        raise VirtualMethodError()

    def match_at_pos(self, pos, s):
        """Return True if the given string matches the text at the given
        position.
        """
        raise VirtualMethodError()

    def line_from_pos(self, pos):
        """Return the 0-based line number for the given position."""
        raise VirtualMethodError()

    def lines_from_positions(self, positions):
        """Yield the associate 0-based line for each of a number of
        positions.  This can be much faster than multiple calls to
        `line_from_pos` for some accessors.
        """
        for pos in positions:
            yield self.line_from_pos(pos)

    def line_start_pos_from_pos(self, pos):
        """Return the position of the start of the line of the given pos."""
        raise VirtualMethodError()

    def pos_from_line_and_col(self, line, col):
        """Return the position of the given line and column."""
        raise VirtualMethodError()

    @property
    def text(self):
        """All buffer content (as a unicode string)."""
        raise VirtualMethodError()

    def text_range(self, start, end):
        raise VirtualMethodError()

    def length(self):
        """Return the length of the buffer.

        Note that whether this returns a *character* pos or a *byte* pos is
        left fuzzy so that SilverCity and SciMoz implementations can be
        efficient. All that is guaranteed is that the *_at_pos() methods
        work as expected.
        """
        raise VirtualMethodError()
    # def gen_pos_and_char_fwd(self, start_pos):
    #    """Generate (<pos>, <char>) tuples forward from the starting
    #    position until the end of the document.
    #
    #    Note that whether <pos> is a *character* pos or a *byte* pos is
    #    left fuzzy so that SilverCity and SciMoz implementations can be
    #    efficient.
    #    """
    #    raise VirtualMethodError()

    def gen_tokens(self):
        """Generator for all styled tokens in the buffer.

        Currently this should yield token dict a la SilverCity's
        tokenize_by_style().
        """
        raise VirtualMethodError()

    def contiguous_style_range_from_pos(self, pos):
        """Returns a 2-tuple (start, end) giving the span of the sequence of
        characters with the style at position pos."""
        raise VirtualMethodError()


class SilverCityAccessor(Accessor):
    def __init__(self, lexer, content):
        # Assume buffer encoding is always UTF-8
        self.lexer = lexer
        self.content = unicode(content)

    def reset_content(self, content):
        """A backdoor specific to this accessor to allow the equivalent of
        updating the buffer/file/content.
        """
        self.content = unicode(content)
        self.__tokens_cache = None
        self.__position_data_cache = None

    __tokens_cache = None

    @property
    def tokens(self):
        if self.__tokens_cache is None:
            self.__tokens_cache = self.lexer.tokenize_by_style(self.content)
        return self.__tokens_cache

    def _char_pos_from_byte_pos(self, pos):
        line = self.line_from_pos(pos)
        byte_offset, char_offset = self.__position_data[line][:2]
        next_byte_offset = (byte_offset +
                            len(self.content[char_offset].encode("utf-8")))
        try:
            while next_byte_offset <= pos:
                byte_offset = next_byte_offset
                char_offset += 1
                next_byte_offset += len(self.content[
                                        char_offset].encode("utf-8"))
        except IndexError:
            pass  # running past EOF
        return char_offset

    def char_at_pos(self, pos):
        return self.content[self._char_pos_from_byte_pos(pos)]

    def _token_at_pos(self, pos):
        # XXX Locality of reference should offer an optimization here.
        # Binary search for appropriate token.
        lower, upper = 0, len(self.tokens) - 1  # [lower-limit, upper-limit)
        sentinel = 15
        while sentinel > 0:
            idx = ((upper - lower) / 2) + lower
            token = self.tokens[idx]
            # print "_token_at_pos %d: token idx=%d text[%d:%d]=%r"\
            #      % (pos, idx, token["start_index"], token["end_index"],
            #         token["text"])
            # start, end = token["start_index"], token["end_index"]
            if lower == upper:
                return token
            elif pos < token["start_index"]:
                upper = idx
            elif pos > token["end_index"]:
                lower = idx + 1
            else:
                return token
            sentinel -= 1
        else:
            raise CodeIntelError("style_at_pos binary search sentinel hit: "
                                 "there is likely a logic problem here!")

    def style_at_pos(self, pos):
        return self._token_at_pos(pos)["style"]

    def line_and_col_at_pos(self, pos):
        line = self.line_from_pos(pos)
        byte_offset, char_offset = self.__position_data[line][:2]

        line_char_offset = char_offset
        try:
            while byte_offset < pos:
                byte_offset += len(self.content[char_offset].encode("utf-8"))
                char_offset += 1
        except IndexError:
            char_offset += 1  # EOF
        return line, char_offset - line_char_offset

    # PERF: If perf is important for this accessor then could do much
    #      better with smarter use of _token_at_pos() for these two.
    def gen_char_and_style_back(self, start, stop):
        assert -1 <= stop <= start, "stop: %r, start: %r" % (stop, start)
        for pos in range(start, stop, -1):
            yield (self.char_at_pos(pos), self.style_at_pos(pos))

    def gen_char_and_style(self, start, stop):
        assert 0 <= start <= stop, "start: %r, stop: %r" % (start, stop)
        for pos in range(start, stop):
            yield (self.char_at_pos(pos), self.style_at_pos(pos))

    def match_at_pos(self, pos, s):
        char_pos = self._char_pos_from_byte_pos(pos)
        return self.content[char_pos:char_pos+len(s)] == s

    __position_data_cache = None

    @property
    def __position_data(self):
        """A list holding the cache of line position data.  The index is the
        line number; the value is a four-tuple of (start pos in bytes,
        start pos in chars, line length in bytes, line length in chars).
        """
        if self.__position_data_cache is None:
            data = []
            byte_offset = 0
            char_offset = 0
            for line_str in self.content.splitlines(True):
                byte_length = len(line_str.encode("utf-8"))
                char_length = len(line_str)
                data.append((
                    byte_offset, char_offset, byte_length, char_length))
                byte_offset += byte_length
                char_offset += char_length
            self.__position_data_cache = data
        return self.__position_data_cache

    def lines_from_char_positions(self, starts):
        """Yield the 0-based lines given the *character* positions."""
        line_starts = [p[1] for p in self.__position_data]  # in chars
        for char_pos in starts:
            # see line_from_pos for the adjustments
            yield bisect.bisect_left(line_starts, char_pos + 1) - 1

    def line_from_pos(self, byte_pos):
        r"""
            >>> sa = SilverCityAccessor(lexer,
            ...         #0         1           2         3
            ...         #01234567890 123456789 01234567890 12345
            ...         'import sys\nif True:\nprint "hi"\n# bye')
            >>> sa.line_from_pos(0)
            0
            >>> sa.line_from_pos(9)
            0
            >>> sa.line_from_pos(10)
            0
            >>> sa.line_from_pos(11)
            1
            >>> sa.line_from_pos(22)
            2
            >>> sa.line_from_pos(34)
            3
            >>> sa.line_from_pos(35)
            3
        """
        # Search for (byte_pos,) in the position data so we will always come
        # "before" the line we want (i.e. we have the index of the line itself)
        # the +1 is to make sure we get the line after (so we can subtract it)
        # this is because for a position not at line start, we get the next line
        # instead.
        return bisect.bisect_left(self.__position_data, (byte_pos + 1,)) - 1

    def line_start_pos_from_pos(self, pos):
        return self.__position_data[self.line_from_pos(pos)][0]

    def pos_from_line_and_col(self, line, col):
        byte_offset, char_offset = self.__position_data[line][:2]
        substring = self.content[char_offset:char_offset+col].encode("utf-8")
        return byte_offset + len(substring)

    @property
    def text(self):
        return self.content

    def text_range(self, start, end):
        return self.content[self._char_pos_from_byte_pos(start):
                            self._char_pos_from_byte_pos(end)]

    def length(self):
        byte_offset, byte_length = self.__position_data[-1][::2]
        return byte_offset + byte_length

    def gen_tokens(self):
        for token in self.tokens:
            yield token

    def contiguous_style_range_from_pos(self, pos):
        token = self._token_at_pos(pos)
        return (token["start_index"], token["end_index"] + 1)


class SciMozAccessor(Accessor):
    def __init__(self, scimoz, silvercity_lexer):
        self.scimoz = WeakReference(scimoz)
        self.silvercity_lexer = silvercity_lexer

    def char_at_pos(self, pos):
        return self.scimoz().getWCharAt(pos)

    def style_at_pos(self, pos):
        return self.scimoz().getStyleAt(pos)

    def line_and_col_at_pos(self, pos):
        scimoz = self.scimoz()
        line = scimoz.lineFromPosition(pos)
        col = pos - scimoz.positionFromLine(line)
        return line, col

    # These two are *much* faster than repeatedly calling char_at_pos()
    # and style_at_pos().
    def gen_char_and_style_back(self, start, stop):
        if start > stop:
            # For scimoz.getStyledText(), it's (inclusive, exclusive)
            styled_text = self.scimoz().getStyledText(stop+1, start+1)
            for i in range(len(styled_text)-2, -2, -2):
                yield (styled_text[i], ord(styled_text[i+1]))
        elif start == stop:
            pass
        else:
            raise AssertionError("start (%r) < stop (%r)" % (start, stop))

    def gen_char_and_style(self, start, stop):
        if start < stop:
            # For scimoz.getStyledText(), it's (inclusive, exclusive)
            styled_text = self.scimoz().getStyledText(start, stop)
            for i in range(0, len(styled_text), 2):
                yield (styled_text[i], ord(styled_text[i+1]))
        elif start == stop:
            pass
        else:
            raise AssertionError("start (%r) > stop (%r)" % (start, stop))

    # XXX def match_at_pos(self, pos, s):...
    def line_from_pos(self, pos):
        return self.scimoz().lineFromPosition(pos)

    def lines_from_positions(self, positions):
        # Note: for a large enough set of positions it might be faster
        # to use the algorithm in SilverCityAccessor.
        scimoz = self.scimoz()
        for pos in positions:
            yield scimoz.lineFromPosition(pos)

    def line_start_pos_from_pos(self, pos):
        scimoz = self.scimoz()
        return scimoz.positionFromLine(scimoz.lineFromPosition(pos))

    def pos_from_line_and_col(self, line, col):
        return self.scimoz().positionFromLine(line) + col

    @property
    def text(self):
        return self.scimoz().text

    def text_range(self, start, end):
        return self.scimoz().getTextRange(start, end)

    def length(self):
        return self.scimoz().length
        # raise NotImplementedError(
        #    "Calculating the *character* length of a SciMoz buffer can "
        #    "be expensive. Are you sure you want to use this method? "
        #    "Try accessor.gen_pos_and_char_fwd() first.")

    def gen_tokens(self):
        if self.silvercity_lexer:
            # PERF: This is not a great solution but see bug 54217.
            acc = SilverCityAccessor(self.silvercity_lexer, self.text)
            for token in acc.gen_tokens():
                yield token
        else:
            # Silvercity lexer doesn't exist, use styles straight from SciMoz.
            scimoz = self.scimoz()
            styled_text = scimoz.getStyledText(0, scimoz.length)
            text = styled_text[::2]
            styles = styled_text[1::2]
            start_index = 0
            prev_style = -1
            last_i = len(styles) - 1
            for i in range(len(styles)):
                style = styles[i]
                if style != prev_style or i == last_i:
                    token_text = text[start_index:i]
                    if token_text:
                        token = {
                            'style': ord(prev_style),
                            'text': token_text,
                            'start_index': start_index,
                            'end_index': i-1,
                            'start_column': 0,  # unset
                            'end_column': 0,   # unset
                            'start_line': 0,   # unset
                            'end_line': 0,     # unset
                        }
                        yield token
                    start_index = i
                    prev_style = style

    def contiguous_style_range_from_pos(self, pos):
        curr_style = self.style_at_pos(pos)
        i = pos - 1
        while i >= 0 and self.style_at_pos(i) == curr_style:
            i -= 1
        start_pos = i + 1

        last_pos = self.length()
        i = pos + 1
        while i < last_pos and self.style_at_pos(i) == curr_style:
            i += 1
        end_pos = i  # Point one past the end
        return (start_pos, end_pos)

    @property
    def udl_family_chunk_ranges(self):
        """Generate a list of continguous UDL-family ranges.

        Generates 3-tuples:
            (<udl-family>, <start-byte-offset>, <end-byte-offset>)
        where
            <udl-family> is one of "M", "CSS", "CSL", "SSL", "TPL"
            <start-byte-offset> is inclusive
            <end-byte-offset> is exclusive (like a Python range)

        Note: For non-UDL languages this will return on chunk that is the
        whole document and <udl-family> will be None.
        """
        # LexUDL will set indicator 18 on the start char (or set of chars)
        # beginning a new UDL family section.
        scimoz = self.scimoz()

        # Note: value must match that in LexUDL.cxx and koILinter.idl.
        DECORATOR_UDL_FAMILY_TRANSITION = 18

        pos = 0
        length = scimoz.length
        while pos < length:
            start = scimoz.indicatorStart(DECORATOR_UDL_FAMILY_TRANSITION, pos)
            end = scimoz.indicatorEnd(DECORATOR_UDL_FAMILY_TRANSITION, start+1)
            if start == end == 0:  # No indicators.
                yield (None, 0, length)
                break
            start = max(start-1, 0)
            # print "range: %d (%r) - %d (%r): %s" % (
            #    start, scimoz.getWCharAt(start),
            #    end, scimoz.getWCharAt(end-1),
            #    self._udl_family_from_style(scimoz.getStyleAt(pos)))
            # print util.indent(repr(scimoz.getTextRange(start, end)))
            yield (self._udl_family_from_style(scimoz.getStyleAt(pos)),
                   start, end)
            pos = end + 1

    _udl_family_from_start_style = {
        ScintillaConstants.SCE_UDL_M_DEFAULT: "M",
        ScintillaConstants.SCE_UDL_CSS_DEFAULT: "CSS",
        ScintillaConstants.SCE_UDL_CSL_DEFAULT: "CSL",
        ScintillaConstants.SCE_UDL_SSL_DEFAULT: "SSL",
        ScintillaConstants.SCE_UDL_TPL_DEFAULT: "TPL",
    }
    _udl_family_start_styles = list(sorted(
        _udl_family_from_start_style.keys()))

    @classmethod
    def _udl_family_from_style(cls, style):
        """Determine which UDL family this style is in. Returns one
        of M, CSS, CSL, SSL or TPL.
        """
        idx = bisect.bisect_right(cls._udl_family_start_styles, style)
        start_style = cls._udl_family_start_styles[idx-1]
        fam = cls._udl_family_from_start_style[start_style]
        return fam


class KoDocumentAccessor(SciMozAccessor):
    """An accessor that lazily defers to the first view attached to this
    Komodo document object.
    """
    def __init__(self, doc, silvercity_lexer):
        self.doc = WeakReference(doc)
        self.silvercity_lexer = silvercity_lexer

    def _get_scimoz_ref(self):
        try:
            view = self.doc().getView()
        except (COMException, AttributeError), ex:
            # Race conditions on file opening in Komodo can result
            # in self.doc() being None or an error in .getView().
            raise NoBufferAccessorError(str(ex))
        return view.scimoz

    if _xpcom_:
        # The view is implemented in JavaScript, so we need to proxy the
        # _get_scimoz_ref() call in order to get the scimoz (plugin)
        # object, then we make a proxy for the scimoz object and return
        # it.
        #
        # The ProxyToMainThread decorator is required, to ensure *all*
        # the "koDoc" and "view" calls are run on the main thread.
        # Without this Komodo can crash in garbage collection,
        # complaining that JS objects were used/created on a thread.

        @components.ProxyToMainThread
        def _get_proxied_scimoz_ref(self):
            scimoz = self._get_scimoz_ref()

            class SciMozProxy:
                def __init__(self, sm):
                    self.sm = sm

                @property
                @components.ProxyToMainThread
                def length(self):
                    return self.sm.length

                @property
                @components.ProxyToMainThread
                def text(self):
                    return self.sm.text

                @components.ProxyToMainThread
                def getTextRange(self, *args):
                    return self.sm.getTextRange(*args)

                @components.ProxyToMainThread
                def getStyledText(self, *args):
                    return self.sm.getStyledText(*args)

                @components.ProxyToMainThread
                def getWCharAt(self, *args):
                    return self.sm.getWCharAt(*args)

                @components.ProxyToMainThread
                def getStyleAt(self, *args):
                    return self.sm.getStyleAt(*args)

                @components.ProxyToMainThread
                def lineFromPosition(self, *args):
                    return self.sm.lineFromPosition(*args)

                @components.ProxyToMainThread
                def positionFromLine(self, *args):
                    return self.sm.positionFromLine(*args)

                @components.ProxyToMainThread
                def indicatorStart(self, *args):
                    return self.sm.indicatorStart(*args)

                @components.ProxyToMainThread
                def indicatorEnd(self, *args):
                    return self.sm.indicatorEnd(*args)
            return SciMozProxy(scimoz)

    def scimoz(self):
        """Re-get scimoz every time it's needed.

        This ensures scimoz will be properly proxied when calling off
        the main thread."""

        if not _xpcom_:
            return self._get_scimoz_ref()
        else:
            return self._get_proxied_scimoz_ref()


class AccessorCache:
    """Utility class used to cache buffer styling information"""

    def __init__(self, accessor, position, fetchsize=20, debug=False):
        """Document accessor cache contructor. Will cache fetchsize style info
        pieces starting from position - 1.

        @param accessor {Accessor} a form of document accessor
        @param position {int} where in the document to start caching from (exclusive)
        @param fetchsize {int} how much cache is stored/retrived at a time
        """
        self._accessor = accessor
        self._cachefetchsize = fetchsize
        self._debug = debug
        # self._debug = True
        self._reset(position)

    # Private
    def _reset(self, position):
        self._pos = position
        self._ch = None
        self._style = None
        # cachePos is used to store where self._pos is inside the _cache
        self._cachePos = 0
        self._chCache = []
        self._styleCache = []
        # cacheXXXBufPos is used to store where cache is relative to the buffer
        # _cacheFirstBufPos is inclusive
        self._cacheFirstBufPos = position
        # _cacheLastBufPos is exclusive
        self._cacheLastBufPos = position

    def _extendCacheBackwards(self, byAmount=None):
        if self._cacheFirstBufPos > 0:
            if byAmount is None:
                byAmount = self._cachefetchsize
            # Generate another n tuples (pos, char, style)
            start = max(0, (self._cacheFirstBufPos - byAmount))
            # Add more to the start of the cache
            extendCount = (self._cacheFirstBufPos - start)
            ch_list = []
            style_list = []
            for ch, style in self._accessor.gen_char_and_style(start, self._cacheFirstBufPos):
                ch_list.append(ch)
                style_list.append(style)
            self._chCache = ch_list + self._chCache
            self._styleCache = style_list + self._styleCache
            self._cachePos += extendCount
            self._cacheFirstBufPos = start
            if self._debug:
                print "Extended cache by %d, _cachePos: %d, len now: %d" % (
                    extendCount, self._cachePos, len(self._chCache))
                print "Ch cache now: %r" % (self._chCache)
        else:
            raise IndexError("No buffer left to examine")

    def _extendCacheForwards(self, byAmount=None):
        buf_length = self._accessor.length()
        if self._cacheLastBufPos < buf_length:
            if byAmount is None:
                byAmount = self._cachefetchsize
            # Generate another n tuples (pos, char, style)
            end = min(buf_length, (self._cacheLastBufPos + byAmount))
            # Add more to the end of the cache
            extendCount = end - self._cacheLastBufPos
            for ch, style in self._accessor.gen_char_and_style(self._cacheLastBufPos, end):
                self._chCache.append(ch)
                self._styleCache.append(style)
            self._cacheLastBufPos = end
            if self._debug:
                print "Extended cache by %d, _cachePos: %d, len now: %d" % (
                    extendCount, self._cachePos, len(self._chCache))
                print "Ch cache now: %r" % (self._chCache)
        else:
            raise IndexError("No buffer left to examine")

    # Public
    def dump(self, limit=20):
        if len(self._chCache) > 0:
            print "  pos: %r, ch: %r, style: %r, cachePos: %r, cache len: %d\n  cache: %r" % (self._cachePos + self._cacheFirstBufPos,
                                                                                              self._chCache[
                                                                                              self._cachePos],
                                                                                              self._styleCache[
                                                                                              self._cachePos],
                                                                                              self._cachePos,
                                                                                              len(self._chCache),
                                                                                              self._chCache)
        else:
            print "New cache: %r" % (self._chCache[-limit:])

    def setCacheFetchSize(self, size):
        self._cachefetchsize = size

    def resetToPosition(self, position):
        if self._debug:
            print "resetToPosition: %d" % (position)
            print "self._cacheFirstBufPos: %d" % (self._cacheFirstBufPos)
            print "self._cacheLastBufPos: %d" % (self._cacheLastBufPos)
        if position >= self._cacheLastBufPos:
            if position >= self._cacheLastBufPos + self._cachefetchsize:
                # Clear everything
                self._reset(position)
                return
            else:
                # Just extend forwards
                if self._debug:
                    print "resetToPosition: extending cache forwards"
                self._extendCacheForwards()
        elif position < self._cacheFirstBufPos:
            if position < self._cacheFirstBufPos - self._cachefetchsize:
                # Clear everything
                self._reset(position)
                return
            else:
                # Just extend back
                if self._debug:
                    print "resetToPosition: extending cache backwards"
                self._extendCacheBackwards()
        else:
            # It's in the current cache area, we keep that then
            pass
        self._cachePos = position - self._cacheFirstBufPos
        self._ch = self._chCache[self._cachePos]
        self._style = self._styleCache[self._cachePos]
        self._pos = position
        if self._debug:
            print "self._cachePos: %d, cacheLen: %d" % (self._cachePos, len(self._chCache))
            print "resetToPosition: p: %r, ch: %r, st: %r" % (self._pos, self._ch, self._style)

    # def pushBack(self, numPushed=1):
    #    """Push back the items that were recetly popped off.
    #    @returns {int} Number of pushed items
    #    """
    #    pushItems = self._popped[-numPushed:]
    #    pushItems.reverse()
    #    self._cache += pushItems
    #    if len(self._popped) > 0:
    #        self._currentTuple = self._popped[-1]
    #    else:
    #        self._currentTuple = (self._currentTuple[0] + numPushed, None, None)
    #    return len(pushItems)

    def getCurrentPosCharStyle(self):
        """Get the current buffer position information.
        @returns {tuple} with values (pos, char, style)
        """
        return (self._pos, self._ch, self._style)

    def getPrevPosCharStyle(self, ignore_styles=None, max_look_back=100):
        """Get the previous buffer position information.
        @param ignore_styles {tuple}
        @returns {tuple} with values (pos, char, style), these values will
        all be None if it exceeds the max_look_back.
        @raises IndexError can be raised when nothing left to consume.
        """
        count = 0
        while count < max_look_back:
            count += 1
            self._cachePos -= 1
            if self._cachePos < 0:
                self._extendCacheBackwards()
            self._style = self._styleCache[self._cachePos]
            if ignore_styles is None or self._style not in ignore_styles:
                self._ch = self._chCache[self._cachePos]
                break
        else:
            # Went too far without finding what looking for
            return (None, None, None)
        self._pos = self._cachePos + self._cacheFirstBufPos
        if self._debug:
            print "getPrevPosCharStyle:: pos:%d ch:%r style:%d" % (self._pos, self._ch, self._style)
        return (self._pos, self._ch, self._style)

    def peekPrevPosCharStyle(self, ignore_styles=None, max_look_back=100):
        """Same as getPrevPosCharStyle, but does not move the buffer position.
        @param ignore_styles {tuple}
        @returns {tuple} with values (pos, char, style), these values will
        all be None if it exceeds the max_look_back.
        @raises IndexError can be raised when nothing left to consume.
        """
        # Store the old values.
        old_pos = self._pos
        old_ch = self._ch
        old_style = self._style
        old_cachePos = self._cachePos
        old_cacheFirstBufPos = self._cacheFirstBufPos
        try:
            pos, ch, style = self.getPrevPosCharStyle(
                ignore_styles, max_look_back)
        finally:
            # Restore old values.
            self._pos = old_pos
            self._ch = old_ch
            self._style = old_style
            # The cache may have gotten extended (which is fine), but in that
            # case the old_cachePos is no longer correct, so update it.
            cache_extended_by = old_cacheFirstBufPos - self._cacheFirstBufPos
            self._cachePos = old_cachePos + cache_extended_by
        if self._debug:
            print "peekPrevPosCharStyle:: pos:%d ch:%r style:%d" % (pos, ch, style)
        return (pos, ch, style)

    def getPrecedingPosCharStyle(self, current_style=None, ignore_styles=None,
                                 max_look_back=200):
        """Go back and get the preceding style.
        @returns {tuple} with values (pos, char, style)
        Returns None for both char and style, when out of characters to look
        at and there is still no previous style found.
        """
        if current_style is None:
            current_style = self._styleCache[self._cachePos]
        try:
            new_ignore_styles = [current_style]
            if ignore_styles is not None:
                new_ignore_styles += list(ignore_styles)
            return self.getPrevPosCharStyle(new_ignore_styles, max_look_back)
        except IndexError:
            pass
        # Did not find the necessary style
        return None, None, None

    def getTextBackWithStyle(self, current_style=None, ignore_styles=None,
                             max_text_len=200):
        """Go back and get the preceding text, which is of a different style.
        @returns {tuple} with values (pos, text), pos is position of first text char
        """
        old_p = self._pos
        new_p, c, style = self.getPrecedingPosCharStyle(current_style,
                                                        ignore_styles,
                                                        max_look_back=max_text_len)
        # print "Return %d:%d" % (new_p, old_p+1)
        if style is None:   # Ran out of text to look at
            new_p = max(0, old_p - max_text_len)
            return new_p, self.text_range(new_p, old_p+1)
        else:
            # We don't eat the new styling info
            self._cachePos += 1
            return new_p+1, self.text_range(new_p+1, old_p+1)

    def getNextPosCharStyle(self, ignore_styles=None, max_look_ahead=100):
        """Get the next buffer position information.
        @param ignore_styles {tuple}
        @returns {tuple} with values (pos, char, style), these values will
        all be None if it exceeds the max_look_ahead.
        @raises IndexError can be raised when nothing left to consume.
        """
        max_pos = self._cachePos + max_look_ahead
        while self._cachePos < max_pos:
            self._cachePos += 1
            if self._cachePos >= len(self._chCache):
                self._extendCacheForwards()
            self._style = self._styleCache[self._cachePos]
            if ignore_styles is None or self._style not in ignore_styles:
                self._ch = self._chCache[self._cachePos]
                break
        else:
            # Went too far without finding what looking for
            return (None, None, None)
        self._pos = self._cachePos + self._cacheFirstBufPos
        if self._debug:
            print "getNextPosCharStyle:: pos:%d ch:%r style:%d" % (self._pos, self._ch, self._style)
        return (self._pos, self._ch, self._style)

    def getSucceedingPosCharStyle(self, current_style=None, ignore_styles=None,
                                  max_look_ahead=200):
        """Go forward and get the next different style.
        @returns {tuple} with values (pos, char, style)
        Returns None for both char and style, when out of characters to look
        at and there is still no previous style found.
        """
        if current_style is None:
            current_style = self._styleCache[self._cachePos]
        try:
            new_ignore_styles = [current_style]
            if ignore_styles is not None:
                new_ignore_styles += list(ignore_styles)
            return self.getNextPosCharStyle(new_ignore_styles, max_look_ahead)
        except IndexError:
            pass
        # Did not find the necessary style
        return None, None, None

    def getTextForwardWithStyle(self, current_style=None, ignore_styles=None,
                                max_text_len=200):
        """Go forward and get the succeeding text, which is of a different style.
        @returns {tuple} with values (pos, text), pos is position of last text char.
        """
        old_p = self._pos
        new_p, c, style = self.getSucceedingPosCharStyle(current_style,
                                                         ignore_styles,
                                                         max_look_ahead=max_text_len)
        if style is None:   # Ran out of text to look at
            new_p = min(self._accessor.length(), old_p + max_text_len)
            return new_p, self.text_range(old_p, new_p)
        else:
            # We don't eat the new styling info
            self._cachePos -= 1
            return new_p-1, self.text_range(old_p, new_p)

    def text_range(self, start, end):
        """Return text in range buf[start:end]

        Note: Start position is inclusive, end position is exclusive.
        """
        if start >= self._cacheFirstBufPos and end <= self._cacheLastBufPos:
            cstart = start - self._cacheFirstBufPos
            cend = end - self._cacheFirstBufPos
            if self._debug:
                print "text_range:: cstart: %d, cend: %d" % (cstart, cend)
                print "text_range:: start: %d, end %d" % (start, end)
                print "text_range:: _cacheFirstBufPos: %d, _cacheLastBufPos: %d" % (self._cacheFirstBufPos, self._cacheLastBufPos)
            # It's all in the cache
            return "".join(self._chCache[cstart:cend])
        if self._debug:
            print "text_range:: using parent text_range: %r - %r" % (start, end)
        return self._accessor.text_range(start, end)


# Test function
def _test():
    class _TestAccessor(Accessor):
        def __init__(self, content, styles):
            self.content = content
            self.style = styles

        def length(self):
            return len(self.content)

        def char_at_pos(self, pos):
            return self.content[pos]

        def style_at_pos(self, pos):
            return self.style[pos]

        def gen_char_and_style_back(self, start, stop):
            assert -1 <= stop <= start, "stop: %r, start: %r" % (stop, start)
            for pos in range(start, stop, -1):
                yield (self.char_at_pos(pos), self.style_at_pos(pos))

        def gen_char_and_style(self, start, stop):
            assert 0 <= start <= stop, "start: %r, stop: %r" % (start, stop)
            for pos in range(start, stop):
                yield (self.char_at_pos(pos), self.style_at_pos(pos))

        def text_range(self, start, end):
            return self.content[start:end]

    content = "This is my test buffer\r\nSecond   line\r\nThird line\r\n"
    styles = "1111011011011110111111 2 21111110001111 2 21111101111 2 2".replace(
        " ", "")
    ta = _TestAccessor(content, map(int, styles))
    pos = len(content) - 2
    ac = AccessorCache(ta, pos)
    # ac._debug = True
    for i in range(2):
        assert(ac.getPrevPosCharStyle() == (pos-1, "e", 1))
        assert(ac.getPrecedingPosCharStyle(1) == (pos-5, " ", 0))
        assert(ac.getPrecedingPosCharStyle(0) == (pos-6, "d", 1))
        assert(ac.getPrecedingPosCharStyle(1) == (pos-11, "\n", 2))
        assert(ac.getPrecedingPosCharStyle() == (pos-13, "e", 1))
        assert(ac.getTextBackWithStyle(1) == (pos-16, "line"))
        assert(ac.getPrevPosCharStyle() == (pos-17, " ", 0))
        assert(ac.getPrecedingPosCharStyle(0) == (pos-20, "d", 1))
        if i == 0:
            ac.resetToPosition(pos)

    assert(ac.getCurrentPosCharStyle() == (pos-20, "d", 1))

    # print pos
    # print ac.getSucceedingPosCharStyle()
    assert(ac.getNextPosCharStyle() == (pos-19, " ", 0))
    assert(ac.getSucceedingPosCharStyle() == (pos-16, "l", 1))
    assert(ac.getTextForwardWithStyle(1) == (pos-13, "line"))
    assert(ac.getNextPosCharStyle() == (pos-12, "\r", 2))
    assert(ac.getNextPosCharStyle() == (pos-11, "\n", 2))
    assert(ac.getSucceedingPosCharStyle(2) == (pos-10, "T", 1))
    assert(ac.getSucceedingPosCharStyle() == (pos-5, " ", 0))
    assert(ac.getSucceedingPosCharStyle() == (pos-4, "l", 1))
    assert(ac.getSucceedingPosCharStyle() == (pos, "\r", 2))
    assert(ac.getNextPosCharStyle() == (pos+1, "\n", 2))

    # Bug: http://bugs.activestate.com/show_bug.cgi?id=64227
    #      Ensure text_range uses correct parameters in boundary situations
    ac.resetToPosition(3)
    assert(ac.getTextBackWithStyle(1)[1] == "This")
    ac.resetToPosition(len(content) - 2)
    assert(ac.getTextForwardWithStyle(2)[1] == "\r\n")


# When run from command line
if __name__ == '__main__':
    _test()

########NEW FILE########
__FILENAME__ = buffer
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

import os
from os.path import dirname, join, abspath, normpath, basename
import sys
import re
import operator
import bisect
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import traceback
from hashlib import md5
import time

import SilverCity
from SilverCity import ScintillaConstants
# XXX Import only what we need
from SilverCity.ScintillaConstants import *

from codeintel2.common import *
from codeintel2.util import isident, indent, banner, markup_text

if _xpcom_:
    from xpcom import components
    from xpcom.server import UnwrapObject

# XXX We need to have a better mechanism for rationalizing and sharing
#    common lexer style classes. For now we'll just HACKily grab from
#    Komodo's styles.py. Some of this is duplicating logic in
#    KoLanguageServiceBase.py.
_ko_src_dir = normpath(join(dirname(__file__), *([os.pardir]*3)))
sys.path.insert(0, join(_ko_src_dir, "schemes"))
try:
    import styles
finally:
    del sys.path[0]
    del _ko_src_dir


log = logging.getLogger("codeintel.buffer")


#---- module interface
class Buffer(object):
    if _xpcom_:
        _com_interfaces_ = [components.interfaces.koICodeIntelBuffer]

    # Language-specific attributes that subclasses must fill-in.
    lang = None             # language name
    cpln_fillup_chars = ""  # chars on which autocomplete UI will "fillup"
    cpln_stop_chars = ""    # chars on which autocomplete UI will stop

    # Separator btwn completions in a completion list string for the
    # Scintilla API.
    # We don't use the default, ' ', because so of our languages have
    # completions with spaces in them (e.g. Tcl).
    scintilla_cpln_sep = '\n'
    scintilla_cpln_sep_ord = ord(scintilla_cpln_sep)

    # <prefix><stylename>, scintilla style constants prefix for this
    # language. Most languages just have one prefix (e.g. "SCE_P_" for
    # Python), but HTML, for example, has many.
    sce_prefixes = None

    # Code Browser control. (Note: most code browser control is on the
    # relevant LangIntel).
    #
    # Show a row for this buffer even if empty of code browser data.
    cb_show_if_empty = False

    # Lazily built cache of SCE_* style number (per language) to constant
    # name.
    _style_name_from_style_num_from_lang = {}

    def __init__(self, mgr, accessor, env=None, path=None, encoding=None, lang=None):
        self.mgr = mgr
        self.accessor = accessor  # an Accessor instance
        self._env = env
        self.path = path if path is not None else "<Unsaved>"
        self.encoding = encoding
        if lang is not None:
            self.lang = lang

        self.implicit_completion_skip_styles = dict(
            (s, True) for s in self.comment_styles() + self.string_styles())
        self.completion_skip_styles = dict(
            (s, True) for s in self.number_styles())

    def __repr__(self):
        return "<%s buf '%s'>" % (self.lang,
                                  basename(self.path) if self.path is not None else "(no file)")

    @property
    def env(self):
        """The runtime Environment instance for this buffer."""
        return self._env or self.mgr.env

    _langintel_cache = None

    @property
    def langintel(self):
        if self._langintel_cache is None:
            self._langintel_cache = self.mgr.langintel_from_lang(self.lang)
        return self._langintel_cache

    _langinfo_cache = None

    @property
    def langinfo(self):
        if self._langinfo_cache is None:
            self._langinfo_cache = self.mgr.lidb.langinfo_from_lang(self.lang)
        return self._langinfo_cache

    def lang_from_pos(self, pos):
        return self.lang

    def set_project(self, project):
        if self.env:
            self.env.set_project(project)

    def trg_from_pos(self, pos, implicit=True):
        """If the given position is a _likely_ trigger point, return a
        relevant Trigger instance. Otherwise return the None.

            "pos" is the position at which to check for a trigger point.
            "implicit" (optional) is a boolean indicating if this trigger
                is being implicitly checked (i.e. as a side-effect of
                typing). Defaults to true.

        Implementations of this should be *fast* because editor usage will
        likely call this for most typed characters.

        The default implementation defers to the langintel for this buffer.
        This is generally a better place to implement trg_from_pos if this
        language's content can appear in a multi-language buffer (e.g. CSS).
        """
        return self.langintel.trg_from_pos(self, pos, implicit)

    def preceding_trg_from_pos(self, pos, curr_pos):
        """Look back from the given position for a trigger point within
        range.

            "pos" is the position at which to begin backtracking. (I.e. for
                the first Ctrl+J this is the cursor position, for the next
                Ctrl+J it is the position of the current
                autocomplete/calltip UI.)
            "curr_pos" is the current position -- the one to use to
                determine if within range of a found trigger. (I.e. this is
                the cursor position in Komodo.)

        Here "within range" depends on the language and the trigger. This
        is the main determinant for the "Ctrl+J" (explicitly trigger
        completion now) functionality in Komodo, for example, and the
        ultimate goal is to not surprisingly move the cursor on the user.
        Here is the algorithm:
        - Only consider a *completion* (i.e. TRG_FORM_CPLN) trigger point
          if `pos' is in range. I.e.:
                sys.pat<|>h         # consider the `sys.' trigger
                os.path.join("<|>   # do not consider the `os.path.' trigger
        - Only consider a calltip trigger point inside the argument
          region.

        I.e., "within range" means, we could show the UI for that completion
        in scintilla without having to move the cursor.

        The default implementation defers to the langintel for this buffer.

        Returns a Trigger instance or None.
        """
        return self.langintel.preceding_trg_from_pos(self, pos, curr_pos)

    def async_eval_at_trg(self, trg, ctlr):
        """Asynchronously determine completion/calltip info for the given
        trigger.

            "trg" is the trigger at which to evaluate (a Trigger instance).
            "ctlr" is the controller (a EvalController instance) used to
                relay results and status and to receive control signals.

        Rules for implementation:
        - Must call ctlr.start(buf, trg) at start.
        - Should call ctlr.set_desc(desc) near the start to provide a
          short description of the evaluation.
        - Should log eval errors via ctlr.error(msg, args...).
        - Should log other events via ctlr.{debug|info|warn}.
        - Should respond to ctlr.abort() in a timely manner.
        - If successful, must report results via one of
          ctlr.set_cplns() or ctlr.set_calltips().
        - Must call ctlr.done(some_reason_string) when done.

        Tips for implementation:
        - The typical structure of an async_eval_at_trg() implementation is:
            ctlr.start(self, trg)  # or 'buf' if implemented on LangIntel
            if trg.id == (<lang>, TRG_FORM_CPLN, <type>):
                # handle this trigger type
            elif trg.id == (<lang>, TRG_FORM_CPLN, <type>):
                # handle this trigger type
            ...
        - If evaluation of a particular trigger type is fast (i.e. just a
          lookup in a hardcoded data structure) then it is okay to process
          asynchronously.

        The default implementation defers to the langintel for this buffer.

        Returns no value. All interaction is on the controller. This may
        raise CodeIntelError on an unexpected error condition.
        """
        # XXX xpcom UnwrapObject here?
        self.langintel.async_eval_at_trg(self, trg, ctlr)

    def cplns_from_trg(self, trg, timeout=None, ctlr=None):
        """Return completions for the given trigger point.

            "trg" is the trigger point at which to eval completions.
            "timeout" (optional) is a number of seconds after which to
                abandon completion. Raises EvalTimeout if the timeout is
                reached.
            "ctlr" (optional) is a EvalController instance to use for
                custom interaction with the evaluation.

        This is a convenience synchronous wrapper around async_eval_at_trg().
        Use the async version for any more interesting interaction.

        A "completion" is a 2-tuple -- (<type>, <completion-string>) -- where
        <type> is currently just a string like "variable", "class", etc.
        """
        assert timeout is None or isinstance(timeout, (float, int)),\
            "'timeout' must be None or a number"
        if ctlr is None:
            ctlr = EvalController()
        self.async_eval_at_trg(trg, ctlr)
        ctlr.wait(timeout)
        if not ctlr.is_done():
            ctlr.done("timed out")
            ctlr.abort()
            raise EvalTimeout("eval for %s timed-out" % trg)
        return ctlr.cplns

    def calltips_from_trg(self, trg, timeout=None, ctlr=None):
        """Return calltips for the given trigger point.

            "trg" is the trigger point at which to eval completions.
            "timeout" (optional) is a number of seconds after which to
                abandon completion. Raises EvalTimeout if the timeout is
                reached.
            "ctlr" (optional) is a EvalController instance to use for
                custom interaction with the evaluation.

        This is a convenience synchronous wrapper around async_eval_at_trg().
        Use the async version for any more interesting interaction.
        """
        assert timeout is None or isinstance(timeout, (float, int)),\
            "'timeout' must be None or a number"
        if ctlr is None:
            ctlr = EvalController()
        self.async_eval_at_trg(trg, ctlr)
        ctlr.wait(timeout)
        if not ctlr.is_done():
            ctlr.done("timed out")
            ctlr.abort()
            raise EvalTimeout("eval for %s timed-out" % trg)
        return ctlr.calltips

    def curr_calltip_arg_range(self, trg_pos, calltip, curr_pos, DEBUG=False):
        """Return that range in the calltip of the "current" arg.
        I.e. what argument is currently being entered.

            "trg_pos" is the trigger position.
            "calltip" is the full calltip text.
            "curr_pos" is the current position in the buffer.

        Returns a range: (start, end)
        Set `start == -1` to cancel the calltip, i.e. if the entered text
        has closed the call region.

        The default implementation uses defers to the LangIntel
        singleton for this language.
        """
        return self.langintel.curr_calltip_arg_range(self, trg_pos, calltip,
                                                     curr_pos, DEBUG=DEBUG)

    def text_chunks_from_lang(self, lang):
        """Generate a list of text chunks of the given language content.

        For a single-language buffer this is trivial: 1 chunk of the whole
        buffer. For multi-language buffers, less so.

        Generates 2-tuples:
            (POSITION-OFFSET, TEXT-CHUNK)
        """
        yield 0, self.accessor.text

    @property
    def libs(self):
        """Return the ordered list libraries in which to search for blob
        imports in this buffer.

        Each "library" is an instance of a database *Lib class that
        provides the has_blob()/get_blob() API. See the
        database/database.py module docstring for details.

        Commonly a buffer (for a typical programming language) will have
        some or all of the following libs:
            curdirlib/runtimedirlib
            extradirslib (based on *ExtraPaths prefs in the buffer's env)
            envlib (e.g. from PYTHONPATH, PERL5LIB, ... if set)
            cataloglib
            sitelib
            stdlib
        """
        raise VirtualMethodError("Buffer subclass for lang '%s' should "
                                 "implement the 'libs' property" % self.lang)

    def to_html(self, include_styling=False, include_html=False, title=None,
                do_trg=False, do_eval=False):
        """Return a styled HTML snippet for the current buffer.

            "include_styling" (optional, default False) is a boolean
                indicating if the CSS/JS/informational-HTML should be
                included.
            "include_html" (optional, default False) is a boolean indicating
                if the HTML output should be wrapped into a complete HTML
                document.
            "title" is the HTML document title to use if 'include_html' is
                True.
            "do_trg" (optional, default False) indicates that trigger
                handling should be done. This implies do_eval=True.
            "do_eval" (optional, default False) indicates that completion
                eval should be done.
        """
        from cStringIO import StringIO
        html = StringIO()

        if include_html:
            html.write('''\
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>%s</title>
</head>
<body>
''' % title)

        if include_styling:
            html.write('''
<script type="application/x-javascript">
    function show_class(span) {
        var infobox = document.getElementById("infobox");
        infobox.innerHTML = span.getAttribute("class");
    }
</script>

<style>
#infobox {
    border: 4px solid #e0e0e0;
    background-color: #f0f0f0;
    padding: 10px;
    position: fixed;
    top: 5px;
    right: 5px;
}

/* CSS Tooltips: http://www.communitymx.com/content/article.cfm?cid=4E2C0 */
div.code span.trg {
    font: small-caption;
    vertical-align: bottom;
    color: green;
    position: relative;
    cursor: crosshair;
}
div.code span.trg-info {
    display: none;
    z-index: 25;
    cursor: text;
    min-width: 25em;
    white-space: nowrap;
}
div.code span.trg:hover span.trg-info {
    z-index: 26;
    position: absolute;
    top: 1.0em;
    left: 0.0em;
    display: block;
    padding: 4px;
    background-color: #f0f0f0;
    border: 1px solid #e0e0e0;
}
span.trg-evalerror  { width: 50em; color: red !important; }
span.trg-error      { width: 50em; color: red !important; }
span.trg-notatrg    { color: blue !important; }
span.trg-noresults  { color: orange !important; }
td.trg-evallog {
    color: grey;
    border-left: 1px solid grey;
    padding-left: 5px;
}

/* token highlighting and debugging info */
div.code span:hover {
    background-color: #e0e0e0;
}

div.code span.udl-region:hover {
    background-color: #f0f0f0;
}

/* language-neutral syntax coloring */
div.code {
    font-family: "Courier New", Courier, monospace;
    font-size: small;
}

div.code .comments    { color: grey; }
div.code .keywords    { font-weight: bold; }
div.code .identifiers { color: black; }
div.code .strings     { color: blue; }
div.code .classes,
div.code .functions   { color: green; }
div.code .stderr      { background-color: red; }
div.code .stdout      { background-color: blue; }
div.code .tags        { color: red; }

</style>

<div id="infobox"></div>
''')

        # XXX escape lang name for CSS class
        html.write('<div class="code %s">\n' % self.lang.lower())

        curr_udl_region = None
        ch = last_ch = None
        for token in self.accessor.gen_tokens():
            css_classes = self.style_names_from_style_num(token["style"])
            if css_classes and css_classes[0].startswith("SCE_UDL_"):
                udl_region = css_classes[0].split('_')[2]
                if udl_region == curr_udl_region:
                    pass
                else:
                    if curr_udl_region:
                        html.write('\n</span>\n')
                    html.write('\n<span class="udl-region">\n')
                    curr_udl_region = udl_region
            html.write('<span class="%s" onmouseover="show_class(event.target);">'
                       % ' '.join(css_classes))
            for i, ch in enumerate(token["text"]):
                if ch == "\n" and last_ch == "\r":
                    # Treat '\r\n' as one char.
                    continue
                if do_trg:
                    try:
                        trg = self.trg_from_pos(token["start_index"] + i)
                    except CodeIntelError, ex:
                        html.write(self._html_from_trg_error(ex))
                    else:
                        if trg is not None:
                            html.write(self._html_from_trg(trg,
                                                           do_eval=do_eval))
                # XXX Need to do tab expansion.
                html.write(_htmlescape(ch, quote=True, whitespace=True))
                last_ch = ch
            html.write('</span>')
        if curr_udl_region:
            html.write('\n</span>\n')
        html.write('</div>\n')

        if include_html:
            html.write('''
</body>
</html>
''')

        return html.getvalue()

    def _html_from_trg_error(self, ex):
        marker = "&curren;"
        classes = ["trg"]
        classes.append("trg-error")
        result = _htmlescape(traceback.format_exc(), whitespace=True)
        info_html = '<div>%s</div' % result
        return '<span class="%s">%s<span class="trg-info">%s</span></span>' \
               % (' '.join(classes), marker, info_html)

    def _html_from_trg(self, trg, do_eval=False):
        marker = "&curren;"
        classes = ["trg"]

        try:
            eval_log_stream = StringIO()
            hdlr = logging.StreamHandler(eval_log_stream)
            infoFmt = "%(name)s: %(message)s"
            fmtr = logging.Formatter("%(name)s: %(levelname)s: %(message)s")
            hdlr.setFormatter(fmtr)
            codeintel_logger = logging.getLogger("codeintel")
            codeintel_logger.addHandler(hdlr)
            if do_eval:
                ctlr = LogEvalController(codeintel_logger)
                try:
                    if trg.form == TRG_FORM_CPLN:
                        cplns = self.cplns_from_trg(trg, ctlr=ctlr)
                    else:
                        calltips = self.calltips_from_trg(trg, ctlr=ctlr)
                finally:
                    codeintel_logger.removeHandler(hdlr)
        except NotATriggerError:
            classes.append("trg-notatrg")
            result = "(not a trigger point, false alarm by trg_from_pos())"
        except (EvalError, NotImplementedError,
                # XXX Eventually citdl evaluation shouldn't use
                #    codeintel2.CodeIntelError.
                CodeIntelError), ex:
            classes.append("trg-evalerror")
            result = _htmlescape(traceback.format_exc(), whitespace=True)
        else:
            if trg.form == TRG_FORM_CPLN:
                if not do_eval:
                    classes.append("trg-noresults")
                    result = "(eval skipped)"
                elif cplns:
                    result = "<br />".join(["<em>%s</em> %s" % c
                                            for c in cplns])
                else:
                    classes.append("trg-noresults")
                    result = "(no completions)"
            else:
                if not do_eval:
                    classes.append("trg-noresults")
                    result = "(eval skipped)"
                elif calltips:
                    result = _htmlescape(calltips[0], whitespace=True)
                else:
                    classes.append("trg-noresults")
                    result = "(no calltip)"

        eval_log = _htmlescape(str(trg), whitespace=True)
        eval_log += "<hr />"
        eval_log += _htmlescape(eval_log_stream.getvalue(), whitespace=True)
        info_html = ('<table><tr valign="top">'
                     '<td>%s</td>'
                     '<td class="trg-evallog">%s</td>'
                     '</tr></table>'
                     % (result, eval_log))
        return '<span class="%s">%s<span class="trg-info">%s</span></span>' \
               % (' '.join(classes), marker, info_html)

    #---- Scintilla style helpers.
    def style_names_from_style_num(self, style_num):
        # XXX Would like to have python-foo instead of p_foo or SCE_P_FOO, but
        #    that requires a more comprehensive solution for all langs and
        #    multi-langs.
        style_names = []

        # Get the constant name from ScintillaConstants.
        if self.lang not in self._style_name_from_style_num_from_lang:
            name_from_num \
                = self._style_name_from_style_num_from_lang[self.lang] = {}
            sce_prefixes = self.sce_prefixes
            if sce_prefixes is None:
                # Try and guess the prefix then.
                log.warn("Guessing sce_prefix as 'SCE_%s_' - if that's not "
                         "correct then define 'sce_prefixes' on your buffer"
                         "class", self.lang.upper())
                sce_prefixes = ["SCE_%s_" % (self.lang.upper())]
            for attr in dir(ScintillaConstants):
                for sce_prefix in sce_prefixes:
                    if attr.startswith(sce_prefix):
                        name_from_num[getattr(ScintillaConstants, attr)] = attr
        else:
            name_from_num \
                = self._style_name_from_style_num_from_lang[self.lang]
        const_name = self._style_name_from_style_num_from_lang[
            self.lang].get(style_num, "Unknown style")
        style_names.append("%d - %s" % (style_num, const_name))

        # Get a style group from styles.py.
        if self.lang in styles.StateMap:
            for style_group, const_names in styles.StateMap[self.lang].items():
                if const_name in const_names:
                    style_names.append(style_group)
                    break
        else:
            log.warn("lang '%s' not in styles.StateMap: won't have "
                     "common style groups in HTML output" % self.lang)

        return style_names

    __string_styles = None

    def string_styles(self):
        if self.__string_styles is None:
            state_map = styles.StateMap[self.lang]
            self.__string_styles = [
                getattr(ScintillaConstants, style_name)
                for style_class in ("strings", "stringeol")
                for style_name in state_map.get(style_class, [])
            ]
        return self.__string_styles

    __comment_styles = None

    def comment_styles(self):
        if self.__comment_styles is None:
            state_map = styles.StateMap[self.lang]
            self.__comment_styles = [
                getattr(ScintillaConstants, style_name)
                for style_class in ("comments", "here documents",
                                    "data sections")
                for style_name in state_map.get(style_class, [])
            ]
        return self.__comment_styles

    __number_styles = None

    def number_styles(self):
        if self.__number_styles is None:
            state_map = styles.StateMap[self.lang]
            self.__number_styles = [
                getattr(ScintillaConstants, style_name)
                for style_class in ("numbers",)
                for style_name in state_map.get(style_class, [])
            ]
        return self.__number_styles


class ImplicitBuffer(Buffer):
    """A buffer for a language that is not explicitly registered as
    a codeintel language.
    """
    def __init__(self, lang, mgr, accessor, env=None, path=None,
                 encoding=None):
        self.lang = lang
        Buffer.__init__(self, mgr, accessor, env=env, path=path,
                        encoding=encoding)

    # TODO: Is there a need/use in possibly determining scintilla styles
    #      for this language?
    def string_styles(self):
        return []

    def comment_styles(self):
        return []

    def number_styles(self):
        return []


#---- internal support stuff
# Recipe: htmlescape (1.0+) in C:\trentm\tm\recipes\cookbook
#         + whitespace option
def _htmlescape(s, quote=False, whitespace=False):
    """Replace special characters '&', '<' and '>' by SGML entities.

    Also optionally replace quotes and whitespace with entities and <br/>
    as appropriate.
    """
    s = s.replace("&", "&amp;")  # Must be done first!
    s = s.replace("<", "&lt;")
    s = s.replace(">", "&gt;")
    if quote:
        s = s.replace('"', "&quot;")
    if whitespace:
        s = s.replace(' ', "&nbsp;")
        # XXX Adding that '\n' might be controversial.
        s = re.sub(r"(\r\n|\r|\n)", "<br />\n", s)
    return s


#---- self-test
def _doctest():
    import doctest
    doctest.testmod()

if __name__ == "__main__":
    _doctest()

########NEW FILE########
__FILENAME__ = citadel
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

r"""Handling for citadel parts of CodeIntel.

The origin of the name "citadel": In early dev of codeintel naming for
various things generally began with "CI" for CodeIntel. The (simple) syntax
for defining type guesses (the things that are evaluated against the CIDB)
was (and is) called CITDL (CodeIntel Type Definition Language) -- pronounced
"citadel", in an attempt to be mnemonic. In dev for Komodo 4, the codeintel
system is being generalized to support languages that don't fit in the
CIDB/CITDL-framework so "citadel" is the umbrella term for CIDB/CITDL-based
stuff in the codeintel system.
"""

import os
from os.path import (isfile, isdir, exists, dirname, abspath, join, basename)
import sys
import logging
import time
import re
import traceback
import threading
from pprint import pprint

import ciElementTree as ET
import codeintel2
from codeintel2.buffer import Buffer
from codeintel2.common import *
from codeintel2.indexer import ScanRequest
from codeintel2.langintel import LangIntel


#---- globals
log = logging.getLogger("codeintel.citadel")
# log.setLevel(logging.INFO)


#---- module interface
class CitadelLangIntel(LangIntel):
    """Shared smarts for "citadel"-language content.

    "Citadel" languages are those whose scanning and completion
    evaluation is based on CIDB/CITDL/CIX.
    """


class CitadelBuffer(Buffer):
    """Virtual base class for language Buffers whose completion evaluation
    is based on CIDB/CITDL/CIX.

    CitadelBuffers have the following additional API:
        .defns_from_pos(..) Returns a list of citdl expressions for position.
        .scan(...)          Force a scan of the buffer.
        .scan_time          Time of the last scan (or None if not in the db)
        .scan_error         A string describing why the last scan failed
                            (or None if it didn't fail or there hasn't
                            been a scan)
        .blob_from_lang     Mapping of language to blob (a.k.a. the
                            module Element). This will synchronously
                            scan if there is not scan data already
                            available.

        .tree/.cix          CIX Element tree and serialized CIX of this
                            buffer's scan data.

        .scoperef_from_pos()
        .scoperef_from_blob_and_line()
                            Routines for getting the current scope in
                            the blob scan data. Used for completion eval
                            and code browsing.

        # Two convenience routines for working with the db.
        .load()             Load data about this buffer into the db.
        .unload()           Remove data about this buffer from the db.

    """
    # Local cache for buf data that is stored in the db. Each one of
    # these has a property for access.
    _scan_time_cache = None
    _scan_error_cache = None
    _blob_from_lang_cache = None

    def __init__(self, *args, **kwargs):
        Buffer.__init__(self, *args, **kwargs)
        self._scan_lock = threading.RLock()

    # Scanning can happen on different threads so access to scan data
    # must be guarded.
    def acquire_lock(self):
        self._scan_lock.acquire()

    def release_lock(self):
        self._scan_lock.release()

    _have_checked_db = False

    def _load_buf_data_once(self, skip_once_check=False):
        """Get persisted data for this buffer from the db.
        Raises NotFoundInDatabase is not there.
        """
        if skip_once_check or not self._have_checked_db:
            self._have_checked_db = True
            self._scan_time_cache, self._scan_error_cache, \
                self._blob_from_lang_cache = self.mgr.db.get_buf_data(self)

    def defn_trg_from_pos(self, pos, lang=None):
        """Return a list of CI definitions for the CITDL expression
        at the given pos.
        """
        if lang is None:
            lang = self.lang
        return Trigger(lang, TRG_FORM_DEFN, "defn", pos, False, length=0)

    def defns_from_trg(self, trg, timeout=None, ctlr=None):
        self.async_eval_at_trg(trg, ctlr)
        ctlr.wait(timeout)
        if not ctlr.is_done():
            ctlr.done("timed out")
            ctlr.abort()
            raise EvalTimeout("eval for %s timed-out" % trg)
        return ctlr.defns  # -> list of Definition's

    @property
    def scan_time(self):
        """The time of the last scan data.

        This may be the time of the scan or the modification time of the
        buffer content at the last scan.  Typically this is set via the
        'mtime' optional argument to scan().

        This returns None if this file hasn't been scanned.
        """
        self.acquire_lock()
        try:
            if self._scan_time_cache is None:
                try:
                    self._load_buf_data_once()
                except NotFoundInDatabase:
                    pass
            return self._scan_time_cache
        finally:
            self.release_lock()

    @property
    def scan_error(self):
        "A string describing why the last scan failed, or None if it didn't."
        self.acquire_lock()
        try:
            if self._scan_error_cache is None:
                try:
                    self._load_buf_data_once()
                except NotFoundInDatabase:
                    pass
            return self._scan_error_cache
        finally:
            self.release_lock()

    @property
    def blob_from_lang(self):
        self.acquire_lock()
        try:
            if self._blob_from_lang_cache is None:
                try:
                    self._load_buf_data_once()
                except NotFoundInDatabase:
                    self.release_lock()
                    try:
                        self.scan()
                    finally:
                        self.acquire_lock()
                    self._load_buf_data_once(True)
            return self._blob_from_lang_cache
        finally:
            self.release_lock()

    @property
    def tree(self):
        """The CIX tree for this buffer. Will lazily scan if necessary."""
        self.acquire_lock()
        try:
            # SIDE-EFFECT: scan if necessary
            blob_from_lang = self.blob_from_lang

            tree = ET.Element("codeintel", version="2.0")
            path = self.path
            if os.sep != '/':
                path = path.replace(os.sep, '/')
            file = ET.SubElement(tree, "file", path=path,
                                 lang=self.lang,
                                 mtime=str(self._scan_time_cache))
            if self._scan_error_cache:
                file.set("error", self._scan_error_cache)
            if blob_from_lang:
                for lang, blob in sorted(blob_from_lang.items()):
                    file.append(blob)
            return tree
        finally:
            self.release_lock()

    @property
    def cix(self):
        """The CIX for this buffer. Will lazily scan if necessary."""
        return ET.tostring(self.tree)

    def scan(self, mtime=None, skip_scan_time_check=False):
        """Scan the current buffer.

            "mtime" is the modification time of the buffer content. If
                not given the current time will be used.

        The results are stored on the buffer to be retrieved via the
        scan_time/scan_error/blob_from_lang properties.
        """
        if self.path is None:
            raise CodeIntelError("cannot scan %s buffer: 'path' is not set (setting "
                                 "a fake path starting with '<Unsaved>' is okay)"
                                 % self.lang)

        cile_driver = self.mgr.citadel.cile_driver_from_lang(self.lang)
        if mtime is None:
            mtime = time.time()

        # TODO: Eventually would like the CILEDriver scan methods to have
        #      a signature more inline with
        #      blob_from_lang/scan_time/scan_error. I.e. drop
        #      <file error="..."> mechanism in favour of just raising
        #      CILEError.
        scan_tree = None
        try:
            scan_tree = cile_driver.scan_purelang(self)
        except CodeIntelError, ex:
            exc_info = sys.exc_info()
            exc_class, exc, tb = sys.exc_info()
            tb_path, tb_lineno, tb_func = traceback.extract_tb(tb)[-1][:3]
            scan_error = "%s (%s:%s in %s)" % (
                exc, tb_path, tb_lineno, tb_func)
        except Exception, ex:
            msg = "unexpected error scanning `%s'" % basename(self.path)
            log.exception(msg)
            exc_info = sys.exc_info()
            exc_class, exc, tb = sys.exc_info()
            tb_path, tb_lineno, tb_func = traceback.extract_tb(tb)[-1][:3]
            scan_error = "%s: %s (%s:%s in %s)"\
                         % (msg, exc, tb_path, tb_lineno, tb_func)
        else:
            scan_error = scan_tree[0].get("error")

        self.acquire_lock()
        try:
            self._scan_time_cache = mtime
            self._scan_error_cache = scan_error
        finally:
            self.release_lock()

        # Put it into the database.
        self.mgr.db.update_buf_data(self, scan_tree, mtime, scan_error,
                                    skip_scan_time_check=skip_scan_time_check)
        self._load_buf_data_once(True)

    def scoperef_from_pos(self, pos):
        """Return the scoperef for the given position in this buffer.

        A "scoperef" is a 2-tuple:
            (<blob>, <lpath>)
        where <blob> is the ciElementTree blob for the buffer content
        and <lpath> is an ordered list of names into the blob
        identifying the scope.

        For example, given this "foo.py":

            class Foo:
                baz = 42
                def bar(self):
                    print "bar bar!"

        the scoperef for the print line would be:

            (<Python blob 'foo'>, ["Foo", "bar"])

        If no relevant scope is found (e.g. for example, in markup
        content in PHP) then None is returned.
        """
        try:
            blob = self.blob_from_lang[self.lang]
        except KeyError:
            return None
        line = self.accessor.line_from_pos(pos) + 1  # convert to 1-based
        return self.scoperef_from_blob_and_line(blob, line)

    def scoperef_from_blob_and_line(self, blob, line):  # line is 1-based
        lpath = []
        scope = blob
        while True:
            next_scope_could_be = None
            # PERF: Could make this a binary search if a scope has *lots* of
            # subscopes.
            for subscope in scope.findall("scope"):
                start = int(subscope.get("line"))
                if line < start:
                    break
                end = subscope.get("lineend") and int(subscope.get("lineend"))

                if end is not None:
                    if end < line:
                        next_scope_could_be = None
                    else:
                        next_scope_could_be = subscope
                else:
                    next_scope_could_be = subscope
            if next_scope_could_be is not None:
                lpath.append(next_scope_could_be.get("name"))
                scope = next_scope_could_be
            else:
                break
        return (blob, lpath)

    def scan_if_necessary(self):
        # SIDE-EFFECT: results in `self.scan()` if not in the db.
        self.blob_from_lang

    def unload(self):
        """Remove this buffer from the database."""
        self.mgr.db.remove_buf_data(self)

    # XXX Move citdl_expr_from_trg() here (see PythonBuffer)?


class BinaryBuffer(CitadelBuffer):
    def __init__(self, lang, mgr, env, path):
                                          # mgr, accessor, env, path, encoding
        self.lang = lang
        super(BinaryBuffer, self).__init__(mgr, None, env, path, None)

    def scan(self, mtime=None, skip_scan_time_check=False):
        if self.path is None:
            raise CodeIntelError("cannot scan %s buffer: 'path' is not set (setting "
                                 "a fake path starting with '<Unsaved>' is okay)"
                                 % self.lang)

        cile_driver = self.mgr.citadel.cile_driver_from_lang(self.lang)
        if mtime is None:
            mtime = time.time()

        scan_tree = None
        try:
            scan_tree = cile_driver.scan_binary(self)
        except CodeIntelError, ex:
            exc_info = sys.exc_info()
            exc_class, exc, tb = sys.exc_info()
            tb_path, tb_lineno, tb_func = traceback.extract_tb(tb)[-1][:3]
            scan_error = "%s (%s:%s in %s)" % (
                exc, tb_path, tb_lineno, tb_func)
        except Exception, ex:
            msg = "unexpected error scanning `%s'" % basename(self.path)
            log.exception(msg)
            exc_info = sys.exc_info()
            exc_class, exc, tb = sys.exc_info()
            tb_path, tb_lineno, tb_func = traceback.extract_tb(tb)[-1][:3]
            scan_error = "%s: %s (%s:%s in %s)"\
                         % (msg, exc, tb_path, tb_lineno, tb_func)
        else:
            scan_error = scan_tree[0].get("error")

        self.acquire_lock()
        try:
            self._scan_time_cache = mtime
            self._scan_error_cache = scan_error
        finally:
            self.release_lock()

        # Put it into the database.
        self.mgr.db.update_buf_data(self, scan_tree, mtime, scan_error,
                                    skip_scan_time_check=skip_scan_time_check)
        self._load_buf_data_once(True)

        # TODO: potential race condition here with Buffer.cached_sections().
        self._sections_cache = None

    def string_styles(self):
        return []

    def comment_styles(self):
        return []

    def number_styles(self):
        return []


class ImportHandler:
    """Virtual base class for language-specific "import"-statement handlers.

    The basic job of an import handler is to convert an import statement (i.e.
    a row in the 'import' table) into a row in the CIDB 'module' table. Doing
    this depends on language-specific import semantics.

    A fundamental part of import resolution is the search path. Here the
    search path is broken into three parts:
        - "core" path: built-in to the interpreter/compiler, generally
          dependent on the installation location.
        - "env" path: additional directories specified in a special
          environment variable, e.g. PYTHONPATH, PERL5LIB
        - "custom" path: additional "out-of-band" directories

    Each language-specific ImportHandler is a singleton as doled out by
    Citadel.import_handler_from_lang().
    """
    lang = None

    # DEPRECATED
    PATH_ENV_VAR = None
    corePath = None
    envPath = None
    customPath = None

    def __init__(self, mgr):
        self.mgr = mgr

    # DEPRECATED
    def setCustomPath(self, path):
        """Specify some custom search directories."""
        self.customPath = path

    # DEPRECATED
    def setEnvPath(self, value=None):
        """Specify the value of the PATH-style environment variable.

            "value" is the appropriate environment variable value, e.g.:
                "C:\trentm\mylib;C:\shared\lib-python". If value is None then
                the value will be retrieved from os.environ.

        This will lazily be called if necessary.
        """
        path = []
        if value is None:
            if self.PATH_ENV_VAR:
                path = os.environ.get(self.PATH_ENV_VAR, "").split(os.pathsep)
        else:
            path = value.split(os.pathsep)
        self.envPath = path

    # DEPRECATED
    def setCorePath(self, compiler=None, extra=None):
        """Specify the data needed to determine the core search path.

            "compiler" is the path to the language compiler/interpreter.
                If not specified then the first appropriate
                compiler/interpreter on the path is used.
            "extra" (optional) can be used to specify required extra
                data for determining the core import path.  For example,
                the PHP-specific implementation uses this to specify the
                "php.ini"-config-file path.

        This will lazily be called if necessary.
        """
        # Sub-classes must implement this and set self.corePath as a
        # result (to [] if it could not be determined).
        raise NotImplementedError("setCorePath: pure virtual method call")

    # DEPRECATED: still used by `genScannableFiles` implementations.
    def _getPath(self, cwd=None):
        """Put all the path pieces together and return that list.

        If "cwd" is specified, it is prepended to the list. (In many languages
        the directory of the file with the import statement is first on the
        module search path.)
        """
        if self.corePath is None:
            self.setCorePath()
        if self.envPath is None:
            self.setEnvPath()
        if cwd is not None:
            path = [cwd]
        else:
            path = []
        if self.customPath:
            path += self.customPath
        path += self.envPath
        path += self.corePath
        return path

    #---- new citree-based eval stuff

    # The string that separates dir levels in import names. For example,
    # this would be '.' for Python (import foo.bar), '::' for Perl
    # (use Foo::Bar;), '/' for Ruby, etc. Must be set for each language.
    sep = None

    def find_importables_in_dir(self, dir):
        """Return a mapping of
            import-name -> (path, subdir-import-name, is-dir-import)
        for all possible importable "things" in the given dir. Each part
        is explained below.

        The "import-name" is the string that you'd use in the particular
        language's import statement:
                        import statement        import-name     path
                        ----------------        -----------     ----
            Python:     import foo              foo             foo.py
            Perl:       use Foo;                Foo             Foo.pm
            Ruby:       require 'foo'           foo             foo.rb
            PHP:        require("foo.php")      foo.php         foo.php
                        require("foo.inc")      foo.inc         foo.inc

        For the simple case of a directly imported file in this dir, the
        "subdir-import-name" isn't relevant so None is used:
            Python:     "foo": ("foo.py", None, ...)
            Perl:       "Foo": ("Foo.pm", None, ...)
            Ruby:       "foo": ("foo.rb", None, ...)
            PHP:        "foo.php": ("foo.php", None, ...)
                        "foo.inc": ("foo.inc", None, ...)

        In addition to importable files in the given dir, this function
        must also provide the link to imports in *sub-directories*.  In
        Python a special "__init__.py" in subdirs is actually imported
        when a dir is specified. Here the "subdir-import-name" becomes
        relevant:
            Python:     "bar": ("bar/__init__.py", "__init__", False)

        In most languages there isn't a special file to indicate this.
        However the dir name *can* appear as part of an import
        statement. The "is-dir-import" boolean is used to indicate that
        the "import-name" can be used as part of a multi-level import
        statement:
            Perl:       "Bar": (None, None, True)
            Ruby:       "bar": (None, None, True)
            PHP:        "bar": (None, None, True)

        Some of these latter languages occasionally have an importable
        file *and* a sub-directory of the same name.
            Perl:       LWP.pm and LWP/... in the stdlib
            Ruby:       shell.rb and shell/... in the stdlib
        In these cases:
            Perl:       "LWP": ("LWP.pm", None, True)
            Ruby:       "shell": ("shell.rb", None, True)

        """
        raise NotImplementedError("find_importables_in_dir: virtual method")

    def import_blob_name(self, import_name, libs, ctlr):
        """Return the blob tree for the given import name and libs.

            "import_name" is the name used in the language's
                import/use/require statement under which blob
                information is generally keyed in the database.
            "libs" is an order list of libraries in which to search for
                the blob. See database/database.py's module docstring
                for info on the Library API.
            "ctlr" is the EvalController instance. Logging is done
                on this, and ctlr.is_aborted() may be used to abort
                processing.
        """
        for lib in libs:
            blob = lib.get_blob(import_name)
            if blob is not None:
                ctlr.info("is blob '%s' from %s? yes", import_name, lib)
                return blob
            else:
                ctlr.info("is blob '%s' from %s? no", import_name, lib)
        else:
            raise CodeIntelError("could not find data for %s blob '%s'"
                                 % (self.lang, import_name))


class CitadelEvaluator(Evaluator):
    """A Citadel evaluator -- i.e. the guy that knows how to translate
    a CITDL expression into a list of completions or a calltip.
    """
    citadel = None
    have_requested_reeval_already = False  # sentinel to trap infinite loop

    def __init__(self, ctlr, buf, trg, expr, line):
        Evaluator.__init__(self, ctlr, buf, trg)
        self.lang = buf.lang  # XXX should use trg.lang instead (multi-lang differs)
        self.path = buf.path
        self.cwd = dirname(self.path)
        self.expr = expr  # XXX should be rigorous and use citdl_expr
        self.line = line  # 0-based

    def __str__(self):
        return "'%s' at %s#%s" % (self.expr, basename(self.path), self.line+1)

    def post_process_cplns(self, cplns):
        """Hook for sub-classes to post-process the list of completions.

        Implementations may modify the list in place.

        Note that a common operation that all implementations should
        generally do (and the default impl. *does*) is to sort the list
        of completions case-insensitively by value and with punctuation
        characters sorting last (see bug 77954). Sorting is necessary
        to have type-ahead-find work properly in Scintilla's autocomplete
        UI and case-insensitive sorting is necessary if using Scintilla's
        SCI_AUTOCSETIGNORECASE(true) -- which Komodo is.
        """
        from codeintel2.util import OrdPunctLast
        cplns.sort(key=lambda c: OrdPunctLast(c[1]))
        return cplns

    def post_process_calltips(self, calltips):
        """Hook for sub-classes to post-process the list of calltips.

        Implementations may modify the list in place.
        """
        return calltips

    def post_process_defns(self, defns):
        """Hook for sub-classes to post-process the list of defns.

        Implementations may modify the list in place.
        """
        return defns

    def request_reeval(self):
        """Used for an on_complete callback to CitadelBuffer.scan_and_load()."""
        assert not self.have_requested_reeval_already, \
            "invalid eval usage: cannot request re-eval more than once"
        self.have_requested_reeval_already = True

        if self.ctlr.is_aborted():
            self.ctlr.done("aborting")
            return
        self.ctlr.info("request re-eval of %s", self)
        self.mgr.request_reeval(self)

    def import_resolution_failure(self, name, path):
        """Called by import-resolution code to offer ability to react to
        a module import not resolving in the CIDB.

        The nice-to-have plan was to request a scan of this module and then
        re-evaluate at this trigger when that was finished. If well behaved
        this would give the best completion GOOBE to the user: the first
        time may be slow, but it just works.

        PUNTing on that for now because (1) of fear of this not being
        well-behaved: repeated (and hence performance intensive) attempted
        scanning of a module that doesn't quite make it into to the CIDB.
        Could monitor that with a "3 strikes" rule or something. Also (2),
        the *real* solution should involve re-scanning of modules that
        are newer than our scan info. This logic belongs on a Buffer for
        that module (or something). Revisit when/if refactoring codeintel
        the next time through.
        """
        self.ctlr.warn("no info on import '%s'", name)
        # log.warn("XXX Currently not reacting to import resolution failure. "
        #         "Try to do that later. (path=%s)" % path)

    #---- the guts of the evaluation
    def debug(self, msg, *args):
        self.ctlr.debug(msg, *args)

    def info(self, msg, *args):
        self.ctlr.info(msg, *args)

    def warn(self, msg, *args):
        self.ctlr.warn(msg, *args)

    def error(self, msg, *args):
        self.ctlr.error(msg, *args)


class Citadel(object):
    """The manager of Citadel-parts of the CodeIntel system. This is a
    singleton canonically available from Manager.citadel.

    Usage
    -----

    Typically all interaction with a Citadel is done via a Manager instance.
    Here is what the Manager should be doing.

        citadel = Citadel(mgr, ...)

        citadel.initialize()

        # Use the citadel. The most common methods are:
        #   .{add|stage}_scan_request()

        # Must be finalized to ensure no thread hangs.
        citadel.finalize()
    """
    MIN_CIDB_VERSION = (1, 0)  # minimum supported database version

    def __init__(self, mgr):
        self.mgr = mgr

        self._import_handler_from_lang = {}
        self._cile_driver_from_lang = {}
        self._is_citadel_cpln_from_lang = {}

    def set_lang_info(self, lang, cile_driver_class, is_cpln_lang=False):
        self._cile_driver_from_lang[lang] = cile_driver_class(self.mgr)
        if is_cpln_lang:
            self._is_citadel_cpln_from_lang[lang] = True

    def cile_driver_from_lang(self, lang):
        """Return the CILE driver for this language.

        Raises KeyError if there isn't one registered.
        """
        return self._cile_driver_from_lang[lang]

    def is_citadel_cpln_lang(self, lang):
        """Return true if the given lang is a Citadel-based completion
        lang.
        """
        return lang in self._is_citadel_cpln_from_lang

    def get_citadel_cpln_langs(self):
        return self._is_citadel_cpln_from_lang.keys()

    def finalize(self):
        pass

    def import_handler_from_lang(self, lang):
        """Return an "import"-handler for the given language.

        Returns None if don't know how to handle imports for this language.
        Each language-specific ImportHandler object is a singleton.

        TODO: move this to Manager class.
        """
        if lang not in self._import_handler_from_lang:
            try:
                self._import_handler_from_lang[lang] \
                    = self.mgr.import_handler_class_from_lang[lang](self.mgr)
            except KeyError:
                raise CodeIntelError("there is no registered ImportHandler "
                                     "class for language '%s'" % lang)
        return self._import_handler_from_lang[lang]

########NEW FILE########
__FILENAME__ = citadel_common
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Common definitions for the Citadel parts of codeintel."""

import os
import sys
from hashlib import md5
import re
import stat
import time
import threading
import logging

from codeintel2.common import *


log = logging.getLogger("codeintel.citadel")


class ScanRequest:
    """A request to scan a file for code intel.

    A ScanRequest has the following properties:
        "id" is a unique ID for this request. It is assigned by the
            scheduler when the request is made.
        "path" is the full canonicalized path to the file to scan. The path
            is canonicalized when set in the constructor.
        "language" is the content-type of the file. This determines what
            "Language Engine(s)" are used to scan it. (XXX Specify allowable
            range of languages.)
        "priority" must be one of the PRIORITY_* priorities.
        "force" is a boolean indicating if a scan should be run even if
            the database is already up-to-date for this content.
        "content" is the file content. This can be explicitly given in the
            constructor. This is useful if the current content is not
            saved to disk or if it is difficult to retrieve the content.
            If not specified the loadContent() method will be used to
            get it from the filename.  Subclasses can override
            loadContent() if necessary.
        "md5sum" is the MD5 hexdigest of the content.  If already
            calculated it may be specified in the constructor. Otherwise
            this can be calculated as needed via the calculateMD5()
            method.
        "mtime" is the modified time of the file/content. If this is not
            given, it is determined lazily (if content is NOT specified) or
            defaults to the current time (if content IS specified).
        "scan_imports" is a boolean (default true) indicating that
            imports should be scheduled for scanning when this file is
            loaded into the database.
        "on_complete" (optional) is a callable to call when the scan
            and load is complete.
    """
    def __init__(self, path, language, priority, force=0, content=None,
                 md5sum=None, mtime=None, scan_imports=True,
                 on_complete=None):
        self.id = None
        self.path = path
        self.language = language
        self.priority = priority
        self.force = force
        self.content = content
        if mtime:
            self.mtime = mtime
        elif content is not None:
            # Presumably if the content is being specified rather than having
            # the request's loadContent() determine it, then it is from an
            # editor buffer and may have changed just recently.
            self.mtime = int(time.time())
        else:
            self.mtime = None  # determine lazily
        self.md5sum = md5sum
        self.scan_imports = scan_imports
        self.on_complete = on_complete
        self.complete_event = threading.Event()  # XXX use a pool

    def __repr__(self):
        return "<ScanRequest id:%r, path:'%s'>" % (self.id, self.path)

    def __str__(self):
        return "scan request '%s' (prio %s)" % (self.path, self.priority)

    def complete(self):
        """Called by scheduler when this scan is complete (whether or
        not it was successful/skipped/whatever).
        """
        log.info("complete %s", self)
        self.complete_event.set()
        if self.on_complete:
            try:
                self.on_complete()
            except:
                log.exception("ignoring exception in ScanRequest "
                              "on_complete callback")

    def wait(self, timeout=None):
        """Can be called by code requesting a scan to wait for completion
        of this particular scan.
        """
        self.complete_event.wait(timeout)

    def loadContent(self):
        """If self.content is not set, load it from self.path.

        This also sets self.mtime, if necessary.
        This can raise an EnvironmentError if the file is not accessible.
        """
        if self.content is None:
            self.mtime = os.stat(self.path)[stat.ST_MTIME]
            fin = open(self.path, "r")
            try:
                self.content = fin.read()
            finally:
                fin.close()

    def calculateMD5(self):
        """Calculate and set self.md5sum if is it not already set."""
        if self.md5sum is None:
            self.loadContent()
            self.md5sum = md5(self.content).hexdigest()

    def getCanonicalPath(self):
        return canonicalizePath(self.path)

########NEW FILE########
__FILENAME__ = common
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Code Intelligence: common definitions"""
# Dev Notes:
# - XXX Need some good top-level logging control functions for this package.
# - XXX Rationalize exceptions.
# - XXX Coding style name changes.

__all__ = [
    "Trigger", "Definition", "CILEDriver", "Evaluator",
    "EvalController", "LogEvalController",

    "canonicalizePath", "parseAttributes", "isUnsavedPath",

    "TRG_FORM_CPLN", "TRG_FORM_CALLTIP", "TRG_FORM_DEFN",

    "PRIORITY_CONTROL", "PRIORITY_IMMEDIATE", "PRIORITY_CURRENT",
    "PRIORITY_OPEN", "PRIORITY_BACKGROUND",

    "CodeIntelDeprecationWarning",
    "CodeIntelError", "NotATriggerError", "EvalError", "EvalTimeout",
    "VirtualMethodError", "CitadelError", "NoBufferAccessorError",
    "CILEError", "CIXError", "CIDBError", "DatabaseError",
    "CorruptDatabase", "NotFoundInDatabase", "CITDLError",
    "NoModuleEntry", "NoCIDBModuleEntry",

    "LazyClassAttribute",

    "ENABLE_HEURISTICS",
    "_xpcom_",
]

import os
from os.path import dirname, join, normpath, exists, basename
import sys
import re
import stat
import time
import threading
import logging
import warnings

try:
    from zope.cachedescriptors.property import Lazy as LazyClassAttribute
except ImportError:
    import warnings
    warnings.warn("Unable to import zope.cachedescriptors.property")
    # Fallback to regular properties.
    LazyClassAttribute = property

import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants

if "CODEINTEL_NO_PYXPCOM" in os.environ:
    _xpcom_ = False
else:
    try:
        from xpcom import components
        from xpcom.server import UnwrapObject
        _xpcom_ = True
    except ImportError:
        _xpcom_ = False

# XXX Should only do this hack for non-Komodo local codeintel usage.
# XXX We need to have a better mechanism for rationalizing and sharing
#    common lexer style classes. For now we'll just HACKily grab from
#    Komodo's styles.py. Some of this is duplicating logic in
#    KoLanguageServiceBase.py.
_ko_src_dir = normpath(join(dirname(__file__), *([os.pardir]*3)))
sys.path.insert(0, join(_ko_src_dir, "schemes"))
try:
    import styles
finally:
    del sys.path[0]
    del _ko_src_dir


#---- general codeintel pragmas

# Allow the CILEs to generate type guesses based on type names (e.g.
# "event" is an Event in JS).
ENABLE_HEURISTICS = True


#---- warnings
class CodeIntelDeprecationWarning(DeprecationWarning):
    pass
# Here is how to disable these warnings in your code:
#   import warnings
#   from codeintel2.common import CodeIntelDeprecationWarning
#   warnings.simplefilter("ignore", CodeIntelDeprecationWarning)
warnings.simplefilter(
    "ignore", CodeIntelDeprecationWarning)  # turn off for now


#---- exceptions
class CodeIntelError(Exception):
    """Base Code Intelligence system error."""
    pass
Error = CodeIntelError  # XXX Remove uses of this in favour of CodeIntelError.


class NotATriggerError(CodeIntelError):
    pass


class EvalError(CodeIntelError):
    pass


class EvalTimeout(EvalError):
    pass


class VirtualMethodError(CodeIntelError):
    # TODO: pull out the method and class name from the stack for errmsg
    #      tell user what needs to be implemented
    pass


class CitadelError(CodeIntelError):
    pass


class NoBufferAccessorError(CodeIntelError):
    """The accessor has no buffer/content to access."""
    pass


class CILEError(CitadelError):
    """CILE processing error."""
    # XXX Should add some relevant data to the exception. Perhaps
    #    the request should be passed in and this c'tor can extract
    #    data it wants to keep.  This could be used to facilitate
    #    submitting bug reports on our Language Engines.
    pass


class CIXError(CitadelError):
    """Code Intelligence XML error."""
    pass


class CIDBError(CitadelError):
    """Code Intelligence Database error."""
    # TODO: Transition to DatabaseError and ensure that the change in
    #      base class doesn't cause problems.
    pass


class DatabaseError(CodeIntelError):
    pass


class CorruptDatabase(DatabaseError):
    """Corruption in some part of the database was found."""
    # XXX Should add attributes that indicate which part
    #    was corrupt and/or one of a known set of possible corrupts.
    #    Then add a Database.recover() function that could attempt
    #    to recover with that argument.
    pass


class NotFoundInDatabase(DatabaseError):
    """No data for the buffer was found in the database."""
    pass


class CITDLError(CitadelError):  # XXX Just drop in favour of CitadelError?
    """CITDL syntax error."""
    pass


class NoModuleEntry(CIDBError):
    """There is no entry for this module in the CIDB.

    The "module_path" second constructor argument (possibly None) is required
    to allow completion handling (which will be trapping these errors) to use
    that path to kick off a scan for it. This shouldn't be a burden as the
    import handlers that raise this will just have looked for this path.
    """
    def __init__(self, module_name, module_path):
        CIDBError.__init__(self)
        self.module_name = module_name  # the module name
        self.module_path = module_path

    def __str__(self):
        path_info = ""
        if self.module_path:
            path_info = " (%s)" % os.path.basename(self.module_path)
        return "no module entry for '%s'%s in CIDB"\
               % (self.module_name, path_info)


class NoCIDBModuleEntry(CIDBError):  # XXX change name to NoModuleEntryForPath
    """There is no module entry for the given path in the CIDB."""
    def __init__(self, path):
        CIDBError.__init__(self)
        self.path = path

    def __str__(self):
        return "no module entry for '%s' in CIDB"\
               % os.path.basename(self.path)


#---- globals
# Trigger forms.
TRG_FORM_CPLN, TRG_FORM_CALLTIP, TRG_FORM_DEFN = range(3)

# Priorities at which scanning requests can be scheduled.
PRIORITY_CONTROL = 0        # Special sentinal priority to control scheduler
PRIORITY_IMMEDIATE = 1      # UI is requesting info on this file now
PRIORITY_CURRENT = 2        # UI requires info on this file soon
PRIORITY_OPEN = 3           # UI will likely require info on this file soon
PRIORITY_BACKGROUND = 4     # info may be needed sometime

# TODO: these are unused, drop them
# CIDB base type constants
BT_CLASSREF, BT_INTERFACEREF = range(2)

# TODO: These are unused, drop them, the symbolType2Name below and its dead
#      usage in cb.py.
# CIDB symbol type constants
(ST_FUNCTION, ST_CLASS, ST_INTERFACE, ST_VARIABLE, ST_ARGUMENT) = range(5)
_symbolType2Name = {
    ST_FUNCTION: "function",
    ST_CLASS: "class",
    ST_INTERFACE: "interface",
    ST_VARIABLE: "variable",
    ST_ARGUMENT: "argument"
}


#---- common codeintel base classes
class Trigger(object):
    if _xpcom_:
        _com_interfaces_ = [components.interfaces.koICodeIntelTrigger]

    lang = None  # e.g. "Python", "CSS"
    form = None  # TRG_FORM_CPLN or TRG_FORM_CALLTIP
    type = None  # e.g. "object-members"
    pos = None  # Trigger position, in bytes (of UTF 8)
    implicit = None
    # The number characters of the trigger. For most (but not all) triggers
    # there is a clear distinction between a trigger token and a preceding
    # context token. For example:
    #       foo.<|>         # trigger token is '.', length = 1
    #       Foo::Bar-><|>   # trigger token is '->', length = 2
    # This default to 1.
    length = None
    # The number of characters after pos that should be replaced.  Most of the
    # time this will be zero.  For example
    #      foo.<|>prop      # extentLength is 4, for "prop"
    # Note that this goes in the opposite direction of .length
    extentLength = None
    retriggerOnCompletion = False

    def __init__(
        self, lang, form, type, pos, implicit, length=1, extentLength=0,
            **extra):
        self.lang = lang
        self.form = form
        self.type = type
        self.pos = pos
        self.implicit = implicit
        self.length = length
        self.extentLength = extentLength
        self.extra = extra  # Trigger-specific extra data, if any

    @property
    def id(self):
        return (self.lang, self.form, self.type)

    __name = None

    @property
    def name(self):
        """A more user-friendly name for this trigger, e.g.
        'python-complete-object-members'
        """
        if self.__name is None:
            form_str = {TRG_FORM_CPLN: "complete",
                        TRG_FORM_DEFN: "defn",
                        TRG_FORM_CALLTIP: "calltip"}[self.form]
            self.__name = "%s-%s-%s" % (self.lang.lower(), form_str,
                                        self.type)
        return self.__name

    def __repr__(self):
        explicit_str = (not self.implicit) and " (explicit)" or ""
        return "<Trigger '%s' at %d%s>" % (self.name, self.pos, explicit_str)

    def is_same(self, trg):
        """Return True iff the given trigger is (effectively) the same
        as this one.

        Dev Note: "Effective" is currently left a little fuzzy. Just
        comparing enough to fix Komodo Bug 55378.
        """
        if _xpcom_:
            trg = UnwrapObject(trg)
        if (self.pos == trg.pos
            and self.type == trg.type
            and self.form == trg.form
                and self.lang == trg.lang):
            return True
        else:
            return False

    def to_dict(self):
        """Serialize this trigger as a dictionary
        This is used for out-of-process codeintel
        """
        return dict(lang=self.lang, form=self.form, type=self.type,
                    pos=self.pos, implicit=self.implicit, length=self.length,
                    extentLength=self.extentLength,
                    retriggerOnCompletion=self.retriggerOnCompletion,
                    **self.extra)


class Definition(object):
    if _xpcom_:
        _com_interfaces_ = [components.interfaces.koICodeIntelDefinition]

    lang = None        # e.g. "Python", "CSS"
    path = None        # e.g. "/usr/local/..."
    blobname = None    # e.g. "sys"
    lpath = None       # lookup tuple in blob, e.g. ["MyClass", "afunc"]
    name = None        # e.g. "path"
    line = None        # e.g. 345 (1-based)
    ilk = None         # e.g. "function"
    citdl = None       # e.g. "int"
    signature = None   # e.g. "function xyz(...)"
    doc = None         # e.g. "Xyz is just nasty stuff..."
    attributes = None  # e.g. "local private"
    returns = None     # e.g. "int"
    scopestart = None  # e.g. 320 (1-based)
    scopeend = None    # e.g. 355 (1-based)

    def __init__(self, lang, path, blobname, lpath, name, line, ilk,
                 citdl, doc, signature=None, attributes=None,
                 returns=None, scopestart=None, scopeend=None):
        self.lang = lang
        self.path = path
        self.blobname = blobname
        self.lpath = lpath
        self.name = name
        self.line = line
        self.ilk = ilk
        self.citdl = citdl
        self.doc = doc
        self.signature = signature
        self.attributes = attributes
        self.returns = returns
        self.scopestart = scopestart
        self.scopeend = scopeend

    def __repr__(self):
        if self.path is None:
            return "<Definition: %s '%s' at %s#%s lpath=%s>"\
                % (self.ilk, self.name, self.blobname, self.line, self.lpath)
        else:
            return "<Definition: %s '%s' at %s#%s in %s lpath=%s>"\
                % (self.ilk, self.name, self.blobname, self.line,
                   basename(self.path), self.lpath)

    def equals(self, other):
        """ Equality comparision for XPCOM """
        if _xpcom_:
            try:
                other = UnwrapObject(other)
            except:
                pass
        for attr in (
            "lang", "path", "blobname", "lpath", "name", "line", "ilk",
                "citdl", "doc", "signature", "attributes", "returns"):
            if getattr(self, attr) != getattr(other, attr):
                return False
        return True

    def toString(self):
        """ toString implementation for XPCOM """
        return repr(self)

    @classmethod
    def unique_definitions(cls, defns):
        """Takes a collection of defns and returns the unique list of defns."""
        unique_defns = []
        for defn in defns:
            for unique_defn in unique_defns:
                if unique_defn.path == defn.path and unique_defn == defn:
                    # defn is already in the unique_defn list.
                    break
            else:
                unique_defns.append(defn)
        return unique_defns


class CILEDriver(object):
    """Base class for all CILE drivers.

    CILE stands for "CodeIntel Language Engine". A CILE is the thing that
    knows how to convert content of a specific language to CIX (the XML data
    loaded into the CIDB, then used for completion, code browsers, etc.)

    A CILE *driver* is a class that implements this interface on top of a
    language's CILE. A CILE might be a Python module, a separate executable,
    whatever.
    """
    def __init__(self, mgr):
        self.mgr = mgr

    # DEPRECATED
    def scan(self, request):
        """Scan the given file and return data as a CIX document.

            "request" is a ScanRequest instance.

        This method MUST be re-entrant. The scheduler typically runs a pool
        of scans simultaneously so individual drivers can be called into from
        multiple threads.

        If the scan was successful, returns a CIX document (XML). Note: the
        return value should be unicode string, i.e. NOT an encoded byte
        string -- encoding to UTF-8 is done as necessary elsewhere.

        Raises a CILEError if there was a problem scanning. I.e. a driver
        should be resistant to CILE hangs and crashes.
        """
        raise VirtualMethodError("CILEDriver.scan")

    def scan_purelang(self, buf):
        """Scan the given buffer and return a CIX element tree.

            "buf" is an instance of this language's Buffer class.
        """
        raise VirtualMethodError("CILEDriver.scan_purelang")

    def scan_binary(self, buf):
        """Scan the given binary buffer and return a CIX element tree.

            "buf" is an instance of this language's BinaryBuffer clas
        """
        raise VirtualMethodError("CILEDriver.scan_binary")

    def scan_multilang(self, buf, csl_cile_driver=None):
        """Scan the given multilang (UDL-based) buffer and return a CIX
        element tree.

            "buf" is the multi-lang UDLBuffer instance (e.g.
                lang_rhtml.RHTMLBuffer for RHTML).
            "csl_cile_driver" (optional) is the CSL (client-side language)
                CILE driver. While scanning, CSL tokens should be gathered and,
                if any, passed to the CSL scanner like this:
                    csl_cile_driver.scan_csl_tokens(
                        file_elem, blob_name, csl_tokens)
                The CSL scanner will append a CIX <scope ilk="blob">
                element to the <file> element.

        A language that supports being part of a multi-lang document
        must implement this method.
        """
        raise VirtualMethodError("CILEDriver.scan_multilang")

    def scan_csl_tokens(self, file_elem, blob_name, csl_tokens):
        """Generate a CIX <scope ilk="blob"> tree for the given CSL
        (client-side language) tokens and append the blob to the given
        file element.

        A language that supports being a client-side language in a
        multi-lang document must implement this method. Realistically
        this just means JavaScript for now, but could eventually include
        Python for the new Mozilla DOM_AGNOSTIC work.
        """
        raise VirtualMethodError("CILEDriver.scan_csl_tokens")


class EvalController(object):
    """A class for interaction with an asynchronous evaluation of completions
    or calltips. Typically for "interesting" interaction on would subclass
    this and pass an instance of that class to Buffer.async_eval_at_trg().
    """

    def __init__(self):
        self.complete_event = threading.Event()  # use a pool?
        self._done = False
        self._aborted = False
        self.buf = None
        self.trg = None
        self.cplns = None
        self.calltips = None
        self.defns = None
        self.desc = None
        self.keep_existing = False

    def close(self):
        """Done with this eval controller, clear any references"""
        pass

    def start(self, buf, trg):
        """Called by the evaluation engine to indicate the beginning of
        evaluation and to pass in data the controller might need.
        """
        self.buf = buf
        self.trg = trg

    def set_desc(self, desc):
        self.desc = desc

    def done(self, reason):
        """Called by the evaluation engine to indicate completion handling
        has finished."""
        self.info("done eval: %s", reason)
        self._done = True
        self.buf = None
        self.trg = None
        self.complete_event.set()

    def is_done(self):
        return self._done

    def abort(self):
        """Signal to completion handling system to abort the current
        completion session.
        """
        self._aborted = True

    def is_aborted(self):
        return self._aborted

    def wait(self, timeout=None):
        """Block until this completion session is done or
        until the timeout is reached.
        """
        self.complete_event.wait(timeout)

    def debug(self, msg, *args):
        pass

    def info(self, msg, *args):
        pass

    def warn(self, msg, *args):
        pass

    def error(self, msg, *args):
        pass

    # XXX Perhaps this capturing should be in a sub-class used only for
    #    testing. Normal IDE behaviour is to fwd the data in set_*().
    def set_cplns(self, cplns):
        self.cplns = cplns

    def set_calltips(self, calltips):
        self.calltips = calltips

    def set_defns(self, defns):
        self.defns = defns


class LogEvalController(EvalController):
    def __init__(self, logger_or_log_name=None):
        if isinstance(logger_or_log_name, logging.getLoggerClass()):
            self.logger = logger_or_log_name
        else:
            self.logger = logging.getLogger(logger_or_log_name)
        EvalController.__init__(self)

    def debug(self, msg, *args):
        self.logger.debug(msg, *args)

    def info(self, msg, *args):
        self.logger.info(msg, *args)

    def warn(self, msg, *args):
        self.logger.warn(msg, *args)

    def error(self, msg, *args):
        self.logger.error(msg, *args)


class Evaluator(object):
    """To do asynchronous autocomplete/calltip evaluation you create an
    Evaluator instance (generally a specialized subclass of) and pass it
    to Manager.request_eval() and/or Manager.request_reeval().

    At a minimum a subclass must implement the eval() method making sure
    that the rules described for Buffer.async_eval_at_trg() are followed
    (see buffer.py). Typically this just means:
    - ensuring ctlr.done() is called,
    - reacting to ctlr.is_aborted(), and
    - optionally calling the other EvalController methods as appropriate.

    A subclass should also implement readable __str__ output.

    The manager handles:
    - co-ordinating a queue of evaluation requests
    - only ever running one evaluation at a time (because it only makes sense
      in an IDE to have one on the go)
    - calling the evaluator's eval() method in a subthread
    - calling ctlr.done(<reason>) if the eval terminates with an exception

    One important base class is the CitadelEvaluator (see citadel.py) that
    knows how to do CITDL evaluation using the CIDB. Citadel languages
    (e.g. Perl, Python, ...) will generally use CitadelEvaluators for most
    of their triggers.
    """
    def __init__(self, ctlr, buf, trg):
        assert isinstance(ctlr, EvalController)
        self.ctlr = ctlr
        # assert isinstance(buf, Buffer) # commented out to avoid circular dep
        self.buf = buf
        assert isinstance(trg, Trigger)
        self.trg = trg

    def eval(self):
        self.ctlr.done("eval not implemented")
        raise VirtualMethodError("Evaluator.eval")

    def close(self):
        """Done with this evaluator, clear any references"""
        if self.ctlr is not None:
            self.ctlr.close()


#---- helper methods

# TODO: drop this (see note above)
def symbolType2Name(st):
    return _symbolType2Name[st]

# TODO: drop this, see similar func in parseutil.py


def xmlattrstr(attrs):
    """Construct an XML-safe attribute string from the given attributes

        "attrs" is a dictionary of attributes

    The returned attribute string includes a leading space, if necessary,
    so it is safe to use the string right after a tag name.
    """
    # XXX Should this be using
    from xml.sax.saxutils import quoteattr
    s = ''
    names = attrs.keys()
    names.sort()  # dump attrs sorted by key, not necessary but is more stable
    for name in names:
        s += ' %s=%s' % (name, quoteattr(str(attrs[name])))
    return s


def isUnsavedPath(path):
    """Return true if the given path is a special <Unsaved>\sub\path file."""
    tag = "<Unsaved>"
    length = len(tag)
    if path.startswith(tag) and (len(path) == length or path[length] in "\\/"):
        return True
    else:
        return False

# TODO: move this utils.py
_uriMatch = re.compile("^\w+://")


def canonicalizePath(path, normcase=True):
    r"""Return what CodeIntel considers a canonical version of the given path.

        "path" is the path to canonicalize.
        "normcase" (optional, default True) is a boolean indicating if the
            case should be normalized.

    "Special" paths are ones of the form "<Tag>\sub\path". Supported special
    path tags:
        <Unsaved>       Used when the given path isn't a real file: e.g.
                        unsaved document buffers.

    Raises a ValueError if it cannot be converted to a canonical path.

    >>> canonicalizePath(r"C:\Python22\Lib\os.py")  # normcase on Windows
    'c:\\python22\\lib\\os.py'
    >>> canonicalizePath(r"<Unsaved>\Python-1.py")
    '<Unsaved>\\python-1.py'
    >>> canonicalizePath("<Unsaved>")
    '<Unsaved>'
    >>> canonicalizePath("<Unsaved>\\")
    '<Unsaved>'
    >>> canonicalizePath("ftp://ftp.ActiveState.com/pub")
    'ftp://ftp.ActiveState.com/pub'
    """
    if path is None:
        raise ValueError("cannot canonicalize path, path is None")
    if path.startswith('<'):  # might be a special path
        first, rest = None, None
        for i in range(1, len(path)):
            if path[i] in "\\/":
                first, rest = path[:i], path[i+1:]
                break
        else:
            first, rest = path, None
        if first.endswith('>'):
            tag = first
            subpath = rest
            if tag == "<Unsaved>":
                pass  # leave tag unchanged
            else:
                raise ValueError("unknown special path tag: %s" % tag)
            cpath = tag
            if subpath:
                subpath = os.path.normpath(subpath)
                if normcase:
                    subpath = os.path.normcase(subpath)
                cpath = os.path.join(cpath, subpath)
            return cpath
    if _uriMatch.match(path):  # ftp://, koremote://
        # XXX Should we normcase() a UR[LI]
        return path
    else:
        cpath = os.path.normpath(os.path.abspath(path))
        if normcase:
            cpath = os.path.normcase(cpath)
        return cpath

# TODO: move this utils.py


def parseAttributes(attrStr=None):
    """Parse the given attributes string (from CIX) into an attribute dict."""
    attrs = {}
    if attrStr is not None:
        for token in attrStr.split():
            if '=' in token:
                key, value = token.split('=', 1)
            else:
                key, value = token, 1
            attrs[key] = value
    return attrs


#---- self-test code
if __name__ == '__main__':
    def _test():
        import doctest
        import common
        return doctest.testmod(common)
    _test()

########NEW FILE########
__FILENAME__ = constants_css1
"""
CSS 1 definitions.
"""

import textwrap

CSS_PSEUDO_CLASS_NAMES = """first-letter first-line link active visited
        first-child focus hover lang before after left right first""".split()

CSS_ATTR_DICT = {
    'background': [
    'bottom',
    'center',
    'fixed',
    'inherit',
    'left',
    'none',
    'no-repeat',
    'repeat',
    'repeat-x',
    'repeat-y',
    'rgb(',
    'right',
    'scroll',
    'top',
    'transparent',
    'url(',
    '!important',
    '#',
    ],
    'background-attachment': [
    'fixed',
    'inherit',
    'scroll',
    '!important',
    ],
    'background-color': [
    'inherit',
    'rgb(',
    'transparent',
    '!important',
    '#',
    ],
    'background-image': [
    'inherit',
    'none',
    'url(',
    '!important',
    ],
    'background-position': [
    'bottom',
    'center',
    'inherit',
    'left',
    'right',
    'top',
    '!important',
    ],
    'background-repeat': [
    'inherit',
    'no-repeat',
    'repeat',
    'repeat-x',
    'repeat-y',
    '!important',
    ],
    'border': [
    'dashed',
    'dotted',
    'double',
    'groove',
    'hidden',
    'inherit',
    'inset',
    'medium',
    'none',
    'outset',
    'rgb(',
    'ridge',
    'solid',
    'thick',
    'thin',
    '!important',
    '#',
    ],
    'border-bottom': [
    'dashed',
    'dotted',
    'double',
    'groove',
    'hidden',
    'inherit',
    'inset',
    'medium',
    'none',
    'outset',
    'rgb(',
    'ridge',
    'solid',
    'thick',
    'thin',
    '!important',
    '#',
    ],
    'border-bottom-width': [
    'inherit',
    'medium',
    'thick',
    'thin',
    '!important',
],
    'border-color': [
            'inherit',
            'rgb(',
            'transparent',
            '!important',
            '#',
        ],
    'border-left': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'medium',
            'none',
            'outset',
            'rgb(',
            'ridge',
            'solid',
            'thick',
            'thin',
            '!important',
            '#',
        ],
    'border-left-color': [
            'inherit',
            'rgb(',
            '!important',
            '#',
        ],
    'border-left-style': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'none',
            'outset',
            'ridge',
            'solid',
            '!important',
        ],
    'border-left-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'border-right': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'medium',
            'none',
            'outset',
            'rgb(',
            'ridge',
            'solid',
            'thick',
            'thin',
            '!important',
            '#',
        ],
    'border-right-color': [
            'inherit',
            'rgb(',
            '!important',
            '#',
        ],
    'border-right-style': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'none',
            'outset',
            'ridge',
            'solid',
            '!important',
        ],
    'border-right-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'border-spacing': [
            'inherit',
            '!important',
        ],
    'border-style': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'none',
            'outset',
            'ridge',
            'solid',
            '!important',
        ],
    'border-top': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'medium',
            'none',
            'outset',
            'rgb(',
            'ridge',
            'solid',
            'thick',
            'thin',
            '!important',
            '#',
        ],
    'border-top-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'border-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'clear': [
            'both',
            'inherit',
            'left',
            'none',
            'right',
            '!important',
        ],
    'color': [
            'inherit',
            'rgb(',
            '!important',
            '#',
        ],
    'display': [
            'block',
            'compact',
            'inherit',
            'inline',
            'inline-block',
            'inline-table',
            'list-item',
            'marker',
            'none',
            'run-in',
            'table',
            'table-caption',
            'table-cell',
            'table-column',
            'table-column-group',
            'table-footer-group',
            'table-header-group',
            'table-row',
            'table-row-group',
            '!important',
        ],
    'float': [
            'inherit',
            'left',
            'none',
            'right',
            '!important',
        ],
    'font': [
            '100',
            '200',
            '300',
            '400',
            '500',
            '600',
            '700',
            '800',
            '900',
            'bold',
            'bolder',
            'caption',
            'cursive',
            'fantasy',
            'icon',
            'inherit',
            'italic',
            'large',
            'larger',
            'lighter',
            'medium',
            'menu',
            'message-box',
            'monospace',
            'normal',
            'oblique',
            'sans-serif',
            'serif',
            'small',
            'smaller',
            'small-caps',
            'small-caption',
            'status-bar',
            'xx-large',
            'xx-small',
            'x-large',
            'x-small',
            '!important',
        ],
    'font-family': [
            'cursive',
            'fantasy',
            'inherit',
            'monospace',
            'sans-serif',
            'serif',
            '!important',
        ],
    'font-size': [
            'inherit',
            'large',
            'larger',
            'medium',
            'small',
            'smaller',
            'xx-large',
            'xx-small',
            'x-large',
            'x-small',
            '!important',
        ],
    'font-size-adjust': [
            'inherit',
            'none',
            '!important',
        ],
    'font-stretch': [
            'condensed',
            'expanded',
            'extra-condensed',
            'extra-expanded',
            'inherit',
            'narrower',
            'normal',
            'semi-condensed',
            'semi-expanded',
            'ultra-condensed',
            'ultra-expanded',
            'wider',
            '!important',
        ],
    'font-style': [
            'inherit',
            'italic',
            'normal',
            'oblique',
            '!important',
        ],
    'font-variant': [
            'inherit',
            'normal',
            'small-caps',
            '!important',
        ],
    'font-weight': [
            '100',
            '200',
            '300',
            '400',
            '500',
            '600',
            '700',
            '800',
            '900',
            'bold',
            'bolder',
            'inherit',
            'lighter',
            'normal',
            '!important',
        ],
    'height': [
            'auto',
            'inherit',
            '!important',
        ],
    'letter-spacing': [
            'inherit',
            'normal',
            '!important',
        ],
    'line-height': [
            'inherit',
            'normal',
            '!important',
        ],
    'list-style': [
            'armenian',
            'circle',
            'cjk-ideographic',
            'decimal',
            'decimal-leading-zero',
            'disc',
            'georgian',
            'hebrew',
            'hiragana',
            'hiragana-iroha',
            'inherit',
            'inside',
            'katakana',
            'katakana-iroha',
            'lower-alpha',
            'lower-greek',
            'lower-latin',
            'lower-roman',
            'none',
            'outside',
            'square',
            'upper-alpha',
            'upper-latin',
            'upper-roman',
            'url(',
            '!important',
        ],
    'list-style-image': [
            'inherit',
            'none',
            'url(',
            '!important',
        ],
    'list-style-position': [
            'inherit',
            'inside',
            'outside',
            '!important',
        ],
    'list-style-type': [
            'armenian',
            'circle',
            'cjk-ideographic',
            'decimal',
            'decimal-leading-zero',
            'disc',
            'georgian',
            'hebrew',
            'hiragana',
            'hiragana-iroha',
            'inherit',
            'katakana',
            'katakana-iroha',
            'lower-alpha',
            'lower-greek',
            'lower-latin',
            'lower-roman',
            'none',
            'square',
            'upper-alpha',
            'upper-latin',
            'upper-roman',
            '!important',
        ],
    'margin': [
            'auto',
            'inherit',
            '!important',
        ],
    'margin-bottom': [
            'auto',
            'inherit',
            '!important',
        ],
    'margin-left': [
            'auto',
            'inherit',
            '!important',
        ],
    'margin-right': [
            'auto',
            'inherit',
            '!important',
        ],
    'margin-top': [
            'auto',
            'inherit',
            '!important',
        ],
    'padding': [
            'inherit',
            '!important',
        ],
    'padding-bottom': [
            'inherit',
            '!important',
        ],
    'padding-left': [
            'inherit',
            '!important',
        ],
    'padding-right': [
            'inherit',
            '!important',
        ],
    'padding-top': [
            'inherit',
            '!important',
        ],
    'text-align': [
            'center',
            'inherit',
            'justify',
            'left',
            'right',
            '!important',
        ],
    'text-decoration': [
            'blink',
            'inherit',
            'line-through',
            'none',
            'overline',
            'underline',
            '!important',
        ],
    'text-indent': [
            'inherit',
            '!important',
        ],
    'text-transform': [
            'capitalize',
            'inherit',
            'lowercase',
            'none',
            'uppercase',
            '!important',
        ],
    'vertical-align': [
            'baseline',
            'bottom',
            'inherit',
            'middle',
            'sub',
            'super',
            'text-bottom',
            'text-top',
            'top',
            '!important',
        ],
    'white-space': [
            'inherit',
            'normal',
            'nowrap',
            'pre',
            'pre-wrap',
            'pre-line',
            '!important',
        ],
    'width': [
            'auto',
            'inherit',
            '!important',
        ],
    'word-spacing': [
            'inherit',
            'normal',
            '!important',
        ],
}

CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT = {
    'background'            : """Shorthand for setting the individual background properties""",
    'background-attachment' : """If background image is specified, this specifies whether it is fixed with regard to the viewport ('fixed') or scrolls along with the document ('scroll').""",
    'background-color'      : """Sets the background color of an element, either a <color> value or the keyword 'transparent', to make the underlying colors shine through""",
    'background-image'      : """Sets the background image of an element. When setting a background image, authors should also specify a background color that will be used when the image is unavailable. When the image is available, it is rendered on top of the background color""",
    'background-position'   : """If a background image has been specified, this property specifies its initial position""",
    'background-repeat'     : """If a background image is specified, this property specifies whether the image is repeated (tiled), and how""",
    'border'                : """Shorthand for border-width, border-style and border-color affecting all 4 borders""",
    'border-bottom'         : """Shorthand for border-width, border-style and border-color affecting the bottom border""",
    'border-bottom-width'   : """Sets the width of the bottom border of a box""",
    'border-color'          : """Sets the color of the four borders""",
    'border-left'           : """Shorthand for border-width, border-style and border-color affecting the left border""",
    'border-left-width'     : """Sets the width of the left border of a box""",
    'border-right'          : """Shorthand for border-width, border-style and border-color affecting the right border""",
    'border-right-width'    : """Sets the width of the right border of a box""",
    'border-style'          : """Specifies the line style of a box's four borders (solid, double, dashed, hidden, etc.)""",
    'border-top'            : """Shorthand for border-width, border-style and border-color affecting the top border""",
    'border-top-width'      : """Sets the width of the top border of a box""",
    'border-width'          : """Shorthand for setting 'border-top-width', 'border-right-width', 'border-bottom-width', and 'border-left-width' at the same place in the style sheet. If there is only one value, it applies to all sides. If there are two values, the top and bottom borders are set to the first value and the right and left are set to the second. If there are three values, the top is set to the first value, the left and right are set to the second, and the bottom is set to the third. If there are four values, they apply to the top, right, bottom, and left, respectively.""",
    'clear'                 : """Indicates which sides of an element's box(es) may not be adjacent to an earlier floating box""",
    'color'                 : """This property describes the foreground color of an element's text content""",
    'display'               : """How the element is to be displayed, denotes the box type format""",
    'float'                 : """Specifies whether a box should float to the left, right, or not at all""",
    'font'                  : """Shorthand for setting 'font-style', 'font-variant', 'font-weight', 'font-size', 'line-height', and 'font-family', at the same place in the style sheet""",
    'font-family'           : """Specifies a prioritized list of font family names and/or generic family names""",
    'font-size'             : """Describes the size of the font when set solid""",
    'font-size-adjust'      : """Specifies an aspect value for an element that will preserve the x-height of the first choice font in the substitute font""",
    'font-stretch'          : """Selects a normal, condensed, or extended face from a font family""",
    'font-style'            : """Sets normal (sometimes referred to as "roman" or "upright"), italic, and oblique faces within a font family""",
    'font-variant'          : """Can be used to select font casing 'normal' or 'small-caps'""",
    'font-weight'           : """Specifies the weight of the font""",
    'height'                : """Specifies the content height of boxes generated by block-level and replaced elements""",
    'letter-spacing'        : """Specifies spacing behavior between text characters""",
    'line-height'           : """Specifies the minimal height of each generated inline box""",
    'list-style'            : """Shorthand notation for setting the three properties 'list-style-type', 'list-style-image', and 'list-style-position' at the same place in the style sheet""",
    'list-style-image'      : """Sets the image that will be used as the list item marker""",
    'list-style-position'   : """Specifies the position of the marker box in the principal block box""",
    'list-style-type'       : """Specifies appearance of the list item marker if 'list-style-image' has the value 'none' or if the image pointed to by the URI cannot be displayed""",
    'margin'                : """Shorthand for setting 'margin-top', 'margin-right', 'margin-bottom', and 'margin-left' at the same place in the style sheet""",
    'margin-bottom'         : """Specifies the width of the bottom margin area of a box""",
    'margin-left'           : """Specifies the width of the left margin area of a box""",
    'margin-right'          : """Specifies the width of the right margin area of a box""",
    'margin-top'            : """Specifies the width of the top margin area of a box""",
    'padding'               : """Shorthand for setting 'padding-top', 'padding-right', 'padding-bottom', and 'padding-left' at the same place in the style sheet""",
    'padding-bottom'        : """Sets the bottom width of the containing box""",
    'padding-left'          : """Sets the left width of the containing box""",
    'padding-right'         : """Sets the right width of the containing box""",
    'padding-top'           : """Sets the top width of the containing box""",
    'table-layout'          : """Specifies the algorithm used to lay out the table cells, rows, and columns""",
    'text-align'            : """Specifies how inline content of a block is aligned""",
    'text-decoration'       : """Specifies decorations that are added to the text of an element""",
    'text-indent'           : """Specifies the indentation of the first line of text in a block""",
    'text-transform'        : """Specifies capitalization effects of an element's text""",
    'uri'                   : """An internet reference string.""",
    'vertical-align'        : """Affects the vertical positioning inside a line box of the boxes generated by an inline-level element""",
    'white-space'           : """Specifies how whitespace inside the element is handled""",
    'width'                 : """Specifies the content width of boxes generated by block-level and replaced elements""",
    'word-spacing'          : """Specifies spacing behavior between words""",
}
for property, calltip in CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT.items():
    CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT[
        property] = "\n".join(textwrap.wrap(calltip, 40))

########NEW FILE########
__FILENAME__ = constants_css2
"""
CSS 3 definitions - requires CSS 1 module.
"""

import textwrap

from codeintel2.constants_css1 import CSS_ATTR_DICT as CSS1_ATTR_DICT
from codeintel2.constants_css1 import CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT as CSS1_PROPERTY_ATTRIBUTE_CALLTIPS_DICT

CSS_PSEUDO_CLASS_NAMES = """first-letter first-line link active visited
        first-child focus hover lang before after left right first""".split()

CSS2_SPECIFIC_ATTRS_DICT = {
    'azimuth': [
        'behind',
        'center',
        'center-left',
        'center-right',
        'far-left',
        'far-right',
        'inherit',
        'left',
        'leftwards',
        'left-side',
        'right',
        'rightwards',
        'right-side',
        '!important',
    ],
    'border-bottom-color': [
    'inherit',
    'rgb(',
    '!important',
    '#',
    ],
    'border-bottom-style': [
    'dashed',
    'dotted',
    'double',
    'groove',
    'hidden',
    'inherit',
    'inset',
    'none',
    'outset',
    'ridge',
    'solid',
    '!important',
    ],
    'border-collapse': [
    'collapse',
    'inherit',
    'separate',
    '!important',
    ],
    'border-top-color': [
    'inherit',
    'rgb(',
    '!important',
    '#',
    ],
    'border-top-style': [
    'dashed',
    'dotted',
    'double',
    'groove',
    'hidden',
    'inherit',
    'inset',
    'none',
    'outset',
    'ridge',
    'solid',
    '!important',
    ],
    'bottom': [
    'auto',
    'inherit',
    '!important',
    ],
    'caption-side': [
    'bottom',
    'inherit',
    'left',
    'right',
    'top',
    '!important',
    ],
    'clip': [
    'auto',
    'inherit',
    'rect(',
    '!important',
    ],
    'content': [
    'close-quote',
    'counter(',
    'inherit',
    'no-close-quote',
    'no-open-quote',
    'open-quote',
    'url(',
    '!important',
    ],
    'counter-increment': [
    'inherit',
    'none',
    '!important',
    ],
    'counter-reset': [
    'inherit',
    'none',
    '!important',
    ],
    'cue': [
    'inherit',
    'none',
    'url(',
    '!important',
    ],
    'cue-after': [
    'inherit',
    'none',
    'url(',
    '!important',
    ],
    'cue-before': [
    'inherit',
    'none',
    'url(',
            '!important',
        ],
    'cursor': [
            'auto',
            'crosshair',
            'default',
            'e-resize',
            'help',
            'inherit',
            'move',
            'ne-resize',
            'nw-resize',
            'n-resize',
            'pointer',
            'se-resize',
            'sw-resize',
            's-resize',
            'text',
            'url(',
            'wait',
            'w-resize',
            '!important',
        ],
    'direction': [
            'inherit',
            'ltr',
            'rtl',
            '!important',
        ],
    'elevation': [
            'above',
            'below',
            'higher',
            'inherit',
            'level',
            'lower',
            '!important',
        ],
    'empty-cells': [
            'hide',
            'inherit',
            'show',
            '!important',
        ],
    'left': [
            'auto',
            'inherit',
            '!important',
        ],
    'marker-offset': [
            'auto',
            'inherit',
            '!important',
        ],
    'marks': [
            'crop',
            'cross',
            'inherit',
            'none',
            '!important',
        ],
    'max-height': [
            'inherit',
            'none',
            '!important',
        ],
    'max-width': [
            'inherit',
            'none',
            '!important',
        ],
    'min-height': [
            'inherit',
            '!important',
        ],
    'min-width': [
            'inherit',
            '!important',
        ],
    'orphans': [
            'inherit',
            '!important',
        ],
    'outline': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'invert',
            'medium',
            'none',
            'outset',
            'rgb(',
            'ridge',
            'solid',
            'thick',
            'thin',
            '!important',
            '#',
        ],
    'outline-color': [
            'inherit',
            'invert',
            'rgb(',
            '!important',
            '#',
        ],
    'outline-style': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'none',
            'outset',
            'ridge',
            'solid',
            '!important',
        ],
    'outline-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'overflow': [
            'auto',
            'hidden',
            'inherit',
            'scroll',
            'visible',
            '!important',
        ],
    'page': [
            'auto',
        ],
    'page-break-after': [
            'always',
            'auto',
            'avoid',
            'inherit',
            'left',
            'right',
            '!important',
        ],
    'page-break-before': [
            'always',
            'auto',
            'avoid',
            'inherit',
            'left',
            'right',
            '!important',
        ],
    'page-break-inside': [
            'auto',
            'avoid',
            'inherit',
            '!important',
        ],
    'pause': [
            'inherit',
            'ms',
            's',
            '!important',
        ],
    'pause-after': [
            'inherit',
            'ms',
            's',
            '!important',
        ],
    'pause-before': [
            'inherit',
            'ms',
            's',
            '!important',
        ],
    'pitch': [
            'high',
            'Hz',
            'inherit',
            'kHz',
            'low',
            'medium',
            'x-high',
            'x-low',
            '!important',
        ],
    'pitch-range': [
            'inherit',
            '!important',
        ],
    'play-during': [
            'auto',
            'inherit',
            'none',
            'url(',
            '!important',
        ],
    'position': [
            'absolute',
            'fixed',
            'inherit',
            'relative',
            'static',
            '!important',
        ],
    'quotes': [
            'inherit',
            'none',
            '!important',
        ],
    'richness': [
            'inherit',
            '!important',
        ],
    'right': [
            'auto',
            'inherit',
            '!important',
        ],
    'size': [
            'auto',
            'inherit',
            'landscape',
            'portrait',
            '!important',
        ],
    'speak': [
            'inherit',
            'none',
            'normal',
            'spell-out',
            '!important',
        ],
    'speak-header': [
            'always',
            'inherit',
            'once',
            '!important',
        ],
    'speak-numeral': [
            'continuous',
            'digits',
            'inherit',
            '!important',
        ],
    'speak-punctuation': [
            'code',
            'inherit',
            'none',
            '!important',
        ],
    'speech-rate': [
            'fast',
            'faster',
            'inherit',
            'medium',
            'slow',
            'slower',
            'x-fast',
            'x-slow',
            '!important',
        ],
    'stress': [
            'inherit',
            '!important',
        ],
    'table-layout': [
            'auto',
            'fixed',
            'inherit',
            '!important',
        ],
    'text-shadow': [
            'inherit',
            'none',
            'rgb(',
            '!important',
            '#',
        ],
    'top': [
            'auto',
            'inherit',
            '!important',
        ],
    'unicode-bidi': [
            'bidi-override',
            'embed',
            'inherit',
            'normal',
            '!important',
        ],
    'visibility': [
            'collapse',
            'hidden',
            'inherit',
            'visible',
            '!important',
        ],
    'voice-family': [
            'child',
            'female',
            'inherit',
            'male',
            '!important',
        ],
    'volume': [
            'inherit',
            'loud',
            'medium',
            'silent',
            'soft',
            'x-loud',
            'x-soft',
            '!important',
        ],
    'widows': [
            'inherit',
            '!important',
        ],
    'z-index': [
            'auto',
            'inherit',
            '!important',
        ],
}

CSS2_SPECIFIC_CALLTIP_DICT = {
    'azimuth'               : """Audio: Spatial audio property for aural presentation""",
    'border-bottom-color'   : """Sets the color of the bottom border""",
    'border-bottom-style'   : """Specifies the line style of a box's bottom border (solid, double, dashed, hidden, etc.)""",
    'border-collapse'       : """This property selects a table's border model.""",
    'border-left-color'     : """Sets the color of the left border""",
    'border-left-style'     : """Specifies the line style of a box's left border (solid, double, dashed, hidden, etc.)""",
    'border-right-color'    : """Sets the color of the right border""",
    'border-right-style'    : """Specifies the line style of a box's right border (solid, double, dashed, hidden, etc.)""",
    'border-spacing'        : """The lengths specify the distance that separates adjacent cell borders. If one length is specified, it gives both the horizontal and vertical spacing. If two are specified, the first gives the horizontal spacing and the second the vertical spacing. Lengths may not be negative.""",
    'border-top-color'      : """Sets the color of the top border""",
    'border-top-style'      : """Specifies the line style of a box's top border (solid, double, dashed, hidden, etc.)""",
    'bottom'                : """Specifies how far a box's bottom content edge is offset above the bottom of the box's containing block""",
    'caption-side'          : """Specifies the position of the caption box with respect to the table box""",
    'clip'                  : """A clipping region defines what portion of an element's rendered content is visible""",
    'content'               : """This property is used with the :before and :after pseudo-elements to generate content in a document""",
    'counter-increment'     : """Indicates by how much the counter is incremented for every occurrence of the element. The default increment is 1. Zero and negative integers are allowed.""",
    'counter-reset'         : """Specifies the value that the counter is set to on each occurrence of the element""",
    'cue'                   : """Audio: Shorthand for setting 'cue-before' and 'cue-after'. If two values are given, the first value is 'cue-before' and the second is 'cue-after'. If only one value is given, it applies to both properties.""",
    'cue-after'             : """Audio: Sound to be played after the element to delimit it""",
    'cue-before'            : """Audio: Sound to be played before the element to delimit it""",
    'cursor'                : """Specifies the type of cursor to be displayed for the pointing device""",
    'direction'             : """Specifies the base writing direction of blocks and the direction of embeddings and overrides (see 'unicode-bidi') for the Unicode bidirectional algorithm.""",
    'elevation'             : """Audio: Spatial elevation direction for aural presentation.""",
    'empty-cells'           : """Controls the rendering of borders around cells that have no visible content""",
    'left'                  : """This property specifies how far a box's left content edge is offset to the right of the left edge of the box's containing block""",
    'marker-offset'         : """Specifies the distance between the nearest border edges of a marker box and its associated principal box""",
    'marks'                 : """Specifies whether cross marks or crop marks or both should be rendered just outside the page box edge. Crop marks indicate where the page should be cut. Cross marks (also known as register marks or registration marks) are used to align sheets""",
    'max-height'            : """Maximum height of the containing box""",
    'max-width'             : """Maximum width of the containing box""",
    'min-height'            : """Minimum height of the containing box""",
    'min-width'             : """Minimum width of the containing box""",
    'orphans'               : """Specifies the minimum number of lines of a paragraph that must be left at the bottom of a page""",
    'outline'               : """Shorthand for setting 'outline-style', 'outline-width', and 'outline-color' at the same place in the style sheet""",
    'outline-color'         : """Outline color around visual object""",
    'outline-style'         : """Specifies the line style of the outline (solid, double, dashed, etc.)""",
    'outline-width'         : """Specifies the width of the outline around the element""",
    'overflow'              : """Specifies whether the content of a block-level element is clipped when it overflows the element's box (which is acting as a containing block for the content)""",
    'page'                  : """Specifies a particular type of page where an element should be displayed""",
    'page-break-after'      : """Indicate the user agent should break the page after here""",
    'page-break-before'     : """Indicate the user agent should break the page before here""",
    'page-break-inside'     : """Indicate the user agent should break the page within here""",
    'pause'                 : """Audio: Shorthand for setting 'pause-before' and 'pause-after'. If two values are given, the first value is 'pause-before' and the second is 'pause-after'. If only one value is given, it applies to both properties""",
    'pause-after'           : """Audio: Specifies a pause to be observed after speaking an element's content""",
    'pause-before'          : """Audio: Specifies a pause to be observed before speaking an element's content""",
    'pitch'                 : """Audio: Specifies the average pitch (a frequency) of the speaking voice""",
    'pitch-range'           : """Audio: Specifies variation in average pitch""",
    'play-during'           : """Audio: Similar to the 'cue-before' and 'cue-after' properties, this property specifies a sound to be played as a background while an element's content is spoken""",
    'position'              : """Specifies which of the CSS2 positioning algorithms is used to calculate the position of a box""",
    'quotes'                : """Specifies quotation marks for any number of embedded quotations""",
    'richness'              : """Audio: Specifies the richness, or brightness, of the speaking voice. A rich voice will "carry" in a large room, a smooth voice will not""",
    'right'                 : """This property specifies how far a box's right content edge is offset to the left of the right edge of the box's containing block""",
    'size'                  : """Specifies the size and orientation of a page box""",
    'speak'                 : """Audio: Specifies whether text will be rendered aurally and if so, in what manner""",
    'speak-header'          : """Audio: Specifies whether table headers are spoken before every cell, or only before a cell when that cell is associated with a different header than the previous cell""",
    'speak-numeral'         : """Audio: Controls how numerals are spoken""",
    'speak-punctuation'     : """Audio: Specifies how punctuation is spoken""",
    'speech-rate'           : """Audio: Specifies the speaking rate. Note that both absolute and relative keyword values are allowed""",
    'stress'                : """Audio: Specifies the height of "local peaks" in the intonation contour of a voice""",
    'text-shadow'           : """A comma-separated list of shadow effects to be applied to the text of the element""",
    'top'                   : """This property specifies how far a box's top content edge is offset below the top edge of the box's containing block""",
    'unicode-bidi'          : """Specifies the level of embedding with respect to the bidirectional algorithm""",
    'visibility'            : """Specifies whether the boxes generated by an element are rendered. Invisible boxes still affect layout (set the 'display' property to 'none' to suppress box generation altogether)""",
    'voice-family'          : """Audio: Value is a comma-separated, prioritized list of voice family names""",
    'volume'                : """Audio: Refers to the median volume of the audio""",
    'widows'                : """Specifies the minimum number of lines of a paragraph that must be left at the top of a page""",
    'z-index'               : """For a positioned box, specifies the stack level of the box in the current stacking context and also whether the box establishes a local stacking context.""",
}


# Everything that was in CSS1 is also in CSS2.
CSS_ATTR_DICT = CSS1_ATTR_DICT.copy()
CSS_ATTR_DICT.update(CSS2_SPECIFIC_ATTRS_DICT)
CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT = CSS1_PROPERTY_ATTRIBUTE_CALLTIPS_DICT.copy(
    )
CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT.update(CSS2_SPECIFIC_CALLTIP_DICT)

for property, calltip in CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT.items():
    if property not in CSS2_SPECIFIC_CALLTIP_DICT:
        calltip += " (CSS1, CSS2)"
    else:
        calltip += " (CSS2)"
    CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT[
        property] = "\n".join(textwrap.wrap(calltip, 40))


# Note: The System Colors below are not used yet.
css2_system_colors = {
    'ActiveBorder'           : """Active window border""",
    'ActiveCaption'          : """Active window caption""",
    'AppWorkspace'           : """Background color of multiple document interface""",
    'Background'             : """Desktop background""",
    'ButtonFace'             : """Face color for three-dimensional display elements""",
    'ButtonHighlight'        : """Dark shadow for three-dimensional display elements (for edges facing away from the light source)""",
    'ButtonShadow'           : """Shadow color for three-dimensional display elements""",
    'ButtonText'             : """Text on push buttons""",
    'CaptionText'            : """Text in caption, size box, and scrollbar arrow box""",
    'GrayText'               : """Grayed (disabled) text. This color is set to #000 if the current display driver does not support a solid gray color""",
    'Highlight'              : """Item(s) selected in a control""",
    'HighlightText'          : """Text of item(s) selected in a control""",
    'InactiveBorder'         : """Inactive window border""",
    'InactiveCaption'        : """Inactive window caption""",
    'InactiveCaptionText'    : """Color of text in an inactive caption""",
    'InfoBackground'         : """Background color for tooltip controls""",
    'InfoText'               : """Text color for tooltip controls""",
    'Menu'                   : """Menu background""",
    'MenuText'               : """Text in menus""",
    'Scrollbar'              : """Scroll bar gray area""",
    'ThreeDDarkShadow'       : """Dark shadow for three-dimensional display elements""",
    'ThreeDFace'             : """Face color for three-dimensional display elements""",
    'ThreeDHighlight'        : """Highlight color for three-dimensional display elements""",
    'ThreeDLightShadow'      : """Light color for three-dimensional display elements (for edges facing the light source)""",
    'ThreeDShadow'           : """Dark shadow for three-dimensional display elements""",
    'Window'                 : """Window background""",
    'WindowFrame'            : """Window frame""",
    'WindowText'             : """Text in windows""",
}

# Add the css2 system colors.
# from codeintel2.util import CompareNPunctLast
# for attr, values in CSS_ATTR_DICT.items():
#    if '#' in values or 'rbg(' in values:
#        CSS_ATTR_DICT[attr] = sorted(values + css2_system_colors.keys(),
#                                     cmp=CompareNPunctLast)

########NEW FILE########
__FILENAME__ = constants_css3
"""
CSS 3 definitions - requires CSS 1 and CSS 2 modules.
"""

import textwrap

from codeintel2.constants_css1 import CSS_ATTR_DICT as CSS1_SPECIFIC_ATTRS_DICT
from codeintel2.constants_css1 import CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT as CSS1_SPECIFIC_CALLTIP_DICT
from codeintel2.constants_css2 import CSS2_SPECIFIC_ATTRS_DICT, CSS2_SPECIFIC_CALLTIP_DICT

CSS_PSEUDO_CLASS_NAMES = """
    root
    nth-child(
    nth-last-child(
    nth-of-type(
    nth-last-of-type(
    first-child
    last-child
    first-of-type
    last-of-type
    only-child
    only-of-type
    empty
    link
    visited
    active
    hover
    focus
    target
    lang(
    enabled
    disabled
    checked
    first-line
    first-letter
    before
    after
    not(
""".split()


### START: Auto generated
CSS3_DATA = {

    'alignment-adjust':
    {'description': "The 'alignment-adjust' property allows more\nprecise alignment of elements, such as graphics, that do not have a\nbaseline-table or lack the desired baseline in their baseline-table. With the 'alignment-adjust' property, the position\nof the baseline identified by the 'alignment-baseline' can be explicitly\ndetermined. It also determines precisely the alignment point for each glyph\nwithin a textual element. The user agent should use heuristics to determine\nthe position of a non existing baseline for a given element. Values for the property have the following meaning: 4.7. Repositioning\nthe dominant baseline: the 'baseline-shift' property Name: baseline-shift Value: baseline | sub | super | <percentage> | <length> Initial: baseline Applies to: inline-level elements Inherited: no Percentages: refers to the 'line-height' of the parent element Media: visual Computed value: see text",
        'values': {'<length>': "The alignment-point is on the start-edge of the inline box. Its position\nalong the start-edge relative to the intersection of the dominant-baseline\nand the start-edge is offset by the <length> value. The offset is\nopposite to the shift-direction (positive value) or in the shift-direction\n(negative value). A value of '0cm' makes the dominant-baseline the alignment\npoint.",
                   '<percentage>': "The computed value of the property is this percentage multiplied by the\ncomputed 'line-height' of the element. The alignment point is on the\nstart-edge of the inline box. Its position along the start-edge relative to\nthe intersection of the dominant-baseline and the start-edge is offset by the\ncomputed value. The offset is opposite to the shift-direction (positive\nvalue) or in the shift-direction (negative value). A value of '0%' makes the\ndominant-baseline the alignment point.",
                   'after-edge': 'The alignment point is at the intersection of the start-edge of the\nelement and the after-edge of the extended inline box of the element. This may include or not the line-height of the element, depending on the line-stacking-strategy.',
                   'alphabetic': "The alignment point is at the intersection of the start-edge of the\nelement and the 'alphabetic' baseline of the element.",
                   'auto': "For each glyph corresponding to textual information within the element,\nthe alignment-point is the intersection of the start-edge of the glyph box\nand the block-progression-direction position of the alignment point from the\nfont. Padding, border or margin do not affect that alignment point. The\nalignment point of the inline-level element itself is at the intersection of\nthe start-edge of the first inline box and the baseline identified by the 'alignment-baseline' property if this\nbaseline exists in the baseline-table for the element dominant-baseline. If\nthat specific baseline does not exist, the user agent may use heuristics to\ndetermine where that missing baseline would be. For other inline box content\nlike images, the user agent will use heuristics to determine the position of\nthe alignment point. For example when the resulting baseline is 'alphabetic'\nor 'ideographic', it is expected that the alignment point will be at the\nintersection of the start-edge and the after-edge of the inline box,\nincluding its respective margin. If the resulting baseline is 'hanging', the\nintersection of the start-edge and the before-edge of the inline box,\nincluding its respective margin should be used instead.",
                   'baseline': 'The alignment point is at the intersection of the start-edge of the\nelement and the dominant-baseline of the element.',
                   'before-edge': 'The alignment point is at the intersection of the start-edge of the\nelement and the before-edge of the extended inline box of the element. This may include or not the line-height of the element, depending on the line-stacking-strategy.',
                   'central': "The alignment point is at the intersection of the start-edge of the\nelement and the 'central' baseline of the element.",
                   'hanging': "The alignment point is at the intersection of the start-edge of the\nelement and the 'hanging' baseline of the element.",
                   'ideographic': "The alignment point is at the intersection of the start-edge of the\nelement and the 'ideographic' baseline of the element.",
                   'mathematical': "The alignment point is at the intersection of the start-edge of the\nelement and the 'mathematical' baseline of the element.",
                   'middle': "The alignment point is at the intersection of the start-edge of the\nelement and the 'middle' baseline of the element.",
                   'text-after-edge': "The alignment point is at the intersection of the start-edge of the\nelement and the 'text-after-edge' baseline of the\nelement.",
                   'text-before-edge': "The alignment point is at the intersection of the start-edge of the\nelement and the 'text-before-edge' baseline of the\nelement."}},

    'alignment-baseline':
{'description': "This property specifies how an inline-level element is aligned with\nrespect to its parent. That is, to which of the parent's baselines the\nalignment point of this element is aligned. Unlike the 'dominant-baseline'\nproperty the 'alignment-baseline' property has no effect on its children\ndominant-baselines. Note: The 'alignment-adjust' property specifies how\nthe alignment point is determined and defaults to the baseline with the same\nname as the computed value of the alignment-baseline property. Except for 'use-script', all baseline values refer to the respective\nbaseline-identifier components of the dominant-baseline of the parent, and\nglyphs within the element are aligned similarly to the element itself. The\ndescription for 'use-script' covers these points specifically. The property\nvalues have the following meanings:",
 'values': {'after-edge': "The alignment point of the box is aligned with the 'after-edge' baseline\nof the line box.",
                          'alphabetic': 'The alignment-point of the element being aligned is aligned with the\nlower baseline of the parent.',
                          'baseline': 'The alignment-point of the element being aligned is aligned with the\ndominant baseline of the parent.',
                          'before-edge': "The alignment point of the box is aligned with the 'before-edge' baseline\nof the line box.",
                          'central': "The alignment point of the box is aligned with the 'central' baseline of\nthe parent.",
                          'hanging': 'The alignment-point of the element being aligned is aligned with the\nhanging baseline of the parent.',
                          'ideographic': "The alignment-point of the element being aligned is aligned with the\n'ideographic' baseline of the parent.",
                          'mathematical': 'The alignment-point of the element being aligned is aligned with the\nmathematical baseline of the parent.',
                          'middle': "The alignment point of the box is aligned with the 'middle' baseline of\nthe parent.",
                          'text-after-edge': "The alignment-point of the element being aligned is aligned with the 'text-after-edge' baseline of the parent.",
                          'text-before-edge': "The alignment-point of the element being aligned is aligned with the 'text-before-edge' baseline of the parent.",
                          'use-script': "If the element 'script' property value is 'auto', the alignment\npoint of each glyph is aligned with the baseline-identifier of the script to\nwhich the glyph belongs. If the element 'script' property value is other than 'auto', the\nalignment point of each glyph is aligned with the baseline-identifier\nspecified by the 'script' property. The baseline-identifier position is determined by using the\nrelevant information related to the parent element dominant-baseline set. The\nalignment point of the element itself is aligned as for the 'baseline' value."}},

    'animation':
{'description': "The 'animation' shorthand property combines six of the animation properties into a single property. Name: animation Value: [<animation-name> || <animation-duration> || <animation-timing-function> || <animation-delay> || <animation-iteration-count> || <animation-direction>] [, [<animation-name> || <animation-duration> || <animation-timing-function> || <animation-delay> || <animation-iteration-count> || <animation-direction>] ]* Initial: see individual properties Applies to: block-level and inline-level elements Inherited: no Percentages: N/A Media: visual Computed value: Same as specified value. ======================================================================================================= 4 Animation Events",
 'values': {}},

    'animation-delay':
{'description': "The 'animation-delay' property defines when the animation will start. It allows an animation to begin execution some time after it is applied. An 'animation-delay' value of '0' means the animation will execute as soon as it is applied. Otherwise, the value specifies an offset from the moment the animation is applied, and the animation will delay execution by that offset. If the value for 'animation-delay' is a negative time offset then the animation will execute the moment it is applied, but will appear to have begun execution at the specified offset. That is, the animation will appear to begin part-way through its play cycle. In the case where an animation has implied starting values and a negative 'animation-delay', the starting values are taken from the moment the animation is applied. Name: animation-delay Value: <time> [, <time>]* Initial: 0 Applies to: block-level and inline-level elements Inherited: no Percentages: N/A Media: visual Computed value: Same as specified value. ======================================================================================================= 3.9 The 'animation' Shorthand Property",
 'values': {}},

    'animation-direction':
{'description': "The 'animation-direction' property defines whether or not the animation should play in reverse on alternate cycles. If 'alternate' is specified, the animation cycle iterations that are odd counts are played in the normal direction, and the animation cycle iterations that are even counts are played in a reverse direction. When an animation is played in reverse the timing functions are also reversed. For example, when played in reverse an ease-in animation would appear to be an ease-out animation. Name: animation-direction Value: normal | alternate [, normal | alternate]* Initial: normal Applies to: block-level and inline-level elements Inherited: no Percentages: N/A Media: visual Computed value: Same as specified value. ======================================================================================================= 3.7 The 'animation-play-state' Property We are considering removing 'animation-play-state' since its behaviour can be replicated using other techniques. For example, by querying the computed style, removing the animation and then setting style.",
 'values': {}},

    'animation-duration':
{'description': "The 'animation-duration' property defines the length of time that an animation takes to complete one cycle. Name: animation-duration Value: <time> [, <time>]* Initial: 0 Applies to: block-level and inline-level elements Inherited: no Percentages: N/A Media: visual Computed value: Same as specified value. By default the value is '0', meaning that the animation cycle is immediate (i.e. there will be no animation). A negative value for animation-duration is treated as '0'.",
 'values': {}},

    'animation-iteration-count':
{'description': "The 'animation-iteration-count' property defines the number of times an animation cycle is played. The default value is one, meaning the animation will play from beginning to end once. A value of 'infinite' will cause the animation to repeat forever. Non-integer numbers will cause the animation to end part-way through a cycle. Negative values for 'animation-iteration-count' are treated as zero. This property is often used with an 'animation-direction' value of 'alternate', which will cause the animation to play in reverse on alternate cycles. Name: animation-iteration-count Value: infinite | <number> [, infinite | <number>]* Initial: 1 Applies to: block-level and inline-level elements Inherited: no Percentages: N/A Media: visual Computed value: Same as specified value. ======================================================================================================= 3.6 The 'animation-direction' Property",
 'values': {}},

    'animation-name':
{'description': 'The \'animation-name\' property defines a list of animations that apply. Each name is used to select the keyframe at-rule that provides the property values for the animation. If the name does not match any keyframe at-rule, there are no properties to be animated and the animation will not execute. Furthermore, if the animation name is \'none\' then there will be no animation. This can be used to override any animations coming from the cascade. Name: animation-name Value: none | IDENT [, none | IDENT ]* Initial: none Applies to: block-level and inline-level elements Inherited: no Percentages: N/A Media: visual Computed value: Same as specified value. <p> It is possible for elements to have multiple animations running that change the same property or properties. In this case the animations combine in a manner defined by the property. For example, animations on <span class="prop-name">opacity</span> will add together and animations on <span class="prop-name">transform</span> will have their transformation matrices multiplied. </p> <div class="example"> <p style="display:none"> Example(s): </p> <pre> @keyframes \'border-bloat\' { from { border-width: 0; } to { border-width: 10px; } } @keyframes \'border-diet\' { from { border-width: 4px; } to { border-width: 2px; } } div { animation-name: \'border-bloat\', \'border-diet\'; animation-duration: 10s, 4s; } </pre> <p> The above example has two animations executing on the same property, <span class="prop-name">border-width</span>. The animations are additive. That is, the resulting value for the property will be the addition of the values from the two animations. </p> <p> At time \'<code class=css>0s</code>\' the element\'s border will be 4px wide (0px from \'<code class=property>border-bloat</code>\' plus 4px from \'<code class=property>border-diet</code>\'). At time \'<code class=css>4s</code>\' the element\'s border will be 6px wide (4px from \'<code class=property>border-bloat</code>\' plus 2px from \'<code class=property>border-diet</code>\'). At time \'<code class=css>10s</code>\' the element\'s border will be 10px wide (10px from \'<code class=property>border-bloat</code>\' and no addition from \'<code class=property>border-diet</code>\' as it is no longer executing). </p> </div> ======================================================================================================= 3.3 The \'animation-duration\' Property',
 'values': {}},

    'animation-play-state':
{'description': "The 'animation-play-state' property defines whether the animation is running or paused. A running animation can be paused by setting this property to 'paused'. To continue running a paused animation this property can be set to 'running'. A paused animation will continue to display the current value of the animation in a static state, as if the time of the animation is constant. When a paused animation is resumed, it restarts from the current value, not necessarily from the beginning of the animation. Name: animation-play-state Value: running | paused [, running | paused]* Initial: running Applies to: block-level and inline-level elements Inherited: no Percentages: N/A Media: visual Computed value: Same as specified value. ======================================================================================================= 3.8 The 'animation-delay' Property",
 'values': {}},

    'animation-timing-function':
{'description': "The 'animation-timing-function' property describes how the animation will progress over one cycle of its duration. See the 'transition-timing-function' property [CSS3-TRANSITIONS] {{!CSS3-TRANSITIONS}} for a complete description of timing function calculation. Name: animation-timing-function Value: ease | linear | ease-in | ease-out | ease-in-out | cubic-bezier(<number>, <number>, <number>, <number>) [, ease | linear | ease-in | ease-out | ease-in-out | cubic-bezier(<number>, <number>, <number>, <number>)]* Initial: ease Applies to: block-level and inline-level elements Inherited: no Percentages: N/A Media: visual Computed value: Same as specified value. For a keyframed animation, the 'animation-timing-function' applies between keyframes, not over the entire animation. For example, in the case of an ease-in-out timing function, an animation will ease in at the start of the keyframe and ease out at the end of the keyframe. A 'animation-timing-function' defined within a keyframe block applies to that keyframe, otherwise the timing function specified for the animation is used.",
 'values': {}},

    'appearance':
{'description': 'This document introduces the \'appearance\' property which can be used to\nmake an element look like a standard user interface element on the platform. Example(s): A few \'appearance\' values demonstrated using HTML4 \'appearance\' HTML4 demonstration normal hello button Search push-button hyperlink CSS home page radio-button Sticky checkbox Gift\nwrap pop-up-menu Honey Water White Extra White White Extra Light Amber Light Amber Amber Dark Amber list-menu Honey Water White Extra White White Extra Light Amber Light Amber Amber Dark Amber radio-group tea Earl\nGrey lemon ginger green tea jasmine tea checkbox-group pizza toppings fresh\nbasil fresh garlic fresh spinach green\npeppers mushrooms olives onions pineapple tomatoes field Note to self. password \'appearance\' property detailsExample(s):The \'appearance\' property is a shorthand for \'appearance \', \'color \', \'font \', and \'cursor \'. It sets \'appearance\' to the specified value and the\nother properties to their appropriate system value; \'normal\' resets \'appearance\'to\' normal \' and the others to \'inherit\'. The \'appearance\' property does not affect the\nspecified or computed values of any other properties. If \'appearance\' is not \'normal\', the UA must render the element as\nif it was the specified user interface (UI) control from the platform. The UA\nshould use the computed values of the \'background-*\', \'border-*\', \'padding-*\', \'outline-*\', and \'text-decoration\' properties when they do not have\ntheir initial values and the computed values of \'color\', \'font\', and \'cursor\' (whatever their values) to influence the\nrendering where possible. Any values from those properties that cannot be\nused to influence the rendering of the UI control must not affect the\nrendering at all. For example, the UA should not draw a second border\naround a UI control that already has a border. If \'background-color\'or\'background-image\' have non-initial values and the UA\nis using their values for influencing the rendering of the UI control, then\nthe UA must ensure that the \'color\' property is\nalso used to influence the rendering. Similarly if <span class="property">\'color\'</span> is used to influence the rendering, then <span class="property">\'background-color\'</span> must be used to influence the rendering, and the other <span class="property">\'background-*\'</span> properties should be used to influence the rendering as well. Other properties must not affect the handling of \'appearance\' and must\ninstead be applied according to normal CSS rules. In particular \'margin\', \'display\', \'float\', \'height\', \'width\', and \'line-height\', are not ignored and affect the\nelement as normal. This specification does not define the term "platform". For example, it could be the native graphical rendering\nengine of the operating system, or it could be a user-agent-specific skin. In\naddition, which of several toolkits to use could also be decided on an\nelement-by-element basis depending on the values of the \'background-color\', \'background-image\', \'border-*-style\', and \'outline-style\' properties, so that the\nauthor styles could be honored while still honoring \'appearance\' even though the UA is unable to\ninfluence the rendering of OS native UI controls. Note. The exact list of properties set\nby, influencing, and not affected by \'appearance\' given in the lists above may be\nadjusted based on UA implementor feedback. Appearance values take into account the user interface state (if any) of\nthe element; thus there is no need for separate values for enabled vs.\ndisabled checkboxes for example. Example(s): Influencing the color and\nbackground-color of a button This example demonstrates setting the color and background-color of an\nelement that is set to \' appearance:push-button \'. sample CSS: input[type=button] { appearance:push-button; /* expected from UA defaults */\n} input[type=button].custom { color: #393; background-color: #9cf; } sample (X)HTML fragment: <input type="button" value="Plain button" /> <input type="button" value="With color" class="custom" /> A graphical browser might render\nthese buttons as follows: First, a rounded button\nwith black text on a white background, with shades of gray being used near\nthe edges to give the impression of depth. Second, a similar rounded button but\nwith blue text on a light blue background, and with shades of blue used to\ngive the impression of depth. Your browser on your system: 5.3. System fontsExample(s):This example demonstrates setting the color and background-color of an\nelement that is set to \' appearance:push-button \'. First, a rounded button\nwith black text on a white background, with shades of gray being used near\nthe edges to give the impression of depth. Second, a similar rounded button but\nwith blue text on a light blue background, and with shades of blue used to\ngive the impression of depth.',
 'values': {}},

    'background-clip':
{'description': 'Determines the background painting area.',
 'values': {'border-box': "The background is painted within (clipped to) the border box.",
                          'content-box': "The background is painted within (clipped to) the content box.",
                          'padding-box': "The background is painted within (clipped to) the padding box."}},

    'background-origin':
{'description': "For elements rendered as a single box, specifies the background positioning area. For elements rendered as multiple boxes (e.g., inline boxes on several lines, boxes on several pages) specifies which boxes 'box-decoration-break' operates on to determine the background positioning area(s).",
 'values': {'content-box': "The position is relative to the content box."}},

    'background-size':
{'description': "Specifies the size of the background images. Where <bg-size> = [ <length> | <percentage> | auto ]{1,2} | cover | contain. Values have the following meanings: Here are some examples. The first example stretches the background image independently in both dimensions to completely cover the content area: div { background-image: url(plasma.png); background-repeat: no-repeat; background-size: 100% 100%; background-origin: content-box } The second example stretches the image so that exactly two copies fit horizontally. The aspect ratio is preserved: p { background-image: url(tubes.png); background-size: 50% auto; background-origin: border-box } This example forces the background image to be 15 by 15 pixels: para { background-size: 15px 15px; background-image: url(tile.png)} This example uses the image's intrinsic size. Note that this is the only possible behavior in CSS level 1 and 2. body { background-size: auto; /* default */ background-image: url(flower.png) } The following example rounds the height of the image to 25%, down from the specified value of 30%. At 30%, three images would fit entirely and a fourth only partially. After rounding, four images fit. The width of the image is 20% of the background area width and is not rounded. p { background-image: url(chain.png); background-repeat: no-repeat round; background-size: 20% 30% }",
 'values': {'cover': "Scale the image, while preserving its intrinsic aspect ratio (if any), to the smallest size such that both its width and its height can completely cover the background positioning area.",
            'contain': "Specifies that the background image should be scaled to be as large as possible while ensuring both its dimensions are less than or equal to the corresponding dimensions of the background positioning area.",
            'auto': "[ <length> | <percentage> | auto ]{1,2}. The first value gives the width of the corresponding image, the second value its height. If only one value is given the second is assumed to be 'auto'. A percentage is relative to the background positioning area. An 'auto' value for one dimension is resolved by using the image's intrinsic ratio and the size of the other dimension, or failing that, using the image's intrinsic size, or failing that, treating it as 100%. If both values are 'auto' then the intrinsic width and/or height of the image should be used, if any, the missing dimension (if any) behaving as ''auto'' as described above. If the image has neither an intrinsic width nor an intrinsic height, its size is determined as for 'contain'. Negative values are not allowed."}},

    'baseline-shift':
{'description': "The 'baseline-shift' property allows\nrepositioning of the dominant-baseline relative to the dominant-baseline. The\nshifted object might be a sub- or superscript. Within the shifted element,\nthe whole baseline table is offset; not just a single baseline. For sub- and\nsuperscript, the amount of offset is determined from the nominal font of the\nparent. Values for the property have the following meaning:",
 'values': {'<length>': "The dominant-baseline is shifted in the shift-direction (positive value)\nor opposite to the shift-direction (negative value) of the parent area by the\n<length> value. A value of '0cm' is equivalent to 'baseline'.",
            '<percentage>': "The computed value of the property is this percentage multiplied by the\ncomputed 'line-height' of the parent element. The dominant-baseline is\nshifted in the shift-direction (positive value) or opposite to the\nshift-direction (negative value) of the parent area by the computed value. A\nvalue of '0%' is equivalent to 'baseline'.",
            'baseline': 'There is no baseline shift; the dominant baseline remains in its original\nposition.',
            'sub': 'The dominant baseline is shifted to the default position for subscripts.\nThe offset for this position is determined by the font data for the parent\nnominal font as adjusted by the dominant baseline-table font-size of the\nparent element. If there is no applicable font data the User Agent may use\nheuristic to determine the offset.',
            'super': 'The dominant baseline is shifted to the default position for\nsuperscripts. The offset for this position is determined by the font data for\nthe parent nominal font as adjusted by the dominant baseline-table font-size\nof the parent element. If there is no applicable font data the User Agent may\nuse heuristic to determine the offset.'}},

    'binding':
{'description': 'A property to attach a binding to a particular element.',
 'values': {'url(': 'The specified binding is attached. More than one binding can be specified, resulting in the bindings being attached in the specified order. The relevant language specification(s) define how multiple bindings interact. When the bindings interact through linear inheritance, the last binding specified must inherit from the previous one, and so forth, up to the first binding.',
            'none': 'No bindings are to be attached through CSS.'}},

    'bookmark-label':
{'description': 'This property specifies the label of the bookmark, i.e., the text that will represent the bookmark in the bookmark structure. a { bookmark-label: attr(title, string) }\nh1 { bookmark-label: content() }\nh2 { bookmark-label: content(before) }\n#frog { bookmark-label: "The green frog" } Name: bookmark-target Value: none | <uri> | <attr> Initial: none Applies to: all elements Inherited: no Percentages: N/A Media: all Computed value: For URI values, the absolute URI; for attr() values, the resulting URI or string; for other keywords, as specified. This property specifies the target of the bookmark link..bookmark { bookmark-label: attr(title, string); bookmark-target: attr(href, url);\n}\n...\n<a class="bookmark" title="The green pear" href="#pears"/>.exable { bookmark-label: url(http://www.example.com) } Name: bookmark-state Value: open | closed Initial: open Applies to: block-level elements Inherited: no Percentages: N/A Media: all Computed value: specified valueThis property describes the initial state of a bookmark. * { bookmark-state: closed }\n#open { bookmark-state: open } 11. CMYK colors',
 'values': {}},

    'bookmark-level':
{'description': 'This property describes what level a certain bookmark has in a hierarchical bookmark structure. The highest level is 1, then 2, 3 etc. h1 { bookmark-level: 1 }\nh2 { bookmark-level: 2 }\nh3 { bookmark-level: 3 } Name: bookmark-label Value: content() | attr() | <string> Initial: content() Applies to: all elements Inherited: no Percentages: N/A Media: all Computed value: specified valueThis property specifies the label of the bookmark, i.e., the text that will represent the bookmark in the bookmark structure. a { bookmark-label: attr(title, string) }\nh1 { bookmark-label: content() }\nh2 { bookmark-label: content(before) }\n#frog { bookmark-label: "The green frog" } Name: bookmark-target Value: none | <uri> | <attr> Initial: none Applies to: all elements Inherited: no Percentages: N/A Media: all Computed value: For URI values, the absolute URI; for attr() values, the resulting URI or string; for other keywords, as specified. This property specifies the target of the bookmark link..bookmark { bookmark-label: attr(title, string); bookmark-target: attr(href, url);\n}\n...\n<a class="bookmark" title="The green pear" href="#pears"/>.exable { bookmark-label: url(http://www.example.com) } Name: bookmark-state Value: open | closed Initial: open Applies to: block-level elements Inherited: no Percentages: N/A Media: all Computed value: specified valueThis property describes the initial state of a bookmark. * { bookmark-state: closed }\n#open { bookmark-state: open } 11. CMYK colors',
 'values': {}},

    'bookmark-target':
{'description': 'This property specifies the target of the bookmark link..bookmark { bookmark-label: attr(title, string); bookmark-target: attr(href, url);\n}\n...\n<a class="bookmark" title="The green pear" href="#pears"/>.exable { bookmark-label: url(http://www.example.com) } Name: bookmark-state Value: open | closed Initial: open Applies to: block-level elements Inherited: no Percentages: N/A Media: all Computed value: specified valueThis property describes the initial state of a bookmark. * { bookmark-state: closed }\n#open { bookmark-state: open } 11. CMYK colors',
 'values': {}},

    'border-bottom-left-radius':
{'description': "The two length or percentage values of the 'border-*-radius' properties define the radii of a quarter ellipse that defines the shape of the corner of the outer border edge (see the diagram below). The first value is the horizontal radius, the second the vertical radius. If the second value is omitted it is copied from the first. If either length is zero, the corner is square, not rounded. Percentages for the horizontal radius refer to the width of the border box, whereas percentages for the vertical radius refer to the height of the border box. The two values of ' border-top-left-radius: 55pt 25pt ' define the curvature of the corner. The two values of ' border-top-left-radius: 55pt 25pt ' define the curvature of the corner. The 'border-radius' shorthand sets all four 'border-*-radius' properties. If values are given before and after the slash, then the values before the slash set the horizontal radius and the values after the slash set the vertical radius. If there is no slash, then the values set both radii equally. The four values for each radii are given in the order top-left, top-right, bottom-right, bottom-left. If bottom-left is omitted it is the same as top-right. If bottom-right is omitted it is the same as top-left. If top-right is omitted it is the same as top-left. border-radius: 4em; is equivalent to border-top-left-radius: 4em;\nborder-top-right-radius: 4em;\nborder-bottom-right-radius: 4em;\nborder-bottom-left-radius: 4em; and border-radius: 2em 1em 4em / 0.5em 3em; is equivalent to border-top-left-radius: 2em 0.5em;\nborder-top-right-radius: 1em 3em;\nborder-bottom-right-radius: 4em 0.5em;\nborder-bottom-left-radius: 1em 3em; 4.4.1. Corner ShapingThe padding edge (inner border) radius is the outer border radius minus the corresponding border thickness. In the case where this results in a negative value, the inner radius is zero. (In such cases its center might not coincide with that of the outer border curve.) Likewise the content edge radius is the padding edge radius minus the corresponding padding, or if that is negative, zero. The border and padding thicknesses in the curved region are thus interpolated from the adjoining sides, and when two adjoining borders are of different thicknesses the corner will show a smooth transition between the thicker and thinner borders. Note that this means that if the outer curve extends past the adjacent corner's padding edge, the inner curve may not be a full quarter ellipse. All border styles ('solid', 'dotted', 'inset', etc.) follow the curve of the border. The effect of a rounded corner when the two borders it connects are of unequal thickness (left) and the effect of a rounded corner on borders that are thicker than the radius of the corner (right). 4.4.2. Corner ClippingThe effect of a rounded corner when the two borders it connects are of unequal thickness (left) and the effect of a rounded corner on borders that are thicker than the radius of the corner (right). A box's backgrounds, but not its border-image, are clipped to the appropriate curve (as determined by 'background-clip'). Other effects that clip to the border or padding edge (such as 'overflow' other than 'visible') also must clip to the curve. The content of replaced elements is always trimmed to the content edge curve. Also, the area outside the curve of the border edge does not accept mouse events on behalf of the element. This example adds appropriate padding, so that the contents do not overflow the corners. Note that there is no border, but the background will still have rounded corners. DIV { background: black; color: white; border-radius: 1em; padding: 1em } 4.4.3. Color and Style TransitionsThis example adds appropriate padding, so that the contents do not overflow the corners. Note that there is no border, but the background will still have rounded corners. DIV { background: black; color: white; border-radius: 1em; padding: 1em }Color and style transitions must be contained within the segment of the border that intersects the smallest rectangle that contains both border radii as well as the center of the inner curve (which may be a point representing the corner of the padding edge, if the border radii are smaller than the border-width). The center of color and style transitions between adjoining borders is at the point on the curve that is at an angle that is proportional to the ratio of the border widths. For example, if the top and right border widths are equal, that point is at a 45 angle from the horizontal, and if the top is twice the width of the right the point is at a 30 angle from the horizontal. The line demarcating this transition is drawn between the point at that angle on the outer arc and the point at that angle on the inner arc. It is not defined what these transitions look like, but a gradient is recommended for color transitions that don't involve dotted or dashed borders. Given these corner shapes, color and style transitions must be contained within the green region. In case D the rectangle defined by the border radii does not include the center of the inner curve (which is a sharp corner), so the transition region is expanded to include that corner. Transitions may take up the entire transition region, but are not required to: For example, a gradient color transition between two solid border styles might take up only the region bounded by the tips of the outer radii and the tips of the inner radii (represented in case D by the dark green region). 4.4.4. Overlapping CurvesGiven these corner shapes, color and style transitions must be contained within the green region. In case D the rectangle defined by the border radii does not include the center of the inner curve (which is a sharp corner), so the transition region is expanded to include that corner. Transitions may take up the entire transition region, but are not required to: For example, a gradient color transition between two solid border styles might take up only the region bounded by the tips of the outer radii and the tips of the inner radii (represented in case D by the dark green region). Corner curves must not overlap: When the sum of any two adjacent border radii exceeds the size of the border box, UAs must proportionally reduce the used value of all border radii until none of them overlap. The algorithm for reducing radii is as follows:Let f = min( L i / S i ), where i ? {top, right, bottom, left}, S i is the sum of the radii of the corners on side i, and L top = L bottom = the width of the box, and L left = L right = the height of the box. If f < 1, then all corner radii are reduced by multiplying them by f. Note that this formula ensures that quarter circles remain quarter circles and large radii remain larger than smaller ones, but it may reduce corners that were already small enough, which may make borders of nearby elements that should look the same look different. If the curve interferes with UI elements such as scrollbars, the UA may further reduce the used value of the affected border radii (and only the affected border radii) as much as necessary, but no more. The rendering of the box must be exactly the same as if the reduced border-radius values were those originally specified. For example, the borders A and D of the figure below might be the result of box-sizing: border-box;\nwidth: 6em;\nheight: 2.5em;\nborder-radius: 0.5em 2em 0.5em 2em The height (2.5em) is enough for the specified radii (0.5em plus 2.5em). However, if the height is only 2em, box-sizing: border-box;\nwidth: 6em;\nheight: 2em;\nborder-radius: 0.5em 2em 0.5em 2em all corners need to be reduced by a factor 0.8 to make them fit. The used border radii thus are 0.4em (instead of 0.5em) and 1.6em (instead of 2em). See borders B and C in the figure. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. 4.4.5. Effect on TablesFor example, the borders A and D of the figure below might be the result of box-sizing: border-box;\nwidth: 6em;\nheight: 2.5em;\nborder-radius: 0.5em 2em 0.5em 2emThe height (2.5em) is enough for the specified radii (0.5em plus 2.5em). However, if the height is only 2em, box-sizing: border-box;\nwidth: 6em;\nheight: 2em;\nborder-radius: 0.5em 2em 0.5em 2emall corners need to be reduced by a factor 0.8 to make them fit. The used border radii thus are 0.4em (instead of 0.5em) and 1.6em (instead of 2em). See borders B and C in the figure. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. The 'border-radius' properties do apply to 'table'and'inline-table' elements. When 'border-collapse'is'collapse', the UA may apply the border-radius properties to 'table'and'inline-table' elements, but is not required to. In this case not only must the border radii of adjacent corners not intersect, but the horizontal and vertical radii of a single corner may not extend past the boundaries of the cell at that corner (i.e. the cell's other corners must not be affected by this corner's border-radius). If the computed values of the border radii would cause this effect, then the used values of all the border radii of the table must be reduced by the same factor so that the radii neither intersect nor extend past the boundaries of their respective corner cells. The effect of border-radius on internal table elements is undefined in CSS3 Backgrounds and Borders, but may be defined in a future specification. CSS3 UAs should ignore border-radius properties applied to internal table elements when 'border-collapse'is'collapse'. This example draws ovals of 15em wide and 10em high: DIV.standout { width: 13em; height: 8em; border: solid black 1em; border-radius: 7.5em 5em } 4.5. The border shorthand properties Name: border-top, border-right, border-bottom, border-left Value: <border-width> || <border-style> || <color> Initial: See individual properties Applies to: all elements Inherited: no Percentages: N/A Media: visual Computed value: see individual propertiesThis example draws ovals of 15em wide and 10em high: DIV.standout { width: 13em; height: 8em; border: solid black 1em; border-radius: 7.5em 5em }",
 'values': {}},

    'border-bottom-right-radius':
{'description': "The two length or percentage values of the 'border-*-radius' properties define the radii of a quarter ellipse that defines the shape of the corner of the outer border edge (see the diagram below). The first value is the horizontal radius, the second the vertical radius. If the second value is omitted it is copied from the first. If either length is zero, the corner is square, not rounded. Percentages for the horizontal radius refer to the width of the border box, whereas percentages for the vertical radius refer to the height of the border box. The two values of ' border-top-left-radius: 55pt 25pt ' define the curvature of the corner. The two values of ' border-top-left-radius: 55pt 25pt ' define the curvature of the corner. The 'border-radius' shorthand sets all four 'border-*-radius' properties. If values are given before and after the slash, then the values before the slash set the horizontal radius and the values after the slash set the vertical radius. If there is no slash, then the values set both radii equally. The four values for each radii are given in the order top-left, top-right, bottom-right, bottom-left. If bottom-left is omitted it is the same as top-right. If bottom-right is omitted it is the same as top-left. If top-right is omitted it is the same as top-left. border-radius: 4em; is equivalent to border-top-left-radius: 4em;\nborder-top-right-radius: 4em;\nborder-bottom-right-radius: 4em;\nborder-bottom-left-radius: 4em; and border-radius: 2em 1em 4em / 0.5em 3em; is equivalent to border-top-left-radius: 2em 0.5em;\nborder-top-right-radius: 1em 3em;\nborder-bottom-right-radius: 4em 0.5em;\nborder-bottom-left-radius: 1em 3em; 4.4.1. Corner ShapingThe padding edge (inner border) radius is the outer border radius minus the corresponding border thickness. In the case where this results in a negative value, the inner radius is zero. (In such cases its center might not coincide with that of the outer border curve.) Likewise the content edge radius is the padding edge radius minus the corresponding padding, or if that is negative, zero. The border and padding thicknesses in the curved region are thus interpolated from the adjoining sides, and when two adjoining borders are of different thicknesses the corner will show a smooth transition between the thicker and thinner borders. Note that this means that if the outer curve extends past the adjacent corner's padding edge, the inner curve may not be a full quarter ellipse. All border styles ('solid', 'dotted', 'inset', etc.) follow the curve of the border. The effect of a rounded corner when the two borders it connects are of unequal thickness (left) and the effect of a rounded corner on borders that are thicker than the radius of the corner (right). 4.4.2. Corner ClippingThe effect of a rounded corner when the two borders it connects are of unequal thickness (left) and the effect of a rounded corner on borders that are thicker than the radius of the corner (right). A box's backgrounds, but not its border-image, are clipped to the appropriate curve (as determined by 'background-clip'). Other effects that clip to the border or padding edge (such as 'overflow' other than 'visible') also must clip to the curve. The content of replaced elements is always trimmed to the content edge curve. Also, the area outside the curve of the border edge does not accept mouse events on behalf of the element. This example adds appropriate padding, so that the contents do not overflow the corners. Note that there is no border, but the background will still have rounded corners. DIV { background: black; color: white; border-radius: 1em; padding: 1em } 4.4.3. Color and Style TransitionsThis example adds appropriate padding, so that the contents do not overflow the corners. Note that there is no border, but the background will still have rounded corners. DIV { background: black; color: white; border-radius: 1em; padding: 1em }Color and style transitions must be contained within the segment of the border that intersects the smallest rectangle that contains both border radii as well as the center of the inner curve (which may be a point representing the corner of the padding edge, if the border radii are smaller than the border-width). The center of color and style transitions between adjoining borders is at the point on the curve that is at an angle that is proportional to the ratio of the border widths. For example, if the top and right border widths are equal, that point is at a 45 angle from the horizontal, and if the top is twice the width of the right the point is at a 30 angle from the horizontal. The line demarcating this transition is drawn between the point at that angle on the outer arc and the point at that angle on the inner arc. It is not defined what these transitions look like, but a gradient is recommended for color transitions that don't involve dotted or dashed borders. Given these corner shapes, color and style transitions must be contained within the green region. In case D the rectangle defined by the border radii does not include the center of the inner curve (which is a sharp corner), so the transition region is expanded to include that corner. Transitions may take up the entire transition region, but are not required to: For example, a gradient color transition between two solid border styles might take up only the region bounded by the tips of the outer radii and the tips of the inner radii (represented in case D by the dark green region). 4.4.4. Overlapping CurvesGiven these corner shapes, color and style transitions must be contained within the green region. In case D the rectangle defined by the border radii does not include the center of the inner curve (which is a sharp corner), so the transition region is expanded to include that corner. Transitions may take up the entire transition region, but are not required to: For example, a gradient color transition between two solid border styles might take up only the region bounded by the tips of the outer radii and the tips of the inner radii (represented in case D by the dark green region). Corner curves must not overlap: When the sum of any two adjacent border radii exceeds the size of the border box, UAs must proportionally reduce the used value of all border radii until none of them overlap. The algorithm for reducing radii is as follows:Let f = min( L i / S i ), where i ? {top, right, bottom, left}, S i is the sum of the radii of the corners on side i, and L top = L bottom = the width of the box, and L left = L right = the height of the box. If f < 1, then all corner radii are reduced by multiplying them by f. Note that this formula ensures that quarter circles remain quarter circles and large radii remain larger than smaller ones, but it may reduce corners that were already small enough, which may make borders of nearby elements that should look the same look different. If the curve interferes with UI elements such as scrollbars, the UA may further reduce the used value of the affected border radii (and only the affected border radii) as much as necessary, but no more. The rendering of the box must be exactly the same as if the reduced border-radius values were those originally specified. For example, the borders A and D of the figure below might be the result of box-sizing: border-box;\nwidth: 6em;\nheight: 2.5em;\nborder-radius: 0.5em 2em 0.5em 2em The height (2.5em) is enough for the specified radii (0.5em plus 2.5em). However, if the height is only 2em, box-sizing: border-box;\nwidth: 6em;\nheight: 2em;\nborder-radius: 0.5em 2em 0.5em 2em all corners need to be reduced by a factor 0.8 to make them fit. The used border radii thus are 0.4em (instead of 0.5em) and 1.6em (instead of 2em). See borders B and C in the figure. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. 4.4.5. Effect on TablesFor example, the borders A and D of the figure below might be the result of box-sizing: border-box;\nwidth: 6em;\nheight: 2.5em;\nborder-radius: 0.5em 2em 0.5em 2emThe height (2.5em) is enough for the specified radii (0.5em plus 2.5em). However, if the height is only 2em, box-sizing: border-box;\nwidth: 6em;\nheight: 2em;\nborder-radius: 0.5em 2em 0.5em 2emall corners need to be reduced by a factor 0.8 to make them fit. The used border radii thus are 0.4em (instead of 0.5em) and 1.6em (instead of 2em). See borders B and C in the figure. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. The 'border-radius' properties do apply to 'table'and'inline-table' elements. When 'border-collapse'is'collapse', the UA may apply the border-radius properties to 'table'and'inline-table' elements, but is not required to. In this case not only must the border radii of adjacent corners not intersect, but the horizontal and vertical radii of a single corner may not extend past the boundaries of the cell at that corner (i.e. the cell's other corners must not be affected by this corner's border-radius). If the computed values of the border radii would cause this effect, then the used values of all the border radii of the table must be reduced by the same factor so that the radii neither intersect nor extend past the boundaries of their respective corner cells. The effect of border-radius on internal table elements is undefined in CSS3 Backgrounds and Borders, but may be defined in a future specification. CSS3 UAs should ignore border-radius properties applied to internal table elements when 'border-collapse'is'collapse'. This example draws ovals of 15em wide and 10em high: DIV.standout { width: 13em; height: 8em; border: solid black 1em; border-radius: 7.5em 5em } 4.5. The border shorthand properties Name: border-top, border-right, border-bottom, border-left Value: <border-width> || <border-style> || <color> Initial: See individual properties Applies to: all elements Inherited: no Percentages: N/A Media: visual Computed value: see individual propertiesThis example draws ovals of 15em wide and 10em high: DIV.standout { width: 13em; height: 8em; border: solid black 1em; border-radius: 7.5em 5em }",
 'values': {}},

    'border-image':
{'description': "This is a shorthand property for setting 'border-image-source', 'border-image-slice', 'border-image-width', 'border-image-outset'and'border-image-repeat'. Omitted values are set to their initial values. 6. Miscellaneous Effects 6.1. The 'box-decoration-break' property Name: box-decoration-break Value: slice | clone Initial: slice Applies to: all elements Inherited: no Percentages: N/A Media: visual Computed value: as specified",
 'values': {}},

    'border-radius':
{'description': "The two length or percentage values of the 'border-*-radius' properties define the radii of a quarter ellipse that defines the shape of the corner of the outer border edge (see the diagram below). The first value is the horizontal radius, the second the vertical radius. If the second value is omitted it is copied from the first. If either length is zero, the corner is square, not rounded. Percentages for the horizontal radius refer to the width of the border box, whereas percentages for the vertical radius refer to the height of the border box. The two values of ' border-top-left-radius: 55pt 25pt ' define the curvature of the corner. The two values of ' border-top-left-radius: 55pt 25pt ' define the curvature of the corner. The 'border-radius' shorthand sets all four 'border-*-radius' properties. If values are given before and after the slash, then the values before the slash set the horizontal radius and the values after the slash set the vertical radius. If there is no slash, then the values set both radii equally. The four values for each radii are given in the order top-left, top-right, bottom-right, bottom-left. If bottom-left is omitted it is the same as top-right. If bottom-right is omitted it is the same as top-left. If top-right is omitted it is the same as top-left. border-radius: 4em; is equivalent to border-top-left-radius: 4em;\nborder-top-right-radius: 4em;\nborder-bottom-right-radius: 4em;\nborder-bottom-left-radius: 4em; and border-radius: 2em 1em 4em / 0.5em 3em; is equivalent to border-top-left-radius: 2em 0.5em;\nborder-top-right-radius: 1em 3em;\nborder-bottom-right-radius: 4em 0.5em;\nborder-bottom-left-radius: 1em 3em; 4.4.1. Corner ShapingThe padding edge (inner border) radius is the outer border radius minus the corresponding border thickness. In the case where this results in a negative value, the inner radius is zero. (In such cases its center might not coincide with that of the outer border curve.) Likewise the content edge radius is the padding edge radius minus the corresponding padding, or if that is negative, zero. The border and padding thicknesses in the curved region are thus interpolated from the adjoining sides, and when two adjoining borders are of different thicknesses the corner will show a smooth transition between the thicker and thinner borders. Note that this means that if the outer curve extends past the adjacent corner's padding edge, the inner curve may not be a full quarter ellipse. All border styles ('solid', 'dotted', 'inset', etc.) follow the curve of the border. The effect of a rounded corner when the two borders it connects are of unequal thickness (left) and the effect of a rounded corner on borders that are thicker than the radius of the corner (right). 4.4.2. Corner ClippingThe effect of a rounded corner when the two borders it connects are of unequal thickness (left) and the effect of a rounded corner on borders that are thicker than the radius of the corner (right). A box's backgrounds, but not its border-image, are clipped to the appropriate curve (as determined by 'background-clip'). Other effects that clip to the border or padding edge (such as 'overflow' other than 'visible') also must clip to the curve. The content of replaced elements is always trimmed to the content edge curve. Also, the area outside the curve of the border edge does not accept mouse events on behalf of the element. This example adds appropriate padding, so that the contents do not overflow the corners. Note that there is no border, but the background will still have rounded corners. DIV { background: black; color: white; border-radius: 1em; padding: 1em } 4.4.3. Color and Style TransitionsThis example adds appropriate padding, so that the contents do not overflow the corners. Note that there is no border, but the background will still have rounded corners. DIV { background: black; color: white; border-radius: 1em; padding: 1em }Color and style transitions must be contained within the segment of the border that intersects the smallest rectangle that contains both border radii as well as the center of the inner curve (which may be a point representing the corner of the padding edge, if the border radii are smaller than the border-width). The center of color and style transitions between adjoining borders is at the point on the curve that is at an angle that is proportional to the ratio of the border widths. For example, if the top and right border widths are equal, that point is at a 45 angle from the horizontal, and if the top is twice the width of the right the point is at a 30 angle from the horizontal. The line demarcating this transition is drawn between the point at that angle on the outer arc and the point at that angle on the inner arc. It is not defined what these transitions look like, but a gradient is recommended for color transitions that don't involve dotted or dashed borders. Given these corner shapes, color and style transitions must be contained within the green region. In case D the rectangle defined by the border radii does not include the center of the inner curve (which is a sharp corner), so the transition region is expanded to include that corner. Transitions may take up the entire transition region, but are not required to: For example, a gradient color transition between two solid border styles might take up only the region bounded by the tips of the outer radii and the tips of the inner radii (represented in case D by the dark green region). 4.4.4. Overlapping CurvesGiven these corner shapes, color and style transitions must be contained within the green region. In case D the rectangle defined by the border radii does not include the center of the inner curve (which is a sharp corner), so the transition region is expanded to include that corner. Transitions may take up the entire transition region, but are not required to: For example, a gradient color transition between two solid border styles might take up only the region bounded by the tips of the outer radii and the tips of the inner radii (represented in case D by the dark green region). Corner curves must not overlap: When the sum of any two adjacent border radii exceeds the size of the border box, UAs must proportionally reduce the used value of all border radii until none of them overlap. The algorithm for reducing radii is as follows:Let f = min( L i / S i ), where i ? {top, right, bottom, left}, S i is the sum of the radii of the corners on side i, and L top = L bottom = the width of the box, and L left = L right = the height of the box. If f < 1, then all corner radii are reduced by multiplying them by f. Note that this formula ensures that quarter circles remain quarter circles and large radii remain larger than smaller ones, but it may reduce corners that were already small enough, which may make borders of nearby elements that should look the same look different. If the curve interferes with UI elements such as scrollbars, the UA may further reduce the used value of the affected border radii (and only the affected border radii) as much as necessary, but no more. The rendering of the box must be exactly the same as if the reduced border-radius values were those originally specified. For example, the borders A and D of the figure below might be the result of box-sizing: border-box;\nwidth: 6em;\nheight: 2.5em;\nborder-radius: 0.5em 2em 0.5em 2em The height (2.5em) is enough for the specified radii (0.5em plus 2.5em). However, if the height is only 2em, box-sizing: border-box;\nwidth: 6em;\nheight: 2em;\nborder-radius: 0.5em 2em 0.5em 2em all corners need to be reduced by a factor 0.8 to make them fit. The used border radii thus are 0.4em (instead of 0.5em) and 1.6em (instead of 2em). See borders B and C in the figure. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. 4.4.5. Effect on TablesFor example, the borders A and D of the figure below might be the result of box-sizing: border-box;\nwidth: 6em;\nheight: 2.5em;\nborder-radius: 0.5em 2em 0.5em 2emThe height (2.5em) is enough for the specified radii (0.5em plus 2.5em). However, if the height is only 2em, box-sizing: border-box;\nwidth: 6em;\nheight: 2em;\nborder-radius: 0.5em 2em 0.5em 2emall corners need to be reduced by a factor 0.8 to make them fit. The used border radii thus are 0.4em (instead of 0.5em) and 1.6em (instead of 2em). See borders B and C in the figure. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. The 'border-radius' properties do apply to 'table'and'inline-table' elements. When 'border-collapse'is'collapse', the UA may apply the border-radius properties to 'table'and'inline-table' elements, but is not required to. In this case not only must the border radii of adjacent corners not intersect, but the horizontal and vertical radii of a single corner may not extend past the boundaries of the cell at that corner (i.e. the cell's other corners must not be affected by this corner's border-radius). If the computed values of the border radii would cause this effect, then the used values of all the border radii of the table must be reduced by the same factor so that the radii neither intersect nor extend past the boundaries of their respective corner cells. The effect of border-radius on internal table elements is undefined in CSS3 Backgrounds and Borders, but may be defined in a future specification. CSS3 UAs should ignore border-radius properties applied to internal table elements when 'border-collapse'is'collapse'. This example draws ovals of 15em wide and 10em high: DIV.standout { width: 13em; height: 8em; border: solid black 1em; border-radius: 7.5em 5em } 4.5. The border shorthand properties Name: border-top, border-right, border-bottom, border-left Value: <border-width> || <border-style> || <color> Initial: See individual properties Applies to: all elements Inherited: no Percentages: N/A Media: visual Computed value: see individual propertiesThis example draws ovals of 15em wide and 10em high: DIV.standout { width: 13em; height: 8em; border: solid black 1em; border-radius: 7.5em 5em }",
 'values': {}},

    'border-top-left-radius':
{'description': "The two length or percentage values of the 'border-*-radius' properties define the radii of a quarter ellipse that defines the shape of the corner of the outer border edge (see the diagram below). The first value is the horizontal radius, the second the vertical radius. If the second value is omitted it is copied from the first. If either length is zero, the corner is square, not rounded. Percentages for the horizontal radius refer to the width of the border box, whereas percentages for the vertical radius refer to the height of the border box. The two values of ' border-top-left-radius: 55pt 25pt ' define the curvature of the corner. The two values of ' border-top-left-radius: 55pt 25pt ' define the curvature of the corner. The 'border-radius' shorthand sets all four 'border-*-radius' properties. If values are given before and after the slash, then the values before the slash set the horizontal radius and the values after the slash set the vertical radius. If there is no slash, then the values set both radii equally. The four values for each radii are given in the order top-left, top-right, bottom-right, bottom-left. If bottom-left is omitted it is the same as top-right. If bottom-right is omitted it is the same as top-left. If top-right is omitted it is the same as top-left. border-radius: 4em; is equivalent to border-top-left-radius: 4em;\nborder-top-right-radius: 4em;\nborder-bottom-right-radius: 4em;\nborder-bottom-left-radius: 4em; and border-radius: 2em 1em 4em / 0.5em 3em; is equivalent to border-top-left-radius: 2em 0.5em;\nborder-top-right-radius: 1em 3em;\nborder-bottom-right-radius: 4em 0.5em;\nborder-bottom-left-radius: 1em 3em; 4.4.1. Corner ShapingThe padding edge (inner border) radius is the outer border radius minus the corresponding border thickness. In the case where this results in a negative value, the inner radius is zero. (In such cases its center might not coincide with that of the outer border curve.) Likewise the content edge radius is the padding edge radius minus the corresponding padding, or if that is negative, zero. The border and padding thicknesses in the curved region are thus interpolated from the adjoining sides, and when two adjoining borders are of different thicknesses the corner will show a smooth transition between the thicker and thinner borders. Note that this means that if the outer curve extends past the adjacent corner's padding edge, the inner curve may not be a full quarter ellipse. All border styles ('solid', 'dotted', 'inset', etc.) follow the curve of the border. The effect of a rounded corner when the two borders it connects are of unequal thickness (left) and the effect of a rounded corner on borders that are thicker than the radius of the corner (right). 4.4.2. Corner ClippingThe effect of a rounded corner when the two borders it connects are of unequal thickness (left) and the effect of a rounded corner on borders that are thicker than the radius of the corner (right). A box's backgrounds, but not its border-image, are clipped to the appropriate curve (as determined by 'background-clip'). Other effects that clip to the border or padding edge (such as 'overflow' other than 'visible') also must clip to the curve. The content of replaced elements is always trimmed to the content edge curve. Also, the area outside the curve of the border edge does not accept mouse events on behalf of the element. This example adds appropriate padding, so that the contents do not overflow the corners. Note that there is no border, but the background will still have rounded corners. DIV { background: black; color: white; border-radius: 1em; padding: 1em } 4.4.3. Color and Style TransitionsThis example adds appropriate padding, so that the contents do not overflow the corners. Note that there is no border, but the background will still have rounded corners. DIV { background: black; color: white; border-radius: 1em; padding: 1em }Color and style transitions must be contained within the segment of the border that intersects the smallest rectangle that contains both border radii as well as the center of the inner curve (which may be a point representing the corner of the padding edge, if the border radii are smaller than the border-width). The center of color and style transitions between adjoining borders is at the point on the curve that is at an angle that is proportional to the ratio of the border widths. For example, if the top and right border widths are equal, that point is at a 45 angle from the horizontal, and if the top is twice the width of the right the point is at a 30 angle from the horizontal. The line demarcating this transition is drawn between the point at that angle on the outer arc and the point at that angle on the inner arc. It is not defined what these transitions look like, but a gradient is recommended for color transitions that don't involve dotted or dashed borders. Given these corner shapes, color and style transitions must be contained within the green region. In case D the rectangle defined by the border radii does not include the center of the inner curve (which is a sharp corner), so the transition region is expanded to include that corner. Transitions may take up the entire transition region, but are not required to: For example, a gradient color transition between two solid border styles might take up only the region bounded by the tips of the outer radii and the tips of the inner radii (represented in case D by the dark green region). 4.4.4. Overlapping CurvesGiven these corner shapes, color and style transitions must be contained within the green region. In case D the rectangle defined by the border radii does not include the center of the inner curve (which is a sharp corner), so the transition region is expanded to include that corner. Transitions may take up the entire transition region, but are not required to: For example, a gradient color transition between two solid border styles might take up only the region bounded by the tips of the outer radii and the tips of the inner radii (represented in case D by the dark green region). Corner curves must not overlap: When the sum of any two adjacent border radii exceeds the size of the border box, UAs must proportionally reduce the used value of all border radii until none of them overlap. The algorithm for reducing radii is as follows:Let f = min( L i / S i ), where i ? {top, right, bottom, left}, S i is the sum of the radii of the corners on side i, and L top = L bottom = the width of the box, and L left = L right = the height of the box. If f < 1, then all corner radii are reduced by multiplying them by f. Note that this formula ensures that quarter circles remain quarter circles and large radii remain larger than smaller ones, but it may reduce corners that were already small enough, which may make borders of nearby elements that should look the same look different. If the curve interferes with UI elements such as scrollbars, the UA may further reduce the used value of the affected border radii (and only the affected border radii) as much as necessary, but no more. The rendering of the box must be exactly the same as if the reduced border-radius values were those originally specified. For example, the borders A and D of the figure below might be the result of box-sizing: border-box;\nwidth: 6em;\nheight: 2.5em;\nborder-radius: 0.5em 2em 0.5em 2em The height (2.5em) is enough for the specified radii (0.5em plus 2.5em). However, if the height is only 2em, box-sizing: border-box;\nwidth: 6em;\nheight: 2em;\nborder-radius: 0.5em 2em 0.5em 2em all corners need to be reduced by a factor 0.8 to make them fit. The used border radii thus are 0.4em (instead of 0.5em) and 1.6em (instead of 2em). See borders B and C in the figure. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. 4.4.5. Effect on TablesFor example, the borders A and D of the figure below might be the result of box-sizing: border-box;\nwidth: 6em;\nheight: 2.5em;\nborder-radius: 0.5em 2em 0.5em 2emThe height (2.5em) is enough for the specified radii (0.5em plus 2.5em). However, if the height is only 2em, box-sizing: border-box;\nwidth: 6em;\nheight: 2em;\nborder-radius: 0.5em 2em 0.5em 2emall corners need to be reduced by a factor 0.8 to make them fit. The used border radii thus are 0.4em (instead of 0.5em) and 1.6em (instead of 2em). See borders B and C in the figure. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. The 'border-radius' properties do apply to 'table'and'inline-table' elements. When 'border-collapse'is'collapse', the UA may apply the border-radius properties to 'table'and'inline-table' elements, but is not required to. In this case not only must the border radii of adjacent corners not intersect, but the horizontal and vertical radii of a single corner may not extend past the boundaries of the cell at that corner (i.e. the cell's other corners must not be affected by this corner's border-radius). If the computed values of the border radii would cause this effect, then the used values of all the border radii of the table must be reduced by the same factor so that the radii neither intersect nor extend past the boundaries of their respective corner cells. The effect of border-radius on internal table elements is undefined in CSS3 Backgrounds and Borders, but may be defined in a future specification. CSS3 UAs should ignore border-radius properties applied to internal table elements when 'border-collapse'is'collapse'. This example draws ovals of 15em wide and 10em high: DIV.standout { width: 13em; height: 8em; border: solid black 1em; border-radius: 7.5em 5em } 4.5. The border shorthand properties Name: border-top, border-right, border-bottom, border-left Value: <border-width> || <border-style> || <color> Initial: See individual properties Applies to: all elements Inherited: no Percentages: N/A Media: visual Computed value: see individual propertiesThis example draws ovals of 15em wide and 10em high: DIV.standout { width: 13em; height: 8em; border: solid black 1em; border-radius: 7.5em 5em }",
 'values': {}},

    'border-top-right-radius':
{'description': "The two length or percentage values of the 'border-*-radius' properties define the radii of a quarter ellipse that defines the shape of the corner of the outer border edge (see the diagram below). The first value is the horizontal radius, the second the vertical radius. If the second value is omitted it is copied from the first. If either length is zero, the corner is square, not rounded. Percentages for the horizontal radius refer to the width of the border box, whereas percentages for the vertical radius refer to the height of the border box. The two values of ' border-top-left-radius: 55pt 25pt ' define the curvature of the corner. The two values of ' border-top-left-radius: 55pt 25pt ' define the curvature of the corner. The 'border-radius' shorthand sets all four 'border-*-radius' properties. If values are given before and after the slash, then the values before the slash set the horizontal radius and the values after the slash set the vertical radius. If there is no slash, then the values set both radii equally. The four values for each radii are given in the order top-left, top-right, bottom-right, bottom-left. If bottom-left is omitted it is the same as top-right. If bottom-right is omitted it is the same as top-left. If top-right is omitted it is the same as top-left. border-radius: 4em; is equivalent to border-top-left-radius: 4em;\nborder-top-right-radius: 4em;\nborder-bottom-right-radius: 4em;\nborder-bottom-left-radius: 4em; and border-radius: 2em 1em 4em / 0.5em 3em; is equivalent to border-top-left-radius: 2em 0.5em;\nborder-top-right-radius: 1em 3em;\nborder-bottom-right-radius: 4em 0.5em;\nborder-bottom-left-radius: 1em 3em; 4.4.1. Corner ShapingThe padding edge (inner border) radius is the outer border radius minus the corresponding border thickness. In the case where this results in a negative value, the inner radius is zero. (In such cases its center might not coincide with that of the outer border curve.) Likewise the content edge radius is the padding edge radius minus the corresponding padding, or if that is negative, zero. The border and padding thicknesses in the curved region are thus interpolated from the adjoining sides, and when two adjoining borders are of different thicknesses the corner will show a smooth transition between the thicker and thinner borders. Note that this means that if the outer curve extends past the adjacent corner's padding edge, the inner curve may not be a full quarter ellipse. All border styles ('solid', 'dotted', 'inset', etc.) follow the curve of the border. The effect of a rounded corner when the two borders it connects are of unequal thickness (left) and the effect of a rounded corner on borders that are thicker than the radius of the corner (right). 4.4.2. Corner ClippingThe effect of a rounded corner when the two borders it connects are of unequal thickness (left) and the effect of a rounded corner on borders that are thicker than the radius of the corner (right). A box's backgrounds, but not its border-image, are clipped to the appropriate curve (as determined by 'background-clip'). Other effects that clip to the border or padding edge (such as 'overflow' other than 'visible') also must clip to the curve. The content of replaced elements is always trimmed to the content edge curve. Also, the area outside the curve of the border edge does not accept mouse events on behalf of the element. This example adds appropriate padding, so that the contents do not overflow the corners. Note that there is no border, but the background will still have rounded corners. DIV { background: black; color: white; border-radius: 1em; padding: 1em } 4.4.3. Color and Style TransitionsThis example adds appropriate padding, so that the contents do not overflow the corners. Note that there is no border, but the background will still have rounded corners. DIV { background: black; color: white; border-radius: 1em; padding: 1em }Color and style transitions must be contained within the segment of the border that intersects the smallest rectangle that contains both border radii as well as the center of the inner curve (which may be a point representing the corner of the padding edge, if the border radii are smaller than the border-width). The center of color and style transitions between adjoining borders is at the point on the curve that is at an angle that is proportional to the ratio of the border widths. For example, if the top and right border widths are equal, that point is at a 45 angle from the horizontal, and if the top is twice the width of the right the point is at a 30 angle from the horizontal. The line demarcating this transition is drawn between the point at that angle on the outer arc and the point at that angle on the inner arc. It is not defined what these transitions look like, but a gradient is recommended for color transitions that don't involve dotted or dashed borders. Given these corner shapes, color and style transitions must be contained within the green region. In case D the rectangle defined by the border radii does not include the center of the inner curve (which is a sharp corner), so the transition region is expanded to include that corner. Transitions may take up the entire transition region, but are not required to: For example, a gradient color transition between two solid border styles might take up only the region bounded by the tips of the outer radii and the tips of the inner radii (represented in case D by the dark green region). 4.4.4. Overlapping CurvesGiven these corner shapes, color and style transitions must be contained within the green region. In case D the rectangle defined by the border radii does not include the center of the inner curve (which is a sharp corner), so the transition region is expanded to include that corner. Transitions may take up the entire transition region, but are not required to: For example, a gradient color transition between two solid border styles might take up only the region bounded by the tips of the outer radii and the tips of the inner radii (represented in case D by the dark green region). Corner curves must not overlap: When the sum of any two adjacent border radii exceeds the size of the border box, UAs must proportionally reduce the used value of all border radii until none of them overlap. The algorithm for reducing radii is as follows:Let f = min( L i / S i ), where i ? {top, right, bottom, left}, S i is the sum of the radii of the corners on side i, and L top = L bottom = the width of the box, and L left = L right = the height of the box. If f < 1, then all corner radii are reduced by multiplying them by f. Note that this formula ensures that quarter circles remain quarter circles and large radii remain larger than smaller ones, but it may reduce corners that were already small enough, which may make borders of nearby elements that should look the same look different. If the curve interferes with UI elements such as scrollbars, the UA may further reduce the used value of the affected border radii (and only the affected border radii) as much as necessary, but no more. The rendering of the box must be exactly the same as if the reduced border-radius values were those originally specified. For example, the borders A and D of the figure below might be the result of box-sizing: border-box;\nwidth: 6em;\nheight: 2.5em;\nborder-radius: 0.5em 2em 0.5em 2em The height (2.5em) is enough for the specified radii (0.5em plus 2.5em). However, if the height is only 2em, box-sizing: border-box;\nwidth: 6em;\nheight: 2em;\nborder-radius: 0.5em 2em 0.5em 2em all corners need to be reduced by a factor 0.8 to make them fit. The used border radii thus are 0.4em (instead of 0.5em) and 1.6em (instead of 2em). See borders B and C in the figure. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. 4.4.5. Effect on TablesFor example, the borders A and D of the figure below might be the result of box-sizing: border-box;\nwidth: 6em;\nheight: 2.5em;\nborder-radius: 0.5em 2em 0.5em 2emThe height (2.5em) is enough for the specified radii (0.5em plus 2.5em). However, if the height is only 2em, box-sizing: border-box;\nwidth: 6em;\nheight: 2em;\nborder-radius: 0.5em 2em 0.5em 2emall corners need to be reduced by a factor 0.8 to make them fit. The used border radii thus are 0.4em (instead of 0.5em) and 1.6em (instead of 2em). See borders B and C in the figure. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. These rounded corner might be the result of ' width: 6em; height: 2.5em; border-radius: 0.5em 2em 0.5em 2em ' for A and D; and ditto but with ' height: 2em ' for B and C. The 'border-radius' properties do apply to 'table'and'inline-table' elements. When 'border-collapse'is'collapse', the UA may apply the border-radius properties to 'table'and'inline-table' elements, but is not required to. In this case not only must the border radii of adjacent corners not intersect, but the horizontal and vertical radii of a single corner may not extend past the boundaries of the cell at that corner (i.e. the cell's other corners must not be affected by this corner's border-radius). If the computed values of the border radii would cause this effect, then the used values of all the border radii of the table must be reduced by the same factor so that the radii neither intersect nor extend past the boundaries of their respective corner cells. The effect of border-radius on internal table elements is undefined in CSS3 Backgrounds and Borders, but may be defined in a future specification. CSS3 UAs should ignore border-radius properties applied to internal table elements when 'border-collapse'is'collapse'. This example draws ovals of 15em wide and 10em high: DIV.standout { width: 13em; height: 8em; border: solid black 1em; border-radius: 7.5em 5em } 4.5. The border shorthand properties Name: border-top, border-right, border-bottom, border-left Value: <border-width> || <border-style> || <color> Initial: See individual properties Applies to: all elements Inherited: no Percentages: N/A Media: visual Computed value: see individual propertiesThis example draws ovals of 15em wide and 10em high: DIV.standout { width: 13em; height: 8em; border: solid black 1em; border-radius: 7.5em 5em }",
 'values': {}},

    'box-align':
{'description': "When the size of the containing box is larger than the size of a child, extra space will be available. The 'box-align' property specifies how a box's children are placed and aligned along the direction perpendicular to the box orientation, and where the extra space, if any, is positioned. For horizontal orientation, it specifies how the children are positioned vertically. For vertical orientation, it specifies how the children are positioned horizontally. The amount of extra space may be different for each child. For example, if the containing box has a height of 200 pixels, and it contains two children at 100 and 150 pixels respectively, there will be 100 pixels of extra space for the first child and 50 pixels of space for the second child. The following values are valid for the box-align property, but see the text afterward for more specifics as to how children are positioned.",
 'values': {'baseline': "If this box orientation is inline-axis or horizontal, all children are placed with their baselines aligned, and extra space placed before or after as necessary. For block flows, the baseline of the first non-empty line box located within the element is used. For tables, the baseline of the first cell is used. The children, once aligned on their baselines, should then be placed into the box so that the child with the earliest extent margin has its top margin edge (or bottom margin edge for reverse direction boxes) flush with the top (or bottom) edge of the box's content area. If the box does not have an 'auto' height, overflow will always be on the bottom (or top for reverse direction boxes) edge. If the box orientation is block-axis or vertical, then baseline is interpreted as center.",
            'center': 'Any extra space is divided evenly, with half placed above the child and the other half placed after the child.',
            'end': 'For normal direction boxes, the bottom edge of each child is placed along the bottom of the box. Extra space is placed above the element. For reverse direction boxes, the top edge of each child is placed along the top of the box. Extra space is placed below the element.',
            'start': 'For normal direction boxes, the top edge of each child is placed along the top of the box. Extra space is placed below the element. For reverse direction boxes, the bottom edge of each child is placed along the bottom of the box. Extra space is placed above the element.',
            'stretch': 'The height of each child is adjusted to that of the containing block. However, note the text below.'}},

    'box-decoration-break':
{'description': "When a box is broken at a page break, column break, or, for inline elements, at a line break, the 'box-decoration-break' property specifies whether individual boxes are treated as broken pieces of one continuous box, or whether each box is individually wrapped with the border and padding. For backgrounds it defines how the background positioning area is derived from these multiple boxes and how the element's background is drawn within them. Values have the following meanings: Two possibilities for 'box-decoration-break': on the left, the value 'slice', on the right the value 'clone'.",
 'values': {'slice': "No border and no padding are inserted at the break. No box-shadow is drawn at the broken edge; 'border-radius' has no effect at its corners; and the 'border-image' is rendered for the whole box as if it were unbroken. The effect is as though the element were rendered with no break present, and then sliced by the break afterward. Backgrounds are drawn as if, after the element has been laid out (including any justification, bidi reordering, page breaks, etc.), all the element's boxes are taken and put one after the other in visual order. The background is applied to the bounding box of this composite box and then the boxes are put back, with their share of the background. For boxes broken across lines, first boxes on the same line are connected in visual order. Then boxes on subsequent lines are ordered according to the element's inline progression direction and aligned on the baseline. For example in a left-to-right containing block ('direction'is'ltr'), the first box is the leftmost box on the first line and boxes from subsequent lines are put to the right of it. In a right-to-left containing block, the first box is the rightmost on the first line and subsequent boxes are put to the left of it. For boxes broken across columns, the columns are treated as one continuous element, as if the column boxes were glued together in the block progression direction of the multi-column element. For boxes broken across pages, the page content areas are glued together in the block progression direction of the root element. In these cases, if the pieces have different widths (heights, if the root element / multi-column element is in vertical text mode), then each piece draws its background assuming that the whole element has the same width (height) as this piece. This ensures that right-aligned images stay aligned to the right edge, left-aligned images stay aligned to the left edge, and centered images stay centered."}},

    'box-direction':
{'description': "The 'box-direction' property specifies the direction in which children of a box are displayed.",
 'values': {'normal': 'A box with a computed value of horizontal for box-orient displays its children from left to right. A box with a computed value of vertical displays its children from top to bottom.',
            'reverse': 'A box with a computed value of horizontal for box-orient displays its children from right to left. A box with a computed value of vertical displays its children from bottom to top.'}},

    'box-flex':
{'description': 'An element is flexible when the box-flex property is specified. The box-flex property is a floating point value representing the flexibility of the element. Its initial value is 0, which indicates that the element is inflexible. Elements that are flexible can shrink or grow as the box shrinks and grows. Whenever there is extra space left over in a box, the flexible elements are expanded to fill that space. All flex is relative. For example, a child with a box-flex of 2 is twice as flexible as a child with a box-flex of 1. A negative value for box-flex is not allowed. Flexible elements can be assigned to flex groups using the \'box-flex-group\' property. This property is a natural number value (the first flex group is 1 and higher values are later flex groups). The initial value is 1. In a horizontally oriented box, the preferred width of each child is computed. If the width of the margin box of each child is equal to the width of the containing block, then there is no extra space available, so the preferred widths are used for each child. If the width of the margin box adds up to a value smaller than the width of the containing block, then extra space is available. This extra space is divided up among the flexible children, as described below. If the width of the margin box adds up to a value larger than the width of the containing block, then the flexible children shrink as much as necessary to prevent overflow. Flexibility only applies to elements in normal flow. As absolute and fixed positioned elements are not in flow, any flexibility or flexgroup specified on them is ignored. In addition, as the \'float\' property does not apply to children of flexible boxes, they are considered part of normal flow and flexibility does apply. When dividing up extra space, first take all elements within the first flex group. Each element within that group should be given extra width based on the ratio of that element\'s flexibility compared to the flexibility of other elements within the same flex group. However, if the preferred width of the element plus the extra width allotted to it is larger than the maximum width of the element, then the width is set to that maximum width, and any remaining extra width beyond that is divided up among the other children. In this example there is 60 pixels of extra space available in the containing box. #div1 { display: box; width: 300px; } #button1 { box-flex: 1.0; width: 100px; } #button2 { box-flex: 2.0; width: 140px; } <div id="div1"> <button id="button1">Hello</button> <button id="button2">Goodbye</button> </div> As both child buttons are flexible, the extra space will be divided up between them. The first child button has a flexibility of 1.0 and the second child button has a flexibility of 2.0. The first button will receive 20 pixels of extra width and the second button will receive 40 pixels of extra width, maintaining the same ratio of extra width to flexibility values. This extra width is added to the preferred size of the element. However, if the second button had a maximum width of 150 pixels, it could only grow by 10 pixels before hitting this maximum size, so the remaining 30 pixels would instead be given to the first element, breaking the flexibility ratio. In this example there is 60 pixels of extra space available in the containing box. As both child buttons are flexible, the extra space will be divided up between them. The first child button has a flexibility of 1.0 and the second child button has a flexibility of 2.0. The first button will receive 20 pixels of extra width and the second button will receive 40 pixels of extra width, maintaining the same ratio of extra width to flexibility values. This extra width is added to the preferred size of the element. However, if the second button had a maximum width of 150 pixels, it could only grow by 10 pixels before hitting this maximum size, so the remaining 30 pixels would instead be given to the first element, breaking the flexibility ratio. More specifically, the percentage of extra space that an element may receive is calculated as follows:\' box-flex of child \' / \' total of box-flex values of child and all siblings \'If the width of all flexible children within the group has been increased to their maximum widths, the process repeats for the children within the next flex group, using any space left over from the previous flex group. Once there are no more flex groups, and there is still space remaining, the extra space is divided within the containing box according to the box-pack property. If the box would overflow after the preferred width of the children have been computed, then width is removed from flexible elements in a manner similar to that used when adding extra space. Each flex group is examined in turn and space is removed according to the ratio of the flexibility of each element. Elements do not shrink below their minimum widths. If all children have been shrunk to their minimum sizes, then the box overflows, although if the box-lines property is set to multiple, the box may be able to move elements to additional lines to prevent this. For vertically oriented boxes, the algorithm as described above is similar except using the height instead of the width. When a child box of a horizontally oriented box contains an inline element, it is likely that shrinking the width of the element due to flexibility may cause the inline element to grow in height, as the text within it may need to wrap to additional lines. Examples: #div1 { display: box; box-orient: vertical; height: 200px } <div id="div1"> <button>Cat</button> <button style="box-flex: 1">Piranha</button> <button>Antidisestablishmentarianism</button> </div> In the example above, the box is 200 pixels tall and is more than enough room for the three buttons. Because the first and third buttons are inflexible, they remain the same size, which is their intrinsic size. The second button is specified as being flexible, and because it is the only flexible element in the box, it receives all of the extra space. <div style="display: box; box-orient: vertical;"> <button style="box-flex: 1; height: 1000px;"> Cat </button> </div> In this example, if the height of the box is reduced, for instance, because the user resized the containing viewport, the height of the flexible button also shrinks with the box, despite the specification of 1000 pixels as the preferred height. It continues to shrink until the minimum required height for the button is reached, which here will likely be the height needed to display the button\'s label and border. After that, the button can shrink no further. Elements within a box can therefore have their own notions of minimum and maximum intrinsic sizes. In the above example, the button could not get any smaller than the minimum height required to draw its borders and its text. #div1 { display: box; } #iframe1 { box-flex: 1; min-width: 100px; max-width: 300px; height: 300px; } <div id="div1"> <iframe id="iframe1" src="http://www.mozilla.org/"/> </div> In this example, the iframe has a minimum width of 100 pixels and a maximum width of 300 pixels. If the containing box is less than 100 pixels wide, the iframe will overflow its containing div. If the containing box is between 100 pixels and 300 pixels inclusive, the width of the iframe would be set to that size, minus any necessary padding, borders and margins. If the width of the containing box is larger than 300 pixels, the extra space will be added inside the div. The extra space is added after the iframe inside the box. <p style="display: box;"> <button style="box-flex: 1; max-width: 50px;">Child 1</button> <button style="box-flex: 1; min-width: 50px;">Child 2</button> </p> In this example, the box has been stretched so that it is very wide. The first child has a maximum width of 50 pixels, and it divides the excess space equally with the second child until its maximum width has been reached. After that, since it is not allowed to grow any further, the remaining space all goes to the second child. 6 Packing along the box axis Name: box-pack Value: start | end | center | justify Initial: start Applies to: box elements Inherited: no Percentages: no Media: visual Computed value: specified valueExamples:In the example above, the box is 200 pixels tall and is more than enough room for the three buttons. Because the first and third buttons are inflexible, they remain the same size, which is their intrinsic size. The second button is specified as being flexible, and because it is the only flexible element in the box, it receives all of the extra space. In this example, if the height of the box is reduced, for instance, because the user resized the containing viewport, the height of the flexible button also shrinks with the box, despite the specification of 1000 pixels as the preferred height. It continues to shrink until the minimum required height for the button is reached, which here will likely be the height needed to display the button\'s label and border. After that, the button can shrink no further. Elements within a box can therefore have their own notions of minimum and maximum intrinsic sizes. In the above example, the button could not get any smaller than the minimum height required to draw its borders and its text. In this example, the iframe has a minimum width of 100 pixels and a maximum width of 300 pixels. If the containing box is less than 100 pixels wide, the iframe will overflow its containing div. If the containing box is between 100 pixels and 300 pixels inclusive, the width of the iframe would be set to that size, minus any necessary padding, borders and margins. If the width of the containing box is larger than 300 pixels, the extra space will be added inside the div. The extra space is added after the iframe inside the box. In this example, the box has been stretched so that it is very wide. The first child has a maximum width of 50 pixels, and it divides the excess space equally with the second child until its maximum width has been reached. After that, since it is not allowed to grow any further, the remaining space all goes to the second child.',
 'values': {}},

    'box-flex-group':
{'description': 'An element is flexible when the box-flex property is specified. The box-flex property is a floating point value representing the flexibility of the element. Its initial value is 0, which indicates that the element is inflexible. Elements that are flexible can shrink or grow as the box shrinks and grows. Whenever there is extra space left over in a box, the flexible elements are expanded to fill that space. All flex is relative. For example, a child with a box-flex of 2 is twice as flexible as a child with a box-flex of 1. A negative value for box-flex is not allowed. Flexible elements can be assigned to flex groups using the \'box-flex-group\' property. This property is a natural number value (the first flex group is 1 and higher values are later flex groups). The initial value is 1. In a horizontally oriented box, the preferred width of each child is computed. If the width of the margin box of each child is equal to the width of the containing block, then there is no extra space available, so the preferred widths are used for each child. If the width of the margin box adds up to a value smaller than the width of the containing block, then extra space is available. This extra space is divided up among the flexible children, as described below. If the width of the margin box adds up to a value larger than the width of the containing block, then the flexible children shrink as much as necessary to prevent overflow. Flexibility only applies to elements in normal flow. As absolute and fixed positioned elements are not in flow, any flexibility or flexgroup specified on them is ignored. In addition, as the \'float\' property does not apply to children of flexible boxes, they are considered part of normal flow and flexibility does apply. When dividing up extra space, first take all elements within the first flex group. Each element within that group should be given extra width based on the ratio of that element\'s flexibility compared to the flexibility of other elements within the same flex group. However, if the preferred width of the element plus the extra width allotted to it is larger than the maximum width of the element, then the width is set to that maximum width, and any remaining extra width beyond that is divided up among the other children. In this example there is 60 pixels of extra space available in the containing box. #div1 { display: box; width: 300px; } #button1 { box-flex: 1.0; width: 100px; } #button2 { box-flex: 2.0; width: 140px; } <div id="div1"> <button id="button1">Hello</button> <button id="button2">Goodbye</button> </div> As both child buttons are flexible, the extra space will be divided up between them. The first child button has a flexibility of 1.0 and the second child button has a flexibility of 2.0. The first button will receive 20 pixels of extra width and the second button will receive 40 pixels of extra width, maintaining the same ratio of extra width to flexibility values. This extra width is added to the preferred size of the element. However, if the second button had a maximum width of 150 pixels, it could only grow by 10 pixels before hitting this maximum size, so the remaining 30 pixels would instead be given to the first element, breaking the flexibility ratio. In this example there is 60 pixels of extra space available in the containing box. As both child buttons are flexible, the extra space will be divided up between them. The first child button has a flexibility of 1.0 and the second child button has a flexibility of 2.0. The first button will receive 20 pixels of extra width and the second button will receive 40 pixels of extra width, maintaining the same ratio of extra width to flexibility values. This extra width is added to the preferred size of the element. However, if the second button had a maximum width of 150 pixels, it could only grow by 10 pixels before hitting this maximum size, so the remaining 30 pixels would instead be given to the first element, breaking the flexibility ratio. More specifically, the percentage of extra space that an element may receive is calculated as follows:\' box-flex of child \' / \' total of box-flex values of child and all siblings \'If the width of all flexible children within the group has been increased to their maximum widths, the process repeats for the children within the next flex group, using any space left over from the previous flex group. Once there are no more flex groups, and there is still space remaining, the extra space is divided within the containing box according to the box-pack property. If the box would overflow after the preferred width of the children have been computed, then width is removed from flexible elements in a manner similar to that used when adding extra space. Each flex group is examined in turn and space is removed according to the ratio of the flexibility of each element. Elements do not shrink below their minimum widths. If all children have been shrunk to their minimum sizes, then the box overflows, although if the box-lines property is set to multiple, the box may be able to move elements to additional lines to prevent this. For vertically oriented boxes, the algorithm as described above is similar except using the height instead of the width. When a child box of a horizontally oriented box contains an inline element, it is likely that shrinking the width of the element due to flexibility may cause the inline element to grow in height, as the text within it may need to wrap to additional lines. Examples: #div1 { display: box; box-orient: vertical; height: 200px } <div id="div1"> <button>Cat</button> <button style="box-flex: 1">Piranha</button> <button>Antidisestablishmentarianism</button> </div> In the example above, the box is 200 pixels tall and is more than enough room for the three buttons. Because the first and third buttons are inflexible, they remain the same size, which is their intrinsic size. The second button is specified as being flexible, and because it is the only flexible element in the box, it receives all of the extra space. <div style="display: box; box-orient: vertical;"> <button style="box-flex: 1; height: 1000px;"> Cat </button> </div> In this example, if the height of the box is reduced, for instance, because the user resized the containing viewport, the height of the flexible button also shrinks with the box, despite the specification of 1000 pixels as the preferred height. It continues to shrink until the minimum required height for the button is reached, which here will likely be the height needed to display the button\'s label and border. After that, the button can shrink no further. Elements within a box can therefore have their own notions of minimum and maximum intrinsic sizes. In the above example, the button could not get any smaller than the minimum height required to draw its borders and its text. #div1 { display: box; } #iframe1 { box-flex: 1; min-width: 100px; max-width: 300px; height: 300px; } <div id="div1"> <iframe id="iframe1" src="http://www.mozilla.org/"/> </div> In this example, the iframe has a minimum width of 100 pixels and a maximum width of 300 pixels. If the containing box is less than 100 pixels wide, the iframe will overflow its containing div. If the containing box is between 100 pixels and 300 pixels inclusive, the width of the iframe would be set to that size, minus any necessary padding, borders and margins. If the width of the containing box is larger than 300 pixels, the extra space will be added inside the div. The extra space is added after the iframe inside the box. <p style="display: box;"> <button style="box-flex: 1; max-width: 50px;">Child 1</button> <button style="box-flex: 1; min-width: 50px;">Child 2</button> </p> In this example, the box has been stretched so that it is very wide. The first child has a maximum width of 50 pixels, and it divides the excess space equally with the second child until its maximum width has been reached. After that, since it is not allowed to grow any further, the remaining space all goes to the second child. 6 Packing along the box axis Name: box-pack Value: start | end | center | justify Initial: start Applies to: box elements Inherited: no Percentages: no Media: visual Computed value: specified valueExamples:In the example above, the box is 200 pixels tall and is more than enough room for the three buttons. Because the first and third buttons are inflexible, they remain the same size, which is their intrinsic size. The second button is specified as being flexible, and because it is the only flexible element in the box, it receives all of the extra space. In this example, if the height of the box is reduced, for instance, because the user resized the containing viewport, the height of the flexible button also shrinks with the box, despite the specification of 1000 pixels as the preferred height. It continues to shrink until the minimum required height for the button is reached, which here will likely be the height needed to display the button\'s label and border. After that, the button can shrink no further. Elements within a box can therefore have their own notions of minimum and maximum intrinsic sizes. In the above example, the button could not get any smaller than the minimum height required to draw its borders and its text. In this example, the iframe has a minimum width of 100 pixels and a maximum width of 300 pixels. If the containing box is less than 100 pixels wide, the iframe will overflow its containing div. If the containing box is between 100 pixels and 300 pixels inclusive, the width of the iframe would be set to that size, minus any necessary padding, borders and margins. If the width of the containing box is larger than 300 pixels, the extra space will be added inside the div. The extra space is added after the iframe inside the box. In this example, the box has been stretched so that it is very wide. The first child has a maximum width of 50 pixels, and it divides the excess space equally with the second child until its maximum width has been reached. After that, since it is not allowed to grow any further, the remaining space all goes to the second child.',
 'values': {}},

    'box-lines':
{'description': 'By default a horizontal box will lay out its children in a single row, and a vertical box will lay out its children in a single column. This behavior can be changed using the box-lines property. The default value is single, which means that all elements will be placed in a single row or column, and any elements that don\'t fit will simply be considered overflow. If a value of multiple is specified, however, then the box is allowed to expand to multiple lines (that is, multiple rows or columns) in order to accommodate all of its children. The box must attempt to fit its children on as few lines as possible by shrinking all elements down to their minimum widths or heights if necessary. If the children in a horizontal box still do not fit on a line after being reduced to their minimum widths, then children are moved one by one onto a new line, until the elements remaining on the previous line fit. This process can repeat to an arbitrary number of lines. If a line contains only a single element that doesn\'t fit, then the element should stay on that line and overflow out of the box. The later lines are placed below the earlier lines in normal direction boxes and above in reverse direction boxes. The height of a line is the height of the largest child in that line. No additional space appears between the lines apart from the margins on the largest elements in each line. For calculating the height of a line, margins with a computed value of auto should be treated as having a value of 0. A similar process occurs for children in a vertical box. Later lines in normal direction boxes are placed to the right of earlier lines and to the left in reverse direction boxes. Once the number of lines has been determined, elements with a computed value for box-flex other than 0 stretch as necessary in an attempt to fill the remaining space on the lines. Each line computes flexes independently, so only elements on that line are considered when evaluating flex and flex-groups. The packing of elements in a line, as specified by the box-pack property, is also computed independently for each line. This example shows four buttons that do not fit horizontally. #div1 { display: box; box-lines: multiple; width: 300px; } button { box-flex: 1.0; width: 100px; } <div id="div1"> <button id="button1">Elephant</button> <button id="button2">Tiger</button> <button id="button1">Antelope</button> <button id="button2">Wildebeest</button> </div> The buttons are shrunk to their minimum widths, in this case calculated intrinsically. Assume that the four buttons have a minimum intrinsic width of 80 pixels. This will allow the first three buttons to fit in 240 pixels with 60 pixels left over of remaining space. Because the box-lines property has a specified value of multiple, the fourth button may be moved onto a second line. Flexibility is applied to each element, separately for each line. The first line has 60 pixels of remaining space, so each of the three buttons on that line will receive 20 pixels of extra width. The remaining button on a line of its own will stretch to the entire width of the containing box, or 300 pixels. If the box was resized, the buttons may rearrange onto different lines as necessary. If the style rules in the example above were changed to the following: #div1 { display: box; box-lines: multiple; box-pack: center; width: 300px; } button { box-flex: 1.0; width: 90px; max-width: 90px; } Now, each of the buttons will only stretch to include an additional 10 pixels of width, as the maximum width of 90 pixels is only 10 pixels larger than the minimum intrinsic width of the buttons. The remaining 30 pixels of space left over is divided up and placed inside the box outside of the buttons, as the value of box-pack is center. The fourth button will also appear at 90 pixels wide, centered within the box. 7.1 Multiple Lines and alignmentThis example shows four buttons that do not fit horizontally. The buttons are shrunk to their minimum widths, in this case calculated intrinsically. Assume that the four buttons have a minimum intrinsic width of 80 pixels. This will allow the first three buttons to fit in 240 pixels with 60 pixels left over of remaining space. Because the box-lines property has a specified value of multiple, the fourth button may be moved onto a second line. Flexibility is applied to each element, separately for each line. The first line has 60 pixels of remaining space, so each of the three buttons on that line will receive 20 pixels of extra width. The remaining button on a line of its own will stretch to the entire width of the containing box, or 300 pixels. If the box was resized, the buttons may rearrange onto different lines as necessary. If the style rules in the example above were changed to the following:Now, each of the buttons will only stretch to include an additional 10 pixels of width, as the maximum width of 90 pixels is only 10 pixels larger than the minimum intrinsic width of the buttons. The remaining 30 pixels of space left over is divided up and placed inside the box outside of the buttons, as the value of box-pack is center. The fourth button will also appear at 90 pixels wide, centered within the box.',
 'values': {}},

    'box-ordinal-group':
{'description': 'The children of a box element may be assigned to ordinal groups using the \'box-ordinal-group\' property. This property is a natural number value with an initial value is 1. Ordinal groups can be used in conjunction with the \'box-direction\' property to control the order in which the direct children of a box appear. When the computed box-direction is normal, a box will display its elements starting from the lowest numbered ordinal group and ensure that those elements appear to the left (for horizontal boxes) or at the top (for vertical boxes) of the container. Elements with the same ordinal group are flowed in the order they appear in the source document tree. In the reverse direction, the ordinal groups are examined in the same order, except the elements appear reversed. This example shows how ordinal groups might be used. #div1 { display: box; } #span1 { box-ordinal-group: 2; } #span3 { box-ordinal-group: 2; } #span4 { box-ordinal-group: 1; } <div id="div1"> <span id="span1" >Sentence One</span> <span id="span2" >Sentence Two</span> <span id="span3" >Sentence Three</span> <span id="span4" >Sentence Four</span> </div> The first ordinal group, 1, contains span2 and span4. As span2 does not specify an ordinal group, it will default to 1. The elements will be displayed in document order, so span2 will be displayed before span4. The second ordinal group, 2, contains the remaining two spans. The resulting display order will be: span2 span4 span1 span3This example shows how ordinal groups might be used. The first ordinal group, 1, contains span2 and span4. As span2 does not specify an ordinal group, it will default to 1. The elements will be displayed in document order, so span2 will be displayed before span4. The second ordinal group, 2, contains the remaining two spans. The resulting display order will be:Elements within a box can use the \'visibility\' property to render themselves invisible. Boxes behave like tables in that the value collapsed can be used to specify that an element within a box should not take up any space at all. The computed width and height of a collapsed element are both 0, and the element is not considered when calculating flexibility. Other non-collapsed flexible elements may expand as needed to fill in any space left open by a collapsed element. <h2 id="boxsizing">Box sizing</h2> <table class="propdef">\n<tbody>\n<tr valign=baseline><td><em>Name:</em> <td><dfn id="propdef-box-sizing">box-sizing</dfn>\n<tr valign=baseline><td><em>Value:</em> <td>content-box | padding-box | border-box | margin-box\n<tr valign=baseline><td><em>Initial:</em> <td>1\n<tr valign=baseline><td><em>Applies to:</em> <td>box and block elements\n<tr valign=baseline><td><em>Inherited:</em> <td>no\n<tr valign=baseline><td><em>Percentages:</em> <td>no\n<tr valign=baseline><td><em>Media:</em> <td>visual</a>\n<tr valign=baseline><td><em>Computed value:</em> <td>specified value\n</tbody>\n</table> <p>The <span class="property">\'<code class=property>box-sizing</code>\'</span> property determines how the <span class="property">\'<code class=property>height</code>\'</span> and <span class="property">\'<code class=property>width</code>\'</span> properties should be interpreted. </p><dl> <dt>content-box </dt><dd>This is the behavior of width and height as specified by CSS2. The specified width and height apply to the width and height respectively of the content box of the element. The padding and border of the element are drawn outside the specified width and height. </dd><dt>padding-box </dt><dd>The specified width and height of this element determine the padding box of the element. That is, any padding specified on the element is drawn inside this specified width and height. The content width and height is computed by subtracting the padding of the respective sides from the specified width and height. The padding-box size is the dimension used for the containing block of absolutely positioned blocks. </dd><dt>border-box </dt><dd>The specified width and height of this element determine the border box of the element. That is, any padding or border specified on the element is laid out and drawn inside this specified width and height. The content width and height is computed by subtracting the border and padding of the respective sides from the specified width and height. This is the behavior of width and height as commonly implemented by legacy HTML user agents for replaced elements and input elements. </dd><dt>margin-box </dt><dd>The specified width and height of this element determine the margin box of the element. That is, any margin, padding or border specified on the element is laid out and drawn inside this specified width and height. The content width and height is computed by subtracting the margin, border and padding of the respective sides from the specified width and height. When margins collapse, the height (or width, for horizontal block layout) is calculated before applying any collapsing algorithms. </dd></dl> <p>Note that despite the name of the property, <span class="property">\'<code class=property>box-sizing</code>\'</span> applies to block and table-level elements as well as boxes. 4 Alignment Name: box-align Value: start | end | center | baseline | stretch Initial: stretch Applies to: box elements Inherited: no Percentages: no Media: visual Computed value: specified value',
        'values': {}},

    'box-orient':
{'description': 'A box may lay out its children either horizontally or vertically.',
        'values': {'block-axis': 'The box displays its children along the block axis.',
                          'horizontal': 'The box displays its children from left to right in a horizontal line.',
                          'inline-axis': 'The box displays its children along the inline axis.',
                          'vertical': 'The box displays its children from stacked from top to bottom vertically.'}},

    'box-pack':
{'description': 'When all of the elements within a box are inflexible or when all elements have grown to their maximum sizes and can stretch no further, extra space may be left over in the box. The box-pack property may be used to dictate how any additional space along the box-axis should be distributed between elements. The box-pack property does not affect the position of elements in the opposite direction. That is, box-pack affects only the horizontal position in horizontally oriented boxes and only the vertical position in vertically oriented boxes. <p style="box-align: center; box-pack: center; width: 300px; height: 300px;"> <button>centered</button> </p> In the example above, the button is centered within the box using the \'box-align\' and \'box-pack\' properties together. The former centers the button vertically, and the latter centers the button horizontally. 7 Multiple Lines Name: box-lines Value: single | multiple Initial: single Applies to: box elements Inherited: no Percentages: no Media: visual Computed value: specified value',
        'values': {'center': 'The extra space is divided evenly, with half placed before the first child and the other half placed after the last child.',
                          'end': 'For normal direction boxes, the right edge of the last child is placed at the right side, with all extra space placed before the first child. For reverse direction boxes, the left edge of the first child is placed at the left side, with all extra space placed after the last child.',
                          'justify': 'The space is divided evenly in-between each child, with none of the extra space placed before the first child or after the last child. If there is only one child, treat the pack value as if it were start.',
                          'start': 'For normal direction boxes, the left edge of the first child is placed at the left side, with all extra space placed after the last child. For reverse direction boxes, the right edge of the last child is placed at the right side, with all extra space placed before the first child.'}},

    'box-shadow':
{'description': "The 'box-shadow' property attaches one or more drop-shadows to the box. The property is a comma-separated list of shadows, each specified by 2-4 length values, an optional color, and an optional 'inset' keyword. Omitted lengths are 0; omitted colors are a UA-chosen color. Where <shadow> = inset? && [ <length> {2,4} && <color> ? ]The components of each <shadow> are interpreted as follows: The first length is the horizontal offset of the shadow. A positive value draws a shadow that is offset to the right of the box, a negative length to the left. The second length is the vertical offset. A positive value offsets the shadow down, a negative one up. The third length is a blur distance. Negative values are not allowed. If the blur value is zero, the shadow's edge is sharp. Otherwise, the larger the value, the more the shadow's edge is blurred. See below. The fourth length is a spread distance. Positive values cause the shadow shape to expand in all directions by the specified radius. Negative values cause the shadow shape to contract. See below. Note that for inner shadows, expanding the shadow (creating more shadow area) means contracting the shadow's perimeter shape. The color is the color of the shadow. The 'inset' keyword, if present, changes the drop shadow from an outer shadow (one that shadows the box onto the canvas, as if it were lifted above the canvas) to an inner shadow (one that shadows the canvas onto the box, as if the box were cut out of the canvas and shifted behind it). An outer box-shadow casts a shadow as if the border-box of the element were opaque. The shadow is drawn outside the border edge only: it is clipped inside the border-box of the element. An inner box-shadow casts a shadow as if everything outside the padding edge were opaque. The inner shadow is drawn inside the padding edge only: it is clipped outside the padding box of the element. If the box has a nonzero 'border-radius', the shadow shape is rounded in the same way. The 'border-image' does not affect the shape of the box-shadow. If a spread distance is defined, the shadow is expanded outward or contracted inward by an operation equivalent to applying twice the absolute value of the spread value to a blur operation as defined below and thresholding the result such that for a positive spread distance all non-transparent pixels are given the full shadow color and for a negative spread distance all non-opaque pixels are made transparent. The UA may approximate this operation by taking an outward outset of the specified amount normal to the original shadow perimeter. Alternatively the UA may approximate the transformed shadow perimeter shape by outsetting (insetting, for inner shadows) the shadow's straight edges by the spread distance and increasing (decreasing, for inner shadows) and flooring at zero the corner radii by the same amount. (The UA may even combine these methods, using one method for outer shadows and another for inner ones.) For corners with a zero border-radius, however, the corner must remain sharp-the operation is equivalent to scaling the shadow shape. In any case, the effective width and height of the shadow shape is floored at zero. (A zero-sized shadow shape would cause an outer shadow to disappear, and an inner shadow to cover the entire padding-box.)A non-zero blur distance indicates that the resulting shadow should be blurred, such as by a Gaussian filter. The exact algorithm is not defined; however for a long, straight shadow edge, this should create a color transition the length of the blur distance that is perpendicular to and centered on the shadow's edge, and that ranges from the full shadow color at the radius endpoint inside the shadow to fully transparent at the endpoint outside it. The example below demonstrates the effects of spread and blur on the shadow:The example below demonstrates the effects of spread and blur on the shadow:The shadow effects are applied front-to-back: the first shadow is on top and the others are layered behind. Shadows do not influence layout and may overlap other boxes or their shadows. In terms of stacking contexts and the painting order, the outer shadows of an element are drawn immediately below the background of that element, and the inner shadows of an element are drawn immediately above the background of that element (below the borders and border image, if any). If an element has multiple boxes, all of them get drop shadows, but shadows are only drawn where borders would also be drawn; see 'box-decoration-break'. Shadows do not trigger scrolling or increase the size of the scrollable area. Below are some examples of an orange box with a blue border being being given a drop shadow. border:5px solid blue; background-color:orange; width: 144px; height: 144px; border-radius: 20px; border-radius: 0; box-shadow: rgba(0,0,0,0.4) 10px 10px; box-shadow: rgba(0,0,0,0.4) 10px 10px inset box-shadow: rgba(0,0,0,0.4) 10px 10px 0 10px /* spread */ box-shadow: rgba(0,0,0,0.4) 10px 10px 0 10px /* spread */ insetBelow are some examples of an orange box with a blue border being being given a drop shadow. The 'box-shadow' property applies to the ' ::first-letter ' pseudo-element, but not the ' ::first-line ' pseudo-element. Outer shadows have no effect on internal table elements in the collapsing border model. If a shadow is defined for single border edge in the collapsing border model that has multiple border thicknesses (e.g. an outer shadow on a table where one row has thicker borders than the others, or an inner shadow on a rowspanning table cell that adjoins cells with different border thicknesses), the exact position and rendering of its shadows are undefined. 7. Definitions 7.1. Glossary",
        'values': {}},

    'box-sizing':
{'description': '',
        'values': {'border-box': "The specified width and height (and respective min/max properties) on\nthis element determine the border box of the element. That is, any padding or\nborder specified on the element is laid out and drawn inside this specified\nwidth and height. The content width and height are calculated by subtracting\nthe border and padding widths of the respective sides from the specified 'width'and'height' properties. As the content width and height cannot\nbe negative ( [CSS21], section\n10.2), this computation is floored at 0. Note. This is the behavior of width and\nheight as commonly implemented by legacy HTML user agents for replaced\nelements and input elements.",
                          'content-box': 'This is the behavior of width and height as specified by CSS2.1. The\nspecified width and height (and respective min/max properties) apply to the\nwidth and height respectively of the content box of the element. The padding\nand border of the element are laid out and drawn outside the specified width\nand height.'}},

    'break-after':
{'description': 'These properties describe page/column break behavior before/after/inside the generated box. These are normatively defined in [CSS21] {{!CSS21}} :',
        'values': {'always': 'Always force a page break before (after) the generated box.',
                          'auto': 'Neither force nor forbid a page/column break before (after, inside) the generated box.',
                          'avoid': 'Avoid a page/column break before (after, inside) the generated box.',
                          'left': 'Force one or two page breaks before (after) the generated box so that the next page is formatted as a left page.',
                          'right': 'Force one or two page breaks before (after) the generated box so that the next page is formatted as a right page.'}},

    'break-before':
{'description': 'These properties describe page/column break behavior before/after/inside the generated box. These are normatively defined in [CSS21] {{!CSS21}} :',
        'values': {'always': 'Always force a page break before (after) the generated box.',
                          'auto': 'Neither force nor forbid a page/column break before (after, inside) the generated box.',
                          'avoid': 'Avoid a page/column break before (after, inside) the generated box.',
                          'left': 'Force one or two page breaks before (after) the generated box so that the next page is formatted as a left page.',
                          'right': 'Force one or two page breaks before (after) the generated box so that the next page is formatted as a right page.'}},

    'break-inside':
{'description': 'These properties describe page/column break behavior before/after/inside the generated box. These are normatively defined in [CSS21] {{!CSS21}} :',
        'values': {'always': 'Always force a page break before (after) the generated box.',
                          'auto': 'Neither force nor forbid a page/column break before (after, inside) the generated box.',
                          'avoid': 'Avoid a page/column break before (after, inside) the generated box.',
                          'left': 'Force one or two page breaks before (after) the generated box so that the next page is formatted as a left page.',
                          'right': 'Force one or two page breaks before (after) the generated box so that the next page is formatted as a right page.'}},

    'color-profile':
{'description': 'This property permits the specification of a source color profile other\nthan the default. <dt><strong>none</strong>\n<dd>Any profile information embedded within image data should be ignored.\nThe image should be rendered as if it is already in the destination color space. <i>This value is most useful for demonstration purposes.</i> Example(s): /* use the specified profile, even if the image contains an embedded profile */\nIMG { color-profile: url("http://example.com/profiles/eg.icm") } 3.4. The \'rendering-intent\'\nproperty Name: rendering-intent Value: auto | perceptual | relative-colorimetric | saturation |\nabsolute-colorimetric | inherit Initial: auto Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified value',
        'values': {'<name>': "A name corresponding to a defined color profile that is in the user\nagent's color profile description database. The user agent searches the color\nprofile description database for a color profile\ndescription entry whose name descriptor matches <name> and uses the\nlast matching entry that is found. If a match is found, the corresponding\nprofile overrides an embedded profile inside an image. If no match is found,\nthen the embedded profile inside the image is used.",
                          'url(': 'The location of a standard ICC profile resource. Just like specifying sRGB, it overrides an embedded profile.',
                          'auto': 'This is the default behavior. All colors are presumed to be defined in\nthe sRGB color space unless a more precise embedded profile is specified\nwithin content data. For images that do have a profile built into their data,\nthat profile is used. For images that do not have a profile, the sRGB profile\nis used so that the colors in these images can be kept "in synch" with the\ncolors specified in CSS and HTML.',
                          'sRGB': 'The source profile is assumed to be sRGB. This differs from auto in that it overrides an embedded profile inside an\nimage. For consistency with CSS lexical scanning and parsing rules, the\nkeyword "sRGB" is case-insensitive; however, it is recommended that the mixed\ncapitalization "sRGB" be used for consistency with common industry practice.'}},

    'column-count':
{'description': "This property describes the number of columns of a multicol element. Example: body { column-count: 3 } 3.3. 'columns' Name: columns Value: <'column-width'> || <'column-count'> Initial: see individual properties Applies to: non-replaced block-level elements (except table elements), table cells, and inline-block elements Inherited: no Percentages: N/A Media: visual Computed value: see individual properties",
        'values': {'<integer>': "describes the optimal number of columns into which the content of the element will be flowed. Values must be greater than 0. If both 'column-width'and'column-count' have non-auto values, the integer value describes the maximum number of columns.",
                          'auto': "means that the number of columns will be determined by other properties (e.g., 'column-width', if it has a non-auto value)."}},

    'column-fill':
{'description': 'The values are:',
        'values': {'auto': 'Fills columns sequentially.',
                          'balance': 'Balance content equally between columns, if possible.'}},

    'column-gap':
{'description': "The 'column-gap' property sets the gap between columns. If there is a column rule between columns, it will appear in the middle of the gap. The 'normal' value is UA-specific. A value of '1em' is suggested. Column gaps cannot be negative. 4.2. 'column-rule-color' Name: column-rule-color Value: <color> Initial: same as for 'color' property [CSS21] {{!CSS21}} Applies to: multicol elements Inherited: no Percentages: N/A Media: visual Computed value: the same as the computed value for the 'color' property [CSS21] {{!CSS21}}",
        'values': {}},

    'column-rule':
{'description': "This property is a shorthand for setting 'column-rule-width', 'column-rule-style', and 'column-rule-color' at the same place in the style sheet. Omitted values are set to their initial values. In this example, the column rule and the column gap have the same width. Therefore, they will occupy exactly the same space. body { column-gap: 1em; column-rule-width: 1em; column-rule-style: solid; column-rule-color: black;\n} If a tall image is moved to a column on the next page to find room for it, its natural column may be left empty. If so, the column is is still considered to have content for the purpose of deciding if the column rule should be drawn. 5. Column breaksIn this example, the column rule and the column gap have the same width. Therefore, they will occupy exactly the same space. body { column-gap: 1em; column-rule-width: 1em; column-rule-style: solid; column-rule-color: black;\n}If a tall image is moved to a column on the next page to find room for it, its natural column may be left empty. If so, the column is is still considered to have content for the purpose of deciding if the column rule should be drawn.",
        'values': {}},

    'column-rule-color':
{'description': "This property sets the color of the column rule. The <color> values are defined in [CSS21] {{!CSS21}}. 4.3. 'column-rule-style' Name: column-rule-style Value: <'border-style'> Initial: none Applies to: multicol elements Inherited: no Percentages: N/A Media: visual Computed value: specified value",
        'values': {}},

    'column-rule-style':
{'description': "The 'column-rule-style' property sets the style of the rule between columns of an element. The <border-style> values are defined in [CSS21] {{!CSS21}}. The 'inset' keyword value is shown like the 'ridge' value. The 'outset' value is shown like 'groove'. The 'none' value forces the computed value of 'column-rule-width' to be '0'. 4.4. 'column-rule-width' Name: column-rule-width Value: <'border-width'> Initial: medium Applies to: multicol elements Inherited: no Percentages: N/A Media: visual Computed value: absolute length; '0' if the column rule style is 'none'or'hidden'",
        'values': {}},

    'column-rule-width':
{'description': "This property sets the width of the rule between columns. Negative values are not allowed. 4.5. 'column-rule' Name: column-rule Value: <column-rule-width> || <border-style> || [ <color> | transparent ] Initial: see individual properties Applies to: multicol elements Inherited: no Percentages: N/A Media: visual Computed value: see individual properties",
        'values': {}},

    'column-span':
{'description': 'This property describes how many columns an element spans across. Values are:',
        'values': {'1': 'The element does not span multiple columns.',
                          'all': 'The element spans across all columns. Content in the normal flow that appears before the element is automatically balanced across all columns before the element appears.'}},

    'column-width':
{'description': 'This property describes the width of columns in multicol elements. For example, consider this style sheet: div { width: 100px; column-width: 45px; column-gap: 0; column-rule: none;\n} There is room for two 45px wide columns inside the 100px wide element. In order to fill the available space the actual column width will be increased to 50px. Also, consider this style sheet: div { width: 40px; column-width: 45px; column-gap: 0; column-rule: none;\n} The available space is smaller than the specified column width and the actual column width will therefore be decreased.',
        'values': {'<length>': 'describes the optimal column width. The actual column width may be wider (to fill the available space), or narrower (only if the available space is smaller than the specified column width). Values must be greater than 0.',
                          'auto': "means that the column width will be determined by other properties (e.g., 'column-count', if it has a non-auto value)."}},

    'columns':
{'description': "This is a shorthand property for setting 'column-width'and'column-count'. Omitted values are set to their initial values. Here are some valid declarations using the 'columns' property: columns: 12em; /* column-width: 12em; column-count: auto */\ncolumns: auto 12em; /* column-width: 12em; column-count: auto */\ncolumns: 2; /* column-width: auto; column-count: 2 */\ncolumns: 2 auto; /* column-width: auto; column-count: 2 */\ncolumns: auto; /* column-width: auto; column-count: auto */\ncolumns: auto auto; /* column-width: auto; column-count: auto */ 3.4. Pseudo-algorithmHere are some valid declarations using the 'columns' property: columns: 12em; /* column-width: 12em; column-count: auto */\ncolumns: auto 12em; /* column-width: 12em; column-count: auto */\ncolumns: 2; /* column-width: auto; column-count: 2 */\ncolumns: 2 auto; /* column-width: auto; column-count: 2 */\ncolumns: auto; /* column-width: auto; column-count: auto */\ncolumns: auto auto; /* column-width: auto; column-count: auto */",
        'values': {}},

    'crop':
{'description': 'This property allows a replaced element to be just a rectangular area of\nan object, instead of the whole object. The \'crop\' property adds a step when determining the intrinsic dimensions\nof an element. With \'crop\', the notion of computed intrinsic width\nand height are introduced. When the layout algorithms reference the\n"intrinsic width" (and/or height), they are referring to the computed\nintrinsic width and height. The computed intrinsic width and height of an element are the result of\napplying the crop to the actual intrinsic width and height of the element.',
        'values': {'auto': "The element's computed intrinsic width and height are the same as its\nactual intrinsic width and height.",
                          'inset-rect': 'inset-rect( top, right, bottom, left ). Like rect(), except that the values are offsets relative to the\nrespective edges of the element.',
                          'rect': 'rect( top, right, bottom, left ). Each of the four arguments can be a <length> or a <percentage>. All percentage values are computed relative to\nthe intrinsic dimensions of the element, if there is one. Values are offsets\nrelative to the top left of the element. The computed intrinsic width and\nheight of the element are determined by subtracting the left from the right\nfor the width, and similarly top from bottom for the height. However, if this\ncomputation results in a negative value, it is considered to be zero.'}},

    'dominant-baseline':
{'description': "The 'dominant-baseline' property is used to\ndetermine or re-determine a scaled-baseline-table. A scaled-baseline-table is\na compound value with three components: a baseline-identifier for the dominant baseline; it can be qualified as\nthe 'dominant' baseline-identifier (or 'dominant baseline' in short); the\nbaseline-identifier is basically an 'alignment-baseline' value. a derived baseline-table which contains definition for additional\nbaseline-identifiers related to various scripts, and a baseline-table font-size. Some values of the property re-determine all three values; other only\nreestablish the baseline-table font-size. Values for the property have the\nfollowing meaning:",
        'values': {'alphabetic': "The dominant baseline-identifier is set to the 'alphabetic' baseline, the\nderived baseline-table is constructed using the 'alphabetic' baseline-table\nin the nominal font, and the baseline-table font-size is changed to the value\nof the 'font-size' property on this element. (The 'alphabetic' baseline is\nthe standard baseline for Roman scripts.)",
                          'auto': "If this property occurs on a block or inline-block element, then the user\nagent behavior depends on the value of the 'script' property. If the value of the script\nproperty is 'auto, the 'auto' value is equivalent to 'alphabetic' for\nhorizontal 'writing-mode' values and 'central' for\nvertical 'writing-mode' values. If the value of the\nscript property is other than 'auto', the 'auto' value is equivalent to\n'use-script'",
                          'central': "The dominant baseline-identifier is set to be 'central'. The derived\nbaseline-table is constructed from the defined baselines in a baseline-table\nin the nominal font. That font baseline-table is chosen using the following\npriority order of baseline-table names: 'ideographic', 'alphabetic',\n'hanging'and'mathematical'. The baseline-table is changed to the value of\nthe 'font-size' property on this element.",
                          'hanging': "The dominant baseline-identifier is set to the 'hanging' baseline, the\nderived baseline- table is constructed using the 'hanging' baseline-table in\nthe nominal font, and the baseline-table font-size is changed to the value of\nthe 'font-size' property on this element.",
                          'ideographic': "The dominant baseline-identifier is set to the 'ideographic' baseline,\nthe derived baseline- table is constructed using the 'ideographic'\nbaseline-table in the nominal font, and the baseline-table font-size is\nchanged to the value of the 'font-size' property on this element.",
                          'mathematical': "The dominant baseline-identifier is set to the 'mathematical' baseline,\nthe derived baseline- table is constructed using the 'mathematical'\nbaseline-table in the nominal font, and the baseline-table font-size is\nchanged to the value of the 'font-size' property on this element.",
                          'middle': "The dominant baseline-identifier is set to be 'middle'. The derived\nbaseline-table is constructed from the defined baselines in a baseline-table\nin the nominal font. That font baseline-table is chosen using the following\npriority order of baseline-table names: 'alphabetic', 'ideographic',\n'hanging'and'mathematical'. The baseline-table is changed to the value of\nthe 'font-size' property on this element.",
                          'no-change': 'The dominant baseline-identifier, the baseline-table and the\nbaseline-table font-size remain the same as that of the parent.',
                          'reset-size': "The dominant baseline-identifier and the baseline table remain the same,\nbut the baseline-table font-size is changed to the value of the 'font-size' property on this element. This\nre-scales the baseline table for the current 'font-size'.",
                          'text-after-edge': "The dominant baseline-identifier is set to be 'text-after-edge'. The\nderived baseline-table is constructed from the defined baselines in a\nbaseline-table in the nominal font. That font baseline-table is chosen using\nthe following priority order of baseline-table names: 'alphabetic',\n'ideographic', 'hanging'and'mathematical'. The baseline-table is changed to\nthe value of the 'font-size' property on this element.",
                          'text-before-edge': "The dominant baseline-identifier is set to be 'text-before-edge'. The\nderived baseline-table is constructed from the defined baselines in a\nbaseline-table in the nominal font. That font baseline-table is chosen using\nthe following priority order of baseline-table names: 'alphabetic',\n'ideographic', 'hanging'and'mathematical'. The baseline-table is changed to\nthe value of the 'font-size' property on this element.",
                          'use-script': "The dominant baseline-identifier is set using the computed value of the 'script' property. The 'writing-mode' value, whether horizontal or vertical is used to select the baseline-table\nthat correspond to that baseline-identifier. The baseline-table font-size\ncomponent is set to the value of the 'font-size' property on this element."}},

    'drop-initial-after-adjust':
{'description': "The 'drop-initial-after-adjust' property sets\nthe alignment point of the drop initial for the primary connection point.\nPossible values: Name: drop-initial-before-align Value: caps-height | <'alignment-baseline'> Initial: caps-height Applies to: ::first-letter pseudo element Inherited: no Percentages: N/A Media: visual Computed value: specified values (except for initial and inherit)",
        'values': {'<length>': "The alignment-point is on the end-edge of the inline box. Its position\nalong the end-edge is offset from the after-edge by the <length> value.\nA value of '0cm' makes the text-after-edge the alignment point.",
                          '<percentage>': "The computed value of the property is this percentage multiplied by the\ncomputed 'line-height' of the element. The alignment point is on the end-edge\nof the inline box and is offset from the after-edge by the computed value. A\nvalue of '0%' makes the text-after-edge the alignment point.",
                          'after-edge': "The alignment point is at the intersection of the end-edge of the element\nand the 'after-edge' of the extended inline box of the element. This may include or not the line-height of the element, depending on the line-stacking-strategy.",
                          'alphabetic': "The alignment point is at the intersection of the end-edge of the element\nand the 'alphabetic' baseline of the element.",
                          'central': "The alignment point is at the intersection of the end-edge of the element\nand the 'central' baseline of the element.",
                          'hanging': "The alignment point is at the intersection of the end-edge of the element\nand the 'hanging' baseline of the element.",
                          'ideographic': "The alignment point is at the intersection of the end-edge of the element\nand the 'ideographic' baseline of the element.",
                          'mathematical': "The alignment point is at the intersection of the end-edge of the element\nand the 'mathematical' baseline of the element.",
                          'middle': "The alignment point is at the intersection of the end-edge of the element\nand the 'middle' baseline of the element.",
                          'text-after-edge': "The alignment point is at the intersection of the end-edge of the element\nand the 'text-after-edge' baseline of the element."}},

    'drop-initial-after-align':
{'description': "The 'drop-initial-after-align' property\ndetermines which alignment line within the nth line box (n being defined by\nthe 'drop-initial-value' property) is used at the\nprimary connection point with the initial letter box. The values are the same\nas the 'alignment-baseline' property values. Name: drop-initial-after-adjust Value: central | middle | after-edge | text-after-edge | ideographic |\nalphabetic | mathematical | <percentage> | <length> Initial: text-after-edge Applies to: ::first-letter pseudo element Inherited: no Percentages: refer to combined line height size as provided by drop-initial-value Media: visual Computed value: specified values (except for initial and inherit)The 'drop-initial-after-adjust' property sets\nthe alignment point of the drop initial for the primary connection point.\nPossible values: Name: drop-initial-before-align Value: caps-height | <'alignment-baseline'> Initial: caps-height Applies to: ::first-letter pseudo element Inherited: no Percentages: N/A Media: visual Computed value: specified values (except for initial and inherit)",
        'values': {'<length>': "The alignment-point is on the end-edge of the inline box. Its position\nalong the end-edge is offset from the after-edge by the <length> value.\nA value of '0cm' makes the text-after-edge the alignment point.",
                          '<percentage>': "The computed value of the property is this percentage multiplied by the\ncomputed 'line-height' of the element. The alignment point is on the end-edge\nof the inline box and is offset from the after-edge by the computed value. A\nvalue of '0%' makes the text-after-edge the alignment point.",
                          'after-edge': "The alignment point is at the intersection of the end-edge of the element\nand the 'after-edge' of the extended inline box of the element. This may include or not the line-height of the element, depending on the line-stacking-strategy.",
                          'alphabetic': "The alignment point is at the intersection of the end-edge of the element\nand the 'alphabetic' baseline of the element.",
                          'central': "The alignment point is at the intersection of the end-edge of the element\nand the 'central' baseline of the element.",
                          'hanging': "The alignment point is at the intersection of the end-edge of the element\nand the 'hanging' baseline of the element.",
                          'ideographic': "The alignment point is at the intersection of the end-edge of the element\nand the 'ideographic' baseline of the element.",
                          'mathematical': "The alignment point is at the intersection of the end-edge of the element\nand the 'mathematical' baseline of the element.",
                          'middle': "The alignment point is at the intersection of the end-edge of the element\nand the 'middle' baseline of the element.",
                          'text-after-edge': "The alignment point is at the intersection of the end-edge of the element\nand the 'text-after-edge' baseline of the element."}},

    'drop-initial-before-adjust':
{'description': "The 'drop-initial-before-adjust' property\nsets the alignment point of the drop initial for the secondary connection point.\nThis property is only effective is the value of the 'drop-initial-size' property is 'auto'. Possible\nvalues: 6. Properties index",
        'values': {'<length>': "The alignment-point is on the end-edge of the inline box. Its position\nalong the end-edge is offset from the text-before-edge by the <length>\nvalue. A value of '0cm' makes the text-before-edge the alignment point.",
                          '<percentage>': "The computed value of the property is this percentage multiplied by the\ncomputed 'line-height' of the element. The alignment point is on the end-edge\nof the inline box and is offset from the text-before-edge by the computed\nvalue. A value of '0%' makes the text-before-edge the alignment point.",
                          'before-edge': "The alignment point is at the intersection of the end-edge of the element\nand the 'before-edge' of the extended inline box of the element. This may include or not the line-height of the element, depending on the line-stacking-strategy.",
                          'central': "The alignment point is at the intersection of the end-edge of the element\nand the 'central' baseline of the element.",
                          'hanging': "The alignment point is at the intersection of the end-edge of the element\nand the 'hanging' baseline of the element.",
                          'mathematical': "The alignment point is at the intersection of the end-edge of the element\nand the 'mathematical' baseline of the element.",
                          'middle': "The alignment point is at the intersection of the end-edge of the element\nand the 'middle' baseline of the element.",
                          'text-before-edge': "The alignment point is at the intersection of the end-edge of the element\nand the 'text-before-edge' baseline of the element."}},

    'drop-initial-before-align':
{'description': "The 'drop-initial-before-align' property\ndetermines which alignment line within the initial line box is used at\nthe secondary connection point with the initial letter box. This property is\nonly effective is the value of the 'drop-initial-size' property is 'auto'. Possible\nvalues: Name: drop-initial-before-adjust Value: before-edge | text-before-edge | central | middle | hanging |\nmathematical | <percentage> | <length> Initial: text-before-edge Applies to: ::first-letter pseudo element Inherited: no Percentages: refer to combined line height size as provided by drop-initial-value Media: visual Computed value: specified values (except for initial and inherit)",
        'values': {'<alignment-baseline>': "The values are the same as the 'alignment-baseline' property values.",
                          'caps-height': 'The caps-height alignment line is used.'}},

    'drop-initial-size':
{'description': "The 'drop-initial-size' property controls the partial\nsinking of the initial letter. Using any other value than 'auto' removes the\nsecondary connection line constraint. Possible values: 5.4. Aligning drop initial: the 'drop-initial-before-align', 'drop-initial-before-adjust', 'drop-initial-after-align'and'drop-initial-after-adjust' properties Name: drop-initial-after-align Value: <'alignment-baseline'> Initial: baseline Applies to: ::first-letter pseudo element Inherited: no Percentages: N/A Media: visual Computed value: specified values (except for initial and inherit)",
        'values': {'<length>': 'The drop initial letter is sized using the length value.',
                          '<line>': 'The drop initial letter is sized using the combined line height of the nth\nlines (as determined by the line value). The letter may be stretched on one\ndimension if the line height of each line is variable to avoid circular\nissues.',
                          '<percentage>': "The drop initial letter is sized relatively to the combined line height of\nthe n lines determined by the 'drop-initial-value' property value.",
                          'auto': 'The drop initial letter is sized according to the constraints created by the\nthe ink filling strategy and the two connection lines.'}},

    'drop-initial-value':
{'description': "The 'drop-initial-value' property is the basic\nproperty that activates a drop-initial effect. By providing a value different than\n'initial or '1', the primary connection point is moved after the initial line.\nPossible values: Name: drop-initial-size Value: auto | <line> | <length> | <percentage> Initial: auto Applies to: ::first-letter pseudo element Inherited: no Percentages: refer to combined line height size as provided by drop-initial-value Media: visual Computed value: specified values (except for initial and inherit)",
        'values': {'<integer>': 'The drop initial letter is sunken to the nth line (as determined by the\ninteger value).',
                          'initial': 'The drop initial letter is aligned on the initial line'}},

    'fit':
{'description': "The 'fit' property gives a hint for how to scale a replaced element if neither its 'width' nor its 'height' property is 'auto'. Not all replaced objects can be scaled, but images typically can.",
        'values': {'fill': "Scale the object's height and width independently so that the content just touches all edges of the containing box.",
                          'hidden': 'Do not scale the object.',
                          'meet': "Make the object as large as possible with its width <= 'width' and height <= 'height', while preserving its aspect ratio. Position the object as for the 'hidden' value.",
                          'slice': "Make the object as small as possible with its width >= 'width' and height >= 'height', while preserving its aspect ratio. Position the object as for the 'hidden' value."}},

    'fit-position':
{'description': "The 'fit' property gives a hint for how to scale a replaced element if neither its 'width' nor its 'height' property is 'auto'. Not all replaced objects can be scaled, but images typically can.",
        'values': {'fill': "Scale the object's height and width independently so that the content just touches all edges of the containing box.",
                          'hidden': 'Do not scale the object.',
                          'meet': "Make the object as large as possible with its width <= 'width' and height <= 'height', while preserving its aspect ratio. Position the object as for the 'hidden' value.",
                          'slice': "Make the object as small as possible with its width >= 'width' and height >= 'height', while preserving its aspect ratio. Position the object as for the 'hidden' value."}},

    'float-offset':
{'description': 'This property pushes floated elements in the opposite direction of the where they have been floated with \'float\'. If one value is specified, it is the horizontal offset. If two values are specified, the first is the horizontal and the second is the vertical offset. If an element has only been floated horizontally (e.g., by setting \' float: right \'), this property will only offset the float horizontally, even if a vertical value also has been specified. Likewise, if an element has only been floated vertically, this property will only offset the float vertically. If an element has been floated both horizontally and vertically, this property will offset both horizontally and vertically. If no vertical value has been specified, the vertical offset is set to zero. If the \'gr\' unit or percentage unit is used, it means that the middle of the float should be aligned with the specified grid line (or portion thereof). If another unit is used, it means that the float is pushed a distance equal to the specified length.\'float-offset\' is a good concept for moving a float into the right position. For completeness it should apply to absolute positioning as well. We should reuse existing naming conventions already in place for abspos elements (e.g., \'offset-left, \'right\', or call it \' shift left, \'shift right\' etc.). This code serves as the base document for the examples of this section: <html>\n<style>\ndiv { column-width: 15em; column-gap: 2em; /* shown in red below */ column-rule: thin solid black; /* shown in black below */ padding: 1em; /* shown in blue below */\n}\nimg { display: block; /* shown in dark gray below */\n}\n</style>\n<body>\n<div>\nLorem ipsum dolor sit amet. Nam at jus.\n<img src="foo"/>\nSed imp er di et ris. Cur abi tur et sapen.\n...\n</div>\n</body>\n</html> This code can be rendered as: Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. If this code is added to the base document: img { float: right } it may be rendered as: Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. This code floats images to the bottom of their containing block and sets the width to be that of the column: img { float: bottom; width: 1gr;\n} The column box is the containing block for floats, so if an image naturally appears in the first column it will float to its bottom: Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. This code floats figures to the top of the multi-column element. div.figure { float: top right multicol; width: 1gr } The \'1gr\' value on \'width\' is equal to the width of the containing block. Here is a possible rendering: Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. In this code, the \'float\' property floats the element to the top left of the multi-column element, while the \'float-offset\' property pushes it to the right so that it ends up in the column next to it: div.quote { float: top left multicol; float-offset: 2.5gr; width: 1gr } Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Assuming a three-column layout, the same rendering can be achieved by floating the element to the right instead: div.quote { float: top right multicol; float-offset: 2gr; width: 1gr }This code serves as the base document for the examples of this section: <html>\n<style>\ndiv { column-width: 15em; column-gap: 2em; /* shown in red below */ column-rule: thin solid black; /* shown in black below */ padding: 1em; /* shown in blue below */\n}\nimg { display: block; /* shown in dark gray below */\n}\n</style>\n<body>\n<div>\nLorem ipsum dolor sit amet. Nam at jus.\n<img src="foo"/>\nSed imp er di et ris. Cur abi tur et sapen.\n...\n</div>\n</body>\n</html>This code can be rendered as: Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. If this code is added to the base document: img { float: right }it may be rendered as: Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. This code floats images to the bottom of their containing block and sets the width to be that of the column: img { float: bottom; width: 1gr;\n}The column box is the containing block for floats, so if an image naturally appears in the first column it will float to its bottom: Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. This code floats figures to the top of the multi-column element. div.figure { float: top right multicol; width: 1gr }The \'1gr\' value on \'width\' is equal to the width of the containing block. Here is a possible rendering: Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. In this code, the \'float\' property floats the element to the top left of the multi-column element, while the \'float-offset\' property pushes it to the right so that it ends up in the column next to it: div.quote { float: top left multicol; float-offset: 2.5gr; width: 1gr } Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Assuming a three-column layout, the same rendering can be achieved by floating the element to the right instead: div.quote { float: top right multicol; float-offset: 2gr; width: 1gr }The floated element will never be pushed outside the content edges of the multicol element due to \'float-offset\'. img { float: top right multicol; width: 3gr;\n} The code above floats the element to the top right of the multi-column element. Further, it sets the width of images to the width of two columns plus the gap between them. Here is a possible rendering. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. img { float: top right multicol; width: 2gr;\n} The code above floats the element to the top right of the multi-column element. Further, it sets the width of the image to the width of one column plus one column gap. Here is a possible rendering. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. img { float: top right multicol; width: 1.5gr;\n} The code above floats the element to the top right of the multi-column element. Further, it sets the width of the image to the width of one column plus half the column gap. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. img { float: top left multicol; float-offset: 1.5gr 50%; width: 8em;\n} The first rule in the code above floats images to the top left of the multi-column element. The second rule pushes the float in the opposite directions: to the right and downwards. The horizontal component (\' 1.5gr \') means that the horizontal middle of the element should be in the middle of the gap between the left-most column and the one next to it. Vertically, element should be in the middle of the column. Here is a possible rendering: Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Consider this code: img { float: top left multicol; float-offset: 1.25gr 50%; width: 6em;\n} The only difference between this and the previous example is the horizontal value on \'float-offset\'. The value \' 1.25gr \' means that a point 25% into the image in the inline direction will be aligned with a point 25% into the column gap. Here is a possible rendering: Lorem ipsum dolor sit amet. Nam at jus. Sed imper di et ris. Cur abi tur et sapen. Fusce sed ligula a sic turpis. Lorem ipsum dolor sit amet. Namat jus. Sed imper di et ris curit. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. 15. Conformance User agents that support hyphenation and support this specification must a 16. Appendix A: Default style sheetThe code above floats the element to the top right of the multi-column element. Further, it sets the width of images to the width of two columns plus the gap between them. Here is a possible rendering. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. The code above floats the element to the top right of the multi-column element. Further, it sets the width of the image to the width of one column plus one column gap. Here is a possible rendering. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. The code above floats the element to the top right of the multi-column element. Further, it sets the width of the image to the width of one column plus half the column gap. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. The first rule in the code above floats images to the top left of the multi-column element. The second rule pushes the float in the opposite directions: to the right and downwards. The horizontal component (\' 1.5gr \') means that the horizontal middle of the element should be in the middle of the gap between the left-most column and the one next to it. Vertically, element should be in the middle of the column. Here is a possible rendering: Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Consider this code: img { float: top left multicol; float-offset: 1.25gr 50%; width: 6em;\n}The only difference between this and the previous example is the horizontal value on \'float-offset\'. The value \' 1.25gr \' means that a point 25% into the image in the inline direction will be aligned with a point 25% into the column gap. Here is a possible rendering: Lorem ipsum dolor sit amet. Nam at jus. Sed imper di et ris. Cur abi tur et sapen. Fusce sed ligula a sic turpis. Lorem ipsum dolor sit amet. Namat jus. Sed imper di et ris curit. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imper di et ris. Cur abi tur et sapen. Fusce sed ligula a sic turpis. Lorem ipsum dolor sit amet. Namat jus. Sed imper di et ris curit. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Fusce sed ligula a turpis. Lorem ipsum dolor sit amet. Nam at jus. Sed imp er di et ris. Cur abi tur et sapen. Vivamus a metus. Aenean at risus pharetra ante luctu feugiat quis enim. Cum sociis natoque penatibus et magni.',
        'values': {}},

    'font-size-adjust':
{'description': 'For any given font size, the apparent size and legibility of text varies across fonts. For scripts such as Latin or Cyrillic that distinguish between upper and lowercase letters, the relative height of lowercase letters compared to their uppercase counterparts is a determining factor of legibility. This is commonly referred to as the aspect value. Precisely defined, it is equal to the x-height of a font divided by the font size. In situations where font fallback occurs, fallback fonts may not share the same aspect ratio as the desired font family and will thus appear less readable. The font-size-adjust property is a way to preserve the readability of text when font fallback occurs. It does this by adjusting the font-size so that the x-height is the same irregardless of the font used. The style defined below defines Verdana as the desired font family, but if Verdana is not available Futura or Times will be used. p { font-family: Verdana, Futura, Times; } <p>Lorem ipsum dolor sit amet,...</p> Verdana has a relatively high aspect ratio, lowercase letters are relatively tall compared to uppercase letters, so at small sizes text appears legible. Times has a lower aspect ratio and so if fallback occurs, the text will be less legible at small sizes than Verdana. The style defined below defines Verdana as the desired font family, but if Verdana is not available Futura or Times will be used. Verdana has a relatively high aspect ratio, lowercase letters are relatively tall compared to uppercase letters, so at small sizes text appears legible. Times has a lower aspect ratio and so if fallback occurs, the text will be less legible at small sizes than Verdana. How text rendered in each of these fonts compares is shown below, the columns show text rendered in Verdana, Futura and Times. The same font-size value is used across cells within each row and red lines are included to show the differences in x-height. In the upper half each row is rendered in the same font-size value. The same is true for the lower half but in this half the font-size-adjust property is also set so that the actual font size is adjusted to perserve the x-height across each row. Note how small text remains relatively legible across each row in the lower half. Text with and without the use of font-size-adjustText with and without the use of font-size-adjustThis property allows authors to specify an aspect value for an element that will effectively preserve the x-height of the first choice font, whether it is substituted or not. Values have the following meanings:',
        'values': {'<number>': "Specifies the aspect value used in the calculation below to calculate the adjusted font size: c = ( a / a' ) s where: s = font-size value\na = aspect value as specified by the font-size-adjust property\na' = aspect value of actual font\nc = adjusted font-size to use This value applies to any font that is selected but in typical usage it should be based on the aspect value of the first font in the font-family list. If this is specified accurately, the (a/a') term in the formula above is effectively 1 for the first font and no adjustment occurs. If the value is specified inaccurately, text rendered using the first font in the family list will display differently in older user agents that don't support font-size-adjust.",
                          'none': "Do not preserve the font's x-height."}},

    'font-stretch':
{'description': "Sets a normal, condensed, or expanded face from a font family. When a face does not exist for a given width, normal or condensed values map to a narrower face, otherwise a wider face. Conversely, expanded values map to a wider face, otherwise a narrower face.",
        'values': {'ultra-condensed': 'Specifies a font face that is the most condensed from normal.',
                          'extra-condensed': 'Specifies a font face that is very condensed from normal.',
                          'condensed': 'Specifies a font face that is the condensed from normal.',
                          'semi-condensed': 'Specifies a font face that is slighly more condensed from normal.',
                          'semi-expanded': 'Specifies a font face that is slighly more expanded from normal.',
                          'expanded': 'Specifies a font face that is the expanded from normal.',
                          'extra-expanded': 'Specifies a font face that is very expanded from normal.',
                          'ultra-expanded': 'Specifies a font face that is the most expanded from normal.',
                          'narrower': 'Specifies a font face that is more condensed than normal.',
                          'wider': 'Specifies a font face that is more expanded than normal.'}},

    'grid-columns':
{'description': 'Space for each column or row of the grid can be defined as Length. Note that gr unit can also be used here (it refers to grid of the containing block) Percentage of containing block height and width Relative length (as defined in multi-length type in [HTML401] {{!HTML401}} ): A relative length has the form "i*", where "i" is an integer. When allotting space among elements competing for that space, user agents allot pixel and percentage lengths first, then divide up remaining available space among relative lengths. Each relative length receives a portion of the available space that is proportional to the integer preceding the "*". The value "*" is equivalent to "1*". Thus, if 60 pixels of space are available after the user agent allots pixel and percentage space, and the competing relative lengths are 1*, 2*, and 3*, the 1* will be allotted 10 pixels, the 2* will be allotted 20 pixels, and the 3* will be allotted 30 pixels. This definition is taken directly from HTML4.01. But it doesn\'t have to be exactly same. The number doesn\'t have to be integer. And maybe the number should be required for consistency with other units. A relative length has the form "i*", where "i" is an integer. When allotting space among elements competing for that space, user agents allot pixel and percentage lengths first, then divide up remaining available space among relative lengths. Each relative length receives a portion of the available space that is proportional to the integer preceding the "*". The value "*" is equivalent to "1*". Thus, if 60 pixels of space are available after the user agent allots pixel and percentage space, and the competing relative lengths are 1*, 2*, and 3*, the 1* will be allotted 10 pixels, the 2* will be allotted 20 pixels, and the 3* will be allotted 30 pixels. This definition is taken directly from HTML4.01. But it doesn\'t have to be exactly same. The number doesn\'t have to be integer. And maybe the number should be required for consistency with other units. For example this rule div { grid-columns: 50% * * 4em } adds one grid line in the middle of containing block, another one 4em from the right another one in the middle of remaining spaceAlso, grid lines can be defined in repeating groups. A group is enclosed in parentheses and optionally specifies a maximum number of repetitions in square brackets. Nested repeating groups are not allowed. For example this rule div { grid-rows: 4em (0.25em 1em); } defines a header row of 4em adds as many additional rows as necessary, alternating heights of 0.25em and 1em. For another example this rule div { grid-columns: * (1em *)[2]; }defines 3 columns of equal widths with 1em gaps, which matches a multi-column layout defined as div { column-count: 3; }(assuming 1em is the default value of column gap). 4.2. Natural grid',
        'values': {}},

    'grid-rows':
{'description': 'Space for each column or row of the grid can be defined as Length. Note that gr unit can also be used here (it refers to grid of the containing block) Percentage of containing block height and width Relative length (as defined in multi-length type in [HTML401] {{!HTML401}} ): A relative length has the form "i*", where "i" is an integer. When allotting space among elements competing for that space, user agents allot pixel and percentage lengths first, then divide up remaining available space among relative lengths. Each relative length receives a portion of the available space that is proportional to the integer preceding the "*". The value "*" is equivalent to "1*". Thus, if 60 pixels of space are available after the user agent allots pixel and percentage space, and the competing relative lengths are 1*, 2*, and 3*, the 1* will be allotted 10 pixels, the 2* will be allotted 20 pixels, and the 3* will be allotted 30 pixels. This definition is taken directly from HTML4.01. But it doesn\'t have to be exactly same. The number doesn\'t have to be integer. And maybe the number should be required for consistency with other units. A relative length has the form "i*", where "i" is an integer. When allotting space among elements competing for that space, user agents allot pixel and percentage lengths first, then divide up remaining available space among relative lengths. Each relative length receives a portion of the available space that is proportional to the integer preceding the "*". The value "*" is equivalent to "1*". Thus, if 60 pixels of space are available after the user agent allots pixel and percentage space, and the competing relative lengths are 1*, 2*, and 3*, the 1* will be allotted 10 pixels, the 2* will be allotted 20 pixels, and the 3* will be allotted 30 pixels. This definition is taken directly from HTML4.01. But it doesn\'t have to be exactly same. The number doesn\'t have to be integer. And maybe the number should be required for consistency with other units. For example this rule div { grid-columns: 50% * * 4em } adds one grid line in the middle of containing block, another one 4em from the right another one in the middle of remaining spaceAlso, grid lines can be defined in repeating groups. A group is enclosed in parentheses and optionally specifies a maximum number of repetitions in square brackets. Nested repeating groups are not allowed. For example this rule div { grid-rows: 4em (0.25em 1em); } defines a header row of 4em adds as many additional rows as necessary, alternating heights of 0.25em and 1em. For another example this rule div { grid-columns: * (1em *)[2]; }defines 3 columns of equal widths with 1em gaps, which matches a multi-column layout defined as div { column-count: 3; }(assuming 1em is the default value of column gap). 4.2. Natural grid',
        'values': {}},

    'hanging-punctuation':
{'description': 'This property determines whether a punctuation mark, if one is present, may be placed outside the line box at the start or at the end of a full line of text. If a justified line can fit the punctuation will it expand to push it outside the content area? No. What if the line ends in multiple punctuation marks? Which punctuation marks are affected? Values have the following meanings:',
        'values': {'end': 'Punctuation may hang outside the end edge of the last line.',
                          'end-edge': 'Punctuation may hang outside the end edge of all lines.',
                          'start': 'Punctuation may hang outside the start edge of the first line.'}},

    'hyphenate-after':
{'description': 'This property specifies the minimum number of characters in a hyphenated word after the hyphenation character. The \'auto\' value means that the UA chooses a value that adapts to the current layout. Unless the UA is able to calculate a better value, it is suggested that \'auto\' means 2. Name: hyphenate-lines Value: no-limit | <integer> Initial: no-limit Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified valueThis property indicates the maximum number of successive hyphenated lines in an element. In some cases, user agents may not be able to honor the specified value. The \'no-limit\' value means that there is no limit. Name: hyphenate-character Value: auto | <string> Initial: auto Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified valueThis property specifies a string that is shown when a hyphenate-break occurs. The \'auto\' value means that the user agent should find an appropriate value. <p class=issue>Which character is it, "minus hyphen" or U+2010? In Latin scripts, the hyphen character (U+2010) is often used to indicate that a word has been split. Normally, it will not be necessary to set it explicitly. However, this can easily be done: article { hyphenate-character: "\\2010" } <p class=issue>XSL uses a different list of <a href="http://www.w3.org/TR/2006/CR-xsl11-20060220/#common-hyphenation-properties">properties</a>. Reuse of these properties has been considered. 7. New counter styles 7.1. The \'super-decimal\' list-style-typeIn Latin scripts, the hyphen character (U+2010) is often used to indicate that a word has been split. Normally, it will not be necessary to set it explicitly. However, this can easily be done: article { hyphenate-character: "\\2010" }',
        'values': {}},

    'hyphenate-before':
{'description': 'This property specifies the minimum number of characters in a hyphenated word before the hyphenation character. The \'auto\' value means that the UA chooses a value that adapts to the current layout. Unless the UA is able to calculate a better value, it is suggested that \'auto\' means 2. Name: hyphenate-after Value: <integer> | auto Initial: auto Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified valueThis property specifies the minimum number of characters in a hyphenated word after the hyphenation character. The \'auto\' value means that the UA chooses a value that adapts to the current layout. Unless the UA is able to calculate a better value, it is suggested that \'auto\' means 2. Name: hyphenate-lines Value: no-limit | <integer> Initial: no-limit Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified valueThis property indicates the maximum number of successive hyphenated lines in an element. In some cases, user agents may not be able to honor the specified value. The \'no-limit\' value means that there is no limit. Name: hyphenate-character Value: auto | <string> Initial: auto Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified valueThis property specifies a string that is shown when a hyphenate-break occurs. The \'auto\' value means that the user agent should find an appropriate value. <p class=issue>Which character is it, "minus hyphen" or U+2010? In Latin scripts, the hyphen character (U+2010) is often used to indicate that a word has been split. Normally, it will not be necessary to set it explicitly. However, this can easily be done: article { hyphenate-character: "\\2010" } <p class=issue>XSL uses a different list of <a href="http://www.w3.org/TR/2006/CR-xsl11-20060220/#common-hyphenation-properties">properties</a>. Reuse of these properties has been considered. 7. New counter styles 7.1. The \'super-decimal\' list-style-typeIn Latin scripts, the hyphen character (U+2010) is often used to indicate that a word has been split. Normally, it will not be necessary to set it explicitly. However, this can easily be done: article { hyphenate-character: "\\2010" }',
        'values': {}},

    'hyphenate-character':
{'description': 'This property specifies a string that is shown when a hyphenate-break occurs. The \'auto\' value means that the user agent should find an appropriate value. <p class=issue>Which character is it, "minus hyphen" or U+2010? In Latin scripts, the hyphen character (U+2010) is often used to indicate that a word has been split. Normally, it will not be necessary to set it explicitly. However, this can easily be done: article { hyphenate-character: "\\2010" } <p class=issue>XSL uses a different list of <a href="http://www.w3.org/TR/2006/CR-xsl11-20060220/#common-hyphenation-properties">properties</a>. Reuse of these properties has been considered. 7. New counter styles 7.1. The \'super-decimal\' list-style-typeIn Latin scripts, the hyphen character (U+2010) is often used to indicate that a word has been split. Normally, it will not be necessary to set it explicitly. However, this can easily be done: article { hyphenate-character: "\\2010" }',
        'values': {}},

    'hyphenate-lines':
{'description': 'This property indicates the maximum number of successive hyphenated lines in an element. In some cases, user agents may not be able to honor the specified value. The \'no-limit\' value means that there is no limit. Name: hyphenate-character Value: auto | <string> Initial: auto Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified valueThis property specifies a string that is shown when a hyphenate-break occurs. The \'auto\' value means that the user agent should find an appropriate value. <p class=issue>Which character is it, "minus hyphen" or U+2010? In Latin scripts, the hyphen character (U+2010) is often used to indicate that a word has been split. Normally, it will not be necessary to set it explicitly. However, this can easily be done: article { hyphenate-character: "\\2010" } <p class=issue>XSL uses a different list of <a href="http://www.w3.org/TR/2006/CR-xsl11-20060220/#common-hyphenation-properties">properties</a>. Reuse of these properties has been considered. 7. New counter styles 7.1. The \'super-decimal\' list-style-typeIn Latin scripts, the hyphen character (U+2010) is often used to indicate that a word has been split. Normally, it will not be necessary to set it explicitly. However, this can easily be done: article { hyphenate-character: "\\2010" }',
        'values': {}},

    'hyphenate-resource':
{'description': 'This property specifies a comma-separated list of external resources that can help the UA determine hyphenation points. If more than one resource is specified, the UA should consult each resource until it finds one that is able to determine hyphenation points in a word. The \'none\' value indicates that no external resources are available. In any case, the UA can also use local resources not listed on this property. Often, finding the right hyphenate resource is based on knowing the language of the text. The lang attribute is recommended for encoding the language, and the corresponding selector is used in this example: :lang(dk) { hyphenate-resource: url("hyph_da_DK.dic"), url("hyph_da_NO.dic") } Name: hyphenate-before Value: <integer> | auto Initial: auto Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified valueOften, finding the right hyphenate resource is based on knowing the language of the text. The lang attribute is recommended for encoding the language, and the corresponding selector is used in this example: :lang(dk) { hyphenate-resource: url("hyph_da_DK.dic"), url("hyph_da_NO.dic") }This property specifies the minimum number of characters in a hyphenated word before the hyphenation character. The \'auto\' value means that the UA chooses a value that adapts to the current layout. Unless the UA is able to calculate a better value, it is suggested that \'auto\' means 2. Name: hyphenate-after Value: <integer> | auto Initial: auto Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified valueThis property specifies the minimum number of characters in a hyphenated word after the hyphenation character. The \'auto\' value means that the UA chooses a value that adapts to the current layout. Unless the UA is able to calculate a better value, it is suggested that \'auto\' means 2. Name: hyphenate-lines Value: no-limit | <integer> Initial: no-limit Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified valueThis property indicates the maximum number of successive hyphenated lines in an element. In some cases, user agents may not be able to honor the specified value. The \'no-limit\' value means that there is no limit. Name: hyphenate-character Value: auto | <string> Initial: auto Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified valueThis property specifies a string that is shown when a hyphenate-break occurs. The \'auto\' value means that the user agent should find an appropriate value. <p class=issue>Which character is it, "minus hyphen" or U+2010? In Latin scripts, the hyphen character (U+2010) is often used to indicate that a word has been split. Normally, it will not be necessary to set it explicitly. However, this can easily be done: article { hyphenate-character: "\\2010" } <p class=issue>XSL uses a different list of <a href="http://www.w3.org/TR/2006/CR-xsl11-20060220/#common-hyphenation-properties">properties</a>. Reuse of these properties has been considered. 7. New counter styles 7.1. The \'super-decimal\' list-style-typeIn Latin scripts, the hyphen character (U+2010) is often used to indicate that a word has been split. Normally, it will not be necessary to set it explicitly. However, this can easily be done: article { hyphenate-character: "\\2010" }',
        'values': {}},

    'hyphens':
{'description': 'Values are: Name: hyphenate-resource Value: none | <uri> [, <uri> ]* Initial: none Applies to: all elements Inherited: yes Percentages: N/A Media: visual Computed value: specified value',
        'values': {'auto': "Words can be broken at appropriate hyphenation points, as determined by characters inside the word, resources listed in 'hyphenate-resource', or other UA-dependent resources. Characters inside the word take priority over hyphenation points determined by other resources.",
                          'manual': 'Words are only broken at line breaks where there are characters inside the word that suggest line break opportunities. Characters can be explicit or conditional. In Unicode, U+00AD is a conditional "soft hyphen" and U+2010 is an explicit hyphen. Unicode Standard Annex #14 describes the role of soft hyphens in the Unicode Line breaking algorithm. In HTML, represents the soft hyphen character which suggests a line break opportunity. example.',
                          'none': 'Words are not broken at line breaks, even if characters inside the word suggest line break points.'}},

    'icon':
{'description': '',
        'values': {'url(': 'URIs (see [URI], [RFC1738] and [RFC1808] ) provide a way of identifying resources. The\n<uri> value(s) in this property refer to one or more icons in a comma\ndelimited list. The user agent loads the referenced icons one by one until it\nfinds one that it is able to render. This permits the usage of multiple\ndifferent icon formats for various platforms, and various media for that\nmatter.',
                          'auto': 'Use a default generic icon provided by the user agent.'}},

    'image-orientation':
{'description': "'image-orientation' specifies a rotation in the right or clockwise direction that a user agent applies to an image. In terms of the order of transformations, the image is first rotated, then sized, then positioned. Thus height and width properties apply to the rotated rather than the original image dimensions. Two values for the 'image-orientation' property apply to an image:",
        'values': {'<angle>': 'A positive value rotates the image to the right (in a clockwise direction) by the given number of degrees. Negative values rotate to the left or in a counter-clockwise direction. Specified values outside the range of ]-360, 360[ degrees are moduloed by 360 to produce a computed value within that range. User agents MUST support values which compute to 0, 90, 180, and 270 degrees. Support for other values is optional.',
                          'auto': 'The image will be set to the orientation of the page. That is, for a pixelated image consisting of rows and columns of pixels, a row is displayed across the width of the display surface and a column along the height.'}},

    'image-resolution':
{'description': 'Image resolution, as the term is used in this document, means pixels per physical length, e.g., pixels per inch. Some image formats can record information about the resolution of images. This information can be helpful when determining the actual size of the image in the formatting process. However, the information can also be wrong, in which case it should be ignored. The \'image-resolution\' and \'background-image-resolution\' properties are introduced to determine the correct resolution of images. Name: image-resolution Value: normal | [ from-image || <dpi> ] Initial: normal Applies to: replaced elements and background images? Inherited: yes Percentages: N/A Media: visual Computed value: as specified value (or, should it be only one value?)The values are: This rule specifies that the UA should use the image resolution found in the image itself. img { image-resolution: from-image } Using this rule, the image resolution is set to 300dpi and the resolution in the image, if any, is ignored. img { image-resolution: 300dpi } These rules both specify that the UA should use the image resolution found in the image itself. If the image has no resolution, the resolution is set to 300dpi. img { image-resolution: from-image 300dpi }\nimg { image-resolution: 300dpi from-image } <table class=propdef> <tr> <td><em>Name:</em> <td><dfn>image-resolution</dfn> <tr> <td><em>Value:</em> <td>normal | auto | <dpi> [, normal | <dpi> ]? <tr> <td><em>Initial:</em> <td>normal <tr> <td><em>Applies to:</em> <td>replaced elements <tr> <td><em>Inherited:</em> <td>yes <tr> <td><em>Percentages:</em> <td>N/A <tr> <td><em>Media:</em> <td>visual <tr> <td><em>Computed value:</em> <td>as specified value <span class=issue>(or, should it be only one value?)</span>\n</table> <p>This property accepts either a single value, or a comma-separated\nlist of two values. The values are: <dl>\n<dt>normal <dd>The resolution of the image is unknown, and UAs should not use the\nresolution found in the image. Instead, the image resolution will be\nfound by making image pixels equivalent to CSS pixels. <dt>auto <dd>The UA must look for the resolution in the image itself. If the image has no image resolution, the next value in the comma-separated list is evaluated. <dt><dpi> <dd>The value consists of a number with a \'<code class=property>dpi</code>\' unit identifier. The\nUA should use the specified resolution. </dl> <p>If, after evaluating the specified values, no image resolution has been determined, the UA should behave as if \'<code class=css>normal</code>\' had been specified. <div class="example">\n<p>This rule specifies that the UA should use the image resolution found in the image itself.\n<pre>\nimg { image-resolution: auto }\n</pre>\n</div> <div class="example">\n<p>This rule specifies that the UA should use the image resolution found in the image itself. If the image has no resolution, the resolution is set to 300dpi.\n<pre>\nimg { image-resolution: auto, 300dpi }\n</pre>\n</div> <div class="example">\n<p>Using this rule, the image resolution is set to 300dpi and the resolution in the image, if any, is ignored. <pre>\nimg { image-resolution: 300dpi }\n</pre>\n</div> <div class="issue">\n<p>Should there be a way of setting width, height, resolution on images that are referenced by a URL in the style sheet? E.g., <pre>\nbackground-image: url(image.png, width, height, resolution);\nbackground-image: image-url(image.png, width, height, resolution);\nbackground-image: image(url(image.png), width, height, resolution);\n</pre>\n</div> <table class=propdef> <tr> <td><em>Name:</em> <td><dfn>background-image-resolution</dfn> <tr> <td><em>Value:</em> <td>normal | auto | <dpi> [, normal | <dpi> ]? <tr> <td><em>Initial:</em> <td>normal <tr> <td><em>Applies to:</em> <td>replaced elements <tr> <td><em>Inherited:</em> <td>yes <tr> <td><em>Percentages:</em> <td>N/A <tr> <td><em>Media:</em> <td>visual <tr> <td><em>Computed value:</em> <td>as specified value <span class=issue>(or, should it be only one value?)</span>\n</table> <p class=issue>Introducing one new property in all places where an image can be loaded may not be a scalable solution. Therefore this property is at risk. <p>As \'<code class=property>image-resolution</code>\', except that it describes the resolution of the element\'s background image. 9. Page marks and bleed area',
        'values': {'<dpi>': "The value consists of a number with a 'dpi' unit identifier. The <dpi> value sets the resolution of the image. In combination with 'from-image', the specified dpi is only used if the image does not have a resolution.",
                          'from-image': "The UA must look for the resolution in the image itself. If the image does not have a resolution, the specified <dpi> value is used. If no <dpi> value is specified, the behavior is as if 'normal' had been specified.",
                          'normal': 'The resolution of the image is unknown, and UAs should not use the resolution found in the image. Instead, the image resolution will be found by converting the dimension of the image into CSS pixels.'}},

    'inline-box-align':
{'description': "The 'inline-box-align' property determines\nwhich line of a multi-line inline block align with the previous and next\ninline elements within a line. The alignment strategy for the inline lock\nitself (i.e. the definition of it alignment point and which parent baseline\nshould be used for the alignment) is determined by the inline block element\nbaseline alignment properties applicable to the line being used for the\nalignment. This property has no effect for single line inline block. Possible\nvalues: 5. Initial line and Drop initial 5.1. Initial line",
        'values': {'<integer>': 'Use nth line (as determined by the integer value) of the inline block\nelement for alignment purpose.',
                          'initial': 'Use the initial line of the inline block element for alignment purpose.',
                          'last': 'Use the last line of the inline block element for alignment purpose.'}},

    'line-stacking':
{'description': '', 'values': {}},

    'line-stacking-ruby':
{'description': "This property determines the line stacking method for block elements containing ruby annotation elements (element with 'display: ruby-text'or'display: ruby-text-container'). In all cases the ruby base elements (elements with 'display: ruby-base' or display: ruby-base-container') are considered for line stacking. Possible values:",
        'values': {'exclude-ruby': 'The ruby annotation elements are ignored for line stacking.',
                          'include-ruby': 'The ruby annotation elements are considered for line stacking.'}},

    'line-stacking-shift':
{'description': 'This property determines the line stacking method for block elements containing elements with base-shift. Possible values:',
        'values': {'consider-shifts': 'In determining the stack-height, include the adjusted top-edge and bottom-edge of any characters that have a baseline-shift.',
                          'disregard-shifts': 'In determining the stack-height, include the unshifted top-edge and bottom-edge of any characters that have a baseline-shift.'}},

    'line-stacking-strategy':
{'description': "This property determines the line stacking strategy for stacked line boxes within a containing block element. The term 'stack-height' is used in the context of this property description to indicate the block-progression advance for the line boxes. Possible values:",
        'values': {'block-line-height': "The stack-height is determined by the block element 'line-height' property value. The 'line-height' property value is ignored for inline elements. For alignment purpose, this case is similar to the minimum extended block progression dimension case (strut model). This is the only line-stacking strategy that may cause inline boxes within the line to bleed before and after the line box because the line box is not constrained by its inline boxes.",
                          'grid-height': "The stack-height is the smallest multiple of the block element 'line-height' computed value that can contain the block progression of all the inline elements on that line when those elements are properly aligned. The 'line-height' property value is ignored for inline elements.",
                          'inline-line-height': "The stack-height is the smallest value that contains the extended block progression dimension of all the inline elements on that line when those elements are properly aligned. Since the line spacing information is already included in the computation of the line box, these line boxes are simply stacked adjacent to one another in the formatted block to which they belong. The 'line-height' property value is taken into account for both the inline elements and the block elements. For inline elements, it defines the extended block progression dimension. For block elements, it defines the minimum extended block progression dimension.",
                          'max-height': "The stack-height is the smallest value that contains the block progression dimension of all the inline elements on that line when those elements are properly aligned. The 'line-height' property value is taken into account only for the block elements."}},

    'mark':
{'description': "The 'mark' property is a shorthand for setting 'mark-before'\nand 'mark-after'. If two values are given the first value is\n'mark-before' and the second is 'mark-after'. If only one value\nis given, it applies to both properties. The following two rules are equivalent:",
        'values': {}},

    'mark-after':
{'description': 'The mark properties allow named markers to be attached to the\naudio stream. For compatibility with SSML, this must conform to the xsd:token datatype as defined in XML Schema. Synthesis processors must do one\nor both of the following when encountering a mark:The mark properties have no audible effect on the speech\nand instead just serve to mark points in the stream. Values have the following meanings:',
        'values': {'<string>': 'A string to be used as the name of the mark.'}},

    'mark-before':
{'description': 'The mark properties allow named markers to be attached to the\naudio stream. For compatibility with SSML, this must conform to the xsd:token datatype as defined in XML Schema. Synthesis processors must do one\nor both of the following when encountering a mark:The mark properties have no audible effect on the speech\nand instead just serve to mark points in the stream. Values have the following meanings:',
        'values': {'<string>': 'A string to be used as the name of the mark.'}},

    'marquee-direction':
{'description': 'This property determines the initial direction in which the content moves if the marquee effect is used. \'Forward\' moves the text so that hidden text appears in the normal reading order, \'reverse\' does the opposite. The actual direction therefore depends on \'direction\' and \'overflow-style\' of the element, as follows: \'overflow-style\' \'direction\' \'forward\' \'reverse\' \'marquee-line\' \'ltr\' left right \'rtl\' right left \'marquee-block\' up downNote that \' marquee-style: alternate \' moves content in the opposite direction from this table on every other loop. Note that the \'direction\' property is often set by rules in the UA style sheet based on mark-up in the document, as recommended in CSS 2.1 [CSS21] {{!CSS21}} section 9.10 ("Text direction: the direction and unicode-bidi properties"). 9. The \'marquee-speed\' property Name: marquee-speed Value: slow | normal | fast Initial: normal Applies to: same as \'overflow\' Inherited: no Percentages: N/A Media: visual Computed value: as specified',
        'values': {}},

    'marquee-play-count':
{'description': "This property specifies how many times the content moves. UAs should restart the loop count every time the element turns from completely invisible into (fully or partially) visible. E.g., an element that is outside the viewport starts moving when it is scrolled into view. A UA may also take the visibility of the UA viewport itself into account, e.g., if the element is hidden behind a pop-up window or if the UA is iconified. If 'marquee-play-count' is different for different states of the element, e.g., ' p {marquee-play-count: 0} p:hover {marquee-play-count: infinite} ', the loop counter must be reset each time the element enters a state with a different computed value. For example, if the content of an li overflows under the following style rules, the content moves once when the li gets the focus or is hovered over. But, when it already has the focus when it is hovered over, the 'marquee-play-count' property doesn't change and thus the content doesn't move again: li {overflow: auto; overflow-style: marquee; marquee-play-count: 0}\nli:focus, li:hover {marquee-play-count: 1}For example, if the content of an li overflows under the following style rules, the content moves once when the li gets the focus or is hovered over. But, when it already has the focus when it is hovered over, the 'marquee-play-count' property doesn't change and thus the content doesn't move again: li {overflow: auto; overflow-style: marquee; marquee-play-count: 0}\nli:focus, li:hover {marquee-play-count: 1}If the specified value is 'infinite' or greater than 16, the UA may stop after 16 loops. 8. The 'marquee-direction' property Name: marquee-direction Value: forward | reverse Initial: forward Applies to: same as 'overflow' Inherited: yes Percentages: N/A Media: visual Computed value: as specified",
        'values': {}},

    'marquee-speed':
{'description': 'This property determines how fast the content scrolls. The actual speed depends on the UA and the type of content. But, for a given UA and a given element, the following must always be true: slow < normal < fast. 10. Conformance',
        'values': {}},

    'marquee-style':
{'description': "The values are: This figure shows one loop of ' marquee-style: scroll '. The initial state (1) has all content outside the box to the right. (2) shows an intermediate state. And the final state (3) has all content outside the box on the left. This figure shows one loop of ' marquee-style: slide '. The initial state (1) has all content outside the box to the right. (2) shows an intermediate state. And the final state (3) has the right edge of the content just inside the right edge of the box and some content overflowing to the left of the box. This figure show two loops of ' marquee-style: alternate '. The initial state (1) has the left edge of the content aligned to the left edge of the box and content overflowing on the right. (2) shows an intermediate state, while the content moves to the left. The end of the first loop is state (3). (4) is an intermediate state of the second loop. (5) is the end of the second loop and is equal to state (1).",
        'values': {'alternate': "Bounce back and forth. The following pseudo-code defines the behavior when the initial marquee direction is to the left (see 'marquee-direction'). The other directions are analogous. Set the element to clip the overflow to the left and to the right Create an anonymous box B around the content; set its 'width' so as to include all content and all overflow exactly Set r to false Set n to the value of 'marquee-play-count' While n != 0: If r, set 'margin-right' of B to 0 and 'margin-left'to'auto'; else, set 'margin-left' of B to 0 and 'margin-right'to'auto' If r, decrease 'margin-right' at constant speed (see 'marquee-speed') until 'margin-left' is 0; else, decrease 'margin-left' at constant speed until 'margin-right' is 0 Set r to !r (i.e., the next loop will move in the opposite direction) Decrease n by one",
                          'scroll': "Start completely off one side, scroll all the way across and completely off. The following pseudo-code defines the behavior when the marquee direction is to the left (see 'marquee-direction'). The other directions are analogous. Set the element to clip the overflow to the left and to the right Create an anonymous box B around the content; set its 'width' so as to include all content and all overflow exactly; set its 'margin-right'to'auto' Set n to the value of 'marquee-play-count' While n != 0: Set 'margin-left' of B to 100% (i.e., all contents is off to the right and thus invisible) Decrease 'margin-left' at constant speed (see 'marquee-speed') until 'margin-right' is 100% (i.e., all content is off to the left and thus invisible) Decrease n by one",
                          'slide': "Start completely off one side, scroll in, and stop as soon as no more content is off that side. The following pseudo-code defines the behavior when the marquee direction is to the left (see 'marquee-direction'). The other directions are analogous. Set the element to clip the overflow to the left and to the right Create an anonymous box B around the content; set its 'width' so as to include all content and all overflow exactly; set its 'margin-right'to'auto' Set n to the value of 'marquee-play-count' While n != 0: Set 'margin-left' of B to 100% (i.e., all contents is off to the right and thus invisible) Decrease 'margin-left' at constant speed (see 'marquee-speed') until 'margin-right' is 0 Decrease n by one"}},

    'move-to':
{'description': "The 'move-to' property causes the element or pseudo-element to be removed\nfrom the flow and reinserted at a later point in the document. The content is\nreinserted using the 'pending()' XXX link value of the 'content'\nproperty. This property applies to all elements as well as the '::before',\n'::after', and '::alternate' pseudo-elements. The '::alternate'\npseudo-element in fact exists exclusively for the purpose of being moved by\nthis property, e.g. in the creation of footnotes.",
        'values': {'<identifier>': "The element is not displayed at the current location, but at the next\noccurrence of 'pending(<identifier>)' (where the identifiers match),\nwith all other elements moved to that point, in document order. If at the end\naf the document (after the '::after' pseudo-elements of the root element)\nthere are outstanding elements, then they are all inserted in document order\nat that point.",
                          'here': "The element or pseudo-element is not moved. This value inhibits the\ncreation of '::alternate' pseudo-elements and any pseudo-elements that have\nsuch a pseudo-element as a superior.",
                          'normal': "For '::alternate' pseudo-elements, if the superior parent uses the\n'footnote' counter in its 'content' property then the computed value of\n'move-to'is'footnotes'. For '::alternate' pseudo-elements, if the superior parent uses the\n'endnote' counter in its 'content' property then the computed value of\n'move-to'is'endnotes'. For '::alternate' pseudo-elements, if the superior parent uses the\n'section-note' counter in its 'content' property then the computed value of\n'move-to'is'section-notes'. Otherwise the computed value of the move-to property is 'here'."}},

    'nav-down':
{'description': '',
        'values': {'<id>': "The <id> value consists of a ' # ' character followed by\nan identifier, similar to a fragment identifier in a URL. It indicates the\nelement to which the focus is navigated to in response to directional\nnavigation input respective to the specific property. If the <id> refers to the currently focused element, the\ndirectional navigation input respective to the nav- property is ignored\n- there is no need to refocus the same element.",
                          '<target-name>': 'The <target-name> parameter indicates the target frame for the\nfocus navigation. It is a string and it cannot start with the underscore "_"\ncharacter. If the specified target frame does not exist, the parameter will\nbe treated as the keyword \'current\', which means\nto simply use the frame that the element is in. The keyword \'root\' indicates that the user agent should target the\nfull window.',
                          'auto': 'The user agent automatically determines which element to navigate the\nfocus to in response to directional navigational input.'}},

    'nav-index':
{'description': 'The \'nav-index\' property is an input-method-neutral way of specifying the sequential\nnavigation order (also known as "tabbing order"). Name: nav-index Value: auto | <number> | inherit Initial: auto Applies to: all enabled elements Inherited: no Percentages: n/a Media: interactive Computed value: specified value.',
        'values': {'<number>': "The number (which is non-zero and positive) indicates the sequential\nnavigation order for the element. '1' means first.\nElements with the same nav-index value are navigated in document order when\nthat nav-index value is being navigated.",
                          'auto': "The element's sequential navigation order is assigned automatically by\nthe user agent."}},

    'nav-left':
{'description': '',
        'values': {'<id>': "The <id> value consists of a ' # ' character followed by\nan identifier, similar to a fragment identifier in a URL. It indicates the\nelement to which the focus is navigated to in response to directional\nnavigation input respective to the specific property. If the <id> refers to the currently focused element, the\ndirectional navigation input respective to the nav- property is ignored\n- there is no need to refocus the same element.",
                          '<target-name>': 'The <target-name> parameter indicates the target frame for the\nfocus navigation. It is a string and it cannot start with the underscore "_"\ncharacter. If the specified target frame does not exist, the parameter will\nbe treated as the keyword \'current\', which means\nto simply use the frame that the element is in. The keyword \'root\' indicates that the user agent should target the\nfull window.',
                          'auto': 'The user agent automatically determines which element to navigate the\nfocus to in response to directional navigational input.'}},

    'nav-right':
{'description': '',
        'values': {'<id>': "The <id> value consists of a ' # ' character followed by\nan identifier, similar to a fragment identifier in a URL. It indicates the\nelement to which the focus is navigated to in response to directional\nnavigation input respective to the specific property. If the <id> refers to the currently focused element, the\ndirectional navigation input respective to the nav- property is ignored\n- there is no need to refocus the same element.",
                          '<target-name>': 'The <target-name> parameter indicates the target frame for the\nfocus navigation. It is a string and it cannot start with the underscore "_"\ncharacter. If the specified target frame does not exist, the parameter will\nbe treated as the keyword \'current\', which means\nto simply use the frame that the element is in. The keyword \'root\' indicates that the user agent should target the\nfull window.',
                          'auto': 'The user agent automatically determines which element to navigate the\nfocus to in response to directional navigational input.'}},

    'nav-up':
{'description': '',
        'values': {'<id>': "The <id> value consists of a ' # ' character followed by\nan identifier, similar to a fragment identifier in a URL. It indicates the\nelement to which the focus is navigated to in response to directional\nnavigation input respective to the specific property. If the <id> refers to the currently focused element, the\ndirectional navigation input respective to the nav- property is ignored\n- there is no need to refocus the same element.",
                          '<target-name>': 'The <target-name> parameter indicates the target frame for the\nfocus navigation. It is a string and it cannot start with the underscore "_"\ncharacter. If the specified target frame does not exist, the parameter will\nbe treated as the keyword \'current\', which means\nto simply use the frame that the element is in. The keyword \'root\' indicates that the user agent should target the\nfull window.',
                          'auto': 'The user agent automatically determines which element to navigate the\nfocus to in response to directional navigational input.'}},

    'opacity':
{'description': '',
        'values': {'<alphavalue>': 'Syntactically a <number>. The uniform opacity setting to be applied across an entire object. Any values outside the range 0.0 (fully transparent) to 1.0 (fully opaque) will be clamped to this range. If the object is a container element, then the effect is as if the contents of the container element were blended against the current background using a mask where the value of each pixel of the mask is <alphavalue>.'}},

    'outline-offset':
{'description': "If the computed value of 'outline-offset' is anything other than 0,\nthen the outline is outset from the border edge by that amount. Example(s): For example, to leave 2 pixels of space between a focus outline and the\nelement that has the focus, or is active, the following rule can be used: :focus,:active { outline-offset: 2px } 9. ResizingExample(s):For example, to leave 2 pixels of space between a focus outline and the\nelement that has the focus, or is active, the following rule can be used:",
        'values': {}},

    'overflow-style':
{'description': "This property specifies the preferred scrolling method for elements that overflow (see the 'overflow' property.) If the UA does not support the specified value, it must act as if the value was 'auto'. 6. The 'marquee-style' property Name: marquee-style Value: scroll | slide | alternate Initial: scroll Applies to: same as 'overflow' Inherited: no Percentages: N/A Media: visual Computed value: as specified",
        'values': {'auto': 'The UA chooses the scrolling mechanism. Marquees and scrollbars are common mechanisms, but the UA may also use others.',
                          'marquee-block': 'This selects marquee as the vertical scrolling mechanism (i.e., for content that overflows above or below the box). The scrolling mechanism in the perpendicular direction is left to the UA, but should not be marquee.',
                          'marquee-line': 'This selects marquee as the horizontal scrolling mechanism (i.e., for content that overflows to the left or right). The scrolling mechanism in the perpendicular direction is left to the UA, but should not be marquee.'}},

    'overflow-x':
{'description': "These properties specify whether content is clipped when it overflows the element's content area. It affects the clipping of all of the element's content except any descendant elements (and their respective content and descendants) whose containing block is the viewport or an ancestor of the element. 'Overflow-x' determines clipping at the left and right edges, 'overflow-y' at the top and bottom edges.'Overflow' is a shorthand. If it has one keyword, it sets both 'overflow-x'and'overflow-y' to that keyword; if it has two, it sets 'overflow-x' to the first and 'overflow-y' to the second. Keywords have the following meanings:",
        'values': {'auto': "The behavior of the 'auto' value is UA-dependent, but should cause a scrolling mechanism to be provided for overflowing boxes.",
                          'hidden': 'This value indicates that the content is clipped and that no scrolling mechanism should be provided to view the content outside the clipping region.',
                          'no-content': "When the content doesn't fit in the content box, the whole content is hidden, as if ' visibility: hidden ' were specified. [This idea is due to Till Halbach <tillh@opera.com>, July 21, 2005]",
                          'no-display': "When the content doesn't fit in the content box, the whole box is removed, as if ' display: none ' were specified. [This idea is due to Till Halbach <tillh@opera.com>, July 21, 2005]",
                          'scroll': "This value indicates that the content is clipped and that if the user agent uses a scrolling mechanism that is visible on the screen (such as a scroll bar or a panner), that mechanism should be displayed for a box whether or not any of its content is clipped. This avoids any problem with scrollbars appearing and disappearing in a dynamic environment. When this value is specified and the target medium is 'print', overflowing content may be printed.",
                          'visible': 'This value indicates that content is not clipped, i.e., it may be rendered outside the content box.'}},

    'overflow-y':
{'description': "These properties specify whether content is clipped when it overflows the element's content area. It affects the clipping of all of the element's content except any descendant elements (and their respective content and descendants) whose containing block is the viewport or an ancestor of the element. 'Overflow-x' determines clipping at the left and right edges, 'overflow-y' at the top and bottom edges.'Overflow' is a shorthand. If it has one keyword, it sets both 'overflow-x'and'overflow-y' to that keyword; if it has two, it sets 'overflow-x' to the first and 'overflow-y' to the second. Keywords have the following meanings:",
        'values': {'auto': "The behavior of the 'auto' value is UA-dependent, but should cause a scrolling mechanism to be provided for overflowing boxes.",
                          'hidden': 'This value indicates that the content is clipped and that no scrolling mechanism should be provided to view the content outside the clipping region.',
                          'no-content': "When the content doesn't fit in the content box, the whole content is hidden, as if ' visibility: hidden ' were specified. [This idea is due to Till Halbach <tillh@opera.com>, July 21, 2005]",
                          'no-display': "When the content doesn't fit in the content box, the whole box is removed, as if ' display: none ' were specified. [This idea is due to Till Halbach <tillh@opera.com>, July 21, 2005]",
                          'scroll': "This value indicates that the content is clipped and that if the user agent uses a scrolling mechanism that is visible on the screen (such as a scroll bar or a panner), that mechanism should be displayed for a box whether or not any of its content is clipped. This avoids any problem with scrollbars appearing and disappearing in a dynamic environment. When this value is specified and the target medium is 'print', overflowing content may be printed.",
                          'visible': 'This value indicates that content is not clipped, i.e., it may be rendered outside the content box.'}},

    'page-policy':
{'description': "'page-policy' determines which page-based occurance of a given element is\napplied to a counter or string value: The following example places the chapter name in the header, specifying\nthat it is the value of the string at the end of the page. Example: @string chapter { page-policy: last; }\n@page { size: 21.0cm 29.7cm; /* A4 */ @top { text-align: right; vertical-align: center; content: string (chapter); }\n}",
        'values': {'first': 'Takes the value after the first state change in the counter or string\nduring processing of the page.',
                          'last': 'Takes the value following the final state change on the page.',
                          'start': 'Takes the value of the counter or string at the beginning of the page\n(before applying style to the elements of the page, but after applying it to\nthe @page context itself).'}},

    'phonemes':
{'description': 'This allows authors to specify a phonetic pronunciation for the\ntext contained by the corresponding element.',
        'values': {}},

    'presentation-level':
{'description': "This property sets the element's presentation level (EPL). The values have\nthe following meanings:",
        'values': {}},

    'punctuation-trim':
{'description': 'This property determines whether or not a fullwidth punctuation character should be trimmed (kerned) if it appears at the start or end of a line, or adjacent to another fullwidth punctuation character. Values are defined as follows:',
        'values': {'adjacent': 'Trim (kern) the blank half of fullwidth opening punctuation if its previous adjacent character is a fullwidth opening punctuation, fullwidth middle dot punctuation, fullwidth closing punctuation, or ideographic space (U+3000). Trim (kern) the blank half of fullwidth closing punctuation if its next adjacent character is a fullwidth closing punctuation, fullwidth middle dot punctuation, or ideographic space (U+3000).',
                          'end': 'Trim (kern) the blank half of fullwidth closing punctuation at the end of each line.',
                          'none': 'Do not trim or kern the blank half of fullwidth opening or closing punctuation glyphs.',
                          'start': 'Trim (kern) the blank half of fullwidth opening punctuation at the beginning of each line.'}},

    'rendering-intent':
{'description': "This property permits the specification of a color profile rendering\nintent other than the default. The behavior of values other than auto and inherit are defined by the International Color\nConsortium standard [ICC32]. 3.5. The '@color-profile'\nat-rule",
        'values': {'auto': 'This is the default behavior. The user agent determines the best intent\nbased on the content. For image content containing an embedded profile, it\nshould be assumed that the intent specified within the profile is the desired\nintent. Otherwise, the user agent should use the current profile (based on\nthe color-profile style) and force the\nintent, overriding any intent that may be stored in the profile itself.'}},

    'resize':
{'description': '',
        'values': {'both': 'The UA presents a bidirectional resizing mechanism to allow the user to\nadjust both the height and the width of the element.',
                          'horizontal': 'The UA presents a unidirectional horizontal resizing mechanism to allow\nthe user to adjust only the width of the element.',
                          'none': 'The UA does not present a resizing mechanism on the element, and the user\nis given no direct manipulation mechanism to resize the element.',
                          'vertical': 'The UA presents a unidirectional vertical resizing mechanism to allow the\nuser to adjust only the height of the element.'}},

    'rest':
{'description': "The 'rest' property is a shorthand for setting 'rest-before' and\n'rest-after'. If two values are given, the first value is 'rest-before'\nand the second is 'rest-after'. If only one value is given, it applies\nto both properties.",
        'values': {}},

    'rest-after':
{'description': "These properties specify a rest or prosodic boundary to be observed\nbefore (or after) speaking an element's content. Values have the following\nmeanings:",
        'values': {'<time>': 'Expresses the rest in absolute time units (seconds and milliseconds,\ne.g. "3s", "250ms"). Only positive values are allowed.',
                          'none': 'none, x-weak, weak, medium, strong, and x-strong. These values may be used to indicate the prosodic strength of\nthe break in speech output. The synthesis processor may insert a\nrest as part of its implementation of the prosodic break. The value\n"none" indicates that no prosodic break boundary should be output,\nand can be used to inhibit a prosodic break which the processor\nwould otherwise produce. The other values indicate monotonically\nnon-decreasing (conceptually increasing) break strength between words.\nThe stronger boundaries are typically accompanied by rests. "x-weak"\nand "x-strong" are mnemonics for "extra weak" and "extra strong",\nrespectively.'}},

    'rest-before':
{'description': "These properties specify a rest or prosodic boundary to be observed\nbefore (or after) speaking an element's content. Values have the following\nmeanings:",
        'values': {'<time>': 'Expresses the rest in absolute time units (seconds and milliseconds,\ne.g. "3s", "250ms"). Only positive values are allowed.',
                          'none': 'none, x-weak, weak, medium, strong, and x-strong. These values may be used to indicate the prosodic strength of\nthe break in speech output. The synthesis processor may insert a\nrest as part of its implementation of the prosodic break. The value\n"none" indicates that no prosodic break boundary should be output,\nand can be used to inhibit a prosodic break which the processor\nwould otherwise produce. The other values indicate monotonically\nnon-decreasing (conceptually increasing) break strength between words.\nThe stronger boundaries are typically accompanied by rests. "x-weak"\nand "x-strong" are mnemonics for "extra weak" and "extra strong",\nrespectively.'}},

    'rotation':
{'description': 'Should probably be in the extended Box module instead of here... Name: rotation Value: <angle> Initial: 0 Applies to: block-level elements, inline-table and inline-block Inherited: no Percentages: N/A Media: visual Computed value: 0deg <= angle < 360deg Name: rotation-point Value: <bg-position> Initial: 50% 50% Applies to: block-level elements Inherited: no Percentages: Width and height of border box Media: visual Computed value: for <length> the absolute value, otherwise a percentageThe value of \'rotation-point\' is a pair of values that defines a point as an offset from the top left border edge. Percentages refer to the width and height of the border box. Values may be negative.\'Rotation\' rotates a block-level element counterclockwise around the point given by \'rotation-point\'. The border, padding and content are rotated, and also any background that is not \'fixed\'. All static or relatively positioned child elements (and their static and relatively positioned children, recursively) are rotated along. But absolutely positioned and fixed descendant elements are not. Note that this means that rotation is relative. A child of a box that is rotated 45deg and that has a rotation of -45deg itself, actually ends up horizontal (but probably in a different location than when both rotations had been 0). Rotation doesn\'t affect parent or sibling elements, they are laid out as if the element\'s rotation was 0. Conceptually, the element is first laid out without any rotation, then any relative positioning is applied to it (see [CSS3POS] {{CSS3POS}} ) and finally any rotation. The rotation point is relative to the box after relative positioning. Note that, like relative positioning, rotation can thus cause an element\'s box to overlap other boxes. It is the author\'s responsibility to give the element wide enough margins if such overlapping is not desired. When a box is broken over several columns or pages, each of the boxes is rotated separately around its own rotation point. The computed value of \'rotation\' is the angle normalized to fall in 0deg <= angle < 360deg. The computed value or \'rotation-point\' is a pair in which any <length> is made absolute, keywords are replaced by percentages and percentages are left as specified. This example puts H1 elements upside down. It relies on the \'rotation-point\' having its default value of \' 50% 50% \'. H1 {rotation: 180deg} This example displays column headers in a table diagonally. It uses \'block-progression\' (see [CSS3TEXTLAYOUT] {{!CSS3TEXTLAYOUT}} ) to write the column headers vertically and applies \'rotation\' to rotate the headers 45 degrees to the left. A fairly wide padding is applied, to make sure the text of the headings doesn\'t overlap. thead th { block-progression: rl; padding: 0.5em 1em; rotation: 45deg; rotation-point: bottom left } Example of a table with rotated column headings. This example puts H1 elements upside down. It relies on the \'rotation-point\' having its default value of \' 50% 50% \'. This example displays column headers in a table diagonally. It uses \'block-progression\' (see [CSS3TEXTLAYOUT] {{!CSS3TEXTLAYOUT}} ) to write the column headers vertically and applies \'rotation\' to rotate the headers 45 degrees to the left. A fairly wide padding is applied, to make sure the text of the headings doesn\'t overlap. Example of a table with rotated column headings. In the table example, how are the borders rotated? Because the borders belong to two elements that are rotated individually. Dave Hyatt proposes to generalize the property and call it "transform" with a syntax and functionality like in SVG, i.e., a property that accepts a series of transformations (rotations, translations, arbitrary affine transformations). 14. Stacking contexts',
        'values': {}},

    'rotation-point':
{'description': 'Should probably be in the extended Box module instead of here... Name: rotation Value: <angle> Initial: 0 Applies to: block-level elements, inline-table and inline-block Inherited: no Percentages: N/A Media: visual Computed value: 0deg <= angle < 360deg Name: rotation-point Value: <bg-position> Initial: 50% 50% Applies to: block-level elements Inherited: no Percentages: Width and height of border box Media: visual Computed value: for <length> the absolute value, otherwise a percentageThe value of \'rotation-point\' is a pair of values that defines a point as an offset from the top left border edge. Percentages refer to the width and height of the border box. Values may be negative.\'Rotation\' rotates a block-level element counterclockwise around the point given by \'rotation-point\'. The border, padding and content are rotated, and also any background that is not \'fixed\'. All static or relatively positioned child elements (and their static and relatively positioned children, recursively) are rotated along. But absolutely positioned and fixed descendant elements are not. Note that this means that rotation is relative. A child of a box that is rotated 45deg and that has a rotation of -45deg itself, actually ends up horizontal (but probably in a different location than when both rotations had been 0). Rotation doesn\'t affect parent or sibling elements, they are laid out as if the element\'s rotation was 0. Conceptually, the element is first laid out without any rotation, then any relative positioning is applied to it (see [CSS3POS] {{CSS3POS}} ) and finally any rotation. The rotation point is relative to the box after relative positioning. Note that, like relative positioning, rotation can thus cause an element\'s box to overlap other boxes. It is the author\'s responsibility to give the element wide enough margins if such overlapping is not desired. When a box is broken over several columns or pages, each of the boxes is rotated separately around its own rotation point. The computed value of \'rotation\' is the angle normalized to fall in 0deg <= angle < 360deg. The computed value or \'rotation-point\' is a pair in which any <length> is made absolute, keywords are replaced by percentages and percentages are left as specified. This example puts H1 elements upside down. It relies on the \'rotation-point\' having its default value of \' 50% 50% \'. H1 {rotation: 180deg} This example displays column headers in a table diagonally. It uses \'block-progression\' (see [CSS3TEXTLAYOUT] {{!CSS3TEXTLAYOUT}} ) to write the column headers vertically and applies \'rotation\' to rotate the headers 45 degrees to the left. A fairly wide padding is applied, to make sure the text of the headings doesn\'t overlap. thead th { block-progression: rl; padding: 0.5em 1em; rotation: 45deg; rotation-point: bottom left } Example of a table with rotated column headings. This example puts H1 elements upside down. It relies on the \'rotation-point\' having its default value of \' 50% 50% \'. This example displays column headers in a table diagonally. It uses \'block-progression\' (see [CSS3TEXTLAYOUT] {{!CSS3TEXTLAYOUT}} ) to write the column headers vertically and applies \'rotation\' to rotate the headers 45 degrees to the left. A fairly wide padding is applied, to make sure the text of the headings doesn\'t overlap. Example of a table with rotated column headings. In the table example, how are the borders rotated? Because the borders belong to two elements that are rotated individually. Dave Hyatt proposes to generalize the property and call it "transform" with a syntax and functionality like in SVG, i.e., a property that accepts a series of transformations (rotations, translations, arbitrary affine transformations). 14. Stacking contexts',
        'values': {}},

    'ruby-align':
{'description': "This property can be used on any element to control the text alignment of\nthe ruby text and ruby base contents relative to each other. It applies to all\nthe ruby's in the element. For simple ruby, the alignment is applied to the\nruby child element whose content is shorter: either the rb element or the rt element [ RUBY ]. For complex ruby, the alignment is also applied to the\nruby child elements whose content is shorter: either the rb element and/or one or two rt elements for each related ruby text\nand ruby base element within the rtc and rbc element. Possible values:",
        'values': {'auto': "The user agent determines how the ruby contents are aligned. This is the initial value. The behavior recommended by [ JIS4051 ] is for a wide-cell ruby is to be aligned in the 'distribute-space' mode: Figure 4.2.1 : Wide-cell text in 'auto' ruby alignment is 'distribute-space' justified The recommended behavior for a narrow-cell glyph ruby is to be aligned in the 'center' mode. Figure 4.2.2 : Narrow-width ruby text in 'auto' ruby alignment is centered",
                          'center': 'The ruby text content is centered within the width of the base. If the length of the base is smaller than the length of the ruby text, then the base is centered within the width of the ruby text. Figure 4.2.4 : Center ruby alignment',
                          'distribute-letter': 'If the width of the ruby text is smaller than that of the base, then the ruby text contents are evenly distributed across the width of the base, with the first and last ruby text glyphs lining up with the corresponding first and last base glyphs. If the width of the ruby text is at least the width of the base, then the letters of the base are evenly distributed across the width of the ruby text. Figure 4.2.6 : Distribute-letter ruby alignment',
                          'distribute-space': 'If the width of the ruby text is smaller than that of the base, then the ruby text contents are evenly distributed across the width of the base, with a certain amount of white space preceding the first and following the last character in the ruby text. That amount of white space is normally equal to half the amount of inter-character space of the ruby text. If the width of the ruby text is at least the width of the base, then the same type of space distribution applies to the base. In other words, if the base is shorter than the ruby text, the base is distribute-space aligned. This type of alignment is sometimes referred to as the "1:2:1" alignment [ JIS4051 ]. Figure 4.2.7 : Distribute-space ruby alignment',
                          'left': 'The ruby text content is aligned with the start edge of the base. Figure 4.2.3 : Start ruby alignment',
                          'line-edge': "If the ruby text is not adjacent to a line edge, it is aligned as in 'auto'. If it is adjacent to a line edge, then it is still aligned as in auto, but the side of the ruby text that touches the end of the line is lined up with the corresponding edge of the base. This type of alignment is specified by [ JIS4051 ]. This type of alignment is relevant only to the scenario where the ruby text is longer than the ruby base. In the other scenarios, this is just 'auto'. Figure 4.2.8 : Line edge ruby alignment",
                          'right': 'The ruby text content is aligned with the end edge of the base. Figure 4.2.5 : End ruby alignment'}},

    'ruby-overhang':
{'description': 'This property determines whether, and on which side, ruby text is allowed\nto partially overhang any adjacent text in addition to its own base, when the\nruby text is wider than the ruby base. Note that ruby text is never allowed to\noverhang glyphs belonging to another ruby base. Also the user agent is free to assume\na maximum amount by which ruby text may overhang adjacent text. The user agent may use\nthe [ JIS4051 ] recommendation of using one ruby text character\nlength as the maximum overhang length. Possible values:',
        'values': {'auto': 'The ruby text can overhang text adjacent to the base on either side. [ JIS4051 ] specifies the categories of characters that ruby text can overhang. The user agent is free to follow the [ JIS4051 ] recommendation or specify its own classes of characters to overhang. This is the initial value. Figure 4.3.1 : Ruby overhanging adjacent text',
                          'end': 'The ruby text can overhang the text that follows it. That means, for example, that ruby can overhang text that is to the right of it in horizontal LTR layout, or it can overhang text that is below it in vertical-ideographic layout. Figure 4.3.3 : Ruby overhanging following text only',
                          'none': 'The ruby text cannot overhang any text adjacent to its base, only its own base. Figure 4.3.4 : Ruby not allowed to overhang adjacent text',
                          'start': 'The ruby text can overhang the text that precedes it. That means, for example, that ruby can overhang text that is to the left of it in horizontal LTR layout, or it can overhang text that is above it in vertical-ideographic layout. Figure 4.3.2 : Ruby overhanging preceding text only'}},

    'ruby-position':
{'description': 'This property is used by the parent of elements with display: ruby-text to\ncontrol the position of the ruby text with respect to its base. Such parents\nare typically either the ruby element itself (simple ruby) or the rtc element (complex ruby). This assures that all part of a rtc element will be displayed in the same position. Possible values:',
        'values': {'after': 'The ruby text appears after the base. This is a relatively rare setting used in ideographic East Asian writing systems, most easily found in educational text. Figure 4.1.4 : Bottom ruby in horizontal layout applied to Japanese text If the base appears in a vertical ideographic mode, the bottom ruby appears on the left side of the base and is rendered in the same layout mode as the base (i.e. vertical). Figure 4.1.5 : Bottom ruby in vertical ideographic layout applied to Japanese text',
                          'before': 'The ruby text appears before the base. This is the most common setting used in ideographic East Asian writing systems. This is the initial value. Figure 4.1.1 : Top ruby in horizontal layout applied to Japanese text If the base appears in a vertical-ideographic layout mode, the ruby appears on the right side of the base and is rendered in the same layout mode as the base (i.e. vertical-ideographic). Figure 4.1.2 : Top ruby in vertical ideographic layout applied to Japanese text Note the special case of traditional Chinese as used especially in Taiwan: ruby (made of Bopomofo glyphs) in that context can appear along the right side of the base glyph, as if the text were in vertical layout, but the bases themselves are rendered on a horizontal line, since the actual layout is horizontal: Figure 4.1.3 : " Bopomofo " ruby in traditional Chinese (ruby text shown in blue for clarity) in horizontal layout In order to achieve that effect, vertical-ideographic layout should be set on each individual ruby. That can be accomplished with the following simple CSS rule: ruby.bopomofo { writing-mode: tb-rl } Note: The Bopomofo transcription is written in the normal way as part of the ruby text. The user agent is responsible for ensuring the correct relative alignment and positioning of the glyphs, including those corresponding to the tone marks, when displaying as vertical ruby.',
                          'right': "The ruby text appears on the right of the base. Unlike 'before'and'after', this value is not relative to the text flow direction."}},

    'ruby-span':
{'description': 'This property controls the spanning behavior of annotation elements. Note: A XHTML user agent may also use the rbspan attribute to get the same effect. Possible values:',
        'values': {'attr': "attr(x). The value of attribute 'x' as a string value. The string value is evaluated as a <number> to determine the number of ruby base elements to be spanned by the annotation element. If the <number> is '0', it is replaced by '1'. The <number> is the computed value.",
                          'none': "No spanning. The computed value is '1'."}},

    'string-set':
{'description': 'The \'string-set\' property accepts a comma-separated list of named strings. Each named string is followed by a content list that specifies which text to copy into the named string. Whenever an element with value of \'string-set\' different from \'none\' is encountered, the named strings are assigned their respective value. For the \'string-set\' property, <content-list> expands to one or more of these values, in any order: <p class="issue">Should target-counter() and leader() also be allowed?</p>',
        'values': {'<content>': 'the \' content() \' function returns the content of elements and pseudo-elements. The functional notation accepts an optional argument: \' content() \' Without any arguments, the function returns the textual content of the element, not including the content of its ::before and ::after pseudo-element. The content of the element\'s descendants, including their respective ::before and ::after pseudo-elements, are included in the returned content. \' content(before) \' The function returns the textual content of the ::before pseudo-element the content of the element. \' content(after) \' The function returns the textual content of the ::after pseudo-element the content of the element. \' content(first-letter) \' The function returns the first letter of the content of the element. The definition of a letter is the same as for :first-letter pseudo-elements. The expected use for \' content(first-letter) \' is to create one-letter headers, e.g., in dictionaries. \' env() \' This function returns data from the local environment of the user at the time of formatting. The function accepts one of these keywords: env(url): returns the URL of the document env(date): returns the date on the user\'s system at the time of formatting env(time): returns the time on the user\'s system at the time of formatting env(date-time): returns the date and time on the user\'s system at the time of formatting Information about date and time is formatted according to the locale of the user\'s system. Or, should there be a way to specify the locale? Or should we simply format all in ISO format (e.g., 2010-03-30)? On many systems, preformatted strings in the user\'s locale can be found through the strftime function. The date, time and date-time strings can be found by using the "%x", "%X" and "%c" conversion strings, respectively. @page { @top-right { content: env(url) } @bottom-right { content: env(date-time) }\n}',
                          '<counter>': 'the counter() or counters() function, as per CSS 2.1 section 4.3.5',
                          '<string>': 'a string, e.g. "foo"'}},

    'target':
{'description': 'The \'target\' property is a shorthand property for setting the individual\ntarget properties (i.e., \'target-name\', \'target-new\'and\'target-position\')\nat the same place in the style sheet. Given a valid declaration, the \'target\' property first sets all the\nindividual target properties to their initial values, then assigns explicit\nvalues given in the declaration. <h2>The :link and :visited pseudo-classes</h2> == These are already described in CSS3 Selectors == <h2>The ??? property</h2> <p>An element may represent several links. The ??? property specifies which\nlink to use.</p>\n<pre>p[href] { link: attr(href) }</pre> == Editor thinks this is not developed enough of an idea to include here == <p>Primary and secondary links?</p> == perhaps an issue == <h2 id="profiles">Profiles</h2> <p>[This section explains what parts of this module belong in which\nprofiles.]</p> <p>We have at least 4 profiles: level 1, level 2, level 3 and full</p> == CSS3 Hyperlinks should not have any profiles. This should be all or nothing. == 4. Conformance',
        'values': {}},

    'target-name':
{'description': "The 'target-name' property defines the name of the target destination,\nincluding a few keywords for well known destinations. Name: target-name Value: current | root | parent | new | modal | <string> Initial: current Applies to: hyperlinks Inherited: no Percentages: N/A Media Group(s): interactive visual Computed value: specified value does not apply if 'target-style'is'auto'. In other cases theThe values mean the following: 3.3. The 'target-new'\nproperty",
        'values': {'<string>': "The target is displayed in the existing frame, window or tab of that\nname. If no such named destination exists, a new destination (see\n'target-new') is created with that name.",
                          'current': 'The name of the current frame, tab or window where the link resides. This\nvalue never causes a new destination to be created.',
                          'modal': "If 'target-style'is'frame', this value is treated as 'current'. Otherwise a A new modal window is temporarily created.",
                          'new': "If 'target-style'is'frame', this value is treated as 'current'. Otherwise a A new destination (see 'target-new') is always created.",
                          'parent': "The name of the parent of the current frame. If the current frame has no\nparent this value is treated as 'root'. This value never causes a new\ndestination to be created.",
                          'root': 'The name of the current tab (if there is one) or window. This value never\ncauses a new destination to be created.'}},

    'target-new':
{'description': "The 'target-new' property determines what new target destination (if any)\nis created. Name: target-new Value: window | tab | none Initial: window Applies to: hyperlinks Inherited: no Percentages: N/A Media Group(s): interactive visual Computed value: specified value If a user wanted to have new windows open in new tabs instead, she could\nuse the following user style sheet to do so: * { target-new: tab ! important } 3.4. The\n'target-position' property",
        'values': {'none': 'No new destination is created. The target is not displayed.',
                          'tab': 'The target is displayed in a new tab of an existing window.',
                          'window': 'The target is displayed in a new window.'}},

    'target-position':
{'description': "The 'target-position' property indicates where a new destination (if any)\nis created. Name: target-position Value: above | behind | front | back Initial: above Applies to: hyperlinks Inherited: no Percentages: N/A Media Group(s): interactive visual Computed value: specified value",
        'values': {'above': 'The new destination tab (window) is placed above the current tab (window)\nrespectively.',
                          'back': 'The new destination tab (window) is placed behind all other tabs\n(windows) respectively.',
                          'behind': 'The new destination tab (window) is placed behind the current tab\n(window) respectively.',
                          'front': 'The new destination tab (window) is placed above all other tabs (windows)\nrespectively.'}},

    'text-align-last':
{'description': "This property describes how the last line of a block or a line right before a forced line break is aligned when 'text-align' is set to 'justify'. Values have the same meaning as for 'text-align'.",
        'values': {}},

    'text-emphasis':
{'description': "East Asian documents use small symbols on top of each glyph to emphasize a run of text. For example:Accent emphasis (shown in blue for clarity) applied to Japanese textThis property applies emphasis formatting applied to text. Unlike 'text-decoration', emphasis marks can affect the line height. Values have the following meanings:",
        'values': {'accent': 'Draw calligraphic accent strokes as marks.',
                          'after': 'Draw marks below the text in horizontal layout, to the left in vertical layout.',
                          'before': 'Draw marks above the text in horizontal layout, to the right in vertical layout. This is the default position.',
                          'circle': 'Draw hollow circles as marks.',
                          'disc': 'Draw filled circles as marks.',
                          'dot': 'Draw calligraphic dots as marks.',
                          'none': 'No emphasis marks.'}},

    'text-height':
{'description': "The 'text-height' property determine the block-progression dimension of the text content area of an inline box. Possible values:",
        'values': {'auto': 'The block-progression dimension is based either on the em square determined by the element font-size property value or the cell-height (ascender + descender) related to the element font-size as chosen by the user agent.',
                          'font-size': 'The block-progression dimension is based on the em square as determined by the element font-size.',
                          'max-size': "The block-progression dimension is based on the maximum extents toward the before-edge and after-edge of the box obtained by considering all children elements located on the same line, ruby annotations (elements with 'display:ruby-text') and baseline shifted elements.",
                          'text-size': 'The block-progression dimension is based on the cell-height (ascender + descender) related to the element font-size.'}},

    'text-justify':
{'description': "This property selects the justification method used when 'text-align' is set to 'justify'. It takes the following values:",
        'values': {'auto': 'The UA determines the justification algorithm to follow, based on a balance between performance and adequate presentation quality.',
                          'distribute': 'Justification primarily changes spacing both at word separators and at grapheme cluster boundaries in all scripts except those in the connected and cursive groups.',
                          'inter-cluster': 'Justification primarily changes spacing at word separators and at grapheme cluster boundaries in cluster scripts.',
                          'inter-ideograph': 'Justification primarily changes spacing at word separators and at inter-graphemic boundaries in scripts that use no word spaces',
                          'inter-word': 'Justification primarily changes spacing at word separators',
                          'kashida': 'Justification primarily stretches Arabic and related scripts through the use of kashida or other calligraphic elongation.',
                          'tibetan': 'Justification primarily stretches spaces after shad if the line contains any and/or pads the end of the line with tsek marks if the line already ends in one.'}},

    'text-outline':
{'description': "This property specifies a text outline where the first length represents the outline's thickness and the second represents an optional blur radius. The outline never overlays the text itself. Its effect is the same as that obtained by applying text shadows in every radial direction, i.e. all text shadows whose offsets satisfy the equation x 2 + y 2 = thickness 2. The Timed-Text WG had suggestions for some keywords (text-outline: normal|heavy|light;) as well as a <length> thickness. Should these be added? How would they be defined? (Maybe use (thin|medium|thick) as in border-width ?)The blur radius is a length value that indicates the boundaries of the blur effect. The exact algorithm for computing the blur effect is not specified, but it is only applied to the outer edge of the outline. If the blur radius is not specified, it is equal to zero. Is a second blur radius needed for the inner edge? Or should the blur apply to both edges? Implementations may choose to ignore the blur radius when text outline is combined with a text shadow. A color value must be specified before or after the length values of the outline effect. The color value will be used as the color of the outline.",
        'values': {}},

    'text-wrap':
{'description': 'This property specifies the mode for text wrapping. Possible values:',
        'values': {'none': 'Lines may not break; text that does not fit within the block box overflows it.',
                          'normal': 'Lines may break at allowed break points, as determined by the line-breaking rules in effect. Line breaking behavior defined for the WJ, ZW, and GL line-breaking classes in [ UAX14 ] must be honored.',
                          'suppress': "Line breaking is suppressed within the element: the UA may only break within the element if there are no other valid break points in the line. If the text breaks, line-breaking restrictions are honored as for 'normal'.",
                          'unrestricted': 'Lines may break between any two grapheme clusters. Line-breaking restrictions have no effect and hyphenation does not take place. Character shaping is performed on each side of the break as if the break had not occurred.'}},

    'transition':
{'description': '', 'values': {}},

    'transition-delay':
{'description': '', 'values': {}},

    'transition-duration':
{'description': "This property specifies how long the transition from the old value to the new value should take. By default the value is '0', meaning that the transition is immediate (i.e. there will be no animation). A negative value for transition-duration is treated as '0'.",
        'values': {}},

    'transition-property':
{'description': 'A value of \'none\' means that no property will transition. A value of \'all\' means that every property that is able to undergo a transition will do so. Otherwise, a list of properties to be transitioned is given. We need to generate a list of properties that can be transitioned. Is "none" even a useful value if the initial value is "all"? The syntax is more elegant if transition-duration defaults to 0 and this property defaults to "all", but another option is to default this property to "none" and duration to something reasonable, e.g., 250ms. This would force an author to specify transition-property in the shorthand all the time though. If one of the identifiers listed is not a recognized property name or is not an animatable property, the implementation must still start transitions on the animatable properties in the list using the duration, delay, and timing function at their respective indices in the lists for \'transition-duration\', \'transition-delay\', and \'transition-timing-function\'. In other words, unrecognized or non-animatable properties must be kept in the list to preserve the matching of indices. Are \'all\', \'none\', \'inherit\', and \'initial\' allowed as items in a list of identifiers (of length greater than one)?If one of the identifiers listed is a shorthand property, implementations must start transitions for any of its longhand sub-properties that are animatable, using the duration, delay, and timing function at the index corresponding to the shorthand. If a property is specified multiple times in the value of \'transition-property\' (either on its own or via a shorthand that contains it), then the transition that starts uses the duration, delay, and timing function at the index corresponding to the last occurrence of the property.',
        'values': {}},

    'transition-timing-function':
{'description': "The timing functions have the following definitions. ======================================================================================================= 2.4. The 'transition-delay' Property",
        'values': {'cubic-bezier': 'Specifies a cubic-bezier curve. The four values specify points P 1 and P 2 of the curve as (x1, y1, x2, y2). All values must be in the range [0, 1] or the definition is invalid.',
                          'ease': 'The ease function is equivalent to cubic-bezier(0.25, 0.1, 0.25, 1.0).',
                          'ease-in': 'The ease-in function is equivalent to cubic-bezier(0.42, 0, 1.0, 1.0).',
                          'ease-in-out': 'The ease-in-out function is equivalent to cubic-bezier(0.42, 0, 0.58, 1.0)',
                          'ease-out': 'The ease-out function is equivalent to cubic-bezier(0, 0, 0.58, 1.0).',
                          'linear': 'The linear function is equivalent to cubic-bezier(0.0, 0.0, 1.0, 1.0).'}},

    'voice-balance':
{'description': "The 'voice-balance' property refers to the balance between left and right channels, and presumes a two channel (stereo) model that is widely supported on consumer audio equipment. Values have the following meanings:",
        'values': {'<number>': "An integer or floating point number between '-100'and'100'. For '-100' only the left channel is audible. Simarly for '100' or '+100' only the right channel is audible. For '0' both channels have the same level, so that the speech appears to be coming from the center.",
                          'center': "Same as '0'.",
                          'left': "Same as '-100'.",
                          'leftwards': "Moves the sound to the left, relative to the inherited voice balance. More precisely, subtract 20 from the inherited value and clip the resulting value to the range '-100'and'100'.",
                          'right': "Same as '100'or'+100'.",
                          'rightwards': "Moves the sound to the right, relative to the inherited voice balance. More precisely, add 20 to the inherited value and clip the resulting value to the range '-100'and'100'."}},

    'voice-duration':
{'description': "Allows authors to specify how long it should take to render the selected element's content. This property overrides the 'voice-rate' property. Values have the following meanings:",
        'values': {'<time>': 'Specifies a value in seconds or milliseconds for the desired time to take to speak the element contents, for instance, "250ms", or "3s". Only positive numbers are allowed.'}},

    'voice-pitch':
{'description': "Specifies the average pitch (a frequency) of the speaking voice. The average pitch of a voice depends on the voice family. For example, the average pitch for a standard male voice is around 120Hz, but for a female voice, it's around 210Hz. Values have the following meanings:",
        'values': {'<number>': 'A positive integer or floating point number that specifies the average pitch of the speaking voice in Hertz.',
                          '<percentage>': 'Specifies a relative change to the inherited value.',
                          'x-low': 'Extra low pitch level.',
                          'low': 'Low pitch level.',
                          'medium': 'Medium pitch level.',
                          'high': 'High pitch level.',
                          'x-high': 'Extra high pitch level.'}},

    'voice-pitch-range':
{'description': 'Specifies variation in average pitch. The perceived pitch of a human voice is determined by the fundamental frequency and typically has a value of 120Hz for a male voice and 210Hz for a female voice. Human languages are spoken with varying inflection and pitch; these variations convey additional meaning and emphasis. Thus, a highly animated voice, i.e., one that is heavily inflected, displays a high pitch range. This property specifies the range over which these variations occur, i.e., how much the fundamental frequency may deviate from the average pitch. Values have the following meanings:',
        'values': {'<number>': 'An non-negative integer or floating point number indicating pitch range in Hertz. Low ranges produce a flat, monotonic voice. A high range produces animated voices.',
                          '<percentage>': 'Specifies a relative change to the inherited value.',
                          'x-low': 'Extra low pitch range.',
                          'low': 'Low pitch range.',
                          'medium': 'Medium pitch range.',
                          'high': 'High pitch range.',
                          'x-high': 'Extra high pitch range.'}},

    'voice-rate':
{'description': 'This property controls the speaking rate. The default rate for a voice depends on the language and dialect and on the personality of the voice. The default rate for a voice should be such that it is experienced as a normal speaking rate for the voice when reading aloud text. Since voices are processor-specific, the default rate will be as well.',
        'values': {'<percentage>': 'Applies to the default speaking rate for each voice. Thus 50% means half the normal rate for this voice.',
                          'x-slow': 'Extra slow voice speed.',
                          'slow': 'Slow voice speed.',
                          'medium': 'Medium voice speed.',
                          'fast': 'Fast voice speed.',
                          'x-fast': 'Extra fast voice speed.'}},

    'voice-stress':
{'description': 'Indicates the strength of emphasis to be applied. Emphasis is indicated using a combination of pitch change, timing changes, loudness and other acoustic differences) that varies from one language to the next. Values have the following meanings:',
        'values': {'none': "Inhibits the synthesizer from emphasizing words it would normally emphasize.",
                          'moderate': 'Gives a moderare emphasis of a word.',
                          'strong': 'Gives a strong emphasis on a word.',
                          'reduced': 'Effectively the opposite of emphasizing a word. For example, when the phrase "going to" is reduced it may be spoken as "gonna".'}},

    'voice-volume':
{'description': "The 'voice-volume' refers to the amplitude of the waveform output by the speech synthesiser. This may be mixed with other audio sources, influencing the perceived loudness of synthetic speech relative to these sources. Note that voice-volume does not apply to audio cues for which there is a separate means to set the relative loudness. Values have the following meanings:",
        'values': {'<number>': "An integer or floating point number in the range '0'to'100'. '0' represents silence (the minimum level), and 100 corresponds to the maximum level. The volume scale is linear amplitude.",
                          '<percentage>': "Percentage values are calculated relative to the inherited value, and are then clipped to the range '0'to'100'.",
                          'silent': 'Zero volume (0).',
                          'x-soft': 'Extra soft volume.',
                          'soft': 'Low volume.',
                          'medium': 'Medium volume.',
                          'loud': 'High volume.',
                          'x-loud': 'Highest volume (100).'}},

    'white-space-collapse':
{'description': 'This section is still under discussion and may change in future drafts. This property declares whether and how white space inside the element is collapsed. Values have the following meanings, which must be interpreted according to the white space processing rules :',
        'values': {'collapse': 'This value directs user agents to collapse sequences of white space into a single character (or in some cases, no character).',
                          'discard': 'This value directs user agents to "discard" all white space in the element.',
                          'preserve': 'This value prevents user agents from collapsing sequences of white space. Line breaks are preserved.',
                          'preserve-breaks': "This value collapses white space as for 'collapse', but preserves line breaks."}},

    'word-break':
{'description': "CSS distinguishes between two levels of strictness in the rules for implicit line breaking in CJK text. The precise set of rules in effect for the strict and loose levels is up to the UA and should follow language conventions. However, this specification does recommend that the following breaks be forbidden in strict line breaking and allowed in loose:Breaks between Hangul syllable blocks are allowed in both strict and loose rules: to restrict breaks in Korean to spaces, the 'keep-all' value of 'word-break' can be specified. Information on line breaking conventions can be found in [ JIS4051 ] for Japanese, [ ???? ] for Chinese, and [?] for Korean, and in [ UAX14 ] for all scripts in Unicode. The CSS Working Group notes that although UAX 14 contains a wealth of information about line breaking conventions, a literal implementation of its algorithm has been found to be inadequate in multiple situations. Any guidance for appropriate references here would be much appreciated. This property specifies what set of line breaking restrictions are in effect within the element. Values have the following meanings:",
        'values': {'break-all': "As for 'break-strict', except CJK scripts break according to the rules for 'loose'.",
                          'break-strict': "Same as 'normal' for CJK scripts, but non-CJK scripts can break anywhere. This option is used mostly when the text is predominantly CJK characters with few non-CJK excerpts and it is desired that the text be more evenly distributed on each line.",
                          'keep-all': "Same as 'normal' for all non-CJK scripts. However, sequences of CJK characters can no longer break on implied break points. This option should only be used where the presence of white space characters still creates line-breaking opportunities, as in Korean.",
                          'loose': "As for 'normal', but CJK scripts use a less restrictive set of line-breaking restrictions.",
                          'normal': 'Breaks non-CJK scripts according to their own rules while using a strict set of line breaking restrictions for CJK scripts (Hangul, Japanese Kana, and CJK ideographs).'}},

    'word-wrap':
{'description': "This property specifies whether the UA may break within a word to prevent overflow when an otherwise-unbreakable string is too long to fit within the line box. It only has an effect when 'text-wrap' is either 'normal'or'suppress'. Possible values:",
        'values': {'break-word': 'An unbreakable "word" may be broken at an arbitrary point if there are no otherwise-acceptable break points in the line. Shaping characters are still shaped as if the word were not broken, and grapheme clusters must together stay as one unit.',
                          'normal': 'Lines may break only at allowed break points.'}},
}

### END: Auto generated


CSS3_SPECIFIC_ATTRS_DICT = {}
CSS3_SPECIFIC_CALLTIP_DICT = {}
for attr, details in CSS3_DATA.items():
    values = details.get("values", {})
    attr_completions = sorted(values.keys())
    if attr_completions:
        CSS3_SPECIFIC_ATTRS_DICT[attr] = attr_completions
    else:
        CSS3_SPECIFIC_ATTRS_DICT[attr] = []
    description = details.get("description")
    if description:
        desc_lines = textwrap.wrap(description, width=60)
        if values:
            desc_lines.append("")
            for value, attr_desc in values.items():
                attr_desc = "  %r: %s" % (value, attr_desc)
                attr_desc_lines = textwrap.wrap(attr_desc, width=50)
                for i in range(len(attr_desc_lines)):
                    attr_line = attr_desc_lines[i]
                    if i > 0:
                        attr_line = "        " + attr_line
                    desc_lines.append(attr_line)
        CSS3_SPECIFIC_CALLTIP_DICT[attr] = "\n".join(
            desc_lines).encode("ascii", 'replace')

removed_css2_items = ["azimuth", "clip", "pointer-events"]

maybe_removed_css2_items = [
    "border-collapse", "border-spacing", "bottom",
    "direction", "elevation", "empty-cells", "left", "marker-offset",
    "pitch", "pitch-range", "play-during", "position",
    "richness", "right", "speak-header", "speak-numeral",
    "speak-punctuation", "speech-rate", "stress",
    "table-layout", "text-transform", "top",
    "unicode-bidi", "volume", "z-index",
]

CSS_ATTR_DICT = CSS1_SPECIFIC_ATTRS_DICT.copy()
CSS_ATTR_DICT.update(CSS2_SPECIFIC_ATTRS_DICT)
CSS_ATTR_DICT.update(CSS3_SPECIFIC_ATTRS_DICT)

CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT = CSS1_SPECIFIC_CALLTIP_DICT.copy()
CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT.update(CSS2_SPECIFIC_CALLTIP_DICT)
CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT.update(CSS3_SPECIFIC_CALLTIP_DICT)

# Remove the css 2 properties that are no longer in css 3.
for name in removed_css2_items:
    CSS_ATTR_DICT.pop(name, None)
    CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT.pop(name, None)

for property, calltip in CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT.items():
    if property not in CSS3_SPECIFIC_CALLTIP_DICT:
        if property in CSS2_SPECIFIC_CALLTIP_DICT:
            calltip += "\n(CSS2, CSS3)"
        else:
            calltip += "\n(CSS1, CSS2, CSS3)"
    else:
        calltip += "\n(CSS3)"
    CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT[property] = calltip


# Note: The CSS3 color names below are not used yet.
css3_color_names = [
    'aliceblue',
    'antiquewhite',
    'aqua',
    'aquamarine',
    'azure',
    'beige',
    'bisque',
    'black',
    'blanchedalmond',
    'blue',
    'blueviolet',
    'brown',
    'burlywood',
    'cadetblue',
    'chartreuse',
    'chocolate',
    'coral',
    'cornflowerblue',
    'cornsilk',
    'crimson',
    'cyan',
    'darkblue',
    'darkcyan',
    'darkgoldenrod',
    'darkgray',
    'darkgreen',
    'darkgrey',
    'darkkhaki',
    'darkmagenta',
    'darkolivegreen',
    'darkorange',
    'darkorchid',
    'darkred',
    'darksalmon',
    'darkseagreen',
    'darkslateblue',
    'darkslategray',
    'darkslategrey',
    'darkturquoise',
    'darkviolet',
    'deeppink',
    'deepskyblue',
    'dimgray',
    'dimgrey',
    'dodgerblue',
    'firebrick',
    'floralwhite',
    'forestgreen',
    'fuchsia',
    'gainsboro',
    'ghostwhite',
    'gold',
    'goldenrod',
    'gray',
    'green',
    'greenyellow',
    'grey',
    'honeydew',
    'hotpink',
    'indianred',
    'indigo',
    'ivory',
    'khaki',
    'lavender',
    'lavenderblush',
    'lawngreen',
    'lemonchiffon',
    'lightblue',
    'lightcoral',
    'lightcyan',
    'lightgoldenrodyellow',
    'lightgray',
    'lightgreen',
    'lightgrey',
    'lightpink',
    'lightsalmon',
    'lightseagreen',
    'lightskyblue',
    'lightslategray',
    'lightslategrey',
    'lightsteelblue',
    'lightyellow',
    'lime',
    'limegreen',
    'linen',
    'magenta',
    'maroon',
    'mediumaquamarine',
    'mediumblue',
    'mediumorchid',
    'mediumpurple',
    'mediumseagreen',
    'mediumslateblue',
    'mediumspringgreen',
    'mediumturquoise',
    'mediumvioletred',
    'midnightblue',
    'mintcream',
    'mistyrose',
    'moccasin',
    'navajowhite',
    'navy',
    'oldlace',
    'olive',
    'olivedrab',
    'orange',
    'orangered',
    'orchid',
    'palegoldenrod',
    'palegreen',
    'paleturquoise',
    'palevioletred',
    'papayawhip',
    'peachpuff',
    'per',
    'pink',
    'plum',
    'powderblue',
    'purple',
    'red',
    'rosybrown',
    'royalblue',
    'saddlebrown',
    'salmon',
    'sandybrown',
    'seagreen',
    'seashell',
    'sienna',
    'silver',
    'skyblue',
    'slateblue',
    'slategray',
    'slategrey',
    'snow',
    'springgreen',
    'steelblue',
    'tan',
    'teal',
    'thistle',
    'tomato',
    'turquoise',
    'violet',
    'wheat',
    'white',
    'whitesmoke',
    'yellow',
    'yellowgreen',
]

# Add the css3 named colors.
# from codeintel2.util import CompareNPunctLast
# for attr, values in CSS_ATTR_DICT.items():
#    if '#' in values or 'rbg(' in values:
#        CSS_ATTR_DICT[attr] = sorted(values + css3_color_names,
#                                     cmp=CompareNPunctLast)

########NEW FILE########
__FILENAME__ = constants_css_microsoft_extensions
"""
Microsoft CSS extensions.
"""

import textwrap

### START: Auto generated

CSS_MICROSOFT_DATA = {
    '-ms-accelerator': {
        'description': "Extension",
    },
    '-ms-background-position-x': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-background-position-y': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-behavior': {
        'description': "Extension",
    },
    '-ms-block-progression': {
        'description': "CSS3 - Editor's Draft",
    },
    '-ms-filter': {
        'description': "Extension - Sets or retrieves the filter or collection of filters applied to the object.",
        'values': {
            'progid:DXImageTransform.Microsoft.Alpha': "Adjusts the opacity of the content of the object.",
            'progid:DXImageTransform.Microsoft.BasicImage': "Adjusts the color processing, image rotation, or opacity of the content of the object.",
            'progid:DXImageTransform.Microsoft.Blur': "Blurs the content of the object so that it appears out of focus.",
            'progid:DXImageTransform.Microsoft.Chroma': "Displays a specific color of the content of the object as transparent.",
            'progid:DXImageTransform.Microsoft.Compositor': "Displays new content of the object as a logical color combination of the new and original content. The color and alpha values of each version of the content are evaluated to determine the final color on the output image.",
            'progid:DXImageTransform.Microsoft.DropShadow': "Creates a solid silhouette of the content of the object, offset in the specified direction. This creates the illusion that the content is floating and casting a shadow.",
            'progid:DXImageTransform.Microsoft.Emboss': "Displays the content of the object as an embossed texture using grayscale values.",
            'progid:DXImageTransform.Microsoft.Engrave': "Displays the content of the object as an engraved texture using grayscale values.",
            'progid:DXImageTransform.Microsoft.Glow': "Adds radiance around the outside edges of the content of the object so that it appears to glow.",
            'progid:DXImageTransform.Microsoft.ICMFilter': "Converts the color content of the object based on an Image Color Management (ICM) profile. This enables improved display of specific content, or simulated display for hardware devices, such as printers or monitors.",
            'progid:DXImageTransform.Microsoft.Light': "Creates the effect of a light shining on the content of the object.",
            'progid:DXImageTransform.Microsoft.MaskFilter': "Displays transparent pixels of the object content as a color mask, and makes the nontransparent pixels transparent.",
            'progid:DXImageTransform.Microsoft.Matrix': "Resizes, rotates, or reverses the content of the object using matrix transformation.",
            'progid:DXImageTransform.Microsoft.MotionBlur': "Causes the content of the object to appear to be in motion.",
            'progid:DXImageTransform.Microsoft.Shadow': "Creates a solid silhouette of the content of the object, offset in the specified direction. This creates the illusion of a shadow.",
            'progid:DXImageTransform.Microsoft.Wave': "Performs a sine wave distortion of the content of the object  along the vertical axis.",
        }
    },
    '-ms-ime-mode': {
        'description': "Extension",
    },
    '-ms-layout-grid': {
        'description': "CSS3 - Editor's Draft",
    },
    '-ms-layout-grid-char': {
        'description': "CSS3 - Editor's Draft",
    },
    '-ms-layout-grid-line': {
        'description': "CSS3 - Editor's Draft",
    },
    '-ms-layout-grid-mode': {
        'description': "CSS3 - Editor's Draft",
    },
    '-ms-layout-grid-type': {
        'description': "CSS3 - Editor's Draft",
    },
    '-ms-line-break': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-line-grid-mode': {
        'description': "CSS3 - Editor's Draft",
    },
    '-ms-interpolation-mode': {
        'description': "Extension",
    },
    '-ms-overflow-x': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-overflow-y': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-scrollbar-3dlight-color': {
        'description': "Extension",
    },
    '-ms-scrollbar-arrow-color': {
        'description': "Extension",
    },
    '-ms-scrollbar-base-color': {
        'description': "Extension",
    },
    '-ms-scrollbar-darkshadow-color': {
        'description': "Extension",
    },
    '-ms-scrollbar-face-color': {
        'description': "Extension",
    },
    '-ms-scrollbar-highlight-color': {
        'description': "Extension",
    },
    '-ms-scrollbar-shadow-color': {
        'description': "Extension",
    },
    '-ms-scrollbar-track-color': {
        'description': "Extension",
    },
    '-ms-text-align-last': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-text-autospace': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-text-justify': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-text-kashida-space': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-text-overflow': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-text-underline-position': {
        'description': "Extension",
    },
    '-ms-word-break': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-word-wrap': {
        'description': "CSS3 - Working Draft",
    },
    '-ms-writing-mode': {
        'description': "CSS3 - Editor's Draft",
    },
    '-ms-zoom': {
        'description': "Extension",
    },
}

### END: Auto generated


CSS_MICROSOFT_SPECIFIC_ATTRS_DICT = {}
CSS_MICROSOFT_SPECIFIC_CALLTIP_DICT = {}
for attr, details in CSS_MICROSOFT_DATA.items():
    values = details.get("values", {})
    versions = details.get("versions", [])
    attr_completions = sorted(values.keys())
    if attr_completions:
        CSS_MICROSOFT_SPECIFIC_ATTRS_DICT[attr] = attr_completions
    else:
        CSS_MICROSOFT_SPECIFIC_ATTRS_DICT[attr] = None
    description = details.get("description", '')
    if versions:
        description += "\nVersions: %s\n" % (", ".join(versions))
    if description:
        desc_lines = textwrap.wrap(description, width=60)
        if values:
            desc_lines.append("")
            for value, attr_desc in values.items():
                attr_desc = "  %r: %s" % (value, attr_desc)
                attr_desc_lines = textwrap.wrap(attr_desc, width=50)
                for i in range(len(attr_desc_lines)):
                    attr_line = attr_desc_lines[i]
                    if i > 0:
                        attr_line = "        " + attr_line
                    desc_lines.append(attr_line)
        CSS_MICROSOFT_SPECIFIC_CALLTIP_DICT[attr] = "\n".join(
            desc_lines).encode("ascii", 'replace')

########NEW FILE########
__FILENAME__ = constants_css_moz_extensions
"""
Mozilla CSS extensions.
"""

import textwrap

# Auto generated from:
#  'src/codeintel/support/gencix/css/gen_moz_css_properties.py'

### START: Auto generated

CSS_MOZ_DATA = {

    '-moz-appearance':
    {'description': "The -moz-appearance CSS property is used in Gecko (Firefox) to display an element using a platform-native styling based on the operating system's theme.",
        'values': {'-moz-mac-unified-toolbar': 'New in Firefox 3.5. Mac OS X only. This causes the toolbar and title bar to render using the unified toolbar style common to Mac OS X 10.4 and later applications.',
                   '-moz-win-browsertabbar-toolbox': 'New in Firefox 3. Windows Vista and later. This toolbox style is meant to be used for the tab bar in a browser.',
                   '-moz-win-communications-toolbox': 'New in Firefox 3. Windows Vista and later. This toolbox style is meant to be used in communications and productivity applications. Corresponding foreground color is -moz-win-communicationstext .',
                   '-moz-win-glass': 'New in Firefox 3.5. Windows Vista and later. This style applies the Aero Glass effect to the element.',
                   '-moz-win-media-toolbox': 'New in Firefox 3. Windows Vista and later. This toolbox style is meant to be used in applications that manage media objects. Corresponding foreground color is -moz-win-mediatext .',
                   'button': 'The element is drawn like a button.',
                   'checkbox': 'The element is drawn like a checkbox, including only the actual "checkbox" portion.',
                   'checkbox-container': 'The element is drawn like a container for a checkbox, which may include a prelighting background effect under certain platforms. Normally a would contain a label and a checkbox.',
                   'checkbox-small': '',
                   'dialog': 'The element is styled like a dialog box, which includes background color and other properties.',
                   'listbox': '',
                   'menuitem': 'The element is styled as menu item, item is highlighted when hovered.',
                   'menulist': '',
                   'menulist-button': 'The element is styled as a button that would indicate a menulist can be opened.',
                   'menulist-textfield': 'The element is styled as the text field for a menulist.',
                   'menupopup': '',
                   'none': 'No special styling is applied. (Default)',
                   'progressbar': 'The element is styled like a progress bar.',
                   'radio': 'The element is drawn like a radio button, including only the actual "radio button" portion.',
                   'radio-container': 'The element is drawn like a container for a radio button, which may include a prelighting background effect under certain platforms. Normally would contain a label and a radio button.',
                   'radio-small': '',
                   'resizer': '',
                   'scrollbar': '',
                   'scrollbarbutton-down': '',
                   'scrollbarbutton-left': '',
                   'scrollbarbutton-right': '',
                   'scrollbarbutton-up': '',
                   'scrollbartrack-horizontal': '',
                   'scrollbartrack-vertical': '',
                   'separator': '',
                   'statusbar': '',
                   'tab': '',
                          'tab-left-edge': 'Obsolete. ',
                          'tabpanels': '',
                          'textfield': '',
                          'toolbar': '',
                          'toolbarbutton': '',
                          'toolbox': '',
                          'tooltip': '',
                          'treeheadercell': '',
                          'treeheadersortarrow': '',
                          'treeitem': '',
                          'treetwisty': '',
                          'treetwistyopen': '',
                          'treeview': '',
                          'window': ''},
        'version': 'Firefox 1.0 (1.0)'},

    '-moz-background-clip':
{'description': "The background-clip CSS property specifies whether an element's background, either the color or image, extends underneath its border. -moz-background-clip is supported up to Gecko version 1.9.2 (Firefox 3.6). Warning: To support both, older and newer versions of Gecko (Firefox), you have to add both properties in the stylesheet. See examples.",
 'values': {'border': '(Firefox 1.0-3.6). The background extends to the outside edge of the border (but underneath the border in z-ordering). Default value, but see Browser compatibility section below for special case Internet Explorer 7.',
            'border-box': '(Requires Gecko 1.9.3). The background extends to the outside edge of the border (but underneath the border in z-ordering). Default value, but see Browser compatibility section below for special case Internet Explorer 7.',
                          'content-box': 'Requires Gecko 1.9.3. The background is painted within (clipped to) the content box.',
                          'padding': '(Firefox 1.0-3.6). No background is drawn below the border (background extends to the outside edge of the padding).',
                          'padding-box': '(Requires Gecko 1.9.3). No background is drawn below the border (background extends to the outside edge of the padding).'},
 'version': 'Firefox (Gecko) 1.0-3.6 (1.2-1.9.2)'},

    '-moz-background-inline-policy':
{'description': 'In Gecko -based applications like Firefox, the -moz-background-inline-policy CSS property specifies how the background image of an inline element is determined when the content of the inline element wraps onto multiple lines. The choice of position has significant effects on repetition.',
 'values': {'bounding-box': 'The background image is positioned (and repeated) in the smallest rectangle that contains all of the inline boxes for the element. It is then clipped to be visible only within those boxes, according to the -moz-background-clip property.',
            'continuous': 'The background image is positioned (and repeated) as if the inline box were not broken across lines, and then this long rectangle is sliced into pieces for each line.',
                          'each-box': 'The background image is positioned (and repeated) separately for each box of the inline element. This means that an image with background-repeat : no-repeat may be repeated multiple times.'}},

    '-moz-background-origin':
{'description': 'The background-origin CSS property determines the background positioning area (the origin of a background-image). background-origin does not apply when background-attachment is fixed . -moz-background-origin is supported up to Gecko version 1.9.2 (Firefox 3.6). Warning: To support both, older and newer versions of Gecko (Firefox), you have to add both properties in the stylesheet. See examples.',
 'values': {'border': '(Firefox 1.0-3.6). The background position is relative to the border, so the image can go behind the border.',
            'border-box': '(New in Firefox 4). The background position is relative to the border, so the image can go behind the border.',
                          'content': '(Firefox 1.0-3.6). The background position is relative to the content.',
                          'content-box': '(New in Firefox 4). The background position is relative to the content.',
                          'padding': '(Firefox 1.0-3.6). Default value. The background position is relative to the padding. (For single boxes " 0 0 " is the upper left corner of the padding edge, " 100% 100% " is the lower right corner.)',
                          'padding-box': '(New in Firefox 4). Default value. The background position is relative to the padding. (For single boxes " 0 0 " is the upper left corner of the padding edge, " 100% 100% " is the lower right corner.)'},
 'version': 'Firefox (Gecko) 1.0-3.6 (1.2-1.9.2)'},

    '-moz-background-size':
{'description': 'The background-size CSS property specifies the size of the background images. -moz-background-size is supported by Gecko version 1.9.2 (Firefox 3.6). Warning: To support both, Firefox 3.6 and newer versions, you have to include both properties in the stylesheet. See examples.',
 'values': {'<length>': 'Scales the background image to the specified length in the desired dimension.',
            '<percentage>': "Scales the background image in the desired dimension to the specified percentage of the background positioning area, which is determined by the value of -moz-background-origin . The background positioning area is, by default, the area containing the content of the box and its padding; the area may also be changed to just the content or to the area containing borders, padding, and content. If the background's attachment is fixed , the background positioning area is instead the entire area of the browser window, not including the area covered by scrollbars if they are present.",
            'auto': 'Scales the background image in the relevant direction such that its intrinsic proportions are maintained.',
            'contain': 'Specifies that the background image should be scaled to be as large as possible while ensuring both its dimensions are less than or equal to the corresponding dimensions of the background positioning area.',
            'cover': 'Specifies that the background image should be scaled to be as small as possible while ensuring both its dimensions are greater than or equal to the corresponding dimensions of the background positioning area.'},
 'version': 'Firefox (Gecko) 3.6 (1.9.2)'},

    '-moz-binding':
{'description': 'The -moz-binding CSS property is used by Mozilla-based applications to attach an XBL binding to a DOM element.',
 'values': {'<uri>': 'The URI for the XBL binding (including the fragment identifier).',
            'none': 'no XBL binding is applied to the element.'}},

    '-moz-border-bottom-colors':
{'description':
    'In Mozilla applications like Firefox, -moz-border-bottom-colors sets a list of colors for the bottom border.'},

    '-moz-border-end':
{},

    '-moz-border-end-color':
{},

    '-moz-border-end-style':
{},

    '-moz-border-end-width':
{},

    '-moz-border-image':
{'description': 'The border-image CSS property allows drawing an image on the borders of elements. This makes drawing complex looking widgets much simpler than it has been and removes the need for nine boxes in some cases.',
 'values': {'<border-width>': '(optional). If the slash / is present in the property value, the one, two, three or four values after it are used for the width of the border instead of the border-width properties. The order of the values is the same as for border-width .',
            '<image>': '(required). The image value is a <uri> , e.g. url(http://example.org/image.png)',
                          '<number>': '| <percentage> (required). One, two, three or four values represent inward offsets from the top, right, bottom, and left edges of the image (respectively), dividing it into nine regions: four corners, four edges and a middle. One value belongs to all four sides of the image. Two values belong 1. to top and bottom and 2. to right and left side. Three values belong 1. to top, 2. to the right and left side and 3. to bottom. Four values belong to the top, right, bottom and left edge of the image in that order. In Gecko 1.9.1 (Firefox 3.5) the middle part of the image is drawn like a background-image of the element. This may change in future versions. Percentages are relative to the width/height of the image. Numbers represent pixels in the image (if the image is a raster image) or vector coordinates (if the image is an SVG image).',
                          'none': 'No image displayed, other border styles are used.',
                          'stretch': '| round | repeat (optional). One or two keywords, that specify how the images for the sides and the middle part are scaled and tiled. stretch (default value) will cause images to be scaled to fit their box. round will tile the images, but also scale them so that a whole number fit in the box. repeat simply tiles the images inside the box. The first keyword describes how to draw the top, middle, and bottom images, while the second describes the left and right borders. If the second is absent, it is assumed to be the same as the first. If both are absent, the default value stretch is used.'},
        'version': 'Firefox (Gecko) 3.5 (1.9.1)'},

    '-moz-border-left-colors':
{'description':
    'In Mozilla applications like Firefox, the -moz-border-left-colors sets a list of colors for the left border.'},

    '-moz-border-radius':
{'description': 'In Mozilla applications like Firefox, the -moz-border-radius CSS property can be used to give borders rounded corners. The radius applies also to the background even if the element has no border.',
        'values': {'<length>': 'See <length> for possible units.',
                          '<percentage>': 'In Gecko (Firefox) Non-standard : A percentage, relative to the width of the box (the percentage is relative to the width even when specifying the radius for a height). In CSS 3: Percentages for the horizontal radius refer to the width of the box, whereas percentages for the vertical radius refer to the height of the box.'},
        'version': 'Firefox (Gecko) 1.0 (1.0)'},

    '-moz-border-radius-bottomleft':
{'description':
    'In Mozilla applications, -moz-border-radius-bottomleft sets the rounding of the bottom-left corner of the border.'},

    '-moz-border-radius-bottomright':
{'description':
    'In Mozilla applications, -moz-border-radius-bottomright sets the rounding of the bottom-right corner of the border.'},

    '-moz-border-radius-topleft':
{'description': 'In Mozilla applications like Firefox, the -moz-border-radius-topleft CSS property sets the rounding of the top-left corner of the element.',
        'values': {'<length>': 'See <length> for possible units.',
                          '<percentage>': 'In Gecko (Firefox) Non-standard : Relative to the width of the box (the percentage is relative to the width even when specifying the radius for a height). In CSS 3: Percentages for the horizontal radius refer to the width of the box, whereas percentages for the vertical radius refer to the height of the box.'},
        'version': 'Firefox 1.0 (Gecko 1.0)'},

    '-moz-border-radius-topright':
{'description':
    'In Mozilla applications like Firefox, the -moz-border-radius-topright CSS property sets the rounding of the top-right corner of the border.'},

    '-moz-border-right-colors':
{'description':
    'In Mozilla applications like Firefox, -moz-border-right-colors sets a list of colors for the right border.'},

    '-moz-border-start':
{},

    '-moz-border-start-color':
{},

    '-moz-border-start-style':
{},

    '-moz-border-start-width':
{},

    '-moz-border-top-colors':
{'description': 'In Mozilla applications like Firefox, the -moz-border-top-colors CSS property sets a list of colors for the top border.',
        'values': {'<color>': 'Specifies the color of a line of pixels in the bottom border. transparent is valid. See <color> values for possible units.',
                          'none': 'Default, no colors are drawn or border-color is used, if specified.'}},

    '-moz-box-align':
{'description': 'In Mozilla applications, -moz-box-align specifies how a XUL box\naligns its contents across (perpendicular to) the direction of its layout. The effect of this is only\nvisible if there is extra space in the box.',
        'values': {'baseline': "The box aligns the baselines of the contents (lining up the text). This only applies if the box'sorientation is horizontal.",
                          'center': 'The box aligns contents in the center, dividing any extra space equally between the start and the end.',
                          'end': 'The box aligns contents at the end, leaving any extra space at the start.',
                          'start': 'The box aligns contents at the start, leaving any extra space at the end.',
                          'stretch': 'The box stretches the contents so that there is no extra space in the box.'}},

    '-moz-box-direction':
{'description': 'In Mozilla applications, -moz-box-direction specifies whether a box lays out its contents normally (from the top or left edge), or in reverse (from the bottom or right edge).',
        'values': {'normal': 'The box lays out its contents from the start (the left or top edge).',
                          'reverse': 'The box lays out its contents from the end (the right or bottom edge).'}},

    '-moz-box-flex':
{'description': "In Mozilla applications, -moz-box-flex specifies how a box grows\nto fill the box that contains it, in the direction of the containing box's layout.",
        'values': {'0': 'The box does not grow.'}},

    '-moz-box-flexgroup':
{},

    '-moz-box-ordinal-group':
{'description': 'Indicates the ordinal group the element belongs to. Elements with a lower ordinal group are displayed before those with a higher ordinal group.',
        'values': {}},

    '-moz-box-orient':
{'description': 'In Mozilla applications, -moz-box-orient specifies whether a box\nlays out its contents horizontally or vertically.',
        'values': {'horizontal': 'The box lays out its contents horizontally.',
                          'vertical': 'The box lays out its contents vertically.'}},

    '-moz-box-pack':
{'description': 'In Mozilla applications, -moz-box-pack specifies how a box\npacks its contents in the direction of its layout. The effect of this is only\nvisible if there is extra space in the box.',
        'values': {'center': 'The box packs contents in the center, dividing any extra space equally between the start and the end.',
                          'end': 'The box packs contents at the end, leaving any extra space at the start.',
                          'justify': '?',
                          'start': 'The box packs contents at the start, leaving any extra space at the end.'}},

    '-moz-box-shadow':
{'description': 'The box-shadow CSS property accepts one or more shadow effects as a comma-separated list. It allows to cast a drop shadow from the frame of almost any arbitrary element. If a border-radius is specified on the element with a box shadow, the box shadow will take on the same rounded corners. The z-ordering of multiple box shadows is the same as multiple text-shadows (the first specified shadow is on top).',
        'values': {'<blur-radius>': "(optional). This is a third <length> value. The larger this value, the bigger the blur, so the shadow becomes bigger and lighter. Negative values are not allowed. If not specified, it will be 0 (the shadow's edge is sharp).",
                          '<color>': "(optional). See <color> values for possible keywords and notations. If not specified, the color depends on the browser. In Gecko (Firefox), the value of the color property is used. WebKit's shadow is transparent and therefore useless if <color> is omitted.",
                          '<offset-x>': '<offset-y> (required). This are two <length> values to set the shadow offset. <offset-x> specifies the horizontal distance. Negative values place the shadow to the left of the element. <offset-y> specifies the vertical distance. Negative values place the shadow above the element. See <length> for possible units. If both values are 0 , the shadow is placed behind the element (and may generate a blur effect if <blur-radius> and/or <spread-radius> is set).',
                          '<spread-radius>': '(optional). This is a fourth <length> value. Positive values will cause the shadow to expand and grow bigger, negative values will cause the shadow to shrink. If not specified, it will be 0 (the shadow will be the same size as the element).',
                          'inset': '(optional). If not specified (default), the shadow is assumed to be a drop shadow (as if the box were raised above the content). The presence of the inset keyword changes the shadow to one inside the frame (as if the content was depressed inside the box). Inset shadows are drawn above background, but below border and content.'},
        'version': 'Firefox (Gecko) 3.5 (1.9.1)'},

    '-moz-box-sizing':
{'description': '< CSS < CSS Reference < CSS Reference:Mozilla Extensions',
        'values': {}},

    '-moz-column-count':
{'description': 'In Mozilla applications like Firefox, the -moz-column-count CSS property can be used to set the ideal number of columns into which the content of the element will be flowed.',
        'values': {'<integer>': 'Describes the ideal number of columns into which the content of the element will be flowed.'},
        'version': 'Firefox (Gecko) 1.5 (1.8)'},

    '-moz-column-gap':
{'description': 'In Mozilla applications like Firefox, the -moz-column-gap CSS property sets the gap between columns for block elements which are specified to display as a multi-column element.',
        'values': {'<length>': 'A non-negative value in any of the CSS <length> units to specify the gap between columns.',
                          'normal': 'Default value, depends on the user agent. In desktop browsers like Firefox this is 1em. In Gecko 1.8.1 (Firefox 2.0) and before the default value was 0 .'},
        'version': 'Firefox (Gecko) 1.5 (1.8)'},

    '-moz-column-rule':
{'description': 'In multi-column layouts, the -moz-column-rule CSS property specifies a straight line, or "rule", to be drawn between each column. -moz-column-rule is a convenient shorthand to avoid setting each of the individual -moz-column-rule-* properties separately: -moz-column-rule-width , -moz-column-rule-style and -moz-column-rule-color .',
        'values': {'<border-style>': 'Required , default value none is used if absent. See border-style for possible values and details.',
                          '<border-width>': 'Optional, is one value or keyword of: <length> | thin | medium | thick Default value medium is used if absent. See border-width for details.',
                          '<color>': "Optional , see <color> value. Default value if absent: currentColor , the value of the element's color property (foreground color)."},
        'version': 'Firefox (Gecko) 3.5 (1.9.1)'},

    '-moz-column-rule-color':
{'description': 'The -moz-column-rule-color CSS property lets you set the color of the rule drawn between columns in multi-column layouts.',
        'values': {'<color>': 'See <color> values.'},
        'version': 'Firefox (Gecko) 3.0 (1.9.1)'},

    '-moz-column-rule-style':
{'description': 'The -moz-column-rule-style CSS property lets you set the style of the rule drawn between columns in multi-column layouts.',
        'values': {'<border-style>': 'See border-style'},
        'version': 'Firefox (Gecko) 3.0 (1.9.1)'},

    '-moz-column-rule-width':
{'description': 'The -moz-column-rule-width CSS property lets you set the width of the rule drawn between columns in multi-column layouts.',
        'values': {'<border-width>': 'See border-width .'},
        'version': 'Firefox (Gecko) 3.0 (1.9.1)'},

    '-moz-column-width':
{'description': 'In Mozilla applications like Firefox, the -moz-column-width CSS property suggests an optimal column width. The actual column width may be wider (to fill the available space), or narrower (only if the available space is smaller than the specified column width).',
        'values': {'<length>': 'See <length> value for possible units.'},
        'version': 'Firefox (Gecko) 1.5 (1.8)'},

    '-moz-float-edge':
{'description': 'bug 432891', 'values': {}},

    '-moz-force-broken-image-icon':
{'description': '-moz-force-broken-image-icon is an extended CSS property, for more info see bug 58646 . The value 1 forces a broken image icon even if the image has alt text',
        'values': {'<integer>': ''}},

    '-moz-image-region':
{'description':
    'For certain XUL elements and pseudo-elements that use an image from the list-style-image property, this property specifies a region of the image that is used in place of the whole image. This allows elements to use different pieces of the same image to improve performance.'},

    '-moz-margin-end':
{'description': 'In left to right (LTR) situations, the -moz-margin-end CSS property specifies the right margin and is synonymous with margin-right . In RTL cases it sets the left margin (same as margin-left ).',
        'values': {'<length>': 'Specifies a fixed width.',
                          '<percentage>': 'A percentage with respect to the width of the containing block.'},
        'version': 'Firefox (Gecko) 1.0 (1.7)'},

    '-moz-margin-start':
{'description': 'In left to right (LTR) situations the -moz-margin-start CSS property specifies the left margin and is synonymous with margin-left . In RTL cases it sets the right margin (same as margin-right ).',
        'values': {'<length>': 'Specifies a fixed width.',
                          '<percentage>': 'a percentage with respect to the width of the containing block.'},
        'version': 'Firefox (Gecko) 1.0 (1.7)'},

    '-moz-opacity':
{'description': 'The opacity CSS property specifies the transparency of an element, i.e. the degree to which the background behind the element is overlaid.',
        'values': {'0': '< number < 1. The element is translucent (background can be seen).',
                          '1': 'The element is fully opaque (solid).'},
        'version': 'Firefox (Gecko) 0.9 (1.7) opacity'},

    '-moz-outline':
{'description': '(OBSOLETE) Starting with Gecko 1.8 (Firefox 1.5), the standard CSS 2.1 outline property is supported as well. Use of outline is preferred to -moz-outline .',
        'values': {}},

    '-moz-outline-color':
{'description': '(OBSOLETE) Starting with Gecko 1.8 / Firefox 1.5, the standard CSS 2.1 outline-color property is supported as well. Use of outline-color is preferred to -moz-outline-color .',
        'values': {}},

    '-moz-outline-offset':
{'description': '(OBSOLETE) Support since Gecko 1.8 (Firefox 1.5) contemporary with the standard CSS 3 outline-offset property. Use only outline-offset .',
        'values': {}},

    '-moz-outline-radius':
{'description': 'In Mozilla applications like Firefox, the -moz-outline-radius CSS property can be used to give outlines rounded corners. An outline is a line that is drawn around elements, outside the border edge, to make the element stand out.',
        'values': {'<length>': 'See <length> for possible values',
                          '<percentage>': 'A <percentage> , relative to the width of the box'}},

    '-moz-outline-radius-bottomleft':
{'description':
    'In Mozilla applications, -moz-outline-radius-bottomleft sets the rounding of the bottom-left corner of the outline.'},

    '-moz-outline-radius-bottomright':
{'description':
    'In Mozilla applications, -moz-outline-radius-bottomright sets the rounding of the bottom-right corner of the outline.'},

    '-moz-outline-radius-topleft':
{'description':
    'In Mozilla applications, -moz-outline-radius-topleft sets the rounding of the top-left corner of the outline.'},

    '-moz-outline-radius-topright':
{'description':
    'In Mozilla applications, -moz-outline-radius-topright sets the rounding of the top-right corner of the outline.'},

    '-moz-outline-style':
{'description': '(OBSOLETE) Starting with Gecko 1.8 / Firefox 1.5, the standard CSS 2.1 outline-style property is supported as well. Use of outline-style is preferred to -moz-outline-style .',
        'values': {}},

    '-moz-outline-width':
{'description': '(OBSOLETE) Starting with Gecko 1.8 / Firefox 1.5, the standard CSS 2.1 outline-width property is supported as well. Use of outline-width is preferred to -moz-outline-width .',
        'values': {}},

    '-moz-padding-end':
{'description': "When rendering right-to-left text, -moz-padding-end flips the element's padding without having to specify absolute left or right. In a left-to-right text display -moz-padding-end is treated as a right sided padding, while in a right-to-left display it is padded on the left.",
        'values': {'<length>': 'Specifies a fixed width.',
                          '<percentage>': 'a percentage with respect to the width of the containing block.'}},

    '-moz-padding-start':
{'description': 'In Right to Left situations -moz-padding-start flips the elements padding without having to specify absolute left or right. In a Left to Right display -moz-padding-start would be treated as a left sided padding, and alternately in a Right to Left display it would become the right.',
        'values': {'<length>': 'Specifies a fixed width.',
                          '<percentage>': 'a percentage with respect to the width of the containing block.'}},

    '-moz-stack-sizing':
{'description': '-moz-stack-sizing is an extended CSS property. Normally, a stack will change its size so that all of its child elements are completely visible. For example, moving a child of the stack far to the right will widen the stack so the child remains visible.',
        'values': {'ignore': "The stack won't consider this child when calculating the its size.",
                          'stretch-to-fit': "The child will influence the stack's size."}},

    '-moz-transform':
{'description': '< CSS < CSS Reference < CSS Reference:Mozilla Extensions Introduced in Gecko 1.9.1 (Firefox 3.5 / Thunderbird 3 / SeaMonkey 2)',
        'values': {'none': 'Specifies that no transform should be applied.',
                          'transform-function': 'One or more of the CSS transform functions to be applied, see below.'}},

    '-moz-transform-origin':
{'description': "The -moz-transform-origin CSS property lets you modify the origin for transformations of an element. For example, the transform-origin of the rotate() function is the centre of rotation. (This property is applied by first translating the element by the negated value of the property, then applying the element's transform, then translating by the property value.)",
        'values': {'<length>': 'With a value pair of e.g. 2cm 1cm , the transform-origin is placed 2cm to the right and 1cm below the upper left corner of the element.',
                          '<percentage>': 'With a value pair of 0% 0% , (or just 0 0 ) the transform-origin is the upper left corner of the box. A value pair of 100% 100% places the transform-origin to the lower right corner. With a value pair of 14% 84% , the point 14% across and 84% down the box is the transform-origin.',
                          'bottom': 'right | right bottom. Same as 100% 100%',
                          'center': '| center center. Same as 50% 50% (default value)',
                          'left': '| left center | center left. Same as 0 50%',
                          'right': '| right center | center right. Same as 100% 50%',
                          'top': '| top center | center top. Same as 50% 0'},
        'version': 'Firefox (Gecko) 3.5 (1.9.1)'},

    '-moz-transition':
{'description': 'The -moz-transition CSS property is a shorthand property for -moz-transition-property , -moz-transition-duration , -moz-transition-timing-function , and -moz-transition-delay .',
        'version': 'Firefox (Gecko) 3.7? (Gecko 1.9.3)'},

    '-moz-transition-delay':
{'description': 'The -moz-transition-delay CSS property specifies the number of seconds to wait between a change being requested to a property that is to be transitioned and the start of the transition effect .',
        'values': {'time': "The number of seconds to wait between a property's value changing and the start of the animation effect."},
        'version': 'Firefox (Gecko) 3.7? (Gecko 1.9.3)'},

    '-moz-transition-duration':
{'description': 'The -moz-transition-duration CSS property specifies the number of seconds a transition animation should take to complete. By default, the value is 0, meaning that no animation will occur.',
        'values': {'time': 'The number of seconds the transition from the old value of a property to the new value should take.'},
        'version': 'Firefox (Gecko) 3.7? (Gecko 1.9.3)'},

    '-moz-transition-property':
{'description': 'The -moz-transition-property CSS property is used to specify the names of CSS properties to which a transition effect should be applied.',
        'values': {'all': 'All properties that can have an animated transition will do so.',
                          'none': 'No properties will transition.',
                          'property-name': 'A property to which a transition effect should be applied when its value changes.'},
        'version': 'Firefox (Gecko) 3.7? (Gecko 1.9.3)'},

    '-moz-transition-timing-function':
{'description': 'The -moz-transition-timing-function CSS property is used to describe how the intermediate values of the CSS properties being affected by a transition effect are calculated. This in essence lets you establish an acceleration curve, so that the speed of the transition can vary over its duration.',
        'values': {'cubic-bezier': 'Specifies a cubic bezier curve to use as the easing function. The four number values specify the P 1 and P 2 points of the curve as (x 1 , y 1 , x 2 , y 2 ). All values must be in the range [0.0, 1.0] inclusive.',
                          'ease': 'This keyword sets the easing function to cubic-bezier(0.25, 0.1, 0.25, 1.0) .',
                          'ease-in': 'This keyword sets the easing function to cubic-bezier(0.42, 0.0, 1.0, 1.0) .',
                          'ease-in-out': 'This keyword sets the easing function to cubic-bezier(0.42, 0.0, 0.58, 1.0) .',
                          'ease-out': 'This keyword sets the easing function to cubic-bezier(0.0, 0.0, 0.58, 1.0) .',
                          'linear': 'This keyword sets the easing function to cubic-bezier(0.0, 0.0, 1.0, 1.0) .'},
        'version': 'Firefox (Gecko) 3.7? (Gecko 1.9.3)'},

    '-moz-user-focus':
{'description': "Used to indicate whether the element can have the focus. By setting this to 'ignore', you can disable focusing the element, which means that the user will not be able to activate the element. The element will be skipped in the tab sequence. A similar property 'user-focus' has been proposed for CSS3.",
        'values': {'ignore': 'The element does not accept the keyboard focus and will be skipped in the tab order.',
                          'normal': 'The element can accept the keyboard focus.'}},

    '-moz-user-input':
{'description': 'In Mozilla applications, -moz-user-input determines if an element will accept user input.',
        'values': {'disabled': 'The element does not accept user input. However, this is not the same as setting disabled to true, in that the element is drawn normally.',
                          'enabled': 'The element accepts user input. For textboxes, this is the default behavior.',
                          'none': 'The element does not respond to user input, and it does not become :active .'}},

    '-moz-user-modify':
{},

    '-moz-user-select':
{'description': "Controls the appearance (only) of selection. This does not have any affect on actual selection operation. This doesn't have any effect on content loaded as chrome, except in textboxes.",
        'values': {'-moz-none': 'The text of the element and sub-elements cannot be selected, but selection can be enabled on sub-elements using -moz-user-select:text .',
                          'all': 'In HTML editor, if double-click or context-click occurred in sub-elements, the highest ancestor with this value will be selected.',
                          'none': 'The text of the element and sub-elements will appear as if they cannot be selected. Any use of Selection however will contain these elements.',
                          'text': 'The text can be selected by the user.'}},

    '-moz-window-shadow':
{'description': '-moz-window-shadow specifies whether a window will have a shadow. Currently it only works on Mac OS X.',
        'values': {'default': 'The window will have a shadow with the default window shadow style.',
                          'none': "The window won't have a shadow."}},
}


### END: Auto generated


CSS_MOZ_SPECIFIC_ATTRS_DICT = {}
CSS_MOZ_SPECIFIC_CALLTIP_DICT = {}
for attr, details in CSS_MOZ_DATA.items():
    values = details.get("values", {})
    attr_completions = sorted(values.keys())
    if attr_completions:
        CSS_MOZ_SPECIFIC_ATTRS_DICT[attr] = attr_completions
    else:
        CSS_MOZ_SPECIFIC_ATTRS_DICT[attr] = None
    description = details.get("description")
    if description:
        desc_lines = textwrap.wrap(description, width=60)
        if values:
            desc_lines.append("")
            for value, attr_desc in values.items():
                attr_desc = "  %r: %s" % (value, attr_desc)
                attr_desc_lines = textwrap.wrap(attr_desc, width=50)
                for i in range(len(attr_desc_lines)):
                    attr_line = attr_desc_lines[i]
                    if i > 0:
                        attr_line = "        " + attr_line
                    desc_lines.append(attr_line)
        CSS_MOZ_SPECIFIC_CALLTIP_DICT[attr] = "\n".join(
            desc_lines).encode("ascii", 'replace')

########NEW FILE########
__FILENAME__ = constants_css_webkit_extensions
"""
Safari/Webkit CSS extensions.
"""

import textwrap

### START: Auto generated

CSS_WEBKIT_DATA = {

    '-webkit-animation':
    {'description': u'Combines common animation properties into a single property.',
        'syntax': u'-webkit-animation: name duration timing_function delay iteration_count direction [, ... ];',
        'values': {u'delay': u'Defines when an animation starts.',
                  u'direction': u'Determines whether the animation should play in reverse on alternate iterations.',
                  u'duration': u'Specifies the length of time that an animation takes to complete one iteration.',
                  u'iteration_count': u'Specifies the number of times an animation iterates.',
                  u'name': u'The name of the animation.',
                  u'timing_function': u'Defines how an animation progresses between keyframes.'},
        'versions': [u'Safari 4.0', u'iPhone OS 2.0']},

    '-webkit-animation-delay':
{'description': u'Defines when an animation starts.',
 'syntax': u'-webkit-animation-delay: time [, ...];',
 'values': {u'0': u'(by default) ',
                  u'now': u'The animation begins immediately. Available in iPhone OS 2.0 and later.'},
 'versions': [u'Safari 4.0', u'iPhone OS 2.0']},

    '-webkit-animation-direction':
{'description': u'Determines whether the animation should play in reverse on alternate iterations.',
 'syntax': u'-webkit-animation-direction: direction [, ...]',
 'values': {u'alternate': u'Play even-numbered iterations of the animation in the forward direction and odd-numbered iterations in the reverse direction. \n When an animation is played in reverse, the timing functions are also reversed. For example, when played in reverse, an ease-in animation appears as an ease-out animation.',
                          u'normal': u'(by default) Play each iteration of the animation in the forward direction.'},
 'versions': [u'Safari 4.0', u'iPhone OS 2.0']},

    '-webkit-animation-duration':
{'description': u'Specifies the length of time that an animation takes to complete one iteration.',
 'syntax': u'-webkit-animation-duration: time [, ...]',
 'values': {u'0': u'(by default) ', u'<time>': ''},
 'versions': [u'Safari 4.0', u'iPhone OS 2.0']},

    '-webkit-animation-iteration-count':
{'description': u'Specifies the number of times an animation iterates.',
 'syntax': u'-webkit-animation-iteration-count: number [, ...]',
 'values': {u'1': u'(by default) ',
                  u'infinite': u'Repeats the animation forever.'},
 'versions': [u'Safari 4.0', u'iPhone OS 2.0']},

    '-webkit-animation-name':
{'description': u'Specifies the name of an animation.',
 'syntax': u'-webkit-animation-name: name [, ...]',
 'values': {u'name': u'The name of the animation.'},
 'versions': [u'Safari 4.0', u'iPhone OS 2.0']},

    '-webkit-animation-play-state':
{'description': u'Determines whether the animation is running or paused.',
 'syntax': u'-webkit-animation-play-state: play_state [, ...];',
 'values': {u'paused': u'Pauses the animation.',
            u'running': u'(by default) Plays the animation.'},
 'versions': [u'Safari 4.0', u'iPhone OS 2.0']},

    '-webkit-animation-timing-function':
{'description': u'Defines how an animation progresses between keyframes.',
 'syntax': u'-webkit-animation-timing-function: function [, ...]',
 'values': {u'<function>': '',
            u'ease': u'(by default) Equivalent to  cubic-bezier(0.25, 0.1, 0.25, 1.0) .',
            u'ease-in': u'Equivalent to  cubic-bezier(0.42, 0, 1.0, 1.0) .',
            u'ease-in-out': u'Equivalent to  cubic-bezier(0.42, 0, 0.58, 1.0) .',
            u'ease-out': u'Equivalent to  cubic-bezier(0, 0, 0.58, 1.0) .',
            u'linear': u'Equivalent to  cubic-bezier(0.0, 0.0, 1.0, 1.0) .'},
 'versions': [u'Safari 4.0', u'iPhone OS 2.0']},

    '-webkit-appearance':
{'description': u'Changes the appearance of buttons and other controls to resemble native controls.',
 'syntax': u'-webkit-appearance: appearance;',
 'values': {u'button': '',
            u'button-bevel': '',
            u'caps-lock-indicator': u'The indicator that appears in a password field when Caps Lock is active. Available in Safari 4.0 and later. Available in iPhone OS 2.0 and later.',
            u'caret': '',
            u'checkbox': '',
            u'default-button': '',
            u'listbox': '',
            u'listitem': '',
            u'media-fullscreen-button': '',
            u'media-mute-button': '',
            u'media-play-button': '',
            u'media-seek-back-button': '',
            u'media-seek-forward-button': '',
            u'media-slider': '',
            u'media-sliderthumb': '',
            u'menulist': '',
            u'menulist-button': '',
            u'menulist-text': '',
                          u'menulist-textfield': '',
                          u'none': '',
                          u'push-button': '',
                          u'radio': '',
                          u'scrollbarbutton-down': u'Unsupported in Safari 4.0',
                          u'scrollbarbutton-left': u'Unsupported in Safari 4.0',
                          u'scrollbarbutton-right': u'Unsupported in Safari 4.0',
                          u'scrollbarbutton-up': u'Unsupported in Safari 4.0',
                          u'scrollbargripper-horizontal': u'Unsupported in Safari 4.0',
                          u'scrollbargripper-vertical': u'Unsupported in Safari 4.0',
                          u'scrollbarthumb-horizontal': u'Unsupported in Safari 4.0',
                          u'scrollbarthumb-vertical': u'Unsupported in Safari 4.0',
                          u'scrollbartrack-horizontal': u'Unsupported in Safari 4.0',
                          u'scrollbartrack-vertical': u'Unsupported in Safari 4.0',
                          u'searchfield': '',
                          u'searchfield-cancel-button': '',
                          u'searchfield-decoration': '',
                          u'searchfield-results-button': '',
                          u'searchfield-results-decoration': '',
                          u'slider-horizontal': '',
                          u'slider-vertical': '',
                          u'sliderthumb-horizontal': '',
                          u'sliderthumb-vertical': '',
                          u'square-button': '',
                          u'textarea': '',
                          u'textfield': ''},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-backface-visibility':
{'description': u'Determines whether or not a transformed element is visible when it is not facing the screen.',
        'syntax': u'-webkit-backface-visibility: visibility;',
        'values': {u'hidden': u'The element is invisible if it is not facing the screen.',
                          u'visible': u'(by default) The element is always visible even when it is not facing the screen.'},
        'versions': [u'iPhone OS 2.0']},

    '-webkit-background-clip':
{'description': u'Specifies the clipping behavior of the background of a box.',
        'syntax': u'-webkit-background-clip: behavior;',
        'values': {u'border': u'The background clips to the border of the box.',
                          u'content': u'The background clips to the content of the box.',
                          u'padding': u'The background clips to the padding of the box.',
                          u'text': u'The background clips to the text of the box. Available in Safari 4.0 and later.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-background-composite':
{'description': u'Sets a compositing style for background images and colors.',
        'syntax': u'-webkit-background-composite: compositing_style;',
        'values': {u'border': u'(by default) The background extends into the border area',
                          u'padding': u'The background extends only into the padding area enclosed by the border'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-background-origin':
{'description': u'Determines where the  background-position  property is anchored.',
        'syntax': u'-webkit-background-origin: origin;',
        'values': {u'origin': u'The origin of the background position.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-background-size':
{'description': u'Overrides the size of a background image.',
        'syntax': u'-webkit-background-size: length;',
        'values': {u'length': u'The width and height of the background image.',
                          u'length_x': u'The width of the background image.',
                          u'length_y': u'The height of the background image.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-border-bottom-left-radius':
{'description': u'Specifies that the bottom-left corner of a box be rounded with the specified radius.',
        'syntax': u'-webkit-border-bottom-left-radius: radius;',
        'values': {u'horizontal_radius': u'The horizontal radius of the rounded corner.',
                          u'radius': u'The radius of the rounded corner.',
                          u'vertical_radius': u'The vertical radius of the rounded corner.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-border-bottom-right-radius':
{'description': u'Specifies that the bottom-right corner of a box be rounded with the specified radius.',
        'syntax': u'-webkit-border-bottom-right-radius: radius;',
        'values': {u'horizontal_radius': u'The horizontal radius of the rounded corner.',
                          u'radius': u'The radius of the rounded corner.',
                          u'vertical_radius': u'The vertical radius of the rounded corner.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-border-horizontal-spacing':
{'description': u'Defines the spacing between the horizontal portion of an element\u2019s border and the content within.',
        'syntax': u'-webkit-border-horizontal-spacing: value;',
        'values': {u'value': u'The amount of horizontal spacing.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-border-image':
{'description': u'Specifies an image as the border for a box.',
        'syntax': u'-webkit-border-image: uri top right bottom left x_repeat y_repeat',
        'values': {u'repeat': u'The image is tiled.',
                          u'round': u'The image is stretched before it is tiled to prevent partial tiles.',
                          u'stretch': u'The image is stretched to the size of the border.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-border-radius':
{'description': u'Specifies that the corners of a box be rounded with the specified radius.',
        'syntax': u'-webkit-border-radius: radius;',
        'values': {u'horizontal_radius': u'The horizontal radius of the rounded corners.',
                          u'radius': u'The radius of the rounded corners.',
                          u'vertical_radius': u'The vertical radius of the rounded corners.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-border-top-left-radius':
{'description': u'Specifies that the top-left corner of a box be rounded with the specified radius.',
        'syntax': u'-webkit-border-top-left-radius: radius;',
        'values': {u'horizontal_radius': u'The horizontal radius of the rounded corner.',
                          u'radius': u'The radius of the rounded corner.',
                          u'vertical_radius': u'The vertical radius of the rounded corner.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-border-top-right-radius':
{'description': u'Specifies that the top-right corner of a box be rounded with the specified radius.',
        'syntax': u'-webkit-border-top-right-radius: radius;',
        'values': {u'horizontal_radius': u'The horizontal radius of the rounded corner.',
                          u'radius': u'The radius of the rounded corner.',
                          u'vertical_radius': u'The vertical radius of the rounded corner.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-border-vertical-spacing':
{'description': u'Defines the spacing between the vertical portion of an element\u2019s border and the content within.',
        'syntax': u'-webkit-border-vertical-spacing: value;',
        'values': {u'value': u'The amount of vertical spacing.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-box-align':
{'description': u'Specifies the alignment of nested elements within an outer flexible box element.',
        'syntax': u'-webkit-box-align: alignment;',
        'values': {u'baseline': u'Elements are aligned with the baseline of the box.',
                          u'center': u'Elements are aligned with the center of the box.',
                          u'end': u'Elements are aligned with the end of the box.',
                          u'start': u'Elements are aligned with the start of the box.',
                          u'stretch': u'Elements are stretched to fill the box.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-box-direction':
{'description': u'Specifies the direction in which child elements of a flexible box element are laid out.',
        'syntax': u'-webkit-box-direction: layout_direction;',
        'values': {u'normal': u'(by default) Elements are laid out in the default direction.',
                          u'reverse': u'Elements are laid out in the reverse direction.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-box-flex':
{'description': u'Specifies an element\u2019s flexibility.',
        'syntax': u'-webkit-box-flex: flex_value;',
        'values': {u'<flexvalue>': u'Floating-point number'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-box-flex-group':
{'description': u'Specifies groups of dynamically resizing elements that are adjusted to be the same size.',
        'syntax': u'-webkit-box-flex-group: group_number;',
        'values': {u'<group_number>': u'Integer, nonnegative value'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-box-lines':
{'description': u'Specifies whether a flexible box should contain multiple lines of content.',
        'syntax': u'-webkit-box-lines: behavior;',
        'values': {u'multiple': u'The box can contain multiple lines of content.',
                          u'single': u'The box can contain only one line of content.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-box-ordinal-group':
{'description': u'Specifies a rough ordering of elements in a flexible box.',
        'syntax': u'-webkit-box-ordinal-group: group_number;',
        'values': {u'<group_number>': u'Integer, nonnegative value'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-box-orient':
{'description': u'Specifies the layout of elements nested within a flexible box element.',
        'syntax': u'-webkit-box-orient: orientation;',
        'values': {u'block-axis': u"Elements are oriented along the box's axis.",
                          u'horizontal': u'Elements are oriented horizontally.',
                          u'inline-axis': u'Elements are oriented along the inline axis.',
                          u'vertical': u'Elements are oriented vertically.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-box-pack':
{'description': u'Specifies alignment of child elements within the current element in the direction of orientation.',
        'syntax': u'-webkit-box-pack: alignment;',
        'values': {u'center': u'Child elements are aligned to the center of the element.',
                          u'end': u'Child elements are aligned to the end of the element.',
                          u'justify': u'Child elements are justified with both the start and end of the element.',
                          u'start': u'Child elements are aligned to the start of the element.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-box-reflect':
{'description': u'Defines a reflection of a border box.',
        'syntax': u'-webkit-box-reflect: direction offset mask-box-image;',
        'values': {u'above': u'The reflection appears above the border box.',
                          u'below': u'The reflection appears below the border box.',
                          u'left': u'The reflection appears to the left of the border box.',
                          u'right': u'The reflection appears to the right of the border box.'},
        'versions': [u'iPhone OS 2.0']},

    '-webkit-box-shadow':
{'description': u'Applies a drop shadow effect to the border box of an object.',
        'syntax': u'-webkit-box-shadow: hoff voff blur color;',
        'values': {u'none': u'(by default) The box has no shadow.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-box-sizing':
{'description': u'Specifies that the size of a box be measured according to either its content (default) or its total size including borders.',
        'syntax': u'-webkit-box-sizing: sizing_model;',
        'values': {u'border-box': u'The box size includes borders in addition to content.',
                          u'content-box': u'(by default) The box size only includes content.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-column-break-after':
{'description': u'Determines whether a column break can and should occur after an element in a multicolumn flow layout.',
        'syntax': u'-webkit-column-break-after: policy;',
        'values': {u'always': u'A column break is always inserted after the element.',
                          u'auto': u'(by default) A right column break is inserted after the element where appropriate.',
                          u'avoid': u'Column breaks are avoided after the element.',
                          u'left': u'A left column break is inserted after the element.',
                          u'right': u'A right column break is inserted after the element.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-column-break-before':
{'description': u'Determines whether a column break can and should occur before an element in a multicolumn flow layout.',
        'syntax': u'-webkit-column-break-before: policy;',
        'values': {u'always': u'A column break is always inserted before the element.',
                          u'auto': u'(by default) A right column break is inserted before the element where appropriate.',
                          u'avoid': u'Column breaks are avoided before the element.',
                          u'left': u'A left column break is inserted before the element.',
                          u'right': u'A right column break is inserted before the element.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-column-break-inside':
{'description': u'Determines whether a column break should be avoided within the bounds of an element in a multicolumn flow layout.',
        'syntax': u'-webkit-column-break-inside: policy;',
        'values': {u'auto': u'(by default) A right column break is inserted within the element where appropriate.',
                          u'avoid': u'Column breaks are avoided within the element.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-column-count':
{'description': u'Specifies the number of columns desired in a multicolumn flow.',
        'syntax': u'-webkit-column-count: number_of_columns;',
        'values': {u'<number_of_columns>': u'Integer, nonnegative value',
                          u'auto': u'(by default) The element has one column.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-column-gap':
{'description': u'Specifies the space between columns in a multicolumn flow.',
        'syntax': u'-webkit-column-gap: width;',
        'values': {u'<width>': u'Length unit',
                          u'normal': u'(by default) Columns in the element have the normal gap width between them.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-column-rule':
{'description': u'Specifies the color, style, and width of the column rule.',
        'syntax': u'-webkit-column-rule: width style color;',
        'values': {u'color': u'The color of the column rule.',
                          u'style': u'The style of the column rule.',
                          u'width': u'The width of the column rule.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-column-rule-color':
{'description': u'Specifies the color of the column rule.',
        'syntax': u'-webkit-column-rule-color: color;',
        'values': {u'-webkit-activelink': u'The default color of a hyperlink that is being clicked.',
                          u'-webkit-focus-ring-color': u'The color that surrounds a UI element, such as a text field, that has focus.',
                          u'-webkit-link': u'The default color of a hyperlink that has been visited.',
                          u'-webkit-text': u'The default text color.',
                          u'activeborder': '',
                          u'activecaption': '',
                          u'appworkspace': '',
                          u'aqua': '',
                          u'background': '',
                          u'black': '',
                          u'blue': '',
                          u'buttonface': '',
                          u'buttonhighlight': '',
                          u'buttonshadow': '',
                          u'buttontext': '',
                          u'captiontext': '',
                          u'currentcolor': u"(by default) The value of the element's color property.",
                          u'fuchsia': '',
                          u'gray': '',
                          u'graytext': '',
                          u'green': '',
                          u'grey': '',
                          u'highlight': '',
                          u'highlighttext': '',
                          u'inactiveborder': '',
                          u'inactivecaption': '',
                          u'inactivecaptiontext': '',
                          u'infobackground': '',
                          u'infotext': '',
                          u'lime': '',
                          u'maroon': '',
                          u'match': '',
                          u'menu': '',
                          u'menutext': '',
                          u'navy': '',
                          u'olive': '',
                          u'orange': '',
                          u'purple': '',
                          u'red': '',
                          u'scrollbar': '',
                          u'silver': '',
                          u'teal': '',
                          u'threeddarkshadow': '',
                          u'threedface': '',
                          u'threedhighlight': '',
                          u'threedlightshadow': '',
                          u'threedshadow': '',
                          u'transparent': '',
                          u'white': '',
                          u'window': '',
                          u'windowframe': '',
                          u'windowtext': '',
                          u'yellow': ''},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-column-rule-style':
{'description': u'Specifies the style of the column rule.',
        'syntax': u'-webkit-column-rule-style: style;',
        'values': {u'dashed': u'The column rule has a dashed line style.',
                          u'dotted': u'The column rule has a dotted line style.',
                          u'double': u'The column rule has a double solid line style.',
                          u'groove': u'The column rule has a grooved style.',
                          u'hidden': u'The column rule is hidden.',
                          u'inset': u'The column rule has an inset style.',
                          u'none': u'The column rule has no style.',
                          u'outset': u'The column rule has an outset style.',
                          u'ridge': u'The column rule has a ridged style.',
                          u'solid': u'The column rule has a solid line style.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-column-rule-width':
{'description': u'Specifies the width of the column rule.',
        'syntax': u'-webkit-column-rule-width: width;',
        'values': {u'<width>': u'Length unit',
                          u'medium': u'The column rule has a medium width.',
                          u'thick': u'The column rule has a thick width.',
                          u'thin': u'The column rule has a thin width.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-column-width':
{'description': u'Specifies the width of the column in a multicolumn flow.',
        'syntax': u'-webkit-column-width: width;',
        'values': {u'<width>': u'Length unit',
                          u'auto': u'(by default) Columns in the element are of normal width.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-columns':
{'description': u'A composite property that specifies the width and number of columns in a multicolumn flow layout.',
        'syntax': u'-webkit-columns: width count;',
        'values': {u'count': u'The number of columns.',
                          u'width': u'The width of each column.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-dashboard-region':
{'description': u'Specifies the behavior of regions in a Dashboard widget.',
        'syntax': u'-webkit-dashboard-region: dashboard-region(...) [...];',
        'values': {u'none': u'No behavior is specified.'},
        'versions': [u'Safari 3.0']},

    '-webkit-line-break':
{'description': u'Specifies line-breaking rules for CJK (Chinese, Japanese, and Korean) text.',
        'syntax': u'-webkit-line-break: setting;',
        'values': {u'after-white-space': u'The line breaks after white space.',
                          u'normal': u'(by default) A standard line-breaking rule.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-margin-bottom-collapse':
{'description': u"Specifies the behavior of an element's bottom margin if it is adjacent to an element with a margin. Elements can maintain their respective margins or share a single margin between them.",
        'syntax': u'-webkit-margin-bottom-collapse: collapse_behavior;',
        'values': {u'collapse': u'Two adjacent margins are collapsed into a single margin.',
                          u'discard': u'The element\u2019s margin is discarded if it is adjacent to another element with a margin.',
                          u'separate': u'Two adjacent margins remain separate.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-margin-collapse':
{'description': u'Specifies the behavior of an element\u2019s vertical margins if it is adjacent to an element with a margin. Elements can maintain their respective margins or share a single margin between them.',
        'syntax': u'-webkit-margin-collapse: collapse_behavior;',
        'values': {u'collapse_behavior': u'The behavior of the vertical margins.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-margin-start':
{'description': u'Provides the width of the starting margin.',
        'syntax': u'-webkit-margin-start: width;',
        'values': {u'<width>': u'Number as a percentage, length unit',
                          u'auto': u'(by default) The margin is automatically determined.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-margin-top-collapse':
{'description': u'Specifies the behavior of an element\u2019s top margin if it is adjacent to an element with a margin. Elements can maintain their respective margins or share a single margin between them.',
        'syntax': u'-webkit-margin-top-collapse: collapse_behavior;',
        'values': {u'collapse': u'Two adjacent margins are collapsed into a single margin.',
                          u'discard': u'The element\u2019s margin is discarded if it is adjacent to another element with a margin.',
                          u'separate': u'Two adjacent margins remain separate.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-marquee':
{'description': u'Defines properties for showing content as though displayed on an electronic marquee sign.',
        'syntax': u'-webkit-marquee: direction increment repetition style speed;',
        'values': {u'direction': u'The direction of the marquee.',
                          u'increment': u'The distance the marquee moves in each increment',
                          u'repetition': u'The number of times the marquee repeats.',
                          u'speed': u'The scroll or slide speed of the marquee.',
                          u'style': u'The style of the marquee\u2019s motion.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-marquee-direction':
{'description': u'Specifies the direction of motion for a marquee box.',
        'syntax': u'-webkit-marquee-direction: direction;',
        'values': {u'ahead': u'The marquee moves from bottom to top.',
                          u'auto': u'(by default) The marquee moves in the default direction.',
                          u'backwards': u'The marquee moves from right to left.',
                          u'down': u'The marquee moves from bottom to top.',
                          u'forwards': u'The marquee moves from left to right.',
                          u'left': u'The marquee moves from right to left.',
                          u'reverse': u'The marquee moves from top to bottom.',
                          u'right': u'The marquee moves from left to right.',
                          u'up': u'The marquee moves from bottom to top.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-marquee-increment':
{'description': u'Defines the distance the marquee moves in each increment.',
        'syntax': u'-webkit-marquee-increment: distance;',
        'values': {u'<distance>': u'Number as a percentage, length unit',
                          u'large': u'The marquee moves a large amount in each increment.',
                          u'medium': u'The marquee moves a medium amount in each increment.',
                          u'small': u'The marquee moves a small amount in each increment.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-marquee-repetition':
{'description': u'Specifies the number of times a marquee box repeats (or  infinite ).',
        'syntax': u'-webkit-marquee-repetition: iterations;',
        'values': {u'<iterations>': u'Integer, nonnegative value',
                          u'infinite': u'(by default) The marquee repeats infinitely.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-marquee-speed':
{'description': u'Defines the scroll or slide speed of a marquee box.',
        'syntax': u'-webkit-marquee-speed: speed;',
        'values': {u'<distance>': u'Integer, nonnegative value',
                          u'<time>': u'Time unit, nonnegative value',
                          u'fast': u'The marquee moves at a fast speed.',
                          u'normal': u'The marquee moves at a normal speed.',
                          u'slow': u'The marquee moves at a slow speed.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-marquee-style':
{'description': u'Specifies the style of marquee motion.',
        'syntax': u'-webkit-marquee-style: style;',
        'values': {u'alternate': u'The marquee shifts back and forth.',
                          u'none': u'The marquee does not move.',
                          u'scroll': u'The marquee loops in its specified direction.',
                          u'slide': u'The marquee moves in its specified direction, but stops either when the entirety of its content has been displayed or the content reaches the opposite border of its box, whichever comes second.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-mask':
{'description': u'Defines a variety of mask properties within one declaration.',
        'syntax': u'-webkit-mask: attachment, clip, origin, image, repeat, composite, box-image;',
        'values': {u'attachment': u'Defines the scrolling or fixed nature of the image mask. See  -webkit-mask-attachment .',
                          u'clip': u'Specifies whether the mask should extend into the border of a box. See  -webkit-mask-clip .',
                          u'composite': u'Sets a compositing style for a mask. See  -webkit-mask-composite .',
                          u'image': u'Defines an image to be used as a mask for an element. See  -webkit-mask-image .',
                          u'origin': u'Determines where the  -webkit-mask-position  property is anchored. See  -webkit-mask-origin .',
                          u'repeat': u'Defines the repeating qualities of a mask. See  -webkit-mask-repeat .'},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-attachment':
{'description': u'Defines the scrolling or fixed nature of the image mask.',
        'syntax': u'-webkit-mask-attachment: mask_attachment;',
        'values': {u'fixed': u'The mask does not move when the page scrolls.',
                          u'scroll': u'The image moves when the page scrolls.'},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-box-image':
{'description': u'Defines an image to be used as a mask for a border box.',
        'syntax': u'-webkit-mask-box-image: uri top right bottom left x_repeat y_repeat;',
        'values': {u'bottom': u'The distance from the bottom edge of the image.',
                          u'left': u'The distance from the left edge of the image.',
                          u'right': u'The distance from the right edge of the image.',
                          u'top': u'The distance from the top edge of the image.',
                          u'uri': u'The file path of the image.',
                          u'x_repeat': u'The horizontal repeat style.',
                          u'y_repeat': u'The vertical repeat style.'},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-clip':
{'description': u'Specifies whether the mask should extend into the border of a box.',
        'syntax': u'-webkit-mask-clip: behavior;',
        'values': {u'behavior': u'The clipping behavior of the mask.'},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-composite':
{'description': u'Sets a compositing style for a mask.',
        'syntax': u'-webkit-mask-composite: compositing_style;',
        'values': {u'border': u'(by default) ', u'padding': ''},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-image':
{'description': u'Defines an image to be used as a mask for an element.',
        'syntax': u'-webkit-mask-image: value;',
        'values': {u'value': u'The file path of the image.'},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-origin':
{'description': u'Determines where the -webkit-mask-position property is anchored.',
        'syntax': u'-webkit-mask-origin: origin;',
        'values': {u'border': u"The mask's position is anchored at the upper-left corner of the element's border.",
                          u'content': u"The mask's position is anchored at the upper-left corner of the element's content.",
                          u'padding': u"The mask's position is anchored at the upper-left corner of the element's padding."},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-position':
{'description': u'Defines the position of a mask.',
        'syntax': u'-webkit-mask-position: xpos;',
        'values': {u'<position>': '',
                          u'bottom': '',
                          u'center': '',
                          u'left': '',
                          u'right': '',
                          u'top': ''},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-position-x':
{'description': u'Defines the x-coordinate of the position of a mask.',
        'syntax': u'-webkit-mask-position-x: value;',
        'values': {u'value': u'The x-coordinate of the position of the mask.'},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-position-y':
{'description': u'Defines the y-coordinate of the position of a mask.',
        'syntax': u'-webkit-mask-position-y: value;',
        'values': {u'value': u'The y-coordinate of the position of the mask.'},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-repeat':
{'description': u'Defines the repeating qualities of a mask.',
        'syntax': u'-webkit-mask-repeat: value;',
        'values': {u'value': u'The repeating behavior of the mask.'},
        'versions': [u'Safari 4.0']},

    '-webkit-mask-size':
{'description': u'Overrides the size of a mask.',
        'syntax': u'-webkit-mask-size: length;',
        'values': {u'length': u'The width and height of the mask.',
                          u'length_x': u'The width of the mask.',
                          u'length_y': u'The height of the mask.'},
        'versions': [u'Safari 4.0']},

    '-webkit-nbsp-mode':
{'description': u'Defines the behavior of nonbreaking spaces within text.',
        'syntax': u'-webkit-nbsp-mode: behavior;',
        'values': {u'normal': u'Nonbreaking spaces are treated as usual.',
                          u'space': u'Nonbreaking spaces are treated like standard spaces.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-padding-start':
{'description': u'Provides the width of the starting padding.',
        'syntax': u'-webkit-padding-start: width;',
        'values': {u'<length>': '', u'<percentage>': ''},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-perspective':
{'description': u'Gives depth to a scene, causing elements farther away from the viewer to appear smaller.',
        'syntax': u'-webkit-perspective: value;',
        'values': {u'<distance>': u'Length in pixel',
                          u'none': u'(by default) No perspective transform is applied.'},
        'versions': [u'iPhone OS 2.0']},

    '-webkit-perspective-origin':
{'description': u'Sets the origin of the  -webkit-perspective  property described in  "-webkit-perspective."',
        'syntax': u'-webkit-perspective-origin: posx posy;',
        'values': {u'50%': u'50% (by default) ',
                          u'<percentage>': '',
                          u'bottom': u'Sets the y-origin to the bottom of the element\u2019s border box.',
                          u'center': u'Sets the x or y origin to the center of the element\u2019s border box. If this constant appears before  left  or  right , specifies the y-origin. If it appears after  top  or  bottom , specifies the x-origin. If appears alone, centers both the x and y origin.',
                          u'left': u'Sets the x-origin to the left side of the border box.',
                          u'right': u'Sets the x-origin to the right side of the border box.',
                          u'top': u'Sets the y-origin to the top of the element\u2019s border box.'},
        'versions': [u'iPhone OS 2.0']},

    '-webkit-rtl-ordering':
{'description': u'Overrides ordering defaults for right-to-left content.',
        'syntax': u'-webkit-rtl-ordering: order;',
        'values': {u'logical': u'Raw content is in mixed order (requiring a bidirectional renderer).',
                          u'visual': u'Right-to-left content is encoded in reverse order so an entire line of text can be rendered from left to right in a unidirectional fashion.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-tap-highlight-color':
{'description': u'Overrides the highlight color shown when the user taps a link or a JavaScript clickable element in Safari on iPhone.',
        'syntax': u'-webkit-tap-highlight-color: color;',
        'values': {u'color': u'The tapped link color.'},
        'versions': [u'iPhone OS 1.1.1']},

    '-webkit-text-fill-color':
{'description': u'Specifies a fill color for text.',
        'syntax': u'-webkit-text-fill-color: color;',
        'values': {u'-webkit-activelink': u'The default color of a hyperlink that is being clicked.',
                          u'-webkit-focus-ring-color': u'The color that surrounds a UI element, such as a text field, that has focus.',
                          u'-webkit-link': u'The default color of a hyperlink that has been visited.',
                          u'-webkit-text': u'The default text color.',
                          u'activeborder': '',
                          u'activecaption': '',
                          u'appworkspace': '',
                          u'aqua': '',
                          u'background': '',
                          u'black': '',
                          u'blue': '',
                          u'buttonface': '',
                          u'buttonhighlight': '',
                          u'buttonshadow': '',
                          u'buttontext': '',
                          u'captiontext': '',
                          u'currentcolor': u'(by default) The value of the element\u2019s color property.',
                          u'fuchsia': '',
                          u'gray': '',
                          u'graytext': '',
                          u'green': '',
                          u'grey': '',
                          u'highlight': '',
                          u'highlighttext': '',
                          u'inactiveborder': '',
                          u'inactivecaption': '',
                          u'inactivecaptiontext': '',
                          u'infobackground': '',
                          u'infotext': '',
                          u'lime': '',
                          u'maroon': '',
                          u'match': '',
                          u'menu': '',
                          u'menutext': '',
                          u'navy': '',
                          u'olive': '',
                          u'orange': '',
                          u'purple': '',
                          u'red': '',
                          u'scrollbar': '',
                          u'silver': '',
                          u'teal': '',
                          u'threeddarkshadow': '',
                          u'threedface': '',
                          u'threedhighlight': '',
                          u'threedlightshadow': '',
                          u'threedshadow': '',
                          u'transparent': '',
                          u'white': '',
                          u'window': '',
                          u'windowframe': '',
                          u'windowtext': '',
                          u'yellow': ''},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-text-security':
{'description': u'Specifies the shape to use in place of letters in a password input field.',
        'syntax': u'-webkit-text-security: shape;',
        'values': {u'circle': u'A circle shape.',
                          u'disc': u'A disc shape.',
                          u'none': u'No shape is used.',
                          u'square': u'A square shape.'},
        'versions': [u'Safari 3.0', u'iPhone OS 1.0']},

    '-webkit-text-size-adjust':
{'description': u'Specifies a size adjustment for displaying text content in Safari on iPhone.',
        'syntax': u'-webkit-text-size-adjust: percentage;',
        'values': {u'<percentage>': u'The size in percentage at which to display text in Safari on iPhone.',
                          u'auto': u'The text size is automatically adjusted for Safari on iPhone.',
                          u'none': u'(by default) The text size is not adjusted.'},
        'versions': [u'iPhone OS 1.0']},

    '-webkit-text-stroke':
{'description': u'Specifies the width and color of the outline (stroke) of text.',
        'syntax': u'-webkit-text-stroke: width color;',
        'values': {u'color': u'The color of the stroke.',
                          u'width': u'The width of the stroke.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-text-stroke-color':
{'description': u'Specifies the color of the outline (stroke) of text.',
        'syntax': u'-webkit-text-stroke-color: color;',
        'values': {u'-webkit-activelink': u'The default color of a hyperlink that is being clicked.',
                          u'-webkit-focus-ring-color': u'The color that surrounds a UI element, such as a text field, that has focus.',
                          u'-webkit-link': u'The default color of a hyperlink that has been visited.',
                          u'-webkit-text': u'The default text color.',
                          u'activeborder': '',
                          u'activecaption': '',
                          u'appworkspace': '',
                          u'aqua': '',
                          u'background': '',
                          u'black': '',
                          u'blue': '',
                          u'buttonface': '',
                          u'buttonhighlight': '',
                          u'buttonshadow': '',
                          u'buttontext': '',
                          u'captiontext': '',
                          u'currentcolor': u"(by default) The value of the element's color property.",
                          u'fuchsia': '',
                          u'gray': '',
                          u'graytext': '',
                          u'green': '',
                          u'grey': '',
                          u'highlight': '',
                          u'highlighttext': '',
                          u'inactiveborder': '',
                          u'inactivecaption': '',
                          u'inactivecaptiontext': '',
                          u'infobackground': '',
                          u'infotext': '',
                          u'lime': '',
                          u'maroon': '',
                          u'match': '',
                          u'menu': '',
                          u'menutext': '',
                          u'navy': '',
                          u'olive': '',
                          u'orange': '',
                          u'purple': '',
                          u'red': '',
                          u'scrollbar': '',
                          u'silver': '',
                          u'teal': '',
                          u'threeddarkshadow': '',
                          u'threedface': '',
                          u'threedhighlight': '',
                          u'threedlightshadow': '',
                          u'threedshadow': '',
                          u'transparent': '',
                          u'white': '',
                          u'window': '',
                          u'windowframe': '',
                          u'windowtext': '',
                          u'yellow': ''},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-text-stroke-width':
{'description': u'Specifies the width for the text outline.',
        'syntax': u'-webkit-text-stroke-width: width;',
        'values': {u'<width>': u'Length unit',
                          u'medium': u'A medium stroke.',
                          u'thick': u'A thick stroke.',
                          u'thin': u'A thin stroke.'},
        'versions': [u'Safari 3.0', u'iPhone OS 2.0']},

    '-webkit-touch-callout':
{'description': u'Disables the default callout shown when you touch and hold a touch target.',
        'syntax': u'-webkit-touch-callout: behavior;',
        'values': {u'inherit': '', u'none': ''},
        'versions': [u'iPhone OS 2.0']},

    '-webkit-transform':
{'description': u'Specifies transformations to be applied to an element.',
        'syntax': u'-webkit-transform: function ... ;',
        'values': {u'<function>': '',
                          u'none': u'(by default) No transforms are applied.'},
        'versions': [u'Safari 3.1', u'iPhone OS 2.0']},

    '-webkit-transform-origin':
{'description': u'Sets the origin for the  -webkit-transform  property.',
        'syntax': u'-webkit-transform-origin: posx;',
        'values': {u'50%': u'50% (by default) ',
                          u'bottom': '',
                          u'center': '',
                          u'left': '',
                          u'right': '',
                          u'top': ''},
        'versions': [u'Safari 3.1', u'iPhone OS 2.0']},

    '-webkit-transform-origin-x':
{'description': u'The x coordinate of the origin for transforms applied to an element with respect to its border box.',
        'syntax': u'-webkit-transform-origin-x: posx;',
        'values': {u'posx': u'The x origin as a percentage or value.'},
        'versions': [u'Safari 3.1', u'iPhone OS 2.0']},

    '-webkit-transform-origin-y':
{'description': u'The y coordinate of the origin for transforms applied to an element with respect to its border box.',
        'syntax': u'-webkit-transform-origin-y: posy;',
        'values': {u'posy': u'The y origin as a percentage or value.'},
        'versions': [u'Safari 3.1', u'iPhone OS 2.0']},

    '-webkit-transform-origin-z':
{'description': u'The z coordinate of the origin for transforms applied to an element with respect to its border box.',
        'syntax': u'-webkit-transform-origin-z: posz;',
        'values': {u'posz': u'The z origin as a percentage or value.'},
        'versions': [u'iPhone OS 2.0']},

    '-webkit-transform-style':
{'description': u'Defines how nested, transformed elements are rendered in 3D space.',
        'syntax': u'-webkit-transform-style: style;',
        'values': {u'flat': u'(by default) Flatten all children of this element into the 2D plane.',
                          u'preserve-3d': u'Preserve the 3D perspective.'},
        'versions': [u'iPhone OS 2.0']},

    '-webkit-transition':
{'description': u'Combines  -webkit-transition-delay ,  -webkit-transition-duration ,  -webkit-transition-property , and  -webkit-transition-timing-function  into a single property.',
        'syntax': u'-webkit-transition: property duration timing_function delay [, ...];',
        'values': {u'delay': u'Defines when the transition starts. See  -webkit-transition-delay .',
                          u'duration': u'Defines how long the transition from the old value to the new value should take. See  -webkit-transition-duration .',
                          u'property': u'Specifies the name of the CSS property to which the transition is applied. See  -webkit-transition-property .',
                          u'timing_function': u'Specifies how the intermediate values used during a transition are calculated. See  -webkit-transition-timing-function .'},
        'versions': [u'Safari 3.1', u'iPhone OS 2.0']},

    '-webkit-transition-delay':
{'description': u'Defines when the transition starts.',
        'syntax': u'-webkit-transition-delay: time [, ...];',
        'values': {u'0': u'(by default) ',
                          u'now': u'The transition begins immediately. Available in iPhone OS 2.0 and later.'},
        'versions': [u'Safari 4.0', u'iPhone OS 2.0']},

    '-webkit-transition-duration':
{'description': u'Defines how long the transition from the old value to the new value should take.',
        'syntax': u'-webkit-transition-duration: time [, ...];',
        'values': {u'0': u'(by default) '},
        'versions': [u'Safari 3.1', u'iPhone OS 2.0']},

    '-webkit-transition-property':
{'description': u'Specifies the name of the CSS property to which the transition is applied.',
        'syntax': u'-webkit-transition-property: name;',
        'values': {u'<name>': u'CSS property name',
                          u'all': u'(by default) The default transition name.',
                          u'none': u'No transition specified.'},
        'versions': [u'Safari 3.1', u'iPhone OS 2.0']},

    '-webkit-transition-timing-function':
{'description': u'Specifies how the intermediate values used during a transition are calculated.',
        'syntax': u'-webkit-transition-timing-function: timing_function [, ...];',
        'values': {u'<timing_function>': '',
                          u'ease': u'(by default) Equivalent to  cubic-bezier(0.25, 0.1, 0.25, 1.0)',
                          u'ease-in': u'Equivalent to  cubic-bezier(0.42, 0, 1.0, 1.0)',
                          u'ease-in-out': u'Equivalent to  cubic-bezier(0.42, 0, 0.58, 1.0)',
                          u'ease-out': u'Equivalent to  cubic-bezier(0, 0, 0.58, 1.0)',
                          u'linear': u'Equivalent to  cubic-bezier(0.0, 0.0, 1.0, 1.0)'},
        'versions': [u'Safari 3.1', u'iPhone OS 2.0']},

    '-webkit-user-drag':
{'description': u'Specifies that an entire element should be draggable instead of its contents.',
        'syntax': u'-webkit-user-drag: behavior;',
        'values': {u'auto': u'(by default) The default dragging behavior is used.',
                          u'element': u'The entire element is draggable instead of its contents.',
                          u'none': u'The element cannot be dragged at all.'},
        'versions': [u'Safari 3.0']},

    '-webkit-user-modify':
{'description': u'Determines whether a user can edit the content of an element.',
        'syntax': u'-webkit-user-modify: policy;',
        'values': {u'read-only': u'The content is read-only.',
                          u'read-write': u'The content can be read and written.',
                          u'read-write-plaintext-only': u'The content can be read and written, but any rich formatting of pasted text is lost.'},
        'versions': [u'Safari 3.0']},

    '-webkit-user-select':
{'description': u'Determines whether a user can select the content of an element.',
        'syntax': u'-webkit-user-select: policy;',
        'values': {u'auto': u'(by default) The user can select content in the element.',
                          u'none': u'The user cannot select any content.',
                          u'text': u'The user can select text in the element.'},
        'versions': [u'Safari 3.0', u'iPhone OS 3.0']},
}


### END: Auto generated


CSS_WEBKIT_SPECIFIC_ATTRS_DICT = {}
CSS_WEBKIT_SPECIFIC_CALLTIP_DICT = {}
for attr, details in CSS_WEBKIT_DATA.items():
    values = details.get("values", {})
    versions = details.get("versions", [])
    attr_completions = sorted(values.keys())
    if attr_completions:
        CSS_WEBKIT_SPECIFIC_ATTRS_DICT[attr] = attr_completions
    else:
        CSS_WEBKIT_SPECIFIC_ATTRS_DICT[attr] = None
    description = details.get("description", '')
    if versions:
        description += "\nVersions: %s\n" % (", ".join(versions))
    if description:
        desc_lines = textwrap.wrap(description, width=60)
        if values:
            desc_lines.append("")
            for value, attr_desc in values.items():
                attr_desc = "  %r: %s" % (value, attr_desc)
                attr_desc_lines = textwrap.wrap(attr_desc, width=50)
                for i in range(len(attr_desc_lines)):
                    attr_line = attr_desc_lines[i]
                    if i > 0:
                        attr_line = "        " + attr_line
                    desc_lines.append(attr_line)
        CSS_WEBKIT_SPECIFIC_CALLTIP_DICT[attr] = "\n".join(
            desc_lines).encode("ascii", 'replace')

########NEW FILE########
__FILENAME__ = css_linter
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
# Copyright (c) 2000-2011 ActiveState Software Inc.

"""Parse CSS/Less/SCSS for linting purposes only"""

import copy
import os
import sys
import traceback
import re
import time
import logging
import SilverCity
from SilverCity import CSS, ScintillaConstants
from codeintel2.shared_lexer import EOF_STYLE, Lexer
from codeintel2.lang_css import CSSLangIntel, raw_word_lists

log = logging.getLogger("css_linter")
# log.setLevel(logging.DEBUG)

# This class is by both the parser and lexer


class _CSSLexerClassifier(object):

    def is_attribute(self, tok):
        return tok['style'] == ScintillaConstants.SCE_CSS_ATTRIBUTE

    def is_directive(self, tok):
        return tok['style'] == ScintillaConstants.SCE_CSS_DIRECTIVE

    def is_identifier(self, tok):
        return tok['style'] in (ScintillaConstants.SCE_CSS_IDENTIFIER,
                                ScintillaConstants.SCE_CSS_IDENTIFIER2,
                                ScintillaConstants.SCE_CSS_IDENTIFIER3,
                                ScintillaConstants.SCE_CSS_EXTENDED_IDENTIFIER,
                                ScintillaConstants.SCE_CSS_EXTENDED_PSEUDOELEMENT,
                                ScintillaConstants.SCE_CSS_UNKNOWN_IDENTIFIER)

    def is_unknown_identifier(self, tok):
        return tok['style'] == ScintillaConstants.SCE_CSS_UNKNOWN_IDENTIFIER

    def is_special_identifier(self, tok):
        return tok['style'] in (ScintillaConstants.SCE_CSS_ID,
                                ScintillaConstants.SCE_CSS_CLASS,
                                ScintillaConstants.SCE_CSS_PSEUDOCLASS,
                                ScintillaConstants.SCE_CSS_PSEUDOELEMENT,
                                ScintillaConstants.SCE_CSS_UNKNOWN_PSEUDOCLASS,
                                ScintillaConstants.SCE_CSS_EXTENDED_PSEUDOCLASS,
                                ScintillaConstants.SCE_CSS_EXTENDED_PSEUDOELEMENT,)

    def is_important(self, tok, text):
        return (tok['style'] == ScintillaConstants.SCE_CSS_IMPORTANT
                and tok['text'] == text)

    def is_mixin(self, tok):
        return tok['style'] == ScintillaConstants.SCE_CSS_MIXIN

    _number_re = re.compile(r'-?(?:\d+(?:\.\d*)?|\.\d+)')

    def is_number(self, tok):
        return (tok['style'] == ScintillaConstants.SCE_CSS_NUMBER
                or (tok['style'] == ScintillaConstants.SCE_CSS_VALUE
                    and self._number_re.match(tok['text'])))

    def is_operator(self, tok, target=None):
        if tok['style'] != ScintillaConstants.SCE_CSS_OPERATOR:
            return False
        elif target is None:
            return True
        else:
            return target == tok['text']

    def is_operator_choose(self, tok, targets):
        if tok['style'] != ScintillaConstants.SCE_CSS_OPERATOR:
            return False
        else:
            return tok['text'] in targets

    def is_string(self, tok):
        return tok['style'] in (ScintillaConstants.SCE_CSS_DOUBLESTRING,
                                ScintillaConstants.SCE_CSS_SINGLESTRING,)

    def is_stringeol(self, tok):
        return tok['style'] == ScintillaConstants.SCE_CSS_STRINGEOL

    def is_tag(self, tok):
        return (tok['style'] == ScintillaConstants.SCE_CSS_TAG
                or self.is_operator(tok, "*"))

    def is_value(self, tok, target=None):
        if not (tok['style'] in (ScintillaConstants.SCE_CSS_VALUE,
                                 ScintillaConstants.SCE_CSS_NUMBER)):
            return False
        elif target is None:
            return True
        else:
            return tok['text'] == target

    def is_value_or_identifier(self, tok):
        return self.is_value(tok) or self.is_identifier(tok)

    def is_comment(self, ttype):
        return ttype in (ScintillaConstants.SCE_CSS_COMMENT,)

    @property
    def style_comment(self):
        return ScintillaConstants.SCE_CSS_COMMENT

    @property
    def style_default(self):
        return ScintillaConstants.SCE_CSS_DEFAULT

    @property
    def style_operator(self):
        return ScintillaConstants.SCE_CSS_OPERATOR

_classifier = None

    # Routines that shared_lexer require:

# No need for a UDL class -- since everything here goes through
# SilverCity, it always uses pure styles.


class SyntaxErrorEOF(SyntaxError):
    pass


def get_silvercity_lexer(language):
    return {"CSS": CSS.CSSLexer,
            "SCSS": CSS.SCSSLexer,
            "Less": CSS.LessLexer}.get(language, CSS.CSSLexer)


class _CSSLexer(Lexer):
    def __init__(self, code, language):
        Lexer.__init__(self)
        # We don't care about any JS operators in `...` escapes
        terms = '@{ ${ ~= |= ::'
        if language == "Less":
            terms += ' || &&'
        self.multi_char_ops = self.build_dict(terms)

        self.classifier = _classifier
        get_silvercity_lexer(language)().tokenize_by_style(
            code, self._fix_token_list)
        self.prepare_token_list_for_use()
        self.string_types = [ScintillaConstants.SCE_CSS_DOUBLESTRING,
                             ScintillaConstants.SCE_CSS_SINGLESTRING,
                             ]

    def _fix_token_list(self, **tok):
        ttype = tok['style']
        tval = tok['text']
        if ttype == ScintillaConstants.SCE_CSS_OPERATOR and len(tval) > 1:
            self.append_split_tokens(
                tok, self.multi_char_ops, end_column_offset=0)
        else:
            self.complete_token_push(tok)

    def next_token_is_whitespace(self, tok):
        return self.peek_next_token(
        )['style'] in (EOF_STYLE, self.classifier.style_comment,
                       self.classifier.style_default)

    def get_next_token(self):
        res = Lexer.get_next_token(self)
        # Column adjustment
        # print "get_next_token: " + res
        if res['start_column'] is not None:
            res['end_column'] = res['start_column'] + len(res['text'])
        return res


class Result(object):
    """
    Status: 1 for errors, 0 for warnings.  Default is warning
    """
    def __init__(self, message, line_start, col_start, line_end, col_end, status=1):
        self.message = message
        if line_start is not None:
            if line_end < line_start:
                line_end = line_start
            if line_start == line_end and col_end <= col_start:
                col_end = col_start + 1
        self.line_start = line_start
        self.col_start = col_start
        self.line_end = line_end
        self.col_end = col_end
        self.status = status

    def __str__(self):
        if self.line_start is None:
            return "%s: %s: EOF" % ((self.status == 1 and "Error" or "Warning"),
                                    self.message)
        else:
            return "%s: %s: <%d:%d> = <%d:%d>" % ((self.status == 1 and "Error" or "Warning"),
                                                  self.message,
                                                  self.line_start, self.col_start,
                                                  self.line_end, self.col_end)


class _CSSParser(object):

    _PARSE_REGION_AT_START = 0
    _PARSE_REGION_SAW_CHARSET = 1
    _PARSE_REGION_SAW_IMPORT = 2
    _PARSE_REGION_SAW_OTHER = 3

    def __init__(self, language):
        self._supportsNestedDeclaration = language in ("Less", "SCSS")
        self.language = language
        self._structural_pseudo_classes_with_args = [
            "nth-child",
            "nth-last-child",
            "nth-of-type",
            "nth-last-of-type",
        ]
        self._structural_pseudo_classes_no_args = [
            "root",
            "empty",
            "first-child",
            "only-child",
            "last-child",
            "first-of-type",
            "last-of-type",
            "only-of-type",
        ]
        self._structural_pseudo_classes_other = [
            "not",
            "-moz-any",
        ]

    def _add_result(self, message, tok, status=1):
        self._add_result_tok_parts(message,
                                   tok['start_line'], tok['start_column'],
                                   tok['end_line'], tok[
                                       'end_column'], tok['text'],
                                   status)

    def _add_result_tok_parts(self, message, line_start, col_start, line_end, col_end, text, status=1):
        if not self._results or self._results[-1].line_end < line_start:
            if not "got" in message:
                if line_start is None:
                    message += ", reached end of file"
                elif text:
                    message += ", got '%s'" % (text)
            self._results.append(Result(
                message, line_start, col_start, line_end, col_end, status))

    def parse(self, text):
        self.token_q = []
        self._results = []
        global _classifier
        if _classifier is None:
            _classifier = _CSSLexerClassifier()
        self._classifier = _classifier
        self._tokenizer = _CSSLexer(text, self.language)
        if self.language == "Less":
            self._less_mixins = {}  # => name => parameter list
        self._parse()
        return self._results

    def _parser_putback_recover(self, tok):
        self._tokenizer.put_back(tok)
        raise SyntaxError()

    def _parse(self):
        self._at_start = True
        self._charset = "UTF-8"
        self._parse_top_level()

    def _parse_ruleset(self):
        self._parse_selector()

        while True:
            tok = self._tokenizer.get_next_token()
            if tok['style'] == EOF_STYLE:
                self._add_result("expecting a block of declarations", tok)
                return
            self._check_tag_tok(tok, 1)
            if not self._classifier.is_operator(tok, ","):
                break
            self._parse_selector()
        self._parse_declarations(tok)  # tok is the non-comma, should be "{"

    def _parse_selector(self, resolve_selector_property_ambiguity=False):
        """
        selector : simple_selector [ combinator selector
                                     | S [ combinator? selector ]?
                                   ]? ;
        simple_selector : element_name [HASH | class | attrib | pseudo ]*
                          | [HASH | class | attrib | pseudo ]+;

        Instead, here we'll loop through selectors, allowing
        combinators if we find them.

        Note that error-recovery takes place here, not at the top-level.
        """
        require_simple_selector = True
        while True:
            res = self._parse_simple_selector(require_simple_selector,
                                              resolve_selector_property_ambiguity)
            if not res:
                break
            if resolve_selector_property_ambiguity and not require_simple_selector:
                # More than one simple selector in a row means it's not a
                # property
                self._saw_selector = True
            require_simple_selector = False
            tok = self._tokenizer.get_next_token()
            if tok['style'] == EOF_STYLE:
                # bug 94621 -- If we're on EOF while processing a selector,
                # give up on this loop
                break
            self._check_tag_tok(tok, 2)
            if not self._classifier.is_operator_choose(tok, ("+", ">", "~")):
                self._tokenizer.put_back(tok)
            else:
                require_simple_selector = True

    def _pseudo_element_check(self, tok, saw_pseudo_element):
        if saw_pseudo_element:
            self._add_result_tok_parts(
                "Pseudo elements must appear at the end of a selector chain",
                tok['start_line'], tok['start_column'],
                tok['end_line'], tok['end_column'],
                "", 1)

    def _reparse_structural_tokens(self, tok):
        # Just pull in all the text up to ')', and build a text part,
        # keeping spaces, keeping whitespace
        # Look for this:
        # ['-'|'+']? INTEGER? {N} [S* ['-'|'+'] S* INTEGER]?

        # This routine repackages the tokens, because strings like "-3n"
        # appear as an unknown identifier, but should be three separate
        # tokens.  The last token will be the end-token, normally a ")" op.

        ret_toks = []
        num_ptn = re.compile(r'(\d+)(.*)')
        while True:
            if (tok['style'] == EOF_STYLE or
                    (self._classifier.is_operator(tok) and tok['text'] in ");}{}")):
                ret_toks.append(tok)
                self._tokenizer.put_back(tok)
                return ret_toks
            tokText = tok['text']
            while True:
                if tokText.startswith("-") or tokText.startswith("+"):
                    newTok = tok.copy()
                    newTok['text'] = '-'
                    tok['text'] = tokText[0]
                    tok['end_column'] = tok['start_column'] + 1
                    tok['style'] = ScintillaConstants.SCE_CSS_OPERATOR
                    ret_toks.append(tok)
                    newTok['start_column'] = tok['end_column']
                    tok = newTok
                    tokText = tokText[1:]
                else:
                    m = num_ptn.match(tokText)
                    if m:
                        newTok = tok.copy()
                        newTok['text'] = '-'
                        tok['text'] = m.group(1)
                        tok['end_column'] = tok[
                            'start_column'] + len(tok['text'])
                        tok['style'] = ScintillaConstants.SCE_CSS_NUMBER
                        ret_toks.append(tok)
                        newTok['start_column'] = tok['end_column']
                        tok = newTok
                        tokText = m.group(2)
                    elif tokText[0].lower() == "n":
                        newTok = tok.copy()
                        newTok['text'] = '-'
                        tok['text'] = tokText[0]
                        tok['end_column'] = tok['start_column'] + 1
                        tok['style'] = ScintillaConstants.SCE_CSS_VALUE
                        ret_toks.append(tok)
                        newTok['start_column'] = tok['end_column']
                        tok = newTok
                        tokText = tokText[1:]
                    else:
                        # Just append it and deal with it later
                        ret_toks.append(tok)
                        tok = self._tokenizer.get_next_token()
                        break  # break inner loop, go back to outer loop
                if not tokText:
                    # Start working on another token.
                    tok = self._tokenizer.get_next_token()
                    break  # break inner loop, go back to outer loop

            # end while tokText
        # end while looping over tokens waiting for a ")"
    def _parse_structural_pseudo_class_arg(self):
        """ Weird grammar:
        nth : S* nthPart S* ;

        nthPart: ['-'|'+']? INTEGER? {N} [S* ['-'|'+'] S* INTEGER]?
               | ['-'|'+']? INTEGER
               | {ODD}
               | {EVEN}
               ;

        Note that + will be colored as an op, but - will be colored as
        an unknown identifier
        """
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_tag(tok) and tok['text'].lower() in ("odd", "even"):
            return
        tokens = self._reparse_structural_tokens(tok)
        end_tok = tokens.pop()  # This was also put back
        if not tokens:
            self._add_result("expecting a value", end_tok)
            return
        tok = tokens.pop(0)
        if self._classifier.is_operator(tok) and tok['text'] in ('-', '+'):
            tokSign = tok
            if not tokens:
                self._add_result("expecting a number or N", end_tok)
                return
            tok = tokens.pop(0)
            if tokSign['end_line'] != tok['start_line'] or tokSign['end_column'] != tok['start_column']:
                self._add_result(
                    "expecting no space before %s" % tok['text'], tok)
        met_requirement = False
        tokNum = None
        if self._classifier.is_number(tok):
            if not tokens:
                return  # all ok
            met_requirement = True
            tokNum = tok
            tok = tokens.pop(0)
        if self._classifier.is_value(tok) and tok['text'].lower() == 'n':
            if not tokens:
                return  # all ok
            if tokNum and (tokNum['end_line'] != tok['start_line']
                           or tokNum['end_column'] != tok['start_column']):
                self._add_result(
                    "expecting no space before %s" % tok['text'], tok)
            tok = tokens.pop(0)
        elif not met_requirement:
            self._add_result("expecting a number or N", tok)
            # Complain and give up
            return
        else:
            # If we didn't see an 'n', we need to leave
            self._add_result("expecting ')'", tok)
            return
        # Look for a second 'sign'
        require_number = False
        if self._classifier.is_operator(tok) and tok['text'] in ('-', '+'):
            if not tokens:
                self._add_result("expecting a number", end_tok)
                return
            tok = tokens.pop(0)
        if self._classifier.is_number(tok):
            if not tokens:
                return
        else:
            self._add_result("expecting a number", tok)
        if tokens:
            self._add_result("expecting ')'", tokens[0])

    def _parse_simple_selector(self, match_required, resolve_selector_property_ambiguity):
        saw_pseudo_element = False
        current_name = None
        num_selected_names = 0
        could_have_mixin = False
        while True:
            tok = self._tokenizer.get_next_token()
            if tok['style'] == EOF_STYLE:
                break
            self._check_tag_tok(tok, 3)
            log.debug("_parse_simple_selector: got tok %s", tok)
            if self._classifier.is_tag(tok):
                # Namespace check
                tok = self._tokenizer.get_next_token()
                if self._classifier.is_operator(tok, "|"):
                    tok = self._tokenizer.get_next_token()
                    if not self._classifier.is_tag(tok):
                        self._add_result("expecting an element name", tok)
                        self._tokenizer.put_back(tok)
                else:
                    self._tokenizer.put_back(tok)
                num_selected_names += 1
                self._pseudo_element_check(tok, saw_pseudo_element)
                current_name = tok['text']
                could_have_mixin = False
            elif self._classifier.is_identifier(tok):
                num_selected_names += 1
                self._pseudo_element_check(tok, saw_pseudo_element)
                if not self._supportsNestedDeclaration:
                    self._add_result(
                        "expecting a tag name, got unrecognized name %s (style %d)" % (
                            tok['text'], tok['style']),
                        tok, status=0)
                current_name = tok['text']
                could_have_mixin = False
            elif self._classifier.is_operator(tok):
                if tok['text'] == ":":
                    if resolve_selector_property_ambiguity and not self._saw_selector:
                        # This is the crucial point
                        # Are we looking at
                        # font: ....
                        #    or
                        # a:hover ...
                        # We take the easy way out and resolve this by looking at coordinates
                        #
                        # We also assume that anyone using Less or SCSS is more interested in
                        # readability than conciseness, so we aren't dealing
                        # with minified CSS.
                        if self._tokenizer.next_token_is_whitespace(tok):
                            self._tokenizer.put_back(tok)
                            return False
                    prev_tok = tok
                    tok = self._tokenizer.get_next_token()
                    if self._classifier.is_number(tok):
                        self._tokenizer.put_back(tok)
                        self._tokenizer.put_back(prev_tok)
                        return False
                    if not self._check_special_identifier(prev_tok, tok):
                        return False
                    num_selected_names += 1
                    current_name = tok['text']
                    if (tok['text'] in self._structural_pseudo_classes_with_args
                            or tok['text'] in self._structural_pseudo_classes_other):  # "not", "-moz-any"
                        prev_tok = tok
                        tok = self._tokenizer.get_next_token()
                        if self._classifier.is_operator(tok, "("):
                            if prev_tok['text'] in self._structural_pseudo_classes_with_args:
                                self._parse_structural_pseudo_class_arg()
                            else:
                                # It's the CSS3 "not" or -moz-any selector
                                while True:
                                    self._parse_simple_selector(
                                        True, resolve_selector_property_ambiguity=False)
                                    tok = self._tokenizer.get_next_token()
                                    if not self._classifier.is_operator(tok) or tok['text'] != ",":
                                        self._parser_putback_recover(tok)
                                        break
                            self._parse_required_operator(")")
                        else:
                            if prev_tok['text'] in self._structural_pseudo_classes_args:
                                self._add_result(
                                    "expecting a parenthesized structural pseudo-class argument")
                            self._tokenizer.put_back(tok)
                    # elif tok['text'] in self._structural_pseudo_classes_no_args:
                    #    pass # Nothing to do
                    could_have_mixin = False
                elif tok['text'] in ("#", ".", "::",):
                    prev_tok = tok
                    could_have_mixin = (self.language == "Less"
                                        and prev_tok['text'] == '.'
                                        and num_selected_names == 0)
                    tok = self._tokenizer.get_next_token()
                    if could_have_mixin and self._classifier.is_mixin(tok):
                        pass
                        # keep going...
                    elif not self._check_special_identifier(prev_tok, tok):
                        return False
                    num_selected_names += 1
                    self._pseudo_element_check(tok, saw_pseudo_element)
                    current_name = tok['text']
                    if prev_tok['text'] == "::":
                        saw_pseudo_element = True
                elif tok['text'] == '[':
                    if resolve_selector_property_ambiguity:
                        # More than one simple selector in a row means it's not
                        # a property
                        self._saw_selector = True
                    self._parse_attribute()
                    num_selected_names += 1
                    could_have_mixin = False
                elif tok['text'] == '{':
                    if num_selected_names == 0 and match_required:
                        self._add_result("expecting a selector, got '{'", tok)
                    # Short-circuit the calling loop.
                    self._tokenizer.put_back(tok)
                    return False
                elif tok['text'] == '}':
                    if could_have_mixin and current_name in self._less_mixins:
                        self._inserted_mixin = True
                        self._tokenizer.put_back(tok)
                        return False
                    # assume we recovered to the end of a "}"
                    could_have_mixin = False
                    num_selected_names = 0
                    continue
                elif tok['text'] == ';' and could_have_mixin and num_selected_names == 1:
                    self._inserted_mixin = True
                    self._tokenizer.put_back(tok)
                    return
                elif tok['text'] == "&" and self.language == "SCSS":
                    self._saw_selector = True
                    num_selected_names += 1
                elif tok['text'] == "&" and self.language == "Less":
                    tok = self._tokenizer.get_next_token()
                    if (self._classifier.is_operator_choose(tok, ("#", ".", ":", "::", ","))
                            or self._classifier.is_special_identifier(tok)):
                        # Parse the qualifier next time around
                        self._saw_selector = True
                        num_selected_names += 1
                    self._tokenizer.put_back(tok)
                else:
                    break
            else:
                break
        if num_selected_names == 0:
            if match_required:
                self._add_result("expecting a selector, got %s" % (
                    tok['text'],), tok)
                tok = self._recover(allowEOF=False, opTokens=("{", "}"))
            # We got a { or }, so short-circuit the calling loop and
            # go parse the declaration
            self._tokenizer.put_back(tok)
            return False
        # Allow either the Mozilla ( id [, id]* ) property syntax or a Less mixin declaration/insertion
        # Note that we have the token that caused us to leave the above loop
        if not self._classifier.is_operator(tok, "("):
            if (could_have_mixin
                and current_name in self._less_mixins
                    and self._classifier.is_operator(tok, ";")):
                self._inserted_mixin = True
            self._tokenizer.put_back(tok)
            return True
        do_recover = False
        if could_have_mixin:
            if current_name in self._less_mixins:
                self._parse_mixin_invocation()
                self._inserted_mixin = True
            else:
                self._parse_mixin_declaration(current_name)
            return
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_tag(tok):
            self._add_result("expecting a property name", tok)
            self._tokenizer.put_back(tok)
            do_recover = True
        else:
            self._parse_identifier_list(self._classifier.is_tag, ",")
            tok = self._tokenizer.get_next_token()
            if not self._classifier.is_operator(tok, ")"):
                self._add_result("expecting ')'", tok)
                do_recover = True
        if do_recover:
            tok = self._recover(allowEOF=False, opTokens=("{", "}"))
            self._tokenizer.put_back(tok)
            return False
        return True

    def _check_special_identifier(self, prev_tok, tok):
        if (self._classifier.is_special_identifier(tok)
            or (self._supportsNestedDeclaration
                and (self._classifier.is_unknown_identifier(tok)
                     or tok['style'] == ScintillaConstants.SCE_CSS_VALUE))):
            return True
        self._add_result("expecting an identifier after %s, got %s" % (
            prev_tok['text'], tok['text']), tok)
        # Give up looking at selectors
        self._tokenizer.put_back(tok)
        return False

    def _parse_attribute(self):
        tok = self._tokenizer.get_next_token()
        if not (self._classifier.is_attribute(tok)
                or self._classifier.is_identifier(tok)
                # tags can happen after *[foo] due to confused lexing
                or self._classifier.is_tag(tok)):
            self._add_result("expecting an identifier", tok)
        else:
            tok = self._tokenizer.get_next_token()
        substring_toks = ("*", "$", "^")
        attr_toks = ("]", "=", "~=", "|=")
        if (self._classifier.is_operator_choose(tok, substring_toks)
                or self._is_scss_variable(tok)):
            tok2 = self._tokenizer.get_next_token()
            if not self._classifier.is_operator_choose(tok2, "="):
                self._add_result(
                    "expecting '=' after substring operator '%s'" % tok['text'], tok2)
                tok = tok2
            else:
                tok = self._tokenizer.get_next_token()
        elif tok['text'] == ']':
            return
        elif self._classifier.is_operator_choose(tok, attr_toks):
            tok = self._tokenizer.get_next_token()
        else:
            self._add_result("expecting one of %s" % (
                ', '.join(attr_toks + substring_toks),), tok)
            self._parser_putback_recover(tok)
        # At this point we've seen a '=' or other op, and should have a
        # value token in hand
        if self._classifier.is_stringeol(tok):
            self._add_result("missing string close-quote", tok)
        elif not (self._classifier.is_string(tok)
                  or self._classifier.is_identifier(tok)
                  or self._classifier.is_tag(tok)):
            self._add_result("expecting an identifier or string", tok)
            self._tokenizer.put_back(tok)
            return
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_operator(tok, ']'):
            self._add_result("expecting a ']'", tok)

    def _parse_assignment(self):
        """
        we saw $var or @var at top-level, expect : expression ;
        """
        self._parse_required_operator(":")
        self._parse_expression()
        self._parse_required_operator(";")

    def _parse_directive(self, prev_tok):
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_directive(tok):
            if (self._classifier.is_tag(tok)
                and (prev_tok['end_line'] != tok['start_line'] or
                     prev_tok['end_column'] != tok['start_column'])):
                self._add_result_tok_parts(
                    "expecting a directive immediately after @",
                    prev_tok['end_line'],
                    prev_tok['end_column'],
                    tok['start_line'],
                    tok['start_column'], "")
            else:
                self._add_result("expecting an identifier after %s" % (
                    prev_tok['text']), tok)
                self._parser_putback_recover(tok)

        if tok['text'] == "charset":
            return self._parse_charset(tok)

        elif tok['text'].lower() == "import":
            if self._region > self._PARSE_REGION_SAW_IMPORT:
                self._add_result("@import allowed only near start of file",
                                 tok)
            elif self._region < self._PARSE_REGION_SAW_IMPORT:
                self._region = self._PARSE_REGION_SAW_IMPORT
            return self._parse_import()

        self._region = self._PARSE_REGION_SAW_OTHER
        if tok['text'].lower() == "media":
            self._parse_media()

        elif tok['text'].lower() == "page":
            self._parse_page()

        elif tok['text'].lower() == "font-face":
            self._parse_declarations()

        elif tok['text'].lower() == "namespace":
            self._parse_namespace()

        elif tok['text'].lower() == "-moz-document":
            self._parse_moz_document()

        elif self.language == "Less":
            self._parse_assignment()
        elif self.language == "SCSS":
            self._parse_scss_mixin_declaration(tok)
        else:
            self._add_result("expecting a directive after %s" % (
                prev_tok['text']), tok)

    def _parse_scss_mixin_declaration(self, tok):
        if not (self._classifier.is_directive(tok) and tok['text'] == "mixin"):
            self._add_result("expecting a directive or 'mixin'", tok)
            self._parser_putback_recover(tok)
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_tag(tok):
            self._add_result("expecting a mixin name", tok)
            self._parser_putback_recover(tok)
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_operator(tok, "("):
            self._parse_mixin_invocation()
        else:
            self._tokenizer.put_back(tok)
        self._parse_declarations()

    def _parse_required_operator(self, op, tok=None):
        if tok is None:
            tok = self._tokenizer.get_next_token()
        if not self._classifier.is_operator(tok, op):
            self._add_result("expecting '%s'" % op, tok)
            self._parser_putback_recover(tok)

    def _parse_optional_operator(self, op, alt_op):
        tok = self._tokenizer.get_next_token()
        have_problem = False
        if not self._classifier.is_operator(tok):
            have_problem = True
        elif tok['text'] not in (op, alt_op):
            have_problem = True
        elif tok['text'] == alt_op:
            self._parser_putback_recover(tok)
        if have_problem:
            self._add_result("expecting '%s'" % op, tok)
            self._parser_putback_recover(tok)

    def _parse_charset(self, charset_tok):
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_stringeol(tok):
            self._add_result("missing string close-quote", tok)
        elif not self._classifier.is_string(tok):
            self._add_result(
                "expecting a string after @charset, got %s" % (tok['text']),
                tok)
            self._parser_putback_recover(tok)
        self._parse_required_operator(';')

        if self._region > self._PARSE_REGION_AT_START:
            self._add_result(
                "@charset allowed only at start of file", charset_tok)
        else:
            self._region = self._PARSE_REGION_SAW_CHARSET

    def _parse_import(self):
        if (not self._parse_url()) and (not self._parse_string()):
            tok = self._tokenizer.get_next_token()
            self._add_result("expecting a string or url", tok)
            # Stay here, hope for the best.
        else:
            tok = self._tokenizer.get_next_token()

        if self._classifier.is_value(tok) and self._lex_identifier(tok):
            self._parse_identifier_list(self._classifier.is_value, ",")
            tok = self._tokenizer.get_next_token()
        self._parse_required_operator(";", tok)

    def _parse_media_list(self):
        # See w3.org/TR/css3-mediaqueries/#syntax
        self._parse_media_query()
        while True:
            tok = self._tokenizer.get_next_token()
            if tok['style'] == EOF_STYLE:
                self._add_result("expecting '{'", tok)
                raise SyntaxErrorEOF()
            if not self._classifier.is_operator(tok, ","):
                self._tokenizer.put_back(tok)
                break
            self._parse_media_query()

    def _parse_media_query(self):
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_operator(tok, "("):
            # expression [ AND expression ]*
            self._tokenizer.put_back(tok)
            self._parse_media_expression()
        else:
            # [ONLY | NOT]? media_type [ AND expression ]*
            if not (self._classifier.is_value_or_identifier(tok) and self._lex_identifier(tok)):
                self._add_result(
                    "expecting an identifier or a parenthesized expression", tok)
                tok = self._recover(allowEOF=True, opTokens=("{",))
                if not self._classifier.is_operator(tok, "{"):
                    raise SyntaxErrorEOF()
                self._tokenizer.put_back(tok)
                return
            if tok['text'].lower() in ("only", "not"):
                tok = self._tokenizer.get_next_token()
                if not (self._classifier.is_value_or_identifier(tok) and self._lex_identifier(tok)):
                    self._add_result("an identifier", tok)
                    tok = self._recover(allowEOF=True, opTokens=("{",))
                    if not self._classifier.is_operator(tok, "{"):
                        raise SyntaxError()
                    self._tokenizer.put_back(tok)
                    return
        # And parse [ AND expression ]*
        while True:
            tok = self._tokenizer.get_next_token()
            if self._classifier.is_value(tok) and tok['text'].lower() == "and":
                self._parse_media_expression()
            else:
                self._tokenizer.put_back(tok)
                break

    def _parse_media_expression(self):
        self._parse_required_operator("(")
        tok = self._tokenizer.get_next_token()
        if not (self._classifier.is_value_or_identifier(tok) and self._lex_identifier(tok)):
            self._add_result("expecting an identifier", tok)
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_operator(tok, ":"):
            self._parse_expression()
            tok = self._tokenizer.get_next_token()
        if not self._classifier.is_operator(tok, ")"):
            self._add_result("expecting ':' or ')'", tok)
            self._tokenizer.put_back(tok)

    def _parse_media(self):
        self._parse_media_list()
        self._parse_inner_rulesets()

    def _parse_inner_rulesets(self):
        self._parse_required_operator("{")
        while True:
            tok = self._tokenizer.get_next_token()
            if tok['style'] == EOF_STYLE:
                self._add_result("expecting '}'", tok)
                return
            elif self._classifier.is_operator(tok, "}"):
                break
            self._tokenizer.put_back(tok)
            self._parse_ruleset()

    def _parse_moz_document(self):
        """
        docrule ::= "@-moz-document" S+ url-list "{" S* ruleset* "}"
        url-list ::= url-item ( "," S* url-item )*
        url-item ::= ( "url(" | "url-prefix(" | "domain(" ) URL ")" |
                     "regexp(" string ")" S*
        """
        while True:
            res = self._parse_moz_document_item()
            if not res:
                break
            tok = self._tokenizer.get_next_token()
            if not self._classifier.is_operator(tok):
                # Stay in this loop, maybe we're seeing more moz-doc items
                self._add_result("expecting ',' or '{'", tok)
                self._tokenizer.put_back(tok)
            elif tok['text'] == "{":
                self._tokenizer.put_back(tok)
                break
            elif tok['text'] != ",":
                # Stay in this loop
                self._add_result("expecting ',' or '{'", tok)
                self._tokenizer.put_back(tok)
        self._parse_inner_rulesets()

    def _parse_page(self):
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_operator(tok, ":"):
            tok = self._tokenizer.get_next_token()
            if not (self._classifier.is_special_identifier(tok)):
                self._add_result("expecting an identifier", tok)
                self._parser_putback_recover(tok)
            else:
                tok = None  # refresh in _parse_declarations
        self._parse_declarations(tok)

    def _parse_namespace(self):
        tok = self._tokenizer.get_next_token()
        if (not self._classifier.is_value(tok)) or tok['text'] == "url(":
            self._tokenizer.put_back(tok)
        if (not self._parse_url()) and (not self._parse_string()):
            self._add_result("expecting a string or url", tok)
            tok = self._recover(allowEOF=True, opTokens=(';', "{"))
            if not self._classifier.is_operator(tok, ';'):
                self._tokenizer.put_back(tok)
            return
        self._parse_required_operator(";")

    def _parse_mixin_declaration(self, current_name):
        """
        Allow ()
              (@foo[:value]) or
              (@foo1[:value1], @foo2[:value2], ... @fooN[:valueN])
        """

        mixin_vars = []
        self._less_mixins[current_name] = mixin_vars
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_operator(tok, ")"):
            return
        if self._classifier.is_operator(tok, "@"):
            while True:
                if not self._classifier.is_operator(tok, "@"):
                    self._add_result("expecting ')' or a directive", tok)
                    raise SyntaxError()
                tok = self._tokenizer.get_next_token()
                if not self._classifier.is_directive(tok):
                    self._add_result("expecting a variable name", tok)
                    raise SyntaxError()
                mixin_vars.append(tok['text'])
                tok = self._tokenizer.get_next_token()
                if self._classifier.is_operator(tok, ":"):
                    self._parse_expression(consumeCommas=False)
                    tok = self._tokenizer.get_next_token()
                if self._classifier.is_operator(tok, ","):
                    tok = self._tokenizer.get_next_token()
                    # Stay in loop
                elif self._classifier.is_operator(tok, ")"):
                    return
                else:
                    self._add_result("expecting ',' or ')'", tok)
                    raise SyntaxError()

        # Just parse a mixin insertion.  This happens when
        # a parameterless mixin was defined, but they look
        # exactly like class selectors.
        self._parse_mixin_invocation()
        self._inserted_mixin = True

    def _parse_mixin_invocation(self):
        """
        comma-separated values, followed by a ")"
        """
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_operator(tok, ")"):
            return
        self._tokenizer.put_back(tok)
        while True:
            tok = self._tokenizer.get_next_token()
            if self._classifier.is_tag(tok):
                pass
            else:
                self._tokenizer.put_back(tok)
                self._parse_expression()
            tok = self._tokenizer.get_next_token()
            if self._classifier.is_operator(tok, ","):
                tok = self._tokenizer.get_next_token()
                # Stay in loop
            elif self._classifier.is_operator(tok, ")"):
                return
            else:
                self._add_result("expecting ',' or ')'", tok)
                raise SyntaxError()

    def _parse_declarations(self, tok=None):
        self._parse_required_operator("{", tok)
        while True:
            tok = self._tokenizer.get_next_token()
            if tok['style'] == EOF_STYLE:
                self._add_result("expecting '}', hit end of file", tok)
                raise SyntaxErrorEOF()
            if self._classifier.is_operator(tok, "}"):
                break
            self._tokenizer.put_back(tok)
            try:
                # TODO: Look ahead for either ';' or '{' to know
                # whether we're entering a nested block or a property
                #
                # The problem with ':' is that they can appear in both selectors
                # as well as after property-names.
                if self._supportsNestedDeclaration:
                    self._parse_declaration_or_nested_block()
                else:
                    self._parse_declaration()
            except SyntaxError:
                tok = self._recover(allowEOF=False, opTokens=(';', "{", "}"))
                t = tok['text']
                if t == ";":
                    pass  # This is good -- continue doing declarations.
                elif t == "}":
                    self._tokenizer.put_back(tok)  # Use this back in loop
                elif t == "{":
                    # Either we're in less/scss, or we missed a selector, fake
                    # it
                    self._parse_declarations(tok)

    def _recover(self, allowEOF, opTokens):
        while True:
            tok = self._tokenizer.get_next_token()
            if tok['style'] == EOF_STYLE:
                if allowEOF:
                    return tok
                raise SyntaxErrorEOF()
            elif self._classifier.is_operator_choose(tok, opTokens):
                return tok

    def _parse_declaration(self):
        """
        Because this is called in a loop, have it return True only if it matches everything
        """
        self._parse_property()
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_operator(tok, ":"):
            self._add_result("expecting ':'", tok)
            # Swallow it
        self._parse_remaining_declaration()

    def _parse_remaining_declaration(self):
        """ SCSS allows nested declarations:
        li {
          font: {
            family: serif; // => font-family: serif; //etc.
            weight: bold;
            size: 1.2em;
          }
        }
        """
        if self.language == "SCSS":
            tok = self._tokenizer.get_next_token()
            have_brace = self._classifier.is_operator(tok, "{")
            self._tokenizer.put_back(tok)
            if have_brace:
                self._parse_declarations()
                return

        self._parse_expression()
        self._parse_priority()
        self._parse_optional_operator(";", "}")

    def _parse_scss_mixin_use(self):
        # Check for reading in a mixin
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_operator(tok, "@"):
            self._tokenizer.put_back(tok)
            return
        tok = self._tokenizer.get_next_token()
        if not (self._classifier.is_directive(tok) and tok['text'] == "include"):
            self._add_result("expecting 'include'", tok)
            self._tokenizer.put_back(tok)
            return
        tok = self._tokenizer.get_next_token()
        if not (self._classifier.is_identifier(tok)
                or self._classifier.is_tag(tok)):
            self._add_result("expecting a mixin name", tok)
            self._parser_putback_recover(tok)
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_operator(tok, "("):
            self._parse_mixin_invocation()
            tok = self._tokenizer.get_next_token()
        self._parse_required_operator(";", tok)
        return True

    def _parse_declaration_or_nested_block(self):
        """
        For Less and SCSS, blocks can nest.  So parse either a property-name
        or full-blown selector here.
        # Key method for Less/SCSS linting.  At this point we can have
        # either a declaration or a nested rule-set.
        """
        # selectors are supersets of property-names, so go with it
        self._saw_selector = False
        self._inserted_mixin = False
        if self.language == "SCSS":
            if self._parse_scss_mixin_use():
                return
        # Try categorizing the next token to remove ambiguity
        tok = self._tokenizer.get_next_token()
        if (self.language == "Less"
                and self._classifier.is_operator_choose(tok, ("+", ">"))):
            self._parse_ruleset()
            return
        self._tokenizer.put_back(tok)
        if (self._classifier.is_identifier(tok)
                and (tok['text'] in raw_word_lists[0] or tok['text'] in raw_word_lists[2])):
            # We have a property
            self._parse_declaration()
            # Don't continue parsing declarations -- the next item could start
            # a nested block.
        else:
            self._parse_selector(resolve_selector_property_ambiguity=True)
            tok = self._tokenizer.get_next_token()
            if self._classifier.is_operator(tok, ","):
                self._parse_ruleset()
                return
            if self._classifier.is_operator(tok, "{"):
                return self._parse_declarations(tok)
            if self._inserted_mixin:
                # Nothing left to do.
                # ; is optional before '}'
                if self._classifier.is_operator(tok, ";"):
                    return
                elif self._classifier.is_operator(tok, "}"):
                    self._tokenizer.put_back(tok)
                    return
            if self._saw_selector:
                self._add_result("expecting '{'", tok)
            if self._classifier.is_operator(tok, ":"):
                self._parse_remaining_declaration()
            else:
                #@NO TEST YET
                self._add_result("expecting ':' or '{'", tok)
                self._parser_putback_recover(tok)

    def _parse_property(self):
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_operator(tok, "*"):
            prev_tok = tok
            tok = self._tokenizer.get_next_token()
        else:
            prev_tok = None
        if not (self._classifier.is_identifier(tok)
                or self._classifier.is_tag(tok)):
            #@NO TEST YET
            self._add_result("expecting a property name", tok)
            self._parser_putback_recover(tok)
        if prev_tok is not None:
            if prev_tok['end_column'] == tok['start_column']:
                self._add_result_tok_parts("Use of non-standard property-name '%s%s'" %
                                           (prev_tok['text'], tok['text']),
                                           prev_tok['start_line'], prev_tok[
                                               'start_column'],
                                           tok['end_line'], tok[
                                               'end_column'], "",
                                           status=0)
            else:
                # Put the token back, trigger an error-message later
                self._tokenizer.put_back(tok)

    def _parse_expression(self, consumeCommas=True):
        if self._parse_term(required=True):
            while True:
                self._parse_operator(consumeCommas)
                if not self._parse_term(required=False):
                    break

    def _parse_operator(self, consumeCommas=True):
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_operator(tok):
            self._tokenizer.put_back(tok)
        elif tok['text'] == "/" or (tok['text'] == "," and consumeCommas):
            # use up
            pass
        elif self.language == "Less" and tok['text'] in ("~", "*", "^", "-", "+", "/", "|", "&", "||", "&&",):
            # use up
            pass
        else:
            self._tokenizer.put_back(tok)

    def _parse_unary_operator(self):
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_operator(tok):
            self._tokenizer.put_back(tok)
            return False
        elif not tok['text'] in ("+", "-"):
            self._tokenizer.put_back(tok)
            return False
        else:
            return True

    def _parse_parenthesized_expression(self):
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_operator(tok, "("):
            self._tokenizer.put_back(tok)
            return False
        self._parse_expression()
        self._parse_required_operator(")")
        return True

    def _parse_escaped_string(self):
        """
        Accept any of
        ~" ... "
        ~` ... `
        ` ... `
        """
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_operator_choose(tok, ("~", '`')):
            self._tokenizer.put_back(tok)
            return False
        if tok['text'] == '~':
            prev_tok = tok
            tok = self._tokenizer.get_next_token()
            if not self._classifier.is_operator(tok) or tok['text'] not in ('"', '`'):
                self._tokenizer.put_back(prev_tok)
                self._tokenizer.put_back(tok)
                return False
        target = tok['text']
        while True:
            tok = self._tokenizer.get_next_token()
            if tok['style'] == EOF_STYLE:
                self._add_result(
                    "expecting '%s', hit end of file" % (target,), tok)
                raise SyntaxErrorEOF()
            elif self._classifier.is_operator(tok, target):
                return True

    def _parse_term(self, required=False):
        exp_num = self._parse_unary_operator()
        have_num = self._parse_number(exp_num)
        if have_num:
            return True
        elif exp_num:
            return False
        if self._parse_string():
            return True
        elif self._parse_url():
            return True
        elif self._parse_hex_color():
            return True
        elif self._parse_function_call_or_term_identifier():
            return True
        elif self._parse_variable_reference():
            return True
        elif self.language == "Less":
            if self._parse_parenthesized_expression():
                return True
            elif self._parse_escaped_string():
                return True
        if required:
            tok = self._tokenizer.get_next_token()
            self._check_tag_tok(tok, 8)
            self._add_result("expecting a value", tok)
            self._tokenizer.put_back(tok)
        return False

    _simple_number_re = re.compile(r'\d+')

    def _parse_number(self, exp_num):
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_number(tok):
            # Bug 94652: Look for unrecognized units
            nextTok = self._tokenizer.get_next_token()
            if (nextTok['style'] == ScintillaConstants.SCE_CSS_VALUE
                and nextTok['start_line'] == tok['end_line']
                    and nextTok['start_column'] == tok['end_column']):
                self._add_result("got an unsupported or unrecognized numeric unit: '%s'" % nextTok[
                                 'text'], nextTok)
            else:
                self._tokenizer.put_back(nextTok)
            return True
        elif (tok['style'] == ScintillaConstants.SCE_CSS_UNKNOWN_PSEUDOCLASS
              and self._simple_number_re.match(tok['text'])):
            return True
        elif exp_num:
            self._add_result("expecting a number", tok)
            self._parser_putback_recover(tok)
        else:
            self._tokenizer.put_back(tok)
        return False

    def _parse_string(self):
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_stringeol(tok):
            self._add_result("missing string close-quote", tok)
        elif not self._classifier.is_string(tok):
            self._tokenizer.put_back(tok)
            return False
        return True

    def _parse_term_identifier(self):
        required = False
        prev_tok = None
        while True:
            tok = self._tokenizer.get_next_token()
            if not (self._classifier.is_value(tok) and self._lex_identifier(tok)):
                if required:
                    self._add_result("expecting an identifier", tok)
                    # Swallow the ':' or '.' that got us here.
                    return False
                else:
                    self._tokenizer.put_back(tok)
                    return prev_tok is not None
            prev_tok = tok
            tok = self._tokenizer.get_next_token()
            if self._classifier.is_operator(tok, "="):
                self._parse_expression()
                return prev_tok  # tok = self._tokenizer.get_next_token()
            if not (self._classifier.is_operator(tok)
                    and tok['text'] in (":", ".")):  # Microsoft additions
                self._tokenizer.put_back(tok)
                return prev_tok
            op_tok = tok
            required = True

    def _parse_identifier(self):
        tok = self._tokenizer.get_next_token()
        if not (self._classifier.is_value(tok) and self._lex_identifier(tok)):
            self._tokenizer.put_back(tok)
            return False
        else:
            return True

    _url_re = re.compile(r'url\((.*)\)\Z')

    def _parse_url(self):
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_value(tok):
            if self._url_re.match(tok['text']):
                return True
            if tok['text'] == "url(":
                # Verify that the actual URL is a string
                if not self._parse_string():
                    tok = self._tokenizer.get_next_token()
                    self._add_result("expecting a quoted URL", tok)
                    self._parser_putback_recover(tok)
                tok = self._tokenizer.get_next_token()
                if not (self._classifier.is_operator(tok, ")")
                        or (self._classifier.is_value(tok) and tok['text'] == ')')):
                    self._add_result("expecting ')'", tok)
                    self._parser_putback_recover(tok)
                else:
                    return True
        self._tokenizer.put_back(tok)
        return False

    _url_item_re = re.compile(r'(?:url|url-prefix|domain)\((.*)\)\Z')

    def _parse_url_item(self):
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_value(tok):
            if self._url_re.match(tok['text']):
                return True
            if tok['text'] == "url(":
                # Verify that the actual URL is a string
                if not self._parse_string():
                    tok = self._tokenizer.get_next_token()
                    self._add_result("expecting a quoted URL", tok)
                    self._parser_putback_recover(tok)
                tok = self._tokenizer.get_next_token()
                if not (self._classifier.is_operator(tok, ")")
                        or (self._classifier.is_value(tok) and tok['text'] == ')')):
                    self._add_result("expecting ')'", tok)
                    self._parser_putback_recover(tok)
                else:
                    return True
        self._tokenizer.put_back(tok)
        return False

    moz_document_item_types = ("url", "url-prefix", "domain", "regexp")
    moz_document_item_types_with_paren = tuple(
        [x + "(" for x in moz_document_item_types])

    def _parse_moz_document_item(self):
        tok = self._tokenizer.get_next_token()
        if not tok['text'].startswith(self.moz_document_item_types_with_paren):
            self._add_result("expecting a -moz-document url-item", tok)
            self._parser_putback_recover(tok)
        if tok['text'] in self.moz_document_item_types_with_paren:
            self._parse_string()
            self._parse_required_operator(")")
        elif tok['text'].startswith("regexp("):
            self._add_result(
                "the regexp argument must be a quoted string", tok)

    _hex_color_re = re.compile(r'#(?:[\da-fA-F]{3}){1,2}\Z')

    def _parse_hex_color(self):
        tok = self._tokenizer.get_next_token()
        if (self._classifier.is_value(tok)
                and self._hex_color_re.match(tok['text'])):
            return True
        elif self.language != "CSS" and self._classifier.is_operator(tok, "#"):
            new_tok = self._tokenizer.get_next_token()
            if self._hex_color_re.match("#" + new_tok['text']):
                return True
            self._tokenizer.put_back(tok)
            self._tokenizer.put_back(new_tok)
        else:
            self._tokenizer.put_back(tok)
        return False

    def _parse_function_call_or_term_identifier(self):
        res = self._parse_term_identifier()
        if not res:
            return False
        tok = self._tokenizer.get_next_token()
        if not self._classifier.is_operator(tok, "("):
            self._tokenizer.put_back(tok)
            return True
        self._parse_expression()  # Includes commas
        self._parse_required_operator(")")
        return True

    def _parse_variable_reference(self):
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_operator(tok, "@") and self.language == "Less":
            tok = self._tokenizer.get_next_token()
            # Allow multiple '@' signs
            while self._classifier.is_operator(tok, "@"):
                tok = self._tokenizer.get_next_token()
            if not (self._classifier.is_attribute(tok)
                    or self._classifier.is_identifier(tok)
                    or self._classifier.is_directive(tok)):
                self._add_result("expecting an identifier", tok)
            return True
        elif self._is_scss_variable(tok):
            return True
        self._tokenizer.put_back(tok)
        return False

    def _parse_priority(self):
        tok = self._tokenizer.get_next_token()
        if self._classifier.is_important(tok, "!important"):
            return
        elif not self._classifier.is_important(tok, "!"):
            self._tokenizer.put_back(tok)
        else:
            tok = self._tokenizer.get_next_token()
            if not self._classifier.is_important(tok, "important"):
                self._add_result("expecting '!important',", tok)
                self._parser_putback_recover(tok)

    def _parse_identifier_list(self, classifier, separator):
        while True:
            tok = self._tokenizer.get_next_token()
            self._check_tag_tok(tok, 9)
            if not self._classifier.is_operator(tok, separator):
                self._tokenizer.put_back(tok)
                break
            tok = self._tokenizer.get_next_token()
            if not (classifier(tok) and self._lex_identifier(tok)):
                self._add_result("expecting an identifier", tok)
                return self._parser_putback_recover(tok)

    def _parse_top_level(self):
        self._region = self._PARSE_REGION_AT_START
        do_declarations_this_time = False  # for recovery
        while True:
            if not do_declarations_this_time:
                tok = self._tokenizer.get_next_token()
                if tok is None:
                    log.error("tok is None")
                    break
                if tok['style'] == EOF_STYLE:
                    return
                self._check_tag_tok(tok, 10)
            try:
                if do_declarations_this_time:
                    do_declarations_this_time = False
                    self._parse_declarations()
                elif self._classifier.is_operator(tok, "@"):
                    self._parse_directive(tok)
                elif self._is_scss_variable(tok):
                    self._parse_assignment()
                else:
                    self._tokenizer.put_back(tok)
                    self._region = self._PARSE_REGION_SAW_OTHER
                    self._parse_ruleset()
            except SyntaxErrorEOF:
                break
            except SyntaxError:
                tok = self._recover(allowEOF=True, opTokens=("{", "}", "@"))
                if tok['style'] == EOF_STYLE:
                    return
                if self._classifier.is_operator(tok, "{"):
                    self._tokenizer.put_back(tok)
                    # slightly convoluted way of running code in the same
                    # try/except block
                    do_declarations_this_time = True
                elif self._classifier.is_operator(tok, "@"):
                    self._tokenizer.put_back(tok)
                # Otherwise consume the "}" and continue

    _identifier_lex_re = re.compile(
        r'(?:[a-zA-Z_\-\x80-\xff]|\\[^\r\n\f0-9a-fA-F])(?:[\w_\-\x80-\xff]|\\[^\r\n\f0-9a-fA-F])*$')

    def _lex_identifier(self, tok):
        return self._identifier_lex_re.match(tok['text'])

    def _is_scss_variable(self, tok):
        if self.language != "SCSS":
            return False
        return (self._classifier.is_identifier(tok)
                and tok['text'][0] == "$")

    _check_tag_tok_count = 0

    def _check_tag_tok(self, tok, loop_id):
        tag = "_check_loop_%d" % (loop_id,)
        if tag not in tok:
            self._check_tag_tok_count += 1
            tok[tag] = self._check_tag_tok_count
        elif tok[tag] == self._check_tag_tok_count:
            raise Exception(
                "Stuck in a loop with tok %s, tag %d" % (tok, loop_id))


class CSSLinter(object):
    def lint(self, text, language="CSS"):
        self._parser = _CSSParser(language)
        return self._parser.parse(text)

########NEW FILE########
__FILENAME__ = catalog
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""The API catalogs-zone of the codeintel database.
See the database/database.py module docstring for an overview.
"""

import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile, normpath,
                     normcase)
import cPickle as pickle
import threading
import time
from hashlib import md5
import bisect
import fnmatch
from glob import glob
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import codecs
import copy
import weakref
import Queue

import ciElementTree as ET
from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.util import dedent, safe_lang_from_lang, banner, hotshotit
from codeintel2.tree import tree_from_cix_path
from codeintel2.database.util import filter_blobnames_for_prefix
from codeintel2.database.resource import AreaResource


#---- globals
log = logging.getLogger("codeintel.db")
# log.setLevel(logging.DEBUG)


#---- Database zone and lib implementations
class CatalogsZone(object):
    """Singleton zone managing the db/catalogs/... area.

    TODO: Locking: .cull_mem() and .save() will be called periodically
          on indexer thread. Anything they access needs to be guarded.
    """
    _res_index = None
    _blob_index = None
    _toplevelname_index = None
    _toplevelprefix_index = None

    _have_updated_at_least_once = False

    def __init__(self, mgr, catalog_dirs=None):
        self.mgr = mgr
        self.db = mgr.db

        if catalog_dirs is None:
            catalog_dirs = []
        assert isinstance(catalog_dirs, list)
        self.catalog_dirs = catalog_dirs

        self.base_dir = join(self.db.base_dir, "db", "catalogs")

        self._lib_cache = {}  # (lang, selection_res_ids) -> CatalogLib

        self._lock = threading.RLock()
        self._blob_and_atime_from_blobname_from_lang_cache = {}
        self._dbsubpaths_and_lpaths_to_save = []

    def __repr__(self):
        return "<catalog zone>"

    def _selection_from_selector(self, selections):
        """Given a sequence of catalog selection strings (each is a
        catalog name or full path to a catalog .cix file) return a dict
        mapping:

            <normalized-selector> -> <selection-string>

        If "selections" is None, this returns None.
        """
        if selections is None:
            return None
        selection_from_selector = {}
        for selection in selections:
            if isabs(selection):
                selector = normpath(normcase(selection))
            else:
                selector = selection.lower()
            selection_from_selector[selector] = selection
        return selection_from_selector

    _res_ids_from_selector_cache = None

    def _res_ids_from_selections(self, selections):
        """Returns a tuple of the database resource ids for the given
        selections and a list of selections that didn't match any loaded
        resources.
        """
        if self._res_ids_from_selector_cache is None:
            cache = self._res_ids_from_selector_cache = {}
            for cix_area_path, res_data in self.res_index.items():
                cix_path = AreaResource(cix_area_path).path
                res_id = res_data[0]
                cache[normpath(normcase(cix_path))] = [res_id]
                name = splitext(basename(cix_path))[0].lower()
                if name not in cache:
                    cache[name] = []
                cache[name].append(res_id)
            log.debug("_res_ids_from_selector_cache: %r", cache)

        res_ids = []
        missing_selections = []
        for selector, selection \
                in self._selection_from_selector(selections).items():
            try:
                res_ids += self._res_ids_from_selector_cache[selector]
            except KeyError, ex:
                missing_selections.append(selection)
        log.debug("_res_ids_from_selections: res_ids=%r", res_ids)
        return tuple(res_ids), missing_selections

    @LazyClassAttribute
    def _std_catalog_dir(cls):
        return join(dirname(dirname(abspath(__file__))), "catalogs")

    _catalog_dirs = None

    @property
    def catalog_dirs(self):
        return self._catalog_dirs

    @catalog_dirs.setter
    def catalog_dirs(self, value):
        assert not isinstance(value, basestring), \
            "catalog_dirs must be an iterable, not a string"
        catalog_dirs = list(value)
        if self._std_catalog_dir not in catalog_dirs:
            catalog_dirs.append(self._std_catalog_dir)
        self._catalog_dirs = catalog_dirs
        # cause a rescan next time we try to get a catalog lib
        self._have_updated_at_least_once = False

    def get_lib(self, lang, selections=None):
        """Return a CatalogLib for the given lang and selections."""
        assert not isinstance(selections, basestring),\
            "catalog lib 'selections' must be None or a sequence, not %r: %r"\
            % (type(selections), selections)
        if not self._have_updated_at_least_once:
            self.update(selections)

        if selections is not None:
            selection_res_ids, missing_selections \
                = self._res_ids_from_selections(selections)
            if missing_selections:
                self.update(missing_selections)
                selection_res_ids, missing_selections \
                    = self._res_ids_from_selections(selections)
            if missing_selections:
                log.warn("the following catalog selections didn't match "
                         "any loaded API catalog: '%s'",
                         "', '".join(missing_selections))
        else:
            selection_res_ids = None
        key = (lang, selection_res_ids)
        if key not in self._lib_cache:
            self._lib_cache[key] = CatalogLib(self, lang,
                                              selections, selection_res_ids)
        return self._lib_cache[key]

    @property
    def res_index(self):
        """Load and return the resource index (res_index)."""
        if self._res_index is None:
            idxpath = join(self.base_dir, "res_index")
            self._res_index = self.db.load_pickle(idxpath, {})
        return self._res_index

    @property
    def blob_index(self):
        """Load and return the blob index (blob_index)."""
        if self._blob_index is None:
            idxpath = join(self.base_dir, "blob_index")
            self._blob_index = self.db.load_pickle(idxpath, {})
        return self._blob_index

    @property
    def toplevelname_index(self):
        """Load and return the top-level name index (toplevelname_index)."""
        if self._toplevelname_index is None:
            idxpath = join(self.base_dir, "toplevelname_index")
            self._toplevelname_index = self.db.load_pickle(idxpath, {})
        return self._toplevelname_index

    @property
    def toplevelprefix_index(self):
        """Load and return the top-level prefix index (toplevelprefix_index)."""
        if self._toplevelprefix_index is None:
            idxpath = join(self.base_dir, "toplevelprefix_index")
            self._toplevelprefix_index = self.db.load_pickle(idxpath, {})
        return self._toplevelprefix_index

    def save(self):
        self._lock.acquire()
        try:
            for dbsubpath, lpaths in self._dbsubpaths_and_lpaths_to_save:
                self.db.save_pickle(join(self.base_dir, dbsubpath), lpaths)
            self._dbsubpaths_and_lpaths_to_save = []
        finally:
            self._lock.release()

    def cull_mem(self):
        """Drop blobs from cache that have not been accessed in over 5
        minutes.

        To attempt to keep memory consumption under control we want to
        ensure we don't keep everything cached from the db in memory
        until process completion.
        """
        # TOTEST: Does Python/Komodo actually release this memory or
        #        are we kidding ourselves?
        self._lock.acquire()
        try:
            N = 10
            if len(self._blob_and_atime_from_blobname_from_lang_cache) < N:
                # Too few blobs in memory to bother culling.
                return

            log.info("catalog: culling memory")
            now = time.time()
            for lang, blob_and_atime_from_blobname \
                    in self._blob_and_atime_from_blobname_from_lang_cache.items():
                for blobname, (blob, atime) in blob_and_atime_from_blobname.items():
                    if now - atime > 300.0:  # >5 minutes since last access
                        del blob_and_atime_from_blobname[blobname]
        finally:
            self._lock.release()

    def reportMemory(self):
        """
        Report on memory usage from this CatalogsZone.
        @returns {dict} memory usage; keys are the paths, values are a dict of
            "amount" -> number
            "units" -> "bytes" | "count"
            "desc" -> str description
        """
        log.debug("CatalogsZone: reporting memory")
        import memutils

        total_mem_usage = 0
        result = {}
        for lang, blob_and_atime_from_blobname in self._blob_and_atime_from_blobname_from_lang_cache.items():
            for blobname, [blob, atime] in blob_and_atime_from_blobname.items():
                result["explicit/python/codeintel/%s/catalog/%s" % (lang, blobname)] = {
                    "amount": memutils.memusage(blob),
                    "units": "bytes",
                    "desc": "The number of bytes of %s codeintel %s catalog blobs." % (lang, blobname),
                }
        return result

    def avail_catalogs(self, selections=None):
        """Generate a list of available catalogs.

            "selections" (optional) is a list of string of the same form
                as to `.get_lib()'. It is used to determine the boolean
                value of <selected> in the yielded tuples.

        Generated dicts as follows:
            {"name": <catalog-name>,    # 'name' attr of <codeintel> tag
                                        #   or file basename
             "lang": <lang>,            # 'lang' attribute of first <file> tag
             "description": <desc>,     # 'description' attr of <codeintel>
             "cix_path": <cix-path>,
             "selected": <selected>,
             "selection": <selection>,
            }
        where <selected> is boolean indicating if this catalog is
        selected according to "selections" and <selection> is the string
        in "selections" that resulted in this.
        """
        selection_from_selector = self._selection_from_selector(selections)
        for cix_path in (cix_path for d in self.catalog_dirs if exists(d)
                         for cix_path in glob(join(d, "*.cix"))):
            name = lang = description = None
            try:
                for event, elem in ET.iterparse(cix_path, events=("start",)):
                    if elem.tag == "codeintel":
                        name = elem.get("name")
                        description = elem.get("description")
                    elif elem.tag == "file":
                        lang = elem.get("lang")
                        break
            except ET.XMLParserError, ex:
                log.warn("%s: error reading catalog, skipping it (%s)",
                         cix_path, ex)
                continue
            if lang is None:
                log.warn("%s: no 'lang' attribute on catalog <file> tag, "
                         "skipping it", cix_path)
                continue
            if name is None:
                name = splitext(basename(cix_path))[0]
            norm_name = name.lower()
            norm_cix_path = normpath(normcase(cix_path))
            if selection_from_selector is None:
                selected = True
                selection = None
            else:
                selection = (selection_from_selector.get(norm_name)
                             or selection_from_selector.get(norm_cix_path))
                selected = selection is not None
            yield {"name": name,
                   "lang": lang,
                   "description": description,
                   "cix_path": cix_path,
                   "selected": selected,
                   "selection": selection}

    def update(self, selections=None, progress_cb=None):
        """Update the catalog as necessary.

            "selections" (optional) is a list of string of the same form
                as to `.get_lib()' -- used here to filter the catalogs
                that we consider for updating.
            "progress_cb" (optional) is a callable that is called as
                follows to show the progress of the update:
                    progress_cb(<desc>, <value>)
                where <desc> is a short string describing the current step
                and <value> is an integer between 0 and 100 indicating the
                level of completeness.
        """
        self._lock.acquire()
        try:
            self._have_updated_at_least_once = True

            # Figure out what updates need to be done...
            if progress_cb:
                try:
                    progress_cb("Determining necessary catalog updates...", 5)
                except:
                    log.exception("error in progress_cb (ignoring)")
            res_name_from_res_path = dict(  # this is our checklist
                (p, v[2]) for p, v in self.res_index.items())
            todos = []
            log.info("updating %s: %d catalog dir(s)", self,
                     len(self.catalog_dirs))
            for catalog_info in self.avail_catalogs(selections):
                cix_path = catalog_info["cix_path"]
                res = AreaResource(cix_path)
                # check that the update-time is the mtime (i.e. up-to-date)
                try:
                    res_id, last_updated, name, res_data \
                        = self.res_index[res.area_path]
                except KeyError:
                    # add this new CIX file
                    todos.append(("add", res, catalog_info["name"]))
                else:
                    mtime = os.stat(cix_path).st_mtime
                    if last_updated != mtime:  # epsilon? '>=' instead of '!='?
                        # update with newer version
                        todos.append(("update", res, catalog_info["name"]))
                    # else:
                    #    log.debug("not updating '%s' catalog: mtime is unchanged",
                    #              catalog_info["name"])
                    del res_name_from_res_path[res.area_path]  # tick it off

            for res_area_path, res_name in res_name_from_res_path.items():
                # remove this obsolete CIX file
                try:
                    todos.append(("remove", AreaResource(
                        res_area_path), res_name))
                except ValueError, ex:
                    # Skip resources in unknown areas. This is primarily to
                    # allow debugging/testing (when the set of registered
                    # path_areas may not include the set when running in
                    # Komodo.)
                    pass

            # Filter todos on selections, if any.
            if selections is not None:
                selection_from_selector = self._selection_from_selector(
                    selections)
                before = todos[:]
                todos = [todo for todo in todos
                         if todo[2].lower() in selection_from_selector
                         or normpath(normcase(todo[1].path)) in selection_from_selector
                         ]

            # ... and then do them.
            if not todos:
                return
            for i, (action, res, name) in enumerate(todos):
                log.debug("%s `%s' catalog (%s)", action, name, res)
                try:
                    if action == "add":
                        desc = "Adding '%s' API catalog" % basename(
                            res.subpath)
                        if progress_cb:
                            try:
                                progress_cb(desc, (5 + 95/len(todos)*i))
                            except:
                                log.exception(
                                    "error in progress_cb (ignoring)")
                        else:
                            self.db.report_event(desc)
                        self._add_res(res)
                    elif action == "remove":
                        desc = "Removing '%s' API catalog" % basename(
                            res.subpath)
                        if progress_cb:
                            try:
                                progress_cb(desc, (5 + 95/len(todos)*i))
                            except:
                                log.exception(
                                    "error in progress_cb (ignoring)")
                        else:
                            self.db.report_event(desc)
                        self._remove_res(res)
                    elif action == "update":
                        desc = "Updating '%s' API catalog" % basename(
                            res.subpath)
                        if progress_cb:
                            try:
                                progress_cb(desc, (5 + 95/len(todos)*i))
                            except:
                                log.exception(
                                    "error in progress_cb (ignoring)")
                        else:
                            self.db.report_event(desc)
                        # XXX Bad for filesystem. Change this to do it
                        #    more intelligently if possible.
                        self._remove_res(res)
                        self._add_res(res)
                except DatabaseError, ex:
                    log.warn("%s (skipping)" % ex)

            if progress_cb:
                try:
                    progress_cb("Saving catalog indices...", 95)
                except:
                    log.exception("error in progress_cb (ignoring)")
            self._res_ids_from_selector_cache = None  # invalidate this cache
            if self._res_index is not None:
                self.db.save_pickle(
                    join(self.base_dir, "res_index"),
                    self._res_index)
            if self._blob_index is not None:
                self.db.save_pickle(
                    join(self.base_dir, "blob_index"),
                    self._blob_index)
            if self._toplevelname_index is not None:
                self.db.save_pickle(
                    join(self.base_dir, "toplevelname_index"),
                    self._toplevelname_index)
            if self._toplevelprefix_index is not None:
                self.db.save_pickle(
                    join(self.base_dir, "toplevelprefix_index"),
                    self._toplevelprefix_index)
        finally:
            self._lock.release()

    _existing_res_ids_cache = None
    _new_res_id_counter = 0

    def _new_res_id(self):
        if self._existing_res_ids_cache is None:
            self._existing_res_ids_cache \
                = dict((d[0], True) for d in self.res_index.values())
        while True:
            if self._new_res_id_counter not in self._existing_res_ids_cache:
                new_res_id = self._new_res_id_counter
                self._new_res_id_counter += 1
                self._existing_res_ids_cache[new_res_id] = True
                return new_res_id
            self._new_res_id_counter += 1

    def _remove_res(self, res):
        LEN_PREFIX = self.db.LEN_PREFIX
        res_id, last_updated, name, res_data = self.res_index[res.area_path]
        # res_data: {lang -> blobname -> ilk -> toplevelnames}
        for lang, tfifb in res_data.items():
            dbfile_and_res_id_from_blobname = self.blob_index[lang]
            for blobname, toplevelnames_from_ilk in tfifb.items():
                # Update 'blob_index' for $lang.
                dbfile, res_id = dbfile_and_res_id_from_blobname[blobname]
                del dbfile_and_res_id_from_blobname[blobname]

                # Remove ".blob" file (and associated caches).
                pattern = join(self.base_dir, safe_lang_from_lang(lang),
                               dbfile+".*")
                try:
                    for path in glob(pattern):
                        log.debug("fs-write: remove catalog %s blob file '%s'",
                                  lang, basename(path))
                        os.remove(path)
                except EnvironmentError, ex:
                    # XXX If get lots of these, then try harder. Perhaps
                    #    creating a zombies area, or creating a list of
                    #    them: self.db.add_zombie(dbpath).
                    # XXX THis isn't a correct analysis: the dbfile may just
                    #    not have been there.
                    log.warn("could not remove dbfile '%s' (%s '%s'): "
                             "leaving zombie", dbpath, lang, blobname)

                # Update 'toplevel*_index' for $lang.
                # toplevelname_index:   {lang -> ilk -> toplevelname -> res_id -> blobnames}
                # toplevelprefix_index: {lang -> ilk -> prefix -> res_id ->
                # toplevelnames}
                for ilk, toplevelnames in toplevelnames_from_ilk.iteritems():
                    try:
                        bfrft = self.toplevelname_index[lang][ilk]
                        for toplevelname in toplevelnames:
                            del bfrft[toplevelname][res_id]
                            if not bfrft[toplevelname]:
                                del bfrft[toplevelname]
                    except KeyError, ex:
                        self.db.corruption("CatalogsZone._remove_res",
                                           "error removing top-level names of ilk '%s' for "
                                           "'%s' resource from toplevelname_index: %s"
                                           % (ilk, basename(res.path), ex),
                                           "ignore")

                    try:
                        tfrfp = self.toplevelprefix_index[lang][ilk]
                        for toplevelname in toplevelnames:
                            prefix = toplevelname[:LEN_PREFIX]
                            del tfrfp[prefix][res_id]
                            if not tfrfp[prefix]:
                                del tfrfp[prefix]
                    except KeyError, ex:
                        self.db.corruption("CatalogsZone._remove_res",
                                           "error removing top-level name of ilk '%s' for "
                                           "'%s' resource from toplevelprefix_index: %s"
                                           % (ilk, basename(res.path), ex),
                                           "ignore")

        del self.res_index[res.area_path]

    def _add_res(self, res):
        cix_path = res.path
        try:
            tree = tree_from_cix_path(cix_path)
        except ET.XMLParserError, ex:
            log.warn("could not load `%s' into catalog (skipping): %s",
                     cix_path, ex)
            return

        LEN_PREFIX = self.db.LEN_PREFIX
        res_id = self._new_res_id()
        res_data = {}   # {lang -> blobname -> ilk -> toplevelnames}
        name = tree.get("name") or splitext(basename(cix_path))[0]
        for blob in tree.findall("file/scope"):
            lang, blobname = blob.get("lang"), blob.get("name")
            if not lang:
                raise DatabaseError("add `%s': no 'lang' attr on %r"
                                    % (res, blob))

            # Create 'res_data'.
            tfifb = res_data.setdefault(lang, {})
            toplevelnames_from_ilk = tfifb.setdefault(blobname, {})
            if lang in self.db.import_everything_langs:
                for toplevelname, elem in blob.names.iteritems():
                    ilk = elem.get("ilk") or elem.tag
                    if ilk not in toplevelnames_from_ilk:
                        toplevelnames_from_ilk[ilk] = set([toplevelname])
                    else:
                        toplevelnames_from_ilk[ilk].add(toplevelname)

            # Update 'toplevel*_index'.
            # toplevelname_index:   {lang -> ilk -> toplevelname -> res_id -> blobnames}
            # toplevelprefix_index: {lang -> ilk -> prefix -> res_id ->
            # toplevelnames}
            bfrftfi = self.toplevelname_index.setdefault(lang, {})
            tfrfpfi = self.toplevelprefix_index.setdefault(lang, {})
            for ilk, toplevelnames in toplevelnames_from_ilk.iteritems():
                bfrft = bfrftfi.setdefault(ilk, {})
                tfrfp = tfrfpfi.setdefault(ilk, {})
                for toplevelname in toplevelnames:
                    bfr = bfrft.setdefault(toplevelname, {})
                    if res_id not in bfr:
                        bfr[res_id] = set([blobname])
                    else:
                        bfr[res_id].add(blobname)
                    prefix = toplevelname[:LEN_PREFIX]
                    tfr = tfrfp.setdefault(prefix, {})
                    if res_id not in tfr:
                        tfr[res_id] = set([toplevelname])
                    else:
                        tfr[res_id].add(toplevelname)

            # Update 'blob_index'.
            dbfile_and_res_id_from_blobname \
                = self.blob_index.setdefault(lang, {})
            assert blobname not in dbfile_and_res_id_from_blobname, \
                ("codeintel: %s %r blob in `%s' collides "
                    "with existing %s %r blob (from res_id %r) in catalog: "
                    "(XXX haven't decided how to deal with that yet)"
                    % (lang, blobname, cix_path, lang, blobname,
                       dbfile_and_res_id_from_blobname[blobname][1]))
            dbfile = self.db.bhash_from_blob_info(cix_path, lang, blobname)
            dbfile_and_res_id_from_blobname[blobname] = (dbfile, res_id)

            # Write out '.blob' file.
            dbdir = join(self.base_dir, safe_lang_from_lang(lang))
            if not exists(dbdir):
                log.debug("fs-write: mkdir '%s'", dbdir)
                os.makedirs(dbdir)
            log.debug("fs-write: catalog %s blob '%s'", lang, dbfile)
            ET.ElementTree(blob).write(join(dbdir, dbfile+".blob"))

        # Update 'res_index'.
        last_updated = os.stat(cix_path).st_mtime
        self.res_index[res.area_path] \
            = (res_id, last_updated, name, res_data)

    def res_id_from_lang_and_blobname(self, lang, blobname):
        try:
            dbfile, res_id = self.blob_index[lang][blobname]
        except KeyError:
            return None
        else:
            return res_id

    def get_blob(self, lang, blobname, look_in_cache_only=False):
        try:
            dbfile, res_id = self.blob_index[lang][blobname]
        except KeyError:
            return None

        # If index path is in the cache: return it, update its atime.
        now = time.time()
        blob_and_atime_from_blobname \
            = self._blob_and_atime_from_blobname_from_lang_cache.setdefault(lang, {})
        if blobname in blob_and_atime_from_blobname:
            log.debug("cache-read: load %s blob `%s'", lang, blobname)
            blob, atime = blob_and_atime_from_blobname[blobname]
            blob_and_atime_from_blobname[blobname] = (blob, now)
            return blob

        # Need to load and cache it.
        if look_in_cache_only:
            return None
        dbsubpath = join(self.base_dir, safe_lang_from_lang(lang), dbfile)
        blob = self.db.load_blob(dbsubpath)
        blob_and_atime_from_blobname[blobname] = (blob, now)
        return blob

    def lpaths_from_lang_and_blobname(self, lang, blobname):
        """Get lpaths for the named blob.

        We get it from the blob's "lpaths" cache key (calculating that
        if necessary).
        """
        blob = self.get_blob(lang, blobname, look_in_cache_only=True)
        if blob is not None:
            if "lpaths" in blob.cache:
                return blob.cache["lpaths"]
        else:
            blob = self.get_blob(lang, blobname)
            if blob is None:
                raise NotFoundInDatabase("%s '%s' blob not found in catalogs"
                                         % (lang, blobname))
            if "lpaths" in blob.cache:
                return blob.cache["lpaths"]

        # Need to calculate lpaths from 'blob'.
        log.debug("calc symbol info for %s '%s' catalog blob", lang, blobname)
        langintel = self.mgr.langintel_from_lang(lang)
        lpaths = langintel.lpaths_from_blob(blob)

        # Update cache and queue this up to be saved to disk (by .save()).
        blob.cache["lpaths"] = lpaths
        dbfile, res_id = self.blob_index[lang][blobname]
        self._lock.acquire()
        try:
            self._dbsubpaths_and_lpaths_to_save.append(
                (join(safe_lang_from_lang(lang), dbfile+".lpaths"), lpaths)
            )
        finally:
            self._lock.release()

        return lpaths


class CatalogLib(object):
    """A light lang-specific and selection-filtered view on the whole
    CatalogsZone.
    """
    name = "cataloglib"

    def __init__(self, catalogs_zone, lang,
                 selections=None, selection_res_ids=None):
        self.catalogs_zone = catalogs_zone
        self.lang = lang
        self.selections = selections
        if selection_res_ids is None:
            self.selection_res_id_set = None
        else:
            self.selection_res_id_set = set(selection_res_ids)
        self._import_handler = None
        self._blob_imports_from_prefix_cache = {}

    _repr_cache = None

    def __repr__(self):
        if self._repr_cache is None:
            # Include the base names of the selected resources in the name.
            if self.selection_res_id_set is None:
                selection_names = ['(all)']
            else:
                selection_names = []
                for s in self.selections:
                    if isabs(s):
                        selection_names.append(splitext(basename(s))[0])
                    else:
                        selection_names.append(s)
            self._repr_cache = "<%s cataloglib: %s>"\
                               % (self.lang, ', '.join(selection_names))
        return self._repr_cache

    @property
    def import_handler(self):
        if self._import_handler is None:
            self._import_handler \
                = self.catalogs_zone.mgr.citadel.import_handler_from_lang(self.lang)
        return self._import_handler

    def has_blob(self, blobname):
        res_id = self.catalogs_zone.res_id_from_lang_and_blobname(self.lang,
                                                                  blobname)
        if res_id is None:
            return False
        if self.selection_res_id_set is None:
            return True
        return res_id in self.selection_res_id_set

    def get_blob(self, blobname):
        if not self.has_blob(blobname):  # knows how to filter on selections
            return None
        return self.catalogs_zone.get_blob(self.lang, blobname)

    def get_blob_imports(self, prefix):
        """Return the set of imports under the given prefix.

            "prefix" is a tuple of import name parts. E.g. ("xml", "sax")
                for "import xml.sax." in Python. Or ("XML", "Parser") for
                "use XML::Parser::" in Perl.

        See description in database.py docstring for details.
        """
        # This code works fine if prefix is the empty tuple.
        if prefix not in self._blob_imports_from_prefix_cache:
            try:
                dbfile_and_res_id_from_blobname \
                    = self.catalogs_zone.blob_index[self.lang]
            except KeyError:
                return set()

            if self.selection_res_id_set is None:
                matches = filter_blobnames_for_prefix(
                    dbfile_and_res_id_from_blobname,
                    prefix,
                    self.import_handler.sep)
            else:
                matches = filter_blobnames_for_prefix(
                    (bn
                     for bn, (f, res_id) in dbfile_and_res_id_from_blobname.items()
                     if res_id in self.selection_res_id_set),
                    prefix,
                    self.import_handler.sep)
            self._blob_imports_from_prefix_cache[prefix] = matches
        return self._blob_imports_from_prefix_cache[prefix]

    def _blobnames_from_toplevelname(self, toplevelname, ilk=None):
        """Yield all blobnames in the currently selected catalogs
        with the given toplevelname.

        If "ilk" is given then only symbols of that ilk will be considered.
        """
        # toplevelname_index: {lang -> ilk -> toplevelname -> res_id ->
        # blobnames}
        if self.lang in self.catalogs_zone.toplevelname_index:
            for i, potential_bfrft \
                    in self.catalogs_zone.toplevelname_index[self.lang].iteritems():
                if ilk is not None and i != ilk:
                    continue
                if toplevelname not in potential_bfrft:
                    continue
                potential_bfr = potential_bfrft[toplevelname]
                if self.selection_res_id_set is None:
                    for blobnames in potential_bfr.itervalues():
                        for blobname in blobnames:
                            yield blobname
                else:
                    for res_id, blobnames in potential_bfr.iteritems():
                        if res_id not in self.selection_res_id_set:
                            continue
                        for blobname in blobnames:
                            yield blobname

    def hits_from_lpath(self, lpath, ctlr=None, curr_buf=None):
        assert isinstance(lpath, tuple)  # common mistake to pass in a string

        hits = []
        for blobname in self._blobnames_from_toplevelname(lpath[0]):
            lpaths = self.catalogs_zone.lpaths_from_lang_and_blobname(
                self.lang, blobname)
            if lpath not in lpaths:
                continue
            blob = self.catalogs_zone.get_blob(self.lang, blobname)
            # TODO: Convert lpath's in tree-evalrs to tuples instead of lists.
            elem = _elem_from_scoperef((blob, list(lpath)))
            hits.append((elem, (blob, list(lpath[:-1]))))

        return hits

    def toplevel_cplns(self, prefix=None, ilk=None, ctlr=None):
        """Return completion info for all top-level names matching the
        given prefix and ilk in all selected blobs in this lib.

            "prefix" is a 3-character prefix with which to filter top-level
                names. If None (or not specified), results are not filtered
                based on the prefix.
            "ilk" is a symbol type (e.g. "class", "variable", "function")
                with which to filter results. If None (or not specified),
                results of any ilk are returned.
            "ctlr" (optional) is an EvalController instance. If
                specified it should be used in the normal way (logging,
                checking .is_aborted()).

        Returns a list of 2-tuples: (<ilk>, <name>).

        Note: the list is not sorted, because often some special sorting
        is required for the different completion evaluators that might use
        this API.
        """
        cplns = []
        if prefix is None:
            # Use 'toplevelname_index':
            #   {lang -> ilk -> toplevelname -> res_id -> blobnames}
            toplevelname_index = self.catalogs_zone.toplevelname_index
            if self.lang in toplevelname_index:
                if ilk is not None:
                    try:
                        bfrft = toplevelname_index[self.lang][ilk]
                    except KeyError:
                        pass
                    else:
                        if self.selection_res_id_set is None:
                            cplns += [(ilk, t) for t in bfrft]
                        else:
                            cplns += [(ilk, t) for t, bfr in bfrft.iteritems()
                                      if self.selection_res_id_set.intersection(bfr)]
                elif self.selection_res_id_set is None:
                    for i, bfrft in toplevelname_index[self.lang].iteritems():
                        cplns += [(i, t) for t in bfrft]
                else:  # ilk=None, have a selection set
                    for i, bfrft in toplevelname_index[self.lang].iteritems():
                        cplns += [(i, t) for t, bfr in bfrft.iteritems()
                                  if self.selection_res_id_set.intersection(bfr)]
        else:
            # Use 'toplevelprefix_index':
            #   {lang -> ilk -> prefix -> res_id -> toplevelnames}
            toplevelprefix_index = self.catalogs_zone.toplevelprefix_index
            if self.lang in toplevelprefix_index:
                if ilk is not None:
                    try:
                        tfr = toplevelprefix_index[self.lang][ilk][prefix]
                    except KeyError:
                        pass
                    else:
                        if self.selection_res_id_set is None:
                            cplns += [(ilk, t)
                                      for toplevelnames in tfr.itervalues()
                                      for t in toplevelnames]
                        else:
                            cplns += [(ilk, t)
                                      for r in self.selection_res_id_set.intersection(tfr)
                                      for t in tfr[r]]
                elif self.selection_res_id_set is None:
                    for i, tfrfp in toplevelprefix_index[self.lang].iteritems():
                        if prefix not in tfrfp:
                            continue
                        cplns += [(i, t)
                                  for toplevelnames in tfrfp[prefix].itervalues()
                                  for t in toplevelnames]
                else:  # ilk=None, have a selection set
                    for i, tfrfp in toplevelprefix_index[self.lang].iteritems():
                        if prefix not in tfrfp:
                            continue
                        tfr = tfrfp[prefix]
                        cplns += [(i, t)
                                  for r in self.selection_res_id_set.intersection(tfr)
                                  for t in tfr[r]]
        return cplns


#---- internal support routines
def _elem_from_scoperef(scoperef):
    """A scoperef is (<blob>, <lpath>). Return the actual elem in
    the <blob> ciElementTree being referred to.  Returns None if not found.
    """
    elem = scoperef[0]
    for lname in scoperef[1]:
        try:
            elem = elem.names[lname]
        except KeyError:
            return None
    return elem

########NEW FILE########
__FILENAME__ = database
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""The new database for codeintel2.

# Usage

There is a single Database instance on the codeintel Manager (mgr.db).
All entry points to the database are via this instance.

There are two common modes of interaction:

1. Getting info for a particular buffer. E.g., for a code browser or for
   information on a current file. Here all interaction can be done via a
   few methods on the main Database class.

    Database.get_buf_data(buf)
    Database.get_buf_scan_time(buf)
    Database.update_buf_data(buf, ...)
    Database.remove_buf_data(buf)

2. Working with a blob (a.k.a. module) given a list of libs.
   Typically this is done during completion evaluation (i.e. detemining
   what completions to show for "foo."). Here a particular environment
   will have a list of "libs", all of them from the main Database
   instance, via, e.g.:

    Database.get_stdlib(...)
    Database.get_catalog_lib(...)
    Database.get_lang_lib(...)
    etc.

   A "lib" instance has the following standard interface:

    .has_blob(blobname)
        Returns True iff a so-named blob is provided by this lib.

    .get_blob(blobname)
        Returns the so-named blob (the importable section of a CIX
        element tree) provided by this lib, or None if it isn't.

    .get_blob_imports(prefix)
        Returns a set of blobnames to complete the given import prefix.
        This is generally used for completion on import statements, e.g.
            import <|>      # lib.get_blob_imports(prefix=())
            import foo.<|>  # lib.get_blob_imports(prefix=('foo',))
        Note that prefix has to be a tuple (rather than a list) because
        the method is automatically cached.

        Items in the returned set a 2-tuples, (<import-name>,
        <is-dir-import>), where <is-dir-import> is a boolean indicating
        if this is a prefix for a multidir import. For example, in
        Perl's stdlib there is an "HTTP::Request" module, but no "HTTP"
        module. One of returned items would be:
            ("HTTP", True)
        The set can have both (e.g. Perl's LWP.pm and LWP/UserAgent.pm):
            ("LWP", False)   # for "use LWP;"
            ("LWP", True)     # prefix for "use LWP::UserAgent;"

    .hits_from_lpath(lpath, ctlr=None, curr_buf=None)
        Returns all "hits" for the given lookup path in all blobs in
        this lib.  This is to support "import-everything" semantics
        necessary for langs like JavaScript (no explicit local import
        statements) and PHP (with auto-loading anything can happen). It
        is possible that other langs may not support this.

    .toplevel_cplns(prefix=None, ilk=None, ctlr=None):
        Find all toplevel names starting with the given prefix in all
        blobs in this lib and return a list of completions:
            (<ilk>, <name>)
        where <ilk> is, e.g., "class" or "function" or "variable", etc.
        'ilk' can be specified to restrict the results to names of that
        ilk. If prefix is None then *all* toplevel names are returned.

   where "blob" is the generic internal name used for "the token with
   which you import", e.g.:

        LANGUAGE    IMPORT STATEMENT        BLOBNAME
        --------    ----------------        --------
        Python      import foo              foo
        Perl        use Foo;                Foo
        PHP         include("foo.php");     foo.php


# Database structure

The database is divided into *zones*, primarily along
common-implementation lines. E.g. dir under "db" is a zone.


<base-dir>/                 # E.g. ~/.komodo/6.0/codeintel
    README.txt
    VERSION
    db/
        # Any dir at this level is an independent database for a
        # single DB "zone".

        # API Catalogs zone -- codeintel API data loaded from .cix files
        # in one of the db_catalog_dirs.
        catalogs/
            res_index   # cix-path -> (res_id, last-updated, name,
                        #              {lang -> blobname -> ilk -> toplevelnames})
            blob_index              # {lang -> blobname -> (dbfile, res_id)}
            toplevelname_index      # {lang -> ilk -> toplevelname -> res_id -> blobnames}
            toplevelprefix_index    # {lang -> ilk -> prefix -> res_id -> toplevelnames}
            <safe-lang>/
                <dbfiles>

        # Codeintel includes .cix files for a number of language stdlibs
        # (all in "codeintel2/stdlibs/<lang>[-<ver>].cix"). These are
        # loaded here (as needed).
        stdlibs/
            res_index                   # cix-path -> last-updated
            vers_and_names_from_lang(lang) # ordered list of (ver, name)
            <stdlib-name>/
                blob_index              # {blobname -> dbfile}
                toplevelname_index      # {ilk -> toplevelname -> blobnames}
                toplevelprefix_index    # {ilk -> prefix -> toplevelnames}
                <dbfiles>

        # Language-specific zones (data for all scanned resources that
        # don't belong to a project).  Sub-separation is done by source
        # dir to not have too many dbfiles in a directory and to match
        # the fact the import lookup is generally by dir.
        # Note: the 'toplevelname_index' is to support
        # "import-everything" semantics (i.e. lib.hits_from_lpath()).
        <safe-lang-name>/
            lang
            <dir-hash>/                 # md5 of dir path
                path
                res_index               # basename -> scan_time, scan_error,
                                        #             {blobname -> ilk -> toplevelnames}
                blob_index              # {blobname -> dbfile}
                toplevelname_index      # {ilk -> toplevelname -> blobnames}
                <dbfiles>
            ...

        # Multi-lang zones (e.g. RHTML has Ruby and JavaScript) differ a
        # little bit but are mostly the same as single-lang zones.
        <safe-multi-lang-name>/
            lang
            <dir-hash>/                 # md5 of dir path
                path
                res_index               # basename
                                        #   -> scan_time, scan_error,
                                        #      {lang -> blobname -> ilk -> toplevelnames}
                blob_index              # {lang -> blobname -> dbfile}
                toplevelname_index      # {lang -> ilk -> toplevelname -> blobnames}
                <dbfiles>

        # Project-support
        # (OBSOLETE, not used)
        projs/
            <proj-path-hash>/
                path                # project file path
                dirs_from_basename  # index of basenames in project
                update_time         #XXX time 'dirs_from_basename' last updated

                TODO: Eventually could have a project catalog made up
                      from '.cix' files in the project tree.


# Actions

Optimizing the following actions on the database determines the db
structure.

1. Add resource. [done by database updating: various places]
2. Remove resource. [done by database updating: various places]
3. Update resource. [done by database updating: various places]
4. Has blob (for a given lang). [done by import handling during
   completion eval]
5. Load blob. [done by import handling during completion eval]
6. Where is given top-level name defined.
7. What are the top-level names matching the given prefix and ilk.


# Logging

There are some logging rules for this module to support the test suite.
- All writes to the filesystem should have a log message that begins
  with "fs-write: ".
- All reads from the filesystem should have a log message that begins
  with "fs-read: ". (TODO)

Note: Currently only doing this for LangZone stuff. This will be easier
if/when add fs interaction is moved to one place (on the Database
class).


# TODO

- bullet proof all db interaction for fs failure, corruption, etc.
  (see notes in test2/test_db.py)
- add search_index for object browser functionality
- add torture tests for this
- investigate (1) removing 'lang' redundancy in DB where possible (shouldn't
  be necessary for single-lang libraries), (2) using lang-id's instead of
  the language name to improve perf.


# Database.clean() and .check() TODO

- dbfiles for paths viewed as another language will persist in the DB
  (although I think the index entries will have been removed).
  These should be cleaned out.
- check for collisions in catalog: same lang, same blobname provided by
  two CIX files
"""

import sys
import os
from os.path import (join, dirname, exists, expanduser, expandvars, splitext, basename,
                     split, abspath, isabs, isdir, isfile)
import cPickle as pickle
from cPickle import UnpicklingError
import threading
import time
from hashlib import md5
import bisect
import fnmatch
from glob import glob
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import codecs
import copy
import weakref
import Queue

import ciElementTree as ET
from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.util import dedent, safe_lang_from_lang, banner
from codeintel2.tree import tree_from_cix_path
from codeintel2.database.util import rmdir
from codeintel2.database.stdlib import StdLibsZone
from codeintel2.database.catalog import CatalogsZone
from codeintel2.database.langlib import LangZone
from codeintel2.database.multilanglib import MultiLangZone
from codeintel2.database.projlib import ProjectZone


#---- globals
log = logging.getLogger("codeintel.db")
# log.setLevel(logging.DEBUG)


#---- Database zone and lib implementations

class Database(object):
    """Manages the persistence data store for codeintel. This is a
    singleton instance, available from 'Manager().db'.

    The main data stored here is citree data for code blobs (i.e.
    importable modules). However, this intends to be usable for other
    types of data (e.g. things that might be useful for codeintel on
    non-programming languages like HTML, XML (e.g. schema info) and
    CSS).

    Dev Notes:
    - We'll start with just custom methods for different types of things
      and only "go generic" if it seems helpful.
    """
    # Database version.
    # VERSION is the version of this Database code. The property
    # "version" is the version of the database on disk. The patch-level
    # version number should be used for small upgrades to the database.
    #
    # db change log:
    # - 2.0.24: (JS ordering of arguments, bug 94267)
    # - 2.0.23: (JS added __file_local__, bug 90823)
    # - 2.0.22: (Node.js core API documentation parser changes)
    # - 2.0.21: (PHP namespace top-level-name performance tweaks)
    # - 2.0.20: (PHP namespace class inheritance scanning)
    #   http://bugs.activestate.com/show_bug.cgi?id=84840
    # - 2.0.19: (Tcl statements include lassign)
    #   http://bugs.activestate.com/show_bug.cgi?id=75267
    # - 2.0.18: (PHP Alternative Control Syntax)
    #   http://bugs.activestate.com/show_bug.cgi?id=78957
    # - 2.0.17: (PHP variables) Parse complex variable definitions.
    #   http://bugs.activestate.com/show_bug.cgi?id=74625
    #   PHP stdlibs were also updated.
    # - 2.0.16: (PHP constants) Adding "ilk='constant'" attribute to
    #   PHP variables that are marked as constants.
    # - 2.0.15: (PHP/JS import-everything semantics.) Add
    #   "toplevelprefix_index" to stdlibs and catalogs zones. Currently
    #   not adding this index for (multi)lang zones (see comment in
    #   LangTopLevelNameIndex.toplevel_cplns()).
    # - 2.0.14: (PHP/JS import-everything semantics.) Update
    #   "toplevelname_index" for multilang, stdlibs and catalogs zones.
    # - 2.0.13: (PHP/JS import-everything semantics.) Update
    #   "toplevelname_index" for lang zone.
    # - 2.0.12: Only generate "toplevelname_index" for some langs. Use
    #   ".blob" extension for blobs in StdLibsZone. Use "blob_index" in
    #   StdLibsZone (as with other zones). Support "toplevelname_index"
    #   in StdLibsZone.
    # - 2.0.11: Update (Multi)LangZone's with "toplevelname_index" to
    #   support "import everything" semantics.
    # - 2.0.10: Manually adding a "src" attribute to blobs in
    #   (Multi)LangZone's. Needed for "Goto Definition" in determining
    #   file location.
    # - 2.0.9: 'blob_index' renamings in (Multi)LangZone's in prep for
    #   `lib.hits_from_lpath()' implementations.
    # - 2.0.8: Add catalog 'name' to CatalogsZone res_index. Needed for
    #   proper filtering on selection in CatalogsZone.update().
    # - 2.0.7: refactor to CatalogsZone and db/catalogs/... (i.e., plural)
    # - 2.0.6: Catalog zone updates to support catalog selection.
    # - 2.0.5: Fix to <bhash>.lpaths determination for JS. Only affected
    #   catalog zone.
    # - 2.0.4: Updates to catalog-zone indeces for "top-level names"
    #   caching (to support fast .hits_from_lpath()).
    # - 2.0.3: Add ".blob" to dbfile filenames in preparation for
    #   persisted cache keys (which will be stored as <bhash>.<key>
    #   next to the <bhash>.blob).
    # - 2.0.2: added scan_error to res_index in LangZone and MultiLangZone,
    #   add "lang" file to lang zones for reverse safe_lang -> lang lookup
    # - 2.0.1: s/VERSION.txt/VERSION/, made PHP a MultiLangZone
    VERSION = "2.0.24"

    LEN_PREFIX = 3  # Length of prefix in 'toplevelprefix_index' indeces.

    # Possible return values from .upgrade_info().
    (UPGRADE_NOT_NECESSARY,
     UPGRADE_NOT_POSSIBLE,
     UPGRADE_NECESSARY) = range(3)

    def __init__(self, mgr, base_dir=None, catalog_dirs=None,
                 event_reporter=None,
                 import_everything_langs=None):
        """
            "base_dir" (optional) specifies the base directory for
                the codeintel database. If not given it will default to
                '~/.codeintel'.
            "catalog_dirs" (optional) is a list of catalog dirs in
                addition to the std one to use for the CatalogsZone. All
                *.cix files in a catalog dir are made available.
            "event_reporter" (optional) is a callback that will be called
                    event_reporter(<event-desc-string>)
                before "significant" long processing events in the DB. This
                may be useful to forward to a status bar in a GUI.
            "import_everything_langs" (optional) is a set of lang names
                for which the `lib.hits_from_lpath()' API should be
                supported. This method is typically used to support
                "import-everything" cpln eval semantics.  Supporting it
                requires the 'toplevelname_index' indeces which adds
                significant space and perf burdens. If not specified,
                only JavaScript and PHP are included in the set.
        """
        self.mgr = mgr
        self._lock = threading.RLock()  # XXX Perhaps use per-zone locks?

        self._catalogs_zone = None
        self._stdlibs_zone = None
        self._lang_zone_from_lang = {}
        self._proj_zone_from_proj_path = weakref.WeakValueDictionary()

        if base_dir is None:
            self.base_dir = expandvars(expanduser(join("~", ".codeintel")))
        elif not isabs(base_dir):
            self.base_dir = abspath(base_dir)
        else:
            self.base_dir = base_dir

        self.catalog_dirs = catalog_dirs
        self.event_reporter = event_reporter

        if import_everything_langs is None:
            self.import_everything_langs = set()
        else:
            assert isinstance(import_everything_langs, set)
            self.import_everything_langs = import_everything_langs

        self.corruptions = []  # list of noted errors during db operation

    def acquire_lock(self):
        self._lock.acquire()

    def release_lock(self):
        self._lock.release()

    @property
    def version(self):
        """Return the version of the db on disk (or None if cannot
        determine).
        """
        path = join(self.base_dir, "VERSION")
        try:
            fin = open(path, 'r')
        except EnvironmentError, ex:
            return None
        try:
            return fin.read().strip()
        finally:
            fin.close()

    def upgrade_info(self):
        """Returns information indicating if a db upgrade is necessary
        and possible.

        Returns one of the following:
            (UPGRADE_NOT_NECESSARY, None)
            (UPGRADE_NOT_POSSIBLE, "<reason>")
            (UPGRADE_NECESSARY, None)
        """
        if self.version == self.VERSION:
            return (Database.UPGRADE_NOT_NECESSARY, None)
        # Presuming that we *have* an upgrade path from the current
        # version.
        return (Database.UPGRADE_NECESSARY, None)

    def create(self):
        log.info("create db in `%s'", self.base_dir)
        self.acquire_lock()
        try:
            log.debug("fs-write: create db skeleton in '%s'", self.base_dir)
            try:
                os.makedirs(self.base_dir)
            except:  # in case we had a race somewhere
                if not isdir(self.base_dir):
                    raise
            open(join(self.base_dir, "README.txt"), 'w').write(dedent("""
                This is a database for the Code Intelligence system (a
                subsystem of SublimeCodeIntel). Do NOT modify anything in here
                unless you know what you are doing.

                See http://github.com/SublimeCodeIntel/SublimeCodeIntel for details.
            """))
            open(join(self.base_dir, "VERSION"), 'w').write(self.VERSION)
            config_file = join(self.base_dir, "config")
            if not exists(config_file):
                open(config_file, 'w').write("{}")
            os.mkdir(join(self.base_dir, "db"))
        finally:
            self.release_lock()

    def reset(self, backup=True):
        """Move the given database out of the way to make way for a new one.

            "backup" (optional, default True) is a boolean indicating if
                the original database should be backed up. If so, the backup
                is $base_dir+".err".
        """
        self.acquire_lock()
        try:
            if exists(self.base_dir):
                # TODO: make this more bullet proof
                if backup:
                    err_base_dir = self.base_dir + ".err"
                    log.info("backing up db to '%s'", err_base_dir)
                    if os.path.exists(err_base_dir):
                        rmdir(err_base_dir)
                        for i in range(10):  # Try to avoid OSError from slow-deleting NTFS
                            if not os.path.exists(err_base_dir):
                                break
                            time.sleep(1)
                    if os.path.exists(err_base_dir):  # couldn't remove it
                        log.warn("couldn't remove old '%s' (skipping backup)",
                                 err_base_dir)
                        rmdir(self.base_dir)
                    else:
                        os.rename(self.base_dir, err_base_dir)
                else:
                    rmdir(self.base_dir)

            self._catalogs_zone = None
            self._stdlibs_zone = None
            self.create()
        finally:
            self.release_lock()

    def upgrade(self):
        """Upgrade the current database.

        Typically this is only called if .upgrade_info() returns
        UPGRADE_NECESSARY.
        """
        self.acquire_lock()
        try:
            # 'version' is the DB ver on disk, 'VERSION' is the target ver.
            curr_ver = self.version
            while curr_ver != self.VERSION:
                try:
                    result_ver, upgrader, upgrader_arg \
                        = self._result_ver_and_upgrader_and_arg_from_curr_ver[curr_ver]
                except KeyError:
                    raise DatabaseError("cannot upgrade from db v%s: no "
                                        "upgrader for this version"
                                        % curr_ver)
                log.info("upgrading from db v%s to db v%s ...",
                         curr_ver, result_ver)
                if upgrader_arg is not None:
                    upgrader(self, curr_ver, result_ver, upgrader_arg)
                else:
                    upgrader(self, curr_ver, result_ver)
                curr_ver = result_ver
        finally:
            self.release_lock()

    def _upgrade_wipe_db(self, curr_ver, result_ver):
        """Sometimes it is justified to just wipe the DB and start over."""
        assert result_ver == self.VERSION
        if exists(self.base_dir):
            log.debug("fs-write: wipe db")
            rmdir(self.base_dir)
        self.create()

    def _upgrade_wipe_db_catalogs(self, curr_ver, result_ver):
        catalog_dir = join(self.base_dir, "db", "catalogs")
        if exists(catalog_dir):
            log.debug("fs-write: wipe db/catalogs")
            rmdir(catalog_dir)
        open(join(self.base_dir, "VERSION"), 'w').write(result_ver)

    def _upgrade_wipe_db_langzones(self, curr_ver, result_ver):
        for lang in self._gen_langs_in_db():
            safe_lang = safe_lang_from_lang(lang)
            langzone_dir = join(self.base_dir, "db", safe_lang)
            if exists(langzone_dir):
                log.debug("fs-write: wipe db/%s", safe_lang)
                rmdir(langzone_dir)
        open(join(self.base_dir, "VERSION"), 'w').write(result_ver)

    def _upgrade_wipe_db_langs(self, curr_ver, result_ver, langs):
        for lang in langs:
            safe_lang = safe_lang_from_lang(lang)
            # stdlibs zone
            self.get_stdlibs_zone().remove_lang(lang)

            # API catalogs zone
            # TODO: CatalogsZone needs a .remove_lang(). Until then we just
            #      remove the whole thing.

            # (multi)langzone
            langzone_dir = join(self.base_dir, "db", safe_lang)
            if exists(langzone_dir):
                log.debug("fs-write: wipe db/%s", safe_lang)
                rmdir(langzone_dir)

        catalog_dir = join(self.base_dir, "db", "catalogs")
        if exists(catalog_dir):
            log.debug("fs-write: wipe db/catalogs")
            rmdir(catalog_dir)

        open(join(self.base_dir, "VERSION"), 'w').write(result_ver)

    _result_ver_and_upgrader_and_arg_from_curr_ver = {
        None: (VERSION, _upgrade_wipe_db, None),
        "2.0.1": (VERSION, _upgrade_wipe_db, None),
        "2.0.2": (VERSION, _upgrade_wipe_db, None),
        "2.0.3": (VERSION, _upgrade_wipe_db, None),
        "2.0.4": (VERSION, _upgrade_wipe_db, None),
        "2.0.5": (VERSION, _upgrade_wipe_db, None),
        "2.0.6": (VERSION, _upgrade_wipe_db, None),
        "2.0.7": (VERSION, _upgrade_wipe_db, None),
        "2.0.8": (VERSION, _upgrade_wipe_db, None),
        "2.0.9": (VERSION, _upgrade_wipe_db, None),
        "2.0.10": (VERSION, _upgrade_wipe_db, None),
        "2.0.11": (VERSION, _upgrade_wipe_db, None),
        "2.0.12": (VERSION, _upgrade_wipe_db, None),
        "2.0.13": (VERSION, _upgrade_wipe_db, None),
        # Techically only needed to wipe 'stdlibs' and 'catalogs' for
        # PHP and JavaScript, but this is easier.
        "2.0.14": (VERSION, _upgrade_wipe_db, None),
        "2.0.15": (VERSION, _upgrade_wipe_db_langs, ["PHP"]),
        "2.0.16": (VERSION, _upgrade_wipe_db_langs, ["PHP"]),
        "2.0.17": (VERSION, _upgrade_wipe_db_langs, ["PHP"]),
        "2.0.18": (VERSION, _upgrade_wipe_db_langs, ["Tcl"]),
        "2.0.19": (VERSION, _upgrade_wipe_db_langs, ["PHP"]),
        "2.0.20": (VERSION, _upgrade_wipe_db_langs, ["PHP"]),
        "2.0.21": (VERSION, _upgrade_wipe_db_langs, ["Node.js"]),
        "2.0.22": (VERSION, _upgrade_wipe_db_langs, ["JavaScript", "Node.js"]),
        "2.0.23": (VERSION, _upgrade_wipe_db_langs, ["JavaScript", "Node.js"]),
    }

    def report_event(self, desc):
        """Report a "significant" event in database processing.

        Various parts of the database can call this with a string
        description before performing some significant event. If
        this database was created with an event-reporter callback
        then it will be passed on.

        Guidelines:
        - report an event before doing a *long* action (e.g. importing a
          stdlib CIX file)
        - report None when that long action is completed
        """
        log.info("event: %s", desc)
        if self.event_reporter:
            try:
                self.event_reporter(desc)
            except Exception, ex:
                log.exception("error calling event reporter: %s", ex)

    def save(self):
        # Dev Notes:
        # - This is being called by the Manager.finalize().
        # - Don't need to call .save() for StdLibsZone because it saves
        #   immediately when updating (lazily on first use).
        # - XXX The plan is that a bookkeeper thread should also
        #   periodically call this.
        if self._catalogs_zone:
            self._catalogs_zone.save()
        for lang_zone in self._lang_zone_from_lang.values():
            lang_zone.save()

    def cull_mem(self):
        """Cull memory usage as necessary"""
        # this is currently called via the indexer (see _iteration)
        for zone in self.get_all_zones():
            try:
                zone.cull_mem()
            except:
                log.exception("Failed to cull memory for zone %r", zone)
        try:
            import gc
            gc.collect()
        except:
            pass

    _non_lang_db_dirs = ["catalogs", "stdlibs", "projs"]

    def _gen_langs_in_db(self):
        for d in os.listdir(join(self.base_dir, "db")):
            if d in self._non_lang_db_dirs:
                continue
            lang_path = join(self.base_dir, "db", d, "lang")
            if not exists(lang_path):
                log.warn("unexpected lang-zone db dir without 'lang' file: "
                         "`%s' (skipping)" % dirname(lang_path))
                continue
            fin = open(lang_path, 'r')
            try:
                lang = fin.read().strip()
            finally:
                fin.close()
            yield lang

    # Unused yet.
    def clean(self):
        """Clean out any expired/old codeintel information."""
        # TODO: Do other zones need cleaning?
        for lang in self._gen_langs_in_db():
            if not self.mgr.is_citadel_lang(lang):
                continue
            lang_zone = self._get_lang_zone(lang)
            lang_zone.clean()

    def check(self):
        """Return a list of internal consistency errors (if any) for the
        database.
        """
        errors = []

        for corruption in self.corruptions:
            errors.append("database corruption during '%s': %s (resolution: %s)"
                          % corruption)

        if self.version != self.VERSION:
            errors.append("VERSION mismatch: current DB version, '%s', is "
                          "not the latest, '%s'"
                          % (self.version, self.VERSION))

        errors += self._check_catalogszone()

        # TODO: check stdlibs zone

        for lang in self._gen_langs_in_db():
            if not self.mgr.is_citadel_lang(lang):
                continue
            lang_zone = self._get_lang_zone(lang)
            if not exists(lang_zone.base_dir):
                continue
            if isinstance(lang_zone, MultiLangZone):
                errors += self._check_multilangzone(lang_zone)
            else:
                errors += self._check_langzone(lang_zone)

        projs_dir = join(self.base_dir, "db", "projs")
        if exists(projs_dir):
            for dir in [join(projs_dir, d) for d in os.listdir(projs_dir)]:
                if not isdir(dir):
                    continue
                errors += self._check_proj_dir(dir)

        return errors

    def _check_catalogszone(self):
        log.debug("check catalogs zone...")
        # TODO: check toplevelname_index
        errors = []
        catalogs_zone = self.get_catalogs_zone()
        cix_path_from_res_id = {}
        for cix_path, res_data in catalogs_zone.res_index.items():
            res_id, last_updated, name, toplevelnames_from_blobname_from_lang \
                = res_data
            if res_id in cix_path_from_res_id:
                errors.append("catalogs zone: res_id %s used for both "
                              "'%s' and '%s'", cix_path_from_res_id[res_id],
                              cix_path)
            cix_path_from_res_id[res_id] = cix_path
        return errors

    def _check_proj_dir(self, proj_dir):
        log.debug("check '%s' proj zone...", basename(proj_dir))
        errors = []
        path_path = join(proj_dir, "path")
        if not exists(path_path):
            errors.append("proj zone: '%s/path' datafile does not exist"
                          % basename(proj_dir))
        return errors

    def _check_langzone(self, lang_zone):
        # Each blobname in the 'res_index' should have an entry and
        # dbfile in 'blob_index'.
        log.debug("check '%s' lang zone...", lang_zone.lang)
        errors = []

        for d in os.listdir(lang_zone.base_dir):
            if not isdir(join(lang_zone.base_dir, d)):
                continue

            path_path = join(lang_zone.base_dir, d, "path")
            if not exists(path_path):
                errors.append("%s lang zone: 'path' datafile does not "
                              "exist in '%s' dbdir" % (lang_zone.lang, d))
                path = d
            else:
                path = codecs.open(path_path, encoding="utf-8").read()
            res_index = lang_zone.load_index(path, "res_index", {})
            blob_index = lang_zone.load_index(path, "blob_index", {})
            # TODO
            # toplevelname_index = lang_zone.load_index(
            #        path, "toplevelname_index", {})

            all_blobnames = {}
            for filename, (scan_time, scan_error, res_data) \
                    in res_index.items():
                # res_data: {blobname -> ilk -> toplevelnames}
                for blobname in res_data:
                    if blobname in all_blobnames:
                        errors.append("%s lang zone: blob '%s' provided "
                                      "by more than one file in '%s' dir"
                                      % (lang_zone.lang, blobname, path))
                        continue
                    all_blobnames[blobname] = True
                    try:
                        dbfile = blob_index[blobname]
                    except KeyError:
                        errors.append(
                            "%s lang zone: blob '%s' provided by '%s' is "
                            "not in '%s/blob_index' index"
                            % (lang_zone.lang, blobname,
                               join(path, filename), d))
                        continue
                    if not exists(join(lang_zone.base_dir, d, dbfile+".blob")):
                        errors.append(
                            "%s lang zone: dbfile for blob '%s' provided "
                            "by '%s' does not exist (%s)"
                            % (lang_zone.lang, blobname,
                               join(path, filename),
                               join(d, dbfile)))
                    # Note: Could check that the dbfile actually
                    # includes a valid tree providing the named
                    # blob. That would make .check() very slow for
                    # large db's though.

        return errors

    def _check_multilangzone(self, lang_zone):
        # Each blobname in the 'res_index' should have an entry and
        # dbfile in 'blob_index'.
        log.debug("check '%s' multilang zone...", lang_zone.lang)
        errors = []

        for d in os.listdir(lang_zone.base_dir):
            if not isdir(join(lang_zone.base_dir, d)):
                continue

            path_path = join(lang_zone.base_dir, d, "path")
            if not exists(path_path):
                errors.append("%s lang zone: 'path' datafile does not "
                              "exist in '%s' dbdir" % (lang_zone.lang, d))
                path = d
            else:
                path = codecs.open(path_path, encoding="utf-8").read()
            res_index = lang_zone.load_index(path, "res_index", {})
            blob_index = lang_zone.load_index(path, "blob_index", {})
            # toplevelname_index = lang_zone.load_index(
            #        path, "toplevelname_index", {})

            all_langs_and_blobnames = {}
            for filename, (scan_time, scan_error, res_data) \
                    in res_index.items():
                # res_data: {lang -> blobname -> ilk -> toplevelnames}
                for lang, blobname in (
                    (lang, tfifb.keys()[
                     0])  # only one blob per lang in a resource
                    for lang, tfifb in res_data.items()
                ):
                    if (lang, blobname) in all_langs_and_blobnames:
                        errors.append("%s lang zone: %s blob '%s' provided "
                                      "by more than one file in '%s' dir"
                                      % (lang_zone.lang, lang, blobname, path))
                        continue
                    all_langs_and_blobnames[(lang, blobname)] = True
                    try:
                        dbfile = blob_index[lang][blobname]
                    except KeyError:
                        errors.append(
                            "%s lang zone: %s blob '%s' provided by '%s' is "
                            "not in '%s/blob_index'"
                            % (lang_zone.lang, lang, blobname,
                               join(path, filename), d))
                        continue
                    if not exists(join(lang_zone.base_dir, d, dbfile+".blob")):
                        errors.append(
                            "%s lang zone: dbfile for %s blob '%s' provided "
                            "by '%s' does not exist (%s)"
                            % (lang_zone.lang, lang, blobname,
                               join(path, filename), join(d, dbfile)))
                    # Note: Could check that the dbfile actually
                    # includes a valid tree providing the named
                    # blob. That would make .check() very slow for
                    # large db's though.

        return errors

    def corruption(self, action, desc, resolution):
        """Note a corruption in the database during operation.

            "action" is a string describing during what db action was
                being done when the corruption was discovered. Typically
                this is the method name.
            "desc" is a description of the corruption.
            "resolution" is a description of what was done to resolve or
                work-around the problem. Common resolutions:
                    'ignore'    work around the prob and continue on
                    'recover'
                    'remove buf data'

        This is called by internal database handlers.
        """
        log.warn("database corruption during '%s': %s (resolution: %s)",
                 action, desc, resolution)
        self.corruptions.append((action, desc, resolution))

    def get_catalogs_zone(self):
        if self._catalogs_zone is None:
            self._catalogs_zone = CatalogsZone(self.mgr, self.catalog_dirs)
        return self._catalogs_zone

    def get_catalog_lib(self, lang, selections=None):
        """Get a lang-specific handler for the catalog of loaded CIX files.

            "lang" is the language.
            "selections" (optional) is a set of catalog names (or full
                path to the CIX files) to use.  Essentially it is a
                filter.  If not specified, all available catalogs for
                this language are used. Otherwise only the selected
                catalogs are used. A catalog "name" is the
                (case-normalized) basename of the .cix file.
        """
        return self.get_catalogs_zone().get_lib(lang, selections)

    def get_stdlibs_zone(self):
        if self._stdlibs_zone is None:
            self._stdlibs_zone = StdLibsZone(self)
        return self._stdlibs_zone

    def get_stdlib(self, lang, ver=None):
        """Get a stdlib zone for the given language and version.

        On first get of a stdlib for a particular language, all
        available stdlibs for that lang are updated, if necessary.
        """
        return self.get_stdlibs_zone().get_lib(lang, ver)

    def _get_lang_zone(self, lang):
        if lang not in self._lang_zone_from_lang:
            if self.mgr.is_multilang(lang):
                self._lang_zone_from_lang[lang] = MultiLangZone(self.mgr, lang)
            else:
                self._lang_zone_from_lang[lang] = LangZone(self.mgr, lang)
        return self._lang_zone_from_lang[lang]

    def get_lang_lib(self, lang, name, dirs, sublang=None):
        """Get a language-specific zone handler for the given
        directories.

            "lang" is the language name, e.g. "Python".
            "name" is a user-friendly name for this particular lang-lib,
                e.g. "envlib" for set of dirs in PYTHONPATH or "sitelib"
                for the dirs in the Perl sitelib. This name is just used
                for logging and debugging.
            "dirs" is the ordered set of directories in this lib.
            "sublang" is used for multi-lang libs to indicate
                sub-language for which lookups will be done. For
                example, to get a PHP lang lib for which .has_blob()
                will search for PHP content (rather than JavaScript)
                sublang must be 'PHP'.  (For single-lang libs
                this should be None.)
        """
        assert isinstance(dirs, (tuple, list))
        lang_zone = self._get_lang_zone(lang)
        if isinstance(lang_zone, MultiLangZone):
            return lang_zone.get_lib(name, dirs, sublang)
        else:
            return lang_zone.get_lib(name, dirs)

    def get_proj_zone(self, proj):
        """Get a project zone handler for the given project.

            "proj" is an object representing the project. It should have
                the following interface:
                    proj.path       path to project file
                TODO: determine needed interface
        """
        proj_path = proj.path
        proj_zone = self._proj_zone_from_proj_path.get(proj_path)
        if proj_zone is None:
            proj_zone = ProjectZone(self.mgr, self, proj)
            self._proj_zone_from_proj_path[proj_path] = proj_zone
        return proj_zone

    def get_proj_lib(self, proj, lang):
        return self.get_proj_zone(proj).get_lib(lang)

    def get_all_zones(self):
        """ Get all LangZones for debugging """
        if self._catalogs_zone:
            yield self._catalogs_zone
        if self._stdlibs_zone:
            yield self._stdlibs_zone
        for zone in self._lang_zone_from_lang.values()[:]:
            yield zone
        for zone in self._proj_zone_from_proj_path.values()[:]:
            yield zone

    def load_blob(self, dbsubpath):
        """Load the blob and all persisted blob cache keys from disk."""
        log.debug("fs-read: load blob `%s'", dbsubpath[len(self.base_dir)+1:])
        blob = ET.parse(dbsubpath+".blob").getroot()
        blob_files = glob(dbsubpath+".*")
        for blob_cache_file in blob_files:
            ext = splitext(blob_cache_file)[1]
            if ext == ".blob":
                continue  # this is the blob ET itself
            cache_key = ext[1:]
            try:
                blob.cache[cache_key] = self.load_pickle(blob_cache_file)
            except (UnpicklingError, ImportError), ex:
                log.warn("error unpickling `%s' (skipping): %s",
                         blob_cache_file, ex)
        return blob

    def load_pickle(self, path, default=None):
        """Load the given pickle path.

        Note that attempting to unpickle a non-pickle file can raise
        cPickle.UnpicklingError or ImportError. For example:
            >>> import cPickle as pickle
            >>> pickle.load(open("foo.txt", 'rb'))
            Traceback (most recent call last):
              File "<stdin>", line 1, in ?
            ImportError: No module named odeintel: INFO: eval 'raven' at raven.py#29
        """
        if exists(path):
            log.debug("fs-read: load pickle `%s'", path[len(self.base_dir)+1:])
            fin = open(path, 'rb')
            try:
                return pickle.load(fin)
            except:
                if default is not None:
                    return default
                raise
            finally:
                fin.close()
        elif default is not None:
            return default
        else:
            raise OSError("`%s' does not exist" % path)

    def save_pickle(self, path, obj):
        if not exists(dirname(path)):
            log.debug("fs-write: mkdir '%s'",
                      dirname(path)[len(self.base_dir)+1:])
            try:
                os.makedirs(dirname(path))
            except OSError, ex:
                log.warn("error creating `%s': %s", dirname(path), ex)
        log.debug("fs-write: '%s'", path[len(self.base_dir)+1:])
        fout = open(path, 'wb')
        try:
            pickle.dump(obj, fout, 2)
        finally:
            fout.close()

    #---- Convenience methods for getting database hash keys.
    # MD5 hexdigests are used to generate keys into the db (typically
    # file paths).
    # TODO:PERF: evaluate perf improvement with caching of this
    def bhash_from_blob_info(self, res_path, lang, blobname):
        """Return a unique name for a blob dbfile.

        This is used as the filename for the dbfile for this blob.
        """
        s = ':'.join([res_path, lang, blobname])
        if isinstance(s, unicode):
            s = s.encode(sys.getfilesystemencoding())
        return md5(s).hexdigest()

    # TODO:PERF: evaluate perf improvement with caching of this
    def dhash_from_dir(self, dir):
        """Return a hash path to use internally in the db for the given dir."""
        if isinstance(dir, unicode):
            dir = dir.encode(sys.getfilesystemencoding())
        return md5(dir).hexdigest()

    #---- The following are convenience methods for working with a
    #     particular LangZone and a buffer.
    def get_buf_scan_time(self, buf):
        """Return the mtime for the given buffer in the database or
        return None.
        """
        return self._get_lang_zone(buf.lang).get_buf_scan_time(buf)

    def get_buf_data(self, buf):
        """Return the tree for the given buffer in the database or
        raise NotFoundInDatabase.
        """
        return self._get_lang_zone(buf.lang).get_buf_data(buf)

    def remove_buf_data(self, buf):
        """Remove data for this buffer from the database.

        If this resource isn't in the database, then this is a no-op.
        """
        self._get_lang_zone(buf.lang).remove_buf_data(buf)

    def update_buf_data(self, buf, scan_tree, scan_time, scan_error,
                        skip_scan_time_check=False):
        """Add or update data for this buffer into the database."""
        self._get_lang_zone(buf.lang).update_buf_data(
            buf, scan_tree, scan_time, scan_error,
            skip_scan_time_check=skip_scan_time_check)

########NEW FILE########
__FILENAME__ = langlib
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""The langzone of the codeintel database.
See the database/database.py module docstring for an overview.
"""

import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile, normpath)
import threading
import time
from glob import glob
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import codecs
import copy

import ciElementTree as ET
from codeintel2.common import *
from codeintel2 import util
from codeintel2.database.util import rmdir
from codeintel2.database.langlibbase import LangDirsLibBase


#---- globals

log = logging.getLogger("codeintel.db")
# log.setLevel(logging.DEBUG)


#---- Database zone and lib implementations
class LangDirsLib(LangDirsLibBase):
    """A zone providing a view into an ordered list of dirs in a
    db/$lang/... area of the db.

    These are dished out via Database.get_lang_lib(), which indirectly
    then is dished out by the LangZone.get_lib(). Mostly this is just a
    view on the LangZone singleton for this particular language.

    Dev Notes:
    - The goal is to provide quick has_blob() and get_blob() -- i.e.
      some caching is involved (if 'foo' referred to
      'some/path/to/foo.py' a minute ago then it still does). As well,
      scanning/loading is done automatically as necessary. For example,
      if a request for Perl blob 'Bar' is made but there is no 'Bar' in
      the database yet, this code looks for a 'Bar.pm' on the file
      system and will scan it, load it and return the blob for it.
    """
    def __init__(self, lang_zone, lock, lang, name, dirs):
        LangDirsLibBase.__init__(self)
        self.lang_zone = lang_zone
        self._lock = lock
        self.mgr = lang_zone.mgr
        self.lang = lang
        self.name = name
        self.dirs = dirs
        self.import_handler \
            = self.mgr.citadel.import_handler_from_lang(self.lang)

        self._blob_imports_from_prefix_cache = {}
        self._importables_from_dir_cache = {}

        # We keep a "weak" merged cache of blobname lookup for all dirs
        # in this zone -- where "weak" means that we verify a hit by
        # checking the current real blob_index for that dir (which may
        # have changed). This caching slows down lookup for single-dir
        # LangDirsZones, but should scale better for LangDirsZones with
        # many dirs. (TODO-PERF: test this assertion.)
        self._dir_and_blobbase_from_blobname = {}

    def __repr__(self):
        return "<%s %s>" % (self.lang, self.name)

    def _acquire_lock(self):
        self._lock.acquire()

    def _release_lock(self):
        self._lock.release()

    def has_blob(self, blobname, ctlr=None):
        dbsubpath = self._dbsubpath_from_blobname(blobname, ctlr=ctlr)
        return dbsubpath is not None

    def has_blob_in_db(self, blobname, ctlr=None):
        """Return true if the blobname is in the database.

        Typically this method is only used for debugging and .has_blob()
        is what you want.
        """
        dbsubpath = self._dbsubpath_from_blobname(
            blobname, ctlr=ctlr, only_look_in_db=True)
        return dbsubpath is not None

    def get_blob(self, blobname, ctlr=None):
        self._acquire_lock()
        try:
            dbsubpath = self._dbsubpath_from_blobname(blobname, ctlr=ctlr)
            if dbsubpath is not None:
                return self.lang_zone.load_blob(dbsubpath)
            else:
                return None
        finally:
            self._release_lock()

    def get_blob_imports(self, prefix):
        """Return the set of imports under the given prefix.

            "prefix" is a tuple of import name parts. E.g. ("xml", "sax")
                for "import xml.sax." in Python. Or ("XML", "Parser") for
                "use XML::Parser::" in Perl.

        See description in database.py docstring for details.
        """
        self._acquire_lock()
        try:
            if prefix not in self._blob_imports_from_prefix_cache:
                if prefix:
                    for dir in self.dirs:
                        importables = self._importables_from_dir(dir)
                        if prefix[0] in importables:
                            sub_importables = self._importables_from_dir(
                                join(dir, *prefix))
                            imports = set(
                                (name, is_dir_import)
                                for name, (_, _, is_dir_import)
                                in sub_importables.items()
                            )
                            break
                    else:
                        imports = set()
                else:
                    imports = set()
                    for dir in self.dirs:
                        importables = self._importables_from_dir(dir)
                        imports.update(
                            (name, is_dir_import)
                            for name, (_, _, is_dir_import)
                            in importables.items()
                        )
                self._blob_imports_from_prefix_cache[prefix] = imports
            return self._blob_imports_from_prefix_cache[prefix]
        finally:
            self._release_lock()

    def blobs_with_basename(self, basename, ctlr=None):
        """Return all blobs that match the given base path.

        I.e. a filename lookup across all files in the dirs of this lib.

            "basename" is a string, e.g. 'Http.js'
            "ctlr" (optional) is an EvalController instance. If
                specified it should be used in the normal way (logging,
                checking .is_aborted()).

        A "blob" is a global scope-tag hit in all of the blobs for the execution
        set buffers.

        Returns the empty list if no hits.
        """
        self.ensure_all_dirs_scanned(ctlr=ctlr)
        blobs = []
        # we can't use self.get_blob because that only returns one answer; we
        # we need all of them.

        self._acquire_lock()
        try:
            for dir in self.dirs:
                dbfile_from_blobname = self.lang_zone.dfb_from_dir(dir, {})
                blobbase = dbfile_from_blobname.get(basename)
                if blobbase is not None:
                    dhash = self.lang_zone.dhash_from_dir(dir)
                    dbsubpath = join(dhash, blobbase)
                    blobs.append(self.lang_zone.load_blob(dbsubpath))
        finally:
            self._release_lock()
        return blobs

    def hits_from_lpath(self, lpath, ctlr=None, curr_buf=None):
        """Return all hits of the given lookup path.

        I.e. a symbol table lookup across all files in the dirs of this
        lib.

            "lpath" is a lookup name list, e.g. ['Casper', 'Logging']
                or ['dojo', 'animation'].
            "ctlr" (optional) is an EvalController instance. If
                specified it should be used in the normal way (logging,
                checking .is_aborted()).
            "curr_buf" (optional), if specified, is the current buf for
                which this query is being made. Hits from it should be
                skipped (i.e. don't bother searching it).

        A "hit" is (<CIX node>, <scope-ref>).  Each one represent a
        scope-tag or variable-tag hit in all of the blobs for the
        execution set buffers.

        Returns the empty list if no hits.
        """
        assert isinstance(lpath, tuple)  # common mistake to pass in a string

        # Need to have (at least once) scanned all importables.
        # Responsibility for ensuring the scan data is *up-to-date*
        # is elsewhere.
        self.ensure_all_dirs_scanned(ctlr=ctlr)

        if curr_buf:
            curr_blobname = curr_buf.blob_from_lang.get(
                self.lang, {}).get("name")
            curr_buf_dir = dirname(curr_buf.path)

        # Naive implementation (no caching)
        hits = []
        for dir in self.dirs:
            if ctlr and ctlr.is_aborted():
                log.debug("ctlr aborted")
                break

            toplevelname_index = self.lang_zone.load_index(
                dir, "toplevelname_index", {})
            for blobname in toplevelname_index.get_blobnames(lpath[0], ()):
                if curr_buf and curr_buf_dir == dir and blobname == curr_blobname:
                    continue
                blob = self.get_blob(blobname, ctlr=ctlr)
                try:
                    elem = blob
                    for p in lpath:
                        # LIMITATION: *Imported* names at each scope are
                        # not being included here. This is fine while we
                        # just care about JavaScript.
                        if curr_buf:
                            if "__file_local__" in elem.get("attributes", "").split():
                                # this is a file-local element in a different blob,
                                # don't look at it
                                raise KeyError
                        elem = elem.names[p]
                except KeyError:
                    continue
                hits.append((elem, (blob, list(lpath[:-1]))))

        return hits

    def toplevel_cplns(self, prefix=None, ilk=None, ctlr=None):
        """Return completion info for all top-level names matching the
        given prefix and ilk in all blobs in this lib.

            "prefix" is a 3-character prefix with which to filter top-level
                names. If None (or not specified), results are not filtered
                based on the prefix.
            "ilk" is a symbol type (e.g. "class", "variable", "function")
                with which to filter results. If None (or not specified),
                results of any ilk are returned.
            "ctlr" (optional) is an EvalController instance. If
                specified it should be used in the normal way (logging,
                checking .is_aborted()).

        Returns a list of 2-tuples: (<ilk>, <name>).

        Note: the list is not sorted, because often some special sorting
        is required for the different completion evaluators that might use
        this API.
        """
        self.ensure_all_dirs_scanned(ctlr=ctlr)
        cplns = []
        # Naive implementation (no caching)
        for dir in self.dirs:
            if ctlr and ctlr.is_aborted():
                log.debug("ctlr aborted")
                break

            try:
                toplevelname_index = self.lang_zone.load_index(
                    dir, "toplevelname_index")
            except EnvironmentError:
                # No toplevelname_index for this dir likely indicates that
                # there weren't any files of the current lang in this dir.
                continue
            cplns += toplevelname_index.toplevel_cplns(prefix=prefix, ilk=ilk)
        return cplns

    def _importables_from_dir(self, dir):
        if dir not in self._importables_from_dir_cache:
            self._importables_from_dir_cache[dir] \
                = self.import_handler.find_importables_in_dir(dir)
        return self._importables_from_dir_cache[dir]

    def _dbsubpath_from_blobname(self, blobname, ctlr=None,
                                 only_look_in_db=False):
        """Return the subpath to the dbfile for the given blobname,
        or None if not found.

        Remember that this is complicated by possible multi-level
        imports. E.g. "import foo.bar" or "import foo" where 'foo'
        refers to 'foo/__init__.py'.
        """
        assert blobname is not None, "'blobname' cannot be None"
        lang_zone = self.lang_zone

        self._acquire_lock()
        try:
            # Use our weak cache to try to return quickly.
            if blobname in self._dir_and_blobbase_from_blobname:
                blobdir, blobbase \
                    = self._dir_and_blobbase_from_blobname[blobname]

                # Check it. The actual info for that dir may have changed.
                dbfile_from_blobname = lang_zone.dfb_from_dir(blobdir)
                if blobbase in dbfile_from_blobname:
                    log.debug("have blob '%s' in '%s'? yes (in weak cache)",
                              blobname, blobdir)
                    return join(lang_zone.dhash_from_dir(blobdir),
                                dbfile_from_blobname[blobbase])
                # Drop from weak cache.
                del self._dir_and_blobbase_from_blobname[blobname]

            # Brute force: look in each dir.
            blobparts = blobname.split(self.import_handler.sep)
            blobbase = blobparts[-1]
            for dir in self.dirs:
                if ctlr and ctlr.is_aborted():
                    log.debug("aborting search for blob '%s' on %s: "
                              "ctlr aborted", blobname, self)
                    return None

                # Is the blob in 'blobdir' (i.e. a non-multi-level import
                # that has been scanned already).
                blobdir = join(dir, *blobparts[:-1])
                dbfile_from_blobname = lang_zone.dfb_from_dir(blobdir, {})
                if self.lang == "Perl":
                    # Perl uses the full blob name - not just the blob base,
                    # see bug 89106 for details.
                    if blobname in dbfile_from_blobname:
                        self._dir_and_blobbase_from_blobname[blobname] \
                            = (blobdir, blobname)
                        log.debug("have blob '%s' in '%s'? yes (in dir index)",
                                  blobname, blobdir)
                        return join(lang_zone.dhash_from_dir(blobdir),
                                    dbfile_from_blobname[blobname])
                if blobbase in dbfile_from_blobname:
                    self._dir_and_blobbase_from_blobname[blobname] \
                        = (blobdir, blobbase)
                    log.debug("have blob '%s' in '%s'? yes (in dir index)",
                              blobname, blobdir)
                    return join(lang_zone.dhash_from_dir(blobdir),
                                dbfile_from_blobname[blobbase])

                importables = self._importables_from_dir(blobdir)
                # 'importables' look like, for Python:
                #   {'foo':  ('foo.py',          None,       False),
                #    'pkg':  ('pkg/__init__.py', '__init__', False)}
                # for Perl:
                #   {'LWP':  ('LWP.pm',          None,       True),
                #    'File': (None,              None,       True)}
                #    |        |                  |           `-- is-dir-import
                #    |        |                  `-- subdir-blobbase
                #    |        `-- blobfile
                #    `-- blobbase

                if blobbase not in importables:
                    continue

                blobfile, subdir_blobbase, is_dir_import = importables[
                    blobbase]
                if blobfile is None:
                    # There isn't an actual importable file here -- just
                    # a dir prefix to a multidir import.
                    log.debug("have blob '%s' in %s? no", blobname, self)
                    continue
                elif os.sep in blobfile:
                    # This is an import from a subdir. We need to get a new
                    # dbf.
                    blobdir = join(blobdir, dirname(blobfile))
                    blobfile = basename(blobfile)
                    blobbase = subdir_blobbase
                    dbfile_from_blobname = lang_zone.dfb_from_dir(blobdir, {})
                    if blobbase in dbfile_from_blobname:
                        self._dir_and_blobbase_from_blobname[blobname] \
                            = (blobdir, blobbase)
                        log.debug("have blob '%s' in '%s'? yes (in dir index)",
                                  blobname, blobdir)
                        return join(lang_zone.dhash_from_dir(blobdir),
                                    dbfile_from_blobname[blobbase])

                # The file isn't loaded.
                if not only_look_in_db:
                    log.debug("%s importables in '%s':\n    %s", self.lang,
                              blobdir, importables)
                    log.debug("'%s' likely provided by '%s' in '%s': "
                              "attempting load", blobname, blobfile, blobdir)
                    try:
                        buf = self.mgr.buf_from_path(
                            join(blobdir, blobfile), self.lang)
                    except (EnvironmentError, CodeIntelError), ex:
                        # This can occur if the path does not exist, such as a
                        # broken symlink, or we don't have permission to read
                        # the file, or the file does not contain text.
                        continue
                    buf.scan_if_necessary()

                    dbfile_from_blobname = lang_zone.dfb_from_dir(blobdir, {})
                    if self.lang == "Perl":
                        # Perl uses the full blob name - not just the blob base,
                        # see bug 89106 for details.
                        if blobname in dbfile_from_blobname:
                            self._dir_and_blobbase_from_blobname[blobname] \
                                = (blobdir, blobname)
                            log.debug(
                                "have blob '%s' in '%s'? yes (in dir index)",
                                blobname, blobdir)
                            return join(lang_zone.dhash_from_dir(blobdir),
                                        dbfile_from_blobname[blobname])
                    if blobbase in dbfile_from_blobname:
                        self._dir_and_blobbase_from_blobname[blobname] \
                            = (blobdir, blobbase)
                        log.debug("have blob '%s' in '%s'? yes (after load)",
                                  blobname, blobdir)
                        return join(lang_zone.dhash_from_dir(blobdir),
                                    dbfile_from_blobname[blobbase])

            log.debug("have blob '%s' in %s? no", blobname, self)
            return None
        finally:
            self._release_lock()


class LangTopLevelNameIndex(object):
    """A wrapper around the plain-dictionary toplevelname_index for a
    LangZone dir to provide better performance for continual updating
    and some simpler access.

        {ilk -> toplevelname -> blobnames}

    # Problem

    A 'toplevelname_index' is a merge of {blobname -> ilk -> toplevelnames}
    data for all resources in its dir.  As those resources are
    continually re-scanned (e.g. as a file is edited in Komodo), it
    would be too expensive to update this index everytime.

    # Solution

    Keep a list of "recent updates" and only merge them into the main
    data when that buf hasn't been updated in "a while" and when needed
    for saving the index. Note: Buffer *removals* are not put on-deck,
    but removed immediately.

    # .get_blobnames(..., ilk=None)

    Originally the toplevelname_index stored {toplevelname -> blobnames}.
    The per-"ilk" level was added afterwards to support occassional ilk
    filtering for PHP (and possible eventually other langs).

    .get_blobnames() still behaves like a {toplevelname -> blobnames}
    mapping, but it provides an optional "ilk" keyword arg to limit the
    results to that ilk.

    # Notes on locking

    This class does not guard its datastructures with locking. It is up
    to the LangZone using this to guard against simultaneous access on
    separate threads.
    """
    def __init__(self, data=None, timeout=90):
        # toplevelname_index data: {ilk -> toplevelname -> blobnames}
        if data is None:
            self._data = {}
        else:
            self._data = data

        # Time (in seconds) to hold a change "on deck".
        # Timed-out changes are merged on .get() and .update().
        self.timeout = timeout
        self._on_deck = {
            # basename                           # the basename of the buf path
            #   -> [timestamp,                   # time of the last update
            #       # The dict in res_index, a.k.a. 'res_data'
            #       {blobname -> ilk -> toplevelnames},
            #       # Lazily generated pivot, a.k.a. 'res_data_pivot'
            #       {ilk -> toplevelname -> blobnames}
            #      ]
        }

    def __repr__(self):
        num_toplevelnames = sum(len(v) for v in self._data.itervalues())
        return ("<LangTopLevelNameIndex: %d top-level name(s), "
                "%d update(s) on-deck>"
                % (num_toplevelnames, len(self._on_deck)))

    def merge(self):
        """Merge all on-deck changes with `self.data'."""
        for base, (timestamp, res_data,
                   res_data_pivot) in self._on_deck.items():
            if res_data_pivot is None:
                res_data_pivot = self._pivot_res_data(res_data)
            # res_data_pivot: {ilk -> toplevelname -> blobnames}
            # "bft" means blobnames_from_toplevelname
            for ilk, bft in res_data_pivot.iteritems():
                data_bft = self._data.setdefault(ilk, {})
                for toplevelname, blobnames in bft.iteritems():
                    if toplevelname not in data_bft:
                        data_bft[toplevelname] = blobnames
                    else:
                        data_bft[toplevelname].update(blobnames)
            del self._on_deck[base]

    def merge_expired(self, now):
        """Merge expired on-deck changes with `self.data'."""
        for base, (timestamp, res_data,
                   res_data_pivot) in self._on_deck.items():
            if now - timestamp < self.timeout:
                continue

            if res_data_pivot is None:
                res_data_pivot = self._pivot_res_data(res_data)
            # res_data_pivot: {ilk -> toplevelname -> blobnames}
            # "bft" means blobnames_from_toplevelname
            for ilk, bft in res_data_pivot.iteritems():
                data_bft = self._data.setdefault(ilk, {})
                for toplevelname, blobnames in bft.iteritems():
                    if toplevelname not in data_bft:
                        data_bft[toplevelname] = blobnames
                    else:
                        data_bft[toplevelname].update(blobnames)
            del self._on_deck[base]

    @property
    def data(self):
        self.merge()
        return self._data

    def update(self, base, old_res_data, new_res_data):
        now = time.time()
        self.remove(base, old_res_data)
        self._on_deck[base] = [now, new_res_data, None]
        self.merge_expired(now)

    def remove(self, base, old_res_data):
        if base in self._on_deck:
            del self._on_deck[base]
        else:
            # Remove old refs from current data.
            # old_res_data:   {blobname -> ilk -> toplevelnames}
            # self._data: {ilk -> toplevelname -> blobnames}
            for blobname, toplevelnames_from_ilk in old_res_data.iteritems():
                for ilk, toplevelnames in toplevelnames_from_ilk.iteritems():
                    for toplevelname in toplevelnames:
                        try:
                            self._data[ilk][toplevelname].remove(blobname)
                        except KeyError:
                            pass  # ignore this for now, might indicate corruption
                        else:
                            if not self._data[ilk][toplevelname]:
                                del self._data[ilk][toplevelname]
                    if not self._data.get(ilk):
                        del self._data[ilk]

    def _pivot_res_data(self, res_data):
        # res_data:       {blobname -> ilk -> toplevelnames}
        # res_data_pivot: {ilk -> toplevelname -> blobnames}
        res_data_pivot = {}
        for blobname, toplevelnames_from_ilk in res_data.iteritems():
            for ilk, toplevelnames in toplevelnames_from_ilk.iteritems():
                pivot_bft = res_data_pivot.setdefault(ilk, {})
                for toplevelname in toplevelnames:
                    if toplevelname not in pivot_bft:
                        pivot_bft[toplevelname] = set([blobname])
                    else:
                        pivot_bft[toplevelname].add(blobname)
        return res_data_pivot

    def toplevel_cplns(self, prefix=None, ilk=None):
        """Return completion info for all top-level names matching the
        given prefix and ilk.

            "prefix" is a 3-character prefix with which to filter top-level
                names. If None (or not specified), results are not filtered
                based on the prefix.
            "ilk" is a symbol type (e.g. "class", "variable", "function")
                with which to filter results. If None (or not specified),
                results of any ilk are returned.

        Returns a list of 2-tuples: (<ilk>, <name>).
        """
        self.merge_expired(time.time())

        # Need to check merged and on-deck items:
        cplns = []

        # ...on-deck items
        for base, (timestamp, res_data,
                   res_data_pivot) in self._on_deck.items():
            if res_data_pivot is None:
                res_data_pivot = self._on_deck[base][2] \
                    = self._pivot_res_data(res_data)
            # res_data_pivot: {ilk -> toplevelname -> blobnames}
            if ilk is None:
                for i, bft in res_data_pivot.iteritems():
                    cplns += [(i, toplevelname) for toplevelname in bft]
            elif ilk in res_data_pivot:
                cplns += [(ilk, toplevelname)
                          for toplevelname in res_data_pivot[ilk]]

        # ...merged data
        # self._data: {ilk -> toplevelname -> blobnames}
        if ilk is None:
            for i, bft in self._data.iteritems():
                cplns += [(i, toplevelname) for toplevelname in bft]
        elif ilk in self._data:
            cplns += [(ilk, toplevelname)
                      for toplevelname in self._data[ilk]]

        # Naive implementation: Instead of maintaining a separate
        # 'toplevelprefix_index' (as we do for StdLibsZone and CatalogsZone)
        # for now we'll just gather all results and filter on the prefix
        # here. Only if this proves to be a perf issue will we add the
        # complexity of another index:
        #   {ilk -> prefix -> toplevelnames}
        if prefix is not None:
            cplns = [(i, t) for i, t in cplns if t.startswith(prefix)]

        return cplns

    def get_blobnames(self, toplevelname, default=None, ilk=None):
        """Return the blobnames defining the given toplevelname.

        If "ilk" is given then only symbols of that ilk will be considered.
        If not match is found the "default" is returned.
        """
        self.merge_expired(time.time())

        blobnames = set()
        # First check on-deck items.
        for base, (timestamp, res_data,
                   res_data_pivot) in self._on_deck.items():
            if res_data_pivot is None:
                res_data_pivot = self._on_deck[base][2] \
                    = self._pivot_res_data(res_data)
            # res_data_pivot: {ilk -> toplevelname -> blobnames}
            if ilk is None:
                for bft in res_data_pivot.itervalues():
                    if toplevelname in bft:
                        blobnames.update(bft[toplevelname])
            elif ilk in res_data_pivot:
                if toplevelname in res_data_pivot[ilk]:
                    blobnames.update(res_data_pivot[ilk][toplevelname])

        # TODO: Put lookup in merged data ahead of lookup in on-deck -- so
        #      we don't do on-deck work if not necessary.
        # Then, fallback to already merged data.
        # self._data: {ilk -> toplevelname -> blobnames}
        if ilk is None:
            for bft in self._data.itervalues():
                if toplevelname in bft:
                    blobnames.update(bft[toplevelname])
        elif ilk in self._data:
            if toplevelname in self._data[ilk]:
                blobnames.update(self._data[ilk][toplevelname])

        if blobnames:
            return blobnames
        return default


class LangZone(object):
    """Singleton zone managing a particular db/$lang/... area.

    # caching and memory control

    We cache all retrieved indices and blobs and maintain their latest
    access time. To try to manage memory consumption, we rely on a
    bookkeeper thread (the indexer) to periodically call .cull_mem() --
    which unloads cache items that have not been accessed in a while.

    (TODO:
    - Get the indexer to actually call .cull_mem() and .save()
      periodically.
    - Test that .cull_mem() actually results in the process releasing
      memory.)

    # robustness (TODO)

    Work should be done to improve robustness.
    - Collect filesystem interactions in one place.
    - Rationalize OSError handling.
    - Consider a journal system, if necessary/feasible. My hope is to
      get away without one and rely on graceful recovery. The db does
      not store critical info so can allow some loss of data (it can all
      be regenerated).
    """
    toplevelname_index_class = LangTopLevelNameIndex

    def __init__(self, mgr, lang):
        self.mgr = mgr
        self.db = mgr.db
        self.lang = lang
        self.base_dir = join(self.db.base_dir, "db",
                             util.safe_lang_from_lang(lang))
        self._check_lang(lang)
        self._hook_handlers = self.mgr.hook_handlers_from_lang(lang)

        self._lock = threading.RLock()

        self._dhash_from_dir_cache = {}
        self._dirslib_cache = {}

        # We cache the set of recent indeces and blobs in memory.
        #   {db-subpath: [index-object, <atime>]),
        #    ...}
        # For example:
        #   {'7bce640bc48751b128af5c8bf5df8412/res_index':
        #       [<res-index>, 1158289000]),
        #    ...}
        self._index_and_atime_from_dbsubpath = {}
        # TODO-PERF: Use set() object for this? Compare perf.
        self._is_index_dirty_from_dbsubpath = {}  # set of dirty indeces
        # TODO: blob caching and *use* this
        # self._blob_and_atime_from_dbsubpath = {}

        # XXX Need a 'dirty-set' for blobs? No, because currently
        #    .update_buf_data() saves blob changes to disk immediately. Not
        #    sure that is best for perf. Definitely not ideal for the
        #    "editset".

    def __repr__(self):
        return "<%s lang db>" % self.lang

    def _acquire_lock(self):
        self._lock.acquire()

    def _release_lock(self):
        self._lock.release()

    def _check_lang(self, lang):
        """Ensure that the given lang matches case exactly with the lang
        in the db. If this invariant is broken, then weird things with
        caching can result.
        """
        if exists(self.base_dir):
            lang_path = join(self.base_dir, "lang")
            try:
                fin = open(lang_path, 'r')
            except EnvironmentError, ex:
                self.db.corruption("LangZone._check_lang",
                                   "could not open `%s': %s" % (lang_path, ex),
                                   "recover")
                fin = open(lang_path, 'w')
                try:
                    fin.write(lang)
                finally:
                    fin.close()
            else:
                try:
                    lang_on_disk = fin.read().strip()
                finally:
                    fin.close()
                assert lang_on_disk == lang

    # TODO: If Database.dhash_from_dir() grows caching, then this
    #      shouldn't bother.
    def dhash_from_dir(self, dir):
        if dir not in self._dhash_from_dir_cache:
            self._dhash_from_dir_cache[dir] = self.db.dhash_from_dir(dir)
        return self._dhash_from_dir_cache[dir]

    def dfb_from_dir(self, dir, default=None):
        """Get the {blobname -> dbfile} mapping index for the given dir.

        'dfb' stands for 'dbfile_from_blobname'.
        This must be called with the lock held.
        """
        return self.load_index(dir, "blob_index", default)

    def get_buf_scan_time(self, buf):
        # TODO Canonicalize path (or assert that it is canonicalized)
        self._acquire_lock()
        try:
            dir, base = split(buf.path)
            res_index = self.load_index(dir, "res_index", {})
            if base not in res_index:
                return None
            return res_index[base][0]
        finally:
            self._release_lock()

    def get_buf_data(self, buf):
        # TODO Canonicalize path (or assert that it is canonicalized)
        #     Should have a Resource object that we pass around that
        #     handles all of this.
        self._acquire_lock()
        try:
            dir, base = split(buf.path)
            res_index = self.load_index(dir, "res_index", {})
            if base not in res_index:
                raise NotFoundInDatabase("%s buffer '%s' not found in database"
                                         % (buf.lang, buf.path))
            scan_time, scan_error, res_data = res_index[base]

            blob_from_lang = {}
            if res_data:
                try:
                    dbfile_from_blobname = self.dfb_from_dir(dir)
                except EnvironmentError, ex:
                    # DB corruption will be noted in remove_buf_data()
                    self.remove_buf_data(buf)
                    raise NotFoundInDatabase("%s buffer '%s' not found in database"
                                             % (buf.lang, buf.path))
                dhash = self.dhash_from_dir(dir)
                for blobname in res_data:
                    dbsubpath = join(dhash, dbfile_from_blobname[blobname])
                    try:
                        blob = self.load_blob(dbsubpath)
                    except ET.XMLParserError, ex:
                        self.db.corruption("LangZone.get_buf_data",
                                           "could not parse dbfile for '%s' blob: %s"
                                           % (blobname, ex),
                                           "recover")
                        self.remove_buf_data(buf)
                        raise NotFoundInDatabase(
                            "`%s' buffer `%s' blob was corrupted in database"
                            % (buf.path, blobname))
                    except EnvironmentError, ex:
                        self.db.corruption("LangZone.get_buf_data",
                                           "could not read dbfile for '%s' blob: %s"
                                           % (blobname, ex),
                                           "recover")
                        self.remove_buf_data(buf)
                        raise NotFoundInDatabase(
                            "`%s' buffer `%s' blob not found in database"
                            % (buf.path, blobname))
                    lang = blob.get("lang")
                    assert lang is not None
                    blob_from_lang[lang] = blob

            return scan_time, scan_error, blob_from_lang
        finally:
            self._release_lock()

    def remove_path(self, path):
        """Remove the given resource from the database."""
        # TODO Canonicalize path (or assert that it is canonicalized)
        #     Should have a Resource object that we pass around that
        #     handles all of this.
        self._acquire_lock()
        try:
            dir, base = split(path)

            res_index = self.load_index(dir, "res_index", {})
            try:
                scan_time, scan_error, res_data = res_index[base]
            except KeyError:
                # This resource isn't loaded in the db. Nothing to remove.
                return

            try:
                blob_index = self.load_index(dir, "blob_index")
            except EnvironmentError, ex:
                self.db.corruption("LangZone.remove_path",
                                   "could not read blob_index for '%s' dir: %s" % (
                                       dir, ex),
                                   "recover")
                blob_index = {}

            is_hits_from_lpath_lang = self.lang in self.db.import_everything_langs
            if is_hits_from_lpath_lang:
                try:
                    toplevelname_index = self.load_index(
                        dir, "toplevelname_index")
                except EnvironmentError, ex:
                    self.db.corruption("LangZone.remove_path",
                                       "could not read toplevelname_index for '%s' dir: %s"
                                       % (dir, ex),
                                       "recover")
                    toplevelname_index = self.toplevelname_index_class()

            dhash = self.dhash_from_dir(dir)
            del res_index[base]
            for blobname in res_data:
                try:
                    dbfile = blob_index[blobname]
                except KeyError:
                    blob_index_path = join(dhash, "blob_index")
                    self.db.corruption("LangZone.remove_path",
                                       "'%s' blob not in '%s'"
                                       % (blobname, blob_index_path),
                                       "ignore")
                    continue
                del blob_index[blobname]
                for path in glob(join(self.base_dir, dhash, dbfile+".*")):
                    log.debug("fs-write: remove %s blob file '%s/%s'",
                              self.lang, dhash, basename(path))
                    os.remove(path)
            if is_hits_from_lpath_lang:
                toplevelname_index.remove(base, res_data)

            self.changed_index(dir, "res_index")
            self.changed_index(dir, "blob_index")
            if is_hits_from_lpath_lang:
                self.changed_index(dir, "toplevelname_index")
        finally:
            self._release_lock()
        # TODO Database.clean() should remove dirs that have no
        #     blob_index entries.

    def remove_buf_data(self, buf):
        """Remove the given buffer from the database."""
        self.remove_path(buf.path)

    def update_buf_data(self, buf, scan_tree, scan_time, scan_error,
                        skip_scan_time_check=False):
        """Update this LangZone with the buffer data.

        @param buf {CitadelBuffer} the buffer whose data is being added
            to the database.
        @param scan_tree {ciElementTree} the CIX scan data. Might be None
            if there was an early scanning failure.
        @param scan_time {timestamp} the time of the scan, typically the
            mtime of the file
        @param scan_error {str} an error string if scanning failed, or
            None if it was succesful.
        @param skip_scan_time_check {boolean} (default False) is a
            boolean indicating if the buffer data should be updated even
            if `scan_time` is <= that in the database.
        """
        self._acquire_lock()
        try:
            # TODO: Canonicalize path (or assert that it is canonicalized)
            dir, base = split(buf.path)

            # Get the current data, if any.
            res_index = self.load_index(dir, "res_index", {})
            res_index_has_changed = False
            blob_index = self.load_index(dir, "blob_index", {})
            blob_index_has_changed = False
            is_hits_from_lpath_lang = self.lang in self.db.import_everything_langs
            if is_hits_from_lpath_lang:
                # TODO: Not sure {} for a default is correct here.
                toplevelname_index = self.load_index(
                    dir, "toplevelname_index", {})
                toplevelname_index_has_changed = False
            try:
                (old_scan_time, old_scan_error, old_res_data) = res_index[base]
            except KeyError:    # adding a new entry
                (old_scan_time, old_scan_error, old_res_data) = None, None, {}
            else:               # updating an existing entry
                if not skip_scan_time_check and scan_time is not None \
                   and scan_time <= old_scan_time:
                    log.debug("skipping db update for '%s': %s < %s and "
                              "no 'skip_scan_time_check' option",
                              base, scan_time, old_scan_time)
                    return

            log.debug("update from %s buf '%s'", buf.lang, buf.path)

            # Parse the tree and get the list of blobnames.
            # res_data: {blobname -> ilk -> toplevelnames}
            new_res_data = {}
            new_blobnames_and_blobs = []
            if scan_tree:
                for blob in scan_tree[0]:
                    lang = blob.get("lang")
                    assert blob.get("lang") == self.lang, "'%s' != '%s' (blob %r)" % (
                        blob.get("lang"), self.lang, blob)
                    blobname = blob.get("name")
                    toplevelnames_from_ilk = new_res_data.setdefault(
                        blobname, {})
                    for toplevelname, elem in blob.names.iteritems():
                        if "__file_local__" in elem.get("attributes", "").split():
                            # don't put file local things in toplevel names
                            continue
                        ilk = elem.get("ilk") or elem.tag
                        if ilk not in toplevelnames_from_ilk:
                            toplevelnames_from_ilk[ilk] = set([toplevelname])
                        else:
                            toplevelnames_from_ilk[ilk].add(toplevelname)
                    new_blobnames_and_blobs.append((blobname, blob))

            # Determine necessary changes to res_index.
            if scan_error:
                if (scan_time != old_scan_time
                        or scan_error != old_scan_error):
                    res_index[base] = (scan_time, scan_error,
                                       old_res_data)
                    res_index_has_changed = True

            else:
                # Only consider new blobs if there wasn't a scan error.
                # I.e., we want to preserve the last good scan info.

                if (scan_time != old_scan_time
                    or scan_error != old_scan_error
                        or new_res_data != old_res_data):
                    res_index[base] = (scan_time, scan_error,
                                       new_res_data)
                    res_index_has_changed = True

                if is_hits_from_lpath_lang:
                    if new_res_data != old_res_data:
                        toplevelname_index.update(base,
                                                  old_res_data, new_res_data)
                        toplevelname_index_has_changed = True

                # Determine necessary changes to blob_index and the
                # dbfiles and then make them.
                dbfile_changes = []
                for blobname, blob in new_blobnames_and_blobs:
                    if blobname in old_res_data:
                        dbfile_changes.append(("update", blobname, blob))
                    else:
                        dbfile_changes.append(("add", blobname, blob))
                for blobname in old_res_data:
                    if blobname not in new_res_data:
                        dbfile_changes.append(("remove", blobname, None))

                dhash = self.dhash_from_dir(dir)
                for action, blobname, blob in dbfile_changes:
                    if action == "add":
                        dbfile = self.db.bhash_from_blob_info(
                            buf.path, self.lang, blobname)
                        blob_index[blobname] = dbfile
                        blob_index_has_changed = True
                        dbdir = join(self.base_dir, dhash)
                        if not exists(dbdir):
                            self._mk_dbdir(dbdir, dir)
                        # XXX What to do on write failure?
                        log.debug("fs-write: %s blob '%s/%s'",
                                  self.lang, dhash, dbfile)
                        if blob.get("src") is None:
                            blob.set(
                                "src", buf.path)   # for defns_from_pos() support
                        ET.ElementTree(blob).write(join(dbdir, dbfile+".blob"))
                    elif action == "remove":
                        dbfile = blob_index[blobname]
                        del blob_index[blobname]
                        blob_index_has_changed = True
                        # XXX What to do on removal failure?
                        log.debug("fs-write: remove %s blob '%s/%s'",
                                  self.lang, dhash, dbfile)
                        os.remove(join(self.base_dir, dhash, dbfile+".blob"))
                    elif action == "update":
                        # Try to only change the dbfile on disk if it is
                        # different.
                        s = StringIO()
                        if blob.get("src") is None:
                            blob.set(
                                "src", buf.path)   # for defns_from_pos() support
                        ET.ElementTree(blob).write(s)
                        new_dbfile_content = s.getvalue()
                        dbfile = blob_index[blobname]
                        dbpath = join(self.base_dir, dhash, dbfile+".blob")
                        # PERF: Might be nice to cache the new dbfile
                        #       content for the next time this resource is
                        #       updated. For files under edit this will be
                        #       common. I.e. just for the "editset".
                        try:
                            fin = open(dbpath, 'r')
                        except (OSError, IOError), ex:
                            # Technically if the dbfile doesn't exist, this
                            # is a sign of database corruption. No matter
                            # though (for this blob anyway), we are about to
                            # replace it.
                            old_dbfile_content = None
                        else:
                            try:
                                old_dbfile_content = fin.read()
                            finally:
                                fin.close()
                        if new_dbfile_content != old_dbfile_content:
                            if not exists(dirname(dbpath)):
                                self._mk_dbdir(dirname(dbpath), dir)
                            # XXX What to do if fail to write out file?
                            log.debug("fs-write: %s blob '%s/%s'",
                                      self.lang, dhash, dbfile)
                            fout = open(dbpath, 'w')
                            try:
                                fout.write(new_dbfile_content)
                            finally:
                                fout.close()

            if res_index_has_changed:
                self.changed_index(dir, "res_index")
            if blob_index_has_changed:
                self.changed_index(dir, "blob_index")
            if is_hits_from_lpath_lang and toplevelname_index_has_changed:
                self.changed_index(dir, "toplevelname_index")
        finally:
            self._release_lock()
        # TODO Database.clean() should remove dirs that have no
        #     blob_index entries.

    def _mk_zone_skel(self):
        log.debug("fs-write: mkdir '%s'", self.base_dir)
        os.makedirs(self.base_dir)
        log.debug("fs-write: create 'lang'")
        fout = codecs.open(join(self.base_dir, "lang"), 'wb', 'utf-8')
        try:
            fout.write(self.lang)
        finally:
            fout.close()

    def _mk_dbdir(self, dbdir, dir):
        if not exists(self.base_dir):
            self._mk_zone_skel()
        log.debug("fs-write: mkdir '%s'", dbdir[len(self.base_dir)+1:])
        os.mkdir(dbdir)
        log.debug("fs-write: '%s/path'", dbdir[len(self.base_dir)+1:])
        fout = codecs.open(join(dbdir, "path"), 'wb', 'utf-8')
        try:
            fout.write(dir)
        finally:
            fout.close()

    def load_blob(self, dbsubpath):
        """This must be called with the lock held."""
        log.debug("TODO: LangZone.load_blob: add blob caching!")
        log.debug("fs-read: load %s blob '%s'", self.lang, dbsubpath)
        dbpath = join(self.base_dir, dbsubpath+".blob")
        blob = ET.parse(dbpath).getroot()
        for hook_handler in self._hook_handlers:
            try:
                hook_handler.post_db_load_blob(blob)
            except:
                log.exception("error running hook: %r.post_db_load_blob(%r)",
                              hook_handler, blob)
        return blob

    def load_index(self, dir, index_name, default=None):
        """Get the indicated index.

            "dir" is the dir path this index represents.
            "index_name" is the name of the index.
            "default" (default None) indicate the value to return for
                the index if the index doesn't exist. If not set (or
                None) then an OSError is raised if the index doesn't exist.

        The index is loaded from a pickle on disk, if necessary, put
        into the cache system, and returned.

        This must be called with the lock held.
        """
        self._acquire_lock()
        try:
            dbsubpath = join(self.db.dhash_from_dir(dir), index_name)

            # If index path is in the cache: return it, update its atime.
            now = time.time()
            if dbsubpath in self._index_and_atime_from_dbsubpath:
                log.debug(
                    "cache-read: load %s index '%s'", self.lang, dbsubpath)
                self._index_and_atime_from_dbsubpath[dbsubpath][1] = now
                return self._index_and_atime_from_dbsubpath[dbsubpath][0]

            # Otherwise, load it.
            log.debug("fs-read: load %s index '%s'", self.lang, dbsubpath)
            dbpath = join(self.base_dir, dbsubpath)
            index = self.db.load_pickle(dbpath, default)
            if index_name == "toplevelname_index":
                index = self.toplevelname_index_class(index)
            self._index_and_atime_from_dbsubpath[dbsubpath] = [index, now]
            return index
        finally:
            self._release_lock()

    def changed_index(self, dir, index_name):
        """Note that we've changed this index (so it can be saved as
        appropriate).
        """
        self._acquire_lock()
        try:
            now = time.time()
            dbsubpath = join(self.db.dhash_from_dir(dir), index_name)
            self._index_and_atime_from_dbsubpath[dbsubpath][1] = now
            self._is_index_dirty_from_dbsubpath[dbsubpath] = True
        finally:
            self._release_lock()

    def save_index(self, dbsubpath, index):
        if isinstance(index, self.toplevelname_index_class):
            index = index.data
        self.db.save_pickle(join(self.base_dir, dbsubpath), index)

    def save(self):
        self._acquire_lock()
        try:
            for dbsubpath in self._is_index_dirty_from_dbsubpath:
                self.save_index(dbsubpath,
                                self._index_and_atime_from_dbsubpath[dbsubpath][0])
            self._is_index_dirty_from_dbsubpath = {}
        finally:
            self._release_lock()

    def cull_mem(self):
        """Drop indeces and tree from cache that have not been
        accessed in over 5 minutes.

        To attempt to keep memory consumption under control we want to
        ensure we don't keep everything cached from the db in memory
        until process completion. The plan is to have a thread
        periodically cull memory.
        """
        # TOTEST: Does Python/Komodo actually release this memory or
        #        are we kidding ourselves?
        log.debug("LangZone: culling memory")
        TIME_SINCE_ACCESS = 300.0  # 5 minutes since last access
        self._acquire_lock()
        try:
            N = 30
            if len(self._index_and_atime_from_dbsubpath) < N:
                # Too few indeces in memory to bother culling.
                return

            now = time.time()
            for dbsubpath, (index, atime) \
                    in self._index_and_atime_from_dbsubpath.items():
                if now - atime > TIME_SINCE_ACCESS:
                    if dbsubpath in self._is_index_dirty_from_dbsubpath:
                        self.save_index(dbsubpath, index)
                        del self._is_index_dirty_from_dbsubpath[dbsubpath]
                    del self._index_and_atime_from_dbsubpath[dbsubpath]
        except:
            log.exception("Exception culling memory")
        finally:
            self._release_lock()

        # XXX Database.clean(): Go through each $lang/dir/res_index and
        #    clean out files in the index but that don't actually exist
        #    anymore.
        # XXX Database.clean(): drop memory for indeces that are quite
        #    old (say haven't been accessed in 20 minutes).
        # XXX Database.check(): Shouldn't have too many cached indeces in
        #    memory. How old is the oldest one? Estimate memory size
        #    used by all loaded indeces?

    # TODO: When a directory no longer exists on the filesystem - should we
    #          1) remove the db data, or
    #          2) mark it as expired.
    #       Option 2 would work better for (network) mounted filesystems, as it
    #       could just be an intermittent issue.
    def clean(self):
        """Clean out any expired/old codeintel information."""
        base_dir = self.base_dir
        if not exists(base_dir):
            return
        for d in os.listdir(base_dir):
            path_path = join(base_dir, d, "path")
            if not exists(path_path):
                continue
            path = codecs.open(path_path, encoding="utf-8").read()
            if not exists(path):
                # Referenced directory no longer exists - so remove the db
                # info.
                log.debug("clean:: scanned directory no longer exists: %r",
                          path)
                rmdir(join(base_dir, d))

    def get_lib(self, name, dirs):
        """
        Dev Notes:
        We make a lib for a particular sequence of dirs a singleton because:
        1. The sequence of dirs for a language's import path tends to
           not change, so the same object will tend to get used.
        2. This allows caching of filesystem lookups to be done naturally
           on the LangDirsLib instance.

        To ensure that this cache doesn't grow unboundedly we only allow
        there to be N cached LangDirsLib's. A good value for N is when
        there are relatively few cache misses. Ideally we'd want to
        count the number of cache misses (i.e. LangDirsLib instance
        creations) for a number of "typical" uses of codeintel -- i.e. a
        long running Komodo profile. Failing that we'll just use N=10.
        """
        assert isinstance(dirs, (tuple, list))
        canon_dirs = tuple(set(abspath(normpath(expanduser(d))) for d in dirs))
        if canon_dirs in self._dirslib_cache:
            return self._dirslib_cache[canon_dirs]

        langdirslib = LangDirsLib(self, self._lock, self.lang, name,
                                  canon_dirs)
        # Ensure that these directories are all *up-to-date*.
        langdirslib.ensure_all_dirs_scanned()

        self._dirslib_cache[canon_dirs] = langdirslib

        return langdirslib

    def reportMemory(self):
        """
        Report on memory usage from this LangZone.
        @returns {dict} memory usage; keys are the paths, values are a dict of
            "amount" -> number
            "units" -> "bytes" | "count"
            "desc" -> str description
        """
        log.debug("%s LangZone: reporting memory", self.lang)
        import memutils
        return {
            "komodo\\codeintel/langzone/%s/index-cache" % (self.lang,): {
                "amount": len(self._index_and_atime_from_dbsubpath),
                "units": "count",
                "desc": "Number of cached indices.",
            },
            "explicit/python/codeintel/%s/index-cache" % (self.lang,): {
                "amount": memutils.memusage(self._index_and_atime_from_dbsubpath),
                "units": "bytes",
                "desc": "The number of bytes of %s codeintel index caches." % (self.lang,),
            },
        }

########NEW FILE########
__FILENAME__ = langlibbase
#!python
# Copyright (c) 2004-2011 ActiveState Software Inc.
# See the file LICENSE.txt for licensing information.

"""Shared base class for LangDirsLib / MultiLangDirsLib
See langlib.py / multilanglib.py
"""

import logging
from os.path import join
from contextlib import contextmanager
from codeintel2.common import *

#---- globals
log = logging.getLogger("codeintel.db")
# log.setLevel(logging.DEBUG)

#---- Base lang lib implementation


class LangDirsLibBase(object):
    def __init__(self):
        self._have_ensured_scanned_from_dir_cache = set()

    def ensure_all_dirs_scanned(self, ctlr=None):
        """Ensure that all importables in this dir have been scanned
        into the db at least once.
        """
        # filter out directories we've already scanned, so that we don't need
        # to report them (this also filters out quite a few spurious
        # notifications)
        dirs = frozenset(
            filter(
                lambda d: d not in self._have_ensured_scanned_from_dir_cache,
                self.dirs))
        if not dirs:
            # all directories have already been scanned; nothing to do.
            log.debug("Skipping scanning dirs %r - all scanned",
                      self.dirs)
            return

        reporter = self.lang_zone.db.event_reporter

        if reporter and hasattr(reporter, "onScanStarted"):
            # TODO: i18n w/ PluralForms
            msg = "Scanning %r directories" % (len(dirs),)
            if len(dirs) == 1:
                msg = "Scanning one directory"
            reporter.onScanStarted(msg, dirs)

        log.debug("ensure_all_dirs_scanned: scanning %r directories",
                  len(dirs))
        scanned = set()
        try:
            for dir in dirs:
                if ctlr:
                    if ctlr.is_aborted():
                        log.debug("ctlr aborted")
                        break
                try:
                    if reporter and hasattr(reporter, "onScanDirectory"):
                        reporter.onScanDirectory(
                            "Scanning %s files in '%s'" % (self.lang, dir),
                            dir,
                            len(scanned),
                            len(dirs))
                except:
                    pass  # eat any errors about reporting progress
                self.ensure_dir_scanned(
                    dir, ctlr=ctlr, reporter=lambda msg: None)
                scanned.add(dir)
        finally:
            # report that we have stopped scanning
            log.debug("ensure_all_dirs_scanned: finished scanning %r/%r dirs",
                      len(scanned), len(dirs))
            if reporter and hasattr(reporter, "onScanComplete"):
                reporter.onScanComplete(dirs, scanned)

    def ensure_dir_scanned(self, dir, ctlr=None, reporter=None):
        """Ensure that all importables in this dir have been scanned
        into the db at least once.
        """
        # TODO: should "self.lang" in this function be "self.sublang" for
        # the MultiLangDirsLib case?
        if dir not in self._have_ensured_scanned_from_dir_cache:
            if reporter is None:
                reporter = self.lang_zone.db.event_reporter
            if not callable(reporter):
                reporter = None
            res_index = self.lang_zone.load_index(dir, "res_index", {})
            importables = self._importables_from_dir(dir)
            importable_values = [i[0] for i in importables.values()
                                 if i[0] is not None]
            for base in importable_values:
                if ctlr and ctlr.is_aborted():
                    log.debug("ctlr aborted")
                    return
                if base not in res_index:
                    if reporter:
                        reporter("scanning %s files in '%s'" % (
                            self.lang, dir))
                        reporter = None  # don't report again
                    try:
                        buf = self.mgr.buf_from_path(join(dir, base),
                                                     lang=self.lang)
                    except (EnvironmentError, CodeIntelError), ex:
                        # This can occur if the path does not exist, such as a
                        # broken symlink, or we don't have permission to read
                        # the file, or the file does not contain text.
                        continue
                    if ctlr is not None:
                        ctlr.info("load %r", buf)
                    buf.scan_if_necessary()

            # Remove scanned paths that don't exist anymore.
            removed_values = set(
                res_index.keys()).difference(importable_values)
            for base in removed_values:
                if ctlr and ctlr.is_aborted():
                    log.debug("ctlr aborted")
                    return
                if reporter:
                    reporter("scanning %s files in '%s'" % (self.lang, dir))
                    reporter = None  # don't report again
                basename = join(dir, base)
                self.lang_zone.remove_path(basename)

            self._have_ensured_scanned_from_dir_cache.add(dir)

########NEW FILE########
__FILENAME__ = multilanglib
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""The multilang-zone of the codeintel database.
See the database/database.py module docstring for an overview.
"""

import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile, normpath)
from glob import glob
from pprint import pprint, pformat
import time
import logging
from cStringIO import StringIO
import copy

import ciElementTree as ET
from codeintel2.common import *
from codeintel2.database.langlibbase import LangDirsLibBase
from codeintel2.database.langlib import LangZone
from codeintel2 import util


#---- globals

log = logging.getLogger("codeintel.db")
# log.setLevel(logging.DEBUG)


#---- Database zone and lib implementations
class MultiLangDirsLib(LangDirsLibBase):
    """A zone providing a view into an ordered list of dirs in a
    db/$multilang/... area of the db.

    These are dished out via Database.get_lang_lib(), which indirectly
    then is dished out by the MultiLangZone.get_lib(). Mostly this is
    just a view on the MultiLangZone singleton for this particular
    language.
    """
    def __init__(self, lang_zone, lock, lang, name, dirs, sublang):
        LangDirsLibBase.__init__(self)
        self.lang_zone = lang_zone
        self._lock = lock
        self.mgr = lang_zone.mgr
        self.lang = lang
        self.name = name
        self.dirs = dirs
        self.sublang = sublang
        self.import_handler \
            = self.mgr.citadel.import_handler_from_lang(sublang)

        # We keep a "weak" merged cache of blobname lookup for all dirs
        # in this zone -- where "weak" means that we verify a hit by
        # checking the current real dbfile_from_blobname index for that
        # dir (which may have changed). This caching slows down lookup
        # for single-dir LangDirsZones, but should scale better for
        # LangDirsZones with many dirs. (TODO-PERF: test this assertion.)
        self._dir_and_blobbase_from_blobname = {}
        self._importables_from_dir_cache = {}

    def __repr__(self):
        return "<%s %s>" % (self.lang, self.name)

    def _acquire_lock(self):
        self._lock.acquire()

    def _release_lock(self):
        self._lock.release()

    def get_dirs(self):
        return self.dirs

    def has_blob(self, blobname, ctlr=None):
        dbsubpath = self._dbsubpath_from_blobname(blobname, ctlr=ctlr)
        return dbsubpath is not None

    def has_blob_in_db(self, blobname, ctlr=None):
        """Return true if the blobname is in the database.

        Typically this method is only used for debugging and .has_blob()
        is what you want.
        """
        dbsubpath = self._dbsubpath_from_blobname(
            blobname, ctlr=ctlr, only_look_in_db=True)
        return dbsubpath is not None

    def get_blob(self, blobname, ctlr=None, specific_dir=None):
        self._acquire_lock()
        try:
            dbsubpath = self._dbsubpath_from_blobname(
                blobname, ctlr=ctlr, specific_dir=specific_dir)
            if dbsubpath is not None:
                return self.lang_zone.load_blob(dbsubpath)
            else:
                return None
        finally:
            self._release_lock()

    def hits_from_lpath(self, lpath, ctlr=None, curr_buf=None):
        """Return all hits of the given lookup path.

        I.e. a symbol table lookup across all files in the dirs of this
        lib.

            "lpath" is a lookup name list, e.g. ['Casper', 'Logging']
                or ['dojo', 'animation'].
            "ctlr" (optional) is an EvalController instance. If
                specified it should be used in the normal way (logging,
                checking .is_aborted()).
            "curr_buf" (optional), if specified, is the current buf for
                which this query is being made. Hits from it should be
                skipped (i.e. don't bother searching it).

        A "hit" is (<CIX node>, <scope-ref>).  Each one represent a
        scope-tag or variable-tag hit in all of the blobs for the
        execution set buffers.

        Returns the empty list if no hits.
        """
        assert isinstance(lpath, tuple)  # common mistake to pass in a string

        # Need to have (at least once) scanned all importables.
        # Responsibility for ensuring the scan data is *up-to-date*
        # is elsewhere.
        self.ensure_all_dirs_scanned(ctlr=ctlr)

        if curr_buf:
            curr_blobname = curr_buf.blob_from_lang.get(
                self.lang, {}).get("name")
            curr_buf_dir = dirname(curr_buf.path)

        # Naive implementation (no caching)
        hits = []
        for dir in self.dirs:
            if ctlr and ctlr.is_aborted():
                log.debug("ctlr aborted")
                break

            hit_lpath = lpath
            toplevelname_index = self.lang_zone.load_index(
                dir, "toplevelname_index", {})
            for blobname in toplevelname_index.get_blobnames(
                    self.lang, lpath[0], ()):
                if curr_buf and curr_buf_dir == dir and blobname == curr_blobname:
                    continue
                blob = self.get_blob(blobname, ctlr=ctlr, specific_dir=dir)
                elem = blob
                try:
                    for i, p in enumerate(lpath):
                        # LIMITATION: *Imported* names at each scope are
                        # not being included here. This *should* be okay for
                        # PHP because imports only add symbols to the
                        # top-level. Worse case: the user has to add another
                        # dir to his "extra-dirs" pref.
                        try:
                            elem = elem.names[p]
                        except KeyError:
                            if i == 0 and "\\" in p and self.lang == "PHP":
                                # Deal with PHP namespaces.
                                namespace, elemname = p.rsplit("\\", 1)
                                elem = blob.names[namespace].names[elemname]
                                # The actual hit namespace has a different hit
                                # lpath.
                                hit_lpath = (
                                    namespace, elemname) + hit_lpath[1:]
                            else:
                                raise
                except KeyError:
                    continue
                hits.append((elem, (blob, list(hit_lpath[:-1]))))

        return hits

    def toplevel_cplns(self, prefix=None, ilk=None, ctlr=None):
        """Return completion info for all top-level names matching the
        given prefix and ilk in all blobs in this lib.

            "prefix" is a 3-character prefix with which to filter top-level
                names. If None (or not specified), results are not filtered
                based on the prefix.
            "ilk" is a symbol type (e.g. "class", "variable", "function")
                with which to filter results. If None (or not specified),
                results of any ilk are returned.
            "ctlr" (optional) is an EvalController instance. If
                specified it should be used in the normal way (logging,
                checking .is_aborted()).

        Returns a list of 2-tuples: (<ilk>, <name>).

        Note: the list is not sorted, because often some special sorting
        is required for the different completion evaluators that might use
        this API.
        """
        self.ensure_all_dirs_scanned(ctlr=ctlr)
        cplns = []
        # Naive implementation (no caching)
        for dir in self.dirs:
            if ctlr and ctlr.is_aborted():
                log.debug("ctlr aborted")
                break

            try:
                toplevelname_index = self.lang_zone.load_index(
                    dir, "toplevelname_index")
            except EnvironmentError:
                # No toplevelname_index for this dir likely indicates that
                # there weren't any files of the current lang in this dir.
                continue
            cplns += toplevelname_index.toplevel_cplns(
                self.lang, prefix=prefix, ilk=ilk)
        return cplns

    def _importables_from_dir(self, dir):
        if dir not in self._importables_from_dir_cache:
            self._importables_from_dir_cache[dir] \
                = self.import_handler.find_importables_in_dir(dir)
        return self._importables_from_dir_cache[dir]

    def _dbsubpath_from_blobname(self, blobname, ctlr=None,
                                 only_look_in_db=False, specific_dir=None):
        """Return the subpath to the dbfile for the given blobname,
        or None if not found.

        Remember that this is complicated by possible multi-level
        imports. E.g. "include('foo/bar.php')".
        """
        lang_zone = self.lang_zone

        self._acquire_lock()
        try:
            # Use our weak cache to try to return quickly.
            if blobname in self._dir_and_blobbase_from_blobname:
                blobdir, blobbase = self._dir_and_blobbase_from_blobname[
                    blobname]

                # Check it. The actual info for that dir may have changed.
                dbfile_from_blobname = lang_zone.dfb_from_dir(
                    blobdir, self.sublang)
                if blobbase in dbfile_from_blobname:
                    log.debug("have blob '%s' in '%s'? yes (in weak cache)",
                              blobname, blobdir)
                    return join(lang_zone.dhash_from_dir(blobdir),
                                dbfile_from_blobname[blobbase])
                del self._dir_and_blobbase_from_blobname[
                    blobname]  # drop from weak cache

            # Brute force: look in each dir.
            assert self.import_handler.sep is not None, \
                "%r.sep is None, this must be set" % self.import_handler
            blobparts = blobname.split(self.import_handler.sep)
            blobbase = blobparts[-1]
            for dir in self.dirs:
                if specific_dir is not None and dir != specific_dir:
                    continue
                if ctlr and ctlr.is_aborted():
                    log.debug(
                        "aborting search for blob '%s' on %s: ctlr aborted",
                        blobname, self)
                    return None

                # Is the blob in 'blobdir' (i.e. a non-multi-level import
                # that has been scanned already).
                blobdir = join(dir, *blobparts[:-1])
                dbfile_from_blobname = lang_zone.dfb_from_dir(
                    blobdir, self.sublang, {})
                if blobbase in dbfile_from_blobname:
                    self._dir_and_blobbase_from_blobname[blobname] \
                        = (blobdir, blobbase)
                    log.debug("have blob '%s' in '%s'? yes (in dir index)",
                              blobname, blobdir)
                    return join(lang_zone.dhash_from_dir(blobdir),
                                dbfile_from_blobname[blobbase])

                importables = self._importables_from_dir(blobdir)
                # 'importables' look like, for PHP:
                #   {'foo.php': ('foo.php', None, False),
                #    'foo.inc': ('foo.inc', None, False),
                #    'somedir': (None,      None, True)}

                if blobbase not in importables:
                    continue

                blobfile, subdir_blobbase, is_dir_import = importables[
                    blobbase]
                if blobfile is None:
                    # There isn't an actual importable file here -- just
                    # a dir prefix to a multidir import.
                    log.debug("have blob '%s' in %s? no", blobname, self)
                    return None
                elif os.sep in blobfile:
                    # This is an import from a subdir. We need to get a new
                    # dbf.
                    blobdir = join(blobdir, dirname(blobfile))
                    blobfile = basename(blobfile)
                    blobbase = subdir_blobbase
                    dbfile_from_blobname = lang_zone.dfb_from_dir(
                        blobdir, self.sublang, {})
                    if blobbase in dbfile_from_blobname:
                        self._dir_and_blobbase_from_blobname[blobname] \
                            = (blobdir, blobbase)
                        log.debug("have blob '%s' in '%s'? yes (in dir index)",
                                  blobname, blobdir)
                        return join(lang_zone.dhash_from_dir(blobdir),
                                    dbfile_from_blobname[blobbase])

                # The file isn't loaded.
                if not only_look_in_db:
                    log.debug("%s importables in '%s':\n    %s", self.sublang,
                              blobdir, importables)
                    log.debug("'%s' likely provided by '%s' in '%s': "
                              "attempting load", blobname, blobfile, blobdir)
                    try:
                        buf = self.mgr.buf_from_path(
                            join(blobdir, blobfile), self.lang)
                    except (EnvironmentError, CodeIntelError), ex:
                        # This can occur if the path does not exist, such as a
                        # broken symlink, or we don't have permission to read
                        # the file, or the file does not contain text.
                        continue
                    buf.scan_if_necessary()

                    dbfile_from_blobname = lang_zone.dfb_from_dir(
                        blobdir, self.sublang, {})
                    if blobbase in dbfile_from_blobname:
                        self._dir_and_blobbase_from_blobname[blobname] \
                            = (blobdir, blobbase)
                        log.debug("have blob '%s' in '%s'? yes (after load)",
                                  blobname, blobdir)
                        return join(lang_zone.dhash_from_dir(blobdir),
                                    dbfile_from_blobname[blobbase])

            log.debug("have blob '%s' in %s? no", blobname, self)
            return None
        finally:
            self._release_lock()


class MultiLangTopLevelNameIndex(object):
    """A wrapper around the plain-dictionary toplevelname_index for a
    MultiLangZone dir to provide better performance for continual updating
    and some simpler access.

        {lang -> ilk -> toplevelname -> blobnames}

    # Problem

    A 'toplevelname_index' is a merge of
        {lang -> blobname -> ilk -> toplevelnames}
    data for all resources in its dir.  As those resources are
    continually re-scanned (e.g. as a file is edited in Komodo), it
    would be too expensive to update this index everytime.

    # Solution

    Keep a list of "recent updates" and only merge them into the main
    data when that buf hasn't been updated in "a while" and when needed
    for saving the index. Note: Buffer *removals* are not put on-deck,
    but removed immediately.

    # .get_blobnames(lang, ..., ilk=None)

    Originally the toplevelname_index stored
        {lang -> toplevelname -> blobnames}
    The per-"ilk" level was added afterwards to support occassional ilk
    filtering for PHP (and possible eventually other langs).

    .get_blobnames() still behaves like a {lang -> toplevelname -> blobnames}
    mapping, but it provides an optional "ilk" keyword arg to limit the
    results to that ilk.

    # Notes on locking

    This class does not guard its datastructures with locking. It is up
    to the MultiLangZone using this to guard against simultaneous access
    on separate threads.
    """
    def __init__(self, data=None, timeout=90):
        # toplevelname_index data: {lang -> ilk -> toplevelname -> blobnames}
        if data is None:
            self._data = {}
        else:
            self._data = data

        # Time (in seconds) to hold a change "on deck".
        # Timed-out changes are merged on .get() and .update().
        self.timeout = timeout
        self._on_deck = {
            # basename                           # the basename of the buf path
            #   -> [timestamp,                   # time of the last update
            #       # The dict in res_index, a.k.a. 'res_data'
            #       {lang -> blobname -> ilk -> toplevelnames},
            #       # Lazily generated pivot, a.k.a. 'res_data_pivot'
            #       {lang -> ilk -> toplevelname -> blobnames}
            #      ]
        }

    def __repr__(self):
        return "<MultiLangTopLevelNameIndex: %d update(s) on-deck>"\
               % len(self._on_deck)

    def merge(self):
        """Merge all on-deck changes with `self.data'."""
        for base, (timestamp, res_data,
                   res_data_pivot) in self._on_deck.items():
            if res_data_pivot is None:
                res_data_pivot = self._pivot_res_data(res_data)
            # res_data_pivot: {lang -> ilk -> toplevelname -> blobnames}
            # "bftfi" means blobnames_from_toplevelname_from_ilk
            for lang, bftfi in res_data_pivot.iteritems():
                data_bftfi = self._data.setdefault(lang, {})
                for ilk, bft in bftfi.iteritems():
                    data_bft = data_bftfi.setdefault(ilk, {})
                    for toplevelname, blobnames in bft.iteritems():
                        if toplevelname not in data_bft:
                            data_bft[toplevelname] = blobnames
                        else:
                            data_bft[toplevelname].update(blobnames)
            del self._on_deck[base]

    def merge_expired(self, now):
        """Merge expired on-deck changes with `self.data'."""
        for base, (timestamp, res_data,
                   res_data_pivot) in self._on_deck.items():
            if now - timestamp < self.timeout:
                continue

            if res_data_pivot is None:
                res_data_pivot = self._pivot_res_data(res_data)
            # res_data_pivot: {lang -> ilk -> toplevelname -> blobnames}
            # "bftfi" means blobnames_from_toplevelname_from_ilk
            for lang, bftfi in res_data_pivot.iteritems():
                data_bftfi = self._data.setdefault(lang, {})
                for ilk, bft in bftfi.iteritems():
                    data_bft = data_bftfi.setdefault(ilk, {})
                    for toplevelname, blobnames in bft.iteritems():
                        if toplevelname not in data_bft:
                            data_bft[toplevelname] = blobnames
                        else:
                            data_bft[toplevelname].update(blobnames)
            del self._on_deck[base]

    @property
    def data(self):
        self.merge()
        return self._data

    def update(self, base, old_res_data, new_res_data):
        now = time.time()
        self.remove(base, old_res_data)
        self._on_deck[base] = [now, new_res_data, None]
        self.merge_expired(now)

    def remove(self, base, old_res_data):
        if base in self._on_deck:
            del self._on_deck[base]
        else:
            # Remove old refs from current data.
            # old_res_data: {lang -> blobname -> ilk -> toplevelnames}
            # self._data:   {lang -> ilk -> toplevelname -> blobnames}
            for lang, tfifb in old_res_data.iteritems():
                if lang not in self._data:
                    continue
                data_bftfi = self._data[lang]
                for blobname, tfi in tfifb.iteritems():
                    for ilk, toplevelnames in tfi.iteritems():
                        for toplevelname in toplevelnames:
                            try:
                                data_bftfi[ilk][toplevelname].remove(blobname)
                            except KeyError:
                                pass  # ignore this for now, might indicate corruption
                            else:
                                if not data_bftfi[ilk][toplevelname]:
                                    del data_bftfi[ilk][toplevelname]
                        if not data_bftfi.get(ilk):
                            del data_bftfi[ilk]
                if not self._data[lang]:
                    del self._data[lang]

    def _pivot_res_data(self, res_data):
        # res_data:       {lang -> blobname -> ilk -> toplevelnames}
        # res_data_pivot: {lang -> ilk -> toplevelname -> blobnames}
        res_data_pivot = dict(
            (lang, {}) for lang in res_data
        )
        for lang, tfifb in res_data.iteritems():
            for blobname, toplevelnames_from_ilk in tfifb.iteritems():
                for ilk, toplevelnames in toplevelnames_from_ilk.iteritems():
                    pivot_bft = res_data_pivot[lang].setdefault(ilk, {})
                    for toplevelname in toplevelnames:
                        if toplevelname not in pivot_bft:
                            pivot_bft[toplevelname] = set([blobname])
                        else:
                            pivot_bft[toplevelname].add(blobname)
        return res_data_pivot

    def toplevel_cplns(self, lang, prefix=None, ilk=None):
        """Return completion info for all top-level names matching the
        given prefix and ilk.

            "prefix" is a 3-character prefix with which to filter top-level
                names. If None (or not specified), results are not filtered
                based on the prefix.
            "ilk" is a symbol type (e.g. "class", "variable", "function")
                with which to filter results. If None (or not specified),
                results of any ilk are returned.

        Returns a list of 2-tuples: (<ilk>, <name>).
        """
        self.merge_expired(time.time())

        # Need to check merged and on-deck items:
        cplns = []

        # ...on-deck items
        for base, (timestamp, res_data,
                   res_data_pivot) in self._on_deck.items():
            if lang not in res_data:
                continue
            if res_data_pivot is None:
                res_data_pivot = self._on_deck[base][2] \
                    = self._pivot_res_data(res_data)
            # res_data_pivot: {lang -> ilk -> toplevelname -> blobnames}
            bftfi = res_data_pivot[lang]
            if ilk is None:
                for i, bft in bftfi.iteritems():
                    cplns += [(i, toplevelname) for toplevelname in bft]
            elif ilk in bftfi:
                cplns += [(ilk, toplevelname) for toplevelname in bftfi[ilk]]

        # ...merged data
        # self._data: {lang -> ilk -> toplevelname -> blobnames}
        if lang in self._data:
            bftfi = self._data[lang]
            if ilk is None:
                for i, bft in bftfi.iteritems():
                    cplns += [(i, toplevelname) for toplevelname in bft]
            elif ilk in bftfi:
                cplns += [(ilk, toplevelname) for toplevelname in bftfi[ilk]]

        # Naive implementation: Instead of maintaining a separate
        # 'toplevelprefix_index' (as we do for StdLibsZone and CatalogsZone)
        # for now we'll just gather all results and filter on the prefix
        # here. Only if this proves to be a perf issue will we add the
        # complexity of another index:
        #   {lang -> ilk -> prefix -> toplevelnames}
        if prefix is not None:
            cplns = [(i, t) for i, t in cplns if t.startswith(prefix)]

        return cplns

    # TODO: Change this API to just have the empty list as a default.
    #      No point in the 'default' arg.
    def get_blobnames(self, lang, toplevelname, default=None, ilk=None):
        """Return the blobnames of the given lang defining the given
        toplevelname.

        If "ilk" is given then only symbols of that ilk will be considered.
        If not match is found the "default" is returned.
        """
        self.merge_expired(time.time())

        blobnames = set()
        # First check on-deck items.
        for base, (timestamp, res_data,
                   res_data_pivot) in self._on_deck.items():
            if lang not in res_data:
                continue
            if res_data_pivot is None:
                res_data_pivot = self._on_deck[base][2] \
                    = self._pivot_res_data(res_data)
            # res_data_pivot: {lang -> ilk -> toplevelname -> blobnames}
            bftfi = res_data_pivot[lang]
            if ilk is None:
                for bft in bftfi.itervalues():
                    if toplevelname in bft:
                        blobnames.update(bft[toplevelname])
            elif ilk in bftfi:
                if toplevelname in bftfi[ilk]:
                    blobnames.update(bftfi[ilk][toplevelname])

        # TODO: Put lookup in merged data ahead of lookup in on-deck -- so
        #      we don't do on-deck work if not necessary.
        # Then, fallback to already merged data.
        # self._data: {lang -> ilk -> toplevelname -> blobnames}
        if lang in self._data:
            bftfi = self._data[lang]
            if ilk is None:
                for bft in bftfi.itervalues():
                    if toplevelname in bft:
                        blobnames.update(bft[toplevelname])
            elif ilk in bftfi:
                if toplevelname in bftfi[ilk]:
                    blobnames.update(bftfi[ilk][toplevelname])

        if blobnames:
            return blobnames
        return default


class MultiLangZone(LangZone):
    toplevelname_index_class = MultiLangTopLevelNameIndex

    def dfb_from_dir(self, dir, sublang, default=None):
        """Get the {blobname -> dbfile} mapping index for the given dir
        and lang.

        'dfb' stands for 'dbfile_from_blobname'.
        This must be called with the lock held.
        """
        blob_index = self.load_index(dir, "blob_index", default=default)
        try:
            return blob_index[sublang]
        except KeyError, ex:
            if default is not None:
                return default
            raise

    def get_buf_data(self, buf):
        # TODO Canonicalize path (or assert that it is canonicalized)
        #     Should have a Resource object that we pass around that
        #     handles all of this.
        self._acquire_lock()
        try:
            dir, base = split(buf.path)
            res_index = self.load_index(dir, "res_index", {})
            if base not in res_index:
                raise NotFoundInDatabase("%s buffer '%s' not found in database"
                                         % (buf.lang, buf.path))
            scan_time, scan_error, res_data = res_index[base]

            try:
                blob_index = self.load_index(dir, "blob_index")
            except EnvironmentError, ex:
                self.db.corruption("MultiLangZone.get_buf_data",
                                   "could not find 'blob_index' index: %s" % ex,
                                   "recover")
                raise NotFoundInDatabase("%s buffer '%s' not found in database"
                                         % (buf.lang, buf.path))

            dhash = self.dhash_from_dir(dir)
            blob_from_lang = {}
            # res_data: {lang -> blobname -> ilk -> toplevelnames}
            for lang, blobname in (
                (lang, tfifb.keys()[
                 0])  # only one blob per lang in a resource
                for lang, tfifb in res_data.items()
            ):
                dbsubpath = join(dhash, blob_index[lang][blobname])
                try:
                    blob = self.load_blob(dbsubpath)
                except ET.XMLParserError, ex:
                    self.db.corruption("MultiLangZone.get_buf_data",
                                       "could not parse dbfile for '%s' blob: %s"
                                       % (blobname, ex),
                                       "recover")
                    self.remove_buf_data(buf)
                    raise NotFoundInDatabase(
                        "`%s' buffer %s `%s' blob was corrupted in database"
                        % (buf.path, lang, blobname))
                except EnvironmentError, ex:
                    self.db.corruption("MultiLangZone.get_buf_data",
                                       "could not read dbfile for '%s' blob: %s"
                                       % (blobname, ex),
                                       "recover")
                    self.remove_buf_data(buf)
                    raise NotFoundInDatabase(
                        "`%s' buffer %s `%s' blob not found in database"
                        % (buf.path, lang, blobname))
                assert blob.get("lang") == lang
                blob_from_lang[lang] = blob

            return scan_time, scan_error, blob_from_lang
        finally:
            self._release_lock()

    def remove_path(self, path):
        """Remove the given resource from the database."""
        # TODO Canonicalize path (or assert that it is canonicalized)
        #     Should have a Resource object that we pass around that
        #     handles all of this.
        self._acquire_lock()
        try:
            dir, base = split(path)

            res_index = self.load_index(dir, "res_index", {})
            try:
                scan_time, scan_error, res_data = res_index[base]
            except KeyError:
                # This resource isn't loaded in the db. Nothing to remove.
                return

            try:
                blob_index = self.load_index(dir, "blob_index")
            except EnvironmentError, ex:
                self.db.corruption("MultiLangZone.remove_path",
                                   "could not read blob_index for '%s' dir: %s" % (
                                       dir, ex),
                                   "recover")
                blob_index = {}

            is_hits_from_lpath_lang = self.lang in self.db.import_everything_langs
            if is_hits_from_lpath_lang:
                try:
                    toplevelname_index = self.load_index(
                        dir, "toplevelname_index")
                except EnvironmentError, ex:
                    self.db.corruption("MultiLangZone.remove_path",
                                       "could not read toplevelname_index for '%s' dir: %s"
                                       % (dir, ex),
                                       "recover")
                    toplevelname_index = self.toplevelname_index_class()

            dhash = self.dhash_from_dir(dir)
            del res_index[base]
            # res_data: {lang -> blobname -> ilk -> toplevelnames}
            for lang, blobname in (
                (lang, tfifb.keys()[
                 0])  # only one blob per lang in a resource
                for lang, tfifb in res_data.items()
            ):
                try:
                    dbfile = blob_index[lang][blobname]
                except KeyError:
                    blob_index_path = join(dhash, "blob_index")
                    self.db.corruption("MultiLangZone.remove_path",
                                       "%s '%s' blob not in '%s'"
                                       % (lang, blobname, blob_index_path),
                                       "ignore")
                    continue
                del blob_index[lang][blobname]
                for path in glob(join(self.base_dir, dhash, dbfile+".*")):
                    log.debug("fs-write: remove %s|%s blob file '%s/%s'",
                              self.lang, lang, dhash, basename(path))
                    os.remove(path)
            if is_hits_from_lpath_lang:
                toplevelname_index.remove(base, res_data)

            self.changed_index(dir, "res_index")
            self.changed_index(dir, "blob_index")
            if is_hits_from_lpath_lang:
                self.changed_index(dir, "toplevelname_index")
        finally:
            self._release_lock()
        # XXX Database.clean() should remove dirs that have no
        #    dbfile_from_blobname entries.

    def remove_buf_data(self, buf):
        """Remove the given resource from the database."""
        self.remove_path(buf.path)

    def update_buf_data(self, buf, scan_tree, scan_time, scan_error,
                        skip_scan_time_check=False):
        """Update this MultiLangZone with the buffer data.

        @param buf {CitadelBuffer} the buffer whose data is being added
            to the database.
        @param scan_tree {ciElementTree} the CIX scan data. Might be None
            if there was an early scanning failure.
        @param scan_time {timestamp} the time of the scan, typically the
            mtime of the file
        @param scan_error {str} an error string if scanning failed, or
            None if it was succesful.
        @param skip_scan_time_check {boolean} (default False) is a
            boolean indicating if the buffer data should be updated even
            if `scan_time` is <= that in the database.
        """
        self._acquire_lock()
        try:
            # TODO: Canonicalize path (or assert that it is canonicalized)
            dir, base = split(buf.path)

            # Get the current data, if any.
            res_index = self.load_index(dir, "res_index", {})
            res_index_has_changed = False
            blob_index = self.load_index(dir, "blob_index", {})
            blob_index_has_changed = False
            is_hits_from_lpath_lang = self.lang in self.db.import_everything_langs
            if is_hits_from_lpath_lang:
                # TODO: Not sure {} for a default is correct here.
                toplevelname_index = self.load_index(
                    dir, "toplevelname_index", {})
                toplevelname_index_has_changed = False
            try:
                (old_scan_time, old_scan_error, old_res_data) = res_index[base]
            except KeyError:    # adding a new entry
                (old_scan_time, old_scan_error, old_res_data) = None, None, {}
            else:               # updating an existing entry
                if not skip_scan_time_check and scan_time is not None \
                   and scan_time <= old_scan_time:
                    log.debug("skipping db update for '%s': %s < %s and "
                              "no 'skip_scan_time_check' option",
                              base, scan_time, old_scan_time)
                    return

            log.debug("update from %s buf '%s'", buf.lang, buf.path)

            # Parse the tree and get the list of blobnames.
            # res_data: {lang -> blobname -> ilk -> toplevelnames}
            new_res_data = {}
            new_blob_from_lang_and_blobname = {}
            if scan_tree:
                for blob in scan_tree[0]:
                    lang = blob.get("lang")
                    blobname = blob.get("name")
                    new_blob_from_lang_and_blobname[(lang, blobname)] = blob
                    tfifb = new_res_data.setdefault(lang, {})
                    toplevelnames_from_ilk = tfifb.setdefault(blobname, {})
                    for toplevelname, elem in blob.names.iteritems():
                        ilk = elem.get("ilk") or elem.tag
                        if ilk not in toplevelnames_from_ilk:
                            toplevelnames_from_ilk[ilk] = set([toplevelname])
                        else:
                            toplevelnames_from_ilk[ilk].add(toplevelname)
                        # For PHP namespaces, we also want to add all namespace
                        # child items, as this will make it easy for tree_php
                        # to lookup a Fully Qualified Namespace (FQN).
                        if ilk == "namespace" and lang == "PHP":
                            for childname, childelem in elem.names.iteritems():
                                child_ilk = childelem.get(
                                    "ilk") or childelem.tag
                                child_fqn = "%s\\%s" % (
                                    toplevelname, childname)
                                if child_ilk not in toplevelnames_from_ilk:
                                    toplevelnames_from_ilk[
                                        child_ilk] = set([child_fqn])
                                else:
                                    toplevelnames_from_ilk[
                                        child_ilk].add(child_fqn)

            # Determine necessary changes to res_index.
            if scan_error:
                if (scan_time != old_scan_time
                        or scan_error != old_scan_error):
                    res_index[base] = (scan_time, scan_error,
                                       old_res_data)
                    res_index_has_changed = True

            else:
                # Only consider new blobs if there wasn't a scan error.
                # I.e., we want to preserve the last good scan info.

                if (scan_time != old_scan_time
                    or scan_error != old_scan_error
                        or new_res_data != old_res_data):
                    res_index[base] = (scan_time, scan_error,
                                       new_res_data)
                    res_index_has_changed = True

                if is_hits_from_lpath_lang:
                    if new_res_data != old_res_data:
                        toplevelname_index.update(base,
                                                  old_res_data, new_res_data)
                        toplevelname_index_has_changed = True

                # Determine necessary changes to dbfile_from_blobname index
                # and the dbfiles and then make them.
                dbfile_changes = []
                for (lang, blobname), blob \
                        in new_blob_from_lang_and_blobname.items():
                    try:
                        old_res_data[lang][blobname]
                    except KeyError:
                        dbfile_changes.append(("add", lang, blobname, blob))
                    else:
                        dbfile_changes.append(("update", lang, blobname, blob))

                for lang, old_tfifb in old_res_data.items():
                    for blobname in old_tfifb:
                        try:
                            new_res_data[lang][blobname]
                        except KeyError:
                            dbfile_changes.append((
                                "remove", lang, blobname, None))

                dhash = self.dhash_from_dir(dir)
                for action, lang, blobname, blob in dbfile_changes:
                    if action == "add":
                        dbfile = self.db.bhash_from_blob_info(
                            buf.path, lang, blobname)
                        blob_index.setdefault(lang, {})[blobname] = dbfile
                        blob_index_has_changed = True
                        dbdir = join(self.base_dir, dhash)
                        if not exists(dbdir):
                            self._mk_dbdir(dbdir, dir)
                        # XXX What to do on write failure?
                        log.debug("fs-write: %s|%s blob '%s/%s'",
                                  self.lang, lang, dhash, dbfile)
                        if blob.get("src") is None:
                            blob.set(
                                "src", buf.path)   # for defns_from_pos() support
                        ET.ElementTree(blob).write(join(dbdir, dbfile+".blob"))
                    elif action == "remove":
                        dbfile = blob_index[lang][blobname]
                        del blob_index[lang][blobname]
                        blob_index_has_changed = True
                        # XXX What to do on removal failure?
                        log.debug("fs-write: remove %s|%s blob '%s/%s'",
                                  self.lang, lang, dhash, dbfile)
                        try:
                            os.remove(join(
                                self.base_dir, dhash, dbfile+".blob"))
                        except EnvironmentError, ex:
                            self.db.corruption("MultiLangZone.update_buf_data",
                                               "could not remove dbfile for '%s' blob: %s"
                                               % (blobname, ex),
                                               "ignore")
                    elif action == "update":
                        # Try to only change the dbfile on disk if it is
                        # different.
                        s = StringIO()
                        if blob.get("src") is None:
                            blob.set(
                                "src", buf.path)   # for defns_from_pos() support
                        ET.ElementTree(blob).write(s)
                        new_dbfile_content = s.getvalue()
                        dbfile = blob_index[lang][blobname]
                        dbpath = join(self.base_dir, dhash, dbfile+".blob")
                        # PERF: Might be nice to cache the new dbfile
                        #       content for the next time this resource is
                        #       updated. For files under edit this will be
                        #       common. I.e. just for the "editset".
                        try:
                            fin = open(dbpath, 'r')
                        except (OSError, IOError), ex:
                            # Technically if the dbfile doesn't exist, this
                            # is a sign of database corruption. No matter
                            # though (for this blob anyway), we are about to
                            # replace it.
                            old_dbfile_content = None
                        else:
                            try:
                                old_dbfile_content = fin.read()
                            finally:
                                fin.close()
                        if new_dbfile_content != old_dbfile_content:
                            if not exists(dirname(dbpath)):
                                self._mk_dbdir(dirname(dbpath), dir)
                            # XXX What to do if fail to write out file?
                            log.debug("fs-write: %s|%s blob '%s/%s'",
                                      self.lang, lang, dhash, dbfile)
                            fout = open(dbpath, 'w')
                            try:
                                fout.write(new_dbfile_content)
                            finally:
                                fout.close()

            if res_index_has_changed:
                self.changed_index(dir, "res_index")
            if blob_index_has_changed:
                self.changed_index(dir, "blob_index")
            if is_hits_from_lpath_lang and toplevelname_index_has_changed:
                self.changed_index(dir, "toplevelname_index")
        finally:
            self._release_lock()
        # TODO: Database.clean() should remove dirs that have no
        #      blob_index entries.

    def get_lib(self, name, dirs, sublang):
        assert isinstance(dirs, (tuple, list))
        assert sublang is not None, "must specify '%s' sublang" % self.lang

        canon_dirs = tuple(set(abspath(normpath(expanduser(d))) for d in dirs))
        key = (canon_dirs, sublang)
        if key in self._dirslib_cache:
            return self._dirslib_cache[key]

        langdirslib = MultiLangDirsLib(self, self._lock, self.lang,
                                       name, canon_dirs, sublang)

        self._dirslib_cache[key] = langdirslib

        return langdirslib

########NEW FILE########
__FILENAME__ = projlib
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile)
import threading
from hashlib import md5
from pprint import pprint, pformat
import logging
import codecs
import weakref

from codeintel2.common import *


#---- globals
log = logging.getLogger("codeintel.db")


#---- Database zone and lib implementations
class ProjectZone(object):
    """Manage a 'db/projs/<proj-hash>/...' area of the database.

    A project zone works with a project object(*) to provide quick
    mapping of a (lang, blobname) to a file in the project, if any.

    # Dealing with updating

    Knowing when a file has been removed from a project is fairly easy:
    we hit it in the cache, then do a quick stat (or query on the
    project) to ensure it it still there.

    Knowing when a file has been added to a project is harder. Fully
    hooking into Komodo's file system-level dir watching and various
    in-Komodo update notifications is hard (doesn't translate well to
    simply requiring an API on the project object) and isn't perfect
    anyway. Ideally .dirs_from_basename() is all handled by the project
    object and we don't have to worry about it. However, Komodo Projects
    aren't currently setup to do this well, so codeintel is taking the
    burden of caching.

    The planned solution is to attempt a reasonable job of creating the
    dirs_from_basename cache and then providing a manual interface
    (perhaps right-click on Project -> "Refresh Status") to update.

    (*) The project object is required to have the following API:
        TODO: spec the API.
    """
    def __init__(self, mgr, db, proj):
        self.mgr = mgr
        self.db = db
        self.proj = proj

        self.name = basename(proj.path)
        self.base_dir = join(self.db.base_dir, "db", "projs",
                             md5(proj.path).hexdigest())
        self._proj_lib_from_lang = weakref.WeakValueDictionary()
        self._idx_lock = threading.RLock()
        self._dirs_from_basename = None
        self._is_idx_dirty = False

    def __repr__(self):
        return "<proj '%s' zone>" % self.name

    def __del__(self):
        try:
            self.save()
        except:
            log.exception("error saving %s" % self)

    def get_dirs_from_basename(self):
        self._idx_lock.acquire()
        try:
            if self._dirs_from_basename is None:
                log.debug("fs-read: load %s 'dirs_from_basename' index", self)
                self._dirs_from_basename = self.db.load_pickle(
                    join(self.base_dir, "dirs_from_basename"), {})
            return self._dirs_from_basename
        finally:
            self._idx_lock.release()

    def set_dirs_from_basename(self, value):
        self._idx_lock.acquire()
        try:
            old_value = self.dirs_from_basename
            self._dirs_from_basename = value
            if old_value != value:
                # PERF: can this be smarter? Would have to be on
                #      .update() for that.
                self._is_idx_dirty = True
        finally:
            self._idx_lock.release()
    dirs_from_basename = property(get_dirs_from_basename,
                                  set_dirs_from_basename, None, "index of basenames in project")

    def _mk_dbdir(self):
        log.debug("fs-write: mkdir '%s'", self.base_dir)
        os.makedirs(self.base_dir)
        log.debug("fs-write: '%s/path'", self.base_dir)
        fout = codecs.open(join(self.base_dir, "path"), 'wb', 'utf-8')
        try:
            fout.write(self.proj.path)
        finally:
            fout.close()

    def save(self):
        self._idx_lock.acquire()
        try:
            if self._is_idx_dirty:
                if not exists(self.base_dir):
                    self._mk_dbdir()
                self.db.save_pickle(join(self.base_dir, "dirs_from_basename"),
                                    self._dirs_from_basename)
                self._is_idx_dirty = False
        finally:
            self._idx_lock.release()

    def update(self, nice=False):
        """Update the index for the list of files in the project.

            "nice" (default False) is a boolean indicating if this
                update process should attempt to keep the CPU load low.
        """
        if nice:
            XXX
        # XXX Update this to handle includes, excludes,
        #    static-project-entries. I.e. move this logic to the
        #    project where it can handle this stuff.
        dirs_from_basename = {}
        for dirpath, dirnames, filenames in os.walk(self.proj.base_dir):
            for filename in filenames:
                dirs_from_basename.setdefault(filename, []).append(dirpath)
        self.dirs_from_basename = dirs_from_basename

    def _likely_filename_from_lang_and_blobname(self, lang, blobname):
        # XXX Need to canonicalize filename.
        # XXX Shouldn't be hardcoding this stuff here. Defer out to the
        #    lang_*.py modules.
        # XXX Do we have to worry about multi-level imports here? E.g.,
        #       Python:  os.path
        #       Perl:    LWP::UserAgent
        #       Ruby:    yaml/context
        #       PHP:     blah/blam.php
        if lang in ("Python", "Python3"):
            return blobname+".py"
        else:
            XXX

    def has_blob(self, lang, blobname):
        lang_lib = self._lang_lib_for_blob(lang, blobname)
        if lang_lib is None:
            return False
        return lang_lib.has_blob(blobname)

    def get_blob(self, lang, blobname):
        lang_lib = self._lang_lib_for_blob(lang, blobname)
        if lang_lib is None:
            return None
        return lang_lib.get_blob(blobname)

    def _lang_lib_for_blob(self, lang, blobname):
        filename = self._likely_filename_from_lang_and_blobname(lang, blobname)
        try:
            dirs = self.dirs_from_basename[filename]
        except KeyError:
            return None
        else:
            # XXX This may be a perf issue because of a possibly large
            #    number of created LangDirsLib's -- which was unexpected
            #    when the LangDirsLibs caching was designed on LangZone.
            #    The cache size may need to be increased or some other
            #    scheme considered.
            return self.db.get_lang_lib(lang, "proj '%s' lib" % self.name,
                                        dirs,
                                        sublang=lang)  # for PHP

    def get_lib(self, lang):
        proj_lib = self._proj_lib_from_lang.get(lang)
        if proj_lib is None:
            proj_lib = ProjectLib(self, lang)
            self._proj_lib_from_lang[lang] = proj_lib
        return proj_lib


class ProjectLib(object):
    # Light lang-specific wrapper around a ProjectZone (akin to
    # CatalogLig).
    def __init__(self, proj_zone, lang):
        self.proj_zone = proj_zone
        self.lang = lang

    def __repr__(self):
        return "<proj '%s' %s lib>" % (self.proj_zone.name, self.lang)

    def has_blob(self, blobname):
        return self.proj_zone.has_blob(self.lang, blobname)

    def get_blob(self, blobname):
        return self.proj_zone.get_blob(self.lang, blobname)

########NEW FILE########
__FILENAME__ = resource
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****


# TODO: docstring

import os
from os.path import join, dirname, abspath, isabs
import logging


#---- globals
log = logging.getLogger("codeintel.db")
# log.setLevel(logging.DEBUG)


#---- Resource classes
# For abstraction and canonicalization of paths.

class Resource(object):
    """A reference to a resource for the database.

    Typically this is just a path to a file on the local disk. However
    the intention is to also support remote file urls (TODO) and unsaved
    files (TODO).

    This class also provides canonicalization on comparison of resource
    paths.
    """

    def __init__(self, path):
        self.path = path

    @property
    def canon_path(self):
        # normalize os.altsep to os.sep? or even consider normalizing to
        # all '/'. This gets more complicated if have URL resources for
        # remote files: subclassing.
        XXX


class AreaResource(Resource):
    """A resource that is at a relative path under some area.

    For example, at 'template/Perl.pl' under 'the Komodo user data
    dir' or at 'catalog/baz.cix' under 'the codeintel2 package dir'.

    TODO: change ctor sig to AreaResource([area, ] path). More logical
    to have input be in same order as .area_path.
    """
    # The known path areas. We only have use for the one right now.
    _path_areas = {
        "ci-pkg-dir": dirname(dirname(abspath(__file__))),
    }
    _ordered_area_items = [(d, a) for a, d in _path_areas.items()]
    _ordered_area_items.sort(key=lambda i: len(i[0]), reverse=True)

    @classmethod
    def area_and_subpath_from_path(cls, path):
        # XXX Need to worry about canonicalization!
        for area_dir, area in cls._ordered_area_items:
            if (path.startswith(area_dir)
                # Ensure we are matching at a dir boundary. This implies
                # a limitation that there *is* a subpath. I'm fine with
                # that.
                    and path[len(area_dir)] in (os.sep, os.altsep)):
                return area, path[len(area_dir)+1:]
        return None, path

    def __init__(self, path, area=None):
        """Create an area-relative resource.

            "path" is either the full path to the resource, or a
                relative path under the given area name. "area" must be
                specified for the latter.
            "area" (optional) can be given to specify under which area
                this resource resides. If not given, the best-fit of the
                known path areas will be used.
        """
        if area is not None:
            if area not in self._path_areas:
                raise ValueError("unknown path area: `%s'" % area)
            self.area = area
            if isabs(path):
                area_base = self._path_areas[area]
                if not path.startswith(area_base):
                    raise ValueError("cannot create AreaResource: `%s' is "
                                     "not under `%s' area (%s)"
                                     % (path, area, area_base))
                self.subpath = path[len(area_base)+1:]
            else:
                self.subpath = path
        elif isinstance(path, tuple):  # as per AreaResource.area_path
            self.area, self.subpath = path
        else:
            self.area, self.subpath = self.area_and_subpath_from_path(path)

    def __str__(self):
        if self.area:
            return "[%s]%s%s" % (self.area, os.sep, self.subpath)
        else:
            return self.subpath

    def __repr__(self):
        return "AreaResource(%r, %r)" % (self.path, self.area)

    @property
    def area_path(self):
        return (self.area, self.subpath)

    @property
    def path(self):
        if self.area is None:
            return self.subpath
        else:
            return join(self._path_areas[self.area], self.subpath)

########NEW FILE########
__FILENAME__ = stdlib
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""The stdlib zone of the codeintel database.
See the database/database.py module docstring for an overview.
"""


import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile)
import cPickle as pickle
import threading
import time
import bisect
import fnmatch
from glob import glob
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import codecs
import copy
import weakref
import Queue

import ciElementTree as ET
from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.util import dedent, safe_lang_from_lang, banner
from codeintel2.tree import tree_from_cix_path
from codeintel2.database.resource import AreaResource
from codeintel2.database.util import (rmdir, filter_blobnames_for_prefix)


#---- globals
log = logging.getLogger("codeintel.db")
# log.setLevel(logging.DEBUG)


#---- Database zone and lib implementations
class StdLib(object):
    """Singleton lib managing a particular db/stdlibs/<stdlib-name>
    area of the db.

    These are dished out via Database.get_stdlib(), which indirectly
    then is dished out by the StdLibsZone.get_lib().

    Because (1) any updating of the stdlib db area for this language has
    already been done (by StdLibsZone.get_lib()) and (2) this is a
    singleton: we shouldn't have to worry about locking.
    """
    _blob_index = None
    _toplevelname_index = None
    _toplevelprefix_index = None

    def __init__(self, db, base_dir, lang, name):
        self.db = db
        self.lang = lang
        self.name = name
        self.base_dir = base_dir
        self._import_handler = None
        self._blob_imports_from_prefix_cache = {}
        self._blob_from_blobname = {}

    def __repr__(self):
        return "<%s stdlib>" % self.name

    @property
    def import_handler(self):
        if self._import_handler is None:
            self._import_handler \
                = self.db.mgr.citadel.import_handler_from_lang(self.lang)
        return self._import_handler

    @property
    def blob_index(self):
        if self._blob_index is None:
            idxpath = join(self.base_dir, "blob_index")
            self._blob_index = self.db.load_pickle(idxpath)
        return self._blob_index

    @property
    def toplevelname_index(self):
        if self._toplevelname_index is None:
            idxpath = join(self.base_dir, "toplevelname_index")
            self._toplevelname_index = self.db.load_pickle(idxpath)
        return self._toplevelname_index

    @property
    def toplevelprefix_index(self):
        if self._toplevelprefix_index is None:
            idxpath = join(self.base_dir, "toplevelprefix_index")
            self._toplevelprefix_index = self.db.load_pickle(idxpath)
        return self._toplevelprefix_index

    def has_blob(self, blobname):
        return blobname in self.blob_index

    def get_blob(self, blobname):
        # Cache the blob once. Don't need to worry about invalidating the stdlib
        # blobs as stdlibs should not change during a Komodo session, bug
        # 65502.
        blob = self._blob_from_blobname.get(blobname)
        if blob is None:
            try:
                dbfile = self.blob_index[blobname]
            except KeyError:
                return None
            blob = self.db.load_blob(join(self.base_dir, dbfile))
            self._blob_from_blobname[blobname] = blob
        return blob

    def get_blob_imports(self, prefix):
        """Return the set of imports under the given prefix.

            "prefix" is a tuple of import name parts. E.g. ("xml", "sax")
                for "import xml.sax." in Python. Or ("XML", "Parser") for
                "use XML::Parser::" in Perl.

        See description in database.py docstring for details.
        """
        if prefix not in self._blob_imports_from_prefix_cache:
            matches = filter_blobnames_for_prefix(self.blob_index,
                                                  prefix, self.import_handler.sep)
            self._blob_imports_from_prefix_cache[prefix] = matches
        return self._blob_imports_from_prefix_cache[prefix]

    def hits_from_lpath(self, lpath, ctlr=None, curr_buf=None):
        """Return all hits of the given lookup path.

        I.e. a symbol table lookup across all files in the dirs of this
        lib.

            "lpath" is a lookup name list, e.g. ['Casper', 'Logging']
                or ['dojo', 'animation'].
            "ctlr" (optional) is an EvalController instance. If
                specified it should be used in the normal way (logging,
                checking .is_aborted()).
            "curr_buf" (optional) is not relevant for StdLib. Used for
                other *Lib classes.

        A "hit" is (<CIX node>, <scope-ref>).  Each one represent a
        scope-tag or variable-tag hit in all of the blobs for the
        execution set buffers.

        Returns the empty list if no hits.
        """
        assert isinstance(lpath, tuple)  # common mistake to pass in a string
        hits = []
        # toplevelname_index: {ilk -> toplevelname -> blobnames}
        for blobnames_from_toplevelname in self.toplevelname_index.itervalues():
            for blobname in blobnames_from_toplevelname.get(lpath[0], ()):
                blob = self.get_blob(blobname)
                try:
                    elem = blob
                    for p in lpath:
                        # LIMITATION: *Imported* names at each scope are
                        # not being included here. This is fine while we
                        # just care about JavaScript.
                        elem = elem.names[p]
                except KeyError:
                    continue
                hits.append((elem, (blob, list(lpath[:-1]))))
        return hits

    def toplevel_cplns(self, prefix=None, ilk=None):
        """Return completion info for all top-level names matching the
        given prefix and ilk in all blobs in this lib.

            "prefix" is a 3-character prefix with which to filter top-level
                names. If None (or not specified), results are not filtered
                based on the prefix.
            "ilk" is a symbol type (e.g. "class", "variable", "function")
                with which to filter results. If None (or not specified),
                results of any ilk are returned.
            "ctlr" (optional) is an EvalController instance. If
                specified it should be used in the normal way (logging,
                checking .is_aborted()).

        Returns a list of 2-tuples: (<ilk>, <name>).

        Note: the list is not sorted, because often some special sorting
        is required for the different completion evaluators that might use
        this API.
        """
        cplns = []
        if prefix is None:
            # Use 'toplevelname_index': {ilk -> toplevelname -> blobnames}
            for i, bft in self.toplevelname_index.iteritems():
                if ilk is not None and i != ilk:
                    continue
                cplns += [(i, toplevelname) for toplevelname in bft]
        else:
            # Use 'toplevelprefix_index':
            #   {ilk -> prefix -> toplevelnames}
            if ilk is not None:
                try:
                    toplevelnames = self.toplevelprefix_index[ilk][prefix]
                except KeyError:
                    pass
                else:
                    cplns += [(ilk, t) for t in toplevelnames]
            else:
                for i, tfp in self.toplevelprefix_index.iteritems():
                    if prefix not in tfp:
                        continue
                    cplns += [(i, t) for t in tfp[prefix]]

        return cplns

    def reportMemory(self, reporter, closure=None):
        """
        Report on memory usage from this StdLib.
        @returns {dict} memory usage; keys are the paths, values are a dict of
            "amount" -> number
            "units" -> "bytes" | "count"
            "desc" -> str description
        """
        log.debug("%s StdLib %s: reporting memory", self.lang, self.name)
        import memutils
        return {
            "explicit/python/codeintel/%s/stdlib/%s" % (self.lang, self.name): {
                "amount": memutils.memusage(self._blob_from_blobname) +
                memutils.memusage(
                    self._blob_imports_from_prefix_cache),
                "units": "bytes",
                "desc": "The number of bytes of %s codeintel stdlib %s blobs." % (self.lang, self.name),
            }
        }
        return total_mem_usage


class StdLibsZone(object):
    """Singleton zone managing the db/stdlibs/... area.

    Because this is a singleton we shouldn't have to worry about locking
    to prevent corruption.
    """
    _res_index = None                   # cix-path -> last-updated

    def __init__(self, db):
        self.db = db
        self.stdlibs_dir = join(dirname(dirname(__file__)), "stdlibs")
        self.base_dir = join(self.db.base_dir, "db", "stdlibs")
        self._stdlib_from_stdlib_ver_and_name = {
        }  # cache of StdLib singletons
        self._vers_and_names_from_lang = {
        }  # lang -> ordered list of (ver, name)

    def vers_and_names_from_lang(self, lang):
        "Returns an ordered list of (ver, name) for the given lang."
        #  _vers_and_names_from_lang = {
        #    "php": [
        #              ((4,3), "php-4.3"),
        #              ((5.0), "php-5.0"),
        #              ((5.1), "php-5.1"),
        #              ((5.2), "php-5.2"),
        #              ((5,3), "php-5.3")
        #         ],
        #    "ruby": [
        #              (None, "ruby"),
        #         ],
        #    ...
        #  }
        vers_and_names = self._vers_and_names_from_lang.get(lang)
        if vers_and_names is None:
            # Find the available stdlibs for this language.
            cix_glob = join(
                self.stdlibs_dir, safe_lang_from_lang(lang)+"*.cix")
            cix_paths = glob(cix_glob)
            vers_and_names = []
            for cix_path in cix_paths:
                name = splitext(basename(cix_path))[0]
                if '-' in name:
                    base, ver_str = name.split('-', 1)
                    ver = _ver_from_ver_str(ver_str)
                else:
                    base = name
                    ver = None
                if base.lower() != lang.lower():
                    # Only process when the base name matches the language.
                    # I.e. skip if base is "python3" and lang is "python".
                    continue
                vers_and_names.append((ver, name))
            vers_and_names.sort()
            self._vers_and_names_from_lang[lang] = vers_and_names
        return vers_and_names

    @property
    def res_index(self):
        "cix-path -> last-updated"
        if self._res_index is None:
            idxpath = join(self.base_dir, "res_index")
            self._res_index = self.db.load_pickle(idxpath, {})
        return self._res_index

    def save(self):
        if self._res_index is not None:
            self.db.save_pickle(join(self.base_dir, "res_index"),
                                self._res_index)

    def cull_mem(self):
        """Cull memory usage as appropriate.
        This is a no-op for StdLibsZone because its memory use is bounded and
        doesn't really need culling.
        """
        pass

    def reportMemory(self):
        """
        Report on memory usage from this StdLibZone.
        @returns {dict} memory usage; keys are the paths, values are a dict of
            "amount" -> number
            "units" -> "bytes" | "count"
            "desc" -> str description
        """
        log.debug("StdLibZone: reporting memory")
        result = {}
        for stdlib in self._stdlib_from_stdlib_ver_and_name.values():
            result.update(stdlib.reportMemory())
        return result

    def get_lib(self, lang, ver_str=None):
        """Return a view into the stdlibs zone for a particular language
        and version's stdlib.

            "lang" is the language, e.g. "Perl", for which to get a
                stdlib.
            "ver_str" (optional) is a specific version of the language,
                e.g. "5.8".

        On first get of a stdlib for a particular language, all
        available stdlibs for that lang are updated, if necessary.

        Returns None if there is not stdlib for this language.
        """
        vers_and_names = self.vers_and_names_from_lang(lang)
        if not vers_and_names:
            return None
        if ver_str is None:
            # Default to the latest version.
            ver = vers_and_names[-1][0]
        else:
            ver = _ver_from_ver_str(ver_str)

        # Here is something like what we have for PHP:
        #    vers_and_names = [
        #        (None, "php"),
        #        ((4,0), "php-4.0"),
        #        ((4,1), "php-4.1"),
        #        ((4,2), "php-4.2"),
        #        ((4,3), "php-4.3"),
        #        ((5,0), "php-5.0"),
        #        ((5,1), "php-5.1"),
        #    ]
        # We want to (quickly) pick the best fit stdlib for the given
        # PHP version:
        #   PHP (ver=None): php
        #   PHP 3.0:        php
        #   PHP 4.0:        php-4.0 (exact match)
        #   PHP 4.0.2:      php-4.0 (higher sub-version)
        #   PHP 4.4:        php-4.3
        #   PHP 6.0:        php-5.1
        key = (ver, "zzz")  # 'zzz' > any stdlib name (e.g., 'zzz' > 'php-4.2')
        idx = max(0, bisect.bisect_right(vers_and_names, key)-1)
        log.debug("best stdlib fit for %s ver=%s in %s is %s",
                  lang, ver, vers_and_names, vers_and_names[idx])

        stdlib_match = vers_and_names[idx]
        stdlib_ver, stdlib_name = stdlib_match

        if stdlib_match not in self._stdlib_from_stdlib_ver_and_name:
            # TODO: This _update_lang_with_ver method should really moved into
            #       the StdLib class.
            self._update_lang_with_ver(lang, ver=stdlib_ver)
            stdlib = StdLib(self.db,
                            join(self.base_dir, stdlib_name),
                            lang, stdlib_name)
            self._stdlib_from_stdlib_ver_and_name[stdlib_match] = stdlib

        return self._stdlib_from_stdlib_ver_and_name[stdlib_match]

    def _get_preload_zip(self):
        return join(self.stdlibs_dir, "stdlibs.zip")

    def can_preload(self):
        """Return True iff can preload."""
        if exists(self.base_dir):
            log.info("can't preload stdlibs: `%s' exists", self.base_dir)
            return False
        try:
            import process
            import which
        except ImportError, ex:
            log.info("can't preload stdlibs: %s", ex)
            return False
        try:
            which.which("unzip")
        except which.WhichError, ex:
            log.info("can't preload stdlibs: %s", ex)
            return False
        preload_zip = self._get_preload_zip()
        if not exists(preload_zip):
            log.info("can't preload stdlibs: `%s' does not exist", preload_zip)
            return False
        return True

    def preload(self, progress_cb=None):
        """Pre-load the stdlibs zone, if able.

            "progress_cb" (optional) is a callable that is called as
                follows to show the progress of the update:
                    progress_cb(<desc>, <value>)
                where <desc> is a short string describing the current step
                and <value> is an integer between 0 and 100 indicating the
                level of completeness.

        Use `.can_preload()' to determine if able to pre-load.
        """
        import which
        import process

        log.debug("preloading stdlibs zone")
        if progress_cb:
            try:
                progress_cb("Preloading stdlibs...", None)
            except:
                log.exception("error in progress_cb (ignoring)")
        preload_zip = self._get_preload_zip()
        unzip_exe = which.which("unzip")
        cmd = '"%s" -q -d "%s" "%s"'\
              % (unzip_exe, dirname(self.base_dir), preload_zip)
        p = process.ProcessOpen(cmd, stdin=None)
        stdout, stderr = p.communicate()
        retval = p.wait()
        if retval:
            raise OSError("error running '%s'" % cmd)

    # TODO: Add ver_str option (as per get_lib above) and only update
    #      the relevant stdlib.
    def remove_lang(self, lang):
        """Remove the given language from the stdlib zone."""
        log.debug("update '%s' stdlibs", lang)

        # Figure out what updates need to be done...
        cix_glob = join(self.stdlibs_dir, safe_lang_from_lang(lang)+"*.cix")
        todo = []
        for area, subpath in self.res_index:
            res = AreaResource(subpath, area)
            if fnmatch.fnmatch(res.path, cix_glob):
                todo.append(("remove", AreaResource(subpath, area)))

        # ... and then do them.
        self._handle_res_todos(lang, todo)
        self.save()

    def _update_lang_with_ver(self, lang, ver=None, progress_cb=None):
        """Import stdlib data for this lang, if necessary.

            "lang" is the language to update.
            "ver" (optional) is a specific version of the language,
                e.g. (5, 8).
            "progress_cb" (optional) is a callable that is called as
                follows to show the progress of the update:
                    progress_cb(<desc>, <value>)
                where <desc> is a short string describing the current step
                and <value> is an integer between 0 and 100 indicating the
                level of completeness.
        """
        log.debug("update '%s' stdlibs", lang)
        # Figure out what updates need to be done...
        if progress_cb:
            try:
                progress_cb("Determining necessary updates...", 5)
            except:
                log.exception("error in progress_cb (ignoring)")
        if ver is not None:
            ver_str = ".".join(map(str, ver))
            cix_path = join(self.stdlibs_dir,
                            "%s-%s.cix" % (safe_lang_from_lang(lang), ver_str))
        else:
            cix_path = join(self.stdlibs_dir,
                            "%s.cix" % (safe_lang_from_lang(lang), ))

        # Need to acquire db lock, as the indexer and main thread may both be
        # calling into _update_lang_with_ver at the same time.
        self.db.acquire_lock()
        try:
            todo = []
            res = AreaResource(cix_path, "ci-pkg-dir")
            try:
                last_updated = self.res_index[res.area_path]
            except KeyError:
                todo.append(("add", res))
            else:
                mtime = os.stat(cix_path).st_mtime
                if last_updated != mtime:  # epsilon? '>=' instead of '!='?
                    todo.append(("update", res))

            # ... and then do them.
            self._handle_res_todos(lang, todo, progress_cb)
            self.save()
        finally:
            self.db.release_lock()

    def update_lang(self, lang, progress_cb=None, ver=None):
        vers_and_names = self.vers_and_names_from_lang(lang)
        if ver is not None:
            ver = _ver_from_ver_str(ver)
            key = (
                ver, "zzz")  # 'zzz' > any stdlib name (e.g., 'zzz' > 'php-4.2')
            idx = max(0, bisect.bisect_right(vers_and_names, key)-1)
            log.debug("update_lang: best stdlib fit for %s ver=%s in %s is %s",
                      lang, ver, vers_and_names, vers_and_names[idx])
            # Just update the one version for this language.
            vers_and_names = [vers_and_names[idx]]
        for ver, name in vers_and_names:
            self._update_lang_with_ver(lang, ver, progress_cb)

    def _handle_res_todos(self, lang, todo, progress_cb=None):
        if not todo:
            return
        for i, (action, res) in enumerate(todo):
            cix_path = res.path
            name = splitext(basename(cix_path))[0]
            if '-' in name:
                base, ver_str = name.split('-', 1)
                ver = _ver_from_ver_str(ver_str)
            else:
                base = name
                ver = None
            assert base == safe_lang_from_lang(lang)

            log.debug("%s %s stdlib: `%s'", action, name, cix_path)
            verb = {"add": "Adding", "remove": "Removing",
                    "update": "Updating"}[action]
            desc = "%s %s stdlib" % (verb, name)
            if progress_cb:
                try:
                    progress_cb(desc, (5 + 95/len(todo)*i))
                except:
                    log.exception("error in progress_cb (ignoring)")
            else:
                self.db.report_event(desc)

            if action == "add":
                self._add_res(res, lang, name, ver)
            elif action == "remove":
                self._remove_res(res, lang, name, ver)
            elif action == "update":
                # XXX Bad for filesystem. Change this to do it
                #    more intelligently if possible.
                self._remove_res(res, lang, name, ver)
                self._add_res(res, lang, name, ver)

    def _remove_res(self, res, lang, name, ver):
        log.debug("%s stdlibs: remove %s", lang, res)
        del self.res_index[res.area_path]
        dbdir = join(self.base_dir, name)
        try:
            rmdir(dbdir)
        except OSError, ex:
            try:
                os.rename(dbdir, dbdir+".zombie")
            except OSError, ex2:
                log.error("could not remove %s stdlib database dir `%s' (%s): "
                          "couldn't even rename it to `%s.zombie' (%s): "
                          "giving up", name, dbdir, ex, name, ex2)
            else:
                log.warn("could not remove %s stdlib database dir `%s' (%s): "
                         "moved it to `%s.zombie'", name, dbdir, ex)

    def _add_res(self, res, lang, name, ver):
        log.debug("%s stdlibs: add %s", lang, res)
        cix_path = res.path
        try:
            tree = tree_from_cix_path(cix_path)
        except ET.XMLParserError, ex:
            log.warn("could not load %s stdlib from `%s' (%s): skipping",
                     name, cix_path, ex)
            return

        dbdir = join(self.base_dir, name)
        if exists(dbdir):
            log.warn("`db/stdlibs/%s' already exists and should not: "
                     "removing it", name)
            try:
                rmdir(dbdir)
            except OSError, ex:
                log.error("could not remove `%s' to create %s stdlib in "
                          "database (%s): skipping", dbdir, name)
        if not exists(dbdir):
            os.makedirs(dbdir)

        # Create 'blob_index' and 'toplevel*_index' and write out
        # '.blob' file.
        LEN_PREFIX = self.db.LEN_PREFIX
        is_hits_from_lpath_lang = lang in self.db.import_everything_langs
        blob_index = {}  # {blobname -> dbfile}
        toplevelname_index = {}  # {ilk -> toplevelname -> blobnames}
        toplevelprefix_index = {}  # {ilk -> prefix -> toplevelnames}
        for blob in tree.findall("file/scope"):
            assert lang == blob.get("lang"), \
                "Adding %s resource %s to %s blob" % (
                    lang, res, blob.get("lang"))
            blobname = blob.get("name")
            dbfile = self.db.bhash_from_blob_info(cix_path, lang, blobname)
            blob_index[blobname] = dbfile
            ET.ElementTree(blob).write(join(dbdir, dbfile+".blob"))
            for toplevelname, elem in blob.names.iteritems():
                if "__local__" in elem.get("attributes", "").split():
                    # this is internal to the stdlib
                    continue
                ilk = elem.get("ilk") or elem.tag
                bft = toplevelname_index.setdefault(ilk, {})
                if toplevelname not in bft:
                    bft[toplevelname] = set([blobname])
                else:
                    bft[toplevelname].add(blobname)
                prefix = toplevelname[:LEN_PREFIX]
                tfp = toplevelprefix_index.setdefault(ilk, {})
                if prefix not in tfp:
                    tfp[prefix] = set([toplevelname])
                else:
                    tfp[prefix].add(toplevelname)

        self.db.save_pickle(join(dbdir, "blob_index"), blob_index)
        self.db.save_pickle(join(dbdir, "toplevelname_index"),
                            toplevelname_index)
        self.db.save_pickle(join(dbdir, "toplevelprefix_index"),
                            toplevelprefix_index)

        mtime = os.stat(cix_path).st_mtime
        self.res_index[res.area_path] = mtime


#---- internal support stuff
def _ver_from_ver_str(ver_str):
    """Convert a version string to a version object as used internally
    for the "stdlibs" area of the database.

        >>> _ver_from_ver_str("5.8")
        (5, 8)
        >>> _ver_from_ver_str("1.8.2")
        (1, 8, 2)
        >>> _ver_from_ver_str("ecma")
        'ecma'
        >>> _ver_from_ver_str("ie")
        'ie'
    """
    ver = []
    for s in ver_str.split('.'):
        try:
            ver.append(int(s))
        except ValueError:
            ver.append(s)
    return tuple(ver)

########NEW FILE########
__FILENAME__ = util
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

import os
import sys
import logging
import shutil


log = logging.getLogger("codeintel.db")


def filter_blobnames_for_prefix(candidates, prefix, sep):
    """Given a iterator of candidate blob names, return a set of
    2-tuples indicating each match:

        (<sub-name>, <is-partial-match>)

    where,
        <sub-name> is the import component after the prefix
        <is-partial-match> is a boolean indicating if suffix is
            multipart.

    For example, given:
        candidates = ["LWP",
                      "LWP::Authen::Basic", "LWP::Authen::Digest",
                      "LWP::ConnCache",
                      "LWP::Protocol",
                      "LWP::Protocol::http", "LWP::Protocol::https",
                      "LWP::UserAgent"]
        prefix = ("LWP",)
        sep = "::"
    the returned items should be:
        ("Authen",    True)
        ("ConnCache", False)
        ("Protocol",  False)
        ("Protocol",  True)
        ("UserAgent", False)
    """
    matches = set()
    if not prefix:
        for name in candidates:
            if name == "*":
                continue  # skip "built-in" blob
            if sep in name:
                matches.add((name[:name.index(sep)], True))
            else:
                matches.add((name, False))
    else:
        sep_len = len(sep)
        sepped_prefix = sep.join(prefix)
        for name in candidates:
            if name == "*":
                continue  # skip "built-in" blob
            if name.startswith(sepped_prefix + sep):
                # e.g. prefix is "xml", and we see "xml.sax" and "xml.bar.foo"
                subname = name[len(sepped_prefix)+sep_len:]
                # subname is "sax" and "bar.foo"
                if sep in subname:
                    # we want to return bar, not bar.foo
                    subname = subname[:subname.index(sep)]
                    is_partial_match = True
                else:
                    is_partial_match = False
                matches.add((subname, is_partial_match))
    return matches


def rmdir(dir):
    """Remove the given dir. Raises an OSError on failure."""
    if sys.platform == "win32":
        # Apparent just running 'rd' (or else because run via
        # process.Process) on Windows == DOS box flash (bug 61348).
        log.debug("fs-write: rmdir `%s'", dir)
        shutil.rmtree(dir, 0, _rmtree_onerror)
    else:
        run('rm -rf "%s"' % dir)


def _rmtree_onerror(rm_func, path, exc_info):
    if exc_info[0] == OSError:
        # presuming because file is read-only
        os.chmod(path, 0777)
        rm_func(path)


#---- internal support routines
# Recipe: run (0.5.3) in /home/trentm/tm/recipes/cookbook
_RUN_DEFAULT_LOGSTREAM = ("RUN", "DEFAULT", "LOGSTREAM")


def __run_log(logstream, msg, *args, **kwargs):
    if not logstream:
        pass
    elif logstream is _RUN_DEFAULT_LOGSTREAM:
        try:
            log
        except NameError:
            pass
        else:
            if hasattr(log, "debug"):
                log.debug(msg, *args, **kwargs)
    else:
        logstream(msg, *args, **kwargs)


def run(cmd, logstream=_RUN_DEFAULT_LOGSTREAM):
    """Run the given command.

        "cmd" is the command to run
        "logstream" is an optional logging stream on which to log the
            command. If None, no logging is done. If unspecifed, this
            looks for a Logger instance named 'log' and logs the command
            on log.debug().

    Raises OSError is the command returns a non-zero exit status.
    """
    __run_log(logstream, "running '%s'", cmd)

    # Using os.system on Windows == DOS box flash (bug 61348).
    # TODO: Perhaps we should use Process for all plats? (bug 65961).
    if sys.platform == "win32":
        import process
        p = process.ProcessOpen(cmd, stdin=None)
        p.communicate()
        retval = p.wait()
    else:
        retval = os.system(cmd)

    if hasattr(os, "WEXITSTATUS"):
        status = os.WEXITSTATUS(retval)
    else:
        status = retval
    if status:
        # TODO: add std OSError attributes or pick more approp. exception
        raise OSError("error running '%s': %r" % (cmd, status))


def run_in_dir(cmd, cwd, logstream=_RUN_DEFAULT_LOGSTREAM):
    """Run the given command in the given working directory.

        "cmd" is the command to run
        "cwd" is the directory in which the commmand is run.
        "logstream" is an optional logging stream on which to log the
            command. If None, no logging is done. If unspecifed, this
            looks for a Logger instance named 'log' and logs the command
            on log.debug().

    Raises OSError is the command returns a non-zero exit status.
    """
    old_dir = os.getcwd()
    try:
        os.chdir(cwd)
        __run_log(logstream, "running '%s' in '%s'", cmd, cwd)
        run(cmd, logstream=None)
    finally:
        os.chdir(old_dir)

########NEW FILE########
__FILENAME__ = environment
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Runtime environment handling for codeintel

"Environment" here means more than just the environment variables (i.e.
os.environ). It also means preferences/settings/conditions that are part
of the running environment for a codeintel Manager or Buffer.

Generally the relevant environment is used to get data such environment
variables and preferences (e.g., what Python interpreter is relevant,
what level of JS DOM APIs should be considered).

The Manager has an 'env' attribute (by default, an Environment instance)
and, optionally, a buffer can have a custom environment (also the 'env'
attribute). The latter is useful for sharing a project environment
across all buffers part of the same project.

For example, Buffers created for files in Komodo currently have a
KoCodeIntelEnvironment instance. All buffers belonging to the same project
share a single such instance that incorporates project settings. Buffers
not part of a project share a default instance that just uses global
Komodo settings.

Read the base Environment class for details on the API.
"""

import os
import logging


log = logging.getLogger("codeintel.environment")
# log.setLevel(logging.DEBUG)


class Environment(object):
    """The base Environment class. It defines the API that all types
    of "environments" in codeintel must implement and provides a base
    implementation that:
    - has no prefs
    - maps envvars to os.environ, and
    - has some basic file associations for 'assoc_patterns_from_lang()'.

    Every environment must have a 'cache' attribute that is a wide open
    dictionary. Various parts of the codeintel system can (and do) use
    this cache for maintain runtime calculated date.
    """
    def __init__(self, environ=None):
        self.cache = {}
        self.environ = environ or dict(os.environ)

    def __repr__(self):
        return "<Environment>"

    def has_envvar(self, name):
        """Return True if the named envvar exists."""
        return name in self.environ

    def get_envvar(self, name, default=None):
        """Return the value of the named envvar, if it exists. Otherwise
        return the given default, if any, or None.
        """
        return self.environ.get(name, default)

    def get_all_envvars(self):
        """Return a dictionary of all environment variables."""
        return dict(self.environ)

    def has_pref(self, name):
        """Return True if the named pref exists."""
        return False

    def get_pref(self, name, default=None):
        """Return the value of the named pref, if it exists. Otherwise
        return the given default, if any, or None.
        """
        return default

    def get_all_prefs(self, name, default=None):
        """Return a list with the value of the named pref at each
        "pref-level". If not defined at a particular level the 'default'
        value will be placed at that index.

        Note: This was added to support Komodo's multi-level pref system.
        Most simple Environment classes only support one level.
        """
        return [self.get_pref(name, default)]

    def add_pref_observer(self, name, callback):
        pass

    def remove_pref_observer(self, name, callback):
        pass

    def remove_all_pref_observers(self):
        pass

    _default_assoc_patterns_from_lang = {
        "Python": ["*.py"],
        "Python3": ["*.py"],
        "JavaScript": ["*.js"],
        "PHP": ["*.php", "*.inc", "*.module"],
        "Perl": ["*.pm", "*.pl"],
        "Tcl": ["*.tcl"],
        "Ruby": ["*.rb"],
    }

    def assoc_patterns_from_lang(self, lang):
        """Return a list of filename patterns identifying the given
        language. Returns the empty list if don't have any info for that
        lang.
        """
        return self._default_assoc_patterns_from_lang.get(lang, [])

    def get_proj_base_dir(self):
        """Return the full path to the project base dir, or None if this
        environment does not represent a project.
        """
        return None


class SimplePrefsEnvironment(Environment):
    """A simple environment that supports basic key/value prefs and
    pref change observation.

    Whenever a pref changes, any registered callbacks for that pref name
    will be called as follows:
        callback(<env>, <pref-name>)

    Note: There is no support for *deleting* a pref. Just set it to
    None.  The reason for not supporting this is that it would require
    complicating pref observer notification to be able to distinguish
    setting pref to None and deleting it.
    """
    def __init__(self, **prefs):
        Environment.__init__(self, prefs.get('env'))
        self._prefs = prefs
        self._pref_observer_callbacks_from_name = {}

    def set_pref(self, name, value):
        self._prefs[name] = value
        self._notify_pref_observers(name)

    def has_pref(self, name):
        return name in self._prefs

    def get_pref(self, name, default=None):
        if name not in self._prefs:
            return default
        return self._prefs[name]

    def get_all_prefs(self, name, default=None):
        return [self.get_pref(name, default)]

    # TODO: Add ability to be able to call add_pref_observer() without
    #      having to worry if have already done so for this name.
    def add_pref_observer(self, name, callback):
        if name not in self._pref_observer_callbacks_from_name:
            self._pref_observer_callbacks_from_name[name] = []
        self._pref_observer_callbacks_from_name[name].append(callback)

    def remove_pref_observer(self, name, callback):
        self._pref_observer_callbacks_from_name[name].remove(callback)

    def remove_all_pref_observers(self):
        self._pref_observer_callbacks_from_name = {}

    def _notify_pref_observers(self, name):
        for callback in self._pref_observer_callbacks_from_name.get(name, []):
            try:
                callback(self, name)
            except:
                log.exception("error in pref observer for pref '%s' change",
                              name)


class DefaultEnvironment(SimplePrefsEnvironment):
    """The default environment used by the Manager if no environment is
    provided.
    """
    _default_prefs = {
        "codeintel_selected_catalogs": ["pywin32"],
        "codeintel_max_recursive_dir_depth": 10,
    }

    def __init__(self):
        SimplePrefsEnvironment.__init__(self, **self._default_prefs)

########NEW FILE########
__FILENAME__ = gencix_utils
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Shared CIX tools for Code Intelligence

    CIX helpers for codeintel creation. Code Intelligence XML format. See:
        http://specs.tl.activestate.com/kd/kd-0100.html#xml-based-import-export-syntax-cix
"""

import os
import sys
import re
import shutil
from cStringIO import StringIO
import warnings

from ciElementTree import Element, ElementTree, SubElement
from codeintel2.util import parseDocSummary

# Dictionary of known js types and what they map to
known_javascript_types = {
    "object":       "Object",
    "obj":          "Object",
    "function":     "Function",
    "array":        "Array",
    "string":       "String",
    "text":         "String",
    "int":          "Number",
    "integer":      "Number",
    "number":       "Number",
    "numeric":      "Number",
    "decimal":      "Number",
    "short":        "Number",
    "unsigned short": "Number",
    "long":         "Number",
    "unsigned long": "Number",
    "float":        "Number",
    "bool":         "Boolean",
    "boolean":      "Boolean",
    "true":         "Boolean",
    "false":        "Boolean",
    "date":         "Date",
    "regexp":       "RegExp",
    # Dom elements
    "element":      "Element",
    "node":         "Node",
    "domnode":      "DOMNode",
    "domstring":    "DOMString",
    "widget":       "Widget",
    "domwidget":    "DOMWidget",
    "htmlelement":  "HTMLElement",
    "xmldocument":  "XMLDocument",
    "htmldocument": "HTMLDocument",
    # Special
    "xmlhttprequest": "XMLHttpRequest",
    "void":          "",
    # Mozilla special
    "UTF8String":    "String",
    "AString":       "String",
}


def standardizeJSType(vartype):
    """Return a standardized name for the given type if it is a known type.

    Example1: given vartype of "int", returns "Number"
    Example2: given vartype of "YAHOO.tool", returns "YAHOO.tool"
    """

    if vartype:
        typename = known_javascript_types.get(vartype.lower(), None)
        if typename is None:
            # print "Unknown type: %s" % (vartype)
            return vartype
        return typename

spacere = re.compile(r'\s+')


def condenseSpaces(s):
    """Remove any line enedings and condense multiple spaces"""

    s = s.replace("\n", " ")
    s = spacere.sub(' ', s)
    return s.strip()


def remove_directory(dirpath):
    """ Recursively remove the directory path given """

    if os.path.exists(dirpath):
        shutil.rmtree(dirpath, ignore_errors=True)


def getText(elem):
    """Return the internal text for the given ElementTree node"""

    l = []
    for element in elem.getiterator():
        if element.text:
            l.append(element.text)
        if element.tail:
            l.append(element.tail)
    return " ".join(l)


def getAllTextFromSubElements(elem, subelementname):
    descnodes = elem.findall(subelementname)
    if len(descnodes) == 1:
        return getText(descnodes[0])
    return None

_invalid_char_re = re.compile(
    u'[^\u0009\u000A\u000D\u0020-\uD7FF\uE000-\uFFFD]')


def strip_invalid_xml_chars(s):
    """Return the string with any invalid XML characters removed.

    The valid characters are listed here:
        http://www.w3.org/TR/REC-xml/#charsets
        #x9 | #xA | #xD | [#x20-#xD7FF] | [#xE000-#xFFFD] | [#x10000-#x10FFFF]
    """
    return _invalid_char_re.sub("", s)


def setCixDoc(cixelement, doctext, parse=False):
    if parse:
        doclines = parseDocSummary(doctext.splitlines(0))
        doctext = "\n".join(doclines)
    elif sys.platform.startswith("win"):
        doctext = doctext.replace("\r\n", "\n")
    # TODO: By default clip doc content down to a smaller set -- just
    #      enough for a good calltip. By then also want an option to
    #      *not* clip, for use in documentation generation.
    # if len(doctext) > 1000:
    #    warnings.warn("doctext for cixelement: %r has length: %d" % (
    #                    cixelement.get("name"), len(doctext)))
    cixelement.attrib["doc"] = strip_invalid_xml_chars(doctext)


def setCixDocFromNodeChildren(cixelement, node, childnodename):
    doctext = getAllTextFromSubElements(node, childnodename)
    if doctext:
        setCixDoc(cixelement, condenseSpaces(doctext), parse=True)


def addCixArgument(cixelement, argname, argtype=None, doc=None):
    cixarg = SubElement(cixelement, "variable", ilk="argument", name=argname)
    if argtype:
        addCixType(cixarg, argtype)
    if doc:
        setCixDoc(cixarg, doc)
    return cixarg


def addCixReturns(cixelement, returntype=None):
    if returntype and returntype != "void":
        cixelement.attrib["returns"] = returntype


def addCixType(cixobject, vartype):
    if vartype:
        cixobject.attrib["citdl"] = vartype


def addCixAttribute(cixobject, attribute):
    attrs = cixobject.get("attributes")
    if attrs:
        sp = attrs.split()
        if attribute not in sp:
            attrs = "%s %s" % (attrs, attribute)
    else:
        attrs = attribute
    cixobject.attrib["attributes"] = attrs


def addClassRef(cixclass, name):
    refs = cixclass.get("classrefs", None)
    if refs:
        if name not in refs.split(" "):
            cixclass.attrib["classrefs"] = "%s %s" % (refs, name)
    else:
        cixclass.attrib["classrefs"] = "%s" % (name)


def addInterfaceRef(cixinterface, name):
    refs = cixinterface.get("interfacerefs", None)
    if refs:
        if name not in refs.split(" "):
            cixinterface.attrib["interfacerefs"] = "%s %s" % (refs, name)
    else:
        cixinterface.attrib["interfacerefs"] = "%s" % (name)


def setCixSignature(cixelement, signature):
    cixelement.attrib["signature"] = signature


def createCixVariable(cixobject, name, vartype=None, attributes=None):
    if attributes:
        v = SubElement(cixobject, "variable", name=name,
                       attributes=attributes)
    else:
        v = SubElement(cixobject, "variable", name=name)
    if vartype:
        addCixType(v, vartype)
    return v


def createCixFunction(cixmodule, name, attributes=None):
    if attributes:
        return SubElement(cixmodule, "scope", ilk="function", name=name,
                          attributes=attributes)
    else:
        return SubElement(cixmodule, "scope", ilk="function", name=name)


def createCixInterface(cixmodule, name):
    return SubElement(cixmodule, "scope", ilk="interface", name=name)


def createCixClass(cixmodule, name):
    return SubElement(cixmodule, "scope", ilk="class", name=name)


def createCixNamespace(cixmodule, name):
    return SubElement(cixmodule, "scope", ilk="namespace", name=name)


def createCixModule(cixfile, name, lang, src=None):
    if src is None:
        return SubElement(cixfile, "scope", ilk="blob", name=name, lang=lang)
    else:
        return SubElement(cixfile, "scope", ilk="blob", name=name, lang=lang, src=src)


def createOrFindCixModule(cixfile, name, lang, src=None):
    for module in cixfile.findall("./scope"):
        if module.get("ilk") == "blob" and module.get("name") == name and \
           module.get("lang") == lang:
            return module
    return createCixModule(cixfile, name, lang, src)


def createCixFile(cix, path, lang="JavaScript", mtime="1102379523"):
    return SubElement(cix, "file",
                      lang=lang,
                      # mtime=mtime,
                      path=path)


def createCixRoot(version="2.0", name=None, description=None):
    cixroot = Element("codeintel", version=version)
    if name is not None:
        cixroot.attrib["name"] = name
    if description is not None:
        cixroot.attrib["description"] = description
    return cixroot

# Add .text and .tail values to make the CIX output pretty. (Only have
# to avoid "doc" tags: they are the only ones with text content.)


def prettify(elem, level=0, indent='  ', youngestsibling=0):
    if elem and elem.tag != "doc":
        elem.text = '\n' + (indent*(level+1))
    for i in range(len(elem)):
        prettify(elem[i], level+1, indent, i == len(elem)-1)
    elem.tail = '\n' + (indent*(level-youngestsibling))


def get_cix_string(cix, prettyFormat=True):
    # Get the CIX.
    if prettyFormat:
        prettify(cix)
    cixstream = StringIO()
    cixtree = ElementTree(cix)
    cixstream.write('<?xml version="1.0" encoding="UTF-8"?>\n')
    cixtree.write(cixstream)
    cixcontent = cixstream.getvalue()
    cixstream.close()
    return cixcontent


def outline_ci_elem(elem, _lvl=0, brief=False, doSort=False, includeLineNos=False):
    """Return an outline of the given codeintel tree element."""
    indent = '  '
    result = []

    def _dump(s):
        if includeLineNos:
            startline = elem.get("line")
            lineend = elem.get("lineend")
            line_str = ""
            if startline or lineend:
                line_str = " (%r-%r)" % (startline, lineend)
            result.append(indent*_lvl + s + line_str + '\n')
        else:
            result.append(indent*_lvl + s + '\n')

    if elem.tag == "codeintel":
        _lvl -= 1  # don't count this one
    elif brief:
        name = elem.get("name")
        if name:
            _dump(name)
    elif elem.tag == "file":
        lang = elem.get("lang")
        _dump("file %(path)s [%(lang)s]" % elem.attrib)
    elif elem.tag == "variable":
        if elem.get("ilk") == "argument":
            s = "arg "+elem.get("name")  # skip?
        else:
            s = "var "+elem.get("name")
        if elem.get("citdl"):
            s += " [%s]" % elem.get("citdl")
        _dump(s)
    elif elem.tag == "scope" and elem.get("ilk") == "function" \
            and elem.get("signature"):
        _dump("function %s" % elem.get("signature").split('\n')[0])
    elif elem.tag == "scope" and elem.get("ilk") == "blob":
        lang = elem.get("lang")
        _dump("blob %(name)s [%(lang)s]" % elem.attrib)
    elif elem.tag == "scope" and elem.get("ilk") == "class" \
            and elem.get("classrefs"):
        _dump("%s %s(%s)" % (elem.get("ilk"), elem.get("name"),
                             ', '.join(elem.get("classrefs").split())))
    elif elem.tag == "scope":
        _dump("%s %s" % (elem.get("ilk"), elem.get("name")))
    elif elem.tag == "import":
        module = elem.get("module")
        symbol = elem.get("symbol")
        alias = elem.get("alias")
        value = "import '%s" % (module, )
        if symbol:
            value += ".%s" % (symbol, )
        value += "'"
        if alias:
            value + " as %r" % (alias, )
        _dump(value)
    else:
        raise ValueError("unknown tag: %r (%r)" % (elem.tag, elem))

    if doSort and hasattr(elem, "names") and elem.names:
        for name in sorted(elem.names.keys()):
            child = elem.names[name]
            result.append(outline_ci_elem(child, _lvl=_lvl+1,
                                          brief=brief, doSort=doSort,
                                          includeLineNos=includeLineNos))
    else:
        for child in elem:
            result.append(outline_ci_elem(child, _lvl=_lvl+1,
                                          brief=brief, doSort=doSort,
                                          includeLineNos=includeLineNos))
    return "".join(result)


def remove_cix_line_numbers_from_tree(tree):
    for node in tree.getiterator():
        node.attrib.pop("line", None)
        node.attrib.pop("lineend", None)

########NEW FILE########
__FILENAME__ = hooks
#!/usr/bin/env python
# Copyright (c) 2006-2008 ActiveState Software Inc.
# See LICENSE.txt for license details.

"""Parts of the codeintel system may provide hooks for customization
by external modules. Implementing a hook is done by adding a
`CodeIntelHookHandler` instance with the manager, like this:

    ---- codeintel_foo.py ----
    # My codeintel 'foo' hook.

    from codeintel2.hooks import HookHandler

    class FooHookHandler(HookHandler):
        name = "foo"
        langs = ["Python"]  # only hook into handling for Python code

        # Add implementation of one or more hooks (see below)...

    def register(mgr):
        # This will be called by the Manager on startup.
        mgr.add_hook_handler(FooHookHandler(mgr))
    --------------------------
"""

from pprint import pformat

from codeintel2.common import *


class HookHandler(object):
    """Virtual base class for all hook handlers."""
    name = None     # sub-classes must define a meaningful name (a string)

    # Sub-classes must define the list of language names they operate
    # on. E.g.,
    #   langs = ["Perl"]
    #   langs = ["HTML", "XML"]
    #   langs = ["*"]   # Means operate on all languages. Use sparingly!
    langs = None

    def __init__(self, mgr):
        self.mgr = mgr

    # Hook: `post_db_load_blob(blob)'
    #
    # Called just after a blob is loaded from the the codeintel database.
    # Note that this hook is not currently called for blobs from API
    # Catalogs or in language stdlibs.
    #
    # A "blob" is a ciElementTree (a slight tweak to an ElementTree
    # object) representing the scan info for code of a single language
    # in a single file.
    #
    # The hook-handler may modify (in-place) or just look at the blob.
    # The resulting changes to the blob, if any, are NOT saved to the
    # database.
    # Potential uses for this hook might be to add implicit state to
    # a file for a certain framework, e.g. adding context info to a
    # Django template, adding implicit imports to a PHP Zend Framework
    # controller file.
    def post_db_load_blob(self, blob):
        pass

########NEW FILE########
__FILENAME__ = indexer
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""The codeintel indexer is a thread that handles scanning files and
loading them into the database. There is generally one indexer on the
Manager instance.

    mgr.idxr = Indexer(mgr)

XXX A separate indexer instance may be used for batch updates of the db.
"""
# TODO:
# - How are scan errors handled? do we try to keep from re-scanning over
#   and over? Perhaps still use mtime to only try again on new content.
#   Could still have a "N strikes in the last 1 minute" rule or
#   something.
# - batch updating (still wanted? probably)

import os
import sys
import threading
import time
import bisect
import Queue
from hashlib import md5
import traceback

import logging

from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.database.langlib import LangDirsLib
from codeintel2.database.multilanglib import MultiLangDirsLib

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- globals
log = logging.getLogger("codeintel.indexer")
# log.setLevel(logging.DEBUG)


#---- internal support
class _PriorityQueue(Queue.Queue):
    """A thread-safe priority queue.

    In order to use this the inserted items should be tuples with the
    priority first. Note that subsequent elements of the item tuples will
    be used for secondary sorting. As a result, it is often desirable to
    make the second tuple index be a timestamp so that the queue is a
    FIFO for elements with the same priority, e.g.:
        item = (PRIORITY, time.time(), element)

    Usage:
        q = _PriorityQueue(0)  # unbounded queue
        q.put( (2, time.time(), "second") )
        q.put( (1, time.time(), "first") )
        q.put( (3, time.time(), "third") )
        priority, timestamp, value = q.get()
    """
    def _put(self, item):
        bisect.insort(self.queue, item)

    # The following are to ensure a *list* is being used as the internal
    # Queue data structure. Python 2.4 switched to using a deque
    # internally which doesn't have the insert() method that
    # bisect.insort() uses.
    def _init(self, maxsize):
        self.maxsize = maxsize
        self.queue = []

    def _get(self):
        return self.queue.pop(0)


class _Request(object):
    """Base class for a queue-able thing.

    A request object must have an 'id'. This is used for "staging"
    requests on the queue. A staged request will sit around for 'delay'
    amount of time before actually being put on the processing queue.
    During that wait, a subsequent stage request with the same 'id' will
    replace the first one -- including resetting the delay. This is
    useful for staging relatively expensive processing in the background
    for content that is under ongoing changes (e.g. for processing an
    editor buffer while it is being editted).
    """
    # XXX PERF: use a slot?
    id = None

    def __init__(self, id=None):
        if id is not None:
            self.id = id


class _UniqueRequestPriorityQueue(_PriorityQueue):
    """A thread-safe priority queue for '_Request' objects.

    This queue class extends _PriorityQueue with the condition that:
    When adding a _Request to the queue, if a _Request with the same id
    already exists in the queue, then the new _Request inherits the
    higher priority and the earlier timestamp of the two and _replaces_
    the older _Request.

    This condition is added because there is no point in scanning file
    contents from time T1 when a scan of the file contents at time T2
    (more recent) is being requested. It is important to adopt the
    higher priority (and earlier timestamp) to ensure the requestor does
    not starve.

    Note: This presumes that an "item" is this 3-tuple:
        (<priority-number>, <timestamp>, <_Request instance>)
    """
    def __init__(self, maxsize=0):
        _PriorityQueue.__init__(self, maxsize)
        self._item_from_id = {}

    def _put(self, item):
        # Remove a possible existing request for the same file (there can
        # be only one).
        priority, timestamp, request = item
        id = request.id
        if id in self._item_from_id:
            i = self._item_from_id[id]
            self.queue.remove(i)
            p, t, r = i
            item = (min(priority, p), t, request)
        # Add the (possibly updated) item to the queue.
        self._item_from_id[id] = item
        _PriorityQueue._put(self, item)

    def _get(self):
        item = _PriorityQueue._get(self)
        del self._item_from_id[item[-1].id]
        return item


class _StagingRequestQueue(_UniqueRequestPriorityQueue):
    """A thread-safe priority queue for '_Request' objects with delayed
    staging support.

    This queue class extends _UniqueRequestPriorityQueue by adding the
    .stage() method. This method is like the regular .put() method
    except that staged requests are only actually placed on the queue if
    a certain period of inactivity passes without subsequent stage
    requests for the same request id.

    This is to support reasonable performance for live updating while a
    document is being edited. Rather than executing a scan for every
    intermediate edited state, scanning is only  after a period of
    relative inactivity.

    One additional burden is that a "staging thread" is involved so one must
    call this queue's .finalize() method to properly shut it down.

    As with the _ScanRequestQueue this queue presumes that and item is this
    3-tuple:
            (<priority-number>, <timestamp>, <ScanRequest instance>)
    """
    DEFAULT_STAGING_DELAY = 1.5  # default delay from on deck -> on queue (s)

    def __init__(self, maxsize=0, stagingDelay=None):
        """Create a staging scan request queue.

            "maxsize" (optional) is an upperbound limit on the number of
                items in the queue (<= 0 means the queue is unbounded).
            "stagingDelay" (optional) is a number of seconds to use as a
                delay from being staged to being placed on the queue.
        """
        _UniqueRequestPriorityQueue.__init__(self, maxsize)
        if stagingDelay is None:
            self._stagingDelay = self.DEFAULT_STAGING_DELAY
        else:
            self._stagingDelay = stagingDelay
        self._onDeck = {
            # <request-id> : (<time when due>, <priority>, <queue item>)
        }
        self._nothingOnDeck = threading.Lock()
        self._nothingOnDeck.acquire()
        self._terminate = 0  # boolean telling "staging thread" to terminate
        self._stager = threading.Thread(target=self._stagingThread,
                                        name="request staging thread")
        self._stager.setDaemon(True)
        self._stager.start()

    def finalize(self):
        if self._stager:
            self._terminate = 1
            # Make sure staging thread isn't blocked so it can terminate.
            self.mutex.acquire()
            try:
                if not self._onDeck:
                    self._nothingOnDeck.release()
            finally:
                self.mutex.release()
            # Don't bother join'ing because there is no point waiting for
            # up to self._stagingDelay while the staging thread shuts down.
            # self._stager.join()

    def stage(self, item, delay=None):
        if delay is None:
            delay = self._stagingDelay
        self.mutex.acquire()
        try:
            priority, timestamp, request = item
            wasEmpty = not self._onDeck
            if request.id not in self._onDeck \
               or self._onDeck[request.id][1] != PRIORITY_IMMEDIATE:
                self._onDeck[request.id] = (timestamp + delay, priority, item)
                if wasEmpty:
                    self._nothingOnDeck.release()
        finally:
            self.mutex.release()

    def _stagingThread(self):
        """Thread that handles moving requests on-deck to the queue."""
        log.debug("staging thread: start")
        while 1:
            # If nothing is on-deck, wait until there is.
            # log.debug("staging thread: acquire self._nothingOnDeck")
            self._nothingOnDeck.acquire()
            # log.debug("staging thread: acquired self._nothingOnDeck")
            if self._terminate:
                break

            # Place any "due" items on the queue.
            self.mutex.acquire()
            somethingStillOnDeck = 1
            currTime = time.time()
            toQueue = []
            try:
                for id, (timeDue, priority, item) in self._onDeck.items():
                    if currTime >= timeDue:
                        toQueue.append(item)
                        del self._onDeck[id]
                if not self._onDeck:
                    somethingStillOnDeck = 0
            finally:
                if somethingStillOnDeck:
                    self._nothingOnDeck.release()
                self.mutex.release()
            if toQueue:
                log.debug("staging thread: queuing %r", toQueue)
                for item in toQueue:
                    self.put(item)

            # Sleep for a bit.
            # XXX If the latency it too large we may want to sleep for some
            #    fraction of the staging delay.
            log.debug("staging thread: sleep for %.3fs", self._stagingDelay)
            time.sleep(self._stagingDelay)
        log.debug("staging thread: end")


#---- public classes
class XMLParseRequest(_Request):
    """A request to re-parse and XML-y/HTML-y file

    (For XML completion and Komodo's DOMViewer.)
    """
    def __init__(self, buf, priority, force=False):
        if _xpcom_:
            buf = UnwrapObject(buf)
        self.buf = buf
        self.id = buf.path + "#xml-parse"
        self.priority = priority
        self.force = force

    def __repr__(self):
        return "<XMLParseRequest %r>" % self.id

    def __str__(self):
        return "xml parse '%s' (prio %s)" % (self.buf.path, self.priority)


class ScanRequest(_Request):
    """A request to scan a file for codeintel.

    A ScanRequest has the following properties:
        "buf" is the CitadelBuffer instance.
        "priority" must be one of the PRIORITY_* priorities.
        "force" is a boolean indicating if a scan should be run even if
            the database is already up-to-date for this content.
        "mtime" is the modified time of the file/content. If not given
            it defaults to the current time.
        "on_complete" (optional) is a callable to call when the scan
            and load is complete. (XXX: Is this being used by anyone?)

        "status" is set on completion. See .complete() docstring for details.
    """
    status = None

    def __init__(self, buf, priority, force=False, mtime=None, on_complete=None):
        if _xpcom_:
            buf = UnwrapObject(buf)
        self.buf = buf
        self.id = buf.path
        self.priority = priority
        self.force = force
        if mtime is None:
            self.mtime = time.time()
        else:
            self.mtime = mtime
        self.on_complete = on_complete
        self.complete_event = threading.Event()  # XXX use a pool

    def __repr__(self):
        return "<ScanRequest %r>" % self.id

    def __str__(self):
        return "scan request '%s' (prio %s)" % (self.buf.path, self.priority)

    def complete(self, status):
        """Called by scheduler when this scan is complete (whether or
        not it was successful/skipped/whatever).

            "status" is one of the following:
                changed     The scan was done and (presumably) something
                            changed. PERF: Eventually want to be able to
                            detect when an actual change is made to be
                            used elsewhere to know not to update.
                skipped     The scan was skipped.
        """
        log.debug("complete %s", self)
        self.status = status
        self.complete_event.set()
        if self.on_complete:
            try:
                self.on_complete()
            except:
                log.exception("ignoring exception in ScanRequest "
                              "on_complete callback")

    def wait(self, timeout=None):
        """Can be called by code requesting a scan to wait for completion
        of this particular scan.
        """
        self.complete_event.wait(timeout)


class PreloadBufLibsRequest(_Request):
    priority = PRIORITY_BACKGROUND

    def __init__(self, buf):
        if _xpcom_:
            buf = UnwrapObject(buf)
        self.buf = buf
        self.id = buf.path + "#preload-libs"

    def __repr__(self):
        return "<PreloadBufLibsRequest %r>" % self.id

    def __str__(self):
        return "pre-load libs for '%s'" % self.buf.path


class PreloadLibRequest(_Request):
    priority = PRIORITY_BACKGROUND

    def __init__(self, lib):
        self.lib = lib
        self.id = "%s %s with %s dirs#preload-lib" \
                  % (lib.lang, lib.name, len(lib.dirs))

    def __repr__(self):
        return "<PreloadLibRequest %r>" % self.id

    def __str__(self):
        return "pre-load %s %s (%d dirs)" \
               % (self.lib.lang, self.lib.name, len(self.lib.dirs))


class CullMemRequest(_Request):
    id = "cull memory request"
    priority = PRIORITY_BACKGROUND


class IndexerStopRequest(_Request):
    id = "indexer stop request"
    priority = PRIORITY_CONTROL

    def __repr__(self):
        return '<'+self.id+'>'


class IndexerPauseRequest(_Request):
    id = "indexer pause request"
    priority = PRIORITY_CONTROL

    def __repr__(self):
        return '<'+self.id+'>'


class Indexer(threading.Thread):
    """A codeintel indexer thread.

    An indexer is mainly responsible for taking requests to scan
    (Citadel) buffers and load the data into the appropriate LangZone of
    the database.

#XXX Only needed when/if batch updating is redone.
##    This thread manages a queue of ScanRequest's, scheduling the scans in
##    priority order. It has two modes of usage:
##        MODE_DAEMON
##            The scheduler remains running until it is explicitly stopped with
##            the .stop() method.
##        MODE_ONE_SHOT
##            All added requests are processed and then the scheduler
##            terminates. Note that the .stageRequest() method is not
##            allowed in this mode.

    Usage:
        from codeintel.indexer import Indexer
        idxr = Indexer(mgr)
        idxr.start()
        try:
            # idxr.stage_request(<request>)
            # idxr.add_request(<request>)
        finally:
            idxr.finalize()

    Dev Notes:
    - The intention is the indexer will grow to handle other requests as
      well (saving and culling cached parts of the database).
    - There is a potential race condition on request id generation
      if addRequest/stageRequest calls are made from multiple threads.
    """
    MODE_DAEMON, MODE_ONE_SHOT = range(2)
    mode = MODE_DAEMON

    class StopIndexing(Exception):
        """Used to signal that indexer iteration should stop.

        Dev Note: I *could* use StopIteration here, but I don't want to
        possibly misinterpret a real StopIteration.
        """
        pass

    def __init__(self, mgr, on_scan_complete=None):
        """
            "on_scan_complete" (optional), if specified, is called when
                a ScanRequest is completed.

        TODO: add back the requestStartCB and completedCB (for batch updates)
        """
        threading.Thread.__init__(self, name="codeintel indexer")
        self.setDaemon(True)
        self.mgr = mgr
        self.on_scan_complete = on_scan_complete
        if self.mode == self.MODE_DAEMON:
            self._requests = _StagingRequestQueue()
        else:
            self._requests = _UniqueRequestPriorityQueue()
        self._stopping = False
        self._resumeEvent = None

    def finalize(self):
        """Shutdown the indexer.

        This must be done even if the the indexer thread was never
        .start()'ed -- because of the thread used for the
        _StagingRequestQueue.
        """
        self._stopping = True
        if isinstance(self._requests, _StagingRequestQueue):
            self._requests.finalize()
        if self.isAlive():
            self.add_request(IndexerStopRequest())
            try:
                self.join(5)  # see bug 77284
            except AssertionError:
                pass  # thread was not started

    def pause(self):
        self._resumeEvent = threading.Event()
        self._pauseEvent = threading.Event()
        # TODO: shouldn't this be `self.add_request`?
        self.addRequest(IndexerPauseRequest())
        self._pauseEvent.wait()  # wait until the Scheduler is actually paused
        log.debug("indexer: paused")

    def resume(self):
        if self._resumeEvent:
            self._resumeEvent.set()
            self._resumeEvent = None
        log.debug("indexer: resumed")

    def stage_request(self, request, delay=None):
        log.debug("stage %r", request)
        if self.mode == self.MODE_ONE_SHOT:
            raise CodeIntelError("cannot call stage requests on a "
                                 "MODE_ONE_SHOT indexer")
        # self._abortMatchingRunner(request.buf.path, request.buf.lang)
        self._requests.stage((request.priority, time.time(), request), delay)

    def add_request(self, request):
        log.debug("add %r", request)
        # self._abortMatchingRunner(request.buf.path, request.buf.lang)
        self._requests.put((request.priority, time.time(), request))

# XXX re-instate for batch updating (was getNumRequests)
##    def num_requests(self):
##        return self._requests.qsize()

    def run(self):    # the scheduler thread run-time
        log.debug("indexer: start")
##        reason = "failed"
        try:
            while 1:
                try:
                    self._iteration()
                except Queue.Empty:  # for mode=MODE_ONE_SHOT only
##                    reason = "completed"
                    break
                except self.StopIndexing:
##                    reason = "stopped"
                    break
                except:
                    # Because we aren't fully waiting for indexer
                    # termination in `self.finalize` it is possible that
                    # an ongoing request fails (Manager finalization
                    # destroys the `mgr.db` instance). Don't bother
                    # logging an error if we are stopping.
                    #
                    # Note: The typical culprit is a *long*
                    # <PreloadBufLibsRequest> for a PHP or JS library
                    # dir. Ideally this would be split into a number of
                    # lower-prio indexer requests.
                    if not self._stopping:
                        log.exception("unexpected internal error in indexer: "
                                      "ignoring and continuing")
        finally:
##            try:
##                if self._completedCB:
##                    self._completedCB(reason)
##            except:
##                log.exception("unexpected error in completion callback")
            log.debug("indexer thread: stopped")

    def _iteration(self):
        """Handle one request on the queue.

        Raises StopIndexing exception if iteration should stop.
        """
        # log.debug("indexer: get request")
        if self.mode == self.MODE_DAEMON:
            priority, timestamp, request = self._requests.get()
        else:  # mode == self.MODE_ONE_SHOT
            priority, timestamp, request = self._requests.get_nowait()
        # log.debug("indexer: GOT request")

        try:
            if request.priority == PRIORITY_CONTROL:  # sentinel
                if isinstance(request, IndexerStopRequest):
                    raise self.StopIndexing()
                elif isinstance(request, IndexerPauseRequest):
                    self._pauseEvent.set(
                    )  # tell .pause() that Indexer has paused
                    self._resumeEvent.wait()
                    return
                else:
                    raise CodeIntelError("unexpected indexer control "
                                         "request: %r" % request)

            if isinstance(request, ScanRequest):
                # Drop this request if the database is already up-to-date.
                db = self.mgr.db
                buf = request.buf
                status = "changed"
                if not request.force:
                    scan_time_in_db = db.get_buf_scan_time(buf)
                    if scan_time_in_db is not None \
                       and scan_time_in_db > request.mtime:
                        log.debug("indexer: drop %s: have up-to-date data for "
                                  "%s in the db", request, buf)
                        status = "skipped"
                        return

                buf.scan(mtime=request.mtime)

            elif isinstance(request, XMLParseRequest):
                request.buf.xml_parse()

            elif isinstance(request, CullMemRequest):
                log.debug("cull memory requested")
                self.mgr.db.cull_mem()

            # Currently these two are somewhat of a DB zone-specific hack.
            # TODO: The standard DB "lib" iface should grow a
            #      .preload() (and perhaps .can_preload()) with a
            #      ctlr arg. This should be unified with the current
            #      StdLib.preload().
            elif isinstance(request, PreloadBufLibsRequest):
                for lib in request.buf.libs:
                    if isinstance(lib, (LangDirsLib, MultiLangDirsLib)):
                        lib.ensure_all_dirs_scanned()
            elif isinstance(request, PreloadLibRequest):
                lib = request.lib
                assert isinstance(lib, (LangDirsLib, MultiLangDirsLib))
                lib.ensure_all_dirs_scanned()

            if not isinstance(request, CullMemRequest) and self.mode == self.MODE_DAEMON:
                # we did something; ask for a memory cull after 5 minutes
                log.debug("staging new cull mem request")
                self.stage_request(CullMemRequest(), 300)
            self.mgr.db.report_event(None)

        finally:
            if isinstance(request, ScanRequest):
                request.complete(status)
                if self.on_scan_complete:
                    try:
                        self.on_scan_complete(request)
                    except:
                        log.exception("ignoring exception in Indexer "
                                      "on_scan_complete callback")


#---- internal support stuff
# Recipe: indent (0.2.1) in C:\trentm\tm\recipes\cookbook
def _indent(s, width=4, skip_first_line=False):
    """_indent(s, [width=4]) -> 's' indented by 'width' spaces

    The optional "skip_first_line" argument is a boolean (default False)
    indicating if the first line should NOT be indented.
    """
    lines = s.splitlines(1)
    indentstr = ' '*width
    if skip_first_line:
        return indentstr.join(lines)
    else:
        return indentstr + indentstr.join(lines)

########NEW FILE########
__FILENAME__ = jsdoc
#!/usr/bin/env python

# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

""" Utility class used for the parsing of Javascript comments.

This uses the JavaSciptDoc style (JSDoc 2)
"http://code.google.com/p/jsdoc-toolkit/" for allowing comments to specify
specific information about the file structure.

The TAGS we use for JavaScript is based upon what JSDoc
supplies and what YAHOO has done. A YAHOO example is:

/**
 * Method for creating a slider
 *
 * @private
 * @param {String} s the name of the slider.
 * @param {String} id element id to place the silder within
 * @param {int} leftPadding is the size of the padding field on the left
 * @param {int} rightPadding optional field for setting the size of the padding
 *              field on the right.
 * @return {Slider} a horizontal slider control
 */

Notes:
* comments and type information "{...}" are optional
* {} type field can be either the first or second position after the field.
* field comments can span multiple lines.
"""

# JSDoc tags and the help (calltip) for the tag.
# Note: Not all of these have a meaning for the javascript ciler.
jsdoc_tags = {
    "augments":     "Extends another class and adds methods or properties of its own.\n"
                    "Note: Same as @extends.\n"
                    "Example: /** @augments SomeClass */",

    "argument":     "Provide information about a function parameter.\n"
                    "Note: Deprecated - use @param.\n"
                    "Example: /** @argument {String} arg1  The first argument */",

    "author":       "The author of this component.\n"
                    "Example: /** @author John Smith jsmith@jsmith.com.mars */",

    "borrows":      "Uses a method or property defined in another class.\n"
                    "Example: /** @borrows Remote#transfer as this.send */",

    "class":        "This tag is used in a constructor's documentation block\n"
                    "to provide information about the actual class.\n"
                    "Example: /** @class MyClass */",

    "constant":     "Marks a variable as being constant.\n"
                    "Example: /** @constant */",

    "constructor":  "Mark as being the constructor for the class.\n"
                    "Example: /** @constructor */",

    "constructs":   "Used with @lends tag - indicates this is used to create\n"
                    "instances of the class.\n"
                    "Example: /** @constructs */",

    "default":      "Documents the default value of an object.\n"
                    'Example: /** @default "bright" */',

    "deprecated":   "Mark as not being supported anymore.\n"
                    "Deprecated components should not be used, as they\n"
                    "will usually be removed in some future version.\n"
                    "Example: /** @deprecated since 5.2 - use Other instead */",

    "description":  "Sets this as the main description line to be used.\n"
                    "Example: /** @description Use this line for describing */",

    "event":        "Tag a function that can be fired as an Event.\n"
                    "Example: /** @event */",

    "example":      "Used to show an example code usage snippet.\n"
                    "Example: /** @example\n"
                    "           * var field = forceField(10);\n"
                    "           */",

    "exports":      "Document as using a different name.\n"
                    "Example: /** @exports MyClass as ns.OtherClass */",

    "extends":      "The base class this class extends.\n"
                    "Note: Same as @augments.\n"
                    "Example: /** @extends ParentClass */",

    "field":        "Document as a property field - not as a function.\n"
                    "Example: /** @field */",

    "fileoverview": "This documentation block will be used to provide\n"
                    "an overview for the current file.\n"
                    "Example: /** @fileoverview */",

    "function":     "Document a property as being a function.\n"
                    "Example: /** @function */",

    "ignore":       "Item will be ignored by JSDoc.\n"
                    "Example: /** @ignore */",

    "inner":        "Mark a inner function as not being externally accessible.\n"
                    "Example: /** @inner */",

    "lends":        "Document all object properties as belonging to\n"
                    "another namespace.\n"
                    "Example: /** @lends OtherClass */",

    "link":         "Create a documentation link to another symbol.\n"
                    "Example: /** @sometag See here {@link MyClass}. */",

    "memberOf":     "Marks as being a member of the supplied namespace.\n"
                    "Example: /** @memberOf MyClass */",

    "name":         "Use the supplied name for the following object.\n"
                    "Example: /** @name MyProperty */",

    "namespace":    "Namespace where the element resides.\n"
                    "Example: /** @namespace Can be used to do stuff. */",

    "param":        "Provide information about a function parameter.\n"
                    "Note: The type field {} is optional.\n"
                    "Example: /** @param {String} arg1  The first argument */",

    "private":      "Member is private.\n"
                    "This means it will not be shown in any documentation.\n"
                    "Komodo's Code Browser shows this with a locked image.\n"
                    "Example: /** @private */",

    "property":     "Document a member variable.\n"
                    "Note: The type field {} is optional.\n"
                    "Example: /** @property {String} name  The description */",

    "public":       "Causes object to be documented as exposed.\n"
                    "Example: /** @public */",

    "requires":     "Define a dependency upon another class.\n"
                    "Example: /** @requires OtherClass  Because it does! */",

    "returns":      "Provide information about the return value of a function.\n"
                    "Example: /** @returns {Array} An array of items. */",

    "see":          "Link to another class or function.\n"
                    "Example: /** @see ClassName#methodName */",

    "since":        "Specify the version that this item was added in.\n"
                    "Example: /** @since version 5.0.2 */",

    "static":       "Static member, only one instance ever defined.\n"
                    "Example: /** @static */",

    "tags":         "User defined tag names - comma separated.\n"
                    "Example: /** @tags testcase,knownfailure */",

    "throws":       "Method call may throw this type of exception.\n"
                    "Example: /** @throws {OutOfMemeory} Text of when thrown */",

    "type":         "Variable type.\n"
                    "Example: /** @type String */",

    "version":      "Version number of the current file or class.\n"
                    "Example: /** @version 1.0.8 */",

}


# stripTags from ASPN cookbook (unknown contributor)
# http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/440481
def stripTags(s):
    """Remove the html tags from the string s -> str"""
    # This list is neccesarry because chk() would otherwise not know
    # that intag in stripTags() is ment, and not a new intag variable in chk().
    intag = [False]

    def chk(c):
        if intag[0]:
            intag[0] = (c != '>')
            return False
        elif c == '<':
            intag[0] = True
            return False
        return True

    return ''.join(c for c in s if chk(c))


class JSDocParameter:
    def __init__(self, paramname, paramtype=None, doc=None):
        self.paramname = paramname
        self.paramtype = paramtype
        self.doc = doc

    def __repr__(self):
        return "JSDocParameter: %r (%r) - %r" % (self.paramname, self.paramtype,
                                                 self.doc)


class JSDoc:
    A_CLASS = 0x01
    A_CONSTRUCTOR = 0x02
    A_PRIVATE = 0x04
    A_STATIC = 0x08
    A_CONSTANT = 0x10
    A_DEPRECATED = 0x20
    A___LOCAL__ = 0x40

    def __init__(self, comment=None, strip_html_tags=False):
        self._reset()
        self.strip_html_tags = strip_html_tags
        if comment:
            # Full comment initially given
            # print "JSDoc comment: %r" % (comment)
            self.parse(comment)

    def __repr__(self):
        result = []
        if self.attributes:
            attrs = []
            if self.attributes & self.A_CLASS:
                if self.classname:
                    result.append("Classname:  %s" % (self.classname))
                else:
                    attrs.append("class")
            elif self.attributes & self.A_CONSTRUCTOR:
                attrs.append("constructor")
            elif self.attributes & self.A_PRIVATE:
                attrs.append("private")
            elif self.attributes & self.A_STATIC:
                attrs.append("static")
            elif self.attributes & self.A_CONSTANT:
                attrs.append("constant")
            elif self.attributes & self.A_DEPRECATED:
                attrs.append("deprecated")
            if len(attrs) > 0:
                result.append(" ".join(attrs))
        if self.namespace:
            result.append("Namespace:  %s" % (self.namespace))
        if self.baseclasses:
            result.append("baseclasses:  %s" % (self.baseclasses))
        for cp in self.params:
            result.append(str(cp))
        if self.type:
            result.append("Type:  %s" % (self.type))
        if self.tags:
            result.append("Tags:  %s" % (self.tags))
        if self.returns:
            result.append("Returns:  %s" % (str(self.returns)))
        if self.doc:
            result.append("Doc:\n" + self.doc)
        return "JSDoc:\n  %s" % ("\n  ".join(result))

    def _reset(self):
        self.comment = None
        self.baseclasses = []
        self.doc = None
        self.classname = None
        self.namespace = None
        self.type = None
        self.tags = None
        self.attributes = 0
        # params is a list of JSDocParameter's
        self.params = []
        # returns is a JSDocParameter (does not have a paramname though)
        self.returns = None

    def _getTypeField(self, value):
        # Examples:
        #  'int'
        #  '{String}'
        #  'boolean|Object'
        #  'Array[](Number[])'
        # YUI Example:
        #   * @param {<a href="http://www.w3.org/TR/2000/WD-DOM-Level-1-20000929/level-one-
        #   * html.html#ID-22445964">HTMLDivElement</a>} p_oElement Object specifying the
        #   * <code>&#60;div&#62;</code> element of the context menu.
        if not value:
            return value

        # Only take first field if multiples are given
        pipePos = value.find('|')
        if pipePos > 0:
            value = value[:pipePos]

        value = value.strip()
        if value[-1] == "}":
            value = value[:-1]
            sp = value.split("{", 1)
            if len(sp) > 1:
                value = sp[1]
                sp = value.split(":", 1)
                if len(sp) > 1:
                    value = sp[1]
        # Added to remove YUI's href docs from the citdl type
        href_pos = value.find('<a href="')
        if href_pos >= 0:
            # We only want the href link text
            end_a_tag_pos = value.find('</a>')
            if end_a_tag_pos:
                value = value[:end_a_tag_pos]
                # Find matching close tag >
                href_pos = value.rfind('>')
                if href_pos >= 0:
                    value = value[href_pos+1:]

        # If a brace is in the value, it's an array
        bracePos = value.find("[")
        if bracePos >= 0:
            value = "Array"
        return value.strip()

    # Examples:
    #  "{Boolean}       true if the date is OOM"
    #  "el {HTMLElement} the element to animate"
    #  "{string}  sCategory  The log category for the message."
    #  "String The name of this dude."
    def _getTypeFieldFromString(self, value):
        """Return tuple (type, rest of string)"""
        if not value.strip():
            return (None, None)
        sp = value.split("{", 1)
        if len(sp) > 1:
            before = sp[0]
            value = sp[1]
            sp = value.split("}", 1)
            value = sp[0]
            if len(sp) > 1:
                after = sp[1]
                return (self._getTypeField(value), before + after)
        else:
            sp = value.split(None, 1)
            if len(sp) > 1:
                return (self._getTypeField(sp[0]), sp[1])
            return (self._getTypeField(sp[0]), '')
        return (None, value)

    def _handle_base(self, value):
        self.baseclasses.append(value)

    # Same as base
    def _handle_augments(self, value):
        self._handle_base(value)
    # Same as base

    def _handle_extends(self, value):
        self._handle_base(value)

    def _handle_class(self, value):
        self.attributes |= self.A_CLASS
        self.classname = value

    def _handle_constructor(self, value):
        self.attributes |= self.A_CONSTRUCTOR

    def _handle_namespace(self, value):
        self.namespace = value

    def _handle_private(self, value):
        self.attributes |= self.A_PRIVATE

    def _handle_static(self, value):
        self.attributes |= self.A_STATIC

    def _handle_final(self, value):
        self.attributes |= self.A_CONSTANT

    def _handle_deprecated(self, value):
        self.attributes |= self.A_DEPRECATED

    def _handle___local__(self, value):
        self.attributes |= self.A___LOCAL__

    def _handle_param(self, value):
        paramname = None
        paramtype = None
        doc = None
        sp = value.split(None, 2)
        for s in sp[:2]:
            if paramtype is None and s and s[0] == '{':
                # type information
                paramtype = self._getTypeField(s)
            elif paramname is None:
                paramname = s
        # Should have at least the paramname by now
        if paramname and paramtype:
            if len(sp) > 2:
                doc = sp[2]
            else:
                doc = None
        else:
            doc = " ".join(sp[1:3])
        cp = JSDocParameter(paramname, paramtype, doc)
        self.params.append(cp)
    # Same as param.

    def _handle_argument(self, value):
        return self._handle_param(value)

    def _handle_tags(self, value):
        self.tags = value

    def _handle_type(self, value):
        self.type = self._getTypeFieldFromString(value)[0]

    def _handle_return(self, value):
        returntype, doc = self._getTypeFieldFromString(value)
        if returntype:
            self.returns = JSDocParameter(None, returntype, doc)
    # Same as return

    def _handle_returns(self, value):
        return self._handle_return(value)

    def parse(self, comment):
        self._reset()
        if self.strip_html_tags:
            comment = stripTags(comment)
        self.comment = comment
        if not comment:
            return False
        in_doc = True
        doc = []
        lines = self.comment.splitlines(0)
        # Check to see if it's an actual javadoc
        isJSDoc = False
        # Once we reach the tags we don't add to the doc anymore, only
        # to the tags
        tagElements = []
        for line in lines:
            line = line.strip()
            # print "line: %r" % (line)
            if not isJSDoc:
                # Note: "*//**" style comes from the ciler using two comments
                # See bug: http://bugs.activestate.com/show_bug.cgi?id=68727
                if "/**" in line:
                    # It looks like a javadoc from here
                    isJSDoc = True
                    line = line.split("/*", 1)[1]
                    if not line or line == "*":
                        continue
                    if line.endswith("*/"):
                        line = line[:-2].strip()
                else:
                    continue
            # It's a javadoc, so parse up the fields
            if line == "*/":
                # End of the doc.
                isJSDoc = False
            elif line.endswith("*//**"):
                self._reset()
                self.comment = comment
            elif line == "*":
                doc.append("")
            elif len(line) > 2 and line[:2] in ("* ", "*\t"):
                sp = line.split(None, 1)
                # print sp
                if len(sp) > 1:
                    if sp[1][0] == '@':
                        # It's a javadoc field
                        # print sp
                        docfield = sp[1][1:]
                        sp = docfield.split(None, 1)
                        # print sp
                        # print "Tag: %r" % (sp[0])
                        if sp[0] == "description":
                            if len(sp) > 1:
                                doc.append(sp[1])
                            in_doc = True
                        else:
                            tagElements.append(sp)
                            in_doc = False
                    elif tagElements and doc and not in_doc:  # This is a continued param field
                        tagData = tagElements[-1]
                        if len(tagData) == 1:
                            tagData.append(sp[1])
                        else:
                            tagData[1] += "\n%s" % (sp[1])
                    else:  # This is still the main doc string
                        doc.append(sp[1])
                        in_doc = True
            elif len(line) > 2:
                # In a jsdoc, but this line does not start with a star.
                doc.append(line)
        self.doc = "\n".join(doc).rstrip()
        # Parse the tags now
        for tagData in tagElements:
            handle_call = getattr(self, "_handle_%s" % (tagData[0]), None)
            if handle_call is not None:
                if len(tagData) == 1:
                    value = ""
                else:
                    value = tagData[1].strip()
                handle_call(value)
            # else: # We don't handle this param

    def isClass(self):
        return self.attributes & self.A_CLASS

    def isConstructor(self):
        return self.attributes & self.A_CONSTRUCTOR

    def isPrivate(self):
        return self.attributes & self.A_PRIVATE

    def isStatic(self):
        return self.attributes & self.A_STATIC

    def isConstant(self):
        return self.attributes & self.A_CONSTANT

    def isDeprecated(self):
        return self.attributes & self.A_DEPRECATED

    def is__local__(self):
        """Komodo extension: __local__ (see cix-2.0.rng)"""
        return self.attributes & self.A___LOCAL__


############################################################
#                       Test code                          #
############################################################

def _test():
    sample_comment = """/**
 * Utility to set up the prototype, constructor and superclass properties to
 * support an inheritance strategy that can chain constructors and methods.
 *
 * @param {function} subclass   the object to modify
 * @param {function} superclass the object to inherit.
 *  Second line of param superclass doc.
 * @tags these,are,my,tags
 */
"""

    # Test the general usage of the class
    jd = JSDoc(sample_comment)
    assert(len(jd.params) == 2)
    assert(jd.params[0].paramname == "subclass")
    assert(jd.params[0].paramtype == "function")
    assert(jd.params[0].doc == "the object to modify")
    assert(jd.params[1].paramname == "superclass")
    assert(jd.params[1].paramtype == "function")
    assert(jd.params[
           1].doc == "the object to inherit.\nSecond line of param superclass doc.")
    assert(jd.tags == "these,are,my,tags")
    # print jd

    # Test specific internal functions of the class
    paramtype, doc = jd._getTypeFieldFromString(
        "el {HTMLElement} the element to animate")
    assert(paramtype == "HTMLElement")
    assert(doc == "el  the element to animate")
    paramtype = jd._getTypeField("Array[](Number[])")
    assert(paramtype == "Array")
    paramtype = jd._getTypeField("Number|Array[])")
    assert(paramtype == "Number")

    jd._reset()
    jd._handle_param(
        "{string}  sSource    The source of the the message (opt)")
    assert(len(jd.params) == 1 and
           jd.params[0].paramname == "sSource" and
           jd.params[0].paramtype == "string")

    jd._reset()
    jd._handle_param("oParent {Node} this node's parent node")
    assert(len(jd.params) == 1 and
           jd.params[0].paramname == "oParent" and
           jd.params[0].paramtype == "Node")

    jd._reset()
    jd._handle_returns("{array} Array of result objects")
    assert(jd.returns and
           not jd.returns.paramname and
           jd.returns.paramtype == "array")

    jd._reset()
    jd._handle_class("The superclass of all menu containers.")
    assert(jd.attributes & jd.A_CLASS)
    assert(jd.isClass())

    jd._reset()
    jd._handle_private("")
    assert(jd.attributes & jd.A_PRIVATE)
    assert(jd.isPrivate())

    jd._reset()
    jd._handle_static("")
    assert(jd.attributes & jd.A_STATIC)
    assert(jd.isStatic())

    jd._reset()
    jd._handle_constructor("")
    assert(jd.attributes & jd.A_CONSTRUCTOR)
    assert(jd.isConstructor())

    jd._reset()
    jd._handle_deprecated("")
    assert(jd.attributes & jd.A_DEPRECATED)
    assert(jd.isDeprecated())

    jd._reset()
    jd._handle_base("YAHOO.widget.Menu")
    assert("YAHOO.widget.Menu" in jd.baseclasses)
    jd._reset()
    jd._handle_extends("YAHOO.util.DragDrop")
    assert("YAHOO.util.DragDrop" in jd.baseclasses)

    jd._reset()
    jd._handle_type("YAHOO.widget.MenuModuleItem")
    assert(jd.type == "YAHOO.widget.MenuModuleItem")
    jd._reset()
    jd._handle_type("{HTMLImageElement}")
    assert(jd.type == "HTMLImageElement")

    # Test short one-liners.
    short_type_comment = """/** @type String */"""
    jd = JSDoc(short_type_comment)
    assert(jd.type == "String")

    short_type_comment_with_tab = """/**\t@type String */"""
    jd = JSDoc(short_type_comment_with_tab)
    assert(jd.type == "String")

    short_type_command_with_fluff = """/** @type {String} Fluff */"""
    jd = JSDoc(short_type_command_with_fluff)
    assert(jd.type == "String")

# Main function


def main():
    _test()

# When run from command line
if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = langintel
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Base LangIntel class definition

Each lang_*.py registers a LangIntel instance -- a singleton (somewhat
similar to Komodo's language services, I suppose). This langintel defines
smarts for handling language content. This module contains some mixins
so that particular languages can implement the requisite interface easily.

Any single-language buffer has a '.langintel' attribute pointing to this
singleton. Any multi-language buffer (i.e. a subclass of UDLBuffer) has
a '.langintel_from_udl_family' dictionary.

TODO:
- document what interfaces a particular LangIntel is meant to provide

Dev Notes:
- Usage of LangIntel objects in code should always use 'langintel' in
  the variable name.
"""

import os
import re
import operator
from pprint import pformat, pprint
import logging

from codeintel2.common import *
from codeintel2.util import banner, indent, markup_text, isident, isdigit
import langinfo

if _xpcom_:
    from xpcom.server import UnwrapObject

log = logging.getLogger("codeintel.langintel")


class LangIntel(object):
    """Smarts about content of a given language.

    Typically the Buffer implementations defer to a language's LangIntel
    class for handling stuff specific to that language content. This is
    how multi-language buffers are handled.
    """
    # All "leaf" LangIntel subclasses must set the `lang` attribute.
    lang = None
    # Used by `preceding_trg_from_pos` for 3-char triggering for some langs.
    _last_trg_type = None

    def __init__(self, mgr):
        self.mgr = mgr

    _langinfo_cache = None

    @property
    def langinfo(self):
        if self._langinfo_cache is None:
            try:
                self._langinfo_cache = self.mgr.lidb.langinfo_from_komodo_lang(
                    self.lang)
            except langinfo.LangInfoError, ex:
                self._langinfo_cache = None
                log.exception("error getting langinfo for '%s'", self.lang)
        return self._langinfo_cache

    # Code Browser integration.
    cb_import_group_title = "Imports"
    cb_globalvar_group_title = "Global Variables"
    cb_group_global_vars = True

    def cb_blob_detail_from_elem_and_buf(self, elem, buf):
        if elem.get("lang") != buf.lang:  # multi-lang doc
            return "%s Code in %s" % (elem.get("lang"), buf.path)
        else:
            dir, base = os.path.split(buf.path)
            if dir:
                return "%s (%s)" % (base, dir)
            else:
                return base

    def cb_import_data_from_elem(self, elem):
        # Python form by default.
        alias = elem.get("alias")
        symbol = elem.get("symbol")
        module = elem.get("module")
        if alias:
            if symbol:
                name = "%s (%s.%s)" % (alias, module, symbol)
                detail = "from %(module)s import %(symbol)s as %(alias)s" % locals(
                )
            else:
                name = "%s (%s)" % (alias, module)
                detail = "import %(module)s as %(alias)s" % locals()
        elif symbol:
            name = '.'.join([module, symbol])
            detail = "from %(module)s import %(symbol)s" % locals()
        else:
            name = module
            detail = "import %(module)s" % locals()
        return {"name": name, "detail": detail}

    def cb_variable_data_from_elem(self, elem):
        attrs = elem.get("attributes", "").split()
        if elem.get("ilk") == "argument":
            img = "argument"
        elif "__instancevar__" in attrs:
            img = "instance-variable"
        else:
            img = "variable"
        if "private" in attrs:
            img += "-private"
        elif "protected" in attrs:
            img += "-protected"
        # TODO: Add 'detail'. C.f. cb.py::getDescForSymbol().
        return {"name": elem.get("name"),
                "img": img}

    def cb_function_detail_from_elem(self, elem):
        # by default (some languages may choose to override)
        sig = elem.get("signature")
        if sig:
            return sig
        else:
            return elem.get("name")+"(...)"

    def cb_class_detail_from_elem(self, elem):
        classrefs = elem.get("classrefs")
        if classrefs:
            return elem.get("name") + "(" + classrefs + ")"
        return elem.get("name")+"()"

    def cb_trait_detail_from_elem(self, elem):
        return elem.get("name")

    def cb_interface_detail_from_elem(self, elem):
        interfacerefs = elem.get("interfacerefs")
        if interfacerefs:
            return elem.get("name") + "(" + interfacerefs + ")"
        return elem.get("name")+"()"

    def cb_namespace_detail_from_elem(self, elem):
        return elem.get("name")

    def cb_data_from_elem_and_buf(self, elem, buf):
        """Return a dict of info for a code browser row for this element.

        - Should define "name" key.
        - Can define "detail" key. This is the string displayed when
          hovering over the image in the code browser.
        - Can define "img" key. This is string used to identify the
          image type. The following are common values:
            argument, variable, class, function, import, interface, namespace
          The symbol-types have -protected and -private versions, e.g.:
            variable-private, variable-protected, class-private, ...
          As well, many of the languages have associated icons:
            Perl, Python, JavaScript, Ruby, ...
          A few special ones for class instance vars:
            instance-variable, instance-variable-protected,
            instance-variable-private
          Some special ones:
            container, scanning, error
        """
        if elem.tag == "import":
            data = {"img": "import"}
            data.update(self.cb_import_data_from_elem(elem))
            return data

        elif elem.tag == "variable":
            return self.cb_variable_data_from_elem(elem)

        elif elem.tag == "scope":
            ilk = elem.get("ilk")
            if ilk == "blob":
                img = elem.get("lang")
                detail = self.cb_blob_detail_from_elem_and_buf(elem, buf)
            else:
                img = ilk
                attrs = elem.get("attributes", "").split()
                if "private" in attrs:
                    img += "-private"
                elif "protected" in attrs:
                    img += "-protected"
                if ilk == "function":
                    detail = self.cb_function_detail_from_elem(elem)
                elif ilk == "class":
                    detail = self.cb_class_detail_from_elem(elem)
                elif ilk == "interface":
                    detail = self.cb_interface_detail_from_elem(elem)
                elif ilk == "namespace":
                    detail = self.cb_namespace_detail_from_elem(elem)
                elif ilk == "trait":
                    detail = self.cb_trait_detail_from_elem(elem)
                else:  # what else could it be?
                    log.warn("don't know how to get cb detail for '%s' elem",
                             ilk)
                    detail = elem.get("name")

            return {"name": elem.get("name"),
                    "img": img,
                    "detail": detail}
        else:
            return {"name": repr(elem)}


class ImplicitLangIntel(LangIntel):
    def __init__(self, lang, mgr):
        self.lang = lang
        LangIntel.__init__(self, mgr)

    def trg_from_pos(self, buf, pos, implicit=True):
        return None

    def preceding_trg_from_pos(self, buf, pos, curr_pos):
        return None

    def async_eval_at_trg(self, buf, trg, ctlr):
        if _xpcom_:
            trg = UnwrapObject(trg)
            ctlr = UnwrapObject(ctlr)
        ctlr.start(buf, trg)
        ctlr.done("success")


class ParenStyleCalltipIntelMixin(object):
    """A mixin class to implement `curr_calltip_arg_range' for languages
    with parenthesis-style call signatures.
    """
    # A sequence of terminator characters for a calltip region.
    calltip_region_terminators = tuple(']});')

    def calltip_verify_termination(self, accessor, ch, trg_pos, curr_pos):
        """Hook to allow language-specific, context-specific checking."""
        return True

    _parsed_calltip_cache = (
        None, None)  # (<last-calltip>, <last-parsed-calltip>)

    def curr_calltip_arg_range(self, buf, trg_pos, calltip, curr_pos,
                               DEBUG=False):
        """Return that range in the calltip of the "current" arg.
        I.e. what argument is currently being entered.

            "buf" is the buffer object on which this is being done.
            "trg_pos" is the trigger position.
            "calltip" is the full calltip text.
            "curr_pos" is the current position in the buffer.

        Returns a range: (start, end)
        Set `start == -1` to cancel the calltip, i.e. if the entered text
        has closed the call region.

        The default implementation uses:
            self.calltip_region_terminators
        to handle languages with calltip signatures with the following
        characteristics:
        - uses '(' and ')' to bound the argument list (though because of
          support for ';' statement termination, this isn't absolutely
          required)
        - uses a comma to separate arguments
        - basic block delimiters are {}, (), and []

        For example:
            foo()
            blam(a, b)
            range([start,] stop[, step]) -> list of integers
            bar(arg1, *args, **kwargs)
            flash(boom, bang=42)
        """
        # Dev Notes:
        # - Eventually should pass in the trigger to aid in processing.
        # - TODO figure out dependence on buf.comment_styles() and
        #   buf.string_styles()
        accessor = buf.accessor
        if DEBUG:
            print banner("curr_calltip_arg_range")
            print "calltip:\n%s" % indent(calltip)
            print "buffer:\n%s" % indent(markup_text(accessor.text,
                                                     trg_pos=trg_pos,
                                                     pos=curr_pos))

        # Start from the trigger position and walk forward to the current
        # pos: counting args and looking for termination of the calltip
        # region.
        skip_styles = dict(
            (s, True) for s in buf.comment_styles() + buf.string_styles())
        if accessor.style_at_pos(trg_pos-1) in skip_styles:
            skip_styles = {}
        comma_count = 0
        blocks = {
            # Map a block start token to its block end token.
            '(': ')', '[': ']', '{': '}',
        }
        block_stack = []
        p = trg_pos
        for ch, style in accessor.gen_char_and_style(trg_pos, curr_pos):
            if DEBUG:
                print "pos %2d: %r (%2s) --" % (p, ch, style),
            if style in skip_styles:
                if DEBUG:
                    print "skip"
            elif ch in blocks:
                if DEBUG:
                    print "open block"
                block_stack.append(blocks[ch])
            elif block_stack:
                if ch == block_stack[-1]:
                    if DEBUG:
                        print "close block"
                    block_stack.pop()
                elif ch in self.calltip_region_terminators:
                    if DEBUG:
                        print "end of call region: (-1, -1)"
                    return (-1, -1)
                elif DEBUG:
                    print "ignore (in block)"
            elif ch == ',':
                if DEBUG:
                    print "next arg"
                comma_count += 1
            elif ch in self.calltip_region_terminators and \
                    self.calltip_verify_termination(accessor, ch, trg_pos, curr_pos):
                if DEBUG:
                    print "end of call region: (-1, -1)"
                return (-1, -1)
            elif DEBUG:
                print "ignore"
            p += 1

        # Parse the signature from the calltip. If there is no signature
        # then we default to not indicating any arg range.
        if self._parsed_calltip_cache[0] == calltip:
            parsed = self._parsed_calltip_cache[1]
        else:
            parsed = _parse_calltip(calltip, DEBUG)
            self._parsed_calltip_cache = (calltip, parsed)
        if parsed is None:
            if DEBUG:
                print "couldn't parse any calltip: (0, 0)"
            return (0, 0)
        signature, name, args = parsed
        if DEBUG:
            print "parsed calltip:\n  signature:\n%s\n  name:\n%s\n  args:\n%s"\
                  % (indent(signature), indent(name), indent(pformat(args)))

        if not args:
            if DEBUG:
                print "no args in signature: (0, 0)"
            return (0, 0)
        elif comma_count >= len(args):
            # XXX ellipsis
            if DEBUG:
                print "more commas than args: ellipsis?"
            span = args[-1].span  # default to last arg
        else:
            span = args[comma_count].span

        if DEBUG:
            print "curr calltip range (%s, %s):" % (span[0], span[1])
            print indent(signature)
            print "    %s%s" % (' '*span[0], '-'*(span[1]-span[0]))
        return span


class ProgLangTriggerIntelMixin(object):
    """A mixin class to implement `preceding_trg_from_pos' for
    programming languages.

    How do you know if this is appropriate for your language? Write
    some test cases using assertPrecedingTriggerMatches() and see
    if this mixin works for those tests. It works fine for Python and
    Perl, for example.
    """
    # A sequence of characters at which all triggers occur.
    trg_chars = tuple('.(')

    # A sequence of characters at which all calltip triggers occur.
    calltip_trg_chars = tuple('(')

    # A dict of chars at which to always stop backtracking looking
    # for a preceding trigger point.  If no style is given the
    # character alone is sufficient.  Otherwise trigger if the
    # style matches.
    preceding_trg_terminators = {';': None}

    def preceding_trg_from_pos(self, buf, pos, curr_pos,
                               preceding_trg_terminators=None, DEBUG=False):
        accessor = buf.accessor
        if preceding_trg_terminators is None:
            preceding_trg_terminators = self.preceding_trg_terminators
        if DEBUG:
            print banner("preceding_trg_from_pos(pos=%r, curr_pos=%r)"
                         % (pos, curr_pos))
            print indent(markup_text(accessor.text, pos=curr_pos,
                                     start_pos=pos))
            print banner(None, '-')

        # Skip over comments and strings in our checking, unless we are
        # in one of these styles for the whole range. This is so an explicit
        # trigger in a comment (or, e.g., a doc string) will work, but
        # the appearance of small comments or strings in code will not mess
        # things up.
        comment_and_string_styles = dict(
            (s, True) for s in buf.comment_styles() + buf.string_styles())
        skip_styles = {}
        start_style = accessor.style_at_pos(pos-1)
        EOL_CHARS = tuple("\n\r")

        # Limiting simplification: Only backtrack a max of 200 chars.
        # Can increase that if necessary. The problem is detecting a
        # statement boundary backwards in langs like Python and Ruby
        # where you can't rely on ';' (actually
        # `preceding_trg_terminators').
        limit = max(1, pos - 200)

        # First stage. We only consider autocomplete trigger (i.e.
        # trg.form==TRG_FORM_COMPLETION) if within range of the
        # curr_pos. Here "within range" means you don't have to more the
        # cursor to show the autocomplete UI.
        first_stage_limit = curr_pos
        for (char, style) in accessor.gen_char_and_style_back(curr_pos-1,
                                                              limit-1):
            if not isident(char):
                break
            first_stage_limit -= 1
        if DEBUG:
            print "[stage 1] first_stage_limit=%d (prev_ch=%r)"\
                  % (first_stage_limit,
                     (first_stage_limit > 0
                      and accessor.char_at_pos(first_stage_limit-1)
                      or None))
        p = pos
        if p >= first_stage_limit:
            for (prev_ch, prev_style) in accessor.gen_char_and_style_back(p-1,
                                                                          first_stage_limit-2):
                if (not skip_styles and prev_style != start_style
                    # EOLs in comments seem to always be style 0. Don't count
                    # them.
                        and prev_ch not in EOL_CHARS):
                    if DEBUG:
                        print "[stage 1] have seen a style change (%d -> %d), " \
                              "now skipping strings and comments" \
                              % (start_style, prev_style)
                    skip_styles = comment_and_string_styles
                if DEBUG:
                    print "[stage 1] consider pos %2d: prev_ch=%r (%d) --"\
                          % (p, prev_ch, prev_style),
                if prev_style in skip_styles:
                    if DEBUG:
                        print "comment or string, skip it"
                elif self._is_terminating_char(prev_ch, prev_style,
                                               preceding_trg_terminators):
                    if DEBUG:
                        print "in `preceding_trg_terminators': break"
                    return None
                elif prev_ch in self.trg_chars:
                    if DEBUG:
                        print "trigger char, try it"
                    trg = buf.trg_from_pos(p, implicit=False)
                    if trg:
                        if DEBUG:
                            print "[stage 1] %s" % trg
                        return trg
                    p -= 1
                    break
                elif DEBUG:
                    print "not a trigger char, skip it"
                p -= 1
        if DEBUG:
            print "[stage 1] end of possible autocomplete trigger range"

        # Second stage. We only consider calltip triggers now
        # (self.calltip_trg_chars).
        #
        # As well, ignore enclosed paren sections to make sure we are
        # in-range. For example, we shouldn't trigger on "bar(" here:
        #   foo(bar("skip", "this", "arg", "list"), <|>)
        close_paren_count = 0
        for (prev_ch, prev_style) in accessor.gen_char_and_style_back(p-1, limit-2):
            if (not skip_styles and prev_style != start_style
                # EOLs in comments seem to always be style 0. Don't count
                # them.
                    and prev_ch not in EOL_CHARS):
                if DEBUG:
                    print "[stage 2] seen a style change (%d -> %d), now " \
                          "skipping strings and comments" \
                          % (start_style, prev_style)
                skip_styles = comment_and_string_styles

            if DEBUG:
                print "[stage 2] consider pos %2d: prev_ch=%r (%d) --"\
                      % (p, prev_ch, prev_style),
            if prev_style in skip_styles:
                if DEBUG:
                    print "comment or string, skip it"
            elif prev_ch == ')':
                close_paren_count += 1
                if DEBUG:
                    print "close paren: count=%d" % close_paren_count
            elif close_paren_count and prev_ch == '(':
                close_paren_count -= 1
                if DEBUG:
                    print "open paren: count=%d" % close_paren_count
            elif self._is_terminating_char(prev_ch, prev_style,
                                           preceding_trg_terminators):
                if DEBUG:
                    print "in `preceding_trg_terminators': break"
                return None
            elif prev_ch in self.calltip_trg_chars:
                if DEBUG:
                    print "trigger char, try it"
                trg = buf.trg_from_pos(p, implicit=False)
                if trg:
                    if DEBUG:
                        print "[stage 2] %s" % trg
                    return trg
            elif DEBUG:
                print "not a trigger char, skip it"
            p -= 1

        return None

    def _is_terminating_char(self, ch, style, preceding_trg_terminators):
        terminating_style = preceding_trg_terminators.get(ch, -1)
        return terminating_style is None or terminating_style == style


class PythonCITDLExtractorMixin(object):
    """A LangIntel mixin class for
        citdl_expr_from_trg()
    for Python-like syntax.
    """

    # Dictionary of literal types to specific language citdl type.
    # Example for Python: {"string": "str"}
    # Example for JavaScript: {"string": "String"}
    citdl_from_literal_type = {}

    def _citdl_expr_from_pos(self, buf, pos, implicit=False,
                             include_forwards=False, DEBUG=False, trg=None,
                             array_as_attr=False):

        # PERF: Would dicts be faster for all of these?
        WHITESPACE = tuple(" \t\n\r\v\f")
        EOL = tuple("\r\n")
        BLOCKCLOSES = tuple(")}]")
        STOPOPS = tuple("({[,&+-=!^|%/<>;:#@")
        EXTRA_STOPOPS_PRECEDING_IDENT = BLOCKCLOSES  # Might be others.

        # TODO: clean this up for LangIntel-usage
        if implicit:
            skip_styles = buf.implicit_completion_skip_styles
        else:
            skip_styles = buf.completion_skip_styles
        string_styles = buf.string_styles()
        comment_styles = buf.comment_styles()

        # XXX Add sentinel num chars?
        citdl_expr = []
        accessor = buf.accessor
        i = pos

        is_udl_buffer = False
        from codeintel2.udl import UDLBuffer
        if isinstance(buf, UDLBuffer):
            # We need to check for udl transition points and not go beyond the
            # current sub-language, bug 95946.
            is_udl_buffer = True
            udl_lang = buf.lang_from_pos(pos)

        # Move ahead to include forward chars as well
        # We stop when we go out of the expression or when the expression is
        # becomes a multiple fragment, i.e.
        #  'sys.pa<|>th.expanduser' -> 'sys.path'
        if include_forwards:
            buf_length = accessor.length()
            if i < buf_length:
                max_look_ahead = min(buf_length, i+100)
                lastch_was_whitespace = False
                while i < max_look_ahead:
                    ch = accessor.char_at_pos(i)
                    style = accessor.style_at_pos(i)
                    if is_udl_buffer and buf.lang_from_style(style) != udl_lang:
                        if DEBUG:
                            print "UDL boundary at pos %d, changed from %r to %r" % (
                                i, udl_lang, buf.lang_from_style(style))
                        break
                    if ch in WHITESPACE:
                        lastch_was_whitespace = True
                    elif ch in ".)}]" or ch in STOPOPS:
                        break
                    elif lastch_was_whitespace:
                        break
                    else:
                        lastch_was_whitespace = False
                    i += 1
                # Move back to last valid char
                i -= 1
            else:
                i = buf_length - 1
            if DEBUG:
                if i > pos:
                    print "Including chars from pos %d up to %d" % (pos, i)
                else:
                    print "No valid chars forward from pos %d, i now: %d" % (pos, i)

        # Be careful here, we cannot move from code into a comment, but we
        # can be in a comment to begin with.
        first_citdl_expr_style = None
        first_citdl_expr_style_is_comment = False
        while i >= 0:
            ch = accessor.char_at_pos(i)
            style = accessor.style_at_pos(i)
            if is_udl_buffer and buf.lang_from_style(style) != udl_lang:
                if DEBUG:
                    print "UDL boundary at pos %d, changed from %r to %r" % (
                        i, udl_lang, buf.lang_from_style(style))
                break
            if ch in WHITESPACE:
                # drop all whitespace
                while i >= 0:
                    ch = accessor.char_at_pos(i)
                    if ch in WHITESPACE \
                       or (ch == '\\' and accessor.char_at_pos(i+1) in EOL):
                        if DEBUG:
                            print "drop whitespace: %r" % accessor.char_at_pos(i)
                    else:
                        break
                    i -= 1
                # If there are two whitespace-separated words with no .
                # in between we're changing expressions:
                #   if foo<|> and ...
                #   def foo<|>(...
                if i >= 0 and citdl_expr and isident(citdl_expr[-1]) \
                   and ch != '.':
                    if DEBUG:
                        print "stop at non-dot: %r" % ch
                    break
            elif style in string_styles:  # Convert to string
                citdl_type = self.citdl_from_literal_type.get("string")
                if DEBUG:
                    print "found string style, converting to: %s and now " \
                          "finished" % (citdl_type)
                if citdl_type:
                    citdl_expr += reversed(citdl_type)
                break
            elif style in skip_styles:  # drop styles to ignore
                while i >= 0 and accessor.style_at_pos(i) in skip_styles:
                    if DEBUG:
                        print "drop char of style to ignore: %r"\
                              % accessor.char_at_pos(i)
                    i -= 1
            elif ch in STOPOPS or (
                # This check ensures that, for example, we get "foo" instead
                # of "bar()foo" in the following:
                #      bar()
                #      foo<|>.
                citdl_expr and citdl_expr[-1] != '.'
                    and ch in EXTRA_STOPOPS_PRECEDING_IDENT):
                if DEBUG:
                    print "stop at stop-operator %d: %r" % (i, ch)
                break
            elif ch in BLOCKCLOSES:
                if DEBUG:
                    print "found block at %d: %r" % (i, ch)
                citdl_expr.append(ch)

                BLOCKS = {  # map block close char to block open char
                    ')': '(',
                    ']': '[',
                    '}': '{',
                }
                stack = []  # stack of blocks: (<block close char>, <style>)
                stack.append((ch, style, BLOCKS[ch], i))
                i -= 1
                num_lines = 0
                content_styles = []
                while i >= 0:
                    ch = accessor.char_at_pos(i)
                    style = accessor.style_at_pos(i)
                    content_styles.append(style)
                    if DEBUG:
                        print "finding matching brace: ch %r (%s), stack %r"\
                              % (ch, ', '.join(buf.style_names_from_style_num(style)), stack)
                    if ch in EOL:
                        num_lines += 1
                    if num_lines >= 3:
                        if DEBUG:
                            print "stop search for matching brace at 3 line sentinel"
                        break
                    elif ch in BLOCKS and style not in skip_styles:
                        stack.append((ch, style, BLOCKS[ch]))
                    elif ch == stack[-1][2] and style not in skip_styles:
                        # XXX Replace the second test with the following
                        #    when LexPython+SilverCity styling bugs are fixed
                        #    (spurious 'stderr' problem):
                        #       and style == stack[-1][1]:
                        last_frame = stack.pop()
                        if not stack:
                            content_styles.pop()  # Drop the thing that matched
                            if array_as_attr and \
                                    all(style in string_styles for style in content_styles):
                                prop = accessor.text_range(
                                    i + 1, last_frame[3])
                                if DEBUG:
                                    print "Injecting %s" % (prop,)
                                citdl_expr.append(prop)
                            if DEBUG:
                                print "jump to matching brace at %d: %r" % (i, ch)
                            citdl_expr.append(ch)
                            if trg and ch == "(":
                                # save the text in params, in case the completion
                                # needs to special-case things depending on the
                                # argument.
                                params = trg.extra.setdefault("_params", [])
                                params.insert(0, accessor.text_range(
                                    i + 1, last_frame[3]))
                            i -= 1
                            break
                    i -= 1
                else:
                    # Didn't find the matching brace.
                    if DEBUG:
                        print "couldn't find matching brace"
                    raise EvalError("could not find matching brace for "
                                    "'%s' at position %d"
                                    % (stack[-1][0], stack[-1][3]))

            else:
                if DEBUG:
                    style_names = buf.style_names_from_style_num(style)
                    print "add char: %r (%s)" % (ch, ', '.join(style_names))
                if first_citdl_expr_style is None:
                    # Remember the first citdl style we found
                    first_citdl_expr_style = style
                    first_citdl_expr_style_is_comment = style in comment_styles
                elif first_citdl_expr_style != style and \
                    (first_citdl_expr_style_is_comment or
                     style in comment_styles):
                    # We've moved into or out of a comment, let's leave now
                    # Fixes: http://bugs.activestate.com/show_bug.cgi?id=65672
                    break
                citdl_expr.append(ch)
                i -= 1

        citdl_expr.reverse()
        citdl_expr = ''.join(citdl_expr)
        if DEBUG:
            print "return: %r" % citdl_expr
            print banner("done")
        return citdl_expr

    def citdl_expr_from_trg(self, buf, trg):
        """Return a Python CITDL expression preceding the given trigger.

        The expression drops newlines, whitespace, and function call
        arguments -- basically any stuff that is not used by the codeintel
        database system for determining the resultant object type of the
        expression. For example (in which <|> represents the given position):

            GIVEN                       RETURN
            -----                       ------
            foo<|>.                     foo
            foo(bar<|>.                 bar
            foo(bar,blam)<|>.           foo()
            foo(bar,                    foo()
                blam)<|>.
            @foo<|>(                    foo

        If (trg.form == TRG_FORM_DEFN), then it's similar to above, except it
        looks forward to grab additional characters.

            GIVEN                       RETURN
            -----                       ------
            foo<|>.                     foo
            f<|>oo.bar                  foo.bar
            foo(bar<|>.                 bar
            foo(bar,blam)<|>.           foo()
            foo(bar,                    foo().bar
                blam).b<|>ar
        """
        DEBUG = False
        if DEBUG:
            print banner("Python-style citdl_expr_from_trg @ %d" % trg.pos)
        if trg.form == TRG_FORM_DEFN:
            pos = trg.pos
            expr = self._citdl_expr_from_pos(buf, pos, implicit=True, trg=trg,
                                             include_forwards=True, DEBUG=DEBUG)
            if expr:
                # Chop off any trailing "." characters
                return expr.rstrip(".")
            return expr
        else:
            if trg.type == 'array-members':
                # Get everything before the bracket position.
                pos = trg.extra.get('bracket_pos') - 1
            else:
                pos = trg.pos - 2   # skip ahead of the trigger char
            return self._citdl_expr_from_pos(buf, pos, implicit=trg.implicit,
                                             DEBUG=DEBUG, trg=trg)


#---- internal calltip parsing support

class Arg(object):
    def __init__(self):
        self.start = None
        self.end = None
        self.name_chs = []
        self.default_chs = []

    def done(self, p):
        self.end = p

    def append_ch(self, p, ch):
        if not self.name_chs:
            self.start = p
        self.name_chs.append(ch)

    def append_default_ch(self, p, ch):
        self.default_chs.append(ch)

    def __nonzero__(self):
        return operator.truth(self.name_chs)

    def __repr__(self):
        default_str = (self.default
                       and ', default=%r' % self.default
                       or '')
        return "Arg(%r, %s, %s%s)" \
               % (self.name, self.start, self.end, default_str)

    @property
    def name(self):
        return ''.join(self.name_chs)

    @property
    def default(self):
        if self.default_chs:
            return ''.join(self.default_chs)
        else:
            return None

    @property
    def span(self):
        return (self.start, self.end)


def _parse_calltip(calltip, DEBUG=False):
    r"""Parse the given calltip text as follows:

        >>> _parse_calltip('foo(a)\nblam')
        ('foo(a)', 'foo', [Arg('a', 4, 5)])
        >>> _parse_calltip('foo(a, b)')
        ('foo(a, b)', 'foo', [Arg('a', 4, 5), Arg('b', 7, 8)])
        >>> _parse_calltip('foo(a=42)')
        ('foo(a=42)', 'foo', [Arg('a', 4, 8, default='42')])
        >>> _parse_calltip('flash(boom, bang=42)')
        ('flash(boom, bang=42)', 'flash', [Arg('boom', 6, 10), Arg('bang', 12, 19, default='42')])

    Not currently doing anything magical for calltips like these:
        range([start,] stop[, step]) -> list of integers
    """
    signature = calltip.splitlines(0)[0]
    arg_start_pos = signature.find('(')
    if arg_start_pos == -1 or ')' not in signature:
        if DEBUG:
            print "no '(' and ')' in first line of calltip"
        return None
    name = calltip[:arg_start_pos].strip()

    # XXX Should add block skipping.
    # skip_blocks = {
    #    '"': '"',
    #    "'": "'",
    #    "/*": "*/",  # JavaScript comments
    #}

    length = len(signature)
    p = arg_start_pos + 1
    args = [Arg()]
    OPERATOR, ARGUMENT, DEFAULT = range(3)
    WHITESPACE = tuple(" \t[]")
    state = OPERATOR
    while p < length:
        ch = signature[p]
        if ch == ')':
            break  # end of argument region
        elif state == OPERATOR:
            if ch in WHITESPACE:
                pass
            elif ch == ',':
                args[-1].done(p)
                args.append(Arg())
            else:
                state = ARGUMENT
                continue  # do this char again
        elif state == ARGUMENT:
            if ch == ',':
                state = OPERATOR
                continue
            elif ch == '=':
                state = DEFAULT
            else:
                args[-1].append_ch(p, ch)
        elif state == DEFAULT:
            if ch == ',':
                state = OPERATOR
                continue
            else:
                args[-1].append_default_ch(p, ch)
        p += 1
    if not args[-1]:
        del args[-1]
    else:
        args[-1].done(p)
    return (signature, name, args)

########NEW FILE########
__FILENAME__ = lang_css
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""CSS support for CodeIntel"""

import os
from os.path import isfile, isdir, exists, dirname, abspath, splitext, join
import sys
import stat
import string
from cStringIO import StringIO
import logging
import traceback
from pprint import pprint

import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants
from SilverCity.ScintillaConstants import (
    SCE_CSS_DIRECTIVE, SCE_CSS_DOUBLESTRING, SCE_CSS_IDENTIFIER,
    SCE_CSS_IDENTIFIER2, SCE_CSS_OPERATOR, SCE_CSS_SINGLESTRING,
    SCE_CSS_TAG, SCE_CSS_UNKNOWN_IDENTIFIER, SCE_CSS_VALUE,
    SCE_UDL_CSS_COMMENT, SCE_UDL_CSS_DEFAULT, SCE_UDL_CSS_IDENTIFIER,
    SCE_UDL_CSS_NUMBER, SCE_UDL_CSS_OPERATOR, SCE_UDL_CSS_STRING,
    SCE_UDL_CSS_WORD, SCE_UDL_M_STRING, SCE_UDL_M_ATTRNAME, SCE_UDL_M_OPERATOR,
)
from SilverCity import Keywords

from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.util import (OrdPunctLast, make_short_name_dict,
                             makePerformantLogger)
from codeintel2.langintel import LangIntel, ParenStyleCalltipIntelMixin
from codeintel2.udl import UDLBuffer, is_udl_css_style
from codeintel2.accessor import AccessorCache

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- globals
lang = "CSS"
log = logging.getLogger("codeintel.css")
makePerformantLogger(log)
WHITESPACE = tuple(" \t\r\n")  # care about '\v', '\f'?


#---- language support
# Taken from the Scite version 2.0.2 css.properties file
# Silvercity wants the # of wordlists to be the same as the
# number hardwired in the lexer, so that's why there are 5 empty lists.
raw_word_lists = [
    # CSS1 keywords
    """
    background background-attachment background-color background-image
    background-position background-repeat border border-bottom
    border-bottom-width border-color border-left border-left-width
    border-right border-right-width border-style border-top
    border-top-width border-width
    clear color display float font
    font-family font-size font-style font-variant font-weight height
    letter-spacing line-height list-style list-style-image
    list-style-position list-style-type margin margin-bottom margin-left
    margin-right margin-top padding padding-bottom padding-left
    padding-right padding-top text-align text-decoration text-indent
    text-transform vertical-align white-space width word-spacing
    """,
    # CSS pseudo-classes
    """
    active after before first first-child first-letter first-line
    focus hover lang left link right visited
    """,

    # CSS2 keywords
    """
    ascent azimuth baseline bbox border-bottom-color
    border-bottom-style border-collapse border-color border-left-color
    border-left-style border-right-color border-right-style
    border-spacing border-style border-top-color border-top-style
    bottom cap-height caption-side centerline clip content
    counter-increment counter-reset cue cue-after cue-before cursor
    definition-src descent direction elevation empty-cells
    font-size-adjust font-stretch left marker-offset marks mathline
    max-height max-width min-height min-width orphans outline
    outline-color outline-style outline-width overflow page
    page-break-after page-break-before page-break-inside panose-1
    pause pause-after pause-before pitch pitch-range play-during
    position quotes richness right size slope speak speak-header
    speak-numeral speak-punctuation speech-rate src stemh stemv stress
    table-layout text-shadow top topline unicode-bidi unicode-range
    units-per-em visibility voice-family volume widows widths x-height
    z-index
    """,
    # CSS3 Properties
    """
    border-top-left-radius
    border-top-right-radius
    border-bottom-left-radius
    border-bottom-right-radius
    border-radius
    """,
    # Pseudo-elements
    "",
    # Browser-Specific CSS Properties
    "",
    # Browser-Specific Pseudo-classes
    "",
    # Browser-Specific Pseudo-elements
    "",
]


class CSSLexer(Lexer):
    lang = "CSS"

    def __init__(self):
        self._properties = SilverCity.PropertySet()
        self._lexer = SilverCity.find_lexer_module_by_id(
            ScintillaConstants.SCLEX_CSS)
        self._keyword_lists = []
        for i in range(len(raw_word_lists)):
            self._keyword_lists.append(SilverCity.WordList(raw_word_lists[i]))


class _StraightCSSStyleClassifier(object):
    def is_css_style(self, style, accessorCacheBack=None):
        return True

    def is_default(self, style, accessorCacheBack=None):
        return style in self.default_styles

    def is_comment(self, style, accessorCacheBack=None):
        return style in self.comment_styles

    def is_string(self, style, accessorCacheBack=None):
        return style in self.string_styles

    def is_operator(self, style, accessorCacheBack=None):
        return style in self.operator_styles or \
            style == ScintillaConstants.SCE_CSS_IMPORTANT

    def is_identifier(self, style, accessorCacheBack=None):
        return style in self.identifier_styles

    def is_value(self, style, accessorCacheBack=None):
        return style in self.value_styles

    def is_tag(self, style, accessorCacheBack=None):
        return style in self.tag_styles

    def is_class(self, style, accessorCacheBack=None):
        return style in self.class_styles

    def is_number(self, style, accessorCacheBack=None):
        return style in self.number_styles

    @property
    def default_styles(self):
        return (ScintillaConstants.SCE_CSS_DEFAULT, )

    @property
    def comment_styles(self):
        return (ScintillaConstants.SCE_CSS_COMMENT,)

    @property
    def string_styles(self):
        return (ScintillaConstants.SCE_CSS_SINGLESTRING,
                ScintillaConstants.SCE_CSS_DOUBLESTRING)

    @property
    def operator_styles(self):
        return (ScintillaConstants.SCE_CSS_OPERATOR, )

    @property
    def identifier_styles(self):
        return (ScintillaConstants.SCE_CSS_IDENTIFIER,
                ScintillaConstants.SCE_CSS_IDENTIFIER2,
                ScintillaConstants.SCE_CSS_UNKNOWN_IDENTIFIER)

    @property
    def value_styles(self):
        return (ScintillaConstants.SCE_CSS_VALUE,
                ScintillaConstants.SCE_CSS_NUMBER)

    @property
    def tag_styles(self):
        return (ScintillaConstants.SCE_CSS_TAG, )

    @property
    def class_styles(self):
        return (ScintillaConstants.SCE_CSS_CLASS, )

    @property
    def number_styles(self):
        return ()

    @property
    def ignore_styles(self):
        return (ScintillaConstants.SCE_CSS_DEFAULT,
                ScintillaConstants.SCE_CSS_COMMENT)

DebugStatus = False


class _UDLCSSStyleClassifier(_StraightCSSStyleClassifier):
    def is_css_style(self, style, accessorCacheBack=None):
        return is_udl_css_style(style)

    def _is_html_style_attribute(self, ac, style):
        # Check to see if it's a html style attribute
        # Note: We are starting from the html string delimiter, i.e.:
        #   <body style=<|>"abc...
        DEBUG = DebugStatus
        # We may have already found out this is a style attribute, check it
        if getattr(ac, "is_html_style_attribute", False):
            return True
        p, ch, style = ac.getPrecedingPosCharStyle(style,
                                                   ignore_styles=self.ignore_styles)
        if DEBUG:
            print "  _is_html_style_attribute:: Prev style: %d, ch: %r" % (
                  style, ch, )
        if style == SCE_UDL_M_OPERATOR:
            p, ch, style = ac.getPrecedingPosCharStyle(style,
                                                       ignore_styles=self.ignore_styles)
            if style == SCE_UDL_M_ATTRNAME:
                p, name = ac.getTextBackWithStyle(style)
                if DEBUG:
                    print "  _is_html_style_attribute:: HTML Attribute: %r" % (
                          name, )
                if name == "style":
                    # Remember this is a html style attribute
                    ac.is_html_style_attribute = True
                    return True
        return False

    def is_identifier(self, style, accessorCacheBack=None):
        if style not in self.identifier_styles:
            return False

        # Previous style must be operator and one of "{;"
        ac = accessorCacheBack
        if ac is not None:
            DEBUG = DebugStatus
            # DEBUG = True
            pcs = ac.getCurrentPosCharStyle()
            if DEBUG:
                print "  is_identifier:: pcs: %r" % (pcs, )
            try:
                # Check that the preceding character before the identifier
                ppcs = ac.getPrecedingPosCharStyle(pcs[2],
                                                   ignore_styles=self.ignore_styles)
                if DEBUG:
                    print "  is_identifier:: ppcs: %r" % (ppcs, )
                if self.is_operator(ppcs[2]) and ppcs[1] in "{;":
                    return True
                elif ppcs[2] == SCE_UDL_M_STRING and \
                        self._is_html_style_attribute(ac, ppcs[2]):
                    return True
                if DEBUG:
                    print "  is_identifier:: Not an identifier style"
            finally:
                # Reset the accessor back to the current position
                ac.resetToPosition(pcs[0])
        return False

    def is_class(self, style, accessorCacheBack=None):
        ac = accessorCacheBack
        if ac is not None:
            pcs = ac.getCurrentPosCharStyle()
            print "  is_class:: pcs: %r" % (pcs, )
            if self.is_operator(pcs[2]) and pcs[1] in ">.;}{":
                return True
            try:
                DEBUG = DebugStatus
                # Check that the preceding character before the identifier is a
                # "."
                ppcs = ac.getPrecedingPosCharStyle(pcs[2],
                                                   ignore_styles=self.ignore_styles)
                if DEBUG:
                    print "  is_class:: ppcs: %r" % (ppcs, )
                if ppcs[2] in self.identifier_styles:
                    ppcs = ac.getPrecedingPosCharStyle(ppcs[2],
                                                       ignore_styles=self.ignore_styles)
                    if self.is_operator(ppcs[2]) and ppcs[1] == ".":
                        return True
                    elif not is_udl_css_style(ppcs[2]):
                        return True
                # If there is no identifer, may be operator, which is okay
                elif not is_udl_css_style(ppcs[2]) or \
                        (self.is_operator(ppcs[2]) and ppcs[1] in "};"):
                    return True
                if DEBUG:
                    print "  is_class:: Not a class style"
            finally:
                # Reset the accessor back to the current position
                ac.resetToPosition(pcs[0])
        return False

    def is_tag(self, style, accessorCacheBack=None):
        ac = accessorCacheBack
        if ac is not None:
            # Tags follow operators or other tags
            # For use, we'll go back until we find an operator in "}>"
            if style in self.identifier_styles:
                DEBUG = DebugStatus
                p, ch, style = ac.getCurrentPosCharStyle()
                start_p = p
                min_p = max(0, p - 50)
                try:
                    while p > min_p:
                        # Check that the preceding character before the
                        # identifier is a "."
                        p, ch, style = ac.getPrecedingPosCharStyle(style,
                                                                   ignore_styles=self.ignore_styles)
                        if style in self.operator_styles:
                            # Thats good, we get our decision now
                            if ch in "}>":
                                return True
                            elif ch == ",":
                                # Might be following another tag, "div, div",
                                # http://bugs.activestate.com/show_bug.cgi?id=58637
                                continue
                            if DEBUG:
                                print "  is_tag:: Not a tag operator ch: %s" % (ch)
                            return False
                        elif not self.is_css_style(style):
                            if DEBUG:
                                print "  is_tag:: Not a css style: %d, ch: %r" % (style, ch, )
                            if style == SCE_UDL_M_STRING and \
                               self._is_html_style_attribute(ac, style):
                                return False
                            return True
                        elif style not in self.identifier_styles:
                            if DEBUG:
                                print "  is_tag:: Not a tag style, style: %d" % (style)
                            return False
                        # else: # Thats okay, we'll keep going
                finally:
                    # Reset the accessor back to the current position
                    ac.resetToPosition(start_p)
        return False

    @property
    def default_styles(self):
        return (ScintillaConstants.SCE_UDL_CSS_DEFAULT, )

    @property
    def comment_styles(self):
        return (ScintillaConstants.SCE_UDL_CSS_COMMENT,)

    @property
    def string_styles(self):
        return (ScintillaConstants.SCE_UDL_CSS_STRING, )

    @property
    def operator_styles(self):
        return (ScintillaConstants.SCE_UDL_CSS_OPERATOR, )

    @property
    def identifier_styles(self):
        return (ScintillaConstants.SCE_UDL_CSS_IDENTIFIER,
                ScintillaConstants.SCE_UDL_CSS_WORD)

    @property
    def value_styles(self):
        return (ScintillaConstants.SCE_UDL_CSS_WORD,
                ScintillaConstants.SCE_UDL_CSS_IDENTIFIER,
                ScintillaConstants.SCE_UDL_CSS_NUMBER)

    @property
    def tag_styles(self):
        return (ScintillaConstants.SCE_CSS_TAG, )

    @property
    def number_styles(self):
        return (ScintillaConstants.SCE_UDL_CSS_NUMBER, )

    @property
    def ignore_styles(self):
        return (ScintillaConstants.SCE_UDL_CSS_DEFAULT,
                ScintillaConstants.SCE_UDL_CSS_COMMENT)


StraightCSSStyleClassifier = _StraightCSSStyleClassifier()
UDLCSSStyleClassifier = _UDLCSSStyleClassifier()


class CSSLangIntel(LangIntel, ParenStyleCalltipIntelMixin):
    lang = "CSS"

    @LazyClassAttribute
    def CSS_ATTRIBUTES(self):
        # CSS attributes:
        #     key (string) is the css property (attribute) name
        #     value (list) is the possible css property (attribute) values
        from codeintel2 import constants_css3 as constants_css
        from codeintel2 import constants_css_microsoft_extensions
        from codeintel2 import constants_css_moz_extensions
        from codeintel2 import constants_css_webkit_extensions
        attrs = constants_css.CSS_ATTR_DICT.copy()
        attrs.update(
            constants_css_microsoft_extensions.CSS_MICROSOFT_SPECIFIC_ATTRS_DICT)
        attrs.update(constants_css_moz_extensions.CSS_MOZ_SPECIFIC_ATTRS_DICT)
        attrs.update(
            constants_css_webkit_extensions.CSS_WEBKIT_SPECIFIC_ATTRS_DICT)
        return attrs

    @LazyClassAttribute
    def CSS_PROPERTY_NAMES(self):
        # Setup the names triggered for "property-names"
        return sorted(self.CSS_ATTRIBUTES.keys(), key=OrdPunctLast)

    @LazyClassAttribute
    def CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT(self):
        # Calltips for css property attributes
        from codeintel2 import constants_css3 as constants_css
        from codeintel2 import constants_css_microsoft_extensions
        from codeintel2 import constants_css_moz_extensions
        from codeintel2 import constants_css_webkit_extensions
        calltips = constants_css.CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT.copy()
        calltips.update(
            constants_css_microsoft_extensions.CSS_MICROSOFT_SPECIFIC_CALLTIP_DICT)
        calltips.update(
            constants_css_moz_extensions.CSS_MOZ_SPECIFIC_CALLTIP_DICT)
        calltips.update(
            constants_css_webkit_extensions.CSS_WEBKIT_SPECIFIC_CALLTIP_DICT)
        return calltips

    @LazyClassAttribute
    def CSS_HTML_TAG_NAMES(self):
        # Tag names
        return sorted(Keywords.hypertext_elements.split())

    @LazyClassAttribute
    def CSS_PSEUDO_CLASS_NAMES(self):
        # pseudo-class-names
        from codeintel2 import constants_css3 as constants_css
        return sorted(constants_css.CSS_PSEUDO_CLASS_NAMES, key=OrdPunctLast)

    @LazyClassAttribute
    def CSS_AT_RULE_NAMES(self):
        # at rules
        return sorted(
            ["import", "media", "charset", "font-face", "page", "namespace"],
            key=OrdPunctLast)

    def preceding_trg_from_pos(self, buf, pos, curr_pos):
        DEBUG = DebugStatus  # not using 'logging' system, because want to be fast
        # DEBUG = True # not using 'logging' system, because want to be fast

        if DEBUG:
            print "\npreceding_trg_from_pos -- pos: %d, curr_pos: %d" % (
                pos, curr_pos, )
        if isinstance(buf, UDLBuffer):
            styleClassifier = UDLCSSStyleClassifier
        else:
            styleClassifier = StraightCSSStyleClassifier
        ac = AccessorCache(buf.accessor, curr_pos+1, fetchsize=50)
        currTrg = self._trg_from_pos(buf, (curr_pos == pos) and pos or pos+1,
                                     implicit=False, DEBUG=DEBUG,
                                     ac=ac, styleClassifier=styleClassifier)
        if DEBUG:
            print "  currTrg: %r" % (currTrg, )

        # If we're not looking for a previous trigger, or else the current
        # trigger position is for a calltip, then do not look any further.
        if (pos == curr_pos) or (currTrg and currTrg.form == TRG_FORM_CALLTIP):
            return currTrg
        # Else, work our way backwards from pos.

        ac.resetToPosition(pos+1)
        p, ch, style = ac.getPrevPosCharStyle()
        if DEBUG:
            print "  preceding_trg_from_pos: p: %r, ch: %r, style: %r" % (p, ch, style)
        min_p = max(0, p - 200)
        ignore_styles = styleClassifier.comment_styles + \
            styleClassifier.string_styles + \
            styleClassifier.number_styles
        while p > min_p and styleClassifier.is_css_style(style):
            p, ch, style = ac.getPrecedingPosCharStyle(
                style, ignore_styles=ignore_styles, max_look_back=100)
            if DEBUG:
                print "  preceding_trg_from_pos: Trying preceding p: %r, ch: %r, style: %r" % (p, ch, style)
            if ch and (isident(ch) or ch in ":( \t"):
                trg = self._trg_from_pos(buf, p+1, implicit=False, DEBUG=DEBUG,
                                         ac=ac, styleClassifier=styleClassifier)
                if trg is not None:
                    if DEBUG:
                        print "trg: %r" % (trg, )
                    if currTrg is not None:
                        if currTrg.type != trg.type:
                            if DEBUG:
                                print "  Next trigger is a different type, ending search"
                            return None
                        elif currTrg.form != trg.form:
                            return trg
                        elif DEBUG:
                            print "  Found same trigger again, continuing " \
                                  "looking for a different trigger"
                    else:
                        return trg
        return None

    def _trg_from_pos(self, buf, pos, implicit=True, DEBUG=False, ac=None, styleClassifier=None):
        # DEBUG = True # not using 'logging' system, because want to be fast
        if DEBUG:
            print "\n----- CSS _trg_from_pos(pos=%r, implicit=%r) -----"\
                  % (pos, implicit)
        try:
            if pos == 0:
                return None

            if ac is None:
                ac = AccessorCache(buf.accessor, pos, fetchsize=50)
            else:
                ac.resetToPosition(pos)
            # Ensure this variable is initialized as False, it is used by UDL
            # for checking if the css style is inside of a html tag, example:
            #   <p style="mycss: value;" />
            # When it's found that it is such a case, this value is set True
            ac.is_html_style_attribute = False

            last_pos, last_char, last_style = ac.getPrevPosCharStyle()
            if DEBUG:
                print "  _trg_from_pos:: last_pos: %s" % last_pos
                print "  last_char: %r" % last_char
                print "  last_style: %s" % last_style

            # The easy ones are triggering after any of '#.[: '.
            # For speed, let's get the common ' ' out of the way. The only
            # trigger on space is 'complete-property-values'.

            if styleClassifier.is_default(last_style):
                if DEBUG:
                    print "  _trg_from_pos:: Default style: %d, ch: %r" % (last_style, last_char)
                # Move backwards resolving ambiguity, default on "property-
                # values"
                min_pos = max(0, pos - 200)
                while last_pos > min_pos:
                    last_pos, last_char, last_style = ac.getPrevPosCharStyle()
                    if styleClassifier.is_operator(last_style, ac) or styleClassifier.is_value(last_style, ac):
                        if DEBUG:
                            print " _trg_from_pos: space => property-values"
                        return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                                       pos, implicit)
                    elif styleClassifier.is_tag(last_style, ac):
                        if DEBUG:
                            print " _trg_from_pos: space => tag-names"
                        return Trigger("CSS", TRG_FORM_CPLN, "tag-names",
                                       pos, implicit)
                    elif styleClassifier.is_identifier(last_style, ac):
                        if DEBUG:
                            print " _trg_from_pos: space => property-names"
                        return Trigger("CSS", TRG_FORM_CPLN, "property-names",
                                       pos, implicit)
                if DEBUG:
                    print " _trg_from_pos: couldn't resolve space, settling on property-names"
                return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                               pos, implicit)

            elif styleClassifier.is_operator(last_style, ac):
                # anchors
                if DEBUG:
                    print "  _trg_from_pos:: OPERATOR style"
                if last_char == '#':
                    return Trigger("CSS", TRG_FORM_CPLN, "anchors",
                                   pos, implicit)

                elif last_char == ':':
                    try:
                        p, ch, style = ac.getPrevPosCharStyle(
                            ignore_styles=styleClassifier.ignore_styles)
                        if DEBUG:
                            print "  _trg_from_pos:: Looking at p: %d, ch: %r, style: %d" % (p, ch, style)
                    except IndexError:
                        style = None
                    if DEBUG:
                        print "  _trg_from_pos:: style: %r" % (style)
                    if style is None or \
                       not styleClassifier.is_identifier(style, ac):
                    # if style is None or \
                    #   not styleClassifier.is_css_style(style) or \
                    #   styleClassifier.is_class(style, ac):
                        # complete for pseudo-class-names
                        return Trigger(
                            "CSS", TRG_FORM_CPLN, "pseudo-class-names",
                            pos, implicit)
                    else:
                    # if styleClassifier.is_identifier(style, ac):
                        # calltip for property-values
                        return Trigger(
                            "CSS", TRG_FORM_CALLTIP, "property-values",
                            pos, implicit)

                # class-names
                elif last_char == '.':
                    return Trigger("CSS", TRG_FORM_CPLN, "class-names",
                                   pos, implicit)

                # at-rule
                elif last_char == '@':
                    # p, ch, style = ac.getPrevPosCharStyle(ignore_styles=styleClassifier.comment_styles)
                    # XXX - Should check not beyond first rule set
                    #     - Should check not within a rule block.
                    return Trigger("CSS", TRG_FORM_CPLN, "at-rule",
                                   pos, implicit)

                elif last_char == '/':
                    try:
                        p, ch, style = ac.getPrevPosCharStyle()
                    except IndexError:
                        pass
                    else:
                        if ch == "<":
                            # Looks like start of closing '</style>'
                            # tag. While typing this the styling will
                            # still be in the CSS range.
                            return Trigger(buf.m_lang, TRG_FORM_CPLN,
                                           "end-tag", pos, implicit)

            # tag-names
            elif styleClassifier.is_tag(last_style, ac):
                # We trigger on tag names of specified length >= 1 char
                if DEBUG:
                    print "  _trg_from_pos:: TAG style"
                p, ch, style = last_pos, last_char, last_style
                try:
                    while p >= 0:
                        if DEBUG:
                            print "  _trg_from_pos:: Looking at p: %d, ch: %r, style: %d" % (p, ch, style)
                        if not isident(ch):
                            p += 1
                            break
                        elif style != last_style:
                            if DEBUG:
                                print "  _trg_from_pos:: Current style is not a tag: %d" % (style)
                            return None
                        p, ch, style = ac.getPrevPosCharStyle()
                except IndexError:
                    p = 0
                return Trigger("CSS", TRG_FORM_CPLN, "tag-names",
                               p, implicit)

            elif styleClassifier.is_identifier(last_style, ac):
                if DEBUG:
                    print "  _trg_from_pos:: IDENTIFIER style"
                # property-names
                # print "here", accessor.text_range(0, pos)
                # We trigger on identifier names with any length >= 1 char
                pos = last_pos
                while pos >= 0:
                    pos, ch, style = ac.getPrevPosCharStyle()
                    if not isident(ch):
                        break
                    elif style != last_style:
                        return None
                extentLength = last_pos - pos
                # cover ": " following the identifier if it's there (since we
                # add it to the autocomplete in _async_eval_at_trg)
                following_text = ac.text_range(last_pos + 1, last_pos + 3)
                for idx, char in enumerate(": "):
                    try:
                        if following_text[idx] == char:
                            extentLength += 1
                        else:
                            break
                    except IndexError:
                        break
                return Trigger("CSS", TRG_FORM_CPLN, "property-names",
                               pos+1, implicit, extentLength=extentLength)

            elif styleClassifier.is_value(last_style, ac):
                p, ch, style = ac.getPrevPosCharStyle(
                    ignore_styles=styleClassifier.comment_styles)
                if DEBUG:
                    print "  _trg_from_pos:: VALUE style"
                    print "  _trg_from_pos::   p: %s" % p
                    print "  _trg_from_pos::   ch: %r" % ch
                    print "  _trg_from_pos::   style: %s" % style
                    ac.dump()
                # Implicit triggering only happens on a whitespace character
                # after any one of these ":,%) " characters
                # Note: last_char can be a value style yet also be whitespace
                #       in straight CSS.
                if last_char in WHITESPACE:
                    return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                                   last_pos+1, implicit)
                elif ch in WHITESPACE or ch in ":,%)":
                    # Check to ensure this is not a pseudo-class! Bug:
                    #   http://bugs.activestate.com/show_bug.cgi?id=71073
                    if ch == ":":
                        # Last style must be an identifier then!
                        pp, pch, pstyle = ac.getPrevPosCharStyle(
                            ignore_styles=styleClassifier.ignore_styles)
                        if DEBUG:
                            print "pp: %d, pch: %r, pstyle: %d" % (pp, pch,
                                                                   pstyle)
                        if not styleClassifier.is_identifier(pstyle, ac):
                            # This is likely a pseudo-class definition then,
                            # no trigger here.
                            if DEBUG:
                                print "pseudo-class style found, no trigger."
                            return None
                    return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                                   p+1, implicit)
                # For explicit, we can also be inside a property already
                if not implicit and isident(ch):
                    # If there is already part of a value there, we need to move
                    # the trigger point "p" to the start of the value.
                    while isident(ch):
                        p, ch, style = ac.getPrevPosCharStyle()
                    return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                                   p+1, implicit)
                return None

            elif DEBUG:
                print "  _trg_from_pos:: Unexpected style: %d, ch: %r" % (last_style, last_char)

            # XXX "at-property-names" - Might be used later
            # elif last_style == SCE_CSS_DIRECTIVE:
            #    # property-names
            #    # We trigger on identifier names with length == 3
            #    #print "here", accessor.text_range(0, pos)
            #    if pos >= 4 and accessor.char_at_pos(pos - 4) == ' ' and \
            #       self._is_ident_of_length(accessor, pos, length=3):
            #        # We are good for completion
            #        if DEBUG:
            #            print "Got a trigger for 'at-property-names'"
            #        return Trigger("CSS", TRG_FORM_CPLN, "at-property-names",
            #                       pos-3, implicit, extra={"ac": ac})

        except IndexError:
            # Wen't out of range of buffer before we found anything useful
            pass

        if DEBUG:
            print "----- CSS trg_from_pos() -----"
        return None

    def trg_from_pos(self, buf, pos, implicit=True, ac=None):
        DEBUG = DebugStatus  # not using 'logging' system, because want to be fast
        if isinstance(buf, UDLBuffer):
            # This is CSS content in a multi-lang buffer.
            return self._trg_from_pos(buf, pos, implicit, DEBUG, ac, UDLCSSStyleClassifier)
        else:
            return self._trg_from_pos(buf, pos, implicit, DEBUG, ac, StraightCSSStyleClassifier)

    def _async_eval_at_trg(self, buf, trg, ctlr, styleClassifier):
        # Note: Currently this is NOT asynchronous. I believe that is fine
        # as long as evaluation is fast -- because the IDE UI thread could
        # be blocked on this. If processing might be slow (e.g. scanning
        # a number of project files for appropriate anchors, etc.), then
        # this should be made asynchronous.
        DEBUG = DebugStatus
        # DEBUG = True
        if DEBUG:
            print "\n----- async_eval_at_trg(trg=%r) -----"\
                  % (trg)

        # Setup the AccessorCache
        extra = trg.extra
        ac = None
        # print "Extra: %r" % (extra)
        if isinstance(extra, dict):
            extra = extra.get("extra", None)
            if isinstance(extra, dict):
                ac = extra.get("ac", None)
                if ac and DEBUG:
                    print "  _async_eval_at_trg:: Trigger had existing AC"
                    ac.dump()
        if ac is None:
            if DEBUG:
                print "  _async_eval_at_trg:: Created new trigger!"
            ac = AccessorCache(buf.accessor, trg.pos, fetchsize=20)

        ctlr.start(buf, trg)
        pos = trg.pos

        try:
            if trg.id == ("CSS", TRG_FORM_CPLN, "tag-names"):
                if DEBUG:
                    print "  _async_eval_at_trg:: 'tag-names'"
                cplns = self.CSS_HTML_TAG_NAMES
                if DEBUG:
                    print "  _async_eval_at_trg:: cplns:", cplns
                if cplns:
                    ctlr.set_cplns([("element", v) for v in cplns])
                ctlr.done("success")
            elif trg.id == ("CSS", TRG_FORM_CPLN, "anchors"):
                # Can be a colour or an id tag, depending upon what the
                # previous char/style is
                # The previous style must be an op style or alphanumeric ch
                # i = 0
                # max_total_lookback = 100 # Up to 100 chars back
                # while i < max_total_lookback:
                #    p, ch, style = ac.getPrecedingPosCharStyle(last_style,
                #                    ignore_styles=styleClassifier.ignore_styles)
                #    if not is_udl_css_style(style) or \
                #       (styleClassifier.is_operator(style, ac) and \
                #        ch in "};"):
                #    i = last_pos - p
                # XXX - Needs to lookup the project HTML files for anchors...
                # anchors = self._get_all_anchors_names_in_project(accessor)
                ctlr.done("success")
            elif trg.id == ("CSS", TRG_FORM_CPLN, "class-names"):
                # raise NotImplementedError("not yet implemented: completion for "
                #                          "most css triggers")
                ctlr.done("success")
            elif trg.id == ("CSS", TRG_FORM_CPLN, "property-names"):
                cplns = self.CSS_PROPERTY_NAMES
                if cplns:
                    # Note: we add the colon as well - see bug 89913.
                    ctlr.set_cplns([("property", v + ": ") for v in cplns])
                    # We want to show the property values after autocompleting.
                    trg.retriggerOnCompletion = True
                    # print "  _async_eval_at_trg:: cplns:", cplns
                ctlr.done("success")
            elif trg.id == ("CSS", TRG_FORM_CALLTIP, "property-values"):
                property, v1, v2 \
                    = self._extract_css_declaration(ac, styleClassifier, trg,
                                                    is_for_calltip=True)
                if DEBUG:
                    print "  _async_eval_at_trg:: Property name: %r" % \
                        (property, )
                try:
                    calltip = self.CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT[
                        property]
                    if DEBUG:
                        print "  _async_eval_at_trg:: calltip:", calltip
                    ctlr.set_calltips([calltip])
                except KeyError:
                    # print "Unknown CSS property: '%s'" % (property)
                    pass    # Ignore unknown CSS attributes
                ctlr.done("success")
            elif trg.id == ("CSS", TRG_FORM_CPLN, "property-values"):
                property, current_value, values \
                    = self._extract_css_declaration(ac, styleClassifier, trg)
                if DEBUG:
                    print "  _async_eval_at_trg:: XXX property: %r, " \
                          " current_value: %r, values: %r" % (property,
                                                              current_value,
                                                              values)
                try:
                    # print "\ndict:", self.CSS_ATTRIBUTES[property]
                    property_values = sorted(self.CSS_ATTRIBUTES[property],
                                             key=OrdPunctLast)
                    # Check if it matches anything, if not, dismiss the list
                    if current_value:
                        clen = len(current_value)
                        for v in property_values:
                            if clen <= len(v) and current_value == v[:clen]:
                                # Found a match
                                break
                        # Else, return the full list, even though no match made
                        # XXX - May want to cancel the CC list, any way to do
                        # this?
                    cplns = [("value", v)
                             for v in property_values
                             if v not in values or v == current_value]
                    ctlr.set_cplns(cplns)
                except KeyError:
                    if DEBUG:
                        print "  _async_eval_at_trg:: Unknown CSS property: "\
                              "'%s'" % (property)
                    pass    # Ignore unknown CSS attributes
                ctlr.done("success")

                # XXX Handling for property not in list.
            elif trg.id == ("CSS", TRG_FORM_CPLN, "pseudo-class-names"):
                cplns = [("pseudo-class", v)
                         for v in self.CSS_PSEUDO_CLASS_NAMES]
                ctlr.set_cplns(cplns)
                ctlr.done("success")
            elif trg.id == ("CSS", TRG_FORM_CPLN, "at-rule"):
                cplns = [("rule", v)
                         for v in self.CSS_AT_RULE_NAMES]
                ctlr.set_cplns(cplns)
                ctlr.done("success")

            # Punt - Lower priority
            # elif trg.id == ("CSS", TRG_FORM_CPLN, "units"):

            # Punt - Fancy
            # elif trg.id == ("CSS", TRG_FORM_CPLN, "import-url"):

            # Punt - uncommon
            # elif trg.id == ("CSS", TRG_FORM_CPLN, "attr-names"):
            # elif trg.id == ("CSS", TRG_FORM_CPLN, "attr-values"):

            else:
                raise NotImplementedError("not yet implemented: completion for "
                                          "most css triggers: trg.id: %s" % (trg.id,))
        except IndexError:
            # Tried to go out of range of buffer, nothing appropriate found
            if DEBUG:
                print "  _async_eval_at_trg:: ** Out of range error **"
            ctlr.done("success")

    def async_eval_at_trg(self, buf, trg, ctlr):
        if isinstance(buf, UDLBuffer):
            # This is CSS content in a multi-lang buffer.
            return self._async_eval_at_trg(buf, trg, ctlr,
                                           UDLCSSStyleClassifier)
        else:
            return self._async_eval_at_trg(buf, trg, ctlr,
                                           StraightCSSStyleClassifier)

    def _get_all_anchors_names_in_project(self):
        # anchors = []
        # pos = 0
        # LENGTH = accessor.length
        # style = 0
        # func_style_at_pos = accessor.style_at_pos
        # func_char_at_pos = accessor.char_at_pos
        # while pos < LENGTH:
        #    if func_char_at_pos(pos) == '#' and \
        #       func_style_at_pos(pos) == SCE_CSS_OPERATOR:
        #        # Likely an anchor
        #        pass
        #    pos += 1
        # return anchors
        return []

    def _is_ident_of_length(self, accessor, pos, length=3):
        # Fourth char to left should not be an identifier
        if pos > length and isident(accessor.char_at_pos((pos - length) - 1)):
            return False
        # chars to left should all be identifiers
        for i in range(pos - 1, (pos - length) - 1, -1):
            if not isident(accessor.char_at_pos(i)):
                return False
        return True

    def _extract_css_declaration(self, ac, styleClassifier, trg,
                                 is_for_calltip=False):
        """Extract the CSS declaration around the given position.

        Returns a 3-tuple:
            (<property>, <current_value>, <value_list>)

        If is_for_calltip is true, we do not bother to parse out the values, so
        <current_value> and <value_list> will be empty.

        The value gets parsed into <value_list>, a list of individual values.
        Comments and strings are striped from the return value.

        If the <current_value> is '', then the trigger position is
        ready to start a new value.
        """
        DEBUG = DebugStatus
        # DEBUG = True
        # PERF: Use accessor.gen_chars_and_styles() if possible.
        try:
            ac.resetToPosition(trg.pos)
            p, ch, style = ac.getPrevPosCharStyle()
            if not styleClassifier.is_operator(style, ac):
                if DEBUG:
                    print "Current ch is not an operator, so getting the " \
                          "preceeding one, p: %d, ch: %r, style: %d" % \
                          (p, ch, style, )
                p, ch, style = ac.getPrevPosCharStyle(
                    ignore_styles=styleClassifier.ignore_styles)
        except IndexError:
            # This occurs when already at the end of the buffer, so we reset to
            # the last buffer position then
            ac.resetToPosition(trg.pos - 1)
            p, ch, style = ac.getCurrentPosCharStyle()
        if DEBUG:
            print """------ _extract_css_declaration -----"""
            print "  _extract_css_declaration:: Trg.pos: %d" % (trg.pos)
            # ac._debug = True
            print "  _extract_css_declaration:: pos: %r" % (p)
            print "  _extract_css_declaration:: ch: %r" % (ch)
            print "  _extract_css_declaration:: style: %r" % (style)
            ac.dump()
        # Walk back to ':' operator.
        num_close_parenthesis = 0
        min_pos = max(0, trg.pos - 200)  # Lookback up to 200 chars in total
        while p >= min_pos:
            # print "ch: %r, style: %d" % (ch, style, )
            if ch == ':' and styleClassifier.is_operator(style, ac):
                break
            elif num_close_parenthesis > 0:
                if ch == "(":
                    num_close_parenthesis -= 1
                    if DEBUG:
                        print "Found matching open paren," \
                              " num_close_parenthesis now: %d" % (
                                  num_close_parenthesis)
                elif DEBUG:
                    print "Ignoring everything inside the parenthesis"
            elif ch == "(" and (styleClassifier.is_operator(style) or
                                styleClassifier.is_value(style)):
                if DEBUG:
                    print "Already inside a paren, no cpln's then."
                    # XXX SCSS and Less support arithmetic expressions
                return (None, None, None)
            elif ch == ")" and (styleClassifier.is_operator(style) or
                                styleClassifier.is_value(style)):
                num_close_parenthesis += 1
                if DEBUG:
                    print "Found close paren, need to skip over contents," \
                          " num_close_parenthesis: %d" % (
                              num_close_parenthesis)
            elif styleClassifier.is_operator(style):
                if ch not in ":,%":
                    if DEBUG:
                        print "%s: couldn't find ':' operator, found invalid " \
                              "operator: %d %r %d" % (trg.name, p, ch, style)
                    # TODO: SCSS and Less support arithmetic expressions
                    return (None, None, None)
            elif styleClassifier.is_string(style):
                # Used to skip over string items in property values
                if DEBUG:
                    print "Found string style, ignoring it"
            elif not (styleClassifier.is_value(style) or styleClassifier.is_default(style)):
                # old CSS lexer: everything betwee ":" and ';' used to be a
                # value.
                if DEBUG:
                    print "%s: couldn't find ':' operator, found invalid " \
                          "style: pcs: %d %r %d" % (trg.name, p, ch, style)
                return (None, None, None)
            p, ch, style = ac.getPrevPosCharStyle(
                ignore_styles=styleClassifier.ignore_styles)
        else:
            if DEBUG:
                print "%s: couldn't find ':' operator within 200 chars, " \
                      "giving up" % (trg.name)
            return (None, None, None)

        if DEBUG:
            print "  _extract_css_declaration:: Found ':' at pos: %d" % (p)
        # Parse out the property name.
        colan_pos = p
        p, ch, style = ac.getPrecedingPosCharStyle(style,
                                                   ignore_styles=styleClassifier.ignore_styles,
                                                   max_look_back=150)
        if style not in styleClassifier.identifier_styles:
            if DEBUG:
                print "  _extract_css_declaration:: No identifier style found" \
                      " before ':', found style %d instead" % (style)
            return (None, None, None)
        p, property = ac.getTextBackWithStyle(style)
        property = property.strip()

        if is_for_calltip:
            # We have all the info we need
            if DEBUG:
                print "  _extract_css_declaration:: Returning property: %r" % (
                    property)
            return (property, '', [])

        # Walk forward parsing the value information, ends when we hit a ";" or
        # have gone ahead a maximum of 200 chars.
        ac.resetToPosition(colan_pos)
        prev_pos, prev_ch, prev_style = ac.getCurrentPosCharStyle()
        from_pos = prev_pos
        p = colan_pos
        # Value info, list of tuples (pos, text)
        value_info = []
        max_p = p + 200
        try:
            while p < max_p:
                p, ch, style = ac.getNextPosCharStyle(
                    max_look_ahead=100, ignore_styles=styleClassifier.comment_styles)
                if p is None or not styleClassifier.is_css_style(style):
                    # Went past max_look_ahead, just use what we've got then
                    if DEBUG:
                        print "%s: css value reached max length or end of " \
                              "document: trg.pos %d" % (trg.name, trg.pos)
                    value_info.append((from_pos, ac.text_range(from_pos, p)))
                    break

                # Sass test
                if ch == "\n" and self.lang == "Sass" and styleClassifier.is_default(style):
                    value_info.append((from_pos, ac.text_range(from_pos, p)))
                    break
                if ch in WHITESPACE or styleClassifier.is_string(style):
                    if not prev_ch in WHITESPACE and not styleClassifier.is_string(prev_style):
                        value_info.append((
                            from_pos, ac.text_range(from_pos, p)))
                    from_pos = p+1
                elif styleClassifier.is_operator(style):
                    if ch in ";{}":
                        value_info.append((
                            from_pos, ac.text_range(from_pos, p)))
                        break
                    # Other chars should be okay to collect
                elif not styleClassifier.is_value(style) and \
                        style not in styleClassifier.ignore_styles:
                    if DEBUG:
                        print "%s: invalid style found: pos %d, style: %d" % (
                            trg.name, trg.pos, style)
                    return (None, None, None)
                prev_pos, prev_ch, prev_style = p, ch, style
            else:
                if DEBUG:
                    print "%s: css value too long: trg.pos %d" % (trg.name, trg.pos)
                return (None, None, None)
        except IndexError:
            if DEBUG:
                print "ran out of buffer"

        # Work out the values and the current value
        current_value = None
        values = []
        trg_pos = trg.pos
        for p, value in value_info:
            if value and _isident_first_char(value[0]):
                if DEBUG:
                    print "Is a valid value, p: %d, value: %r" % (p, value, )
                values.append(value)
                if current_value is None and trg_pos >= p and \
                   trg_pos <= p + len(value):
                    current_value = value

        if DEBUG:
            print "  _extract_css_declaration:: Returning property: %r, " \
                  "current_value: %r, values: %r" % (property, current_value,
                                                     values)
        return (property, current_value, values)


class CSSBuffer(Buffer):
    lang = "CSS"
    sce_prefixes = ["SCE_CSS_"]
    # Removed '(' - double braces for completions that contain a '(' (bug 80063)
    # Removed '.' - conflict with floating point values: .5em (bug 80126)
    # Removed '{' - gets in way of "rule {" style declarations (bug 82358)
    # Removed '#' - gets in the way of hex colors and id selectors (bug 82968)
    # Removed '>' - gets in the way of child selectors (bug 87403)
    cpln_fillup_chars = " '\";},/"
    cpln_stop_chars = " ('\";{},.>/"


#---- internal support stuff
_ident_chars_dictionary = dict((ch, 1) for ch in
                               string.lowercase + string.uppercase + string.digits + "-")


def _isident_first_char(char):
    return isident(char) and char != "-" and (char < "0" or char > "9")


def isident(char):
    # In CSS2, identifiers  (including element names, classes, and IDs in
    # selectors) can contain only the characters [A-Za-z0-9] and ISO 10646
    # characters 161 and higher, plus the hyphen (-); they cannot start with a
    # hyphen or a digit
    return char in _ident_chars_dictionary or ord(char) >= 161


def _isdigit(char):
    return "0" <= char <= "9"


def _is_udl_css_ident(char):
    return "a" <= char <= "z" or "A" <= char <= "Z" \
        or char == "_" or char == "="


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=CSSLexer(),
                      buf_class=CSSBuffer,
                      langintel_class=CSSLangIntel,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_django
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Django support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.langintel import LangIntel
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin

if _xpcom_:
    from xpcom.server import UnwrapObject

#---- globals

lang = "Django"
log = logging.getLogger("codeintel.django")


django_keywords = [
    "and",
    "as",
    "by",
    "in",
    "not",
    "or",
]

django_tags = [
    "autoescape",
    "block",
    "comment",
    "csrf_token",
    "cycle",
    "debug",
    "else",
    "empty",   # used with for loop
    "extends",
    "filter",
    "firstof",
    "for",
    "if",
    "ifchanged",
    "ifequal",
    "ifnotequal",
    "include",
    "load",
    "now",
    "regroup",
    "spaceless",
    "ssi",
    "templatetag",
    "url",
    "widthratio",
    "with",

    # end tags
    "endautoescape",
    "endblock",
    "endcomment",
    "endfilter",
    "endfor",
    "endif",
    "endifchanged",
    "endifequal",
    "endifnotequal",
    "endspaceless",
    "endwith",

    # Escape keywords
    "openblock",
    "closeblock",
    "openvariable",
    "closevariable",
    "openbrace",
    "closebrace",
]

django_default_filter_names = [
    # These are default filter names in django
    "add",
    "addslashes",
    "capfirst",
    "center",
    "cut",
    "date",
    "default",
    "default_if_none",
    "dictsort",
    "dictsortreversed",
    "divisibleby",
    "escape",
    "escapejs",
    "filesizeformat",
    "first",
    "fix_ampersands",
    "floatformat",
    "get_digit",
    "iriencode",
    "join",
    "last",
    "length",
    "length_is",
    "linebreaks",
    "linebreaksbr",
    "linenumbers",
    "ljust",
    "lower",
    "make_list",
    "phone2numeric",
    "pluralize",
    "pprint",
    "random",
    "removetags",
    "rjust",
    "safe",
    "safeseq",
    "slice",
    "slugify",
    "stringformat",
    "striptags",
    "time",
    "timesince",
    "timeuntil",
    "title",
    "truncatewords",
    "truncatewords_html",
    "unordered_list",
    "upper",
    "urlencode",
    "urlize",
    "urlizetrunc",
    "wordcount",
    "wordwrap",
    "yesno",
]


#---- language support

class DjangoLexer(UDLLexer):
    lang = lang


class DjangoBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    tpl_lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "Django"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    # - wanted for CSS completion: " ('\";},.>"
    # - wanted for JS completion:  "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    # - dropping '-' because causes problem with CSS (bug 78312)
    # - dropping '!' because causes problem with CSS "!important" (bug 78312)
    cpln_stop_chars = "'\" (;},~`@#%^&*()=+{}]|\\;,.<>?/"


class DjangoLangIntel(LangIntel):
    lang = lang

    # Used by ProgLangTriggerIntelMixin.preceding_trg_from_pos()
    trg_chars = tuple('| ')
    calltip_trg_chars = tuple()

    def trg_from_pos(self, buf, pos, implicit=True, DEBUG=False):
        """
            CODE       CONTEXT      RESULT
            '{<|>'     anywhere     tag names, i.e. {% if %}
            'foo|<|>'  filters      filter names, i.e. {{ foo|capfirst }}
        """
        # DEBUG = True # not using 'logging' system, because want to be fast
        if DEBUG:
            print "\n----- Django trg_from_pos(pos=%r, implicit=%r) -----"\
                  % (pos, implicit)

        if pos < 2:
            return None
        accessor = buf.accessor
        last_pos = pos - 1
        last_char = accessor.char_at_pos(last_pos)
        if DEBUG:
            print "  last_pos: %s" % last_pos
            print "  last_char: %r" % last_char
            print 'accessor.text_range(last_pos-2, last_pos): %r' % (accessor.text_range(last_pos-2, last_pos), )

        if last_char == " " and \
           accessor.text_range(last_pos-2, last_pos) == "{%":
            if DEBUG:
                print "  triggered: 'complete-tags'"
            return Trigger(lang, TRG_FORM_CPLN,
                           "complete-tags", pos, implicit)

        if last_char == "|":
            if DEBUG:
                print "  triggered: 'complete-filters'"
            return Trigger(lang, TRG_FORM_CPLN,
                           "complete-filters", pos, implicit)

    _djangotag_cplns = [("element", t) for t in sorted(django_tags)]
    _djangofilter_cplns = [("function", t) for t in sorted(
        django_default_filter_names)]

    def async_eval_at_trg(self, buf, trg, ctlr):
        if _xpcom_:
            trg = UnwrapObject(trg)
            ctlr = UnwrapObject(ctlr)

        ctlr.start(buf, trg)

        # Django tag completions
        if trg.id == (lang, TRG_FORM_CPLN, "complete-tags"):
            ctlr.set_cplns(self._djangotag_cplns)
            ctlr.done("success")
            return
        if trg.id == (lang, TRG_FORM_CPLN, "complete-filters"):
            ctlr.set_cplns(self._djangofilter_cplns)
            ctlr.done("success")
            return

        ctlr.done("success")


class DjangoCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"
    tpl_lang = "Django"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=DjangoLexer(),
                      buf_class=DjangoBuffer,
                      langintel_class=DjangoLangIntel,
                      import_handler_class=None,
                      cile_driver_class=DjangoCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_html
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""HTML support for CodeIntel"""

import os
import sys
import logging
import re
import traceback
from pprint import pprint

from codeintel2.common import *
from codeintel2.langintel import LangIntel
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin
from codeintel2.lang_xml import XMLLangIntel
from HTMLTreeParser import html_optional_close_tags

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- globals
lang = "HTML"
log = logging.getLogger("codeintel.html")


#---- language support
class HTMLLexer(UDLLexer):
    lang = lang


class HTMLLangIntel(XMLLangIntel):
    lang = lang

    def get_valid_tagnames(self, buf, pos, withPrefix=False):
        node = buf.xml_node_at_pos(pos)
        # print "get_valid_tagnames NODE %s:%s xmlns[%s]
        # %r"%(buf.xml_tree.prefix(node),node.localName,node.ns,node.tag)
        handlerclass = buf.xml_tree_handler(node)
        tagnames = None
        if node is not None:  # or not tree.parent(node):
            tagnames = set(handlerclass.tagnames(buf.xml_tree, node))
            while node is not None and node.localName in html_optional_close_tags:
                node = buf.xml_tree.parent(node)
                if node is not None:
                    tagnames = tagnames.union(
                        handlerclass.tagnames(buf.xml_tree, node))
        if not tagnames and hasattr(handlerclass, "dataset"):
            tagnames = handlerclass.dataset.all_element_types()
        if not tagnames:
            return None
        tagnames = list(tagnames)
        tagnames.sort()
        if withPrefix and node is not None:
            prefix = buf.xml_tree.prefix(node)
            if prefix:
                return ["%s:%s" % (prefix, name) for name in tagnames]
        return tagnames

    def cpln_end_tag(self, buf, trg):
        node = buf.xml_node_at_pos(trg.pos)
        if node is None:
            return None
        tagName = buf.xml_tree.tagname(node)
        if not tagName:
            return []

        # here on, we're only working with HTML documents
        line, col = buf.accessor.line_and_col_at_pos(trg.pos)
        names = [tagName]
        # if this is an optional close node, get parents until a node that
        # requires close is found
        while node is not None and node.localName in html_optional_close_tags:
            node = buf.xml_tree.parent(node)
            if node is None:
                break
            if not node.end:
                names.append(buf.xml_tree.tagname(node))
                continue
        return [('element', tagName+">") for tagName in names]


class HTMLBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    m_lang = "HTML"
    csl_lang = "JavaScript"
    css_lang = "CSS"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    # - wanted for CSS completion: " ('\";},.>"
    # - wanted for JS completion:  "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    # - dropping '-' because causes problem with CSS and XML (bug 78312)
    # - dropping '!' because causes problem with CSS "!important" (bug 78312)
    cpln_stop_chars = "'\" ;,~`@#%^&*()=+{}]|\\,.<>?/"


class HTMLCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=HTMLLexer(),
                      buf_class=HTMLBuffer,
                      langintel_class=HTMLLangIntel,
                      cile_driver_class=HTMLCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_html5
#!/usr/bin/env python
# Copyright (c) 2010 ActiveState Software Inc.
# See LICENSE.txt for license details.

"""HTML 5 support for CodeIntel"""

import logging

from codeintel2.common import _xpcom_
from codeintel2.lang_html import HTMLLexer, HTMLLangIntel, HTMLBuffer, HTMLCILEDriver

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- globals

lang = "HTML5"
log = logging.getLogger("codeintel.html5")
# log.setLevel(logging.DEBUG)


#---- language support

class HTML5Lexer(HTMLLexer):
    # This must be defined as "HTML" in order to get autocompletion working.
    lang = "HTML"


class HTML5LangIntel(HTMLLangIntel):
    lang = lang


class HTML5Buffer(HTMLBuffer):
    lang = lang

    # Override the xml_default_dataset_info in order to change the DTD catalog
    # that gets used for HTML completions. The namespace is set through the
    # Komodo prefs system (defaultHTML5Decl and
    # defaultHTML5DeclSystemIdentifier).
    def xml_default_dataset_info(self, node=None):
        if self._xml_default_dataset_info is None:
            import koXMLDatasetInfo
            datasetSvc = koXMLDatasetInfo.getService()
            self._xml_default_dataset_info = (
                datasetSvc.getDefaultPublicId(lang, self.env),
                None,
                datasetSvc.getDefaultNamespace(lang, self.env))
        return self._xml_default_dataset_info


class HTML5CILEDriver(HTMLCILEDriver):
    lang = lang


#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=HTML5Lexer(),
                      buf_class=HTML5Buffer,
                      langintel_class=HTML5LangIntel,
                      cile_driver_class=HTML5CILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_javascript
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""JavaScript support for Code Intelligence

    This is a Language Engine for the Code Intelligence (codeintel) system.
    Code Intelligence XML format. See:
        http://specs.tl.activestate.com/kd/kd-0100.html#xml-based-import-export-syntax-cix


Future ideas and changes for the JavaScript ciler:

  * give anonymous functions a unique identifier, so referencing code
    is able to look up the correct anonymous function.

  * create a class prototype structure

  * separate class prototype variables and functions from the local variables

  * use better push/pop handling
"""

import os
from os.path import splitext, basename, exists, dirname, normpath
import sys
import types
import logging
import operator
from cStringIO import StringIO
import weakref
from glob import glob
from collections import deque

from ciElementTree import Element, ElementTree, SubElement

import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants
from SilverCity.ScintillaConstants import (
    SCE_C_COMMENT, SCE_C_COMMENTDOC, SCE_C_COMMENTDOCKEYWORD,
    SCE_C_COMMENTDOCKEYWORDERROR, SCE_C_COMMENTLINE,
    SCE_C_COMMENTLINEDOC, SCE_C_DEFAULT, SCE_C_IDENTIFIER, SCE_C_NUMBER,
    SCE_C_OPERATOR, SCE_C_STRING, SCE_C_CHARACTER, SCE_C_STRINGEOL, SCE_C_WORD,
    SCE_UDL_CSL_COMMENT, SCE_UDL_CSL_COMMENTBLOCK, SCE_UDL_CSL_DEFAULT,
    SCE_UDL_CSL_IDENTIFIER, SCE_UDL_CSL_NUMBER, SCE_UDL_CSL_OPERATOR,
    SCE_UDL_CSL_REGEX, SCE_UDL_CSL_STRING, SCE_UDL_CSL_WORD,
)

from codeintel2.citadel import CitadelBuffer, ImportHandler, CitadelLangIntel
from codeintel2.buffer import Buffer
from codeintel2.tree_javascript import JavaScriptTreeEvaluator
from codeintel2 import util
from codeintel2.common import *
from codeintel2.indexer import PreloadBufLibsRequest, PreloadLibRequest
from codeintel2.jsdoc import JSDoc, JSDocParameter, jsdoc_tags
from codeintel2.gencix_utils import *
from codeintel2.database.langlib import LangDirsLib
from codeintel2.udl import UDLBuffer, is_udl_csl_style
from codeintel2.accessor import AccessorCache, KoDocumentAccessor
from codeintel2.langintel import (ParenStyleCalltipIntelMixin,
                                  ProgLangTriggerIntelMixin,
                                  PythonCITDLExtractorMixin)

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- globals
lang = "JavaScript"
# Setup the logger
log = logging.getLogger("codeintel.javascript.lang")
# log.setLevel(logging.DEBUG)
# log.setLevel(logging.INFO)
util.makePerformantLogger(log)

# When enabled, will add a specific path attribute to each cix element for where
# this element was originally created from, good for debugging gencix JavaScript
# API catalogs (YUI, ExtJS).
ADD_PATH_CIX_INFO = False
# ADD_PATH_CIX_INFO = True

# States used by JavaScriptScanner when parsing information
S_DEFAULT = 0
S_IN_ARGS = 1
S_IN_ASSIGNMENT = 2
S_IGNORE_SCOPE = 3
S_OBJECT_ARGUMENT = 4

# Types used by JavaScriptScanner when parsing information
TYPE_NONE = 0
TYPE_FUNCTION = 1
TYPE_VARIABLE = 2
TYPE_GETTER = 3
TYPE_SETTER = 4
TYPE_MEMBER = 5
TYPE_OBJECT = 6
TYPE_CLASS = 7
TYPE_PARENT = 8
TYPE_ALIAS = 9


#---- language support
class JavaScriptLexer(Lexer):
    lang = lang

    def __init__(self, mgr):
        self._properties = SilverCity.PropertySet()
        self._lexer = SilverCity.find_lexer_module_by_id(
            ScintillaConstants.SCLEX_CPP)
        jsli = mgr.lidb.langinfo_from_lang(self.lang)
        self._keyword_lists = [
            SilverCity.WordList(' '.join(jsli.keywords)),
            SilverCity.WordList(),
            SilverCity.WordList(),
            SilverCity.WordList(),
            SilverCity.WordList()
        ]


class PureJavaScriptStyleClassifier:
    def __init__(self):
        self.is_udl = False
        self.operator_style = SCE_C_OPERATOR
        self.identifier_style = SCE_C_IDENTIFIER
        self.keyword_style = SCE_C_WORD
        self.comment_styles = (SCE_C_COMMENT,
                               SCE_C_COMMENTDOC,
                               SCE_C_COMMENTLINE,
                               SCE_C_COMMENTLINEDOC,
                               SCE_C_COMMENTDOCKEYWORD,
                               SCE_C_COMMENTDOCKEYWORDERROR)
        self.string_styles = (
            SCE_C_STRING, SCE_C_CHARACTER, SCE_C_STRINGEOL)
        self.whitespace_style = SCE_C_DEFAULT
        self.ignore_styles = self.comment_styles + (self.whitespace_style, )


class UDLJavaScriptStyleClassifier:
    def __init__(self):
        self.is_udl = True
        self.operator_style = SCE_UDL_CSL_OPERATOR
        self.identifier_style = SCE_UDL_CSL_IDENTIFIER
        self.keyword_style = SCE_UDL_CSL_WORD
        self.comment_styles = (SCE_UDL_CSL_COMMENT,
                               SCE_UDL_CSL_COMMENTBLOCK,)
        self.string_styles = (SCE_UDL_CSL_STRING, )
        self.whitespace_style = SCE_UDL_CSL_DEFAULT
        self.ignore_styles = self.comment_styles + (self.whitespace_style, )

pureJSClassifier = PureJavaScriptStyleClassifier()
udlJSClassifier = UDLJavaScriptStyleClassifier()


class JavaScriptLangIntel(CitadelLangIntel,
                          ParenStyleCalltipIntelMixin,
                          ProgLangTriggerIntelMixin,
                          PythonCITDLExtractorMixin):
    lang = lang
    _evaluatorClass = JavaScriptTreeEvaluator
    extraPathsPrefName = "javascriptExtraPaths"

    # The way namespacing is done with variables in JS means that grouping
    # global vars is just annoying.
    cb_group_global_vars = False
    # Define the trigger chars we use, used by ProgLangTriggerIntelMixin
    trg_chars = tuple(".(,@'\" ")
    calltip_trg_chars = tuple('(')   # excluded ' ' for perf (bug 55497)
    # Define literal mapping to citdl member, used in PythonCITDLExtractorMixin
    citdl_from_literal_type = {"string": "String"}

    def cb_variable_data_from_elem(self, elem):
        """Use the 'namespace' image in the Code Browser for a variable
        acting as one.
        """
        data = CitadelLangIntel.cb_variable_data_from_elem(self, elem)
        if len(elem) and data["img"].startswith("variable"):
            data["img"] = data["img"].replace("variable", "namespace")
        return data

    def _functionCalltipTrigger(self, ac, jsClassifier, pos, DEBUG=False):
        # Implicit calltip triggering from an arg separater ",", we trigger a
        # calltip if we find a function open paren "(" and function identifier
        #   http://bugs.activestate.com/show_bug.cgi?id=93864
        if DEBUG:
            print "Arg separater found, looking for start of function, pos: %r" % (pos, )
        ac.getPrevPosCharStyle()
        # Move back to the open paren of the function
        paren_count = 0
        p = pos
        min_p = max(0, p - 100)  # look back max 100 chars
        while p > min_p:
            p, c, style = ac.getPrecedingPosCharStyle(
                ignore_styles=jsClassifier.comment_styles)
            if DEBUG:
                print '  p: %r, ch: %r, st: %d' % (p, c, style)
            loopcount = 0
            while style == jsClassifier.operator_style and loopcount < 10:
                loopcount += 1
                if c == ")":
                    paren_count += 1
                    if DEBUG:
                        print '    paren_count: %r' % (paren_count, )
                elif c == "(":
                    if DEBUG:
                        print '    paren_count: %r' % (paren_count, )
                    if paren_count == 0:
                        # We found the open brace of the func
                        trg_from_pos = p+1
                        p, ch, style = ac.getPrevPosCharStyle()
                        if DEBUG:
                            print "  function start found, pos: %d" % (p, )
                        if style in jsClassifier.ignore_styles:
                            # Find previous non-ignored style then
                            p, c, style = ac.getPrecedingPosCharStyle(
                                style, jsClassifier.ignore_styles)
                        if style == jsClassifier.identifier_style:
                            # Ensure that this isn't a new function
                            # declaration.
                            p, c, style = ac.getPrecedingPosCharStyle(
                                style, jsClassifier.ignore_styles)
                            if style == jsClassifier.keyword_style:
                                p, prev_text = ac.getTextBackWithStyle(
                                    style, jsClassifier.ignore_styles, max_text_len=len("function")+1)
                                if prev_text in ("function", ):
                                    # Don't trigger here
                                    return None
                            return Trigger(lang, TRG_FORM_CALLTIP,
                                           "call-signature",
                                           trg_from_pos, implicit=True)
                        return None
                    else:
                        paren_count -= 1
                elif c in ";{}":
                    # Gone too far and noting was found
                    if DEBUG:
                        print "  no function found, hit stop char: %s at p: %d" % (c, p)
                    return None
                p, c, style = ac.getPrevPosCharStyle()
                if DEBUG:
                    print '  p: %r, ch: %r, st: %d' % (p, c, style)
        # Did not find the function open paren
        if DEBUG:
            print "  no function found, ran out of chars to look at, p: %d" % (p,)
        return None

    def trg_from_pos(self, buf, pos, implicit=True,
                     lang=None):
        DEBUG = False  # not using 'logging' system, because want to be fast
        # DEBUG = True
        # if DEBUG:
        #    print util.banner("JavaScript trg_from_pos(pos=%r, implicit=%r)"
        #                      % (pos, implicit))

        if pos == 0:
            return None

        if lang is None:
            lang = self.lang

        if isinstance(buf, UDLBuffer):
            jsClassifier = udlJSClassifier
        else:
            jsClassifier = pureJSClassifier

        accessor = buf.accessor
        last_pos = pos - 1
        last_char = accessor.char_at_pos(last_pos)
        last_style = accessor.style_at_pos(last_pos)
        if DEBUG:
            print "  last_pos: %s" % last_pos
            print "  last_ch: %r" % last_char
            print "  last_style: %r" % last_style

        if (jsClassifier.is_udl and last_char == '/'
            and last_pos > 0 and accessor.char_at_pos(last_pos-1) == '<'
            and last_style not in (SCE_UDL_CSL_STRING,
                                   SCE_UDL_CSL_COMMENTBLOCK,
                                   SCE_UDL_CSL_COMMENT,
                                   SCE_UDL_CSL_REGEX)):
            # Looks like start of closing '</script>' tag. While typing this
            # the styling will still be in the CSL range.
            return Trigger(buf.m_lang, TRG_FORM_CPLN,
                           "end-tag", pos, implicit)

        # JSDoc completions
        elif last_char == "@" and last_style in jsClassifier.comment_styles:
            # If the preceeding non-whitespace character is a "*" or newline
            # then we complete for jsdoc tag names
            p = last_pos - 1
            min_p = max(
                0, p - 50)      # Don't bother looking more than 50 chars
            if DEBUG:
                print "Checking match for jsdoc completions"
            while p >= min_p and \
                    accessor.style_at_pos(p) in jsClassifier.comment_styles:
                ch = accessor.char_at_pos(p)
                p -= 1
                # if DEBUG:
                #    print "Looking at ch: %r" % (ch)
                if ch == "*" or ch in "\r\n":
                    break
                elif ch not in " \t\v":
                    # Not whitespace, not a valid tag then
                    return None
            else:
                # Nothing found in the specified range
                if DEBUG:
                    print "trg_from_pos: not a jsdoc"
                return None
            if DEBUG:
                print "Matched trigger for jsdoc completion"
            return Trigger(lang, TRG_FORM_CPLN,
                           "jsdoc-tags", pos, implicit)

        # JSDoc calltip
        elif last_char in " \t" and last_style in jsClassifier.comment_styles:
            # whitespace in a comment, see if it matches for jsdoc calltip
            p = last_pos - 1
            min_p = max(
                0, p - 50)      # Don't bother looking more than 50 chars
            if DEBUG:
                print "Checking match for jsdoc calltip"
            ch = None
            ident_found_pos = None
            while p >= min_p and \
                    accessor.style_at_pos(p) in jsClassifier.comment_styles:
                ch = accessor.char_at_pos(p)
                p -= 1
                if ident_found_pos is None:
                    # print "jsdoc: Looking for identifier, at ch: %r" % (ch)
                    if ch in " \t":
                        pass
                    elif _isident(ch):
                        ident_found_pos = p+1
                    else:
                        if DEBUG:
                            print "No jsdoc, whitespace not preceeded by an " \
                                  "identifer"
                        return None
                elif ch == "@":
                    # This is what we've been looking for!
                    jsdoc_field = accessor.text_range(p+2, ident_found_pos+1)
                    if DEBUG:
                        print "Matched trigger for jsdoc calltip: '%s'" % (jsdoc_field, )
                    return Trigger(lang, TRG_FORM_CALLTIP,
                                   "jsdoc-tags", ident_found_pos, implicit,
                                   jsdoc_field=jsdoc_field)
                elif not _isident(ch):
                    if DEBUG:
                        print "No jsdoc, identifier not preceeded by an '@'"
                    # Not whitespace, not a valid tag then
                    return None
            # Nothing found in the specified range
            if DEBUG:
                print "No jsdoc, ran out of characters to look at."

        elif last_char not in self.trg_chars:
            # Check if this could be a 'complete-names' trigger, this is
            # an implicit 3-character trigger i.e. " win<|>" or an explicit
            # trigger on 3 or more characters. We cannot support less than than
            # 3-chars without involving a big penalty hit (as our codeintel
            # database uses a 3-char index).
            if last_pos >= 2 and (last_style == jsClassifier.identifier_style or
                                  last_style == jsClassifier.keyword_style):
                if DEBUG:
                    print "Checking for 'names' three-char-trigger"
                # The previous two characters must be the same style.
                p = last_pos - 1
                min_p = max(0, p - 1)
                citdl_expr = [last_char]
                while p >= min_p:
                    if accessor.style_at_pos(p) != last_style:
                        if DEBUG:
                            print "No 'names' trigger, inconsistent style: " \
                                  "%d, pos: %d" % (accessor.style_at_pos(p), p)
                        break
                    citdl_expr += accessor.char_at_pos(p)
                    p -= 1
                else:
                    # Now check the third character back.
                    # "p < 0" is for when we are at the start of a document.
                    if p >= 0:
                        ac = None
                        style = accessor.style_at_pos(p)
                        if style == last_style:
                            if implicit:
                                if DEBUG:
                                    print "No 'names' trigger, third char " \
                                          "style: %d, pos: %d" % (style, p)
                                return None
                            else:
                                # explicit can be longer than 3-chars, skip over
                                # the rest of the word/identifier.
                                ac = AccessorCache(accessor, p)
                                p, ch, style = ac.getPrecedingPosCharStyle(
                                    last_style,
                                    jsClassifier.ignore_styles,
                                    max_look_back=80)

                        # Now we know that we are three identifier characters
                        # preceeded by something different, which is not that
                        # common, we now need to be a little more cpu-intensive
                        # with our search to ensure we're not preceeded by a
                        # dot ".", as this would mean a different cpln type!

                        if style == jsClassifier.whitespace_style:
                            # Find out what occurs before the whitespace,
                            # ignoring whitespace and comments.
                            if ac is None:
                                ac = AccessorCache(accessor, p)
                            p, ch, style = ac.getPrecedingPosCharStyle(style,
                                                                       jsClassifier.ignore_styles,
                                                                       max_look_back=80)
                        if style is not None:
                            ch = accessor.char_at_pos(p)
                            if ch == ".":
                                if DEBUG:
                                    print "No 'names' trigger, third char " \
                                          "is a dot"
                                return None
                            elif style == jsClassifier.keyword_style:
                                p, prev_text = ac.getTextBackWithStyle(
                                    style, jsClassifier.ignore_styles, max_text_len=len("function")+1)
                                if prev_text in ("function", ):
                                    # We don't trigger after function, this is
                                    # defining a new item that does not exist.
                                    if DEBUG:
                                        print "No 'names' trigger, preceeding "\
                                              "text is 'function'"
                                    return None
                    if DEBUG:
                        print "triggering 'javascript-complete-names' at " \
                              "pos: %d" % (last_pos - 2, )

                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "names", last_pos - 2, implicit,
                                   citdl_expr="".join(reversed(citdl_expr)))
            if DEBUG:
                print "trg_from_pos: no: %r is not in %r" % (
                    last_char, "".join(self.trg_chars), )
            return None

        elif last_style == jsClassifier.operator_style:
            # Go back and check what we are operating on, should be
            # an identifier or a close brace type ")]}".
            p = last_pos - 1
            while p >= 0:
                style = accessor.style_at_pos(p)
                if style == jsClassifier.identifier_style:
                    break
                elif style == jsClassifier.keyword_style and last_char == ".":
                    break
                elif style == jsClassifier.operator_style and \
                        last_char == "." and accessor.char_at_pos(p) in ")]}":
                    break
                elif style in jsClassifier.string_styles:
                    break
                elif style not in jsClassifier.ignore_styles:
                    # Else, wrong style for calltip
                    if DEBUG:
                        print "not a trigger: unexpected style: %d at pos: %d" \
                              % (style, p)
                    return None
                p -= 1
            else:
                # Did not find the necessary style, no completion/calltip then
                return None

            if last_char == ".":
                if style in jsClassifier.string_styles:
                    return Trigger(lang, TRG_FORM_CPLN,
                                   "literal-members", pos, implicit,
                                   citdl_expr="String")
                elif style == jsClassifier.keyword_style:
                    # Check if it's a "this." expression
                    isThis = False
                    if last_pos >= 4:
                        word = []
                        p = last_pos - 1
                        p_end = last_pos - 5
                        while p > p_end:
                            word.insert(0, accessor.char_at_pos(p))
                            p -= 1
                        if "".join(word) == "this":
                            isThis = True
                    if not isThis:
                        return None
                return Trigger(lang, TRG_FORM_CPLN,
                               "object-members", pos, implicit)
            elif last_char in "(,":
                # p is now at the end of the identifier, go back and check
                # that we are not defining a function
                ac = AccessorCache(accessor, p)
                # Implicit calltip triggering from an arg separater ","
                #   http://bugs.activestate.com/show_bug.cgi?id=93864
                if implicit and last_char == ',':
                    return self._functionCalltipTrigger(ac, jsClassifier, p, DEBUG)
                # Get the previous style, if it's a keyword style, check that
                # the keyword is not "function"
                prev_pos, prev_char, prev_style = ac.getPrecedingPosCharStyle(
                    jsClassifier.identifier_style, jsClassifier.ignore_styles)
                if prev_style == jsClassifier.keyword_style:
                    p, prev_text = ac.getTextBackWithStyle(
                        prev_style, jsClassifier.ignore_styles, max_text_len=len("function")+1)
                    if prev_text in ("function", ):
                        # Don't trigger here
                        return None
                return Trigger(lang, TRG_FORM_CALLTIP,
                               "call-signature", pos, implicit)

        elif last_style in jsClassifier.string_styles and last_char in "\"'":
            prev_pos = last_pos - 1
            prev_char = accessor.char_at_pos(prev_pos)
            if prev_char != '[':
                prev_style = accessor.style_at_pos(prev_pos)
                ac = AccessorCache(accessor, prev_pos)
                if prev_style in jsClassifier.ignore_styles:
                    # Look back further.
                    prev_pos, prev_char, prev_style = ac.getPrevPosCharStyle(
                        ignore_styles=jsClassifier.ignore_styles)
            if prev_char == '[':
                # We're good to go.
                if DEBUG:
                    print "Matched trigger for array completions"
                return Trigger(lang, TRG_FORM_CPLN,
                               "array-members", pos, implicit,
                               bracket_pos=prev_pos, trg_char=last_char)

        return None

    def preceding_trg_from_pos(self, buf, pos, curr_pos,
                               preceding_trg_terminators=None, DEBUG=False):
        DEBUG = False
        if DEBUG:
            print "pos: %d" % (pos, )
            print "ch: %r" % (buf.accessor.char_at_pos(pos), )
            print "curr_pos: %d" % (curr_pos, )

        # Check if we can match on either of the 3-character trigger or on the
        # normal preceding_trg_terminators.

        # Try the default preceding_trg_from_pos handler
        if pos != curr_pos and self._last_trg_type == "names":
            # The last trigger type was a 3-char trigger "names", we must try
            # triggering from the same point as before to get other available
            # trigger types defined at the same poisition or before.
            trg = ProgLangTriggerIntelMixin.preceding_trg_from_pos(
                self, buf, pos+2, curr_pos, preceding_trg_terminators,
                DEBUG=DEBUG)
        else:
            trg = ProgLangTriggerIntelMixin.preceding_trg_from_pos(
                self, buf, pos, curr_pos, preceding_trg_terminators,
                DEBUG=DEBUG)

        # Now try the 3-char trigger, if we get two triggers, take the closest
        # match.
        names_trigger = None
        if isinstance(buf, UDLBuffer):
            jsClassifier = udlJSClassifier
        else:
            jsClassifier = pureJSClassifier

        style = None
        if pos > 0:
            accessor = buf.accessor
            if pos == curr_pos:
                # We actually care about whats left of the cursor.
                pos -= 1
            style = accessor.style_at_pos(pos)
            if style in (jsClassifier.identifier_style, jsClassifier.keyword_style):
                ac = AccessorCache(accessor, pos)
                prev_pos, prev_ch, prev_style = ac.getPrecedingPosCharStyle(
                    style)
                if prev_style is not None and (pos - prev_pos) > 3:
                    # We need at least 3 character for proper completion
                    # handling.
                    names_trigger = self.trg_from_pos(
                        buf, prev_pos + 4, implicit=False)

        if DEBUG:
            print "trg: %r" % (trg, )
            print "names_trigger: %r" % (names_trigger, )
            print "last_trg_type: %r" % (self._last_trg_type, )

        if names_trigger:
            if not trg:
                trg = names_trigger
            # Two triggers, choose the best one.
            elif trg.pos == names_trigger.pos:
                if self._last_trg_type != "names":
                    # The names trigger gets priority over the other trigger
                    # types, unless the previous trigger was also a names trg.
                    trg = names_trigger
            elif trg.pos < names_trigger.pos:
                trg = names_trigger

        elif trg is None and style in jsClassifier.comment_styles:
            # Check if there is a JSDoc to provide a calltip for, example:
            #       /** @param foobar {sometype} This is field for <|>
            if DEBUG:
                print "\njs preceding_trg_from_pos::jsdoc: check for calltip"
            comment = accessor.text_range(max(0, curr_pos-200), curr_pos)
            at_idx = comment.rfind("@")
            if at_idx >= 0:
                if DEBUG:
                    print "\njs preceding_trg_from_pos::jsdoc: contains '@'"
                space_idx = comment[at_idx:].find(" ")
                if space_idx >= 0:
                    # Trigger after the space character.
                    trg_pos = (curr_pos - len(
                        comment)) + at_idx + space_idx + 1
                    if DEBUG:
                        print "\njs preceding_trg_from_pos::jsdoc: calltip at %d" % (trg_pos, )
                    trg = self.trg_from_pos(buf, trg_pos, implicit=False)

        if trg:
            self._last_trg_type = trg.type
        return trg

    _jsdoc_cplns = [("variable", t) for t in sorted(jsdoc_tags)]

    def async_eval_at_trg(self, buf, trg, ctlr):
        if _xpcom_:
            trg = UnwrapObject(trg)
            ctlr = UnwrapObject(ctlr)
        ctlr.start(buf, trg)

        # JSDoc completions
        if trg.id == (self.lang, TRG_FORM_CPLN, "jsdoc-tags"):
            # TODO: Would like a "javadoc tag" completion image name.
            ctlr.set_cplns(self._jsdoc_cplns)
            ctlr.done("success")
            return

        # JSDoc calltip
        elif trg.id == (self.lang, TRG_FORM_CALLTIP, "jsdoc-tags"):
            # TODO: Would like a "javadoc tag" completion image name.
            jsdoc_field = trg.extra.get("jsdoc_field")
            if jsdoc_field:
                # print "jsdoc_field: %r" % (jsdoc_field, )
                calltip = jsdoc_tags.get(jsdoc_field)
                if calltip:
                    ctlr.set_calltips([calltip])
            ctlr.done("success")
            return

        if trg.type == "literal-members":
            # We could leave this to citdl_expr_from_trg, but this is a
            # little bit faster, since we already know the citdl expr.
            citdl_expr = trg.extra.get("citdl_expr")
        elif trg.type == "names":
            # We could leave this to citdl_expr_from_trg, but since we already
            # know the citdl expr, use it.
            citdl_expr = trg.extra.get("citdl_expr")
        else:
            try:
                citdl_expr = self.citdl_expr_from_trg(buf, trg)
            except CodeIntelError, ex:
                ctlr.error(str(ex))
                ctlr.done("error")
                return
        line = buf.accessor.line_from_pos(trg.pos)
        evalr = self._evaluatorClass(ctlr, buf, trg, citdl_expr, line)
        buf.mgr.request_eval(evalr)

    def _extra_dirs_from_env(self, env):
        extra_dirs = set()
        include_project = env.get_pref("codeintel_scan_files_in_project", True)
        if include_project:
            proj_base_dir = env.get_proj_base_dir()
            if proj_base_dir is not None:
                extra_dirs.add(proj_base_dir)  # Bug 68850.
        for pref in env.get_all_prefs(self.extraPathsPrefName):
            if not pref:
                continue
            extra_dirs.update(d.strip() for d in pref.split(os.pathsep)
                              if exists(d.strip()))
        if extra_dirs:
            log.debug("%s extra lib dirs: %r", self.lang, extra_dirs)
            max_depth = env.get_pref("codeintel_max_recursive_dir_depth", 10)
            # Always include common JS associations - bug 91915.
            js_assocs = env.assoc_patterns_from_lang("JavaScript")
            if self.lang != "JavaScript":
                # Add any language specific associations.
                js_assocs = set(js_assocs)
                js_assocs.update(env.assoc_patterns_from_lang(self.lang))
                js_assocs = list(js_assocs)
            extra_dirs = tuple(
                util.gen_dirs_under_dirs(extra_dirs,
                                         max_depth=max_depth,
                                         interesting_file_patterns=js_assocs)
            )

            # TODO Why doesn't it pick-up the value in the setting file???

            exclude_patterns = env.get_pref("codeintel_scan_exclude_dir", {"JavaScript": ["/build/"]}).get(self.lang)
            if not exclude_patterns is None:
                for p in exclude_patterns:
                    extra_dirs = [d for d in extra_dirs if not re.search(p, d)]

        else:
            extra_dirs = ()  # ensure retval is a tuple
        return extra_dirs

    def _get_stdlibs_from_env(self, env=None):
        return [self.mgr.db.get_stdlib(self.lang)]

    def libs_from_buf(self, buf):
        env = buf.env

        # A buffer's libs depend on its env and the buf itself so
        # we cache it on the env and key off the buffer.
        if "javascript-buf-libs" not in env.cache:
            env.cache["javascript-buf-libs"] = weakref.WeakKeyDictionary()
        cache = env.cache["javascript-buf-libs"]  # <buf-weak-ref> -> <libs>

        if buf not in cache:
            env.add_pref_observer(self.extraPathsPrefName,
                                  self._invalidate_cache_and_rescan_extra_dirs)
            env.add_pref_observer("codeintel_selected_catalogs",
                                  self._invalidate_cache)
            env.add_pref_observer("codeintel_max_recursive_dir_depth",
                                  self._invalidate_cache)
            env.add_pref_observer("codeintel_scan_files_in_project",
                                  self._invalidate_cache)
            env.add_pref_observer("codeintel_scan_exclude_dir",
                                  self._invalidate_cache)

            db = self.mgr.db
            libs = []

            # - extradirslib
            extra_dirs = self._extra_dirs_from_env(env)
            if extra_dirs:
                libs.append(db.get_lang_lib(self.lang, "extradirslib",
                                            extra_dirs))

            # Warn the user if there is a huge number of import dirs that
            # might slow down completion.
            num_import_dirs = len(extra_dirs)
            if num_import_dirs > 100:
                msg = "This buffer is configured with %d %s import dirs: " \
                      "this may result in poor completion performance" % \
                      (num_import_dirs, self.lang)
                self.mgr.report_message(msg, "\n".join(extra_dirs))

            if buf.lang == self.lang:
                # - curdirlib (before extradirslib; only if pure JS file)
                cwd = dirname(normpath(buf.path))
                if cwd not in extra_dirs:
                    libs.insert(0, db.get_lang_lib(
                        self.lang, "curdirlib", [cwd]))

            # - cataloglibs
            if buf.lang == "HTML5":
                # Implicit HTML 5 catalog additions.
                libs.append(db.get_catalog_lib("JavaScript", ["html5"]))
            catalog_selections = env.get_pref("codeintel_selected_catalogs")
            libs.append(db.get_catalog_lib(self.lang, catalog_selections))

            # - stdlibs
            libs += self._get_stdlibs_from_env(env)

            cache[buf] = libs
        return cache[buf]

    def _invalidate_cache(self, env, pref_name):
        if "javascript-buf-libs" in env.cache:
            log.debug("invalidate 'javascript-buf-libs' cache on %r", env)
            del env.cache["javascript-buf-libs"]

    def _invalidate_cache_and_rescan_extra_dirs(self, env, pref_name):
        self._invalidate_cache(env, pref_name)
        extra_dirs = self._extra_dirs_from_env(env)
        if extra_dirs:
            extradirslib = self.mgr.db.get_lang_lib(
                self.lang, "extradirslib", extra_dirs)
            request = PreloadLibRequest(extradirslib)
            self.mgr.idxr.stage_request(request, 1.0)

    def lpaths_from_blob(self, blob):
        """Return <lpaths> for this blob
        where,
            <lpaths> is a set of externally referencable lookup-paths, e.g.
                [("YAHOO",), ("YAHOO", "util"), ...]

        Note: The jury is out on whether this should include imports.
        However, currently this is only being used for JS (no imports)
        so it doesn't yet matter.
        """
        return set(lpath for child in blob
                   for lpath in _walk_js_symbols(child))

    def citdl_expr_from_trg(self, buf, trg):
        """Return a CITDL expression preceding the given trigger.  This is the
        JavaScript specialization; all it does is set array_as_attr to True.
        """
        DEBUG = False
        if trg.form != TRG_FORM_DEFN:
            if trg.type == 'array-members':
                # Get everything before the bracket position.
                pos = trg.extra.get('bracket_pos') - 1
            else:
                pos = trg.pos - 2   # skip past the trigger char
            return self._citdl_expr_from_pos(buf, pos, implicit=trg.implicit,
                                             DEBUG=DEBUG, trg=trg,
                                             array_as_attr=True)

        return PythonCITDLExtractorMixin.citdl_expr_from_trg(self, buf, trg)


class JavaScriptBuffer(CitadelBuffer):
    lang = lang

    # Fillup chars for JavaScript: basically, any non-identifier char.
    # XXX - '@' removed in order to better support XPCOM completions:
    #           Components.interfaces['@mozilla.]
    #       Whilst not an ideal solution, as when the '.' is hit we run into the
    #       same problem again... the ideal solution would be to override the
    #       cpln_fillup_chars to be only "\"'" for the 'array-members' trigger
    #       event. But this is not yet possible...
    # - dropped ' ' It gets in the way of common usage: "var " (bug 77950).
    cpln_fillup_chars = "~`!#%^&*()-=+{}[]|\\;:'\",.<>?/"
    cpln_stop_chars = "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ "
    sce_prefixes = ["SCE_C_"]

    cb_show_if_empty = True

    def __init__(self, *args, **kwargs):
        CitadelBuffer.__init__(self, *args, **kwargs)

        if isinstance(self.accessor, KoDocumentAccessor):
            # Encourage the database to pre-scan dirs relevant to completion
            # for this buffer -- because of recursive-dir-include-everything
            # semantics for JavaScript this first-time scan can take a while.
            request = PreloadBufLibsRequest(self)
            self.mgr.idxr.stage_request(request, 1.0)

    @property
    def libs(self):
        return self.langintel.libs_from_buf(self)

    @property
    def stdlib(self):
        return self.libs[-1]

    def scoperef_from_blob_and_line(self, blob, line):
        """Return the scope for the given position in this buffer.

            "line" is 1-based.

        See CitadelBuffer.scoperef_from_pos() for details.
        JavaScript has two differences here:
        - <variable>'s are scopes if they have child tags. This CIX
          technique is used in JavaScript to define customized object
          instances.
        - Currently a JavaScript "class" line range may not include its
          methods in some cases.
            function Foo() {
            }
            Foo.prototype.bar = function() {
            }
          Class "Foo" has a line range that does not include method "bar".
          c.f. test javascript/cpln/intermixed_class_definitions
        """
        DEBUG = False
        if DEBUG:
            print "scoperef_from_pos: look for line %d in %r" % (line, blob)

        best_fit_lpath = None
        for scope, lpath in _walk_js_scopes(blob):
            start = int(scope.get("line"))
            # JS CIX <scope> should alway have lineend. The default is
            # because JS <variable>'s with content (i.e. anonymous
            # custom Object instances) do not typically have lineend.
            # Note: not sure the fallback is correct.
            end = int(scope.get("lineend", start))
            if DEBUG:
                print "scoperef_from_pos:    scope %r (%r-%r)?"\
                      % (scope, start, end),
            if line < start:
                if DEBUG:
                    print "no, before start"
                continue
            elif line > end:
                if DEBUG:
                    print "no, after end"
                continue
            elif line <= end:
                if DEBUG:
                    print "yes, could be"
                best_fit_lpath = lpath
            else:
                if DEBUG:
                    print "no, passed end"
                if best_fit_lpath is not None:
                    break
        if best_fit_lpath is not None:
            return (blob, best_fit_lpath)
        else:
            return (blob, [])


class JavaScriptImportHandler(ImportHandler):

    # The file extensions that this import handler will use when importing.
    import_file_extensions = (".js", )
    ignore_file_extensions = (".min.js", "-min.js", ".pkg.js", "-pkg.js", )

    def setCorePath(self, compiler=None, extra=None):
        self.corePath = []

    def _findScannableFiles(self, (files, searchedDirs), dirname, names):
        if sys.platform.startswith("win"):
            cpath = dirname.lower()
        else:
            cpath = dirname
        if cpath in searchedDirs:
            while names:
                del names[0]
            return
        else:
            searchedDirs[cpath] = 1
        for i in range(len(names)-1, -1, -1):  # backward so can del from list
            path = os.path.join(dirname, names[i])
            if os.path.isdir(path):
                pass
            elif names[i].endswith(self.import_file_extensions) and not names[i].endswith(self.ignore_file_extensions):
                # XXX The list of extensions should be settable on
                #    the ImportHandler and Komodo should set whatever is
                #    set in prefs.
                # XXX This check for files should probably include
                #    scripts, which might likely not have the
                #    extension: need to grow filetype-from-content smarts.
                files.append(path)

    def find_importables_in_dir(self, dir):
        """See citadel.py::ImportHandler.find_importables_in_dir() for
        details.

        Importables for JavaScript look like this:
            {"foo.js":  ("foo.js", None, False),
             "somedir": (None,     None, True)}

        TODO: log the fs-stat'ing a la codeintel.db logging.
        """
        from os.path import join, isdir, splitext

        if dir == "<Unsaved>":
            # TODO: stop these getting in here.
            return {}

        # TODO: log the fs-stat'ing a la codeintel.db logging.
        try:
            names = os.listdir(dir)
        except OSError, ex:
            return {}
        dirs, nondirs = set(), set()
        for name in names:
            try:
                if isdir(join(dir, name)):
                    dirs.add(name)
                else:
                    nondirs.add(name)
            except UnicodeDecodeError:
                # Hit a filename that cannot be encoded in the default encoding.
                # Just skip it. (Bug 82268)
                pass

        importables = {}
        for name in nondirs:
            base, ext = splitext(name)
            if not name.endswith(self.import_file_extensions) or name.endswith(self.ignore_file_extensions):
                continue
            if base in dirs:
                importables[base] = (name, None, True)
                dirs.remove(base)
            else:
                importables[base] = (name, None, False)
        for name in dirs:
            importables[name] = (None, None, True)

        return importables


class JavaScriptCILEDriver(CILEDriver):
    lang = lang

    def scan_purelang(self, buf):
        # print >> sys.stderr, buf.path
        log.info("scan_purelang: path: %r lang: %s", buf.path, buf.lang)
        norm_path = buf.path
        if sys.platform == "win32":
            # CIX requires a normalized path.
            norm_path = norm_path.replace('\\', '/')
        mtime = "XXX"
        jscile = JavaScriptCiler(self.mgr, norm_path, mtime, lang=buf.lang)
        # Profiling code: BEGIN
        # import hotshot, hotshot.stats
        # profiler = hotshot.Profile("%s.prof" % (__file__))
        # profiler.runcall(jscile.scan_puretext, buf.accessor.text)
        # Profiling code: END
        jscile.scan_puretext(buf.accessor.text)

        tree = createCixRoot()
        jscile.convertToElementTreeFile(tree, file_lang=self.lang)

        return tree

    def scan_multilang(self, buf, csl_cile_driver=None):
        """Given the buffer, scan the buffer tokens for CSL UDL tokens."""

        # print >> sys.stderr, buf.path
        log.info("scan_multilang: path: %r lang: %s", buf.path, buf.lang)

        norm_path = buf.path
        if sys.platform == "win32":
            # CIX requires a normalized path.
            norm_path = norm_path.replace('\\', '/')
        # XXX Remove mtime when move to CIX 2.0.
        mtime = "XXX"
        jscile = JavaScriptCiler(self.mgr, norm_path, mtime)

        jscile.setStyleValues(wordStyle=SCE_UDL_CSL_WORD,
                              identiferStyle=SCE_UDL_CSL_IDENTIFIER,
                              operatorStyle=SCE_UDL_CSL_OPERATOR,
                              stringStyles=(SCE_UDL_CSL_STRING, ),
                              numberStyle=SCE_UDL_CSL_NUMBER,
                              commentStyles=jscile.UDL_COMMENT_STYLES)
        for token in buf.accessor.gen_tokens():
            # The tokens can be a generator of mixed UDL tokens (CSL, SSL, CSS
            # etc.). Need to parse out the tokens that are not CSL.
            if is_udl_csl_style(token['style']):
                jscile.token_next(**token)
        # Ensure we take notice of any text left in the ciler
        jscile._endOfScanReached()
        # We've parsed up the JavaScript, fix any variables types
        jscile.cile.updateAllScopeNames()

        tree = createCixRoot()
        jscile.convertToElementTreeFile(
            tree, file_lang=buf.lang, module_lang=self.lang)
        return tree

    def scan_csl_tokens(self, file_elem, blob_name, csl_tokens):
        """csl_tokens are pure JavaScript UDL tokens.

        There is no need to parse out other types of tokens.
        """

        # print >> sys.stderr, file_elem.get("path")
        log.info("scan_csl_tokens: %r", file_elem.get("path"))
        blob_elem = createCixModule(file_elem, blob_name, lang,
                                    src=file_elem.get("path"))
        jscile = JavaScriptCiler(self.mgr)
        jscile.setStyleValues(wordStyle=SCE_UDL_CSL_WORD,
                              identiferStyle=SCE_UDL_CSL_IDENTIFIER,
                              operatorStyle=SCE_UDL_CSL_OPERATOR,
                              stringStyles=(SCE_UDL_CSL_STRING, ),
                              numberStyle=SCE_UDL_CSL_NUMBER,
                              commentStyles=jscile.UDL_COMMENT_STYLES)
        for csl_token in csl_tokens:
            jscile.token_next(**csl_token)
        # Ensure we take notice of any text left in the ciler
        jscile._endOfScanReached()
        # We've parsed up the JavaScript, fix any variables types
        jscile.cile.updateAllScopeNames()
        jscile.convertToElementTreeModule(blob_elem)


# Everything is JS is an object.... MUMUHAHAHAHAHAHAAAA.......

class JSObject:
    def __init__(self, name, parent, lineno, depth, type=None,
                 doc=None, isLocal=False, isHidden=False, path=None, pos=None):
        self.name = name
        self.parent = parent
        self.cixname = self.__class__.__name__[2:].lower()
        self.line = lineno
        self.lineend = -1
        self.depth = depth
        self.type = type
        self.path = path
        self.pos = pos  # Used for argument positions - 0 indexed.
        self._class = None  # Used when part of a class
        self.classes = {}  # declared sub-classes
        self.members = {}  # all private member variables used in class
        self.variables = {}  # all variables used in class
        self.functions = {}
        self.anonymous_functions = []  # anonymous functions declared in scope
        self.attributes = []    # Special attributes for object
        self.returnTypes = []    # List of possible return values
        self.constructor = None
        self.classrefs = []
        self.doc = doc
        self.metadata = None
        self.isHidden = isHidden  # Special case, should not be output to cix
        if isLocal:
            # XXX: TODO: It may be appropriate to just use private..., although
            #            my feeling of the difference between the two names
            #            is that private elements should still be listed in
            #            completions from the class itself, whereas local
            #            should not...
            #
            # Local has a special meaning within the javascript tree evaluator,
            # elements with a "__local__" attribute will not be included in js
            # codeintel completion results.
            self.attributes.append("__local__")
            # Private has a special meaning within the code browser,
            # an element with a "private" attribute shows a small lock icon.
            # Private also has special meaning for jsdoc purposes, where it
            # means not to show documentation for these elements.
            self.attributes.append("private")

        self.doc = doc
        self.jsdoc = None
        if self.doc:
            # Turn the doc list into a JSDoc object
            self.jsdoc = JSDoc("".join(self.doc))

    def setParent(self, parent):
        # Validate the parent/child relationship. This is to avoid possible
        # recursion errors - bug 85481.
        seen_scopes = [self]
        parent_scope = parent
        while parent_scope:
            if parent_scope in seen_scopes:
                raise CodeIntelError("setParent:: recursion error, scope: %r, "
                                     "parent: %r" % (self.name, parent_scope.name))
            seen_scopes.append(parent_scope)
            parent_scope = parent_scope.parent
        self.parent = parent

    def getFullPath(self):
        if self.parent:
            return self.parent.getFullPath() + [self.name]
        return [self.name]

    def addAttribute(self, attr):
        if attr not in self.attributes:
            self.attributes.append(attr)

    def removeAttribute(self, attr):
        while attr in self.attributes:
            self.attributes.remove(attr)

    def hasChildren(self):
        return self.variables or self.functions or self.classes or self.members

    def isAnonymous(self):
        return self.name.startswith("(anonymous")

    def addClassRef(self, baseclass):
        assert isinstance(baseclass, (
            str, unicode)), "baseclass %r is not a str" % (baseclass,)
        if baseclass not in self.classrefs:
            self.classrefs.append(baseclass)

    def _mergeVariables(self, existingvar, newvar):
        # If there is no citdl type yet, assign it the given type
        if newvar.type and not existingvar.type:
            log.debug(
                "marging VAR:%s, setting type: %r", existingvar.name, newvar.type)
            existingvar.type = newvar.type
        # TODO: We could choose the simpler type, i.e. if types were "foo" or
        #       "int", then we should choose "int" as it's a base JS type.
        # if newvar.type and newvar.type != existingvar.type:
        #    print "  %r existing type: %r,  new type: %r" % (existingvar.name, existingvar.type, newvar.type)
        # See if the locality has changed - bug 93726.
        if "__file_local__" in existingvar.attributes and \
           not "__file_local__" in newvar.attributes:
            existingvar.removeAttribute("__file_local__")
            # This should be the main definition of this variable - so prefer
            # other fields (like citdl) too.
            if newvar.type:
                existingvar.type = newvar.type

    def addVariable(self, name, value=None, metadata=None):
        """Add a variable in this scope (possibly as a property)
        @param name {unicode} The name of the variable
        @param value {JSObject} The value of the variable
        @param metadata {dict} Extra metadata about the assignment
        @returns {JSObject} The resulting variable (possibly different from
                |value| if one with the given |name| exists)
        """
        v = self.variables.get(name, None)
        if v is None:
            v = self.members.get(name, None)
        if v is None:
            log.info("VAR:%s, line:%d, type:%r, scope:%r, meta:%r",
                     name, value.line, value.type, self.name, metadata)
            v = value
            self.variables[name] = v
        else:
            self._mergeVariables(v, value)
        if metadata:
            if v.metadata is None:
                v.metadata = metadata
            else:
                v.metadata.update(metadata)
        return v

    def addMemberVariable(self, name, value):
        """Add a member variable to this object
        @param name {unicode} The name of the member
        @param value {JSObject} The value to add
        @returns {JSObject} The resulting member (possibly different from
                |value| if one with the given |name| exists)
        """
        assert isinstance(value, JSObject), \
            "addMemberVariable: bad value%r" % (value,)
        v = self.members.get(name, None)
        if v is None:
            v = self.variables.get(name, None)
        if v is None:
            log.info("CLASSMBR: %r, in %s %r", name, self.cixname, self.name)
            self.members[name] = v = value
        else:
            self._mergeVariables(v, value)
        return v

    def getReturnType(self):
        """Get the JS return type for this function, JSDoc gets precedence."""
        bestType = None
        if self.jsdoc and self.jsdoc.returns:
            bestType = self.jsdoc.returns.paramtype
        elif len(self.returnTypes) > 0:
            d = {}
            bestCount = 0
            bestType = None
            for rtype in self.returnTypes:
                if isinstance(rtype, (str, unicode)):
                    count = d.get(rtype, 0) + 1
                    d[rtype] = count
                    if count > bestCount:
                        bestType = rtype
        if bestType:
            bestType = standardizeJSType(bestType)
        return bestType

    def __repr__(self):
        return "\n".join(self.outline())

    def outline(self, depth=0):
        result = []
        if self.cixname == "function":
            s = "%s%s %s(%s)" % (
                " " * depth, self.cixname, self.name, ", ".join(self.args))
            r = self.getReturnType()
            if r:
                s += " => %s" % (r, )
            result.append(s)
        elif self.cixname == "class" and self.classrefs:
            result.append("%s%s %s [%s]" % (
                " " * depth, self.cixname, self.name, self.classrefs))
        elif self.cixname == "variable" and (self.type or (self.jsdoc and self.jsdoc.type)):
            result.append("%s%s %s [%s]" % (" " * depth, self.cixname, self.name, self.type or (
                self.jsdoc and self.jsdoc.type)))
        else:
            result.append("%s%s %s" % (" " * depth, self.cixname, self.name))
        for attrname in ("classes", "members", "functions", "variables"):
            d = getattr(self, attrname, {})
            for v in d.values():
                result += v.outline(depth + 2)
        return result

    def toElementTree(self, cixelement):
        if not self.name:
            log.info("%s has no name, line: %d, ignoring it.",
                     self.cixname, self.line)
            return None
        if self.cixname == "function":
            cixobject = createCixFunction(cixelement, self.name)
        elif self.cixname in ("object", "variable"):
            cixobject = createCixVariable(cixelement, self.name)
        elif self.cixname in ("class"):
            cixobject = createCixClass(cixelement, self.name)
        # else:
        #    print "self.cixname: %r" %(self.cixname)

        cixobject.attrib["line"] = str(self.line)
        if self.lineend >= 0:
            cixobject.attrib["lineend"] = str(self.lineend)
        if ADD_PATH_CIX_INFO and self.path:
            cixobject.attrib["path"] = self.path

        jsdoc = self.jsdoc
        if jsdoc:
            # print "jsdoc: %r" % (jsdoc)
            # the docstring
            # docElem.text = self.doc
            attributeDocs = []
            if jsdoc.isDeprecated():
                attributeDocs.append("DEPRECATED")
                self.attributes.append("deprecated")
            if jsdoc.isPrivate():
                attributeDocs.append("PRIVATE")
                if "private" not in self.attributes:
                    self.attributes.append("private")
            if jsdoc.isStatic():
                attributeDocs.append("STATIC")
                if "__static__" not in self.attributes:
                    self.attributes.append("__static__")
            if jsdoc.isConstant():
                attributeDocs.append("CONSTANT")
                if "constant" not in self.attributes:
                    self.attributes.append("constant")
            if jsdoc.isConstructor():
                attributeDocs.append("CONSTRUCTOR")
                if "__ctor__" not in self.attributes:
                    self.attributes.append("__ctor__")
            if jsdoc.is__local__():
                attributeDocs.append("__LOCAL__")
                if "__local__" not in self.attributes:
                    self.attributes.append("__local__")
            if jsdoc.tags:
                cixobject.attrib["tags"] = jsdoc.tags
            if jsdoc.doc:
                if attributeDocs:
                    setCixDoc(cixobject, "%s: %s" % (
                        " ".join(attributeDocs), jsdoc.doc))
                else:
                    setCixDoc(cixobject, jsdoc.doc)

        # Additional one-off attributes
        if self.attributes:
            cixobject.attrib["attributes"] = " ".join(self.attributes)

        # Additional meta-data.
        if self.metadata:
            for key, value in self.metadata.items():
                cixobject.attrib[key] = value

        # Add the type information, JSDoc overrides whatever the ciler found
        if jsdoc and jsdoc.type:
            # Convert the value into a standard name
            addCixType(cixobject, standardizeJSType(jsdoc.type))
        elif self.type:
            assert isinstance(self.type, (str, unicode)), \
                "self.type %r is not a str" % (self.type)
            addCixType(cixobject, standardizeJSType(self.type))

        if isinstance(self, JSFunction):
            signature = "%s(" % (self.name)
            # Add function arguments
            if self.args:
                signature += ", ".join(self.args)
                # Add function arguments to tree
            # Add signature - calltip
            signature += ")"
            cixobject.attrib["signature"] = signature
            # Add return type for functions, JSDoc gets precedence
            returnType = self.getReturnType()
            if returnType:
                addCixReturns(cixobject, returnType)

            # Add a "this" member for class functions
            if self._class:
                createCixVariable(cixobject, "this", vartype=self._class.name)
            elif self.parent and self.parent.cixname in ("object", "variable"):
                createCixVariable(cixobject, "this", vartype=self.parent.name)

        if self.cixname == "class":
            for baseclass in self.classrefs:
                addClassRef(cixobject, baseclass)
        if self.jsdoc and self.jsdoc.baseclasses:
            for baseclass in self.jsdoc.baseclasses:
                if baseclass not in self.classrefs:
                    addClassRef(cixobject, baseclass)

        # Note that arguments must be kept in the order they were defined.
        variables = self.variables.values()
        arguments = [x for x in variables if isinstance(x, JSArgument)]
        variables = [x for x in variables if not isinstance(x, JSArgument)]
        allValues = sorted(arguments, key=operator.attrgetter("pos", "name")) + \
            sorted(self.functions.values() + self.members.values() +
                   self.classes.values() + variables +
                   self.anonymous_functions,
                   key=operator.attrgetter("line", "name"))

        # If this is a variable with child elements, yet has a citdl type of
        # something that is not an "Object", don't bother to adding these child
        # elements, as we will just go with what the citdl information holds.
        # http://bugs.activestate.com/show_bug.cgi?id=78484
        # Ideally the ciler should include this information and have the tree
        # handler combine the completions from the citdl and also the child
        # elements, but this is not yet possible.
        if allValues and self.cixname == 'variable' and \
           cixobject.get("citdl") and cixobject.get("citdl") not in ("Object", "require()"):
            log.info("Variable of type: %r contains %d child elements, "
                     "ignoring them.", cixobject.get("citdl"), len(allValues))
            return None

        # Sort and include contents
        for v in allValues:
            if not v.isHidden:
                v.toElementTree(cixobject)

        return cixobject


class JSVariable(JSObject):
    def __init__(self, name, parent, line, depth, vartype='', doc=None,
                 isLocal=False, path=None, pos=None):
        if isinstance(vartype, list):
            vartype = ".".join(vartype)
        JSObject.__init__(self, name, parent, line, depth, type=vartype,
                          doc=doc, isLocal=isLocal, path=path, pos=pos)


class JSAlias(JSVariable):
    """An alias, which is a simple assignment from a variable (or possibly a
    class)."""
    def __init__(self, *args, **kwargs):
        """Initialize the alias
        @param target {list of unicode} The type name expression (e.g. ["Array"]
                or ["window", "document"]) to alias to
        @param scope {JSObject} The scope in which the assignment takes place,
                used to resolve the target
        @see JSVariable.__init__ - all other arguments are inherited
        """
        target = kwargs.pop("target", None)
        assert target is not None, "JSAlias requires a target= keyword argument"
        scope = kwargs.pop("scope", None)
        assert scope is not None, "JSAlias requires a scope= keyword argument"
        JSVariable.__init__(self, *args, **kwargs)
        self.cixname = "variable"
        self.target = target
        self.scope = scope


class JSArgument(JSVariable):
    """An argument for a function (or constructor)"""
    def __init__(self, *args, **kwargs):
        JSVariable.__init__(self, *args, **kwargs)
        self.cixname = "variable"
        if not self.type and ENABLE_HEURISTICS:
            if self.name == 'event':  # assume that variables named event are Events
                log.debug(
                    "JSArgument: assuming argument named event is a Event")
                self.type = "Event"

    def outline(self, depth=0):
        result = []
        if self.type or (self.jsdoc and self.jsdoc.type):
            result.append("%sargument %s [%s]" % (
                " " * depth, self.name, self.type or (self.jsdoc and self.jsdoc.type)))
        else:
            result.append("%sargument %s" % (" " * depth, self.name))
        for attrname in ("classes", "members", "functions", "variables"):
            d = getattr(self, attrname, {})
            for v in d.values():
                result += v.outline(depth + 2)
        return result

    def toElementTree(self, *args, **kwargs):
        cixelement = JSVariable.toElementTree(self, *args, **kwargs)
        if cixelement is not None:
            cixelement.attrib["ilk"] = "argument"
        return cixelement


class JSFunction(JSObject):
    """A JavaScript function"""
    def __init__(self, funcname, parent, args, lineno, depth=0, doc=None,
                 isLocal=False, isHidden=False, path=None):
        """Initialize the function
        @param funcname {unicode} The name of the function
        @param parent {JSObject} The parent scope
        @param args {JSArgs} The arguments to the function
        @param lineo {int} The line the function starts at
        @param depth {int}
        @param doc {list of unicode} Documentation comment for the function
        @param isLocal {bool} Whether this function is local
        @param isHidden {bool} Whether this function should be hidden (not
            output into the cix file)
        @param path {list of unicode} The path to the function
        """
        # funcname: string
        # args: list (or None)
        JSObject.__init__(self, funcname, parent, lineno, depth,
                          doc=doc, isLocal=isLocal, isHidden=isHidden, path=path)
        if isinstance(parent, JSClass):
            self._class = parent
        self._parent_assigned_vars = []
        self._callers = set()
        self.args = list(args or [])
        for pos, arg in enumerate(self.args):
            self.addVariable(
                arg, JSArgument(name=arg, parent=self, line=lineno,
                                depth=depth, pos=pos))

    ##
    # @rtype {string or JSObject} add this possible return type
    def addReturnType(self, rtype):
        self.returnTypes.append(rtype)

    def addCaller(self, caller, pos, line):
        """Add caller information to this function"""
        if isinstance(caller, (list, tuple)):
            caller = ".".join(caller)
        self._callers.add((pos, caller, line))

    def toElementTree(self, cixelement):
        if self.jsdoc:
            # fix up argument info from jsdoc
            for jsdocParam in self.jsdoc.params:
                var = self.variables.get(jsdocParam.paramname)
                if isinstance(var, JSArgument):
                    var.type = standardizeJSType(jsdocParam.paramtype)
                    # fake a JSDoc (since it's already all parsed)
                    var.jsdoc = JSDoc()
                    var.jsdoc.doc = jsdocParam.doc
        cixobject = JSObject.toElementTree(self, cixelement)
        if not cixobject:
            return cixobject
        for pos, caller, line in self._callers:
            SubElement(cixobject, "caller", citdl=caller,
                       pos=str(pos), line=str(line), attributes="__hidden__")
        return cixobject


class JSClass(JSObject):
    """A JavaScript class object (a function with a non-default .prototype)"""
    def __init__(self, name, parent, lineno, depth, doc=None, path=None):
        """Initialize the class
        @see JSObject.__init__
        """
        JSObject.__init__(
            self, name, parent, lineno, depth, doc=doc, path=path)
        self.constructor = name


class JSFile:
    """CIX specifies that a <file> tag have zero or more <module> children.
    In JavaScript this is a one-to-one relationship, so this class represents both
    (and emits the XML tags for both).
    """
    def __init__(self, path, mtime=None):
        self.path = path
        self.name = os.path.basename(path)
        self.parent = None
        self.cixname = self.__class__.__name__[2:].lower()
        # XXX Drop mtime when move to CIX 2.0.
        if mtime is None:
            mtime = "XXX"
        self.mtime = mtime

        self.functions = {}  # functions declared in file
        self.anonymous_functions = []  # anonymous functions declared in file
        self.classes = {}  # classes declared in file
        self.variables = {}  # all variables used in file

    def __repr__(self):
        return "\n".join(self.outline())

    def getFullPath(self):
        return [self.name]

    def isAnonymous(self):
        return False

    def outline(self):
        result = ["File: %r" % (self.name)]
        for attrname in ("classes", "functions", "variables"):
            d = getattr(self, attrname, {})
            for v in d.values():
                result += v.outline(2)
        return result

    def hasChildren(self):
        return self.variables or self.functions or self.classes

    def _findScopeWithName(self, name, scopeStack, type="variables"):
        """Find a object somewhere on the given scope stack with the given name
        @param name {unicode} The name to look for
        @param scopeStack {list of JSObject} The scope stack, with the outermost
                (and therefore last searched) scope at the lowest index
        @param type {str} The type of property to look for, e.g. "variables",
                "classs", "functions"
        @returns {JSObject or None} The object found, or None
        """
        if not name:
            return None
        log.debug("_findScopeWithName: %r with name:%r in scopeStack:%r",
                  type, name, scopeStack[-1].name)
        # Work up the scope stack looking for the name
        # for scopePos in range(len(scope) - 1, -1, -1):
        #    currentScope = scope[scopePos]
        for scopePos in range(len(scopeStack) - 1, -1, -1):
            currentScope = scopeStack[scopePos]
            # print "Looking in scope %r" % (currentScope.name)
            # print "Looking in %s: %r" % (currentScope.__class__.__name__,
            #                             currentScope.name)
            namesDict = getattr(currentScope, type, None)
            if namesDict:
                foundScope = namesDict.get(name)
                if foundScope:
                    log.debug("Found %r in scope:%r(%s)", name,
                              currentScope.name, currentScope.cixname)
                    return foundScope
        log.debug("NO scope found for: %r", name)
        return None

    def _lookupVariableType(self, varType, jsobject, scopeStack, depth=0):
        """Resolves a variable type string to a JSObject representing a well-
                known JavaScript type
        @param varType {str} The type to look up as a dot-separated string, e.g.
                "Foo.Bar.baz" or "Array"
        @param jsobject {JSObject} The starting JSObject candidate (in case
                varType is well-known)
        @param scopeStack {list} The scope stack, with the outermost (and
                therefore last searched) scope at the lowest index
        @param depth {int} (For internal use to prevent deep recursion)
        @returns {JSObject or None} The variable type, or None
        """
        # print "Looking for varType:%r in scope:%r" % (varType,
        # scopeStack[-1].name)
        assert not varType or isinstance(varType, (str, unicode)), \
            "varType %r is not a string" % varType
        if depth < 10 and varType:
            # Don't look any further if it's a known type
            if varType.lower() in known_javascript_types:
                return jsobject
            sp = varType.split(".")
            # print "sp: %r" % (sp)
            namePos = 0
            while namePos < len(sp):
                name = sp[namePos]
                # print "sp[%d]: %r" % (namePos, name)
                foundScope = self._findScopeWithName(
                    name, scopeStack, type="variables")
                alternateScopeStack = scopeStack
                while foundScope and isinstance(foundScope, JSArgument) and \
                        not foundScope.type and foundScope.parent in alternateScopeStack:
                    log.debug("found untyped argument %r on %r, trying next",
                              foundScope.name, foundScope.parent.name)
                    alternateScopeStack[alternateScopeStack.index(
                        foundScope.parent):] = []
                    foundScope = self._findScopeWithName(
                        name, alternateScopeStack, type="variables")
                if not foundScope:
                    # print "Trying member variables"
                    # Then look for a class members with this name
                    foundScope = self._findScopeWithName(
                        name, scopeStack, type="members")
                    # if foundScope:
                    #    print "Found a member variable with this name"
                if not foundScope:
                    # Then look for a class with this name
                    # print "Trying class"
                    foundScope = self._findScopeWithName(
                        name, scopeStack, type="classes")
                    if foundScope:
                        # print "Found a class with this name"
                        # Only search this scope now
                        scopeStack.append(foundScope)
                if not foundScope:
                    break  # returns None
                # print "Found scope"
                if isinstance(foundScope, JSVariable):
                    # print "Recursively searching scope"
                    assert foundScope.type is None or isinstance(foundScope.type, (str, unicode)), \
                        "foundScope %r has invalid type %r" % (
                            foundScope, foundScope.type)
                    foundScope = self._lookupVariableType(
                        foundScope.type, foundScope, scopeStack, depth+1)
                # return self._lookupVariableType(foundType, scopeStack)
                namePos += 1
            # print "Returning: %s" % foundScope
            return foundScope
        return None
        # print "jsobject:%r" % (jsobject)
        # print "jsobject.type:%r" % (jsobject.type)

    def _lookupVariableTypes(self, jstypelist, scopeStack):
        """Work out variable types according to their namespace
        @param jstypelist {list of JSObject} The list of types that shold be
            examined
        @param scopeStack {list} The scope stack, with the outermost (and
            therefore last searched) scope at the lowest index
        @returns {None}
        """

        for jstype in jstypelist:
            if hasattr(jstype, "classes"):
                # Recursive lookup for the class variables
                self._lookupVariableTypes(
                    jstype.classes.values(), scopeStack + [jstype])
            if hasattr(jstype, "functions"):
                # Recursive lookup for the function variables
                self._lookupVariableTypes(
                    jstype.functions.values(), scopeStack + [jstype])
            if hasattr(jstype, "variables"):
                for jsvariable in jstype.variables.values():
                    varType = jsvariable.type
                    if varType:
                        actualType = self._lookupVariableType(
                            varType, jsvariable, scopeStack + [jstype])
                        if actualType and actualType != jsvariable:
                            if isinstance(actualType, JSVariable) and not actualType.hasChildren():
                                log.debug(
                                    "variable %r: replacing type %r with %r",
                                    jsvariable.name, jsvariable.type, actualType.type)
                                jsvariable.type = actualType.type
                            else:
                                log.debug(
                                    "variable %r: replacing type %r with %r",
                                    jsvariable.name, jsvariable.type, actualType.name)
                                jsvariable.type = actualType.name
            # Lookup function return type values
            if isinstance(jstype, JSFunction):
                for i in range(len(jstype.returnTypes)):
                    returnType = jstype.returnTypes[i]
                    # print "Looking up function return type: %r" %
                    # (returnType, )
                    if isinstance(returnType, (str, unicode)):
                        actualType = self._lookupVariableType(
                            returnType, jstype, scopeStack + [jstype])
                        if actualType and actualType != jstype:
                            # print "actualType: %r" % (actualType, )
                            # Use the variable name if it's type is "Object"
                            if isinstance(actualType, JSVariable) and \
                               actualType.type != "Object":
                                # print "ActualType is: %r" % (actualType.type)
                                jstype.returnTypes[i] = actualType.type
                            else:
                                # print "ActualType is: %r" % (actualType.name)
                                jstype.returnTypes[i] = actualType.name

    def _updateClassConstructors(self, jsobject):
        """Recursively update the class constructor name of the given class
        @param jsobject {list of JSObject} The JSClasses (or things things
            containing the JSClasses) to find constructors to mark as ctors
        """
        if isinstance(jsobject, JSClass):
            if jsobject.constructor:
                jsfunc = self._findScopeWithName(
                    jsobject.constructor, [jsobject], type='functions')
                if jsfunc and "__ctor__" not in jsfunc.attributes:
                    log.debug(
                        "Making function:%r the constructor for class:%r",
                        jsfunc.name, jsobject.name)
                    jsfunc.attributes.append("__ctor__")
        allObjects = jsobject.functions.values() + jsobject.classes.values() + \
            jsobject.variables.values()
        if not isinstance(jsobject, JSFile):
            allObjects += jsobject.members.values()
        for subobj in allObjects:
            self._updateClassConstructors(subobj)

    def updateAllScopeNames(self):
        """We've gathered as much information as possible, update all scope
        names as best as possible."""

        log.info("****************************************")
        log.info("Finished scanning, updating all scope names")
        self._lookupVariableTypes([self], [])
        log.info("Updating all class constructor names")
        self._updateClassConstructors(self)

    def addVariable(self, name, value=None, metadata=None):
        """Add the given variable to this file
        @see JSObject.addVariable
        """
        assert value is not None, "no value given"
        v = self.variables.get(name, None)
        if v is None:
            log.info(
                "VAR: %s on line %d, type:%r (class %r)", name, value.line,
                value.type, type(value))
            self.variables[name] = v = value
        # Else if there is no citdl type yet, assign it the given type
        elif value.type and not v.type:
            log.debug("existing VAR:%s, setting type: %r", name, value.type)
            v.type = value.type
        if metadata:
            if v.metadata is None:
                v.metadata = metadata
            else:
                v.metadata.update(metadata)
        return v

    def convertToElementTreeModule(self, cixmodule):
        """Convert this file to a <scope> in the cix (DOM) tree
        @param cixmodule {Element} The <scope type="blob"> to write to
        """
        # Sort and include contents
        allValues = self.functions.values() + self.variables.values() + \
            self.classes.values() + self.anonymous_functions
        for v in sorted(allValues, key=operator.attrgetter("line", "name")):
            if not v.isHidden:
                v.toElementTree(cixmodule)

    def convertToElementTreeFile(self, cixelement, file_lang, module_lang=None):
        """Convert this file to a new .cix file
        @param cixelement {Element} The root <codeintel> element in a CIX file
        @param file_lang The language of this file (possibly not JavaScript in
            a mutli-language file)
        @param module_lang The language of this module (defaults to file_lang)
        """
        if module_lang is None:
            module_lang = file_lang
        cixfile = createCixFile(cixelement, self.path, lang=file_lang,
                                mtime=str(self.mtime))
        cixmodule = createCixModule(cixfile, self.name, lang=module_lang,
                                    src=self.path)
        self.convertToElementTreeModule(cixmodule)


class JavaScriptCiler:
    JS_COMMENT_STYLES = (SCE_C_COMMENT,
                         SCE_C_COMMENTDOC,
                         SCE_C_COMMENTLINE,
                         SCE_C_COMMENTLINEDOC,
                         SCE_C_COMMENTDOCKEYWORD,
                         SCE_C_COMMENTDOCKEYWORDERROR)
    UDL_COMMENT_STYLES = (SCE_UDL_CSL_COMMENT,
                          SCE_UDL_CSL_COMMENTBLOCK)

    def __init__(self, mgr, path="", mtime=None, lang="JavaScript"):
        """Initialize the ciler
        @param mgr {codeintel2.manager.Manager} codeintel manager
        @param path {str} Normalized filesystem path to the file being scanned
        @param mtime {str} The last modified timestamp
        @param lang {str} The language being scanned
        """
        self.mgr = mgr
        self.path = path
        self.lang = lang
        # hook up the lexical matches to a function that handles the token

        # Working variables, used in conjunction with state
        self.lineno = 0
        self.last_lineno = 0
        self.depth = 0
        self.styles = []
        self.text = []
        self.in_variable_definition = False  # for multi variable assignment
        self.comment = []
        self.last_comment_and_jsdoc = [None, None]
        self.argumentPosition = 0
        self.argumentTextPosition = 0  # keep track of arg position in self.text
        self.objectArguments = []

        # state : used to store the current JS lexing state
        # state_stack : used to store JS state to return to
        self.state = S_DEFAULT
        self.state_stack = deque()

        # JScile will store all references for what we scan in
        self.cile = JSFile(path, mtime)
        # Cile information, used to store code structure
        self.currentScope = self.cile
        self._scopeStack = [self.currentScope]
        self.objectStack = [self.currentScope]
        self.currentClass = None
        # Used for determining Javascript closures
        self.bracket_depth = 0
        self.lastText = []
        self.lastScope = None

        self._metadata = {}
        self._anonid = 0

        # Document styles used for deciding what to do
        # Note: Can be customized by calling setStyleValues()
        self.JS_WORD = SCE_C_WORD
        self.JS_IDENTIFIER = SCE_C_IDENTIFIER
        self.JS_OPERATOR = SCE_C_OPERATOR
        self.JS_STRINGS = (SCE_C_STRING, SCE_C_CHARACTER, )
        self.JS_NUMBER = SCE_C_NUMBER
        # js_cile styles are styles that the ciler uses
        self.JS_CILE_STYLES = self.JS_STRINGS + \
            (self.JS_WORD, self.JS_IDENTIFIER,
             self.JS_OPERATOR, self.JS_NUMBER)

    # Allows to change styles used by scanner
    # Needed for UDL languages etc... where the style bits are different
    def setStyleValues(self, wordStyle=SCE_C_WORD,
                       identiferStyle=SCE_C_IDENTIFIER,
                       operatorStyle=SCE_C_OPERATOR,
                       stringStyles=(
                       SCE_C_STRING, SCE_C_CHARACTER, ),
                       numberStyle = SCE_C_NUMBER,
                       commentStyles = None):
        self.JS_WORD = wordStyle
        self.JS_IDENTIFIER = identiferStyle
        self.JS_OPERATOR = operatorStyle
        self.JS_STRINGS = stringStyles
        self.JS_NUMBER = numberStyle
        self.JS_CILE_STYLES = self.JS_STRINGS + \
            (self.JS_WORD, self.JS_IDENTIFIER,
             self.JS_OPERATOR, self.JS_NUMBER)
        if commentStyles:
            self.JS_COMMENT_STYLES = commentStyles

    def _logVariables(self):
        """Helper method to log about the current state"""
        if log.level >= logging.DEBUG:
            log.debug("    lineno:%r, state:%r, depth:%r", self.lineno,
                      self.state, self.depth)
            log.debug("    currentScope: %r", self.currentScope)
            log.debug("")

    def incBlock(self):
        """Increment the block (scope) count"""
        self.depth = self.depth+1
        log.info("incBlock: depth:%d, line:%d, currentScope:%r",
                 self.depth, self.lineno, self.currentScope.name)
        if not self.currentScope:
            log.info(
                "incBlock:: No currentScope available. Defaulting to global file scope.")
            # Use the global file scope then
            self.currentScope = self.cile
        if len(self.objectStack) == 0 or self.currentScope != self.objectStack[-1]:
            # Not the same scope...
            self.objectStack.append(self.currentScope)
        self._scopeStack.append(self.currentScope)

    def decBlock(self):
        """Decrement the block (scope) count"""
        log.info("decBlock: depth:%d, line:%d, leavingScope:%r",
                 self.depth, self.lineno, self.currentScope.name)
        if self.depth > 0:
            self.depth = self.depth-1
            self.lastScope = self.currentScope
            # Update lineend for scope
            if hasattr(self.currentScope, "lineend"):
                self.currentScope.lineend = self.lineno
                if isinstance(self.currentScope, JSClass) and \
                   len(self.currentScope.functions) == 1:
                    jsfunc = self.currentScope.functions.values()[0]
                    if jsfunc.depth == self.depth and jsfunc.lineend == -1:
                        jsfunc.lineend = self.lineno
                        log.debug("Setting lineend: %d for scope %r",
                                  self.lineno, jsfunc)
                log.debug("Setting lineend: %d for scope %r",
                          self.lineno, self.currentScope.name)
            else:
                log.debug("Current scope does not have a lineend: %r",
                          self.currentScope.name)
            self._scopeStack.pop()
            # assert(len(self._scopeStack) > 0)
            if self._scopeStack[-1] != self.objectStack[-1]:
                self.objectStack.pop()
                # assert(len(self.objectStack) > 0)
            self.currentScope = self._scopeStack[-1]
            log.debug("decBlock: currentScope:%r", self.currentScope.name)
            if not self.currentScope:
                log.info(
                    "decBlock:: No currentScope available. Defaulting to global file scope.")
                # Use the global file scope then
                self.currentScope = self.cile
                return
            # Update currentClass variable
            oldCurrentClass = self.currentClass
            if isinstance(self.currentScope, JSClass):
                self.currentClass = self.currentScope
                log.debug("Currentclass now: %r", self.currentClass.name)
            elif isinstance(self.currentScope, JSFunction):
                self.currentClass = self.currentScope._class
                if self.currentClass:
                    log.debug("Currentclass now: %r", self.currentClass.name)
                else:
                    log.debug("Currentclass now: %r", self.currentClass)
            else:
                self.currentClass = None
                log.debug("Currentclass now: %r", self.currentClass)
            # Update line number for the current class if it doesn't have one
            # already
            if oldCurrentClass and oldCurrentClass.lineend == -1 and \
               oldCurrentClass != self.currentClass:
                oldCurrentClass.lineend = self.lineno
        else:  # Likely there is a syntax error in the document
            log.debug(
                "decBlock:: Scope already at 0. Document has syntax errors.")

    def _findInScope(self, name, attrlist=("variables", ), scope=None):
        """Find the object of the given name in the given scope
        @param name {str} The name of the object to look for
        @param attrlist {seq of str} The attributes to look into (e.g.,
            "variables", "functions", "classes")
        @param scope {JSObject} The scope in which to find the object
        @returns {JSObject or None} The found object, an immediate child of the
            scope.
        """
        assert scope is not None, "Missing scope"
        for attr in attrlist:
            namesDict = getattr(scope, attr, None)
            if namesDict:
                subscope = namesDict.get(name)
                if subscope:
                    log.debug("_findInScope: Found a scope for: %r in %s.%s:",
                              name, scope.name, attr)
                    return subscope
        # Not found
        return None

    def _resolveAlias(self, namelist, scope=None):
        """Resolve the given alias
        @param namelist {seq of str} The path to the alias to resolve
        @param scope {JSObject} The starting scope; defaults to the current scope
        @returns {tuple of scope, {seq of str}} The scope and namelist for the
            (recursively) resolved namelist; alternatively, tuple (None, None)
            if the alias could not be resolved (e.g. not an alias)
        """
        if not namelist:
            return (None, None)
        namelist = namelist[:]
        if scope is None:
            scope = self.currentScope
        lastScope, lastNamelist = scope, namelist[:]
        log.debug(
            "_resolveAlias: Resolving alias %r in scope %r", namelist, scope.name)
        aliasDepth = 0  # prevent infinite loop
        found = False
        while namelist:
            log.debug(
                "_resolveAlias: Looking for %r in scope %r", namelist, scope.name)
            namesDict = getattr(scope, "variables", None)
            if not namesDict:
                # this scope has no variables
                log.debug(
                    "_resolveAlias: scope %r has no variables", scope.name)
                break
            name = namelist.pop(0)
            foundVar = namesDict.get(name)
            if foundVar is None:
                # can't find the wanted name
                log.debug(
                    "_resolveAlias: scope %r does not have variable %r", scope.name, name)
                break
            if isinstance(foundVar, JSAlias) and aliasDepth < 10:
                lastScope = scope = foundVar.scope
                namelist = foundVar.target + namelist
                if namelist[-1].endswith("()"):
                    # resolved to a function call; drop the call syntax
                    namelist[-1] = namelist[-1][:-2]
                lastNamelist = namelist[:]
                aliasDepth += 1
                log.debug("_resolveAlias: found alias %r on %r; new names %r",
                          foundVar.name, scope.name, namelist)
            else:
                # found a non-alias variable
                scope = foundVar
        log.debug(
            "_resolveAlias: finished resolve: scope %r namelist %r depth %r",
            lastScope.name, lastNamelist, aliasDepth)
        if aliasDepth == 0:
            return (None, None)
        return (lastScope, lastNamelist)

    def _locateScopeForName(self, namelist, attrlist=("variables", ), scope=None):
        """Find the scope referenced by namelist, or if it is not itself a scope,
        the containing scope
        @param namelist {seq of str} The path to the object, e.g. ["foo", "bar"]
        @param attrlist {seq of str} The types of attributes to look at
        @param scope {JSObject} The starting scope; defaults to the current scope
        @returns {JSObject} The object, if it is a scope; otherwise, the scope
            containing the object, if it is a variable.
        """

        if not namelist:
            return None
        namelist = namelist[:]  # copy
        if scope is None:
            scope = self.currentScope
        log.debug("Finding in scope: %s.%r with names: %r",
                  scope.name, attrlist, namelist)
        # If variables are defined, also search members, which is the
        # correstponding group for class scopes.
        if "variables" in attrlist:
            attrlist += ("members", )
            noVariables = False
        else:
            # add variables because aliases are stored there
            attrlist += ("variables", )
            noVariables = True
        # Work up the scope stack looking for the classname
        aliasDepth = 0
        firstAliasFound = None
        while scope:
            currentScope = scope
            log.debug("Looking in scope %r", currentScope.name)
            foundScope = None
            namePos = -1
            while namePos < len(namelist) - 1:
                namePos = namePos + 1
                name = namelist[namePos]
                # attrToLookIn = "variables"
                # if len(namelist) == 0:
                for attrToLookIn in attrlist:
                    log.debug(
                        "Looking for name:%r in %s of scope with name:%r",
                        name, attrToLookIn, currentScope.name)
                    namesDict = getattr(currentScope, attrToLookIn, None)
                    if namesDict:
                        foundScope = namesDict.get(name)
                        if isinstance(foundScope, JSAlias) and aliasDepth < 10:
                            if firstAliasFound is None:
                                firstAliasFound = foundScope
                            # This is an alias; look again with its target
                            namelist[:namePos+1] = foundScope.target
                            currentScope = scope = foundScope.scope
                            namePos = -1
                            aliasDepth += 1
                            log.debug(
                                "_locateScopeForName: encountered alias %r, restarting with %r on %r",
                                name, namelist, scope.name)
                            break  # continue outer for loop
                        elif attrToLookIn == "variables" and noVariables:
                            # we didn't originally want to pick up variables
                            continue
                        if foundScope:
                            log.debug(
                                "_locateScopeForName: Found scope %r for: %r", foundScope.name, name)
                            # Look in this sub-scope if we have more names to
                            # check
                            if type != "variables" or namePos < len(namelist) - 1:
                                currentScope = foundScope
                            # else we've located the scope we want
                            break  # goes to else: of outer for loop at end of namelist
                else:
                    # Not found
                    break
            else:
                log.debug("Found %r in scope:%s.%s",
                          namelist, currentScope.name, attrToLookIn)
                return currentScope
            # Try parent scope
            scope = scope.parent
        if firstAliasFound:
            log.debug(
                "Found alias, but no alias target, returning just the alias: %r", firstAliasFound.name)
            return firstAliasFound
        log.debug("NO scope found for: %r", namelist)
        return None

    ##
    # Create a JSFunction and add it to the current scope
    # @param namelist {list} list of names for the function
    # @param args {list} list of arguments for the function
    # @param doc {list} list of comment strings for given scope
    #
    def addFunction(self, namelist, args=None, doc=None, isLocal=False,
                    isHidden=False):
        log.debug("AddFunction: %s(%s)", namelist, args)
        funcName = namelist[-1]
        toScope = self.currentScope
        if len(namelist) > 1:
            isLocal = False
            scopeNames = namelist[:-1]
            if "prototype" in namelist:
                pIndex = namelist.index("prototype")
                scopeNames = namelist[:pIndex]
                jsclass = self._addClassPart(
                    funcName, self.ADD_CLASS_FUNCTION, scopeNames, args=args, doc=doc, path=self.path)
                # Ensure we onte the currentClass which we'll be working with
                self.currentClass = jsclass
                return
            else:
                toScope = self._findOrCreateScope(namelist[
                                                  :-1], ('variables', 'classes', 'functions'))
        elif isinstance(toScope, JSFile):
            isLocal = False
        log.info("FUNC: %s(%s) isLocal:%r adding to %s %r", funcName, args,
                 isLocal, toScope.cixname, toScope.name)
        # log.debug("jsdoc: %r", JSDoc("".join(doc)))
        fn = JSFunction(funcName, toScope, args, self.lineno, self.depth,
                        doc=doc, isLocal=isLocal, isHidden=isHidden)
        toScope.functions[fn.name] = fn
        self.currentScope = fn
        # Special jsdoc parameter telling us explicitly that it's a class
        jsdoc_says_class = False
        if fn.jsdoc and fn.jsdoc.isClass():
            jsdoc_says_class = True
        # Also check the last comment, sometimes it's meant for this scope
        if not jsdoc_says_class and self.last_comment_and_jsdoc[0]:
            last_jsdoc = self.last_comment_and_jsdoc[1]
            if last_jsdoc is None:
                last_jsdoc = JSDoc("".join(self.last_comment_and_jsdoc[0]))
                self.last_comment_and_jsdoc[1] = last_jsdoc
                if last_jsdoc.isClass() and \
                   fn.name == last_jsdoc.classname:
                    # Name is same, check the namespace as well if it exists
                    nspc = reversed(last_jsdoc.namespace.split("."))
                    scope = fn.parent
                    for name in nspc:
                        if scope is None or name != scope.name:
                            break
                        scope = scope.parent
                    else:
                        jsdoc_says_class = True
                        fn.jsdoc = last_jsdoc
                        log.debug("last_jsdoc classname: %r, namespace: %r",
                                  last_jsdoc.classname, last_jsdoc.namespace)
        if fn.name and jsdoc_says_class:
            # Ick, this is really a class constructor
            jsclass = self._convertFunctionToClass(fn)
            jsclass.doc = None
            jsclass.jsdoc = None

    def _createAnonymousFunctionName(self):
        self._anonid += 1
        return "(anonymous %d)" % (self._anonid, )

    ##
    # Create an anonymous JSFunction and add it to the current scope.
    # @param args {list} list of arguments for the function
    # @param doc {list} list of comment strings for given scope
    #
    def addAnonymousFunction(self, args=None, doc=None, isHidden=False):
        name = self._createAnonymousFunctionName()
        log.info("addAnonymousFunction: %s(%s)", name, args)
        toScope = self.currentScope
        fn = JSFunction(name, toScope, args, self.lineno, self.depth,
                        doc=doc, isLocal=True, isHidden=isHidden,
                        path=self.path)
        toScope.anonymous_functions.append(fn)
        self.currentScope = fn
        return fn

    ##
    # Create a JSFunction and add it to the current scope
    # @param namelist {list} list of names for the function
    # @param args {list} list of arguments for the function
    # @param doc {list} list of comment strings for given scope
    #
    def addClassFunction(self, namelist, args=None, doc=None):
        log.debug("AddClassFunction: %s(%s)", namelist, args)
        toScope = self.currentClass
        if not toScope:
            # See if it's a function, we'll convert it into a class then
            if isinstance(self.currentScope, JSFunction):
                toScope = self._convertFunctionToClass(self.currentScope)
        if not toScope or len(namelist) > 1:
            self.addFunction(namelist, args, doc)
        else:
            funcName = namelist[-1]
            log.info("FUNC: %s(%s) on line %d", funcName, args, self.lineno)
            fn = JSFunction(
                funcName, toScope, args, self.lineno, self.depth, doc=doc)
            toScope.functions[fn.name] = fn
            self.currentScope = fn

    ADD_CLASS = 0
    ADD_CLASS_MEMBER = 1
    ADD_CLASS_VARIABLE = 2
    ADD_CLASS_FUNCTION = 3
    ADD_CLASS_PARENT = 4
    ADD_CLASS_CONSTRUCTOR = 5

    def _addClassPart(self, partName, addType, scopeNames=None, args=None, doc=None, path=None, varCtor=JSVariable):
        """Add something to this class
        @param partName {unicode} The name of the thing to add
        @param addType {int} What sort of thing to add; can be one of ADD_CLASS
                (add a new child class), ADD_CLASS_MEMBER (a member varaible),
                ADD_CLASS_VARIABLE (a member variable), ADD_CLASS_FUNCTION (a
                method), ADD_CLASS_PARENT (an object on this class's prototype
                chain), ADD_CLASS_CONSTRUCTOR (a constructor function)
        @param scopeNames {list of unicode} The expression to locate the part
        @param args {JSArguments} The arguments to a method when using
                ADD_CLASS_FUNCTION
        @param doc {list of unicode} The documentation comment for this part
        @param path {list of unicode}
        @param varCtor {callable} The constructor function to create a variable
                for use with ADD_CLASS_MEMBER / ADD_CLASS_VARIABLE; the
                signature should match that of JSVariable
        """
        log.debug(
            "_addClassPart: partName:%r, addType:%r, scopeNames:%r, args:%r",
            partName, addType, scopeNames, args)
        jsclass = None
        fn = None
        # Find the class to place this part into
        # jsclass = self._findClassWithNames(scopeNames)
        if scopeNames:
            # Look for the class first, then if we don't find it look for
            # a function or variable: bug 70324
            jsclass = self._locateScopeForName(
                scopeNames, attrlist=("classes", ))
            # Note: We could have an alias object, in that case we look for
            #       something better, see test "variable_aliasing_komodo.js"
            if jsclass is None or not isinstance(jsclass, JSClass):
                jsclass = self._locateScopeForName(scopeNames, attrlist=(
                    "classes", "functions", "variables", ))
                if isinstance(jsclass, JSFunction):
                    # Convert it to a class
                    jsclass = self._convertFunctionToClass(jsclass)
        else:
            jsclass = self.currentClass
        if not jsclass and scopeNames:
            if len(scopeNames) > 1:
                toScope = self._findOrCreateScope(scopeNames, attrlist=(
                    "classes", "functions", "variables", ))
            else:
                toScope = self.currentScope
            className = scopeNames[-1]
            jsclass = JSClass(
                className, toScope, self.lineno, self.depth, doc=doc, path=path)
            self.currentScope.classes[jsclass.name] = jsclass
            log.info("CLASS: %r on line %d in %r at depth %d", jsclass.name,
                     jsclass.line, self.currentScope.name, self.depth)
            self.currentScope = jsclass

        if addType == self.ADD_CLASS_FUNCTION:
            log.info(
                "CLASS_FUNC: %s(%s) on line %d", partName, args, self.lineno)
            fn = JSFunction(
                partName, jsclass, args, self.lineno, self.depth, doc=doc)
            fn._class = jsclass
            jsclass.functions[fn.name] = fn
            # print "num functions: %d" % (len(jsclass.functions))
            self.currentScope = fn
        elif addType == self.ADD_CLASS_MEMBER:
            if partName not in jsclass.variables:
                log.info("CLASS_MBR added: %r", partName)
                v = varCtor(
                    partName, jsclass, self.lineno, self.depth, doc=doc, path=self.path)
                jsclass.variables[partName] = v
            else:
                log.info("CLASS_MBR already exists: %r", partName)
        elif addType == self.ADD_CLASS_VARIABLE:
            if partName not in jsclass.variables:
                log.info("CLASS_VBR added: %r", partName)
                v = varCtor(
                    partName, jsclass, self.lineno, self.depth, doc=doc, path=self.path)
                jsclass.variables[partName] = v
            else:
                log.info("CLASS_MBR already exists: %r", partName)
        elif addType == self.ADD_CLASS_PARENT:
            log.info("CLASS_PARENT: %r", partName)
            jsclass.addClassRef(partName)
        elif addType == self.ADD_CLASS_CONSTRUCTOR:
            log.info("CLASS_CTOR: %r", partName)
            jsclass.constructor = partName

        if jsclass:
            self.currentClass = jsclass
            if addType == self.ADD_CLASS:
                self.currentScope = jsclass
            elif addType == self.ADD_CLASS_PARENT and partName == "Object":
                self.currentScope = jsclass
        return jsclass

    # a class part using prototype.name = function
    # def addClassPart(self):
    #    self._addClassPart()

    # a class using classname.prototype = { ... }
    def addClass(self, namelist, doc=None, path=None, varCtor=JSVariable):
        """Add a new class using scope.classname.prototype = {...}
        @param namelist {list of unicode} The path to get to the class; in the
                example above, ["scope", "classname"]
        @param doc {list of unicode} Documentation comment associated with this class
        @param varCtor {callable} The constructor function to create a variable
                for use with ADD_CLASS_MEMBER / ADD_CLASS_VARIABLE; the
                signature should match that of JSVariable
        """
        jsclass = self._addClassPart(namelist[
                                     -1], self.ADD_CLASS, scopeNames=namelist, doc=doc, path=path, varCtor=varCtor)
        return jsclass

    def addAnonymousClass(self, namelist, doc=None):
        # Example syntax: c.prototype = { rows: { return this._rows.length; } }
        self.addClass(namelist[:-1], doc=doc)

    def addClassOrVariableMember(
        self, namelist, typeNames, scope=None, doc=None,
        assignAsCurrentScope=False,
            isLocal=False, varCtor=JSVariable):
        """Add the variable to the given scope or current scope

        If the scope is a
          * variable or object: add as a variable to this scope.
          * class: add as a member to this class.
          * function: then this is a little more tricky:
            * If it's class function, then add as a member for the class.
            * If it's a function inside a variable/object, then add as a
              variable to the variable/object.
            * If it's just a function on it's own, turn the function into a
              class and then add a member variable for the class.
        """
        if not scope:
            scope = self.currentScope

        log.debug(
            "addClassOrVariableMember: namelist:%r, type:%r, isLocal:%r, scope (%s):%s",
            namelist, typeNames, isLocal, scope.cixname, scope.name)
        memberName = namelist[-1]

        if len(namelist) > 2 and "prototype" in namelist:
            pIndex = namelist.index("prototype")
            scopeNames = namelist[:pIndex]
            log.debug("Adding class prototype. class name: %r, variable: %r",
                      scopeNames, memberName)
            scope = self._addClassPart(memberName, self.ADD_CLASS_MEMBER,
                                       scopeNames=scopeNames, args=None, doc=doc,
                                       path=self.path, varCtor=varCtor)
            v = scope

        elif len(namelist) >= 2:
            # Find the scope to apply to.
            scope = self._findOrCreateScope(namelist[:-1],
                                            attrlist=("variables", "classes"),
                                            fromScope=scope)
            v = varCtor(memberName, scope, self.lineno, self.depth,
                        vartype=typeNames, doc=doc, isLocal=isLocal, path=self.path)
            v = scope.addVariable(memberName, value=v)
            if assignAsCurrentScope:
                self.currentScope = v

        elif scope.cixname in ("object", "variable"):
            if isLocal:
                log.warn("addClassOrVariableMember: %s:%d Trying to add %r as "
                         "a local member variable??",
                         self.cile.name, self.lineno, namelist)
                return
            v = varCtor(memberName, scope, self.lineno, self.depth,
                        vartype=typeNames, doc=doc, isLocal=isLocal, path=self.path)
            v = scope.addVariable(memberName, value=v)
            if assignAsCurrentScope:
                self.currentScope = v

        # Special case - classes and anonymous functions
        elif isinstance(scope, JSClass) or scope.isAnonymous():
            v = varCtor(memberName, scope, self.lineno, self.depth,
                        vartype=typeNames, doc=doc, isLocal=isLocal, path=self.path)
            v = scope.addMemberVariable(memberName, value=v)
            if assignAsCurrentScope:
                self.currentScope = v

        elif isinstance(scope, JSFunction):
            # If it's a function already within a class, then thats okay
            parentScope = scope.parent
            if not parentScope:
                log.debug("addClassOrVariableMember: ignoring assignment %r "
                          "into a dummy function", namelist)
                return None
            log.debug("ParentScope is: %s (%s)",
                      parentScope.name, parentScope.cixname)
            if isinstance(parentScope, JSClass):
                self.currentClass = parentScope
                log.debug("Assigning to parent class: %r:%r",
                          parentScope.cixname, parentScope.name)
                v = varCtor(memberName, parentScope, self.lineno, self.depth,
                            typeNames, doc=doc, isLocal=isLocal, path=self.path)
                v = parentScope.addMemberVariable(memberName, value=v)
                if assignAsCurrentScope:
                    self.currentScope = v
            # If it's a function within a variable, then thats okay too
            elif parentScope and parentScope.cixname in ("object", "variable"):
                log.debug("Assigning to parent scope: %r:%r",
                          parentScope.cixname, parentScope.name)
                v = varCtor(memberName, parentScope, self.lineno, self.depth,
                            vartype=typeNames, doc=doc, isLocal=isLocal, path=self.path)
                v = parentScope.addVariable(memberName, value=v)
                # We need to keep track of what we assign in this particular
                # case, as we may later turn this function into it's own class,
                # and then we'll need to grab these "this." variables back!
                # Example code:
                #   var ko = {}
                #   ko.f1 = function() { this.x = 1; }   // x assigned to ko
                #   ko.f1.prototype.run = function() {}  // convert f1 to class
                #   // Now we want ko.x to move into class ko.f1
                scope._parent_assigned_vars.append(v)

                if assignAsCurrentScope:
                    self.currentScope = v
            # Convert the function to class then
            else:
                # If the class name exists already, assign to that class
                func = scope
                funcName = func.name
                jsclass = self._locateScopeForName(
                    [funcName], attrlist=("classes", ), scope=scope)
                if not jsclass:
                    log.debug(
                        "Creating class %r, function %r now ctor", funcName, funcName)
                    # Turn function into a constructor for the class
                    jsclass = self._convertFunctionToClass(func)
                else:
                    # Update the function class information
                    self._convertFunctionToClassContructor(func, jsclass)
                v = varCtor(memberName, jsclass, self.lineno, self.depth,
                            typeNames, doc=doc, isLocal=isLocal, path=self.path)
                v = jsclass.addMemberVariable(memberName, value=v)
                if assignAsCurrentScope:
                    self.currentScope = v
        elif isinstance(scope, JSFile):
            v = self.addVariable(namelist, typeNames, scope, doc,
                                 assignAsCurrentScope, isLocal,
                                 varCtor=varCtor)
        else:
            log.info(
                "addClassOrVariableMember:: Invalid scope type. Could not add %r to scope: %r - %r",
                namelist, scope.cixname, scope.name)
            v = None
        return v

    def addClassParent(self, namelist, typeNames):
        log.debug(
            "addClassParent: namelist:%r, typeNames:%r", namelist, typeNames)
        self._addClassPart(".".join(
            typeNames), self.ADD_CLASS_PARENT, namelist[:-1], path=self.path)

    def addGetter(self, namelist, typeNames, scopeNames=None, doc=None):
        log.debug("addGetter: namelist:%r, type: %r, scopeNames: %r", namelist,
                  typeNames, scopeNames)
        if scopeNames:
            toScope = self._locateScopeForName(
                scopeNames, attrlist=("variables", "classes"))
            if not toScope:
                log.info(
                    "addGetter:: Not adding getter. Could not find scope for: %r",
                    scopeNames)
                return
            self.currentScope = toScope
        else:
            toScope = self.currentScope
        self.addClassOrVariableMember(namelist, typeNames, toScope, doc=doc)

    def addSetter(self, namelist, scopeNames=None, doc=None):
        log.debug(
            "addSetter: namelist:%r, scopeNames: %r", namelist, scopeNames)
        if scopeNames:
            toScope = self._locateScopeForName(
                scopeNames, attrlist=("variables", "classes"))
            if not toScope:
                log.info(
                    "addSetter:: Not adding setter. Could not find scope for: %r",
                    scopeNames)
                return
            self.currentScope = toScope
        else:
            toScope = self.currentScope
        self.addClassOrVariableMember(namelist, [], toScope, doc=doc)

    def _convertFunctionToClassContructor(self, jsfunc, jsclass):
        # Mark it as a constructor if it's not already so marked
        funcName = jsfunc.name
        # Copy attributes across, except for "__ctor__"
        class_attributes = jsfunc.attributes[:]
        if "__ctor__" not in jsfunc.attributes:
            jsfunc.attributes.append("__ctor__")
        else:
            class_attributes.remove("__ctor__")
        jsclass.attributes = class_attributes
        # Might already be the contructor for the class
        if funcName not in jsclass.functions:
            parentScope = jsfunc.parent
            log.debug(
                "Converting function: %r into a class contructor for: %r",
                funcName, jsclass.name)
            jsclass.functions[funcName] = jsfunc
            # Update references
            if jsfunc.isAnonymous():
                parentScope.anonymous_functions.remove(jsfunc)
                parentScope.anonymous_functions.append(jsclass)
            else:
                parentScope.functions.pop(funcName, None)
                parentScope.classes[funcName] = jsclass
            # Fix starting line number
            if jsfunc.line < jsclass.line:
                jsclass.line = jsfunc.line
            # Copy over non-local variables from the function to the class,
            # all the local variables stay inside the function scope.
            for varName, v in jsfunc.variables.items():
                isLocal = "__local__" in v.attributes or isinstance(
                    v, JSArgument)
                if not isLocal:
                    # Add to class and remove from the function
                    jsclass.variables[varName] = JSVariable(
                        varName, jsclass, v.line,
                        v.depth, v.type, v.doc,
                        isLocal=isLocal, path=self.path)
                    del jsfunc.variables[varName]
        parent = jsfunc.parent
        for var in getattr(jsfunc, '_parent_assigned_vars', []):
            log.debug("Converting function: Moved parent assigned variable %r "
                      "into the class instance", var.name)
            jsclass.members[var.name] = var
            parent.variables.pop(var.name, None)

        # Copy across all non-local members, bug 88549.
        for name, jsobject in jsfunc.variables.items():
            if '__local__' not in jsobject.attributes and not isinstance(jsobject, JSArgument):
                jsclass.variables[name] = jsobject
                jsfunc.variables.pop(name, None)
        for name, jsobject in jsfunc.functions.items():
            if '__local__' not in jsobject.attributes:
                jsclass.functions[name] = jsobject
                jsfunc.functions.pop(name, None)
        for name, jsobject in jsfunc.classes.items():
            if '__local__' not in jsobject.attributes:
                jsclass.classes[name] = jsobject
                jsfunc.classes.pop(name, None)

        jsfunc._parent_assigned_vars = []
        jsfunc._class = jsclass
        jsfunc.setParent(jsclass)
        return jsclass

    def _convertFunctionToClass(self, jsfunc):
        """Convert the provided JSFunction into a JSClass and return it."""
        funcName = jsfunc.name
        log.debug("Creating class %r, from function %r", funcName, funcName)
        jsclass = JSClass(
            funcName, jsfunc.parent, jsfunc.line, self.depth - 1, jsfunc.doc)
        self._convertFunctionToClassContructor(jsfunc, jsclass)
        if self.currentScope == jsfunc:
            self.currentClass = jsclass
        # Copy across the classrefs from the jsdoc (if any).
        if jsfunc.jsdoc and jsfunc.jsdoc.baseclasses:
            for baseclass in jsfunc.jsdoc.baseclasses:
                jsclass.addClassRef(baseclass)
            jsfunc.jsdoc.baseclasses = []
        return jsclass

    def _convertFunctionToClosureVariable(self, jsfunc):
        funcName = jsfunc.name
        log.info(
            "Creating variable %r, from function closure %r", funcName, funcName)
        jsvariable = JSVariable(funcName, jsfunc.parent, jsfunc.line,
                                jsfunc.depth, jsfunc.type, jsfunc.doc, path=self.path)
        if jsfunc.returnTypes:
            jsro = jsfunc.returnTypes[0]
            # print jsro
            if isinstance(jsro, JSVariable):
                # Convert this object into the variable
                jsro.setParent(jsfunc.parent)
                jsro.line = jsfunc.line
                jsro.name = funcName
                jsvariable = jsro
        parent = jsfunc.parent
        if not jsfunc.isAnonymous():
            parent.functions.pop(funcName, None)
            parent.variables[funcName] = jsvariable
        return jsvariable

    def _findOrCreateScope(self, namelist, attrlist=("variables", ),
                           fromScope=None, isLocal=False):
        # Don't create a window scope - bug 87442.
        global_var = {
            "JavaScript": "window",
            "Node.js":    "global",
        }.get(self.lang)
        if namelist[0] == global_var:
            fromScope = self.cile
            namelist = namelist[1:]
            if not namelist:
                return fromScope
        # Ensure the scope exists, else create it
        # Find the base scope first
        if fromScope is None:
            fromScope = self.currentScope
        log.debug("_findOrCreateScope: %r, attrlist: %r, from scope: %s",
                  namelist, attrlist, fromScope.name)
        name = namelist[0]

        # Determine where variables get added when they are not found
        if isLocal:
            applyToScope = fromScope
        else:
            applyToScope = self.cile   # Global file level

        resolvedScope, resolvedNamelist = self._resolveAlias(
            namelist, fromScope)
        if resolvedScope is not None and resolvedNamelist:
            # don't use the resolved namelist if it resolves to an undeclared
            # global object; doing so can cause us to shadow things found in the
            # standard library
            if resolvedScope is not self.cile or \
                    self._findInScope(resolvedNamelist[0], attrlist, resolvedScope) is not None:
                fromScope, namelist = resolvedScope, resolvedNamelist

        isTheFirstName = True
        for name in namelist:
            # When looking for the first name of the scope, traverse the parent
            # chain, subsequent names *must* reside within the current scope
            # being checked!
            if isTheFirstName:
                isTheFirstName = False
                scope = self._locateScopeForName([name], attrlist, fromScope)
            else:
                scope = self._findInScope(name, attrlist, fromScope)
            if not scope:
                v = JSVariable(name, applyToScope, self.lineno, self.depth,
                               vartype="Object", path=self.path)
                scope = applyToScope.addVariable(name, value=v)
                log.info(
                    "Could not find %r in scope: %r, creating variable (type=Object) for it on scope %r!!!",
                         name, fromScope.name, applyToScope.name)
                scope.attributes.append("__file_local__")
            fromScope = scope
            applyToScope = scope
        return fromScope

    def addVariable(self, namelist, typeNames, toScope=None, doc=None,
                    assignAsCurrentScope=False, isLocal=False, value=None,
                    varCtor=JSVariable):
        varName = namelist[-1]
        if toScope is None:
            toScope = self.currentScope
        log.debug("addVariable: %r, typeNames:%r, isLocal: %r, scope: %r",
                  namelist, typeNames, isLocal, toScope.name)

        if len(namelist) > 1:
            if namelist[-2] == "prototype":
                # Adding to an existing class then
                toScope = self._locateScopeForName(
                    namelist[:-2], attrlist=("classes", ))
                if not toScope:
                    # Create a class for it then
                    log.debug("Creating class now: %r", namelist[:-2])
                    toScope = self.addClass(
                        namelist[:-2], doc=doc, path=self.path,
                                            varCtor=varCtor)
                    # raise CodeIntelError("Could not find scope for: %r" %
                    # (namelist[:-2], ))
                if varName == "constructor":
                    if isinstance(typeNames, JSObject):
                        ctorName = typeNames.type
                    else:
                        ctorName = ".".join(typeNames)
                    func = self._locateScopeForName(
                        [ctorName], attrlist=("functions", ))
                    if func:
                        return self._convertFunctionToClassContructor(func, toScope)
                    else:
                        return self._addClassPart(
                            ctorName, self.ADD_CLASS_CONSTRUCTOR,
                                                  namelist[
                                                      :-2], doc=doc, path=self.path,
                                                  varCtor=varCtor)
                else:
                    return self._addClassPart(varName, self.ADD_CLASS_VARIABLE,
                                              namelist[
                                                  :-2], doc=doc, path=self.path,
                                              varCtor=varCtor)
            else:
                # Find or create the parent scope
                toScope = self._findOrCreateScope(namelist[:-1],
                                                  ('variables', 'classes',
                                                   'functions'),
                                                  fromScope=toScope,
                                                  isLocal=isLocal)
        elif not isLocal:
            # Try and find the scope we are assigning to, should be in
            # a parent scope somewhere!
            # print("addVariable: namelist:%r, typeNames:%r, isLocal: %r, line:
            # %d" % (namelist, typeNames, isLocal, self.lineno))
            fromscope = toScope
            toScope = self._locateScopeForName(namelist,
                                               ('variables', 'classes',
                                                'functions'),
                                               toScope)
            if toScope is None:
                # if self.text[0] not in ("var", "const"):
                #    sys.stderr.write("Undeclared var in %s:%d, %r in %s %r\n" % (
                #            self.cile.name,
                #            self.lineno, varName, fromscope.cixname, fromscope.name))
                # Place it at the global level then
                toScope = self.cile
            else:
                toScope = toScope.parent

        # Add it to scope if it's not already in there
        if toScope:
            if isinstance(toScope, JSVariable):
                # toScope.type can be None if it's an implicitly defined scope
                # (i.e. ones we picked up by observing properties being set on it)
                if toScope.type is not None and toScope.type.lower() not in ("object", ):
                    # Not going to add sub-variables, as it's likely a class
                    # object already, which has this variable information set
                    # if not toScope.type:
                    #    msg = "Assignment to a unknown type, %s:%d, %r (%s)" % (self.filename, self.lineno, ".".join(namelist), toScope.type)
                    #    print >> sys.stderr, msg
                    return None
            # if not isLocal and varName not in toScope.variables:
            # print("addVariable: namelist:%r, typeNames:%r, isLocal: %r, line:
            # %d" % (namelist, typeNames, isLocal, self.lineno))
            if value is None:
                value = varCtor(varName, toScope, self.lineno, self.depth,
                                vartype=typeNames, doc=doc, isLocal=isLocal, path=self.path)
            v = toScope.addVariable(
                varName, value=value, metadata=self._metadata)
            if assignAsCurrentScope:
                self.currentScope = v
            return v

        # We kinda lost the scope somewhere
        return None

    def addObjectVariable(self, namelist, toScope=None, doc=None,
                          isLocal=False):
        if not toScope:
            toScope = self.currentScope
        log.debug("addObjectVariable: namelist:%r, scope:%r", namelist,
                  toScope.name)
        varName = namelist[-1]

        if len(namelist) > 1:
            # Ensure the scope exists, else create it
            if "prototype" in namelist:
                classnames = namelist[:namelist.index("prototype")]
                toScope = self.addClass(classnames, doc=self.comment)
            else:
                toScope = self._findOrCreateScope(namelist[:-1], (
                    "variables", "classes", "functions"), toScope)
            # Assignment to a function, outside the function scope... create a
            # class for it
            if isinstance(toScope, JSFunction):
                toScope = self._convertFunctionToClass(toScope)
        # Add it to scope if it's not already in there
        v = JSVariable(varName, toScope, self.lineno, self.depth,
                       vartype=["Object"], doc=doc, isLocal=isLocal, path=self.path)
        v = toScope.addVariable(varName, value=v)
        self.currentScope = v

    def addReturnObject(self, doc=None):
        log.debug("addReturnObject: scope:%r", self.currentScope.name)
        jsro = JSVariable("", self.currentScope, self.lineno,
                          self.depth, vartype="Object", doc=doc, path=self.path)
        if isinstance(self.currentScope, JSFunction):
            self.currentScope.addReturnType(jsro)
        # else:
        #   TODO: This is ignoring the return type for function getters.
        self.currentScope = jsro
        return jsro

    def addFunctionReturnType(self, typeNames, doc=None):
        if isinstance(self.currentScope, JSFunction):
            log.debug("addFunctionReturnType: type: %r, scope:%r",
                      typeNames, self.currentScope.name)
            self.currentScope.addReturnType(".".join(typeNames))

    ##
    # Read everything up to and including the matching close paren
    # @param styles list
    # @param text list
    # @param p int position in the styles and text list
    # @param paren string type of parenthesis
    def _getParenArguments(self, styles, text, p, paren=None):
        # Examples:
        #  (arg1, arg2) {
        #   => [(arg1, arg2)]
        #  [row][this.columns[column][0]];
        #   => [row]

        if paren is None:
            paren = text[p]
        parenMatches = {'{': '}', '[': ']', '(': ')'}
        args = []
        oppParen = parenMatches.get(paren)
        if oppParen is None:
            log.info("_getParenArguments:: No matching paren for: %r, "
                     "ignoring arguments.", paren)
            return args, p
        parenCount = 0
        while p < len(styles):
            args.append(text[p])
            if styles[p] == self.JS_OPERATOR:
                if text[p] == paren:
                    parenCount += 1
                elif text[p] == oppParen:
                    parenCount -= 1
                    if parenCount <= 0:
                        p += 1
                        break
            p += 1
        return args, p

    def _skipOverParenArguments(self, styles, text, p, paren="("):
        args, p = self._getParenArguments(styles, text, p, paren)
        return p

    # Skip over all the variable assignment details. Returns position at
    # the end of the assignment, usually a "," or a ";" character.
    #
    # Examples:
    #    var nGroupIndex = typeof <|>p_nGroupIndex=="number" ?p_nGroupIndex :0,
    #        aGroup = this._getItemGroup(nGroupIndex);
    # should skip to "aGroup = this._getItemGroup(nGroupIndex);"
    def _skipToEndOfVariableAssignment(self, styles, text, p):
        old_p = p
        while p < len(styles):
            style = styles[p]
            if style == self.JS_OPERATOR:
                t = text[p]
                if t in '([{':
                    p = self._skipOverParenArguments(styles, text, p, t)
                    continue
                elif t in ',;':
                    break
            p += 1
        if old_p == p:
            # Ensure we at least move somewhere (avoid recursion)
            p += 1
        log.debug("_skipToEndOfVariableAssignment:: skipped text %r, p: %d",
                  text[old_p:p], p)
        return p

    def _getArgumentsFromPos(self, styles, text, pos):
        log.debug("_getArgumentsFromPos: text: %r", text[pos:])
        if pos < len(styles) and styles[pos] == self.JS_OPERATOR and text[pos] == "(":
            ids = []
            pos += 1
            start_pos = pos
            while pos < len(styles):
                if styles[pos] == self.JS_IDENTIFIER:
                    ids.append(text[pos])
                elif styles[pos] != self.JS_OPERATOR or text[pos] != ",":
                    break
                pos += 1
            return ids, pos
        return None, pos

    def _getIdentifiersFromPos(self, styles, text, pos):
        log.debug("_getIdentifiersFromPos: text: %r", text[pos:])
        start_pos = pos
        ids = []
        last_style = self.JS_OPERATOR
        while pos < len(styles):
            style = styles[pos]
            if style == self.JS_IDENTIFIER or \
               (style == self.JS_WORD and text[pos] == "this"):
                if last_style != self.JS_OPERATOR:
                    break
                ids.append(text[pos])
            elif style == self.JS_OPERATOR and text[pos] == "[" and \
                len(styles) - pos > 2 and styles[pos + 1] in self.JS_STRINGS and \
                text[pos + 2] == "]":
                # blah["string here"]
                part = text[pos + 1]
                if len(part) > 1 and part[0] in ("'", '"') and part[-1] == part[0]:
                    part = part[1:-1]  # trim quotes
                ids.append(part)
                pos += 2
            elif style != self.JS_OPERATOR or text[pos] != "." or \
                last_style != self.JS_IDENTIFIER:
                break
            pos += 1
            last_style = style
        return ids, pos

    ##
    # Grab all necessary citdl information from the given text
    # @param styles list
    # @param text list
    # @param p int position in the styles and text list
    # @return the citdl list and the position after the last item swallowed
    def _getCitdlTypeInfo(self, styles, text, p):
        log.debug("_getCitdlTypeInfo:: text: %r", text[p:])
        citdl = []
        last_style = self.JS_OPERATOR
        while p < len(styles):
            style = styles[p]
            # log.debug("p: %d, text[p]: %r", p, text[p])
            # print "style: %d, last_style: %d" % (style, last_style)
            if style == self.JS_IDENTIFIER or text[p] == "this":
                if last_style != self.JS_OPERATOR:
                    break
                citdl.append(text[p])
                style = self.JS_IDENTIFIER
            elif style == self.JS_OPERATOR and last_style == self.JS_IDENTIFIER:
                if text[p] == ".":
                    pass
                elif text[p] == ")":
                    # Collect after the closing brace - bug 80581.
                    style = last_style
                elif text[p] == "(":
                    paren_pos = p
                    if citdl == ['require']:
                        # Deal with CommonJS (NodeJS) require statements.
                        args, p = self._getParenArguments(styles, text, p)
                        if len(args) >= 3 and styles[paren_pos+1] in self.JS_STRINGS:
                            self._metadata[
                                'required_library_name'] = self._unquoteJsString(args[1])
                            log.debug("Dealing with CommonJS require(%s)",
                                      self._metadata['required_library_name'])
                    else:
                        p = self._skipOverParenArguments(styles, text, p)
                    if citdl:
                        if len(citdl) > 1 and 'QueryInterface' == citdl[-1]:
                            # QueryInterface is specific to xpcom interfaces.
                            citdl = []
                            # Don't want the "." items in the citdl
                            for t in text[paren_pos+1:p-1]:
                                if t != ".":
                                    citdl.append(t)
                        else:
                            citdl[-1] = citdl[-1] + "()"
                    style = self.JS_IDENTIFIER
                    p -= 1   # Are at the pos after the paren, move back to it
                elif text[p] == "[":
                    # Arrays, just read in the arguments and add it to the
                    # citdl
                    args, p = self._getParenArguments(styles, text, p, "[")
                    if args and citdl:
                        # Check if this is an xpcom component.
                        if citdl in (["CC"], ["Cc"],
                                      ["Components", "classes"]) and \
                           (p+2) < len(styles) and \
                           text[p] == "." and \
                           text[p+1] in ("getService", "createInstance") and \
                           text[p+2] == "(":
                            # Add the xpcom interface information.
                            # TODO: Change this once array completions are
                            #       supported
                            citdl, p = self._getArgumentsFromPos(styles, text,
                                                                 p+2)
                        else:
                            citdl[-1] = citdl[-1] + "".join(args)
                    style = self.JS_IDENTIFIER
                    p -= 1  # We are are after the last "]", move back
                else:
                    break
            else:
                break
            p += 1
            last_style = style
        return citdl, p

    def _getVariableType(self, styles, text, p, assignmentChar="="):
        """
        Get the type of the variable
        @param styles {list} The (scintilla) styles for the text
        @param text {list} The tokens to examine
        @param p {int} Offset into text/styles to start looking
        @param assignmentChar {str} The assignment character used
        @returns {tuple} {list} type names,
                         {int} new offset (p),
                         {bool} true if this is a new instance
        """
        log.debug("_getVariableType: text: %r, assign char: %s", text[p:],
                  assignmentChar)
        typeNames = []
        if p >= len(styles):
            # Nothing left to examine
            return typeNames, p, False

        if assignmentChar and styles[p] == self.JS_OPERATOR and \
           text[p] == assignmentChar:
            # Assignment to the variable
            p += 1
        if p < len(styles) and styles[p] == self.JS_OPERATOR and \
           text[p] in "+-":
            # Example: var x = -1;
            # Skip over + and -, commonly used with strings and integers
            p += 1

        isNew = False
        isAlias = False

        if p < len(styles):
            if styles[p] == self.JS_WORD:
                # Keyword
                keyword = text[p]
                if keyword == "new":
                    typeNames, p = self._getCitdlTypeInfo(styles, text, p+1)
                    p -= 1   # We are already at the next position, step back
                    # When resolving a class, we want to drop the function call
                    # from the citdl and just use the identifier itself.
                    for i, t in enumerate(typeNames):
                        if t.endswith("()"):
                            typeNames[i] = t[:-2]
                            break
                    # if not typeNames:
                    #    typeNames = ["object"]
                    isNew = True
                elif keyword in ("true", "false"):
                    typeNames = ["boolean"]
                elif keyword == "this":
                    typeNames, p = self._getCitdlTypeInfo(styles, text, p)
                    p -= 1   # We are already at the next position, step back
                # Don't record null, as it doesn't help us with anything
                # elif keyword == "null":
                #    typeNames = ["null"]
                p += 1
            elif styles[p] in self.JS_STRINGS:
                typeNames = ["string"]
                p += 1
            elif styles[p] == self.JS_NUMBER:
                typeNames = ["int"]
                p += 1
            elif styles[p] == self.JS_IDENTIFIER:
                typeNames, p = self._getCitdlTypeInfo(styles, text, p)
                if not isNew:
                    # this refers to an identifier without "new", it's an alias
                    isAlias = True
            elif styles[p] == self.JS_OPERATOR:
                if text[p] == "{":
                    # This is actually a newly created object
                    typeNames = ["Object"]
                    p += 1
                elif text[p] == "[":
                    while p+1 < len(styles):
                        if text[p] == "]" and styles[p] == self.JS_OPERATOR:
                            break
                        p += 1
                    typeNames = ["Array"]
                    p += 1
        return typeNames, p, isAlias

    def _unquoteJsString(self, s):
        """Return the string without quotes around it"""
        return Utils.unquoteJsString(s)

    def _getVariableDetail(self, namelist, styles, text, p, assignmentChar="="):
        # this.myname = "123";
        # myclass.prototype.list = function () {
        # this.myname = new function(x, y) {
        # var num = mf.field1;
        # names = { "myname": 1, "yourname": 2 }

        log.debug(
            "_getVariableDetail: namelist: %r, text:%r", namelist, text[p:])

        if len(namelist) > 1 and "prototype" in namelist:
            # Check for special class prototypes
            protoName = namelist[-1]
            if protoName == "prototype":
                typeNames, p, isAlias = self._getVariableType(
                    styles, text, p, assignmentChar)
                return (TYPE_PARENT, typeNames, None, p)
            elif namelist[-2] == "prototype":
                typeNames = []
                if p+1 < len(styles) and styles[p+1] in self.JS_STRINGS:
                    typeNames = [self._unquoteJsString(text[p+1])]
                if protoName == "__defineGetter__":
                    return (TYPE_GETTER, typeNames, None, p)
                elif protoName == "__defineSetter__":
                    return (TYPE_SETTER, typeNames, None, p)
        elif len(namelist) == 1 and p+1 < len(styles) and \
             styles[p] == self.JS_IDENTIFIER:
            keyword = namelist[0]
            if keyword == "get":
                # get log() {
                newnamelist, p = self._getIdentifiersFromPos(styles, text, p)
                namelist.pop()
                for name in newnamelist:
                    namelist.append(name)
                log.debug("Found getter:%r", namelist)
                return (TYPE_GETTER, [], None, p)
            elif keyword == "set":
                # set application(value) {
                newnamelist, p = self._getIdentifiersFromPos(styles, text, p)
                namelist.pop()
                for name in newnamelist:
                    namelist.append(name)
                log.debug("Found setter:%r", namelist)
                return (TYPE_SETTER, [], None, p)

        if p+1 < len(styles) and styles[p+1] == self.JS_OPERATOR and text[p+1] == "{":
            # This is actually a newly created object
            return (TYPE_OBJECT, [], None, p+2)
        elif p+2 < len(styles) and styles[p+1] == self.JS_WORD and \
             text[p+1] == "function":
            # Skip over any function name
            # Example:  var f = function my_f(a, b) { }
            p += 2
            while p < len(styles):
                if text[p] == "(":
                    break
                p += 1
            args, p = self._getArgumentsFromPos(styles, text, p)
            return (TYPE_FUNCTION, [], args, p)
        elif p+3 < len(styles) and styles[p+1] == self.JS_WORD and \
             text[p+1] == "new" and text[p+2] == "function":
            # Skip over any function name
            # Example:  var f = new function my_f(a, b) { }
            p += 3
            while p < len(styles):
                if text[p] == "(":
                    break
                p += 1
            args, p = self._getArgumentsFromPos(styles, text, p)
            return (TYPE_FUNCTION, [], args, p)
        else:
            typeNames, p, isAlias = self._getVariableType(
                styles, text, p, assignmentChar)
            if len(namelist) > 2 and namelist[-2:] == ["prototype", "constructor"]:
                # Foo.prototype.constructor = bar; don't treat as an alias
                pass
            elif isAlias and typeNames != namelist:
                log.debug("_getVariableDetail: %r is an alias to %r",
                          namelist, typeNames)
                return (TYPE_ALIAS, typeNames, None, p)
            return (TYPE_VARIABLE, typeNames, None, p)

    def _variableHandler(self, lineno, styles, text, p, namelist,
                         allowedAssignmentChars="=",
                         isLocal=False):
        log.debug("_variableHandler:: namelist:%r, p:%d, isLocal: %r",
                  namelist, p, isLocal)
        # print "p:", p
        # print "text:", text[p:]

        # The while loop is used to handle multiple variable assignments.
        # Example1:
        #   var x = 1, y = 2, z = 3;
        #     namelist: ['x']
        #     text:     ['=', '1', ',', 'y', '=', '2', ',', 'z', '=', '3', ';']
        #
        # Example2:
        #   var x = y = z = 1;
        #     namelist: ['x']
        #     text:     ['=', 'y', '=', 'z', '=', '1', ';']
        #
        # Example3:
        #   var x, y, z = 1;
        #     namelist: ['x']
        #     text:     [',', 'y', ',', 'z', '=', '1', ';']
        #
        # Example4:
        #  this.ab['xyz']={one:1,"two":2};
        #    namelist: ['this', 'ab']
        #    text:     ['[', "'xyz'", ']', '=', '{']]
        #
        already_looped = False
        while p < len(styles):
            self._metadata = {}
            # log.debug("_variableHandler:: p: %d, text: %r", p, text[p:])
            if already_looped:
                # We've already done one loop, need to get a new namelist
                #     text:     [',', 'y', '=', '2', ',', 'z', '=', '3']
                # log.debug("_variableHandler:: already_looped:: text:%r,
                # p:%d", text[p:], p)
                if text[p] == "=" and styles[p] == self.JS_OPERATOR and len(typeNames) > 0:
                    # Assignment to an assignment (aka Example 2)
                    namelist = typeNames
                elif text[p] != "," or styles[p] != self.JS_OPERATOR:
                    p = self._skipToEndOfVariableAssignment(styles, text, p)
                    if p < len(styles) and text[p] == ";":
                        p += 1
                    continue
                else:
                    # Multiple assignment (aka Example 1)
                    namelist, p = self._getIdentifiersFromPos(
                        styles, text, p+1)

                # The namelist may contain array assignments that we cannot
                # deal with, check to ensure we have a variable assignment that
                # we can deal with.
                #   Handled array assignment examples:
                #     this['field1'] =
                #   Unhandled array assignment examples:
                #     this[0] =
                #     myvar[unknownvar] =
                #
                new_namelist = []
                for name in namelist:
                    if '[' in name:
                        name_parts = name.split('[')
                        for subname in name_parts:
                            if subname.endswith("]"):
                                subname = subname[:-1]
                                # ensure the array reference is a string, otherwise
                                # we cannot do anything with it.
                                if not subname or subname[0] not in "'\"":
                                    log.debug(
                                        "_variableHandler:: Ignoring non-string indexed array assignment: %r", namelist)
                                    return
                                subname = self._unquoteJsString(subname)
                            new_namelist.append(subname)
                    else:
                        new_namelist.append(name)
                namelist = new_namelist
                log.debug(
                    "_variableHandler:: already_looped:: namelist now:%r, p:%d", namelist, p)

            if len(namelist) < 1:
                log.debug(
                    "_variableHandler:: Invalid namelist! Text: %r", text)
                return

            # Whether the namelist includes an array piece whose name/scope
            # could not be determined (i.e. foo[myname] = 1), as myname is
            # an unknown.
            unknown_array_namelist = False

            if p >= len(styles) or text[p] in ",;":
                # It's a uninitialized variable?
                already_known = False
                if len(namelist) == 1:
                    for varType in ("variables", "classes", "functions", "members"):
                        if namelist[0] in getattr(self.currentScope, varType, {}):
                            # it's a variable we already know about, don't
                            # shadow it
                            log.debug(
                                "uninitialized variable %r is already known, skipping",
                                      namelist)
                            already_known = True
                            break
                if not already_known:
                    log.debug("Adding uninitialized variable: %r, line: %d",
                              namelist, lineno)
                    self.addVariable(namelist, [],
                                     doc=self.comment,
                                     isLocal=isLocal)
                already_looped = True
                continue

            if p+1 < len(styles) and text[p] == '[' and \
                 styles[p] == self.JS_OPERATOR:
                # It may be an  array assignment (Example4 above).
                unknown_array_namelist = True
                array_args, p = self._getParenArguments(styles, text, p, '[')
                if len(array_args) == 3 and array_args[1][0] in "'\"":
                    unknown_array_namelist = False
                    namelist.append(self._unquoteJsString(array_args[1]))
                    log.debug("Namelist includes an array scope, now: %r",
                              namelist)
                if p >= len(styles):
                    already_looped = True
                    continue

            typeNames = []
            name_prefix = namelist[0]
            assignChar = text[p]
            try_getter_setter = False

            addToClass = False
            assignToCurrentScope = False
            if assignChar == ":" or name_prefix == "this":
                assignToCurrentScope = True
                if name_prefix == "this" or \
                   isinstance(self.currentScope, JSClass):
                    addToClass = True

            if p+1 < len(styles) and len(namelist) == 1 and \
               name_prefix in ("get", "set") and styles[p] == self.JS_IDENTIFIER:
                log.debug("First element in namelist is a getter/setter")
                try_getter_setter = True

            if p+1 < len(styles) and (try_getter_setter or
                                        (styles[p] == self.JS_OPERATOR and
                                         assignChar in allowedAssignmentChars)):
                if name_prefix == "this":
                    namelist = namelist[1:]
                    if len(namelist) < 1:
                        log.debug(
                            "_variableHandler:: No namelist for 'this'! Text: %r", text)
                        return
                    name_prefix = namelist[0]
                elif name_prefix[0] in "'\"":
                    # String assignment  { "myfield" : 123, ....
                    name_prefix = self._unquoteJsString(name_prefix)
                    namelist = [name_prefix]
                    # Treat it like a variable/object assignment
                    assignToCurrentScope = True

                # Assignment to the scope
                # print "text[p:]", text[p:]
                varType, typeNames, args, p = self._getVariableDetail(
                    namelist, styles, text, p, assignmentChar=assignChar)
                if varType == TYPE_ALIAS:
                    if len(typeNames) < 1 or len(typeNames) == 1 and typeNames[0] in known_javascript_types:
                        # "alias" to a primitive
                        varType = TYPE_VARIABLE
                varType_mapping = dict([(
                    v, k) for k, v in globals().items() if k.startswith("TYPE_")])
                log.debug("_variableHandler:: varType:%r, typeNames:%r, args:%r, p: %d", varType_mapping.get(
                    varType, varType), typeNames, args, p)
                if varType == TYPE_FUNCTION:
                    if addToClass:
                        log.debug(
                            "_variableHandler:: Line %d, class function: %r(%r)",
                                  lineno, namelist, args)
                        self.addClassFunction(namelist, args, doc=self.comment)
                    else:
                        log.debug(
                            "_variableHandler:: Line %d, function: %r(%r)",
                                  lineno, namelist, args)
                        self.addFunction(namelist, args, doc=self.comment,
                                         isLocal=(not assignToCurrentScope))
                elif varType == TYPE_VARIABLE or varType == TYPE_ALIAS:
                    if varType == TYPE_VARIABLE:
                        varCtor = JSVariable
                        typeString = "type"
                    else:  # TYPE_ALIAS
                        varCtor = lambda *args, **kwargs: \
                            JSAlias(target=typeNames, scope=self.currentScope,
                                    *args, **kwargs)
                        typeString = "alias"

                    if assignToCurrentScope:
                        log.debug(
                            "_variableHandler:: Line %d, class member variable: %r (%s=%r)",
                                  lineno, namelist, typeString, typeNames)
                        self.addClassOrVariableMember(namelist, typeNames,
                                                      doc=self.comment,
                                                      isLocal=isLocal,
                                                      varCtor=varCtor)
                    else:
                        if len(namelist) > 1:
                            log.debug(
                                "_variableHandler:: Line %d, scoped assignment: %r, %s=%r scope %r",
                                      lineno, namelist, typeString, typeNames, self.currentScope.name)
                        else:
                            log.debug(
                                "_variableHandler:: Line %d, local variable assignment: %r, %s=%r scope %r",
                                      lineno, namelist, typeString, typeNames, self.currentScope.name)
                        # XXX - Check this, do we need this hack?
                        if typeNames == ["Object"] and text[-1] == "{":
                            # Turn it into a class
                            log.info(
                                "_variableHandler:: Turning Object into class: %r", namelist)
                            # self.addVariable(namelist, typeNames)
                            self.addClass(
                                namelist, doc=self.comment, path=self.path, varCtor=varCtor)
                        else:
                            self.addVariable(namelist, typeNames,
                                             doc=self.comment,
                                             isLocal=isLocal,
                                             varCtor=varCtor)
                    # We ignore any defined functions, as we gain no value from
                    # them
                elif varType == TYPE_PARENT:
                    if len(typeNames) > 0:
                        self.addClassParent(namelist, typeNames)
                    else:
                        self.addAnonymousClass(namelist, doc=self.comment)
                elif varType == TYPE_GETTER:
                    log.debug("_variableHandler:: Found getter:%r", namelist)
                    self.addGetter(namelist, [], doc=self.comment)
                elif varType == TYPE_SETTER:
                    log.debug("_variableHandler:: Found setter:%r", namelist)
                    self.addSetter(namelist, doc=self.comment)
                elif varType == TYPE_OBJECT:
                    # var obj = { observer: function() { ... }, count: 10 }
                    if not typeNames:
                        typeNames = ["Object"]
                    if unknown_array_namelist:
                        # Create a dummy object that will then accept any
                        # subsequent scope assignments. This object will *not*
                        # be included in the cix output.
                        log.debug("_variableHandler:: Line: %d, unknown array "
                                  "assingment, creating a dummy variable: %r",
                                  lineno, namelist)
                        self.currentScope = JSObject(None, self.currentScope,
                                                     self.lineno, self.depth,
                                                     "Object", path=self.path)
                    elif assignToCurrentScope:
                        log.debug(
                            "_variableHandler:: Line %d, class object variable: %r", lineno,
                                  namelist)
                        self.addClassOrVariableMember(namelist, typeNames,
                                                      doc=self.comment,
                                                      assignAsCurrentScope=True)
                    else:
                        log.debug(
                            "_variableHandler:: Line %d, object variable: %r", lineno,
                                  namelist)
                        self.addObjectVariable(namelist, doc=self.comment,
                                               isLocal=isLocal)
                else:
                    log.info(
                        "_variableHandler:: Ignoring. Unhandled assignment type: %r",
                             text)
                    return
            else:
                log.debug(
                    "_variableHandler:: Line %d, calling scoped variable: %r",
                          lineno, namelist)
                for pos, obj in self.objectArguments:
                    if not isinstance(obj, JSFunction):
                        continue
                    # we have a function, tell it about the caller
                    obj.addCaller(caller=namelist, pos=pos, line=lineno)
            already_looped = True

    def createObjectArgument(self, styles, text):
        log.debug("createObjectArgument")
        # obj = toScope.addVariable(varName, self.lineno, self.depth, "Object",
        # doc=doc)
        obj = JSObject(
            None, None, self.lineno, self.depth, "Object", path=self.path)
        return obj

    def _addCodePiece(self, styles, text, pos=0):
        if pos >= len(styles):
            return
        lineno = self.lineno

        log.debug("*** Line: %d ********************************", lineno)
        # log.debug("Styles: %r", self.styles)
        log.debug("Text: %r", self.text[pos:])
        log.debug("currentScope: %s %r", self.currentScope.cixname,
                  self.currentScope.name)
        if self.currentClass:
            log.debug("currentClass: %r", self.currentClass.name)
        if self.in_variable_definition:
            log.debug(
                "in_variable_definition: %r", self.in_variable_definition)
        # print "%d: %r" % (lineno, " ".join(self.text[pos:]))
        # log.debug("Comment: %r", self.comment)
        # log.debug("")

        firstStyle = styles[pos]
        if firstStyle == self.JS_WORD:
            # Keyword
            keyword = text[pos]
            if keyword == "function":
                isLocal = not isinstance(self.currentScope, JSFile)
                namelist, p = self._getIdentifiersFromPos(styles, text, pos+1)
                if namelist:
                    args, p = self._getArgumentsFromPos(styles, text, p)
                    log.debug("Line %d, function: %r(%r)",
                              lineno, namelist, args)
                    self.addFunction(namelist, args, doc=self.comment,
                                     isLocal=isLocal)
                else:
                    # We shall add the function, but without a name as it does
                    # not really have one... it's anonymous.
                    args, p = self._getArgumentsFromPos(styles, text, p)
                    self.addAnonymousFunction(args, doc=self.comment)
            elif keyword == "this":
                # Member variable of current object
                p = pos+1
                if p < len(styles) and styles[p] == self.JS_OPERATOR and \
                   text[p] == ".":
                    namelist, p = self._getIdentifiersFromPos(
                        styles, text, p+1)
                    self._variableHandler(
                        lineno, styles, text, p, ["this"] + namelist)
            elif keyword in ("let", "var", "const"):
                # Variable of current scope
                self.in_variable_definition = True
                namelist, p = self._getIdentifiersFromPos(styles, text, pos+1)
                # if in the global/file scope the variable is global also,
                # if the scope is something else, add as a local variable
                if namelist:
                    isLocal = not isinstance(self.currentScope, JSFile)
                    if p < len(styles):
                        self._variableHandler(
                            lineno, styles, text, p, namelist,
                                              isLocal=isLocal)
                    else:
                        log.debug(
                            "Adding uninitialized variable: %r, line: %d",
                                  namelist, lineno)
                        self.addVariable(namelist, [],
                                         doc=self.comment,
                                         isLocal=isLocal)
            elif keyword == "return":
                p = pos+1
                if p < len(styles) and styles[p] == self.JS_OPERATOR and \
                   text[p] == "{":
                    # Returning a new object
                    self.addReturnObject(doc=self.comment)
                    ## XXX - Fixme to allow variables with sub-elements
                    # log.debug("Ignoring scope due to return of object")
                    # newstate = S_IGNORE_SCOPE
                else:
                    # Return types are only valid in functions
                    if isinstance(self.currentScope, JSFunction):
                        typeNames, p, isAlias = self._getVariableType(
                            styles, text, pos+1, assignmentChar=None)
                        # varType, typeNames, args, p =
                        # self._getVariableDetail([], styles, text, pos,
                        # assignmentChar="return")
                        log.debug("Return type: %r", typeNames)
                        self.addFunctionReturnType(typeNames)
            elif keyword == "if":
                # if (....) xyz
                p = self._skipOverParenArguments(styles, text, pos+1)
                self._addCodePiece(styles, text, p)
            elif keyword == "else":
                pos += 1
                # Check for: 'else if (....) xyz'
                if pos < len(styles) and styles[pos] == self.JS_WORD and \
                   text[pos] == "if":
                    pos = self._skipOverParenArguments(styles, text, pos+1)
                self._addCodePiece(styles, text, pos)
            else:
                log.debug("_addCodePiece: Unhandled keyword:%r", keyword)
        elif firstStyle == self.JS_IDENTIFIER:
            isLocal = False
            if self.in_variable_definition:
                if self.currentScope != self.cile and \
                   ((pos > 0 and text[pos-1] == ",") or
                    (self.lastText and self.lastText[-1] == ",")):
                    isLocal = True
                else:
                    self.in_variable_definition = False
            # Defining scope for action
            namelist, p = self._getIdentifiersFromPos(styles, text, pos)
            self._variableHandler(lineno, styles, text, p, namelist,
                                  allowedAssignmentChars=":=",
                                  isLocal=isLocal)
        elif firstStyle == self.JS_OPERATOR:
            if self.lastText and self.lastText[-1] == "{" and \
               text[:2] == ['(', ')'] and isinstance(self.lastScope, JSFunction):
                # It's a closure
                log.debug("Found a closure: function: %r", self.lastScope.name)
                self._convertFunctionToClosureVariable(self.lastScope)
            else:
                # We don't do anything here
                log.debug("Ignoring when starting with an operator")
        elif firstStyle in self.JS_STRINGS:
            # Check for object string names, see below:
            #   "element1": [ 1, "one" ],
            #   "field1": "name",
            # print "String assignment: %r" % (text[pos], )
            # print "Text: %r" % (text, )
            if pos+1 < len(styles) and \
               styles[pos+1] == self.JS_OPERATOR and text[pos+1] == ":":
                self._variableHandler(lineno, styles, text, pos+1,
                                      text[pos:pos+1],
                                      allowedAssignmentChars=":",
                                      isLocal=False)
        else:
            log.debug("Unhandled first style:%d", firstStyle)

        self._resetState()
        # if log.level == logging.DEBUG:
        #    print
        #    print '\n'.join(self.cile.outline())
        #    print

    def _chooseBestVariable(self, jsvar1, jsvar2):
        # 1. Choose the one with a jsdoc.
        if jsvar1.jsdoc and not jsvar2.jsdoc:
            return jsvar1
        if jsvar2.jsdoc and not jsvar1.jsdoc:
            return jsvar2
        # 2. Choose the one with the a citdl.
        if jsvar1.type and not jsvar2.type:
            return jsvar1
        if jsvar2.type and not jsvar1.type:
            return jsvar2
        # 3. Choose the one with the best citdl. We prefer the one
        #    that is not a standard type, because standard types
        #    can be null or boring :D
        citdl1 = standardizeJSType(jsvar1.type)
        citdl2 = standardizeJSType(jsvar2.type)
        if citdl1 in known_javascript_types and \
           not citdl2 in known_javascript_types:
            return jsvar2
        if citdl2 in known_javascript_types and \
           not citdl1 in known_javascript_types:
            return jsvar1
        # 4. Default to the first one given.
        return jsvar1

    def _copyObjectToAnother(self, jsobject, jsother):
        # print
        # print "Full outline:"
        # print '\n'.join(self.cile.outline())
        # print
        # print "jsobject:"
        # print '\n'.join(jsobject.outline())
        # print
        # print "jsother:"
        # print '\n'.join(jsother.outline())

        appliedToGlobalScope = False
        if jsother == self.cile:
            appliedToGlobalScope = True

        for fieldname in ('classes', 'members', 'variables', 'functions', ):
            d_obj = getattr(jsobject, fieldname, {})
            d_oth = getattr(jsother, fieldname, {})
            for name, jsobj in d_obj.items():
                # Check the parents are not the same.
                if jsobj.parent == jsother:
                    parent = jsobj.parent
                    log.warn("%s %r has parent %s %r, file: %s#%d",
                             parent.cixname, parent.name, jsother.cixname,
                             jsother.name, self.cile.name, self.lineno)
                jsobj.setParent(jsother)
                if appliedToGlobalScope:
                    # Remove the __local__ and private attributes
                    if "__local__" in jsobj.attributes:
                        jsobj.attributes.remove("__local__")
                    if "private" in jsobj.attributes:
                        jsobj.attributes.remove("private")
                if fieldname == 'functions' and jsobj._class:
                    jsobj._class = jsobj.parent
            d_oth.update(d_obj)
        # Ensure the variables are not already known as member variables.
        d_members = getattr(jsother, "members", {})
        d_variables = getattr(jsother, "variables", {})

        for name, jsobj in d_variables.items():
            if name in d_members:
                # Decide which one to keep then, remove the variable and then
                # replace the member with the best choice.
                del d_variables[name]
                d_members[name] = self._chooseBestVariable(d_members[name],
                                                           jsobj)
                log.info("Dupe found: %s %r has both variable and member %r, "
                         "keeping %r", jsother.cixname, jsother.name, name,
                         d_members[name])

        if jsobject.anonymous_functions:
            jsother.anonymous_functions = jsobject.anonymous_functions
            jsobject.anonymous_functions = []

    def _handleDefineProperty(self, styles, text, p):
        # text example:
        #   ['(', 'namespace', ',', '"propname"', ',', '{', ')']
        namelist, p = self._getIdentifiersFromPos(styles, text, p+1)
        if namelist and p+3 < len(styles) and styles[p+1] in self.JS_STRINGS:
            propertyname = self._unquoteJsString(text[p+1])
            if namelist == ["this"]:
                scope = self.currentScope
            else:
                scope = self._findOrCreateScope(namelist, (
                    'variables', 'classes', 'functions'))
            v = JSVariable(propertyname, scope, self.lineno, self.depth)
            if self.lastScope and isinstance(self.lastScope, JSFunction):
                v.type = "%s()" % (self.lastScope.name, )
            scope.addVariable(propertyname, value=v)

    def _handleYAHOOExtension(self, styles, text, p):
        # text example:
        #   ['(', 'Dog', ',', 'Mammal', ',', '{', ')']
        # print "YAHOO!!!!!!"
        # print "len(self.objectArguments): %d" % (len(self.objectArguments), )
        if p+5 < len(styles) and text[p] == "(" and len(self.objectArguments) == 1:
            extendClassNamelist, p = self._getIdentifiersFromPos(
                styles, text, p+1)
            log.debug(
                "_handleYAHOOExtension:: extendClassNamelist: %r", extendClassNamelist)
            parentClassNamelist, p = self._getIdentifiersFromPos(
                styles, text, p+1)
            if extendClassNamelist and parentClassNamelist:
                # Add class parent reference
                # print "Extending %r, parent %r" % (extendClassNamelist,
                # parentClassNamelist)
                jsclass = self._addClassPart(".".join(
                    parentClassNamelist), self.ADD_CLASS_PARENT, extendClassNamelist, path=self.path)
                # Now add all information from objectArguments
                self._copyObjectToAnother(self.objectArguments[0][1], jsclass)
        # log.setLevel(logging.WARN)

    def _handleDojoExtension(self, type, styles, text, p):
        if p+4 < len(styles) and text[p] == "(" and len(self.objectArguments) == 1:
            if type == 'declare':
                extendClassNamelist = self._unquoteJsString(
                    text[p+1]).split('.')
                p += 2
                parentClassNamelist, p = self._getIdentifiersFromPos(
                    styles, text, p+1)
                if len(extendClassNamelist) > 1:
                    scope = self._findOrCreateScope(extendClassNamelist[
                                                    :-1], ('variables', 'classes', 'functions'))
                else:
                    scope = self.currentScope
                # TODO: should use the lineno of dojo.declare rather than
                # self.objectArguments[0][1].line below
                jsclass = JSClass(extendClassNamelist[
                                  -1], scope, self.objectArguments[0][1].line, self.depth)
                scope.classes[jsclass.name] = jsclass
                if parentClassNamelist:
                    jsclass = self._addClassPart(".".join(
                        parentClassNamelist), self.ADD_CLASS_PARENT, extendClassNamelist, path=self.path)
                else:
                    args, p = self._getParenArguments(styles, text, p, '[')
                    parentClassNamelists = ['']
                    for arg in args[1:-1]:
                        if arg == '{':  # super class is null
                            break
                        if arg == ',':
                            parentClassNamelists.append('')
                            continue
                        parentClassNamelists[-1] += arg
                    if len(parentClassNamelists[0]):
                        self._addClassPart(' '.join(
                            parentClassNamelists), self.ADD_CLASS_PARENT, extendClassNamelist, path=self.path)

            else:  # extend
                extendClassNamelist, p = self._getIdentifiersFromPos(
                    styles, text, p+1)
                jsclass = self._locateScopeForName(extendClassNamelist, attrlist=(
                    "classes", "functions", "variables", ))
                if not jsclass:
                    return
                if isinstance(jsclass, JSFunction):
                    jsclass = self._convertFunctionToClass(jsclass)

            if jsclass:
                obj = self.objectArguments[0][1]
                self._copyObjectToAnother(obj, jsclass)
                for f in jsclass.functions:
                    jsclass.functions[f]._class = jsclass
                for f in jsclass.anonymous_functions:
                    f._class = jsclass
                # Change function constructor name to the class name so that it
                # is correctly recognized by Komodo as the constructor.
                if 'constructor' in jsclass.functions:
                    func = jsclass.functions.pop('constructor')
                    func.name = jsclass.name
                    jsclass.functions[jsclass.name] = func

    def _removeObjectFromScope(self, jsobject):
        removename = jsobject.name
        parent = jsobject.parent
        if parent:
            searchScopeNames = ("variables", "functions", "classes",)
            if not isinstance(parent, JSFile):
                searchScopeNames += ("members", )
            for scopeName in searchScopeNames:
                scope = getattr(parent, scopeName)
                if removename in scope and scope[removename] == jsobject:
                    log.debug("Removing %r from scope: %s in %r",
                              removename, scopeName, parent.name)
                    scope.pop(removename)
            if jsobject in parent.anonymous_functions:
                parent.anonymous_functions.remove(jsobject)

    def _handleFunctionApply(self, namelist=None):
        """Everything in the function is applied to the supplied scope/namelist"""
        # XXX : TODO
        #       Not everything should be applied. Only the "this." items get
        #       applied!
        # Examples:
        #   (function() { this.xyz = 1; }).apply(namelist);
        #   // Giving namelist an xyz member.

        if namelist is None:
            scope = self.cile
        else:
            # Find the scope
            scope = self._findOrCreateScope(namelist, attrlist=(
                'variables', 'classes', 'functions', ))
        if self.lastScope and isinstance(self.lastScope, JSFunction):
            applyFrom = self.lastScope
            parent = applyFrom.parent
            if isinstance(parent, JSClass) and \
               parent.name == applyFrom.name:
                # We apply everything from the parent then, except the function
                # itself, start by copying everything inside the function.
                self._copyObjectToAnother(applyFrom, scope)
                # Remove the function now
                del parent.functions[applyFrom.name]
                # The class/parent becomes our next target to copy
                applyFrom = parent
            # Copy across everything in the applyFrom object
            self._copyObjectToAnother(applyFrom, scope)
            # We need to remove the applyFrom object, it's life is done
            self._removeObjectFromScope(applyFrom)
        elif self.lastScope and isinstance(self.lastScope, JSVariable):
            self._copyObjectToAnother(self.lastScope, scope)
        elif self.objectArguments and isinstance(self.objectArguments[0][1], JSObject):
            self._copyObjectToAnother(self.objectArguments[0][1], scope)

    def _handleFunctionWithArguments(self):
        styles = self.styles
        if len(styles) == 0:
            return
        text = self.text
        lineno = self.lineno

        log.debug("*** _handleFunctionWithArguments line: %d ***", lineno)
        # log.debug("Styles: %r", self.styles)
        log.debug("Text: %r", self.text)
        # log.debug("Comment: %r", self.comment)
        # log.debug("")

        pos = 0
        firstStyle = styles[pos]
        getsetPos = None
        try:
            getsetPos = text.index("__defineGetter__")
        except ValueError:
            try:
                getsetPos = text.index("__defineSetter__")
            except ValueError:
                pass
        if getsetPos is not None and len(styles) > getsetPos+3 and \
           styles[getsetPos+2] in self.JS_STRINGS:
            scopeNames, p = self._getIdentifiersFromPos(styles, text, pos)
            namelist = [self._unquoteJsString(text[getsetPos+2])]
            if scopeNames and scopeNames[0] != "this":
                namelist = scopeNames[:-1] + namelist
            if text[getsetPos] == "__defineSetter__":
                self.addSetter(namelist, doc=self.comment)
            else:
                # Getter is different, it can have a type.
                citdl = None
                for i, scope in self.objectArguments:
                    if isinstance(scope, JSFunction):
                        self.lineno = scope.line
                        citdl = scope.getReturnType()
                        break
                if citdl:
                    self.addGetter(namelist, [citdl], doc=self.comment)
                else:
                    self.addGetter(namelist, [], doc=self.comment)
        elif firstStyle == self.JS_IDENTIFIER:
            namelist, p = self._getIdentifiersFromPos(styles, text, pos)
            if not namelist:
                return
            # print "namelist: %r" % (namelist, )
            if namelist == ["Object", "defineProperty"]:
                # Defines a property on a given scope.
                self._handleDefineProperty(styles, text, p)
            elif namelist == ["XPCOMUtils", "defineLazyGetter"]:
                # Mozilla way to define a property on a given scope.
                self._handleDefineProperty(styles, text, p)
            elif namelist[0] == "YAHOO" and \
               namelist[1:] in (["extend"], ["lang", "extend"]):
                # XXX - Should YAHOO API catalog be enabled then?
                self._handleYAHOOExtension(styles, text, p)
            elif namelist[0] == "dojo" and \
               namelist[1:] in (["extend"], ["declare"]):
                self._handleDojoExtension(namelist[1], styles, text, p)
            elif namelist == ["Ext", "extend"]:
                # Same as what YAHOO does.
                self._handleYAHOOExtension(styles, text, p)
            elif namelist == ["Ext", "apply"] and text[p:p+1] == ["("]:
                # Similar to the regular function apply (see below)
                namelist, p = self._getIdentifiersFromPos(styles, text, p+1)
                if namelist:
                    log.info(
                        "Handling Ext.apply on: %r, line: %d", namelist, self.lineno)
                    self._handleFunctionApply(namelist)
        elif firstStyle == self.JS_OPERATOR:
            if text[:4] == [")", ".", "apply", "("]:
                # Special case for function apply
                namelist, p = self._getIdentifiersFromPos(styles, text, pos+4)
                if namelist:
                    self._handleFunctionApply(namelist)
                elif text[3:5] == ["(", ")"]:
                    # Applied to the global namespace
                    self._handleFunctionApply()

    def _findScopeFromContext(self, styles, text):
        """Determine from the text (a namelist) what scope the text is referring
        to. Returns the scope found or None.
        """
        log.debug("_findScopeFromContext: %r" % (text, ))
        scope = None
        try:
            idx = text.index("prototype")
        except ValueError:
            pass
        else:
            # We have a class prototype, find the class and return with that
            # as the current scope. If it's a function that is not part of a
            # class, then convert the function into a class.
            if idx >= 2 and text[idx-1] == ".":
                namelist, p = self._getIdentifiersFromPos(
                    styles[:idx-1], text[:idx-1], 0)
                if namelist:
                    scope = self._locateScopeForName(
                        namelist, attrlist=("classes", ))
                    if not scope:
                        self._locateScopeForName(
                            namelist, attrlist=("functions", ))
                        if isinstance(scope, JSFunction):
                            # Scope is a function, it should be a class,
                            # convert it now.
                            scope = self._convertFunctionToClass(scope)
                    if scope:
                        log.debug("_findScopeFromContext: found %s %r",
                                  scope.cixname, scope.name)
        return scope

    def _resetState(self, newstate=S_DEFAULT):
        self.state = newstate
        self.bracket_depth = 0
        self.styles = []
        self.lastText = self.text
        self.text = []
        if self.comment:
            self.last_comment_and_jsdoc = [self.comment, None]
        self.comment = []
        self.argumentPosition = 0
        self.argumentTextPosition = 0
        self.objectArguments = []
        # log.debug("Set state %d, line: %d", self.state, self.lineno, )

    def _popPreviousState(self, keep_style_and_text=False):
        current_styles = self.styles
        current_text = self.text
        current_arguments = self.objectArguments
        previous_state = self.state
        if len(self.state_stack) >= 1:
            # Reset to previous state
            self.state, self.bracket_depth, self.styles, \
                self.text, self.lastText, self.comment, \
                self.argumentPosition, self.argumentTextPosition, \
                self.objectArguments, \
                self.in_variable_definition = self.state_stack.pop()
        else:
            # Reset them all
            self._resetState()
        log.debug("_popPreviousState:: previous: %d, current: %d",
                  previous_state, self.state)
        if keep_style_and_text:
            self.styles += current_styles
            self.text += current_text
            self.objectArguments = current_arguments

    def _pushAndSetState(self, newstate=S_DEFAULT):
        self.state_stack.appendleft((self.state, self.bracket_depth, self.styles,
                                 self.text, self.lastText, self.comment,
                                 self.argumentPosition,
                                 self.argumentTextPosition,
                                 self.objectArguments,
                                 self.in_variable_definition))
        self._resetState(newstate)
        self.in_variable_definition = False

    def _endOfScanReached(self):
        """Ensure any remaining text is included in the cile"""
        if len(self.styles) > 0:
            self._addCodePiece(self.styles, self.text, pos=0)

    def token_next(self, style, text, start_column, start_line, **other_args):
        """Loops over the styles in the document and stores important info.

        When enough info is gathered, will perform a call to analyze the code
        and generate subsequent language structures. These language structures
        will later be used to generate XML output for the document."""

        if style in self.JS_CILE_STYLES:
            # We keep track of these styles and the text associated with it.
            # When we gather enough info, these will be sent to the
            # _addCodePiece() function which will analyze the info.

            # We want to use real line numbers starting from 1 (not 0)
            start_line += 1
            # print "state: %d, text: %r" % (self.state, self.text, )
            # log.debug("state: %d, line: %d, self.text: %r, text: %r",
            # self.state, start_line, self.text, text)

            if self.state == S_DEFAULT and len(self.styles) > 0 and \
               self.last_lineno < start_line:
                # We have moved down line(s) and we have data, check if we
                # need to add code from the previous line(s)
                # XXX: Need to be careful with e4x!
                if ((style != self.JS_OPERATOR or text[0] not in "({[.,=") and
                    (self.styles[-1] != self.JS_OPERATOR or
                     self.text[-1] not in "({[.,=") and
                    # We need to ignore certains cases, such as:
                    #   "new \n function", see bug 82569.
                    (self.styles[-1] != self.JS_WORD or self.text[-1] != "new")):
                    self._addCodePiece(self.styles, self.text, pos=0)
                    self.in_variable_definition = False
            self.lineno = start_line
            if style != self.JS_OPERATOR:
                self.styles.append(style)
                self.text.append(text)
            else:
                if text == "(":  # Only the "(", it's like above
                    # Check if this is of the form "(function { .... })"
                    # This is a fix for self invoking functions/closures
                    #   http://bugs.activestate.com/show_bug.cgi?id=63297
                    if not self.text:
                        log.debug("Ignoring initial brace: '(' on line %d",
                                  self.lineno)
                        return
                # log.debug("token_next: line %d, %r, text: %r" % (self.lineno,
                # text, self.text))
                for op in text:
                    self.styles.append(style)
                    self.text.append(op)
                    # if self.state == S_OBJECT_ARGUMENT:
                    #    if op not in "{}":
                    #        continue
                    if op == "(":
                        if self.bracket_depth == 0:
                            # We can start defining arguments now
                            log.debug(
                                "Entering S_IN_ARGS state, line: %d, col: %d", start_line, start_column)
                            newscope = self._findScopeFromContext(
                                self.styles, self.text)
                            self._pushAndSetState(S_IN_ARGS)
                            if newscope and self.currentScope != newscope:
                                log.debug("Adjusting scope to: %r %r",
                                          newscope.cixname, newscope.name)
                                # Need to temporarily adjust the scope to deal
                                # with getters, setters and class prototypes.
                                self.currentScope = newscope
                            self.argumentTextPosition = len(self.text)
                        self.bracket_depth += 1
                    elif op == ")":
                        self.bracket_depth -= 1
                        if self.bracket_depth <= 0:
                            # Pop the state, but keep the style and text of
                            # the arguments
                            last_state = self.state
                            self._popPreviousState(keep_style_and_text=True)
                            if self.state != S_IN_ARGS and last_state == S_IN_ARGS:
                                self._handleFunctionWithArguments()
                            log.debug(
                                "Entering state %d, line: %d, col: %d", self.state, start_line, start_column)
                        elif isinstance(self.lastScope, JSFunction) and self.text[-3:] == ['{', '(', ')']:
                            # It's a function argument closure.
                            self.lastScope = self._convertFunctionToClosureVariable(
                                self.lastScope)
                    # elif op == "=":
                    #    if text == op:
                    #        log.debug("Entering S_IN_ASSIGNMENT state, line: %d, col: %d", start_line, start_column)
                    #        self.state = S_IN_ASSIGNMENT
                    elif op == "{":
                        # Increasing depth/scope, could be an argument object
                        if self.state == S_IN_ARGS:
                            # __defineGetter__("num", function() { return
                            # this._num });
                            argTextPos = self.argumentTextPosition
                            if len(self.text) >= 2 and self.text[-2] == ")":
                                # foo( ... ( ... ) {
                                # this really only makes sense as a function expression definition
                                # foo( ... function (...) {
                                # this function may have multiple arguments, so we can't trust
                                # self.argumentTextPosition (which was
                                # clobbered)
                                try:
                                    argsStart = len(self.text) - list(
                                        reversed(self.text)).index("(")
                                    if argsStart > 1:
                                        functionPos = argsStart - \
                                            2  # position of "function" keyword
                                        if self.styles[functionPos] == self.JS_IDENTIFIER:  # named function
                                            functionPos -= 1
                                        if functionPos > -1 and \
                                           self.styles[functionPos] == self.JS_WORD and \
                                           self.text[functionPos] == "function":
                                            # this is indeed a function; check
                                            # arguments for sanity
                                            args = self.text[argsStart:-2]
                                            if all(x == ',' for x in args[1::2]):
                                                # Passing a function as one of the arguments,
                                                # need to create a JSFunction scope for this,
                                                # as various information may be needed, i.e.
                                                # a getter function return
                                                # type.
                                                obj = self.addAnonymousFunction(
                                                    args=args[::2])
                                                # don't append to self.objectArguments here, we do
                                                # it later when we see the
                                                # closing brace
                                                self._pushAndSetState(
                                                    S_DEFAULT)
                                except ValueError:
                                    # no "(" found in self.text
                                    pass
                            elif len(self.text) >= 2 and \
                               ((self.text[-2] == "(" and
                                 self.argumentPosition == 0) or
                                (self.text[-2] == "," and
                                 self.argumentPosition > 0)):
                                # It's an object argument
                                log.debug(
                                    "Entering S_OBJECT_ARGUMENT state, line: %d, col: %d", start_line, start_column)
                                # print "Entering S_OBJECT_ARGUMENT state,
                                # line: %d, col: %d" % (start_line,
                                # start_column)
                                obj = self.createObjectArgument(
                                    self.styles, self.text)
                                self.currentScope = obj
                                self._pushAndSetState(S_OBJECT_ARGUMENT)
                            else:
                                self._pushAndSetState(S_IN_ARGS)
                        else:
                            self._addCodePiece(self.styles, self.text, pos=0)
                            self._pushAndSetState(S_DEFAULT)
                        self.incBlock()
                    elif op == "}":
                        # Decreasing depth/scope
                        previous_state = self.state
                        if self.state != S_IN_ARGS:
                            # only add this piece if we're not in an arg state
                            self._addCodePiece(self.styles, self.text, pos=0)
                        self._popPreviousState()
                        if self.state == S_IN_ARGS:
                            self.objectArguments.append((
                                self.argumentPosition, self.currentScope))
                            log.debug(
                                "Leaving S_OBJECT_ARGUMENT state, entering S_IN_ARGS state, line: %d, col: %d", start_line, start_column)
                            # print "Leaving S_OBJECT_ARGUMENT state, entering
                            # S_IN_ARGS state, line: %d, col: %d" %
                            # (start_line, start_column)
                        self.decBlock()
                    elif op == "," and self.text[0] not in ("let", "var", "const"):
                        # Ignore when it's inside arguments
                        if self.state == S_IN_ARGS:
                            self.argumentPosition += 1
                            self.argumentTextPosition = len(self.text)
                        else:
                            self._addCodePiece(self.styles, self.text, pos=0)
                    elif op == ";":
                        # Statement is done
                        if self.state != S_IN_ARGS:
                            # only add this piece if we're not in an arg state
                            self._addCodePiece(self.styles, self.text, pos=0)
                        self.in_variable_definition = False
            # Remember the last code line we looked at
            self.last_lineno = self.lineno
        elif style in self.JS_COMMENT_STYLES:
            self.comment.append(text)

    def scan_puretext(self, content, updateAllScopeNames=True):
        """Scan the given pure javascript content"""

        # XXX Should eventually use lang_javascript.JavaScriptLexer()
        #    because (1) it's word lists might differ and (2) the
        #    codeintel system manages one instance of it.
        JavaScriptLexer(self.mgr).tokenize_by_style(content, self.token_next)
        # Ensure we take notice of any text left in the ciler
        self._endOfScanReached()
        if updateAllScopeNames:
            # We've parsed up the JavaScript, fix any variables types
            self.cile.updateAllScopeNames()

    def convertToElementTreeFile(self, cixelement, file_lang, module_lang=None):
        """Store JS information into the cixelement as a file(s) sub element"""
        self.cile.convertToElementTreeFile(cixelement, file_lang, module_lang)

    def convertToElementTreeModule(self, cixmodule):
        """Store JS information into already created cixmodule"""
        self.cile.convertToElementTreeModule(cixmodule)


class Utils(object):
    @staticmethod
    def unquoteJsString(s):
        """Return the string without quotes around it"""
        if len(s) >= 2 and s[0] in "\"'":
            return s[1:-1]
        return s

#---- internal support stuff


def _isident(char):
    return "a" <= char <= "z" or "A" <= char <= "Z" or char == "_"


def _isdigit(char):
    return "0" <= char <= "9"


def _walk_js_scopes(scope, lpath=None):
    """Walk the subscopes of the given element.
    Note that in JavaScript <variable> elements with children are
    considered a scope.  Yields (scope, lpath) depth-first.  The given
    top-level element is not yielded.
    """
    if lpath is None:
        lpath = []
    for subscope in scope:
        if subscope.tag == "variable" and not subscope:
            continue
        sublpath = lpath + [subscope.get("name")]
        yield (subscope, sublpath)
        for r in _walk_js_scopes(subscope, sublpath):
            yield r


def _walk_js_symbols(elem, _prefix=None):
    if _prefix:
        lpath = _prefix + (elem.get("name"), )
    else:
        lpath = (elem.get("name"), )
    yield lpath
    if elem.tag == "variable":
        pass  # don't descend into variables
    elif not (elem.tag == "scope" and elem.get("ilk") == "function"):
        for child in elem:
            for child_lpath in _walk_js_symbols(child, lpath):
                yield child_lpath


#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=JavaScriptLexer(mgr),
                      buf_class=JavaScriptBuffer,
                      langintel_class=JavaScriptLangIntel,
                      import_handler_class=JavaScriptImportHandler,
                      cile_driver_class=JavaScriptCILEDriver,
                      is_cpln_lang=True,
                      import_everything=True)

########NEW FILE########
__FILENAME__ = lang_less
#!/usr/bin/env python
# Copyright (c) 2010 ActiveState Software Inc.
# See LICENSE.txt for license details.

"""Less support for CodeIntel"""

import logging

from codeintel2.common import _xpcom_
from codeintel2.lang_css import CSSLexer, CSSLangIntel, CSSBuffer
from codeintel2.lang_css import isident, WHITESPACE
from codeintel2.accessor import AccessorCache
from codeintel2.common import Trigger, TRG_FORM_CPLN, TRG_FORM_CALLTIP
from codeintel2.util import OrdPunctLast
# ... and a whole lot more?

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- globals

log = logging.getLogger("codeintel.less")
# log.setLevel(logging.DEBUG)


#---- language support

class LessLexer(CSSLexer):
    # This must be defined as "Less" in order to get autocompletion working.
    lang = "Less"

    def __init__(self):
        CSSLexer.__init__(self)
        self._properties['lexer.css.less.language'] = '1'


class SCSSLexer(CSSLexer):
    # This must be defined as "SCSS" in order to get autocompletion working.
    lang = "SCSS"

    def __init__(self):
        CSSLexer.__init__(self)
        self._properties['lexer.css.scss.language'] = '1'


class SassLexer(CSSLexer):
    # This must be defined as "Sass" in order to get autocompletion working.
    lang = "Sass"

    def __init__(self):
        CSSLexer.__init__(self)
        # self._properties.setProperty('lexer.css.sass.language', '1')
        self._properties['lexer.css.sass.language'] = '1'

DebugStatus = False


def _OrdPunctLastOnSecondItem(value):
    return OrdPunctLast(value[1])


class _NestedCSSLangIntel(CSSLangIntel):
    def _trg_from_pos(self, buf, pos, implicit=True, DEBUG=False, ac=None, styleClassifier=None):
        # DEBUG = True # not using 'logging' system, because want to be fast
        if DEBUG:
            print "\n----- %s _trg_from_pos(pos=%r, implicit=%r) -----"\
                  % (self.lang, pos, implicit)
        try:
            if pos == 0:
                return None

            if ac is None:
                ac = AccessorCache(buf.accessor, pos, fetchsize=50)
            else:
                ac.resetToPosition(pos)
            # Ensure this variable is initialized as False, it is used by UDL
            # for checking if the css style is inside of a html tag, example:
            #   <p style="mycss: value;" />
            # When it's found that it is such a case, this value is set True
            ac.is_html_style_attribute = False

            last_pos, last_char, last_style = ac.getPrevPosCharStyle()
            if DEBUG:
                print "  _trg_from_pos:: last_pos: %s" % last_pos
                print "  last_char: %r" % last_char
                print "  last_style: %s" % last_style

            # The easy ones are triggering after any of '#.[: '.
            # For speed, let's get the common ' ' out of the way. The only
            # trigger on space is 'complete-property-values'.

            if styleClassifier.is_default(last_style):
                if DEBUG:
                    print "  _trg_from_pos:: Default style: %d, ch: %r" % (last_style, last_char)
                # Move backwards resolving ambiguity, default on "property-
                # values"
                min_pos = max(0, pos - 200)
                while last_pos > min_pos:
                    last_pos, last_char, last_style = ac.getPrevPosCharStyle()
                    if styleClassifier.is_operator(last_style, ac) or styleClassifier.is_value(last_style, ac):
                        if DEBUG:
                            print " _trg_from_pos: space => property-values"
                        return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                                       pos, implicit, extra={"ac": ac})
                    elif styleClassifier.is_tag(last_style, ac):
                        # Now we need to move further back to see which
                        # region we're in.
                        if DEBUG:
                            print " _trg_from_pos: space => tag-names"
                        return self._get_property_name_trigger_check_context(ac, styleClassifier, pos, implicit)
                    elif styleClassifier.is_identifier(last_style, ac):
                        if DEBUG:
                            print " _trg_from_pos: space => property-names"
                        return Trigger(
                            self.lang, TRG_FORM_CPLN, "tag-or-property-names",
                            pos, implicit, extra={"ac": ac})
                if DEBUG:
                    print " _trg_from_pos: couldn't resolve space, settling on property-names"
                return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                               pos, implicit, extra={"ac": ac})

            elif styleClassifier.is_operator(last_style, ac):
                # anchors
                if DEBUG:
                    print "  _trg_from_pos:: OPERATOR style"
                if last_char == '#':
                    return Trigger("CSS", TRG_FORM_CPLN, "anchors",
                                   pos, implicit, extra={"ac": ac})

                elif last_char == ':':
                    try:
                        p, ch, style = ac.getPrevPosCharStyle(
                            ignore_styles=styleClassifier.ignore_styles)
                        if DEBUG:
                            print "  _trg_from_pos:: Looking at p: %d, ch: %r, style: %d" % (p, ch, style)
                    except IndexError:
                        style = None
                    if DEBUG:
                        print "  _trg_from_pos:: style: %r" % (style)
                    if style is None or \
                       not styleClassifier.is_identifier(style, ac):
                    # if style is None or \
                    #   not styleClassifier.is_css_style(style) or \
                    #   styleClassifier.is_class(style, ac):
                        # complete for pseudo-class-names
                        return Trigger(
                            "CSS", TRG_FORM_CPLN, "pseudo-class-names",
                            pos, implicit, extra={"ac": ac})
                    else:
                    # if styleClassifier.is_identifier(style, ac):
                        # calltip for property-values
                        return Trigger(
                            "CSS", TRG_FORM_CALLTIP, "property-values",
                            pos, implicit, extra={"ac": ac})

                # class-names
                elif last_char == '.':
                    return Trigger("CSS", TRG_FORM_CPLN, "class-names",
                                   pos, implicit, extra={"ac": ac})

                # at-rule
                elif last_char == '@':
                    # p, ch, style = ac.getPrevPosCharStyle(ignore_styles=styleClassifier.comment_styles)
                    # XXX - Should check not beyond first rule set
                    #     - Should check not within a rule block.
                    return Trigger("CSS", TRG_FORM_CPLN, "at-rule",
                                   pos, implicit, extra={"ac": ac})
                # Not quite like CSS: don't handle </

            # tag-names
            elif styleClassifier.is_tag(last_style, ac):
                # We trigger on tag names of specified length >= 1 char
                if DEBUG:
                    print "  _trg_from_pos:: TAG style"
                p, ch, style = last_pos, last_char, last_style
                try:
                    while p >= 0:
                        if DEBUG:
                            print "  _trg_from_pos:: Looking at p: %d, ch: %r, style: %d" % (p, ch, style)
                        if not isident(ch):
                            p += 1
                            break
                        elif style != last_style:
                            if DEBUG:
                                print "  _trg_from_pos:: Current style is not a tag: %d" % (style)
                            return None
                        p, ch, style = ac.getPrevPosCharStyle()
                except IndexError:
                    p = 0
                return self._get_property_name_trigger_check_context(ac, styleClassifier, p, implicit)

            elif styleClassifier.is_identifier(last_style, ac):
                if DEBUG:
                    print "  _trg_from_pos:: IDENTIFIER style"
                # property-names
                # print "here", accessor.text_range(0, pos)
                # We trigger on identifier names with any length >= 1 char
                pos = last_pos
                while pos >= 0:
                    pos, ch, style = ac.getPrevPosCharStyle()
                    if not isident(ch):
                        break
                    elif style != last_style:
                        return None
                return self._get_property_name_trigger_check_context(ac, styleClassifier, pos + 1, implicit)

            elif styleClassifier.is_value(last_style, ac):
                p, ch, style = ac.getPrevPosCharStyle(
                    ignore_styles=styleClassifier.comment_styles)
                if DEBUG:
                    print "  _trg_from_pos:: VALUE style"
                    print "  _trg_from_pos::   p: %s" % p
                    print "  _trg_from_pos::   ch: %r" % ch
                    print "  _trg_from_pos::   style: %s" % style
                    ac.dump()
                # Implicit triggering only happens on a whitespace character
                # after any one of these ":,%) " characters
                # Note: last_char can be a value style yet also be whitespace
                #       in straight CSS.
                if last_char in WHITESPACE:
                    return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                                   last_pos+1, implicit, extra={"ac": ac})
                elif ch in WHITESPACE or ch in ":,%)":
                    # Check to ensure this is not a pseudo-class! Bug:
                    #   http://bugs.activestate.com/show_bug.cgi?id=71073
                    if ch == ":":
                        # Last style must be an identifier then!
                        pp, pch, pstyle = ac.getPrevPosCharStyle(
                            ignore_styles=styleClassifier.ignore_styles)
                        if DEBUG:
                            print "pp: %d, pch: %r, pstyle: %d" % (pp, pch,
                                                                   pstyle)
                        if not styleClassifier.is_identifier(pstyle, ac):
                            # This is likely a pseudo-class definition then,
                            # no trigger here.
                            if DEBUG:
                                print "pseudo-class style found, no trigger."
                            return None
                    return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                                   p+1, implicit, extra={"ac": ac})
                # For explicit, we can also be inside a property already
                if not implicit and isident(ch):
                    # If there is already part of a value there, we need to move
                    # the trigger point "p" to the start of the value.
                    while isident(ch):
                        p, ch, style = ac.getPrevPosCharStyle()
                    return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                                   p+1, implicit, extra={"ac": ac})
                return None

            elif DEBUG:
                print "  _trg_from_pos:: Unexpected style: %d, ch: %r" % (last_style, last_char)

            # XXX "at-property-names" - Might be used later
            # elif last_style == SCE_CSS_DIRECTIVE:
            #    # property-names
            #    # We trigger on identifier names with length == 3
            #    #print "here", accessor.text_range(0, pos)
            #    if pos >= 4 and accessor.char_at_pos(pos - 4) == ' ' and \
            #       self._is_ident_of_length(accessor, pos, length=3):
            #        # We are good for completion
            #        if DEBUG:
            #            print "Got a trigger for 'at-property-names'"
            #        return Trigger("CSS", TRG_FORM_CPLN, "at-property-names",
            #                       pos-3, implicit, extra={"ac": ac})

        except IndexError:
            # Wen't out of range of buffer before we found anything useful
            pass

        if DEBUG:
            print "----- CSS trg_from_pos() -----"
        return None

    def _get_property_name_trigger_check_context(self, ac,
                                                 styleClassifier, pos, implicit):
        min_pos = pos - 200
        if min_pos < 1:
            min_pos = 1
        try:
            ac.resetToPosition(pos)
        except IndexError:
            # We're at the start, so return tags only
            return Trigger("CSS", TRG_FORM_CPLN, "tag-names",
                           pos, implicit, extra={"ac": ac})

        # States:
        #
        last_pos, last_ch, last_style = ac.getCurrentPosCharStyle()
        # print "_get_property_name_trigger_check_context: last_pos:%d,
        # last_ch:%c, last_style:%d" % (last_pos, last_ch, last_style)
        cpln_type = None
        p = last_pos
        while p > min_pos:
            try:
                p, ch, style = ac.getPrevPosCharStyle()
            except IndexError:
                p, ch, style = last_pos, last_ch, last_style
            if ch == '\n' and styleClassifier.is_default(style):
                # Main heuristic: if the tag starts on col 1, assume we're at
                # the top-level
                if (styleClassifier.is_tag(last_style)
                        or styleClassifier.is_operator(last_style)):
                    cpln_type = "tag-names"
                    break
                elif styleClassifier.is_default(last_style):
                    cpln_type = "tag-or-property-names"
                    break
            elif ch == '{' and styleClassifier.is_operator(style):
                cpln_type = "tag-or-property-names"
                break
            if p < min_pos:
                break
            last_ch = ch
            last_style = style
        if cpln_type is None:
            if p <= 0:
                cpln_type = "tag-names"
            else:
                cpln_type = "tag-or-property-names"
        if cpln_type == "tag-or-property-names":
            lang = self.lang
        else:
            lang = "CSS"  # Use the parent class.
        return Trigger(lang, TRG_FORM_CPLN, cpln_type,
                       pos, implicit, extra={"ac": ac})

    def _async_eval_at_trg(self, buf, trg, ctlr, styleClassifier):
        if _xpcom_:
            trg = UnwrapObject(trg)
            ctlr = UnwrapObject(ctlr)
        # Handle ambiguous property-names here
        DEBUG = DebugStatus
        # DEBUG = True
        if DEBUG:
            print "Less: _async_eval_at_trg: trg: %s(%r)" % (trg, trg)
        if trg.id != (self.lang, TRG_FORM_CPLN, "tag-or-property-names"):
            CSSLangIntel._async_eval_at_trg(
                self, buf, trg, ctlr, styleClassifier)
            return
        if DEBUG:
            print "\n----- async_eval_at_trg(trg=%r) -----"\
                  % (trg)

        # Setup the AccessorCache
        extra = trg.extra
        ac = None
        # print "Extra: %r" % (extra)
        if isinstance(extra, dict):
            extra = extra.get("extra", None)
            if isinstance(extra, dict):
                ac = extra.get("ac", None)
                if ac and DEBUG:
                    print "  _async_eval_at_trg:: Trigger had existing AC"
                    ac.dump()
        if ac is None:
            if DEBUG:
                print "  _async_eval_at_trg:: Created new trigger!"
            ac = AccessorCache(buf.accessor, trg.pos, fetchsize=20)

        ctlr.start(buf, trg)
        pos = trg.pos
        try:
            cplns1 = [("property", v + ": ") for v in self.CSS_PROPERTY_NAMES]
            cplns2 = [("element", v) for v in self.CSS_HTML_TAG_NAMES]
            cplns = sorted(cplns1 + cplns2, key=_OrdPunctLastOnSecondItem)
            # Note: we add the colon as well - see bug 89913.
            ctlr.set_cplns(cplns)
            # print "  _async_eval_at_trg:: cplns:", cplns
            ctlr.done("success")
            trg.retriggerOnCompletion = True
        except IndexError:
            # Tried to go out of range of buffer, nothing appropriate found
            if DEBUG:
                print "  _async_eval_at_trg:: ** Out of range error **"
            ctlr.done("success")


class _NestedSassLangIntel(_NestedCSSLangIntel):
    """ The difference here is that we don't want to put up triggers in
    the leading whitespace of a line.
    """
    def _trg_from_pos(self, buf, pos, implicit=True, DEBUG=False, ac=None, styleClassifier=None):
        # DEBUG = True # not using 'logging' system, because want to be fast
        if DEBUG:
            print "\n----- %s _trg_from_pos(pos=%r, implicit=%r) -----"\
                  % (self.lang, pos, implicit)
        try:
            if pos == 0:
                return None

            if ac is None:
                ac = AccessorCache(buf.accessor, pos, fetchsize=50)
            else:
                ac.resetToPosition(pos)
            # Ensure this variable is initialized as False, it is used by UDL
            # for checking if the css style is inside of a html tag, example:
            #   <p style="mycss: value;" />
            # When it's found that it is such a case, this value is set True
            ac.is_html_style_attribute = False

            last_pos, last_char, last_style = ac.getPrevPosCharStyle()
            if DEBUG:
                print "  _trg_from_pos:: last_pos: %s" % last_pos
                print "  last_char: %r" % last_char
                print "  last_style: %s" % last_style

            # All we want to know with sass is if we're in the white-space on
            # of after the start of a line.  If yes, don't trigger, because
            # the user might want to just type more spaces.

            if styleClassifier.is_default(last_style):
                if DEBUG:
                    print "  _trg_from_pos:: Default style: %d, ch: %r" % (last_style, last_char)
                if last_char == '\n':
                    # SASS: we don't want to put up a box until we start typing
                    # something.
                    if DEBUG:
                        print "Found \\n at current pos, don't trigger."
                    return None
                min_pos = max(0, pos - 200)
                while last_pos > min_pos:
                    last_pos, last_char, last_style = ac.getPrevPosCharStyle()
                    if styleClassifier.is_default(last_style):
                        if last_char == '\n':
                            return None
                    else:
                        break
            # Fallback and do SCSS/Less/CSS triggering.
            # TODO: Support ":color blue" colon-first notation.
            # TODO: After ",\n", offer tag-names if the above line starts with a tab.
            #      Otherwise, indent the same level, and then offer tag-names.
            return _NestedCSSLangIntel._trg_from_pos(self, buf, pos, implicit=implicit, DEBUG=DEBUG, ac=None, styleClassifier=styleClassifier)
        except IndexError:
            pass


class LessLangIntel(_NestedCSSLangIntel):
    # This must be defined as "Less" in order to get autocompletion working.
    lang = "Less"


class SCSSLangIntel(_NestedCSSLangIntel):
    lang = "SCSS"


class SassLangIntel(_NestedSassLangIntel):
    lang = "Sass"


class LessBuffer(CSSBuffer):
    lang = "Less"


class SCSSBuffer(CSSBuffer):
    lang = "SCSS"


class SassBuffer(CSSBuffer):
    lang = "Sass"
    cpln_fillup_chars = CSSBuffer.cpln_fillup_chars.replace(" ", "")
    cpln_stop_chars = CSSBuffer.cpln_stop_chars.replace(" ", "")

#---- registration


def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info("Less",
                      silvercity_lexer=LessLexer(),
                      buf_class=LessBuffer,
                      langintel_class=LessLangIntel,
                      is_cpln_lang=True)
    mgr.set_lang_info("SCSS",
                      silvercity_lexer=SCSSLexer(),
                      buf_class=SCSSBuffer,
                      langintel_class=SCSSLangIntel,
                      is_cpln_lang=True)
    mgr.set_lang_info("Sass",
                      silvercity_lexer=SassLexer(),
                      buf_class=SassBuffer,
                      langintel_class=SassLangIntel,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_mason
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Mason support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin

#---- globals

lang = "Mason"
log = logging.getLogger("codeintel.mason")


#---- language support
class MasonLexer(UDLLexer):
    lang = lang


class MasonBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    tpl_lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "Perl"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    # - wanted for CSS completion: " ('\";},.>"
    # - wanted for JS completion:  "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    # - dropping '-' because causes problem with CSS (bug 78312)
    # - dropping '!' because causes problem with CSS "!important" (bug 78312)
    # TODO: adjust for Perl, if necessary
    cpln_stop_chars = "'\" (;},~`@#%^&*()=+{}]|\\;,.<>?/"


class MasonCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"
    ssl_lang = "Perl"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=MasonLexer(),
                      buf_class=MasonBuffer,
                      import_handler_class=None,
                      cile_driver_class=MasonCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_nodejs
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2010-2011
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""NodeJS support for CodeIntel"""

import os
import json
import logging

from codeintel2.util import makePerformantLogger
from codeintel2.lang_javascript import (JavaScriptLexer,
                                        JavaScriptLangIntel,
                                        JavaScriptBuffer,
                                        JavaScriptImportHandler,
                                        JavaScriptCILEDriver)
from codeintel2.tree_javascript import JavaScriptTreeEvaluator

#---- globals

lang = "Node.js"
log = logging.getLogger("codeintel.nodejs")
# log.setLevel(logging.DEBUG)
makePerformantLogger(log)


#---- language support

class NodeJSTreeEvaluator(JavaScriptTreeEvaluator):
    @property
    def nodejslib(self):
        if not hasattr(self, "_nodejslib"):
            for lib in self.libs:
                if lib.name == "node.js stdlib":
                    self._nodejslib = lib
                    break
            else:
                self._nodejslib = None
        return self._nodejslib

    def _hits_from_commonjs_require(self, requirename, scoperef):
        """Resolve hits from a CommonJS require() invocation"""
        # this overrides the version in tree_javascript
        # (JavaScriptTreeEvaluator)
        from codeintel2.database.langlib import LangDirsLib
        from codeintel2.database.multilanglib import MultiLangDirsLib
        from codeintel2.database.catalog import CatalogLib

        self.log("resolving require(%r) in %r", requirename, scoperef[0])

        stdlib = self.nodejslib
        if stdlib.has_blob(requirename + ".js"):
            # require(X) where X is a core module
            self.log("require(%r) is a core module", requirename)
            blob = stdlib.blobs_with_basename(
                requirename + ".js", ctlr=self.ctlr)[0]
            exports = blob.names.get("exports")
            return self._hits_from_variable_type_inference(exports, [blob, ["exports"]])

        srcdir = os.path.dirname(scoperef[0].get("src") or self.buf.path)
        if srcdir == "":
            # no source directory, can't do non-core lookups
            self.log(
                "no source directory found, can't resolve require(%r)", requirename)
            return []

        def get_hits_from_lib(lib, filename):
            """Get the hits from a given LangDirsLib, or None"""
            hits = []
            basename = os.path.basename(filename)
            blobs = lib.blobs_with_basename(basename, ctlr=self.ctlr)
            for blob in blobs or []:
                if os.path.normpath(blob.get("src")) != filename:
                    # wrong file
                    continue
                self.log("require() found at %s", filename)
                exports = blob.names.get("exports")
                if exports is not None and exports.tag == "variable":
                    hits += self._hits_from_variable_type_inference(
                        exports, [blob, ["exports"]])
                else:
                    # try module.exports
                    module = blob.names.get("module")
                    if module is not None:
                        exports = module.names.get("exports")
                        if exports is not None and exports.tag == "variable":
                            hits += self._hits_from_variable_type_inference(
                                exports, [blob, ["module", "exports"]])
            return hits or None

        def load_as_file(path):
            """Load "path" as a file and return hits from there
            If it does not exist / isn't a valid node.js module, return None
            """
            path = os.path.normpath(path)
            if os.path.isfile(path):
                filename = path
            elif os.path.isfile(path + ".js"):
                filename = path + ".js"
            else:
                # we don't deal with binary components; otherwise, it's missing
                return None
            self.log("looking to resolve require() via %s", path)
            dirname = os.path.dirname(filename)

            for lib in self.libs:
                if lib == self.nodejslib:
                    # skip the core modules, they're looked at above
                    continue
                if not isinstance(lib, (LangDirsLib, MultiLangDirsLib)):
                    # can't deal with anything but these
                    self.log("skipping lib %r, don't know how to deal", lib)
                    continue

                if dirname in map(os.path.normpath, lib.dirs):
                    # Found a lib with the directory we want. Whether we found
                    # a hit or not, we don't need to look in any other libs
                    # (since they will just give the same results)
                    self.log(
                        "looking up lib %r (filename %r)", lib.dirs, filename)
                    return get_hits_from_lib(lib, filename)

            # none of the libs we know about has it, but we do have a file...
            # try to force scan it
            lib = self.mgr.db.get_lang_lib(
                self.lang, "node_modules_lib", (dirname,))
            return get_hits_from_lib(lib, filename)

        def load_as_directory(path):
            """Load "path" as a directory and return hits from there
            If it does not exist / isn't a valid node.js module, return None
            """
            path = os.path.normpath(path)
            if not os.path.isdir(path):
                # not a directory, don't bother
                return None
            hits = None
            manifest_path = os.path.join(path, "package.json")
            if os.path.isfile(manifest_path):
                manifest_file = open(manifest_path)
                try:
                    manifest = json.load(manifest_file)
                    if "main" in manifest:
                        main_path = os.path.join(path, manifest.get("main"))
                        main_path = os.path.normpath(main_path)
                        self.log("found module via %r, trying %r",
                                 manifest_path, main_path)
                        hits = load_as_file(main_path)
                except ValueError, e:
                    self.log("Error loading %r: %r", manifest_path, e)
                finally:
                    manifest_file.close()
            if hits is None:
                hits = load_as_file(os.path.join(path, "index"))
            return hits

        if requirename.lstrip(".").startswith("/"):
            self.log("require(%r) is file system", requirename)
            # filesystem path
            if requirename.startswith("/"):
                filename = requirename
            elif requirename.startswith("./") or requirename.startswith("../"):
                filename = os.path.join(srcdir, requirename)
            else:
                # invalid name
                return []
            filename = os.path.normpath(filename)
            self.log(
                "resolving relative require(%r) via %s", requirename, filename)
            hits = load_as_file(filename)
            if hits is None:
                hits = load_as_directory(filename)
            return hits or []

        # if we get here, this is a bare module name, require("foo") or
        # require("foo/bar")
        parts = os.path.normpath(srcdir).split(os.sep)
        try:
            root_index = parts.index("node_modules") - 1
        except ValueError:
            # no node_modules in the path at all
            root_index = -1
        for part_index in range(len(parts), root_index, -1):
            if part_index > 0 and parts[part_index - 1] == "node_modules":
                # don't try foo/node_modules/node_modules
                continue
            dir = os.sep.join(parts[:part_index] + ["node_modules"])
            hits = load_as_file(os.path.join(dir, requirename))
            if hits is None:
                hits = load_as_directory(os.path.join(dir, requirename))
            if hits is not None:
                return hits

        # last-ditch: try the extradirs pref
        extra_dirs = []
        for pref in self.buf.env.get_all_prefs(self.langintel.extraPathsPrefName):
            if not pref:
                continue
            for dir in pref.split(os.pathsep):
                dir = dir.strip()
                if not os.path.isdir(dir):
                    continue
                if not dir in extra_dirs:
                    extra_dirs.append(dir)
        for dir in extra_dirs:
            hits = load_as_file(os.path.join(dir, requirename))
            if hits is None:
                hits = load_as_directory(os.path.join(dir, requirename))
            if hits is not None:
                return hits

        self.log("Failed to find module for require(%r)", requirename)

        # getting here means we exhausted all possible modules; give up
        return []


class NodeJSLexer(JavaScriptLexer):
    lang = lang


class NodeJSLangIntel(JavaScriptLangIntel):
    lang = lang
    _evaluatorClass = NodeJSTreeEvaluator
    interpreterPrefName = "nodejsDefaultInterpreter"
    extraPathsPrefName = "nodejsExtraPaths"

    def _get_nodejs_version_from_env(self, env=None):
        import process
        executable = env.get_pref("nodejsDefaultInterpreter", None)
        if not executable:
            import which
            path = [d.strip()
                    for d in env.get_envvar("PATH", "").split(os.pathsep)
                    if d.strip()]
            try:
                executable = which.which("node", path=path)
            except which.WhichError:
                pass
        if not executable:
            return None
        if not os.path.exists(executable):
            log.info("Node.js executable %s does not exist", executable)
            return None
        p = process.ProcessOpen([executable, "--version"],
                                env=env.get_all_envvars(), stdin=None)
        stdout, stderr = p.communicate()
        if p.returncode != 0:
            log.info("Failed to find Node.js version: %r: %s",
                     p.returncode, stderr)
            return None  # Failed to run
        version = stdout.lstrip("v")
        short_ver = ".".join(version.split(".", 2)[:2])
        return short_ver

    def _get_stdlibs_from_env(self, env=None):
        libdir = os.path.join(os.path.dirname(__file__), "lib_srcs", "node.js")
        version = self._get_nodejs_version_from_env(env)
        if version:
            versioned_libdir = os.path.join(libdir, version)
        if version and os.path.isdir(versioned_libdir):
            # we have a lib matching the running version of Node.js
            libdir = versioned_libdir
        else:
            # No valid Node.js version, or no matching lib: use highest we have
            versions = [tuple(int(part or 0) for part in v.split("."))
                        for v in os.listdir(libdir)
                        if os.path.isdir(os.path.join(libdir, v))
                        and not v.strip("0123456789.")]
            if versions:
                max_version = sorted(versions, reverse=True)[0]
                version = ".".join(str(v) for v in max_version)
                libdir = os.path.join(libdir, version)
        db = self.mgr.db
        node_sources_lib = db.get_lang_lib(lang="Node.js",
                                           name="node.js stdlib",
                                           dirs=(libdir,))
        return [node_sources_lib,
                db.get_stdlib(self.lang)]


class NodeJSBuffer(JavaScriptBuffer):
    lang = lang


class NodeJSImportHandler(JavaScriptImportHandler):
    lang = lang


class NodeJSCILEDriver(JavaScriptCILEDriver):
    lang = lang

#---- registration


def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=NodeJSLexer(mgr),
                      buf_class=NodeJSBuffer,
                      langintel_class=NodeJSLangIntel,
                      import_handler_class=NodeJSImportHandler,
                      cile_driver_class=NodeJSCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_perl
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Perl support for CodeIntel"""

import os
from os.path import (normpath, join, exists, splitext, basename, isdir,
                     normcase, dirname, islink, isabs)
import sys
import logging
import time
from glob import glob
import re
from pprint import pprint, pformat
import weakref

import process
from ciElementTree import Element, SubElement, tostring
import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants

from codeintel2.common import *
from codeintel2.citadel import (ImportHandler, CitadelBuffer,
                                CitadelEvaluator, CitadelLangIntel)
from codeintel2.citadel_common import ScanRequest
from codeintel2.indexer import PreloadLibRequest
from codeintel2.parseutil import urlencode_path
from codeintel2 import perlcile
from codeintel2.util import isident, isdigit, banner, indent, markup_text
from codeintel2.tree_perl import (PerlTreeEvaluator,
                                  PerlPackageSubsTreeEvaluator,
                                  PerlPackageMembersTreeEvaluator)
from codeintel2.langintel import (ParenStyleCalltipIntelMixin,
                                  ProgLangTriggerIntelMixin)

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- globals
line_end_re = re.compile("(?:\r\n|\r)")

lang = "Perl"
log = logging.getLogger("codeintel.perl")
# log.setLevel(logging.DEBUG)


#---- language support
class PerlLexer(Lexer):
    lang = "Perl"

    def __init__(self):
        self._properties = SilverCity.PropertySet()
        self._lexer = SilverCity.find_lexer_module_by_id(
            ScintillaConstants.SCLEX_PERL)
        self._keyword_lists = [
            SilverCity.WordList(SilverCity.Keywords.perl_keywords)
        ]


# TODO: Merge handling of perl-complete-module-exports in with this one.
#      Will just need a boolean flag (on the trigger) indicating that
#      submodules should NOT be included.
class PerlImportsEvaluator(Evaluator):
    def __str__(self):
        return "Perl imports"

    def eval(self, mgr):
        try:
            prefix = self.trg.extra["prefix"]
            if prefix:
                self.ctlr.set_desc("subimports of '%s'" % prefix)
                prefix_tuple = tuple(prefix.split("::"))
            else:
                self.ctlr.set_desc("available imports")
                prefix_tuple = ()

            all_imports = set()
            for lib in self.buf.libs:
                # Reminder: A codeintel "blob" corresponds to a Perl module.
                all_imports.update(lib.get_blob_imports(prefix_tuple))

            if all_imports:
                cplns = [((is_dir_import and "directory" or "module"), name)
                         for name, is_dir_import in all_imports]
                cplns.sort(key=lambda i: i[1].upper())
                self.ctlr.set_cplns(cplns)
        finally:
            self.ctlr.done("success")


class PerlLangIntel(CitadelLangIntel,
                    ParenStyleCalltipIntelMixin,
                    ProgLangTriggerIntelMixin):
    lang = "Perl"

    # Add '=' to the default set for Perl. For example:
    #   my $foo =
    #     ^     ^
    #     |     `-- terminate calltip here
    #     `-- calltip triggers here
    # Because Perl doesn't have keywords args to functions this can work.
    calltip_region_terminators = tuple(']});=')
    preceding_trg_terminators = {';': None, '=': None}

    # XXX This cog regen is out-of-date. Re-write to parse perl.cix?
    # To regenerate this block:
    # - install the cog Python tool:
    #   http://www.nedbatchelder.com/code/cog/index.html
    # - run "cog -r lang_perl.py"
    #[[[cog
    # import cog
    # import os, sys
    # sys.path.insert(0, os.path.join(os.pardir, "codeintel"))
    # import cidb
    # dbpath = cidb.find_komodo_cidb_path()
    # sql = """SELECT symbol.name FROM file,scan,module,symbol
    #          WHERE file.compare_path LIKE '%perl.cix'
    #            AND scan.file_id=file.id AND module.scan_id=scan.id
    #            AND symbol.module_id=module.id AND symbol.type=0"""
    # cog.outl('_allow_trg_on_space_from_identifier = {')
    # for line in cidb.query(dbpath, 3, sql, "csv"):
    #    cog.outl('    "%s": 1,' % line.strip())
    # cog.outl('}')
    #]]]
    _allow_trg_on_space_from_identifier = {
        "-r": 1,
        "-w": 1,
        "-x": 1,
        "-o": 1,
        "-R": 1,
        "-W": 1,
        "-X": 1,
        "-O": 1,
        "-e": 1,
        "-z": 1,
        "-s": 1,
        "-f": 1,
        "-d": 1,
        "-l": 1,
        "-p": 1,
        "-S": 1,
        "-b": 1,
        "-c": 1,
        "-t": 1,
        "-u": 1,
        "-g": 1,
        "-k": 1,
        "-T": 1,
        "-B": 1,
        "-M": 1,
        "-A": 1,
        "-C": 1,
        "UNITCHECK": 1,
        "abs": 1,
        "accept": 1,
        "alarm": 1,
        "atan2": 1,
        "bind": 1,
        "binmode": 1,
        "bless": 1,
        "break": 1,
        "caller": 1,
        "chdir": 1,
        "chmod": 1,
        "chomp": 1,
        "chop": 1,
        "chown": 1,
        "chr": 1,
        "chroot": 1,
        "close": 1,
        "closedir": 1,
        "connect": 1,
        "continue": 1,
        "cos": 1,
        "crypt": 1,
        "dbmclose": 1,
        "dbmopen": 1,
        "default": 1,
        "defined": 1,
        "delete": 1,
        "die": 1,
        "do": 1,
        "dump": 1,
        "each": 1,
        "eof": 1,
        "eval": 1,
        "exec": 1,
        "exists": 1,
        "exit": 1,
        "exp": 1,
        "fcntl": 1,
        "fileno": 1,
        "flock": 1,
        "fork": 1,
        "format": 1,
        "formline": 1,
        "getc": 1,
        "getlogin": 1,
        "getpeername": 1,
        "getpgrp": 1,
        "getppid": 1,
        "getpriority": 1,
        "getpwnam": 1,
        "getgrnam": 1,
        "gethostbyname": 1,
        "getnetbyname": 1,
        "getprotobyname": 1,
        "getpwuid": 1,
        "getgrgid": 1,
        "getservbyname": 1,
        "gethostbyaddr": 1,
        "getnetbyaddr": 1,
        "getprotobynumber": 1,
        "getservbyport": 1,
        "getpwent": 1,
        "getgrent": 1,
        "gethostent": 1,
        "getnetent": 1,
        "getprotoent": 1,
        "getservent": 1,
        "setpwent": 1,
        "setgrent": 1,
        "sethostent": 1,
        "setnetent": 1,
        "setprotoent": 1,
        "setservent": 1,
        "endpwent": 1,
        "endgrent": 1,
        "endhostent": 1,
        "endnetent": 1,
        "endprotoent": 1,
        "endservent": 1,
        "getsockname": 1,
        "getsockopt": 1,
        "given": 1,
        "glob": 1,
        "gmtime": 1,
        "goto": 1,
        "grep": 1,
        "hex": 1,
        "import": 1,
        "index": 1,
        "int": 1,
        "ioctl": 1,
        "join": 1,
        "keys": 1,
        "kill": 1,
        "last": 1,
        "lc": 1,
        "lcfirst": 1,
        "length": 1,
        "link": 1,
        "listen": 1,
        "local": 1,
        "localtime": 1,
        "lock": 1,
        "log": 1,
        "lstat": 1,
        "m": 1,
        "map": 1,
        "mkdir": 1,
        "msgctl": 1,
        "msgget": 1,
        "msgrcv": 1,
        "msgsnd": 1,
        "my": 1,
        "next": 1,
        "no": 1,
        "oct": 1,
        "open": 1,
        "opendir": 1,
        "ord": 1,
        "our": 1,
        "pack": 1,
        "package": 1,
        "pipe": 1,
        "pop": 1,
        "pos": 1,
        "print": 1,
        "printf": 1,
        "prototype": 1,
        "push": 1,
        "q": 1,
        "qq": 1,
        "qr": 1,
        "qx": 1,
        "qw": 1,
        "quotemeta": 1,
        "rand": 1,
        "read": 1,
        "readdir": 1,
        "readline": 1,
        "readlink": 1,
        "readpipe": 1,
        "recv": 1,
        "redo": 1,
        "ref": 1,
        "rename": 1,
        "reset": 1,
        "return": 1,
        "reverse": 1,
        "rewinddir": 1,
        "rindex": 1,
        "rmdir": 1,
        "s": 1,
        "say": 1,
        "scalar": 1,
        "seek": 1,
        "seekdir": 1,
        "select": 1,
        "semctl": 1,
        "semget": 1,
        "semop": 1,
        "send": 1,
        "setpgrp": 1,
        "setpriority": 1,
        "setsockopt": 1,
        "shift": 1,
        "shmctl": 1,
        "shmget": 1,
        "shmread": 1,
        "shmwrite": 1,
        "shutdown": 1,
        "sin": 1,
        "sleep": 1,
        "socket": 1,
        "socketpair": 1,
        "sort": 1,
        "splice": 1,
        "split": 1,
        "sprintf": 1,
        "sqrt": 1,
        "srand": 1,
        "stat": 1,
        "state": 1,
        "study": 1,
        "substr": 1,
        "symlink": 1,
        "syscall": 1,
        "sysopen": 1,
        "sysread": 1,
        "sysseek": 1,
        "system": 1,
        "syswrite": 1,
        "tell": 1,
        "telldir": 1,
        "tie": 1,
        "tied": 1,
        "time": 1,
        "times": 1,
        "tr": 1,
        "truncate": 1,
        "uc": 1,
        "ucfirst": 1,
        "umask": 1,
        "undef": 1,
        "unlink": 1,
        "unpack": 1,
        "untie": 1,
        "unshift": 1,
        "utime": 1,
        "values": 1,
        "vec": 1,
        "wait": 1,
        "waitpid": 1,
        "wantarray": 1,
        "warn": 1,
        "when": 1,
        "write": 1,
        "y": 1,
    }
    #[[[end]]]

    # Match a subroutine definition. Used by trg_from_pos()
    _sub_pat = re.compile(r"\bsub\s+(\w+(::|'))*\w+$")
    # All Perl trigger points occur at one of these characters:
    #   ' ' (space)         only supported for built-in functions
    #   '(' (open paren)
    #   '>' (greater than)  "->" actually
    #   ':' (colon)         "::" actually
    trg_chars = tuple(' (>:')
    calltip_trg_chars = tuple(' (')

    def trg_from_pos(self, buf, pos, implicit=True):
        """
        Implemented triggers
            calltip-space-call-signature
            calltip-call-signature
            complete-package-members
            complete-*-subs meaning the actual trigger is one of:
                complete-package-subs
                complete-object-subs
            complete-available-imports

        Not yet implemented:
            complete-module-exports
        """
        DEBUG = False  # not using 'logging' system, because want to be fast
        if DEBUG:
            print banner("trg_from_pos(pos=%r, implicit=%r)"
                         % (pos, implicit))

        accessor = buf.accessor
        last_pos = pos - 1
        last_ch = accessor.char_at_pos(last_pos)
        if DEBUG:
            print "  last_pos: %s" % last_pos
            print "  last_ch: %r" % last_ch

        # All Perl trigger points occur at one of the trg_chars.
        if last_ch not in self.trg_chars:
            if DEBUG:
                print "no: %r is not in %r" % (last_ch, self.trg_chars)
            return None
        elif last_ch == ':' \
            and not (last_pos > 0
                     and accessor.char_at_pos(last_pos-1) == ':'):
            if DEBUG:
                penultimate_ch = (last_pos > 0
                                  and accessor.char_at_pos(last_pos-1) or '')
                print "no: %r is not '::'" % (penultimate_ch+last_ch)
            return None
        elif last_ch == '>' \
                and not (last_pos > 0 and accessor.char_at_pos(last_pos-1) == '-'):
            if DEBUG:
                penultimate_ch = (last_pos > 0
                                  and accessor.char_at_pos(last_pos-1) or '')
                print "no: %r is not '->'" % (penultimate_ch+last_ch)
            return None

        # We should never trigger in some styles (strings, comments, etc.).
        last_style = accessor.style_at_pos(last_pos)
        if DEBUG:
            last_style_names = buf.style_names_from_style_num(last_style)
            print "  style: %s %s" % (last_style, last_style_names)
        if (implicit and last_style in buf.implicit_completion_skip_styles
                or last_style in buf.completion_skip_styles):
            if DEBUG:
                print "no: completion is suppressed "\
                      "in style at %s: %s %s"\
                      % (last_pos, last_style, last_style_names)
            return None

        WHITESPACE = tuple(' \t\n\r')
        if last_ch == ' ':
            # This can be either "calltip-space-call-signature",
            # "complete-available-imports", or None (or
            # "complete-module-exports" when that is implemented).
            #
            # calltip-call-signature:
            #   Perl syntax allows a parameter list to be passed to a
            #   function name without enclosing parens. From a quick perusal
            #   of sample Perl code (from a default ActivePerl install)
            #   calling function this way seems to be limited to a number of
            #   core Perl built-ins or some library methods. For efficiency
            #   Komodo will maintain an explicit list of such function names
            #   for which a calltip with trigger without parentheses.
            #   XXX May want to make this a user-configurable list.
            #
            # complete-available-imports:
            #   After 'use', 'require' or 'no' by itself on a line.
            #
            LIMIT = 50
            text = accessor.text_range(max(
                0, last_pos-LIMIT), last_pos)  # working text
            if DEBUG:
                print "  working text: %r" % text
            i = len(text)-1
            if i >= 0 and not (isident(text[i]) or isdigit(text[i])):
                if DEBUG:
                    print "no: two before trigger point is not "\
                          "an ident char: '%s'" % text[i]
                return None
            while i >= 0:  # parse out the preceding identifier
                if not isident(text[i]):
                    identifier = text[i+1:]
                    # Whitespace is allowed between a Perl variable special
                    # char and the variable name, e.g.: "$ myvar", "@  mylist"
                    j = i
                    while j >= 0 and text[j] in WHITESPACE:  # parse off whitespace
                        j -= 1
                    if j >= 0:
                        preceding_ch = text[j]
                    else:
                        preceding_ch = None
                    break
                i -= 1
            else:
                preceding_ch = None
                identifier = text
            if DEBUG:
                print "  identifier: %r" % identifier
            if not identifier:
                if DEBUG:
                    print "no: no identifier preceding trigger point"
                return None
            if DEBUG:
                print "  preceding char: %r" % preceding_ch
            if identifier in ("use", "require", "no"):
                return Trigger("Perl", TRG_FORM_CPLN,
                               "available-imports", pos, implicit, prefix="")
            if preceding_ch and preceding_ch in "$@&%\\*":  # indicating a Perl variable
                if DEBUG:
                    print "no: triggering on space after Perl "\
                          "variables not supported"
                return None
            if identifier not in self._allow_trg_on_space_from_identifier:
                if DEBUG:
                    print ("no: identifier not in set for which "
                           "space-triggering is supported "
                           "(_allow_trg_on_space_from_identifier)")
                return None
            # Specifically disallow trigger on defining a sub matching one of
            # space-trigger names, i.e.: 'sub split <|>'. Optmization: Assume
            # that there is exacly one space between 'sub' and the subroutine
            # name. Almost all examples in the Perl lib seem to follow this.
            if i >= 3 and text[i-3:i+1] == "sub ":
                if DEBUG:
                    print "no: do not trigger in sub definition"
                return None
            if DEBUG:
                print "calltip-space-call-signature"
            return Trigger("Perl", TRG_FORM_CALLTIP,
                           "space-call-signature", pos, implicit)

        elif last_ch == '(':
            # This can be either "calltip-call-signature" or None (or
            # "complete-module-exports" when that is implemented).
            LIMIT = 100
            text = accessor.text_range(max(
                0, last_pos-LIMIT), last_pos)  # working text
            if DEBUG:
                print "  working text: %r" % text
            i = len(text)-1
            while i >= 0 and text[i] in WHITESPACE:  # parse off whitespace
                i -= 1
            if i >= 0 and not (isident(text[i]) or isdigit(text[i])):
                if DEBUG:
                    print "no: first non-ws char before "\
                          "trigger point is not an ident char: '%s'" % text[i]
                return None
            end = i+1
            while i >= 0:  # parse out the preceding identifier
                if not isident(text[i]):
                    identifier = text[i+1:end]
                    # Whitespace is allowed between a Perl variable special
                    # char and the variable name, e.g.: "$ myvar", "@  mylist"
                    j = i
                    while j >= 0 and text[j] in WHITESPACE:  # parse off whitespace
                        j -= 1
                    if j >= 0:
                        preceding_ch = text[j]
                    else:
                        preceding_ch = None
                    break
                i -= 1
            else:
                preceding_ch = None
                identifier = text[:end]
            if DEBUG:
                print "  identifier: %r" % identifier
            if DEBUG:
                assert ' ' not in identifier, "parse error: space in identifier: %r" % identifier
            if not identifier:
                if DEBUG:
                    print "no: no identifier preceding trigger point"
                return None
            if DEBUG:
                print "  preceding char: %r" % preceding_ch
            if preceding_ch and preceding_ch in "$@%\\*":
                # '&foo(' *is* a trigger point, but the others -- '$foo(',
                # '&$foo(', etc. -- are not because current CodeIntel wouldn't
                # practically be able to determine the method to which $foo
                # refers.
                if DEBUG:
                    print "no: calltip trigger on Perl var not supported"
                return None
            if identifier in ("if", "else", "elsif", "while", "for",
                              "sub", "unless", "my", "our"):
                if DEBUG:
                    print "no: no trigger on anonymous sub or control structure"
                return None
            # Now we want to rule out the subroutine definition lines, e.g.:
            #    sub FOO(<|>
            #    sub FOO::BAR(<|>
            #    sub FOO'BAR(<|>
            #    sub FOO::BAR::BAZ(<|>
            # Note: Frankly 80/20 rules out the last three.
            line = text[:end].splitlines(0)[-1]
            if DEBUG:
                print "  trigger line: %r" % line
            if "sub " in line:  # only use regex if "sub " on that line
                if DEBUG:
                    print "  *could* be a subroutine definition"
                if self._sub_pat.search(line):
                    if DEBUG:
                        print "no: no trigger on Perl sub definition"
                    return None
            if DEBUG:
                print "calltip-call-signature"
            return Trigger("Perl", TRG_FORM_CALLTIP, "call-signature",
                           pos, implicit)

        elif last_ch == '>':
            # Must be "complete-package-subs", "complete-object-subs"
            # or None. Note that we have already checked (above) that the
            # trigger string is '->'. Basically, as long as the first
            # non-whitespace char preceding the '->' is an identifier char,
            # then this is a trigger point.
            LIMIT = 50
            text = accessor.text_range(max(
                0, last_pos-1-LIMIT), last_pos-1)  # working text
            if DEBUG:
                print "  working text: %r" % text
            i = len(text)-1
            while i >= 0 and text[i] in WHITESPACE:  # parse off whitespace
                i -= 1
            if i < 0:
                if DEBUG:
                    print "no: no non-whitespace text preceding '->'"
                return None
            elif not (isident(text[i]) or text[i].isdigit()):
                if DEBUG:
                    print "no: first non-ws char before "\
                          "trigger point is not an ident char: '%s'" % text[i]
                return None
            # At this point we know it is either "complete-package-subs"
            # or "complete-object-subs". We don't really care to take
            # the time to distinguish now -- trg_from_pos is supposed to be
            # quick -- and we don't have to.
            if DEBUG:
                print "complete-*-subs"
            return Trigger("Perl", TRG_FORM_CPLN, "*-subs", pos, implicit,
                           length=2)

        elif last_ch == ':':
            # Must be "complete-package-members" or
            # "complete-available-imports" or None. Note that we have
            # already checked (above) that the trigger string is '::'.
            # Basically, as long as the first char preceding the '::' is
            # an identifier char or one of Perl's funny variable
            # identifying characters, then this is a trigger point.
            LIMIT = 50
            text = accessor.text_range(max(
                0, last_pos-1-LIMIT), last_pos-1)  # working text
            if DEBUG:
                print "  working text: %r" % text
            i = len(text)-1
            if i < 0:
                if DEBUG:
                    print "no: no text preceding '::'"
                return None
            ch = text[i]
            if not (isident(ch) or isdigit(ch) or ch == '$'):
                # Technically should allow '@', '%' and '&' in there, but
                # there a total of 5 of all of this in the Perl std lib.
                # 80/20 rule.
                if DEBUG:
                    print "no: first char before trigger "\
                          "point is not an ident char or '$': '%s'" % ch
                return None
            # Check if this is in a 'use' or 'require' statement.
            while i > 0 and text[i-1] not in WHITESPACE:  # skip to whitespace
                i -= 1
            prefix = text[i:pos-2]
            while i > 0 and text[i-1] in WHITESPACE:  # skip over whitespace
                i -= 1
            start_idx = end_idx = i
            while start_idx > 0 and (isident(text[start_idx-1])
                                     or text[start_idx-1] in '$@%'):
                start_idx -= 1
            ident = text[start_idx:end_idx]
            if ident in ("use", "require", "no"):
                if DEBUG:
                    print "complete-available-imports (prefix=%r)" % prefix
                return Trigger("Perl", TRG_FORM_CPLN, "available-imports",
                               pos, implicit, length=2, prefix=prefix)
            if DEBUG:
                print "complete-package-members (prefix=%r)" % prefix
            return Trigger("Perl", TRG_FORM_CPLN, "package-members", pos,
                           implicit, length=2, prefix=prefix)

        return None

    _perl_var_pat = re.compile(
        r"((?P<prefix>[$@%\\*&]+)\s*)?(?P<scope>(::)?\b((?!\d)\w*?(::|'))*)(?P<name>(?!\d)\w+)$")

    def citdl_expr_and_prefix_filter_from_trg(self, buf, trg):
        """Parse out the Perl expression at the given trigger and return
        a CITDL expression for it (and possibly a variable prefixj
        filter).

        Returns a 2-tuple:
            (<CITDL-expression>, <variable-prefix-filter>)

        For all triggers except TRG_FORM_DEFN, we parse out the Perl
        expression preceding the trigger position, simplify the
        expression (by removing whitespace, etc.) and translate that to
        an appropriate CITDL (*) expression. Set to None if there is no
        appropriate such expression. For TRG_FORM_DEFN triggers we first
        move forward to the end of the current word.

        As well, a variable prefix filter may be returned, useful for
        post-processing of completions. For example:

            Perl code           CITDL expression    prefix filter
            ---------           ----------------    -------------
            Foo::Bar<|>::       Foo::Bar            None
            $Foo::Bar<|>::      Foo::Bar            $

        Optimization Notes:
        - We can throw out Perl expressions with function calls
          because CodeIntel does not currently handle return values.
        - We can throw out Perl exprs that span an EOL: 80/20 rule. (We
          currently don't throw these away, though.)
        - Abort at hash and list indexing: the types of elements in these
          objects are not tracked by CodeIntel.
        - Punt on Perl references, e.g. \$foo, \@bar. XXX I wonder if I can
          just ignore references and assume the user is doing the right
          thing. I.e. I just presume that a reference is dereferenced
          properly when required. Dunno.
        - Currently we don't really make use of the styling info because we
          abort at indexing, function call arguments, etc. where recognizing
          string/number/regex boundaries would be useful. This info might be
          useful later if this algorithm is beefed up.
        - Ignore ampersand, e.g. &foo. This is just an old way to call perl
          functions - bug 87870, we can just ignore it for codeintel.

        Examples:

            GIVEN                       LEADING EXPR            CITDL EXPR
            -----                       ------------            ----------
            split <|>                   split                   split
            chmod(<|>                   chmod                   chmod
            $Foo::bar(<|>               $Foo::bar               Foo.$bar
            &$make_coffee(<|>           &$make_coffee           $make_coffee
            Win32::OLE-><|>             Win32::OLE              Win32::OLE
            Win32::OLE->GetObject(<|>   Win32::OLE->GetObject   Win32::OLE.GetObject
            split join <|>              join                    join
            foo->bar(<|>                foo->bar                foo.bar

        Note that the trigger character is sometimes necessary to resolve
        ambiguity. Given "Foo::Bar" without the trailing trigger char, we
        cannot know if the CITDL should be "Foo.Bar" or "Foo::Bar":

            GIVEN               CITDL EXPR
            -----               ----------
            Foo::Bar::<|>       Foo::Bar
            $Foo::Bar::<|>      Foo::Bar
            Foo::Bar-><|>       Foo::Bar
            Foo::Bar(<|>        Foo.Bar
            Foo::Bar <|>        Foo.Bar
            $Foo::Bar-><|>      Foo.$Bar
            $Foo::Bar(<|>       Foo.$Bar
            $Foo::Bar <|>       Foo.$Bar

        * http://specs.tl.activestate.com/kd/kd-0100.html#citdl
        """
        DEBUG = False
        if DEBUG:
            print
            print banner("citdl_expr_and_prefix_filter_from_trg @ %d"
                         % trg.pos)
            print markup_text(buf.accessor.text, trg_pos=trg.pos)
            print banner(None, '-')

        if trg.implicit:
            skip_styles = buf.implicit_completion_skip_styles
        else:
            skip_styles = {}
        filter, citdl = None, []

        accessor = buf.accessor
        LIMIT = max(0, trg.pos-100)  # working text area
        if trg.form == TRG_FORM_DEFN:
            # "Go to Definition" triggers can be in the middle of an
            # expression. If so we want to move forward to the end of
            # the current *part*. E.g., given:
            #   $fo<+>o->bar()
            # move forward to:
            #   $foo<|>->bar()
            # and NOT to:
            #   $foo->bar<|>()
            #
            # Perl package names are considered one "part":
            #   $Fo<+>o::Bar->blah()           $Foo::Bar<|>->blah()
            #
            # Note: I suspect there are some problems with the
            # subsequent parsing on when/if to convert "Foo::Bar" to
            # "Foo.Bar" since codeintel2 changed Perl cpln eval.
            p = trg.pos
            length = accessor.length()
            while p < length:
                if not _is_perl_var_char(accessor.char_at_pos(p)):
                    break
                p += 1
            # Gracefully handle some situations where we are positioned
            # after a trigger string. E.g. "Foo::Bar::<|> "
            if p >= 2 and accessor.text_range(p-2, p) in ("->", "::"):
                p = p - 2

            if DEBUG:
                print "'defn'-trigger: adjust position %d" % (p-trg.pos)
        else:
            p = trg.pos - trg.length

        p -= 1
        while p >= LIMIT:
            # Parse off a perl variable/identifier.
            if DEBUG:
                print "look for Perl var at end of %r"\
                      % accessor.text_range(LIMIT, p+1)
            match = self._perl_var_pat.search(
                accessor.text_range(LIMIT, p+1))
            if not match:
                if DEBUG:
                    if p-LIMIT > 20:
                        segment = '...'+accessor.text_range(p-20, p+1)
                    else:
                        segment = accessor.text_range(LIMIT, p+1)
                    print "could not match a Perl var off %r" % segment
                citdl = None
                break
            prefix = match.group("prefix") or ""
            if "&" in prefix:
                prefix = prefix.replace("&", "")
            scope = match.group("scope")
            name = match.group("name")

            trg_ch = None
            try:
                # TODO:PERF: Use the available faster accessor methods here.
                trg_ch = accessor.char_at_pos(p+1)
            except IndexError, ex:
                if trg.form != TRG_FORM_DEFN:
                    log.warn("text does not include trailing trigger "
                             "char to resolve possible ambiguities in '%s'",
                             match.group(0))
            if trg_ch == ':':
                # XXX fix off-by-one here
                # Foo::Bar<|>::       Foo::Bar
                # $Foo::Bar<|>::      Foo::Bar
                citdl.insert(0, scope+name)  # intentionally drop prefix
                # The prefix string is relevant for filtering the list of
                # members for AutoComplete. E.g. if the prefix char is '&' then
                # only subs should be shown. If '%', then only hashes.
                filter = prefix
            elif trg_ch == '-' and not prefix:
                # XXX fix off-by-one here
                # Foo::Bar<|>->       Foo::Bar
                citdl.insert(0, scope+name)
            else:
                # XXX fix off-by-one here
                # Foo::Bar<|>(        Foo.Bar
                # Foo::Bar<|>         Foo.Bar         # trigger char is a space here
                # $Foo::Bar<|>->      Foo.$Bar
                # $Foo::Bar<|>(       Foo.$Bar
                # $Foo::Bar<|>        Foo.$Bar        # trigger char is a space here
                citdl.insert(0, prefix+name)
                if scope:
                    scope = scope[:-2]  # drop trailing '::'
                    if scope:
                        citdl.insert(0, scope)
            p -= len(match.group(0))
            if DEBUG:
                print "parse out Perl var: %r (prefix=%r, scope=%r, "\
                      "name=%r): %r" % (match.group(0), prefix, scope,
                                        name, citdl)

            # Preceding characters will determine if we stop or continue.
            WHITESPACE = tuple(" \t\n\r\v\f")
            while p >= LIMIT and accessor.char_at_pos(p) in WHITESPACE:
                # if DEBUG: print "drop whitespace: %r" % text[p]
                p -= 1
            if p >= LIMIT and accessor.style_at_pos(p) in skip_styles:
                if DEBUG:
                    style = accessor.style_at_pos(p)
                    style_names = buf.style_names_from_style_num(style)
                    print "stop at style to ignore: %r (%s %s)"\
                          % (accessor.char_at_pos(p), style, style_names)
                break
            elif p >= LIMIT+1 and accessor.text_range(p-1, p+1) == '->':
                if DEBUG:
                    print "parse out '->'"
                p -= 2
                while p >= LIMIT and accessor.char_at_pos(p) in WHITESPACE:
                    # if DEBUG: print "drop whitespace: %r" % text[p]
                    p -= 1
                continue
            else:
                break

        if citdl:
            retval = ('.'.join(citdl), filter)
        else:
            retval = (None, filter)
        if DEBUG:
            print "returning: %r" % (retval,)
            banner("done")
        return retval

    def async_eval_at_trg(self, buf, trg, ctlr):
        if _xpcom_:
            trg = UnwrapObject(trg)
            ctlr = UnwrapObject(ctlr)
        assert trg.lang == "Perl"
        ctlr.start(buf, trg)

        if trg.id == ("Perl", TRG_FORM_CPLN, "available-imports"):
            evalr = PerlImportsEvaluator(ctlr, buf, trg)
            buf.mgr.request_eval(evalr)
            return

        # Remaining triggers all use this parsed CITDL expr.
        # Extract the leading CITDL expression (and possible filter,
        # i.e. '$', '@', ...).
        try:
            citdl_expr, filter \
                = self.citdl_expr_and_prefix_filter_from_trg(buf, trg)
        except CodeIntelError, ex:
            ctlr.error(str(ex))
            ctlr.done("error")
            return

        # Perl's trg_from_pos doesn't distinguish btwn "package-subs"
        # and "object-subs" trigger type -- calling them both "*-subs".
        # Let's do so here.
        if trg.type == "*-subs":
            assert citdl_expr
            if isident(citdl_expr[0]):
                trg.type = "package-subs"
            else:
                trg.type = "object-subs"

        if trg.id == ("Perl", TRG_FORM_CPLN, "package-members"):
            # [prefix]SomePackage::<|>
            # Note: This trigger has the "prefix" extra attr which could
            #       be used instead of the leading CITDL expr parse.
            line = buf.accessor.line_from_pos(trg.pos)
            evalr = PerlPackageMembersTreeEvaluator(ctlr, buf, trg, citdl_expr,
                                                    line, filter)
            buf.mgr.request_eval(evalr)
        elif trg.id == ("Perl", TRG_FORM_CPLN, "package-subs"):
            # SomePackage-><|>
            assert not filter, "shouldn't be Perl filter prefix for " \
                "'complete-package-subs': %r" % filter
            line = buf.accessor.line_from_pos(trg.pos)
            evalr = PerlPackageSubsTreeEvaluator(
                ctlr, buf, trg, citdl_expr, line)
            buf.mgr.request_eval(evalr)
        # TODO: Might want to handle TRG_FORM_DEFN differently.
        else:
            if citdl_expr is None:
                ctlr.info("no CITDL expression found for %s" % trg)
                ctlr.done("no trigger")
                return
            line = buf.accessor.line_from_pos(trg.pos)
            if trg.id[1] == TRG_FORM_DEFN and citdl_expr[0] == '$':
                current_pos = trg.pos
                lim = buf.accessor.length
                while buf.accessor.style_at_pos(current_pos) == ScintillaConstants.SCE_PL_SCALAR and current_pos < lim:
                    current_pos += 1
                c = buf.accessor.char_at_pos(current_pos)
                if c == '[':
                    citdl_expr = '@' + citdl_expr[1:]
                elif c == '{':
                    citdl_expr = '%' + citdl_expr[1:]
            evalr = PerlTreeEvaluator(ctlr, buf, trg, citdl_expr,
                                      line, filter)
            buf.mgr.request_eval(evalr)

    def libs_from_buf(self, buf):
        env = buf.env

        # A buffer's libs depend on its env and the buf itself so
        # we cache it on the env and key off the buffer.
        if "perl-buf-libs" not in env.cache:
            env.cache["perl-buf-libs"] = weakref.WeakKeyDictionary()
        cache = env.cache["perl-buf-libs"]  # <buf-weak-ref> -> <libs>

        if buf not in cache:
            # - curdirlib
            # Using the dirname of this buffer isn't always right, but
            # hopefully is a good first approximation.
            cwd = dirname(buf.path)
            if cwd == "<Unsaved>":
                libs = []
            else:
                libs = [self.mgr.db.get_lang_lib("Perl", "curdirlib", [cwd])]

            libs += self._buf_indep_libs_from_env(env)
            cache[buf] = libs
        return cache[buf]

    def perl_info_from_env(self, env):
        # Return an array of [perl_ver, config_dirs, import_path]
        cache_key = self.lang + "-info"
        info = env.cache.get(cache_key)
        if info is None:
            perlInterpreter = self._perl_from_env(env)
            if not perlInterpreter:
                log.warn("no Perl interpreter was found from which to determine the "
                         "codeintel information")
                info = None, None, None
            else:
                info = self._perl_info_from_perl(perlInterpreter, env)
            env.cache[cache_key] = info
        return info

    def _perl_from_env(self, env):
        import which
        path = [d.strip()
                for d in env.get_envvar("PATH", "").split(os.pathsep)
                if d.strip()]
        try:
            return which.which("perl", path=path)
        except which.WhichError:
            return None

    def _perl_info_from_perl(self, perl, env):
        """Call the given Perl and return:
            (<version>, <config_dirs>, <import_path>)
        where <config_dirs> is a dict with (relevant) dirs from
        Config.pm.
        """
        import process

        info_cmd = (r'use Config;'
                    r'print "version:$Config{version}\n";'
                    r'print "siteprefix:$Config{siteprefix}\n";'
                    r'print "archlib:$Config{archlib}\n";'
                    r'print "privlib:$Config{privlib}\n";'
                    r'print "vendorarch:$Config{vendorarch}\n";'
                    r'print "vendorlib:$Config{vendorlib}\n";'
                    r'print join("\n", @INC);')
        argv = [perl, "-e", info_cmd]
        log.debug("run `%s -e ...'", perl)
        p = process.ProcessOpen(argv, env=env.get_all_envvars(), stdin=None)
        stdout, stderr = p.communicate()
        stdout_lines = stdout.splitlines(0)
        retval = p.returncode
        if retval:
            log.warn("failed to determine Perl info:\n"
                     "  path: %s\n"
                     "  retval: %s\n"
                     "  stdout:\n%s\n"
                     "  stderr:\n%s\n",
                     perl, retval, indent('\n'.join(stdout_lines)),
                     indent(stderr))

        perl_ver = stdout_lines[0].split(':', 1)[1]
        config_dirs = dict(
            siteprefix=stdout_lines[1].split(':', 1)[1],
            archlib=stdout_lines[2].split(':', 1)[1],
            privlib=stdout_lines[3].split(':', 1)[1],
            vendorarch=stdout_lines[4].split(':', 1)[1],
            vendorlib=stdout_lines[5].split(':', 1)[1],
        )
        import_path = stdout_lines[6:]

        return perl_ver, config_dirs, import_path

    def _extra_dirs_from_env(self, env):
        extra_dirs = set()
        for pref in env.get_all_prefs("perlExtraPaths"):
            if not pref:
                continue
            extra_dirs.update(d.strip() for d in pref.split(os.pathsep)
                              if exists(d.strip()))
        return tuple(extra_dirs)

    def _buf_indep_libs_from_env(self, env):
        """Create the buffer-independent list of libs."""
        cache_key = "perl-libs"
        if cache_key not in env.cache:
            env.add_pref_observer("perl", self._invalidate_cache)
            env.add_pref_observer("perlExtraPaths",
                                  self._invalidate_cache_and_rescan_extra_dirs)
            env.add_pref_observer("codeintel_selected_catalogs",
                                  self._invalidate_cache)
            db = self.mgr.db

            # Gather information about the current perl.
            perl = None
            if env.has_pref("perl"):
                perl = env.get_pref("perl").strip() or None
            if not perl or not exists(perl):
                perl = self._perl_from_env(env)
            if not perl:
                log.warn("no Perl was found from which to determine the "
                         "import path")
                perl_ver, config_dirs, import_path = None, {}, []
            else:
                perl_ver, config_dirs, import_path \
                    = self._perl_info_from_perl(perl, env)

            libs = []

            # - extradirslib
            extra_dirs = self._extra_dirs_from_env(env)
            if extra_dirs:
                log.debug("Perl extra lib dirs: %r", extra_dirs)
                libs.append(db.get_lang_lib("Perl", "extradirslib",
                                            extra_dirs))

            # Figuring out where the lib and sitelib dirs are is hard --
            # or at least complex from my P.O.V.
            # - For ActivePerl (on Linux, at least):
            #      $ perl -e 'print join "\n", @INC'
            #      /home/trentm/opt/ActivePerl-5.8.8.818/site/lib
            #           (sitearch, sitelib, siteprefix)
            #      /home/trentm/opt/ActivePerl-5.8.8.818/lib
            #           (archlib, privlib)
            #      . (???, we'll handle with curdirlib)
            # - For /usr/bin/perl on skink (ubuntu 6):
            #      $ /usr/bin/perl -e 'print join "\n", @INC'
            #      /etc/perl (???)
            #      /usr/local/lib/perl/5.8.7 (sitearch, siteprefix)
            #      /usr/local/share/perl/5.8.7 (sitelib, siteprefix)
            #      /usr/lib/perl5 (vendorarch)
            #      /usr/share/perl5 (vendorlib)
            #      /usr/lib/perl/5.8 (archlib)
            #      /usr/share/perl/5.8 (privlib)
            #      /usr/local/lib/site_perl (???, siteprefix)
            paths_from_libname = {"sitelib": [], "envlib": [], "stdlib": []}
            for dir in import_path:
                dir = normpath(dir)
                if dir == ".":  # -> curdirlib (handled separately)
                    continue
                if islink(dir):
                    # Note: this doesn't handle multiple levels of
                    # links.
                    link_value = os.readlink(dir)
                    if isabs(link_value):
                        dir = link_value
                    else:
                        dir = normpath(join(dirname(dir), link_value))

                if not isdir(dir):
                    log.debug("perl @INC value '%s' is not a dir: dropping it",
                              dir)
                    continue
                for config_dir_name in ("archlib", "privlib",
                                        "vendorarch", "vendorlib"):
                    if config_dirs[config_dir_name] \
                       and dir.startswith(config_dirs[config_dir_name]):
                        paths_from_libname["stdlib"].append(dir)
                        break
                else:
                    if config_dirs["siteprefix"] \
                            and dir.startswith(config_dirs["siteprefix"]):
                        paths_from_libname["sitelib"].append(dir)
                    else:
                        paths_from_libname["envlib"].append(dir)
            log.debug("Perl %s paths for each lib:\n%s",
                      perl_ver, indent(pformat(paths_from_libname)))

            # - envlib, sitelib, cataloglib, stdlib
            if paths_from_libname["envlib"]:
                libs.append(db.get_lang_lib("Perl", "envlib",
                                            paths_from_libname["envlib"]))
            if paths_from_libname["sitelib"]:
                libs.append(db.get_lang_lib("Perl", "sitelib",
                                            paths_from_libname["sitelib"]))
            catalog_selections = env.get_pref("codeintel_selected_catalogs")
            libs += [
                db.get_catalog_lib("Perl", catalog_selections),
                db.get_stdlib("Perl", perl_ver)
            ]
            env.cache[cache_key] = libs

        return env.cache[cache_key]

    def _invalidate_cache(self, env, pref_name):
        for key in ("perl-buf-libs", "perl-libs"):
            if key in env.cache:
                log.debug("invalidate '%s' cache on %r", key, env)
                del env.cache[key]

    def _invalidate_cache_and_rescan_extra_dirs(self, env, pref_name):
        self._invalidate_cache(env, pref_name)
        extra_dirs = self._extra_dirs_from_env(env)
        if extra_dirs:
            extradirslib = self.mgr.db.get_lang_lib(
                "Perl", "extradirslib", extra_dirs)
            request = PreloadLibRequest(extradirslib)
            self.mgr.idxr.stage_request(request, 1.0)

    #---- code browser integration
    cb_import_group_title = "Uses and Requires"

    def cb_import_data_from_elem(self, elem):
        alias = elem.get("alias")
        symbol = elem.get("symbol")
        module = elem.get("module")
        if symbol:
            if symbol == "*":
                name = module
                detail = "use %s" % module
            elif symbol == "**":
                name = module
                detail = "use %s qw(:<tag>)" % module
            else:
                name = "::".join([module, symbol])
                detail = "use %s qw(%s)" % (module, symbol)
        else:
            name = module
            # This is either "use Foo ();" or "require Foo;". A search
            # the of the Perl 5.8 site lib should that the latter is about
            # 6 times more likely -- lets use that.
            detail = "require %s" % module
        return {"name": name, "detail": detail}


class PerlBuffer(CitadelBuffer):
    lang = "Perl"
    sce_prefixes = ["SCE_PL_"]

    cb_show_if_empty = True

    # 'cpln_fillup_chars' exclusions for Perl:
    # - cannot be '-' for "complete-*-subs" because:
    #       attributes::->import(__PACKAGE__, \$x, 'Bent');
    # - cannot be '{' for "complete-object-subs" because:
    #       my $d = $self->{'escape'};
    # - shouldn't be ')' because:
    #       $dumper->dumpValue(\*::);
    # - shouldn't be ':' (bug 65292)
    cpln_fillup_chars = "~`!@#$%^&*(=+}[]|\\;'\",.<>?/ "
    cpln_stop_chars = "-~`!@#$%^&*()=+{}[]|\\;:'\",.<>?/ "

    def __init__(self, *args, **kwargs):
        CitadelBuffer.__init__(self, *args, **kwargs)

        # Some Perl styles in addition to the usual comment and string styles
        # in which completion triggering should not happen.
        self.completion_skip_styles[ScintillaConstants.SCE_PL_REGEX] = True

    @property
    def libs(self):
        return self.langintel.libs_from_buf(self)

    @property
    def stdlib(self):
        return self.libs[-1]


class PerlImportHandler(ImportHandler):
    PATH_ENV_VAR = "PERL5LIB"
    sep = "::"

    def _shellOutForPath(self, compiler):
        import process
        sep = "--WomBa-woMbA--"
        argv = [compiler, "-e", "print join('%s', @INC);" % sep]
        env = dict(os.environ)
        if "PERL5LIB" in env:
            del env["PERL5LIB"]
        if "PERLLIB" in env:
            del env["PERLLIB"]

        p = process.ProcessOpen(argv, env=env, stdin=None)
        output, error = p.communicate()
        retval = p.returncode
        if retval:
            raise CodeIntelError("could not determine Perl import path: %s"
                                 % error)
        path = [normpath(d) for d in output.split(sep)]
        # cwd handled separately
        path = [p for p in path if p not in (os.curdir, os.getcwd())]
        return path

    def setCorePath(self, compiler=None, extra=None):
        if compiler is None:
            import which
            compiler = which.which("perl")
        self.corePath = self._shellOutForPath(compiler)

    def _findScannableFiles(self,
                            (files, searchedDirs,
                             skipTheseDirs, skipRareImports),
                            dirname, names):
        if sys.platform.startswith("win"):
            cpath = dirname.lower()
        else:
            cpath = dirname
        if cpath in searchedDirs:
            while names:
                del names[0]
            return
        else:
            searchedDirs[cpath] = 1
        if skipRareImports:
            # Skip .pl files when scanning a Perl lib/sitelib.
            scannableExts = (".pm",)
        else:
            scannableExts = (".pl", ".pm")
        for i in range(len(names)-1, -1, -1):  # backward so can del from list
            path = join(dirname, names[i])
            if isdir(path):
                if normcase(path) in skipTheseDirs:
                    del names[i]
                elif skipRareImports and not ('A' <= names[i][0] <= 'Z'):
                    # Perl good practice dictates that all module directories
                    # begin with a capital letter. Therefore, we skip dirs
                    # that start with a lower case.
                    del names[i]
            elif splitext(names[i])[1] in scannableExts:
                # XXX The list of extensions should be settable on
                #    the ImportHandler and Komodo should set whatever is
                #    set in prefs.
                # XXX This check for files should probably include
                #    scripts, which might likely not have the
                #    extension: need to grow filetype-from-content smarts.
                files.append(path)

    def find_importables_in_dir(self, dir):
        """See citadel.py::ImportHandler.find_importables_in_dir() for
        details.

        Importables for Perl look like this:
            {"Shell": ("Shell.pm", None, False),
             "LWP":   ("LWP.pm",   None, True),
             "XML":   (None,       None, True)}

        Notes:
        - Drop the "auto" dir (it holds the binary module bits).
        - Keep non-capitalized dirs and modules (e.g. want "strict" in
          cplns for "use <|>").
        """
        from os.path import join, isdir, splitext

        if dir == "<Unsaved>":
            # TODO: stop these getting in here.
            return {}

        # TODO: log the fs-stat'ing a la codeintel.db logging.
        try:
            names = os.listdir(dir)
        except OSError, ex:
            return {}
        dirs, nondirs = set(), set()
        for name in names:
            if isdir(join(dir, name)):
                dirs.add(name)
            else:
                nondirs.add(name)

        importables = {}
        dirs.discard("auto")
        for name in nondirs:
            base, ext = splitext(name)
            if ext != ".pm":
                continue
            if base in dirs:
                importables[base] = (name, None, True)
                dirs.remove(base)
            else:
                importables[base] = (name, None, False)
        for name in dirs:
            importables[name] = (None, None, True)

        return importables


class PerlCILEDriver(CILEDriver):
    lang = lang

    def scan_purelang(self, buf):
        log.info("scan_purelang: path: %r lang: %s", buf.path, buf.lang)
        return perlcile.scan_purelang(buf)

    def scan_multilang(self, buf, csl_cile_driver=None):
        """Scan the given multilang (UDL-based) buffer and return a CIX
        element tree, and shuffle any CSL tokens to the CSL CileDriver.
        """
        log.info("scan_multilang: path: %r lang: %s", buf.path, buf.lang)
        tree = Element("codeintel", version="2.0")
        path = buf.path
        if sys.platform == "win32":
            path = path.replace('\\', '/')
        file_node = SubElement(tree, "file", lang=buf.lang, path=path)
        # module = SubElement(file_node, "scope", ilk="blob", lang="Perl",
        # name=basename(path))
        csl_tokens, has_perl_code = perlcile.scan_multilang(
            buf.accessor.gen_tokens(), file_node)
        blob_node = file_node.getchildren()[0]
        if not has_perl_code:
            assert len(blob_node) == 0
            # The CILE clients don't want to hear there's no perl code in the
            # buffer
            file_node.remove(blob_node)
        else:
            blob_node.set('name', basename(path))
        if csl_cile_driver and csl_tokens:
            csl_cile_driver.scan_csl_tokens(file_node, basename(buf.path),
                                            csl_tokens)
        return tree


#---- internal support stuff
def _is_perl_var_char(char):
    return "a" <= char <= "z" or "A" <= char <= "Z" or "0" <= char <= "9" \
           or char in "_:$%@"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=PerlLexer(),
                      buf_class=PerlBuffer,
                      langintel_class=PerlLangIntel,
                      import_handler_class=PerlImportHandler,
                      cile_driver_class=PerlCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_php
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Shane Caraveo (ShaneC@ActiveState.com)
#   Trent Mick (TrentM@ActiveState.com)
#   Todd Whiteman (ToddW@ActiveState.com)

"""codeintel support for PHP"""

import os
from os.path import isdir, join, basename, splitext, exists, dirname
import sys
import re
import logging
import time
import warnings
from cStringIO import StringIO
import weakref
from glob import glob

from SilverCity.ScintillaConstants import (SCE_UDL_SSL_DEFAULT,
                                           SCE_UDL_SSL_OPERATOR,
                                           SCE_UDL_SSL_IDENTIFIER,
                                           SCE_UDL_SSL_WORD,
                                           SCE_UDL_SSL_VARIABLE,
                                           SCE_UDL_SSL_STRING,
                                           SCE_UDL_SSL_NUMBER,
                                           SCE_UDL_SSL_COMMENT,
                                           SCE_UDL_SSL_COMMENTBLOCK)

from codeintel2.parseutil import *
from codeintel2.phpdoc import phpdoc_tags
from codeintel2.citadel import ImportHandler, CitadelLangIntel
from codeintel2.udl import UDLBuffer, UDLLexer, UDLCILEDriver, is_udl_csl_style, XMLParsingBufferMixin
from codeintel2.common import *
from codeintel2 import util
from codeintel2.indexer import PreloadBufLibsRequest, PreloadLibRequest
from codeintel2.gencix_utils import *
from codeintel2.tree_php import PHPTreeEvaluator
from codeintel2.langintel import (ParenStyleCalltipIntelMixin,
                                  ProgLangTriggerIntelMixin)
from codeintel2.accessor import AccessorCache, KoDocumentAccessor

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- global data
lang = "PHP"
log = logging.getLogger("codeintel.php")
# log.setLevel(logging.DEBUG)
util.makePerformantLogger(log)

#---- language support


class PHPLexer(UDLLexer):
    lang = lang


def _walk_php_symbols(elem, _prefix=None):
    if _prefix:
        lpath = _prefix + (elem.get("name"), )
    else:
        lpath = (elem.get("name"), )
    yield lpath
    if not (elem.tag == "scope" and elem.get("ilk") == "function"):
        for child in elem:
            for child_lpath in _walk_php_symbols(child, lpath):
                yield child_lpath


class PHPLangIntel(CitadelLangIntel, ParenStyleCalltipIntelMixin,
                   ProgLangTriggerIntelMixin):
    lang = lang

    # Used by ProgLangTriggerIntelMixin.preceding_trg_from_pos()
    trg_chars = tuple('$>:(,@"\' \\')
    calltip_trg_chars = tuple('(')   # excluded ' ' for perf (bug 55497)

    # named styles used by the class
    whitespace_style = SCE_UDL_SSL_DEFAULT
    operator_style = SCE_UDL_SSL_OPERATOR
    identifier_style = SCE_UDL_SSL_IDENTIFIER
    keyword_style = SCE_UDL_SSL_WORD
    variable_style = SCE_UDL_SSL_VARIABLE
    string_style = SCE_UDL_SSL_STRING
    comment_styles = (SCE_UDL_SSL_COMMENT, SCE_UDL_SSL_COMMENTBLOCK)
    comment_styles_or_whitespace = comment_styles + (whitespace_style, )

    def _functionCalltipTrigger(self, ac, pos, DEBUG=False):
        # Implicit calltip triggering from an arg separater ",", we trigger a
        # calltip if we find a function open paren "(" and function identifier
        #   http://bugs.activestate.com/show_bug.cgi?id=70470
        if DEBUG:
            print "Arg separater found, looking for start of function"
        # Move back to the open paren of the function
        paren_count = 0
        p = pos
        min_p = max(0, p - 200)  # look back max 200 chars
        while p > min_p:
            p, c, style = ac.getPrecedingPosCharStyle(
                ignore_styles=self.comment_styles)
            if style == self.operator_style:
                if c == ")":
                    paren_count += 1
                elif c == "(":
                    if paren_count == 0:
                        # We found the open brace of the func
                        trg_from_pos = p+1
                        p, ch, style = ac.getPrevPosCharStyle()
                        if DEBUG:
                            print "Function start found, pos: %d" % (p, )
                        if style in self.comment_styles_or_whitespace:
                            # Find previous non-ignored style then
                            p, c, style = ac.getPrecedingPosCharStyle(
                                style, self.comment_styles_or_whitespace)
                        if style in (self.identifier_style, self.keyword_style):
                            return Trigger(lang, TRG_FORM_CALLTIP,
                                           "call-signature",
                                           trg_from_pos, implicit=True)
                    else:
                        paren_count -= 1
                elif c in ";{}":
                    # Gone too far and noting was found
                    if DEBUG:
                        print "No function found, hit stop char: %s at p: %d" % (c, p)
                    return None
        # Did not find the function open paren
        if DEBUG:
            print "No function found, ran out of chars to look at, p: %d" % (p,)
        return None

    #@util.hotshotit
    def trg_from_pos(self, buf, pos, implicit=True, DEBUG=False, ac=None):
        # DEBUG = True
        if pos < 4:
            return None

        # DEBUG = True
        # Last four chars and styles
        if ac is None:
            ac = AccessorCache(buf.accessor, pos, fetchsize=4)
        last_pos, last_char, last_style = ac.getPrevPosCharStyle()
        prev_pos, prev_char, prev_style = ac.getPrevPosCharStyle()
        # Bump up how much text is retrieved when cache runs out
        ac.setCacheFetchSize(20)

        if DEBUG:
            print "\nphp trg_from_pos"
            print "  last_pos: %s" % last_pos
            print "  last_char: %s" % last_char
            print "  last_style: %r" % last_style
            ac.dump()

        try:
            # Note: If a "$" exists by itself, it's styled as whitespace.
            #       Generally we want it to be indicating a variable instead.
            if last_style == self.whitespace_style and last_char != "$":
                if DEBUG:
                    print "Whitespace style"
                WHITESPACE = tuple(" \t\n\r\v\f")
                if not implicit:
                    # If we're not already at the keyword style, find it
                    if prev_style != self.keyword_style:
                        prev_pos, prev_char, prev_style = ac.getPrecedingPosCharStyle(
                            last_style, self.comment_styles)
                        if DEBUG:
                            print "Explicit: prev_pos: %d, style: %d, ch: %r" % (prev_pos, prev_style, prev_char)
                else:
                    prev_pos = pos - 2
                if last_char in WHITESPACE and \
                    (prev_style == self.keyword_style or
                     (prev_style == self.operator_style and prev_char == ",")):
                    p = prev_pos
                    style = prev_style
                    ch = prev_char
                    # print "p: %d" % p
                    while p > 0 and style == self.operator_style and ch == ",":
                        p, ch, style = ac.getPrecedingPosCharStyle(
                            style, self.comment_styles_or_whitespace)
                        # print "p 1: %d" % p
                        if p > 0 and style == self.identifier_style:
                            # Skip the identifier too
                            p, ch, style = ac.getPrecedingPosCharStyle(
                                style, self.comment_styles_or_whitespace)
                            # print "p 2: %d" % p
                    if DEBUG:
                        ac.dump()
                    p, text = ac.getTextBackWithStyle(
                        style, self.comment_styles, max_text_len=len("implements"))
                    if DEBUG:
                        print "ac.getTextBackWithStyle:: pos: %d, text: %r" % (p, text)
                    if text in ("new", "extends"):
                        return Trigger(lang, TRG_FORM_CPLN, "classes", pos, implicit)
                    elif text in ("implements", ):
                        return Trigger(lang, TRG_FORM_CPLN, "interfaces", pos, implicit)
                    elif text in ("use", ):
                        return Trigger(lang, TRG_FORM_CPLN, "use", pos, implicit)
                    elif prev_style == self.operator_style and \
                            prev_char == "," and implicit:
                        return self._functionCalltipTrigger(ac, prev_pos, DEBUG)
            elif last_style == self.operator_style:
                if DEBUG:
                    print "  lang_style is operator style"
                    print "Prev char: %r" % (prev_char)
                    ac.dump()
                if last_char == ":":
                    if not prev_char == ":":
                        return None
                    ac.setCacheFetchSize(10)
                    p, c, style = ac.getPrecedingPosCharStyle(
                        prev_style, self.comment_styles)
                    if DEBUG:
                        print "Preceding: %d, %r, %d" % (p, c, style)
                    if style is None:
                        return None
                    elif style == self.keyword_style:
                        # Check if it's a "self::" or "parent::" expression
                        p, text = ac.getTextBackWithStyle(self.keyword_style,
                                                          # Ensure we don't go
                                                          # too far
                                                          max_text_len=6)
                        if DEBUG:
                            print "Keyword text: %d, %r" % (p, text)
                            ac.dump()
                        if text not in ("parent", "self", "static"):
                            return None
                    return Trigger(lang, TRG_FORM_CPLN, "static-members",
                                   pos, implicit)
                elif last_char == ">":
                    if prev_char == "-":
                        p, c, style = ac.getPrevPosCharStyle(
                            ignore_styles=self.comment_styles_or_whitespace)
                        if style in (self.variable_style, self.identifier_style) or \
                           (style == self.operator_style and c == ')'):
                            return Trigger(
                                lang, TRG_FORM_CPLN, "object-members",
                                pos, implicit)
                        elif DEBUG:
                            print "Preceding style is not a variable, pos: %d, style: %d" % (p, style)
                elif last_char in "(,":
                    # where to trigger from, updated by "," calltip handler
                    if DEBUG:
                        print "Checking for function calltip"

                    # Implicit calltip triggering from an arg separater ","
                    #   http://bugs.activestate.com/show_bug.cgi?id=70470
                    if implicit and last_char == ',':
                        return self._functionCalltipTrigger(ac, prev_pos, DEBUG)

                    if prev_style in self.comment_styles_or_whitespace:
                        # Find previous non-ignored style then
                        p, c, prev_style = ac.getPrecedingPosCharStyle(
                            prev_style, self.comment_styles_or_whitespace)
                    if prev_style in (self.identifier_style, self.keyword_style):
                        return Trigger(
                            lang, TRG_FORM_CALLTIP, "call-signature",
                            pos, implicit)
                elif last_char == "\\":
                    # Ensure does not trigger when defining a new namespace,
                    # i.e., do not trigger for:
                    #      namespace foo\<|>
                    style = last_style
                    while style in (self.operator_style, self.identifier_style):
                        p, c, style = ac.getPrecedingPosCharStyle(
                            style, max_look_back=30)
                    if style == self.whitespace_style:
                        p, c, style = ac.getPrecedingPosCharStyle(
                            self.whitespace_style, max_look_back=30)
                    if style is None:
                        if DEBUG:
                            print "Triggering namespace completion"
                        return Trigger(
                            lang, TRG_FORM_CPLN, "namespace-members",
                            pos, implicit)
                    prev_text = ac.getTextBackWithStyle(style, max_text_len=15)
                    if DEBUG:
                        print "prev_text: %r" % (prev_text, )
                    if prev_text[1] == "use":
                        if DEBUG:
                            print "Triggering use-namespace completion"
                        return Trigger(lang, TRG_FORM_CPLN, "use-namespace",
                                       pos, implicit)
                    elif prev_text[1] != "namespace":
                        if DEBUG:
                            print "Triggering namespace completion"
                        return Trigger(
                            lang, TRG_FORM_CPLN, "namespace-members",
                            pos, implicit)

            elif last_style == self.variable_style or \
                    (not implicit and last_char == "$"):
                if DEBUG:
                    print "Variable style"
                # Completion for variables (builtins and user defined variables),
                # must occur after a "$" character.
                if not implicit and last_char == '$':
                    # Explicit call, move ahead one for real trigger position
                    pos += 1
                if not implicit or prev_char == "$":
                    # Ensure we are not triggering over static class variables.
                    # Do this by checking that the preceding text is not "::"
                    # http://bugs.activestate.com/show_bug.cgi?id=78099
                    p, c, style = ac.getPrecedingPosCharStyle(last_style,
                                                              max_look_back=30)
                    if c == ":" and style == self.operator_style and \
                            ac.getTextBackWithStyle(style, max_text_len=3)[1] == "::":
                        return None
                    return Trigger(lang, TRG_FORM_CPLN, "variables",
                                   pos-1, implicit)
            elif last_style in (self.identifier_style, self.keyword_style):
                if DEBUG:
                    if last_style == self.identifier_style:
                        print "Identifier style"
                    else:
                        print "Identifier keyword style"
                # Completion for keywords,function and class names
                # Works after first 3 characters have been typed
                # if DEBUG:
                #    print "identifier_style: pos - 4 %s" % (accessor.style_at_pos(pos - 4))
                # third_char, third_style = last_four_char_and_styles[2]
                # fourth_char, fourth_style = last_four_char_and_styles[3]
                if prev_style == last_style:
                    trig_pos, ch, style = ac.getPrevPosCharStyle()
                    if style == last_style:
                        p, ch, style = ac.getPrevPosCharStyle(
                            ignore_styles=self.comment_styles)
                        # style is None if no change of style (not ignored) was
                        # found in the last x number of chars
                        # if not implicit and style == last_style:
                        #    if DEBUG:
                        #        print "Checking back further for explicit call"
                        #    p, c, style = ac.getPrecedingPosCharStyle(style, max_look_back=100)
                        #    if p is not None:
                        #        trg_pos = p + 3
                        if style in (None, self.whitespace_style,
                                     self.operator_style):
                            # Ensure we are not in another trigger zone, we do
                            # this by checking that the preceeding text is not
                            # one of "->", "::", "new", "function", "class",
                            # ...
                            if style == self.whitespace_style:
                                p, c, style = ac.getPrecedingPosCharStyle(
                                    self.whitespace_style, max_look_back=30)
                            if style is None:
                                return Trigger(
                                    lang, TRG_FORM_CPLN, "functions",
                                    trig_pos, implicit)
                            prev_text = ac.getTextBackWithStyle(
                                style, max_text_len=15)
                            if DEBUG:
                                print "prev_text: %r" % (prev_text, )
                            if (prev_text[1] not in ("new", "function", "use",
                               "class", "interface", "implements",
                               "public", "private", "protected",
                                                    "final", "abstract", "instanceof",)
                                        # For the operator styles, we must use
                                        # endswith, as it could follow a "()",
                                        # bug 90846.
                                        and prev_text[1][-2:] not in ("->", "::",)
                                        # Don't trigger when accessing a
                                        # namespace - bug 88736.
                                        and not prev_text[1].endswith("\\")):
                                return Trigger(
                                    lang, TRG_FORM_CPLN, "functions",
                                    trig_pos, implicit)
                        # If we want implicit triggering on more than 3 chars
                        # elif style == self.identifier_style:
                        #    p, c, style = ac.getPrecedingPosCharStyle(self.identifier_style)
                        #    return Trigger(lang, TRG_FORM_CPLN, "functions",
                        #                   p+1, implicit)
                        elif DEBUG:
                            print "identifier preceeded by an invalid style: " \
                                  "%r, p: %r" % (style, p, )

                    elif last_char == '_' and prev_char == '_' and \
                            style == self.whitespace_style:
                        # XXX - Check the php version, magic methods only
                        #       appeared in php 5.
                        p, ch, style = ac.getPrevPosCharStyle(
                            ignore_styles=self.comment_styles)
                        if style == self.keyword_style and \
                           ac.getTextBackWithStyle(style, max_text_len=9)[1] == "function":
                            if DEBUG:
                                print "triggered:: complete magic-methods"
                            return Trigger(
                                lang, TRG_FORM_CPLN, "magic-methods",
                                prev_pos, implicit)

            # PHPDoc completions
            elif last_char == "@" and last_style in self.comment_styles:
                # If the preceeding non-whitespace character is a "*" or newline
                # then we complete for phpdoc tag names
                p = last_pos - 1
                min_p = max(0, p - 50)      # Don't look more than 50 chars
                if DEBUG:
                    print "Checking match for phpdoc completions"
                accessor = buf.accessor
                while p >= min_p and \
                        accessor.style_at_pos(p) in self.comment_styles:
                    ch = accessor.char_at_pos(p)
                    p -= 1
                    # if DEBUG:
                    #    print "Looking at ch: %r" % (ch)
                    if ch in "*\r\n":
                        break
                    elif ch not in " \t\v":
                        # Not whitespace, not a valid tag then
                        return None
                else:
                    # Nothing found in the specified range
                    if DEBUG:
                        print "trg_from_pos: not a phpdoc"
                    return None
                if DEBUG:
                    print "Matched trigger for phpdoc completion"
                return Trigger("PHP", TRG_FORM_CPLN,
                               "phpdoc-tags", pos, implicit)

            # PHPDoc calltip
            elif last_char in " \t" and last_style in self.comment_styles:
                # whitespace in a comment, see if it matches for phpdoc calltip
                p = last_pos - 1
                min_p = max(0, p - 50)      # Don't look more than 50 chars
                if DEBUG:
                    print "Checking match for phpdoc calltip"
                ch = None
                ident_found_pos = None
                accessor = buf.accessor
                while p >= min_p and \
                        accessor.style_at_pos(p) in self.comment_styles:
                    ch = accessor.char_at_pos(p)
                    p -= 1
                    if ident_found_pos is None:
                        # print "phpdoc: Looking for identifier, ch: %r" % (ch)
                        if ch in " \t":
                            pass
                        elif _isident(ch):
                            ident_found_pos = p+1
                        else:
                            if DEBUG:
                                print "No phpdoc, whitespace not preceeded " \
                                      "by an identifer"
                            return None
                    elif ch == "@":
                        # This is what we've been looking for!
                        phpdoc_field = accessor.text_range(p+2,
                                                           ident_found_pos+1)
                        if DEBUG:
                            print "Matched trigger for phpdoc calltip: '%s'" % (
                                phpdoc_field, )
                        return Trigger("PHP", TRG_FORM_CALLTIP,
                                       "phpdoc-tags", ident_found_pos, implicit,
                                       phpdoc_field=phpdoc_field)
                    elif not _isident(ch):
                        if DEBUG:
                            print "No phpdoc, identifier not preceeded by '@'"
                        # Not whitespace, not a valid tag then
                        return None
                # Nothing found in the specified range
                if DEBUG:
                    print "No phpdoc, ran out of characters to look at."

            # Array completions
            elif last_style == self.string_style and last_char in '\'"':
                if prev_char != '[':
                    if prev_style in self.comment_styles_or_whitespace:
                        # Look back further.
                        prev_pos, prev_char, prev_style = ac.getPrevPosCharStyle(
                            ignore_styles=self.comment_styles_or_whitespace)
                if prev_char == '[':
                    # We're good to go.
                    if DEBUG:
                        print "Matched trigger for array completions"
                    return Trigger("PHP", TRG_FORM_CPLN,
                                   "array-members", pos, implicit,
                                   bracket_pos=prev_pos,
                                   trg_char=last_char)

            # Variable completions inside of comments
            elif prev_char == "$" and last_style in self.comment_styles:
                if DEBUG:
                    print "Comment variable style"
                # Completion for variables (builtins and user defined variables),
                # must occur after a "$" character.
                return Trigger(lang, TRG_FORM_CPLN, "comment-variables",
                               pos-1, implicit)

            elif DEBUG:
                print "trg_from_pos: no handle for style: %d" % last_style

        except IndexError:
            # Not enough chars found, therefore no trigger
            pass

        return None

    #@util.hotshotit
    def preceding_trg_from_pos(self, buf, pos, curr_pos,
                               preceding_trg_terminators=None, DEBUG=False):
        # DEBUG = True
        # Try the default preceding_trg_from_pos handler
        trg = ProgLangTriggerIntelMixin.preceding_trg_from_pos(
            self, buf, pos, curr_pos, preceding_trg_terminators,
            DEBUG=DEBUG)
        if trg is not None:
            return trg

        # Else, let's try to work out some other options
        accessor = buf.accessor
        prev_style = accessor.style_at_pos(curr_pos - 1)
        if prev_style in (self.identifier_style, self.keyword_style):
            # We don't know what to trigger here... could be one of:
            # functions:
            #   apache<$><|>_getenv()...
            #   if(get_e<$><|>nv()...
            # classes:
            #   new Exce<$><|>ption()...
            #   extends Exce<$><|>ption()...
            # interfaces:
            #   implements apache<$><|>_getenv()...
            ac = AccessorCache(accessor, curr_pos)
            pos_before_identifer, ch, prev_style = \
                ac.getPrecedingPosCharStyle(prev_style)
            if DEBUG:
                print "\nphp preceding_trg_from_pos, first chance for identifer style"
                print "  curr_pos: %d" % (curr_pos)
                print "  pos_before_identifer: %d" % (pos_before_identifer)
                print "  ch: %r" % ch
                print "  prev_style: %d" % prev_style
                ac.dump()
            if pos_before_identifer < pos:
                resetPos = min(pos_before_identifer + 4, accessor.length() - 1)
                ac.resetToPosition(resetPos)
                if DEBUG:
                    print "preceding_trg_from_pos:: reset to position: %d, ac now:" % (resetPos)
                    ac.dump()
                # Trigger on the third identifier character
                return self.trg_from_pos(buf, resetPos,
                                         implicit=False, DEBUG=DEBUG, ac=ac)
            elif DEBUG:
                print "Out of scope of the identifier"

        elif prev_style in self.comment_styles:
            # Check if there is a PHPDoc to provide a calltip for, example:
            #       /** @param $foo foobar - This is field for <|>
            if DEBUG:
                print "\nphp preceding_trg_from_pos::phpdoc: check for calltip"
            comment = accessor.text_range(max(0, curr_pos-200), curr_pos)
            at_idx = comment.rfind("@")
            if at_idx >= 0:
                if DEBUG:
                    print "\nphp preceding_trg_from_pos::phpdoc: contains '@'"
                space_idx = comment[at_idx:].find(" ")
                if space_idx >= 0:
                    # Trigger after the space character.
                    trg_pos = (curr_pos - len(
                        comment)) + at_idx + space_idx + 1
                    if DEBUG:
                        print "\nphp preceding_trg_from_pos::phpdoc: calltip at %d" % (trg_pos, )
                    return self.trg_from_pos(buf, trg_pos,
                                             implicit=False, DEBUG=DEBUG)

    _phpdoc_cplns = [("variable", t) for t in sorted(phpdoc_tags)]

    #@util.hotshotit
    def async_eval_at_trg(self, buf, trg, ctlr):
        if _xpcom_:
            trg = UnwrapObject(trg)
            ctlr = UnwrapObject(ctlr)
        pos = trg.pos
        ctlr.start(buf, trg)
        # print "trg.type: %r" % (trg.type)

        # PHPDoc completions
        if trg.id == ("PHP", TRG_FORM_CPLN, "phpdoc-tags"):
            # TODO: Would like a "javadoc tag" completion image name.
            ctlr.set_cplns(self._phpdoc_cplns)
            ctlr.done("success")
            return

        # PHPDoc calltip
        elif trg.id == ("PHP", TRG_FORM_CALLTIP, "phpdoc-tags"):
            phpdoc_field = trg.extra.get("phpdoc_field")
            if phpdoc_field:
                # print "phpdoc_field: %r" % (phpdoc_field, )
                calltip = phpdoc_tags.get(phpdoc_field)
                if calltip:
                    ctlr.set_calltips([calltip])
            ctlr.done("success")
            return

        elif trg.type in ("classes", "interfaces"):
            # Triggers from zero characters, thus calling citdl_expr_from_trg
            # is no help
            line = buf.accessor.line_from_pos(pos)
            evalr = PHPTreeEvaluator(ctlr, buf, trg, "", line)
            buf.mgr.request_eval(evalr)

        else:
            try:
                citdl_expr = self.citdl_expr_from_trg(buf, trg)
            except CodeIntelError, ex:
                ctlr.error(str(ex))
                ctlr.done("error")
                return
            line = buf.accessor.line_from_pos(pos)
            evalr = PHPTreeEvaluator(ctlr, buf, trg, citdl_expr, line)
            buf.mgr.request_eval(evalr)

    def _citdl_expr_from_pos(self, trg, buf, pos, implicit=True,
                             include_forwards=False, DEBUG=False):
        # DEBUG = True
        # PERF: Would dicts be faster for all of these?
        WHITESPACE = tuple(" \t\n\r\v\f")
        EOL = tuple("\r\n")
        BLOCKCLOSES = tuple(")}]")
        STOPOPS = tuple("({[,&$+=^|%/<;:->!.@?")
        EXTRA_STOPOPS_PRECEDING_IDENT = BLOCKCLOSES  # Might be others.

        # TODO: This style picking is a problem for the LangIntel move.
        if trg.type == "comment-variables":
            # Dev note: skip_styles in the other cases below will be a dict.
            skip_styles = set()
        elif implicit:
            skip_styles = buf.implicit_completion_skip_styles
        else:
            skip_styles = buf.completion_skip_styles

        citdl_expr = []
        accessor = buf.accessor

        # Use a cache of characters, easy to keep track this way
        i = pos
        ac = AccessorCache(accessor, i)

        if include_forwards:
            try:
                # Move ahead to include forward chars as well
                lastch_was_whitespace = False
                while 1:
                    i, ch, style = ac.getNextPosCharStyle()
                    if DEBUG:
                        print "include_forwards:: i now: %d, ch: %r" % (i, ch)
                    if ch in WHITESPACE:
                        lastch_was_whitespace = True
                        continue
                    lastch_was_whitespace = False
                    if ch in STOPOPS:
                        if DEBUG:
                            print "include_forwards:: ch in STOPOPS, i:%d ch:%r" % (i, ch)
                        break
                    elif ch in BLOCKCLOSES:
                        if DEBUG:
                            print "include_forwards:: ch in BLOCKCLOSES, i:%d ch:%r" % (i, ch)
                        break
                    elif lastch_was_whitespace:
                        # Two whitespace separated words
                        if DEBUG:
                            print "include_forwards:: ch separated by whitespace, i:%d ch:%r" % (i, ch)
                        break
                # Move back to last valid char
                i -= 1
                if DEBUG:
                    if i > pos:
                        print "include_forwards:: Including chars from pos %d up to %d" % (pos, i)
                    else:
                        print "include_forwards:: No valid chars forward from pos %d, i now: %d" % (pos, i)
            except IndexError:
                # Nothing forwards, user what we have then
                i = min(i, accessor.length() - 1)
                if DEBUG:
                    print "include_forwards:: No more buffer, i now: %d" % (i)
            ac.resetToPosition(i)

        ch = None
        try:
            while i >= 0:
                if ch == None and include_forwards:
                    i, ch, style = ac.getCurrentPosCharStyle()
                else:
                    i, ch, style = ac.getPrevPosCharStyle()
                if DEBUG:
                    print "i now: %d, ch: %r" % (i, ch)

                if ch in WHITESPACE:
                    if trg.type in ("use-namespace", "namespace-members"):
                        # Namespaces cannot be split over whitespace.
                        break
                    while ch in WHITESPACE:
                        # drop all whitespace
                        next_char = ch
                        i, ch, style = ac.getPrevPosCharStyle()
                        if ch in WHITESPACE \
                           or (ch == '\\' and next_char in EOL):
                            if DEBUG:
                                print "drop whitespace: %r" % ch
                    # If there are two whitespace-separated words then this is
                    # (likely or always?) a language keyword or declaration
                    # construct at which we want to stop. E.g.
                    #   if foo<|> and ...
                    #   def foo<|>(...
                    #   if \foo<|>(...     # uses a namespace
                    if citdl_expr \
                       and (_isident(citdl_expr[-1]) or citdl_expr[-1] == '\\') \
                       and (_isident(ch) or _isdigit(ch)):
                        if DEBUG:
                            print "stop at (likely?) start of keyword or "\
                                  "declaration: %r" % ch
                        break
                    # Not whitespace anymore, move into the main checks below
                    if DEBUG:
                        print "Out of whitespace: i now: %d, ch: %s" % (i, ch)

                if style in skip_styles:  # drop styles to ignore
                    while i >= 0 and style in skip_styles:
                        i, ch, style = ac.getPrevPosCharStyle()
                        if DEBUG:
                            print "drop char of style to ignore: %r" % ch
                elif ch in ":>" and i > 0:
                    # Next char has to be ":" or "-" respectively
                    prev_pos, prev_ch, prev_style = ac.getPrevPosCharStyle()
                    if (ch == ">" and prev_ch == "-") or \
                       (ch == ":" and prev_ch == ":"):
                        citdl_expr.append(".")
                        if DEBUG:
                            print "Turning member accessor '%s%s' into '.'" % (prev_ch, ch)
                        i -= 2
                    else:
                        if DEBUG:
                            print "citdl_expr: %r" % (citdl_expr)
                            print "stop at special stop-operator %d: %r" % (i, ch)
                        break
                elif (ch in STOPOPS or ch in EXTRA_STOPOPS_PRECEDING_IDENT) and \
                     (ch != ")" or (citdl_expr and citdl_expr[-1] != ".")):
                    if ch == '$':
                        # This may not be the end of the road, given static
                        # variables are accessed through "Class::$static".
                        prev_pos, prev_ch, prev_style = ac.peekPrevPosCharStyle(
                        )
                        if prev_ch == ":":
                            # Continue building up the citdl then.
                            continue
                    if DEBUG:
                        print "citdl_expr: %r" % (citdl_expr)
                        print "stop at stop-operator %d: %r" % (i, ch)
                    break
                elif ch in BLOCKCLOSES:
                    if DEBUG:
                        print "found block at %d: %r" % (i, ch)
                    citdl_expr.append(ch)

                    BLOCKS = {  # map block close char to block open char
                        ')': '(',
                        ']': '[',
                        '}': '{',
                    }
                    stack = []
                        # stack of blocks: (<block close char>, <style>)
                    stack.append((ch, style, BLOCKS[ch], i))
                    while i >= 0:
                        i, ch, style = ac.getPrevPosCharStyle()
                        if DEBUG:
                            print "finding matching brace: ch %r (%s), stack %r"\
                                  % (ch, ', '.join(buf.style_names_from_style_num(style)), stack)
                        if ch in BLOCKS and style not in skip_styles:
                            stack.append((ch, style, BLOCKS[ch]))
                        elif ch == stack[-1][2] and style not in skip_styles:
                            # XXX Replace the second test with the following
                            #    when LexPython+SilverCity styling bugs are fixed
                            #    (spurious 'stderr' problem):
                            #       and style == stack[-1][1]:
                            stack.pop()
                            if not stack:
                                if DEBUG:
                                    print "jump to matching brace at %d: %r" % (i, ch)
                                citdl_expr.append(ch)
                                break
                    else:
                        # Didn't find the matching brace.
                        if DEBUG:
                            print "couldn't find matching brace"
                        raise EvalError("could not find matching brace for "
                                        "'%s' at position %d"
                                        % (stack[-1][0], stack[-1][3]))

                else:
                    if DEBUG:
                        style_names = buf.style_names_from_style_num(style)
                        print "add char: %r (%s)" % (ch, ', '.join(style_names))
                    citdl_expr.append(ch)
                    i -= 1
        except IndexError:
            # Nothing left to consume, return what we have
            pass

        # Remove any unecessary starting dots
        while citdl_expr and citdl_expr[-1] == ".":
            citdl_expr.pop()
        citdl_expr.reverse()
        citdl_expr = ''.join(citdl_expr)
        if DEBUG:
            print "return: %r" % citdl_expr
            print util.banner("done")
        return citdl_expr

    def citdl_expr_from_trg(self, buf, trg):
        """Return a PHP CITDL expression preceding the given trigger.

        The expression drops newlines, whitespace, and function call
        arguments -- basically any stuff that is not used by the codeintel
        database system for determining the resultant object type of the
        expression. For example (in which <|> represents the given position):

            GIVEN                           RETURN
            -----                           ------
            foo-<|>>                        foo
            Foo:<|>:                        Foo
            foo(bar-<|>>                    bar
            foo(bar,blam)-<|>>              foo()
            foo(bar,                        foo()
                blam)-<|>>
            foo(arg1, arg2)->bar-<|>>       foo().bar
            Foo(arg1, arg2)::bar-<|>>       Foo().bar
            Foo\bar:<|>:                    Foo\bar
            Foo\bar::bam-<|>>               Foo\bar.bam
            Foo\bar(arg1, arg2)::bam-<|>>   Foo\bar().bam
        """
        # DEBUG = True
        DEBUG = False
        if DEBUG:
            print util.banner("%s citdl_expr_from_trg @ %r" % (buf.lang, trg))

        if trg.form == TRG_FORM_CPLN:
            # "->" or "::"
            if trg.type == "classes":
                i = trg.pos + 1
            elif trg.type == "functions":
                i = trg.pos + 3   # 3-char trigger, skip over it
            elif trg.type in ("variables", "comment-variables"):
                i = trg.pos + 1   # triggered on the $, skip over it
            elif trg.type == "array-members":
                i = trg.extra.get("bracket_pos")   # triggered on foo['
            elif trg.type == "use":
                i = trg.pos + 1
            elif trg.type == "namespace-members" or \
                    trg.type == "use-namespace":
                i = trg.pos - 1
            else:
                i = trg.pos - 2  # skip past the trigger char
            return self._citdl_expr_from_pos(trg, buf, i, trg.implicit,
                                             DEBUG=DEBUG)
        elif trg.form == TRG_FORM_DEFN:
            return self.citdl_expr_under_pos(trg, buf, trg.pos, DEBUG)
        else:   # trg.form == TRG_FORM_CALLTIP:
            # (<|>
            return self._citdl_expr_from_pos(trg, buf, trg.pos-1, trg.implicit,
                                             DEBUG=DEBUG)

    def citdl_expr_under_pos(self, trg, buf, pos, DEBUG=False):
        """Return a PHP CITDL expression around the given pos.

        Similar to citdl_expr_from_trg(), but looks forward to grab additional
        characters.

            GIVEN                       RETURN
            -----                       ------
            foo-<|>>                    foo
            F<|>oo::                    Foo
            foo->ba<|>r                 foo.bar
            f<|>oo->bar                 foo
            foo(bar-<|>>                bar
            foo(bar,blam)-<|>>          foo()
            foo(bar,                    foo()
                blam)-<|>>
            foo(arg1, arg2)->bar-<|>>   foo().bar
            Foo(arg1, arg2)::ba<|>r->   Foo().bar
            Fo<|>o(arg1, arg2)::bar->   Foo
        """
        # DEBUG = True
        expr = self._citdl_expr_from_pos(trg, buf, pos-1, implicit=True,
                                         include_forwards=True, DEBUG=DEBUG)
        if expr:
            # Chop off any trailing "." characters
            return expr.rstrip(".")
        return expr

    def libs_from_buf(self, buf):
        env = buf.env

        # A buffer's libs depend on its env and the buf itself so
        # we cache it on the env and key off the buffer.
        if "php-buf-libs" not in env.cache:
            env.cache["php-buf-libs"] = weakref.WeakKeyDictionary()
        cache = env.cache["php-buf-libs"]  # <buf-weak-ref> -> <libs>

        if buf not in cache:
            # - curdirlib
            # Using the dirname of this buffer isn't always right, but
            # hopefully is a good first approximation.
            cwd = dirname(buf.path)
            if cwd == "<Unsaved>":
                libs = []
            else:
                libs = [self.mgr.db.get_lang_lib(
                    "PHP", "curdirlib", [cwd], "PHP")]

            libs += self._buf_indep_libs_from_env(env)
            cache[buf] = libs
        return cache[buf]

    def lpaths_from_blob(self, blob):
        """Return <lpaths> for this blob
        where,
            <lpaths> is a set of externally referencable lookup-paths, e.g.
                [("MyOwnClass",), ("MyOwnClass", "function1"), ...]
        """
        return set(lpath for child in blob
                   for lpath in _walk_php_symbols(child))

    def _php_from_env(self, env):
        import which
        path = [d.strip()
                for d in env.get_envvar("PATH", "").split(os.pathsep)
                if d.strip()]
        for exe_name in ("php", "php4", "php-cgi", "php-cli"):
            try:
                return which.which(exe_name, path=path)
            except which.WhichError:
                pass
        return None

    def _php_info_from_php(self, php, env):
        """Call the given PHP and return:
            (<version>, <include_path>)
        Returns (None, []) if could not determine.
        """
        import process
        import tempfile

        # Use a marker to separate the start of output from possible
        # leading lines of PHP loading errors/logging.
        marker = "--- Start of Good Stuff ---"
        info_cmd = (r'<?php '
                    + r'echo("%s\n");' % marker
                    + r'echo(phpversion()."\n");'
                    + r'echo(ini_get("include_path")."\n");'
                    + r' ?>')

        argv = [php]
        envvars = env.get_all_envvars()
        php_ini_path = env.get_pref("phpConfigFile")
        if php_ini_path:
            envvars["PHPRC"] = php_ini_path

        fd, filepath = tempfile.mkstemp(suffix=".php")
        try:
            os.write(fd, info_cmd)
            os.close(fd)
            argv.append(filepath)
            p = process.ProcessOpen(argv, env=env.get_all_envvars())
            stdout, stderr = p.communicate()
        finally:
            os.remove(filepath)

        stdout_lines = stdout.splitlines(0)
        retval = p.returncode
        if retval:
            log.warn("failed to determine PHP info:\n"
                     "  path: %s\n"
                     "  retval: %s\n"
                     "  stdout:\n%s\n"
                     "  stderr:\n%s\n",
                     php, retval, util.indent('\n'.join(stdout_lines)),
                     util.indent(stderr))
            return None, []

        stdout_lines = stdout_lines[stdout_lines.index(marker)+1:]
        php_ver = stdout_lines[0]
        include_path = [p.strip() for p in stdout_lines[1].split(os.pathsep)
                        if p.strip()]

        return php_ver, include_path

    def _extra_dirs_from_env(self, env):
        extra_dirs = set()
        include_project = env.get_pref("codeintel_scan_files_in_project", True)
        if include_project:
            proj_base_dir = env.get_proj_base_dir()
            if proj_base_dir is not None:
                extra_dirs.add(proj_base_dir)  # Bug 68850.
        for pref in env.get_all_prefs("phpExtraPaths"):
            if not pref:
                continue
            extra_dirs.update(d.strip() for d in pref.split(os.pathsep)
                              if exists(d.strip()))
        if extra_dirs:
            log.debug("PHP extra lib dirs: %r", extra_dirs)
            max_depth = env.get_pref("codeintel_max_recursive_dir_depth", 10)
            php_assocs = env.assoc_patterns_from_lang("PHP")
            extra_dirs = tuple(
                util.gen_dirs_under_dirs(extra_dirs,
                                         max_depth=max_depth,
                                         interesting_file_patterns=php_assocs)
            )
        else:
            extra_dirs = ()  # ensure retval is a tuple
        return extra_dirs

    def _buf_indep_libs_from_env(self, env):
        """Create the buffer-independent list of libs."""
        cache_key = "php-libs"
        if cache_key not in env.cache:
            env.add_pref_observer("php", self._invalidate_cache)
            env.add_pref_observer("phpExtraPaths",
                                  self._invalidate_cache_and_rescan_extra_dirs)
            env.add_pref_observer("phpConfigFile",
                                  self._invalidate_cache)
            env.add_pref_observer("codeintel_selected_catalogs",
                                  self._invalidate_cache)
            env.add_pref_observer("codeintel_max_recursive_dir_depth",
                                  self._invalidate_cache)
            env.add_pref_observer("codeintel_scan_files_in_project",
                                  self._invalidate_cache)
            # (Bug 68850) Both of these 'live_*' prefs on the *project*
            # prefset can result in a change of project base dir. It is
            # possible that we can false positives here if there is ever
            # a global pref of this name.
            env.add_pref_observer("import_live",
                                  self._invalidate_cache_and_rescan_extra_dirs)
            env.add_pref_observer("import_dirname",
                                  self._invalidate_cache_and_rescan_extra_dirs)

            db = self.mgr.db

            # Gather information about the current php.
            php = None
            if env.has_pref("php"):
                php = env.get_pref("php").strip() or None
            if not php or not exists(php):
                php = self._php_from_env(env)
            if not php:
                log.warn("no PHP was found from which to determine the "
                         "import path")
                php_ver, include_path = None, []
            else:
                php_ver, include_path \
                    = self._php_info_from_php(php, env)

            libs = []

            # - extradirslib
            extra_dirs = self._extra_dirs_from_env(env)
            for extra_dir in extra_dirs:
                libs.append(db.get_lang_lib("PHP", "extradirslib",
                                            [extra_dir], "PHP"))

            # - inilib (i.e. dirs in the include_path in PHP.ini)
            include_dirs = [d for d in include_path
                            if d != '.'  # handled separately
                            if exists(d)]
            if include_dirs:
                max_depth = env.get_pref(
                    "codeintel_max_recursive_dir_depth", 10)
                php_assocs = env.assoc_patterns_from_lang("PHP")
                include_dirs = tuple(
                    util.gen_dirs_under_dirs(include_dirs,
                                             max_depth=max_depth,
                                             interesting_file_patterns=php_assocs)
                )
                if include_dirs:
                    libs.append(db.get_lang_lib("PHP", "inilib",
                                                include_dirs, "PHP"))

            # Warn the user if there is a huge number of import dirs that
            # might slow down completion.
            all_dirs = list(extra_dirs) + list(include_dirs)
            num_import_dirs = len(all_dirs)
            if num_import_dirs > 100:
                msg = "This buffer is configured with %d %s import dirs: " \
                      "this may result in poor completion performance" % \
                      (num_import_dirs, self.lang)
                self.mgr.report_message(msg, "\n".join(all_dirs))

            # - cataloglib, stdlib
            catalog_selections = env.get_pref("codeintel_selected_catalogs")
            libs += [
                db.get_catalog_lib("PHP", catalog_selections),
                db.get_stdlib("PHP", php_ver)
            ]
            env.cache[cache_key] = libs

        return env.cache[cache_key]

    def _invalidate_cache(self, env, pref_name):
        for key in ("php-buf-libs", "php-libs"):
            if key in env.cache:
                log.debug("invalidate '%s' cache on %r", key, env)
                del env.cache[key]

    def _invalidate_cache_and_rescan_extra_dirs(self, env, pref_name):
        self._invalidate_cache(env, pref_name)
        extra_dirs = self._extra_dirs_from_env(env)
        if extra_dirs:
            extradirslib = self.mgr.db.get_lang_lib(
                "PHP", "extradirslib", extra_dirs, "PHP")
            request = PreloadLibRequest(extradirslib)
            self.mgr.idxr.stage_request(request, 1.0)

    #---- code browser integration
    cb_import_group_title = "Includes and Requires"

    def cb_import_data_from_elem(self, elem):
        alias = elem.get("alias")
        symbol = elem.get("symbol")
        module = elem.get("module")
        if alias is not None:
            if symbol is not None:
                name = "%s (%s\%s)" % (alias, module, symbol)
                detail = "from %(module)s import %(symbol)s as %(alias)s" % locals(
                )
            else:
                name = "%s (%s)" % (alias, module)
                detail = "import %(module)s as %(alias)s" % locals()
        elif symbol is not None:
            if module == "\\":
                name = '\\%s' % (symbol)
            else:
                name = '%s\\%s' % (module, symbol)
            detail = "from %(module)s import %(symbol)s" % locals()
        else:
            name = module
            detail = 'include "%s"' % module
        return {"name": name, "detail": detail}

    def cb_variable_data_from_elem(self, elem):
        """Use the 'constant' image in the Code Browser for a variable constant.
        """
        data = CitadelLangIntel.cb_variable_data_from_elem(self, elem)
        if elem.get("ilk") == "constant":
            data["img"] = "constant"
        return data


class PHPBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "PHP"

    cb_show_if_empty = True

    # Fillup chars for PHP: basically, any non-identifier char.
    # - dropped '#' to prevent annoying behavior with $form['#foo']
    # - dropped '@' I could find no common use of "@" following func/variable
    # - dropped '$' It gets in the way of common usage: "$this->$"
    # - dropped '\\' I could find no common use of "\" following func/variable
    # - dropped '?' It gets in the way of common usage: "<?php "
    # - dropped '/', it gets in the way of "</" closing an XML/HTML tag
    # - dropped '!' It gets in the way of "<!" in XML/HTML tag (bug 78632)
    # - dropped '=' It gets in the way of "<a href=" in XML/HTML cpln (bug 78632)
    # - dropped ':' It gets in the way of "<a d:blah=" in XML/HTML cpln
    # - dropped '>' It gets in the way of "<p>asdf</" in XML/HTML tag cpln (bug 80348)
    cpln_fillup_chars = "~`%^&*()-+{}[]|;'\",.< "
    # TODO: c.f. cpln_stop_chars stuff in lang_html.py
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    # - dropping '#' because we need it for $form['#foo']
    # - dropping '$' because: MyClass::$class_var
    # - dropping '-' because causes problem with CSS (bug 78312)
    # - dropping '!' because causes problem with CSS "!important" (bug 78312)
    cpln_stop_chars = "~`@%^&*()=+{}]|\\;:'\",.<>?/ "

    def __init__(self, *args, **kwargs):
        super(PHPBuffer, self).__init__(*args, **kwargs)

        if isinstance(self.accessor, KoDocumentAccessor):
            # Encourage the database to pre-scan dirs relevant to completion
            # for this buffer -- because of recursive-dir-include-everything
            # semantics for PHP this first-time scan can take a while.
            request = PreloadBufLibsRequest(self)
            self.mgr.idxr.stage_request(request, 1.0)

    @property
    def libs(self):
        return self.langintel.libs_from_buf(self)

    @property
    def stdlib(self):
        return self.libs[-1]


class PHPImportHandler(ImportHandler):
    sep = '/'

    def setCorePath(self, compiler=None, extra=None):
        # XXX To do this independent of Komodo this would need to do all
        #    the garbage that koIPHPInfoEx is doing to determine this. It
        #    might also require adding a "rcfile" argument to this method
        #    so the proper php.ini file is used in the "_shellOutForPath".
        #    This is not crucial now because koCodeIntel._Manager() handles
        #    this for us.
        if not self.corePath:
            raise CodeIntelError("Do not know how to determine the core "
                                 "PHP include path. 'corePath' must be set "
                                 "manually.")

    def _findScannableFiles(self, (files, searchedDirs), dirname, names):
        if sys.platform.startswith("win"):
            cpath = dirname.lower()
        else:
            cpath = dirname
        if cpath in searchedDirs:
            while names:
                del names[0]
            return
        else:
            searchedDirs[cpath] = 1
        for i in range(len(names)-1, -1, -1):  # backward so can del from list
            path = os.path.join(dirname, names[i])
            if os.path.isdir(path):
                pass
            elif os.path.splitext(names[i])[1] in (".php", ".inc",
                                                   ".module", ".tpl"):
                # XXX The list of extensions should be settable on
                #    the ImportHandler and Komodo should set whatever is
                #    set in prefs. ".module" and ".tpl" are for
                #    drupal-nerds until CodeIntel gets this right.
                # XXX This check for files should probably include
                #    scripts, which might likely not have the
                #    extension: need to grow filetype-from-content smarts.
                files.append(path)

    def find_importables_in_dir(self, dir):
        """See citadel.py::ImportHandler.find_importables_in_dir() for
        details.

        Importables for PHP look like this:
            {"foo.php": ("foo.php", None, False),
             "bar.inc": ("bar.inc", None, False),
             "somedir": (None,      None, True)}

        TODO: log the fs-stat'ing a la codeintel.db logging.
        """
        from os.path import join, isdir
        from fnmatch import fnmatch

        if dir == "<Unsaved>":
            # TODO: stop these getting in here.
            return {}

        try:
            names = os.listdir(dir)
        except OSError, ex:
            return {}
        dirs, nondirs = set(), set()
        for name in names:
            try:
                if isdir(join(dir, name)):
                    dirs.add(name)
                else:
                    nondirs.add(name)
            except UnicodeDecodeError:
                # Hit a filename that cannot be encoded in the default encoding.
                # Just skip it. (Bug 82268)
                pass

        importables = {}
        patterns = self.mgr.env.assoc_patterns_from_lang("PHP")
        for name in nondirs:
            for pattern in patterns:
                if fnmatch(name, pattern):
                    break
            else:
                continue
            if name in dirs:
                importables[name] = (name, None, True)
                dirs.remove(name)
            else:
                importables[name] = (name, None, False)
        for name in dirs:
            importables[name] = (None, None, True)
        return importables


class PHPCILEDriver(UDLCILEDriver):
    lang = lang
    ssl_lang = "PHP"
    csl_lang = "JavaScript"

    def scan_multilang(self, buf, csl_cile_driver=None):
      # try:
        """Scan the given multilang (UDL-based) buffer and return a CIX
        element tree.

            "buf" is the multi-lang Buffer instance (e.g.
                lang_rhtml.RHTMLBuffer for RHTML).
            "csl_cile_driver" (optional) is the CSL (client-side language)
                CILE driver. While scanning, CSL tokens should be gathered and,
                if any, passed to the CSL scanner like this:
                    csl_cile_driver.scan_csl_tokens(
                        file_elem, blob_name, csl_tokens)
                The CSL scanner will append a CIX <scope ilk="blob"> element
                to the <file> element.
        """
        log.info("scan_multilang: path: %r lang: %s", buf.path, buf.lang)
        # Create the CIX tree.
        mtime = "XXX"
        fullpath = buf.path
        cixtree = createCixRoot()
        cixfile = createCixFile(cixtree, fullpath, lang=buf.lang)
        if sys.platform.startswith("win"):
            fullpath = fullpath.replace('\\', '/')
        basepath = os.path.basename(fullpath)
        cixblob = createCixModule(cixfile, basepath, "PHP", src=fullpath)

        phpciler = PHPParser(fullpath, buf.accessor.text, mtime)
        csl_tokens = phpciler.scan_multilang_content(buf.accessor.text)
        phpciler.convertToElementTreeModule(cixblob)

        # Hand off the csl tokens if any
        if csl_cile_driver and csl_tokens:
            csl_cile_driver.scan_csl_tokens(cixfile, basepath, csl_tokens)

        return cixtree

      # except Exception, e:
      #    print "\nPHP cile exception"
      #    import traceback
      #    traceback.print_exc()
      #    print
      #    raise


#---- internal routines and classes
# States used by PHP scanner when parsing information
S_DEFAULT = 0
S_IN_ARGS = 1
S_IN_ASSIGNMENT = 2
S_IGNORE_SCOPE = 3
S_OBJECT_ARGUMENT = 4
S_GET_HEREDOC_MARKER = 5
S_IN_HEREDOC = 6
S_TRAIT_RESOLUTION = 7
# Special tags for multilang handling (i.e. through UDL)
S_OPEN_TAG = 10
S_CHECK_CLOSE_TAG = 11
S_IN_SCRIPT = 12

# Types used by JavaScriptScanner when parsing information
TYPE_NONE = 0
TYPE_FUNCTION = 1
TYPE_VARIABLE = 2
TYPE_GETTER = 3
TYPE_SETTER = 4
TYPE_MEMBER = 5
TYPE_OBJECT = 6
TYPE_CLASS = 7
TYPE_PARENT = 8


def _sortByLineCmp(val1, val2):
    try:
    # if hasattr(val1, "line") and hasattr(val2, "line"):
        return cmp(val1.linestart, val2.linestart)
    except AttributeError:
        return cmp(val1, val2)


def sortByLine(seq):
    seq.sort(_sortByLineCmp)
    return seq


class PHPArg:
    def __init__(self, name, citdl=None, signature=None, default=None):
        """Set details for a function argument"""
        self.name = name
        self.citdl = citdl
        if signature:
            self.signature = signature
        else:
            if citdl:
                self.signature = "%s $%s" % (citdl, name)
            else:
                self.signature = "$%s" % (name, )
        self.default = default

    def __repr__(self):
        return self.signature

    def updateCitdl(self, citdl):
        self.citdl = citdl
        if self.signature.startswith("$") or self.signature.startswith("&") or \
           " " not in self.signature:
            self.signature = "%s %s" % (citdl, self.signature)
        else:
            self.signature = "%s %s" % (citdl, self.signature.split(" ", 1)[1])

    def toElementTree(self, cixelement, linestart=None):
        cixarg = addCixArgument(cixelement, self.name, argtype=self.citdl)
        if self.default:
            cixarg.attrib["default"] = self.default
        if linestart is not None:
            cixarg.attrib["line"] = str(linestart)


class PHPVariable:

    # PHPDoc variable type sniffer.
    _re_var = re.compile(
        r'^\s*@var\s+(\$(?P<variable>\w+)\s+)?(?P<type>[\w\\]+)(?:\s+(?P<doc>.*?))?', re.M | re.U)
    _ignored_php_types = ("object", "mixed")

    def __init__(self, name, line, vartype='', attributes='', doc=None,
                 fromPHPDoc=False, namespace=None):
        self.name = name
        self.types = [(line, vartype, fromPHPDoc)]
        self.linestart = line
        if attributes:
            if not isinstance(attributes, list):
                attributes = attributes.strip().split()
            self.attributes = ' '.join(attributes)
        else:
            self.attributes = None
        self.doc = doc
        self.created_namespace = None
        if namespace:
            self.created_namespace = namespace.name

    def addType(self, line, type, fromPHPDoc=False):
        self.types.append((line, type, fromPHPDoc))

    def __repr__(self):
        return "var %s line %s type %s attributes %s\n"\
               % (self.name, self.linestart, self.types, self.attributes)

    def toElementTree(self, cixblob):
        # Work out the best vartype
        vartype = None
        doc = None
        if self.doc:
            # We are only storing the doc string for cases where we have an
            # "@var" phpdoc tag, we should actually store the docs anyway, but
            # we don't yet have a clean way to ensure the doc is really meant
            # for this specific variable (i.e. the comment was ten lines before
            # the variable definition).
            if "@var" in self.doc:
                doc = uncommentDocString(self.doc)
                # get the variable citdl type set by "@var"
                all_matches = re.findall(self._re_var, doc)
                if len(all_matches) >= 1:
                    # print "all_matches[0]: %r" % (all_matches[0], )
                    vartype = all_matches[0][2]
                    if vartype and vartype.lower() in self._ignored_php_types:
                        # Ignore these PHP types, they don't help codeintel.
                        # http://bugs.activestate.com/show_bug.cgi?id=77602
                        vartype = None

        if not vartype and self.types:
            d = {}
            max_count = 0
            for line, vtype, fromPHPDoc in self.types:
                if vtype:
                    if fromPHPDoc:
                        if vtype.lower() in self._ignored_php_types:
                            # Ignore these PHP types, they don't help
                            # codeintel.
                            continue
                        # The doc gets priority.
                        vartype = vtype
                        break
                    count = d.get(vtype, 0) + 1
                    d[vtype] = count
                    if count > max_count:
                        # Best found so far
                        vartype = vtype
                        max_count = count
        cixelement = createCixVariable(cixblob, self.name, vartype=vartype,
                                       attributes=self.attributes)
        if doc:
            setCixDoc(cixelement, doc)
        cixelement.attrib["line"] = str(self.linestart)
        if self.created_namespace:
            # Need to remember that the object was created in a namespace, so
            # that the starting lookup scope can start in the given namespace.
            cixelement.attrib["namespace"] = self.created_namespace
        return cixelement


class PHPConstant(PHPVariable):
    def __init__(self, name, line, vartype=''):
        PHPVariable.__init__(self, name, line, vartype)

    def __repr__(self):
        return "constant %s line %s type %s\n"\
               % (self.name, self.linestart, self.types)

    def toElementTree(self, cixblob):
        cixelement = PHPVariable.toElementTree(self, cixblob)
        cixelement.attrib["ilk"] = "constant"
        return cixelement


class PHPFunction:
    def __init__(self, funcname, phpArgs, lineno, depth=0,
                 attributes=None, doc=None, classname='', classparent='',
                 returnType=None, returnByRef=False):
        self.name = funcname
        self.args = phpArgs
        self.linestart = lineno
        self.lineend = None
        self.depth = depth
        self.classname = classname
        self.classparent = classparent
        self.returnType = returnType
        self.returnByRef = returnByRef
        self.variables = {}  # all variables used in class
        # build the signature before we add any attributes that are not part
        # of the signature
        if returnByRef:
            self.signature = '&%s' % (self.name)
        else:
            self.signature = '%s' % (self.name)
        if attributes:
            attrs = ' '.join(attributes)
            self.shortSig = '%s %s' % (attrs, self.name)
        else:
            self.shortSig = self.name
        # both php 4 and 5 constructor methods
        if funcname == '__construct' or (classname and funcname.lower() == classname.lower()):
            attributes.append('__ctor__')
# if we add destructor attributes...
#        elif funcname == '__destruct':
#            attributes += ['__dtor__']
        self.attributes = attributes and ' '.join(attributes) or ''
        self.doc = None

        if doc:
            if isinstance(doc, list):
                doc = "".join(doc)
            docinfo = parseDocString(doc)
            self.doc = docinfo[0]
            # See if there are any PHPDoc arguments defined in the docstring.
            if docinfo[1]:
                for argInfo in docinfo[1]:
                    for phpArg in self.args:
                        if phpArg.name == argInfo[1]:
                            phpArg.updateCitdl(argInfo[0])
                            break
                    else:
                        self.args.append(PHPArg(argInfo[1], citdl=argInfo[0]))
            if docinfo[2]:
                self.returnType = docinfo[2][0]
        if self.returnType:
            self.signature = '%s %s' % (self.returnType, self.signature, )
        self.signature += "("
        if self.args:
            self.signature += ", ".join([x.signature for x in self.args])
        self.signature += ")"

    def addReturnType(self, returnType):
        if self.returnType is None:
            self.returnType = returnType

    def __str__(self):
        return self.signature
        # The following is busted and outputting multiple lines from __str__
        # and __repr__ is bad form: make debugging prints hard.
        # if self.doc:
        #    if self.args:
        #        return "%s(%s)\n%s" % (self.shortSig, self.args.argline, self.doc)
        #    else:
        #        return "%s()\n%s" % (self.shortSig, self.doc)
        # return "%s(%s)" % (self.shortSig, self.argline)

    def __repr__(self):
        return self.signature

    def hasArgumentWithName(self, name):
        if self.args:
            for phpArg in self.args:
                if phpArg.name == name:
                    return True
        return False

    def toElementTree(self, cixblob):
        cixelement = createCixFunction(cixblob, self.name,
                                       attributes=self.attributes)
        cixelement.attrib["line"] = str(self.linestart)
        if self.lineend is not None:
            cixelement.attrib['lineend'] = str(self.lineend)
        setCixSignature(cixelement, self.signature)
        if self.doc:
            setCixDoc(cixelement, self.doc)
        if self.args:
            for phpArg in self.args:
                phpArg.toElementTree(cixelement, self.linestart)
        if self.returnType:
            addCixReturns(cixelement, self.returnType)
        # Add a "this" and "self" member for class functions
        # if self.classname:
        #    createCixVariable(cixelement, "this", vartype=self.classname)
        #    createCixVariable(cixelement, "self", vartype=self.classname)
        # Add a "parent" member for class functions that have a parent
        # if self.classparent:
        #    createCixVariable(cixelement, "parent", vartype=self.classparent)

        # XXX for variables inside functions
        for v in self.variables.values():
            v.toElementTree(cixelement)


class PHPInterface:
    def __init__(self, name, extends, lineno, depth, doc=None):
        self.name = name
        self.extends = extends
        self.linestart = lineno
        self.lineend = None
        self.depth = depth
        self.constants = {}  # declared class constants
        self.members = {}  # declared class variables
        self.variables = {}  # all variables used in class
        self.functions = {}
        self.doc = None
        if doc:
            self.doc = uncommentDocString(doc)

    def __repr__(self):
        # dump our contents to human readable form
        r = "INTERFACE %s" % self.name
        if self.extends:
            r += " EXTENDS %s" % self.extends
        r += '\n'

        if self.constants:
            r += "Constants:\n"
            for m in self.constants:
                r += "    var %s line %s\n" % (m, self.constants[m])

        if self.members:
            r += "Members:\n"
            for m in self.members:
                r += "    var %s line %s\n" % (m, self.members[m])

        if self.functions:
            r += "functions:\n"
            for f in self.functions.values():
                r += "    %r" % f

        if self.variables:
            r += "variables:\n"
            for v in self.variables.values():
                r += "    %r" % v

        return r + '\n'

    def toElementTree(self, cixblob):
        cixelement = createCixInterface(cixblob, self.name)
        cixelement.attrib["line"] = str(self.linestart)
        if self.lineend is not None:
            cixelement.attrib["lineend"] = str(self.lineend)
        signature = "%s" % (self.name)
        if self.extends:
            signature += " extends %s" % (self.extends)
            for name in self.extends.split(","):
                addInterfaceRef(cixelement, name.strip())
            # SubElement(cixelement, "classref", name=self.extends)
        cixelement.attrib["signature"] = signature

        if self.doc:
            setCixDoc(self.doc)

        allValues = self.functions.values() + self.constants.values() + \
            self.members.values() + self.variables.values()
        for v in sortByLine(allValues):
            v.toElementTree(cixelement)


class PHPClass:

    cixtype = "CLASS"
    # PHPDoc magic property sniffer.
    _re_magic_property = re.compile(
        r'^\s*@property(-(?P<type>read|write))?\s+((?P<citdl>[\w\\]+)\s+)?(?P<name>\$\w+)(?:\s+(?P<doc>.*?))?', re.M | re.U)
    _re_magic_method = re.compile(
        r'^\s*@method\s+((?P<citdl>[\w\\]+)\s+)?(?P<name>\w+)(\(\))?(?P<doc>.*?)$', re.M | re.U)

    def __init__(self, name, extends, lineno, depth, attributes=None,
                 interfaces=None, doc=None):
        self.name = name
        self.extends = extends
        self.linestart = lineno
        self.lineend = None
        self.depth = depth
        self.constants = {}  # declared class constants
        self.members = {}  # declared class variables
        self.variables = {}  # all variables used in class
        self.functions = {}
        self.traits = {}
        self.traitOverrides = {}
        if interfaces:
            self.interfaces = interfaces.split(',')
        else:
            self.interfaces = []
        if attributes:
            self.attributes = ' '.join(attributes)
        else:
            self.attributes = None
        self.doc = None
        if doc:
            if isinstance(doc, list):
                doc = "".join(doc)
            self.doc = uncommentDocString(doc)
            if self.doc.find("@property") >= 0:
                all_matches = re.findall(self._re_magic_property, self.doc)
                for match in all_matches:
                    varname = match[4][1:]  # skip "$" in the name.
                    v = PHPVariable(varname, lineno, match[3], doc=match[5])
                    self.members[varname] = v
            if self.doc.find("@method") >= 0:
                all_matches = re.findall(self._re_magic_method, self.doc)
                for match in all_matches:
                    citdl = match[1] or None
                    fnname = match[2]
                    fndoc = match[4]
                    phpArgs = []
                    fn = PHPFunction(
                        fnname, phpArgs, lineno, depth=self.depth+1,
                        doc=fndoc, returnType=citdl)
                    self.functions[fnname] = fn

    def __repr__(self):
        # dump our contents to human readable form
        r = "%s %s" % (self.cixtype, self.name)
        if self.extends:
            r += " EXTENDS %s" % self.extends
        r += '\n'

        if self.constants:
            r += "Constants:\n"
            for m in self.constants:
                r += "    var %s line %s\n" % (m, self.constants[m])

        if self.members:
            r += "Members:\n"
            for m in self.members:
                r += "    var %s line %s\n" % (m, self.members[m])

        if self.functions:
            r += "functions:\n"
            for f in self.functions.values():
                r += "    %r" % f

        if self.variables:
            r += "variables:\n"
            for v in self.variables.values():
                r += "    %r" % v

        if self.traits:
            r += "traits:\n"
            for k, v in self.traits.items():
                r += "    %r" % k
            if self.traitOverrides:
                r += "trait overrides:\n"
                for k, v in self.traitOverrides.items():
                    r += "    %r, %r" % (k, v)

        return r + '\n'

    def addTraitReference(self, name):
        self.traits[name] = []

    def addTraitOverride(self, namelist, alias, visibility=None, insteadOf=False):
        self.traitOverrides[".".join(namelist)] = (
            alias, visibility, insteadOf)

    def _toElementTree(self, cixblob, cixelement):
        cixelement.attrib["line"] = str(self.linestart)
        if self.lineend is not None:
            cixelement.attrib["lineend"] = str(self.lineend)
        if self.attributes:
            cixelement.attrib["attributes"] = self.attributes

        if self.doc:
            setCixDoc(cixelement, self.doc)

        if self.extends:
            addClassRef(cixelement, self.extends)

        if self.traits:
            cixelement.attrib["traitrefs"] = " ".join(self.traits)
            for citdl, data in self.traitOverrides.items():
                alias, vis, insteadOf = data
                if alias and not insteadOf:
                    name = alias
                else:
                    name = citdl.split(".")[-1]
                override_elem = SubElement(
                    cixelement, "alias", name=name, citdl=citdl)
                if insteadOf:
                    override_elem.attrib["insteadof"] = alias
                if vis:
                    override_elem.attrib["attributes"] = vis

        for i in self.interfaces:
            addInterfaceRef(cixelement, i.strip())

        allValues = self.functions.values() + self.constants.values() + \
            self.members.values() + self.variables.values()
        for v in sortByLine(allValues):
            v.toElementTree(cixelement)

    def toElementTree(self, cixblob):
        cixelement = createCixClass(cixblob, self.name)
        self._toElementTree(cixblob, cixelement)


class PHPTrait(PHPClass):
    cixtype = "TRAIT"

    def toElementTree(self, cixblob):
        cixelement = SubElement(cixblob, "scope", ilk="trait", name=self.name)
        self._toElementTree(cixblob, cixelement)


class PHPImport:
    def __init__(self, name, lineno, alias=None, symbol=None):
        self.name = name
        self.lineno = lineno
        self.alias = alias
        self.symbol = symbol

    def __repr__(self):
        # dump our contents to human readable form
        if self.alias:
            return "IMPORT %s as %s\n" % (self.name, self.alias)
        else:
            return "IMPORT %s\n" % self.name

    def toElementTree(self, cixmodule):
        elem = SubElement(
            cixmodule, "import", module=self.name, line=str(self.lineno))
        if self.alias:
            elem.attrib["alias"] = self.alias
        if self.symbol:
            elem.attrib["symbol"] = self.symbol
        return elem


def qualifyNamespacePath(namespace_path):
    # Ensure the namespace does not begin or end with a backslash.
    return namespace_path.strip("\\")


class PHPNamespace:
    def __init__(self, name, lineno, depth, doc=None):
        assert not name.startswith("\\")
        assert not name.endswith("\\")
        self.name = name
        self.linestart = lineno
        self.lineend = None
        self.depth = depth
        self.doc = None
        if doc:
            self.doc = uncommentDocString(doc)

        self.functions = {}  # functions declared in file
        self.classes = {}  # classes declared in file
        self.constants = {}  # all constants used in file
        self.interfaces = {}  # interfaces declared in file
        self.includes = []  # imported files/namespaces

    def __repr__(self):
        # dump our contents to human readable form
        r = "NAMESPACE %s\n" % self.name

        for v in self.includes:
            r += "    %r" % v

        r += "constants:\n"
        for v in self.constants.values():
            r += "    %r" % v

        r += "interfaces:\n"
        for v in self.interfaces.values():
            r += "    %r" % v

        r += "functions:\n"
        for f in self.functions.values():
            r += "    %r" % f

        r += "classes:\n"
        for c in self.classes.values():
            r += repr(c)

        return r + '\n'

    def toElementTree(self, cixblob):
        cixelement = createCixNamespace(cixblob, self.name)
        cixelement.attrib["line"] = str(self.linestart)
        if self.lineend is not None:
            cixelement.attrib["lineend"] = str(self.lineend)

        if self.doc:
            setCixDoc(cixelement, self.doc)

        for v in self.includes:
            v.toElementTree(cixelement)

        allValues = self.functions.values() + self.constants.values() + \
            self.interfaces.values() + self.classes.values()
        for v in sortByLine(allValues):
            v.toElementTree(cixelement)


class PHPFile:
    """CIX specifies that a <file> tag have zero or more
    <scope ilk="blob"> children.  In PHP this is a one-to-one
    relationship, so this class represents both (and emits the XML tags
    for both).
    """
    def __init__(self, filename, content=None, mtime=None):
        self.filename = filename
        self.content = content
        self.mtime = mtime
        self.error = None

        self.content = content
        if mtime is None:
            self.mtime = int(time.time())

        self.functions = {}  # functions declared in file
        self.classes = {}  # classes declared in file
        self.variables = {}  # all variables used in file
        self.constants = {}  # all constants used in file
        self.includes = []  # imported files/namespaces
        self.interfaces = {}  # interfaces declared in file
        self.namespaces = {}  # namespaces declared in file

    def __repr__(self):
        # dump our contents to human readable form
        r = "FILE %s\n" % self.filename

        for v in self.includes:
            r += "    %r" % v

        r += "constants:\n"
        for v in self.constants.values():
            r += "    %r" % v

        r += "interfaces:\n"
        for v in self.interfaces.values():
            r += "    %r" % v

        r += "functions:\n"
        for f in self.functions.values():
            r += "    %r" % f

        r += "variables:\n"
        for v in self.variables.values():
            r += "    %r" % v

        r += "classes:\n"
        for c in self.classes.values():
            r += repr(c)

        r += "namespaces:\n"
        for v in self.namespaces.values():
            r += "    %r" % v

        return r + '\n'

    def convertToElementTreeModule(self, cixmodule):
        for v in self.includes:
            v.toElementTree(cixmodule)

        allValues = self.constants.values() + self.functions.values() + \
            self.interfaces.values() + self.variables.values() + \
            self.classes.values() + self.namespaces.values()
        for v in sortByLine(allValues):
            v.toElementTree(cixmodule)

    def convertToElementTreeFile(self, cix):
        if sys.platform.startswith("win"):
            path = self.filename.replace('\\', '/')
        else:
            path = self.filename
        cixfile = createCixFile(cix, path, lang="PHP", mtime=str(self.mtime))
        if self.error:
            cixfile.attrib["error"] = self.error
        cixmodule = createCixModule(cixfile, os.path.basename(self.filename),
                                    "PHP")
        self.convertToElementTreeModule(cixmodule)


class PHPcile:
    def __init__(self):
        # filesparsed contains all files parsed
        self.filesparsed = {}

    def clear(self, filename):
        # clear include links from the cache
        if filename not in self.filesparsed:
            return
        del self.filesparsed[filename]

    def __repr__(self):
        r = ''
        for f in self.filesparsed:
            r += repr(self.filesparsed[f])
        return r + '\n'

    # def toElementTree(self, cix):
    #    for f in self.filesparsed.values():
    #        f.toElementTree(cix)

    def convertToElementTreeModule(self, cixmodule):
        for f in self.filesparsed.values():
            f.convertToElementTreeModule(cixmodule)

    def convertToElementTreeFile(self, cix):
        for f in self.filesparsed.values():
            f.convertToElementTreeFile(cix)


class PHPParser:

    PHP_COMMENT_STYLES = (SCE_UDL_SSL_COMMENT, SCE_UDL_SSL_COMMENTBLOCK)
    # lastText, lastStyle are use to remember the previous tokens.
    lastText = None
    lastStyle = None

    def __init__(self, filename, content=None, mtime=None):
        self.filename = filename
        self.cile = PHPcile()
        self.fileinfo = PHPFile(self.filename, content, mtime)

        # Working variables, used in conjunction with state
        self.classStack = []
        self.currentClass = None
        self.currentNamespace = None
        self.currentFunction = None
        self.csl_tokens = []
        self.lineno = 0
        self.depth = 0
        self.styles = []
        self.linenos = []
        self.text = []
        self.comment = None
        self.comments = []
        self.heredocMarker = None

        # state : used to store the current JS lexing state
        # return_to_state : used to store JS state to return to
        # multilang_state : used to store the current UDL lexing state
        self.state = S_DEFAULT
        self.return_to_state = S_DEFAULT
        self.multilang_state = S_DEFAULT

        self.PHP_WORD = SCE_UDL_SSL_WORD
        self.PHP_IDENTIFIER = SCE_UDL_SSL_IDENTIFIER
        self.PHP_VARIABLE = SCE_UDL_SSL_VARIABLE
        self.PHP_OPERATOR = SCE_UDL_SSL_OPERATOR
        self.PHP_STRINGS = (SCE_UDL_SSL_STRING,)
        self.PHP_NUMBER = SCE_UDL_SSL_NUMBER

        # XXX bug 44775
        # having the next line after scanData below causes a crash on osx
        # in python's UCS2 to UTF8.  leaving this here for later
        # investigation, see bug 45362 for details.
        self.cile.filesparsed[self.filename] = self.fileinfo

    # parses included files
    def include_file(self, filename):
        # XXX Very simple prevention of include looping.  Really should
        # recurse the indices to make sure we are not creating a loop
        if self.filename == filename:
            return ""

        # add the included file to our list of included files
        self.fileinfo.includes.append(PHPImport(filename, self.lineno))

    def incBlock(self):
        self.depth = self.depth+1
        # log.debug("depth at %d", self.depth)

    def decBlock(self):
        self.depth = self.depth-1
        # log.debug("depth at %d", self.depth)
        if self.currentClass and self.currentClass.depth == self.depth:
            # log.debug("done with class %s at depth %d",
            # self.currentClass.name, self.depth)
            self.currentClass.lineend = self.lineno
            log.debug("done with %s %s at depth %r",
                      isinstance(
                          self.currentClass, PHPInterface) and "interface" or "class",
                      self.currentClass.name, self.depth)
            self.currentClass = self.classStack.pop()
        if self.currentNamespace and self.currentNamespace.depth == self.depth:
            log.debug("done with namespace %s at depth %r",
                      self.currentNamespace.name, self.depth)
            self.currentNamespace.lineend = self.lineno
            self.currentNamespace = None
        elif self.currentFunction and self.currentFunction.depth == self.depth:
            self.currentFunction.lineend = self.lineno
            # XXX stacked functions used to work in php, need verify still is
            self.currentFunction = None

    def addFunction(self, name, phpArgs=None, attributes=None, doc=None,
                    returnByRef=False):
        log.debug("FUNC: %s(%r) on line %d", name, phpArgs, self.lineno)
        classname = ''
        extendsName = ''
        if self.currentClass:
            classname = self.currentClass.name
            extendsName = self.currentClass.extends
        self.currentFunction = PHPFunction(name,
                                           phpArgs,
                                           self.lineno,
                                           self.depth,
                                           attributes=attributes,
                                           doc=doc,
                                           classname=classname,
                                           classparent=extendsName,
                                           returnByRef=returnByRef)
        if self.currentClass:
            self.currentClass.functions[
                self.currentFunction.name] = self.currentFunction
        elif self.currentNamespace:
            self.currentNamespace.functions[
                self.currentFunction.name] = self.currentFunction
        else:
            self.fileinfo.functions[
                self.currentFunction.name] = self.currentFunction
        if isinstance(self.currentClass, PHPInterface) or self.currentFunction.attributes.find('abstract') >= 0:
            self.currentFunction.lineend = self.lineno
            self.currentFunction = None

    def addReturnType(self, typeName):
        if self.currentFunction:
            log.debug("RETURN TYPE: %r on line %d", typeName, self.lineno)
            self.currentFunction.addReturnType(typeName)
        else:
            log.debug("addReturnType: No current function for return value!?")

    def addClass(self, name, extends=None, attributes=None, interfaces=None, doc=None, isTrait=False):
        toScope = self.currentNamespace or self.fileinfo
        if name not in toScope.classes:
            # push the current class onto the class stack
            self.classStack.append(self.currentClass)
            # make this class the current class
            cixClass = isTrait and PHPTrait or PHPClass
            self.currentClass = cixClass(name,
                                         extends,
                                         self.lineno,
                                         self.depth,
                                         attributes,
                                         interfaces,
                                         doc=doc)
            toScope.classes[self.currentClass.name] = self.currentClass
            log.debug(
                "%s: %s extends %s interfaces %s attributes %s on line %d in %s at depth %d\nDOCS: %s",
                self.currentClass.cixtype,
                self.currentClass.name, self.currentClass.extends,
                self.currentClass.interfaces, self.currentClass.attributes,
                self.currentClass.linestart, self.filename, self.depth,
                self.currentClass.doc)
        else:
            # shouldn't ever get here
            pass

    def addClassMember(self, name, vartype, attributes=None, doc=None, forceToClass=False):
        if self.currentFunction and not forceToClass:
            if name not in self.currentFunction.variables:
                phpVariable = self.currentClass.members.get(name)
                if phpVariable is None:
                    log.debug("Class FUNC variable: %r", name)
                    self.currentFunction.variables[name] = PHPVariable(name,
                                                                       self.lineno,
                                                                       vartype,
                                                                       doc=doc)
                elif vartype:
                    log.debug(
                        "Adding type information for VAR: %r, vartype: %r",
                        name, vartype)
                    phpVariable.addType(self.lineno, vartype)
        elif self.currentClass:
            phpVariable = self.currentClass.members.get(name)
            if phpVariable is None:
                log.debug("CLASSMBR: %r", name)
                self.currentClass.members[name] = PHPVariable(
                    name, self.lineno,
                    vartype,
                    attributes,
                    doc=doc)
            elif vartype:
                log.debug(
                    "Adding type information for CLASSMBR: %r, vartype: %r",
                    name, vartype)
                phpVariable.addType(self.lineno, vartype)

    def addClassConstant(self, name, vartype, doc=None):
        """Add a constant variable into the current class."""
        if self.currentClass:
            phpConstant = self.currentClass.constants.get(name)
            if phpConstant is None:
                log.debug("CLASS CONST: %r", name)
                self.currentClass.constants[name] = PHPConstant(
                    name, self.lineno,
                    vartype)
            elif vartype:
                log.debug("Adding type information for CLASS CONST: %r, "
                          "vartype: %r", name, vartype)
                phpConstant.addType(self.lineno, vartype)

    def addInterface(self, name, extends=None, doc=None):
        toScope = self.currentNamespace or self.fileinfo
        if name not in toScope.interfaces:
            # push the current interface onto the class stack
            self.classStack.append(self.currentClass)
            # make this interface the current interface
            self.currentClass = PHPInterface(
                name, extends, self.lineno, self.depth)
            toScope.interfaces[name] = self.currentClass
            log.debug("INTERFACE: %s extends %s on line %d, depth %d",
                      name, extends, self.lineno, self.depth)
        else:
            # shouldn't ever get here
            pass

    def setNamespace(self, namelist, usesBracketedStyle, doc=None):
        """Create and set as the current namespace."""
        if self.currentNamespace:
            # End the current namespace before starting the next.
            self.currentNamespace.lineend = self.lineno - 1

        if not namelist:
            # This means to use the global namespace, i.e.:
            #   namespace { // global code }
            # http://ca3.php.net/manual/en/language.namespaces.definitionmultiple.php
            self.currentNamespace = None
        else:
            depth = self.depth
            if not usesBracketedStyle:
                # If the namespacing does not uses brackets, then there is no
                # good way to find out when the namespace end, we can only
                # guarentee that the namespace ends if another namespace starts.
                # Using None as the depth will ensure these semantics hold.
                depth = None
            namespace_path = qualifyNamespacePath("\\".join(namelist))
            namespace = self.fileinfo.namespaces.get(namespace_path)
            if namespace is None:
                namespace = PHPNamespace(namespace_path, self.lineno, depth,
                                         doc=doc)
                self.fileinfo.namespaces[namespace_path] = namespace
            self.currentNamespace = namespace
            log.debug("NAMESPACE: %r on line %d in %s at depth %r",
                      namespace_path, self.lineno, self.filename, depth)

    def addNamespaceImport(self, namespace, alias):
        """Import the namespace."""
        namelist = namespace.split("\\")
        namespace_path = "\\".join(namelist[:-1])
        if namespace.startswith("\\") and not namespace_path.startswith("\\"):
            namespace_path = "\\%s" % (namespace_path, )
        symbol = namelist[-1]
        toScope = self.currentNamespace or self.fileinfo
        toScope.includes.append(PHPImport(namespace_path, self.lineno,
                                          alias=alias, symbol=symbol))
        log.debug("IMPORT NAMESPACE: %s\%s as %r on line %d",
                  namespace_path, symbol, alias, self.lineno)

    def addVariable(self, name, vartype='', attributes=None, doc=None,
                    fromPHPDoc=False):
        log.debug("VAR: %r type: %r on line %d", name, vartype, self.lineno)
        phpVariable = None
        already_existed = True
        if self.currentFunction:
            phpVariable = self.currentFunction.variables.get(name)
            # Also ensure the variable is not a function argument.
            if phpVariable is None and \
               not self.currentFunction.hasArgumentWithName(name):
                phpVariable = PHPVariable(name, self.lineno, vartype,
                                          attributes, doc=doc,
                                          fromPHPDoc=fromPHPDoc)
                self.currentFunction.variables[name] = phpVariable
                already_existed = False
        elif self.currentClass:
            pass
            # XXX this variable is local to a class method, what to do with it?
            # if m.group('name') not in self.currentClass.variables:
            #    self.currentClass.variables[m.group('name')] =\
            #        PHPVariable(m.group('name'), self.lineno)
        else:
            # Variables cannot get defined in a namespace, so if it's not a
            # function or a class, then it goes into the global scope.
            phpVariable = self.fileinfo.variables.get(name)
            if phpVariable is None:
                phpVariable = PHPVariable(name, self.lineno, vartype,
                                          attributes, doc=doc,
                                          fromPHPDoc=fromPHPDoc,
                                          namespace=self.currentNamespace)
                self.fileinfo.variables[name] = phpVariable
                already_existed = False

        if phpVariable and already_existed:
            if doc:
                if phpVariable.doc:
                    phpVariable.doc += doc
                else:
                    phpVariable.doc = doc
            if vartype:
                log.debug("Adding type information for VAR: %r, vartype: %r",
                          name, vartype)
                phpVariable.addType(
                    self.lineno, vartype, fromPHPDoc=fromPHPDoc)
        return phpVariable

    def addConstant(self, name, vartype='', doc=None):
        """Add a constant at the global or namelisted scope level."""

        log.debug(
            "CONSTANT: %r type: %r on line %d", name, vartype, self.lineno)
        toScope = self.currentNamespace or self.fileinfo
        phpConstant = toScope.constants.get(name)
        # Add it if it's not already defined
        if phpConstant is None:
            if vartype and isinstance(vartype, (list, tuple)):
                vartype = ".".join(vartype)
            toScope.constants[name] = PHPConstant(name, self.lineno, vartype)

    def addDefine(self, name, vartype='', doc=None):
        """Add a define at the global or namelisted scope level."""

        log.debug("DEFINE: %r type: %r on line %d", name, vartype, self.lineno)
        # Defines always go into the global scope unless explicitly defined
        # with a namespace:
        #   http://ca3.php.net/manual/en/language.namespaces.definition.php
        toScope = self.fileinfo
        namelist = name.split("\\")
        if len(namelist) > 1:
            namespace_path = "\\".join(namelist[:-1])
            namespace_path = qualifyNamespacePath(namespace_path)
            log.debug("defined in namespace: %r", namespace_path)
            namespace = toScope.namespaces.get(namespace_path)
            # Note: This does not change to the namespace, it just creates
            #       it when it does not already exist!
            if namespace is None:
                namespace = PHPNamespace(namespace_path, self.lineno,
                                         self.depth)
                self.fileinfo.namespaces[namespace_path] = namespace
            toScope = namespace
        const_name = namelist[-1]
        phpConstant = toScope.constants.get(const_name)
        # Add it if it's not already defined
        if phpConstant is None:
            if vartype and isinstance(vartype, (list, tuple)):
                vartype = ".".join(vartype)
            toScope.constants[const_name] = PHPConstant(
                const_name, self.lineno, vartype)

    def _parseOneArgument(self, styles, text):
        """Create a PHPArg object from the given text"""

        # Arguments can be of the form:
        #  foo($a, $b, $c)
        #  foo(&$a, &$b, &$c)
        #  foo($a, &$b, $c)
        #  foo($a = "123")
        #  makecoffee($types = array("cappuccino"), $coffeeMaker = NULL)
        # Arguments can be statically typed declarations too, bug 79003:
        #  foo(MyClass $a)
        #  foo(string $a = "123")
        #  foo(MyClass &$a)
        # References the inner class:
        #  static function bar($x=self::X)

        pos = 0
        name = None
        citdl = None
        default = None
        sig_parts = []
        log.debug("_parseOneArgument: text: %r", text)
        while pos < len(styles):
            sig_parts.append(text[pos])
            if name is None:
                if styles[pos] == self.PHP_VARIABLE:
                    name = self._removeDollarSymbolFromVariableName(text[pos])
                elif styles[pos] in (self.PHP_IDENTIFIER, self.PHP_WORD):
                    # Statically typed argument.
                    citdl = text[pos]
                    sig_parts.append(" ")
                elif text[pos] == '&':
                    sig_parts.append(" ")
            elif not citdl:
                if text[pos] == "=":
                    sig_parts[-1] = " = "
                    # It's an optional argument
                    default = "".join(text[pos+1:])
                    valueType, pos = self._getVariableType(styles, text, pos+1)
                    if valueType:
                        citdl = valueType[0]
                    break
            else:
                pos += 1
                break
            pos += 1
        sig_parts += text[pos:]
        if name is not None:
            return PHPArg(name, citdl=citdl, signature="".join(sig_parts),
                          default=default)

    def _getArgumentsFromPos(self, styles, text, pos):
        """Return a list of PHPArg objects"""

        p = pos
        log.debug("_getArgumentsFromPos: text: %r", text[p:])
        phpArgs = []
        if p < len(styles) and styles[p] == self.PHP_OPERATOR and text[p] == "(":
            p += 1
            paren_count = 0
            start_pos = p
            while p < len(styles):
                if styles[p] == self.PHP_OPERATOR:
                    if text[p] == "(":
                        paren_count += 1
                    elif text[p] == ")":
                        if paren_count <= 0:
                            # End of the arguments.
                            break
                        paren_count -= 1
                    elif text[p] == "," and paren_count == 0:
                        # End of the current argument.
                        phpArg = self._parseOneArgument(styles[start_pos:p],
                                                        text[start_pos:p])
                        if phpArg:
                            phpArgs.append(phpArg)
                        start_pos = p + 1
                p += 1
            if start_pos < p:
                phpArg = self._parseOneArgument(styles[start_pos:p],
                                                text[start_pos:p])
                if phpArg:
                    phpArgs.append(phpArg)
        return phpArgs, p

    def _getOneIdentifierFromPos(self, styles, text, pos, identifierStyle=None):
        if identifierStyle is None:
            identifierStyle = self.PHP_IDENTIFIER
        log.debug("_getIdentifiersFromPos: text: %r", text[pos:])
        start_pos = pos
        ids = []
        last_style = self.PHP_OPERATOR
        isNamespace = False
        while pos < len(styles):
            style = styles[pos]
            # print "Style: %d, Text[%d]: %r" % (style, pos, text[pos])
            if style == identifierStyle:
                if last_style != self.PHP_OPERATOR:
                    break
                if isNamespace:
                    ids[-1] += text[pos]
                else:
                    ids.append(text[pos])
            elif style == self.PHP_OPERATOR:
                t = text[pos]
                isNamespace = False
                if t == "\\":
                    isNamespace = True
                    if ids:
                        ids[-1] += "\\"
                    else:
                        ids.append("\\")
                elif ((t != "&" or last_style != self.PHP_OPERATOR) and
                      (t != ":" or last_style != identifierStyle)):
                    break
            else:
                break
            pos += 1
            last_style = style
        return ids, pos

    def _getIdentifiersFromPos(self, styles, text, pos, identifierStyle=None):
        typeNames, p = self._getOneIdentifierFromPos(
            styles, text, pos, identifierStyle)
        if typeNames:
            typeNames[0] = self._removeDollarSymbolFromVariableName(
                typeNames[0])
        log.debug(
            "typeNames: %r, p: %d, text left: %r", typeNames, p, text[p:])
        # Grab additional fields
        # Example: $x = $obj<p>->getFields()->field2
        while p+2 < len(styles) and styles[p] == self.PHP_OPERATOR and \
                text[p] in (":->\\"):
            isNamespace = False
            if text[p] == "\\":
                isNamespace = True
            p += 1
            log.debug("while:: p: %d, text left: %r", p, text[p:])
            if styles[p] == self.PHP_IDENTIFIER or \
               (styles[p] == self.PHP_VARIABLE and text[p-1] == ":"):
                additionalNames, p = self._getOneIdentifierFromPos(
                    styles, text, p, styles[p])
                log.debug("p: %d, additionalNames: %r", p, additionalNames)
                if additionalNames:
                    if isNamespace:
                        if typeNames:
                            typeNames[-1] += "\\%s" % (additionalNames[0])
                        else:
                            typeNames.append("\\%s" % (additionalNames[0]))
                    else:
                        typeNames.append(additionalNames[0])
                    if p < len(styles) and \
                       styles[p] == self.PHP_OPERATOR and text[p][0] == "(":
                        typeNames[-1] += "()"
                        p = self._skipPastParenArguments(styles, text, p+1)
                        log.debug(
                            "_skipPastParenArguments:: p: %d, text left: %r", p, text[p:])
        return typeNames, p

    def _skipPastParenArguments(self, styles, text, p):
        paren_count = 1
        while p < len(styles):
            if styles[p] == self.PHP_OPERATOR:
                if text[p] == "(":
                    paren_count += 1
                elif text[p] == ")":
                    if paren_count == 1:
                        return p+1
                    paren_count -= 1
            p += 1
        return p

    _citdl_type_from_cast = {
        "int":       "int",
        "integer":   "int",
        "bool":      "boolean",
        "boolean":   "boolean",
        "float":     "int",
        "double":    "int",
        "real":      "int",
        "string":    "string",
        "binary":    "string",
        "array":     "array()",   # array(), see bug 32896.
        "object":    "object",
    }

    def _getVariableType(self, styles, text, p, assignmentChar="="):
        """Set assignmentChar to None to skip over looking for this char first"""

        log.debug("_getVariableType: text: %r", text[p:])
        typeNames = []
        if p+1 < len(styles) and (assignmentChar is None or
                                  (styles[p] == self.PHP_OPERATOR and
                                   text[p] == assignmentChar)):
            # Assignment to the variable
            if assignmentChar is not None:
                p += 1
                if p+1 >= len(styles):
                    return typeNames, p

            if styles[p] == self.PHP_OPERATOR and text[p] == '&':
                log.debug("_getVariableType: skipping over reference char '&'")
                p += 1
                if p+1 >= len(styles):
                    return typeNames, p

            elif p+3 <= len(styles) and styles[p] == self.PHP_OPERATOR and \
                    text[p+2] == ')' and text[p+1] in self._citdl_type_from_cast:
                # Looks like a casting:
                # http://ca.php.net/manual/en/language.types.type-juggling.php#language.types.typecasting
                #   $bar = (boolean) $foo;
                typeNames = [self._citdl_type_from_cast.get(text[p+1])]
                log.debug("_getVariableType: casted to type: %r", typeNames)
                p += 3
                return typeNames, p

            if styles[p] == self.PHP_WORD:
                # Keyword
                keyword = text[p].lower()
                p += 1
                if keyword == "new":
                    typeNames, p = self._getIdentifiersFromPos(styles, text, p)
                    # if not typeNames:
                    #    typeNames = ["object"]
                elif keyword in ("true", "false"):
                    typeNames = ["boolean"]
                elif keyword == "array":
                    typeNames = ["array()"]
                elif keyword == "clone":
                    # clone is a special method - bug 85534.
                    typeNames, p = self._getIdentifiersFromPos(styles, text, p,
                                                               identifierStyle=self.PHP_VARIABLE)
            elif styles[p] in self.PHP_STRINGS:
                p += 1
                typeNames = ["string"]
            elif styles[p] == self.PHP_NUMBER:
                p += 1
                typeNames = ["int"]
            elif styles[p] == self.PHP_IDENTIFIER:
                # PHP Uses mixed upper/lower case for boolean values.
                if text[p].lower() in ("true", "false"):
                    p += 1
                    typeNames = ["boolean"]
                else:
                    typeNames, p = self._getIdentifiersFromPos(styles, text, p)
                    # Don't record null, as it doesn't help us with anything
                    if typeNames == ["NULL"]:
                        typeNames = []
                    elif typeNames and p < len(styles) and \
                            styles[p] == self.PHP_OPERATOR and text[p][0] == "(":
                        typeNames[-1] += "()"
            elif styles[p] == self.PHP_VARIABLE:
                typeNames, p = self._getIdentifiersFromPos(
                    styles, text, p, self.PHP_VARIABLE)
            elif styles[p] == self.PHP_OPERATOR and text[p] == "\\":
                typeNames, p = self._getIdentifiersFromPos(
                    styles, text, p, self.PHP_IDENTIFIER)

        return typeNames, p

    def _getKeywordArguments(self, styles, text, p, keywordName):
        arguments = None
        while p < len(styles):
            if styles[p] == self.PHP_WORD and text[p] == keywordName:
                # Grab the definition
                p += 1
                arguments = []
                last_style = self.PHP_OPERATOR
                namespaced = False
                while p < len(styles):
                    if styles[p] == self.PHP_IDENTIFIER and \
                       last_style == self.PHP_OPERATOR:
                        if namespaced:
                            arguments[-1] += text[p]
                            namespaced = False
                        else:
                            arguments.append(text[p])
                    elif styles[p] == self.PHP_OPERATOR and text[p] == "\\":
                        if not arguments or last_style != self.PHP_IDENTIFIER:
                            arguments.append(text[p])
                        else:
                            arguments[-1] += text[p]
                        namespaced = True
                    elif styles[p] != self.PHP_OPERATOR or text[p] != ",":
                        break
                    last_style = styles[p]
                    p += 1
                arguments = ", ".join(arguments)
                break
            p += 1
        return arguments

    def _getExtendsArgument(self, styles, text, p):
        return self._getKeywordArguments(styles, text, p, "extends")

    def _getImplementsArgument(self, styles, text, p):
        return self._getKeywordArguments(styles, text, p, "implements")

    def _unquoteString(self, s):
        """Return the string without quotes around it"""
        if len(s) >= 2 and s[0] in "\"'":
            return s[1:-1]
        return s

    def _removeDollarSymbolFromVariableName(self, name):
        if name[0] == "$":
            return name[1:]
        return name

    def _getIncludePath(self, styles, text, p):
        """Work out the include string and return it (without the quotes)"""

        # Some examples (include has identical syntax):
        #   require 'prepend.php';
        #   require $somefile;
        #   require ('somefile.txt');
        # From bug: http://bugs.activestate.com/show_bug.cgi?id=64208
        # We just find the first string and use that
        #   require_once(CEON_CORE_DIR . 'core/datatypes/class.CustomDT.php');
        # Skip over first brace if it exists
        if p < len(styles) and \
           styles[p] == self.PHP_OPERATOR and text[p] == "(":
            p += 1
        while p < len(styles):
            if styles[p] in self.PHP_STRINGS:
                requirename = self._unquoteString(text[p])
                if requirename:
                    # Return with the first string found, we could do better...
                    return requirename
            p += 1
        return None

    def _unescape_string(self, s):
        """Unescape a PHP string."""
        return s.replace("\\\\", "\\")

    def _getConstantNameAndType(self, styles, text, p):
        """Work out the constant name and type is, returns these as tuple"""

        # Some examples (include has identical syntax):
        #   define('prepend', 1);
        #   define ('somefile', "file.txt");
        #   define('\namespace\CONSTANT', True);
        #   define(__NAMESPACE__ . '\CONSTANT', True);
        constant_name = ""
        constant_type = None
        if styles[p] == self.PHP_OPERATOR and text[p] == "(":
            p += 1
        while p < len(styles):
            if styles[p] in self.PHP_STRINGS:
                constant_name += self._unquoteString(text[p])
            elif styles[p] == self.PHP_WORD and \
                    text[p] == "__NAMESPACE__" and self.currentNamespace:
                # __NAMESPACE__ is a special constant - we can expand this as we
                # know what the current namespace is.
                constant_name += self.currentNamespace.name
            elif text[p] == ",":
                constant_type, p = self._getVariableType(styles, text, p+1,
                                                         assignmentChar=None)
                break
            p += 1
        # We must ensure the name (which came from a PHP string is unescaped),
        # bug 90795.
        return self._unescape_string(constant_name), constant_type

    def _addAllVariables(self, styles, text, p):
        while p < len(styles):
            if styles[p] == self.PHP_VARIABLE:
                namelist, p = self._getIdentifiersFromPos(
                    styles, text, p, self.PHP_VARIABLE)
                if len(namelist) == 1:
                    name = self._removeDollarSymbolFromVariableName(
                        namelist[0])
                    # Don't add special internal variable names
                    if name in ("this", "self"):
                        # Lets see what we are doing with this
                        if p+3 < len(styles) and "".join(text[p:p+2]) in ("->", "::"):
                            # Get the variable the code is accessing
                            namelist, p = self._getIdentifiersFromPos(
                                styles, text, p+2)
                            typeNames, p = self._getVariableType(
                                styles, text, p)
                            if len(namelist) == 1 and typeNames:
                                log.debug(
                                    "Assignment through %r for variable: %r", name, namelist)
                                self.addClassMember(namelist[0],
                                                    ".".join(typeNames),
                                                    doc=self.comment,
                                                    forceToClass=True)
                    elif name is not "parent":
                        # If next text/style is not an "=" operator, then add
                        # __not_defined__, which means the variable was not yet
                        # defined at the position it was ciled.
                        attributes = None
                        if p < len(styles) and text[p] != "=":
                            attributes = "__not_yet_defined__"
                        self.addVariable(name, attributes=attributes)
            p += 1

    def _handleVariableComment(self, namelist, comment):
        """Determine any necessary information from the provided comment.
        Returns true when the comment was used to apply variable info, false
        otherwise.
        """
        log.debug("_handleVariableComment:: namelist: %r, comment: %r",
                  namelist, comment)
        if "@var" in comment:
            doc = uncommentDocString(comment)
            # get the variable citdl type set by "@var"
            all_matches = re.findall(PHPVariable._re_var, doc)
            if len(all_matches) >= 1:
                # print all_matches[0]
                varname = all_matches[0][1]
                vartype = all_matches[0][2]
                php_variable = None
                if varname:
                    # Optional, defines the variable this is applied to.
                    php_variable = self.addVariable(varname, vartype,
                                                    doc=comment,
                                                    fromPHPDoc=True)
                    return True
                elif namelist:
                    php_variable = self.addVariable(namelist[0], vartype,
                                                    doc=comment,
                                                    fromPHPDoc=True)
                    return True
        return False

    def _variableHandler(self, styles, text, p, attributes, doc=None,
                         style="variable"):
        log.debug("_variableHandler:: style: %r, text: %r, attributes: %r",
                  style, text[p:], attributes)
        classVar = False
        if attributes:
            classVar = True
            if "var" in attributes:
                attributes.remove("var")  # Don't want this in cile output
        if style == "const":
            if self.currentClass is not None:
                classVar = True
            elif self.currentNamespace is not None:
                classVar = False
            else:
                log.debug("Ignoring const %r, as not defined in a "
                          "class or namespace context.", text)
                return
        looped = False
        while p < len(styles):
            if looped:
                if text[p] != ",":  # Variables need to be comma delimited.
                    p += 1
                    continue
                p += 1
            else:
                looped = True
            if style == "const":
                namelist, p = self._getIdentifiersFromPos(styles, text, p,
                                                          self.PHP_IDENTIFIER)
            elif text[p:p+3] == ["self", ":", ":"]:
                # Handle things like: "self::$instance = FOO", bug 92813.
                classVar = True
                namelist, p = self._getIdentifiersFromPos(styles, text, p+3,
                                                          self.PHP_VARIABLE)
            else:
                namelist, p = self._getIdentifiersFromPos(styles, text, p,
                                                          self.PHP_VARIABLE)
            if not namelist:
                break
            log.debug("namelist:%r, p:%d", namelist, p)
            # Remove the dollar sign
            name = self._removeDollarSymbolFromVariableName(namelist[0])
            # Parse special internal variable names
            if name == "parent":
                continue
            thisVar = False
            if name in ("this", "self", ):
                classVar = True
                thisVar = True  # need to distinguish between class var types.
                if len(namelist) <= 1:
                    continue
                # We don't need the this/self piece of the namelist.
                namelist = namelist[1:]
                name = namelist[0]
            if len(namelist) != 1:
                # Example:  "item->foo;"  translates to namelist: [item, foo]
                if self.comment:
                    # We may be able to get some PHPDoc out of the comment.
                    if self._handleVariableComment(namelist, self.comment):
                        self.comment = None
                log.info("multiple part variable namelist (ignoring): "
                         "%r, line: %d in file: %r", namelist,
                         self.lineno, self.filename)
                continue
            if name.endswith("()"):
                # Example:  "foo(x);"  translates to namelist: [foo()]
                if self.comment:
                    # We may be able to get some PHPDoc out of the comment.
                    if self._handleVariableComment(namelist, self.comment):
                        self.comment = None
                log.info("variable is making a method call (ignoring): "
                         "%r, line: %d in file: %r", namelist,
                         self.lineno, self.filename)
                continue

            assignChar = text[p]
            typeNames = []
            mustCreateVariable = False
            # Work out the citdl, we also ensure this is not just a comparison,
            # i.e. not "$x == 2".
            if p+1 < len(styles) and styles[p] == self.PHP_OPERATOR and \
                assignChar in "=" and \
               (p+2 >= len(styles) or text[p+1] != "="):
                # Assignment to the variable
                mustCreateVariable = True
                typeNames, p = self._getVariableType(
                    styles, text, p, assignChar)
                log.debug("typeNames: %r", typeNames)
                # Skip over paren arguments from class, function calls.
                if typeNames and p < len(styles) and \
                   styles[p] == self.PHP_OPERATOR and text[p] == "(":
                    p = self._skipPastParenArguments(styles, text, p+1)

            # Create the variable cix information.
            if mustCreateVariable or (not thisVar and p < len(styles) and
                                      styles[p] == self.PHP_OPERATOR and
                                      text[p] in ",;"):
                log.debug("Line %d, variable definition: %r",
                          self.lineno, namelist)
                if style == "const":
                    if classVar:
                        self.addClassConstant(name, ".".join(typeNames),
                                              doc=self.comment)
                    else:
                        self.addConstant(name, ".".join(typeNames),
                                         doc=self.comment)
                elif classVar and self.currentClass is not None:
                    self.addClassMember(name, ".".join(typeNames),
                                        attributes=attributes, doc=self.comment,
                                        forceToClass=classVar)
                else:
                    self.addVariable(name, ".".join(typeNames),
                                     attributes=attributes, doc=self.comment)

    def _useKeywordHandler(self, styles, text, p):
        log.debug("_useKeywordHandler:: text: %r", text[p:])
        looped = False
        while p < len(styles):
            if looped:
                if text[p] != ",":  # Use statements need to be comma delimited.
                    p += 1
                    continue
                p += 1
            else:
                looped = True

            namelist, p = self._getIdentifiersFromPos(styles, text, p)
            log.debug("use:%r, p:%d", namelist, p)
            if namelist:
                alias = None
                if p+1 < len(styles):
                    if styles[p] == self.PHP_WORD and \
                       text[p] == "as":
                        # Uses an alias
                        alias, p = self._getIdentifiersFromPos(
                            styles, text, p+1)
                        if alias:
                            alias = alias[0]
                if self.currentClass:
                    # Must be a trait.
                    self.currentClass.addTraitReference(namelist[0])
                else:
                    # Must be a namespace reference.
                    self.addNamespaceImport(namelist[0], alias)

    def _handleTraitResolution(self, styles, text, p, doc=None):
        log.debug("_handleTraitResolution:: text: %r", text[p:])
        # Examples:
        #       B::smallTalk insteadof A;
        #       B::bigTalk as talk;
        #       sayHello as protected;
        #       sayHello as private myPrivateHello;

        # Can only be defined on a trait or a class.
        if not self.currentClass:
            log.warn(
                "_handleTraitResolution:: not in a class|trait definition")
            return

        # Look for the identifier first.
        #
        namelist, p = self._getIdentifiersFromPos(styles, text, p,
                                                  self.PHP_IDENTIFIER)
        log.debug("namelist:%r, p:%d", namelist, p)
        if not namelist or p+2 >= len(text):
            log.warn("Not enough arguments in trait use statement: %r", text)
            return

        # Get the keyword "as", "insteadof"
        keyword = text[p]
        log.debug("keyword:%r", keyword)
        p += 1

        # Get the settings.
        alias = None
        visibility = None
        # Get special attribute keywords.
        if keyword == "as" and \
           text[p] in ("public", "protected", "private"):
            visibility = text[p]
            p += 1
            log.debug("_handleTraitResolution: visibility %r", visibility)
        if p < len(text):
            # Get the alias name.
            names, p = self._getIdentifiersFromPos(styles, text, p)
            if names:
                alias = names[0]
                if len(names) > 1:
                    log.warn("Ignoring multiple alias identifiers in text: %r",
                             text)
        if alias or visibility:
            # Set override.
            self.currentClass.addTraitOverride(namelist, alias,
                                               visibility=visibility,
                                               insteadOf=(keyword == "insteadof"))
        else:
            self.warn("Unknown trait resolution: %r", text)

    def _addCodePiece(self, newstate=S_DEFAULT, varnames=None):
        styles = self.styles
        if len(styles) == 0:
            return
        text = self.text
        lines = self.linenos

        log.debug("*** Line: %d ********************************", self.lineno)
        # log.debug("Styles: %r", self.styles)
        log.debug("Text: %r", self.text)
        # log.debug("Comment: %r", self.comment)
        # log.debug("")

        pos = 0
        attributes = []
        firstStyle = styles[pos]

        try:
            # We may be able to get some PHPDoc out of the comment already,
            # such as targeted "@var " comments.
            # http://bugs.activestate.com/show_bug.cgi?id=76676
            if self.comment and self._handleVariableComment(None, self.comment):
                self.comment = None

            # Eat special attribute keywords
            while firstStyle == self.PHP_WORD and \
                text[pos] in ("var", "public", "protected", "private",
                              "final", "static", "abstract"):
                attributes.append(text[pos])
                pos += 1
                firstStyle = styles[pos]

            if firstStyle == self.PHP_WORD:
                keyword = text[pos].lower()
                pos += 1
                if pos >= len(lines):
                    # Nothing else here, go home
                    return
                self.lineno = lines[pos]
                if keyword in ("require", "include", "require_once", "include_once"):
                    # Some examples (include has identical syntax):
                    # require 'prepend.php';
                    # require $somefile;
                    # require ('somefile.txt');
                    # XXX - Below syntax is not handled...
                    # if ((include 'vars.php') == 'OK') {
                    namelist = None
                    if pos < len(styles):
                        requirename = self._getIncludePath(styles, text, pos)
                        if requirename:
                            self.include_file(requirename)
                        else:
                            log.debug(
                                "Could not work out requirename. Text: %r",
                                text[pos:])
                elif keyword == "define":
                    # Defining a constant
                    #   define("FOO",     "something");
                    #   define('TEST_CONSTANT', FALSE);
                    name, citdl = self._getConstantNameAndType(
                        styles, text, pos)
                    if name:
                        self.addDefine(name, citdl)

                elif keyword == "const":
                    # Defining a class constant
                    #   const myconstant = x;
                    self._variableHandler(styles, text, pos, attributes,
                                          doc=self.comment, style="const")

                elif keyword == "function":
                    namelist, p = self._getIdentifiersFromPos(
                        styles, text, pos)
                    log.debug("namelist:%r, p:%d", namelist, p)
                    if namelist:
                        returnByRef = (text[pos] == "&")
                        phpArgs, p = self._getArgumentsFromPos(styles, text, p)
                        log.debug("Line %d, function: %r(%r)",
                                  self.lineno, namelist, phpArgs)
                        if len(namelist) != 1:
                            log.info("warn: invalid function name (ignoring): "
                                     "%r, line: %d in file: %r", namelist,
                                     self.lineno, self.filename)
                            return
                        self.addFunction(namelist[0], phpArgs, attributes,
                                         doc=self.comment,
                                         returnByRef=returnByRef)
                elif keyword == "class" or keyword == "trait":
                    # Examples:
                    #   class SimpleClass {
                    #   class SimpleClass2 extends SimpleClass {
                    #   class MyClass extends AbstractClass implements TestInterface, TestMethodsInterface {
                    #
                    namelist, p = self._getIdentifiersFromPos(
                        styles, text, pos)
                    if namelist and "{" in text:
                        if len(namelist) != 1:
                            log.info("warn: invalid class name (ignoring): %r, "
                                     "line: %d in file: %r", namelist,
                                     self.lineno, self.filename)
                            return
                        extends = self._getExtendsArgument(styles, text, p)
                        implements = self._getImplementsArgument(
                            styles, text, p)
                        # print "extends: %r" % (extends)
                        # print "implements: %r" % (implements)
                        self.addClass(namelist[0], extends=extends,
                                      attributes=attributes,
                                      interfaces=implements, doc=self.comment,
                                      isTrait=(keyword == "trait"))
                elif keyword == "interface":
                    # Examples:
                    #   interface Foo {
                    #   interface SQL_Result extends SeekableIterator, Countable {
                    #
                    namelist, p = self._getIdentifiersFromPos(
                        styles, text, pos)
                    if namelist and "{" in text:
                        if len(namelist) != 1:
                            log.info("warn: invalid interface name (ignoring): "
                                     "%r, line: %d in file: %r", namelist,
                                     self.lineno, self.filename)
                            return
                        extends = self._getExtendsArgument(styles, text, p)
                        self.addInterface(namelist[
                                          0], extends, doc=self.comment)
                elif keyword in ("return", "yield"):
                    # Returning value for a function call
                    #   return 123;
                    #   return $x;
                    typeNames, p = self._getVariableType(
                        styles, text, pos, assignmentChar=None)
                    log.debug("typeNames:%r", typeNames)
                    if typeNames:
                        self.addReturnType(".".join(typeNames))
                elif keyword == "catch" and pos+3 >= len(text):
                    # catch ( Exception $e)
                    pos += 1   # skip the paren
                    typeNames, p = self._getVariableType(
                        styles, text, pos, assignmentChar=None)
                    namelist, p = self._getIdentifiersFromPos(
                        styles, text, p, self.PHP_VARIABLE)
                    if namelist and typeNames:
                        self.addVariable(namelist[0], ".".join(typeNames))
                elif keyword == "namespace":
                    namelist, p = self._getIdentifiersFromPos(
                        styles, text, pos)
                    log.debug("namelist:%r, p:%d", namelist, p)
                    if namelist:
                        usesBraces = "{" in text
                        self.setNamespace(namelist, usesBraces,
                                          doc=self.comment)
                elif keyword == "use":
                    self._useKeywordHandler(styles, text, pos)
                    if text and text[-1] == "{":
                        self.return_to_state = newstate
                        newstate = S_TRAIT_RESOLUTION
                else:
                    log.debug("Ignoring keyword: %s", keyword)
                    self._addAllVariables(styles, text, pos)

            elif firstStyle == self.PHP_IDENTIFIER:
                if text[0] == "self":
                    self._variableHandler(styles, text, pos, attributes,
                                          doc=self.comment)
                elif self.state == S_TRAIT_RESOLUTION:
                    self._handleTraitResolution(
                        styles, text, pos, doc=self.comment)
                    log.debug("Trait resolution: text: %r, pos: %d", text, pos)
                    # Stay in this state.
                    newstate = S_TRAIT_RESOLUTION
                else:
                    log.debug("Ignoring when starting with identifier")
            elif firstStyle == self.PHP_VARIABLE:
                # Defining scope for action
                self._variableHandler(styles, text, pos, attributes,
                                      doc=self.comment)
            else:
                log.debug("Unhandled first style:%d", firstStyle)
        finally:
            self._resetState(newstate)

    def _resetState(self, newstate=S_DEFAULT):
        self.state = newstate
        self.styles = []
        self.linenos = []
        self.text = []
        self.comment = None
        self.comments = []

    def token_next(self, style, text, start_column, start_line, **other_args):
        """Loops over the styles in the document and stores important info.

        When enough info is gathered, will perform a call to analyze the code
        and generate subsequent language structures. These language structures
        will later be used to generate XML output for the document."""
        # log.debug("text: %r", text)
        # print "text: %r, style: %r" % (text, style)

        if self.state == S_GET_HEREDOC_MARKER:
            if not text.strip():
                log.debug("Ignoring whitespace after <<<: %r", text)
                return
            self.heredocMarker = self._unquoteString(text)
            log.debug("getting heredoc marker: %r, now in heredoc state", text)
            self._resetState(S_IN_HEREDOC)

        elif self.state == S_IN_HEREDOC:
            # Heredocs *must* be on the start of a newline
            if text == self.heredocMarker and self.lastText and \
               self.lastText[-1] in "\r\n":
                log.debug("end of heredoc: %r", self.heredocMarker)
                self._resetState(self.return_to_state)
            else:
                log.debug("ignoring heredoc material")

        elif (style in (self.PHP_WORD, self.PHP_IDENTIFIER,
                        self.PHP_OPERATOR, self.PHP_NUMBER, self.PHP_VARIABLE) or
              style in (self.PHP_STRINGS)):
            # We keep track of these styles and the text associated with it.
            # When we gather enough info, these will be sent to the
            # _addCodePiece() function which will analyze the info.
            self.lineno = start_line + 1

            if style != self.PHP_OPERATOR:
                # Have to trim whitespace, as the identifier style is
                # also the default whitespace style... ugly!
                if style == self.PHP_IDENTIFIER:
                    text = text.strip()
                if text:
                    self.text.append(text)
                    self.styles.append(style)
                    self.linenos.append(self.lineno)
                    # print "Text:", text
            else:
                # Do heredoc parsing, since UDL cannot as yet
                if text == "<<<":
                    self.return_to_state = self.state
                    self.state = S_GET_HEREDOC_MARKER
                # Remove out any "<?php" and "?>" tags, see syntax description:
                #   http://www.php.net/manual/en/language.basic-syntax.php
                elif text.startswith("<?"):
                    if text[:5].lower() == "<?php":
                        text = text[5:]
                    elif text.startswith("<?="):
                        text = text[len("<?="):]
                    else:
                        text = text[len("<?"):]
                elif text.startswith("<%"):
                    if text.startswith("<%="):
                        text = text[len("<%="):]
                    else:
                        text = text[len("<%"):]
                if text.endswith("?>"):
                    text = text[:-len("?>")]
                elif text.endswith("<%"):
                    text = text[:-len("%>")]

                col = start_column + 1
                # for op in text:
                #    self.styles.append(style)
                #    self.text.append(op)
                # log.debug("token_next: line %d, %r" % (self.lineno, text))
                for op in text:
                    self.styles.append(style)
                    self.text.append(op)
                    self.linenos.append(self.lineno)
                    if op == "(":
                        # We can start defining arguments now
                        # log.debug("Entering S_IN_ARGS state")
                        self.return_to_state = self.state
                        self.state = S_IN_ARGS
                    elif op == ")":
                        # log.debug("Entering state %d", self.return_to_state)
                        self.state = self.return_to_state
                    elif op == "=":
                        if text == op:
                            # log.debug("Entering S_IN_ASSIGNMENT state")
                            self.state = S_IN_ASSIGNMENT
                    elif op == "{":
                        # Increasing depth/scope, could be an argument object
                        self._addCodePiece()
                        self.incBlock()
                    elif op == "}":
                        # Decreasing depth/scope
                        if len(self.text) == 1:
                            self._resetState()
                        else:
                            self._addCodePiece()
                        self.decBlock()
                    elif op == ":":
                        # May be an alternative syntax
                        if len(self.text) > 0 and \
                           self.styles[0] == self.PHP_WORD and \
                           self.text[0].lower() in ("if", "elseif", "else", "while", "for", "foreach", "switch"):
                            # print "Alt syntax? text: %r" % (self.text, )
                            self._addCodePiece()
                        elif "case" in self.text or "default" in self.text:
                            # Part of a switch statement - bug 86927.
                            self._addCodePiece()
                    elif op == ";":
                        # Statement is done
                        if len(self.text) > 0 and \
                           self.styles[0] == self.PHP_WORD and \
                           self.text[-1].lower() in ("endif", "endwhile", "endfor", "endforeach", "endswitch"):
                            # Alternative syntax, remove this from the text.
                            self.text = self.text[:-1]
                        self._addCodePiece()
                    col += 1
        elif style in self.PHP_COMMENT_STYLES:
            # Use rstrip to remove any trailing spaces or newline characters.
            comment = text.rstrip()
            # Check if it's a continuation from the last comment. If we have
            # already collected text then this is a comment in the middle of a
            # statement, so do not set self.comment, but rather just add it to
            # the list of known comment sections (self.comments).
            if not self.text:
                if style == SCE_UDL_SSL_COMMENT and self.comment and \
                   start_line <= (self.comments[-1][2] + 1) and \
                   style == self.comments[-1][1]:
                    self.comment += comment
                else:
                    self.comment = comment
            self.comments.append([comment, style, start_line, start_column])
        elif style == SCE_UDL_SSL_DEFAULT and \
                self.lastStyle in self.PHP_COMMENT_STYLES and text[0] in "\r\n":
            # This is necessary as line comments are supplied to us without
            # the newlines, so check to see if this is a newline and if the
            # last line was a comment, append it the newline to it.
            if self.comment:
                self.comment += "\n"
            self.comments[-1][0] += "\n"
        elif is_udl_csl_style(style):
            self.csl_tokens.append({"style": style,
                                    "text": text,
                                    "start_column": start_column,
                                    "start_line": start_line})
        self.lastText = text
        self.lastStyle = style

    def scan_multilang_content(self, content):
        """Scan the given PHP content, only processes SSL styles"""
        PHPLexer().tokenize_by_style(content, self.token_next)
        return self.csl_tokens

    def convertToElementTreeFile(self, cixelement):
        """Store PHP information into the cixelement as a file(s) sub element"""
        self.cile.convertToElementTreeFile(cixelement)

    def convertToElementTreeModule(self, cixblob):
        """Store PHP information into already created cixblob"""
        self.cile.convertToElementTreeModule(cixblob)


#---- internal utility functions

def _isident(char):
    return "a" <= char <= "z" or "A" <= char <= "Z" or char == "_"


def _isdigit(char):
    return "0" <= char <= "9"


#---- public module interface


#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=PHPLexer(),
                      buf_class=PHPBuffer,
                      langintel_class=PHPLangIntel,
                      import_handler_class=PHPImportHandler,
                      cile_driver_class=PHPCILEDriver,
                      is_cpln_lang=True,
                      import_everything=True)

########NEW FILE########
__FILENAME__ = lang_python
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Python support for CodeIntel"""

import os
from os.path import (isfile, isdir, exists, dirname, splitext,
                     join, basename, normcase)
import sys
import logging
import random
import parser
from glob import glob
import weakref
import re
import imp
from pprint import pprint, pformat
import itertools

import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants
from SilverCity.Keywords import python_keywords

from codeintel2.common import *
from codeintel2.citadel import (CitadelBuffer, CitadelEvaluator, ImportHandler,
                                CitadelLangIntel)
from codeintel2.indexer import PreloadLibRequest
from codeintel2 import pythoncile
from codeintel2.util import (banner, indent, markup_text, isident, isdigit,
                             makePerformantLogger)
from codeintel2 import tree
from codeintel2.tree_python import PythonTreeEvaluator, PythonImportLibGenerator
from codeintel2.langintel import (ParenStyleCalltipIntelMixin,
                                  ProgLangTriggerIntelMixin,
                                  PythonCITDLExtractorMixin)

from codeintel2.tree import tree_from_cix

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- globals
_SCAN_BINARY_FILES = False

lang = "Python"
log = logging.getLogger("codeintel.python")
# log.setLevel(logging.DEBUG)
makePerformantLogger(log)

CACHING = True  # DEPRECATED: kill it

# See http://effbot.org/zone/pythondoc.htm
_g_pythondoc_tags = list(sorted("param keyparam return exception def "
                                "defreturn see link linkplain".split()))

_g_python_magic_method_names = sorted([
    '__init__',
    '__new__',
    '__del__',
    '__repr__',
    '__str__',
    '__lt__',
    '__le__',
    '__eq__',
    '__ne__',
    '__gt__',
    '__ge__',
    '__cmp__',
    '__rcmp__',
    '__hash__',
    '__nonzero__',
    '__unicode__',
    # Attribute access
    '__getattr__',
    '__setattr__',
    '__delattr__',
    # New style classes
    '__getattribute__',
    '__call__',
    # Sequence classes
    '__len__',
    '__getitem__',
    '__setitem__',
    '__delitem__',
    '__iter__',
    '__reversed__',
    '__contains__',
    '__getslice__',
    '__setslice__',
    '__delslice__',
    # Integer like operators
    '__add__',
    '__sub__',
    '__mul__',
    '__floordiv__',
    '__mod__',
    '__divmod__',
    '__pow__',
    '__lshift__',
    '__rshift__',
    '__and__',
    '__xor__',
    '__or__',
    '__div__',
    '__truediv__',
    '__radd__',
    '__rsub__',
    '__rmul__',
    '__rdiv__',
    '__rtruediv__',
    '__rfloordiv__',
    '__rmod__',
    '__rdivmod__',
    '__rpow__',
    '__rlshift__',
    '__rrshift__',
    '__rand__',
    '__rxor__',
    '__ror__',
    '__iadd__',
    '__isub__',
    '__imul__',
    '__idiv__',
    '__itruediv__',
    '__ifloordiv__',
    '__imod__',
    '__ipow__',
    '__ilshift__',
    '__irshift__',
    '__iand__',
    '__ixor__',
    '__ior__',
    '__neg__',
    '__pos__',
    '__abs__',
    '__invert__',
    '__complex__',
    '__int__',
    '__long__',
    '__float__',
    '__oct__',
    '__hex__',
    '__index__',
    '__coerce__',
    # Context managers
    '__enter__',
    '__exit__',
])

#---- language support


class PythonLexer(Lexer):
    lang = lang

    def __init__(self):
        self._properties = SilverCity.PropertySet()
        self._lexer = SilverCity.find_lexer_module_by_id(
            ScintillaConstants.SCLEX_PYTHON)
        self._keyword_lists = [
            SilverCity.WordList(python_keywords),
            SilverCity.WordList(""),  # hilighted identifiers
        ]


class PythonImportsEvaluator(Evaluator):
    lang = lang

    def __str__(self):
        return "Python imports"

    def eval(self, mgr):
        try:
            imp_prefix = tuple(self.trg.extra["imp_prefix"])
            if imp_prefix:
                libs = self.buf.libs
                if not imp_prefix[0]:
                    if not imp_prefix[-1]:
                        # Deal with last item being empty, i.e. "from ."
                        imp_prefix = imp_prefix[:-1]
                    lookuppath = self.buf.path
                    while imp_prefix and not imp_prefix[0]:
                        lookuppath = dirname(lookuppath)
                        imp_prefix = imp_prefix[1:]
                    libs = [mgr.db.get_lang_lib(self.lang, "curdirlib",
                                                [lookuppath])]
                else:
                    # We use a special lib generator - that will lazily load
                    # additional directory libs when there are no matches found.
                    # This is a smart import facility - to detect imports from
                    # a parent directory when they are not explicitly on the
                    # included path list, quite common for Django and other
                    # Python frameworks that mangle the sys.path at runtime.
                    libs = PythonImportLibGenerator(mgr, self.lang,
                                                    self.buf.path, imp_prefix,
                                                    libs)
                self.ctlr.set_desc("subimports of '%s'" % '.'.join(imp_prefix))
                cplns = []
                for lib in libs:
                    imports = lib.get_blob_imports(imp_prefix)
                    if imports:
                        cplns.extend(
                            ((is_dir_import and "directory" or "module"), name)
                            for name, is_dir_import in imports
                        )

                    if self.trg.type == "module-members":
                        # Also add top-level members of the specified module.
                        dotted_prefix = '.'.join(imp_prefix)
                        if lib.has_blob(dotted_prefix):
                            blob = lib.get_blob(dotted_prefix)
                            for name in blob.names:
                                elem = blob.names[name]
                                cplns.append((elem.get(
                                    "ilk") or elem.tag, name))

                            # TODO: Consider using the value of __all__
                            #      if defined.
                            for e in blob:
                                attrs = e.get("attributes", "").split()
                                if "__hidden__" not in attrs:
                                    try:
                                        cplns += self._members_from_elem(
                                            e, mgr)
                                    except CodeIntelError, ex:
                                        log.warn(
                                            "%s (skipping members for %s)",
                                            ex, e)
                    if cplns:
                        break
                if cplns:
                    cplns = list(set(cplns))  # remove duplicates
            else:
                self.ctlr.set_desc("available imports")
                all_imports = set()
                for lib in self.buf.libs:
                    all_imports.update(lib.get_blob_imports(imp_prefix))
                cplns = [((is_dir_import and "directory" or "module"), name)
                         for name, is_dir_import in all_imports]
            if cplns:
                cplns.sort(key=lambda i: i[1].upper())
                self.ctlr.set_cplns(cplns)
        finally:
            self.ctlr.done("success")

    # XXX: This function is shamelessly copy/pasted from
    #     tree_python.py:PythonTreeEvaluator because there was no clear
    # way to reuse this shared functionality. See another XXX below, though.
    def _members_from_elem(self, elem, mgr):
        """Return the appropriate set of autocomplete completions for
        the given element. Typically this is just one, but can be more for
        '*'-imports
        """
        members = set()
        if elem.tag == "import":
            alias = elem.get("alias")
            symbol_name = elem.get("symbol")
            module_name = elem.get("module")
            if symbol_name:
                import_handler = mgr.citadel.import_handler_from_lang(
                    self.trg.lang)
                try:
                    blob = import_handler.import_blob_name(
                        module_name, self.buf.libs, self.ctlr)
                except:
                    log.warn(
                        "limitation in handling imports in imported modules")
                    raise

                if symbol_name == "*":  # can it be so?
                    for m_name, m_elem in blob.names.items():
                        m_type = m_elem.get("ilk") or m_elem.tag
                        members.add((m_type, m_name))
                elif symbol_name in blob.names:
                    symbol = blob.names[symbol_name]
                    member_type = (symbol.get("ilk") or symbol.tag)
                    members.add((member_type, alias or symbol_name))
                else:
                    # To correctly determine the type, we'd need to
                    # examine all the imports of this blob, and then see
                    # if any of those imports match the name... which is
                    # better left to the tree evaluator (tree_python).
                    #
                    # For now, we just add it as an unknown type.
                    members.add(('unknown', alias or symbol_name))
                    log.info(
                        "could not resolve symbol %r on %r, added as 'unknown'",
                        symbol_name, module_name)
            else:
                cpln_name = alias or module_name.split('.', 1)[0]
                members.add(("module", cpln_name))
        else:
            members.add((elem.get("ilk") or elem.tag, elem.get("name")))
        return members


class PythonLangIntel(CitadelLangIntel, ParenStyleCalltipIntelMixin,
                      ProgLangTriggerIntelMixin,
                      PythonCITDLExtractorMixin):
    lang = lang
    interpreterPrefName = "python"
    extraPathsPrefName = "pythonExtraPaths"

    # Used by ProgLangTriggerIntelMixin.preceding_trg_from_pos().
    trg_chars = tuple(" (.")

    citdl_from_literal_type = {"string": "str"}

    @LazyClassAttribute
    def keywords(self):
        from SilverCity.Keywords import python_keywords
        return python_keywords.split(" ")

    def async_eval_at_trg(self, buf, trg, ctlr):
        if _xpcom_:
            trg = UnwrapObject(trg)
            ctlr = UnwrapObject(ctlr)
        ctlr.start(buf, trg)
        if trg.type in ("object-members", "call-signature",
                        "literal-members") or \
           trg.form == TRG_FORM_DEFN:
            line = buf.accessor.line_from_pos(trg.pos)
            if trg.type == "literal-members":
                # We could leave this to citdl_expr_from_trg, but this is a
                # little bit faster, since we already know the citdl expr.
                citdl_expr = trg.extra.get("citdl_expr")
            else:
                try:
                    citdl_expr = self.citdl_expr_from_trg(buf, trg)
                except CodeIntelError, ex:
                    ctlr.error(str(ex))
                    ctlr.done("error")
                    return
            evalr = PythonTreeEvaluator(ctlr, buf, trg, citdl_expr, line)
            buf.mgr.request_eval(evalr)
        elif trg.id == (self.lang, TRG_FORM_CPLN, "local-symbols"):
            line = buf.accessor.line_from_pos(trg.pos)
            citdl_expr = trg.extra.get("citdl_expr")
            evalr = PythonTreeEvaluator(ctlr, buf, trg, citdl_expr, line)
            buf.mgr.request_eval(evalr)
        elif trg.id == (self.lang, TRG_FORM_CPLN, "magic-symbols"):
            symbolstype = trg.extra.get("symbolstype")
            cplns = []
            if symbolstype == "string":
                cplns = [("variable", "__main__")]
            elif symbolstype == "def":
                posttext = trg.extra.get("posttext", "")
                posttext = posttext.split("\n", 1)[0]
                if posttext and "(" in posttext:
                    cplns = [(
                        "function", t) for t in _g_python_magic_method_names]
                else:
                    cplns = [(
                        "function", t + "(self") for t in _g_python_magic_method_names]
            elif symbolstype == "global":
                text = trg.extra.get("text")
                if text.endswith("if"):
                    # Add the extended name version.
                    cplns = [("variable", t) for t in (
                        "__file__", "__loader__", "__name__ == '__main__':", "__package__")]
                else:
                    cplns = [("variable", t) for t in (
                        "__file__", "__loader__", "__name__", "__package__")]
            ctlr.set_cplns(cplns)
            ctlr.done("success")
        elif trg.id == (self.lang, TRG_FORM_CPLN, "pythondoc-tags"):
            # TODO: Would like a "tag" completion image name.
            cplns = [("variable", t) for t in _g_pythondoc_tags]
            ctlr.set_cplns(cplns)
            ctlr.done("success")
        elif trg.type == "available-exceptions":
            evalr = PythonTreeEvaluator(ctlr, buf, trg, None, -1)
            buf.mgr.request_eval(evalr)
        elif trg.type in ("available-imports", "module-members"):
            evalr = PythonImportsEvaluator(ctlr, buf, trg)
            buf.mgr.request_eval(evalr)
        else:
            raise NotImplementedError("not yet implemented: completion for "
                                      "Python '%s' trigger" % trg.name)

    # Note: Python 1.5.2 does not support sys.version_info.
    info_cmd = (
        r"import sys;"
        r"sys.stdout.write('.'.join(map(str, sys.version_info))+'\n');"
        r"sys.stdout.write(sys.prefix+'\n');"
        r"sys.stdout.write('\n'.join(sys.path));")

    def _python_info_from_python(self, python, env):
        """Call the given Python and return:
            (<version>, <sys.prefix>, <lib-dir>, <site-lib-dir>, <sys.path>)

        TODO: Unicode path issues?
        """
        import process
        argv = [python, "-c", self.info_cmd]
        log.debug("run `%s -c ...'", python)
        p = process.ProcessOpen(argv, env=env.get_all_envvars(), stdin=None)
        stdout, stderr = p.communicate()
        stdout_lines = stdout.splitlines(0)
        retval = p.returncode
        if retval:
            log.warn("failed to determine Python info:\n"
                     "  path: %s\n"
                     "  retval: %s\n"
                     "  stdout:\n%s\n"
                     "  stderr:\n%s\n",
                     python, retval, indent('\n'.join(stdout_lines)),
                     indent(stderr))

        # We are only to rely on the first 2 digits being in the form x.y.
        ver_match = re.search("([0-9]+.[0-9]+)", stdout_lines[0])
        if ver_match:
            ver = ver_match.group(1)
        else:
            ver = None
        prefix = stdout_lines[1]
        if sys.platform == "win32":
            libdir = join(prefix, "Lib")
        else:
            libdir = join(prefix, "lib", "python"+ver)
        sitelibdir = join(libdir, "site-packages")
        sys_path = stdout_lines[2:]
        return ver, prefix, libdir, sitelibdir, sys_path

    def _gen_python_import_paths_from_dirs(self, dirs):
        """Generate all Python import paths from a given list of dirs.

        This involves handling .pth files on the given dirs. It generates
        import "paths" rather than "dirs" because Python .egg files can be
        returned.

        Dev Notes:
        - Python's .pth files can have *executable* Python code. This
          currently is not handled (those kinds of lines are skipped).
        """
        for dir in dirs:
            if not exists(dir):
                continue
            yield dir
            try:
                for pth_path in glob(join(dir, "*.pth")):
                    for p in self._gen_python_import_paths_from_pth_path(pth_path):
                        yield p
            except EnvironmentError, ex:
                log.warn("error analyzing .pth files in '%s': %s", dir, ex)

    def _gen_python_import_paths_from_pth_path(self, pth_path):
        pth_dir = dirname(pth_path)
        for line in open(pth_path, 'r'):
            line = line.strip()
            if line.startswith("#"):  # comment line
                continue
            path = join(pth_dir, line)
            if exists(path):
                yield path

    def _extra_dirs_from_env(self, env):
        extra_dirs = set()
        for pref in env.get_all_prefs(self.extraPathsPrefName):
            if not pref:
                continue
            extra_dirs.update(d.strip() for d in pref.split(os.pathsep)
                              if exists(d.strip()))
        if extra_dirs:
            extra_dirs = set(
                self._gen_python_import_paths_from_dirs(extra_dirs)
            )
            log.debug("Python extra lib dirs: %r", extra_dirs)
        return tuple(extra_dirs)

    def interpreter_from_env(self, env):
        """Returns:
            - absolute path to either the preferred or
              default system interpreter
            - None if none of the above exists
        """
        # Gather information about the current python.
        python = None
        if env.has_pref(self.interpreterPrefName):
            python = env.get_pref(self.interpreterPrefName).strip() or None

        if not python or not exists(python):
            import which
            syspath = env.get_envvar("PATH", "")
            path = [d.strip() for d in syspath.split(os.pathsep)
                    if d.strip()]
            try:
                python = which.which("python", path=path)
            except which.WhichError:
                pass  # intentionally supressed

        if python:
            python = os.path.abspath(python)

        return python

    def python_info_from_env(self, env):
        cache_key = self.lang + "-info"
        info = env.cache.get(cache_key)
        if info is None:
            python = self.interpreter_from_env(env)
            if not python:
                log.warn("no Python was found from which to determine the "
                         "codeintel information")
                info = None, None, None, None, []
            else:
                info = self._python_info_from_python(python, env)
            env.cache[cache_key] = info
        return info

    def _buf_indep_libs_from_env(self, env):
        """Create the buffer-independent list of libs."""
        cache_key = self.lang + "-libs"
        libs = env.cache.get(cache_key)
        if libs is None:
            env.add_pref_observer(
                self.interpreterPrefName, self._invalidate_cache)
            env.add_pref_observer(self.extraPathsPrefName,
                                  self._invalidate_cache_and_rescan_extra_dirs)
            env.add_pref_observer("codeintel_selected_catalogs",
                                  self._invalidate_cache)
            db = self.mgr.db

            ver, prefix, libdir, sitelibdir, sys_path \
                = self.python_info_from_env(env)
            libs = []

            # - extradirslib
            extra_dirs = self._extra_dirs_from_env(env)
            if extra_dirs:
                libs.append(db.get_lang_lib(self.lang, "extradirslib",
                                            extra_dirs))

            # Figure out which sys.path dirs belong to which lib.
            paths_from_libname = {"sitelib": [], "envlib": [], "stdlib": []}
            canon_sitelibdir = sitelibdir and normcase(sitelibdir) or None
            canon_prefix = prefix and normcase(prefix) or None
            canon_libdir = libdir and normcase(libdir) or None
            canon_libdir_plat_prefix = libdir and normcase(
                join(libdir, "plat-")) or None
            canon_libdir_lib_prefix = libdir and normcase(
                join(libdir, "lib-")) or None
            for dir in sys_path:
                STATE = "envlib"
                canon_dir = normcase(dir)
                if dir == "":  # -> curdirlib (already handled)
                    continue
                elif canon_dir.endswith(".zip") and isfile(dir):
                    log.warn("`%s': not handling .zip file on Python sys.path",
                             dir)
                    continue
                elif canon_dir.endswith(".egg") and isfile(dir):
                    # log.warn("`%s': not handling .egg file on Python sys.path",
                    #         dir)
                    continue
                elif canon_dir.startswith(canon_sitelibdir):
                    STATE = "sitelib"
                # Check against the known list of standard library locations.
                elif canon_dir == canon_libdir or \
                    canon_dir.startswith(canon_libdir_plat_prefix) or \
                        canon_dir.startswith(canon_libdir_lib_prefix):
                    STATE = "stdlib"
                if not exists(dir):
                    continue
                paths_from_libname[STATE].append(dir)
            log.debug("Python %s paths for each lib:\n%s",
                      ver, indent(pformat(paths_from_libname)))

            # - envlib, sitelib, cataloglib, stdlib
            if paths_from_libname["envlib"]:
                libs.append(db.get_lang_lib(self.lang, "envlib",
                                            paths_from_libname["envlib"]))
            if paths_from_libname["sitelib"]:
                libs.append(db.get_lang_lib(self.lang, "sitelib",
                                            paths_from_libname["sitelib"]))
            catalog_selections = env.get_pref("codeintel_selected_catalogs")
            libs += [
                db.get_catalog_lib(self.lang, catalog_selections),
                db.get_stdlib(self.lang, ver)
            ]
            env.cache[cache_key] = libs

        return libs

    def libs_from_buf(self, buf):
        env = buf.env

        # A buffer's libs depend on its env and the buf itself so
        # we cache it on the env and key off the buffer.
        cache_key = self.lang + "-buf-libs"
        cache = env.cache.get(cache_key)  # <buf-weak-ref> -> <libs>
        if cache is None:
            cache = weakref.WeakKeyDictionary()
            env.cache[cache_key] = cache

        if buf not in cache:
            # - curdirlib
            # Using the dirname of this buffer isn't always right, but
            # hopefully is a good first approximation.
            libs = []
            if buf.path:
                cwd = dirname(buf.path)
                if cwd != "<Unsaved>":
                    libs = [self.mgr.db.get_lang_lib(
                        self.lang, "curdirlib", [cwd])]

            libs += self._buf_indep_libs_from_env(env)
            cache[buf] = libs
        return cache[buf]

    def _invalidate_cache(self, env, pref_name):
        for key in (self.lang + "-buf-libs", self.lang + "-libs"):
            if key in env.cache:
                log.debug("invalidate '%s' cache on %r", key, env)
                del env.cache[key]

    def _invalidate_cache_and_rescan_extra_dirs(self, env, pref_name):
        self._invalidate_cache(env, pref_name)
        extra_dirs = self._extra_dirs_from_env(env)
        if extra_dirs:
            extradirslib = self.mgr.db.get_lang_lib(
                self.lang, "extradirslib", extra_dirs)
            request = PreloadLibRequest(extradirslib)
            self.mgr.idxr.stage_request(request, 1.0)


# class PythonCitadelEvaluator(CitadelEvaluator):
#    def post_process_cplns(self, cplns):
#        """Drop special __FOO__ methods.
#
#        Note: Eventually for some Python completions we might want to leave
#        these in. For example:
#
#            class Bar(Foo):
#                def __init__(self):
#                    Foo.<|>    # completions should include "__init__" here
#        """
#        for i in range(len(cplns)-1, -1, -1):
#            value = cplns[i][1]
#            if value.startswith("__") and value.endswith("__"):
#                del cplns[i]
#        return CitadelEvaluator.post_process_cplns(self, cplns)


# "from", "from .", "from .."
_dotted_from_rx = re.compile(r'from($|\s+\.+)')


class PythonBuffer(CitadelBuffer):
    lang = lang
    # Fillup chars for Python: basically, any non-identifier char.
    # - remove '*' from fillup chars because: "from foo import <|>*"
    cpln_fillup_chars = "~`!@#$%^&()-=+{}[]|\\;:'\",.<>?/ "
    cpln_stop_chars = "~`!@#$%^&*()-=+{}[]|\\;:'\",.<>?/ "
    sce_prefixes = ["SCE_P_"]

    cb_show_if_empty = True

    keyword_style = ScintillaConstants.SCE_P_WORD
    identifier_style = ScintillaConstants.SCE_P_IDENTIFIER

    @property
    def libs(self):
        return self.langintel.libs_from_buf(self)

    def trg_from_pos(self, pos, implicit=True):
        """Python trigger types:

        python-complete-object-members
        python-calltip-call-signature
        python-complete-pythondoc-tags
        complete-available-imports
        complete-module-members

        Not yet implemented:
            complete-available-classes
            calltip-base-signature
        """
        DEBUG = False  # not using 'logging' system, because want to be fast
        if DEBUG:
            print "\n----- Python trg_from_pos(pos=%r, implicit=%r) -----"\
                  % (pos, implicit)

        if pos == 0:
            return None
        accessor = self.accessor
        last_pos = pos - 1
        last_char = accessor.char_at_pos(last_pos)
        if DEBUG:
            print "  last_pos: %s" % last_pos
            print "  last_char: %r" % last_char

        # Quick out if the preceding char isn't a trigger char.
        # Note: Cannot use this now that we have a 2-char locals trigger.
        # if last_char not in " .(@_,":
        #    if DEBUG:
        #        print "trg_from_pos: no: %r is not in ' .(@'_" % last_char
        #    return None

        style = accessor.style_at_pos(last_pos)
        if DEBUG:
            style_names = self.style_names_from_style_num(style)
            print "  style: %s (%s)" % (style, ", ".join(style_names))

        if last_char == "@":
            # Possibly python-complete-pythondoc-tags (the only trigger
            # on '@').
            #
            # Notes:
            # - PythonDoc 2.1b6 started allowing pythondoc tags in doc
            #   strings which we are yet supporting here.
            # - Trigger in comments should only happen if the comment
            #   begins with the "##" pythondoc signifier. We don't
            #   bother checking that (PERF).
            if style in self.comment_styles():
                # Only trigger at start of comment line.
                WHITESPACE = tuple(" \t")
                SENTINEL = 20
                i = last_pos-1
                while i >= max(0, last_pos-SENTINEL):
                    ch = accessor.char_at_pos(i)
                    if ch == "#":
                        return Trigger(self.lang, TRG_FORM_CPLN,
                                       "pythondoc-tags", pos, implicit)
                    elif ch in WHITESPACE:
                        pass
                    else:
                        return None
                    i -= 1
            return None

        # Remaing triggers should never trigger in some styles.
        if (implicit and style in self.implicit_completion_skip_styles and last_char != '_'
                or style in self.completion_skip_styles):
            if DEBUG:
                print "trg_from_pos: no: completion is suppressed "\
                      "in style at %s: %s (%s)"\
                      % (last_pos, style, ", ".join(style_names))
            return None

        if last_char == " ":
            # used for:
            #    * complete-available-imports
            #    * complete-module-members
            #    * complete-available-exceptions

            # Triggering examples ('_' means a space here):
            #   import_                 from_
            # Non-triggering examples:
            #   from FOO import_        Ximport_
            # Not bothering to support:
            #;  if FOO:import_          FOO;import_

            # Typing a space is very common so lets have a quick out before
            # doing the more correct processing:
            if last_pos-1 < 0 or accessor.char_at_pos(last_pos-1) not in "etm,":
                return None

            working_text = accessor.text_range(max(0, last_pos-200),
                                               last_pos)
            line = self._last_logical_line(working_text).strip()
            if not line:
                return None
            ch = line[-1]
            line = line.replace('\t', ' ')

            # from <|>
            # import <|>
            if line == "from" or line == "import":
                return Trigger(self.lang, TRG_FORM_CPLN,
                               "available-imports", pos, implicit,
                               imp_prefix=())

            # is it "from FOO import <|>" ?
            if line.endswith(" import"):
                if line.startswith('from '):
                    imp_prefix = tuple(line[len('from '):-len(
                        ' import')].strip().split('.'))
                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "module-members", pos, implicit,
                                   imp_prefix=imp_prefix)

            if line == "except" or line == "raise" or line.endswith((" except", " raise")):
                return Trigger(self.lang, TRG_FORM_CPLN,
                               "available-exceptions", pos, implicit)

            if ch == ',':
                # is it "from FOO import BAR, <|>" ?
                if line.startswith('from ') and ' import ' in line:
                    imp_prefix = tuple(line[len('from '):line.index(
                        ' import')].strip().split('.'))
                    # Need better checks
                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "module-members", pos, implicit,
                                   imp_prefix=imp_prefix)

        elif last_char == '.':  # must be "complete-object-members" or None
            # If the first non-whitespace character preceding the '.' in the
            # same statement is an identifer character then trigger, if it
            # is a ')', then _maybe_ we should trigger (yes if this is
            # function call paren).
            #
            # Triggering examples:
            #   FOO.            FOO .                       FOO; BAR.
            #   FOO().          FOO.BAR.                    FOO(BAR, BAZ.
            #   FOO().BAR.      FOO("blah();", "blam").     FOO = {BAR.
            #   FOO(BAR.        FOO[BAR.
            #   ...more cases showing possible delineation of expression
            # Non-triggering examples:
            #   FOO..
            #   FOO[1].         too hard to determine sequence element types
            #   from FOO import (BAR.
            # Not sure if want to support:
            #   "foo".          do we want to support literals? what about
            #                   lists? tuples? dicts?
            working_text = accessor.text_range(max(0, last_pos-200),
                                               last_pos)
            line = self._last_logical_line(working_text).strip()
            if line:
                ch = line[-1]
                if (isident(ch) or isdigit(ch) or ch in '.)'):
                    line = line.replace('\t', ' ')
                    m = _dotted_from_rx.match(line)
                    if m:
                        dots = len(m.group(1).strip())
                        # magic value for imp_prefix, means "from .<|>"
                        imp_prefix = tuple('' for i in xrange(dots+2))
                        return Trigger(self.lang, TRG_FORM_CPLN,
                                       "available-imports", pos, implicit,
                                       imp_prefix=imp_prefix)
                    elif line.startswith('from '):
                        if ' import ' in line:
                            # we're in "from FOO import BAR." territory,
                            # which is not a trigger
                            return None
                        # from FOO.
                        imp_prefix = tuple(line[len(
                            'from '):].strip().split('.'))
                        return Trigger(self.lang, TRG_FORM_CPLN,
                                       "available-imports", pos, implicit,
                                       imp_prefix=imp_prefix)
                    elif line.startswith('import '):
                        # import FOO.
                        # figure out the dotted parts of "FOO" above
                        imp_prefix = tuple(line[len(
                            'import '):].strip().split('.'))
                        return Trigger(self.lang, TRG_FORM_CPLN,
                                       "available-imports", pos, implicit,
                                       imp_prefix=imp_prefix)
                    else:
                        return Trigger(self.lang, TRG_FORM_CPLN,
                                       "object-members", pos, implicit)
                elif ch in ("\"'"):
                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "literal-members", pos, implicit,
                                   citdl_expr="str")
            else:
                ch = None
            if DEBUG:
                print "trg_from_pos: no: non-ws char preceding '.' is not "\
                      "an identifier char or ')': %r" % ch
            return None

        elif last_char == "_":
            # used for:
            #    * complete-magic-symbols

            # Triggering examples:
            #   def __<|>init__
            #   if __<|>name__ == '__main__':
            #   __<|>file__

            # Ensure double "__".
            if last_pos-1 < 0 or accessor.char_at_pos(last_pos-1) != "_":
                return None

            beforeChar = None
            beforeStyle = None
            if last_pos-2 >= 0:
                beforeChar = accessor.char_at_pos(last_pos-2)
                beforeStyle = accessor.style_at_pos(last_pos-2)

            if DEBUG:
                print "trg_from_pos:: checking magic symbol, beforeChar: %r" % (beforeChar)
            if beforeChar and beforeChar in "\"'" and beforeStyle in self.string_styles():
                if DEBUG:
                    print "trg_from_pos:: magic-symbols - string"
                return Trigger(self.lang, TRG_FORM_CPLN,
                               "magic-symbols", last_pos-1, implicit,
                               symbolstype="string")

            elif beforeChar == "." and beforeStyle != style:
                # Turned this off, as it interferes with regular "xxx." object
                # completions.
                return None

            if beforeStyle == style:
                # No change in styles between the characters -- abort.
                return None

            text = accessor.text_range(max(0, last_pos-20), last_pos-1).strip()
            if beforeChar and beforeChar in " \t":
                if text.endswith("def"):
                    posttext = accessor.text_range(pos,
                                                   min(accessor.length, pos+20)
                                                   ).replace(" ", "")
                    if DEBUG:
                        print "trg_from_pos:: magic-symbols - def"
                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "magic-symbols", last_pos-1, implicit,
                                   symbolstype="def",
                                   posttext=posttext)
            if DEBUG:
                print "trg_from_pos:: magic-symbols - global"
            return Trigger(self.lang, TRG_FORM_CPLN,
                           "magic-symbols", last_pos-1, implicit,
                           symbolstype="global", text=text)

        elif last_char == '(':
            # If the first non-whitespace character preceding the '(' in the
            # same statement is an identifer character then trigger calltip,
            #
            # Triggering examples:
            #   FOO.            FOO (                       FOO; BAR(
            #   FOO.BAR(        FOO(BAR, BAZ(               FOO = {BAR(
            #   FOO(BAR(        FOO[BAR(
            # Non-triggering examples:
            #   FOO()(      a function call returning a callable that is
            #               immediately called again is too rare to bother
            #               with
            #   def foo(    might be a "calltip-base-signature", but this
            #               trigger is not yet implemented
            #   import (    will be handled by complete_members
            #   class Foo(  is an "complete-available-classes" trigger,
            #               but this is not yet implemented
            working_text = accessor.text_range(max(0, last_pos-200), last_pos)
            line = self._last_logical_line(working_text).rstrip()
            if line:
                ch = line[-1]
                if isident(ch) or isdigit(ch):
                    # If this is:
                    #   def foo(
                    # then this might be the (as yet unimplemented)
                    # "calltip-base-signature" trigger or it should not be a
                    # trigger point.
                    #
                    # If this is:
                    #   class Foo(
                    # then this should be the (as yet unimplemented)
                    # "complete-available-classes" trigger.
                    line = line.replace('\t', ' ')
                    lstripped = line.lstrip()
                    if lstripped.startswith("def"):
                        if DEBUG:
                            print "trg_from_pos: no: point is function declaration"
                    elif lstripped.startswith("class") and '(' not in lstripped:
                        # Second test is necessary to not exclude:
                        #   class Foo(bar(<|>
                        if DEBUG:
                            print "trg_from_pos: no: point is class declaration"
                    elif lstripped.startswith('from ') and ' import' in lstripped:
                        # Need better checks
                        # is it "from FOO import (<|>" ?
                        imp_prefix = tuple(lstripped[len(
                            'from '):lstripped.index(' import')].split('.'))
                        if DEBUG:
                            print "trg_from_pos: from FOO import ("
                        return Trigger(self.lang, TRG_FORM_CPLN,
                                       "module-members", pos, implicit,
                                       imp_prefix=imp_prefix)
                    else:
                        return Trigger(self.lang, TRG_FORM_CALLTIP,
                                       "call-signature", pos, implicit)
                else:
                    if DEBUG:
                        print "trg_from_pos: no: non-ws char preceding "\
                              "'(' is not an identifier char: %r" % ch
            else:
                if DEBUG:
                    print "trg_from_pos: no: no chars preceding '('"
            return None
        elif last_char == ',':
            working_text = accessor.text_range(max(0, last_pos - 200), last_pos)
            line = self._last_logical_line(working_text)
            if line:
                last_bracket = line.rfind("(")
                if last_bracket >= 0:
                    pos = (pos - (len(line) - last_bracket))
                    return Trigger(self.lang, TRG_FORM_CALLTIP,
                                   "call-signature", pos, implicit)
                return None
            else:
                return None

        elif pos >= 2 and style in (self.identifier_style, self.keyword_style):
            # 2 character trigger for local symbols
            if DEBUG:
                if style == self.identifier_style:
                    print "Identifier style"
                else:
                    print "Identifier keyword style"
            # Previous char also need to be an identifier/word, then the one
            # before that needs to be something different (operator/space).
            if (accessor.style_at_pos(last_pos-1) != style or
                    (pos > 2 and accessor.style_at_pos(last_pos-2) == style)):
                if DEBUG:
                    print "Not a block of two ident/word chars"
                return None
            if pos > 2 and accessor.char_at_pos(last_pos-2) == ".":
                if DEBUG:
                    print "  preceeded by '.' operator - not a trigger"
                return None

            # Check if it makes sense to show the completions here. If defining
            # a class name, or function name, you don't want to see completions.
            # Also, do not override another completion type (e.g. imports).
            start = accessor.line_start_pos_from_pos(pos)
            preceeding_text = accessor.text_range(start, last_pos-2).strip()
            if preceeding_text:
                first_word = preceeding_text.split(" ")[0]
                if first_word in ("class", "def", "import", "from", "except"):
                    if DEBUG:
                        print "  no trigger, as starts with %r" % (first_word, )
                    # Don't trigger over the top of another trigger, i.e.
                    #   complete-available-imports
                    #   complete-module-members
                    #   complete-available-exceptions
                    return None

            citdl_expr = accessor.text_range(last_pos-1, last_pos+1)
            if DEBUG:
                print "  triggered 2 char symbol trigger: %r" % (citdl_expr, )
            return Trigger(self.lang, TRG_FORM_CPLN, "local-symbols",
                           last_pos-1, implicit,
                           citdl_expr=citdl_expr,
                           preceeding_text=preceeding_text)

    def _last_logical_line(self, text):
        lines = text.splitlines(0) or ['']
        logicalline = lines.pop()
        while lines and lines[-1].endswith('\\'):
            logicalline = lines.pop()[:-1] + ' ' + logicalline
        return logicalline


class PythonImportHandler(ImportHandler):
    lang = lang  # XXX do this for other langs as well
    PATH_ENV_VAR = "PYTHONPATH"
    sep = '.'

    def __init__(self, mgr):
        ImportHandler.__init__(self, mgr)
        self.__stdCIXScanId = None

    # TODO: may not be used. If so, drop it.
    def _shellOutForPath(self, compiler):
        import process
        argv = [compiler, "-c", "import sys; print('\\n'.join(sys.path))"]
        # Can't use -E to ignore PYTHONPATH because older versions of
        # Python don't have it (e.g. v1.5.2).
        env = dict(os.environ)
        if "PYTHONPATH" in env:
            del env["PYTHONPATH"]
        if "PYTHONHOME" in env:
            del env["PYTHONHOME"]
        if "PYTHONSTARTUP" in env:
            del env["PYTHONSTARTUP"]

        p = process.ProcessOpen(argv, env=env, stdin=None)
        stdout, stderr = p.communicate()
        retval = p.returncode
        path = [line for line in stdout.splitlines(0)]
        if path and (path[0] == "" or path[0] == os.getcwd()):
            del path[0]  # cwd handled separately
        return path

    def setCorePath(self, compiler=None, extra=None):
        if compiler is None:
            import which
            compiler = which.which("python")
        self.corePath = self._shellOutForPath(compiler)

    def _findScannableFiles(self,
                            (files, searchedDirs, skipRareImports,
                             importableOnly),
                            dirname, names):
        if sys.platform.startswith("win"):
            cpath = dirname.lower()
        else:
            cpath = dirname
        if cpath in searchedDirs:
            while names:
                del names[0]
            return
        else:
            searchedDirs[cpath] = 1
        if skipRareImports:
            if (basename(dirname) == "encodings"
                    and "undefined.py" in names):
                # Skip most of the specific encoding definitions (saves
                # about 50 files).
                names = [n for n in names if n == "__init__.py"
                         or os.path.splitext(n)[0].endswith("_codec")]
        for i in range(len(names)-1, -1, -1):  # backward so can del from list
            path = os.path.join(dirname, names[i])
            if os.path.isdir(path):
                if skipRareImports:
                    # Skip Python's test package (saves over 200 files)
                    # and other likely test dirs.
                    if names[i] in ("test", "tests"):
                        del names[i]
                        continue
                if importableOnly:
                    possibles = [os.path.join(path, "__init__.py"),
                                 os.path.join(path, "__init__.pyc"),
                                 os.path.join(path, "__init__.pyo")]
                    for possible in possibles:
                        if os.path.isfile(possible):
                            break
                    else:
                        del names[i]  # don't traverse non-package dirs
                        continue
                if path.endswith(os.path.join("win32com", "gen_py")):
                    del names[i]
                    continue
            elif os.path.splitext(names[i])[1] in self._gen_suffixes():
                # XXX The list of Python extensions should be settable on
                #    the ImportHandler and Komodo should set whatever is
                #    set in prefs.
                # XXX This check for "Python" files should probably include
                #    python scripts, which might likely not have the
                #    extension: need to grow filetype-from-content smarts.
                files.append(path)

    def _gen_suffixes(self):
        """Generate a sequence of scannable file suffixes in the
           preferred order of scanning.
        """
        yield ".py"
        yield ".pyw"

        if _SCAN_BINARY_FILES:
            yield ".pyc"
            yield ".pyo"
            for suffix, mode, mod_type in imp.get_suffixes():
                if suffix[0] == '.' and mod_type == imp.C_EXTENSION:
                    yield suffix

    def find_importables_in_dir(self, imp_dir):
        """See citadel.py::ImportHandler.find_importables_in_dir() for
        details.

        Importables for Python look like this:
            {"foo":    ("foo.py",             None,       False),
             "foolib": ("foolib/__init__.py", "__init__", False),
             "bar":    ("bar.pyc",            None,       False),
             "baz":    ("baz.pyo",            None,       False),
             "qoox":   ("qoox.pyd",           None,       False),
             "qooz":   ("qooz.so",            None,       False),

        Note: .pyd are .so handling depends on the platform.

        If several files happen to have the same name but different
        suffixes, the one with preferred suffix wins. The suffixe preference
        is defined by the order of elements in the sequence generated
        by _gen_suffixes().

        This particularly means that sources always win over binaries.
        """
        if imp_dir == "<Unsaved>":
            # TODO: stop these getting in here.
            return {}

        importables = {}

        if os.path.isdir(imp_dir):
            suffixes = dict((s, i) for i, s
                            in enumerate(self._gen_suffixes(), 1))
            modules = []
            for name in os.listdir(imp_dir):
                mod, suffix = os.path.splitext(name)
                if mod != '__init__':
                    init = os.path.join(name, '__init__.py')
                    if os.path.exists(os.path.join(imp_dir, init)):
                            modules.append((0, name, (
                                init, '__init__', False)))
                    else:
                        if suffix in suffixes:
                            modules.append((suffixes[suffix], mod,
                                            (name, None, False)))

            modules.sort(key=lambda mod: mod[0])

            for _, mod, importable in modules:
                if mod not in importables:
                    importables[mod] = importable

        return importables


class PythonCILEDriver(CILEDriver):
    lang = lang

    def scan_purelang(self, buf):
        log.info("scan_purelang: path: %r lang: %s", buf.path, buf.lang)
        # log.warn("TODO: python cile that uses elementtree")
        content = buf.accessor.text
        if isinstance(content, unicode):
            encoding = buf.encoding or "utf-8"
            try:
                content = content.encode(encoding)
            except UnicodeError, ex:
                raise CodeIntelError("cannot encode Python content as %r (%s)"
                                     % (encoding, ex))
        el = pythoncile.scan_et(content, buf.path, lang=self.lang)
        return el

    def scan_binary(self, buf):
        log.info("scan_binary: path: %r lang: %s", buf.path, buf.lang)
        from codeintel2 import pybinary
        python = buf.langintel.interpreter_from_env(buf.env)
        if not python:
            raise CodeIntelError("cannot find a usable Python interpreter")
        cix = pybinary.safe_scan(buf.path, python)
        return tree_from_cix(cix)


#---- internal support stuff


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=PythonLexer(),
                      buf_class=PythonBuffer,
                      langintel_class=PythonLangIntel,
                      import_handler_class=PythonImportHandler,
                      cile_driver_class=PythonCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_python3
#!/usr/bin/env python
# Copyright (c) 2010 ActiveState Software Inc.
# See LICENSE.txt for license details.

"""Python 3 support for CodeIntel"""

import logging

from codeintel2.common import LazyClassAttribute
from codeintel2.lang_python import (PythonLexer, PythonLangIntel,
                                    PythonImportsEvaluator, PythonBuffer,
                                    PythonImportHandler, PythonCILEDriver)


#---- globals

lang = "Python3"
log = logging.getLogger("codeintel.python3")
# log.setLevel(logging.DEBUG)


#---- language support

class Python3Lexer(PythonLexer):
    lang = lang


class Python3LangIntel(PythonLangIntel):
    lang = lang
    interpreterPrefName = "python3"
    extraPathsPrefName = "python3ExtraPaths"

    @LazyClassAttribute
    def keywords(self):
        from SilverCity.Keywords import python3_keywords
        return python3_keywords.split(" ")


class Python3Buffer(PythonBuffer):
    lang = lang


class Python3ImportHandler(PythonImportHandler):
    lang = lang


class Python3CILEDriver(PythonCILEDriver):
    lang = lang

#---- registration


def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=Python3Lexer(),
                      buf_class=Python3Buffer,
                      langintel_class=Python3LangIntel,
                      import_handler_class=Python3ImportHandler,
                      cile_driver_class=Python3CILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_rhtml
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""RHTML support for CodeIntel"""

import os
from os.path import (isfile, isdir, exists, dirname, abspath, splitext,
                     join, basename)
import sys
from cStringIO import StringIO
import logging
import re
import traceback
from pprint import pprint
from glob import glob

from codeintel2.common import *
from codeintel2.lang_ruby_common import RubyCommonBufferMixin
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin
from codeintel2.citadel import CitadelEvaluator


#---- globals
lang = "RHTML"
log = logging.getLogger("codeintel.rhtml")
# log.setLevel(logging.DEBUG)

#---- language support


class RHTMLLexer(UDLLexer):
    lang = lang


# Dev Notes:
# - DO_NOT_PUT_IN_FILLUPS = '!'
# - curr_calltip_arg_range (will need to pass in trigger when get to
#    this point)
class RHTMLBuffer(UDLBuffer, XMLParsingBufferMixin, RubyCommonBufferMixin):
    def __init__(self, mgr, accessor, env=None, path=None, *args, **kwargs):
        UDLBuffer.__init__(self, mgr, accessor, env, path, *args, **kwargs)
        self.check_for_rails_app_path(path)

    lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "Ruby"
    tpl_lang = "RHTML"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    # - wanted for CSS completion: " ('\";},.>"
    # - wanted for JS completion:  "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    # - dropping '-' because causes problem with CSS (bug 78312)
    # - dropping '!' because causes problem with CSS "!important" (bug 78312)
    # - TODO: adjust for Ruby, if necessary
    # - TODO: adjust for RHTML, if necessary
    cpln_stop_chars = "'\" (;},~`@#%^&*()=+{}]|\\;,.<>?/"


class RHTMLCILEDriver(UDLCILEDriver):
    lang = lang
    ssl_lang = "Ruby"
    csl_lang = "JavaScript"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=RHTMLLexer(),
                      buf_class=RHTMLBuffer,
                      cile_driver_class=RHTMLCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_ruby
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Ruby support for CodeIntel"""

import os
from os.path import basename, splitext, isdir, join, normcase, \
    normpath, exists, dirname
import time
import sys
import logging
import re
from pprint import pformat
from glob import glob
import weakref

from ciElementTree import Element, SubElement, tostring
import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants
from SilverCity.ScintillaConstants import (
    SCLEX_RUBY, SCE_RB_DEFAULT, SCE_RB_COMMENTLINE,
    SCE_RB_REGEX, SCE_RB_IDENTIFIER, SCE_RB_WORD, SCE_RB_OPERATOR,
    SCE_RB_CLASSNAME, SCE_RB_DEFNAME, SCE_RB_MODULE_NAME,
    SCE_UDL_M_OPERATOR, SCE_UDL_SSL_DEFAULT, SCE_UDL_SSL_IDENTIFIER,
    SCE_UDL_SSL_OPERATOR, SCE_UDL_SSL_VARIABLE, SCE_UDL_SSL_WORD,
    SCE_UDL_TPL_OPERATOR
)
from SilverCity.Keywords import ruby_keywords

from codeintel2.common import *
from codeintel2.citadel import (ImportHandler, CitadelBuffer, CitadelEvaluator,
                                CitadelLangIntel)
from codeintel2.citadel_common import ScanRequest
from codeintel2.indexer import PreloadLibRequest
from codeintel2.parseutil import urlencode_path
from codeintel2.udl import UDLBuffer
from codeintel2.accessor import AccessorCache
from codeintel2 import rubycile
from codeintel2.langintel import (ParenStyleCalltipIntelMixin,
                                  ProgLangTriggerIntelMixin)

from codeintel2.lang_ruby_common import RubyCommonBufferMixin
from codeintel2.util import (isident, isdigit, banner, indent, markup_text,
                             hotshotit, makePerformantLogger)
from codeintel2.tree import tree_2_0_from_tree_0_1
from codeintel2.tree_ruby import RubyTreeEvaluator

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- globals
lang = "Ruby"
log = logging.getLogger("codeintel.ruby")
# log.setLevel(logging.DEBUG)
makePerformantLogger(log)

CACHING = True  # XXX obsolete, kill it

_trg_type_to_trg_char = {'lib-paths': ['\'', True],
                         'lib-subpaths': ['/', True],
                         'object-methods': ['.', False],
                         'literal-methods': ['.', False],
                         'available-modules': [' ', False],
                         'available-modules-and-classes': ['<', False],
                         'module-names': [':', False],
                         'instance-vars': ['@', True],
                         'class-vars': ['@', True],
                         'global-vars': ['$', True],
                         }


#---- language support

class RubyLexer(Lexer):
    lang = "Ruby"

    def __init__(self):
        self._properties = SilverCity.PropertySet()
        self._lexer = SilverCity.find_lexer_module_by_id(SCLEX_RUBY)
        self._keyword_lists = [
            SilverCity.WordList(ruby_keywords)
        ]


# TODO: This isn't used. Drop it.
class RubyCitadelEvaluator(CitadelEvaluator):
    def __init__(self, ctlr, buf, trg, expr, line, converted_dot_new=None):
        CitadelEvaluator.__init__(self, ctlr, buf, trg, expr, line)
        self.converted_dot_new = converted_dot_new

    def post_process_calltips(self, calltips):
        if self.converted_dot_new:
            # "Foo.new(" is really using "Foo.initialize(". We swapped
            # that for calltip evaluation, now swap it back.
            for i, c in enumerate(calltips):
                if c.startswith("initialize"):
                    calltips[i] = "new" + c[len("initialize"):]
        return calltips

    def post_process_cplns(self, cplns):
        """Skip operator-typical methods like "+", "===", etc.

        XXX Should we skip methods beginning with "_" and or "__foo__"
            as well?
        """
        cplns = [c for c in cplns if isident(c[1][0])]
        cplns.sort(key=lambda c: c[1].upper())
        return cplns


class RubyImportsEvaluator(Evaluator):
    def __init__(self, ctlr, buf, trg, import_handler, prefix):
        Evaluator.__init__(self, ctlr, buf, trg)
        self.import_handler = import_handler
        self.prefix = prefix

    def __str__(self):
        return "Ruby subimports of '%s'" % self.prefix

    def eval(self, mgr):
        self.ctlr.set_desc("subimports of '%s'" % self.prefix)
        cwd = dirname(self.buf.path)  # XXX Should eventually use relevant env
        # TODO:XXX Update to use the newer `find_importables_in_dir`.
        #   `findSubImportsOnDisk` is deprecated.
        subimports = self.import_handler.findSubImportsOnDisk(
            self.prefix, cwd)
        if subimports:
            cplns = []
            for subimport in subimports:
                if subimport[-1] == '/':
                    cplns.append(("directory", subimport[:-1]))
                else:
                    cplns.append(("module", subimport))
            cplns.sort(key=lambda c: c[1].upper())
            self.ctlr.set_cplns(cplns)
        self.ctlr.done("success")


class RubyBuffer(CitadelBuffer, RubyCommonBufferMixin):
    lang = "Ruby"
    sce_prefixes = ["SCE_RB_"]

    cb_show_if_empty = True

    # Characters that should automatically invoke the current completion item:
    # XXX Figure out the appropriate set (get Eric to help).
    # - Cannot be '!' or '?' or '=' (I think) because those can be part of a
    #   method name.
    # - Cannot be "'" or '"' because that can get in the way. E.g.:
    #       require 'cgi<|>
    #   At this point the selected item can be "cgi-lib". Filling up
    #   with a quote would select "cgi-lib" instead of the possibly
    #   intended "cgi".
    # - Cannot be '.' because of '..' operator for ranges. E.g.:
    #       1..1000
    #   would result in (or whatever the first Fixnum method is):
    #       1.abs.1000
    cpln_fillup_chars = "~`@#$%^&*(+}[]|\\;:,<>/ "
    cpln_stop_chars = cpln_fillup_chars + "'\"."

    def __init__(self, mgr, accessor, env=None, path=None, *args, **kwargs):
        CitadelBuffer.__init__(self, mgr, accessor, env, path, *args, **kwargs)
        self.check_for_rails_app_path(path)

        # Skip styles are a bit different for Ruby:
        # - for *some* cases autocomplete *is* automatically triggered
        #   in a string
        # - you *can* trigger on a number
        self.implicit_completion_skip_styles = dict(
            (s, True) for s in self.comment_styles())
        self.completion_skip_styles = self.implicit_completion_skip_styles.copy(
        )
        self.completion_skip_styles[SCE_RB_REGEX] = True

    @property
    def libs(self):
        return self.langintel.libs_from_buf(self)


class _CommonStyleClassifier(object):
    def __init__(self, buf):
        self.buf = buf

    @property
    def ignore_styles(self):
        return self.ignoreStyles


class _RubyStyleClassifier(_CommonStyleClassifier):
    # This class delegates mostly to its Buffer object.
    # class-specific methods first...

    def is_ruby_style_at_pos(self, pos):
        # All chars are in Ruby code in pure Ruby buffers,
        # no need to get the style at position pos
        return True

    def is_identifier_or_word_style(self, style):
        return style == SCE_RB_IDENTIFIER or style == SCE_RB_WORD

    def is_identifier_style(self, style):
        return style == SCE_RB_IDENTIFIER

    def is_operator_style(self, style):
        return style == SCE_RB_OPERATOR

    def is_default_style(self, style):
        return style == SCE_RB_DEFAULT

    def is_identifier_or_definition_style(self, style):
        """ Check if a style is either a identifier reference or a definition
        of a thing that can be referenced by an identifier """
        return style in (SCE_RB_IDENTIFIER, SCE_RB_CLASSNAME,
                         SCE_RB_DEFNAME, SCE_RB_MODULE_NAME)

    def __getattr__(self, name):
        return getattr(self.buf, name)

    ignoreStyles = (SCE_RB_DEFAULT, SCE_RB_COMMENTLINE)


class _UDLStyleClassifier(_CommonStyleClassifier):
    def __init__(self, buf):
        _CommonStyleClassifier.__init__(self, buf)
        self._implicit_completion_skip_styles = None
        self._completion_skip_styles = None

    def is_ruby_style_at_pos(self, pos):
        style = self.buf.accessor.style_at_pos(pos)
        return SCE_UDL_SSL_DEFAULT <= style <= SCE_UDL_SSL_VARIABLE

    @property
    def implicit_completion_skip_styles(self):
        if self._implicit_completion_skip_styles is None:
            # XXX - do we have access to the language info?
            self._implicit_completion_skip_styles = {

                ScintillaConstants.SCE_UDL_SSL_COMMENT: True,
                ScintillaConstants.SCE_UDL_SSL_COMMENTBLOCK: True,
            }
        return self._implicit_completion_skip_styles

    @property
    def completion_skip_styles(self):
        if self._completion_skip_styles is None:
            self._completion_skip_styles = {

                ScintillaConstants.SCE_UDL_SSL_COMMENT: True,
                ScintillaConstants.SCE_UDL_SSL_COMMENTBLOCK: True,
                ScintillaConstants.SCE_UDL_SSL_REGEX: True,
            }
        return self._completion_skip_styles

    def is_identifier_or_word_style(self, style):
        return style == SCE_UDL_SSL_IDENTIFIER or style == SCE_UDL_SSL_WORD

    def is_identifier_style(self, style):
        return style == SCE_UDL_SSL_IDENTIFIER

    def is_identifier_or_definition_style(self, style):
        return style == SCE_UDL_SSL_IDENTIFIER

    def is_operator_style(self, style):
        return style == SCE_UDL_SSL_OPERATOR

    # These aren't properties in buffer.py, so they can't be here either.
    def comment_styles(self):
        return (ScintillaConstants.SCE_UDL_SSL_COMMENT,)

    def number_styles(self):
        return (ScintillaConstants.SCE_UDL_SSL_NUMBER,)

    def string_styles(self):
        return (ScintillaConstants.SCE_UDL_SSL_STRING, )

    def is_default_style(self, style):
        return style == SCE_UDL_SSL_DEFAULT

    ignoreStyles = (ScintillaConstants.SCE_UDL_SSL_DEFAULT,
                    ScintillaConstants.SCE_UDL_SSL_COMMENT)


class RubyLangIntel(CitadelLangIntel,
                    ParenStyleCalltipIntelMixin,
                    ProgLangTriggerIntelMixin):
    lang = "Ruby"

    calltip_region_terminators = tuple(']});\r\n')
    # newlines are for ending calltips triggered on a space

    def libs_from_buf(self, buf):
        env = buf.env

        # A buffer's libs depend on its env and the buf itself so
        # we cache it on the env and key off the buffer.
        if "ruby-buf-libs" not in env.cache:
            env.cache["ruby-buf-libs"] = weakref.WeakKeyDictionary()
        cache = env.cache["ruby-buf-libs"]  # <buf-weak-ref> -> <libs>

        if buf not in cache:
            libs = self._buf_indep_libs_from_env(env)[:]

            # - curdirlib (in Ruby '.' is *last* in the import path)
            cwd = dirname(buf.path)
            if cwd != "<Unsaved>":
                libs.append(self.mgr.db.get_lang_lib(
                    "Ruby", "curdirlib", [cwd]))

            cache[buf] = libs
        return cache[buf]

    def _ruby_from_env(self, env):
        import which
        path = [d.strip()
                for d in env.get_envvar("PATH", "").split(os.pathsep)
                if d.strip()]
        try:
            return which.which("ruby", path=path)
        except which.WhichError:
            return None

    _gem_ver_ptn = re.compile(r'(.+?)(-[\d+\.]+)$')

    def _ruby_info_from_ruby(self, ruby, env):
        """Call the given Ruby and return:
            (<version>, <lib-dir>, <site-lib-dir>, <import-dirs>, <gem-dirs>)

        TODO: Unicode path issues?
        """
        import process

        # Ruby 1.5.2 does not support sys.version_info.
        info_cmd = "puts RUBY_VERSION; puts $:"
        argv = [ruby, "-e", info_cmd]
        log.debug("run `%s -e ...'", ruby)
        p = process.ProcessOpen(argv, env=env.get_all_envvars(), stdin=None)
        stdout, stderr = p.communicate()
        stdout_lines = stdout.splitlines(0)
        retval = p.returncode
        if retval:
            log.warn("failed to determine Ruby info:\n"
                     "  path: %s\n"
                     "  retval: %s\n"
                     "  stdout:\n%s\n"
                     "  stderr:\n%s\n",
                     ruby, retval, indent('\n'.join(stdout_lines)),
                     indent(stderr))

        ruby_ver = stdout_lines[0]
        _ver_parts = ruby_ver.split('.', 2)
        short_ver = '.'.join(_ver_parts[:2])
        if len(_ver_parts) >= 3:
            sub_minor_ver = int(_ver_parts[2])
        else:
            sub_minor_ver = 0

        prefix = dirname(dirname(ruby))
        libdir = join(prefix, "lib", "ruby", short_ver)
        sitelibdir = join(prefix, "lib", "ruby", "site_ruby")
        # Need to normpath() these because they come out, e.g.:
        #   c:/ruby184/lib/ruby/site_ruby/1.8
        # on Windows.
        import_path = [normpath(p) for p in stdout_lines[1:]]

        def get_first_gem_dir_candidate():
            gems_dir_part1 = join(prefix, "lib", "ruby", "gems")
            gems_dir_version = join(gems_dir_part1, short_ver)
            if exists(gems_dir_version):
                return join(gems_dir_version, "gems")
            for i in range(sub_minor_ver + 1):
                cand_ver = "%s.%d" % (gems_dir_version, i)
                if exists(cand_ver):
                    return join(cand_ver, "gems")
            return None

        # Get the list of relevant Gem lib dirs.
        def gem_ver_from_ver_str(ver_str):
            parts = ver_str.split('.')
            try:
                parts = map(int, parts)
            except ValueError:
                return ver_str
            else:
                return tuple(parts)
        gems_dir = get_first_gem_dir_candidate()
        gem_ver_and_dir_from_name = {
            # "actionmailer": ((1,2,5), ".../actionmailer-1.2.5"),
        }
        if gems_dir:
            for dir in glob(join(gems_dir, "*-*")):
                if not isdir(dir):
                    continue
                m = self._gem_ver_ptn.match(basename(dir))
                if not m:
                    continue
                name, ver_str = m.groups()
                gem_ver = gem_ver_from_ver_str(ver_str)
                if name in gem_ver_and_dir_from_name:
                    if gem_ver > gem_ver_and_dir_from_name[name][0]:
                        gem_ver_and_dir_from_name[name] = (gem_ver, dir)
                else:
                    gem_ver_and_dir_from_name[name] = (gem_ver, dir)
        log.debug("ruby gem dir info: %s", pformat(gem_ver_and_dir_from_name))
        gem_lib_dirs = []
        for name, (gem_ver, dir) in sorted(gem_ver_and_dir_from_name.items()):
            gem_lib_dir = join(dir, "lib")
            if isdir(gem_lib_dir):
                gem_lib_dirs.append(gem_lib_dir)

        return ruby_ver, libdir, sitelibdir, import_path, gem_lib_dirs

    def _extra_dirs_from_env(self, env):
        extra_dirs = set()
        for pref in env.get_all_prefs("rubyExtraPaths"):
            if not pref:
                continue
            # TODO: need to support Gems specially?
            extra_dirs.update(d.strip() for d in pref.split(os.pathsep)
                              if exists(d.strip()))
        return tuple(extra_dirs)

    def _buf_indep_libs_from_env(self, env):
        """Create the buffer-independent list of libs."""
        cache_key = "ruby-libs"
        if cache_key not in env.cache:
            env.add_pref_observer("ruby", self._invalidate_cache)
            env.add_pref_observer("rubyExtraPaths",
                                  self._invalidate_cache_and_rescan_extra_dirs)
            env.add_pref_observer("codeintel_selected_catalogs",
                                  self._invalidate_cache)
            db = self.mgr.db

            # Gather information about the current ruby.
            ruby = None
            if env.has_pref("ruby"):
                ruby = env.get_pref("ruby").strip() or None
            if not ruby or not exists(ruby):
                ruby = self._ruby_from_env(env)
            if not ruby:
                log.warn("no Ruby was found from which to determine the "
                         "import path")
                ver, libdir, sitelibdir, import_path, gem_lib_dirs \
                    = None, None, None, [], []
            else:
                ver, libdir, sitelibdir, import_path, gem_lib_dirs \
                    = self._ruby_info_from_ruby(ruby, env)

            libs = []

            # - extradirslib
            extra_dirs = self._extra_dirs_from_env(env)
            if extra_dirs:
                log.debug("Ruby extra lib dirs: %r", extra_dirs)
                libs.append(db.get_lang_lib("Ruby", "extradirslib",
                                            extra_dirs))

            # Figure out which sys.path dirs belong to which lib.
            paths_from_libname = {"sitelib": [], "envlib": [], "stdlib": []}
            STATE = "envlib"
            canon_libdir = libdir and normcase(libdir) or None
            canon_sitelibdir = sitelibdir and normcase(sitelibdir) or None
            for dir in import_path:
                canon_dir = normcase(dir)
                if dir == ".":  # -> curdirlib (handled separately)
                    continue
                # TODO: need to support gems specially?
                elif dir.startswith(sitelibdir):
                    STATE = "sitelib"
                elif dir.startswith(libdir):
                    STATE = "stdlib"
                if not exists(dir):
                    continue
                paths_from_libname[STATE].append(dir)
            log.debug("Ruby %s paths for each lib:\n%s", ver, indent(
                pformat(paths_from_libname)))

            # - envlib, sitelib, gemlib, cataloglib, stdlib
            if paths_from_libname["envlib"]:
                libs.append(db.get_lang_lib("Ruby", "envlib",
                                            paths_from_libname["envlib"]))
            if paths_from_libname["sitelib"]:
                libs.append(db.get_lang_lib("Ruby", "sitelib",
                                            paths_from_libname["sitelib"]))
            if gem_lib_dirs:
                libs.append(db.get_lang_lib("Ruby", "gemlib", gem_lib_dirs))
            catalog_selections = env.get_pref("codeintel_selected_catalogs")
            libs += [
                db.get_catalog_lib("Ruby", catalog_selections),
                db.get_stdlib("Ruby", ver)
            ]
            env.cache[cache_key] = libs

        return env.cache[cache_key]

    def _invalidate_cache(self, env, pref_name):
        for key in ("ruby-buf-libs", "ruby-libs"):
            if key in env.cache:
                log.debug("invalidate '%s' cache on %r", key, env)
                del env.cache[key]

    def _invalidate_cache_and_rescan_extra_dirs(self, env, pref_name):
        self._invalidate_cache(env, pref_name)
        extra_dirs = self._extra_dirs_from_env(env)
        if extra_dirs:
            extradirslib = self.mgr.db.get_lang_lib(
                "Ruby", "extradirslib", extra_dirs)
            request = PreloadLibRequest(extradirslib)
            self.mgr.idxr.stage_request(request, 1.0)

    # All Ruby trigger points occur at one of these characters:
    #   '.' (period)        [eval implemented]
    #   ' ' (space)
    #   '(' (open paren)    [eval implemented]
    #   ':' (colon)         "::" actually [eval implemented]
    #   '@' (at-sign)       "@..." for instance var,
    #                       "@@..." for class vars
    #   '$' (dollar sign)
    #   "'" (single-quote)  [eval implemented]
    #   '"' (double-quote)  [eval implemented]
    #   '/' (slash)         [eval implemented]
    #
    #   At least three characters into an identifier (\w_)+
    #
    #   spaces -- for class inheritance, include, & call-tips
    #
    trg_chars = tuple('. (:@$"\'/')  # the full set
    calltip_trg_chars = tuple('( ')
    RUBY_KEYWORDS = dict((k, True) for k in ruby_keywords.split())

    def _get_prev_token_skip_ws(self, pos, accessor, styleClassifier):
        prev_start_pos, prev_end_pos = accessor.contiguous_style_range_from_pos(
            pos - 1)
        if prev_start_pos == 0 or not styleClassifier.is_ruby_style_at_pos(prev_start_pos):
            return prev_start_pos, prev_end_pos
        prev_style = accessor.style_at_pos(prev_start_pos)
        if styleClassifier.is_default_style(prev_style):
            prev_start_pos, prev_end_pos = accessor.contiguous_style_range_from_pos(
                prev_start_pos - 1)
        return prev_start_pos, prev_end_pos

    def _get_token_before_namelist(self, pos, accessor, styleClassifier, lim=-1):
        """ Walk backwards skipping (name, comma) pairs.
        If lim is given and is positive stop once we reach 0, to avoid spending
        too much time here
        """
        while True:
            prev_start_pos, prev_end_pos = self._get_prev_token_skip_ws(
                pos, accessor, styleClassifier)
            if prev_start_pos == 0 or not styleClassifier.is_ruby_style_at_pos(prev_start_pos):
                return 0, 0
            prev_style = accessor.style_at_pos(prev_start_pos)
            if not styleClassifier.is_identifier_or_word_style(prev_style):
                return 0, 0
            prev_start_pos, prev_end_pos = self._get_prev_token_skip_ws(
                prev_start_pos, accessor, styleClassifier)
            if prev_start_pos == 0 or not styleClassifier.is_ruby_style_at_pos(prev_start_pos):
                return 0, 0
            elif not styleClassifier.is_operator_style(prev_style):
                return 0, 0
            op = accessor.text_range(prev_start_pos, prev_end_pos)
            if op != ",":
                return prev_start_pos, prev_end_pos
            lim -= 1
            if lim == 0:
                return 0, 0

    def _is_completable_name(self, pos, accessor, styleClassifier):
        """
         Ensure we are not in another trigger zone, we do
         this by checking that the preceeding text is not
         one of "." or "::"
         Also ignore words in block var names:
         {do or "{"}, "|", {name, ","}*
        """
        if pos == 0:
            return True
        prev_start_pos, prev_end_pos = self._get_prev_token_skip_ws(
            pos, accessor, styleClassifier)
        if prev_start_pos == 0 or not styleClassifier.is_ruby_style_at_pos(prev_start_pos):
            return True
        prev_style = accessor.style_at_pos(prev_start_pos)
        if not styleClassifier.is_operator_style(prev_style):
            return True
        op = accessor.text_range(prev_start_pos, prev_end_pos)
        if op in (".", "::"):
            return False
        if op == ",":
            prev_start_pos, prev_end_pos = self._get_token_before_namelist(
                prev_start_pos,
                accessor, styleClassifier,
                lim=5)
            if prev_start_pos <= 0:
                return False
            prev_style = accessor.style_at_pos(prev_start_pos)
            if not styleClassifier.is_operator_style(prev_style):
                return True
            op = accessor.text_range(prev_start_pos, prev_end_pos)
        if op[-1] != "|":  # last character
            return True
        elif op == "{|":
            # Special case due to the way the accessor combines tokens of same
            # style
            return False
        # Now look back for either a brace or a 'do'
        prev_start_pos, prev_end_pos = self._get_prev_token_skip_ws(
            prev_start_pos, accessor, styleClassifier)
        if prev_start_pos == 0 or not styleClassifier.is_ruby_style_at_pos(prev_start_pos):
            return False
        op = accessor.text_range(prev_start_pos, prev_end_pos)
        return op not in ("{", "do")

    def trg_from_pos(self, buf, pos, implicit=True, DEBUG=False):
        """If the given position is a _likely_ trigger point, return the
        trigger type. Otherwise return None.
        """
        if pos <= 0:
            return None

        styleClassifier = (isinstance(buf, UDLBuffer) and _UDLStyleClassifier
                           or _RubyStyleClassifier)(buf)
        DEBUG = False  # not using 'logging' system, because want to be fast
        if DEBUG:
            print banner("Ruby trg_from_pos(pos=%r, implicit=%r)"
                         % (pos, implicit))

        accessor = buf.accessor
        last_pos = pos - 1
        last_ch = accessor.char_at_pos(last_pos)
        if DEBUG:
            print "  last_pos: %s" % last_pos
            print "  last_ch: %r" % last_ch

        # All Ruby trigger points occur at one of the trg_chars.
        # Also some require specific two (or more) character combos that
        # we can use to filter quickly.
        if last_ch not in self.trg_chars:
            # Can we do a complete-names?
            last_style = accessor.style_at_pos(last_pos)
            if last_ch.isalnum() or last_ch == '_':
                # Gather as long as they're identifier or word chars
                MIN_LENGTH = 3
                if styleClassifier.is_identifier_or_word_style(last_style):
                    start_pos, end_pos = accessor.contiguous_style_range_from_pos(
                        last_pos)
                    # XXX Is end_pos pointing one past the end?
                    if pos - start_pos == MIN_LENGTH or not implicit:
                        ident = accessor.text_range(start_pos, end_pos)
                        prefix = ident[:pos - start_pos]
                        if self._is_completable_name(start_pos, accessor, styleClassifier):
                            return Trigger("Ruby", TRG_FORM_CPLN,
                                           "names",
                                           start_pos, implicit, length=0, prefix=prefix)
            if DEBUG:
                print "no: %r is not in %r"\
                      % (last_ch, self.trg_chars)
            return None
        elif last_ch == ' ':
            if last_pos <= 0:
                return None
            penultimate_ch = accessor.char_at_pos(last_pos-1)
            prev_style = accessor.style_at_pos(last_pos - 1)
            # Complex conditions, so express them this way to simplify
            if styleClassifier.is_operator_style(prev_style) and penultimate_ch == "<":
                pass
            elif styleClassifier.is_identifier_or_word_style(prev_style):
                # XXX Reject keywords
                pass
            else:
                if DEBUG:
                    print "no: %r is not '< ' or ending a word"\
                          "(i.e. 'include ')" % (penultimate_ch+last_ch)
                return None
        elif last_ch == ':' \
            and not (last_pos > 0
                     and accessor.char_at_pos(last_pos-1) == ':'):
            if DEBUG:
                penultimate_ch = (last_pos > 0
                                  and accessor.char_at_pos(last_pos-1) or '')
                print "no: %r is not '::'"\
                      % (penultimate_ch+last_ch)
            return None

        # Suppress triggering in some styles.
        TRIGGER_IN_STRING_CHARS = tuple('\'"/')
        last_style = accessor.style_at_pos(last_pos)
        if DEBUG:
            style_names = buf.style_names_from_style_num(last_style)
            print "  style: %s %s" % (last_style, style_names)
        suppress = False
        if implicit:
            if last_style in styleClassifier.implicit_completion_skip_styles:
                suppress = True
            elif last_style in styleClassifier.string_styles():
                if last_ch not in TRIGGER_IN_STRING_CHARS:
                    # The ', ", and / trigger chars *always* trigger in
                    # a string.
                    suppress = True
            elif last_ch in TRIGGER_IN_STRING_CHARS:
                suppress = True
        elif last_style in styleClassifier.completion_skip_styles:
            # If the user requests code-completion and previous char is
            # in this style, suppress it.
            suppress = True

        if suppress:
            if DEBUG:
                print "no: completion is suppressed in style at %s: %s %s"\
                      % (last_pos, last_style, style_names)
            return None

        WHITESPACE = tuple(' \t\n\r')
        EOL = tuple('\n\r')
        if last_ch == ' ':
            # This may be one of the following:
            #   class FOO < |       complete-available-modules-and-classes
            #       not implemented yet, "<" not in trg-char tuple.
            #   include |           complete-available-modules
            #   method              calltip-call-signature
            # Simplifying assumptions:
            # With whitespace allow for a completion list after '<'
            # in {class Name <}, but allow for any calltip after an identifier.
            #   (above) that the preceding char (stored in
            #   'penultimate_ch') is '<' or a word or identifier.
            # - The construct doesn't have to be on one line.
            LIMIT = 50
            text = accessor.text_range(max(
                0, last_pos-LIMIT), last_pos)  # working text
            if DEBUG:
                print "  working text: %r" % text
            i = len(text)-1
            while i > 0:  # Skip back to start of line.
                if text[i] in EOL:
                    break
                i -= 1
            line = text[i:].lstrip()
            if DEBUG:
                print "  line: %r" % line
            if penultimate_ch == "<":
                if not line.startswith("class"):
                    if DEBUG:
                        print "no: line does not start with 'class'"
                    return None
                if DEBUG:
                    print "complete-available-modules-and-classes"
                return Trigger("Ruby", TRG_FORM_CPLN,
                               "available-modules-and-classes",
                               pos, implicit)
            elif line.strip() == "include":
                if DEBUG:
                    print "complete-available-modules"
                return Trigger("Ruby", TRG_FORM_CPLN, "available-modules",
                               pos, implicit)
            else:  # maybe a calltip on a paren-free call
                if DEBUG:
                    print "calltip-call-signature"
                return Trigger("Ruby", TRG_FORM_CALLTIP, "call-signature",
                               pos, implicit)

        elif last_ch == '.':
            # This can be:
            #   FOO.|               complete-object-methods
            #   LITERAL.|           complete-literal-methods
            #   but bug62397: not for a fixnum
            # Examples:
            #   Foo.
            #   foo.
            #   @foo.
            #   ::foo.
            #   (foo + 1).    <-- We don't bother with this one for now
            #                     because CITDL processing won't resolve
            #                     the expression anyway.
            #   foo2.
            # Allow literals too:
            #   0.      3.14.
            #   1e6.    [].
            #   {}.     'foo'.      "bar".
            # Weird literals (pickaxe p319):
            #   %W{...}   # also q, Q, r, w, x, <empty> instead of 'W'
            #   0d123456, 0xff, -0b10_1010  # specific base laterals
            #   ?\M-a     # char literals
            #   here docs
            #   symbols
            # Counter examples:
            #   foo  .          Don't allow whitespace in between.
            #                   No examples in Ruby stdlib that I can
            #                   see and more often interferes with range
            #                   operator.
            #   foo['bar'].     would need to find matching '[' and
            #                   ensure no ident char immediately
            #                   preceding (that's a heuristic)
            #   %W{foo}.        don't want to go there yet
            #
            #  def\w+CLASSNAME. Don't trigger on CLASSNAME, as we're in
            #                   a definition context, not a use one.
            if last_pos > 0:
                last_last_pos = last_pos - 1
                last_last_ch = accessor.char_at_pos(last_last_pos)
                if DEBUG:
                    print "  prev char = %r" % last_last_ch
                if last_last_ch in '"\'':
                    return Trigger("Ruby", TRG_FORM_CPLN,
                                   "literal-methods", pos, implicit,
                                   literal="String")
                elif last_last_ch == '}':
                    # Might be Hash literal:
                    #   @tk_windows = {}.<|>taint
                    # Need to rule out counter examples:
                    #   attributes.collect{|name, value| ...}.<|>to_s
                    #   FileTest.exist?("#{@filename}.<|>#{i}")
                    #   @result = Thread.new { perform_with_block }.<|>value
                    # Simplifying assumption (because too many counter
                    # examples are more common): only trigger on exactly
                    #   {}.<|>
                    if last_pos > 1 \
                       and accessor.char_at_pos(last_pos-2) == '{':
                        return Trigger("Ruby", TRG_FORM_CPLN,
                                       "literal-methods", pos, implicit,
                                       literal="Hash")
                    else:
                        return None
                elif last_last_ch == ']':
                    # Might be Array literal:
                    #   @tk_table_list = [].<|>taint
                    #   [1,2,3].<|>
                    # Need to rule out counter examples:
                    #   @@services[host][port].stop
                    #   foo[blah].bang
                    # Algorithm: Look back on currently line for
                    # matching '['. If the char before that is a space,
                    # then consider it an Array. If can't find matching
                    # '[' on this line, then consider it an Array.
                    wrk_line = accessor.text_range(
                        accessor.line_start_pos_from_pos(last_pos),
                        last_last_pos)
                    block_count = 1
                    for ch in reversed(wrk_line):
                        if not block_count:
                            if ch in WHITESPACE or ch in '=,(':
                                return Trigger("Ruby", TRG_FORM_CPLN,
                                               "literal-methods", pos,
                                               implicit, literal="Array")
                            return None
                        if ch == '[':
                            block_count -= 1
                        elif ch == ']':
                            block_count += 1
                    else:
                        return Trigger("Ruby", TRG_FORM_CPLN,
                                       "literal-methods", pos,
                                       implicit, literal="Array")
                    return None
                elif isident(last_last_ch):
                    LIMIT = 50
                    text = accessor.text_range(max(
                        0, last_pos-LIMIT), last_pos)  # working text
                    if text.find("def") > -1:
                        # String.find fails faster than Regex.search
                        idx = max(text.rfind("\n"), text.rfind("\r"))
                        if idx > -1:
                            line = text[idx + 1:]
                        else:
                            line = text
                        if self._method_def_header.search(line):
                            if DEBUG:
                                print "==> bailing out, defining something"
                            return None
                    return Trigger("Ruby", TRG_FORM_CPLN,
                                   "object-methods", pos, implicit)
                elif isdigit(last_last_ch):
                    # Could be a numeric literal or an ident.
                    wrk_line = accessor.text_range(
                        accessor.line_start_pos_from_pos(last_pos),
                        last_pos)
                    if DEBUG:
                        print "'<digit>.': numeric literal or identifier"
                        print "check for leading number in %r" % wrk_line
                    if self._leading_float_re.search(wrk_line):
                        return Trigger("Ruby", TRG_FORM_CPLN,
                                       "literal-methods", pos,
                                       implicit, literal="Float")
                    elif self._leading_number_re.search(wrk_line):
                        return (not implicit and
                                Trigger("Ruby", TRG_FORM_CPLN,
                                        "literal-methods", pos,
                                        implicit, literal="Fixnum")) or None
                    else:
                        return Trigger("Ruby", TRG_FORM_CPLN,
                                       "object-methods", pos, implicit)
                else:
                    return None

        elif last_ch == '(':
            # This may be:
            #   FOO(|           calltip-call-signature
            # - Want to be sure to exclude precedence parens after
            #   keywords: "if (", "while (", etc.
            # - XXX Are there instances of this trigger that we just
            #   want to drop here because of practical limitations in the
            #   Ruby codeintel handling -- as there are with Perl?
            LIMIT = 100
            text = accessor.text_range(max(
                0, last_pos-LIMIT), last_pos)  # working text
            if DEBUG:
                print "  working text: %r" % text
            i = len(text)-1
            while i >= 0 and text[i] in WHITESPACE:  # parse off whitespace
                i -= 1
            RUBY_SPECIAL_METHOD_END_CHARS = "?!"  # XXX what about '='?
            if i >= 0 and not (isident(text[i]) or isdigit(text[i])
                               or text[i] in RUBY_SPECIAL_METHOD_END_CHARS):
                if DEBUG:
                    print "no: first non-ws char before "\
                          "trigger point is not an ident char: '%s'" % text[i]
                return None
            end = i+1
            if text[i] in RUBY_SPECIAL_METHOD_END_CHARS:
                i -= 1
            while i >= 0:  # parse out the preceding identifier
                if isdigit(text[i]):
                    # might be an identifier, need to keep looking
                    pass
                elif not isident(text[i]):
                    # Identifier can be prefixed with '$', '@' or '@@'.
                    if i >= 1 and text[i-1:i+1] == "@@":
                        start = i-1
                    elif text[i] in "$@":
                        start = i
                    else:
                        start = i+1
                    identifier = text[start:end]
                    break
                i -= 1
            else:
                identifier = text[:end]
            if DEBUG:
                print "  identifier: %r" % identifier
            if not identifier:
                if DEBUG:
                    print "no: no identifier preceding trigger point"
                return None
            elif isdigit(identifier[0]):
                if DEBUG:
                    print "no: token preceding trigger "\
                          "point is not a legal identifier"
                return None
            if identifier in self.RUBY_KEYWORDS:
                if DEBUG:
                    print "no: no trigger on paren "\
                          "after keyword: %r" % identifier
                return None
            # Now we want to rule out subroutine definition lines, e.g.:
            #    def foo(
            #    def ClassName.foo(
            #    def self.foo(
            #    def (wacked+out).foo(
            line = text[:end].splitlines(0)[-1]
            if DEBUG:
                print "  trigger line: %r" % line
            if line.lstrip().startswith("def"):
                if DEBUG:
                    print "no: no trigger on Ruby func definition"
                return None
            if DEBUG:
                print "calltip-call-signature"
            return Trigger("Ruby", TRG_FORM_CALLTIP, "call-signature",
                           pos, implicit)

        elif last_ch in ('"', "'"):
            # This may be one of these:
            #   require '|              complete-lib-paths
            #   require "|              complete-lib-paths
            LIMIT = 50
            text = accessor.text_range(max(
                0, last_pos-LIMIT), last_pos)  # working text
            if DEBUG:
                print "  working text: %r" % text
            i = len(text)-1
            # Parse off whitespace before quote.
            while i >= 0 and text[i] in WHITESPACE:
                i -= 1
            # Ensure that the "require" keyword immediately precedes the
            # quote.
            # XXX *Could* consider allowing preceding ';' or '#' rather
            #    than just whitespace.
            LEN_REQUIRE = 7  # len("require")
            i += 1  # point to one past "require"; simplifies indexing
            if i > LEN_REQUIRE and text[i-LEN_REQUIRE:i] == "require" \
               and text[i-1-LEN_REQUIRE] in WHITESPACE:
                pass
            elif i == LEN_REQUIRE and text[:i] == "require":
                pass
            else:
                if DEBUG:
                    print "no: quote not preceded by bare 'require'"
                return None
            if DEBUG:
                print "complete-lib-paths"
            return Trigger("Ruby", TRG_FORM_CPLN, "lib-paths",
                           pos, implicit)

        elif last_ch == '/':
            # This may be one of these:
            #   require 'foo/|          complete-lib-subpaths
            #   require "foo/|          complete-lib-subpaths
            # Simplifying assumption: this must all be on the same line.
            LIMIT = 75
            text = accessor.text_range(max(
                0, last_pos-LIMIT), last_pos)  # working text
            if DEBUG:
                print "  working text: %r" % text
            # Get the current line.
            i = len(text)-1
            while i > 0:  # Skip back to start of line.
                if text[i] in EOL:
                    break
                elif not styleClassifier.is_ruby_style_at_pos(i):
                    # Did we get back more than one char?
                    if i < last_pos:
                        i += 1
                    break
                i -= 1
            line = text[i:].lstrip()
            if DEBUG:
                print "  line: %r" % line
            # Optimization: Just check that the line looks like a
            # require statement. This might miss things like:
            #       foo; require 'bar/baz'
            # but who does that? 80/20
            LEN_REQUIRE = 7  # len("require") == 7
            if not line.startswith("require") \
               or line[LEN_REQUIRE] not in WHITESPACE \
               or line[LEN_REQUIRE:].lstrip()[0] not in ("'", '"'):
                if DEBUG:
                    print "no: line doesn't start with "\
                          "/require\\s+['\"]/: <<%r>>" % line
                return None
            if DEBUG:
                print "complete-lib-subpaths"
            return Trigger("Ruby", TRG_FORM_CPLN, "lib-subpaths",
                           pos, implicit)

        elif last_ch == ':':
            # This may be:
            #   MODULE::|           complete-module-names
            # We've already checked (above) that the preceding character
            # is ':'.
            LIMIT = 50
            text = accessor.text_range(max(
                0, last_pos-LIMIT), last_pos)  # working text
            if DEBUG:
                print "  working text: %r" % text
            # Just walk over the preceding token until we are pretty
            # sure it can be a variable name: there is a letter or
            # underscore in it.
            i = len(text) - 2  # len('::') == 2
            while i >= 0:
                if isident(text[i]):
                    break  # good enough, could be an identifier
                elif isdigit(text[i]):
                    i -= 1  # might be an identifier, need to keep looking
                else:
                    if DEBUG:
                        print "no: '::' not preceded with "\
                              "identifier: %r" % text[i]
                    return None
            else:
                if DEBUG:
                    print "no: '::' not preceded with "\
                          "identifier: %r" % text[i]
                return None
            if DEBUG:
                print "complete-module-names"
            return Trigger("Ruby", TRG_FORM_CPLN, "module-names",
                           pos, implicit, length=2)

        elif last_ch == '@':
            # Is likely (always?) one of:
            #       @@|             complete-class-vars
            #       @|              complete-instance-vars
            if (last_pos > 0 and accessor.char_at_pos(last_pos-1) == '@'):
                if DEBUG:
                    print "complete-class-vars"
                return Trigger("Ruby", TRG_FORM_CPLN, "class-vars",
                               pos, implicit, length=2)
            else:
                if DEBUG:
                    print "complete-instance-vars"
                return Trigger("Ruby", TRG_FORM_CPLN, "instance-vars",
                               pos, implicit)

        elif last_ch == '$':
            # Is likely (always?) this:
            #       $|              complete-global-vars
            if DEBUG:
                print "complete-global-vars"
            return Trigger("Ruby", TRG_FORM_CPLN, "global-vars",
                           pos, implicit)

        return None

    # Match a Ruby number literal.
    # Limitations:
    # - 0d123456, 0xff, -0b10_1010  # specific base laterals
    _number_pat = r"""
          \d+\.\d+                  # float
        | \d+(\.\d+)?([eE][-+]?\d+)  # exp float
    """
    _leading_float_re = re.compile("(?<!\w)(%s)$" % _number_pat, re.X)
    _leading_number_re = re.compile("(?<!\w)\d+$")

    _method_def_header = re.compile(r'\bdef\s+\w+$')

    # Example Ruby "leading expressions":
    #   send
    #   File.open
    #   Zlib::Deflate.deflate
    #   0.step (XXX punt on numbers for now)
    #   @assigned
    #   @@foo
    #   $blah
    #   @assigned.foo
    #   @ingredients.has_key?
    #   $_  (XXX punt on the special vars for now)
    _leading_citdl_expr_pat = re.compile(r"""
        (
            (       # the set of those with @, @@, $ prefix
                (@@|@|\$)%(ident)s(\.%(ident)s)*
            )
            |
            (       # or, the set of those without the prefix
                %(ident)s(::%(ident)s)*(\.%(ident)s)*
            )
            |       # or a literal
            (
                (?P<literal>\]|\}|\'|\"|%(number)s|(?<!\w)\d+)(?P<literal_tail>(\.%(ident)s)*)
            )
        )
        [?!]?       # methods can end with '?' or '!' (XXX what about '='?)
        \s*$        # anchored at the end of the string
        """ % {"ident": "((?!\d)\w+)", "number": _number_pat}, re.X)

    #@hotshotit
    def preceding_trg_from_pos(self, buf, pos, curr_pos, DEBUG=False):
        """ Cases where we're interested in continuing a trigger:

        Examples:

            GIVEN                                   TRG AT
            -----                                   ----------
        ident1.<$>iden<|>t2 ...                     .
           allow and ignore spaces after '.'
        ident1::<$>iden<|>t2 ...                    ::
           allow and ignore spaces after '::'
        class ident1 <<$> ide<|>nt2                 ' ' after "<"
           allow and ignore spaces after '<'
        require '<$>no-slash-path<|>                '
        require 'path/<$>rest<|>                    /
        <$>iden<|>                                  start of word

        pos is marked by "<$>"
        curr_pos indicated by "<|>"
        """

        styleClassifierClass = (isinstance(buf, UDLBuffer) and _UDLStyleClassifier
                                or _RubyStyleClassifier)
        preceding_trg_terminators = None
        if styleClassifierClass == _UDLStyleClassifier:
            preceding_trg_terminators = {"%": SCE_UDL_TPL_OPERATOR}
        trg = ProgLangTriggerIntelMixin.preceding_trg_from_pos(
            self, buf, pos, curr_pos,
            preceding_trg_terminators=preceding_trg_terminators,
            DEBUG=DEBUG)
        if trg is not None:
            return trg
        if DEBUG:
            print "preceding_trg_from_pos: pos=%d, curr_pos=%d" % (pos, curr_pos)
        styleClassifier = styleClassifierClass(buf)
        # Assume we're on an identifier that doesn't follow a
        # trigger character.  Find its start.
        accessor = buf.accessor
        curr_style = accessor.style_at_pos(curr_pos - 1)
        if styleClassifier.is_identifier_or_word_style(curr_style):
            # Check for one of the following:
            # class ident1 < ide<|>
            # ide<|>
            idx = curr_pos - 2
            for char_and_style in accessor.gen_char_and_style_back(idx, 0):
                if char_and_style[1] != curr_style:
                    break
                idx -= 1
            if idx <= 0:
                if DEBUG:
                    print "Moved to beginning of buffer"
                return None
            trg = self.trg_from_pos(buf, curr_pos, implicit=False, DEBUG=DEBUG)
            return trg
        elif DEBUG:
            print "Ignore current style %d" % curr_style

    def citdl_expr_from_trg(self, buf, trg):
        """Parse out the leading Ruby expression and return a CITDL
        expression for it.

        We parse out the Ruby expression preceding the given position
        (typically a calltip/autocomplete trigger position), simplify the
        expression (by removing whitespace, etc.) and translate that to an
        appropriate CITDL (*) expression. Returns None if there is no
        appropriate such expression.

        Optimization Notes:
        - We can throw out Ruby expressions with function calls
          because CodeIntel does not currently handle return values.
        - Abort at hash and list indexing: the types of elements in these
          objects are not tracked by CodeIntel.
        - Currently we don't really make use of the styling info because we
          abort at indexing, function call arguments, etc. where recognizing
          string/number/regex boundaries would be useful. This info might be
          useful later if this algorithm is beefed up.

        Examples:

            GIVEN                                   CITDL EXPR
            -----                                   ----------
            send(<|>                                send
            foo.instance_of?(<|>                    foo.instance_of?
            File.open(<|>                           File.open
            Zlib::Deflate.deflate(<|>               Zlib::Deflate.deflate
            @assigned.<|>                           @assigned
            @@foo.<|>                               @foo
            $blah.<|>                               @blah
            YAML::PRIVATE_TYPES[r].call(<|>         <punt because of []>
            [$2].pack(<|>                           <punt>
            @db_class::<|>WidgetClassName           <punt: looks to be rare>

            0.<|>                                   Fixnum
            '...'.<|>  "...".<|>                    String
            [].step(<|>                             Array.step
            {}.step(<|>                             Hash.step

        * http://specs.tl.activestate.com/kd/kd-0100.html#citdl
        """
        DEBUG = False
        pos = trg.pos
        styleClassifier = (isinstance(buf, UDLBuffer) and _UDLStyleClassifier
                           or _RubyStyleClassifier)(buf)
        accessor = buf.accessor
        last_pos = pos - 1

        buflen = accessor.length()
        end_pos = pos
        if trg.form == TRG_FORM_DEFN:
            # Move pos forward until at the end of the current expression
            trg_length = 0
            curr_style = accessor.style_at_pos(last_pos)
            if not styleClassifier.is_identifier_or_definition_style(curr_style):
                return None
            idx = pos
            while idx < buflen:
                new_style = accessor.style_at_pos(idx)
                if new_style != curr_style:
                    end_pos = idx
                    break
                idx += 1
        else:
            trg_length = trg.length
            end_pos = pos - trg_length
        wrk_text = buf.accessor.text_range(max(0, pos-100), end_pos)
        if DEBUG:
            print banner("Ruby citdl_expr_from_trg")
            if pos > 100:
                print "...",
            print (wrk_text
                   + "<+>")
            print banner(None, '-')

        # Parse off a Ruby leading expression.
        match = self._leading_citdl_expr_pat.search(wrk_text)
        if not match:
            if trg.type == "names" and not trg.implicit:
                citdl_expr = ""
                if DEBUG:
                    print "trigger-type of current-names: match anything"
            else:
                citdl_expr = None
                if DEBUG:
                    print "could not match a trailing Ruby var"
        elif match.group("literal"):
            literal = match.group("literal")
            literal_tail = match.group("literal_tail")
            ruby_type_from_literal = {']': "Array", '}': "Hash",
                                      '"': "String", "'": "String"}
            if DEBUG:
                print "leading literal (part): %r (tail=%r)"\
                      % (literal, literal_tail)
            try:
                ruby_type = ruby_type_from_literal[match.group('literal')]
            except KeyError:
                if '.' in literal or 'e' in literal or 'E' in literal:
                    ruby_type = "Float"
                else:
                    ruby_type = "Fixnum"
            citdl_expr = ruby_type + literal_tail
        else:
            citdl_expr = match.group(0)
            if DEBUG:
                print "parsed out leading Ruby citdl_expr: %r" % citdl_expr

        if DEBUG:
            print "returning: %r" % citdl_expr
            print banner(None, '-')
        return citdl_expr

    _require_pat = re.compile(r'(?:require|load)\s+[\'"](.*?)$')

    def async_eval_at_trg(self, buf, trg, ctlr):
        if _xpcom_:
            trg = UnwrapObject(trg)
            ctlr = UnwrapObject(ctlr)
        ctlr.start(buf, trg)

        if trg.id == ("Ruby", TRG_FORM_CALLTIP, "call-signature"):  # FOO(<|>
            line = buf.accessor.line_from_pos(trg.pos)
            citdl_expr = self.citdl_expr_from_trg(buf, trg)
            if citdl_expr is None:
                return None

            # Special case for class ".new" constructor:
            # "Foo.new(" is really using "Foo.initialize(".
            if citdl_expr.endswith(".new"):
                converted_dot_new = True
                citdl_expr = citdl_expr[:-len(".new")] + ".initialize"
            else:
                converted_dot_new = False

            evalr = RubyTreeEvaluator(ctlr, buf, trg, citdl_expr, line,
                                      converted_dot_new=converted_dot_new)
            buf.mgr.request_eval(evalr)

        elif trg.form == TRG_FORM_DEFN or \
            (trg.form == TRG_FORM_CPLN and trg.type in (
                "object-methods",                   # FOO.|
                "module-names",                     # MODULE::|
                "literal-methods",		    # LITERAL.
        )):
            line = buf.accessor.line_from_pos(trg.pos)
            citdl_expr = self.citdl_expr_from_trg(buf, trg)
            if citdl_expr is None:
                ctlr.error("couldn't determine leading expression")
                ctlr.done("error")
                return
            evalr = RubyTreeEvaluator(ctlr, buf, trg, citdl_expr, line)
            buf.mgr.request_eval(evalr)

        elif trg.form == TRG_FORM_CPLN and trg.type in (
                "lib-paths",                # require '|, require "|
                "lib-subpaths",             # require 'foo/|, require "foo/
             ):
            if trg.type == "lib-subpaths":
                accessor = buf.accessor
                line = accessor.text_range(
                    accessor.line_start_pos_from_pos(trg.pos),
                    trg.pos-trg.length)
                match = self._require_pat.search(line)
                if not match:
                    return None  # not a trigger point
                require_arg = match.group(1)
            else:
                require_arg = ""

            import_handler \
                = buf.mgr.citadel.import_handler_from_lang("Ruby")
            evalr = RubyImportsEvaluator(ctlr, buf, trg, import_handler,
                                         require_arg)
            buf.mgr.request_eval(evalr)

        elif trg.form == TRG_FORM_CPLN and trg.type == "names":  # FOO|
            line = buf.accessor.line_from_pos(trg.pos)
            extra = trg.extra
            citdl_expr = extra.get("prefix")
            if citdl_expr is None:
                ctlr.error("couldn't determine leading expression")
                ctlr.done("error")
                return
            evalr = RubyTreeEvaluator(ctlr, buf, trg, citdl_expr, line)
            buf.mgr.request_eval(evalr)

        elif trg.form == TRG_FORM_CPLN and trg.type in (
                "available-modules-and-classes",    # class FOO < |
                "class-vars",                       # @@|
                "instance-vars",                    # @|
                "available-modules",                # include |
                "global-vars",                      # $|
             ):
            # XXX NYI. Should disable these at trg_from_pos else will get
            #    statusbar warnings.
            return None

        else:
            raise CodeIntelError("unexpected ruby trigger: %r" % trg)

    #---- code browser integration
    cb_import_group_title = "Requires and Includes"

    def cb_import_data_from_elem(self, elem):
        # require 'zlib' -> <import module="zlib" symbol="*"/>
        # include Comparable -> <import symbol="Comparable"/>
        module = elem.get("module")
        symbol = elem.get("symbol")
        if not module:
            name = symbol
            detail = 'include %s' % symbol
        else:
            name = module
            detail = 'require "%s"' % module
        return {"name": name, "detail": detail}

    def calltip_verify_termination(self, accessor, ch, trg_pos, curr_pos):
        """Terminate on a newline if the trigger was a space"""
        return ch not in ('\r', '\n') or accessor.char_at_pos(trg_pos - 1) == ' '


class RubyImportHandler(ImportHandler):
    PATH_ENV_VAR = "RUBYLIB"
    sep = '/'
    # Dev Notes:
    # - ruby -e "puts $:"
    # - XXX What are the implications of Ruby GEMs?

    # Try to speed up self._getPath() a little bit.
    def __init__(self, mgr):
        ImportHandler.__init__(self, mgr)
        self._pathCache = None
        self._findModuleOnDiskCache = {}
    if CACHING:
        def _getPath(self, cwd=None):
            if self._pathCache is None:
                self._pathCache = ImportHandler._getPath(
                    self)  # intentionally exclude cwd
            if cwd:
                return [cwd] + self._pathCache
            else:
                return self._pathCache

    def _shellOutForPath(self, compiler):
        import process
        argv = [compiler, "-e", "puts $:"]
        # Ruby doesn't have an option (like Python's -E) to ignore env
        # vars.
        env = dict(os.environ)
        if "RUBYLIB" in env:
            del env["RUBYLIB"]
        if "RUBYLIB_PREFIX" in env:
            del env["RUBYLIB_PREFIX"]

        p = process.ProcessOpen(argv, env=env, stdin=None)
        output, stderr = p.communicate()
        retval = p.returncode
        path = output.splitlines(0)
        if sys.platform == "win32":
            path = [p.replace('/', '\\') for p in path]
        # Handle cwd separately.
        path = [p for p in path if p not in ("", ".", os.getcwd())]
        return path

    def setCorePath(self, compiler=None, extra=None):
        if compiler is None:
            import which
            try:
                compiler = which.which("ruby")
            except which.WhichError, ex:
                self.corePath = []  # could not determine
                return
        self.corePath = self._shellOutForPath(compiler)

    def findSubImportsOnDisk(self, module, cwd):
        from os.path import isdir, join, splitext, exists

        path = self._getPath(cwd)
        if os.sep != "/":
            mrelpath = module.replace("/", os.sep)
        else:
            mrelpath = module

        subimports = {}  # use a dict to get a unique list
        for p in path:
            mdir = join(p, mrelpath)
            if not exists(mdir):
                continue
            for name in os.listdir(mdir):
                fullpath = join(mdir, name)
                if fullpath in path:
                    # Don't show dirs that would just lead back to the
                    # another dir on the import path.
                    continue
                elif isdir(fullpath):
                    subimports[name+"/"] = True
                elif splitext(name)[-1] in (".rb", ".so"):
                    subimports[splitext(name)[0]] = True
        return subimports.keys()

    def _findScannableFiles(self,
                            (files, searchedDirs, skipRareImports,
                             importableOnly),
                            dirname, names):
        if sys.platform.startswith("win"):
            cpath = dirname.lower()
        else:
            cpath = dirname
        if cpath in searchedDirs:
            while names:
                del names[0]
            return
        else:
            searchedDirs[cpath] = 1
        # XXX Handle skipRareImports???
        scannableExts = [".rb"]
        for i in range(len(names)-1, -1, -1):  # backward so can del from list
            path = os.path.join(dirname, names[i])
            if os.path.isdir(path):
                pass
            elif os.path.splitext(names[i])[1] in scannableExts:
                # XXX The list of extensions should be settable on
                #    the ImportHandler and Komodo should set whatever is
                #    set in prefs.
                # XXX This check for files should probably include
                #    scripts, which might likely not have the
                #    extension: need to grow filetype-from-content smarts.
                files.append(path)

    def find_importables_in_dir(self, dir):
        """See citadel.py::ImportHandler.find_importables_in_dir() for
        details.

        Importables for Ruby look like this:
            {"shell":   ("shell.rb",   None, True),
             "weakref": ("weakref.rb", None, False),
             "rdoc":    (None,         None, True)}

        Notes:
        - Drop "plat" dir (e.g., "i686-linux" on linux). Using the
          existance of "$dir/rbconfig.rb" to indicate this is a plat
          dir. Optimization: Only look in dirs with a hyphen.

        TODO: log the fs-stat'ing a la codeintel.db logging.
        TODO: consider *.so files when have a story for binary modules
              on the fly
        """
        from os.path import join, isdir, splitext, exists

        if dir == "<Unsaved>":
            # TODO: stop these getting in here.
            return {}

        try:
            names = os.listdir(dir)
        except OSError, ex:
            return {}
        dirs, nondirs = set(), set()
        for name in names:
            if isdir(join(dir, name)):
                if '-' in name and exists(join(dir, name, "rbconfig.rb")):
                    # Looks like a plat dir: skip it.
                    continue
                dirs.add(name)
            else:
                nondirs.add(name)

        importables = {}
        for name in nondirs:
            base, ext = splitext(name)
            if ext != ".rb":
                continue
            if base in dirs:
                importables[base] = (name, None, True)
                dirs.remove(base)
            else:
                importables[base] = (name, None, False)
        for name in dirs:
            importables[name] = (None, None, True)

        return importables


def _blob_scope_from_codeintel_tree(tree):
    if tree.tag == "codeintel":
        node = tree.findall("file/scope")
    # node = tree.getroot().getchildren()[0].getchildren()[0].getchildren()[0];
    return node and node[0]


class RubyCILEDriver(CILEDriver):
    lang = lang

    def scan(self, request):
        request.calculateMD5()
        return rubycile.scan(request.content, request.path,
                             request.md5sum, request.mtime)

    def scan_purelang(self, buf):
        log.info("scan_purelang: path: %r lang: %s", buf.path, buf.lang)
        tree = rubycile.scan_purelang(buf.accessor.text, buf.path)
        blob_scope = _blob_scope_from_codeintel_tree(tree)
        rubycile.check_insert_rails_env(buf.path, blob_scope)
        return tree

    def scan_multilang(self, buf, csl_cile_driver=None):
        """Scan the given multilang (UDL-based) buffer and return a CIX
        element tree.

            "buf" is the multi-lang Buffer instance (e.g.
                lang_rhtml.RHTMLBuffer for RHTML).
            "csl_cile_driver" (optional) is the CSL (client-side language)
                CILE driver. While scanning, CSL tokens should be gathered and,
                if any, passed to the CSL scanner like this:
                    csl_cile_driver.scan_csl_tokens(
                        file_elem, blob_name, csl_tokens)
                The CSL scanner will append a CIX <scope ilk="blob">
                element to the <file> element.
        """
        log.info("scan_multilang: path: %r lang: %s", buf.path, buf.lang)
        tree = Element("codeintel", version="2.0")
        path = buf.path
        if sys.platform == "win32":
            path = path.replace('\\', '/')
        file = SubElement(tree, "file", lang=buf.lang, path=path)
        module = SubElement(file, "scope", ilk="blob", lang="Ruby",
                            name=basename(buf.path))

        # XXX When running inside Komodo we'll have to either implement
        #    SciMozAccessor.gen_tokens() or adapt rubycile to work with
        #    a SciMoz styled text stream. Whichever is easier and
        #    faster.
        csl_tokens, has_ruby_code = \
            rubycile.scan_multilang(buf.accessor.gen_tokens(), module)
        rubycile.check_insert_rails_env(path, module)

        # if the Ruby module node contains no children, remove it (bug 64897)
        if not has_ruby_code:
            assert len(module) == 0
            file.remove(module)

        if csl_cile_driver and csl_tokens:
            csl_cile_driver.scan_csl_tokens(file, basename(buf.path),
                                            csl_tokens)

        # XXX While still generating CIX 0.1, need to convert to CIX 2.0.
        # XXX Trent: This can all be deleted now, right?
        # tree = tree_2_0_from_tree_0_1(tree)

        return tree


#---- internal support stuff
#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=RubyLexer(),
                      buf_class=RubyBuffer,
                      langintel_class=RubyLangIntel,
                      import_handler_class=RubyImportHandler,
                      cile_driver_class=RubyCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_ruby_common
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Common routines for ruby and ruby/rhtml support for CodeIntel"""

import os.path
import logging

log = logging.getLogger("codeintel.ruby.common")
# log.setLevel(logging.DEBUG)


class RubyCommonBufferMixin:
    def check_for_rails_app_path(self, path):
        self.framework_role = None
        if path is None:
            # log.debug("check_for_rails_app_path: no path given")
            return
        apath = os.path.abspath(path)
        aplist = apath.split(os.path.sep)
        role_root = "rails"
        if len(aplist) < 3:
            return
        elif (aplist[-3] == "app" and
             (aplist[-2] == "controllers" and aplist[-1].endswith(".rb")
              or aplist[-2] == "helpers" and aplist[-1].endswith("_helper.rb")
              or aplist[-2] == "models" and aplist[-1].endswith(".rb"))):
            role = '.'.join((role_root, aplist[-2]))
        elif (len(aplist) >= 4
              and aplist[-4] == "app" and aplist[-3] == "views"
              and aplist[-1].endswith((".html.erb", ".rhtml"))):
            role = '.'.join((role_root, aplist[-3], aplist[-2]))
        elif (aplist[-3] == "db" and aplist[-2] == "migrate"
              and aplist[-1][0].isdigit()
              and aplist[-1].endswith(".rb")):
            role = '.'.join((role_root, aplist[-3], aplist[-2]))
        elif (aplist[-3] == "test"
              and aplist[-2] in ("functional", "unit")
              # integration tests not supported until we can find
              # ActionController::IntegrationTest
              and aplist[-1].endswith("_test.rb")):
            role = '.'.join((role_root, aplist[-3], aplist[-2]))
        else:
            return
        self.framework_role = role

########NEW FILE########
__FILENAME__ = lang_smarty
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Smarty support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin

#---- globals

lang = "Smarty"
log = logging.getLogger("codeintel.smarty")


#---- language support
class SmartyLexer(UDLLexer):
    lang = lang


class SmartyBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    tpl_lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "PHP"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    # - wanted for CSS completion: " ('\";},.>"
    # - wanted for JS completion:  "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    # - dropping '-' because causes problem with CSS (bug 78312)
    # - dropping '!' because causes problem with CSS "!important" (bug 78312)
    # TODO: adjust for PHP, if necessary
    cpln_stop_chars = "'\" (;},~`@#%^&*()=+{}]|\\;,.<>?/"


class SmartyCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"
    ssl_lang = "PHP"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=SmartyLexer(),
                      buf_class=SmartyBuffer,
                      import_handler_class=None,
                      cile_driver_class=SmartyCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_tcl
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Tcl support for CodeIntel"""

import sys
import os
import logging
from pprint import pprint
import re

import process

import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants

from codeintel2.citadel import ImportHandler, CitadelBuffer, CitadelLangIntel
from codeintel2.citadel_common import ScanRequest
from codeintel2.common import *
from codeintel2.parseutil import urlencode_path
from codeintel2.tree import tree_from_cix


#---- globals

lang = "Tcl"
log = logging.getLogger("codeintel.tcl")

keywords = ["after", "append", "apply", "array", "auto_execok",
            "auto_import", "auto_load", "auto_load_index", "auto_mkindex",
            "auto_qualify", "auto_reset", "bgerror", "binary", "break",
            "case", "catch", "cd", "chan", "clock", "close", "concat",
            "continue", "dde", "dict", "else", "then", "elseif",
            "encoding", "eof", "error", "eval", "exec", "exit", "expr",
            "fblocked", "fconfigure", "fcopy", "file", "fileevent",
            "flush", "for", "foreach", "format", "gets", "glob", "global",
            "history", "if", "incr", "info", "interp", "join", "lappend",
            "lassign", "lindex", "linsert", "list", "llength", "load",
            "lrange", "lrepeat", "lreplace", "lreverse", "lsearch", "lset",
            "lsort", "namespace", "open", "package", "parray", "pid",
            "pkg_compareExtension", "pkg_mkIndex", "proc", "puts", "pwd",
            "read", "regexp", "registry", "regsub", "rename", "return",
            "scan", "seek", "set", "socket", "source", "split", "string",
            "subst", "switch", "tcl_findLibrary", "tell", "time", "trace",
            "unknown", "unload", "unset", "update", "uplevel", "upvar",
            "variable", "vwait", "while",
            "bell", "bind", "bindtags", "button", "canvas", "checkbutton",
            "clipboard", "destroy", "entry", "event", "focus", "font",
            "frame", "grab", "grid", "image", "label", "labelframe",
            "listbox", "lower", "menu", "menubutton", "message", "option",
            "pack", "panedwindow", "place", "radiobutton", "raise",
            "scale", "scrollbar", "selection", "spinbox", "text", "tk",
            "tk_chooseColor", "tk_chooseDirectory", "tk_getOpenFile",
            "tk_getSaveFile", "tk_menuSetFocus", "tk_messageBox",
            "tk_popup", "tk_textCopy", "tk_textCut", "tk_textPaste",
            "tkwait", "toplevel", "ttk::button", "ttk::checkbutton",
            "ttk::combobox", "ttk::entry", "ttk::frame", "ttk::label",
            "ttk::labelframe", "ttk::menubutton", "ttk::notebook",
            "ttk::panedwindow", "ttk::progressbar", "ttk::radiobutton",
            "ttk::scrollbar", "ttk::separator", "ttk::sizegrip",
            "ttk::style", "ttk::treeview", "ttk::style", "winfo", "wm"]

# Codeintel will assume we're running v 8.6+
# Other clients can pick and choose the keywords they want.
v8_6_keywords = ["coroutine",
                 "finally"
                 "lmap"
                 "on"
                 "tailcall",
                 "throw",
                 "trap"
                 "try",
                 "yield",
                 "yieldto",
                 "zlib",
                 ]


line_end_re = re.compile("(?:\r\n|\r)")


#---- language support

class TclLexer(Lexer):
    lang = "Tcl"

    def __init__(self):
        self._properties = SilverCity.PropertySet()
        self._lexer = SilverCity.find_lexer_module_by_id(
            ScintillaConstants.SCLEX_TCL)
        self._keyword_lists = [
            SilverCity.WordList(' '.join(sorted(keywords + v8_6_keywords)))
        ]


class TclBuffer(CitadelBuffer):
    lang = "Tcl"
    cb_show_if_empty = True


class TclLangIntel(CitadelLangIntel):
    lang = "Tcl"

    def cb_import_data_from_elem(self, elem):
        # XXX Not handling symbol and alias
        module = elem.get("module")
        detail = "package require %s" % module
        return {"name": module, "detail": detail}


class TclImportHandler(ImportHandler):
    # Tcl _does_ have a TCLLIBPATH environment variable for specifying
    # import path elements, but parsing isn't straighforward -- it uses
    # Tcl-syntax -- so we don't bother to separate "envPath" and "corePath"
    # for Tcl.
    PATH_ENV_VAR = None

    def _shellOutForPath(self, compiler):
        import process
        argv = [compiler]
        p = process.ProcessOpen(argv)
        output, stderr = p.communicate("puts [join $auto_path \\n]")
        retval = p.returncode
        path = [os.path.normpath(line) for line in output.splitlines(0)]
        if path and (path[0] == "" or path[0] == os.getcwd()):
            del path[0]  # cwd handled separately
        return path

    def setCorePath(self, compiler=None, extra=None):
        if compiler is None:
            import which
            compiler = which.which("tclsh")
        self.corePath = self._shellOutForPath(compiler)

    def _findScannableFiles(self, (files, searchedDirs, skipRareImports),
                            dirname, names):
        if sys.platform.startswith("win"):
            cpath = dirname.lower()
        else:
            cpath = dirname
        if cpath in searchedDirs:
            while names:
                del names[0]
            return
        else:
            searchedDirs[cpath] = 1
        for i in range(len(names)-1, -1, -1):  # backward so can del from list
            path = os.path.join(dirname, names[i])
            if os.path.isdir(path):
                pass
            elif os.path.splitext(names[i])[1] in (".tcl",):
                # XXX The list of extensions should be settable on
                #    the ImportHandler and Komodo should set whatever is
                #    set in prefs.
                # XXX This check for files should probably include
                #    scripts, which might likely not have the
                #    extension: need to grow filetype-from-content smarts.
                if skipRareImports and names[i] == "pkgIndex.tcl":
                    continue
                files.append(path)


class TclCILEDriver(CILEDriver):
    lang = lang

    def __init__(self, *args):
        CILEDriver.__init__(self, *args)
        # We have circular imports here, so load it at runtime
        from codeintel2 import tclcile
        self.tclcile = tclcile

    def scan(self, request):
        request.calculateMD5()
        return self.tclcile.scan(request.content, request.path,
                                 request.md5sum, request.mtime)

    def scan_purelang(self, buf):
        log.info("scan_purelang: path: %r lang: %s", buf.path, buf.lang)
        return self.tclcile.scan_purelang(buf.accessor.text, buf.path)


#---- internal support stuff
#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=TclLexer(),
                      buf_class=TclBuffer,
                      langintel_class=TclLangIntel,
                      import_handler_class=TclImportHandler,
                      cile_driver_class=TclCILEDriver)

########NEW FILE########
__FILENAME__ = lang_templatetoolkit
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""TemplateToolkit support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin

#---- globals

lang = "TemplateToolkit"
log = logging.getLogger("codeintel.templatetoolkit")


#---- language support
class TemplateToolkitLexer(UDLLexer):
    lang = lang


class TemplateToolkitBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    tpl_lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "Perl"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    # - wanted for CSS completion: " ('\";},.>"
    # - wanted for JS completion:  "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    # - dropping '-' because causes problem with CSS (bug 78312)
    # - dropping '!' because causes problem with CSS "!important" (bug 78312)
    # TODO: adjust for Perl, if necessary
    cpln_stop_chars = "'\" (;},~`@#%^&*()=+{}]|\\;,.<>?/"


class TemplateToolkitCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"
    ssl_lang = "Perl"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=TemplateToolkitLexer(),
                      buf_class=TemplateToolkitBuffer,
                      import_handler_class=None,
                      cile_driver_class=TemplateToolkitCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_twig
#!/usr/bin/env python
# Copyright (c) 2006-2012 ActiveState Software Inc.
# See LICENSE.txt for license details.

"""Twig support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.langintel import LangIntel
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin

if _xpcom_:
    from xpcom.server import UnwrapObject

#---- globals

lang = "Twig"
log = logging.getLogger("codeintel.twig")


twig_keywords = [
    "and",
    "as",
    "b-and",
    "b-or",
    "b-xor",
    "by",
    "in",
    "not",
    "or",
]
twig_keywords2 = [
    "attribute",
    "block",
    "constant",
    "cycle",
    "date",
    "dump",
    "parent",
    "random",
    "range",

    "constant",
    "defined",
    "divisibleby",
    "empty",
    "even",
    "iterable",
    "null",
    "odd",
    "sameas",
]
twig_keywords += twig_keywords2

twig_tags = [
    "autoescape",
    "block",
    "do",
    "embed",
    "extends",
    "filter",
    "flush",
    "for",
    "from",
    "if",
    "import",
    "include",
    "macro",
    "raw",
    "sandbox",
    "set",
    "spaceless",
    "use",

    # end tags
    "endautoescape",
    "endblock",
    "endcomment",
    "endembed",
    "endfilter",
    "endfor",
    "endif",
    "endmacro",
    "endraw",
    "endsandbox",
    "endspaceless",
    "endwith",
]

twig_default_filter_names = [
    # These are default filter names in twig
    "capitalize",
    "convert_encoding",
    "date",
    "default",
    "escape",
    "format",
    "join",
    "json_encode",
    "keys",
    "length",
    "lower",
    "merge",
    "nl2br",
    "number_format",
    "raw",
    "replace",
    "reverse",
    "slice",
    "sort",
    "striptags",
    "title",
    "trim",
    "upper",
    "url_encode",
]


#---- language support

class TwigLexer(UDLLexer):
    lang = lang


class TwigBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    tpl_lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "Twig"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    # - wanted for CSS completion: " ('\";},.>"
    # - wanted for JS completion:  "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    # - dropping '-' because causes problem with CSS (bug 78312)
    # - dropping '!' because causes problem with CSS "!important" (bug 78312)
    cpln_stop_chars = "'\" (;},~`@#%^&*()=+{}]|\\;,.<>?/"


class TwigLangIntel(LangIntel):
    lang = lang

    # Used by ProgLangTriggerIntelMixin.preceding_trg_from_pos()
    trg_chars = tuple('| ')
    calltip_trg_chars = tuple()

    def trg_from_pos(self, buf, pos, implicit=True, DEBUG=False):
        """
            CODE       CONTEXT      RESULT
            '{<|>'     anywhere     tag names, i.e. {% if %}
            'foo|<|>'  filters      filter names, i.e. {{ foo|capfirst }}
        """
        # DEBUG = True # not using 'logging' system, because want to be fast
        if DEBUG:
            print "\n----- Twig trg_from_pos(pos=%r, implicit=%r) -----"\
                  % (pos, implicit)

        if pos < 2:
            return None
        accessor = buf.accessor
        last_pos = pos - 1
        last_char = accessor.char_at_pos(last_pos)
        if DEBUG:
            print "  last_pos: %s" % last_pos
            print "  last_char: %r" % last_char
            print 'accessor.text_range(last_pos-2, last_pos): %r' % (accessor.text_range(last_pos-2, last_pos), )

        if last_char == " " and \
           accessor.text_range(last_pos-2, last_pos) == "{%":
            if DEBUG:
                print "  triggered: 'complete-tags'"
            return Trigger(lang, TRG_FORM_CPLN,
                           "complete-tags", pos, implicit)

        if last_char == "|":
            if DEBUG:
                print "  triggered: 'complete-filters'"
            return Trigger(lang, TRG_FORM_CPLN,
                           "complete-filters", pos, implicit)

    _twigtag_cplns = [("element", t) for t in sorted(twig_tags)]
    _twigfilter_cplns = [("function", t) for t in sorted(
        twig_default_filter_names)]

    def async_eval_at_trg(self, buf, trg, ctlr):
        if _xpcom_:
            trg = UnwrapObject(trg)
            ctlr = UnwrapObject(ctlr)

        ctlr.start(buf, trg)

        # Twig tag completions
        if trg.id == (lang, TRG_FORM_CPLN, "complete-tags"):
            ctlr.set_cplns(self._twigtag_cplns)
            ctlr.done("success")
            return
        if trg.id == (lang, TRG_FORM_CPLN, "complete-filters"):
            ctlr.set_cplns(self._twigfilter_cplns)
            ctlr.done("success")
            return

        ctlr.done("success")


class TwigCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"
    tpl_lang = "Twig"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=TwigLexer(),
                      buf_class=TwigBuffer,
                      langintel_class=TwigLangIntel,
                      import_handler_class=None,
                      cile_driver_class=TwigCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_xbl
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""XBL support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin


#---- globals
lang = "XBL"
log = logging.getLogger("codeintel.xbl")


#---- language support
class XBLLexer(UDLLexer):
    lang = lang


class XBLBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    m_lang = "XML"
    css_lang = "CSS"
    csl_lang = "JavaScript"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    # - wanted for CSS completion: " ('\";},.>"
    # - wanted for JS completion:  "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    cpln_stop_chars = "'\" (;},~`!@#%^&*()-=+{}]|\\;,.<>?/"


# This gives global window completions but does not produce cile
# information, so completions for local variables and functions will
# not work.
class XBLCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=XBLLexer(),
                      buf_class=XBLBuffer,
                      import_handler_class=None,
                      cile_driver_class=XBLCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_xml
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""XML support for CodeIntel"""

import os
from os.path import isfile, isdir, exists, dirname, abspath, splitext, join
import sys
from cStringIO import StringIO
import logging
import re
import traceback
from pprint import pprint

from codeintel2.common import *
from codeintel2.citadel import CitadelBuffer, CitadelEvaluator
from codeintel2.langintel import LangIntel
from codeintel2.udl import UDLBuffer, UDLLexer, XMLParsingBufferMixin

import koXMLTreeService
import koXMLDatasetInfo
from koXMLDatasetInfo import getService

from SilverCity.ScintillaConstants import (SCE_UDL_M_STAGO, SCE_UDL_M_DEFAULT,
                                           SCE_UDL_M_ETAGO, SCE_UDL_M_TAGNAME,
                                           SCE_UDL_M_ATTRNAME, SCE_UDL_M_TAGSPACE,
                                           SCE_UDL_M_STRING,
                                           SCE_UDL_M_PI,
                                           SCE_XML_DEFAULT,
                                           SCE_XML_START_TAG_NAME,
                                           SCE_XML_START_TAG_ATTR_NAME,
                                           SCE_XML_START_TAG_OPEN,
                                           SCE_XML_START_TAG_CLOSE,
                                           SCE_XML_START_TAG_WHITE_SPACE,
                                           SCE_XML_START_TAG_ATTR_QUOT_OPEN,
                                           SCE_XML_START_TAG_ATTR_APOS_OPEN,
                                           SCE_XML_START_TAG_ATTR_QUOT_CLOSE,
                                           SCE_XML_START_TAG_ATTR_APOS_CLOSE,
                                           SCE_XML_START_TAG_ATTR_EQUALS,
                                           SCE_XML_END_TAG_OPEN,
                                           SCE_XML_END_TAG_NAME,
                                           SCE_XML_END_TAG_CLOSE,
                                           SCE_XML_DATA_CHARS,
                                           SCE_XML_DATA_NEWLINE,
                                           SCE_XML_START_TAG_ATTR_APOS_CONTENT,
                                           SCE_XML_START_TAG_ATTR_QUOT_CONTENT,
                                           SCE_XML_PI_OPEN,
                                           )


if _xpcom_:
    from xpcom.server import UnwrapObject


#---- globals
lang = "XML"
log = logging.getLogger("codeintel.xml")

STYLE_DEFAULT = 0
STYLE_START_TAG = 1
STYLE_END_TAG = 2
STYLE_TAG_NAME = 3
STYLE_ATTR_NAME = 4
STYLE_TAG_SPACE = 5
STYLE_STRING = 6
STYLE_PI_OPEN = 7
udl_styles = {
    STYLE_DEFAULT: (SCE_UDL_M_DEFAULT,),
    STYLE_START_TAG: SCE_UDL_M_STAGO,
    STYLE_END_TAG: SCE_UDL_M_ETAGO,
    STYLE_TAG_NAME: SCE_UDL_M_TAGNAME,
    STYLE_ATTR_NAME: SCE_UDL_M_ATTRNAME,
    STYLE_TAG_SPACE: SCE_UDL_M_TAGSPACE,
    STYLE_STRING: (SCE_UDL_M_STRING,),
    STYLE_PI_OPEN: SCE_UDL_M_PI,
}
# XXX FIXME for Lex_XML
pure_styles = {
    STYLE_DEFAULT: (SCE_XML_DEFAULT, SCE_XML_DATA_CHARS, SCE_XML_DATA_NEWLINE),
    STYLE_START_TAG: SCE_XML_START_TAG_OPEN,
    STYLE_END_TAG: SCE_XML_END_TAG_OPEN,
    STYLE_TAG_NAME: SCE_XML_START_TAG_NAME,
    STYLE_ATTR_NAME: SCE_XML_START_TAG_ATTR_NAME,
    STYLE_TAG_SPACE: SCE_XML_START_TAG_WHITE_SPACE,
    STYLE_STRING: (SCE_XML_START_TAG_ATTR_QUOT_OPEN,
                   SCE_XML_START_TAG_ATTR_APOS_OPEN,
                   SCE_XML_START_TAG_ATTR_APOS_CONTENT,
                   SCE_XML_START_TAG_ATTR_QUOT_CONTENT,
                   ),
    STYLE_PI_OPEN: SCE_XML_PI_OPEN,
}
common_namespace_cplns = [('namespace', x) for x in (
    'atom="http://purl.org/atom/ns#"',
    'blogChannel="http://backend.userland.com/blogChannelModule"',
    'dc="http://purl.org/dc/elements/1.1/"',
    'mml="http://www.w3.org/1998/Math/MathML"',
    'rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"',
    'rss="http://purl.org/rss/1.0/"',
    'xhtml="http://www.w3.org/TR/xhtml1/strict"',
    'xsd="http://www.w3.org/2000/10/XMLSchema"',
    'xsi="http://www.w3.org/2000/10/XMLSchema-instance"',
    'xs="http://schemas.xmlsoap.org/soap/envelope/"',
    'xsl="http://www.w3.org/1999/XSL/Transform"',
)]

trg_chars = tuple('<: "\'/!')


#---- language support

class XMLLexer(UDLLexer):
    lang = lang


class XMLLangIntel(LangIntel):
    lang = lang

    def trg_from_pos(self, buf, pos, implicit=True, DEBUG=False):
        """XML trigger types:

        xml-complete-tags-and-namespaces    <|
        xml-complete-ns-tags                <x:|
        xml-complete-tag-attrs              <x:foo |
        xml-complete-ns-tag-attrs           <x:foo y:|
        xml-complete-attr-enum-values       <x:foo y:bar="|
        xml-complete-end-tag                <x ...>...</|
        xml-complete-well-known-ns          <x xmlns:|
        xml-gt-bang                         <!|

        Not yet implemented:
            xml-complete-well-known-ns-value    <x xmlns:x="|
            xml-complete-prolog                 <?xml |
            xml-complete-doctype                <!DOCTYPE |
        """
        # XXX Eventually we'll use UDL for pure XML too, so won't need
        #    this check.
        if isinstance(buf, UDLBuffer):
            styles = udl_styles
        else:
            styles = pure_styles

        if DEBUG:
            print "\n----- UDL %s trg_from_pos(pos=%r, implicit=%r) -----"\
                  % (self.lang, pos, implicit)

        if pos == 0:
            return None
        accessor = buf.accessor
        buf_length = accessor.length()
        last_pos = pos - 1
        last_char = accessor.char_at_pos(last_pos)
        last_style = accessor.style_at_pos(last_pos)
        if DEBUG:
            print "  last_pos: %s" % last_pos
            print "  last_char: %r" % last_char
            print "  last_style: %r %s" \
                  % (last_style, buf.style_names_from_style_num(last_style))
            # for i in xrange(pos):
                # print "style at pos %d (%c) : %d" % (i,
                #   accessor.char_at_pos(i), accessor.style_at_pos(i))

        if last_char == '<' and \
           last_style in styles[STYLE_DEFAULT] or last_style == styles[STYLE_START_TAG]:
            return Trigger(self.lang, TRG_FORM_CPLN, "tags-and-namespaces",
                           pos, implicit)

        elif last_char == '/' and last_style == styles[STYLE_END_TAG]:
            return Trigger(self.lang, TRG_FORM_CPLN, "end-tag",
                           pos, implicit)

        elif last_char == ':':
            # x:|`` **** xml-complete-ns-tags
            # **** list valid tags in given namespace
            if last_style in (styles[STYLE_TAG_NAME], styles[STYLE_ATTR_NAME]):
                current_word = accessor.text_range(
                    *accessor.contiguous_style_range_from_pos(last_pos))
                # Make sure it's the first ":" in the sequence
                if current_word.count(":") != 1:
                    return None
                if current_word == "xmlns:" \
                   and last_style == styles[STYLE_ATTR_NAME]:
                    return Trigger(self.lang, TRG_FORM_CPLN, "well-known-ns",
                                   pos, implicit)
                if last_style == styles[STYLE_TAG_NAME]:
                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "ns-tags", pos, implicit)
                else:
                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "ns-tags-attrs", pos, implicit)

        elif last_char == "!" and pos >= 2:
            last_last_char = accessor.char_at_pos(pos-2)
            last_last_style = accessor.style_at_pos(pos-2)
            if last_last_char == '<' and last_last_style in styles[STYLE_DEFAULT]:
                return Trigger(self.lang, TRG_FORM_CPLN, "gt-bang",
                               pos, implicit)

        elif last_char in (' ', '\t', '\n') \
                and last_style == styles[STYLE_TAG_SPACE]:
            # See bug 65200 for reason for this check.
            have_trg = False
            while last_pos > 0:
                last_pos -= 1
                last_style = accessor.style_at_pos(last_pos)
                if last_style in (styles[STYLE_TAG_SPACE],
                                  styles[STYLE_DEFAULT]):
                    pass
                elif last_style in styles[STYLE_STRING]:
                    have_trg = True
                    break
                elif last_style == styles[STYLE_TAG_NAME]:
                    # Now move back looking for an STAGO, so we don't
                    # trigger on a space after an end-tag
                    while last_pos > 0:
                        last_pos -= 1
                        last_style = accessor.style_at_pos(last_pos)
                        if last_style == styles[STYLE_TAG_NAME]:
                            # <.... foo="val" <|>
                            pass
                        elif last_style == styles[STYLE_START_TAG]:
                            # <foo <|>
                            have_trg = True
                            break
                        else:
                            # </foo <|>
                            break
                    break
                else:
                    return None
            if have_trg:
                return Trigger(self.lang, TRG_FORM_CPLN, "tag-attrs",
                               pos, implicit)
            else:
                return None

        elif last_char in ('\'', '"') and last_style in styles[STYLE_STRING] \
                and pos >= 5:
            # Look back to determine if we're in an <<xmlns:pfx = >> situation
            prev_style = accessor.style_at_pos(pos - 2)
            if prev_style == last_style:
                # It's the end of the string, not the beginning
                return None
            else:
                return Trigger(self.lang, TRG_FORM_CPLN, "attr-enum-values",
                               pos, implicit)
        return None

    def preceding_trg_from_pos(self, buf, pos, curr_pos, DEBUG=False):
        # XXX Eventually we'll use UDL for pure HTML too, so won't need
        #    this check.
        if isinstance(buf, UDLBuffer):
            styles = udl_styles
        else:
            styles = pure_styles

        accessor = buf.accessor
        # print "pos:", pos, ", curr_pos:", curr_pos
        for char, style in accessor.gen_char_and_style_back(pos-1, max(-1, pos-50)):
            # print "Style: %d char %s"% (style, char)
            if char == ":" and style in (styles[STYLE_TAG_NAME], styles[STYLE_ATTR_NAME]) or \
               char in ["<", "!"] and style in styles[STYLE_DEFAULT] or style == styles[STYLE_START_TAG] or \
               char in (' ', '\t', '\n') and style == styles[STYLE_TAG_SPACE] or \
               char in ('\'', '"') and style in styles[STYLE_STRING] or \
               char == '/' and style == styles[STYLE_END_TAG]:
                return self.trg_from_pos(buf, pos, implicit=False, DEBUG=DEBUG)
            pos -= 1
        return None

    def async_eval_at_trg(self, buf, trg, ctlr):
        if _xpcom_:
            trg = UnwrapObject(trg)
            ctlr = UnwrapObject(ctlr)

        cplns = None
        ctlr.start(buf, trg)
        type = trg.type
        if type == "tags-and-namespaces":
            # extract tag hierarchy context -> context
            # pass context to schema-based-evaluator -> completions
            cplns = self.cpln_start_tag(buf, trg, True)
        elif type == "gt-bang":
            cplns = [
                ('doctype', 'DOCTYPE'),
                ('cdata', '[CDATA['),
                ('comment', '--'),
            ]
        elif type == "end-tag":
            cplns = self.cpln_end_tag(buf, trg)
        elif type == "well-known-ns":
            # this is a hack, we should get this from the catalog, but
            # prefix names are *not* standardized.
            cplns = common_namespace_cplns
        elif type == "well-known-ns-uri":
            # we get all uri's known to our catalog system
            uris = getService().resolver.getWellKnownNamspaces()
            cplns = [('namespace', x) for x in uris]
        elif type == "ns-tags":
            plns = self.cpln_start_tag(buf, trg, False)
        elif type == "ns-tags-attrs":
            cplns = self.cpln_start_attrribute(buf, trg)
        elif type == "tag-attrs":
            cplns = self.cpln_start_attrribute(buf, trg)
        elif type == "attr-enum-values":
            cplns = self.cpln_start_attribute_value(buf, trg)
        else:
            ctlr.error(
                "lang_xml.py: async_eval_at_trg:\n    Internal error: Unknown UDL-based XML completion type: %r" % (type,))
            ctlr.done("error")
            return
        if cplns:
            ctlr.set_cplns(cplns)
        ctlr.done("success")

    def get_valid_tagnames(self, buf, pos, withPrefix=False):
        node = buf.xml_node_at_pos(pos)
        # print "get_valid_tagnames NODE %s:%s xmlns[%s]
        # %r"%(buf.xml_tree.prefix(node),node.localName,node.ns,node.tag)
        handlerclass = buf.xml_tree_handler(node)
        tagnames = handlerclass.tagnames(buf.xml_tree, node)
        if not tagnames:
            return None
        tagnames = list(tagnames)
        tagnames.sort()
        if withPrefix and node is not None:
            prefix = buf.xml_tree.prefix(node)
            if prefix:
                return ["%s:%s" % (prefix, name) for name in tagnames]
        return tagnames

    def get_valid_attributes(self, buf, pos):
        """get_valid_attributes
        get the current tag, and return the attributes that are allowed in that
        element
        """
        node = buf.xml_node_at_pos(pos)
        if node is None:
            return None
        # print "get_valid_attributes NODE %s:%s xmlns[%s]
        # %r"%(tree.prefix(node),node.localName,node.ns,node.tag)
        already_supplied = node.attrib.keys()
        handlerclass = buf.xml_tree_handler(node)
        attrs = handlerclass.attrs(buf.xml_tree, node)
        if not attrs:
            return None
        attrs = [name for name in attrs if name not in already_supplied]
        attrs.sort()
        return attrs

    def get_valid_attribute_values(self, attr, buf, pos):
        """get_valid_attribute_values
        get the current attribute, and return the values that are allowed in that
        attribute
        """
        node = buf.xml_node_at_pos(pos)
        if node is None:
            return None
        handlerclass = buf.xml_tree_handler(node)
        values = handlerclass.values(attr, buf.xml_tree, node)
        if not values:
            return None
        values.sort()
        return values

    def cpln_start_tag(self, buf, trg, withPrefix=True):
        lastpos = trg.pos
        if withPrefix:
            accessor = buf.accessor
            lastpos = accessor.text.rfind("<", 0, trg.pos)
            lastpos = max(lastpos, 0)
        tagnames = self.get_valid_tagnames(buf, lastpos, withPrefix=withPrefix)
        if not tagnames:
            return []
        return [('element', tag) for tag in tagnames]

    def cpln_end_tag(self, buf, trg):
        node = buf.xml_node_at_pos(trg.pos)
        if node is None:
            return None
        tagName = buf.xml_tree.tagname(node)
        if not tagName:
            return []
        return [('element', tagName+">")]

    def cpln_start_attribute_value(self, buf, trg):
        accessor = buf.accessor
        attrName = accessor.text_range(
            *accessor.contiguous_style_range_from_pos(trg.pos-3))
        if not attrName:
            log.warn("no attribute name in cpln_start_attribute_value")
            return []

        values = self.get_valid_attribute_values(attrName, buf, trg.pos)
        if not values:
            return []

        return [('attribute_value', value) for value in values]

    def cpln_start_attrribute(self, buf, trg):
        accessor = buf.accessor
        attrs = self.get_valid_attributes(buf, trg.pos)
        if not attrs:
            return []
        attrName = accessor.text_range(
            *accessor.contiguous_style_range_from_pos(trg.pos-1))
        if attrName:
            attrName = attrName.strip()
        if attrName:
            return [('attribute', attr+"=") for attr in attrs if attr.startswith(attrName)]
        return [('attribute', attr+"=") for attr in attrs]


class XMLBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    m_lang = "XML"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    # - Removed '#' - gets in the way of hex colors and id selectors (bug 82968)
    cpln_stop_chars = "'\" (;},~`!@%^&*()-=+{}]|\\;,.<>?/"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=XMLLexer(),
                      buf_class=XMLBuffer,
                      langintel_class=XMLLangIntel,
                      import_handler_class=None,
                      cile_driver_class=None,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_xslt
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""XML support for CodeIntel"""

import logging
from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin
from koXMLDatasetInfo import getService

#---- globals

lang = "XSLT"
log = logging.getLogger("codeintel.xslt")


class XSLTLexer(UDLLexer):
    lang = lang


class XSLTBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    m_lang = "XML"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    cpln_stop_chars = ">'\" "

    def xml_default_dataset_info(self, node):
        # print "%s:%s node %r" % (self.lang, trg.lang, node)
        tree = self.xml_tree
        if node is not None and not tree.namespace(node):
            # Do we have an output element, if so, figure out if we're html.
            # Cheap way to get the output element.
            output = tree.tags.get(tree.namespace(
                tree.root), {}).get('output', None)
            if output is not None:
                lang = output.attrib.get('method').upper()
                publicId = output.attrib.get('doctype-public')
                systemId = output.attrib.get('doctype-system')
                if publicId or systemId:
                    default_dataset_info = (publicId, systemId, None)
                else:
                    datasetSvc = getService()
                    default_dataset_info = (
                        datasetSvc.getDefaultPublicId(lang, self.env),
                        None,
                        datasetSvc.getDefaultNamespace(lang, self.env)
                    )
                # print "get output type %r" % (default_dataset_info,)
                return default_dataset_info
        return XMLParsingBufferMixin.xml_default_dataset_info(self, node)

#---- registration


def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=XSLTLexer(),
                      buf_class=XSLTBuffer,
                      import_handler_class=None,
                      cile_driver_class=None,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = lang_xul
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""XUL support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin


#---- globals

lang = "XUL"
log = logging.getLogger("codeintel.xul")


#---- language support
class XULLexer(UDLLexer):
    lang = lang


class XULBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = "XUL"
    m_lang = "XML"
    css_lang = "CSS"
    csl_lang = "JavaScript"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: ">'\" "
    # - wanted for CSS completion: " ('\";},.>"
    # - wanted for JS completion:  "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "<!<|>" -> "<![CDATA[" cpln
    cpln_stop_chars = "'\" (;},~`!@#%^&*()-=+{}]|\\;,.<>?/"


class XULCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=XULLexer(),
                      buf_class=XULBuffer,
                      import_handler_class=None,
                      cile_driver_class=XULCILEDriver,
                      is_cpln_lang=True)

########NEW FILE########
__FILENAME__ = manager
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""The "Manager" is the controlling instance for a codeintel system."""

import os
from os.path import dirname, join, abspath, splitext, basename, isabs
import sys
import imp
import logging
from collections import defaultdict
from glob import glob
import threading
from Queue import Queue
import warnings
import traceback
import codecs

from SilverCity import ScintillaConstants

import codeintel2
from codeintel2.common import *
from codeintel2.accessor import *
from codeintel2.citadel import Citadel, BinaryBuffer
from codeintel2.buffer import ImplicitBuffer
from codeintel2.langintel import ImplicitLangIntel
from codeintel2.database.database import Database
from codeintel2.environment import DefaultEnvironment
from codeintel2 import indexer
from codeintel2.util import guess_lang_from_path
from codeintel2 import hooks
from codeintel2.udl import XMLParsingBufferMixin, UDLBuffer

import langinfo

if _xpcom_:
    from xpcom.server import UnwrapObject


#---- global variables
log = logging.getLogger("codeintel.manager")
# log.setLevel(logging.INFO)


#---- public interface
class Manager(threading.Thread, Queue):
    # See the module docstring for usage information.

    def __init__(self, db_base_dir=None, on_scan_complete=None,
                 extra_module_dirs=None, env=None,
                 db_event_reporter=None, db_catalog_dirs=None,
                 db_import_everything_langs=None):
        """Create a CodeIntel manager.

            "db_base_dir" (optional) specifies the base directory for
                the codeintel database. If not given it will default to
                '~/.codeintel'.
            "on_scan_complete" (optional) is a callback for Citadel scan
                completion. It will be passed the ScanRequest instance
                as an argument.
            "extra_module_dirs" (optional) is a list of extra dirs
                in which to look for and use "codeintel_*.py"
                support modules (and "lang_*.py" modules, DEPRECATED).
            "env" (optional) is an Environment instance (or subclass).
                See environment.py for details.
            "db_event_reporter" (optional) is a callback that will be called
                    db_event_reporter(<event-desc-string>)
                before "significant" long processing events in the DB. This
                may be useful to forward to a status bar in a GUI.
            "db_catalog_dirs" (optional) is a list of catalog dirs in
                addition to the std one to use for the CatalogsZone. All
                *.cix files in a catalog dir are made available.
            "db_import_everything_langs" (optional) is a set of langs for which
                the extra effort to support Database
                `lib.hits_from_lpath()' should be made. See class
                Database for more details.
        """
        threading.Thread.__init__(self, name="CodeIntel Manager")
        self.setDaemon(True)
        Queue.__init__(self)

        self.citadel = Citadel(self)

        # Module registry bits.
        self._registered_module_canon_paths = set()
        self.silvercity_lexer_from_lang = {}
        self.buf_class_from_lang = {}
        self.langintel_class_from_lang = {}
        self._langintel_from_lang_cache = {}
        self.import_handler_class_from_lang = {}
        self._is_citadel_from_lang = {
        }  # registered langs that are Citadel-based
        self._is_cpln_from_lang = {
        }  # registered langs for which completion is supported
        self._hook_handlers_from_lang = defaultdict(list)

        self.env = env or DefaultEnvironment()
        # The database must be enabled before registering modules.
        self.db = Database(self, base_dir=db_base_dir,
                           catalog_dirs=db_catalog_dirs,
                           event_reporter=db_event_reporter,
                           import_everything_langs=db_import_everything_langs)

        self.lidb = langinfo.get_default_database()
        self._register_modules(extra_module_dirs)

        self.idxr = indexer.Indexer(self, on_scan_complete)

    def upgrade(self):
        """Upgrade the database, if necessary.

        It blocks until the upgrade is complete.  Alternatively, if you
        want more control over upgrading use:
            Database.upgrade_info()
            Database.upgrade()
            Database.reset()
        """
        log.debug("upgrade db if necessary")
        status, reason = self.db.upgrade_info()
        if status == Database.UPGRADE_NECESSARY:
            log.info("db upgrade is necessary")
            self.db.upgrade()
        elif status == Database.UPGRADE_NOT_POSSIBLE:
            log.warn("%s (resetting db)", reason)
            log.info("reset db at `%s' (creating backup)", self.db.base_dir)
            self.db.reset()
        elif status == Database.UPGRADE_NOT_NECESSARY:
            log.debug("no upgrade necessary")
        else:
            raise CodeIntelError("unknown db upgrade status: %r" % status)

    def initialize(self):
        """Initialize the codeintel system."""
        # TODO: Implement DB cleaning.
        # self.db.clean()
        self.idxr.start()

    def _register_modules(self, extra_module_dirs=None):
        """Register codeintel/lang modules.

        @param extra_module_dirs {sequence} is an optional list of extra
            dirs in which to look for and use "codeintel|lang_*.py"
            support modules. By default just the codeintel2 package
            directory is used.
        """
        dirs = [dirname(__file__)]
        if extra_module_dirs:
            dirs += extra_module_dirs

        import_hook = self._ImportHook(
            self._registered_module_canon_paths.union(dirs))
        sys.meta_path.append(import_hook)

        try:
            for dir in dirs:
                for module_path in glob(join(dir, "codeintel_*.py")):
                    self._register_module(module_path)
                for module_path in glob(join(dir, "lang_*.py")):
                    warnings.warn("%s: `lang_*.py' codeintel modules are deprecated, "
                                  "use `codeintel_*.py'. Support for `lang_*.py' "
                                  "will be dropped in Komodo 5.1." % module_path,
                                  CodeIntelDeprecationWarning)
                    self._register_module(module_path)
        finally:
            sys.meta_path.remove(import_hook)

    class _ImportHook(object):
        """This is an import hook for __import__ to look for modules in the
        extra module paths as necessary.  This is needed because a bunch of the
        modules assume they're in the codeintel2 package.
        """

        _suffixes = None

        def __init__(self, paths):
            """Create an import hook
            @param paths {set} The paths to scan in
            """
            self._paths = paths
            self._cache = None

        def find_module(self, fullname, path=None):
            parts = fullname.split(".")
            if len(parts) != 2 or parts[0] != "codeintel2":
                return None
            name = parts[-1]
            for path in self._paths:
                fullpath = join(path, name + ".py")
                if not os.path.exists(fullpath):
                    continue
                self._cache = fullpath
                return self

        def load_module(self, fullname):
            if fullname in sys.modules:
                return sys.modules[fullname]
            parts = fullname.split(".")
            if len(parts) != 2 or parts[0] != "codeintel2":
                raise ImportError("Did not expect to handle import for %s" %
                                  fullname)
            name = parts[-1]
            if self._cache and basename(self._cache) == name + ".py":
                fullpath = self._cache
            else:
                # stale cache
                for path in self._paths:
                    fullpath = join(path, name + ".py")
                    if os.path.exists(fullpath):
                        break
                else:
                    raise ImportError("Failed to locate %s" % fullname)

            try:
                module = imp.load_source(fullname, fullpath)
                sys.modules[fullname] = module
                setattr(codeintel2, name, module)
                return module
            except:
                log.exception("Failed to load %s", fullpath)
                raise

    def _register_module(self, module_path):
        """Register the given codeintel support module.

        @param module_path {str} is the path to the support module.
        @exception ImportError, CodeIntelError

        This will import the given module path and call its top-level
        `register` function passing it the Manager instance. That is
        expected to callback to one or more of:
            mgr.set_lang_info(...)
            mgr.add_hooks_handler(...)
        """
        module_canon_path = canonicalizePath(module_path)
        if module_canon_path in self._registered_module_canon_paths:
            return

        module_dir, module_name = os.path.split(module_path)
        module_name = splitext(module_name)[0]
        module_full_name = "codeintel2." + module_name
        if module_full_name in sys.modules:
            module = sys.modules[module_full_name]
        else:
            iinfo = imp.find_module(module_name, [module_dir])
            module = imp.load_module(module_name, *iinfo)
            sys.modules[module_full_name] = module
            setattr(codeintel2, module_name, module)

        if hasattr(module, "register"):
            log.debug("register `%s' support module", module_path)
            try:
                module.register(self)
            except CodeIntelError, ex:
                log.warn("error registering `%s' support module: %s",
                         module_path, ex)
            except:
                log.exception("unexpected error registering `%s' "
                              "support module", module_path)

        self._registered_module_canon_paths.add(module_canon_path)

    def set_lang_info(self, lang, silvercity_lexer=None, buf_class=None,
                      import_handler_class=None, cile_driver_class=None,
                      is_cpln_lang=False, langintel_class=None,
                      import_everything=False):
        """Called by register() functions in language support modules."""
        if silvercity_lexer:
            self.silvercity_lexer_from_lang[lang] = silvercity_lexer
        if buf_class:
            self.buf_class_from_lang[lang] = buf_class
        if langintel_class:
            self.langintel_class_from_lang[lang] = langintel_class
        if import_handler_class:
            self.import_handler_class_from_lang[lang] = import_handler_class
        if cile_driver_class is not None:
            self._is_citadel_from_lang[lang] = True
            self.citadel.set_lang_info(lang, cile_driver_class,
                                       is_cpln_lang=is_cpln_lang)
        if is_cpln_lang:
            self._is_cpln_from_lang[lang] = True
        if import_everything:
            self.db.import_everything_langs.add(lang)

    def add_hook_handler(self, hook_handler):
        """Add a handler for various codeintel hooks.

        @param hook_handler {hooks.HookHandler}
        """
        assert isinstance(hook_handler, hooks.HookHandler)
        assert hook_handler.name is not None, \
            "hook handlers must have a name: %r.name is None" % hook_handler
        for lang in hook_handler.langs:
            self._hook_handlers_from_lang[lang].append(hook_handler)

    def finalize(self, timeout=None):
        if self.citadel is not None:
            self.citadel.finalize()
        if self.isAlive():
            self.stop()
            self.join(timeout)
        self.idxr.finalize()
        if self.db is not None:
            try:
                self.db.save()
            except Exception:
                log.exception("error saving database")
            self.db = None  # break the reference

    # Proxy the batch update API onto our Citadel instance.
    def batch_update(self, join=True, updater=None):
        return self.citadel.batch_update(join=join, updater=updater)

    def report_message(self, msg, details=None, notification_name="codeintel-message"):
        """Reports a unique codeintel message."""
        log.info("%s: %s: %r", notification_name, msg, details)

    def is_multilang(self, lang):
        """Return True iff this is a multi-lang language.

        I.e. Is this a language that supports embedding of different
        programming languages. For example RHTML can have Ruby and
        JavaScript content, HTML can have JavaScript content.
        """
        try:
            return issubclass(self.buf_class_from_lang[lang], UDLBuffer)
        except KeyError:
            return False  # This typically happens if lang is Text

    def is_xml_lang(self, lang):
        try:
            buf_class = self.buf_class_from_lang[lang]
        except KeyError:
            return False
        return issubclass(buf_class, XMLParsingBufferMixin)

    def is_cpln_lang(self, lang):
        """Return True iff codeintel supports completion (i.e. autocomplete
        and calltips) for this language."""
        return lang in self._is_cpln_from_lang

    def get_cpln_langs(self):
        return self._is_cpln_from_lang.keys()

    def is_citadel_lang(self, lang):
        """Returns True if the given lang has been registered and
        is a Citadel-based language.

        A "Citadel-based" language is one that uses CIX/CIDB/CITDL tech for
        its codeintel. Note that currently not all Citadel-based langs use
        the Citadel system for completion (e.g. Tcl).
        """
        return lang in self._is_citadel_from_lang

    def get_citadel_langs(self):
        return self._is_citadel_from_lang.keys()

    def langintel_from_lang(self, lang):
        if lang not in self._langintel_from_lang_cache:
            try:
                langintel_class = self.langintel_class_from_lang[lang]
            except KeyError:
                langintel = ImplicitLangIntel(lang, self)
            else:
                langintel = langintel_class(self)
            self._langintel_from_lang_cache[lang] = langintel
        return self._langintel_from_lang_cache[lang]

    def hook_handlers_from_lang(self, lang):
        return self._hook_handlers_from_lang.get(lang, []) \
            + self._hook_handlers_from_lang.get("*", [])

    # XXX
    # XXX Cache bufs based on (path, lang) so can share bufs. (weakref)
    # XXX
    def buf_from_koIDocument(self, doc, env=None):
        lang = doc.language
        path = doc.displayPath
        if doc.isUntitled:
            path = join("<Unsaved>", path)
        accessor = KoDocumentAccessor(doc,
                                      self.silvercity_lexer_from_lang.get(lang))
        encoding = doc.encoding.python_encoding_name
        try:
            buf_class = self.buf_class_from_lang[lang]
        except KeyError:
            # No langintel is defined for this class, check if the koILanguage
            # defined is a UDL koILanguage.
            from koUDLLanguageBase import KoUDLLanguage
            if isinstance(UnwrapObject(doc.languageObj), KoUDLLanguage):
                return UDLBuffer(self, accessor, env, path, encoding, lang=lang)
            # Not a UDL language - use the implicit buffer then.
            return ImplicitBuffer(lang, self, accessor, env, path, encoding)
        else:
            buf = buf_class(self, accessor, env, path, encoding)
        return buf

    def buf_from_content(self, content, lang, env=None, path=None,
                         encoding=None):
        lexer = self.silvercity_lexer_from_lang.get(lang)
        accessor = SilverCityAccessor(lexer, content)
        try:
            buf_class = self.buf_class_from_lang[lang]
        except KeyError:
            buf = ImplicitBuffer(lang, self, accessor, env, path, encoding)
        else:
            buf = buf_class(self, accessor, env, path, encoding)
        return buf

    def binary_buf_from_path(self, path, lang=None, env=None):
        buf = BinaryBuffer(lang, self, env, path)
        return buf

    MAX_FILESIZE = 1 * 1024 * 1024   # 1MB

    def buf_from_path(self, path, lang=None, env=None, encoding=None):
        # Detect and abort on large files - to avoid memory errors, bug 88487.
        # The maximum size is 1MB - someone uses source code that big?
        filestat = os.stat(path)
        if filestat.st_size > self.MAX_FILESIZE:
            log.warn(
                "File %r has size greater than 1MB (%d)", path, filestat.st_size)
            raise CodeIntelError('File too big. Size: %d bytes, path: %r' % (
                                 filestat.st_size, path))

        if lang is None or encoding is None:
            import textinfo
            ti = textinfo.textinfo_from_path(path, encoding=encoding,
                                             follow_symlinks=True)
            if lang is None:
                lang = (hasattr(ti.langinfo, "komodo_name")
                        and ti.langinfo.komodo_name
                        or ti.langinfo.name)
            if not ti.is_text:
                return self.binary_buf_from_path(path, lang, env)
            encoding = ti.encoding
            content = ti.text
        else:
            content = codecs.open(path, 'rb', encoding).read()

        # TODO: Re-instate this when have solution for CILE test failures
        #      that this causes.
        # if not isabs(path) and not path.startswith("<Unsaved>"):
        #    path = abspath(path)

        return self.buf_from_content(content, lang, env, path, encoding)

    #---- Completion Evaluation Session/Queue handling
    # The current eval session (an Evaluator instance). A current session's
    # lifetime is as follows:
    # - [self._get()] Starts when the evaluator thread (this class) takes it
    #   off the queue.
    # - [self._put()] Can be aborted (via sess.ctlr.abort()) if a new eval
    #   request comes in.
    # - [eval_sess.eval()] Done when the session completes either by
    #   (1) an unexpected error during sess.eval() or (2) sess.ctlr.is_done()
    #   after sess.eval().
    _curr_eval_sess = None

    def request_eval(self, evalr):
        """Request evaluation of the given completion.

            "evalr" is the Evaluator instance.

        The manager has an evaluation thread on which this evalr will be
        scheduled. Only one request is ever eval'd at one time. A new
        request will cause an existing on to be aborted and requests made in
        the interim will be trumped by this new one.

        Dev Notes:
        - XXX Add a timeout to the put and raise error on timeout?
        """
        # evalr.eval(self)
        self.put((evalr, False))

    def request_reeval(self, evalr):
        """Occassionally evaluation will need to defer until something (e.g.
        scanning into the CIDB) is one. These sessions will re-request
        evaluation via this method.
        """
        self.put((evalr, True))

    def stop(self):
        self.put((None, None))  # Sentinel to tell thread mainloop to stop.

    def run(self):
        while 1:
            eval_sess, is_reeval = self.get()
            if eval_sess is None:  # Sentinel to stop.
                break
            try:
                eval_sess.eval(self)
            except:
                try:
                    self._handle_eval_sess_error(eval_sess)
                except:
                    pass
            finally:
                self._curr_eval_sess = None
        self.db.report_event(None)

    def _handle_eval_sess_error(self, eval_sess):
        exc_info = sys.exc_info()
        tb_path, tb_lineno, tb_func \
            = traceback.extract_tb(exc_info[2])[-1][:3]
        if hasattr(exc_info[0], "__name__"):
            exc_str = "%s: %s" % (exc_info[0].__name__, exc_info[1])
        else:  # string exception
            exc_str = exc_info[0]
        eval_sess.ctlr.error("error evaluating %s: %s "
                             "(%s#%s in %s)", eval_sess, exc_str,
                             tb_path, tb_lineno, tb_func)
        log.exception("error evaluating %s" % eval_sess)
        eval_sess.ctlr.done("unexpected eval error")

    def _put(self, (eval_sess, is_reeval)):
        # Only consider re-evaluation if we are still on the same eval
        # session.
        if is_reeval and self._curr_eval_sess is not eval_sess:
            return

        replace = True
        if hasattr(eval_sess, "ctlr") and eval_sess.ctlr and eval_sess.ctlr.keep_existing:
            # Allow multiple eval sessions; currently used for variable
            # highlighting (bug 80095), may pick up additional uses.  Note that
            # these sessions can still get wiped out by a single replace=False
            # caller.
            replace = False

        if replace:
            # We only allow *one* eval session at a time.
            # - Drop a possible accumulated eval session.
            if len(self.queue):
                self.queue.clear()
            ## - Abort the current eval session.
            if not is_reeval and self._curr_eval_sess is not None:
                self._curr_eval_sess.ctlr.abort()

        # Lazily start the eval thread.
        if not self.isAlive():
            self.start()

        Queue._put(self, (eval_sess, is_reeval))
        if replace:
            assert len(self.queue) == 1

    def _get(self):
        eval_sess, is_reeval = Queue._get(self)
        if is_reeval:
            assert self._curr_eval_sess is eval_sess
        else:
            self._curr_eval_sess = eval_sess
        return eval_sess, is_reeval

########NEW FILE########
__FILENAME__ = controller
#!/usr/bin/env python2

import codeintel2.common
from codeintel2.common import EvalController
import logging
import cStringIO
import pprint

log = logging.getLogger("codeintel.oop.controller")


class OOPEvalController(EvalController):
    """Eval controller for out-of-process codeintel
    """

    have_errors = have_warnings = False
    silent = False

    def __init__(self, driver=None, request=None, trg=None, *args, **kwargs):
        """Create an eval controller
        @param driver {Driver} The OOP driver instance to communicate via
        @param request {Request} The request causing the evaluation
        """
        log.debug("__init__")
        EvalController.__init__(self, *args, **kwargs)

        self.driver = driver
        self.request = request
        self.trg = trg
        self.silent = request.get("silent", False)
        self.keep_existing = request.get("keep_existing", self.keep_existing)

        # Set up a *new* logger to record any errors
        # Note that the output will be discarded if there is no error
        self.log_stream = cStringIO.StringIO()
        self.log_hndlr = logging.StreamHandler(self.log_stream)
        loggerClass = logging.Logger.manager.loggerClass
        if not loggerClass:
            loggerClass = logging.getLoggerClass()
        self.log = loggerClass("codeintel.evaluator")
        self.log.manager = logging.Logger.manager
        self.log.propagate = False
        self.log.addHandler(self.log_hndlr)
        self.best_msg = (0, "")

    def close(self):
        log.debug("close")
        EvalController.close(self)

    def set_desc(self, desc):
        log.debug("set_desc: %s", desc)
        EvalController.set_desc(self, desc)

        if not self.silent:
            self.log.error("error evaluating %s:\n  trigger: %s\n  log:",
                           desc, self.trg)
            # Reset the formatter to be minimal
            fmt = logging.Formatter(fmt="    %(levelname)s: %(message)s")
            self.log_hndlr.setFormatter(fmt)

    def setStatusMessage(self, msg, highlight):
        log.debug("setStatusMessage: %s, %s", msg, highlight)
        self.driver.send(request=self.request, success=None,
                         message=msg, highlight=highlight)

    def abort(self):
        log.debug("abort: %r", self.request)
        if self.is_aborted:
            # Controllers don't abort immediately; this is in the process of
            # aborting but hasn't finished yet
            log.debug("Suppressing repeat abort message: %r", self.request)
            return
        EvalController.abort(self)
        self.driver.fail(request=self.request, msg="aborted")

    def done(self, reason):
        log.debug("done: %s %s", reason,
                  "(aborted)" if self.is_aborted() else "")

        retrigger = self.trg.retriggerOnCompletion if self.trg else False

        if self.cplns:
            # Report completions
            self.driver.send(cplns=self.cplns, request=self.request,
                             retrigger=retrigger)
        elif self.calltips:
            self.driver.send(calltip=self.calltips[0], request=self.request,
                             retrigger=retrigger)
        elif self.defns:
            # We can't exactly serialize blobs directly...
            def defn_serializer(defn):
                return defn.__dict__
            self.driver.send(defns=map(defn_serializer, self.defns or []),
                             request=self.request, retrigger=retrigger)
        elif self.is_aborted():
            pass  # already reported the abort
        elif self.best_msg[0]:
            try:
                msg = "No %s found" % (self.desc,)
                if self.have_errors:
                    msg = self.best_msg[
                        1] + " (error determining %s)" % (self.desc,)
                    self.driver.report_error(self.log_stream.getvalue())
                elif self.have_warnings:
                    msg += "(warning: %s)" % (self.best_msg[1],)
            except TypeError as ex:
                # Guard against this common problem in log formatting above:
                #   TypeError: not enough arguments for format string
                log.exception(
                    "problem logging eval failure: self.log=%r", self.log_entries)
                msg = "error evaluating '%s'" % desc
            self.driver.fail(request=self.request, message=msg)
        else:
            # ERROR
            self.driver.fail(request=self.request, msg=reason)

        self.log = log  # If we have any more problems, put it in the main log
        self.log_stream.close()
        EvalController.done(self, reason)

    def setup_log(self):
        if not self.desc:
            desc = {codeintel2.common.TRG_FORM_CPLN: "completions",
                    codeintel2.common.TRG_FORM_CALLTIP: "calltip",
                    codeintel2.common.TRG_FORM_DEFN: "definition",
                    }.get(self.trg.form, "???")
            self.set_desc(desc)

    def debug(self, msg, *args):
        if self.silent:
            return
        self.setup_log()
        self.log.debug(msg, *args)
        if self.best_msg[0] < logging.DEBUG:
            self.best_msg = (logging.DEBUG, msg % args)

    def info(self, msg, *args):
        if self.silent:
            return
        self.setup_log()
        self.log.info(msg, *args)
        if self.best_msg[0] < logging.INFO:
            self.best_msg = (logging.INFO, msg % args)

    def warn(self, msg, *args):
        if self.silent:
            return
        self.setup_log()
        self.log.warn(msg, *args)
        if self.best_msg[0] < logging.WARN:
            self.best_msg = (logging.WARN, msg % args)
        self.have_warnings = True

    def error(self, msg, *args):
        if self.silent:
            return
        self.setup_log()
        self.log.error(msg, *args)
        if self.best_msg[0] < logging.ERROR:
            self.best_msg = (logging.ERROR, msg % args)
        self.have_errors = True

########NEW FILE########
__FILENAME__ = driver
#!/usr/bin/env python2

try:
    # codeintel will attempt to import xpcom; make sure that's working by
    # explicitly importing xpcom._xpcom, otherwise xpcom.xpt will fail to
    # import
    import xpcom
    import xpcom._xpcom
except ImportError:
    pass

import codeintel2.accessor
import codeintel2.buffer
import codeintel2.common
import codeintel2.indexer
import codeintel2.udl
from codeintel2.database.database import Database, DatabaseError
import codeintel2.environment
import collections
import functools
import imp
import itertools
import json
import logging
import os.path
import Queue
import shutil
import sys
import threading
import traceback
import uuid
from . import controller
from os.path import abspath, normcase, normpath

log = logging.getLogger("codeintel.oop.driver")


class RequestFailure(Exception):
    """ An exception to indicate a request failure
    Raising this exception is equivalent of aborting the current (synchronous)
    request processing and calling Driver.fail().  All arguments are the same as
    when using Driver.fail().
    """
    def __init__(self, *args, **kwargs):
        Exception.__init__(self)
        self.args = args
        self.kwargs = kwargs


class CommandHandler(object):
    """Interface for a class that handles commands from the driver; this may
    choose to be stateless"""

    supportedCommands = []
    """Iterable of commands this handler supports; each item is a string naming
    the command to handle, e.g. "halt-and-catch-fire"."""

    def canHandleRequest(self, request):
        """Double-check if this handler can handle the given request.  This will
        only be called if multiple handlers claim to be able to handle the same
        command; might be useful, for example, if some handlers are language-
        specific.
        @param request {Request} The request to handle.
        @return {bool} Whether this handler can handle the given request.
        """
        raise NotImplementedError

    def handleRequest(self, request, driver):
        """Handle a given request.  No return value is expected; the handler
        should call driver.send() at some point to indicate handle completion
        (or one of the helpers that eventually call driver.send).
        @param request {Request} The request to handle; request.command will be
            a command this handler claims to be able to handle.
        @return None
        @note This is executed on a different thread than where communication
            happens; the implementation is expected to (but doesn't have to)
            block.  Exceptions here will be caught and communicated to the host
            process as a command failure.
        """
        raise NotImplementedError


class LoggingHandler(logging.Handler):
    """Log handler class to forward messages to the main process"""

    def __init__(self, driver):
        logging.Handler.__init__(self)
        self._driver = driver

    def emit(self, record):
        """Emit a record.  Do this over the driver's normal pipe."""
        try:
            if record.levelno < logging.WARNING:
                # Don't log info/debug records. We can look at codeinte.log for
                # those.  This gets especially bad when logging what's being
                # sent over the wire...
                return
            self._driver.send(request=None,
                              command="report-message",
                              type="logging",
                              name=record.name,
                              message=self.format(record),
                              level=record.levelno)
        except (KeyboardInterrupt, SystemExit):
            raise
        except:
            self.handleError(record)


class Driver(threading.Thread):
    """
    Out-of-process codeintel2 driver
    This class implements the main loop of the codeintel worker process
    This should be a singleton object
    """

    # static
    _instance = None
    _command_handler_map = collections.defaultdict(list)
    """Registered command handlers; the key is the command name (a str), and the
    value is a list of command handler instances or (for lazy handlers) a
    single-element tuple containing the callable to get the real handler."""
    _default_handler = None
    """The default (core) command handler; instance of a CoreHandler"""
    _builtin_commands = {}
    """Built-in commands that cannot be overridden"""

    def __init__(self, db_base_dir=None, fd_in=sys.stdin, fd_out=sys.stdout):
        threading.Thread.__init__(self, name="Codeintel OOP Driver")
        assert Driver._instance is None, "Driver should be a singleton"
        Driver._instance = self
        logging.root.addHandler(LoggingHandler(self))
        self.daemon = True

        self.fd_in = fd_in
        self.fd_out = fd_out
        self.abort = None
        self.quit = False
        self.buffers = {}  # path to Buffer objects
        self.next_buffer = 0
        self.active_request = None

        self.send_queue = Queue.Queue()
        self.send_thread = threading.Thread(target=self._send_proc)
        self.send_thread.daemon = True
        self.send_thread.start()

        self.queue = collections.deque()
        self.queue_cv = threading.Condition()
        self.env = Environment(name="global",
                               send_fn=functools.partial(self.send, request=None))

        # Fill out the non-overridable build-in commands
        self._builtin_commands = {}
        for attr in dir(self):
            # Note that we check startswith first to avoid getters etc.
            if attr.startswith("do_") and callable(getattr(self, attr)):
                command = attr[len("do_"):].replace("_", "-")
                self._builtin_commands[command] = getattr(self, attr)

        from codeintel2.manager import Manager
        log.debug("using db base dir %s", db_base_dir)
        self.mgr = Manager(db_base_dir=db_base_dir,
                           db_catalog_dirs=[],
                           db_event_reporter=self._DBEventReporter(self),
                           env=self.env,
                           on_scan_complete=self._on_scan_complete)
        self.mgr.initialize()

    def _on_scan_complete(self, scan_request):
        if scan_request.status in ("changed", "skipped"):
            # Send unsolicited response about the completed scan
            buf = scan_request.buf
            self.send(request=None,
                      path=buf.path,
                      language=buf.lang,
                      command="scan-complete")

    class _DBEventReporter(object):
        def __init__(self, driver):
            self.driver = driver
            self.log = log.getChild("DBEventReporter")
            self.debug = self.log.debug

            # directories being scanned (completed or not)
            # key is unicode path, value is number of times it's active
            self._dirs = collections.defaultdict(int)
            # directories which are complete (unicode path)
            self._completed_dirs = set()

        def send(self, **kwargs):
            self.driver.send(request=None, command="report-message", **kwargs)

        def __call__(self, message):
            """Old-style status messages before long-running jobs
            @param msg {str or None} The message to display
            """
            if len(self._dirs):
                return  # ignore old-style db events if we're doing a scan
            self.debug("db event: %s", message)
            self.send(message=message)

        def onScanStarted(self, description, dirs=set()):
            """Called when a directory scan is about to start
            @param description {unicode} A string suitable for showing the user
                about the upcoming operation
            @param dirs {set of unicode} The directories about to be scanned
            """
            self.debug("scan started: %s (%s dirs)", description, len(dirs))

            assert dirs, "onScanStarted expects non-empty directories"
            if not dirs:  # empty set - we shouldn't have gotten here, but be nice
                return
            for dir_path in dirs:
                self._dirs[dir_path] += 1
            self.send(type="scan-progress", message=description,
                      completed=len(self._completed_dirs),
                      total=len(self._dirs))

        def onScanDirectory(self, description, dir_path, current=None, total=None):
            """Called when a directory is being scanned (out of possibly many)
            @param description {unicode} A string suitable for showing the user
                    regarding the progress
            @param dir {unicode} The directory currently being scanned
            @param current {int} The current progress
            @param total {int} The total number of directories to scan in this
                    request
            """
            self.debug("scan directory: %s (%s %s/%s)",
                       description, dir_path, current, total)

            assert dir_path, "onScanDirectory got no directory"
            if dir_path:
                self._completed_dirs.add(dir_path)
            self.send(type="scan-progress", message=description,
                      completed=len(self._completed_dirs),
                      total=len(self._dirs))

        def onScanComplete(self, dirs=set(), scanned=set()):
            """Called when a scan operation is complete
            @param dirs {set of unicode} The directories that were intially
                   requested to be scanned (as pass in onScanStarted)
            @param scanned {set of unicode} Directories which were successfully
                   scanned.  This may be a subset of dirs if the scan was
                   aborted.
            """
            self.debug("scan complete: scanned %r/%r dirs",
                       len(scanned), len(dirs))

            for dir_path in dirs:
                self._dirs[dir_path] -= 1
                if not self._dirs[dir_path]:
                    del self._dirs[dir_path]
                    self._completed_dirs.discard(dir_path)
            self.send(
                type="scan-progress", completed=len(self._completed_dirs),
                total=len(self._dirs))

    REQUEST_DEFAULT = object()

    def send(self, request=REQUEST_DEFAULT, **kwargs):
        """
        Send a response
        """
        data = dict(kwargs)
        if request is Driver.REQUEST_DEFAULT:
            request = self.active_request
        if request:
            data["req_id"] = request.id
        if "success" not in data:
            data["success"] = True
        elif data["success"] is None:
            del data["success"]
        buf = json.dumps(data, separators=(',', ':'))
        buf_len = str(len(buf))
        log.debug("sending: %s:[%s]", buf_len, buf)
        self.send_queue.put(buf)

    def _send_proc(self):
        while True:
            buf = self.send_queue.get()
            try:
                buf_len = str(len(buf))
                self.fd_out.write(buf_len)
                self.fd_out.write(buf)
            finally:
                self.send_queue.task_done()

    def fail(self, request=REQUEST_DEFAULT, **kwargs):
        kwargs = kwargs.copy()
        if not "command" in kwargs and request:
            try:
                kwargs["command"] = request["command"]
            except KeyError:
                pass
        return self.send(request=request, success=False, **kwargs)

    def exception(self, request=REQUEST_DEFAULT, **kwargs):
        return self.fail(request=request, stack=traceback.format_exc(), **kwargs)

    def get_buffer(self, request=REQUEST_DEFAULT, path=None):
        if request is Driver.REQUEST_DEFAULT:
            request = self.active_request
        if path is None:
            if not "path" in request:
                raise RequestFailure(message="No path given to locate buffer")
            path = request.path
        if abspath(path) == path:
            # this is an actual file path, not a URL or whatever
            path = normcase(normpath(path))
        try:
            buf = self.buffers[path]
        except KeyError:
            buf = None
        else:
            if "language" in request and buf.lang != request.language:
                buf = None  # language changed, re-scan

        if not buf:
            # Need to construct a new buffer
            lang = request.get("language")
            if request.get("text") is not None:
                # pass no content; we'll reset it later
                buf = self.mgr.buf_from_content("", lang, path=path)
            else:
                # read from file
                try:
                    buf = self.mgr.buf_from_path(path, lang,
                                                 encoding=request.get("encoding"))
                except OSError:
                    # Can't read the file
                    buf = self.mgr.buf_from_content("", lang, path=path)
                assert not request.path.startswith("<"), \
                    "Can't create an unsaved buffer with no text"

        if request.get("text") is not None:
            # overwrite the buffer contents if we have new ones
            buf.accessor.reset_content(request.text)

        try:
            env = request["env"]
        except KeyError:
            pass  # no environment set, use current environment
        else:
            if env.get("env", {}) is None and env.get("prefs", []) is None:
                buf._env = None  # explicitly clearing environment
            elif buf._env:
                buf._env.update(env)
            else:
                buf._env = Environment(env, name=os.path.basename(path))

        # log.debug("Got buffer %r: [%s]", buf, buf.accessor.content)
        log.debug("Got buffer %r", buf)

        self.buffers[path] = buf
        return buf

    def do_abort(self, request):
        try:
            req_id = request["id"]
            with self.queue_cv:
                for item in self.queue:
                    if queue.get("req_id") == req_id:
                        self.queue.remove(queue)
                        self.send(request=request)
                        break
                else:
                    self.abort = req_id
                    if self.active_request and self.active_request.id == req_id:
                        # need to wait a bit...
                        self.send(request=request)
                    else:
                        self.fail(request=request,
                                  message="Request %s not found" % (req_id,))
        except RequestFailure as e:
            self.fail(request=request, *e.args, **e.kwargs)
        except Exception as e:
            log.exception(e.message)
            self.exception(request=request, message=e.message)

    def do_add_dirs(self, request):
        catalog_dirs = request.get("catalog-dirs", None)
        if catalog_dirs is not None:
            self.mgr.db.catalog_dirs.extend(catalog_dirs)
            catalog_dirs = self.mgr.db.catalog_dirs
        lexer_dirs = request.get("lexer-dirs", [])
        codeintel2.udl.UDLLexer.add_extra_lexer_dirs(lexer_dirs)
        module_dirs = request.get("module-dirs", [])
        if module_dirs:
            self.mgr._register_modules(module_dirs)
        if catalog_dirs is not None:
            self.mgr.db.get_catalogs_zone().catalog_dirs = catalog_dirs

    def do_load_extension(self, request):
        """Load an extension that, for example, might provide additional
        command handlers"""
        path = request.get("module-path", None)
        if not path:
            raise RequestFailure(msg="load-extension requires a module-path")
        name = request.get("module-name", None)
        if not name:
            raise RequestFailure(msg="load-extension requires a module-name")
        iinfo = imp.find_module(name, [path])
        try:
            module = imp.load_module(name, *iinfo)
        finally:
            if iinfo and iinfo[0]:
                iinfo[0].close()
        callback = getattr(module, "registerExtension", None)
        if not callback:
            raise RequestFailure(msg="load-extension module %s should "
                                     "have a 'registerExtension' method "
                                     "taking no arguments" % (name,))
        callback()
        self.send()  # success, finally

    def do_quit(self, request):
        self.quit = True
        self.send(command="quit")

    def report_error(self, message):
        self.send(request=None,
                  command="report-error",
                  message=unicode(message))

    def start(self):
        """Start reading from the socket and dump requests into the queue"""
        log.info("Running codeintel driver...")
        buf = ""
        self.send(success=None)
        self.daemon = True
        threading.Thread.start(self)
        while not self.quit:
            try:
                ch = self.fd_in.read(1)
            except IOError:
                log.debug(
                    "Failed to read frame length, assuming connection died")
                self.quit = True
                break
            if len(ch) == 0:
                log.debug("Input was closed")
                self.quit = True
                break
            if ch == "{":
                size = int(buf, 10)
                try:
                    buf = ch + self.fd_in.read(
                        size - 1)  # exclude already-read {
                except IOError:
                    log.debug(
                        "Failed to read frame data, assuming connection died")
                    self.quit = True
                    break
                try:
                    buf = buf.decode("utf-8")
                except UnicodeDecodeError:
                    pass  # what :(
                try:
                    data = json.loads(buf)
                    request = Request(data)
                except Exception as e:
                    log.exception(e)
                    self.exception(message=e.message, request=None)
                    continue
                finally:
                    buf = ""
                if request.get("command") == "abort":
                    self.do_abort(request=request)
                else:
                    log.debug("queuing request %r", request)
                    with self.queue_cv:
                        self.queue.appendleft(request)
                        self.queue_cv.notify()
            elif ch in "0123456789":
                buf += ch
            else:
                raise ValueError("Invalid request data: " + ch.encode("hex"))

    def run(self):
        """Evaluate and send results back"""
        log.info("Running codeintel eval thread...")
        buf = ""
        log.debug("default supported commands: %s",
                  ", ".join(self._default_handler.supportedCommands))
        while True:
            with self.queue_cv:
                try:
                    request = self.queue.pop()
                except IndexError:
                    self.queue_cv.wait()
                    continue
            log.debug("doing request %r", request)
            try:
                self.active_request = request
                command = request.command
                # First, check abort and quit; don't allow those to be
                # overridden
                try:
                    builtin = self._builtin_commands[command]
                except KeyError:
                    pass
                else:
                    builtin(request)
                    continue
                handlers = self._command_handler_map.get(command, [])[:]
                if command in self._default_handler.supportedCommands:
                    # The default handler can deal with this, put it at the end
                    handlers.append(self._default_handler)
                for handler in handlers:
                    if isinstance(handler, tuple):
                        try:
                            real_handler = handler[0]()
                        except Exception as ex:
                            log.exception(
                                "Failed to get lazy handler for %s", command)
                            real_handler = None
                        if real_handler is None:
                            # Handler failed to instantiate, drop it
                            try:
                                self._command_handler_map[
                                    "command"].remove(handler)
                            except ValueError:
                                pass  # ... shouldn't happen, but tolerate it
                            continue
                        for handlers in self._command_handler_map.values():
                            try:
                                handlers[handlers.index(
                                    handler)] = real_handler
                            except ValueError:
                                pass  # handler not in this list
                        handler = real_handler
                    if handler.canHandleRequest(request):
                        handler.handleRequest(request, self)
                        break
                else:
                    self.fail(request=request,
                              msg="Don't know how to handle command %s" % (command,))

            except RequestFailure as e:
                self.fail(request=request, *e.args, **e.kwargs)
            except Exception as e:
                log.exception(e.message)
                self.exception(request=request, message=e.message)
            finally:
                self.active_request = None

    @classmethod
    def registerCommandHandler(cls, handlerInstance):
        """Register a command handler"""
        for command in handlerInstance.supportedCommands:
            cls._command_handler_map[command].append(handlerInstance)

    @classmethod
    def registerLazyCommandHandler(cls, supported_commands, constructor):
        """Register a lazy command handler
        @param supported_commands {iterable} The commands to handle; each
            element should be a str of the command name.
        @param constructor {callable} Function to be called to get the real
            command handler; it should take no arguments and return a command
            handler instance.  It may return None if the command is not
            available; it will not be asked again.
        """
        for command in supported_commands:
            cls._command_handler_map[command].append((constructor,))

    @classmethod
    def getInstance(cls):
        """Get the singleton instance of the driver"""
        return Driver._instance


class CoreHandler(CommandHandler):
    """The default command handler for core commands.
    This class is a stateless singleton.  (Other command handlers don't have to
    be)."""

    _stdlib_langs = None

    def __init__(self):
        supportedCommands = set()
        for prop in dir(self):
            if prop.startswith("do_") and callable(getattr(self, prop)):
                supportedCommands.add(prop[len("do_"):].replace("_", "-"))
        self.supportedCommands = list(supportedCommands)

    def canHandleRequest(self, request):
        return True  # we can handle any request we are registered to handle

    def handleRequest(self, request, driver):
        meth = getattr(self, "do_" + request.command.replace("-", "_"))
        meth(request, driver)

    def do_database_info(self, request, driver):
        """Figure out what kind of state the codeintel database is in"""
        try:
            if not os.path.exists(os.path.join(driver.mgr.db.base_dir, "VERSION")):
                log.debug("Database does not exist")
                driver.send(state="preload-needed")
                return
            if not os.path.isdir(os.path.join(driver.mgr.db.base_dir, "db", "stdlibs")):
                log.debug("Database does not have stdlibs")
                driver.send(state="preload-needed")
                return
            driver.mgr.db.check()
            state, details = driver.mgr.db.upgrade_info()
            if state == Database.UPGRADE_NOT_NECESSARY:
                # we _might_ need to deal with the stdlib stuff.
                # assume that having one stdlib per language is good enough
                std_libs = driver.mgr.db.get_stdlibs_zone()
                std_lib_langs = set()
                for lang in self._get_stdlib_langs(driver):
                    for ver, name in std_libs.vers_and_names_from_lang(lang):
                        lib_path = os.path.join(std_libs.base_dir, name)
                        if os.path.exists(lib_path):
                            break
                    else:
                        log.debug("no stdlib found for %s", lang)
                        driver.send(state="preload-needed")
                        break
                else:
                    driver.send(state="ready")
            elif state == Database.UPGRADE_NECESSARY:
                driver.send(state="upgrade-needed")
            elif state == Database.UPGRADE_NOT_POSSIBLE:
                driver.send(state="upgrade-blocked", **{
                            "state-detail": details})
        except Exception:
            log.exception("Error looking up database info")
            driver.send(state="broken",
                        state_detail="Unexpected error getting DB upgrade info")

    def do_database_reset(self, request, driver):
        driver.mgr.db.reset(backup=False)
        driver.send()

    def do_database_upgrade(self, request):
        """Upgrade the database to the current version"""
        try:
            driver.mgr.db.upgrade()
        except DatabaseError as ex:
            errmsg = ("Could not upgrade your Code Intelligence Database "
                      "because: %s. Your database will be backed up "
                      "and a new empty database will be created." % ex)
            driver.exception(message=errmsg)
        except:
            errmsg = ("Unexpected error upgrading your database. "
                      "Your database will be backed up "
                      "and a new empty database will be created.")
            driver.exception(message=errmsg, detail=traceback.format_exc())
        else:
            driver.send()

    def do_database_preload(self, request, driver):
        if not os.path.exists(os.path.join(driver.mgr.db.base_dir, "VERSION")):
            shutil.rmtree(driver.mgr.db.base_dir, ignore_errors=True)
            driver.mgr.db.create()

        progress_base = 0  # progress base for current step
        progress_max = 0  # progress max for current step

        def progress_callback(message, value):
            """Progress callback for codeintel
            @param message {str} A message to display
            @param value {int} Some number between 0 and 100"""
            progress_offset = value * (progress_max - progress_base) / 100.0
            driver.send(success=None, total=100, message=message,
                        progress=(progress_offset + progress_base))

        # Stage 1: stdlibs zone
        # Currently updates the stdlibs for languages that Komodo is
        # configured to use (first found on the PATH or set in prefs).
        driver.send(success=None, progress=0, total=100,
                    message="Pre-loading standard library data...")
        stdlibs_zone = driver.mgr.db.get_stdlibs_zone()
        if stdlibs_zone.can_preload():
            progress_max = 80
            stdlibs_zone.preload(progress_callback)
        else:
            langs = request.get("languages", None)
            if not langs:
                langs = dict(zip(self._get_stdlib_langs(driver),
                                 itertools.repeat(None)))
            progress_base = 5
            progress_incr = (80 - progress_base) / len(
                langs)  # stage 1 goes up to 80%
            for lang, version in sorted(langs.items()):
                if driver.abort == request.id:
                    raise RequestFailure(msg="Aborted", abort=True)
                progress_max = progress_base + progress_incr
                if not version:
                    # Update everything for this language
                    driver.send(
                        success=None, progress=progress_base, total=100,
                        message="%s standard library..." % (lang,))
                    stdlibs_zone.update_lang(lang, ver=None,
                                             progress_cb=progress_callback)
                else:
                    driver.send(
                        success=None, progress=progress_base, total=100,
                        message="%s %s standard library..." % (lang, version))
                    stdlibs_zone.update_lang(lang, ver=version,
                                             progress_cb=progress_callback)
                progress_base = progress_max

        # Stage 2: catalog zone
        # Preload catalogs that are enabled by default (or perhaps
        # more than that). For now we preload all of them.
        driver.send(success=None, progress=80, total=100,
                    message="Pre-loading catalogs...")
        progress_base = 80
        progress_max = 100
        catalogs_zone = driver.mgr.db.get_catalogs_zone()
        catalogs = request.get("catalogs",
                               driver.env.get_pref("codeintel_selected_catalogs", None))
        catalogs_zone.update(request.get("catalogs"),
                             progress_cb=progress_callback)

        driver.send(message="Code intelligence database pre-loaded.")

    def do_get_languages(self, request, driver):
        typ = request.get("type")
        if typ == "cpln":
            driver.send(languages=driver.mgr.get_cpln_langs())
        elif typ == "citadel":
            driver.send(languages=driver.mgr.get_citadel_langs())
        elif typ == "xml":
            driver.send(languages=filter(driver.mgr.is_xml_lang,
                                         driver.mgr.buf_class_from_lang.keys()))
        elif typ == "multilang":
            driver.send(languages=filter(driver.mgr.is_multilang,
                                         driver.mgr.buf_class_from_lang.keys()))
        elif typ == "stdlib-supported":
            driver.send(languages=self._get_stdlib_langs(driver))
        else:
            raise RequestFailure(message="Unknown language type %s" % (typ,))

    def _get_stdlib_langs(self, driver):
        if self._stdlib_langs is None:
            stdlibs_zone = driver.mgr.db.get_stdlibs_zone()
            langs = set()
            for lang in driver.mgr.buf_class_from_lang.keys():
                if stdlibs_zone.vers_and_names_from_lang(lang):
                    langs.add(lang)
            self._stdlib_langs = sorted(langs)
        return self._stdlib_langs

    def do_get_language_info(self, request, driver):
        try:
            language = request.language
        except AttributeError:
            raise RequestFailure(message="No language supplied")
        try:
            cls = driver.mgr.buf_class_from_lang[language]
        except KeyError:
            raise RequestFailure(message="Unknown language %s" % (language,))
        driver.send(**{"completion-fillup-chars": cls.cpln_fillup_chars,
                       "completion-stop-chars": cls.cpln_stop_chars})

    def do_get_available_catalogs(self, request, driver):
        zone = driver.mgr.db.get_catalogs_zone()
        catalogs = []
        for catalog in zone.avail_catalogs():
            catalogs.append({"name": catalog["name"],
                             "lang": catalog["lang"],
                             "description": catalog["description"],
                             "cix_path": catalog["cix_path"],
                             "selection": catalog.get("selection") or
                             catalog["name"] or
                             catalog["cix_path"],
                             })
        driver.send(catalogs=catalogs)

    def do_set_environment(self, request, driver):
        try:
            env = request["env"]
        except KeyError:
            pass
        else:
            driver.env.override_env(env)
        try:
            prefs = request["prefs"]
        except KeyError:
            pass
        else:
            driver.env.override_prefs(prefs)
        driver.send()

    def do_scan_document(self, request, driver):
        buf = driver.get_buffer(request)
        if not driver.mgr.is_citadel_lang(buf.lang):
            driver.send()  # Nothing to do here
            return
        if not hasattr(buf, "scan"):
            driver.send()  # Can't scan this buffer (e.g. Text)
            return
        priority = request.get("priority", codeintel2.common.PRIORITY_CURRENT)
        mtime = request.get("mtime")
        if mtime is not None:
            mtime = long(mtime)

        def on_complete():
            driver.send(request=request)

        assert buf.accessor.text is not None, \
            "No text!"

        scan_request = codeintel2.indexer.ScanRequest(buf,
                                                      priority,
                                                      mtime=mtime,
                                                      on_complete=on_complete)
        if priority <= codeintel2.common.PRIORITY_IMMEDIATE:
            delay = 0
        else:
            delay = 1.5
        driver.mgr.idxr.stage_request(scan_request, delay)

    def do_trg_from_pos(self, request, driver):
        try:
            pos = int(request.pos)
        except AttributeError:
            raise RequestFailure(message="No position given for trigger")
        buf = driver.get_buffer(request)
        if "curr-pos" in request:
            trg = buf.preceding_trg_from_pos(pos, int(request["curr-pos"]))
        elif request.get("type", None) == "defn":
            trg = buf.defn_trg_from_pos(pos, lang=None)
        else:
            trg = buf.trg_from_pos(pos, request.get("implicit", True))
        if not trg:
            driver.send(trg=None)
        else:
            data = trg.to_dict()
            data["path"] = buf.path
            driver.send(trg=data)

    def do_eval(self, request, driver):
        if not "trg" in request:
            raise RequestFailure(msg="No trigger given in request")
        buf = driver.get_buffer(request, path=request.trg["path"])
        try:
            log.debug("trigger data: %s", request.trg)
            data = dict(request.trg)
            del data["retriggerOnCompletion"]
            del data["path"]  # we tacked this on in do_trg_from_pos
            trg = codeintel2.common.Trigger(**data)
        except AttributeError:
            driver.fail(message="No trigger to evaluate")
            return
        ctlr = controller.OOPEvalController(driver, request, trg)
        log.debug("evaluating trigger: %s", trg.to_dict())
        buf.async_eval_at_trg(trg, ctlr)

    def do_calltip_arg_range(self, request, driver):
        buf = driver.get_buffer(request)
        start, end = buf.curr_calltip_arg_range(request.trg_pos,
                                                request.calltip,
                                                request.curr_pos)
        driver.send(start=start, end=end)

    def do_set_xml_catalogs(self, request, driver):
        catalogs = request["catalogs"]
        import koXMLDatasetInfo
        datasetHandler = koXMLDatasetInfo.getService()
        datasetHandler.setCatalogs(catalogs)
        driver.send(request=request)

    def do_get_xml_catalogs(self, request, driver):
        import koXMLDatasetInfo
        public = set()
        system = set()
        datasetHandler = koXMLDatasetInfo.getService()
        for catalog in datasetHandler.resolver.catalogMap.values():
            public.update(catalog.public.keys())
            system.update(catalog.system.keys())
        namespaces = datasetHandler.resolver.getWellKnownNamspaces().keys()
        driver.send(request=request,
                    public=sorted(public),
                    system=sorted(system),
                    namespaces=sorted(namespaces))

Driver._default_handler = CoreHandler()


class Request(dict):
    """
    A request from the consumer
    """
    def __init__(self, *args, **kwargs):
        dict.__init__(self, *args, **kwargs)
        if not "req_id" in self:
            raise ValueError("No request id found")
        if not "command" in self:
            raise ValueError("No command found")
        self.id = self["req_id"]

    def __getattr__(self, name):
        if name in self:
            return self[name]
        raise AttributeError

    def __repr__(self):
        return "Request(%s)" % (json.dumps(self, separators=(',', ':')),)


class Environment(codeintel2.environment.Environment):
    def __init__(self, request={}, send_fn=None, name=None):
        codeintel2.environment.Environment.__init__(self)
        log_name = filter(None, [self.__class__.__name__, name])
        self.log = log.getChild(".".join(log_name))
        self._env = dict(request.get("env", {}))
        self._prefs = [dict(level) for level in request.get("prefs", [])]
        self._observers = {}  # name -> observer
        self._send = send_fn

    def has_envvar(self, name):
        return name in self._env

    def get_envvar(self, name, default=None):
        return self._env.get(name, default)

    def get_all_envvars(self):
        return self._env.copy()

    def set_envvar(self, name, value):
        """Set an environment variable.
        @param name {str} The environment variable name
        @param value {str} The environment variable value
        """
        self._env[name] = value

    def override_env(self, env):
        """Replace the current environment with the new set
        @param env {dict} The new environment variables
        """
        self._env = env.copy()

    def has_pref(self, name):
        return any(name in level for level in self._prefs)

    def get_pref(self, name, default=None):
        for level in self._prefs:
            if name in level:
                return level[name]
        return default

    def get_all_prefs(self, name, default=None):
        return [level.get(name, default) for level in self._prefs]

    def override_prefs(self, prefs):
        """Replace the current prefs with the new set
        @param prefs {list of dict} The new preferences
        """
        changed_prefs = set()
        # All existing prefs will be removed
        changed_prefs.update(*(level.keys() for level in self._prefs))
        # Do the replacement (making a copy)
        self._prefs = [level.copy() for level in prefs]
        # All the new prefs are added
        changed_prefs.update(*(level.keys() for level in self._prefs))
        for pref in changed_prefs:
            self._notify_pref_observers(pref)

    def update(self, request):
        try:
            env = request["env"] or {}
        except KeyError:
            pass
        else:
            self.override_env(env)
        try:
            prefs = request["prefs"] or []
        except KeyError:
            pass
        else:
            self.override_prefs(prefs)

    def add_pref_observer(self, name, callback):
        self.log.debug("Adding pref observer for %s", name)
        try:
            self._observers[name].add(callback)
        except KeyError:
            self._observers[name] = set([callback])
            if self._send:
                self._send(command="global-prefs-observe",
                           add=[name])
            else:
                self.log.warn("Warning: no way to trigger new prefs")

    def remove_pref_observer(self, name, callback):
        self._observers[name].discard(callback)
        if not self._observers[name]:
            del self._observers[name]
            if self._send:
                self._send(command="global-prefs-observe",
                           remove=[name])

    def remove_all_pref_observers(self):
        if self._send:
            self._send(command="global-prefs-observe",
                       remove=self._observers.keys())
        self._observers.clear()

    def _notify_pref_observers(self, name):
        """Call pref observers for the given pref
        @param name {str} The preference name
        """
        # This operates on a snapshot of observers
        for callback in tuple(self._observers.get(name, [])):
            try:
                callback(self, name)
            except:
                log.exception("error in pref observer for pref '%s' change",
                              name)

    def __nonzero__(self):
        """This is considered not-empty if it has anything in either the
        environment or preferences.
        """
        return bool(self._env or self._prefs)


def _get_memory_reporter():
    from .memory_reporter import MemoryCommandHandler
    return MemoryCommandHandler()
Driver.registerLazyCommandHandler(("memory-report",), _get_memory_reporter)
del _get_memory_reporter

########NEW FILE########
__FILENAME__ = memory_reporter
"""
Memory reporting command handler
"""

import ctypes
import logging
import sys
from .driver import CommandHandler

log = logging.getLogger("codeintel.oop.memory-reporter")


class _BaseMemoryCommandHandler(CommandHandler):
    """Base memory report handler
    This handler supports a single command, "memory-report"; this command takes
    no arguments, and returns a single value, "memory"; this is a dictionary.
    Each key of the dictionary is a path of the memory being reported, and the
    value is yet another dictionary with the keys:
        "amount" (int): The amount being reported.
        "units" (str): Either "bytes" or "count"; quantifies the amount.
        "desc" (str): A description of this value.  Must be a sentence.
    """

    supportedCommands = ("memory-report",)

    def canHandleRequest(self, request):
        return request["command"] == "memory-report"

    def handleRequest(self, request, driver):
        assert request["command"] == "memory-report", "Invalid command"
        self.do_memory_report(request, driver)

    def do_memory_report(self, request, driver):
        log.debug("collecting memory reports")
        driver.send(memory=self._get_memory_report(driver))

    def _get_memory_report(self, driver):
        import gc
        import memutils
        gc.collect()
        total = memutils.memusage(gc.get_objects())

        def try_call(method):
            try:
                return method()
            except Exception as ex:
                log.exception(ex)
                return None

        results = {}
        for zone in driver.mgr.db.get_all_zones():
            try:
                results.update(zone.reportMemory())
            except:
                log.exception("Failed to report memory for zone %r", zone)

        for path, data in results.items():
            if path.startswith("explicit/python"):
                if data["units"] == "bytes":
                    total -= data["amount"]

        results["explicit/python/unclassified-objects"] = {
            "amount": total,
            "units": "bytes",
            "desc": "Total bytes used by Python objects.",
        }
        results["vsize"] = {
            "amount": try_call(self._get_virtual_size),
            "units": "bytes",
            "desc": "Memory mapped by the code intelligence process.",
        }
        results["resident"] = {
            "amount": try_call(self._get_resident_size),
            "units": "bytes",
            "desc": "Resident set size in the code intelligence process.",
        }
        results["heap-allocated"] = {
            "amount": try_call(self._get_heap_size),
            "units": "bytes",
            "desc": "The total size of the heap."
        }

        return results

    def _get_virtual_size(self):
        """Get the virual size of this process (everything mapped).
        @returns {long} The vsize, in bytes; or None if unavailable.
        """
        return None

    def _get_resident_size(self):
        """Get the resident set size; this is the subset of vsize that is in
        physical memory (and not mapped to a file on disk).
        @returns {long} The rss, in bytes; or None if unavailable.
        """
        return None

    def _get_heap_size(self):
        """Get the size of the heap.
        @returns {long} The size of the heap, in bytes; or None if unavailable.
        """
        return None

MemoryCommandHandler = _BaseMemoryCommandHandler

if sys.platform.startswith("win"):
    from ctypes import wintypes

    class Win32MemoryHandler(_BaseMemoryCommandHandler):
        def _get_virtual_size(self):
            class MEMORYSTATUSEX(ctypes.Structure):
                _fields_ = [("dwLength", wintypes.DWORD),
                            ("dwMemoryLoad", wintypes.DWORD),
                            ("ullTotalPhys", ctypes.c_uint64),
                            ("ullAvailPhys", ctypes.c_uint64),
                            ("ullTotalPageFile", ctypes.c_uint64),
                            ("ullAvailPageFile", ctypes.c_uint64),
                            ("ullTotalVirtual", ctypes.c_uint64),
                            ("ullAvailVirtual", ctypes.c_uint64),
                            ("ullAvailExtendedVirtual", ctypes.c_uint64)]

                def __init__(self):
                    ctypes.Structure.__init__(self)
                    self.dwLength = ctypes.sizeof(self)

            kernel32 = ctypes.WinDLL("kernel32", use_last_error=True)
            GlobalMemoryStatusEx = kernel32.GlobalMemoryStatusEx
            GlobalMemoryStatusEx.restype = wintypes.BOOL
            GlobalMemoryStatusEx.argtypes = [ctypes.POINTER(MEMORYSTATUSEX)]

            status = MEMORYSTATUSEX()
            if GlobalMemoryStatusEx(status):
                return status.ullTotalVirtual - status.ullAvailVirtual
            return None

        def _get_resident_size(self):
            class PROCESS_MEMORY_COUNTERS(ctypes.Structure):
                _fields_ = [("cb", wintypes.DWORD),
                            ("PageFaultCount", wintypes.DWORD),
                            ("PeakWorkingSetSize", ctypes.c_size_t),
                            ("WorkingSetSize", ctypes.c_size_t),
                            ("QuotaPeakPagedPoolUsage", ctypes.c_size_t),
                            ("QuotaPagedPoolUsage", ctypes.c_size_t),
                            ("QuotaPeakNonPagedPoolUsage", ctypes.c_size_t),
                            ("QuotaNonPagedPoolUsage", ctypes.c_size_t),
                            ("PagefileUsage", ctypes.c_size_t),
                            ("PeakPagefileUsage", ctypes.c_size_t)]

                def __init__(self):
                    ctypes.Structure.__init__(self)
                    self.cb = ctypes.sizeof(self)

            psapi = ctypes.WinDLL("psapi", use_last_error=True)
            GetProcessMemoryInfo = psapi.GetProcessMemoryInfo
            GetProcessMemoryInfo.restype = wintypes.BOOL
            GetProcessMemoryInfo.argtypes = [wintypes.HANDLE,
                                             ctypes.POINTER(
                                                 PROCESS_MEMORY_COUNTERS),
                                             wintypes.DWORD]
            counters = PROCESS_MEMORY_COUNTERS()
            if GetProcessMemoryInfo(-1, counters, ctypes.sizeof(counters)):
                return counters.WorkingSetSize
            return None

        def _get_heap_size(self):
            class PROCESS_HEAP_ENTRY_BLOCK(ctypes.Structure):
                _fields_ = [("hMem", wintypes.HANDLE),
                            ("dwReserved", wintypes.DWORD * 3)]

            class PROCESS_HEAP_ENTRY_REGION(ctypes.Structure):
                _fields_ = [("dwCommittedSize", wintypes.DWORD),
                            ("dwUnCommittedSize", wintypes.DWORD),
                            ("lpFirstBlock", wintypes.LPVOID),
                            ("lpLastBlock", wintypes.LPVOID)]

            class PROCESS_HEAP_ENTRY_UNION(ctypes.Union):
                _fields_ = [("Block", PROCESS_HEAP_ENTRY_BLOCK),
                            ("Region", PROCESS_HEAP_ENTRY_REGION)]

            class PROCESS_HEAP_ENTRY (ctypes.Structure):
                _anonymous_ = ("u",)
                _fields_ = [("lpData", wintypes.LPVOID),
                            ("cbData", wintypes.DWORD),
                            ("cbOverhead", wintypes.BYTE),
                            ("iRegionIndex", wintypes.BYTE),
                            ("wFlags", wintypes.WORD),
                            ("u", PROCESS_HEAP_ENTRY_UNION)]

            kernel32 = ctypes.WinDLL("kernel32", use_last_error=True)
            GetProcessHeaps = kernel32.GetProcessHeaps
            GetProcessHeaps.restype = wintypes.DWORD
            GetProcessHeaps.argtypes = [wintypes.DWORD,
                                        ctypes.POINTER(wintypes.HANDLE)]
            HeapWalk = kernel32.HeapWalk
            HeapWalk.restype = wintypes.BOOL
            HeapWalk.argtypes = [
                wintypes.HANDLE, ctypes.POINTER(PROCESS_HEAP_ENTRY)]

            heapCount = GetProcessHeaps(0, None)
            if not heapCount:
                log.error(
                    "Failed to get heap count: %r", ctypes.get_last_error())
                return None  # Failed; don't care
            heaps = (wintypes.HANDLE * heapCount)()
            heapCount = GetProcessHeaps(len(heaps), heaps)
            if heapCount == 0:
                log.error("Failed to get heaps: %r", ctypes.get_last_error())

            total_data = 0
            total_overhead = 0

            for heap in heaps[:heapCount]:
                entry = PROCESS_HEAP_ENTRY()
                entry.lpData = None
                while HeapWalk(heap, entry):
                    total_data += entry.cbData
                    total_overhead += entry.cbOverhead

            return total_data + total_overhead

    MemoryCommandHandler = Win32MemoryHandler

elif sys.platform.startswith("linux"):
    class LinuxMemoryHandler(_BaseMemoryCommandHandler):
        def __init__(self):
            super(LinuxMemoryHandler, self).__init__()
            import ctypes.util
            self.libc = ctypes.CDLL(ctypes.util.find_library("c"))

        def _get_virtual_size(self):
            try:
                with open("/proc/self/statm", "r") as f:
                    vsize, rss = f.read().split()[:2]
                    return long(vsize, 10) * self.libc.getpagesize()
            except Exception as ex:
                log.exception("Failed to get vsize: %r", ex)

        def _get_resident_size(self):
            try:
                with open("/proc/self/statm", "r") as f:
                    vsize, rss = f.read().split()[:2]
                    return long(rss, 10) * self.libc.getpagesize()
            except Exception as ex:
                log.exception("Failed to get rss: %r", ex)

        def _get_mallinfo(self):
            class mallinfo_t(ctypes.Structure):
                _fields_ = [("arena", ctypes.c_int),
                            ("ordblks", ctypes.c_int),
                            ("smblks", ctypes.c_int),
                            ("hblks", ctypes.c_int),
                            ("hblkhd", ctypes.c_int),
                            ("usmblks", ctypes.c_int),
                            ("fsmblks", ctypes.c_int),
                            ("uordblks", ctypes.c_int),
                            ("fordblks", ctypes.c_int),
                            ("keepcost", ctypes.c_int)]
            mallinfo = self.libc.mallinfo
            mallinfo.restype = mallinfo_t
            mallinfo.argtypes = []
            return mallinfo()

        def _get_heap_size(self):
            return self._get_mallinfo().arena

        def _get_memory_report(self, driver):
            results = super(
                LinuxMemoryHandler, self)._get_memory_report(driver)
            info = self._get_mallinfo()
            results["explicit/heap-overhead"] = {
                "amount": info.arena - info.uordblks - info.fordblks,
                "units": "bytes",
                "desc": "This is the memory allocator overhead.",
            }
            return results

    MemoryCommandHandler = LinuxMemoryHandler

elif sys.platform == "darwin":
    class DarwinMemoryHandler(_BaseMemoryCommandHandler):
        def _get_taskinfo(self):
            integer_t = ctypes.c_int
            natural_t = ctypes.c_uint
            vm_size_t = ctypes.c_ulong

            class time_value_t(ctypes.Structure):
                _fields_ = [("seconds", integer_t),
                            ("microseconds", integer_t)]

                def __repr__(self):
                    return "%s.%s" % (self.seconds, self.microseconds)

            policy_t = ctypes.c_int

            class task_basic_info(ctypes.Structure):
                _pack_ = 4
                _fields_ = [("suspend_count", integer_t),
                            ("virtual_size", vm_size_t),
                            ("resident_size", vm_size_t),
                            ("user_time", time_value_t),
                            ("system_time", time_value_t),
                            ("policy", policy_t)]

                def __repr__(self):
                    return repr(dict((key, getattr(self, key))
                                     for key in dir(self)
                                     if not key.startswith("_")))

            kern_return_t = ctypes.c_int
            mach_port_t = natural_t
            task_name_t = ctypes.c_uint
            task_flavor_t = ctypes.c_uint
            task_info_t = ctypes.POINTER(ctypes.c_int)
            mach_msg_type_number_t = natural_t
            TASK_BASIC_INFO_COUNT = ctypes.sizeof(
                task_basic_info) / ctypes.sizeof(natural_t)
            TASK_BASIC_INFO = 5
            KERN_SUCCESS = 0

            libkern = ctypes.CDLL("/usr/lib/system/libsystem_kernel.dylib")
            task_info = libkern.task_info
            task_info.restype = kern_return_t
            task_info.argtypes = [task_name_t,
                                  task_flavor_t,
                                  ctypes.POINTER(task_basic_info),
                                  ctypes.POINTER(mach_msg_type_number_t)]

            mach_task_self = libkern.mach_task_self
            mach_task_self.restype = mach_port_t
            mach_task_self.argtypes = []

            ti = task_basic_info()

            count = mach_msg_type_number_t(TASK_BASIC_INFO_COUNT)
            kr = task_info(mach_task_self(), TASK_BASIC_INFO,
                           ctypes.byref(ti),
                           ctypes.byref(count))
            if kr != KERN_SUCCESS:
                return None
            return ti

        def _get_virtual_size(self):
            ti = self._get_taskinfo()
            return ti.virtual_size or None if ti else None

        def _get_resident_size(self):
            ti = self._get_taskinfo()
            return ti.resident_size or None if ti else None

        def _get_heap_size(self):
            # Unforunately, I haven't found any sane ways of figuring out our
            # heap size; asking vmmap for data gives us an approximation (though
            # I'm pretty sure it's not the number we want).
            import os
            import subprocess
            stdout = subprocess.check_output(["/usr/bin/vmmap",
                                              "-pages", "-wide",
                                              str(os.getpid())])
            log.debug("stdout:\n%s", stdout)
            lines = iter(stdout.splitlines())
            header = ["MALLOC", "ZONE", "PAGES",
                      "COUNT", "ALLOCATED", "%", "FULL"]
            while lines.next().split() != header:
                pass
            for line in lines:
                if line.startswith("TOTAL "):
                    size = line.split()[3]
                    suffixes = {"B": 1,
                                "K": 1024,
                                "M": 1024 ** 2,
                                "G": 1024 ** 3,
                                "T": 1024 ** 4}
                    if size[-1] in suffixes:
                        size = float(size[:-1]) * suffixes[size[-1]]
                    else:
                        size = float(size)
                    return size

    MemoryCommandHandler = DarwinMemoryHandler

########NEW FILE########
__FILENAME__ = parser_cix
#
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)
#
# This code has intimate knowledge of the code objects defined in
# parser_data.py
#

import os
from os.path import basename, splitext, isfile, isdir, join

from ciElementTree import Element, SubElement, tostring
from codeintel2 import util


def get_common_attrs(node):
    attrs = {}
    attrs = {"name": node.name}
    try:
        attrs["line"] = str(node.line_num)
    except AttributeError:
        pass
    try:
        attrs["lineend"] = str(node.lineend)
    except AttributeError:
        pass
    try:
        if node.is_classmethod:
            attrs["attributes"] = "__classmethod__"
        elif node.is_constructor:
            attrs["attributes"] = "__ctor__"
        else:
            attrs["attributes"] = node.attributes
    except AttributeError:
        pass

    return attrs


def sort_by_lines(adict):
    intermed = [(adict[k].line_num, adict[k].type, k) for k in adict.keys()]
    intermed.sort()
    return intermed


#### ElementTree-based CIX routines

def get_arguments_cix(parse_tree_node, cix_node):
    for c in parse_tree_node.args:
        attrs = get_common_attrs(c)
        attrs['name'] = c.get_full_name()
        if not c.arg_attrs is None:
            attrs['attributes'] = c.arg_attrs
        try:
            lineno = parse_tree_node.line_num
            if lineno is not None:
                attrs['line'] = str(lineno)
        except AttributeError:
            pass
        SubElement(cix_node, 'variable', ilk='argument', **attrs)


def get_docstring_cix(parse_tree_node, cix_node):
    if len(parse_tree_node.doc_lines) >= 1:
        summarylines = util.parseDocSummary(parse_tree_node.doc_lines)
        if len(summarylines) > 0:
            cix_node.set("doc", "\n".join(summarylines))


def get_imports_cix(parse_tree_node, cix_node):
    for imp in getattr(parse_tree_node, "imports", []):
        SubElement(cix_node, "import", module=imp.name, line=str(
            imp.line_num), symbol="*")

# These bring all the names in a namespace into the calling namespace.


def get_includes_cix(parse_tree_node, cix_node):
    for incl in getattr(parse_tree_node, "includes", []):
        SubElement(cix_node, "import", symbol=incl.name, line=str(
            incl.line_num))


def get_signature_cix(parse_tree_node, cix_node):
    signature = getattr(parse_tree_node, 'signature', '')
    if len(signature) > 0:
        cix_node.set('signature', signature)


def get_var_cix(cix_node, var_type, **attrs):
    var_cix_node = SubElement(cix_node, 'variable', **attrs)
    if var_type:
        var_cix_node.set('citdl', var_type)


def _local_varname_test(var_name):
    return var_name[0].islower() or var_name[0] == "_"


def _local_varname_test_true(true):
    return True


def _get_vars_helper(parse_tree_node, cix_node, kind_name, attr_attrs=None,
                     var_test=_local_varname_test_true):
    for line_no, var_type, var_name in sort_by_lines(getattr(parse_tree_node,
                                                             kind_name, {})):
        attrs = {"name": var_name, "line": str(line_no)}
        if attr_attrs:
            if var_test(var_name):
                attrs["attributes"] = attr_attrs
        get_var_cix(cix_node, var_type, **attrs)


def get_globals_cix(parse_tree_node, cix_node):
    _get_vars_helper(parse_tree_node, cix_node, 'global_vars')


def get_vars_cix(parse_tree_node, cix_node):
    _get_vars_helper(parse_tree_node, cix_node, 'local_vars', "__local__",
                     _local_varname_test)
    _get_vars_helper(parse_tree_node, cix_node, 'aliases',
                     "__alias__")
    _get_vars_helper(parse_tree_node, cix_node, 'class_vars', "__local__")
    _get_vars_helper(parse_tree_node, cix_node, 'instance_vars',
                     "__instancevar__ __local__")


def common_module_class_cix(parse_tree_node, cix_node, class_ref_fn=None, **additional_attrs):
    attrs = get_common_attrs(parse_tree_node)
    attrs.update(additional_attrs)
    if 'ilk' not in attrs:
        attrs['ilk'] = 'class'
    class_cix_node = SubElement(cix_node, 'scope', **attrs)
    get_docstring_cix(parse_tree_node, class_cix_node)
    get_signature_cix(parse_tree_node, class_cix_node)
    get_imports_cix(parse_tree_node, class_cix_node)
    get_includes_cix(parse_tree_node, class_cix_node)
    get_vars_cix(parse_tree_node, class_cix_node)
    if class_ref_fn:
        class_ref_fn(parse_tree_node, class_cix_node)
    visit_children_get_cix(parse_tree_node, class_cix_node)


def classref_etree_cix(parse_tree_node, cix_node):
    classrefs = [(len(ref) > 2 and ref[2] or ref[0])
                 for ref in parse_tree_node.classrefs]
    if len(classrefs) > 0:
        cix_node.set('classrefs', " ".join(classrefs))


def class_etree_cix(parse_tree_node, cix_node):
    common_module_class_cix(parse_tree_node, cix_node, classref_etree_cix)


def method_etree_cix(parse_tree_node, cix_node):
    attrs = get_common_attrs(parse_tree_node)
    method_cix_node = SubElement(cix_node, 'scope', ilk='function', **attrs)
    get_docstring_cix(parse_tree_node, method_cix_node)
    get_signature_cix(parse_tree_node, method_cix_node)
    # XXX: Get classrefs, doc, symbols(?)
    get_arguments_cix(parse_tree_node, method_cix_node)
    get_imports_cix(parse_tree_node, method_cix_node)
    get_includes_cix(parse_tree_node, method_cix_node)
    get_vars_cix(parse_tree_node, method_cix_node)
    visit_children_get_cix(parse_tree_node, method_cix_node)


def module_etree_cix(parse_tree_node, cix_node):
    common_module_class_cix(parse_tree_node, cix_node, ilk='namespace')

cb_etree_hash = {"Module": module_etree_cix,
                 "Class": class_etree_cix,
                 "Method": method_etree_cix}


def visit_children_get_cix(parse_tree_node, cix_node):
    for c in parse_tree_node.children:
        cb_etree_hash[c.class_name](c, cix_node)


def produce_elementTree_cix(parse_tree, filename, target_lang, gen_lang="Python"):
    cix_root = Element("codeintel", version="2.0")
    fileAttrs = {"lang": target_lang,
                 "path": filename,
                 }
    file_cix_node = SubElement(cix_root, "file", **fileAttrs)
    module_cix_node = SubElement(file_cix_node, "scope", ilk='blob',
                                 lang=gen_lang,
                                 name=splitext(basename(filename))[0])
    produce_elementTree_contents_cix(parse_tree, module_cix_node)
    return cix_root


def produce_elementTree_contents_cix(parse_tree, cix_node):
    get_docstring_cix(parse_tree, cix_node)
    get_imports_cix(parse_tree, cix_node)
    get_includes_cix(parse_tree, cix_node)
    get_globals_cix(parse_tree, cix_node)
    get_vars_cix(parse_tree, cix_node)
    visit_children_get_cix(parse_tree, cix_node)
    return cix_node

########NEW FILE########
__FILENAME__ = parser_data
#
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)
#
#

VAR_KIND_UNKNOWN = 0
VAR_KIND_GLOBAL = 1
VAR_KIND_CLASS = 2
VAR_KIND_CLASSVAR = 3
VAR_KIND_INSTANCE = 4
VAR_KIND_LOCAL = 5
VAR_KIND_ALIAS = 6


class Name_LineNum:
    def __init__(self, name, line_num, type=None):
        self.line_num = line_num
        self.name = name
        self.type = type


class VarInfo:
    def __init__(self, line_num, type=None):
        self.line_num = line_num
        self.type = type


def update_collection(coll, name, line_num, type=None, attributes=None):
    if name not in coll:
        coll[name] = VarInfo(line_num, type)
    elif coll[name].type is None and type is not None:
        coll[name].type = type
    if attributes and coll['attributes'] is None:
        coll['attributes'] = attributes


class Node:
    def __init__(self, line_num, class_name=None):
        self.children = []
        self.line_num = line_num
        self.indentation = 0
        self.doc_lines = []
        self.imports = []  # require and load stmts
        self.includes = []  # include stmts

        self.class_vars = {}
        self.instance_vars = {}
        self.local_vars = {}
        self.aliases = {}
        if class_name:
            self.class_name = class_name

    def append_node(self, new_node):
        self.children.append(new_node)

    def set_line_end_num(self, line_end_num):
        self.lineend = line_end_num

    def dump_kids(self, indent_level):
        for c in self.children:
            c.dump(indent_level + 2)

    def dump2(self, node_type_name, indent_level, *call_backs):
        print "%s %s %s - line %r:%r" % (" " * indent_level, node_type_name, self.name, self.line_num, getattr(self, 'lineend', '???'))
        if len(self.doc_lines) > 0:
            print "%s Documentation: %s" % (" " * (indent_level + 2), "\n".join(self.doc_lines))
        if len(self.imports) > 0:
            for m in self.imports:
                print "%s Import: %s" % (" " * (indent_level + 2), m.name)
        if len(self.includes) > 0:
            for m in self.includes:
                print "%s Include: %s" % (" " * (indent_level + 2), m.name)
        self.dump_collection('Globals', 'global_vars', indent_level + 2)
        self.dump_collection('Locals', 'local_vars', indent_level + 2)
        self.dump_collection(
            'Instance vars', 'instance_vars', indent_level + 2)
        self.dump_collection('Class vars', 'class_vars', indent_level + 2)
        for cb in call_backs:
            cb()
        self.dump_kids(indent_level)

    def dump_collection(self, label, attr, indent_level):
        if hasattr(self, attr):
            collection = getattr(self, attr)
            if len(collection) > 0:
                print "%s %s: " % (" " * indent_level, label)
                for name, varInfo in collection.items():
                    line, type = varInfo.line_num, varInfo.type
                    if type:
                        typeString = " [" + type + "]"
                    else:
                        typeString = ""
                    print "%s %s - line %s%s" % (" " * (indent_level + 2), name, line, typeString)


class ClassNode(Node):
    def __init__(self, the_name, line_num, unused=False):
        self.name = the_name
        self.classrefs = []
        Node.__init__(self, line_num, "Class")

    def add_classrefs(self, class_ref_name, line_num, classref_type=None):
        if class_ref_name not in [x[0] for x in self.classrefs]:
            self.classrefs.append([class_ref_name, line_num, classref_type])

    def has_classref(self, name):
        return name in [x[0] for x in self.classrefs]

    def dump(self, indent_level):
        def cb():
            classrefs = self.classrefs
            if len(classrefs) > 0:
                for ref in classrefs:
                    print "%sClassref %s - line %s" % (" " * (indent_level + 2),
                                                       ref[0], ref[1])
        self.dump2("Class", indent_level, cb)


class FileNode(Node):
    def __init__(self):
        Node.__init__(self, 0)
        self.global_vars = {}  # Easy to get at

    def dump(self):
        self.name = ""
        self.dump2("file", 0)
        return
        indent_level = 0
        if len(self.imports) > 0:
            for m in self.imports:
                print "%s Import: %s" % (" " * (indent_level + 2), m.name)
        if len(self.includes) > 0:
            for m in self.includes:
                print "%s Include: %s" % (" " * (indent_level + 2), m.name)
        self.dump_kids(0)


class ArgNode:
    def __init__(self, name, extra_info, arg_attrs):
        self.name = name
        self.extra_info = extra_info
        self.arg_attrs = arg_attrs

    def get_full_name(self):
        if self.extra_info:
            return self.extra_info + self.name
        return self.name


class MethodNode(Node):
    def __init__(self, the_name, line_num, is_constructor=False):
        self.name = the_name
        self.is_constructor = is_constructor
        self.signature = ""
        self.args = []
        self.is_classmethod = False
        Node.__init__(self, line_num, "Method")

        # extra_info for Ruby, arg_attrs for Tcl's "args", like Ruby's "*args"
    def add_arg(self, name, extra_info=None, arg_attrs=None):
        self.args.append(ArgNode(name, extra_info, arg_attrs))

    def dump(self, indent_level):
        def cb():
            args = self.args
            for arg in args:
                print "%sArg %s" % (" " * (indent_level + 2), arg.get_full_name())
        self.dump2("Method", indent_level, cb)
        if len(self.signature) > 0:
            print "%sSignature %s" % (" " * (indent_level + 2), self.signature)


class ModuleNode(Node):
    def __init__(self, the_name, line_num, unused=False):
        self.name = the_name
        Node.__init__(self, line_num, "Module")

    def dump(self, indent_level):
        self.dump2("Module", indent_level)


class VariableNode(Node):
    def __init__(self, the_name, line_num):
        self.name = the_name
        Node.__init__(self, line_num, "Variable")

    def dump(self, indent_level):
        self.dump2("Module", indent_level)


class BlockNode(Node):
    def __init__(self, the_name, line_num):
        self.name = the_name
        Node.__init__(self, line_num, "Block")

    def dump(self, indent_level):
        self.dump2("Module", indent_level)

########NEW FILE########
__FILENAME__ = parseutil
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Some CILE parsing utils extracted originally from phpcile and jscile
# but mostly generally useful to CILEs implemented in Python.


import codecs
import locale
import re
import sys
import os

from codeintel2.common import CILEError


#---- exported routines
def tryEncoding(buffer, encoding):
    """ buffer, encoding -> encoding_buffer

        Attempts to encode the buffer using the specified encoding

        Returns None on failure, a Unicode version of the buffer on success.
    """
    # log.info("_tryEncoding...%s",encoding)
    try:
        secret_decoder_ring = codecs.lookup(encoding)[1]
    except LookupError, e:
        # the encoding name doesn't exist, likely a pep263 failure
        # an example is using windows-1250 as the name
        return None
    try:
        (outdata, len) = secret_decoder_ring(buffer)
        return outdata
    except Exception, e:  # Figure out the real exception types
        return None


try:
    _defaultEncoding = locale.getdefaultlocale()[1]
except ValueError:
    _defaultEncoding = None
if _defaultEncoding is not None:
    _defaultEncoding = _defaultEncoding.lower()


def getEncodedBuffer(buffer):
    decodedBuffer = tryEncoding(buffer, 'utf-8')
    if decodedBuffer is not None:
        return (decodedBuffer, 'utf-8', '')
    if _defaultEncoding is not None:
        decodedBuffer = tryEncoding(buffer, _defaultEncoding)
        if decodedBuffer is not None:
            return (decodedBuffer, _defaultEncoding, '')
    return (tryEncoding(buffer, 'iso8859-1'), 'iso8859-1', '')


def urlencode_path(s):
    """URL-encode the given path string.

    This URL-encoding attempts to NOT encode characters that are typically
    legal path characters, e.g. '/', '\\', ':'. This is so that the result
    can more naturally be used as a filepath argument.

    The string must be an 8-bit string (that is all that URL-encoding can
    handle).
    """
    from urllib import quote
    safe = os.sep + (os.altsep or '') + ":"
    return quote(s, safe=safe)


#---- javadoc parsing

_javadoc1 = re.compile(r'\s*\/\*(.*)\*\/', re.S)
_javadoc2 = re.compile(r'^(\s*\*)', re.M)
_linedoc = re.compile(r'^(\s*#|\s*\/\/)', re.M)
_indent = re.compile(r'^([ \t]*)', re.M)
_param = re.compile(
    r'^\s*@param\s+(?P<type>[\w\\]+)\s+\$(?P<name>\w+)(?:\s+?(?P<doc>.*?))?', re.M | re.U)
_return = re.compile(
    r'^\s*@return\s+(?P<type>[\w\\]+)(?:\s+(?P<doc>.*))?', re.M | re.U)


def uncommentDocString(doc):
    # remove block style leading and end comments
    d = '\n'.join(re.findall(_javadoc1, doc))
    if d:
        # remove starting * if javadoc style
        d = re.sub(_javadoc2, '', d)
    else:
        d = doc
        # remove line style comments
        d = re.sub(_linedoc, '', d)

    # trim preceeding blank lines.  we dont want to trim the first non-blank
    # line
    lines = d.split('\n')
    while len(lines) and not lines[0].strip():
        lines.pop(0)
    d = '\n'.join(lines)

    # trip any blank end lines
    d = d.rstrip()

    # guess the indent size
    spaces = re.findall(_indent, d)
    indent = len(spaces[0])
    for s in spaces:
        if len(s) and len(s) < indent:
            indent = len(s)

    # dedent the block
    if not indent:
        return d
    dedent = re.compile(r'^([ \t]{%d})' % indent, re.M)
    d = re.sub(dedent, '', d)
    return d


def parseDocString(doc):
    d = uncommentDocString(doc)
    params = re.findall(_param, d)
    result = re.findall(_return, d)
    if result:
        result = result[0]
    return (d, params, result)


SKIPTOK = 0x01  # don't consider this a token that is to be considered a part of the grammar, like '\n'
MAPTOK = 0x02  # use the token associated with the pattern when it matches
EXECFN = 0x04   # execute the function associated with the pattern when it matches
USETXT = 0x08  # if you match a single character and want its ascii value to be the token


class recollector:
    def __init__(self):
        self.res = {}
        self.regs = {}

    def add(self, name, reg, mods=None):
        self.regs[name] = reg % self.regs
        # print "%s = %s" % (name, self.regs[name])
        if mods:
            self.res[name] = re.compile(self.regs[
                                        name], mods)  # check that it is valid
        else:
            self.res[name] = re.compile(self.regs[
                                        name])  # check that it is valid

# Lexer class borrowed from the PyLRd project,
# http://starship.python.net/crew/scott/PyLR.html


class Lexer:
    eof = -1

    def __init__(self):
        self.tokenmap = {}
        self.prgmap = {}
        self.prglist = []
        self.lasttok = -1
        self.text = ""
        self.textindex = 0
        self.tokennum2name = {}

    def nexttok(self):
        self.lasttok = self.lasttok + 1
        return self.lasttok

    def settext(self, t):
        self.text = t
        self.textindex = 0

    def addmatch(self, prg, func=None, tokname="", attributes=MAPTOK | EXECFN):
        self.prglist.append(prg)
        tok = -2
        if not func:
            attributes = attributes & ~EXECFN
        if not tokname:
            attributes = attributes & ~MAPTOK
        if attributes & MAPTOK:
            self.tokenmap[tokname] = tok = self.nexttok()
        else:
            tok = self.nexttok()
        self.prgmap[prg] = tok, attributes, func
        self.tokennum2name[tok] = tokname

    def scan(self):
        for prg in self.prglist:
            mo = prg.match(self.text, self.textindex)
            if not mo:
                continue
            self.textindex = self.textindex + len(mo.group(0))
            tmpres = mo.group(0)
            t, attributes, fn = self.prgmap[prg]
            # log.debug("'%s' token: %r", self.tokennum2name[t], tmpres)
            if attributes & EXECFN:
                tmpres = apply(fn, (mo,))
            if attributes & USETXT:
                t = ord(mo.group(0)[0])
            return (t, tmpres)
        if self.textindex >= len(self.text):
            return (self.eof, "")
        raise CILEError("Syntax Error in lexer")

########NEW FILE########
__FILENAME__ = perlcile
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
    perlcile - a Code Intelligence Language Engine for the Perl language

    Module Usage:
        from perlcile import scan_purelang
        content = open("foo.pl", "r").read()
        scan_purelang(content, "foo.pl")

    Command-line Usage:
        perlcile.py [<options>...] [<Perl file>]

    Options:
        -h, --help          dump this help and exit
        -V, --version       dump this script's version and exit
        -v, --verbose       verbose output, use twice for more verbose output
        -f, --filename <path>   specify the filename of the file content
                            passed in on stdin, this is used for the "path"
                            attribute of the emitted <file> tag.
        --md5=<string>      md5 hash for the input
        --mtime=<secs>      modification time for output info, in #secs since
                            1/1/70.
        -L, --language <name>
                            the language of the file being scanned
        -c, --clock         print timing info for scans (CIX is not printed)

    One or more Perl files can be specified as arguments or content can be
    passed in on stdin. A directory can also be specified, in which case
    all .pl files in that directory are scanned.

    This is a Language Engine for the Code Intelligence (codeintel) system.
    Code Intelligence XML format. See:
        http://specs.activestate.com/Komodo_3.0/func/code_intelligence.html
        http://specs.tl.activestate.com/kd/kd-0100.html

    The command-line interface will return non-zero iff the scan failed.
"""

import os
import os.path
import sys
import getopt
from hashlib import md5
import re
import logging
import glob
import time
import stat

from ciElementTree import Element, SubElement, tostring
from SilverCity import ScintillaConstants

from codeintel2 import perl_lexer, perl_parser, util
from codeintel2.tree import pretty_tree_from_tree
from codeintel2.common import CILEError
from codeintel2 import parser_cix

#---- global data

_version_ = (0, 1, 0)
log = logging.getLogger("perlcile")
# log.setLevel(logging.DEBUG)

_gClockIt = 0   # if true then we are gathering timing data
_gClock = None  # if gathering timing data this is set to time retrieval fn
_gStartTime = None   # start time of current file being scanned

gProvideFullDocs = False


#---- internal support
# This code has intimate knowledge of the code objects defined in
# perl_parser.py

def scan_purelang(buf):
    content = buf.accessor.text.expandtabs(8)
    tokenizer = perl_lexer.PerlLexer(content, gProvideFullDocs)
    parser = perl_parser.Parser(tokenizer, provide_full_docs=gProvideFullDocs)
    parser.moduleName = buf.path
    parse_tree = parser.parse()
    tree = parser.produce_CIX()
    return tree


def scan_multilang(tokens, module_elem):
    """Build the Perl module CIX element tree.

        "tokens" is a generator of UDL tokens for this UDL-based
            multi-lang document.
        "module_elem" is the <module> element of a CIX element tree on
            which the Perl module should be built.

    This should return a list of the CSL tokens in the token stream.
    """

    tokenizer = perl_lexer.PerlMultiLangLexer(tokens)
    # "PerlHTML" is about all we need for whichever Perl-based
    # template language is being used.  This could just as easily be a
    # boolean that indicates whether we're processing a pure language
    # or a multi-lang one.

    parser = perl_parser.Parser(
        tokenizer, lang="PerlHTML", provide_full_docs=gProvideFullDocs)
    parser.moduleName = ""  # Unknown
    parser.parse()
    parse_tree = parser.produce_CIX_NoHeader(module_elem)
    csl_tokens = tokenizer.get_csl_tokens()
    return csl_tokens, tokenizer.has_perl_code()

#---- mainline


def main(argv):
    logging.basicConfig()
    # Parse options.
    try:
        opts, args = getopt.getopt(argv[1:], "Vvhf:cL:",
                                   ["version", "verbose", "help", "filename=", "md5=", "mtime=",
                                    "clock", "language="])
    except getopt.GetoptError, ex:
        log.error(str(ex))
        log.error("Try `perlcile --help'.")
        return 1
    numVerboses = 0
    stdinFilename = None
    md5sum = None
    mtime = None
    lang = "Perl"
    global _gClockIt
    for opt, optarg in opts:
        if opt in ("-h", "--help"):
            sys.stdout.write(__doc__)
            return
        elif opt in ("-V", "--version"):
            ver = '.'.join([str(part) for part in _version_])
            print "perlcile %s" % ver
            return
        elif opt in ("-v", "--verbose"):
            numVerboses += 1
            if numVerboses == 1:
                log.setLevel(logging.INFO)
            else:
                log.setLevel(logging.DEBUG)
        elif opt in ("-f", "--filename"):
            stdinFilename = optarg
        elif opt in ("-L", "--language"):
            lang = optarg
        elif opt in ("--md5",):
            md5sum = optarg
        elif opt in ("--mtime",):
            mtime = optarg
        elif opt in ("-c", "--clock"):
            _gClockIt = 1
            global _gClock
            if sys.platform.startswith("win"):
                _gClock = time.clock
            else:
                _gClock = time.time

    if len(args) == 0:
        contentOnStdin = 1
        filenames = [stdinFilename or "<stdin>"]
    else:
        contentOnStdin = 0
        paths = []
        for arg in args:
            paths += glob.glob(arg)
        filenames = []
        for path in paths:
            if os.path.isfile(path):
                filenames.append(path)
            elif os.path.isdir(path):
                perlfiles = [os.path.join(path, n) for n in os.listdir(path)
                             if os.path.splitext(n)[1] in (".pl", ".pm")]
                perlfiles = [f for f in perlfiles if os.path.isfile(f)]
                filenames += perlfiles

    if 1:
        for filename in filenames:
            if contentOnStdin:
                log.debug("reading content from stdin")
                content = sys.stdin.read()
                log.debug("finished reading content from stdin")
                if mtime is None:
                    mtime = int(time.time())
            else:
                if mtime is None:
                    mtime = int(os.stat(filename)[stat.ST_MTIME])
                content = open(filename, 'r').read()

            if _gClockIt:
                sys.stdout.write("scanning '%s'..." % filename)
                global _gStartTime
                _gStartTime = _gClock()
            data = scan(
                content, filename, md5sum=md5sum, mtime=mtime, lang=lang)
            if _gClockIt:
                sys.stdout.write(" %.3fs\n" % (_gClock()-_gStartTime))
            elif data:
                sys.stdout.write(data)
    try:
        pass
    except KeyboardInterrupt:
        log.debug("user abort")
        return 1

if __name__ == "__main__":
    sys.exit(main(sys.argv))

########NEW FILE########
__FILENAME__ = perl_lexer
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
Perl lexing support for codeintel/perlcile.py

Get all the lexed tokens from SilverCity, and then return them
on demand to the caller (usually a Perl pseudo-parser).

Usage:
import perl_lexer
lexer = lex_wrapper.Lexer(code)
while 1:
    tok = lexer.get_next_token()
    if tok[0] == EOF_STYLE:
        break;
    # tok is an array of (style, text, start-col, start-line, end-col, end-line)
    # column and line numbers are all zero-based.
"""

import copy
import re
import sys
import string

import SilverCity
from SilverCity import Perl, ScintillaConstants
import shared_lexer
from shared_lexer import EOF_STYLE

pod_markings = re.compile('^=(?:head|item|cut)', re.M)


class PerlLexerClassifier:
    """ This classifier is similar to the parser-level classifier, but
    it works on the SilverCity "raw" tokens as opposed to the
    tokens that get created by the lexer layer.  There should be some
    folding though."""

    def is_comment(self, ttype):
        return ttype in (ScintillaConstants.SCE_PL_COMMENTLINE,
                         ScintillaConstants.SCE_PL_POD)

    @property
    def style_comment(self):
        return ScintillaConstants.SCE_PL_COMMENTLINE

    @property
    def style_default(self):
        return ScintillaConstants.SCE_PL_DEFAULT

    @property
    def style_operator(self):
        return ScintillaConstants.SCE_PL_OPERATOR


class _CommonLexer(shared_lexer.Lexer):
    def __init__(self):
        shared_lexer.Lexer.__init__(self)
        self.q = []
        self.multi_char_ops = self.build_dict(
            '-> ++ -- ** =~ !~ << >> <= >= == != <=> && || ... .. => <<= >>= &&= ||= ~*= /= %= += -= .= &= |= ^= ::')


class PerlLexer(_CommonLexer):
    def __init__(self, code, provide_full_docs=True):
        _CommonLexer.__init__(self)
        self.q = []
        self.classifier = PerlLexerClassifier()
        self._provide_full_docs = provide_full_docs
        Perl.PerlLexer().tokenize_by_style(code, self._fix_token_list)
        self.prepare_token_list_for_use()
        self.string_types = [ScintillaConstants.SCE_PL_STRING,
                             ScintillaConstants.SCE_PL_CHARACTER,
                             ScintillaConstants.SCE_PL_HERE_Q,
                             ScintillaConstants.SCE_PL_HERE_QQ,
                             ScintillaConstants.SCE_PL_STRING_QW,
                             ScintillaConstants.SCE_PL_STRING_Q,
                             ScintillaConstants.SCE_PL_STRING_QQ,
                             ScintillaConstants.SCE_PL_STRING_QX
                             ]

    def _fix_token_list(self, **tok):
        """ SilverCity doesn't know much about Perl, and breaks in two ways:
        1. It doesn't know how to separate sequences of characters into
        separate tokens.
        2. It doesn't know how to map DATASECTIONs into POD sequences.

        It's easier to do this once before processing tokens individually.

        This should all be done in silvercity.  Doing this has leaked the
        whole silvercity abstraction into this module, and it doesn't
        belong here.  This routine works with SilverCity tokens, not
        shared_lexer Tokens.
        """
        if tok['start_column'] > shared_lexer.MAX_REASONABLE_LIMIT:
            return
        ttype = tok['style']
        tval = tok['text']
        if ttype in (ScintillaConstants.SCE_PL_OPERATOR,
                     ScintillaConstants.SCE_PL_VARIABLE_INDEXER) and len(tok['text']) > 1:
            # Scineplex doesn't know how to split some sequences of styled characters
            # into syntactically different tokens, so we do it here.
            # A sequence of characters might need to be split into more than one token.
            # Push all but the last token on the pending block.
            self.append_split_tokens(tok, self.multi_char_ops)
        elif ttype == ScintillaConstants.SCE_PL_IDENTIFIER:
            tok['text'] = tok['text'].strip()
            self.complete_token_push(tok)
        elif (not self._provide_full_docs) and \
                ttype in (ScintillaConstants.SCE_PL_DATASECTION,
                          ScintillaConstants.SCE_PL_POD):
            pass
        elif ttype == ScintillaConstants.SCE_PL_DATASECTION:
            if pod_markings.search(tval):
                # putback (KWD package), (ID main), (OP ;), (POD this)
                col = tok['start_column']
                for new_vals in ((ScintillaConstants.SCE_PL_WORD, "package"),
                                 (ScintillaConstants.SCE_PL_IDENTIFIER,
                                  "main"),
                                 (ScintillaConstants.SCE_PL_OPERATOR, ";")):
                    new_type, new_text = new_vals
                    new_tok = copy.copy(tok)
                    new_tok['text'] = new_text
                    new_tok['style'] = new_type
                    new_tok['start_column'] = col
                    new_tok['end_column'] = col + len(new_text) - 1
                    col = new_tok['end_column'] + 1
                    self.complete_token_push(new_tok)
                tok['style'] = ScintillaConstants.SCE_PL_POD
                tok['text'] = tval
                tok['start_column'] = col
                if tok['start_line'] == tok['end_line']:
                    tok['end_column'] = tok[
                        'start_line'] + len(tok['text']) - 1
                self.complete_token_push(tok)
            else:
                # End of the queue => EOF
                pass
        else:
            self.complete_token_push(tok)


class PerlMultiLangLexer(_CommonLexer):
    def __init__(self, token_source):
        _CommonLexer.__init__(self)
        self.csl_tokens = []
        # http://www.mozilla.org/js/language/grammar14.html
        self.js_multi_char_ops = self.build_dict(
            '++ -- << >> >>> <= >= == != === !== && || *= /= %= += -= <<= >>= >>>= &= ^= |=')
        self.string_types = [ScintillaConstants.SCE_UDL_SSL_STRING
                             ]
        self.classifier = shared_lexer.UDLLexerClassifier()
        self._contains_ssl = False
        self._build_tokens(token_source)
        self.prepare_token_list_for_use()

    def _build_tokens(self, token_source):
        while True:
            try:
                tok = token_source.next()
                self._fix_token_list(tok)
            except StopIteration:
                break

    def _fix_token_list(self, tok):
        """See perl_lexer.py for details on what this routine does."""
        ttype = tok['style']
        tval = tok['text']

        if self.is_udl_csl_family(ttype):
            # Don't adjust the line numbers of CSL tokens this time,
            # have it done later.
            if ttype == ScintillaConstants.SCE_UDL_CSL_OPERATOR and len(tval) > 1:
                # Point the token splitter to the correct token queue
                self.append_split_tokens(tok, self.js_multi_char_ops,
                                         adjust_line=False,
                                         dest_q=self.csl_tokens)
            else:
                self.complete_token_push(tok, adjust_line=False,
                                         dest_q=self.csl_tokens)
        elif self.is_udl_ssl_family(ttype):
            if tok['style'] == ScintillaConstants.SCE_UDL_SSL_OPERATOR and len(tok['text']) > 1:
                self.append_split_tokens(tok, self.multi_char_ops)
            else:
                self.complete_token_push(tok)
            self._contains_ssl = True
        # See comment in RubyMultiLangLexer._fix_token_list
        # on why we probably don't need this code.
        # elif self.is_udl_tpl_family(ttype):
        #    self._contains_ssl = True

    def get_csl_tokens(self):
        return self.csl_tokens

    def has_perl_code(self):
        return self._contains_ssl


def provide_sample_code():
    return r"""use LWP::UserAgent;

# full-line comment
# comment at start of line
 # comment at col 1
  # comment at col 2

{
package Foo;

sub new {
   my ($class, %args) = @_;
   my $self = {count => 0, list = [] };
   bless $self, (ref $class || $class);
}

sub m {
    my ($self, $arg) = @_;
    push @{$self->{list}}, $arg;
    $self->{count} += 1;
    $arg;
}

sub no_paren {
  my ($a, $b,
     $c) = $_;
  print "blah";
}

sub our_generate { my $self = shift; my $file_info = shift;
  $self->{info} = info;
  $self->{files} = [];
  $self->{classes} = [];
  $self->{hyperlinks} = {};
  #comment on what test_fn does
  # more...

  sub test_fn {
        my ($a, $b, $c, $d, $e) = @_;
        $b |= 'val1';
        $c |= f(3);
       print "nothing\n";   # end-of-line comment
       print qq(percent string\n);
    }

   }
   }
"""


if __name__ == "__main__":
    shared_lexer.main(sys.argv, provide_sample_code, PerlLexer)

########NEW FILE########
__FILENAME__ = perl_parser
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""Perl parsing support for codeintel/perlcile.py"""

import copy
import os.path
import string
import sys
import re
import textwrap
import time
import cPickle
import logging

from ciElementTree import Element, SubElement, tostring
from SilverCity import ScintillaConstants
from SilverCity.ScintillaConstants import (
    SCE_PL_DEFAULT, SCE_PL_ERROR, SCE_PL_COMMENTLINE, SCE_PL_POD,
    SCE_PL_NUMBER, SCE_PL_WORD, SCE_PL_STRING, SCE_PL_CHARACTER,
    SCE_PL_PUNCTUATION, SCE_PL_PREPROCESSOR, SCE_PL_OPERATOR,
    SCE_PL_IDENTIFIER, SCE_PL_SCALAR, SCE_PL_ARRAY, SCE_PL_HASH,
    SCE_PL_SYMBOLTABLE, SCE_PL_VARIABLE_INDEXER, SCE_PL_REGEX,
    SCE_PL_REGSUBST, SCE_PL_LONGQUOTE, SCE_PL_BACKTICKS, SCE_PL_DATASECTION,
    SCE_PL_HERE_DELIM, SCE_PL_HERE_Q, SCE_PL_HERE_QQ, SCE_PL_HERE_QX,
    SCE_PL_STRING_Q, SCE_PL_STRING_QQ, SCE_PL_STRING_QX, SCE_PL_STRING_QR,
    SCE_PL_STRING_QW, SCE_PL_POD_VERB, SCE_PL_SUB, SCE_PL_SUB_ARGS,
    SCE_PL_UNKNOWN_FIELD, SCE_PL_STDIN, SCE_PL_STDOUT, SCE_PL_STDERR,
    SCE_PL_FORMAT, SCE_PL_UPPER_BOUND)

from codeintel2.common import CILEError
from codeintel2 import perl_lexer
from codeintel2 import shared_lexer
from codeintel2 import shared_parser

SCE_PL_UNUSED = shared_lexer.EOF_STYLE

log = logging.getLogger("perlcile")
# log.setLevel(logging.DEBUG)

#----  memoize from http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/496879

TIMING = False  # set to true to capture timing data from regexen
REGEXEN = {}  # unused if TIMING is not True


def memoize(function, limit=None):
    if isinstance(function, int):
        def memoize_wrapper(f):
            return memoize(f, function)

        return memoize_wrapper

    dict = {}
    list = []

    def memoize_wrapper(*args, **kwargs):
        key = cPickle.dumps((args, kwargs))
        try:
            list.append(list.pop(list.index(key)))
        except ValueError:
            dict[key] = function(*args, **kwargs)
            list.append(key)
            if limit is not None and len(list) > limit:
                del dict[list.pop(0)]

        return dict[key]

    memoize_wrapper._memoize_dict = dict
    memoize_wrapper._memoize_list = list
    memoize_wrapper._memoize_limit = limit
    memoize_wrapper._memoize_origfunc = function
    memoize_wrapper.func_name = function.func_name
    return memoize_wrapper


class TimingRe:
    "A wrapper around compiled regexen that keeps track of timing data"
    def __init__(self, re, orig_re):
        self._re = re
        self._orig_re = orig_re

    def sub(self, *args):
        return self._timing_operation('sub', *args)

    def match(self, *args):
        return self._timing_operation('match', *args)

    def search(self, *args):
        return self._timing_operation('search', *args)

    def split(self, *args):
        return self._timing_operation('split', *args)

    def findall(self, *args):
        return self._timing_operation('findall', *args)

    def _timing_operation(self, methodname, *args):
        start = time.time()
        retval = getattr(self._re, methodname)(*args)
        end = time.time()
        delta = end-start
        # if delta > 0.01:
        #    print delta,'\t', self._orig_re, str(args)[:80]
        if self._orig_re not in REGEXEN:
            REGEXEN[self._orig_re] = 0.0
        REGEXEN[self._orig_re] += delta
        return retval


@memoize
def re_compile(regex, *args):
    """A version of re.compile which memoizes and optionally keeps track of timing
    data"""
    if TIMING:
        return TimingRe(re.compile(regex, *args), regex)
    else:
        return re.compile(regex, *args)


def re_sub(*args):
    """a version of re.sub which deals with TimingRe objects and prints out
    details of slow regexen"""
    if TIMING:
        start = time.time()
        if isinstance(args[0], TimingRe):
            retval = args[0].sub(*args[1:])
        else:
            retval = re.sub(*args)
        end = time.time()
        delta = end-start
        if delta > 0.01:  # adjust as needed.
            print delta, '\t', args
    else:
        retval = re.sub(*args)
    return retval


class PerlCommonClassifier:
    """Mixin class containing classifier callbacks"""

    def is_array_cb(self, tok):
        tval = tok['text']
        return len(tval) >= 2 and tval[0] == '@' and tval[1] != '$'
        # @$name is more like an expression -- don't return it

    def is_scalar_cb(self, tok):
        tval = tok['text']
        return len(tval) > 1 and tval[0] == '$' and (tval[1].isalnum or tval[1] == "_")

    def is_pod_cb(self, tok):
        return tok['text'][0] == '=' and tok['text'][1].isalnum and tok['text'].find("\n=cut", 5) > 0

    def is_string_qw_cb(self, tok):
        return re_compile(r'^qw\s*[^\w\d_]').match(tok['text'])

    # Used for stripping the quotes off a string
    _quote_patterns = {SCE_PL_STRING: re.compile('^[\'\"](.*)[\'\"]$'),
                       SCE_PL_CHARACTER: re.compile('^\'(.*)\'$'),
                       SCE_PL_STRING_Q: re.compile(r'^q\s*.(.*).$'),
                       SCE_PL_STRING_QQ: re.compile(r'^q\w\s*.(.*).$'),
                       SCE_PL_DEFAULT: re.compile('^.(.*).$'),  # fallback
                       }

    def quote_patterns_cb(self, tok):
        # Caller wants an array.
        return [self.quote_patterns_cb_aux(tok)]

    def quote_patterns_cb_aux(self, tok):
        tval = tok['text']
        if tval[0] == '"':
            return self._quote_patterns[SCE_PL_STRING]
        elif tval[0] == '\'':
            return self._quote_patterns[SCE_PL_CHARACTER]
        elif tval.startswith("Q"):
            return self._quote_patterns[SCE_PL_STRING_QQ]
        elif tval.startswith("q"):
            return self._quote_patterns[SCE_PL_STRING_Q]
        else:
            return self._quote_patterns[SCE_PL_DEFAULT]  # Fallback


class UDLClassifier(PerlCommonClassifier, shared_parser.UDLClassifier):
    pass


class PerlClassifier(PerlCommonClassifier, shared_parser.CommonClassifier):
    def get_builtin_type(self, tok, callback):
        raise CILEError("Unexpected call to perl_parser.get_builtin_type")

    def is_any_operator(self, tok):
        return tok['style'] == ScintillaConstants.SCE_PL_OPERATOR

    def is_comment(self, tok):
        return tok['style'] in (ScintillaConstants.SCE_PL_COMMENT,
                                ScintillaConstants.SCE_PL_POD)

    def is_comment_structured(self, tok, callback):
        return tok['style'] == ScintillaConstants.SCE_PL_POD

    def is_identifier(self, tok, allow_keywords=False):
        return (tok['style'] == ScintillaConstants.SCE_PL_IDENTIFIER or
               (allow_keywords and
                tok['style'] == ScintillaConstants.SCE_PL_WORD))

    def is_index_op(self, tok, pattern=None):
        if not (tok['style'] in (SCE_PL_OPERATOR, SCE_PL_VARIABLE_INDEXER)):
            return False
        elif not pattern:
            return True
        return len(tok['text']) > 0 and pattern.search(tok['text'])

    def is_interpolating_string(self, tok, callback):
        return tok['style'] in [ScintillaConstants.SCE_PL_STRING,
                                ScintillaConstants.SCE_PL_REGEX,
                                ScintillaConstants.SCE_PL_HERE_QQ,
                                ScintillaConstants.SCE_PL_STRING_QQ,
                                ScintillaConstants.SCE_PL_STRING_QR,
                                ScintillaConstants.SCE_PL_STRING_QX
                                ]

    def is_keyword(self, tok, target):
        return tok['style'] == ScintillaConstants.SCE_PL_WORD and tok['text'] == target

    def is_number(self, tok):
        return tok['style'] == ScintillaConstants.SCE_PL_NUMBER

    def is_operator(self, tok, target):
        return tok['style'] == ScintillaConstants.SCE_PL_OPERATOR and tok['text'] == target

    def is_string(self, tok):
        return tok['style'] in [ScintillaConstants.SCE_PL_STRING,
                                ScintillaConstants.SCE_PL_CHARACTER,
                                ScintillaConstants.SCE_PL_HERE_Q,
                                ScintillaConstants.SCE_PL_HERE_QQ,
                                ScintillaConstants.SCE_PL_STRING_Q,
                                ScintillaConstants.SCE_PL_STRING_QQ,
                                ScintillaConstants.SCE_PL_STRING_QX,
                                ]

    def is_string_qw(self, tok, callback):
        return tok['style'] == ScintillaConstants.SCE_PL_STRING_QW

    def is_symbol(self, tok):
        return False

    def is_variable(self, tok):
        return SCE_PL_SCALAR <= tok['style'] <= SCE_PL_SYMBOLTABLE

    # Types of variables
    def is_variable_array(self, tok, callback=None):
        return tok['style'] == ScintillaConstants.SCE_PL_ARRAY and \
            len(tok['text']) > 1 and tok['text'][1] != '$'

    def is_variable_scalar(self, tok, callback=None):
        return tok['style'] == ScintillaConstants.SCE_PL_SCALAR and \
            len(tok['text']) > 1 and tok['text'][1] != '$'

    # Accessors for where we'd rather work with a style than call a predicate
    # fn

    @property
    def style_identifier(self):
        return ScintillaConstants.SCE_PL_IDENTIFIER

    @property
    def style_word(self):
        return ScintillaConstants.SCE_PL_WORD


def _get_classifier(lang):
    """Factory method for choosing the style classifier."""
    cls = lang == "Perl" and PerlClassifier or UDLClassifier
    return cls()

# Parse Perl code

showWarnings = False


class ModuleInfo:
    def __init__(self, provide_full_docs):
        self.provide_full_docs = provide_full_docs

        self.modules = {}
        self.currentFunction = None
        self.currentNS = None
        self.textWrapper = textwrap.TextWrapper()
        self.textWrapper.width = 60
        self.max_doclet_low_water_mark = 80
        self.max_doclet_high_water_mark = 100
        self.pod_escape_seq = {'lt': "&lt;",
                               'gt': "&gt;",
                               'verbar': "|",
                               'sol': "/"}
        # Things for attrs, etc.
        self.export_string = '__exported__'
        self.export_ok_string = '__exportable__'
        self.local_string = '__local__'
        # Cached regular expressions
        self.re_bl = r'\r?\n\s*\r?\n'
        self.tryGettingDoc_Sig_re3 = re_compile(
            r'^=(?:item|head)\w*\s*((?:(?!\n=).)*)(?!\n=)',
            re.M | re.S)
        self.printDocInfo_re4 = re_compile(
            r'^=(?:item|head)\w*\s*((?:(?!\n=).)*)(?!\n=)', re.S | re.M)

        self.printDocInfo_re2 = re_compile(
            r'^=\w+\s+DESCRIPTION%s(.*?)(?:%s|^=)' % (self.re_bl, self.re_bl), re.M)
        self.printDocInfo_re6 = re_compile(
            r'^=\w+\s+SYNOPSIS' + self.re_bl + '(.*?)^=',
            re.M | re.S)
        self.printDocInfo_bdot_re = re_compile(r'\.\s+[A-Z].*\Z')

        self._get_first_sentence_re1 = re_compile(r'\.\s+[A-Z].*\Z', re.S)

        self._simple_depod_e_re = re_compile(r'E<(.*?)>', re.S)
        self._simple_depod_c_re = re_compile(r'C<{2,}\s*(.*?)\s*>{2,}', re.S)
        self._simple_depod_ibcfsxl_re1 = re_compile(r'[IBCFSXL]<[^>\n]*>')
        self._simple_depod_ibcfsxl_re2 = re_compile(
            r'[IBCFSX]<(<*[^<>]*?>*)>', re.S)
        self._simple_depod_l_re = re_compile(r'L<\/?(.*?)>')
        self._simple_depod_rest_re = re_compile(r'\w<\/?(<*.*?>*)>')

        self._depod_re1 = re_compile(
            r'^=begin\s+man\s+.*?^=end\s+man\s*', re.M | re.S)
        self._depod_re2 = re_compile(r'^=\w+\s*', re.M)
        self._depod_re3 = re_compile(r'\]\]>')
        self._depod_re4 = re_compile(r'[\x00-\x08\x0b\x0c\x0e-\x1f]')

        self.trim_ws_re1 = re_compile(r'(?<=\w[\.\!\?])\s+')
        self.trim_ws_re2 = re_compile(r'[\r\n\t]')
        self.trim_ws_re3 = re_compile(r' {2,}')

        self.printFunctions_re1 = re_compile(r'(\S)\s*\n(?:\s*\n)*\s*(\S)')

    def doStartNS(self, ns):
        name = ns.name
        if name not in self.modules:
            self.modules[name] = ns
        self.currentNS = ns

    def doEndNS(self, **attrInfo):
        if 'lineNo' in attrInfo:
            self.currentNS.lineend = attrInfo['lineNo']
        self.currentNS = None

    def getNS(self, name, **attrInfo):
        if name in self.modules:
            return self.modules[name]
        else:
            return NamespaceInfo(name, **attrInfo)

    def doSetArg(self, name):
        self.currentFunction.aArg[name] = []
        self.currentFunction.argList.append(name)

    def doSetParent(self, **attrInfo):
        ns = attrInfo.get('ns')
        if ns:
            self.currentNS.aParent.append(ns)

    def doStartFn(self, fn):
        self.currentFunction = fn

    def doEndFn(self, **attrInfo):
        if 'lineNo' in attrInfo:
            self.currentFunction.lineend = attrInfo.get('lineNo')
        self.currentNS.aFunc.append(self.currentFunction)
        self.currentFunction = None

    def doStartVar(self, **attrInfo):
        self.thisVar = {}
        self.thisVar['name'] = attrInfo.get('name')
        for field in ['line', 'aType', 'scope']:
            if field in attrInfo:
                self.thisVar[field] = attrInfo[field]

    def doEndVar(self, forceGlobal):
        name = self.thisVar['name']
        if (not forceGlobal) and self.currentFunction:
            if name in self.currentFunction.aArg:
                self.currentFunction.aArg[name].append(self.thisVar)
            else:
                self.set_or_append(
                    self.currentFunction.aVar, name, self.thisVar)
        else:
            self.set_or_append(self.currentNS.aVar, name, self.thisVar)
        del self.thisVar

    def set_or_append(self, obj, name, val):
        if name in obj:
            obj[name].append(val)
        else:
            obj[name] = [val]

    def doSetVar(self, **args):
        if 'forceGlobal' in args:
            forceGlobal = args['forceGlobal']
            del args['forceGlobal']
        else:
            forceGlobal = False
        self.doStartVar(**args)
        self.doEndVar(forceGlobal)

    def add_imported_module(self, args, **kwargs):
        args2 = copy.copy(args)
        args2.update(kwargs)
        if self.currentFunction:
            self.currentFunction.aImports.append(args2)
        else:
            self.currentNS.aImports.append(args2)

    def printDocInfo(self, modInfo, funcInfo, currNode):
        docs = modInfo.hDocs['modules']
        modName = modInfo.name
        # These REs need rebuilding each time, as their values change on each
        # call.
        printDocInfo_re1 = re_compile(r'^=\w+\s+NAME%s%s[\s-]+(.*?)(?:%s|^=)' %
                                      (self.re_bl, modName, self.re_bl), re.M)

        try:
            mainDocs = self.modules['main'].hDocs['modules'] or []
        except:
            mainDocs = []
        finalDoc = None
        if not funcInfo:
            # Just dump the module-level docs for now,
            # but favor extracting the synopsis.
            #
            # First, find the first item with a synopsis
            #
            # Otherwise, go with the first one.
            for doc in docs:
                m1 = printDocInfo_re1.search(doc)
                if m1:
                    finalDoc = self.trim_ws(m1.group(1), True)
                    break
                else:
                    m2 = self.printDocInfo_re2.search(doc)
                    if m2:
                        finalDoc = self.trim_ws(m2.group(1), True)
                        break
            if finalDoc is None:
                # Look only for a qualified name in the NAME section,
                # but don't look at the DESCRIPTION part until we can
                # select the main class in a module.
                for doc in mainDocs:
                    m1 = printDocInfo_re1.search(doc)
                    if m1:
                        finalDoc = self.trim_ws(m1.group(1), True)
                        break
        else:
            # First look for the function name in an item
            # Then look in the synopsis.
            # Look for a top-level synopsis first
            funcName = funcInfo.name
            # Allow for datasection-based POD\
            if docs:
                re3_s = (r'''
                                ((?:^=(?:item|head)\w*\s*\r?\n(?:\s*\r?\n)*
                                .*?(?:%s\s*::|%s\s*->|\$[\w_]+\s*->|[ \t]+)
                                %s(?![\w\d_]).*\r?\n\s*\r?\n)+)
                                # Now the description
                                # Everything up to the an equal-sign (or end)
                                ((?:\r?\n|.)*?)(?:^=|\Z)''' %
                        (modName, modName, funcName))
                printDocInfo_re3 = re_compile(re3_s, re.X | re.M)
                for doc in docs:
                    # Speed up: do index before doing a reg
                    if doc.find(funcName) == -1:
                        continue
                    # Find a function definition in an item or head thing
                    # Very general-purpose, might pick up false-positives
                    # The gist:
                    # Look for one or more =item/head lines,
                    # separate by blank lines,
                    # followed by a paragraph description
                    m1 = printDocInfo_re3.search(doc)
                    if m1:
                        part1 = m1.group(1)
                        finalDoc = self.trim_ws(m1.group(2), True)
                        part2 = [self.trim_ws(
                            s, True) for s in self.printDocInfo_re4.findall(part1)]
                        finalDoc = "\n\n".join(part2) + "\n\n" + finalDoc
                        finalDoc = self._get_first_sentence(finalDoc)
                        break
            if not finalDoc:
                # Look in the __END__ section
                # XXXX VERY SLOW
                re1_s = r'''(?:^(?:item|head)\w*\s*
                           .*?
                           \b%s.*%s)+
                            # Now the description
                            # Everything up to the an equal-sign (or end)
                            ((?:\r?\n|.)*?)(?=$|^=)''' % (funcName, self.re_bl)
                printDocInfo_re1 = re_compile(re1_s, re.M | re.X)
                for doc in mainDocs:
                    m1 = printDocInfo_re1.search(doc)
                    if m1:
                        before_period = self.printDocInfo_bdot_re.sub(
                            '.', m1.group(1))
                        finalDoc = self.trim_ws(
                            self._get_first_sentence(m1.group(1)), True)
                        break
            if not finalDoc:
                # Try to find a synopsis entry
                printDocInfo_re7 = re_compile(
                    r'(.*(?:::|->|\b)%s\b.*)' % (funcName,))
                for doc in docs + mainDocs:
                    m1 = self.printDocInfo_re6.search(doc)
                    if m1:
                        synopsis = m1.group(1)
                        m2 = printDocInfo_re7.search(synopsis)
                        if m2:
                            finalDoc = self.trim_ws(
                                self._get_first_sentence(m2.group(1)))
                            break
        if finalDoc:
            self.printDocString(finalDoc, currNode)

    def _get_first_sentence(self, s1):
        s2 = self._get_first_sentence_re1.sub('.', s1)
        return s2

    def printDocString(self, finalDoc, currNode):
        finalDoc2 = self._depod(finalDoc)
        if finalDoc2:
            currNode.set('doc', finalDoc2)

    def _process_e_pod(self, src):
        val = self.pod_escape_seq.get(src.lower())
        if val:
            return val
        if re.search(r'^\d+$', src):
            return '&#%s;' % src
        m1 = re.search(r'^0[Xx]([0-9a-fA-F]+)$', src)
        if m1:
            return '&#x%s;' % src
        else:
            # Assume it's an entity name of somekind,
            # and return it as an escaped representation
            # For example, pod E<eacute> will be encoded as
            #                  &amp;eacute;
            # and will appear as
            #                  &eacute;
            # Not great, but it causes no breakage.
            return '&amp;%s' % src

    def _wrap_process_e_pod(self, m):
        return self._process_e_pod(m.group(1))

    def _simple_depod(self, doc):
        # Simple inline-markup removal (doesn't handle nested inlines)
        # In Perl, do this:
        # $doc =~ s/E<(.*?)>/_process_e_pod($1)/eg;

        doc = re_sub(self._simple_depod_e_re, self._wrap_process_e_pod, doc)

        # And handle the inline codes-- thse nest with E codes...

        doc = self._simple_depod_c_re.sub(r'\1', doc)

        # Above code replaces this:
        # doc = re_sub(r'C<{2,}\s+(.*?)\s+>{2,}', r'\1', doc)
        # doc = XmlAttrEscape(doc) -- No longer needed with ElementTree

        # Allow the other sequences to nest, and loop until there
        # aren't any left.

        old_doc = doc
        while self._simple_depod_ibcfsxl_re1.search(doc):
            # Most formatting sequences wrap a single clump of code
            doc = self._simple_depod_ibcfsxl_re2.sub(r'\1', doc)
            # Handling of links - this is more complicated.
            doc = self._simple_depod_l_re.sub(r'\1', doc)

            # We need to make sure we pull out when nothing changes.
            # XXX A log message would be useful here.
            if old_doc != doc:
                old_doc = doc
            else:
                break
        # Remove any unrecognized sequences
        doc = self._simple_depod_rest_re.sub(r'\1', doc)

        # And shrink entities back into strings.
        # This is done because we can't convert constructs like
        # E<gt> into ">" directly, because they'll prevent
        # proper handling of outer C<...> in strings like 'C<if (a E<gt> b) {
        # ...>'
        doc = doc.replace("&lt;", "<").replace("&gt;", ">")
        return doc

# Precondition: this text is emitted inside a cdata-section

    def _depod(self, doc):
        # Remove embedded man directives
        doc1 = self._depod_re1.sub('', doc)

        # Pull out leading equal signs and the directives
        doc2 = self._depod_re2.sub('', doc1)
        doc3 = self._simple_depod(doc2)
        # Handle strings that could cause the XML parser trouble
        doc4 = self._depod_re3.sub(']<!>]>', doc3)
        doc5 = self._depod_re4.sub('?', doc4)
        return doc5

    def trim_ws(self, str1, truncate=False):
        # First split into sentences
        str2 = str1.strip()
        if truncate:
            sentences = self.trim_ws_re1.split(str2)
            keep_sentences = []
            sum = 0
            # Keep sentences until we pass max_doclet_high_water_mark chars.
            for s in sentences:
                thisLen = len(s)
                if sum and sum + thisLen > self.max_doclet_high_water_mark:
                    break
                s1 = self.trim_ws_re2.sub(' ', s)
                s2 = self.trim_ws_re3.sub(' ', s1)
                keep_sentences.append(s2)
                sum += thisLen
                if sum > self.max_doclet_high_water_mark:
                    break
            str2 = "  ".join(keep_sentences)

        if str2.find("\n") >= 0 or len(str2) > self.textWrapper.width * 1.1:
            str2 = "\n".join(self.textWrapper.wrap(str2))
        return str2

    def printClassParents(self, modInfo, currNode):
        if not hasattr(modInfo, 'aParent'):
            return
        classrefs = [info[0] for info in modInfo.aParent]
        if len(classrefs) > 0:
            currNode.set('classrefs', " ".join(classrefs))

    def printImports(self, modInfo, currNode):
        # -- this will be correct only when there are deliberate conflicts
        # better to use object inheritance to choose methods dynamically.
        # imports = getattr(modInfo, 'aImports', [])
        # imports.reverse()
        for _import in getattr(modInfo, 'aImports', []):
            attrs = _import.keys()
            importNode = SubElement(currNode, "import")
            for k in attrs:
                importNode.set(k, str(_import[k]))

    def printTypeInfo(self, argInfo, currNode):
        types = {}
        for type_ in argInfo:
            typeInfo = type_.get('aType')
            if not typeInfo:
                continue
            elif 'assign' not in typeInfo:
                continue
            tp = typeInfo['assign']
            if tp in types:
                continue
            types[tp] = None
            currNode.set('citdl', tp)

    def printVariables(self, modInfo, currNode):
        if not hasattr(modInfo, 'aVar'):
            return

        def sorter1(a, b):
            return (cmp(a[0]['line'], b[0]['line']) or
                    cmp(a[0]['name'].lower(), b[0]['name'].lower()))

        variables = modInfo.aVar.values()
        variables.sort(sorter1)
        try:
            export_info = modInfo.export_info
        except:
            if not hasattr(self, 'default_export_info'):
                self.default_export_info = {'@EXPORT': {}, '@EXPORT_OK': {}}
            export_info = self.default_export_info
        for varInfo in variables:
            var_name = varInfo[0]['name']
            varNode = SubElement(
                currNode, 'variable', line=str(varInfo[0]['line']),
                name=var_name)
            attr_parts = []
            if var_name in export_info['@EXPORT']:
                attr_parts.append(self.export_string)
            if var_name in export_info['@EXPORT_OK']:
                attr_parts.append(self.export_ok_string)
            try:
                if varInfo[0]['scope'] == 'my':
                    attr_parts.append(self.local_string)
            except:
                pass
            if attr_parts:
                varNode.set('attributes', ' '.join(attr_parts))
            self.printTypeInfo(varInfo, varNode)

    def printFunctions(self, modInfo, currNode):
        for funcInfo in getattr(modInfo, 'aFunc', []):
            sig, docString = self.tryGettingDoc_Sig(modInfo, funcInfo)
            funcName = funcInfo.name
            if not sig:
                sig = '%s(%s)' % (funcName, ', '.join(funcInfo.argList))
            else:
                sig = self._simple_depod(sig.strip())
                sig = self.printFunctions_re1.sub('\\1\n\\2', sig)
            funcNode = SubElement(
                currNode, 'scope', ilk='function', name=funcName)
            for attr_name in ['line', 'lineend']:
                ln = getattr(funcInfo, attr_name, None)
                if ln:
                    funcNode.set(attr_name, str(ln))

            attr_parts = []
            if funcInfo.isConstructor:
                attr_parts.append("__ctor__")
            export_info = modInfo.export_info
            for tuple in [['@EXPORT', self.export_string],
                          ['@EXPORT_OK', self.export_ok_string]]:
                if funcName in export_info[tuple[0]]:
                    attr_parts.append(tuple[1])
            if attr_parts:
                funcNode.set('attributes', ' '.join(attr_parts))

            funcNode.set('signature', sig)

            for argName in funcInfo.argList:
                argInfo = funcInfo.aArg.get(argName)
                if argInfo:
                    kwargs = {'ilk': 'argument', 'name': argInfo[0]['name']}
                    if 'line' in argInfo[0]:
                        kwargs['line'] = str(argInfo[0]['line'])
                    argNode = SubElement(funcNode, 'variable', **kwargs)
                    self.printTypeInfo(argInfo, argNode)
            if self.provide_full_docs:
                if not docString:
                    self.printDocInfo(modInfo, funcInfo, funcNode)
                else:
                    self.printDocString(docString, funcNode)
            self.printImports(funcInfo, funcNode)
            self.printVariables(funcInfo, funcNode)

    def tryGettingDoc_Sig(self, modInfo, funcInfo):
        if not self.provide_full_docs:
            return (None, None)
        modName = modInfo.name
        funcName = funcInfo.name
        re1_s = r"""((?:^=(?:item|head)\w*\s*
                       .*?(?:%s\s*\:\:|%s\s*->|\$[\w_]+\s*->|[ \t])
                       %s(?:[^\w_]|$).*%s)+)
                      # Now the description
                      # Everything up to the an equal-sign (or end)
                      ((?:\r?\n|.)*?)(?:^=|\Z)""" % \
                    (modName, modName, funcName, self.re_bl)
        re1 = re_compile(re1_s, re.X | re.M)
        re2a = re_compile(funcName + r'\s+\w')
        re2b = re_compile(r'\s\w+\s+' + funcName + r'\b')
        re4_s = (r'''^=(?:item|head)\s*\*?\s*\r?\n
                        (?:^\s*\r?\n)*
                        ^\s*C<+(.*%s.*)>+\s*\r?\n
                        (?:^\s*\r?\n)*
                        # Now the description
                        # Everything up to the an equal-sign (or end)
                        ((?:.*\r?\n(?!=))+)''' % (funcName,))
        re4 = re_compile(re4_s, re.M | re.X)
        for doc in modInfo.hDocs['modules'] + self.modules['main'].hDocs['modules']:
            if doc.find(funcName) == -1:
                continue
            m1 = re1.search(doc)
            if m1:
                part1 = m1.group(1)
                # If the function name is followed by text, it's probably
                # an English description.  We need to check for a whole word
                # before the name to avoid the pod directive
                if (re2a.search(part1) or
                        re2b.search(part1)):
                    continue
                finalDoc = self.trim_ws(
                    self._get_first_sentence(m1.group(2)), True)
                part2 = [
                    s.strip() for s in self.tryGettingDoc_Sig_re3.findall(part1)]
                finalSig = (part2 and "\n\n".join(part2)) or None
                return (finalSig, finalDoc)
            else:
                m1 = re4.search(doc)
                if m1:
                    finalSig = m1.group(1)
                    finalDoc = self.trim_ws(
                        self._get_first_sentence(m1.group(2)), True)
                    return (finalSig, finalDoc)
        return (None, None)


class NamespaceInfo:
    def __init__(self, name, **attrInfo):
        self.name = name
        self.line = attrInfo.get('lineNo') or 0
        self.aFunc = []
        self.aVar = {}
        self.aParent = []
        self.hDocs = {'modules': [],  # hash of modules => array of docs,
                      'subs': {}     # subs => subname => array of docs
                      }
        self.aImports = []
        self._isProbablyClass = False
        self.export_info = {'@EXPORT': {},
                            '@EXPORT_OK': {}}

    def isProbablyClass(self, val):
        self._isProbablyClass = val


class FunctionInfo:
    def __init__(self, name, **attrInfo):
        self.name = name
        self.aArg = {}
        self.aVar = {}
        self.resultType = []
        self.argList = []
        self.aImports = []
        self.isConstructor = attrInfo.get('isConstructor', False)
        if 'lineNo' in attrInfo:
            self.line = attrInfo.get('lineNo')

if not os.path.altsep or os.path.altsep == os.path.sep:
    def pathSplitter(s):
        return s.split(os.path.sep)
else:
    def pathSplitter(s):
        return re.split(re_compile('[' + re.escape(os.path.sep)
                                   + re.escape(os.path.altsep) + ']'), s)


class Parser:
    def __init__(self, tokenizer, lang="Perl", provide_full_docs=True):
        self.tokenizer = tokenizer
        self._provide_full_docs = provide_full_docs
        self.block_stack = []
        self.bracket_matchers = {"[": "]", "{": "}", "(": ")"}
        self.classifier = _get_classifier(lang)

        # Use simple knowledge of Perl's syntax
        # to skip quickly through code to skip.
        self.opHash = {"(": [0, 1],
                       ")": [0, -1],
                       "{": [1, 1],
                       "}": [1, -1],
                       "[": [2, 1],
                       "]": [2, -1]}

        self.pragmaNames = {'attributes': None,
                            'attrs': None,
                            'autouse': None,
                            'bigint': None,
                            'bignum': None,
                            'bigrat': None,
                            'blib': None,
                            'bytes': None,
                            'charnames': None,
                            'constant': None,
                            'diagnostics': None,
                            'encoding': None,
                            'fields': None,
                            'filetest': None,
                            'if': None,
                            'integer': None,
                            'less': None,
                            'lib': None,
                            'locale': None,
                            'open': None,
                            'ops': None,
                            'overload': None,
                            're': None,
                            'sigtrap': None,
                            'sort': None,
                            'strict': None,
                            'subs': None,
                            'threads': None,
                            'utf8': None,
                            'vmsish': None,
                            'warnings': None,
                            }
        self.find_open_indexer_re = re_compile(r'[\[{]')
        self.provide_full_docs = provide_full_docs

    def _is_stmt_end_op(self, tok):
        tval = tok['text']
        if self.classifier.is_keyword(tok, 'or'):
            return True
        elif self.classifier.is_any_operator(tok):
            return tval in (';', '||')
        return False

    def _is_string(self, tok):
        return tok['style'] in self.tokenizer.string_types

    def printHeader(self, mtime):
        moduleName = self.moduleName
        root = Element("codeintel", version="2.0")
        fileNode = Element("file", lang="Perl",
                           path=moduleName)
        if mtime:
            fileNode.set('mtime', str(mtime))
        root.append(fileNode)
        return (root, fileNode)

    def printContents(self, moduleContentsName, currNode):
        name = os.path.splitext(os.path.basename(self.moduleName))[0]
        moduleNode = SubElement(
            currNode, 'scope', ilk='blob', lang="Perl", name=name)

        innerModules = self.moduleInfo.modules
        mainInfo = innerModules.get('main', None)
        if mainInfo:
            if self.provide_full_docs:
                self.moduleInfo.printDocInfo(mainInfo, None, moduleNode)
            self.moduleInfo.printImports(mainInfo, moduleNode)
            self.moduleInfo.printVariables(mainInfo, moduleNode)

        def sorter1(a, b):
            amod = innerModules.get(a)
            bmod = innerModules.get(b)
            aline = getattr(amod, 'line', None)
            if aline:
                bline = getattr(bmod, 'line', None)
                if aline and bline:
                    return cmp(aline, bline)
            return cmp(getattr(amod, 'name', ""), getattr(bmod, 'name', ""))

        # Sub-packages need to updated their parent blob name - bug 88814.
        # I.e. when parsing "XML/Simple.pm" the blob name is "Simple", but we
        #      need it be "XML::Simple" in this case. The bestPackageName is
        #      used to find the best matching name.
        packages = [x for x in self.moduleInfo.modules.keys() if x != 'main']
        packages.sort(sorter1)
        bestPackageName = None
        for k in packages:
            modInfo = innerModules[k]

            if name in k and \
               (bestPackageName is None or len(bestPackageName) > k):
                bestPackageName = k
                moduleNode.set("name", bestPackageName)

            classNode = SubElement(
                moduleNode, 'scope', ilk='class', name=modInfo.name, line=str(modInfo.line))
            if hasattr(modInfo, 'lineend'):
                classNode.set('lineend', str(modInfo.lineend))
            self.moduleInfo.printClassParents(modInfo, classNode)
            if self.provide_full_docs:
                self.moduleInfo.printDocInfo(modInfo, None, classNode)
            self.moduleInfo.printImports(modInfo, classNode)
            self.moduleInfo.printVariables(modInfo, classNode)
            self.moduleInfo.printFunctions(modInfo, classNode)

        # And do main's functions after its classes
        if mainInfo:
            self.moduleInfo.printFunctions(mainInfo, moduleNode)

    def printTrailer(self, root):
        pass

    def at_end_expression(self, tok):
        if not self.classifier.is_any_operator(tok):
            return False
        return tok['text'] in (';', ',', '}')

    def collect_multiple_args(self, origLineNo, context, var_scope):
        nameList = []
        while True:
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_variable(tok):
                nameList.append((tok['text'], tok['start_line']))
            else:
                break
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_any_operator(tok):
                tval = tok['text']
                if tval == ")":
                    break
                elif tval != ",":
                    break
        if not self.classifier.is_operator(tok, ")"):
            return
        tok = self.tokenizer.get_next_token()
        isArg = False
        if self.classifier.is_operator(tok, "="):
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_variable_array(tok, self.classifier.is_array_cb) and tok['text'] == "@_":
                tok = self.tokenizer.get_next_token()
                isArg = self._is_stmt_end_op(tok)
            else:
                tok = self.tokenizer.put_back(tok)
        for varInfo in nameList:
            if isArg:
                self.moduleInfo.doSetArg(varInfo[0])
            self.moduleInfo.doSetVar(name=varInfo[0], line=varInfo[1],
                                     scope=var_scope)
    # end collect_multiple_args

    # Expect = shift ;
    def collect_single_arg(self, varName, origLineNo, context, var_scope):
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, '='):
            isArg = False
        else:
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_keyword(tok, 'shift') or tok['text'] == '@_':
                tok = self.tokenizer.get_next_token()
                isArg = self._is_stmt_end_op(tok)
                self.tokenizer.put_back(tok)
            else:
                self.tokenizer.put_back(tok)
                self.finish_var_assignment(varName, origLineNo, False,
                                           scope=var_scope, context=context)
                return
        if isArg:
            self.moduleInfo.doSetArg(varName)
        self.moduleInfo.doSetVar(name=varName, line=origLineNo,
                                 scope=var_scope)

    def de_quote_string(self, tok):
        tval = tok['text']
        patterns = self.classifier.get_quote_patterns(
            tok, self.classifier.quote_patterns_cb)
        for p in patterns:
            m = p.match(tval)
            if m:
                return m.group(1)
        return tval

    # Called from both assignments and
# my <var> = ... statements, where the RHS isn't 'shift' or '@_';
    def finish_var_assignment(self, identifier, origLineNo, forceGlobal, **inherited_args):
        tok = self.tokenizer.get_next_token()

        # Narrow down to these possibilities:

        # 1. We're assigning a method call to a scalar

        # $lhs = $rhs->method()->{property}->...
        #
        # Reduces to
        # $lhs = $rhs

        # 2. We're assigning a string/int -- i.e., it's likely
        # to be a non-object value:

        # $lhs = "acb" eq $q
        # $lhs = $r
        # $lhs = 42

        # 3. We're assigning a constructor
        # Now we can take two forms:
        # <constructor> <subpath>
        # <subpath> -> <constructor>
        # Note that if we don't know anything about the module, we can't say
        # anything intelligent about Package::Midd::Function -- we don't know
        # if this returns a constructor or not, although it likely doesn't.

        rhs_StarterVal = None
        args = {'name': identifier, 'line': origLineNo,
                'forceGlobal': forceGlobal}
        if inherited_args:
            args.update(inherited_args)
        ttype = tok['style']
        if self.classifier.is_variable_scalar(tok, self.classifier.is_scalar_cb):
            rhs_StarterVal = tok['text']
            tok = self.tokenizer.get_next_token()
            # Check and skip indexers
            if self.classifier.is_index_op(tok, self.find_open_indexer_re):
                self.skip_to_close_match()
                tok = self.tokenizer.get_next_token()

            # Now get the list of accessors that take us to the
            # semi-colon or close-brace.  Hop over arg lists.
            # Left looking at ->, ;, }, or leave

            accessors = []
            while self.classifier.is_operator(tok, "->") or self.classifier.is_index_op(tok, self.find_open_indexer_re):
                if tok['text'] == "->":
                    tok = self.tokenizer.get_next_token()
                if self.classifier.is_index_op(tok, self.find_open_indexer_re):
                    propertyName = self._get_property_token()
                    if not propertyName:
                        break
                    accessors.append(propertyName)
                    tok = self.tokenizer.get_next_token()
                elif not self.classifier.is_identifier_or_keyword(tok):
                    break
                else:
                    fqName = self.get_rest_of_subpath(tok['text'], 1)
                    accessors.append(fqName)
                    tok = self.tokenizer.get_next_token()
                if self.classifier.is_operator(tok, "("):
                    self.skip_to_close_paren()
                    tok = self.tokenizer.get_next_token()
            # end while

            if accessors or self.at_end_expression(tok):
                if self.at_end_expression(tok):
                    self.tokenizer.put_back(tok)
                fqname = (accessors and rhs_StarterVal.join(
                    accessors)) or rhs_StarterVal
            self.moduleInfo.doSetVar(**args)

        elif self.classifier.is_number(tok):
            # XXX: Any expressions starting with an integer that
            # don't yield an int value?
            tok = self.tokenizer.get_next_token()
            if self.at_end_expression(tok):
                self.tokenizer.put_back(tok)
            self.moduleInfo.doSetVar(**args)
        elif self._is_string(tok):
            tok = self.tokenizer.get_next_token()
            if self.at_end_expression(tok):
                self.tokenizer.put_back(tok)
            self.moduleInfo.doSetVar(**args)
        elif self.classifier.is_identifier(tok):
            rhs_StarterVal = tok['text']
            tok = self.tokenizer.get_next_token()
            updateVarInfo = None
            if self.classifier.is_operator(tok, "::"):
                # Package->method  or Package::method notation
                rhs_StarterVal = self.get_rest_of_subpath(
                    rhs_StarterVal + '::', 0)
                tok = self.tokenizer.get_next_token()
            if self.classifier.is_operator(tok, "->"):
                # a->b is always good
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_identifier_or_keyword(tok) and tok['text'] == "new":
                    # 80/20 rule: assume a new on a class gives an instance
                    args['aType'] = {'assign': rhs_StarterVal}
            elif self.classifier.is_identifier_or_keyword(tok):
                if rhs_StarterVal.find("::") > -1:
                    # obj A::B is always good
                    pass
                elif rhs_StarterVal == 'new':
                    # 80/20 rule
                    package_name = tok['text']
                    tok = self.tokenizer.get_next_token()
                    if self.classifier.is_operator(tok, "::"):
                        # new Package notation
                        package_name = self.get_rest_of_subpath(
                            package_name + '::', 0)
                        tok = self.tokenizer.get_next_token()
                    args['aType'] = {'assign': package_name}
            self.moduleInfo.doSetVar(**args)
        elif self.classifier.is_keyword(tok, 'bless') and self.moduleInfo.currentFunction:
            self.moduleInfo.currentFunction.isConstructor = True
            self.moduleInfo.doSetVar(**args)
        elif self.classifier.is_keyword(tok, 'new'):
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_identifier(tok):
                package_name = tok['text']
                tok = self.tokenizer.get_next_token()
            else:
                package_name = ""
            if self.classifier.is_operator(tok, "::"):
                package_name = self.get_rest_of_subpath(package_name + '::', 0)
            if package_name != "":
                args['aType'] = {'assign': package_name}
                self.moduleInfo.doSetVar(**args)
        else:
            self.moduleInfo.doSetVar(**args)
            if self.classifier.is_index_op(tok, self.find_open_indexer_re):
                self.tokenizer.put_back(tok)
    # end finish_var_assignment

    def get_exported_names(self, export_keyword):
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, '='):
            self.tokenizer.put_back(tok)
            return
        names = self.get_list_of_strings()
        for obj in names:
            name = obj[0]
            if name[0] == '&':
                name = name[1:]
            self.moduleInfo.currentNS.export_info[export_keyword][name] = None
    # end export_keyword

    def get_for_vars(self):
        tok = self.tokenizer.get_next_token()
        if (tok['style'] == ScintillaConstants.SCE_PL_WORD
                and tok['text'] in ('my', 'state')):
            tlineNo = tok['start_line']
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_variable(tok):
                # Don't do any more processing, as we're probably looking
                # at an open-paren.
                self.moduleInfo.doSetVar(name=tok[
                                         'text'], line=tlineNo, scope='my')

    def get_list_of_var_names(self):
        resArray = []
        while 1:
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_variable(tok):
                resArray.append([tok['text'], tok['start_line']])
            else:
                break
            tok = self.tokenizer.get_next_token()
            if not self.classifier.is_operator(tok, ","):
                break
        return resArray

    def get_list_of_strings(self, tok=None):
        if tok is None:
            tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, "("):
            resArray = []
            while 1:
                # Simple -- either a string or a qw here as well
                tok = self.tokenizer.get_next_token()
                if self._is_string(tok):
                    resArray += self.get_string_array(tok)
                else:
                    break
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_any_operator(tok):
                    if tok['text'] == ")":
                        break
                    elif tok['text'] == ",":
                        continue
                    break
        elif self._is_string(tok):
            resArray = self.get_string_array(tok)
        else:
            return []
        return resArray
    # end get_list_of_strings

    def get_our_vars(self, context, var_scope):
        tok = self.tokenizer.get_next_token()
        varNames = []
        if self.classifier.is_operator(tok, "("):
            varNames = self.get_list_of_var_names()
        elif self.classifier.is_variable(tok):
            tval = tok['text'].strip()
            if tval == '@ISA':
                self.get_parent_namespaces(True)
            else:
                lineNo = tok['start_line']
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_operator(tok, "="):
                    self.finish_var_assignment(
                        tval, lineNo, 0, scope=var_scope, context=context)
                    return
                varNames = [(tval, lineNo)]
        for varInfo in varNames:
            self.moduleInfo.doSetVar(name=varInfo[
                                     0], line=varInfo[1], scope=var_scope)

    # Look for = stringList...
    def get_parent_namespaces(self, doingIsa):
        tok = self.tokenizer.get_next_token()
        if doingIsa:
            if not self.classifier.is_operator(tok, '='):
                self.tokenizer.put_back(tok)
                return
        parentNamespaces = self.get_list_of_strings()
        for parentInfo in parentNamespaces:
            self.moduleInfo.currentNS.aParent.append(parentInfo)

        # Undocumented attribute, but it means one of the methods
        # should either invoke bless, SUPER:: ..., or a parent
        # constructor.
        self.moduleInfo.currentNS.isProbablyClass(True)
    # end get_parent_namespaces

    # Precondition: saw ident, "->", '{'
    # Still looking at the "{"
    def _get_property_token(self):
        tok = self.tokenizer.get_next_token()
        if self._is_string(tok):
            finalVal = self.de_quote_string(tok)
        elif not (self.classifier.is_identifier_or_keyword(tok) or
                  self.classifier.is_variable_scalar(tok, self.classifier.is_scalar_cb)):
            return ""
        else:
            finalVal = tok['text']
        tok = self.tokenizer.get_next_token()

        if not self.classifier.is_index_op(tok, re_compile(r'\}')):
            # Swallow the close-brace for the property.
            finalVal = "???"
            # Consume everything until we find the close-brace
            while True:
                tok = self.tokenizer.get_next_token()
                if tok['style'] == SCE_PL_UNUSED:
                    break
                elif self.classifier.is_index_op(tok, re_compile(r'[\}\]]')):
                    break
        return finalVal

    def get_rest_of_subpath(self, retval, expectingDblColon):
        if expectingDblColon:
            tok = self.tokenizer.get_next_token()
            ttype = tok['style']
            tval = tok['text']
            if not self.classifier.is_operator(tok, "::"):
                self.tokenizer.put_back(tok)
                return retval
            else:
                retval += "::"

        while 1:
            tok = self.tokenizer.get_next_token()
            ttype = tok['style']
            if not self.classifier.is_identifier(tok):
                if ttype != self.classifier.style_word or len(retval) == 0:
                    break
            retval += tok['text']
            tok = self.tokenizer.get_next_token()
            if not self.classifier.is_operator(tok, "::"):
                break
            retval += "::"

        self.tokenizer.put_back(tok)
        return retval
    # end get_rest_of_subpath

    def get_string_array(self, tok):
        if self.classifier.is_string_qw(tok, self.classifier.is_string_qw_cb):
            res = []
            qw_re = re_compile(r'\Aqw\s*.(.*)\s*\S\s*\Z', re.DOTALL)
            match_res = qw_re.match(tok['text'])
            if match_res:
                wordsPart = match_res.group(1)
                # Find first line of token
                finalLineNo = tok['start_line']
                for line in wordsPart.split('\n'):
                    for var in re.split(r'\s', line):
                        if re_compile(r'\s*$').match(var):
                            continue
                        res.append((var, finalLineNo))
                    finalLineNo += 1
            return res
        else:
            tval = self.de_quote_string(tok)
            return [(tval, tok['start_line'])]

    def get_used_vars(self, scope):
        tok = self.tokenizer.get_next_token()
        if self._is_string(tok):
            varNames = self.get_list_of_strings(tok)
        elif self.classifier.is_operator(tok, "("):
            varNames = self.get_list_of_strings()
        else:
            varNames = self.get_list_of_var_names()
        for varInfo in varNames:
            self.moduleInfo.doSetVar(name=varInfo[0],
                                     line=varInfo[1],
                                     scope=scope)

    def look_for_object_var_assignment(self, tok, isInnerSub):
        identifier = tok['text']
        if re_compile(r'^\$[^_\w]').match(identifier) or identifier == '$_':
            # Ignore special variables, and $#$... array ref final-item index
            return
        origLineNo = tok['start_line']
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_index_op(tok):
            self.tokenizer.put_back(tok)
            return
        elif tok['text'] != '=':
            self.tokenizer.put_back(tok)
            return
        # Is it an implicit global?
        checkGlobalScope = True
        forceGlobal = False
        # XXX Update, check this
        if self.moduleInfo.currentFunction:
            # Is it defined in the current function?
            if (identifier in self.moduleInfo.currentFunction.aVar or
                    identifier in self.moduleInfo.currentFunction.aArg):
                checkGlobalScope = False
                # Defined in current function.
            elif isInnerSub:
                checkGlobalScope = False
                # Assume that it's defined in the containing sub
        if checkGlobalScope:
            if identifier not in self.moduleInfo.currentNS.aVar:
                self.moduleInfo.currentNS.aVar[
                    identifier] = [{'name': identifier,
                                    'line': origLineNo}]
            forceGlobal = True
        self.finish_var_assignment(identifier, origLineNo, forceGlobal)
    # end look_for_object_var_assignment

    # Handle arrays, hashes, typeglobs, but don't bother figuring out a type.
    # No 'my', 'our', 'state', or 'use vars' given
    def look_for_var_assignment(self, tok1):
        # First make sure this var hasn't already been defined
        # Is it an implicit global?
        var_name = tok1['text']
        if len(var_name) < 2 or var_name[1] == '$':
            return
        if self.moduleInfo.currentFunction:
            # Is it defined in the current function?
            if (var_name in self.moduleInfo.currentFunction.aVar or
                    var_name in self.moduleInfo.currentFunction.aArg):
                return
            scope = 'my'
        else:
            scope = 'our'
        if var_name in self.moduleInfo.currentNS.aVar:
            return
        tok2 = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok2, "="):
            varInfo = (tok1['text'], tok1['start_line'])
            self.moduleInfo.doSetVar(name=var_name, line=tok1['start_line'],
                                     scope=scope)
        else:
            self.tokenizer.put_back(tok2)

    def process_import(self, fqModule, origLineNo, import_vars=None):
        tok = self.tokenizer.get_next_token()
        if self._is_string(tok) or self.classifier.is_operator(tok, "("):
            varNames = self.get_list_of_strings(tok)
            imports_nothing = not varNames
        else:
            self.tokenizer.put_back(tok)
            varNames = []
            imports_nothing = None
        args = {'module': fqModule, 'line': origLineNo}
        if not varNames:
            if import_vars and not imports_nothing:
                args['symbol'] = '*'
            self.moduleInfo.add_imported_module(args)
        elif [x[0] for x in varNames if x[0][0] == ":"]:
            # If there's a tag, assume we're just bringing in all exported
            # names.
            if import_vars:
                args['symbol'] = '**'
            self.moduleInfo.add_imported_module(args)
        else:
            for varName in varNames:
                self.moduleInfo.add_imported_module(
                    args, line=varName[1], symbol=varName[0])
    # end process_import

    def process_module(self, moduleName, mtime, _showWarnings=False):
        showWarnings = _showWarnings
        self.moduleName = moduleName
        self.parse()
        xmlTree = self.get_CIX(mtime)
        return xmlTree

    def get_CIX(self, mtime=None):
        (root, currNode) = self.printHeader(mtime)
        self.printContents(self.moduleName, currNode)
        self.printTrailer(root)
        return root

    def produce_CIX(self, actual_mtime=None):
        return self.get_CIX(actual_mtime)

    def produce_CIX_NoHeader(self, cix_node):
        """Get the CIX for the current contents, and attach it to the cix_node.
        """
        self.printContents(self.moduleName, cix_node)

    # Codeintel interface to the parser
    def parse(self):
        origLineNo = self.tokenizer.curr_line_no()
        self.moduleInfo = ModuleInfo(self.provide_full_docs)
        self.moduleInfo.doStartNS(NamespaceInfo(
            name='main', lineNo=origLineNo))
        self.process_package_inner_contents(True)
        if self.provide_full_docs:
            # Check for a trailing pod doc
            podName = re_sub(r'.p[ml]$', '.pod', self.moduleName)
            if not os.path.isfile(podName) and os.path.isfile(os.path.join('..', 'test', podName)):
                podName = os.path.join('..', 'test', podName)
            if os.path.isfile(podName):
                try:
                    f = open(podName)
                    pod_str = f.read()
                    f.close()
                    self.moduleInfo.currentNS.hDocs['modules'].append(pod_str)
                except:
                    pass
        self.moduleInfo.doEndNS(lineNo=self.tokenizer.curr_line_no())

    def process_package_inner_contents(self, doingTopLevel):
        currPackage = self.moduleInfo.currentNS
        popNS = 0
        curr_pkg_line_no = self.tokenizer.curr_line_no()
        while 1:
            tok = self.tokenizer.get_next_token()
            ttype = tok['style']
            if ttype == shared_lexer.EOF_STYLE:
                return
            tval = tok['text']
            if ttype == self.classifier.style_word:
                if tval == 'package':
                    packageName = self.get_rest_of_subpath("", 0)
                    if packageName:
                        self.moduleInfo.doEndNS(lineNo=curr_pkg_line_no)
                        ns = self.moduleInfo.getNS(packageName,
                                                   lineNo=self.tokenizer.curr_line_no())
                        self.moduleInfo.doStartNS(ns)
                        popNS = 1
                elif tval == 'sub':
                    self.start_process_sub_definition(False)
                    # Is outer sub
                elif tval in ['BEGIN', 'END', 'AUTOLOAD']:
                    self.skip_anon_sub_contents()
                elif tval in ['our', 'my', 'state']:
                    if tval == 'state':
                        tval = 'my'
                    self.get_our_vars('global', tval)
                    # Small warning: vars defined at this lexical level belong to
                    # the containing package, but are visible without
                    # qualification in other packages in the same file.
                elif tval in ['for', 'foreach']:
                    self.get_for_vars()
                elif tval == 'use':
                    self.process_use(0)
                elif tval == 'require':
                    origLineNo = tok['start_line']
                    tok = self.tokenizer.get_next_token()
                    ttype = tok['style']
                    tval = tok['text']
                    if (self.classifier.is_identifier(tok) or
                        self.classifier.is_variable_scalar(tok,
                                                           self.classifier.is_scalar_cb)):
                        # codeintel allows variables
                        fqModule = self.get_rest_of_subpath(tval, 1)
                        self.process_import(fqModule, origLineNo)

                    elif self.classifier.is_string(tok) and not self.classifier.is_string_qw(tok, self.classifier.is_string_qw_cb):
                        # Rewritten to work with UDL languages as well as
                        # native perl
                        self.process_import(tval, origLineNo)
                else:
                    self.skip_to_end_of_stmt()
            elif self.classifier.is_variable_array(tok, self.classifier.is_array_cb):
                if tval == '@ISA':
                    self.get_parent_namespaces(True)
                elif tval in ('@EXPORT', '@EXPORT_OK'):
                    self.get_exported_names(tval)
                else:
                    self.look_for_var_assignment(tok)
            elif self.classifier.is_any_operator(tok):
                if tval == '{':
                    self.process_package_inner_contents(False)
                elif tval == '}':
                    if not doingTopLevel:
                        if popNS:
                            self.moduleInfo.doEndNS(lineNo=curr_pkg_line_no)
                            self.moduleInfo.doStartNS(currPackage)
                        break
            elif self.classifier.is_variable_scalar(tok, self.classifier.is_scalar_cb):
                self.look_for_object_var_assignment(tok, False)
            elif self.classifier.is_variable(tok):
                if tval == '%EXPORT_TAGS':
                    pass
                else:
                    self.look_for_var_assignment(tok)
            elif self.classifier.is_comment_structured(tok, self.classifier.is_pod_cb):
                self.moduleInfo.currentNS.hDocs['modules'].append(tval)

            curr_pkg_line_no = self.tokenizer.curr_line_no()
    # end process_package_inner_contents

    def process_sub_contents(self, isInnerSub):
        # Get to the open brace or semicolon (outside the parens)
        braceCount = 0
        parenCount = 0
        while True:
            tok = self.tokenizer.get_next_token()
            ttype = tok['style']
            if ttype == SCE_PL_UNUSED:
                return
            # Expect a paren for args, the open-brace, or a semi-colon
            tval = tok['text']
            if parenCount > 0:
                if self.classifier.is_operator(tok, ")"):
                    parenCount -= 1
            elif self.classifier.is_any_operator(tok):
                if tval == "(":
                    parenCount += 1
                elif tval == "{":
                    braceCount = 1
                    break
                elif tval == ';':
                    return

        # So now look for these different things:
        # '}' taking us to brace count of 0
        # my, name, =, shift;
        # my (..., ..., ...) = @_;
        # bless => mark this as a constructor
        # return => try to figure out what we're looking at

        while True:
            tok = self.tokenizer.get_next_token()
            ttype = tok['style']
            if ttype == SCE_PL_UNUSED:
                break
            tval = tok['text']
            if self.classifier.is_index_op(tok):
                if tval == "{":
                    braceCount += 1
                elif tval == "}":
                    braceCount -= 1
                    if braceCount <= 0:
                        break
                elif tval == ':':
                    # Stay here -- it indicates a label
                    pass
                else:
                    self.tokenizer.put_back(tok)
                    self.skip_to_end_of_stmt()
            elif ttype == self.classifier.style_word:
                tlineNo = tok['start_line']
                if tval in ('my', 'state'):
                    tok = self.tokenizer.get_next_token()
                    if self.classifier.is_operator(tok, '('):
                        # Treat 'state' variables as 'my', as both
                        # are only visible locally.
                        self.collect_multiple_args(tlineNo, 'local', 'my')
                    elif self.classifier.is_variable(tok):
                        self.collect_single_arg(tok[
                                                'text'], tlineNo, 'local', 'my')
                        if self.classifier.is_operator(tok, '{'):
                            braceCount += 1
                    else:
                        self.get_our_vars('local', 'my')
                elif tval in ('for', 'foreach'):
                    self.get_for_vars()
                    if self.classifier.is_operator(tok, '{'):
                        braceCount += 1
                elif tval == 'bless':
                    self.moduleInfo.currentFunction.isConstructor = True
                elif tval == 'return':
                    # If we return something of type (<(module)name ('::' name)*> "->" new)
                    # Return an instance of type (module)
                    # Either it returned an identifier, or it put the token
                    # back
                    tok = self.tokenizer.get_next_token()
                    ttype = tok['style']
                    if self.classifier.is_identifier(tok):
                        subclass = self.get_rest_of_subpath(tok['text'], 1)
                        tok = self.tokenizer.get_next_token()
                        if tok['text'] != '->':
                            self.tokenizer.put_back(tok)
                        else:
                            tok = self.tokenizer.get_next_token()
                            if tok['text'] == 'new':
                                if self.moduleInfo.currentFunction:
                                    self.moduleInfo.currentFunction.resultType.append(
                                        subclass)
                            else:
                                self.tokenizer.put_back(tok)
                    else:
                        self.tokenizer.put_back(tok)
                elif tval == 'require':
                    tok = self.tokenizer.get_next_token()
                    ttype = tok['style']
                    if self.classifier.is_identifier(tok):
                        origLineNo = tok['start_line']
                        fqModule = self.get_rest_of_subpath(tok['text'], 1)
                        self.process_import(fqModule, origLineNo)
                elif tval == 'use':
                    self.process_use(1)
                elif tval == 'sub':
                    # Nested subs in Perl aren't really nested --
                    # They're kind of like named closures -- accessible
                    # by name from an outer context, but they can bind
                    # the local state of the sub when defined.
                    # But we can call them anyway, so let's process them

                    self.start_process_sub_definition(True)  # Is inner
                else:
                    self.skip_to_end_of_stmt()
            elif self.classifier.is_variable_scalar(tok, self.classifier.is_scalar_cb):
                self.look_for_object_var_assignment(tok, isInnerSub)
            elif self.classifier.is_variable(tok):
                if tval == '%EXPORT_TAGS':
                    pass
                else:
                    self.look_for_var_assignment(tok)
            elif self.classifier.is_comment_structured(tok, self.classifier.is_pod_cb):
                if self.moduleInfo.currentFunction:
                    name = getattr(
                        self.moduleInfo.currentFunction, 'name', None)
                    if name:
                        # hdoc_subs = self.moduleInfo.currentNS.hDocs['subs']
                        self.moduleInfo.set_or_append(
                            self.moduleInfo.currentNS.hDocs['subs'], name, tval)
        # end while
    # end process_sub_contents

    def process_use(self, local):
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_identifier_or_keyword(tok):
            origLineNo = tok['start_line']
            #@@@ RE
            if re_compile('^[a-z]+$').match(tok['text']):
                if tok['text'] == 'vars':
                    self.get_used_vars(local and 'local' or 'global')
                    return
                elif tok['text'] == 'base':
                    if not local:
                        self.get_parent_namespaces(False)
                    return
                elif tok['text'] in self.pragmaNames:
                    firstMod = tok['text']
                    tok = self.tokenizer.get_next_token()
                    if not self.classifier.is_operator(tok, "::"):
                        self.tokenizer.put_back(tok)
                        return
                    self.tokenizer.put_back(tok)
                    tval = firstMod
                else:
                    tval = tok['text']
            else:
                tval = tok['text']
            fqModule = self.get_rest_of_subpath(tval, 1)
            self.process_import(fqModule, origLineNo, import_vars=1)
    # end process_use

    def skip_anon_sub_contents(self):
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, "{"):
            self.process_package_inner_contents(False)
    # end skip_anon_sub_contents

    def skip_to_close_match(self):
        nestedCount = 1
        while 1:
            tok = self.tokenizer.get_next_token()
            ttype = tok['style']
            if ttype == SCE_PL_UNUSED:
                return
            elif self.classifier.is_index_op(tok):
                tval = tok['text']
                if tval in self.opHash:
                    if self.opHash[tval][1] == 1:
                        nestedCount += 1
                    else:
                        nestedCount -= 1
                        if nestedCount <= 0:
                            break
    # end get_rest_of_subpath

    def skip_to_close_paren(self):
        tok = self.tokenizer.get_next_token()
        nestedCount = 1
        while 1:
            ttype = tok['style']
            if ttype == SCE_PL_UNUSED:
                return
            elif self.classifier.is_any_operator(tok):
                tval = tok['text']
                if tval == "(":
                    nestedCount += 1
                    tok = self.tokenizer.get_next_token()
                elif tval == ")":
                    nestedCount -= 1
                    if nestedCount <= 0:
                        break
                else:
                    tok = self.tokenizer.get_next_token()
            else:
                tok = self.tokenizer.get_next_token()
    # end skip_to_close_paren

    def skip_to_end_of_stmt(self):
        nestedCount = 0
        while 1:
            tok = self.tokenizer.get_next_token()
            ttype = tok['style']
            if ttype == SCE_PL_UNUSED:
                break
            if self.classifier.is_index_op(tok):
                tval = tok['text']
                if tval in self.opHash:
                    if tval == "{":
                        if nestedCount == 0:
                            self.tokenizer.put_back(tok)
                            # At an open-brace, keep going.
                            break
                    vals = self.opHash[tval]
                    if vals[1] == 1:
                        nestedCount += 1
                    else:
                        nestedCount -= 1
                        if nestedCount <= 0:
                            nestedCount = 0
                            if tval == "}":
                                self.tokenizer.put_back(tok)
                                break
                elif tval == ";":
                     # Don't worry about commas, since they don't separate
                     # declaration-type things.
                    if nestedCount == 0:
                        break
    # end skip_to_end_of_stmt

    def start_process_sub_definition(self, isInnerSub):
        tok = self.tokenizer.get_next_token()
        # Watch out for lexer buffoonery
        if self.classifier.is_identifier(tok) and len(tok['text'].strip()) == 0:
            tok = self.tokenizer.get_next_token()
        if (self.classifier.is_operator(tok, "{") or
                not self.classifier.is_identifier_or_keyword(tok)):
            self.tokenizer.put_back(tok)
            self.skip_to_end_of_stmt()
        else:
            startLineNo = tok['start_line']
            fnName = self.get_rest_of_subpath(tok['text'], 0)
            if fnName:
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_operator(tok, "("):
                    self.skip_to_close_paren()
                    tok = self.tokenizer.get_next_token()
                if self.classifier.is_operator(tok, ";"):
                    # Don't process
                    pass
                else:
                    self.tokenizer.put_back(tok)
                    # Python doesn't have Perl's localizer, so we do this
                    # manually.
                    currFunction = self.moduleInfo.currentFunction
                    self.moduleInfo.doStartFn(FunctionInfo(
                        name=fnName.strip(), lineNo=startLineNo))
                    self.process_sub_contents(isInnerSub)
                    self.moduleInfo.doEndFn(
                        lineNo=self.tokenizer.curr_line_no())
                    self.moduleInfo.currentFunction = currFunction
            else:
                self.skipAnonSubContents()
    # end start_process_sub_definition

# end class Parser


def pp(etree, fd):
    s = tostring(etree)
    ind = 0
    iw = 4
    need_nl = False
    # actual_empty_tag_ptn = re_compile(r'<(\w[-\w\d_.]*)([^>]+?)>\s*</\1>',
    # re.S)
    tags = [(re_compile(r'<\?.*?\?>', re.S), False, 0, False),
            (re_compile(r'<!--.*?-->', re.S), False, 0, False),
            (re_compile(
                r'</[^>]+?>', re.S), True, 0, True),  # update before emitting newline
            (re_compile(r'<[^>]+?/>', re.S), True, 0, False),
            (re_compile(
                r'<[^>]+?>', re.S), True, 1, True),  # update after emitting newline
            ]
    fd.write("""<?xml version="1.0" encoding="UTF-8"?>\n""")
    while len(s) > 0:
        if need_nl:
            if s[0:1] == "\r\n":
                s = s[2:]
            elif s[0] == "\n":
                s = s[1:]
            fd.write("\n" + ' ' * (ind * iw))
            need_nl = False
        ltpt = s.find("<")
        if ltpt < 0:
            fd.write(s)
            break
        fd.write(s[0:ltpt])
        s = s[ltpt:]
        # m = actual_empty_tag_ptn.match(s)
        # if m:
        #    print "<%s%s />" % (m.group(1), m.group(2)),
        #    need_nl = True
        #    s = s[len(m.group(1)):]
        #    continue
        for tt in tags:
            m = tt[0].match(s)
            if m:
                tag_end_idx = len(m.group(0))
                need_nl = tt[1]
                if tt[3] and len(s) > tag_end_idx and s[tag_end_idx] != "<":
                    gtpt = s.find(">", tag_end_idx)
                    fd.write(s[0:gtpt+1])
                    s = s[gtpt+1:]
                else:
                    ind += tt[2]
                    fd.write(s[:tag_end_idx])
                    s = s[tag_end_idx:]
                # Preview end-tag breaking
                if s.startswith("</"):
                    need_nl = True
                    if ind > 0:
                        ind -= 1
                break
        else:
            fd.write(s[0:ltpt+1])
            s = s[ltpt+1:]


def main(sample_code, modulePath, mtime, showWarnings, provide_full_docs=True):
    sys.stderr.write("Skipping POD: %r\n" % provide_full_docs)
    sys.exit(1)
    tokenizer = perl_lexer.PerlLexer(sample_code, provide_full_docs)
    parser = Parser(tokenizer, provide_full_docs)
    showWarnings = False
    elementTreeRepn = parser.process_module(modulePath, mtime, showWarnings)
    return elementTreeRepn

if __name__ == "__main__":
    if len(sys.argv) == 1:
        sample_code = perl_lexer.provide_sample_code()
        fs = None
        closefs = False
        modulePath = "__main__"
        mtime = time.time()
    elif sys.argv[1] == "-":
        fs = sys.stdin
        closefs = False
        modulePath = "stdin"
        mtime = time.time()
    else:
        modulePath = sys.argv[1]
        mtime = os.stat(modulePath).st_mtime
        fs = open(modulePath, "r")
        closefs = True
    if fs is not None:
        sample_code = shared_lexer.read_and_detab(fs, closefs)
        # fs comes back closed
    # Don't show the data
    elementTreeRepn = main(sample_code, modulePath, mtime, showWarnings, False)
    sys.stdout.write(tostring(elementTreeRepn))
    sys.stdout.write("\n")

    # pp(elementTreeRepn, sys.stdout)
    # import hotshot, hotshot.stats
    # profiler = hotshot.Profile("%s.prof" % (__file__))
    # profiler.runcall(main, sample_code, modulePath, mtime, showWarnings)
    # regex_data = REGEXEN.items()
    # regex_data.sort(lambda a, b: -cmp(a[1], b[1]))
    # for x in regex_data[:20]:
    #    print x[1], x[0]

########NEW FILE########
__FILENAME__ = phpdoc
#!/usr/bin/env python

""" Utility class used for the parsing of PHPDocumenter comments, aka PHPDoc.

PHPDocumenter is documented online here:
http://manual.phpdoc.org/HTMLSmartyConverter/HandS/li_phpDocumentor.html

/**
 * Method for creating a slider.
 *
 * @static
 * @param string $arg1  The first argument description.
 * @param int leftPadding  The size of the padding field on the left
 * @param int rightPadding  Optional field for setting the size of the padding
 * field on the right.
 * @return Slider  A horizontal slider control
 */

Notes:
* multiple types can be separated by a "|", i.e. int|string|array
* field comments can span multiple lines.
"""

# PHPDoc tags and the help (calltip) for the tag.
# Note: Not all of these have a meaning for the php ciler.
phpdoc_tags = {
    "abstract":     "Mark an abstract class, class variable or method.\n"
                    "@abstract",

    "access":       "Access control for an element. Should be one of\n"
                    "public, protected or private.\n"
                    "@access public|protected|private",

    "author":       "Author of the current element.\n"
                    "@author John Smith <jsmith@pod1.mars>",

    "category":     "Specify a category to organize the documented\n"
                    "element's package into.\n"
                    "@category Testing",

    "copyright":    "Document Copyright information.\n"
                    "@copyright Copyright (c) 2007, John Smith",

    "deprecated":   "Document elements that have been deprecated and should\n"
                    "not be used as they may be removed at any time from a\n"
                    "future version.\n"
                    "@deprecated since versionstring",

    "example":      "Include an external example file with syntax highlighting.\n"
                    "@example reference The description",

    "exception":    "Documents an exception that can be thrown by the method.\n"
                    "@exception Exception when something bad occurs",

    "final":        "Document a class method that should never be overridden\n"
                    "in a child class.\n"
                    "@final",

    "filesource":   "Will create a syntax-highlighted cross-referenced file\n"
                    "containing source code of the current file and link to it.\n"
                    "@filesource",

    "global":       "Document a global variable, or its use in a function.\n"
                    "@global array $GLOBALS['baz']",

    "ignore":       "Prevent documentation of an element.\n"
                    "@ignore",

    "internal":     "Mark documentation as private, internal to the\n"
                    "software project.\n"
                    "@internal Notes for internal use.",

    "license":      "Display a hyperlink to a URL for a license.\n"
                    "@license http://lic.org/lic.php MyLicense",

    "link":         "Display a hyperlink to a URL in the documentation.\n"
                    "@link http://pod.mars/ Mars Pod",

    "method":       "Document a 'Magic' Method of a class.\n"
                    "@method returntype someMethod() description of method",

    "name":         "Specify an alias to use for a procedural page or global\n"
                    "variable in displayed documentation and linking.\n"
                    "Note: Used in conjunction with the @global tag.\n"
                    "@name $baz",

    "package":      "Name to group classes or functions and defines into.\n"
                    "@package packagename",

    "param":        "Provide information about a function parameter.\n"
                    "@param datatype $paramname The description",

    "property":     "Document a 'Magic' Property of a class.\n"
                    "@property datatype $property_name The description",

    "return":       "Specify the return type of a function or method.\n"
                    "@return datatype The description",

    "see":          "Display a link to the documentation for an element.\n"
                    "@see reference",

    "since":        "Document when (at which version) an element was first\n"
                    "added to a package.\n"
                    "@since versionstring",

    "static":       "Document a static property or method.\n"
                    "@static",

    "staticvar":    "Document a static variable's use in a function/method.\n"
                    "@staticvar datatype The description.",

    "subpackage":   "Specify sub-package to group classes or functions and\n"
                    "defines into. Must only be used with the @package tag.\n"
                    "@subpackage subpackagename",

    "throws":       "Documents an exception that can be thrown by the method.\n"
                    "@throws Exception when something bad occurs",

    "todo":         "Document changes that will be made in the future.\n"
                    "@todo The description",

    "tutorial":     "Display a link to the documentation for a tutorial.\n"
                    "@tutorial reference",

    "uses":         "Display a link to the documentation for an element,\n"
                    "and create a backlink in the other element's\n"
                    "documentation to this.\n"
                    "@uses reference The description",

    "var":          "Document the data type of a class variable.\n"
                    "@var datatype The description.",

    "version":      "Version of current element.\n"
                    "@version versionstring",

}

########NEW FILE########
__FILENAME__ = pybinary
#!/usr/bin/env python
# Copyright (c) 2010 ActiveState Software Inc.
# See LICENSE.txt for license details.

"""Python binary file scanner for CodeIntel"""

import os
import sys
import cStringIO as io
import optparse

from process import ProcessOpen


SCAN_PROCESS_TIMEOUT = 2.0


class BinaryScanError(Exception):
    pass


class TimedPopen(ProcessOpen):
    def wait(self):
        return super(TimedPopen, self).wait(SCAN_PROCESS_TIMEOUT)


def safe_scan(path, python):
    """
    Performs a "safe" out-of-process scan.
    It is more safe because if the module being scanned runs amuck,
    it will not ruin the main Komodo interpreter.

        "path"   - is a path to a binary module
        "python" - an absolute path to the interpreter to run the scanner

    Returns a CIX 2.0 string.

    In case of errors raises a BinaryScanError.
    """
    # indirectly calls "_main" defined below

    # this is needed to avoid picking up a stale .pyc file.
    myself = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                          "pybinary.py")

    proc = TimedPopen(cmd="%s %s %s" % (python, myself, path),
                      env=dict(PYTHONPATH=os.pathsep.join(sys.path)))

    out, err = proc.communicate()
    if err:
        raise BinaryScanError(err)

    return out


def scan(path):
    """
    Performs an in-process binary module scan. That means the module is
    loaded (imported) into the current Python interpreter.

        "path" - a path to a binary module to scan

    Returns a CIX 2.0 XML string.
    """

    from gencix.python import gencixcore as gencix

    name, _ = os.path.splitext(os.path.basename(path))
    dir = os.path.dirname(path)

    root = gencix.Element('codeintel', version='2.0', name=name)

    gencix.docmodule(name, root, usefile=True, dir=dir)
    gencix.perform_smart_analysis(root)
    gencix.prettify(root)

    tree = gencix.ElementTree(root)

    stream = io.StringIO()
    try:
        stream.write('<?xml version="1.0" encoding="UTF-8"?>\n')
        tree.write(stream)
        return stream.getvalue()
    finally:
        stream.close()


def _main(argv):
    parser = optparse.OptionParser(usage="%prog mdoulepath")
    (options, args) = parser.parse_args(args=argv)
    if len(args) != 1:
        parser.error("Incorrect number of args")

    mod_path = os.path.abspath(args[0])
    if not os.path.isfile(mod_path):
        parser.error("'%s' is not a file" % mod_path)

    cix = scan(mod_path)
    print cix


if __name__ == '__main__':
    _main(sys.argv[1:])

########NEW FILE########
__FILENAME__ = pythoncile
import os

from codeintel2.pythoncile1 import *

########NEW FILE########
__FILENAME__ = pythoncile1
#!/usr/bin/env python
# Copyright (c) 2004-2006 ActiveState Software Inc.
#
# Contributors:
#   Trent Mick (TrentM@ActiveState.com)

"""
    pythoncile - a Code Intelligence Language Engine for the Python language

    Module Usage:
        from pythoncile import scan
        mtime = os.stat("foo.py")[stat.ST_MTIME]
        content = open("foo.py", "r").read()
        scan(content, "foo.py", mtime=mtime)

    Command-line Usage:
        pythoncile.py [<options>...] [<Python files>...]

    Options:
        -h, --help          dump this help and exit
        -V, --version       dump this script's version and exit
        -v, --verbose       verbose output, use twice for more verbose output
        -f, --filename <path>   specify the filename of the file content
                            passed in on stdin, this is used for the "path"
                            attribute of the emitted <file> tag.
        --md5=<string>      md5 hash for the input
        --mtime=<secs>      modification time for output info, in #secs since
                            1/1/70.
        -L, --language <name>
                            the language of the file being scanned
        -c, --clock         print timing info for scans (CIX is not printed)

    One or more Python files can be specified as arguments or content can be
    passed in on stdin. A directory can also be specified, in which case
    all .py files in that directory are scanned.

    This is a Language Engine for the Code Intelligence (codeintel) system.
    Code Intelligence XML format. See:
        http://specs.activestate.com/Komodo_3.0/func/code_intelligence.html

    The command-line interface will return non-zero iff the scan failed.
"""
# Dev Notes:
# <none>
#
# TODO:
# - type inferencing: asserts
# - type inferencing: return statements
# - type inferencing: calls to isinstance
# - special handling for None may be required
# - Comments and doc strings. What format?
#   - JavaDoc - type hard to parse and not reliable
#     (http://java.sun.com/j2se/javadoc/writingdoccomments/).
#   - PHPDoc? Possibly, but not that rigorous.
#   - Grouch (http://www.mems-exchange.org/software/grouch/) -- dunno yet.
#     - Don't like requirement for "Instance attributes:" landmark in doc
#       strings.
#     - This can't be a full solution because the requirement to repeat
#       the argument name doesn't "fit" with having a near-by comment when
#       variable is declared.
#     - Two space indent is quite rigid
#     - Only allowing attribute description on the next line is limiting.
#     - Seems focussed just on class attributes rather than function
#       arguments.
#   - Perhaps what PerlCOM POD markup uses?
#   - Home grown? My own style? Dunno
# - make type inferencing optional (because it will probably take a long
#   time to generate), this is tricky though b/c should the CodeIntel system
#   re-scan a file after "I want type inferencing now" is turned on? Hmmm.
# - [lower priority] handle staticmethod(methname) and
#   classmethod(methname). This means having to delay emitting XML until
#   end of class scope and adding .visitCallFunc().
# - [lower priority] look for associated comments for variable
#   declarations (as per VS.NET's spec, c.f. "Supplying Code Comments" in
#   the VS.NET user docs)


import os
import sys
import getopt
from hashlib import md5
import re
import logging
import pprint
import glob
import time
import stat
import types
from cStringIO import StringIO
from functools import partial

# this particular ET is different from xml.etree and is expected
# to be returned from scan_et() by the clients of this module
import ciElementTree as et

import compiler
from compiler import ast
from compiler.visitor import dumpNode, ExampleASTVisitor
import parser

from codeintel2.common import CILEError
from codeintel2 import util
from codeintel2 import tdparser

#---- exceptions


class PythonCILEError(CILEError):
    pass


#---- global data
_version_ = (0, 3, 0)
log = logging.getLogger("pythoncile")
# log.setLevel(logging.DEBUG)
util.makePerformantLogger(log)

_gClockIt = 0   # if true then we are gathering timing data
_gClock = None  # if gathering timing data this is set to time retrieval fn
_gStartTime = None   # start time of current file being scanned


#---- internal routines and classes
def _isclass(namespace):
    return (len(namespace["types"]) == 1
            and "class" in namespace["types"])


def _isfunction(namespace):
    return (len(namespace["types"]) == 1
            and "function" in namespace["types"])


def getAttrStr(attrs):
    """Construct an XML-safe attribute string from the given attributes

        "attrs" is a dictionary of attributes

    The returned attribute string includes a leading space, if necessary,
    so it is safe to use the string right after a tag name. Any Unicode
    attributes will be encoded into UTF8 encoding as part of this process.
    """
    from xml.sax.saxutils import quoteattr
    s = ''
    for attr, value in attrs.items():
        if not isinstance(value, basestring):
            value = str(value)
        elif isinstance(value, unicode):
            value = value.encode("utf-8")
        s += ' %s=%s' % (attr, quoteattr(value))
    return s

# match 0x00-0x1f except TAB(0x09), LF(0x0A), and CR(0x0D)
_encre = re.compile('([\x00-\x08\x0b\x0c\x0e-\x1f])')

# XXX: this is not used anywhere, is it needed at all?
if sys.version_info >= (2, 3):
    charrefreplace = 'xmlcharrefreplace'
else:
    # Python 2.2 doesn't have 'xmlcharrefreplace'. Fallback to a
    # literal '?' -- this is better than failing outright.
    charrefreplace = 'replace'


def xmlencode(s):
    """Encode the given string for inclusion in a UTF-8 XML document.

    Note: s must *not* be Unicode, it must be encoded before being passed in.

    Specifically, illegal or unpresentable characters are encoded as
    XML character entities.
    """
    # As defined in the XML spec some of the character from 0x00 to 0x19
    # are not allowed in well-formed XML. We replace those with entity
    # references here.
    #   http://www.w3.org/TR/2000/REC-xml-20001006#charsets
    #
    # Dev Notes:
    # - It would be nice if Python has a codec for this. Perhaps we
    #   should write one.
    # - Eric, at one point, had this change to '_xmlencode' for rubycile:
    #    p4 diff2 -du \
    #        //depot/main/Apps/Komodo-devel/src/codeintel/ruby/rubycile.py#7 \
    #        //depot/main/Apps/Komodo-devel/src/codeintel/ruby/rubycile.py#8
    #   but:
    #        My guess is that there was a bug here, and explicitly
    #        utf-8-encoding non-ascii characters fixed it. This was a year
    #        ago, and I don't recall what I mean by "avoid shuffling the data
    #        around", but it must be related to something I observed without
    #        that code.

    # replace with XML decimal char entity, e.g. '&#7;'
    return _encre.sub(lambda m: '&#%d;' % ord(m.group(1)), s)


def cdataescape(s):
    """Return the string escaped for inclusion in an XML CDATA section.

    Note: Any Unicode will be encoded to UTF8 encoding as part of this process.

    A CDATA section is terminated with ']]>', therefore this token in the
    content must be escaped. To my knowledge the XML spec does not define
    how to do that. My chosen escape is (courteousy of EricP) is to split
    that token into multiple CDATA sections, so that, for example:

        blah...]]>...blah

    becomes:

        blah...]]]]><![CDATA[>...blah

    and the resulting content should be copacetic:

        <b><![CDATA[blah...]]]]><![CDATA[>...blah]]></b>
    """
    if isinstance(s, unicode):
        s = s.encode("utf-8")
    parts = s.split("]]>")
    return "]]]]><![CDATA[>".join(parts)


def _unistr(x):
    if isinstance(x, unicode):
        return x
    elif isinstance(x, str):
        return x.decode('utf8')
    else:
        return unicode(x)


def _et_attrs(attrs):
    return dict((_unistr(k), xmlencode(_unistr(v))) for k, v in attrs.items()
                if v is not None)


def _et_data(data):
    return xmlencode(_unistr(data))


def _node_attrs(node, **kw):
    return dict(name=node["name"],
                line=node.get("line"),
                doc=node.get("doc"),
                attributes=node.get("attributes") or None,
                **kw)


def _node_citdl(node):
    max_type = None
    max_score = -1
    #'guesses' is a types dict: {<type guess>: <score>, ...}
    guesses = node.get("types", {})
    for type, score in guesses.items():
        if ' ' in type:
            # XXX Drop the <start-scope> part of CITDL for now.
            type = type.split(None, 1)[0]
        # Don't emit None types, it does not help us. Fix for bug:
        #  http://bugs.activestate.com/show_bug.cgi?id=71989
        if type != "None":
            if score > max_score:
                max_type = type
                max_score = score
    return max_type


class AST2CIXVisitor:
    """Generate Code Intelligence XML (CIX) from walking a Python AST tree.

    This just generates the CIX content _inside_ of the <file/> tag. The
    prefix and suffix have to be added separately.

    Note: All node text elements are encoded in UTF-8 format by the Python AST
          tree processing, no matter what encoding is used for the file's
          original content. The generated CIX XML will also be UTF-8 encoded.
    """
    DEBUG = 0

    def __init__(self, moduleName=None, content=None, lang="Python"):
        self.lang = lang
        if self.DEBUG is None:
            self.DEBUG = log.isEnabledFor(logging.DEBUG)
        self.moduleName = moduleName
        if content:
            self.lines = content.splitlines(0)
        else:
            self.lines = None
        # Symbol Tables (dicts) are built up for each scope. The namespace
        # stack to the global-level is maintain in self.nsstack.
        self.st = {  # the main module symbol table
            # <scope name>: <namespace dict>
        }
        self.nsstack = []
        self.cix = et.TreeBuilder()

    def emit_start(self, s, attrs={}):
        self.cix.start(s, _et_attrs(attrs))

    def emit_data(self, data):
        self.cix.data(_et_data(data))

    def emit_end(self, s):
        self.cix.end(s)

    def emit_tag(self, s, attrs={}, data=None):
        self.emit_start(s, _et_attrs(attrs))
        if data is not None:
            self.emit_data(data)
        self.emit_end(s)

    def cix_module(self, node):
        """Emit CIX for the given module namespace."""
        # log.debug("cix_module(%s, level=%r)", '.'.join(node["nspath"]),
        # level)
        assert len(node["types"]) == 1 and "module" in node["types"]
        attrs = _node_attrs(node, lang=self.lang, ilk="blob")
        module = self.emit_start('scope', attrs)
        for import_ in node.get("imports", []):
            self.cix_import(import_)
        self.cix_symbols(node["symbols"])
        self.emit_end('scope')

    def cix_import(self, node):
        # log.debug("cix_import(%s, level=%r)", node["module"], level)
        attrs = node
        self.emit_tag('import', attrs)

    def cix_symbols(self, node, parentIsClass=0):
        # Sort variables by line order. This provide the most naturally
        # readable comparison of document with its associate CIX content.
        vars = sorted(node.values(), key=lambda v: v.get("line"))
        for var in vars:
            self.cix_symbol(var, parentIsClass)

    def cix_symbol(self, node, parentIsClass=0):
        if _isclass(node):
            self.cix_class(node)
        elif _isfunction(node):
            self.cix_function(node)
        else:
            self.cix_variable(node, parentIsClass)

    def cix_variable(self, node, parentIsClass=0):
        # log.debug("cix_variable(%s, level=%r, parentIsClass=%r)",
        #          '.'.join(node["nspath"]), level, parentIsClass)
        attrs = _node_attrs(node, citdl=_node_citdl(node))
        if parentIsClass and "is-class-var" not in node:
            # Special CodeIntel <variable> attribute to distinguish from the
            # usual class variables.
            if attrs["attributes"]:
                attrs["attributes"] += " __instancevar__"
            else:
                attrs["attributes"] = "__instancevar__"
        self.emit_tag('variable', attrs)

    def cix_class(self, node):
        # log.debug("cix_class(%s, level=%r)", '.'.join(node["nspath"]), level)

        if node["classrefs"]:
            citdls = (t for t in (_node_citdl(n) for n in node["classrefs"])
                      if t is not None)
            classrefs = " ".join(citdls)
        else:
            classrefs = None

        attrs = _node_attrs(node,
                            lineend=node.get("lineend"),
                            signature=node.get("signature"),
                            ilk="class",
                            classrefs=classrefs)

        self.emit_start('scope', attrs)

        for import_ in node.get("imports", []):
            self.cix_import(import_)

        self.cix_symbols(node["symbols"], parentIsClass=1)

        self.emit_end('scope')

    def cix_argument(self, node):
        # log.debug("cix_argument(%s, level=%r)", '.'.join(node["nspath"]),
        # level)
        attrs = _node_attrs(node, citdl=_node_citdl(node), ilk="argument")
        self.emit_tag('variable', attrs)

    def cix_function(self, node):
        # log.debug("cix_function(%s, level=%r)", '.'.join(node["nspath"]), level)
        # Determine the best return type.
        best_citdl = None
        max_count = 0
        for citdl, count in node["returns"].items():
            if count > max_count:
                best_citdl = citdl

        attrs = _node_attrs(node,
                            lineend=node.get("lineend"),
                            returns=best_citdl,
                            signature=node.get("signature"),
                            ilk="function")

        self.emit_start("scope", attrs)

        for import_ in node.get("imports", []):
            self.cix_import(import_)
        argNames = []
        for arg in node["arguments"]:
            argNames.append(arg["name"])
            self.cix_argument(arg)
        symbols = {}  # don't re-emit the function arguments
        for symbolName, symbol in node["symbols"].items():
            if symbolName not in argNames:
                symbols[symbolName] = symbol
        self.cix_symbols(symbols)
        # XXX <returns/> if one is defined
        self.emit_end('scope')

    def getCIX(self, path):
        """Return CIX content for parsed data."""
        log.debug("getCIX")
        moduleNS = self.st[()]
        self.emit_start('file', dict(lang=self.lang, path=path))
        self.cix_module(moduleNS)
        self.emit_end('file')
        file = self.cix.close()
        return file

    def visitModule(self, node):
        log.info("visitModule")
        nspath = ()
        namespace = {"name": self.moduleName,
                     "nspath": nspath,
                     "types": {"module": 1},
                     "symbols": {}}
        if node.doc:
            summarylines = util.parseDocSummary(node.doc.splitlines(0))
            namespace["doc"] = "\n".join(summarylines)

        if node.lineno:
            namespace["line"] = node.lineno

        self.st[nspath] = namespace
        self.nsstack.append(namespace)
        self.visit(node.node)
        self.nsstack.pop()

    def visitReturn(self, node):
        log.info("visitReturn: %r", node.value)
        citdl_types = self._guessTypes(node.value)
        for citdl in citdl_types:
            if citdl:
                citdl = citdl.split(None, 1)[0]
                if citdl and citdl not in ("None", "NoneType"):
                    if citdl in ("False", "True"):
                        citdl = "bool"
                    func_node = self.nsstack[-1]
                    t = func_node["returns"]
                    t[citdl] = t.get(citdl, 0) + 1

    def visitClass(self, node):
        log.info("visitClass:%d: %r", node.lineno,
                 self.lines and self.lines[node.lineno-1])
        locals = self.nsstack[-1]
        name = node.name
        nspath = locals["nspath"] + (name,)
        namespace = {
            "nspath": nspath,
            "name": name,
            "types": {"class": 1},
            # XXX Example of a base class that might surprise: the
            #    __metaclass__ class in
            #    c:\python22\lib\site-packages\ctypes\com\automation.py
            #    Should this be self._getCITDLExprRepr()???
            "classrefs": [],
            "symbols": {},
        }
        namespace["declaration"] = namespace

        if node.lineno:
            namespace["line"] = node.lineno
        lastNode = node
        while lastNode.getChildNodes():
            lastNode = lastNode.getChildNodes()[-1]
        if lastNode.lineno:
            namespace["lineend"] = lastNode.lineno

        attributes = []
        if name.startswith("__") and name.endswith("__"):
            pass
        elif name.startswith("__"):
            attributes.append("private")
        elif name.startswith("_"):
            attributes.append("protected")
        namespace["attributes"] = ' '.join(attributes)

        if node.bases:
            for baseNode in node.bases:
                baseName = self._getExprRepr(baseNode)
                classref = {"name": baseName, "types": {}}
                for t in self._guessTypes(baseNode):
                    if t not in classref["types"]:
                        classref["types"][t] = 0
                    classref["types"][t] += 1
                namespace["classrefs"].append(classref)
        if node.doc:
            siglines, desclines = util.parsePyFuncDoc(node.doc)
            if siglines:
                namespace["signature"] = "\n".join(siglines)
            if desclines:
                namespace["doc"] = "\n".join(desclines)
        self.st[nspath] = locals["symbols"][name] = namespace

        self.nsstack.append(namespace)
        self.visit(node.code)
        self.nsstack.pop()

    def visitFunction(self, node):
        log.info("visitFunction:%d: %r", node.lineno,
                 self.lines and self.lines[node.lineno-1])
        parent = self.nsstack[-1]
        parentIsClass = _isclass(parent)

        namespace = {
            "types": {"function": 1},
            "returns": {},
            "arguments": [],
            "symbols": {},
        }

        namespace["declaration"] = namespace
        if node.lineno:
            namespace["line"] = node.lineno
        lastNode = node
        while lastNode.getChildNodes():
            lastNode = lastNode.getChildNodes()[-1]
        if lastNode.lineno:
            namespace["lineend"] = lastNode.lineno

        name = node.name

        # Determine attributes
        attributes = []
        if name.startswith("__") and name.endswith("__"):
            pass
        elif name.startswith("__"):
            attributes.append("private")
        elif name.startswith("_"):
            attributes.append("protected")
        if name == "__init__" and parentIsClass:
            attributes.append("__ctor__")

        # process decorators
        prop_var = None
        if node.decorators:
            for deco in node.decorators.nodes:
                deco_name = getattr(deco, 'name', None)
                prop_mode = None

                if deco_name == 'staticmethod':
                    attributes.append("__staticmethod__")
                    continue
                if deco_name == 'classmethod':
                    attributes.append("__classmethod__")
                    continue
                if deco_name == 'property':
                    prop_mode = 'getter'
                elif hasattr(deco, 'attrname') and deco.attrname in ('getter',
                                                                     'setter',
                                                                     'deleter'):
                    prop_mode = deco.attrname

                if prop_mode:
                    if prop_mode == 'getter':
                        # it's a getter, create a pseudo-var
                        prop_var = parent["symbols"].get(name, None)
                        if prop_var is None:
                            prop_var = dict(name=name,
                                            nspath=parent["nspath"] + (name,),
                                            doc=None,
                                            types={},
                                            symbols={})
                            var_attrs = ['property']
                            if name.startswith("__") and name.endswith("__"):
                                pass
                            elif name.startswith("__"):
                                var_attrs.append("private")
                            elif name.startswith("_"):
                                var_attrs.append("protected")
                            prop_var["attributes"] = ' '.join(var_attrs)
                            prop_var["declaration"] = prop_var
                            parent["symbols"][name] = prop_var

                        if not "is-class-var" in prop_var:
                            prop_var["is-class-var"] = 1

                    # hide the function
                    attributes += ['__hidden__']
                    name += " (property %s)" % prop_mode

                    # only one property decorator makes sense
                    break

        namespace["attributes"] = ' '.join(attributes)

        if parentIsClass and name == "__init__":
            fallbackSig = parent["name"]
        else:
            fallbackSig = name
        namespace["name"] = name

        nspath = parent["nspath"] + (name,)
        namespace["nspath"] = nspath

        # Handle arguments. The format of the relevant Function attributes
        # makes this a little bit of pain.
        defaultArgsBaseIndex = len(node.argnames) - len(node.defaults)
        if node.kwargs:
            defaultArgsBaseIndex -= 1
            if node.varargs:
                defaultArgsBaseIndex -= 1
                varargsIndex = len(node.argnames)-2
            else:
                varargsIndex = None
            kwargsIndex = len(node.argnames)-1
        elif node.varargs:
            defaultArgsBaseIndex -= 1
            varargsIndex = len(node.argnames)-1
            kwargsIndex = None
        else:
            varargsIndex = kwargsIndex = None
        sigArgs = []
        for i in range(len(node.argnames)):
            argOrArgTuple = node.argnames[i]

            if isinstance(argOrArgTuple, tuple):
                # If it is a tuple arg with a default assignment, then we
                # drop that info (except for the sig): too hard and too rare
                # to bother with.
                sigArg = str(argOrArgTuple)
                if i >= defaultArgsBaseIndex:
                    defaultNode = node.defaults[i-defaultArgsBaseIndex]
                    try:
                        default = self._getExprRepr(defaultNode)
                    except PythonCILEError, ex:
                        raise PythonCILEError("unexpected default argument node "
                                              "type for Function '%s': %s"
                                              % (node.name, ex))
                    sigArg += "="+default
                sigArgs.append(sigArg)
                arguments = []
                for argName in argOrArgTuple:
                    argument = {"name": argName,
                                "nspath": nspath+(argName,),
                                "doc": None,
                                "types": {},
                                "line": node.lineno,
                                "symbols": {}}
                    arguments.append(argument)
            else:
                argName = argOrArgTuple
                argument = {"name": argName,
                            "nspath": nspath+(argName,),
                            "doc": None,
                            "types": {},
                            "line": node.lineno,
                            "symbols": {}}
                if i == kwargsIndex:
                    argument["attributes"] = "kwargs"
                    sigArgs.append("**"+argName)
                elif i == varargsIndex:
                    argument["attributes"] = "varargs"
                    sigArgs.append("*"+argName)
                elif i >= defaultArgsBaseIndex:
                    defaultNode = node.defaults[i-defaultArgsBaseIndex]
                    try:
                        argument["default"] = self._getExprRepr(defaultNode)
                    except PythonCILEError, ex:
                        raise PythonCILEError("unexpected default argument node "
                                              "type for Function '%s': %s"
                                              % (node.name, ex))
                    sigArgs.append(argName+'='+argument["default"])
                    for t in self._guessTypes(defaultNode):
                        log.info("guessed type: %s ::= %s", argName, t)
                        if t not in argument["types"]:
                            argument["types"][t] = 0
                        argument["types"][t] += 1
                else:
                    sigArgs.append(argName)

                if i == 0 and parentIsClass:
                    # If this is a class method, then the first arg is the class
                    # instance.
                    className = self.nsstack[-1]["nspath"][-1]
                    argument["types"][className] = 1
                    argument["declaration"] = self.nsstack[-1]
                arguments = [argument]

            for argument in arguments:
                if "declaration" not in argument:
                    argument[
                        "declaration"] = argument  # namespace dict of the declaration
                namespace["arguments"].append(argument)
                namespace["symbols"][argument["name"]] = argument
        # Drop first "self" argument from class method signatures.
        # - This is a little bit of a compromise as the "self" argument
        #   should *sometimes* be included in a method's call signature.
        if _isclass(parent) and sigArgs and "__staticmethod__" not in attributes:
            # Delete the first "self" argument.
            del sigArgs[0]
        fallbackSig += "(%s)" % (", ".join(sigArgs))
        if "__staticmethod__" in attributes:
            fallbackSig += " - staticmethod"
        elif "__classmethod__" in attributes:
            fallbackSig += " - classmethod"
        if node.doc:
            siglines, desclines = util.parsePyFuncDoc(node.doc, [fallbackSig])
            namespace["signature"] = "\n".join(siglines)
            if desclines:
                namespace["doc"] = "\n".join(desclines)
        else:
            namespace["signature"] = fallbackSig
        self.st[nspath] = parent["symbols"][name] = namespace

        self.nsstack.append(namespace)
        self.visit(node.code)
        self.nsstack.pop()

        if prop_var:
            # this is a property getter function,
            # copy its return types to the corresponding property variable...
            var_types = prop_var["types"]
            for t in namespace["returns"]:
                if t not in var_types:
                    var_types[t] = 0
                else:
                    var_types[t] += 1
            # ... as well as its line number
            if "line" in namespace:
                prop_var["line"] = namespace["line"]

    def visitImport(self, node):
        log.info("visitImport:%d: %r", node.lineno,
                 self.lines and self.lines[node.lineno-1])
        imports = self.nsstack[-1].setdefault("imports", [])
        for module, alias in node.names:
            import_ = {"module": module}
            if node.lineno:
                import_["line"] = node.lineno
            if alias:
                import_["alias"] = alias
            imports.append(import_)

    def visitFrom(self, node):
        log.info("visitFrom:%d: %r", node.lineno,
                 self.lines and self.lines[node.lineno-1])
        imports = self.nsstack[-1].setdefault("imports", [])
        module = node.modname
        if node.level > 0:
            module = ("." * node.level) + module
        for symbol, alias in node.names:
            import_ = {"module": module, "symbol": symbol}
            if node.lineno:
                import_["line"] = node.lineno
            if alias:
                import_["alias"] = alias
            imports.append(import_)

    # XXX
    # def visitReturn(self, node):
    #    # set __rettypes__ on Functions
    #    pass
    # def visitGlobal(self, node):
    #    # note for future visitAssign to control namespace
    #    pass
    # def visitYield(self, node):
    #    # modify the Function into a generator??? what are the implications?
    #    pass
    # def visitAssert(self, node):
    #    # support the assert hints that Wing does
    #    pass

    def _assignVariable(self, varName, namespace, rhsNode, line,
                        isClassVar=0):
        """Handle a simple variable name assignment.

            "varName" is the variable name being assign to.
            "namespace" is the namespace dict to which to assign the variable.
            "rhsNode" is the ast.Node of the right-hand side of the
                assignment.
            "line" is the line number on which the variable is being assigned.
            "isClassVar" (optional) is a boolean indicating if this var is
                a class variable, as opposed to an instance variable
        """
        log.debug("_assignVariable(varName=%r, namespace %s, rhsNode=%r, "
                  "line, isClassVar=%r)", varName,
                  '.'.join(namespace["nspath"]), rhsNode, isClassVar)
        variable = namespace["symbols"].get(varName, None)

        new_var = False
        if variable is None:
            new_var = True
            variable = {"name": varName,
                        "nspath": namespace["nspath"]+(varName,),
                        # Could try to parse documentation from a near-by
                        # string.
                        "doc": None,
                        # 'types' is a dict mapping a type name to the number
                        # of times this was guessed as the variable type.
                        "types": {},
                        "symbols": {}}
            # Determine attributes
            attributes = []
            if varName.startswith("__") and varName.endswith("__"):
                pass
            elif varName.startswith("__"):
                attributes.append("private")
            elif varName.startswith("_"):
                attributes.append("protected")
            variable["attributes"] = ' '.join(attributes)

            variable["declaration"] = variable
            if line:
                variable["line"] = line
            namespace["symbols"][varName] = variable

        if isClassVar and not "is-class-var" in variable:
            variable["is-class-var"] = 1
            # line number of first class-level assignment wins
            if line:
                variable["line"] = line

        if (not new_var and
            _isfunction(variable) and
            isinstance(rhsNode, ast.CallFunc) and
            rhsNode.args and
            isinstance(rhsNode.args[0], ast.Name) and
            variable["name"] == rhsNode.args[0].name
            ):
            # a speial case for 2.4-styled decorators
            return

        varTypes = variable["types"]
        for t in self._guessTypes(rhsNode, namespace):
            log.info("guessed type: %s ::= %s", varName, t)
            if t not in varTypes:
                varTypes[t] = 0
            varTypes[t] += 1

    def _visitSimpleAssign(self, lhsNode, rhsNode, line):
        """Handle a simple assignment: assignment to a symbol name or to
        an attribute of a symbol name. If the given left-hand side (lhsNode)
        is not an node type that can be handled, it is dropped.
        """
        log.debug("_visitSimpleAssign(lhsNode=%r, rhsNode=%r)", lhsNode,
                  rhsNode)
        if isinstance(lhsNode, ast.AssName):
            # E.g.:  foo = ...
            # Assign this to the local namespace, unless there was a
            # 'global' statement. (XXX Not handling 'global' yet.)
            ns = self.nsstack[-1]
            self._assignVariable(lhsNode.name, ns, rhsNode, line,
                                 isClassVar=_isclass(ns))
        elif isinstance(lhsNode, ast.AssAttr):
            # E.g.:  foo.bar = ...
            # If we can resolve "foo", then we update that namespace.
            variable, citdl = self._resolveObjectRef(lhsNode.expr)
            if variable:
                self._assignVariable(lhsNode.attrname,
                                     variable["declaration"], rhsNode, line)
        else:
            log.debug("could not handle simple assign (module '%s'): "
                      "lhsNode=%r, rhsNode=%r", self.moduleName, lhsNode,
                      rhsNode)

    def visitAssign(self, node):
        log.info("visitAssign:%d: %r", node.lineno,
                 self.lines and self.lines[node.lineno-1])
        lhsNode = node.nodes[0]
        rhsNode = node.expr
        if isinstance(lhsNode, (ast.AssName, ast.AssAttr)):
            # E.g.:
            #   foo = ...       (AssName)
            #   foo.bar = ...   (AssAttr)
            self._visitSimpleAssign(lhsNode, rhsNode, node.lineno)
        elif isinstance(lhsNode, (ast.AssTuple, ast.AssList)):
            # E.g.:
            #   foo, bar = ...
            #   [foo, bar] = ...
            # If the RHS is a sequence with the same number of elements,
            # then we update each assigned-to variable. Otherwise, bail.
            if isinstance(rhsNode, (ast.Tuple, ast.List)):
                if len(lhsNode.nodes) == len(rhsNode.nodes):
                    for i in range(len(lhsNode.nodes)):
                        self._visitSimpleAssign(lhsNode.nodes[i],
                                                rhsNode.nodes[i],
                                                node.lineno)
            elif isinstance(rhsNode, ast.Dict):
                if len(lhsNode.nodes) == len(rhsNode.items):
                    for i in range(len(lhsNode.nodes)):
                        self._visitSimpleAssign(lhsNode.nodes[i],
                                                rhsNode.items[i][0],
                                                node.lineno)
            elif isinstance(rhsNode, ast.CallFunc):
                for i in range(len(lhsNode.nodes)):
                    self._visitSimpleAssign(lhsNode.nodes[i],
                                            None,  # we don't have a good type.
                                            node.lineno)
            else:
                log.info(
                    "visitAssign:: skipping unknown rhsNode type: %r - %r",
                         type(rhsNode), rhsNode)
        elif isinstance(lhsNode, ast.Slice):
            # E.g.:  bar[1:2] = "foo"
            # We don't bother with these: too hard.
            log.info("visitAssign:: skipping slice - too hard")
            pass
        elif isinstance(lhsNode, ast.Subscript):
            # E.g.:  bar[1] = "foo"
            # We don't bother with these: too hard.
            log.info("visitAssign:: skipping subscript - too hard")
            pass
        else:
            raise PythonCILEError("unexpected type of LHS of assignment: %r"
                                  % lhsNode)

    def _handleUnknownAssignment(self, assignNode, lineno):
        if isinstance(assignNode, ast.AssName):
            self._visitSimpleAssign(assignNode, None, lineno)
        elif isinstance(assignNode, ast.AssTuple):
            for anode in assignNode.nodes:
                self._visitSimpleAssign(anode, None, lineno)

    def visitFor(self, node):
        log.info("visitFor:%d: %r", node.lineno,
                 self.lines and self.lines[node.lineno-1])
        # E.g.:
        #   for foo in ...
        # None: don't bother trying to resolve the type of the RHS
        self._handleUnknownAssignment(node.assign, node.lineno)
        self.visit(node.body)

    def visitWith(self, node):
        log.info("visitWith:%d: %r", node.lineno,
                 self.lines and self.lines[node.lineno-1])
        self._handleUnknownAssignment(node.vars, node.lineno)
        self.visit(node.body)

    def visitTryExcept(self, node):
        log.info("visitTryExcept:%d: %r", node.lineno,
                 self.lines and self.lines[node.lineno-1])
        self.visit(node.body)
        for handler in node.handlers:
            try:
                if handler[1]:
                    try:
                        lineno = handler[1].lineno
                    except AttributeError:
                        lineno = node.lineno
                    self._handleUnknownAssignment(handler[1], lineno)
                if handler[2]:
                    self.visit(handler[2])
            except IndexError:
                pass
        if node.else_:
            self.visit(node.else_)

    def _resolveObjectRef(self, expr):
        """Try to resolve the given expression to a variable namespace.

            "expr" is some kind of ast.Node instance.

        Returns the following 2-tuple for the object:
            (<variable dict>, <CITDL string>)
        where,
            <variable dict> is the defining dict for the variable, e.g.
                    {'name': 'classvar', 'types': {'int': 1}}.
                This is None if the variable could not be resolved.
            <CITDL string> is a string of CITDL code (see the spec) describing
                how to resolve the variable later. This is None if the
                variable could be resolved or if the expression is not
                expressible in CITDL (CITDL does not attempt to be a panacea).
        """
        log.debug("_resolveObjectRef(expr=%r)", expr)
        if isinstance(expr, ast.Name):
            name = expr.name
            nspath = self.nsstack[-1]["nspath"]
            for i in range(len(nspath), -1, -1):
                ns = self.st[nspath[:i]]
                if name in ns["symbols"]:
                    return (ns["symbols"][name], None)
                else:
                    log.debug(
                        "_resolveObjectRef: %r not in namespace %r", name,
                              '.'.join(ns["nspath"]))
        elif isinstance(expr, ast.Getattr):
            obj, citdl = self._resolveObjectRef(expr.expr)
            decl = obj and obj["declaration"] or None  # want the declaration
            if (decl  # and "symbols" in decl #XXX this "and"-part necessary?
                and expr.attrname in decl["symbols"]):
                return (decl["symbols"][expr.attrname], None)
            elif isinstance(expr.expr, ast.Const):
                # Special case: specifically refer to type object for
                # attribute access on constants, e.g.:
                #   ' '.join
                citdl = "__builtins__.%s.%s"\
                        % ((type(expr.expr.value).__name__), expr.attrname)
                return (None, citdl)
                # XXX Could optimize here for common built-in attributes. E.g.,
                #    we *know* that str.join() returns a string.
        elif isinstance(expr, ast.Const):
            # Special case: specifically refer to type object for constants.
            return (None, "__builtins__.%s" % type(expr.value).__name__)
        elif isinstance(expr, ast.CallFunc):
            # XXX Would need flow analysis to have an object dict for whatever
            #    a __call__ would return.
            pass

        # Fallback: return CITDL code for delayed resolution.
        log.debug("_resolveObjectRef: could not resolve %r", expr)
        scope = '.'.join(self.nsstack[-1]["nspath"])
        exprrepr = self._getCITDLExprRepr(expr)
        if exprrepr:
            if scope:
                citdl = "%s %s" % (exprrepr, scope)
            else:
                citdl = exprrepr
        else:
            citdl = None
        return (None, citdl)

    def _guessTypes(self, expr, curr_ns=None):
        log.debug("_guessTypes(expr=%r)", expr)
        ts = []
        if isinstance(expr, ast.Const):
            ts = [type(expr.value).__name__]
        elif isinstance(expr, ast.Tuple):
            ts = [tuple.__name__]
        elif isinstance(expr, (ast.List, ast.ListComp)):
            ts = [list.__name__]
        elif hasattr(ast, 'Set') and isinstance(expr, ast.Set):
            ts = [set.__name__]
        elif isinstance(expr, ast.Dict):
            ts = [dict.__name__]
        elif isinstance(expr, (ast.Add, ast.Sub, ast.Mul, ast.Div, ast.Mod,
                               ast.Power)):
            order = ["int", "bool", "long", "float", "complex", "string",
                     "unicode"]
            possibles = self._guessTypes(
                expr.left)+self._guessTypes(expr.right)
            ts = []
            highest = -1
            for possible in possibles:
                if possible not in order:
                    ts.append(possible)
                else:
                    highest = max(highest, order.index(possible))
            if not ts and highest > -1:
                ts = [order[highest]]
        elif isinstance(expr, (ast.FloorDiv, ast.Bitand, ast.Bitor,
                               ast.Bitxor, ast.RightShift, ast.LeftShift)):
            ts = [int.__name__]
        elif isinstance(expr, (ast.Or, ast.And)):
            ts = []
            for node in expr.nodes:
                for t in self._guessTypes(node):
                    if t not in ts:
                        ts.append(t)
        elif isinstance(expr, (ast.Compare, ast.Not)):
            ts = [type(1 == 2).__name__]
        elif isinstance(expr, (ast.UnaryAdd, ast.UnarySub, ast.Invert,
                               ast.Not)):
            ts = self._guessTypes(expr.expr)
        elif isinstance(expr, ast.Slice):
            ts = [list.__name__]
        elif isinstance(expr, ast.Backquote):
            ts = [str.__name__]

        elif isinstance(expr, (ast.Name, ast.Getattr)):
            variable, citdl = self._resolveObjectRef(expr)
            if variable:
                if _isclass(variable) or _isfunction(variable):
                    ts = ['.'.join(variable["nspath"])]
                else:
                    ts = variable["types"].keys()
            elif citdl:
                ts = [citdl]
        elif isinstance(expr, ast.CallFunc):
            variable, citdl = self._resolveObjectRef(expr.node)
            if variable:
                # XXX When/if we support <returns/> and if we have that
                #    info for this 'variable' we can return an actual
                #    value here.
                # Optmizing Shortcut: If the variable is a class then just
                # call its type that class definition, i.e. 'mymodule.MyClass'
                # instead of 'type(call(mymodule.MyClass))'.

                # Remove the common leading namespace elements.
                scope_parts = list(variable["nspath"])
                if curr_ns is not None:
                    for part in curr_ns["nspath"]:
                        if scope_parts and part == scope_parts[0]:
                            scope_parts.pop(0)
                        else:
                            break
                scope = '.'.join(scope_parts)
                if _isclass(variable):
                    ts = [scope]
                else:
                    ts = [scope+"()"]
            elif citdl:
                # For code like this:
                #   for line in lines:
                #       line = line.rstrip()
                # this results in a type guess of "line.rstrip <funcname>".
                # That sucks. Really it should at least be line.rstrip() so
                # that runtime CITDL evaluation can try to determine that
                # rstrip() is a _function_ call rather than _class creation_,
                # which is the current resuilt. (c.f. bug 33493)
                # XXX We *could* attempt to guess based on where we know
                #     "line" to be a module import: the only way that
                #     'rstrip' could be a class rather than a function.
                # TW: I think it should always use "()" no matter if it's
                #     a class or a function. The codeintel handler can work
                #     out which one it is. This gives us the ability to then
                #     distinguish between class methods and instance methods,
                #     as class methods look like:
                #       MyClass.staticmethod()
                #     and instance methods like:
                #       MyClass().instancemethod()
                # Updated to use "()".
                # Ensure we only add the "()" to the type part, not to the
                # scope (if it exists) part, which is separated by a space. Bug:
                #   http://bugs.activestate.com/show_bug.cgi?id=71987
                # citdl in this case looks like "string.split myfunction"
                ts = citdl.split(None, 1)
                ts[0] += "()"
                ts = [" ".join(ts)]
        elif isinstance(expr, (ast.Subscript, ast.Lambda)):
            pass
        else:
            log.info("don't know how to guess types from this expr: %r" % expr)
        return ts

    def _getExprRepr(self, node):
        """Return a string representation for this Python expression.

        Raises PythonCILEError if can't do it.
        """
        s = None
        if isinstance(node, ast.Name):
            s = node.name
        elif isinstance(node, ast.Const):
            s = repr(node.value)
        elif isinstance(node, ast.Getattr):
            s = '.'.join([self._getExprRepr(node.expr), node.attrname])
        elif isinstance(node, ast.List):
            items = [self._getExprRepr(c) for c in node.getChildren()]
            s = "[%s]" % ", ".join(items)
        elif isinstance(node, ast.Tuple):
            items = [self._getExprRepr(c) for c in node.getChildren()]
            s = "(%s)" % ", ".join(items)
        elif hasattr(ast, 'Set') and isinstance(node, ast.Set):
            items = [self._getExprRepr(c) for c in node.getChildren()]
            s = "{%s}" % ", ".join(items)
        elif isinstance(node, ast.Dict):
            items = ["%s: %s" % (self._getExprRepr(k), self._getExprRepr(v))
                     for (k, v) in node.items]
            s = "{%s}" % ", ".join(items)
        elif isinstance(node, ast.CallFunc):
            s = self._getExprRepr(node.node)
            s += "("
            allargs = []
            for arg in node.args:
                allargs.append(self._getExprRepr(arg))
            if node.star_args:
                for arg in node.star_args:
                    allargs.append("*" + self._getExprRepr(arg))
            if node.dstar_args:
                for arg in node.dstar_args:
                    allargs.append("**" + self._getExprRepr(arg))
            s += ",".join(allargs)
            s += ")"
        elif isinstance(node, ast.Subscript):
            s = "[%s]" % self._getExprRepr(node.expr)
        elif isinstance(node, ast.Backquote):
            s = "`%s`" % self._getExprRepr(node.expr)
        elif isinstance(node, ast.Slice):
            dumpNode(node)
            s = self._getExprRepr(node.expr)
            s += "["
            if node.lower:
                s += self._getExprRepr(node.lower)
            s += ":"
            if node.upper:
                s += self._getExprRepr(node.upper)
            s += "]"
        elif isinstance(node, ast.UnarySub):
            s = "-" + self._getExprRepr(node.expr)
        elif isinstance(node, ast.UnaryAdd):
            s = "+" + self._getExprRepr(node.expr)
        elif isinstance(node, ast.Add):
            s = self._getExprRepr(
                node.left) + "+" + self._getExprRepr(node.right)
        elif isinstance(node, ast.Sub):
            s = self._getExprRepr(
                node.left) + "-" + self._getExprRepr(node.right)
        elif isinstance(node, ast.Mul):
            s = self._getExprRepr(
                node.left) + "*" + self._getExprRepr(node.right)
        elif isinstance(node, ast.Div):
            s = self._getExprRepr(
                node.left) + "/" + self._getExprRepr(node.right)
        elif isinstance(node, ast.FloorDiv):
            s = self._getExprRepr(
                node.left) + "//" + self._getExprRepr(node.right)
        elif isinstance(node, ast.Mod):
            s = self._getExprRepr(
                node.left) + "%" + self._getExprRepr(node.right)
        elif isinstance(node, ast.Power):
            s = self._getExprRepr(
                node.left) + "**" + self._getExprRepr(node.right)
        elif isinstance(node, ast.LeftShift):
            s = self._getExprRepr(
                node.left) + "<<" + self._getExprRepr(node.right)
        elif isinstance(node, ast.RightShift):
            s = self._getExprRepr(
                node.left) + ">>" + self._getExprRepr(node.right)
        elif isinstance(node, ast.Keyword):
            s = node.name + "=" + self._getExprRepr(node.expr)
        elif isinstance(node, ast.Bitor):
            creprs = []
            for cnode in node.nodes:
                if isinstance(cnode, (ast.Const, ast.Name)):
                    crepr = self._getExprRepr(cnode)
                else:
                    crepr = "(%s)" % self._getExprRepr(cnode)
                creprs.append(crepr)
            s = "|".join(creprs)
        elif isinstance(node, ast.Bitand):
            creprs = []
            for cnode in node.nodes:
                if isinstance(cnode, (ast.Const, ast.Name)):
                    crepr = self._getExprRepr(cnode)
                else:
                    crepr = "(%s)" % self._getExprRepr(cnode)
                creprs.append(crepr)
            s = "&".join(creprs)
        elif isinstance(node, ast.Bitxor):
            creprs = []
            for cnode in node.nodes:
                if isinstance(cnode, (ast.Const, ast.Name)):
                    crepr = self._getExprRepr(cnode)
                else:
                    crepr = "(%s)" % self._getExprRepr(cnode)
                creprs.append(crepr)
            s = "^".join(creprs)
        elif isinstance(node, ast.Lambda):
            s = "lambda"
            defaultArgsBaseIndex = len(node.argnames) - len(node.defaults)
            if node.kwargs:
                defaultArgsBaseIndex -= 1
                if node.varargs:
                    defaultArgsBaseIndex -= 1
                    varargsIndex = len(node.argnames)-2
                else:
                    varargsIndex = None
                kwargsIndex = len(node.argnames)-1
            elif node.varargs:
                defaultArgsBaseIndex -= 1
                varargsIndex = len(node.argnames)-1
                kwargsIndex = None
            else:
                varargsIndex = kwargsIndex = None
            args = []
            for i in range(len(node.argnames)):
                argOrArgTuple = node.argnames[i]
                if isinstance(argOrArgTuple, tuple):
                    arg = "(%s)" % ','.join(argOrArgTuple)
                    if i >= defaultArgsBaseIndex:
                        defaultNode = node.defaults[i-defaultArgsBaseIndex]
                        try:
                            arg += "="+self._getExprRepr(defaultNode)
                        except PythonCILEError:
                            # XXX Work around some trouble cases.
                            arg += arg+"=..."
                else:
                    argname = node.argnames[i]
                    if i == kwargsIndex:
                        arg = "**"+argname
                    elif i == varargsIndex:
                        arg = "*"+argname
                    elif i >= defaultArgsBaseIndex:
                        defaultNode = node.defaults[i-defaultArgsBaseIndex]
                        try:
                            arg = argname+"="+self._getExprRepr(defaultNode)
                        except PythonCILEError:
                            # XXX Work around some trouble cases.
                            arg = argname+"=..."
                    else:
                        arg = argname
                args.append(arg)
            if args:
                s += " " + ",".join(args)
            try:
                s += ": " + self._getExprRepr(node.code)
            except PythonCILEError:
                # XXX Work around some trouble cases.
                s += ":..."
        else:
            raise PythonCILEError("don't know how to get string repr "
                                  "of expression: %r" % node)
        return s

    def _getCITDLExprRepr(self, node, _level=0):
        """Return a string repr for this expression that CITDL processing
        can handle.

        CITDL is no panacea -- it is meant to provide simple delayed type
        determination. As a result, many complicated expressions cannot
        be handled. If the expression is not with CITDL's scope, then None
        is returned.
        """
        s = None
        if isinstance(node, ast.Name):
            s = node.name
        elif isinstance(node, ast.Const):
            s = repr(node.value)
        elif isinstance(node, ast.Getattr):
            exprRepr = self._getCITDLExprRepr(node.expr, _level+1)
            if exprRepr is None:
                pass
            else:
                s = '.'.join([exprRepr, node.attrname])
        elif isinstance(node, ast.List):
            s = "[]"
        elif isinstance(node, ast.Tuple):
            s = "()"
        elif hasattr(ast, 'Set') and isinstance(node, ast.Set):
            s = "set()"
        elif isinstance(node, ast.Dict):
            s = "{}"
        elif isinstance(node, ast.CallFunc):
            # Only allow CallFunc at the top-level. I.e. this:
            #   spam.ham.eggs()
            # is in scope, but this:
            #   spam.ham().eggs
            # is not.
            if _level != 0:
                pass
            else:
                s = self._getCITDLExprRepr(node.node, _level+1)
                if s is not None:
                    s += "()"
        return s


def _quietCompilerParse(content):
    oldstderr = sys.stderr
    sys.stderr = StringIO()
    try:
        return compiler.parse(content)
    finally:
        sys.stderr = oldstderr


def _quietCompile(source, filename, kind):
    oldstderr = sys.stderr
    sys.stderr = StringIO()
    try:
        return compile(source, filename, kind)
    finally:
        sys.stderr = oldstderr


def _getAST(content):
    """Return an AST for the given Python content.

    If cannot, raise an error describing the problem.
    """
    # EOL issues:
    # compiler.parse() can't handle '\r\n' EOLs on Mac OS X and can't
    # handle '\r' EOLs on any platform. Let's just always normalize.
    # Unfortunately this is work only for the exceptional case. The
    # problem is most acute on the Mac.
    content = '\n'.join(content.splitlines(0))
    # Is this faster?
    #   content = content.replace('\r\n', '\n').replace('\r', '\n')

    errlineno = None  # line number of a SyntaxError
    ast_ = None
    try:
        ast_ = _quietCompilerParse(content)
    except SyntaxError, ex:
        errlineno = ex.lineno
        log.debug("compiler parse #1: syntax error on line %d", errlineno)
    except parser.ParserError, ex:
        log.debug("compiler parse #1: parse error")
        # Try to get the offending line number.
        # compile() only likes LFs for EOLs.
        lfContent = content.replace("\r\n", "\n").replace("\r", "\n")
        try:
            _quietCompile(lfContent, "dummy.py", "exec")
        except SyntaxError, ex2:
            errlineno = ex2.lineno
        except:
            pass
        if errlineno is None:
            raise  # Does this re-raise 'ex' (as we want) or 'ex2'?

    if errlineno is not None:
        # There was a syntax error at this line: try to recover by effectively
        # nulling out the offending line.
        lines = content.splitlines(1)
        offender = lines[errlineno-1]
        log.info("syntax error on line %d: %r: trying to recover",
                 errlineno, offender)
        indent = ''
        for i in range(0, len(offender)):
            if offender[i] in " \t":
                indent += offender[i]
            else:
                break
        lines[errlineno-1] = indent+"pass"+"\n"
        newContent = ''.join(lines)

        errlineno2 = None
        try:
            ast_ = _quietCompilerParse(newContent)
        except SyntaxError, ex:
            errlineno2 = ex.lineno
            log.debug("compiler parse #2: syntax error on line %d", errlineno)
        except parser.ParserError, ex:
            log.debug("compiler parse #2: parse error")
            # Try to get the offending line number.
            # compile() only likes LFs for EOLs.
            lfContent = newContent.replace("\r\n", "\n").replace("\r", "\n")
            try:
                _quietCompile(lfContent, "dummy.py", "exec")
            except SyntaxError, ex2:
                errlineno2 = ex2.lineno
            except:
                pass
            if errlineno2 is None:
                raise

        if ast_ is not None:
            pass
        elif errlineno2 == errlineno:
            raise ValueError("cannot recover from syntax error: line %d"
                             % errlineno)
        else:
            raise ValueError("cannot recover from multiple syntax errors: "
                             "line %d and then %d" % (errlineno, errlineno2))

    if ast_ is None:
        raise ValueError("could not generate AST")

    return ast_


_rx_cache = {}


def _rx(pattern, flags=0):
    if pattern not in _rx_cache:
        _rx_cache[pattern] = re.compile(pattern, flags)
    return _rx_cache[pattern]


def _convert3to2(src):
    # XXX: this might be much faster to do all this stuff by manipulating
    #      parse trees produced by tdparser

    # except Foo as bar => except (Foo,) bar
    src = _rx(r'(\bexcept\s*)(\S.+?)\s+as\s+(\w+)\s*:').sub(
        r'\1(\2,), \3:', src)

    # 0o123 => 123
    src = _rx(r'\b0[oO](\d+)').sub(r'\1', src)

    # print(foo) => print_(foo)
    src = _rx(r'\bprint\s*\(').sub(r'print_(', src)

    # change forms of class Foo(metaclass=Cls3) to class Foo
    src = _rx(r'(\bclass\s+\w+\s*)\(\s*\w+\s*=\s*\w+\s*\)\s*:').sub(
        r'\1:', src)

    # change forms of class Foo(..., arg=Base1, metaclass=Cls3) to class
    # Foo(...)
    src = _rx(r'(\bclass\s+\w+\s*\(.*?),?\s*\w+\s*=.+?\)\s*:').sub(
        r'\1):', src)

    # Remove return type annotations like def foo() -> int:
    src = _rx(r'(\bdef\s+\w+\s*\(.*?\))\s*->\s*\w+\s*:').sub(r'\1:', src)

    # def foo(foo:Bar, baz=lambda x: qoox): => def foo(bar, baz=_lambda(qoox)):
    src = _rx(r'(\bdef\s+\w+\s*\()(.+?)(\)\s*:)').sub(_clean_func_args, src)

    return src


def _clean_func_args(defn):
    argdef = defn.group(2)

    parser = tdparser.PyExprParser()
    try:
        arglist = parser.parse_bare_arglist(argdef)

        seen_args = False
        seen_kw = False
        py2 = []
        for arg in arglist:
            name, value, type = arg
            if name.id == "*":
                if not seen_kw:
                    name.value = "**kwargs"
                    py2.append(arg)
                    seen_kw = True
                    seen_args = True
            elif name.value[:2] == "**":
                if not seen_kw:
                    py2.append(arg)
                    seen_kw = True
                    seen_args = True
            elif name.value[0] == "*":
                if not seen_args:
                    seen_args = True
                    py2.append(arg)
            else:
                if seen_args or seen_kw:
                    break
                else:
                    py2.append(arg)

        cleared = tdparser.arg_list_py(py2)
    except tdparser.ParseError, ex:
        cleared = argdef
        log.exception("Couldn't parse (%r)" % argdef)

    return defn.group(1) + cleared + defn.group(3)


#---- public module interface

def scan_cix(content, filename, md5sum=None, mtime=None, lang="Python"):
    """Scan the given Python content and return Code Intelligence data
    conforming the the Code Intelligence XML format.

        "content" is the Python content to scan. This should be an
            encoded string: must be a string for `md5` and
            `compiler.parse` -- see bug 73461.
        "filename" is the source of the Python content (used in the
            generated output).
        "md5sum" (optional) if the MD5 hexdigest has already been calculated
            for the content, it can be passed in here. Otherwise this
            is calculated.
        "mtime" (optional) is a modified time for the file (in seconds since
            the "epoch"). If it is not specified the _current_ time is used.
            Note that the default is not to stat() the file and use that
            because the given content might not reflect the saved file state.
        "lang" (optional) is the language of the given file content.
            Typically this is "Python" (i.e. a pure Python file), but it
            may also be "DjangoHTML" or similar for Python embedded in
            other documents.
        XXX Add an optional 'eoltype' so that it need not be
            re-calculated if already known.

    This can raise one of SyntaxError, PythonCILEError or parser.ParserError
    if there was an error processing. Currently this implementation uses the
    Python 'compiler' package for processing, therefore the given Python
    content must be syntactically correct.
    """
    codeintel = scan_et(content, filename, md5sum, mtime, lang)
    tree = et.ElementTree(codeintel)

    stream = StringIO()

    # this is against the W3C spec, but ElementTree wants it lowercase
    tree.write(stream, "utf-8")

    raw_cix = stream.getvalue()

    # XXX: why this 0xA -> &#xA; conversion is necessary?
    #      It makes no sense, but some tests break without it
    #      (like cile/scaninputs/path:cdata_close.py)
    cix = raw_cix.replace('\x0a', '&#xA;')

    return cix


def scan_et(content, filename, md5sum=None, mtime=None, lang="Python"):
    """Scan the given Python content and return Code Intelligence data
    conforming the the Code Intelligence XML format.

        "content" is the Python content to scan. This should be an
            encoded string: must be a string for `md5` and
            `compiler.parse` -- see bug 73461.
        "filename" is the source of the Python content (used in the
            generated output).
        "md5sum" (optional) if the MD5 hexdigest has already been calculated
            for the content, it can be passed in here. Otherwise this
            is calculated.
        "mtime" (optional) is a modified time for the file (in seconds since
            the "epoch"). If it is not specified the _current_ time is used.
            Note that the default is not to stat() the file and use that
            because the given content might not reflect the saved file state.
        "lang" (optional) is the language of the given file content.
            Typically this is "Python" (i.e. a pure Python file), but it
            may also be "DjangoHTML" or similar for Python embedded in
            other documents.
        XXX Add an optional 'eoltype' so that it need not be
            re-calculated if already known.

    This can raise one of SyntaxError, PythonCILEError or parser.ParserError
    if there was an error processing. Currently this implementation uses the
    Python 'compiler' package for processing, therefore the given Python
    content must be syntactically correct.
    """
    log.info("scan '%s'", filename)
    if md5sum is None:
        md5sum = md5(content).hexdigest()
    if mtime is None:
        mtime = int(time.time())

    # 'compiler' both (1) wants a newline at the end and (2) can fail on
    # funky *whitespace* at the end of the file.
    content = content.rstrip() + '\n'

    if lang == "Python3":
        # Make Python3 code as compatible with pythoncile's Python2
        # parser as neessary for codeintel purposes.
        content = _convert3to2(content)

    if isinstance(filename, types.UnicodeType):
        filename = filename.encode('utf-8')
    # The 'path' attribute must use normalized dir separators.
    if sys.platform.startswith("win"):
        path = filename.replace('\\', '/')
    else:
        path = filename

    try:
        ast_ = _getAST(content)
        if _gClockIt:
            sys.stdout.write(" (ast:%.3fs)" % (_gClock()-_gStartTime))
    except Exception, ex:
        file = et.Element('file', _et_attrs(dict(lang=lang,
                                                 path=path,
                                                 error=str(ex))))
    else:
        moduleName = os.path.splitext(os.path.basename(filename))[0]
        visitor = AST2CIXVisitor(moduleName, content=content, lang=lang)
        if log.isEnabledFor(logging.DEBUG):
            walker = ExampleASTVisitor()
            walker.VERBOSE = 1
        else:
            walker = None
        compiler.walk(ast_, visitor, walker)
        if _gClockIt:
            sys.stdout.write(" (walk:%.3fs)" % (_gClock()-_gStartTime))
        if log.isEnabledFor(logging.INFO):
            # Dump a repr of the gathering info for debugging
            # - We only have to dump the module namespace because
            #   everything else should be linked from it.
            for nspath, namespace in visitor.st.items():
                if len(nspath) == 0:  # this is the module namespace
                    pprint.pprint(namespace)

        file = visitor.getCIX(path)
        if _gClockIt:
            sys.stdout.write(" (getCIX:%.3fs)" % (_gClock()-_gStartTime))

    codeintel = et.Element('codeintel', _et_attrs(dict(version="2.0")))
    codeintel.append(file)
    return codeintel


#---- mainline
def main(argv):
    logging.basicConfig()

    # Parse options.
    try:
        opts, args = getopt.getopt(argv[1:], "Vvhf:cL:",
            ["version", "verbose", "help", "filename=", "md5=", "mtime=",
             "clock", "language="])
    except getopt.GetoptError, ex:
        log.error(str(ex))
        log.error("Try `pythoncile --help'.")
        return 1
    numVerboses = 0
    stdinFilename = None
    md5sum = None
    mtime = None
    lang = "Python"
    global _gClockIt
    for opt, optarg in opts:
        if opt in ("-h", "--help"):
            sys.stdout.write(__doc__)
            return
        elif opt in ("-V", "--version"):
            ver = '.'.join([str(part) for part in _version_])
            print "pythoncile %s" % ver
            return
        elif opt in ("-v", "--verbose"):
            numVerboses += 1
            if numVerboses == 1:
                log.setLevel(logging.INFO)
            else:
                log.setLevel(logging.DEBUG)
        elif opt in ("-f", "--filename"):
            stdinFilename = optarg
        elif opt in ("-L", "--language"):
            lang = optarg
        elif opt in ("--md5",):
            md5sum = optarg
        elif opt in ("--mtime",):
            mtime = optarg
        elif opt in ("-c", "--clock"):
            _gClockIt = 1
            import time
            global _gClock
            if sys.platform.startswith("win"):
                _gClock = time.clock
            else:
                _gClock = time.time

    if len(args) == 0:
        contentOnStdin = 1
        filenames = [stdinFilename or "<stdin>"]
    else:
        contentOnStdin = 0
        paths = []
        for arg in args:
            paths += glob.glob(arg)
        filenames = []
        for path in paths:
            if os.path.isfile(path):
                filenames.append(path)
            elif os.path.isdir(path):
                pyfiles = [os.path.join(path, n) for n in os.listdir(path)
                           if os.path.splitext(n)[1] == ".py"]
                pyfiles = [f for f in pyfiles if os.path.isfile(f)]
                filenames += pyfiles

    try:
        for filename in filenames:
            if contentOnStdin:
                log.debug("reading content from stdin")
                content = sys.stdin.read()
                log.debug("finished reading content from stdin")
                if mtime is None:
                    mtime = int(time.time())
            else:
                if mtime is None:
                    mtime = int(os.stat(filename)[stat.ST_MTIME])
                fin = open(filename, 'r')
                try:
                    content = fin.read()
                finally:
                    fin.close()

            if _gClockIt:
                sys.stdout.write("scanning '%s'..." % filename)
                global _gStartTime
                _gStartTime = _gClock()
            data = scan_cix(content, filename, md5sum=md5sum, mtime=mtime,
                            lang=lang)
            if _gClockIt:
                sys.stdout.write(" %.3fs\n" % (_gClock()-_gStartTime))
            elif data:
                sys.stdout.write(data)
    except PythonCILEError, ex:
        log.error(str(ex))
        if log.isEnabledFor(logging.DEBUG):
            print
            import traceback
            traceback.print_exception(*sys.exc_info())
        return 1
    except KeyboardInterrupt:
        log.debug("user abort")
        return 1


if __name__ == "__main__":
    sys.exit(main(sys.argv))

########NEW FILE########
__FILENAME__ = pythoncile2
#!/usr/bin/env python

"""A re-write a pythoncile.py using lib2to3 to be able to support Python 3
syntax.

To play along
=============

1. Get a local codeintel build:

    cd src/codeintel
    . bin/setenv.sh    # `bin\setenv.bat` on Windows
    python Makefile.py all

2. Get a local copy of lib2to3 from Python's SVN into codeintel's lib dir
   and patch it with our current modifications.

    cd lib
    svn co http://svn.python.org/projects/sandbox/trunk/2to3/lib2to3
    patch -p0 < ../play/lib2to3.patch
    cd ..

3. Setup an alias called 'pycile' (adjusting the path to Komodo accordingly)

    # Bash
    alias pycile="python2.6 $HOME/as/komodo/src/codeintel/lib/codeintel2/pythoncile2.py"

    # "pycile.bat" for Windows
    @python26 C:\trentm\as\komodo\src\codeintel\lib\codeintel2\pythoncile2.py %*

4. Run 'pycile' on files.

    pycile play\sample.py     # dumps CIX output
    pycile -v play\sample.py  # also pprints the syntax tree from lib2to3
    pycile -vc play\sample.py # compares with CIX from pythoncile.py
"""
# TODO:
# - foo.bar assignments for class instance vars
# - improved type inferencing: raven.py diffs, hi.py, assign.py
# - pass significant set of test suite
# - perf
# - python 2 vs python 3 handling
#
# CIX differences to check:
# - Is it necessary that <import>'s are at the top of their scope, even if
#   not matching the file order? I.e. does the Python evalr use this side-effect?
#
# Syntax TODO:
# - function and class type annonations
# - returns in functions
# - generators
# - local import syntax (play/imports.py -> put in test suite)
# - decorators (on functions and classes)
# - special handling for @classmethod, @staticmethod, @property
# - anything necessary with metaclasses?
# - kwargs to class "bases": used for Python 3 metaclasses, at least
# - global stmt
# - nonlocal stmt (http://docs.python.org/3.0/reference/simple_stmts.html#the-nonlocal-statement)
# - type inferencing as good (plus new types, no unicode, new bytes) as
#   pythoncile.py:_guessTypes
# - tuple-unpacking in function args (dropped in Python 3, but still in
#   older Python 2 syntax)
# - `a, ..., b = blah()` unpacking (and the other forms of this)
#
# New features TODO:
# - support for pythondoc-style type annotations
# - type inferencing from isinstance calls
# - type inferencing from common, well-known methods (e.g. string methods,
#   dict and list methods)

__version_info__ = (2, 0, 0)
__version__ = '2.0.0'  # TODO: map/str thing


import sys
import os
from os.path import *
import time
import logging
import difflib
import re
import optparse
import types
# XXX Use ciElementTree eventually.
from xml.etree import cElementTree as ET
from collections import deque, defaultdict
import itertools
from hashlib import md5
from pprint import pprint


_komodo_src_dir = dirname(dirname(dirname(dirname(abspath(__file__)))))
sys.path.insert(0, join(_komodo_src_dir, "python-sitelib"))
sys.path.insert(0, join(_komodo_src_dir, "codeintel", "lib"))
from codeintel2.tree import pretty_tree_from_tree
from codeintel2 import util

import lib2to3   # should be in codeintel/lib/lib2to3 (read "to play along" above)
from lib2to3.pgen2 import driver
from lib2to3 import pytree, pygram
from lib2to3.pygram import python_symbols
from lib2to3.pgen2 import token

#---- globals

_gOExtraMile = True
_gClockIt = 0   # if true then we are gathering timing data
_gClock = None  # if gathering timing data this is set to time retrieval fn
_gStartTime = None   # start time of current file being scanned

log = logging.getLogger("pythoncile2")


#---- exceptions

class PythonCILEError(Exception):
    pass


#---- core module stuff

def pythoncile2(path, content=None):
    if False:
        # This tweak to the python grammar allows the parser to parse Python 3
        # content. Else it will choke on, at least, the keyword argument in
        # this:
        #       print("foo", file=sys.stderr)
        # TODO: understand why this is
        del pygram.python_grammar.keywords["print"]
    else:
        # However, to parse Python 2 with print as a statement, we need that
        # grammar item.
        # TODO: not sure about Python 2 code with `from __future__ import
        # print_function`
        pass
    dvr = driver.Driver(pygram.python_grammar,
                        convert=pytree.convert,
                        logger=log)

    # Based on `RefactoringTool.refactor_string()`.
    if content is None:
        data = open(path, 'r').read() + '\n'
    else:
        data = content
    # try:
    #    tree = dvr.parse_string(data)
    # except Exception, err:
    #    raise PythonCILEError("Can't parse %s: %s: %s" % (
    #       path, err.__class__.__name__, err))
    ast = dvr.parse_string(data)
    if log.isEnabledFor(logging.DEBUG):
        ast.pprint(indent="`   ")

    # Traverse the AST (actually more of a concrete syntax tree).
    blob = Scope("blob", splitext(basename(path))[0],
                 lang="Python", src=path)
    scanner = Scanner(blob)
    scanner.scan(ast)

    # Build the CIX tree.
    now = time.time()
    codeintel = ET.Element("codeintel", version="2.0")
    file = ET.SubElement(codeintel, "file", lang="Python", mtime=str(now),
                         path=path)
    scanner.gen_cix_tree(file)

    return codeintel


class Scope(dict):
    parent = None

    def __init__(self, ilk, name, **attrs):
        self.ilk = ilk
        self.name = name
        self.attrs = attrs
        # Ordered list of children. Note: the children are also indexed on
        # this scope's dict by name.
        self.children = []

    def __repr__(self):
        return "<Scope: %s '%s'>" % (self.ilk, self.name)

    def _add_child(self, child):
        self.children.append(child)
        self[child.name] = child
        child.parent = self
        return child

    def add_variable(self, name, **attrs):
        return self._add_child(Variable(name, **attrs))

    def add_argument(self, name, **attrs):
        return self._add_child(Argument(name, **attrs))

    def add_scope(self, ilk, name, **attrs):
        return self._add_child(Scope(ilk, name, **attrs))

    def gen_cix_tree(self, parent_elem):
        elem = ET.SubElement(parent_elem, "scope", ilk=self.ilk,
                             name=self.name, **self.attrs)
        for child in self.children:
            child.gen_cix_tree(elem)


class Variable(object):
    parent = None

    def __init__(self, name, **attrs):
        self.name = name
        self.attrs = attrs
        self.citdl_nodes = []

    def __repr__(self):
        return "<Variable: '%s'>" % self.name

    def gen_cix_tree(self, parent_elem):
        ET.SubElement(parent_elem, "variable", name=self.name, **self.attrs)


class Argument(Variable):
    def __repr__(self):
        return "<Argument: '%s'>" % self.name

    def gen_cix_tree(self, parent_elem):
        ET.SubElement(parent_elem, "variable", ilk="argument",
                      name=self.name, **self.attrs)


def _node_lineno(node):
    if hasattr(node, 'lineno'):
        return node.lineno
    else:
        if node.parent:
            return _node_lineno(node.parent)
        else:
            return -1


class Scanner(object):
    def __init__(self, blob):
        self.blob = blob
        self._scope_stack = deque([blob])  # stack of `Scope` instances

    def gen_cix_tree(self, file_elem):
        self.blob.gen_cix_tree(file_elem)

    def _push_scope(self, scope):
        self._scope_stack.append(scope)

    def _peek_scope(self):
        return self._scope_stack[-1]

    def _iter_scopes(self):
        for item in reversed(self._scope_stack):
            yield item

    def _close_scope(self):
        scope = self._scope_stack.pop()
        for var in scope.children:
            if not isinstance(var, Variable):
                continue
            # For now we use the first non-"None" CITDL.
            # TODO: Some experiments to see if the first or last
            #      assignment tends to do better, or some other combo.
            citdl = var.attrs.get("citdl")
            if citdl and citdl is not "None":
                continue
            for node in var.citdl_nodes:
                if isinstance(node, basestring):
                    # Sometimes it has already been rendered to a CITDL string.
                    citdl = node
                else:
                    citdl = self._citdl_from_node(node)
                if citdl and citdl is not "None":
                    var.attrs["citdl"] = citdl
                    break

    def scan(self, ast):
        visitor_from_symbol = {
            python_symbols.funcdef: self.visit_function,
            python_symbols.classdef: self.visit_class,
            python_symbols.import_name: self.visit_import,
            python_symbols.import_from: self.visit_import_from,
            python_symbols.expr_stmt: self.visit_expr,
            python_symbols.return_stmt: self.visit_return,
            python_symbols.for_stmt: self.visit_for,
        }

        traverser = _traverse(ast.children)
        first = traverser.next()
        if first == "end":
            return
        elif (first.type == python_symbols.simple_stmt
              and first.children[0].type == token.STRING):
            docstring_node = first.children[0]
            self.blob.attrs["doc"] = _docstring_from_node(docstring_node)
        else:
            traverser = itertools.chain([first], traverser)
        for node in traverser:
            if node == "end":
                self._close_scope()
                continue
            if node.type == python_symbols.simple_stmt:
                node = node.children[0]
            # print "%sNode(%s)" % ('  '*len(self._scope_stack),
            # pytree.type_repr(node.type))
            visitor = visitor_from_symbol.get(node.type)
            if visitor:
                visitor(node)

    def _citdl_from_node(self, node):
        type = node.type
        citdl = None
        if type == token.NAME:
            citdl = node.value
        elif type == token.STRING:
            citdl = "str"
        elif type == token.NUMBER:
            citdl = "int" if _isint(node.value) else "float"
        elif type == python_symbols.power:
            # e.g. `sys.argv` in `arg=sys.argv`
            # TODO:XXX pythoncile.py returns `Raven` for:
            #       r = Raven()   # if Raven is a class
            # but here we are returning `Raven()`, which makes more sense
            # and is advocated by Todd as well in a pythoncile.py comment.
            # Need to adjust Python evalr accordingly.
            citdl = self._citdl_from_power_node(node)
        elif type == python_symbols.arith_expr:
            # assume the expression will coerce to the first value type
            for c in node.children:
                if c.type not in (token.MINUS, token.PLUS):
                    citdl = self._citdl_from_node(c)
                    break
        elif type == python_symbols.term:
            # assume the expression will coerce to the first value type
            for c in node.children:
                if c.type not in (token.PERCENT, token.STAR, token.SLASH, token.DOUBLESLASH):
                    citdl = self._citdl_from_node(c)
                    break
        elif type == python_symbols.factor:
            citdl = self._citdl_from_node(node.children[1])
        elif type == python_symbols.test:
            # try the "then" part first
            citdl = self._citdl_from_node(node.children[0])
            if citdl is None:
                # can't tell, analyse the "else" part
                citdl = self._citdl_from_node(node.children[4])
        elif type == python_symbols.atom:
            # Multi-token literals.
            citdl = {
                token.LSQB: "list",
                # Note: This could be wrong. It could be a set literal.
                token.LBRACE: "dict",
                # Note: This could be wrong. A '(' could be parens
                # around an expression.
                token.LPAR: "tuple",
            }[node.children[0].type]
        else:
            raise ValueError("unexpected parameters token (line %d): %r"
                             % (_node_lineno(node), node))

        # de-in
        if node.parent.type == python_symbols.for_stmt:
            if citdl is not None:
                citdl += '[]'

        return citdl

    def _citdl_from_power_node(self, node):
        """CITDL for a given python_symbols.power Node type."""
        children = node.children

        from functools import partial as curry

        N = pytree.NodePattern
        N.POWER = curry(N, type=python_symbols.power)
        N.TRAILER = curry(N, type=python_symbols.trailer)

        L = pytree.LeafPattern
        L.NAME = curry(L, type=token.NAME)
        L.LPAR = curry(L, type=token.LPAR, content='(')
        L.RPAR = curry(L, type=token.RPAR, content=')')

        ANY = pytree.WildcardPattern

        funcall_pattern = N.POWER(content=[L.NAME(name="func"),
                                           N.TRAILER(content=[L.LPAR(),
                                                              ANY(),
                                                              L.RPAR()])])

        match = {}
        if funcall_pattern.match(node, results=match):
            func = match['func'].value
            if func in ('range', 'filter', 'map'):
                return 'list'
            elif func in ('list', 'tuple', 'dict'):
                return func

        bits = [children[0].value]
        for c in children[1:]:
            if c.children and c.children[0].type == token.DOT:
                bits += ['.', c.children[1].value]
            else:
                assert c.children[0].type in (token.LPAR, token.LSQB)
                bits += [c.children[0].value, c.children[-1].value]
        return ''.join(bits)

    def visit_return(self, node):
        # TODO: pythoncile.py handled (a) spliting CITDL (scoperef), (b)
        #      excluding "None" and "NoneType", (c) True/False -> bool.
        #      pythoncile.py also gather all return's and picked the most
        #      common guess.
        # TODO:XXX Evaluate the necessity of multiple return statement
        # analysis.
        scope = self._peek_scope()
        assert scope.ilk == "function"
        if not scope.get("returns"):
            citdl = self._citdl_from_node(node.children[1])
            if citdl and citdl is not "None":
                scope.attrs["returns"] = citdl

    def visit_for(self, node):
        children = node.children
        assert len(children) in (6, 8) and children[0].value == 'for', \
            "unexpected for_stmt: %r" % node
        # 0="for"
        # 1=exprlist
        exprlist = children[1]
        # 2="in"
        # 3=testlist
        testlist = children[3]
        # 4=":"
        # 5=suite
        # 6=else
        # 7=suite
        return self._visit_for_or_expr(node, exprlist, testlist)

    def visit_expr(self, node):
        children = node.children
        assert len(children) == 3 and children[1].type == token.EQUAL, \
            "unexpected expr_stmt: %r" % node
        lhs = children[0]
        rhs = children[2]
        return self._visit_for_or_expr(node, lhs, rhs)

    def _visit_for_or_expr(self, node, lhs, rhs):
        parent = self._peek_scope()
        # Get left-hand side item(s).
        #  if lhs.type == token.NAME:
        if lhs.type in (token.NAME, python_symbols.power):
            var_nodes = [lhs]
        elif lhs.type == python_symbols.atom:
            # `[a,b] = ...`
            # `(a,b) = ...`
            # TODO:XXX handle type "power", i.e. `(foo.bar, baz.car) = ...`
            inside = lhs.children[1]
            assert inside.type in (
                python_symbols.testlist_gexp, python_symbols.listmaker)
            var_nodes = inside.children[::2]
            if set(v.type for v in var_nodes) != set([token.NAME]):
                # Skip things like `((e), f) = ...`.
                log.warn("skip expr lhs: `%s`", lhs)
                return
        elif lhs.type == python_symbols.testlist:
            # `a,b = ...`
            # TODO:XXX handle type "power", i.e. `foo.bar, baz.car = ...`
            var_nodes = lhs.children[::2]
            if set(v.type for v in var_nodes) != set([token.NAME]):
                # Skip things like `(e), f = ...`.
                log.warn("skip expr lhs: `%s`", lhs)
                return
        else:
            log.warn("unexpected expr lhs: %r", lhs)
            return

        # Resolve the names.
        var_names = []
        for vnode in var_nodes:
            if vnode.type == python_symbols.power:
                vname, vscope = self._resolve_power_node(vnode)
            else:
                vname, vscope = vnode.value, parent
            if vname:
                var_names.append(vname)

        # Create/get the args.
        # TODO:XXX `global` would be handled here
        vars = []
        for name, vnode in zip(var_names, var_nodes):
            if name not in parent:
                var = parent.add_variable(name, line=str(vnode.lineno))
                vars.append(var)
            # XXX Not sure if this is still needed.
            # vars.append(parent.names[name])

        # Capture nodes for type inferencing these vars.
        # XXX This isn't the correct handling. Need to use vscope
        if rhs.type == token.NAME:
            parent[var_names[0]].citdl_nodes.append(rhs)
        elif rhs.type == python_symbols.atom:
            # `... = [a,b]`
            # `... = []`
            # `... = (a,b)`
            # `... = ()`
            inside = rhs.children[1] if len(rhs.children) > 2 else None
            assert inside is None or inside.type in (
                python_symbols.testlist_gexp, python_symbols.listmaker)
            rhs_nodes = inside.children[::2] if inside else []
            if len(var_names) == len(rhs_nodes):
                for n, r in zip(var_names, rhs_nodes):
                    parent[n].citdl_nodes.append(r)
            else:
                log.warn("expr rhs item count doesn't match lhs: `%s`", node)
        elif rhs.type == python_symbols.power:
            citdl = self._citdl_from_power_node(rhs)
            if citdl:
                for i, n in enumerate(var_names):
                    # TODO:XXX This CITDL syntax, 'foo[0]', is new to evalr.
                    parent[n].citdl_nodes.append(citdl + '[' + str(i) + ']')
        else:
            log.warn("unexpected rhs: %r", rhs)

    def _resolve_power_node(self, node):
        """Resolve the given node to a namespace.

        E.g. given a Node representing `foo.bar` return the namespace (the
        Scope instance) for `foo` and the name "bar".

        @returns {tuple} (<name>, <scope for name>)
        """
        DEBUG = True
        if DEBUG:
            print "-- resolve `%s'" % re.sub(r'\s+', ' ', str(node))
        # return None, None #XXX

        # Example: `self.name` looks like:
        #    Node(power, [
        #    `   Leaf('', NAME, 'self', lineno=4),
        #    `   Node(trailer, [
        #    `   `   Leaf('', DOT, '.', lineno=4),
        #    `   `   Leaf('', NAME, 'name', lineno=4)
        #    `   ])
        #    ]),
        children = node.children

        # Find a namespace for the first name.
        # Example: 'self' -> (<variable 'self'>, <Scope: function '__init__'>)
        name = children[0].value
        for scope in self._iter_scopes():
            # XXX Need to look in *names* in this scope, not just vars.
            # XXX:TODO: test case for that, class def inside function
            if DEBUG:
                print "find first name %r in %r" % (name, scope)
            try:
                var = scope[name]
            except KeyError:
                pass
            else:
                break
        else:
            # Couldn't find `name`.
            return None
        vscope = scope
        if DEBUG:
            print "first name %r is %r in %r" % (name, var, vscope)

        # Resolve that type (i.e. eval its CITDL).
        # Example: <variable 'self'>
        #           -> CITDL 'Person()'
        #           -> (<class 'Person'>, <Scope: blob 'foo'>)
        #           XXX Not sure about that last.
        # XXX Handle it not being a var.
        citdl = var.attrs.get("citdl")
        if not citdl:
            log.debug(
                "cannot resolve var '%s': no type inference (CITDL)", name)
            return None
        name, scope = self._resolve_citdl(citdl, vscope)
        if DEBUG:
            print "citdl %r -> (%r, %r)" % (citdl, name, scope)

        # print "XXX not complete here yet"
        return (name, scope)
        XXX
        # START HERE
        # - need a function to resolve citld from a start scope
        #   Follow _hit_from_citdl() in tree_python.py.

    def _resolve_citdl(self, citdl, start_scope):
        """Resolve the given CITDL and start scope to a
        (<name>, <containing-scope>).

        Note that this is a poorman's version of the full-on _hit_from_cidtl()
        in tree_python.py. This one doesn't look in imports, etc. Mainly this
        is okay because for the CILE'ing we (at least I think so) only need
        to resolve CITDL for assignment to class and function attributes.
        """
        DEBUG = True
        if DEBUG:
            print "-- resolve citdl %r starting in %r" % (citdl, start_scope)
        tokens = list(self._tokenize_citdl(citdl))
        print tokens

        # Find first part.
        first_token = tokens[0]
        scope = start_scope
        while scope:
            if DEBUG:
                print "look for CITDL token %r in %r" % (first_token, scope)
            if first_token in scope:
                break
            scope = scope.parent
        else:
            return None, None

        token = first_token
        for t in tokens[1:]:
            if t not in ('()',):
                next = scope.get(t)
                if next:
                    scope = next
                    token = t
                else:
                    return None, None

            print "*** token=", token, " scope=", scope

        return token, scope

    # Should be shared with other code. See tree_python.py's.
    def _tokenize_citdl(self, citdl):
        for token in citdl.split('.'):
            if token.endswith('()'):
                yield token[:-2]
                yield '()'
            else:
                yield token

    def visit_import_from(self, node):
        pscope = self._peek_scope()
        children = node.children
        line = str(children[0].lineno)
        module = str(children[1]).lstrip()
        tail = children[3]
        tail_type = tail.type
        if tail_type == token.LPAR:
            # `from foo import (a, b, c)
            tail = children[4]
            tail_type = tail.type
        if tail_type in (token.NAME, token.STAR):
            # `from logging import basicConfig`
            pscope.add_elem("import", line=line, module=module,
                            symbol=tail.value)
        elif tail_type == python_symbols.import_as_names:
            # `from os import sep, name`
            # `from os.path import isabs, join`
            for n in tail.children[::2]:
                pscope.add_elem("import", line=line, module=module,
                                symbol=n.value)
        elif tail_type == python_symbols.import_as_name:
            # `from shutil import copy2 as copy`
            pscope.add_elem("import", line=line,
                            module=module,
                            symbol=tail.children[0].value,
                            alias=tail.children[2].value)
        else:
            raise PythonCILEError("unexpected import: `%r`" % node)

    def visit_import(self, node):
        pscope = self._peek_scope()
        children = node.children
        line = str(children[0].lineno)
        tail = children[1]
        tail_type = tail.type
        if tail_type == token.NAME:
            # `import logging`
            pscope.add_elem("import", line=line, module=tail.value)
        elif tail_type == python_symbols.dotted_as_names:
            # `import os, sys`
            for n in tail.children[::2]:
                pscope.add_elem("import", line=line, module=n.value)
        elif tail_type == python_symbols.dotted_name:
            # `import xml.sax`
            tail.set_prefix("")  # drop leading space
            pscope.add_elem("import", line=line, module=str(tail))
        elif tail_type == python_symbols.dotted_as_name:
            # `import xml.sax as saxlib`
            # `import time as timelib`
            pscope.add_elem("import", line=line,
                            module=str(tail.children[0]).lstrip(),
                            alias=tail.children[2].value)
        else:
            raise PythonCILEError("unexpected import: `%s`" % node)

    def visit_function(self, node):
        parent = self._peek_scope()
        children = node.children
        is_method = (parent.ilk == "class")

        body = children[-1]  # `simple_stmt` for one-liner, `suite` otherwise
        last_leaf = body.children[-1]
        lineend = ((last_leaf.lineno - 2)
                   if last_leaf.type == token.DEDENT else last_leaf.lineno)
        name = children[1].value
        attributes = []

        # Signature and doc.
        # TODO: doc processing a la pythoncile.py
        if False:
            # Function sig handling in pythoncile.py:
            fallbackSig += "(%s)" % (", ".join(sigArgs))
            if node.doc:
                siglines, desclines = util.parsePyFuncDoc(
                    node.doc, [fallbackSig])
                namespace["signature"] = "\n".join(siglines)
                if desclines:
                    namespace["doc"] = "\n".join(desclines)
            else:
                namespace["signature"] = fallbackSig
        params = children[2]
        params.children[0].prefix = ""   # Drop leading space on '('.
        if is_method:
            # Drop 'self' arg from params.
            args = params.children[1]
            if args.type == token.RPAR:  # No args, perhaps a @staticmethod?
                a = ""
            elif args.type == token.NAME:  # Just the one arg.
                a = ""
            else:  # typedargslist
                for idx, arg in enumerate(args.children):
                    if arg.type == token.COMMA:
                        idx += 1
                        break
                args.children[
                    idx].prefix = ''  # XXX safe? What about `def method(self,)`?
                a = ''.join(arg.prefix + str(
                    arg) for arg in args.children[idx:])
            if name == "__init__":
                attributes.append("__ctor__")
                signature = parent.name + '(' + a + ')'
            else:
                signature = name + '(' + a + ')'
            if name.startswith("__"):
                if not name.endswith("__"):
                    attributes.append("private")
            elif name.startswith("_"):
                attributes.append("protected")
        else:
            signature = name + str(params)

        attrs = dict(line=str(children[0].lineno),
                     lineend=str(lineend), signature=signature)
        if node.doc:
            attrs["doc"] = node.doc
        if attributes:
            attrs["attributes"] = ' '.join(attributes)
        func = parent.add_scope("function", name, **attrs)
        self._push_scope(func)

        # Function arguments.
        args = params.children[1]
        if args.type == token.RPAR:     # no arguments
            pass  # no arguments
        elif args.type == token.NAME:   # a Leaf, just one argument
            arg = func.add_argument(args.value)
            if is_method:
                arg.attrs["citdl"] = parent.name
        else:
            assert args.type == python_symbols.typedargslist
            arg = arg_modifier = None
            for i, child in enumerate(args.children):
                ctype = child.type
                if ctype == token.NAME:
                    if arg is not None:
                        arg.attrs["citdl"] = child.value
                    else:
                        arg = func.add_argument(child.value)
                        if i == 0 and is_method:
                            arg.attrs["citdl"] = parent.name + "()"
                        elif not arg_modifier:
                            pass
                        elif arg_modifier == token.STAR:
                            arg.attrs["citdl"] = "tuple"
                            arg.attrs["attributes"] = "varargs"
                        elif arg_modifier == token.DOUBLESTAR:
                            arg.attrs["citdl"] = "dict"
                            arg.attrs["attributes"] = "kwargs"
                elif ctype == python_symbols.tfpdef:
                    # `def foo((a,b)=(1,2)):`
                    # Note: This syntax has been dropped from Python 3.
                    assert arg is None
                    tfplist = child.children[1]  # the bit between '(' and ')'
                    arg_names = tfplist.children[::2]
                    assert set(a.type for a in arg_names) == set([token.NAME]), \
                        "unexpected tfplist: %r" % tfplist
                    for a in arg_names:
                        func.add_argument(a.value)
                elif ctype == token.COMMA:
                    arg = arg_modifier = None
                elif ctype in (token.STAR, token.DOUBLESTAR):
                    arg_modifier = ctype
                elif ctype == token.EQUAL:
                    pass
                # The rest are tokens after the '=' for a default arg value.
                elif arg is not None:
                    # arg is None if hit tfpdef syntax above.
                    citdl = self._citdl_from_node(child)
                    if citdl:
                        arg.attrs["citdl"] = citdl

    def visit_class(self, node):
        parent = self._peek_scope()
        children = node.children

        body = children[-1]  # `simple_stmt` for one-liner, `suite` otherwise
        last_leaf = body.children[-1]
        lineend = ((last_leaf.lineno - 2)
                   if last_leaf.type == token.DEDENT else last_leaf.lineno)
        name = children[1].value

        attrs = {
            "line": str(children[0].lineno),
            "lineend": str(lineend),
        }
        if node.doc:
            attrs["doc"] = node.doc

        # Classrefs.
        if children[2].type == token.LPAR:
            idx = 3
            classrefs = []
            while True:
                c = children[idx]
                if c.type == token.RPAR:
                    break
                elif c.type == token.NAME:
                    classrefs.append(c.value)
                else:
                    # XXX This check is only here because I don't have a feel for
                    #    the possible syntax here.
                    assert c.type == token.COMMA, "unexpected classrefs token: %r" % c
                idx += 1
            if classrefs:
                attrs["classrefs"] = ' '.join(classrefs)

        class_ = parent.add_scope("class", name, **attrs)
        self._push_scope(class_)


#---- internal stuff

def _isint(s):
    try:
        int(s)
    except ValueError:
        return False
    else:
        return True

_traverse_scope_types = (
    python_symbols.funcdef,
    python_symbols.classdef,
)


def _traverse(nodes, _offset=None):
    """Helper for AST traversal.

    XXX 'splain
    """
    global _traverse_scope_types
    top = _offset is None
    if _offset is None:
        _offset = 0
    # TODO: PERF issues of islice versus `nodes[_offset]`
    for node in itertools.islice(nodes, _offset, len(nodes)):
        if node.type in _traverse_scope_types:
            # Pull out docstring, if any, and attach to node.
            body = node.children[
                -1]  # `simple_stmt` for one-liner, `suite` otherwise
            if body.type == python_symbols.suite:
                # Child 0 is NEWLINE, child 1 is INDENT.
                docstring_node = body.children[2]
                offset = 3
            else:
                assert body.type == python_symbols.simple_stmt
                docstring_node = body
                offset = 1
            if (isinstance(docstring_node, pytree.Node)
                    and docstring_node.children[0].type == token.STRING):
                # TODO:XXX move off "self"
                doc = _docstring_from_node(docstring_node.children[0])
            else:
                offset = 0
                doc = None
            node.doc = doc

            yield node
            for n in _traverse(body.children, offset):
                yield n
            yield "end"
        elif node.type == python_symbols.if_stmt:
            # Handle each "suite" in the children. There is a pattern.
            i = 0
            children = node.children
            suites = []
            while i < len(children):
                control = children[i].value
                if control in ("if", "elif"):
                    suites.append(children[i+3])
                    i += 4
                elif control == "else":
                    suites.append(children[i+2])
                    i += 3
            for suite in suites:
                for n in _traverse(suite.children, 0):
                    yield n
        elif isinstance(node, pytree.Node):
            yield node
    if top:
        yield "end"


def _docstring_from_node(node):
    """Return the docstring content for the given docstring node."""
    CLIP_LENGTH = 2000
    s = node.value
    # TODO: Python 3's 'b' necessary?
    s = s.lstrip("urb")  # Strip potential leading string modifiers.
    if s.startswith('"""'):
        s = s[3:-3]
    elif s.startswith("'''"):
        s = s[3:-3]
    else:
        assert s[0] in ('"', "'")
        s = s[1:-1]
    return s[:CLIP_LENGTH]
if True:
    # XXX Use the docstring processing in pythoncile.py to ease comparison.
    # When they compare well, then can turn preferred doc processing back on.
    _preferred_docstring_from_node = _docstring_from_node

    def _docstring_from_node(node):
        s = _preferred_docstring_from_node(node)
        lines = util.parseDocSummary(s.splitlines(0))
        return '\n'.join(lines)


def getAttrStr(attrs):
    """Construct an XML-safe attribute string from the given attributes

        "attrs" is a dictionary of attributes

    The returned attribute string includes a leading space, if necessary,
    so it is safe to use the string right after a tag name. Any Unicode
    attributes will be encoded into UTF8 encoding as part of this process.
    """
    from xml.sax.saxutils import quoteattr
    s = ''
    for attr, value in attrs.items():
        if not isinstance(value, basestring):
            value = str(value)
        elif isinstance(value, unicode):
            value = value.encode("utf-8")
        s += ' %s=%s' % (attr, quoteattr(value))
    return s


#---- public module interface

def scan(content, filename, md5sum=None, mtime=None, lang="Python"):
    """Scan the given Python content and return Code Intelligence data
    conforming the the Code Intelligence XML format.

        "content" is the Python content to scan. This should be an
            encoded string: must be a string for `md5` and
            `compiler.parse` -- see bug 73461.
        "filename" is the source of the Python content (used in the
            generated output).
        "md5sum" (optional) if the MD5 hexdigest has already been calculated
            for the content, it can be passed in here. Otherwise this
            is calculated.
        "mtime" (optional) is a modified time for the file (in seconds since
            the "epoch"). If it is not specified the _current_ time is used.
            Note that the default is not to stat() the file and use that
            because the given content might not reflect the saved file state.
        "lang" (optional) is the language of the given file content.
            Typically this is "Python" (i.e. a pure Python file), but it
            may also be "DjangoHTML" or similar for Python embedded in
            other documents.
        XXX Add an optional 'eoltype' so that it need not be
            re-calculated if already known.

    This can raise one of SyntaxError, PythonCILEError or parser.ParserError
    if there was an error processing. Currently this implementation uses the
    Python 'compiler' package for processing, therefore the given Python
    content must be syntactically correct.
    """
    log.info("scan '%s'", filename)
    if md5sum is None:
        md5sum = md5(content).hexdigest()
    if mtime is None:
        mtime = int(time.time())
    # 'compiler' both (1) wants a newline at the end and (2) can fail on
    # funky *whitespace* at the end of the file.
    content = content.rstrip() + '\n'

    if isinstance(filename, types.UnicodeType):
        filename = filename.encode('utf-8')
    # The 'path' attribute must use normalized dir separators.
    if sys.platform.startswith("win"):
        path = filename.replace('\\', '/')
    else:
        path = filename
    fileAttrs = {"language": "Python",
                 "generator": "Python",
                 "path": path}

    try:
        tree2 = pythoncile2(path, content).find('file').find('scope')
        # print >> sys.stderr, ("******************", tree2, tree2.tag, tree2.attrib); sys.stderr.flush()
        # assert False, ('===============', tree2.getchildren()[0].attrib)
        if tree2.get('error'):
            raise Exception(tree2.get('error'))
        if _gClockIt:
            sys.stdout.write(" (ast:%.3fs)" % (_gClock()-_gStartTime))
    except Exception, ex:
        fileAttrs["error"] = str(ex)
        file = '    <file%s/>' % getAttrStr(fileAttrs)
    else:
        if tree2 is None:
            # This happens, for example, with:
            #   foo(bar, baz=1, blam)
            fileAttrs["error"] = "could not generate AST"
            file = '    <file%s/>' % getAttrStr(fileAttrs)
        else:
            pretty_tree_from_tree(tree2)
            cix2 = ET.tostring(tree2, "utf-8")
            fileAttrs["md5"] = md5sum
            fileAttrs["mtime"] = mtime
            moduleName = os.path.splitext(os.path.basename(filename))[0]

            if _gClockIt:
                sys.stdout.write(" (walk:%.3fs)" % (_gClock()-_gStartTime))
            if log.isEnabledFor(logging.INFO):
                # Dump a repr of the gathering info for debugging
                # - We only have to dump the module namespace because
                #   everything else should be linked from it.
                for nspath, namespace in visitor.st.items():
                    if len(nspath) == 0:  # this is the module namespace
                        pprint.pprint(namespace)
            file = '    <file%s>\n\n%s\n    </file>'\
                   % (getAttrStr(fileAttrs), cix2)
            if _gClockIt:
                sys.stdout.write(" (getCIX:%.3fs)" % (_gClock()-_gStartTime))

    cix = '''\
<?xml version="1.0" encoding="UTF-8"?>
<codeintel version="0.1">
%s
</codeintel>
''' % file

    return cix


#---- mainline

class _NoReflowFormatter(optparse.IndentedHelpFormatter):
    """An optparse formatter that does NOT reflow the description."""
    def format_description(self, description):
        return description or ""


def main(argv=None):
    if argv is None:
        argv = sys.argv
    if not logging.root.handlers:
        logging.basicConfig()

    usage = "usage: %prog [PATHS...]"
    version = "%prog "+__version__
    parser = optparse.OptionParser(prog="pythoncile2", usage=usage,
                                   version=version, description=__doc__,
                                   formatter=_NoReflowFormatter())
    parser.add_option("-v", "--verbose", dest="log_level",
                      action="store_const", const=logging.DEBUG,
                      help="more verbose output")
    parser.add_option("-q", "--quiet", dest="log_level",
                      action="store_const", const=logging.ERROR,
                      help="less verbose output (only show errors)")
    parser.add_option("-c", "--compare", action="store_true",
                      help="run against pythoncile.py as well (for testing)")
    parser.set_defaults(log_level=logging.INFO, compare=False)
    opts, paths = parser.parse_args(argv)
    log.setLevel(opts.log_level)
    assert len(paths) == 1, "usage: pythoncile2.py PATH"
    path = paths[0]

    try:
        tree2 = pythoncile2(path)
    except PythonCILEError, ex:
        log.error(str(ex))
        if log.isEnabledFor(logging.DEBUG):
            print
            import traceback
            traceback.print_exception(*sys.exc_info())
        return 1
    except KeyboardInterrupt:
        log.debug("user abort")
        return 1

    pretty_tree_from_tree(tree2)
    cix2 = ET.tostring(tree2, "utf-8")

    if opts.compare:
        cix1 = _pythoncile_cix_from_path(path)
        if log.isEnabledFor(logging.DEBUG):
            print "-- pythoncile1 %s" % path
            print cix1
            print "-- pythoncile2 %s" % path
            print cix2

        # Normalizing for comparison.
        tree1 = ET.fromstring(cix1)
        # - mtime slightly different
        tree1[0].set("mtime", tree2[0].get("mtime"))
        # - pythoncile.py seems to put <import>'s at the top of the scope.
        #   We'll just get tree2 to look like that.
        for scope in tree2.getiterator("scope"):
            if scope.get("ilk") not in ("blob", "function"):
                continue
            indeces = []
            n = 0
            for i, child in enumerate(scope[:]):
                if child.tag == "import":
                    imp = scope[i]
                    del scope[i]
                    scope.insert(n, imp)
                    n += 1
        # - pythoncile2.py set citdl=tuple for 'varargs' arguments, and
        #   citdl=dict for 'kwargs' arguments
        for arg in tree1.getiterator("variable"):
            if arg.get("ilk") != "argument":
                continue
            if arg.get("attributes") == "varargs":
                arg.set("citdl", "tuple")
            elif arg.get("attributes") == "kwargs":
                arg.set("citdl", "dict")
        # - pythoncile2.py will set citdl=None if for `foo(a=None)`, pythoncile.py
        #   does not
        for arg in tree2.getiterator("variable"):
            if arg.get("ilk") != "argument":
                continue
            if arg.get("citdl") == "None":
                del arg.attrib["citdl"]
        # - Just can't agree on 'lineend' value for functions and classes right now.
        #   TODO:XXX Need to eventually make sure that the new lineends
        #            make sense! The main current diff is that pythoncile2
        #            includes trailing comment lines, even it not indented.
        #            I think that is fine -- might even be helpful.
        for scope in tree1.getiterator("scope"):
            if scope.get("ilk") in ("function", "class") and scope.get("lineend"):
                del scope.attrib["lineend"]
        for scope in tree2.getiterator("scope"):
            if scope.get("ilk") in ("function", "class") and scope.get("lineend"):
                del scope.attrib["lineend"]
        # - pythoncile.py incorrectly normalizes double-quotes in function signature
        #   argument default values to single quotes. This normalization will get it
        #   wrong for quotes in quotes.
        for func in tree2.getiterator("scope"):
            if func.get("ilk") == "function":
                sig = func.get("signature")
                if '"' in sig:
                    func.set("signature", sig.replace('"', "'"))
        pretty_tree_from_tree(tree2)
        norm_cix2 = ET.tostring(tree2, "utf-8")
        pretty_tree_from_tree(tree1)
        norm_cix1 = ET.tostring(tree1, "utf-8")

        import difflib
        diff = difflib.unified_diff(
            norm_cix1.splitlines(1),
            norm_cix2.splitlines(1),
            "pythoncile %s (normalized)" % path,
            "pythoncile2 %s (normalized)" % path)
        diff = ''.join(list(diff))
        if diff:
            print diff
    else:
        sys.stdout.write(cix2)


def _pythoncile_cix_from_path(path):
    import subprocess
    argv = [sys.executable, join(
        _komodo_src_dir, "sdk", "bin", "codeintel.py"),
        'scan', '-p', path]
    p = subprocess.Popen(argv, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = p.communicate()
    if stderr:
        lines = [line for line in stderr.splitlines(0)
                 if "error registering" not in line]
        print '\n'.join(lines)
    return stdout

if __name__ == "__main__":
    # sys.exit( main(sys.argv) )
    sys.exit(main(['/home/mikei/tmp/t.py']))

########NEW FILE########
__FILENAME__ = rubycile
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
    rubycile - a Code Intelligence Language Engine for the Ruby language

    Module Usage:
        from rubycile import scan_purelang
        content = open("foo.rb", "r").read()
        scan_purelang(content, "foo.rb")

    Command-line Usage:
        rubycile.py [<options>...] [<Ruby files>...]

    Options:
        -h, --help          dump this help and exit
        -V, --version       dump this script's version and exit
        -v, --verbose       verbose output, use twice for more verbose output
        -f, --filename <path>   specify the filename of the file content
                            passed in on stdin, this is used for the "path"
                            attribute of the emitted <file> tag.
        --md5=<string>      md5 hash for the input
        --mtime=<secs>      modification time for output info, in #secs since
                            1/1/70.
        -L, --language <name>
                            the language of the file being scanned
        -c, --clock         print timing info for scans (CIX is not printed)

    One or more Ruby files can be specified as arguments or content can be
    passed in on stdin. A directory can also be specified, in which case
    all .rb files in that directory are scanned.

    This is a Language Engine for the Code Intelligence (codeintel) system.
    Code Intelligence XML format. See:
        http://specs.tl.activestate.com/kd/kd-0100.html

    The command-line interface will return non-zero iff the scan failed.
"""

import os
from os.path import abspath, basename, dirname, splitext, isfile, isdir, join
import sys
import getopt
import re
import logging
import glob
import time
import stat

from ciElementTree import Element, SubElement, tostring
from SilverCity import ScintillaConstants

from codeintel2 import ruby_lexer, ruby_parser, util
from codeintel2.common import CILEError
from codeintel2 import parser_cix


#---- exceptions

class RubyCILEError(CILEError):
    pass


#---- global data

_version_ = (0, 1, 0)
log = logging.getLogger("rubycile")
# log.setLevel(logging.DEBUG)

dcLog = logging.getLogger("rubycile.dircache")
# dcLog.setLevel(logging.DEBUG)

_gClockIt = 0   # if true then we are gathering timing data
_gClock = None  # if gathering timing data this is set to time retrieval fn
_gStartTime = None   # start time of current file being scanned

gProduceOldCIX = False  # XXX Temporary -- the old format should be pulled out.

# from codeintel2.util import hotshotit


class _DirInfo:
    """
    This class stats a directory to determine when files have
    been added to or removed from it.  Update times are
    platform-dependent.  For example, the Python docs state
    that on Windows update resolution on the st_mtime
    attribute is 2-seconds, but I've observed it to be closer to
    30 seconds.
    """
    def __init__(self, ptn):
        self._data = {}
        self._ptn = ptn

    def get_files(self, dirname):
        if dirname not in self._data:
            self._create(dirname)
        else:
            new_time = self._changed(dirname)
            if new_time:
                self._update(dirname, new_time)
                dcLog.debug("==> " + "\t\n".join(self._data[dirname]['flist']))
        return self._data[dirname]['flist']

    def _changed(self, dirname):
        new_time = self._mtime(dirname)
        if new_time > self._data[dirname]['mtime']:
            return new_time
        return 0

    def _create(self, dirname):
        self._data[dirname] = {'mtime': self._mtime(dirname),
                               'flist': self._files(dirname),
                               }

    def _files(self, dirname):
        return glob.glob(join(dirname, self._ptn))

    def _mtime(self, dirname):
        try:
            return os.stat(dirname)[stat.ST_MTIME]
        except OSError:
            return 0

    def _update(self, dirname, mtime):
        self._data[dirname]['mtime'] = mtime
        self._data[dirname]['flist'] = self._files(dirname)

_modelDirInfo = _DirInfo("*.rb")


def rails_role_from_path(path):
    apath = abspath(path)
    aplist = apath.split(os.path.sep)
    # Allow for someone to built a rails app at root...
    if len(aplist) < 3:
        return None
    elif (aplist[-3] == "app" and
         (aplist[-2] == "controllers" and aplist[-1].endswith(".rb")
          or aplist[-2] == "helpers" and aplist[-1].endswith("_helper.rb")
          or aplist[-2] == "models" and aplist[-1].endswith(".rb"))):
        role_parts = aplist[-3:]
    elif (len(aplist) >= 4
          and aplist[-4] == "app" and aplist[-3] == "views"
          and aplist[-1].endswith((".html.erb", ".rhtml"))):
        role_parts = aplist[-4:]
    elif (aplist[-3] == "db" and
          aplist[-2] == "migrate" and
          aplist[-1].endswith(".rb") and
          aplist[-1][0].isdigit()):
        role_parts = aplist[-3:]
    elif (aplist[-3] == "test" and
          aplist[-2] in ("functional", "integration", "unit") and
          aplist[-1].endswith(".rb")):
        role_parts = aplist[-3:]
    else:
        return None
    return role_parts


def check_insert_rails_env(path, blob_scope):
    role_parts = rails_role_from_path(path)
    if role_parts is None:
        return
    add_models = False
    if len(role_parts) > 1 and role_parts[0] == "app":
        if role_parts[1] == "views":
            # This stuff only works if the evaluator will load class names as well
            # as namespace names.
            blob_scope.insert(0, Element("import", symbol="ActionView::Base"))
        elif len(role_parts) > 2:
            if role_parts[1] in ("controllers", "models"):
                if role_parts[1] == "controllers":
                    if role_parts[2] != "application.rb":
                        blob_scope.insert(0, Element(
                            "import", module="./application", symbol='*'))
                    # For loading models
                    apath = abspath(path)
                    add_models = True
                    models_dir = join(dirname(dirname(apath)), "models")
                    rel_part = "../"
                    # For loading migrations
                    modelName = "*"
                else:
                    # add requires for each migration file
                    # Here's how it works:
                    # If the file is app/models/my_thing.rb,
                    # For each file foo in ../../db/migrate/*.rb,
                    # Try to load module=foo,
                    # symbol=inflector.camelcase(drop_ext(basename(filename)))
                    modelName = ruby_parser.get_inflector().camelize(
                        splitext(basename(path))[0])
                # Load the migration modules
                apath = abspath(path)
                migration_dir = join(dirname(dirname(
                    dirname(apath))), "db", "migrate")
                migration_files = _modelDirInfo.get_files(migration_dir)
                idx = 0
                for migration_file in migration_files:
                    idx += 1
                    base_part = "../../db/migrate/" + \
                        splitext(basename(migration_file))[0]
                    blob_class = blob_scope.find("scope")
                    assert blob_class.get('ilk') == 'class'
                    blob_class.insert(idx, Element(
                        "import", module=base_part, symbol=modelName))
    elif (len(role_parts) > 2
          and ((role_parts[0] == "db" and role_parts[1] == "migrate"
                and role_parts[2][0].isdigit())
               or role_parts[0] == "test")):
        apath = abspath(path)
        add_models = True
        models_dir = join(dirname(dirname(dirname(apath))), "app", "models")
        rel_part = "../../app/"
        if role_parts[0] == "test" and role_parts[1] == 'functional':
            # Each file functional/foo_controller_test.rb will contain a line reading
            # require 'foo'
            # but codeintel won't know where to look for this foo, so we'll tell it explicitly
            # Use 'index' to throw an exception because
            # RubyCommonBufferMixin.check_for_rails_app_path specified this
            # pattern.
            end_part = role_parts[2].index("_test.rb")
            controller_file = rel_part + \
                "controllers/" + role_parts[2][0:end_part]
            blob_scope.insert(0, Element(
                "import", module=controller_file, symbol='*'))
            modelName = '*'
        # XXX - tests can't see migration dirs yet.
        # migration_dir = join(dirname(dirname(dirname(apath))), "db",
        # "migrate")

    if add_models:
        model_files = _modelDirInfo.get_files(models_dir)
        idx = 0
        for model_file in model_files:
            idx += 1
            base_part = rel_part + "models/" + \
                splitext(basename(model_file))[0]
            blob_scope.insert(idx, Element(
                "import", module=base_part, symbol='*'))


# @hotshotit
def scan_purelang(content, filename):
    content = content.expandtabs(8)
    tokenizer = ruby_lexer.RubyLexer(content)
    parser = ruby_parser.Parser(tokenizer, "Ruby")
    parse_tree = parser.parse()
    tree = parser_cix.produce_elementTree_cix(parse_tree, filename,
                                              "Ruby", "Ruby")
    rails_migration_class_nodes = parser.rails_migration_class_tree()
    if rails_migration_class_nodes:
        blob_node = tree.getchildren()[0].getchildren()[0]
        for parse_tree_node in rails_migration_class_nodes:
            assert parse_tree_node.class_name == "Class"
            parser_cix.common_module_class_cix(
                parse_tree_node, blob_node, class_ref_fn=None, attributes="__fabricated__")
            # parser_cix.class_etree_cix(rails_migration_class_tree, blob_node)
    return tree


def scan_multilang(tokens, module_elem):
    """Build the Ruby module CIX element tree.

        "tokens" is a generator of UDL tokens for this UDL-based
            multi-lang document.
        "module_elem" is the <module> element of a CIX element tree on
            which the Ruby module should be built.

    This should return a tuple of:
    * the list of the CSL tokens in the token stream,
    * whether or not the document contains any Ruby tokens (style UDL_SSL...)
    """

    tokenizer = ruby_lexer.RubyMultiLangLexer(tokens)
    parser = ruby_parser.Parser(tokenizer, "RHTML")
    parse_tree = parser.parse()
    parser_cix.produce_elementTree_contents_cix(parse_tree, module_elem)
    csl_tokens = tokenizer.get_csl_tokens()
    return csl_tokens, tokenizer.has_ruby_code()


#---- mainline

def main(argv):
    logging.basicConfig()
    # Parse options.
    try:
        opts, args = getopt.getopt(argv[1:], "Vvhf:cL:",
                                   ["version", "verbose", "help", "filename=", "md5=", "mtime=",
                                    "clock", "language="])
    except getopt.GetoptError, ex:
        log.error(str(ex))
        log.error("Try `rubycile --help'.")
        return 1
    numVerboses = 0
    stdinFilename = None
    md5sum = None
    mtime = None
    lang = "Ruby"
    global _gClockIt
    for opt, optarg in opts:
        if opt in ("-h", "--help"):
            sys.stdout.write(__doc__)
            return
        elif opt in ("-V", "--version"):
            ver = '.'.join([str(part) for part in _version_])
            print "rubycile %s" % ver
            return
        elif opt in ("-v", "--verbose"):
            numVerboses += 1
            if numVerboses == 1:
                log.setLevel(logging.INFO)
            else:
                log.setLevel(logging.DEBUG)
        elif opt in ("-f", "--filename"):
            stdinFilename = optarg
        elif opt in ("-L", "--language"):
            lang = optarg
        elif opt in ("--md5",):
            md5sum = optarg
        elif opt in ("--mtime",):
            mtime = optarg
        elif opt in ("-c", "--clock"):
            _gClockIt = 1
            global _gClock
            if sys.platform.startswith("win"):
                _gClock = time.clock
            else:
                _gClock = time.time

    if len(args) == 0:
        contentOnStdin = 1
        filenames = [stdinFilename or "<stdin>"]
    else:
        contentOnStdin = 0
        paths = []
        for arg in args:
            paths += glob.glob(arg)
        filenames = []
        for path in paths:
            if isfile(path):
                filenames.append(path)
            elif isdir(path):
                rbfiles = [join(path, n) for n in os.listdir(path)
                           if splitext(n)[1] == ".rb"]
                rbfiles = [f for f in rbfiles if isfile(f)]
                filenames += rbfiles

    try:
        for filename in filenames:
            if contentOnStdin:
                log.debug("reading content from stdin")
                content = sys.stdin.read()
                log.debug("finished reading content from stdin")
                if mtime is None:
                    mtime = int(time.time())
            else:
                if mtime is None:
                    mtime = int(os.stat(filename)[stat.ST_MTIME])
                content = open(filename, 'r').read()

            if _gClockIt:
                sys.stdout.write("scanning '%s'..." % filename)
                global _gStartTime
                _gStartTime = _gClock()
            data = scan_purelang(content, filename)
            # data = scan(content, filename, md5sum, mtime, lang=lang)
            if _gClockIt:
                sys.stdout.write(" %.3fs\n" % (_gClock()-_gStartTime))
            elif data:
                sys.stdout.write(data)
    except KeyboardInterrupt:
        log.debug("user abort")
        return 1
    if 0:  # except Exception, ex:
        log.error(str(ex))
        if log.isEnabledFor(logging.DEBUG):
            print
            import traceback
            traceback.print_exception(*sys.exc_info())
        return 1

if __name__ == "__main__":
    sys.exit(main(sys.argv))

########NEW FILE########
__FILENAME__ = ruby_lexer
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
Ruby lexing support for codeintel/rubycile.py

Get all the lexed tokens from SilverCity, and then return them
on demand to the caller (usually a Ruby pseudo-parser).

Usage:
import ruby_lexer
lexer = ruby_lexer.Lexer(code)
while 1:
    tok = lexer.get_next_token()
    if tok[0] == EOF_STYLE:
        break;
    # tok is an array of (style, text, start-col, start-line, end-col, end-line)
    # column and line numbers are all zero-based.
"""

import re
import sys
import string

# import SilverCity
from SilverCity import Ruby, ScintillaConstants
import shared_lexer
from shared_lexer import EOF_STYLE


class RubyLexerClassifier:
    """ This classifier is similar to the parser-level classifier, but
    it works on the SilverCity "raw" tokens as opposed to the
    tokens that get created by the lexer layer.  There should be some
    folding though."""

    def is_comment(self, ttype):
        return ttype in (ScintillaConstants.SCE_RB_COMMENTLINE,
                         ScintillaConstants.SCE_RB_POD)

    @property
    def style_comment(self):
        return ScintillaConstants.SCE_RB_COMMENTLINE

    @property
    def style_default(self):
        return ScintillaConstants.SCE_RB_DEFAULT

    @property
    def style_operator(self):
        return ScintillaConstants.SCE_RB_OPERATOR


class _CommonLexer(shared_lexer.Lexer):
    def __init__(self):
        shared_lexer.Lexer.__init__(self)
        self.q = []
        self.multi_char_ops = self.build_dict(
            '!= !~ && ** :: <= << == => =~ >> ||')


class RubyLexer(_CommonLexer):
    def __init__(self, code):
        _CommonLexer.__init__(self)
        self.classifier = RubyLexerClassifier()
        Ruby.RubyLexer().tokenize_by_style(code, self._fix_token_list)
        self.prepare_token_list_for_use()
        self.string_types = [ScintillaConstants.SCE_RB_STRING,
                             ScintillaConstants.SCE_RB_CHARACTER,
                             ScintillaConstants.SCE_RB_STRING_Q,
                             ScintillaConstants.SCE_RB_STRING_QQ,
                             ScintillaConstants.SCE_RB_STRING_QX,
                             ScintillaConstants.SCE_RB_STRING_QR,
                             ScintillaConstants.SCE_RB_STRING_QW
                             ]

    def _fix_token_list(self, **tok):
        """See perl_lexer.py for details on what this routine does."""
        if tok['style'] == ScintillaConstants.SCE_RB_OPERATOR and len(tok['text']) > 1:
            self.append_split_tokens(tok, self.multi_char_ops, self.q)
        else:
            self.complete_token_push(tok)


class RubyMultiLangLexer(_CommonLexer):
    def __init__(self, token_source):
        _CommonLexer.__init__(self)
        self.csl_tokens = []
        # http://www.mozilla.org/js/language/grammar14.html
        self.js_multi_char_ops = self.build_dict(
            '++ -- << >> >>> <= >= == != === !== && || *= /= %= += -= <<= >>= >>>= &= ^= |=')
        self.string_types = [ScintillaConstants.SCE_UDL_SSL_STRING
                             ]
        self.classifier = shared_lexer.UDLLexerClassifier()
        self._contains_ssl = False
        self._build_tokens(token_source)
        self.prepare_token_list_for_use()

    def _build_tokens(self, token_source):
        while True:
            try:
                tok = token_source.next()
                self._fix_token_list(tok)
            except StopIteration:
                break

    def _fix_token_list(self, tok):
        """See ruby_lexer.py for details on what this routine does."""
        ttype = tok['style']
        tval = tok['text']
        if self.is_udl_csl_family(ttype):
            if ttype == ScintillaConstants.SCE_UDL_CSL_OPERATOR and len(tval) > 1:
                # Point the token splitter to the correct token queue
                self.append_split_tokens(tok, self.js_multi_char_ops,
                                         adjust_line=False,
                                         dest_q=self.csl_tokens)
            else:
                self.complete_token_push(tok, adjust_line=False,
                                         dest_q=self.csl_tokens)
        elif self.is_udl_ssl_family(ttype):
            if tok['style'] == ScintillaConstants.SCE_UDL_SSL_OPERATOR and len(tok['text']) > 1:
                self.append_split_tokens(tok, self.multi_char_ops)
            else:
                self.complete_token_push(tok)
            self._contains_ssl = True
        # The only reason to count TPL tokens is to provide RHTML/Ruby
        # triggers when "<%" or "<%=" falls at the end of the buffer,
        # as in
        # <%=lin<!>.  There will be a delay anyway between when the
        # first TPL or SSL characters are typed, and when the buffer
        # is re-ciled, so there's no need to check TPL tokens.
        # elif self.is_udl_tpl_family(ttype):
        #    self._contains_ssl = True

    def get_csl_tokens(self):
        return self.csl_tokens

    def has_ruby_code(self):
        return self._contains_ssl


def provide_sample_code():
    return r"""require 'rdoc/parsers/parse_rb.rb'

# full-line comment
# comment at start of line
 # comment at col 1
  # comment at col 2

module Generators
  class XMLGenerator < HTMLGenerator # a comment here
    def our_generate(file_info)
      @info       = info
      @files      = []
      @classes    = []
      @hyperlinks = {}
    end
    # comment on what test_fn does
    # more...

    def test_fn(a, b='val1', c=f(3), *d, &e)
       print "nothing\n"   # end-of-line comment
       print %Q(percent string\n)
    end

    def no_paren a, b, \
           c
       print "blah"
    end
  end
end
"""


if __name__ == "__main__":
    shared_lexer.main(sys.argv, provide_sample_code, RubyLexer)

########NEW FILE########
__FILENAME__ = ruby_parser
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""Ruby parsing support for codeintel/rubycile.py"""

import string
import sys
import re
import textwrap

from SilverCity import ScintillaConstants
from codeintel2 import ruby_lexer
from codeintel2 import shared_lexer
from codeintel2 import shared_parser
from codeintel2 import util
from codeintel2.parser_data import Name_LineNum, VarInfo, Node, ClassNode, \
    FileNode, ArgNode, MethodNode, ModuleNode, VariableNode, BlockNode, \
    update_collection
from codeintel2.parser_data import VAR_KIND_UNKNOWN, VAR_KIND_GLOBAL, \
    VAR_KIND_CLASS, VAR_KIND_CLASSVAR, VAR_KIND_INSTANCE, VAR_KIND_LOCAL, \
    VAR_KIND_ALIAS

import logging
log = logging.getLogger("ruby_parser")
# log.setLevel(logging.DEBUG)

# Parse Ruby code

_leading_hash_re = re.compile(r'^\s*\#+\s*')


class RubyCommonClassifier:
    """Mixin class containing classifier callbacks"""

    def is_symbol_cb(self, tok):
        return tok['text'][0] == ":"

    # Used for stripping the quotes off a string
    _quote_patterns = {ScintillaConstants.SCE_RB_STRING: re.compile(
        '^\"(.*)\"$'),
        ScintillaConstants.SCE_RB_CHARACTER: re.compile('^\'(.*)\'$'),
        ScintillaConstants.SCE_RB_STRING_QQ: re.compile('^%Q.(.*).$'),
        ScintillaConstants.SCE_RB_STRING_Q: re.compile('^%q.(.*).$'),
        ScintillaConstants.SCE_RB_DEFAULT: re.compile('^.(.*).$'),
    }

    def quote_patterns_cb(self, tok):
        # Caller wants an array.
        return [self.quote_patterns_cb_aux(tok)]

    def quote_patterns_cb_aux(self, tok):
        tval = tok['text']
        if tval[0] == '"':
            return self._quote_patterns[ScintillaConstants.SCE_RB_STRING]
        elif tval[0] == '\'':
            return self._quote_patterns[ScintillaConstants.SCE_RB_CHARACTER]
        elif tval.startswith("%Q"):
            return self._quote_patterns[ScintillaConstants.SCE_RB_STRING_QQ]
        elif tval.startswith("%q"):
            return self._quote_patterns[ScintillaConstants.SCE_RB_STRING_Q]
        else:
            return self._quote_patterns[ScintillaConstants.SCE_RB_DEFAULT]  # Fallback


class UDLClassifier(RubyCommonClassifier, shared_parser.UDLClassifier):
    pass


class RubyClassifier(RubyCommonClassifier, shared_parser.CommonClassifier):
    """Mixin class containing classifier callbacks"""
    def __init__(self):
        self.narrowStyles = {
            ScintillaConstants.SCE_RB_GLOBAL: VAR_KIND_GLOBAL,
            ScintillaConstants.SCE_RB_INSTANCE_VAR: VAR_KIND_INSTANCE,
            ScintillaConstants.SCE_RB_CLASS_VAR: VAR_KIND_CLASSVAR}

    def get_builtin_type(self, tok, callback):
        if self.is_number(tok):
            numval = tok['text']
            if numval.find(".") >= 0:
                return "Float"
            else:
                return "Fixnum"
        elif self.is_string(tok):
            return "String"
        elif tok['style'] == ScintillaConstants.SCE_RB_STRING_QR:
            return "Regexp"
        elif tok['style'] == ScintillaConstants.SCE_RB_STRING_QW:
            return "Array"
        return None

    def is_any_operator(self, tok):
        return tok['style'] == ScintillaConstants.SCE_RB_OPERATOR

    def is_comment(self, tok):
        return tok['style'] in (ScintillaConstants.SCE_RB_COMMENTLINE,
                                ScintillaConstants.SCE_RB_POD)

    def is_comment_structured(self, tok, callback):
        return tok['style'] == ScintillaConstants.SCE_RB_POD

    def is_identifier(self, tok, allow_keywords=False):
        return (tok['style'] == ScintillaConstants.SCE_RB_IDENTIFIER or
               (allow_keywords and
                tok['style'] in [ScintillaConstants.SCE_RB_WORD,
                                 ScintillaConstants.SCE_RB_WORD_DEMOTED]))

    def is_interpolating_string(self, tok, callback):
        return tok['style'] in [ScintillaConstants.SCE_RB_STRING,
                                ScintillaConstants.SCE_RB_REGEX,
                                ScintillaConstants.SCE_RB_HERE_QQ,
                                ScintillaConstants.SCE_RB_STRING_QQ,
                                ScintillaConstants.SCE_RB_STRING_QR,
                                ScintillaConstants.SCE_RB_STRING_QX
                                ]

    def is_keyword(self, tok, target):
        return tok['style'] == ScintillaConstants.SCE_RB_WORD and tok['text'] == target

    def is_number(self, tok):
        return tok['style'] == ScintillaConstants.SCE_RB_NUMBER

    def is_operator(self, tok, target):
        return tok['style'] == ScintillaConstants.SCE_RB_OPERATOR and tok['text'] == target

    def is_string(self, tok):
        return tok['style'] in [ScintillaConstants.SCE_RB_STRING,
                                ScintillaConstants.SCE_RB_CHARACTER,
                                ScintillaConstants.SCE_RB_HERE_Q,
                                ScintillaConstants.SCE_RB_HERE_QQ,
                                ScintillaConstants.SCE_RB_STRING_Q,
                                ScintillaConstants.SCE_RB_STRING_QQ,
                                ScintillaConstants.SCE_RB_STRING_QX
                                ]

    def is_symbol(self, tok, callback=None):
        return tok['style'] == ScintillaConstants.SCE_RB_SYMBOL

    def tokenStyleToContainerStyle(self, tok, callback):
        return self.narrowStyles.get(tok['style'], VAR_KIND_UNKNOWN)

    # Accessors for where we'd rather work with a style than call a predicate
    # fn

    @property
    def style_identifier(self):
        return ScintillaConstants.SCE_RB_IDENTIFIER

    @property
    def style_operator(self):
        return ScintillaConstants.SCE_RB_OPERATOR

    @property
    def style_word(self):
        return ScintillaConstants.SCE_RB_WORD

lang_specific_classes = {"Ruby": RubyClassifier,
                         "RHTML": UDLClassifier}


def remove_hashes(lines):
    return map(lambda s: _leading_hash_re.sub("", s), lines)


class RailsMigrationData:
    def __init__(self):
        self.tableHookName = None
        self.columns = []   # Array of {name, type} pairs


class RailsMigrationBlock:
    def __init__(self):
        self.table_name = None
        # non-neg means we're in the pertinent scope
        self.class_indentLevel = -1
        self.upFunc_indentLevel = -1
        self.data = []  # Array of RailsMigrationData

_inflector = None


def get_inflector():
    global _inflector
    if _inflector is None:
        import inflector.Inflector
        _inflector = inflector.Inflector.Inflector()
    return _inflector


class Parser:
    # New names could be added to Rails post Rails 2.0,
    # for database-specific types like 'blob'
    _rails_migration_types = ('binary', 'boolean', 'date',
                              'datetime', 'decimal', 'float',
                              'string', 'integer',
                              )

    def __init__(self, tokenizer, lang):
        self.tokenizer = tokenizer
        self.block_stack = []
        self.tree = FileNode()
        self.curr_node = self.tree
        self.bracket_matchers = {"[": "]", "{": "}", "(": ")"}
        self.classifier = lang_specific_classes[lang]()
        self.containers = {VAR_KIND_GLOBAL: [self.tree.global_vars],
                           VAR_KIND_CLASS: [],  # classes
                           VAR_KIND_CLASSVAR: [],
                           VAR_KIND_INSTANCE: [],
                           VAR_KIND_LOCAL: [self.tree.local_vars],  # locals
                           VAR_KIND_ALIAS: [self.tree.aliases],
                           }
        self.rails_migration_block = RailsMigrationBlock()

    def class_has_method(self, curr_node, the_text):
        try:
            class_node = self.containers[VAR_KIND_CLASS][-1]
            for c in class_node.children:
                if isinstance(c, MethodNode) and c.name == the_text:
                    return True
        except:
            pass
        return False

    def curr_block_start_indentation(self):
        try:
            ind = self.block_stack[-1].indentation
        except:
            ind = 0
        return ind

    # This routine compares the current line indentation
    # with the one at the start of the block
    #
    # Neg value: we've moved to far back
    # 0: same ind
    # Pos value: curr indent'n is greater than where we started

    def compare_curr_ind(self):
        start_ind = self.curr_block_start_indentation()
        curr_indent = self.tokenizer.get_curr_indentation()
        return curr_indent - start_ind

    def dump(self):
        self.tree.dump()

    def rails_migration_class_tree(self):
        rails_migration_block = self.rails_migration_block
        inflector = get_inflector()
        nodes = []
        for info in self.rails_migration_block.data:
            if info.tableHookName is None or not info.columns:
                return None
            className = inflector.camelize(
                inflector.singularize(info.tableHookName))
            classNode = ClassNode(className, info.startLine, False)
            classNode.set_line_end_num(info.endLine)
            for attrib_info in info.columns:
                methodNode = MethodNode(attrib_info[0], attrib_info[2])
                methodNode.set_line_end_num(attrib_info[2])
                classNode.append_node(methodNode)
            nodes.append(classNode)
        return nodes

    def parse(self):
        self.parse_aux(self.tree)
        return self.tree

    def get_parsing_objects(self, kwd):
        return {
            "module": [ModuleNode, self.parse_aux],
            "class": [ClassNode, self.parse_aux],
            "def": [MethodNode, self.parse_method]
        }.get(kwd, [None, None])

    def parse_open_parens(self):
        paren_count = 0
        while True:
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_operator(tok, "("):
                paren_count += 1
            else:
                return (tok, paren_count)

    def parse_attr_stmt_capture_info(self, collection, attr_tok, tok, curr_node):
        base_name = tok['text'][1:]
        update_collection(collection,
                          '@' + base_name, tok['start_line'])
        if isinstance(curr_node, ClassNode):
            if attr_tok != 'attr_writer':
                new_node = MethodNode(base_name, tok['start_line'])
                new_node.set_line_end_num(tok['start_line'])
                curr_node.append_node(new_node)
            if attr_tok in ['attr_writer', 'attr_accessor']:
                new_node = MethodNode(base_name + '=', tok['start_line'])
                new_node.set_line_end_num(tok['start_line'])
                new_node.add_arg(base_name, "")
                curr_node.append_node(new_node)

    def parse_attr_stmts(self, attr_tok, curr_node):
        """
        attr_tok is one of ['attr', 'attr_reader', 'attr_writer', 'attr_accessor']
        if curr_node is a ClassNode then set up a bunch of methods as well
        """
        try:
            collection = self.containers[VAR_KIND_INSTANCE][-1]
            if collection is None:
                return
        except:
            return
        (tok, paren_count) = self.parse_open_parens()
        if self.classifier.is_symbol(tok, self.classifier.is_symbol_cb):
            self.parse_attr_stmt_capture_info(
                collection, attr_tok, tok, curr_node)
        # Allow for more, but special case attr's
        while True:
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_operator(tok, ","):
                tok = self.tokenizer.get_next_token()
                # Intern unless attr
                if (self.classifier.is_symbol(tok, self.classifier.is_symbol_cb) and
                        attr_tok != 'attr'):
                    self.parse_attr_stmt_capture_info(
                        collection, attr_tok, tok, curr_node)
            else:
                self.tokenizer.put_back(tok)
                break
        # Might as well consume the closing parens
        while paren_count > 0:
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_operator(tok, ")"):
                paren_count -= 1
            else:
                self.tokenizer.put_back(tok)
                break

    def parse_assignment(self, collectionA, tok_text, start_line):
        if len(collectionA) == 0 or collectionA[-1] is None:
            return

        tok = self.tokenizer.get_next_token()
        # We don't need to Watch out for calls like abc=(1)
        # because that's always an assignment to a local.
        # self.abc=(1) is different

        if self.classifier.is_any_operator(tok):
            if tok['text'] == "=":
                self._finishVarAssignment(collectionA, tok_text, start_line)
                # Look to see if we have an instance of a class
                # This is
                update_collection(collectionA[-1], tok_text, start_line)
                return
            elif tok['text'] in ["::", "."]:
                # Don't store fully-qualified names, but do consume them
                # Keep name for debugging purposes.
                rest_of_name = self.get_fully_qualified_name()
                return
        self.tokenizer.put_back(tok)

    def _actual_string_from_string_or_symbol(self, tok):
        if self.classifier.is_symbol(tok):
            return tok['text'][1:]
        else:
            assert self.classifier.is_string(tok)
            return self.de_quote_string(tok)

    def _parse_migration_create_table_block(self):
        """This code is handled only when in the following conditions:
        1. The file path matches .../db/migrate/*.rb
        2. It's in a class that inherits from ActiveRecord::Migration
        3. It's in a function called "self.up"

        Database fields are found through two functions:
        create_table TABLE-NAME do |handle|
          handle.column COLUMN-NAME TYPE
        end

        To add:
        add_column TABLE-NAME COLUMN-NAME TYPE
        """
        tok = self.tokenizer.get_next_token()
        if not (self.classifier.is_symbol(tok) or self.classifier.is_string(tok)):
            return
        rails_migration_info = RailsMigrationData()
        rails_migration_info.tableHookName = self._actual_string_from_string_or_symbol(
            tok)
        rails_migration_info.startLine = tok['start_line']
        # Assume we don't find the end of the block, so assume the worst
        rails_migration_info.endLine = tok['start_line'] + 1
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, "{") or self.classifier.is_keyword(tok, "do"):
            control_tok = (tok['style'], (tok['text'] == "{" and "}") or "end")
        else:
            return
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, "|"):
            return
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_identifier(tok):
            return
        table_handle = tok['text']
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, "|"):
            return
        add_entry = False
        while True:
            tok = self.tokenizer.get_next_token()
            if tok['style'] == shared_lexer.EOF_STYLE:
                break
            elif tok['style'] == control_tok[0] and tok['text'] == control_tok[1]:
                rails_migration_info.endLine = tok['end_line']
                break
            elif self.classifier.is_identifier(tok) and tok['text'] == table_handle:
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_operator(tok, "."):
                    tok = self.tokenizer.get_next_token()
                    if self.classifier.is_identifier(tok):
                        line_num = tok['start_line']
                        if tok['text'] == 'column':
                            tok = self.tokenizer.get_next_token()
                            if self.classifier.is_symbol(tok) or self.classifier.is_string(tok):
                                column_name = self._actual_string_from_string_or_symbol(
                                    tok)
                                tok = self.tokenizer.get_next_token()
                                if self.classifier.is_operator(tok, ','):
                                    tok = self.tokenizer.get_next_token()
                                    if self.classifier.is_symbol(tok) or self.classifier.is_string(tok):
                                        column_type = self._actual_string_from_string_or_symbol(
                                            tok)
                                    else:
                                        column_type = ""
                                    add_entry = True
                        elif tok['text'] in self._rails_migration_types:
                            column_type = tok['text']
                            tok = self.tokenizer.get_next_token()
                            log.debug("Migration: add %s:%s",
                                      tok['text'], column_type)
                            if self.classifier.is_symbol(tok) or self.classifier.is_string(tok):
                                column_name = self._actual_string_from_string_or_symbol(
                                    tok)
                                add_entry = True
                        elif tok['text'] == "timestamps":
                            # Rails 2.0 migration syntax in these two blocks:
                            # create_table :objects do |t|
                            #   t.<type> :<name>
                            column_type = 'datetime'
                            rails_migration_info.columns.append((
                                'created_at', column_type, line_num))
                            rails_migration_info.endLine = line_num + 1
                            column_name = 'updated_at'
                            add_entry = True
                        if add_entry:
                            rails_migration_info.columns.append(
                                (column_name, column_type, line_num))
                            rails_migration_info.endLine = line_num + 1
                            add_entry = False
                            continue
            # Sanity check any token we have here
            if (tok['style'] == ScintillaConstants.SCE_RB_WORD and
                    tok['text'] in ('class', 'def')):
                self.tokenizer.put_back(tok)
                return
        self.rails_migration_block.data.append(rails_migration_info)
        # end _parse_migration_create_table_block

    def _parse_migration_add_column_stmt(self):
        """This code is handled only when in the following conditions:
        1. The file path matches .../db/migrate/*.rb
        2. It's in a class that inherits from ActiveRecord::Migration
        3. It's in a function called "self.up"
        4. We saw an add_column action.

        Syntax:
        add_column TABLE-NAME COLUMN-NAME TYPE
        """
        tok = self.tokenizer.get_next_token()
        if not (self.classifier.is_symbol(tok) or self.classifier.is_string(tok)):
            return
        table_name = self._actual_string_from_string_or_symbol(tok)
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, ","):
            return
        tok = self.tokenizer.get_next_token()
        if not (self.classifier.is_symbol(tok) or self.classifier.is_string(tok)):
            return
        rails_migration_info = RailsMigrationData()
        rails_migration_info.tableHookName = table_name
        rails_migration_info.endLine = rails_migration_info.startLine = tok[
            'start_line']
        column_name = self._actual_string_from_string_or_symbol(tok)
        column_type = ""
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, ','):
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_symbol(tok) or self.classifier.is_string(tok):
                column_type = self._actual_string_from_string_or_symbol(tok)
            else:
                self.tokenizer.put_back(tok)
        else:
            self.tokenizer.put_back(tok)
        rails_migration_info.columns.append((
            column_name, column_type, rails_migration_info.startLine))
        self.rails_migration_block.data.append(rails_migration_info)

    def _finish_interpolating_string(self, prev_tok):
        """ Matches sequences of "#{", ... "}"
        (which could nest).  Returns a list of all the tokens.
        """

        tok1 = self.tokenizer.get_next_token()
        if not self.classifier.is_any_operator(tok1) or \
           tok1['text'] != "#":
            self.tokenizer.put_back(tok1)
            return [prev_tok]
        tok2 = self.tokenizer.get_next_token()
        if not self.classifier.is_any_operator(tok2) or \
           tok2['text'] != "{":
            self.tokenizer.put_back(tok1)
            self.tokenizer.put_back(tok2)
            return [prev_tok]

        nested_count = 1
        tok_list = [prev_tok, tok1, tok2]
        # At this point process a contiguous stream of tokens
        while True:
            bail_out = False
            new_tok = self.tokenizer.get_next_token()
            if new_tok['style'] == shared_lexer.EOF_STYLE:
                bail_out = True
            elif self.classifier.is_any_operator(new_tok):
                if new_tok['text'] == "#":
                    tok_list.append(new_tok)
                    new_tok = self.tokenizer.get_next_token()
                    if self.classifier.is_any_operator(new_tok) and \
                       new_tok['text'] == "{":
                        nested_count += 1
                    elif nested_count == 0:
                        bail_out = True
                elif new_tok['text'] == "}" and nested_count > 0:
                    nested_count -= 1
                elif nested_count == 0:
                    bail_out = True
            elif self.classifier.is_interpolating_string(new_tok, self._test_interpolate_string):
                pass
            elif nested_count == 0:
                bail_out = True
            if bail_out:
                self.tokenizer.put_back(new_tok)
                return tok_list
            else:
                tok_list.append(new_tok)

    def _at_end_expression(self, tok):
        if not self.classifier.is_any_operator(tok):
            return True
        return tok['text'] in [",", "}", ";"]

    def skip_to_op(self, opText, nestedLevel=1):
        skipped_toks = []
        while 1:
            tok = self.tokenizer.get_next_token()
            skipped_toks.append(tok)
            if tok['style'] == shared_lexer.EOF_STYLE:
                return skipped_toks
            elif self.classifier.is_any_operator(tok):
                if tok['text'] in ["(", "{", "["]:
                    nestedLevel += 1
                elif tok['text'] in ["]", "}", ")"]:
                    nestedLevel -= 1
                    if nestedLevel <= 0:
                        return skipped_toks
                # don't care about other ops
            # don't care about other token types

    def de_quote_string(self, tok):
        tval = tok['text']
        patterns = self.classifier.get_quote_patterns(
            tok, self.classifier.quote_patterns_cb)
        for p in patterns:
            m = p.match(tval)
            if m:
                return m.group(1)
        return tval

    def _finishVarAssignment(self, collectionA, var_name, start_line):
        # See doc for finishVarAssignment in src/perlcile/ParseModule.pm
        # for comments.
        # 1: a = b.c.d.e -- don't bother
        # 2.1: a = <number> <no op>
        # 2.2: a = <string> <no op>
        # 3. a = <classname>.New [( ... )]<no op>

        tok_list = self.get_fully_qualified_name_as_list()
        if not tok_list:
            return
        tok = tok_list[0]
        if self.classifier.is_identifier(tok):
            var_citdl = None
            toks_to_return = tok_list
            if len(toks_to_return) < 3:
                tok2 = self.tokenizer.get_next_token()
                # toks_to_return.append(tok2)
                if self.classifier.is_operator(tok2, ','):
                    # XXX : skip to end -- we must be in a parallel assignment
                    pass
                else:
                    if self._at_end_expression(tok2):
                        var_citdl = tok['text']
                    self.tokenizer.put_back(tok2)
            elif self.classifier.is_operator(toks_to_return[-2], '.') and \
                self.classifier.is_identifier(toks_to_return[-1]) and \
                    toks_to_return[-1]['text'] == 'new':
                    tok3 = self.tokenizer.get_next_token()
                    if self._at_end_expression(tok3):
                        var_citdl = ''.join([tok[
                                            'text'] for tok in tok_list[:-2]])
                        self.tokenizer.put_back(tok3)
                        # toks_to_return.append(tok3)
                    else:
                        if self.classifier.is_operator(tok3, "("):
                            skipped_toks = self.skip_to_op(")")
                            # toks_to_return += skipped_toks
                            tok4 = self.tokenizer.get_next_token()
                        else:
                            tok4 = tok3
                        if self._at_end_expression(tok4):
                            var_citdl = ''.join([tok[
                                                'text'] for tok in tok_list[:-2]])
                        self.tokenizer.put_back(tok4)
            update_collection(collectionA[-1], var_name, start_line, var_citdl)
            # Idea: don't bother putting back these tokens
            # for t in tok_list:
            #    self.tokenizer.put_back(t)
            return

        builtin_type = self.classifier.get_builtin_type(
            tok, self._test_for_builtin_type)
        if builtin_type:
            type1, locn = tok['style'], tok['start_line']
            if self.classifier.is_interpolating_string(tok, self._test_interpolate_string):
                self._finish_interpolating_string(tok)
            tok2 = self.tokenizer.get_next_token()
            if self._at_end_expression(tok2):
                if self.classifier.is_number(tok):
                    type1 = "Number"
                else:
                    type1 = "String"
                update_collection(collectionA[
                                  -1], var_name, start_line, builtin_type)
                toks = [tok2]
            else:
                update_collection(collectionA[-1], var_name, start_line)
                toks = [tok2, tok]
        elif tok['style'] == self.classifier.style_identifier:
            raise(
                "get_fully_qualified_name_as_list failed to process an identifer")
        elif self.classifier.is_operator(tok, "["):
            toks = self._finish_list(
                collectionA, var_name, start_line, tok, "]", "Array")
        elif self.classifier.is_operator(tok, "{"):
            toks = self._finish_list(
                collectionA, var_name, start_line, tok, "}", "Hash")
        else:
            update_collection(collectionA[-1], var_name, start_line)
            toks = [tok]
        for t in reversed(toks):
            self.tokenizer.put_back(t)

    def _finish_list(self, collectionA, var_name, start_line, orig_tok, end_op, class_name):
        skipped_toks = [orig_tok] + self.skip_to_op(end_op)
        final_tok = self.tokenizer.get_next_token()
        skipped_toks.append(final_tok)
        class_name_final = self._at_end_expression(
            final_tok) and class_name or None
        update_collection(collectionA[
                          -1], var_name, start_line, class_name_final)
        return skipped_toks

    def _set_basename_method(self, node_class, curr_node, nm_token):
        if node_class != MethodNode:
            return (nm_token, False)
        method_name = nm_token[0]
        idx1 = method_name.rfind('::')
        if idx1 >= 0:
            idx1_len = 2
        idx2 = method_name.rfind('.')
        if idx2 >= 0:
            idx2_len = 1
        if idx1 < 0:
            if idx2 < 0:
                return (nm_token, False)
            idx = idx2
            idx_len = 1
        elif idx2 < idx1:
            # Includes no idx2
            idx = idx1
            idx_len = 2
        else:
            idx = idx2
            idx_len = 1
        first_part = method_name[0:idx]
        if first_part != getattr(curr_node, 'name', '') and first_part != 'self':
            # We're doing something like defining inside a mix-in
            return (nm_token, False)

        basename = method_name[idx + idx_len:]
        if len(nm_token) != 2:
            raise("Expectations dashed!")

        return ((basename, nm_token[1]), True)

    def _test_interpolate_string(self, tok, generic_tok_type):
        if generic_tok_type == shared_parser.GENERIC_TYPE_REGEX:
            return True
        elif generic_tok_type != shared_parser.GENERIC_TYPE_STRING:
            return False
        tval = tok['text']
        c1 = tval[0]
        if c1 == "'":
            return False
        elif c1 == '"':
            return True
        elif c1 == '%':
            if len(c1) == 1:
                return False  # ???
            c2 = tval[1]
            if c2 in "WwQrx":
                return True
        return False

    # Callback used by get_builtin_type
    def _test_for_builtin_type(self, tok, generic_tok_type):
        if generic_tok_type == shared_parser.GENERIC_TYPE_NUMBER:
            numval = tok['text']
            if numval.find(".") >= 0:
                return "Float"
            else:
                return "Fixnum"
        elif generic_tok_type == shared_parser.GENERIC_TYPE_STRING:
            tval = tok['text']
            if len(tval) > 1 and tval[0] == "%":
                if tval[1] in 'wW':
                    return "Array"
                elif tval[1] == 'r':
                    return "Regexp"
            return "String"
        elif generic_tok_type == shared_parser.GENERIC_TYPE_REGEX:
            return "Regexp"
        else:
            return None

    # Callback used by tokenStyleToContainerStyle
    def _test_token_style(self, tok, is_variable_token):
        if not is_variable_token:
            return VAR_KIND_UNKNOWN
        tval = tok['text']
        if tval[0] == '$':
            return VAR_KIND_GLOBAL
        elif tval[0] == '@':
            if len(tval) > 1 and tval[1] == '@':
                return VAR_KIND_CLASSVAR
            else:
                return VAR_KIND_INSTANCE
        return VAR_KIND_UNKNOWN

    def _try_loading_relative_library(self, tok, curr_node):
        """Look for instances of
        require File.dirname(__FILE__) + <string> and map to
        @<string>"""
        seq_start_line = tok['start_line']
        if not self.classifier.is_identifier(tok) or tok['text'] != 'File':
            return
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, '.'):
            return
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_identifier(tok) or tok['text'] != 'dirname':
            return
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, '('):
            return
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_identifier(tok, True) or tok['text'] != '__FILE__':
            return
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, ')'):
            return
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, '+'):
            return
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_string(tok):
            curr_node.imports.append(Name_LineNum
                                     (self._create_relative_libname(tok),
                                      seq_start_line))

    def _create_relative_libname(self, tok):
        # For now just return the path.  If we need to decorate it
        # to indicate it's a relative path, we'll do that later.
        return self.de_quote_string(tok)[1:]

    def _extract_alias_name(self, tok):
        if self.classifier.is_identifier(tok):
            return tok['text']
        elif self.classifier.is_symbol(tok, self.classifier.is_symbol_cb):
            return tok['text'][1:]
        else:
            return None

    def parse_aux(self, curr_node):
        at_start = True
        while 1:
            tok = self.tokenizer.get_next_token()
            if tok['style'] == shared_lexer.EOF_STYLE:
                break
            # style, text, start_column, start_line, end_column, end_line = tok
            style, text = tok['style'], tok['text']
            if style == self.classifier.style_word:
                if text in ["module", "class", "def"]:
                    # Check to see if we missed some nodes,
                    # using heuristic that the end statements line up
                    # with the start of each block, for definitions

                    if len(self.block_stack) > 0 and self.compare_curr_ind() <= 0:
                        # We missed one or more end's, so put the token
                        # back and try in an outer instance
                        self.tokenizer.put_back(tok)
                        return

                    curr_indent = self.tokenizer.get_curr_indentation()
                    node_class, node_parser = self.get_parsing_objects(text)
                    if node_class is None:
                        sys.stderr.write(
                            "Couldn't get parsing objects for type %s\n" % text)
                        break
                    elif node_class is MethodNode:
                        self.tokenizer.start_sig()

                    # Get the comments before further parsing.
                    comment_lines = remove_hashes(
                        self.tokenizer.curr_comment())
                    nm_token = self.get_fully_qualified_name()
                    if not nm_token[0]:
                        return
                    elif nm_token[0] == "<<" and node_class == ClassNode:
                        # Singleton classes
                        nm_token = self.get_fully_qualified_name()
                        if not nm_token[0]:
                            return

                    if self.rails_migration_block.class_indentLevel >= 0 and nm_token[0] == "self.up":
                        self.rails_migration_block.upFunc_indentLevel = curr_indent
                        rails_migration_clear_upfunc = True
                    else:
                        rails_migration_clear_upfunc = False

                    (nm_token, is_class_method) = self._set_basename_method(
                        node_class, curr_node, nm_token)
                    new_node = node_class(nm_token[0], tok[
                                          'start_line'], nm_token[0] == "initialize")
                    if is_class_method:
                        new_node.is_classmethod = True
                    elif node_class == MethodNode and (isinstance(curr_node, ClassNode) or isinstance(curr_node, ModuleNode)):
                        # Add info on the 'self' variable
                        update_collection(new_node.local_vars, 'self', tok[
                                          'start_line'], curr_node.name)
                    new_node.doc_lines = comment_lines
                    new_node.indentation = curr_indent
                    self.block_stack.append(new_node)
                    curr_node.append_node(new_node)

                    # Push new containers on the symbol table
                    self.containers[VAR_KIND_LOCAL].append(new_node.local_vars)
                    if node_class in [ClassNode, ModuleNode]:
                        self.containers[VAR_KIND_CLASS].append(new_node)
                        self.containers[VAR_KIND_CLASSVAR].append(
                            new_node.class_vars)
                        self.containers[VAR_KIND_INSTANCE].append(
                            new_node.instance_vars)
                        self.containers[VAR_KIND_ALIAS].append(
                            new_node.aliases)

                    # Watch out for class inheritence

                    rails_migration_clear_classref = False
                    if node_class == ClassNode:
                        self.parse_classref(new_node)
                        if new_node.has_classref('ActiveRecord::Migration'):
                            self.rails_migration_block.class_indentLevel = curr_indent
                            rails_migration_clear_classref = True
                    node_parser(new_node)  # Has self bound to it
                    if rails_migration_clear_upfunc:
                        self.rails_migration_block.upFunc_indentLevel = -1
                    elif rails_migration_clear_classref:
                        self.rails_migration_block.class_indentLevel = -1
                    self.block_stack.pop()
                    self.containers[VAR_KIND_LOCAL].pop()
                    if node_class in [ClassNode, ModuleNode]:
                        self.containers[VAR_KIND_CLASSVAR].pop()
                        self.containers[VAR_KIND_INSTANCE].pop()
                        self.containers[VAR_KIND_CLASS].pop()
                        self.containers[VAR_KIND_ALIAS].pop()

                    # Clear any comment that's hanging around
                    self.tokenizer.clear_comments()

                elif text == "alias":
                    new_tok = self.tokenizer.get_next_token()
                    new_name = self._extract_alias_name(new_tok)
                    existing_tok = self.tokenizer.get_next_token()
                    existing_name = self._extract_alias_name(existing_tok)
                    if new_name and existing_name:
                        update_collection(self.containers[VAR_KIND_ALIAS][
                                          -1], new_name, new_tok['start_line'], existing_name)

                        # set a variable in curr_node
                elif text == "end":
                    if len(self.block_stack) > 0:
                        end_position = self.compare_curr_ind()
                        if end_position < 0:
                            # We've gone too far, so put it back and try later
                            curr_node.set_line_end_num(tok['start_line'])
                            self.tokenizer.put_back(tok)
                            return
                        elif end_position == 0:
                            curr_node.set_line_end_num(tok['start_line'])
                            # the caller will pop the stack
                            return

            elif style == self.classifier.style_identifier:
                if text == "require" or text == "load":
                    tok = self.tokenizer.get_next_token()
                    if (self.tokenizer.is_string_token(tok)):
                        tval = self.de_quote_string(tok)
                        if tval.endswith(".rb"):
                            tval = tval[:-3]
                        curr_node.imports.append(
                            Name_LineNum(tval, tok['start_line']))
                    else:
                        self._try_loading_relative_library(tok, curr_node)
                elif text == "include":
                    nm_token = self.get_fully_qualified_name()
                    if nm_token[0]:
                        curr_node.includes.append(Name_LineNum(
                            nm_token[0], nm_token[1]))
                #@@@@ elif text == "base":
                    # semi-hardwired rails thing
                    #@@@@ self.parse_class_extension()
                    # if next() == (OP, ".") \
                      # and next() == (ID, "extend") \
                       # and next() == (OP, "(") \

                elif at_start or tok['start_column'] == self.tokenizer.get_curr_indentation():
                    # Look at these things only at start of line
                    if text in ['attr', 'attr_reader', 'attr_writer', 'attr_accessor']:
                        self.parse_attr_stmts(text, curr_node)
                    elif text == 'create_table' and self.rails_migration_block.upFunc_indentLevel >= 0:
                        self._parse_migration_create_table_block()
                    elif text == 'add_column' and self.rails_migration_block.upFunc_indentLevel >= 0:
                        self._parse_migration_add_column_stmt()
                    elif not self.class_has_method(curr_node, tok['text'] + "="):
                        # Make sure it isn't an assignment function
                        self.parse_assignment(self.containers[
                                              VAR_KIND_LOCAL], text, tok['start_line'])

            elif self.classifier.is_any_operator(tok):
                if text == "{":
                    new_node = BlockNode("{", tok['start_line'])
                    new_node.indentation = self.tokenizer.get_curr_indentation(
                    )
                    # XXX Transfer any children a block defines to the
                    # parent of the block.  Uncommon formulation
                    self.block_stack.append(new_node)
                    self.parse_aux(new_node)
                    self.block_stack.pop()
                elif text == "}":
                    if len(self.block_stack) > 0:
                        end_position = self.compare_curr_ind()
                        if end_position < 0:
                            # We've gone too far, so put it back and try later
                            self.tokenizer.put_back(tok)
                            return
                        elif end_position == 0:
                            # the caller will pop the stack
                            return
            # Check for assignment to some kind of variable
            else:
                narrow_style = self.classifier.tokenStyleToContainerStyle(
                    tok, self._test_token_style)
                if narrow_style != VAR_KIND_UNKNOWN:
                    self.parse_assignment(self.containers[
                                          narrow_style], tok['text'], tok['start_line'])
            # end if WORD block
            # XXX: process variables as well
            at_start = False
        # end while
        return
    # end parse_aux()

    """
    Simplified Ruby function-defn grammar

method_def ::= kDEF fname f_arglist bodystmt kEND
fname ::= ID
f_arglist ::= "(" f_args opt_nl ")" | f_args term
term ::= "\n" | ";"
f_args ::= f_arg(s /,/)
	 | <nothing>
f_arg ::= f_norm_arg | f_opt | f_rest_arg | f_block_arg
f_norm_arg ::= id
f_opt ::= id '=' arg_value
f_rest_arg ::= "*" id?
f_block_arg ::= "&" id

arg_value ::= simple_expn
simple_expn ::= (simple_term | nested_expn)+
simple_term ::= <anything but a ";", "\n", ")", "," or a block-starter or closer
 - the exceptions depend on whether we're in a parenthesized construct or not
simple_inner_expn ::= (simple_term | nested_expn)+
nested_expn ::= "(" simple_expn ")" | "{" simple_expn "}" | "[" simple_expn "]"
"""

    def parse_nested_expn(self, block_end_char):
        while 1:
            tok = self.tokenizer.get_next_token()
            if tok['style'] == shared_lexer.EOF_STYLE:
                return
            elif self.classifier.is_any_operator(tok):
                # Don't look at commas or semi-colons here, as we might be
                # processing nested comma-sep things or even blocks
                if len(tok['text']) == 1:
                    if tok['text'] == block_end_char:
                        return -1
                    elif "[{(".find(tok['text']) >= 0:
                        self.parse_nested_expn(
                            self.bracket_matchers[tok['text']])
            elif self.classifier.is_keyword(tok, "end"):
                if len(self.block_stack) == 0:
                    return
                elif self.compare_curr_ind() <= 0:
                    # Did we go too far?
                    self.tokenizer.put_back(tok)
                    return
    # end parse_nested_expn

    # This might not always work
    def parse_simple_expn(self, has_paren):
        while 1:
            tok = self.tokenizer.get_next_token()
            if tok['style'] == shared_lexer.EOF_STYLE:
                return
            elif self.classifier.is_any_operator(tok):
                if tok['text'] == ",":
                    self.tokenizer.put_back(tok)
                    return
                elif has_paren and tok['text'] == ')':
                    self.tokenizer.put_back(tok)
                    return
                elif not has_paren and tok['text'] == ';':
                    self.tokenizer.put_back(tok)
                    return
                elif len(tok['text']) == 1 and "[{(".find(tok['text']) >= 0:
                    self.parse_nested_expn(self.bracket_matchers[tok['text']])
            elif self.classifier.is_keyword(tok, "end"):
                if len(self.block_stack) == 0:
                    return
                elif self.compare_curr_ind() <= 0:
                    # Did we go too far?
                    self.tokenizer.put_back(tok)
                    return
    # end parse_simple_expn

    def parse_method_args(self, curr_node):
        """
        grammar: def name [( [arg [= val], ...][,*vararg], [, &blockarg])]
        """
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, "("):
            self.tokenizer.put_back(tok)
            return  # No args

        # Simplify the loop by looking to see if we have no args
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, ")"):
            return
        self.tokenizer.put_back(tok)

        while 1:
            have_equals = False
            tok = self.tokenizer.get_next_token()

            # Note -- silvercity swallows \-line-continuations,
            # so we don't need to handle them

            # then check for arg-list termination,
            # and then process the arg...
            extra_info = ""
            if (self.classifier.is_any_operator(tok) and
                    len(tok['text']) == 1 and "*&".find(tok['text']) >= 0):
                extra_info = tok['text']
                tok = self.tokenizer.get_next_token()
            if self.classifier.is_identifier(tok, True):
                txt = tok['text']
                if txt[-1] == '=':
                    txt = txt[:-1]
                    have_equals = True
                curr_node.add_arg(txt, extra_info)
            else:
                # give up -- expected to see an arg, didn't
                return
            # check for an '=' sign
            if not have_equals:
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_operator(tok, '='):
                    have_equals = True

            if have_equals:
                self.parse_simple_expn(True)
                tok = self.tokenizer.get_next_token()

            # First check for white-space, set indent,
            if tok['style'] == shared_lexer.EOF_STYLE:
                return
            elif self.classifier.is_operator(tok, ")"):
                return
            elif self.classifier.is_keyword(tok, 'end') and self.compare_curr_ind() <= 0:
                # Did we go too far?
                self.tokenizer.put_back(tok)
                return
            elif self.classifier.is_operator(tok, ","):
                pass  # Keep parsing
            else:
                self.tokenizer.put_back(tok)
                return
            # end if
        # end while
    # end parse_method_args

    def parse_method(self, curr_node):
        # Get the args before dispatching back to the main routine

        self.parse_method_args(curr_node)
        self.tokenizer.stop_sig()

        # XXX Remove newlines and \-prefixed newlines, with white-space
        curr_node.signature = self.tokenizer.get_sig(
        )  # @@@@ self.trimmer.trim_ws(self.tokenizer.get_sig())

        # Now look for the 'end' on the same line as a special case
        # The start line is contained in curr_node.line_num
        while 1:
            tok = self.tokenizer.get_next_token()
            if tok['style'] == shared_lexer.EOF_STYLE:
                return
            # style, text, start_column, start_line, end_column, end_line = tok
            if tok['end_line'] > self.block_stack[-1].line_num:
                self.tokenizer.put_back(tok)
                break
            #*** Heuristic: if we find an 'end' followed by a newline, end the sub here
            elif self.classifier.is_keyword(tok, "end"):
                # Assume that's the end
                # Let the caller pop the block_stack
                return
        # end while
        self.parse_aux(curr_node)
    # end parse_method

    def parse_classref(self, node):
        toks = []
        tok = self.tokenizer.get_next_token(1)
        fqname = classref_type = None
        if self.classifier.is_operator(tok, "<"):
            fqname, line_start = self.get_fully_qualified_name()
            if fqname == "DelegateClass":
                tok = self.tokenizer.get_next_token(1)
                if self.classifier.is_operator(tok, "("):
                    # No putback once we enter this point
                    inner_name, junk = self.get_fully_qualified_name()
                    tok = self.tokenizer.get_next_token()
                    if self.classifier.is_operator(tok, ")"):
                        fqname = "%s(%s)" % (fqname, inner_name)
                        classref_type = inner_name
                else:
                    toks.append(tok)
        else:
            fqname = "Object"
            line_start = tok['start_line']
            toks.append(tok)
        if fqname is not None:
            node.add_classrefs(fqname, line_start, classref_type)

        for t in toks:
            self.tokenizer.put_back(t)

    def get_fully_qualified_name(self):
        tok = self.tokenizer.get_next_token()
        if tok['style'] == shared_lexer.EOF_STYLE:
            return (None, None)
        name_start = tok['text']
        line_start = tok['start_line']
        # Watch out if it starts with a "::"
        if name_start == "::":
            tok = self.tokenizer.get_next_token()
            if tok['style'] != self.classifier.style_identifier:
                self.tokenizer.put_back(tok)
                return (name_start, line_start)
            name_start += tok['text']

        while 1:
            # Collect operator-type methods
            if self.classifier.is_any_operator(tok):
                while 1:
                    tok = self.tokenizer.get_next_token()
                    if self.classifier.is_any_operator(tok) and tok['text'] not in "()@${};:?,":
                        name_start += tok['text']
                    else:
                        self.tokenizer.put_back(tok)
                        break
                # And it will be the end of the line
                return (name_start, line_start)
            tok = self.tokenizer.get_next_token()
            if not self.classifier.is_any_operator(tok):
                self.tokenizer.put_back(tok)
                break
            if not tok['text'] in ["::", "."]:
                self.tokenizer.put_back(tok)
                break
            tok2 = self.tokenizer.get_next_token()
            if tok2['style'] != self.classifier.style_identifier:
                self.tokenizer.put_back(tok2)
                self.tokenizer.put_back(tok)
                break
            name_start += tok['text'] + tok2['text']
        return (name_start, line_start)

    # Consume { (CapName, ['.' | '::']) | (lcName, '::') }
    # Return a list of the tokens
    def get_fully_qualified_name_as_list(self):
        # Check for a leading '::' and throw it away
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, '::'):
            # Throw it away
            tok = self.tokenizer.get_next_token()

        if self.classifier.is_identifier(tok, False):
            tok_list = [tok]
        else:
            return [tok]

        # Now look for scope-resolution operators:
        # '::' always
        # '.' followed by an upper-case name (not fully Rubyish, but...)

        while True:
            # Check for a continuation
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_any_operator(tok):
                if tok['text'] in ("::", '.'):
                    # Always keep going with a scope-resolution operator
                    tok2 = self.tokenizer.get_next_token()
                    if not self.classifier.is_identifier(tok2, True):
                        self.tokenizer.put_back(tok)
                        self.tokenizer.put_back(tok2)
                        break
                    tok_list.append(tok)
                    tok_list.append(tok2)
                    # Check if we're done
                    if tok['text'] == '.' and not tok2['text'][0].isupper():
                        break
                else:
                    self.tokenizer.put_back(tok)
                    break
            else:
                self.tokenizer.put_back(tok)
                break

        return tok_list

# end class Parser


if __name__ == "__main__":
    if len(sys.argv) == 1:
        sample_code = ruby_lexer.provide_sample_code()
        fs = None
    elif sys.argv[1] == "-":
        fs = sys.stdin
        closefs = False
    else:
        fs = open(sys.argv[1], "r")
        closefs = True
    if fs is not None:
        sample_code = shared_lexer.read_and_detab(fs, closefs)
        # fs comes back closed
    tokenizer = ruby_lexer.RubyLexer(sample_code)
    parser = Parser(tokenizer, "Ruby")
    tree = parser.parse()
    print "Analyze the parse tree"
    tree.dump()

########NEW FILE########
__FILENAME__ = shared_lexer
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)
#
# Common wrapper around SilverCity used by Ruby, Perl

import copy
import re
import sys

from SilverCity import ScintillaConstants

import logging
#---- global data
log = logging.getLogger("codeintel_shared_lexer")
# log.setLevel(logging.DEBUG)

MAX_REASONABLE_LIMIT = 10000

WHITESPACE = '\t\n\x0b\x0c\r '  # don't use string.whitespace (bug 81316)
ws_re = re.compile("^[" + WHITESPACE + "\\\\" + "]*$")
trailing_spaces_re = re.compile("\n([ \t]*)$")
trim_ws_re2 = re.compile(r'[\r\n\t]')
trim_ws_re3 = re.compile(r' {2,}')


def makeToken(style, text="", start_column=None, start_line=None, end_column=None, end_line=None):
    return {
        'style': style,
        'text': text,
        'start_column': start_column,
        'start_line': start_line,
        'end_column': end_column,
        'end_line': end_line,
    }

EOF_STYLE = -1
EOF_TOKEN = {'style': EOF_STYLE,
             'text': None,
             'start_column': None,
             'start_line': None,
             'end_column': None,
             'end_line': None,
             }


class Signature:
    def __init__(self):
        self._gathering = False
        self._text = ""

    def open(self):
        self._gathering = True
        self._text = ""

    def close(self):
        self._gathering = False

    def text(self):
        return self._text

    def append(self, text):
        self._text += text

    def replace(self, text):
        self._text = text

    def is_gathering(self):
        return self._gathering


class Lexer:
    def __init__(self):
        self.gen = self._get_next_token
        self.curr_indentation = 0
        self.curr_comments = []
        self.finished_comment = True
        self.use_leading_spaces = True
        self.signature = Signature()
        self.q = []
        self.curr_line = 1

    def prepare_token_list_for_use(self):
        self.q_position = 0
        self.q_lim = len(self.q)

    def build_dict(self, ws_sep_str):
        the_dict = {}
        for the_key in ws_sep_str.strip().split():
            the_dict[the_key] = 1
        return the_dict

    def is_string_token(self, tok):
        return tok['style'] in self.string_types

    def contains_nl(self, str2):
        return str2.find("\n") >= 0

    def _adapt_line(self, line_num):
        if line_num is None:
            return None
        return line_num + 1

    def complete_token_push(self, tok, adjust_line=True, dest_q=None):
        if dest_q is not None:
            dest_q.append(tok)
        else:
            self.q.append(tok)

    def _get_next_token(self):
        if self.q_position >= self.q_lim:
            return EOF_TOKEN
        tok = self.q[self.q_position]
        self.q_position += 1
        if 'adjust_lines' not in tok:
            for s in ('start_line', 'end_line'):
                if s not in tok:
                    tok[s] = None
                else:
                    tok[s] += 1
            tok['adjust_lines'] = True
        return tok

    def _get_eof_token(self):
        return EOF_TOKEN

    def matches_whitespace(self, text):
        return ws_re.match(text)

    def get_curr_indentation(self):
        return self.curr_indentation

    def curr_comment(self, destroy=1):
        hold = self.curr_comments
        self.curr_comments = []
        return hold

    def clear_comments(self):
        self.curr_comments = []

    def has_comment(self):
        return len(self.curr_comments) > 0

    def is_udl_markup_family(self, ttype):
        return ScintillaConstants.SCE_UDL_M_DEFAULT <= ttype <= ScintillaConstants.SCE_UDL_M_COMMENT

    def is_udl_css_family(self, ttype):
        return ScintillaConstants.SCE_UDL_CSS_DEFAULT <= ttype <= ScintillaConstants.SCE_UDL_CSS_OPERATOR

    def is_udl_csl_family(self, ttype):
        return ScintillaConstants.SCE_UDL_CSL_DEFAULT <= ttype <= ScintillaConstants.SCE_UDL_CSL_REGEX

    def is_udl_ssl_family(self, ttype):
        return ScintillaConstants.SCE_UDL_SSL_DEFAULT <= ttype <= ScintillaConstants.SCE_UDL_SSL_VARIABLE

    def is_udl_tpl_family(self, ttype):
        return ScintillaConstants.SCE_UDL_TPL_DEFAULT <= ttype <= ScintillaConstants.SCE_UDL_TPL_VARIABLE

    # Methods for manipulating signatures

    def start_sig(self):
        self.signature.open()

    def stop_sig(self):
        self.signature.close()

    def trim_ws(self, s1):
        s2 = trim_ws_re2.sub(' ', s1)
        s3 = trim_ws_re3.sub(' ', s2)
        s4 = s3.strip()
        if len(s4) == 0:
            if len(s1) > 0:
                return " "
        return s4

    def get_sig(self):
        return self.signature.text().strip()

    # Main external routines

    def put_back(self, tok):
        if tok['style'] == EOF_STYLE:
            return
        if self.signature.is_gathering():
            sig = self.signature.text()
            last_text = tok['text']
            if sig[-len(last_text):] == last_text:
                sig = sig[0:-len(last_text)]
                self.signature.replace(sig)

        # Skip over white-space nodes
        while True:
            self.q_position -= 1
            if self.q_position < 0:
                raise Exception(
                    "Trying to put back a token when position is at start")
            q_tok = self.q[self.q_position]
            if q_tok['style'] == tok['style'] or q_tok['text'] == tok['text']:
                break

        if tok.get('start_line') is not None:
            # Move back for the current line #
            self.curr_line = self.q[self.q_position]['start_line']

    def peek_next_token(self):
        if self.q_position < self.q_lim:
            return self.q[self.q_position]
        return EOF_TOKEN

    def curr_line_no(self):
        return self.curr_line

    def append_split_tokens(self, tok, multi_char_ops_dict,
                            adjust_line=False, dest_q=None, end_column_offset=1):
        # Treat dest_q like a queue here.
        tval = tok['text']
        split_tokens = []
        while len(tval) > 0:
            if tval in multi_char_ops_dict:
                split_tokens.append(tval)
                break
            else:
                # XXX Handle allowed prefixes, as in "<<" and "<<="
                found_something = False
                for possible_op in multi_char_ops_dict.keys():
                    if tval.startswith(possible_op):
                        split_tokens.append(possible_op)
                        tval = tval[len(possible_op):]
                        found_something = True
                        break
                if not found_something:
                    split_tokens.append(tval[0])
                    tval = tval[1:]
        if len(split_tokens) > 1:
            col = tok['start_column']
            for stxt in split_tokens:
                new_tok = copy.copy(tok)
                new_tok['text'] = stxt
                new_tok['start_column'] = col
                new_tok['end_column'] = col + len(stxt) - end_column_offset
                col = new_tok['end_column']
                self.complete_token_push(
                    new_tok, adjust_line=adjust_line, dest_q=dest_q)
        else:
            self.complete_token_push(
                tok, adjust_line=adjust_line, dest_q=dest_q)

    def get_next_token(self, skip_ws=1):
        while True:
            tok = self.gen()
            gather = self.signature.is_gathering()

            ttype = tok['style']
            if tok.get('start_line') is not None:
                self.curr_line = tok['start_line']
            if ttype == EOF_STYLE:
                # Stop leaning on the queue, just return an eof_token
                self.gen = self._get_eof_token
                self.curr_indentation = 0
            elif ttype == self.classifier.style_comment:
                if self.finished_comment:
                    self.curr_comments = []
                    self.finished_comment = False
                self.curr_comments.append(tok['text'])
                self.use_leading_spaces = False
                if skip_ws:
                    continue
            elif ttype == self.classifier.style_default and self.matches_whitespace(tok['text']):
                if gather:
                    self.signature.append(self.trim_ws(tok['text']))
                has_nl = self.contains_nl(tok['text'])
                if has_nl or self.use_leading_spaces:
                    # Update this line's indentation only if we're at the start
                    if has_nl:
                        try:
                            self.curr_indentation = len(
                                trailing_spaces_re.findall(tok['text'])[-1])
                        except:
                            self.curr_indentation = 0
                    else:
                        self.curr_indentation = len(tok['text'])
                    # Do we still need to count white-space in subsequent
                    # tokens?
                    self.use_leading_spaces = (self.curr_indentation == 0)
                if skip_ws:
                    continue
            else:
                # At this point we're done with comments and leading white-
                # space
                if gather:
                    self.signature.append(tok['text'])
                self.finished_comment = True
                self.use_leading_spaces = False
            # If the loop doesn't continue, break here
            break
        return tok


class UDLLexerClassifier:
    """ This classifier is similar to the parser-level classifier, but
    it works on the SilverCity "raw" tokens as opposed to the
    tokens that get created by the lexer layer.  There should be some
    folding though."""

    def is_comment(self, ttype):
        return ttype in (ScintillaConstants.SCE_UDL_SSL_COMMENT,
                         ScintillaConstants.SCE_UDL_SSL_COMMENTBLOCK)

    @property
    def style_comment(self):
        return ScintillaConstants.SCE_UDL_SSL_COMMENT

    @property
    def style_default(self):
        return ScintillaConstants.SCE_UDL_SSL_DEFAULT

    @property
    def style_operator(self):
        return ScintillaConstants.SCE_UDL_SSL_OPERATOR


def read_and_detab(fs, closefd=False, tabwidth=8):
    sample_code = ""
    try:
        # Decompress tabs so our indentation calculations work
        lines = []
        for line in fs:
            lines.append(line.expandtabs(tabwidth))
        sample_code = "".join(lines)
    finally:
        if closefd:
            fs.close()
    return sample_code


def main(argv, provide_sample_code, specificLexer):
    if len(argv) == 1:
        sample_code = provide_sample_code()
        fs = None
    elif argv[1] == "-":
        fs = sys.stdin
    else:
        fs = open(argv[1], "r")
    if fs is not None:
        sample_code = read_and_detab(fs)
        # fs comes back closed

    lexer_wrapper = specificLexer(sample_code)
    last_line = -1
    while 1:
        tok = lexer_wrapper.get_next_token(1)
        if tok['style'] == EOF_STYLE:
            break
        if last_line != tok['start_line']:
            print "[%d:%d] " % (tok['start_line'], lexer_wrapper.curr_indentation),
            last_line = tok['start_line']
        if lexer_wrapper.has_comment():
            comments = lexer_wrapper.curr_comment(1)
            print comments
        print tok

########NEW FILE########
__FILENAME__ = shared_parser
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)
#

""" Many CILE parsers have to allow for tokens to arrive with
either native Scintilla types, or UDL types (and there might be
more in the future.

This module defines the abstraction layer over the UDL types.

Some routines can't fulfill a request just by looking at the type,
and need to examine the actual text of the token.  But a common
UDL layer can't do that, as each SSL language has different properties.
So callbacks that return to the SSL CILE are used for that purpose.

See ruby_parser.py for examples on writing callbacks for
get_builtin_type, is_interpolating_string, and
tokenStyleToContainerStyle (if any of these are called, that is).

"""
import re

from SilverCity import ScintillaConstants

GENERIC_TYPE_UNKNOWN = 0
GENERIC_TYPE_NUMBER = 1
GENERIC_TYPE_STRING = 2
GENERIC_TYPE_REGEX = 3


class CommonClassifier:
    _quote_patterns = {}

    def get_quote_patterns(self, tok, callback=None):
        ttype = tok['style']
        if ttype in self._quote_patterns:
            return [self._quote_patterns[ttype]]
        elif callback:
            return callback(tok)
        else:
            return self._quote_patterns.values()

    def is_identifier_or_keyword(self, tok):
        return self.is_identifier(tok, True)


class UDLClassifier(CommonClassifier):
    def get_builtin_type(self, tok, callback):
        if self.is_number(tok):
            return callback(tok, GENERIC_TYPE_NUMBER)
        elif self.is_string(tok):
            return callback(tok, GENERIC_TYPE_STRING)
        elif tok['style'] == ScintillaConstants.SCE_UDL_SSL_REGEX:
            return callback(tok, GENERIC_TYPE_REGEX)
        else:
            return callback(tok, GENERIC_TYPE_UNKNOWN)

    def is_any_operator(self, tok):
        return tok['style'] == ScintillaConstants.SCE_UDL_SSL_OPERATOR

    def is_comment(self, tok):
        return tok['style'] in (ScintillaConstants.SCE_UDL_SSL_COMMENT,
                                ScintillaConstants.SCE_UDL_SSL_COMMENTBLOCK)

    def is_comment_structured(self, tok, callback):
        return self.is_comment(tok) and callback and callback(tok)

    def is_identifier(self, tok, allow_keywords=False):
        return (tok['style'] == ScintillaConstants.SCE_UDL_SSL_IDENTIFIER or
               (allow_keywords and
                tok['style'] == ScintillaConstants.SCE_UDL_SSL_WORD))

    def is_index_op(self, tok, pattern=None):
        if tok['style'] != ScintillaConstants.SCE_UDL_SSL_OPERATOR:
            return False
        elif not pattern:
            return True
        return len(tok['text']) > 0 and pattern.search(tok['text'])

    # Everything gets lexed as a string, so we need to look at its structure.
    # We call back to the main CILE parser, which knows more about which kinds
    # of strings can interpolate other values.  This routine assumes all regexes
    # can interpolate.

    def is_interpolating_string(self, tok, callback):
        if tok['style'] == ScintillaConstants.SCE_UDL_SSL_REGEX:
            return callback(tok, GENERIC_TYPE_REGEX)
        elif not self.is_string(tok):
            return False
        else:
            return callback(tok, GENERIC_TYPE_STRING)

    def is_keyword(self, tok, target):
        return tok['style'] == ScintillaConstants.SCE_UDL_SSL_WORD and tok['text'] == target

    def is_number(self, tok):
        return tok['style'] == ScintillaConstants.SCE_UDL_SSL_NUMBER

    def is_operator(self, tok, target):
        return tok['style'] == ScintillaConstants.SCE_UDL_SSL_OPERATOR and tok['text'] == target

    def is_string(self, tok):
        return tok['style'] == ScintillaConstants.SCE_UDL_SSL_STRING

    def is_string_qw(self, tok, callback=None):
        return (tok['style'] == ScintillaConstants.SCE_UDL_SSL_STRING and
                callback and callback(tok))

    def is_symbol(self, tok, callback=None):
        return (tok['style'] == ScintillaConstants.SCE_UDL_SSL_STRING and
                callback and callback(tok))

    def is_variable(self, tok):
        return tok['style'] in (ScintillaConstants.SCE_UDL_SSL_VARIABLE,
                                ScintillaConstants.SCE_UDL_SSL_IDENTIFIER)

    # Types of variables
    def is_variable_array(self, tok, callback=None):
        if not self.is_variable(tok):
            return False
        else:
            return callback and callback(tok)

    def is_variable_scalar(self, tok, callback=None):
        if not self.is_variable(tok):
            return False
        else:
            return callback and callback(tok)

    def tokenStyleToContainerStyle(self, tok, callback):
        return callback(tok, tok['style'] == ScintillaConstants.SCE_UDL_SSL_VARIABLE)

    # Accessors for where we'd rather work with a style than call a predicate
    # fn

    @property
    def style_identifier(self):
        return ScintillaConstants.SCE_UDL_SSL_IDENTIFIER

    @property
    def style_operator(self):
        return ScintillaConstants.SCE_UDL_SSL_OPERATOR

    @property
    def style_word(self):
        return ScintillaConstants.SCE_UDL_SSL_WORD

########NEW FILE########
__FILENAME__ = tclcile
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
    tclcile - a Code Intelligence Language Engine for the Tcl language

    Module Usage:
        from tclcile import scan_purelang
        content = open("foo.tcl", "r").read()
        scan_purelang(content, "foo.tcl")

    Command-line Usage:
        tclcile.py [<options>...] [<Tcl files>...]

    Options:
        -h, --help          dump this help and exit
        -V, --version       dump this script's version and exit
        -v, --verbose       verbose output, use twice for more verbose output
        -f, --filename <path>   specify the filename of the file content
                            passed in on stdin, this is used for the "path"
                            attribute of the emitted <file> tag.
        --md5=<string>      md5 hash for the input
        --mtime=<secs>      modification time for output info, in #secs since
                            1/1/70.
        -L, --language <name>
                            the language of the file being scanned
        -c, --clock         print timing info for scans (CIX is not printed)

    One or more Tcl files can be specified as arguments or content can be
    passed in on stdin. A directory can also be specified, in which case
    all .rb files in that directory are scanned.

    This is a Language Engine for the Code Intelligence (codeintel) system.
    Code Intelligence XML format. See:
        http://specs.tl.activestate.com/kd/kd-0100.html

    The command-line interface will return non-zero iff the scan failed.
"""

import os
from os.path import basename, splitext, isfile, isdir, join
import sys
import getopt
from hashlib import md5
import re
import logging
import glob
import time
import stat

from ciElementTree import Element, SubElement, tostring
from SilverCity import ScintillaConstants

from codeintel2 import tcl_lexer, tcl_parser
from codeintel2.common import CILEError
from codeintel2 import parser_cix


#---- exceptions

class TclCILEError(CILEError):
    pass


#---- global data

_version_ = (0, 1, 0)
log = logging.getLogger("tclcile")
# log.setLevel(logging.DEBUG)

_gClockIt = 0   # if true then we are gathering timing data
_gClock = None  # if gathering timing data this is set to time retrieval fn
_gStartTime = None   # start time of current file being scanned


def scan_purelang(content, filename):
    content = content.expandtabs(8)
    tokenizer = tcl_lexer.TclLexer(content)
    parser = tcl_parser.Parser(tokenizer, "Tcl")
    parse_tree = parser.parse()
    # XXX Change last arg from "Tcl" to "tclcile"?
    tree = parser_cix.produce_elementTree_cix(parse_tree, filename, "Tcl",
                                              "Tcl")
    return tree


def scan_multilang(tokens, module_elem):
    """Build the Tcl module CIX element tree.

        "tokens" is a generator of UDL tokens for this UDL-based
            multi-lang document.
        "module_elem" is the <module> element of a CIX element tree on
            which the Tcl module should be built.

    This should return a list of the CSL tokens in the token stream.
    """
    tokenizer = tcl_lexer.TclMultiLangLexer(tokens)
    parser = tcl_parser.Parser(tokenizer, "AOL")  # TODO: What is AOL here?
    parse_tree = parser.parse()
    parser_cix.produce_elementTree_contents_cix(parse_tree, module_elem)
    csl_tokens = tokenizer.get_csl_tokens()
    return csl_tokens


#---- mainline

def main(argv):
    logging.basicConfig()
    # Parse options.
    try:
        opts, args = getopt.getopt(argv[1:], "Vvhf:cL:",
                                   ["version", "verbose", "help", "filename=", "md5=", "mtime=",
                                    "clock", "language="])
    except getopt.GetoptError, ex:
        log.error(str(ex))
        log.error("Try `tclcile --help'.")
        return 1
    numVerboses = 0
    stdinFilename = None
    md5sum = None
    mtime = None
    lang = "Tcl"
    global _gClockIt
    for opt, optarg in opts:
        if opt in ("-h", "--help"):
            sys.stdout.write(__doc__)
            return
        elif opt in ("-V", "--version"):
            ver = '.'.join([str(part) for part in _version_])
            print "tclcile %s" % ver
            return
        elif opt in ("-v", "--verbose"):
            numVerboses += 1
            if numVerboses == 1:
                log.setLevel(logging.INFO)
            else:
                log.setLevel(logging.DEBUG)
        elif opt in ("-f", "--filename"):
            stdinFilename = optarg
        elif opt in ("-L", "--language"):
            lang = optarg
        elif opt in ("--md5",):
            md5sum = optarg
        elif opt in ("--mtime",):
            mtime = optarg
        elif opt in ("-c", "--clock"):
            _gClockIt = 1
            global _gClock
            if sys.platform.startswith("win"):
                _gClock = time.clock
            else:
                _gClock = time.time

    if len(args) == 0:
        contentOnStdin = 1
        filenames = [stdinFilename or "<stdin>"]
    else:
        contentOnStdin = 0
        paths = []
        for arg in args:
            paths += glob.glob(arg)
        filenames = []
        for path in paths:
            if isfile(path):
                filenames.append(path)
            elif isdir(path):
                rbfiles = [join(path, n) for n in os.listdir(path)
                           if splitext(n)[1] == ".rb"]
                rbfiles = [f for f in rbfiles if isfile(f)]
                filenames += rbfiles

    try:
        for filename in filenames:
            if contentOnStdin:
                log.debug("reading content from stdin")
                content = sys.stdin.read()
                log.debug("finished reading content from stdin")
                if mtime is None:
                    mtime = int(time.time())
            else:
                if mtime is None:
                    mtime = int(os.stat(filename)[stat.ST_MTIME])
                content = open(filename, 'r').read()

            if _gClockIt:
                sys.stdout.write("scanning '%s'..." % filename)
                global _gStartTime
                _gStartTime = _gClock()
            data = tostring(scan_purelang(content, filename))
            if _gClockIt:
                sys.stdout.write(" %.3fs\n" % (_gClock()-_gStartTime))
            elif data:
                sys.stdout.write(data)
    except KeyboardInterrupt:
        log.debug("user abort")
        return 1
    if 0:  # except Exception, ex:
        log.error(str(ex))
        if log.isEnabledFor(logging.DEBUG):
            print
            import traceback
            traceback.print_exception(*sys.exc_info())
        return 1

if __name__ == "__main__":
    sys.exit(main(sys.argv))

########NEW FILE########
__FILENAME__ = tcl_lexer
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
Tcl lexing support for codeintel/tclcile.py

Get all the lexed tokens from SilverCity, and then return them
on demand to the caller (usually a Tcl pseudo-parser).

Usage:
import tcl_lexer
lexer = lex_wrapper.Lexer(code)
while 1:
    tok = lexer.get_next_token()
    if tok[0] == EOF_STYLE:
        break;
    # tok is an array of (style, text, start-col, start-line, end-col, end-line)
    # column and line numbers are all zero-based.
"""

import copy
import re
import sys
import string

import SilverCity
from SilverCity import ScintillaConstants
import shared_lexer
from shared_lexer import EOF_STYLE

from codeintel2 import lang_tcl


class TclLexerClassifier:
    """ This classifier is similar to the parser-level classifier, but
    it works on the SilverCity "raw" tokens as opposed to the
    tokens that get created by the lexer layer.  There should be some
    folding though."""

    def is_comment(self, ttype):
        return ttype == ScintillaConstants.SCE_TCL_COMMENT

    @property
    def style_comment(self):
        return ScintillaConstants.SCE_TCL_COMMENT

    @property
    def style_default(self):
        return ScintillaConstants.SCE_TCL_DEFAULT

    @property
    def style_operator(self):
        return ScintillaConstants.SCE_TCL_OPERATOR

#---- global data

op_re = re.compile(r'([\\\{\}\[\]])')


class TclLexer(shared_lexer.Lexer):
    def __init__(self, code):
        shared_lexer.Lexer.__init__(self)
        self.q = []
        self.classifier = TclLexerClassifier()
        lang_tcl.TclLexer().tokenize_by_style(code, self._fix_token_list)
        self.prepare_token_list_for_use()
        self.string_types = [ScintillaConstants.SCE_TCL_STRING,
                             ScintillaConstants.SCE_TCL_CHARACTER,
                             ScintillaConstants.SCE_TCL_LITERAL
                             ]

    def _fix_token_list(self, **tok):
        """ Same as perl_lexer: split op tokens into separate
            recognizable operators.
        """
        if tok['start_column'] > shared_lexer.MAX_REASONABLE_LIMIT:
            return
        tval = tok['text']
        if tok['style'] == ScintillaConstants.SCE_TCL_OPERATOR and len(tval) > 1:
            # In Tcl rely on white-space to separate operators except for
            # braces, brackets, and backslashes
            new_tokens = [x for x in op_re.split(tval) if x]  # drop empties
            if len(new_tokens) == 1:
                self.complete_token_push(tok)
            else:
                col = tok['start_column']
                for stxt in new_tokens:
                    new_tok = copy.copy(tok)
                    new_tok['text'] = stxt
                    new_tok['start_column'] = col
                    new_tok['end_column'] = col + len(stxt) - 1
                    col = new_tok['end_column']
                    self.q.append(new_tok)
        else:
            self.complete_token_push(tok)


def provide_sample_code():
    return r"""# ----------------------------------------------------------------------------
#  Command Dialog::create
# ----------------------------------------------------------------------------
proc Dialog::create { path args } {
    global   tcl_platform
    variable _widget

    array set maps [list Dialog {} .bbox {}]
    array set maps [Widget::parseArgs Dialog $args]

    # Check to see if the -class flag was specified
    set dialogClass "Dialog"
    array set dialogArgs $maps(Dialog)
    if { [info exists dialogArgs(-class)] } {
	set dialogClass $dialogArgs(-class)
    }

    puts "Test a long string" ; # proper comment
    puts "bogus comment follows -- no ;" # proper comment
}

"""


if __name__ == "__main__":
    shared_lexer.main(sys.argv, provide_sample_code, TclLexer)

########NEW FILE########
__FILENAME__ = tcl_parser
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****
#
# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""Tcl parsing support for codeintel/tclcile.py"""

import string
import sys
import re
import textwrap
import logging

log = logging.getLogger("tcl_parser")

from SilverCity import ScintillaConstants
from codeintel2 import tcl_lexer
from codeintel2 import shared_lexer
from codeintel2 import shared_parser
from codeintel2.parser_data import Name_LineNum, VarInfo, Node, ClassNode, \
    FileNode, ArgNode, MethodNode, ModuleNode, VariableNode, BlockNode, \
    update_collection
from codeintel2.parser_data import VAR_KIND_GLOBAL, VAR_KIND_LOCAL


class TclClassifier(shared_parser.CommonClassifier):
    _quote_patterns = {ScintillaConstants.SCE_TCL_STRING: re.compile(
        '^\"(.*)\"$'),
        ScintillaConstants.SCE_TCL_DEFAULT: re.compile('^.(.*).$'),
    }

    def get_builtin_type(self, tok, callback):
        if self.is_number(tok):
            numval = tok['text']
            if numval.find(".") >= 0:
                return "Float"
            else:
                return "Fixnum"
        elif self.is_string(tok):
            return "String"
        return None

    def is_any_operator(self, tok):
        return tok['style'] == ScintillaConstants.SCE_TCL_OPERATOR

    def is_comment(self, tok):
        return tok['style'] == ScintillaConstants.SCE_TCL_COMMENT

    def is_comment_structured(self, tok, callback):
        return False

    def is_identifier(self, tok, allow_keywords=False):
        return (tok['style'] == ScintillaConstants.SCE_TCL_IDENTIFIER or
               (allow_keywords and
                tok['style'] == ScintillaConstants.SCE_TCL_WORD))

    def is_interpolating_string(self, tok, callback):
        return tok['style'] == ScintillaConstants.SCE_TCL_STRING

    def is_keyword(self, tok, target):
        return tok['style'] == ScintillaConstants.SCE_TCL_WORD and tok['text'] == target

    def is_number(self, tok):
        return tok['style'] == ScintillaConstants.SCE_TCL_NUMBER

    def is_operator(self, tok, target):
        return tok['style'] == ScintillaConstants.SCE_TCL_OPERATOR and tok['text'] == target

    def is_string(self, tok):
        return tok['style'] in [ScintillaConstants.SCE_TCL_STRING,
                                ScintillaConstants.SCE_TCL_CHARACTER,
                                ScintillaConstants.SCE_TCL_LITERAL
                                ]

    def is_symbol(self, tok):
        return False

    def quote_patterns_cb(self, tok):
        tval = tok['text']
        if tval[0] == '"':
            return self._quote_patterns[ScintillaConstants.SCE_TCL_STRING]
        elif tval[0] == '\'':
            return self._quote_patterns[ScintillaConstants.SCE_TCL_CHARACTER]
        else:
            return self._quote_patterns[ScintillaConstants.SCE_TCL_DEFAULT]  # Fallback

    # Accessors for where we'd rather work with a style than call a predicate
    # fn

    @property
    def style_identifier(self):
        return ScintillaConstants.SCE_TCL_IDENTIFIER

    @property
    def style_operator(self):
        return ScintillaConstants.SCE_TCL_OPERATOR

    @property
    def style_word(self):
        return ScintillaConstants.SCE_TCL_WORD

lang_specific_classes = {"Tcl": TclClassifier,
                         "AOL": shared_parser.UDLClassifier}

leading_hash_re = re.compile(r'^\s*\#+\s*')
mostly_dashes = re.compile(r'\s*-{10}')
spaces_and_braces_re = re.compile(r'\s*\}\s*$')


def remove_hashes(lines):
    len1 = len(lines)
    if len1 == 0:
        return []
    set1 = [leading_hash_re.sub("", s) for s in lines]
    if len1 > 0 and mostly_dashes.match(set1[0]):
        del set1[0]
    if len1 > 1 and mostly_dashes.match(set1[-1]):
        del set1[-1]
    return set1

# Parse Tcl code


class Parser:
    def __init__(self, tokenizer, lang):
        self.tokenizer = tokenizer
        self.block_stack = []
        self.tree = FileNode()
        self.curr_node = self.tree
        self.classifier = lang_specific_classes[lang]()
        self.containers = {VAR_KIND_GLOBAL: [self.tree.global_vars],
                           VAR_KIND_LOCAL: [self.tree.local_vars]}  # locals

    def _get_fully_qualified_braced_name(self, start_line, start_column):
        brace_count = 1
        name_parts = []
        while 1:
            tok = self.tokenizer.get_next_token(skip_ws=0)
            if tok['style'] == shared_lexer.EOF_STYLE:
                break
            elif self.classifier.is_any_operator(tok):
                if tok['text'] == "{":
                    brace_count += 1
                elif tok['text'] == "}":
                    brace_count -= 1
                    if brace_count == 0:
                        break
            if tok['start_line'] > start_line or tok['start_column'] > start_column:
                name_parts.append(" ")
            start_column = tok['end_column'] + 1
            start_line = tok['start_line']
            name_parts.append(tok['text'])  # XXX backslashes?
        return "".join(name_parts)

    def get_fully_qualified_name(self):
        tok = self.tokenizer.get_next_token()
        if tok['style'] == shared_lexer.EOF_STYLE:
            return (None, None)
        line_start = tok['start_line']
        if self.classifier.is_operator(tok, "{"):
            return (self._get_fully_qualified_braced_name(line_start, tok['end_column'] + 1), line_start)
        name_start = tok['text']
        # Watch out if it starts with a "::"
        if name_start == "::":
            col = tok['end_column'] + 1
            tok = self.tokenizer.get_next_token()
            if tok['start_column'] != col or not self.classifier.is_identifier(tok):
                self.tokenizer.put_back(tok)
                return (name_start, line_start)
            name_start += tok['text']

        col = tok['end_column'] + 1
        while 1:
            # Collect operator-type methods
            tok = self.tokenizer.get_next_token()
            if tok['start_column'] == col and self.classifier.is_operator(tok, "::"):
                name_start += tok['text']
                col += 2
            else:
                self.tokenizer.put_back(tok)
                break

            tok = self.tokenizer.get_next_token()
            if tok['start_column'] == col and self.classifier.is_identifier(tok, True):
                name_start += tok['text']
                col = tok['end_column'] + 1
            else:
                self.tokenizer.put_back(tok)
                break
        return (name_start, line_start)

    def parse(self):
        while self.parse_aux(self.tree):
            pass
        return self.tree

    def get_parsing_objects(self, kwd):
        return {
            "namespace": [ModuleNode, self.parse_aux],
            "proc": [MethodNode, self.parse_method]
        }.get(kwd, [None, None])

    def _parse_name_list(self):
        vars = []
        while True:
            tok = self.tokenizer.get_next_token()
            if tok['style'] == shared_lexer.EOF_STYLE or \
                    self.classifier.is_operator(tok, "}"):
                break
            if self.classifier.is_identifier(tok):
                vars.append(tok['text'])
        return vars

    def parse_method(self, curr_node):
        # Syntax: proc name { args } { body }
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, "{"):
            # Standard, keep going
            do_regular_args = True
        elif self.classifier.is_identifier(tok):
            # Assume it's the one arg
            if tok['text'] == "args":
                curr_node.add_arg(tok['text'], None, "varargs")
            else:
                curr_node.add_arg(tok['text'])
            curr_node.signature = "%s {%s}" % (curr_node.name, tok['text'])
            do_regular_args = False
        else:
            self.tokenizer.put_back(tok)
            return

        if do_regular_args:
            braceCount = 1
            init_indentation = curr_node.indentation
            tok_count = 0
            tok_lim = 1000
            self.tokenizer.start_sig()
            argStart = True
            while 1:
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_any_operator(tok):
                    argStart = False
                    tval = tok['text']
                    if tval == "{":
                        braceCount += 1
                        if braceCount == 2:
                            argStart = True
                    elif tval == "}":
                        braceCount -= 1
                        if braceCount <= 0:
                            break
                        elif braceCount == 1:
                            argStart = True
                elif argStart:
                    if braceCount == 2:  # Wait for a } to get next arg.
                        argStart = False
                    if self.classifier.is_identifier(tok, True):
                        if tok['text'] == "args" and braceCount == 1:
                            # We need to peek at the next token
                            tok2 = self.tokenizer.get_next_token()
                            if self.classifier.is_operator(tok2, "}"):
                                curr_node.add_arg(tok['text'], None, "varargs")
                                break
                            else:
                                self.tokenizer.put_back(tok2)
                        curr_node.add_arg(tok['text'])
                tok_count += 1
                if tok_count > tok_lim and tok['start_column'] < init_indentation:
                    break

            self.tokenizer.stop_sig()
            # XXX Check white-space in the sig
            # We don't know we've hit the end of the sig until we hit
            # that final "}", so we need to pull it out.
            curr_node.signature = "%s {%s}" % (curr_node.name,
                                               spaces_and_braces_re.sub('', self.tokenizer.get_sig()))

        # Now get the body
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, "{"):
            # Give up
            self.tokenizer.put_back(tok)
            return
        braceCount = 1
        self.parse_aux(curr_node, 1)  # Count the brace we just saw.
    # end parse_method

    def parse_assignment(self, tok_text, start_line, isLocal=True):
        # Don't bother trying to type it yet.
        # Figure out whether we're in a proc or not

        if isLocal:
            collectionA = self.containers[VAR_KIND_LOCAL]
        else:
            collectionA = self.containers[VAR_KIND_GLOBAL]

        if len(collectionA) == 0 or collectionA[-1] is None:
            return
        possibleType = self._finishVarAssignment(
            collectionA, tok_text, start_line)
        update_collection(collectionA[-1], tok_text, start_line, possibleType)

    def _finishVarAssignment(self, collectionA, var_name, start_line):
        # XXX Add type info
        return None

    def parse_aux(self, curr_node, braceCount=0):
        init_indentation = curr_node.indentation
        tok_count = 0
        tok_lim = 1000
        cmdStart = True
        curr_globals = {}
        while 1:
            tok = self.tokenizer.get_next_token()
            if tok['style'] == shared_lexer.EOF_STYLE:
                break
            # style, text, start_column, start_line, end_column, end_line = tok
            style, text = tok['style'], tok['text']
            if style == self.classifier.style_word and \
               (cmdStart or tok['start_column'] == self.tokenizer.get_curr_indentation()):
                cmdStart = False
                if text in ["namespace", "proc"]:
                    curr_indent = self.tokenizer.get_curr_indentation()
                    if text == "namespace":
                        tok1 = self.tokenizer.get_next_token()
                        if not (self.classifier.is_identifier(tok1, True) and tok1['text'] == "eval"):
                            continue
                    node_class, node_parser = self.get_parsing_objects(text)
                    if node_class is None:
                        sys.stderr.write(
                            "Couldn't get parsing objects for type %s\n" % text)
                        break

                    # Get the comments before further parsing.
                    comment_lines = remove_hashes(
                        self.tokenizer.curr_comment())
                    nm_token = self.get_fully_qualified_name()
                    fqname = nm_token[0]
                    if not fqname:
                        break
                    # Handle only local names for now
                    if fqname.startswith("::") and text == "namespace":
                            fqname = fqname[2:]

                    new_node = node_class(fqname, tok['start_line'])
                    new_node.doc_lines = comment_lines
                    new_node.indentation = curr_indent
                    self.block_stack.append(new_node)
                    curr_node.append_node(new_node)

                    # Push new containers on the symbol table
                    self.containers[VAR_KIND_LOCAL].append(new_node.local_vars)

                    node_parser(new_node)  # Has self bound to it
                    self.block_stack.pop()
                    self.containers[VAR_KIND_LOCAL].pop()

                    # Clear any comment that's hanging around
                    self.tokenizer.clear_comments()

                elif text == "package":
                    tok1 = self.tokenizer.get_next_token()
                    if self.classifier.is_identifier(tok1, True):
                        if tok1['text'] == "require":
                            tok2 = self.tokenizer.get_next_token()
                            if self.classifier.is_identifier(tok2, True) and tok2['text'] != "Tcl":
                                curr_node.imports.append(Name_LineNum(
                                    tok2['text'], tok['start_line']))
                elif text == "global":
                    # XXX: all tokens following 'global' should be declared
                    # vars
                    tok = self.tokenizer.get_next_token()
                    if self.classifier.is_identifier(tok, True):
                        curr_globals[tok['text']] = None
                elif text == "set":
                    # XXX: Needs to handle lappend, append, incr, variable
                    # XXX: possibly dict set, array set, upvar, lassign,
                    # XXX: foreach, regsub (non-inline)
                    tok = self.tokenizer.get_next_token()
                    if self.classifier.is_identifier(tok, True):
                        if tok['text'] in curr_globals:
                            pass
                        else:
                            self.parse_assignment(tok['text'], tok[
                                                  'start_line'], isinstance(curr_node, MethodNode))
                elif text == "lassign":
                    tok = self.tokenizer.get_next_token()
                    if self.classifier.is_operator(tok, "{"):
                        start_line = tok['start_line']
                        isLocal = isinstance(curr_node, MethodNode)
                        if isLocal:
                            collectionA = self.containers[VAR_KIND_LOCAL]
                        else:
                            collectionA = self.containers[VAR_KIND_GLOBAL]
                        vars = self._parse_name_list()
                        for v in vars:
                            update_collection(collectionA[-1], v, start_line)
            elif self.classifier.is_any_operator(tok):
                cmdStart = False
                if text == "{":
                    braceCount += 1
                elif text == "}":
                    braceCount -= 1
                    if braceCount <= 0:
                        break
                elif text in (";", "["):
                    cmdStart = True
                elif text == "\\":
                    # Skip the next token, whatever it is - bug 74850
                    tok = self.tokenizer.get_next_token()
            else:
                cmdStart = False
            # Sanity check to make sure we haven't gone too far.
            tok_count += 1
            if tok_count > tok_lim and tok['start_column'] < init_indentation:
                break
        # end while
        curr_node.set_line_end_num(self.tokenizer.curr_line_no())
        return tok['style'] != shared_lexer.EOF_STYLE
    # end parse_aux()


# end class Parser

if __name__ == "__main__":
    if len(sys.argv) == 1:
        sample_code = tcl_lexer.provide_sample_code()
        fs = None
    elif sys.argv[1] == "-":
        fs = sys.stdin
        closefs = False
    else:
        fs = open(sys.argv[1], "r")
        closefs = True
    if fs is not None:
        sample_code = shared_lexer.read_and_detab(fs, closefs)
        # fs comes back closed
    tokenizer = tcl_lexer.TclLexer(sample_code)
    parser = Parser(tokenizer, "Tcl")
    tree = parser.parse()
    print "Analyze the parse tree"
    tree.dump()

########NEW FILE########
__FILENAME__ = tdparser
"""
A simple Top-Down Python expression parser.

This parser is based on the "Simple Top-Down Parsing in Python" article by
Fredrik Lundh (http://effbot.org/zone/simple-top-down-parsing.htm)

These materials could be useful for understanding ideas behind
the Top-Down approach:

 * Top Down Operator Precedence -- Douglas Crockford
   http://javascript.crockford.com/tdop/tdop.html

 * Top-Down operator precedence parsing -- Eli Benderski
   http://eli.thegreenplace.net/2010/01/02/top-down-operator-precedence-parsing/

 * Top down operator precedence -- Vaughan R. Pratt
   http://portal.acm.org/citation.cfm?doid=512927.512931

This implementation is a subject to change as it is very premature.
"""

import re
import cStringIO as sio
import tokenize


class ParseError(Exception):
    pass

type_map = {tokenize.NUMBER: "(literal)",
            tokenize.STRING: "(literal)",
            tokenize.OP: "(operator)",
            tokenize.NAME: "(name)"}


def gen_python_tokens(source):
    stream = tokenize.generate_tokens(sio.StringIO(source).readline)
    for token, value, begin, end in (t[:4] for t in stream):
        if token in type_map:
            yield type_map[token], value, begin, end
        elif token == tokenize.NEWLINE:
            continue
        elif token == tokenize.ENDMARKER:
            break
        else:
            raise ParseError("Syntax error at (%r) in text (%r) -- "
                             "unexpected token (%r)" % (value, source,
                                                        tokenize.tok_name[token]))
    yield "(end)", "(end)", None, None


class Symbol(object):
    id = None
    value = None
    first = second = third = None

    def __init__(self, parser, begin, end):
        self.parser = parser
        self.begin = begin
        self.end = end

    def nud(self):
        raise ParseError("Syntax error (%r)" % self)

    def led(self, left):
        raise ParseError("Unknown operator (%r)" % self)

    def py(self):
        if self.id[0] != "(":
            return self.id
        else:
            return self.value

    def __repr__(self):
        if self.id in ("(name)", "(literal)"):
            return "(%s %s)" % (self.id[1:-1], self.value)
        children = (str(item) for item in (self.first, self.second, self.third)
                    if item is not None)
        out = " ".join((self.id,) + tuple(children))
        return "(" + out + ")"

    @property
    def token(self):
        return self.parser.token

    @token.setter
    def token(self, token):
        self.parser.token = token

    @property
    def next(self):
        return self.parser.next

    @property
    def expression(self):
        return self.parser.expression

    @property
    def advance(self):
        return self.parser.advance


class Parser(object):
    token = None
    next = None

    def __init__(self, grammar=None):
        self.grammar = grammar or self.grammar

    def symbol(self, id, bp=0):
        return self.grammar.symbol(d, bp)

    def expression(self, rbp=0):
        t = self.token
        self.token = self.next()
        left = t.nud()
        while rbp < self.token.lbp:
            t = self.token
            self.token = self.next()
            left = t.led(left)
        return left

    def advance(self, id=None):
        if id and self.token.id != id:
            raise ParseError("Expected '%r', got '%r'" % (id, self.token))
        self.token = self.next()

    def gen_python_symbols(self, source):
        for id, value, begin, end in gen_python_tokens(source):
            if id == "(literal)":
                symbol = self.grammar.get_symbol(id)
                inst = symbol(self, begin, end)
                inst.value = value
            else:
                symbol = self.grammar.get_symbol(value)
                if symbol:
                    inst = symbol(self, begin, end)
                elif id == "(name)":
                    symbol = self.grammar.get_symbol(id)
                    inst = symbol(self, begin, end)
                    inst.value = value
                else:
                    raise ParseError("Unknown operator (%r)" % id)
            yield inst

    def parse(self, source):
        self.next = self.gen_python_symbols(source).next
        self.token = self.next()
        result = self.expression()
        if self.token.id != "(end)":
            raise ParseError("Expected end, got '%r'" % self.token)
        return result


class Grammar(object):
    symbol_table = {}

    def __init__(self):
        class proto(Symbol):
            pass
        self.proto = proto

    def common(self, fn):
        setattr(self.proto, fn.__name__, fn)
        return fn

    def method(self, id, bp=0):
        sym = self.symbol(id, bp)
        assert issubclass(sym, Symbol)

        def bind(fn):
            setattr(sym, fn.__name__, fn)
        return bind

    def symbol(self, id, bp=0):
        if id in self.symbol_table:
            sym = self.symbol_table[id]
        else:
            # can this be done with partials?
            class sym(self.proto):
                pass
            sym.__name__ = "symbol-" + id
            sym.id = id
            sym.lbp = bp
            self.symbol_table[id] = sym
        sym.lbp = max(bp, sym.lbp)
        return sym

    def get_symbol(self, id):
        return self.symbol_table.get(id)

    def infix(self, id, bp):
        @self.method(id, bp)
        def led(self, left):
            self.first = left
            self.second = self.expression(bp)
            return self

        @self.method(id, bp)
        def py(self):
            return "%s %s %s" % (self.first.py(), self.id, self.second.py())

    def prefix(self, id, bp):
        @self.method(id, bp)
        def nud(self):
            self.first = self.expression(bp)
            self.second = None
            return self

        @self.method(id, bp)
        def py(self):
            return "%s%s" % (self.id, self.first.py())

    def infix_r(self, id, bp):
        @self.method(id, bp)
        def led(self, left):
            self.first = left
            self.second = self.expression(bp-1)
            return self

        @self.method(id, bp)
        def py(self):
            return "%s %s %s" % (self.first.py(), self.value, self.second.py())

    def constant(self, id):
        @self.method(id)
        def nud(self):
            self.id = "(literal)"
            self.value = id
            return self


def arg_list_py(args):
    buf = []
    for name, value, type in args:
        if value:
            buf.append("%s=%s" % (name.py(), value.py()))
        else:
            buf.append(name.py())
    return ", ".join(buf)


def call_list_py(args):
    buf = []
    for name, value in args:
        value_py = value and value.py() or ''
        if name:
            if name.id in ("*", "**"):
                arg = name.id + value.py()
            else:
                arg = "%s=%s" % (name.id, value_py)
        else:
            arg = value_py
        buf.append(arg)
    return ", ".join(buf)


def py_expr_grammar():
    self = Grammar()

    self.symbol("lambda", 20)
    self.symbol(":", 10)

    self.symbol("if", 20)
    self.symbol("else")

    self.infix_r("or", 30)
    self.infix_r("and", 40)
    self.prefix("not", 50)

    self.infix("in", 60)
    self.infix("not", 60)  # in, not in

    self.infix("is", 60)  # is, is not

    self.infix("<", 60)
    self.infix("<=", 60)
    self.infix(">", 60)
    self.infix(">=", 60)
    self.infix("<>", 60)
    self.infix("!=", 60)
    self.infix("==", 60)

    self.infix("|", 70)
    self.infix("^", 80)
    self.infix("&", 90)

    self.infix("<<", 100)
    self.infix(">>", 100)

    self.infix("+", 110)
    self.infix("-", 110)

    self.infix("*", 120)
    self.infix("/", 120)
    self.infix("//", 120)
    self.infix("%", 120)

    self.prefix("-", 130)
    self.prefix("+", 130)
    self.prefix("~", 130)

    self.infix_r("**", 140)

    self.symbol(".", 150)

    self.symbol("[", 150)
    self.symbol("]")

    self.symbol("(", 150)
    self.symbol(")")
    self.symbol(",")
    self.symbol("=")

    self.symbol("{", 150)
    self.symbol("}")

    self.symbol("(literal)").nud = lambda self: self
    self.symbol("(name)").nud = lambda self: self
    self.symbol("(end)")

    self.constant("None")
    self.constant("True")
    self.constant("False")

    @self.method("*")
    def py(self):
        if self.first:
            return "%s %s %s" % (self.first.py(), self.id, self.second.py())
        else:
            return self.value

    @self.method("**")
    def py(self):
        if self.first:
            return "%s %s %s" % (self.first.py(), self.id, self.second.py())
        else:
            return self.value

    @self.method("(")
    def nud(self):
        self.first = []
        comma = False
        if self.token.id != ")":
            while 1:
                if self.token.id == ")":
                    break
                self.first.append(self.expression())
                if self.token.id == ",":
                    comma = True
                    self.advance(",")
                else:
                    break
        self.advance(")")
        if not self.first or comma:
            return self  # tuple
        else:
            return self.first[0]

    @self.method("(")
    def led(self, left):
        self.first = left
        self.second = []
        if self.token.id != ")":
            while 1:
                name = None
                if self.token.id in ('*', '**'):
                    name = self.token
                    self.advance(self.token.id)
                    value = self.expression()
                else:
                    t = self.expression()
                    if self.token.id == "=":
                        if t.id != "(name)":
                            raise ParseError("Expected a name, got '%r'" % arg)
                        self.advance("=")
                        name = t
                        value = self.expression()
                    else:
                        value = t

                self.second.append((name, value))
                if self.token.id != ",":
                    break
                self.advance(",")
        self.advance(")")
        self.id = "(call)"
        return self

    @self.method("(")
    def py(self):
        if self.second:
            return "%s(%s)" % (self.first.py(), call_list_py(self.second))
        else:
            return "(%s)" % ", ".join(i.py() for i in self.first)

    @self.method("if")
    def led(self, left):
        self.first = left
        self.second = self.expression()
        self.advance("else")
        self.third = self.expression()
        return self

    @self.method("if")
    def py(self):
        return "%s if %s else %s" % (self.first.py(),
                                     self.second.py(),
                                     self.third.py())

    @self.method(".")
    def led(self, left):
        if self.token.id != "(name)":
            ParseError("Expected an attribute name, got '%r'" % self.token)
        self.first = left
        self.second = self.token
        self.advance()
        return self

    @self.method(".")
    def py(self):
        return "%s.%s" % (self.first.py(), self.second.py())

    @self.method("[")
    def nud(self):
        self.first = []
        while self.token.id != "]":
            self.first.append(self.expression())
            if self.token.id == ",":
                self.advance(",")
            else:
                break
        self.advance("]")
        return self

    @self.method("[")
    def led(self, left):
        self.id = "(index)"
        self.first = left
        self.second = self.expression()
        self.advance("]")
        return self

    @self.method("[")
    def py(self):
        if self.second:
            return "%s[%s]" % (self.first,
                               ", ".join(i.py() for i in self.second))
        else:
            return "[%s]" % ", ".join(i.py() for i in self.first)

    @self.method("{")
    def nud(self):
        self.first = []
        while self.token.id != "}":
            self.first.append(self.expression())
            self.advance(":")
            self.first.append(self.expression())
            if self.token.id == ",":
                self.advance(",")
            else:
                break
        self.advance("}")
        return self

    @self.method("{")
    def py(self):
        return "{%s}" % (", ".join("%s: %s" % (i[0].py(), i[1].py())
                                   for i in self.first))

    @self.method("lambda")
    def nud(self):
        if self.token.id != ":":
            self.first = self.argument_list(in_lambda=True)
        else:
            self.first = []
        self.advance(":")
        self.second = self.expression()
        return self

    @self.method("lambda")
    def py(self):
        return "lambda %s: %s" % (arg_list_py(self.first), self.second.py())

    @self.method("not")
    def led(self, left):
        if self.token.id != "in":
            raise ParseError("Expected 'in', got '%r'" % self.token)
        self.advance()
        self.id = "not in"
        self.first = left
        self.second = self.expression(60)
        return self

    @self.method("is")
    def led(self, left):
        if self.token.id == "not":
            self.advance()
            self.id = "is not"
        self.first = left
        self.second = self.expression(60)
        return self

    @self.common
    def advance_name(self):
        if self.token.id != "(name)":
            ParseError("Expected an argument name, got '%r'" % self.token)
        t = self.token
        self.advance()
        return t

    @self.common
    def argument_list(self, in_lambda=False):
        arglist = []
        while 1:
            val = None
            type = None
            check_annotation = False
            check_default_value = False
            if self.token.id == "*":
                arg = self.token
                self.advance("*")
                if self.token.id == ",":
                    arg.value = "*"
                else:
                    arg = self.advance_name()
                    arg.value = "*" + arg.value
                    check_annotation = True
            elif self.token.id == "**":
                self.advance("**")
                arg = self.advance_name()
                arg.value = "**" + arg.value
                check_annotation = True
            else:
                arg = self.advance_name()
                check_annotation = True
                check_default_value = True

            if check_default_value and self.token.id == "=":
                self.advance("=")
                val = self.expression()
                check_default_value = False

            if not in_lambda:
                if check_annotation and self.token.id == ":":
                    self.advance(":")
                    type = self.expression()
                    if check_default_value and self.token.id == "=":
                        self.advance("=")
                        val = self.expression()

            if self.token.id == "->":
                self.advance("->")
                self.expression()

            arglist.append((arg, val, type))

            if self.token.id == ",":
                self.advance(",")
            else:
                break
        return arglist

    return self


class PyExprParser(Parser):
    grammar = py_expr_grammar()

    def parse_bare_arglist(self, source):
        self.next = self.gen_python_symbols(source.strip()).next
        self.token = self.next()
        arglist = self.token.argument_list()
        if self.token.id != "(end)":
            raise ParseError("Expected end, got '%r'" % self.token)
        return arglist


if __name__ == '__main__':
    import sys
    if len(sys.argv) < 2:
        print "Usage: tdparser.py filename"
    parser = PyExprParser()
    res = parser.parse_bare_arglist(file(sys.argv[1]).read())
    print res

########NEW FILE########
__FILENAME__ = tree
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""New citree-based codeintel evaluation engine.

A 'citree' is basically an ElementTree of a CIX document with some tweaks.
The idea is to use these for completion/calltip evaluation instead of the
CIDB. This is mainly about performance but also about fixing some
limitations, bugs, and having a better code design (i.e. where lang-specific
quirks can be dealt with cleanly).
"""

import sys
from os.path import normpath
import logging
import re

import ciElementTree as ET
if not getattr(ET, "_patched_for_komodo_", False):
    import warnings
    warnings.warn("Not using codeintel's patched elementtree: "
                  "this may cause problems")

from codeintel2.common import *
from codeintel2.citadel import CitadelEvaluator


log = logging.getLogger("codeintel.tree")

CIX_VERSION = "2.0"


def tree_2_0_from_tree_0_1(tree):
    """Convert CIX 0.1 to CIX 2.0."""
    # - update some of the no longer used <file> attributes
    #   - drop "generator"
    try:
        del tree[0].attrib["generator"]
    except KeyError:
        pass
    #   - drop 'md5' and 'mtime' on the <file> tag
    try:
        del tree[0].attrib["md5"]
    except KeyError:
        pass
    try:
        del tree[0].attrib["mtime"]
    except KeyError:
        pass
    #   - move "language" attribute on <file> to "lang" and to "lang" on
    #     <module> (New multi-lang CIX output will allow one file to
    #     have modules of different langs.)
    for file in tree.getiterator("file"):
        lang = file.get("language")
        if lang is not None:
            file.set("lang", lang)
            for module in file.getiterator("module"):
                if module.get("lang") is None:
                    module.set("lang", lang)
            try:
                del file.attrib["language"]
            except KeyError:
                # Be tolerant of transitional CIX.
                pass

    # - move <doc> and <signature> optional sub tags into parent
    #   attribute
    # PERF: This could be done better.
    for tag in ("variable", "function", "class", "module", "interface",
                "argument", "classref", "interfaceref"):
        for node in tree.getiterator(tag):
            for child in reversed(node):
                # reversed() so can modify while iterating over
                if child.tag == "signature":
                    if child.text:  # be tolerant of <signature />
                        node.set("signature", child.text)
                    node.remove(child)
                elif child.tag == "doc":
                    if child.text:  # be tolerant of <doc />
                        node.set("doc", child.text)
                    node.remove(child)
            if not node:  # no children now
                node.text = None

    # - move non-variable tags to attributes
    #   (XXX currently <classref> and <interfaceref> tags are not moved)
    for tag in ("variable", "argument", "classref", "interfaceref"):
        for node in tree.getiterator(tag):
            for child in reversed(node):
                if child.tag == "type":
                    node.set("citdl", child.get("type"))
                    node.remove(child)
            if not node:  # no remaining children
                node.text = None
            if tag == "argument":
                node.tag = "variable"
                node.set("ilk", "argument")

    # - move <returns> to a <function> attribute
    for node in tree.getiterator("function"):
        for child in reversed(node):  # PERF: could just check last child
            if child.tag == "returns":
                assert child[0].tag == "type"
                node.set("returns", child[0].get("type"))
                node.remove(child)

    # - move classrefs and interfacerefs to attributes
    #   Note: <classref attribute="__mixin__"> => "mixinrefs" attribute.
    #   This is used by Ruby (though not used for eval, yet).
    for scope_ilk in ("class", "interface"):
        for node in tree.getiterator(scope_ilk):
            interfacerefs = []
            classrefs = []
            mixinrefs = []
            for child in reversed(node):
                if child.tag == "classref":
                    if "__mixin__" in child.get("attributes", ""):
                        mixinrefs.append(child.get("citdl")
                                         or child.attrib["name"])
                    else:
                        classrefs.append(child.get("citdl")
                                         or child.attrib["name"])
                    node.remove(child)
                elif child.tag == "interfaceref":
                    interfacerefs.append(child.get("citdl")
                                         or child.attrib["name"])
                    node.remove(child)
            if classrefs:
                classrefs.reverse()
                assert not [c for c in classrefs if ' ' in c]
                node.set("classrefs", ' '.join(classrefs))
            if interfacerefs:
                interfacerefs.reverse()
                assert not [i for i in interfacerefs if ' ' in i]
                node.set("interfacerefs", ' '.join(interfacerefs))
            if mixinrefs:
                mixinrefs.reverse()
                assert not [m for m in mixinrefs if ' ' in m]
                node.set("mixinrefs", ' '.join(mixinrefs))
            if len(node) == 0:
                node.text = None

    # - make all scope tags a "scope" tag (easier for elem.find() usage)
    for tag in ("class", "function", "interface", "module"):
        for node in tree.getiterator(tag):
            node.tag = "scope"
            if tag == "class" and "__namespace__" in node.get("attributes", ""):
                node.set("ilk", "namespace")
                attributes = node.get("attributes").split()
                attributes.remove("__namespace__")
                if not attributes:
                    del node.attrib["attributes"]
                else:
                    node.set("attributes", ' '.join(attributes))
            elif tag == "module":
                node.set("ilk", "blob")
            else:
                node.set("ilk", tag)

    tree.set("version", "2.0")
    return tree


def tree_from_cix_path(cix_path):
    """Return a (ci)tree for the CIX content in the given path.

    Raises pyexpat.ExpatError if the CIX content could not be parsed.
    """
    tree = ET.parse(cix_path).getroot()
    version = tree.get("version")
    if version == CIX_VERSION:
        return tree
    elif version == "0.1":
        return tree_2_0_from_tree_0_1(tree)
    else:
        raise CodeIntelError("unknown CIX version: %r" % version)


def tree_from_cix(cix):
    """Return a (ci)tree for the given CIX content.

    Raises pyexpat.ExpatError if the CIX content could not be parsed.
    """
    if isinstance(cix, unicode):
        cix = cix.encode("UTF-8", "xmlcharrefreplace")
    tree = ET.XML(cix)
    version = tree.get("version")
    if version == CIX_VERSION:
        return tree
    elif version == "0.1":
        return tree_2_0_from_tree_0_1(tree)
    else:
        raise CodeIntelError("unknown CIX version: %r" % version)


def pretty_tree_from_tree(tree, indent_width=2):
    """Add appropriate .tail and .text values to the given tree so that
    it will have a pretty serialization.

    Note: This modifies the tree *in-place*.
    Presumption: This is a CIX 2.0 tree.
    """
    INDENT = ' '*indent_width

    def _prettify(elem, indent_level=0):
        if elem:  # i.e. has children
            elem.text = '\n' + INDENT*(indent_level+1)
            for child in elem:
                _prettify(child, indent_level+1)
            elem[-1].tail = '\n' + INDENT*indent_level
            elem.tail = '\n' + INDENT*indent_level
        else:
            elem.text = None
            elem.tail = '\n' + INDENT*indent_level

    _prettify(tree)
    return tree


def check_tree(tree):
    """Generate warnings/errors for common mistakes in CIX trees.

    Yields tuples of the form:
        ("warning|error", <msg>)
    """
    assert tree.tag == "codeintel",\
        "can only check starting from <codeintel> element"
    assert tree.get("version") == CIX_VERSION, \
        "can only check CIX v%s trees" % CIX_VERSION

    # - file 'lang' is set, not 'language'
    file = tree[0]
    if not file.get("lang"):
        yield ("error", "no 'lang' attr on <file> element")
    if file.get("language"):
        yield ("warning", "'language' attr on <file> element is obsolete,"
                          "use 'lang'")

    for blob in file:
        if blob.get("ilk") != "blob":
            yield ("error", "element under <file> is not ilk=blob: %r" % blob)
        # - blob 'lang' is set
        if not blob.get("lang"):
            yield ("error", "no 'lang' attr on <blob> element: %r" % blob)

        # - classrefs are space separated, not with commas (warn)
        for class_elem in blob.getiterator("scope"):
            if class_elem.get("ilk") != "class":
                continue
            classrefs = class_elem.get("classrefs")
            if not classrefs:
                continue
            if ',' in classrefs:
                yield ("warning", "multiple class references in 'classrefs' "
                                  "attr on class scopes must be "
                                  "space-separated: %r may be using "
                                  "comma-separation: %r"
                                  % (class_elem, classrefs))


class TreeEvaluator(CitadelEvaluator):
    def get_start_scoperef(self):
        linenum = self.line + 1  # convert to 1-based
        try:
            blob = self.buf.blob_from_lang[self.trg.lang]
        except KeyError:
            raise EvalError("no %s scan info for %r" % (self.lang, self.buf))
        return self.buf.scoperef_from_blob_and_line(blob, linenum)

    def eval(self, mgr):
        self.mgr = mgr
        self.citadel = mgr.citadel

        if self.ctlr.is_aborted():
            self.ctlr.done("aborting")
            return
        self.ctlr.info("eval %s  %s", self, self.trg)

        self.pre_eval()

        try:
            if self.trg.form == TRG_FORM_CPLN:
                cplns = self.eval_cplns()
                if cplns:
                    cplns = self.post_process_cplns(cplns)
                self.info("    cplns: %r", cplns)
                if cplns:
                    self.ctlr.set_cplns(cplns)
            elif self.trg.form == TRG_FORM_CALLTIP:
                calltips = self.eval_calltips()
                if calltips:
                    calltips = self.post_process_calltips(calltips)
                self.info("    calltips: %r", calltips)
                if calltips:
                    self.ctlr.set_calltips(calltips)
            else:  # self.trg.form == TRG_FORM_DEFN
                defns = self.eval_defns()
                if defns:
                    defns = Definition.unique_definitions(defns)
                    defns = self.post_process_defns(defns)
                self.info("    defns: %r", defns)
                if defns:
                    self.ctlr.set_defns(defns)
            self.ctlr.done("success")
        except CodeIntelError, ex:
            # XXX Should we have an error handling hook here?
            self.ctlr.error("evaluating %s: %s", self, ex)
            self.ctlr.done("eval error")
        except Exception:
            log.exception("Unexpected error with evaluator: %s", self)
            # Must still mark done on the ctlr to avoid leaks - bug 65502.
            self.ctlr.done("eval error")

    def scope_stack_from_tree_and_linenum(self, tree, linenum):
        """Get the start scope for the given line.

            "linenum" appears to be 0-based, however all CIX line data
                is 1-based so we'll convert here.

        Dev Notes:
        - XXX Add built-in scope.
        """
        linenum += 1  # convert to 1-based
        # XXX This is presuming that the tree has only one blob.
        scope_stack = [tree.find("file/scope")]
        while True:
            next_scope_could_be = None
            # PERF: Could make this a binary search if a scope has *lots* of
            # subscopes.
            for scope in scope_stack[-1].findall("scope"):
                start = int(scope.get("line"))
                if start <= linenum \
                   and (not scope.get("lineend")
                        or linenum <= int(scope.get("lineend"))):
                    next_scope_could_be = scope
                elif start > linenum:
                    break
            if next_scope_could_be is not None:
                scope_stack.append(next_scope_could_be)
            else:
                break
        return scope_stack

    # TODO: split out '()' as a separate token.
    def _tokenize_citdl_expr(self, citdl):
        for token in citdl.split('.'):
            yield token

    def _join_citdl_expr(self, tokens):
        return '.'.join(tokens)

    def str_elem(self, elem):
        if elem.tag == "scope":
            return "%s %s" % (elem.get("ilk"), elem.get("name"))
        else:
            return "%s %s" % (elem.tag, elem.get("name"))

    def str_elem_and_children(self, elem):
        s = [self.str_elem(elem)]
        for child in elem:
            s.append(self.str_elem(child))
        return "%s: %s" % (self.str_elem(elem),
                           ', '.join(self.str_elem(c) for c in elem))

    def str_import(self, elem):
        # c.f. cb.py::getDescForImport()
        module = elem.get("module")
        symbol = elem.get("symbol")
        alias = elem.get("alias")
        if alias and symbol:
            s = "from %(module)s import %(symbol)s as %(alias)s" % locals()
        elif alias:
            s = "import %(module)s as %(alias)s" % locals()
        elif symbol:
            s = "from %(module)s import %(symbol)s" % locals()
        else:
            s = "import %(module)s" % locals()
        return s

    # logging funcs (perhaps best on controller)
    def log_start(self):
        self._log = []

    def log(self, msg, *args, **kwargs):
        """
            kwargs:
                "cached" (boolean) indicates if result was from cache
        """
        log_indent = ' '*4
        if True:    # just print as we go
            if args:
                s = [msg % args]
            else:
                s = [msg]
            if kwargs.get("cached"):
                s.append(" (cached)")
            self.info('%s', ''.join(s))
        else:       # capture log for latter printing
            self._log.append(msg, args, kwargs)

    def pre_eval(self):
        self.curr_tree = self.buf.tree
        # ET.dump(self.curr_tree)

    def _eval_citdl_expr(self, expr, scope_stack):
        """Return the citree node for the given CITDL expression.

            os.environ.get() -> <class 'str' on stdlib blob 'built-in'>
        """
        tokens = list(self._tokenize_citdl_expr(expr))
        assert tokens, "have to adjust handling if no tokens"
        obj = self._eval_citdl_token(tokens[0], scope_stack)

        for i, token in enumerate(tokens[1:]):
            if token.endswith("()"):
                token = token[-2:]
                call = True
            else:
                call = False

            if obj.tag == "import":
                obj = self._eval_import_getattr(obj, token,
                                                self._join_citdl_expr(tokens[:i+2]))
            else:
                # XXX marky: this code does not appear to be used!
                # (nobody seems to define _eval_getattr)
                obj = self._eval_getattr(obj, token,
                                         self._join_citdl_expr(tokens[:i+2]))

            if call:
                raise CodeIntelError("_eval_citdl_expr(%r): not handling "
                                     "call on %r "
                                     % (expr, self.str_elem(obj)))

        if obj.tag == "import":
            raise CodeIntelError("_eval_citdl_expr: cannot return import "
                                 "<%s>: need to resolve it"
                                 % self.str_import(obj))
        return obj

    def _resolve_import(self, module_name, symbol_name=None):
        """Return a loaded citree node for the given import info.

            "module_name" is the name of the module to import.
            "symbol_name" (if given) is the attribute on that module to
                return.
        """
        # TODO: get logging right
        # XXX All the logging stuff should go on the controller and that
        #    should get passed in here for appropriate logging of this
        #    eval.
        # XXX Will this screw up for, e.g. in Python:
        #    'import codeintel.utils'?
        import_handler = self.citadel.import_handler_from_lang(self.lang)
        module = import_handler.import_blob_name(
            module_name, self.buf.libs, self.ctlr)
        self.log("module '%s' imports <%s>", module_name,
                 self.str_elem(module))

        if symbol_name:
            # XXX logging won't be right here
            return self._eval_getattr(module, symbol_name,
                                      "%s.%s" % (module_name, symbol_name))
            # XXX Here is the _eval_getattr code to duplicate.
            # self.log("lookup '%s' on <%s>:", name, self.str_elem(obj))
            # for child in obj:
            #     if child.get("name") == name:
            #         attr = child
            #         self.log("'%s' is <%s>", citdl_expr, self.str_elem(child))
            #         return attr
            # else:
            #     raise CodeIntelError("couldn't find '%s' attribute on <%s>"
            #                          % (name, self.str_elem(obj)))
        else:
            return module

    def _eval_import(self, imp, name):
        """Return the object imported, if any, with the given import
        node (in a citree) and name.

        Return value: If successful it returns the citree node imported.
        If 'name' was not found in a '*'-import then None is returned
        (e.g. it is not exceptional that 'from os import *' does not
        import 'fuzzywuzzy'). If the import could not be resolved, but
        it looks like it should have been, then an error is raised.
        """
        # One of these:
        #   'os' may be from <import os>:
        #       ...
        #       'os' is <blob os>
        #   'os' is from <import os>: <blob os> (cached)
        #
        # Python
        # if non-* import and matches:
        # 'os' is from <import os>
        # is <import os> from <project foo>? no
        # ...
        # is <import os> from <python-2.4-stdlib>? yes: <blob os>
        # 'os' is <blob os>
        #
        # 'dirname' may be from <from os.path import *>:
        #     is <from os.path import *> from <project foo>? no
        #     ...
        # is <from os.path import *> from <python-2.4-stdlib>? yes: <blob
        # os.path>

        # TOTEST:
        # - 'from xml import dom', does that get it right? I doubt it.

        module_name = imp.get("module")
        symbol_name = imp.get("symbol")
        alias = imp.get("alias")
        obj = None
        if alias:
            if alias == name:   # <import foo as name> or <from foo import bar as name>
                self.log("'%s' is from <%s>", name, self.str_import(imp))
                return self._resolve_import(module_name, symbol_name)
        elif symbol_name:
            assert symbol_name != "**", "only Perl should be using '**' for imports"
            if symbol_name == "*":   # <from foo import *>
                self.log("'%s' may be from <%s>", name, imp)
                # XXX some variation of _resolve_import to specify just
                #    importing the module.
                try:
                    module = self._resolve_import(module_name)
                except CodeIntelError, ex:  # use equivalent of NoModuleEntry?
                    self.warn("could not resolve '%s' import to handle <%s>",
                              module_name, self.str_import(imp))
                    return None
                # TODO:
                # see if name in export list (__all__ for Python,
                #   @EXPORT for Perl, default all top-level symbols)
                # if so, eval getattr of name on module object
                self.warn("not handling <%s>!", self.str_import(imp))
            if symbol_name == name:  # <from foo import name>
                self.log("'%s' is from <%s>", name, self.str_import(imp))
                return self._resolve_import(module_name, symbol_name)
        elif module_name == name:    # <import foo>
            self.log("'%s' is from <%s>", name, self.str_import(imp))
            return self._resolve_import(module_name)
        return None

    def _eval_citdl_token(self, token, scope_stack):
        start_scope_str = self.str_elem(scope_stack[-1])
        self.log("eval '%s' at <%s>:", token, start_scope_str)

        while scope_stack:
            scope = scope_stack.pop()
            self.log("is '%s' accessible on <%s>?",
                     token, self.str_elem(scope))
            for child in reversed(scope):
                # Check children in reverse because last definition in
                # file wins. A correct refinement *for the top-level*
                # would be to skip anything defined later in the file
                # than the current start position.
                # TODO-PERF: The list of symbols on a scope should be a
                #            dict to speed up this loop. This is complicated
                #            by '*' imports.

                if child.tag == "import":
                    obj = self._eval_import(child, token)
                    if obj:
                        return obj
                elif child.get("name") == token:
                    obj = child
                    if obj.tag == "variable":
                        citdl = obj.get("citdl")
                        if not citdl:
                            self.log("'%s' is <%s> which is of unknown type",
                                     token, self.str_elem(obj))
                            raise CodeIntelError(
                                "don't know type of <%s> on <%s>"
                                % (self.str_elem(obj), self.str_elem(scope)))
                        else:
                            self.log("'%s' is <%s> which is '%s'", token,
                                     self.str_elem(obj), citdl)
                            obj = self._eval_citdl_expr(
                                citdl, scope_stack+[scope])
                            self.log("'%s' is <%s>", token,
                                     self.str_elem(obj))
                    else:
                        self.log("'%s' is <%s>", token, self.str_elem(obj))
                    return obj
            else:
                continue
        else:
            raise CodeIntelError("couldn't resolve '%s' starting at %s"
                                 % (token, start_scope_str))

    def _defn_from_hit(self, hit):
        elem, (blob, lpath) = hit
        # self.log("_defn_from_hit:: blob: %r", blob)
        # for attr_name, attr_value in blob.attrib.items():
        #    self.log("attr_name: %r, attr_value: %r", attr_name, attr_value)
        # self.log("_defn_from_hit:: elem: %r", elem)

        path = blob.get("src", None)
        name = elem.get("name", None)
        line = elem.get(
            "line", 1)  # e.g. for an import, just use the first line
        if line is not None:
            try:
                line = int(line)
            except ValueError:
                line = 1
        ilk = elem.get("ilk") or elem.tag
        citdl = elem.get("citdl", None)
        doc = elem.get("doc", None)
        signature = elem.get("signature", None)
        attributes = elem.get("attributes", None)
        returns = elem.get("returns", None)
        try:
            scope = self._elem_from_scoperef((blob, lpath))
        except AttributeError:
            scopestart = 1
            scopeend = 0
        else:
            def safe_int_get(attr, default_value):
                try:
                    return int(scope.get(attr, default_value))
                except (ValueError, AttributeError):
                    return default_value
            scopestart = safe_int_get("line", 1)
            scopeend = safe_int_get("lineend", 0)

        # Only fixup paths that do not look like URIs.
        if path and not re.match(r"^\w+:\/\/", path):
            if sys.platform == "win32":
                path = path.replace('/', '\\')  # unnormalize path
            path = normpath(path)  # remove possible '.' and '..' elements
        defn = Definition(blob.get("lang"), path, blob.get("name"), lpath,
                          name, line, ilk, citdl, doc,
                          signature, attributes, returns, scopestart, scopeend)
        return defn

    class _infinite_recursion_checker(object):
        def __init__(self, evalr):
            self.evalr = evalr

        def __enter__(self):
            self.evalr._eval_count_all += 1
            if self.evalr._eval_count_all >= self.evalr._SENTINEL_MAX_ALL_COUNT:
                raise EvalError("Too much recursion")

        def __exit__(self, exc_type, exc_value, traceback):
            self.evalr._eval_count_all -= 1

    # The SENTINEL_MAX_EXPR_COUNT could probably be *reduced*.
    # Note: This is an approximation that we are infinitely looping
    # on the same evaluation. The *actual* appropriate key would be:
    #
    #   (expr, scoperef)
    #
    # but that is overkill for now, I think.
    _SENTINEL_MAX_EXPR_COUNT = 10
    _SENTINEL_MAX_ALL_COUNT = 100
    _eval_count_from_expr = None
    _eval_count_all = 0

    def _check_infinite_recursion(self, expr):
        if self._eval_count_from_expr is None:
            # Move this init into eval() when on TreeEvalutor.
            self._eval_count_from_expr = {}
        eval_count = self._eval_count_from_expr.get(expr, 0)
        eval_count += 1
        if eval_count >= self._SENTINEL_MAX_EXPR_COUNT:
            raise EvalError("hit eval sentinel: expr '%s' eval count "
                            "is %d (abort)" % (expr, eval_count))
        self._eval_count_from_expr[expr] = eval_count
        return TreeEvaluator._infinite_recursion_checker(self)


#---- internal support stuff

def _dump_element(elem, indent=''):
    """Dump an element tree without using ET.dump() which
    (1) uses XML syntax,
    (2) can blow up if an attribute is set to None accidentally.

    This is only useful for debugging.
    """
    s = "%selement '%s': %s" % (indent, elem.tag, elem.attrib)
    print s
    for child in elem:
        _dump_element(child, indent+'  ')

########NEW FILE########
__FILENAME__ = tree_javascript
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Completion evaluation code for JavaScript"""

import logging
import types
import re
from pprint import pformat
from itertools import chain

from codeintel2.common import *
from codeintel2.util import indent
from codeintel2.tree import TreeEvaluator


class CandidatesForTreeEvaluator(TreeEvaluator):
    # Note: the "alt" changes added in change 281350 make some of the
    # functionality on this class *not* appropriate for the shared
    # TreeEvaluator. I.e. _elem_from_scoperef et al should be moved
    # *out* of CandidatesForTreeEvaluator.

    # This is a dict when set, multiple elements that have the same lpath will
    # be set in here, ensuring we get the correct one from an lpath lookup.
    # Fixes the following bug:
    #   http://bugs.activestate.com/show_bug.cgi?id=71666
    # Ideally, this would not be needed once elem.names[] can return a tuple,
    # see the following bug for reference:
    #   http://bugs.activestate.com/show_bug.cgi?id=71941
    _alt_elem_from_scoperef = None

    def _elem_from_scoperef(self, scoperef):
        """A scoperef is (<blob>, <lpath>). Return the actual elem in
        the <blob> ciElementTree being referred to.
        """
        elem = scoperef[0]
        i = 0
        for lname in scoperef[1]:
            i += 1
            if self._alt_elem_from_scoperef is not None:
                scoperef_names = ".".join(scoperef[1][:i])
                alt_elem = self._alt_elem_from_scoperef.get(scoperef_names)
                if alt_elem is not None:
                    elem = alt_elem
                    continue
            elem = elem.names[lname]
        return elem

    def _tokenize_citdl_expr(self, expr):
        chars = iter(zip(expr, chain(expr[1:], (None,))))
        buffer = []

        def get_pending_token():
            if buffer:
                yield "".join(buffer)
            del buffer[:]

        def get_quoted_string(ch):
            quote = ch
            local_buffer = []
            for ch, next in chars:
                # print "quote: quote=[%s] ch=[%s] next=[%s] token=%r" % (
                #    quote, ch, next, local_buffer)
                if ch == "\\":
                    local_buffer.append(chars.next()[0])
                elif ch == quote:
                    if local_buffer:
                        yield "".join(local_buffer)
                    break
                else:
                    local_buffer.append(ch)

        BLOCK_MAP = {"(": ")", "[": "]"}

        for ch, next in chars:
            # print "ch=[%s] next=[%s] token=%r" % (ch, next, buffer)
            if ch in ('"', "'"):  # quoted string
                for token in get_pending_token():
                    yield token
                for token in get_quoted_string(ch):
                    yield token
            elif ch == ".":
                for token in get_pending_token():
                    yield token
                buffer = []
            elif ch in BLOCK_MAP:
                block = [ch, BLOCK_MAP[ch]]
                emit = ch in ("[",)
                for token in get_pending_token():
                    yield token
                if next == block[1]:
                    chars.next()  # consume close quote
                    yield block[0] + block[1]
                elif next in ('"', "'"):  # quoted string
                    chars.next()  # consume open bracket
                    next_tokens = list(get_quoted_string(next))
                    ch, next = chars.next()
                    if ch == block[1] and emit:
                        for next_token in next_tokens:
                            yield next_token
                    else:
                        yield block[0] + block[1]

            else:
                buffer.append(ch)
        if buffer:
            yield "".join(buffer)

    def _join_citdl_expr(self, tokens):
        return '.'.join(tokens).replace('.()', '()')


class JavaScriptTreeEvaluator(CandidatesForTreeEvaluator):
    def eval_cplns(self):
        self.log_start()
        start_scoperef = self.get_start_scoperef()
        self.info("start scope is %r", start_scoperef)

        if self.trg.type == "names":
            cplns = list(self._completion_names_from_scope(self.expr,
                                                           start_scoperef))
        else:
            hits = self._hits_from_citdl(self.expr, start_scoperef)
            cplns = list(self._members_from_hits(hits))
            if not cplns:
                raise CodeIntelError("No completions found")
        # For logging messages every call
        # print indent('\n'.join("%s: %s" % (lvl, args and m % (args) or m)
        #                for lvl,m, args in self.ctlr.log))
        # print indent('\n'.join(["Hit: %r" % (cpln, ) for cpln in cplns]))
        return cplns

    def eval_calltips(self):
        self.log_start()
        start_scoperef = self.get_start_scoperef()
        self.info("start scope is %r", start_scoperef)
        hits = self._hits_from_citdl(self.expr, start_scoperef)
        if not hits:
            raise CodeIntelError("No calltips found")
        return self._calltips_from_hits(hits)

    def eval_defns(self):
        self.log_start()
        start_scoperef = self.get_start_scoperef()
        self.info("start scope is %r", start_scoperef)
        hits = self._hits_from_citdl(self.expr, start_scoperef, defn_only=True)
        if not hits:
            raise CodeIntelError("No definitions found")
        return [self._defn_from_hit(x) for x in hits]

    def parent_scoperef_from_scoperef(self, scoperef,
                                      started_in_builtin_window_scope=False):
        """
        For JavaScript-in-the-browser the top-level scope is the
        Window object instance. For now we are always presuming we
        are running in the browser if the language is JavaScript.

        Problem: if we *started* on the Window class then the parent
        scope should be -> built-in-blob. This is what
        'started_in_builtin_window_scope' is used for.
        """
        blob, lpath = scoperef
        global_var = self._global_var
        if not started_in_builtin_window_scope \
           and lpath == [global_var] and blob is self.built_in_blob:
            return None
        elif lpath:
            return (blob, lpath[:-1])
        elif blob is self.built_in_blob:
            if started_in_builtin_window_scope:
                return None
            elif global_var is not None:
                return (self.built_in_blob, [global_var])
        else:
            return (self.built_in_blob, [])

    @property
    def _global_var(self):
        """
        The type of the global variable
        """
        if self.trg.lang == "Node.js":
            return "global"
        return "Window"

    _langintel = None

    @property
    def langintel(self):
        if self._langintel is None:
            self._langintel = self.mgr.langintel_from_lang(self.trg.lang)
        return self._langintel

    _libs = None

    @property
    def libs(self):
        if self._libs is None:
            self._libs = self.langintel.libs_from_buf(self.buf)
        return self._libs

    @property
    def stdlib(self):
        # JS stdlib is always the last one.
        return self.libs[-1]

    _built_in_blob = None

    @property
    def built_in_blob(self):
        if self._built_in_blob is None:
            self._built_in_blob = self.stdlib.get_blob("*")
        return self._built_in_blob

    ## Specific element completions ##

    def _hit_from_first_token(self, token, scoperef):
        """Find the token at the given or a parent scope.

        Returns the found elem and the scope at which it was found. If
        not found, this returns (None, None).
        """
        self.log("find '%s' starting at %s", token, scoperef)

        # Because we fake JavaScript classes and put the ctor
        # function inside the class, we need to push start scopes at
        # the class to the ctor. See test
        # javascript/cpln/ctor_scope_cheat for an example of why.
        try:
            elem = self._elem_from_scoperef(scoperef)
        except KeyError, ex:
            self.warn("_hit_from_first_token:: no elem for scoperef: %r",
                      scoperef)
            return (None, None)
        if elem.get("ilk") == "class":
            class_name = elem.get("name")
            try:
                ctor = elem.names[class_name]
            except KeyError:
                pass
            else:
                if "__ctor__" in ctor.get("attributes", ""):
                    scoperef = (scoperef[0], scoperef[1]+[class_name])
                    self.log("push scope to class ctor %s", scoperef)

        started_in_builtin_window_scope = (scoperef[0] is self.built_in_blob
                                           and scoperef[1] and scoperef[1][0] == self._global_var)
        while 1:
            try:
                elem = self._elem_from_scoperef(scoperef)
            except KeyError, ex:
                raise EvalError("could not resolve scoperef %r: %s"
                                % (scoperef, ex))
            try:
                candidate = elem.names[token]
                if "__ctor__" in candidate.get("attributes", ""):
                    # In JavaScript we include the constructor
                    # function for a (faked) class as a method.
                    # We must skip it here or resolution of 'this'
                    # in a JS class methods will always hit the ctor
                    # instead of the class (which is by far the
                    # common case).
                    raise KeyError("skipping JavaScript ctor")
                self.log("is '%s' accessible on %s? yes", token, scoperef)
                return candidate, scoperef
            except KeyError:
                self.log("is '%s' accessible on %s? no", token, scoperef)
                scoperef = self.parent_scoperef_from_scoperef(scoperef,
                                                              started_in_builtin_window_scope)
                if not scoperef:
                    return None, None

    def _members_from_hits(self, hits):
        members = set()
        curr_blob = self.buf.blob_from_lang.get(self.lang, None)
        for elem, scope in hits:
            # In JavaScript we include the constructor function for a
            # (faked) class as a method. Completion on an instance of
            # this class shouldn't see the ctor.
            skip_js_ctor = (elem.tag == "scope" and elem.get("ilk") == "class")

            if elem.get("ilk") == "function":
                # Functions have an implicit citdl type of "Function". See bug:
                # http://bugs.activestate.com/show_bug.cgi?id=76504
                try:
                    subhits = self._hits_from_type_inference("Function", scope)
                    members.update(self._members_from_hits(subhits))
                except CodeIntelError:
                    pass  # Ignore if Function was not found

            for child in elem:
                if elem.get("ilk") == "function" and child.get("ilk") == "argument":
                    # function arguments are not members, skip them.
                    # (we might still find properties of functions, though)
                    continue
                # Only add locals when the current scope is the same
                # as the variable scope.
                attributes = child.get("attributes", "").split()
                if curr_blob is not None and scope[0] != curr_blob:
                    if "__file_local__" in attributes:
                        self.log("skipping file_local %r in %r", elem, scope)
                        continue
                if "__local__" in attributes:
                    # XXX: Move start_scoperef to be a part of the class
                    # start_scoperef = self.get_start_scoperef()
                    # scope_elem = start_scoperef[0]
                    # for lname in start_scoperef[1]:
                    #    if elem == scope_elem:
                    #        members.add( ("variable", child.get("name")) )
                    #        break
                    #    scope_elem = scope_elem.names[lname]
                    # else: # Don't show this variable
                    continue

                if child.tag == "scope":
                    if skip_js_ctor and child.get("ilk") == "function" \
                       and "__ctor__" in attributes:
                        continue
                    members.add((child.get("ilk"), child.get("name")))
                elif child.tag == "variable":
                    if len(child):
                        members.add(("namespace", child.get("name")))
                    else:
                        members.add(("variable", child.get("name")))
                else:
                    raise NotImplementedError("unknown hit child tag '%s': %r"
                                              % (child.tag, child))
            for classref in elem.get("classrefs", "").split():
                try:
                    subhits = self._hits_from_type_inference(classref, scope)
                    members.update(self._members_from_hits(subhits))
                except CodeIntelError:
                    pass  # Ignore when parent class not found, bug 65447
        return members

    def _calltip_from_func(self, elem):
        # See "Determining a Function CallTip" in the spec for a
        # discussion of this algorithm.
        signature = elem.get("signature")
        doc = elem.get("doc")
        ctlines = []
        if not signature:
            name = elem.get("name")
            # XXX Note difference for Tcl in _getSymbolCallTips.
            ctlines = [name + "(...)"]
        else:
            ctlines = signature.splitlines(0)
        if doc:
            ctlines += doc.splitlines(0)
        return '\n'.join(ctlines)

    def _calltip_from_class(self, elem):
        # If the class has a defined signature then use that.
        name = elem.get("name")
        signature = elem.get("signature")
        doc = elem.get("doc")
        if signature:
            ctlines = signature.splitlines(0)
            if doc:
                ctlines += doc.splitlines(0)
            return '\n'.join(ctlines)
        elif name in elem.names:
            # Typically the class element has a contructor function of
            # the same name as the class.
            ctor = elem.names[name]
            self.log("ctor is %r", ctor)
            return self._calltip_from_func(ctor)
        else:
            ctlines = [name + "(...)"]
            if doc:
                ctlines += doc.splitlines(0)
            return '\n'.join(ctlines)

    def _calltips_from_hits(self, hits):
        """
        c.f. CitadelEvaluator._getSymbolCallTips()
        """
        calltips = []

        for elem, scoperef in hits:
            # self.log("calltip for hit: %r", hit)
            if elem.tag == "variable":
                # Ignore variable hits.
                self.debug("_calltips_from_hits:: ignoring variable: %r", elem)
                continue
            elif elem.tag == "scope":
                ilk = elem.get("ilk")
                if ilk == "function":
                    calltips.append(self._calltip_from_func(elem))
                elif ilk == "class":
                    calltips.append(self._calltip_from_class(elem))
                else:
                    raise NotImplementedError("unexpected scope ilk for "
                                              "calltip hit: %r" % elem)
            else:
                raise NotImplementedError("unexpected elem for calltip "
                                          "hit: %r" % elem)

            ## Bug 59438: adding "(from $lpath in $file)" when helpful
            ## in calltips.
            ## TODO: Don't include all (or part) when not useful:
            ##       document.getElementsByClassName -> "(from document in
            ##       prototype)". The "document in" in not necessary.
            ## TODO: Bad with empty lpath: "(from  in prototype)"
            ## TODO: Problematic for test suite with "rand??" module names.
            ## TODO: Don't add for a local hit.
            # blobname = scoperef[0].get("name")
            # if blobname == "*":
            #    blobname = "stdlib"
            # scopename = '.'.join(scoperef[1])
            # calltips[-1] += "\n(from %s in %s)" % (scopename, blobname)
        return calltips

    def _hits_from_citdl(self, expr, scoperef, defn_only=False):
        with self._check_infinite_recursion(expr):

            if "[]" in expr:
                # TODO: We cannot resolve array type inferences yet.
                # Note that we do allow arrays types with a string key, since
                # that's an alternative form for property access
                raise CodeIntelError(
                    "no type-inference yet for arrays: %r" % expr)

            tokens = list(self._tokenize_citdl_expr(expr))

            # self.log("expr tokens: %r", tokens)

            # First part... we try to match as much as possible straight up
            hits, nconsumed = self._hits_from_first_part(tokens, scoperef)
            if not hits:
                raise CodeIntelError(
                    "could not resolve first part of '%s'" % expr)
            self.debug("_hits_from_citdl: first part: %r -> %r",
                       tokens[:nconsumed], hits)

            # ...the remainder.
            remaining_tokens = tokens[nconsumed:]
            for token in tokens[nconsumed:]:
                new_hits = []
                for elem, scoperef in hits:
                    self.debug("_hits_from_citdl: resolve %r on %r in %r",
                               token, elem, scoperef)
                    if token == "()":
                        try:
                            new_hits += self._hits_from_call(elem, scoperef)
                        except CodeIntelError, ex:
                            self.warn("could resolve call on %r: %s", elem, ex)
                        continue
                    try:
                        new_hit = self._hit_from_getattr(
                            elem, scoperef, token)
                    except CodeIntelError, ex:
                        if token == "prototype" and elem.get("ilk") == "class":
                            self.debug("_hits_from_citdl: using class %r for "
                                       "its prototype", elem)
                            new_hits.append((elem, scoperef))
                        else:
                            self.warn(str(ex))
                    else:
                        new_hits.append(new_hit)
                hits = new_hits

            # Resolve any variable type inferences.
            # XXX Don't we have to *recursively* resolve hits?
            #    If that is done, then need to watch out for infinite loop
            #    because _hits_from_variable_type_inference() for a variable
            #    with children just returns itself. I.e. you *can't* resolve
            #    the <variable> away.
            resolved_hits = []
            if self.buf:
                curr_blob = self.buf.blob_from_lang.get(self.lang, {})
            else:
                curr_blob = None

            for elem, scoperef in hits:
                if scoperef[0] != curr_blob:
                    if "__file_local__" in elem.get("attributes", "").split():
                        self.log(
                            "skipping __file_local__ %r in %r", elem, scoperef)
                        continue
                if elem.tag == "variable" and not defn_only:
                    try:
                        if (not elem.get("citdl")) and elem.get("ilk") == "argument":
                            # this is an argument, try to infer things from the
                            # caller
                            subhits = self._hits_from_argument(elem, scoperef)
                        else:
                            subhits = self._hits_from_variable_type_inference(
                                elem, scoperef)
                    except CodeIntelError, ex:
                        self.warn("could not resolve %r: %s", elem, ex)
                    else:
                        resolved_hits += subhits
                else:
                    resolved_hits.append((elem, scoperef))

            return resolved_hits

    def _hits_from_argument(self, elem, scoperef):
        """
        Return hits for an argument of a function based on its caller
        @param elem The argument; must have ilk=argument
        @param scoperef The scope containing the element
        @returns list of hits
        """
        assert elem.get("ilk") == "argument", \
            "_hits_from_argument expects an argument, got a %r" % elem.get(
                "ilk")
        hits = []
        scope = self._elem_from_scoperef(
            scoperef)  # the function the argument is in

        args = [arg for arg in scope.findall(
            "variable") if arg.get("ilk") == "argument"]
        for pos in range(len(args)):
            if args[pos].get("name") == elem.get("name"):
                break
        else:
            # can't find the argument?
            return []

        for caller in scope.getiterator("caller"):
            citdl = caller.get("citdl")
            caller_pos = int(caller.get("pos") or 0)  # 1-indexed
            if citdl is None or caller_pos < 1:
                # invalid caller
                continue
            for caller_hit in self._hits_from_citdl(citdl, scoperef):
                caller_func = caller_hit[0]  # the calling function
                if caller_func.get("ilk") != "function":
                    # nevermind, not a function
                    continue
                caller_args = [arg for arg in caller_func.getiterator(
                    "variable") if arg.get("ilk") == "argument"]
                if caller_pos > len(caller_args):
                    # no such argument
                    continue
                caller_arg = caller_args[caller_pos - 1]
                citdl = caller_arg.get("citdl")
                if not citdl:
                    continue
                for citdl_hit in self._hits_from_citdl(citdl, caller_hit[1]):
                    # got the function being called, now look up the argument
                    # by pos
                    func = citdl_hit[0]
                    if func.get("ilk") != "function":
                        continue
                    args = [arg for arg in func.getiterator(
                        "variable") if arg.get("ilk") == "argument"]
                    if pos >= len(args):
                        continue
                    citdl = args[pos].get("citdl")
                    if not citdl:
                        continue
                    hits += self._hits_from_citdl(citdl, citdl_hit[1])
        return hits

    def _hits_from_call(self, elem, scoperef):
        """Resolve the function call inference for 'elem' at 'scoperef'."""
        if elem.tag == "variable":
            hits = []
            var_hits = self._hits_from_variable_type_inference(elem, scoperef)
            for var_elem, var_scoperef in var_hits:
                if var_elem != elem:
                    try:
                        hits += self._hits_from_call(var_elem, var_scoperef)
                    except CodeIntelError:
                        pass  # Keep trying other alternatives
            if not hits:
                raise CodeIntelError("could not resolve call on %r." % elem)
            return hits
        if elem.get("ilk") == "class":
            return [(elem, scoperef)]
        if elem.get("ilk") != "function":
            raise CodeIntelError("_hits_from_call:: unexpected element type %r"
                                 % elem)

        # CommonJS / NodeJS hack
        if elem.get("name") == "require" and \
           scoperef[0] is self.built_in_blob and \
           not scoperef[1]:
            try:
                requirename = self.trg.extra.get("_params", []).pop(0)
            except IndexError:
                requirename = None
            if requirename is not None:
                import codeintel2.lang_javascript
                requirename = codeintel2.lang_javascript.Utils.unquoteJsString(
                    requirename)
                self.log("_hits_from_call: resolving CommonJS require(%r)",
                         requirename)
                hits = self._hits_from_commonjs_require(requirename, scoperef)
                if len(hits) > 0:
                    return hits

        resolver = getattr(elem, "resolve", None)
        try:
            param = self.trg.extra.get("_params", []).pop(0)
        except IndexError:
            param = None
        if resolver and param is not None:
            try:
                self.log("Attempting to use extra resolver %r param %r",
                         resolver, param)
                hits = resolver(evlr=self, action="call", scoperef=scoperef,
                                param=param)
                if hits:
                    return hits
            except:
                self.log("Extra resolver %r: Failed to resolve %s",
                         resolver, scoperef)
        else:
            self.log("_hits_from_call: no resolver on %r", elem)

        citdl = elem.get("returns")
        if not citdl:
            raise CodeIntelError("no return type info for %r" % elem)
        self.log("_hits_from_call: resolve '%s' for %r, scoperef: %r",
                 citdl, elem, scoperef)
        # scoperef has to be set to the function called
        scoperef = (scoperef[0], scoperef[1]+[elem.get("name")])
        return self._hits_from_citdl(citdl, scoperef)

    def _hit_from_getattr(self, elem, scoperef, token):
        """Resolve the getattr of 'token' on the given 'elem'.

        Raises CodeIntelError if could not resolve it.

        Algorithm:
        - Try to resolve it.
        - Call a hook to make an educated guess. Some attribute names
          are strong signals as to the object type -- typically those
          for common built-in classes.
        """
        self.log("resolve getattr '%s' on %r in %r:", token, elem, scoperef)
        if elem.tag == "variable":
            hits = self._hits_from_variable_type_inference(elem, scoperef)
        elif elem.tag == "scope" and elem.get("ilk") == "function":
            # Functions have an implicit citdl type of "Function". Bug 80880.
            hits = self._hits_from_type_inference("Function", scoperef)
        else:
            assert elem.tag == "scope", "elem tag is not 'scope': %r" % elem.tag
            hits = [(elem, scoperef)]

        for hit_elem, hit_scoperef in hits:
            self.log("_hit_from_getattr:: hit elem %r, scoperef: %r",
                     hit_elem, hit_scoperef)
            ilk = hit_elem.get("ilk")
            if hit_elem.tag == "variable":
                attr = hit_elem.names.get(token)
                if attr is not None:
                    self.log("attr is %r on %r", attr, hit_elem)
                    var_scoperef = (hit_scoperef[0],
                                    hit_scoperef[1]+[hit_elem.get("name")])
                    return (attr, var_scoperef)
            elif ilk == "function":
                return self._hit_from_getattr(hit_elem, hit_scoperef, token)

            elif ilk == "class":
                attr = hit_elem.names.get(token)
                if attr is not None:
                    self.log("attr is %r on %r", attr, hit_elem)
                    if hit_scoperef:
                        class_scoperef = (hit_scoperef[0],
                                          hit_scoperef[1]+[hit_elem.get("name")])
                        # If this is a variable defined in a class, move the
                        # scope to become the position in the class where the
                        # variable was defined (usually the ctor class function)
                        # this ensures we get the right citdl lookup. See bug:
                        # http://bugs.activestate.com/show_bug.cgi?id=71343
                        lineno = int(attr.get("line", "-1"))
                        if attr.tag == "variable" and \
                           lineno > int(hit_elem.get("line", "-1")) and \
                           lineno <= int(hit_elem.get("lineend", "-1")):
                            # get the scope of the variable
                            blob, lpath = self.buf.scoperef_from_blob_and_line(
                                hit_elem,
                                lineno)
                            if lpath:
                                class_scoperef = (class_scoperef[0],
                                                  class_scoperef[1]+lpath)
                                self.log(
                                    "Updating scoperef to: %r", class_scoperef)
                    else:
                        class_scoperef = (None, [hit_elem.get("name")])
                    return (attr, class_scoperef)
                for classref in hit_elem.get("classrefs", "").split():
                    try:
                        base_hits = self._hits_from_type_inference(classref,
                                                                   hit_scoperef)
                    except CodeIntelError:
                        pass  # Ignore when parent class not found, bug 65447
                    else:
                        for base_elem, base_scoperef in base_hits:
                            if token in base_elem.names:
                                self.log("is '%s' from %s base class? yes",
                                         token, base_elem)
                                new_scoperef = (base_scoperef[0],
                                                base_scoperef[1] +
                                                [base_elem.get("name")])
                                return (base_elem.names[token], new_scoperef)
                            self.log("is '%s' from %s base class? no", token,
                                     base_elem)
            else:
                raise NotImplementedError("unexpected scope ilk: %r" % ilk)
        raise CodeIntelError("could not resolve '%s' getattr on %r in %r"
                             % (token, elem, scoperef))

    def _hits_from_variable_type_inference(self, elem, scoperef):
        """Resolve the type inference for 'elem' at 'scoperef'."""
        assert elem.tag == "variable"

        hits = []

        citdl = elem.get("citdl")

        if citdl == "require()":
            # Node.js / CommonJS hack: try to resolve things via require()
            requirename = elem.get('required_library_name')
            if requirename:
                self.log(
                    "_hits_from_variable_type_inference: resolving require(%r)",
                    requirename)
                hits += self._hits_from_commonjs_require(requirename, scoperef)

        if len(elem) != 0:
            # This is CIX for a JavaScript custom Object instance: a
            # common pattern in JS. See test javascript/cpln/local2.
            # remember to also return things from require()
            return hits + [(elem, scoperef)]

        if not citdl:
            raise CodeIntelError("no type-inference info for %r" % elem)

        self.log("resolve '%s' type inference for %r:", citdl, elem)

        if citdl == elem.get("name") and citdl not in elem.names:
            # The citdl expression is the same as the variable name, this will
            # create a recursive citdl lookup loop. What we likely want is a
            # different match that has the same name, so we go looking for it.
            # Fix for bug: http://bugs.activestate.com/show_bug.cgi?id=71666
            self.log("_hits_from_variable_type_inference:: recursive citdl "
                     " expression found, trying alternatives.")
            try:
                parent_elem = self._elem_from_scoperef(scoperef)
            except KeyError, ex:
                raise CodeIntelError(
                    "could not resolve recursive citdl expression %r" % citdl)
            else:
                alt_hits = []
                # Look for alternative non-variable matches.
                for child in parent_elem:
                    if child.tag != "variable" and child.get("name") == citdl:
                        alt_hits.append((child, scoperef))
                        # Remember the alternative hit, in case we need to
                        # look up this lpath again.
                        if self._alt_elem_from_scoperef is None:
                            self._alt_elem_from_scoperef = {}
                        alt_sref_name = ".".join(scoperef[1] + [citdl])
                        self._alt_elem_from_scoperef[alt_sref_name] = child
                        self.log(
                            "Alternative hit found: %r, scoperef: %r", child, scoperef, )
                if alt_hits:
                    return alt_hits
                # Try from the parent scoperef then.
                scoperef = self.parent_scoperef_from_scoperef(scoperef)
                if scoperef is None:
                    # When we run out of scope, raise an error
                    raise CodeIntelError(
                        "could not resolve recursive citdl expression %r" % citdl)
                # Continue looking using _hits_from_citdl with the parent.
                self.log(
                    "Continue search for %r from the parent scope.", citdl)

        try:
            hits += self._hits_from_citdl(citdl, scoperef)
        except EvalError:
            # shut up eval errors if we managed to get _some_ hits
            if not hits:
                raise

        return hits

    def _hits_from_type_inference(self, citdl, scoperef):
        """Resolve the 'citdl' type inference at 'scoperef'."""
        self.log("resolve '%s' type inference:", citdl)
        return self._hits_from_citdl(citdl, scoperef)

    def _hits_from_first_part(self, tokens, scoperef):
        """Resolve the first part of the expression.

        If the first token is found at the global or built-in level (or
        not found at all locally) then it may be a shared namespace with
        other files in the execution set. Get that down to a list of
        hits and a remaining list of expression tokens.
        """
        elem, scoperef = self._hit_from_first_token(tokens[0], scoperef)
        if elem is not None:
            self.log("_hit_from_first_part: found elem: %s %r at %r",
                     elem.get("ilk") or elem.tag, elem.get("name"),
                     scoperef[1])

        if (elem is None            # first token wasn't found
            or not scoperef[1]      # first token was found at global level
            # first token was found on built-in Window class (the top scope)
            or (scoperef[1] == ['Window'] and scoperef[0].get("name") == "*")
            ):
            # Search symbol table in execution set.
            #
            # Example: 'myPet.name.toLowerCase()' and 'myPet' is found
            # at top-level. First lookup 'myPet.name.toLowerCase'
            # (everything up to first '()'), in execution set, then
            # 'myPet.name', then 'myPet'. The last one should always hit
            # in current file, at least.
            for first_call_idx, token in enumerate(tokens):
                if token == "()":
                    break
            else:
                first_call_idx = len(tokens)

            hits = []
            for nconsumed in range(first_call_idx, 0, -1):
                lpath = tuple(tokens[:nconsumed])  # for hits_from_lpath()
                if elem is not None and len(lpath) > 1:
                    # Try at the current elem we found in the file
                    try:
                        self.log("Checking for deeper local match %r from scoperef %r", lpath[
                                 1:], scoperef)
                        check_elem = elem
                        for p in lpath[1:]:   # we matched first token already
                            check_elem = check_elem.names[p]
                        check_scoperef = (scoperef[
                                          0], scoperef[1] + list(lpath[:-1]))
                        hits.insert(0, (check_elem,
                                        check_scoperef))
                        self.log("_hit_from_first_part: found deeper local elem: "
                                 "%s %r at %r",
                                check_elem.get("ilk") or check_elem.tag,
                                check_elem.get("name"),
                                check_scoperef[1])
                    except KeyError:
                        pass

                for lib in self.libs:
                    self.log("lookup '%s' in %s", '.'.join(lpath), lib)
                    hits_here = lib.hits_from_lpath(lpath, self.ctlr,
                                                    curr_buf=self.buf)
                    if hits_here:
                        self.log("found %d hits in lib", len(hits_here))
                        hits += hits_here
                if hits:
                    break
            if elem is not None:
                if not hits or nconsumed == 1:
                    hits.insert(0, (elem, scoperef))
                    nconsumed = 1
                else:
                    # Hits were found in the libs that are deeper than
                    # the hit in the local buf: we need to adjust the
                    # local hit.
                    new_elem = elem
                    for token in tokens[1:nconsumed]:
                        try:
                            new_elem = new_elem.names[token]
                        except KeyError:
                            break
                    else:
                        if new_elem not in (e for e, sr in hits):
                            new_scoperef = (scoperef[0], tokens[:nconsumed-1])
                            hits.insert(0, (new_elem, new_scoperef))
        else:
            hits = [(elem, scoperef)]
            nconsumed = 1

        return hits, nconsumed

    def _hits_from_commonjs_require(self, requirename, scoperef):
        """Resolve hits from a CommonJS require() invocation"""
        # Files usually end with a ".js" suffix, though others are like
        # ".node" are possible.
        #
        # TODO: Get these from node using "require.extensions".
        requirename += ".js"
        from codeintel2.database.langlib import LangDirsLib
        from codeintel2.database.multilanglib import MultiLangDirsLib
        from codeintel2.database.catalog import CatalogLib
        hits = []
        for lib in self.libs:
            blobs = None
            if isinstance(lib, (LangDirsLib, MultiLangDirsLib)):
                blobs = lib.blobs_with_basename(requirename, ctlr=self.ctlr)
            elif isinstance(lib, CatalogLib):
                blob = lib.get_blob(requirename)
                if blob is not None:
                    blobs = [blob]
            for blob in blobs or []:
                exports = blob.names.get("exports")
                if exports is not None and exports.tag == "variable":
                    hits += self._hits_from_variable_type_inference(
                        exports, [blob, ["exports"]])
                else:
                    self.log(
                        "Exported exports to be a variable, got %r instead", exports)
        return hits

    ## n-char trigger completions ##

    def _completion_names_from_scope(self, expr, scoperef):
        """Return all available element names beginning with expr"""
        self.log("_completion_names_from_scope:: %r, scoperef: %r",
                 expr, scoperef)
        # global_blob = self._elem_from_scoperef(self._get_global_scoperef(scoperef))
        # Get all of the imports

        # Keep a dictionary of completions.
        all_completions = {}

        # We start off having JS keywords at a bare minimum.
        keywords = self.langintel.langinfo.keywords
        for name in keywords:
            if not expr or name.startswith(expr):
                all_completions[name] = "keyword"

        # From the local scope, walk up the parent chain including matches as
        # we go.
        # XXX - Can we skip the global (stdlib) blob in here?
        loopcount = -1
        while scoperef and scoperef[0] is not None:
            loopcount += 1
            # Iterate over the contents of the scope.
            self.log("_completion_names_from_scope:: checking scoperef: %r",
                     scoperef)
            elem = self._elem_from_scoperef(scoperef)
            if elem is None:
                continue
            for name in elem.names:
                # self.log("_completion_names_from_scope:: checking name: %r",
                #         name)
                if name and name.startswith(expr):
                    if name not in all_completions:
                        hit_elem = elem.names[name]
                        if loopcount and "__local__" in hit_elem.get("attributes", "").split():
                            # Skip things that should only be local to the
                            # original scope.
                            # self.log("_completion_names_from_scope:: skipping local %r",
                            #         name)
                            continue
                        all_completions[name] = hit_elem.get(
                            "ilk") or hit_elem.tag
            # Continue walking up the scope chain...
            scoperef = self.parent_scoperef_from_scoperef(scoperef)

        # Builtins
        # Find the matching names (or all names if no expr)
        cplns = self.stdlib.toplevel_cplns(prefix=expr)
        for ilk, name in cplns:
            if name not in all_completions:
                all_completions[name] = ilk

        # "Import everything", iterate over all known libs
        for lib in self.libs:
            # Find the matching names (or all names if no expr)
            self.log("_completion_names_from_scope:: include everything from "
                     "lib: %r", lib)
            cplns = lib.toplevel_cplns(prefix=expr)
            for ilk, name in cplns:
                if name not in all_completions:
                    all_completions[name] = ilk

        return [(ilk, name) for name, ilk in all_completions.items()]

########NEW FILE########
__FILENAME__ = tree_perl
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Completion evaluation code for Perl.

Dev Note: A Perl "package" vs. a Perl "module"
----------------------------------------------

A Perl *module* is the content of a .pm file (or .so file for binary
modules) that one imports via a "use" or "require" statement. This
corresponds to a codeintel "blob".

A Perl *package* is a language construct that is created in Perl modules
(or Perl scripts) via the "package" statement. Typically (*are* there
exceptions?) a Perl module file "Foo/Bar.pm" will define a "Foo::Bar"
package. These are represented in codeintel/CIX with a *class*.

Hence:

    -------- Salad.pm --------
    use strict;
    package Salad;
    # ...
    1;
    --------------------------

    <codeintel version="2.0">
      <file path="Salad.pm" lang="Perl">
        <scope ilk="blob" name="Salad">     <!-- this is the Salad *module* -->
          <scope ilk="class" name="Salad">  <!-- this is the Salad *package* -->
              ...
          </scope>
        </scope>
      </file>
    <codeintel>

"""

import re
from pprint import pprint

from codeintel2.common import *
from codeintel2.tree import TreeEvaluator
from codeintel2.database.stdlib import StdLib
from codeintel2.util import banner, isident


#---- internal support class for Perl package import semantics

class _PerlPkgTable(object):
    """An object for handling Perl module/package import semantics. Each
    cpln evaluation creates one of these to determine (and cache) the
    working set of loaded Perl packages.

    Usage:
        pkg_tbl = _PerlPkgTable(blob,       # top-level (i.e. current) blob
                                buf.libs)   # DB libs for the current buffer

        # Generate (<blob>, <package-names>) tuples for loaded packages.
        for blob, pkg_names in pkg_tbl.gen_loaded_pkgs():
            ...

        # Get the pkg (CIX 'class' element) defining the named package.
        pkg = pkg_tbl.pkg_from_pkg_name(pkg_name)
        mod, pkg = pkg_tbl.mod_and_pkg_from_pkg_name(pkg_name)
    """
    # TODO: Consider an index (a la toplevelname_index) for imported
    #      Perl packages. Post-4.0. Only iff Perl cpln needs the
    #      speed.

    def __init__(self, blob, libs):
        self.blob = blob
        self.libs = libs

        self._generator_cache = None
        self._mod_from_pkg_name = {}
        # Used to support multiple calls to .gen_loaded_pkgs()
        self._item_cache = []

    @property
    def _generator(self):
        if self._generator_cache is None:
            self._generator_cache = self._gen_loaded_pkgs(self.blob, set())
        return self._generator_cache

    def pkg_from_pkg_name(self, pkg_name):
        """Return the package (a CIX <scope ilk="class"> element) for
        the given package name. If the package definition cannot be
        found, this returns None.
        """
        if pkg_name in self._mod_from_pkg_name:
            mod = self._mod_from_pkg_name[pkg_name]
            if mod is not None:
                return mod.names.get(pkg_name)
        for mod, pkg_names in self._generator:
            if mod is None:
                continue
            if pkg_name in pkg_names:
                return mod.names.get(pkg_name)
        return None

    def mod_and_pkg_from_pkg_name(self, pkg_name):
        """Return the module (a CIX <scope ilk="blob">) and package (a
        CIX <scope ilk="class"> element) for the given package name. If
        the package definition cannot be found, this returns
        (None, None).
        """
        if pkg_name in self._mod_from_pkg_name:
            mod = self._mod_from_pkg_name[pkg_name]
            if mod is not None:
                return mod, mod.names.get(pkg_name)
        for mod, pkg_names in self._generator:
            if mod is None:
                continue
            if pkg_name in pkg_names:
                return mod, mod.names.get(pkg_name)
        return None, None

    def gen_loaded_pkgs(self):
        """Generate loaded (*) Perl packages recursively, starting from
        the given blob.

        This yields the following 2-tuples:
            (<blob>, <set of packages defined in this blob>)

        A "loaded" Perl package is one that is imported (via "use" or
        "require") or locally defined via a "package" statement.

        If a particular Perl module cannot be imported it is presumed to
        define one package of the same name (which is typical). In this
        case, <blob> will be None.
        """
        for item in self._item_cache:
            yield item
        for item in self._generator:
            yield item

    def _gen_loaded_pkgs(self, mod, handled_mod_names):
        mod_names, pkg_names = self._pkg_info_from_mod(mod)
        item = (mod, pkg_names)
        self._item_cache.append(item)
        for pkg_name in pkg_names:
            self._mod_from_pkg_name[pkg_name] = mod
        yield item

        for mod_name in (m for m in mod_names if m not in handled_mod_names):
            handled_mod_names.add(mod_name)
            for lib in self.libs:
                mod = lib.get_blob(mod_name)
                if mod is not None:
                    break
            else:
                # self.debug("could not import module %r, assuming it "
                #           "defines package of same name", mod_name)
                item = (None, set([mod_name]))
                self._item_cache.append(item)
                self._mod_from_pkg_name[mod_name] = None
                yield item
                continue

            for item in self._gen_loaded_pkgs(mod, handled_mod_names):
                yield item

    def _imported_mod_names_from_mod(self, mod):
        """Yield "reasonable" module names imported in the given module.

        "Reasonable" here means those that can be handled by the Perl
        cpln evalrs. The issue is Perl 'require' statements that can
        quote a string, use string interpolation, etc.
        """
        from os.path import splitext

        for imp_elem in mod.getiterator("import"):
            mod_name = imp_elem.get("module")

            if '$' in mod_name:
                # Abort on these guys:
                #   require $blah;        <import module="$blah"/>
                #   require '$foo.pm';    <import module="'$foo.pm'"/>
                continue
            elif mod_name[0] in ('"', "'"):
                # Try to gracefully handle these guys:
                #   require 'MyFoo.pm';   <import module="'MyFoo.pm'"/>
                # require "MyBar.pm";   <import module="&quot;MyBar.pm&quot;"/>
                sans_quotes = mod_name[1:-1]
                sans_ext, ext = splitext(sans_quotes)
                if ext != ".pm":
                    # Note that we don't allow '.pl' b/c the import
                    # mechanics won't pick those up. I suspect that the
                    # frequency of "require 'foo.pl'" is low enough that
                    # we don't need to worry about this.
                    continue
                mod_name = sans_ext.replace('/', '::')
            yield mod_name

    def _pkg_info_from_mod(self, mod):
        """Return Perl package info for this module blob.

        Returns a 2-tuple:
            (<set of imported module names>, <set of defined package names>)
        """
        key = "perl-pkg-info"
        if key not in mod.cache:
            mod_names = set(self._imported_mod_names_from_mod(mod))
            # print "%r imports: %s" % (mod, ', '.join(mod_names))

            # Perl packages can only be defined at the top-level.
            pkg_names = set(elem.get("name") for elem in mod
                            if elem.get("ilk") == "class")
            # print "%r defines: %s" % (mod, ', '.join(pkg_names))

            mod.cache[key] = (mod_names, pkg_names)
        return mod.cache[key]


#---- the tree evaluators
class CandidatesForTreeEvaluator(TreeEvaluator):
    """Candidate functionality for the base TreeEvaluator class to be
    shared by the other lang-specific TreeEvaluators.

    TODO: evaluate and move these to base class sometime after K4
    """

    _built_in_blob = None

    @property
    def built_in_blob(self):
        if self._built_in_blob is None:
            stdlib = self.buf.stdlib
            assert isinstance(stdlib, StdLib), \
                "buf.stdlib did not return a StdLib instance: %r" % stdlib
            self._built_in_blob = stdlib.get_blob("*")
        return self._built_in_blob

    def parent_scoperef_from_scoperef(self, scoperef):
        blob, lpath = scoperef
        if lpath:
            return (blob, lpath[:-1])
        elif blob is self.built_in_blob:
            return None
        else:
            return (self.built_in_blob, [])

    def _elem_from_scoperef(self, scoperef):
        """A scoperef is (<blob>, <lpath>). Return the actual elem in
        the <blob> ciElementTree being referred to.
        """
        elem = scoperef[0]
        for lname in scoperef[1]:
            elem = elem.names[lname]
        return elem

    def _tokenize_citdl_expr(self, expr):
        for tok in expr.split('.'):
            if tok.endswith('()'):
                yield tok[:-2]
                yield '()'
            else:
                yield tok

    def _join_citdl_expr(self, tokens):
        return '.'.join(tokens).replace('.()', '()')

    # The SENTINEL_MAX_EXPR_COUNT could probably be *reduced*.
    # Note: This is an approximation that we are infinitely looping
    # on the same evaluation. The *actual* appropriate key would be:
    #
    #   (expr, scoperef)
    #
    # but that is overkill for now, I think.
    _SENTINEL_MAX_EXPR_COUNT = 10
    _eval_count_from_expr = None

    def _check_infinite_recursion(self, expr):
        if self._eval_count_from_expr is None:
            # Move this init into eval() when on TreeEvalutor.
            self._eval_count_from_expr = {}
        eval_count = self._eval_count_from_expr.get(expr, 0)
        eval_count += 1
        if eval_count >= self._SENTINEL_MAX_EXPR_COUNT:
            raise EvalError("hit eval sentinel: expr '%s' eval count "
                            "is %d (abort)" % (expr, eval_count))
        self._eval_count_from_expr[expr] = eval_count


class PerlTreeEvaluatorBase(CandidatesForTreeEvaluator):
    def __init__(self, ctlr, buf, trg, expr, line, prefix_filter=None):
        CandidatesForTreeEvaluator.__init__(self, ctlr, buf, trg, expr, line)
        self.prefix_filter = prefix_filter

    def pre_eval(self):
        curr_blob = self.buf.blob_from_lang[self.trg.lang]
        self.pkg_tbl = _PerlPkgTable(curr_blob, self.buf.libs)

    def _func_members_from_pkg(self, pkg_name, pkg, _handled_pkg_names=None):
        """Return the function completions for the given Perl package
        (traversing package inheritance, if any).
        """
        # Guard against infinite recursion.
        if _handled_pkg_names is None:
            _handled_pkg_names = set()
        if pkg_name in _handled_pkg_names:
            return []
        _handled_pkg_names.add(pkg_name)

        # Get the locally defined subs.
        members = [("function", n) for n, el in pkg.names.items()
                   if el.get("ilk") == "function"]

        # Get inherited subs.
        for classref in pkg.get("classrefs", "").split():
            if classref == "Exporter":
                # Special case: skip "Exporter" base class members in
                # Perl. These are not desired 99% of the time.
                continue
            self.info("add inherited functions from %r", classref)
            classref_pkg = self.pkg_tbl.pkg_from_pkg_name(classref)
            members += self._func_members_from_pkg(classref, classref_pkg,
                                                   _handled_pkg_names)

        return members

    # Special Perl variables/subs to typically _exclude_ from completions.
    _special_names_to_skip = set([
        "$AUTOLOAD", "AUTOLOAD", "DESTROY",
        "@EXPORT", "@EXPORT_FAIL", "@EXPORT_OK", "%EXPORT_TAGS",
        "@ISA", "import", "unimport",
    ])
    _perl_var_tokenizer = re.compile(r"([$\\%&@]+)?(\w+)")

    def post_process_cplns(self, cplns):
        DEBUG = False
        if DEBUG:
            print banner("Perl post_process_cplns (before)")
            pprint(cplns)

        trg_type = self.trg.type
        if trg_type in ("package-subs", "object-subs"):
            # TODO: This may not be necessary if current evalr only
            #      generates the function.
            cplns = [c for c in cplns
                     if c[0] == "function"
                     if c[1] not in self._special_names_to_skip]
        elif trg_type == "package-members":
            if self.prefix_filter in ('', '&'):  # filter out variables
                cplns = [c for c in cplns
                         if c[0] != "variable"
                         if c[1] not in self._special_names_to_skip]
            elif self.prefix_filter in ('$', '@', '%'):  # filter out funcs
                cplns = [c for c in cplns
                         if c[0] != "function"
                         if c[1] not in self._special_names_to_skip]
            else:
                cplns = [c for c in cplns
                         if c[1] not in self._special_names_to_skip]

            # Morph type and value of variable based on the prefix.
            # For example the completions for: `$HTTP::Message::` include
            # ("variable", "$VERSION"). The actual correct completion is
            # "VERSION" (no '$'-prefix). We morph this to ("$variable",
            # "VERSION") so that:
            # 1. the proper completion will be used, and
            # 2. the different type string can be used for a custom
            #    autocomplete image.
            # Ditto for '@' and '%'.
            morphed_cplns = []
            for type, value in cplns:
                if type == "variable":
                    match = self._perl_var_tokenizer.match(value)
                    if not match:
                        self.warn("could not parse Perl var '%s': "
                                  "pattern='%s'", value,
                                  self._perl_var_tokenizer.pattern)
                        continue
                    prefix, name = match.groups()
                    if DEBUG:
                        print "tokenize perl var: %r -> %r %r"\
                              % (value, prefix, name)
                    if prefix:
                        prefix = prefix[-1]  # only last char is relevant

                    if self.prefix_filter in (None, '*', '$'):
                        # '*': pass all
                        # '$': pass all because arrays and hashes can have
                        #      a '$' prefix for subsequent indexing
                        pass
                    elif self.prefix_filter and self.prefix_filter != prefix:
                        # If the filter is '%' or '@', then filter out vars
                        # not of that persuasion.
                        continue

                    # TODO: Test cases for these and review by Perl guy.
                    if prefix in ('$', '%', '@'):
                        # Don't yet support '*' special a/c image.
                        type = prefix+type
                    value = name
                morphed_cplns.append((type, value))
            cplns = morphed_cplns

        cplns = CandidatesForTreeEvaluator.post_process_cplns(self, cplns)
        if DEBUG:
            print banner("(after)", '-')
            pprint(cplns)
            print banner(None, '-')
        return cplns


class PerlPackageMembersTreeEvaluator(PerlTreeEvaluatorBase):
    """TreeEvaluator to handle 'perl-complete-package-members'.

        [prefix]SomePackage::<|>
    """
    # TODO: Consider implementing this subtlety (if current behaviour is
    #       not pleasing):
    #   - if trigger is explicit, then don't bother ensuring package
    #     is imported: *presume* it is
    #   - if trigger is implicit, then ensure package is imported

    def eval_cplns(self):
        self.log_start()

        prefix = self.expr + "::"
        prefix_len = len(prefix)
        prefix_matches = set()
        matching_blob = None
        for blob, pkg_names in self.pkg_tbl.gen_loaded_pkgs():
            for pkg_name in pkg_names:
                if pkg_name == self.expr:
                    matching_blob = blob
                elif pkg_name.startswith(prefix):
                    prefix_match = pkg_name[prefix_len:]
                    if "::" in prefix_match:
                        prefix_match = prefix_match[:prefix_match.index("::")]
                    # self.debug("prefix match: %r -> %r", pkg_name,
                    # prefix_match)
                    prefix_matches.add(prefix_match)

        if prefix_matches:
            self.info("loaded pkg prefix matches: %r", prefix_matches)
        cplns = [("class", pm) for pm in prefix_matches]
        if matching_blob is not None:
            try:
                pkg = matching_blob.names[self.expr]
            except KeyError:
                self.warn("%s unexpectedly doesn't define package %r",
                          matching_blob, self.expr)
            else:
                self.info("pkg match for %r: %r", self.expr, pkg)
                cplns += self._members_from_pkg(self.expr, pkg)

        return cplns

    def _members_from_pkg(self, pkg_name, pkg, _handled_pkg_names=None):
        """Return the completions for the given Perl package (traversing
        package inheritance, if any).
        """
        # Guard against infinite recursion.
        if _handled_pkg_names is None:
            _handled_pkg_names = set()
        if pkg_name in _handled_pkg_names:
            return []
        _handled_pkg_names.add(pkg_name)

        # Get the locally defined members.
        members = []
        for name, elem in pkg.names.items():
            # self.debug("%r: %r", name, elem)
            if elem.tag == "variable":
                if "__local__" not in elem.get("attributes", ""):
                    members.append(("variable", name))
            else:
                members.append((elem.get("ilk"), name))

        # Note: For perl-complete-package-members, inherited package
        # members should NOT be included. See
        # test_perl.py::test_myvars_2(). (Noting this because it might
        # be surprising.)

        return members


class PerlPackageSubsTreeEvaluator(PerlTreeEvaluatorBase):
    """TreeEvaluator to handle 'perl-complete-package-subs'

        SomePackage-><|>
    """
    def eval_cplns(self):
        self.log_start()

        # First ensure that this Perl package has been loaded.
        pkg = self.pkg_tbl.pkg_from_pkg_name(self.expr)
        if pkg is None:
            self.error("Perl package %r is not loaded", self.expr)
            return None

        self.info("pkg match for %r: %r", self.expr, pkg)
        return self._func_members_from_pkg(self.expr, pkg)

    def _func_members_from_pkg(self, pkg_name, pkg, _handled_pkg_names=None):
        """Return the function completions for the given Perl package
        (traversing package inheritance, if any).
        """
        # Guard against infinite recursion.
        if _handled_pkg_names is None:
            _handled_pkg_names = set()
        if pkg_name in _handled_pkg_names:
            return []
        _handled_pkg_names.add(pkg_name)

        # Get the locally defined subs.
        members = [("function", n) for n, el in pkg.names.items()
                   if el.get("ilk") == "function"]

        # Get inherited subs.
        for classref in pkg.get("classrefs", "").split():
            if classref == "Exporter":
                # Special case: skip "Exporter" base class members in
                # Perl. These are not desired 99% of the time.
                continue
            self.info("add inherited functions from %r", classref)
            classref_pkg = self.pkg_tbl.pkg_from_pkg_name(classref)
            members += self._func_members_from_pkg(classref, classref_pkg,
                                                   _handled_pkg_names)

        return members


class PerlTreeEvaluator(PerlTreeEvaluatorBase):
    """TreeEvaluator to handle the following triggers:

        perl-calltip-space-call-signature   "open <|>"
        perl-calltip-call-signature         "some_func(<|>"
        perl-complete-object-subs           "$foo-><|>"

    TODO: perl-defn-defn
    """
    def __init__(self, ctlr, buf, trg, expr, line, prefix_filter=None):
        PerlTreeEvaluatorBase.__init__(self, ctlr, buf, trg, expr, line)
        self.prefix_filter = prefix_filter

    def eval_cplns(self):
        self.log_start()
        start_scoperef = self.get_start_scoperef()
        self.info("start scope is %r", start_scoperef)
        hit = self._hit_from_citdl(self.expr, start_scoperef)

        elem, scoperef = hit
        if not (elem.tag == "scope" and elem.get("ilk") == "class"):
            perl_type = self._perl_type_from_elem(elem)
            self.error("cannot get completions from a Perl %s: '%s' is "
                       "<%s %s> (expected a Perl package element)",
                       perl_type, self.expr, perl_type, elem.get("name"))
            return None
        return self._func_members_from_pkg(elem.get("name"), elem)

    def eval_calltips(self):
        self.log_start()
        start_scoperef = self.get_start_scoperef()
        self.info("start scope is %r", start_scoperef)
        elem, scoperef = self._hit_from_citdl(self.expr, start_scoperef)
        if not (elem.tag == "scope" and elem.get("ilk") == "function"):
            perl_type = self._perl_type_from_elem(elem)
            self.error("cannot call a Perl %s: '%s' is <%s %s>",
                       perl_type, self.expr, perl_type, elem.get("name"))
            return None
        return [self._calltip_from_func(elem)]

    def eval_defns(self):
        self.log_start()
        start_scoperef = self.get_start_scoperef()
        self.info("start scope is %r", start_scoperef)
        hit = self._hit_from_citdl(self.expr, start_scoperef, defn_only=True)
        elem, (blob, lpath) = hit
        # Bug 99113 - Unlike all the other languages, the Perl scoperef
        # contains the item we're trying to resolve, so drop it.
        fixed_hit = (elem, (blob, lpath[:-1]))
        return [self._defn_from_hit(fixed_hit)]

    def _perl_type_from_elem(self, elem):
        if elem.tag == "scope":
            ilk = elem.get("ilk")
            return {"function": "sub",
                    "class": "package",
                    "blob": "module"}.get(ilk, ilk)
        else:
            return "variable"

    def _calltip_from_func(self, elem):
        # See "Determining a Function CallTip" in the spec for a
        # discussion of this algorithm.
        signature = elem.get("signature")
        if not signature:
            ctlines = [elem.get("name") + "(...)"]
        else:
            ctlines = signature.splitlines(0)
        doc = elem.get("doc")
        if doc:
            ctlines += doc.splitlines(0)
        return '\n'.join(ctlines)

    def _hit_from_citdl(self, expr, scoperef, defn_only=False):
        """Resolve the given CITDL expression (starting at the given
        scope) down to a non-import/non-variable hit: i.e. down to a
        function or class (a.k.a., Perl package).
        """
        self._check_infinite_recursion(expr)

        tokens = list(self._tokenize_citdl_expr(expr))
        # self.debug("expr tokens: %r", tokens)

        # First part...
        first_token = tokens.pop(0)
        hit = self._hit_from_first_part(first_token, scoperef)
        if not hit:
            raise CodeIntelError("could not resolve '%s'" % first_token)
        # self.debug("_hit_from_citdl: first part: %r -> %r", first_token, hit)

        # ...remaining parts.
        while tokens:
            token = tokens.pop(0)
            if token == "()":
                raise CodeIntelError("eval of Perl function calls not yet "
                                     "implemented: %r" % expr)
            self.info("lookup '%s' on %r in %r", token, *hit)
            # TODO: Should we catch CodeIntelError, self.error() and
            #      return None?
            hit = self._hit_from_getattr(token, *hit)
        if tokens:
            raise CodeIntelError("multi-part Perl CITDL expr '%s' cannot "
                                 "yet be handled" % expr)

        # Resolve any variable type inferences.
        elem, scoperef = hit
        if elem.tag == "variable" and not defn_only:
            hit = self._hit_from_variable_type_inference(elem, scoperef)

        self.info("'%s' is %s on %s", expr, *hit)
        return hit

    def _hit_from_first_part(self, first_token, scoperef):
        """Find a hit for the first part of the tokens.

        Returns a <hit> or None if could not resolve.

        Examples:
            '$ua'    -> <variable '$ua'>,
                        (<blob 'myscript'>, [])
            'Dumper' -> <function 'Dumper'>,
                        (<blob 'Data::Dumper'>, ['Data::Dumper'])
            'Data::Dumper' ->
                        <class 'Data::Dumper'>,
                        (<blob 'Data::Dumper'>, [])
        """
        # self.log("find '%s' starting at %s:", first_token, scoperef)
        while 1:
            elem = self._elem_from_scoperef(scoperef)
            if first_token in elem.names:
                # TODO: skip __hidden__ names
                self.log("is '%s' accessible on %s? yes: %s",
                         first_token, scoperef, elem.names[first_token])
                scoperef[1].append(first_token)
                return elem.names[first_token], scoperef

            if "::" not in first_token:
                hit = self._hit_from_elem_imports(first_token, elem)
                if hit is not None:
                    self.log("is '%s' accessible on %s? yes: %s",
                             first_token, scoperef, hit[0])
                    return hit

            mod, pkg = self.pkg_tbl.mod_and_pkg_from_pkg_name(first_token)
            if mod is not None:
                self.log("is '%s' accessible on %s? yes: %s",
                         first_token, scoperef, pkg)
                return (pkg, (mod, [first_token]))

            self.log("is '%s' accessible on %s? no", first_token, scoperef)
            scoperef = self.parent_scoperef_from_scoperef(scoperef)
            if not scoperef:
                return None

    def _hit_from_getattr(self, token, elem, scoperef):
        """Return a hit for a getattr on the given element.

        Returns <hit> or raises CodeIntelError if cannot resolve.
        """
        if elem.tag == "variable":
            elem_is_var_on_entry = True
            elem, scoperef = self._hit_from_variable_type_inference(
                elem, scoperef)
        else:
            elem_is_var_on_entry = False

        assert elem.tag == "scope"
        ilk = elem.get("ilk")
        if ilk == "class":  # i.e. a Perl package
            attr = elem.names.get(token)
            if attr is not None:
                return attr, (scoperef[0], scoperef[1] + [token])

            # To inherit or not to inherit
            # ============================
            #
            # Both of the following get here:
            #   $ua->foo();              lookup "foo" on LWP::UserAgent
            #   Data::Dumper::Dumper();  lookup "Dumper" on Data::Dumper
            # However, only the former should include inherited methods.
            #
            # I *believe* we can tell the difference based on whether
            # 'elem' (on entry to this function) is a variable. If it is
            # a variable then this is the former case.
            #
            # Note that we cannot use the trigger type to determine this
            # because this could be part of eval of
            # "perl-calltip-call-signature" for both:
            #   $ua->foo(<|>);
            #   Data::Dumper::Dumper(<|>);
            if elem_is_var_on_entry:
                # Look on inherited packages (test 'perl/cpln/lwp'
                # tests for multi-level inheritance).
                for base_mod, base_pkg \
                        in self._inherited_mods_and_pkgs_from_pkg(elem):
                    attr = base_pkg.names.get(token)
                    if attr is not None:
                        return attr, (base_mod, [base_pkg.get("name")])

        elif ilk == "blob":  # i.e. a Perl module
            raise CodeIntelError("didn't expect a getattr on a Perl "
                                 "module: %r on %r" % (token, elem))
            # attr = elem.names.get(first_token)
            # if attr is not None:
            #    self.log("attr is %r in %r", attr, elem)
            #    return attr, scoperef

        elif ilk == "function":
            raise CodeIntelError("cannot get attributes of a "
                                 "function: %r on %r" % (token, elem))

        else:
            raise NotImplementedError("unexpected scope ilk: %r" % ilk)

        raise CodeIntelError("could not resolve '%s' attr on %s"
                             % (token, elem))

    def _inherited_mods_and_pkgs_from_pkg(self, pkg, _handled_pkg_names=None):
        """Generate the inherited packages of the given package.

        Yields (mod, pkg) 2-tuples. The "Exporter" package is skipped.
        """
        pkg_name = pkg.get("name")

        # Guard against infinite recursion.
        if _handled_pkg_names is None:
            _handled_pkg_names = set()
        if pkg_name not in _handled_pkg_names:
            _handled_pkg_names.add(pkg_name)

            for classref in pkg.get("classrefs", "").split():
                if classref == "Exporter":
                    # Special case: skip "Exporter" base class members in
                    # Perl. These are not desired 99% of the time.
                    continue
                classref_mod, classref_pkg \
                    = self.pkg_tbl.mod_and_pkg_from_pkg_name(classref)
                if classref_pkg is None:
                    continue
                yield (classref_mod, classref_pkg)
                for item in self._inherited_mods_and_pkgs_from_pkg(
                        classref_pkg, _handled_pkg_names):
                    yield item

    def _hit_from_elem_imports(self, token, elem):
        """See if token is from one of the imports on this <scope> elem.

        Returns <hit> or None if not found.
        """
        for imp_elem in (i for i in elem if i.tag == "import"):
            # Note: Perl <import> elements never use 'alias'.
            symbol_name = imp_elem.get("symbol")
            module_name = imp_elem.get("module")
            assert module_name, \
                "bogus Perl <import> without module name: %r" % imp_elem

            if not symbol_name:
                # use Foo ();           <import module="Foo"/>
                # require $blah;        <import module="$blah"/>
                # require '$foo.pm';    <import module="'$foo.pm'"/>
                # require 'MyFoo.pm';   <import module="'MyFoo.pm'"/>
                # require "MyBar.pm";   <import module="&quot;MyBar.pm&quot;"/>
                pass

            elif symbol_name == token:
                # use Foo qw(a);        <import module="Foo" symbol="a"/>
                mod, pkg = self.pkg_tbl.mod_and_pkg_from_pkg_name(module_name)
                if mod is not None:
                    elem = pkg.names.get(token)
                    if elem is not None:
                        # TODO: Should we exclude this if not in
                        #      @EXPORT_OK?
                        self.debug("is '%s' from %r? yes: %s",
                                   token, imp_elem, elem)
                        return (elem, (mod, [module_name]))

            elif symbol_name == "*":
                # use Foo;              <import module="Foo" symbol="*"/>
                mod, pkg = self.pkg_tbl.mod_and_pkg_from_pkg_name(module_name)
                if mod is not None:
                    elem = pkg.names.get(token)
                    if elem is not None \
                       and "__exported__" in elem.get("attributes", ""):
                        self.debug("is '%s' from %r? yes: %s",
                                   token, imp_elem, elem)
                        return (elem, (mod, [module_name]))

            elif symbol_name == "**":
                # use Foo qw(:key);     <import module="Foo" symbol="**"/>
                mod, pkg = self.pkg_tbl.mod_and_pkg_from_pkg_name(module_name)
                if mod is not None:
                    elem = pkg.names.get(token)
                    # "__exported__" attribute means in @EXPORT
                    # "__exportable__" attribute means in @EXPORT_OK
                    if elem is not None \
                       and "__export" in elem.get("attributes", ""):
                        self.debug("is '%s' from %r? yes: %s",
                                   token, imp_elem, elem)
                        return (elem, (mod, [module_name]))

            self.debug("is '%s' from %r? no", token, imp_elem)
        return None

    def _hit_from_variable_type_inference(self, elem, scoperef):
        """Resolve the type inference for the given element."""
        # TODO:PERF: Consider cheating here with the knowledge that the
        #           current perlcile (the one as of Komodo 4.0.0) never
        #           emits anything except a package name for a type
        #           inference.
        citdl = elem.get("citdl")
        if not citdl:
            raise CodeIntelError("no type-inference info for %r" % elem)
        self.info("resolve '%s' type inference for %r:", citdl, elem)
        return self._hit_from_citdl(citdl, scoperef)

    def _hit_from_type_inference(self, citdl, scoperef):
        """Resolve the 'citdl' type inference at 'scoperef'."""
        # TODO:PERF: Consider cheating here with the knowledge that the
        #           current perlcile (the one as of Komodo 4.0.0) never
        #           emits anything except a package name for a type
        #           inference.
        self.info("resolve '%s' type inference:", citdl)
        return self._hit_from_citdl(citdl, scoperef)

########NEW FILE########
__FILENAME__ = tree_php
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Completion evaluation code for PHP"""

from codeintel2.common import *
from codeintel2.tree import TreeEvaluator
from codeintel2.util import make_short_name_dict, banner


php_magic_global_method_data = {
    "__autoload": "__autoload(string $className)\n"
    "This function is automatically called when a class\n"
    "is being called, but which hasn't been defined yet.",
}
php_magic_class_method_data = {
    "__construct": "__construct([mixed $args [, $...]])\n"
    "Initializes a newly created class instance.\n"
    "Note: parent constructors will need to be implictly\n"
    "called.",
    "__destruct": "__destruct()\n"
    "This function is called when all references to this\n"
    "particular class instance are removed or when the\n"
    "object is explicitly destroyed.\n"
    "Note: parent destructors will need to be implictly\n"
    "called.",
    "__call": "__call(string $name, array $arguments) -> mixed\n"
    "Is triggered when your class instance (and inherited\n"
    "classes) does not contain the method name.",
    "__callStatic": "__callStatic(string $name, array $arguments) -> mixed\n"
                    "Is triggered when your class is accessed statically\n"
                    "and it does not contain the method name.",
    "__get": "__get(string $name) -> mixed\n"
                    "Is triggered when your class instance (and inherited\n"
                    "classes) does not contain the member or method name.",
    "__set": "__set(string $name, mixed $value)\n"
                    "Is triggered when your class instance (and inherited\n"
                    "classes) does not contain the member or method name.",
    "__isset": "__isset(string $name) -> bool\n"
                    "Overload the isset function for the class instance.",
    "__unset": "__unset(string $name)\n"
                    "Overload the unset function for the class instance.",
    "__sleep": "__sleep() -> array\n"
                    "Called through serialize in order to generate a\n"
                    "storable representation of a class instance. Returns\n"
                    "an array of the variable names that need to\n"
                    "be stored.",
    "__wakeup": "__wakeup()\n"
                    "Called through unserialize after restoring a\n"
                    "a class instance with it's serialized values.",
    "__toString": "__toString() -> string\n"
                    "Returns a string representation of the class instance.",
    "__set_state": "__set_state(array $properties)\n"
                    "Static method that is called to restore a class\n"
                    "instance's state that was previously exported\n"
                    "using the var_export() function. Properties are\n"
                    "in the form array('property' => value, ...).",
    "__clone": "__clone()\n"
                    "When the class instance is cloned using the\n"
                    "clone($object) function call, a new class instance\n"
                    "is created with shallow copies of all $object's\n"
                    "values. This function is then called after to allow\n"
                    "the new instance to update any of these values.",
}
php_keyword_calltip_data = {
    "array": "array(<list>)\n"
    "Create a PHP array.",
    "declare": "declare(directive)\n"
    "Set execution directives for a block of code.\n",
    "echo": "echo($arg1 [, $arg2... ])\n"
    "Output one or more strings.",
    "eval": "eval($code) => mixed\n"
    "Evaluate the $code string as PHP code.",
    "exit": "exit($status)\n"
    "$status can be either a string or an int.\n"
    "Outputs $status and then terminates the current script.\n"
    "If status is an integer, that value will also be used as\n"
    "the exit status. Exit statuses should be in the range 0\n"
    "to 254, the exit status 255 is reserved by PHP and shall\n"
    "not be used. The status 0 is used to terminate the\n"
    "program successfully. PHP >= 4.2.0 does NOT print the\n"
    "status if it is an integer.",
    "include": "include(file_path)\n"
    "Includes and evaluates the specified file, produces a\n"
    "Fatal Error on error.",
    "include_once": "include_once(file_path)\n"
                    "Includes and evaluates the specified file if it hasn't\n"
                    "been included before, produces a Fatal Error on error.",
    "print": "print($arg)\n"
                    "Output the $arg string.",
    "require": "require(file_path)\n"
                    "Includes and evaluates the specified file, produces a\n"
                    "Fatal Error on error.",
    "require_once": "require_once(file_path)\n"
                    "Includes and evaluates the specified file if it hasn't\n"
                    "been included before, produces a Fatal Error on error.",
}


class PHPTreeEvaluator(TreeEvaluator):
    """
    scoperef: (<blob>, <lpath>) where <lpath> is list of names
        self._elem_from_scoperef()
    hit: (<elem>, <scoperef>)
    """

    # Calltips with this expression value are ignored. See bug:
    # http://bugs.activestate.com/show_bug.cgi?id=61497
    php_ignored_calltip_expressions = ("if", "elseif",
                                       "for", "foreach",
                                       "while",
                                       "switch",
                                       )

    php_magic_global_method_cplns = [("function", name) for name in
                                     sorted(php_magic_global_method_data.keys())]
    # Classes can use both global and class specific functions.
    php_magic_class_method_cplns = [("function", name) for name in
                                    sorted(php_magic_class_method_data.keys())]

    # A variable used to track the recursion depth of _hit_from_citdl().
    eval_depth = 0

    # TODO: candidate for base TreeEvaluator class
    _langintel = None

    @property
    def langintel(self):
        if self._langintel is None:
            self._langintel = self.mgr.langintel_from_lang(self.trg.lang)
        return self._langintel

    # TODO: candidate for base TreeEvaluator class
    _libs = None

    @property
    def libs(self):
        if self._libs is None:
            self._libs = self.langintel.libs_from_buf(self.buf)
        return self._libs

    def get_next_scoperef(self, scoperef):
        blob, lpath = scoperef
        elem = self._elem_from_scoperef(scoperef)
        linenum = self.line + 1  # convert to 1-based
        for subelem in elem.getchildren():
            start = int(subelem.get("line"))
            if start > linenum:
                if subelem.tag == "scope":
                    lpath.append(subelem.get("name"))
                break
        return (blob, lpath)

    # Un-comment for an indented log record, each indented level will represent
    # a layer of recursion - which is quite useful for debugging.
    # def log_start(self):
    #    TreeEvaluator.log_start(self)
    #    self.eval_depth = 0
    # def debug(self, msg, *args):
    #    msg = '  ' * self.eval_depth + msg
    #    TreeEvaluator.debug(self, msg, *args)
    # def info(self, msg, *args):
    #    msg = '  ' * self.eval_depth + msg
    #    TreeEvaluator.info(self, msg, *args)

    def eval_cplns(self):
        self.log_start()
        self._imported_blobs = {}
        start_scope = self.get_start_scoperef()
        trg = self.trg
        if trg.type == "variables":
            return self._variables_from_scope(self.expr, start_scope)
        elif trg.type == "comment-variables":
            next_scope = self.get_next_scoperef(start_scope)
            return self._comment_variables_from_scope(self.expr, next_scope)
        elif trg.type == "functions":
            # The 3-character trigger, which not actually specific to
            # functions.
            retval = self._keywords_from_scope(self.expr, start_scope) + \
                self._functions_from_scope(self.expr, start_scope) + \
                self._constants_from_scope(self.expr, start_scope) + \
                self._classes_from_scope(self.expr[:3], start_scope) + \
                self._imported_namespaces_from_scope(
                    self.expr, start_scope)
            # if self.ctlr.is_aborted():
            #    return None
            return retval
        elif trg.type == "classes":
            return self._classes_from_scope(None, start_scope) + \
                self._imported_namespaces_from_scope(None, start_scope)
        elif trg.type == "use":
            # When inside of a trait or a class - return trait completions, else
            # look for namespace completions.
            global_scoperef = self._get_global_scoperef(start_scope)
            elem = self._elem_from_scoperef(start_scope)
            if elem.get("ilk") in ("class", "trait"):
                return self._traits_from_scope(None, global_scoperef)
            else:
                # All available namespaces and all available/global classes.
                return self._namespaces_from_scope(None, start_scope) + \
                    self._classes_from_scope(None, global_scoperef,
                                             allowGlobalClasses=True)
        elif trg.type == "namespace-members" and (not self.expr or self.expr == "\\"):
            # All available namespaces and include all available global
            # functions/classes/constants as well.
            global_scoperef = self._get_global_scoperef(start_scope)
            cplns = self._namespaces_from_scope(self.expr, start_scope)
            cplns += self._functions_from_scope(None, global_scoperef)
            cplns += self._constants_from_scope(None, global_scoperef)
            cplns += self._classes_from_scope(None, global_scoperef)
            return cplns
        elif trg.type == "interfaces":
            return self._interfaces_from_scope(self.expr, start_scope) + \
                self._imported_namespaces_from_scope(self.expr, start_scope)
        elif trg.type == "magic-methods":
            elem = self._elem_from_scoperef(start_scope)
            if elem.get("ilk") == "function":
                # Use the parent for our check.
                blob, lpath = start_scope
                if len(lpath) > 1:
                    elem = self._elem_from_scoperef((blob, lpath[:-1]))
            if elem.get("ilk") in ("class", "trait"):
                # All looks good, return the magic class methods.
                return self.php_magic_class_method_cplns
            else:
                # Return global magic methods.
                return self.php_magic_global_method_cplns
        elif trg.type == "namespace-members" or \
                trg.type == "use-namespace":
            # Find the completions:
            cplns = []
            expr = self.expr
            if trg.type == "use-namespace" and expr and not expr.startswith("\\"):
                # Importing a namespace, uses a FQN name - bug 88736.
                expr = "\\" + expr
            fqn = self._fqn_for_expression(expr, start_scope)
            hits = self._hits_from_namespace(fqn, start_scope)
            if hits:
                # self.log("self.expr: %r", self.expr)
                # self.log("hits: %r", hits)
                cplns = list(self._members_from_hits(hits))
                # self.log("cplns: %r", cplns)
            # Return additional sub-namespaces that start with this prefix.
            if hits and hits[0][0] is not None:
                # We hit a namespace, return additional namespaces that
                # start with the hit's fully qualified name (fqn).
                fqn = hits[0][0].get("name")

            self.debug("eval_cplns:: adding namespace hits that start with "
                       "fqn: %r", fqn)
            namespaces = self._namespaces_from_scope(fqn, start_scope)
            # self.log("namespaces: %r", namespaces)
            for ilk, n in namespaces:
                namespace = n[len(fqn):]
                if namespace and namespace.startswith("\\"):
                    cplns.append((ilk, namespace.strip("\\")))
            return cplns
        else:
            hit = self._hit_from_citdl(self.expr, start_scope)
            if hit[0] is not None:
                self.log("self.expr: %r", self.expr)
                # special handling for parent, explicitly set the
                # protected and private member access for this case
                if self.expr == "parent" or \
                   self.expr.startswith("parent."):
                    self.log("Allowing protected parent members")
                    return list(
                        self._members_from_hit(hit, allowProtected=True,
                                               allowPrivate=False))
                elif self.trg.type == "array-members":
                    return list(self._members_from_array_hit(hit, self.trg.extra.get('trg_char')))
                else:
                    return list(self._members_from_hit(hit))

    def eval_calltips(self):
        self.log_start()
        self._imported_blobs = {}
        start_scope = self.get_start_scoperef()
        # Ignore doing a lookup on certain expressions
        # XXX - TODO: Might be better to do this in trg_from_pos.
        expr = self.expr
        if expr in self.php_ignored_calltip_expressions:
            return None
        elif expr in php_keyword_calltip_data:
            return [php_keyword_calltip_data.get(expr)]
        # XXX - Check the php version, magic methods only appeared in php 5.
        elif expr in php_magic_class_method_data:
            elem = self._elem_from_scoperef(start_scope)
            if elem.get("ilk") == "function":
                # Use the parent for our check.
                blob, lpath = start_scope
                if len(lpath) > 1:
                    elem = self._elem_from_scoperef((blob, lpath[:-1]))
            if elem.get("ilk") in ("class", "trait"):
                # Use the class magic methods.
                return [php_magic_class_method_data[expr]]
            # Else, let the tree work it out.
        elif expr in php_magic_global_method_data:
            elem = self._elem_from_scoperef(start_scope)
            if elem.get("ilk") == "function":
                # Check the parent is not a class. See:
                # http://bugs.activestate.com/show_bug.cgi?id=69758
                blob, lpath = start_scope
                if len(lpath) > 1:
                    elem = self._elem_from_scoperef((blob, lpath[:-1]))
            if elem.get("ilk") in ("class", "trait"):
                # Not available inside a class.
                return []
            return [php_magic_global_method_data[expr]]
        hit = self._hit_from_citdl(expr, start_scope)
        return self._calltips_from_hit(hit)

    def eval_defns(self):
        self.log_start()
        self._imported_blobs = {}
        start_scoperef = self.get_start_scoperef()
        self.info("start scope is %r", start_scoperef)

        hit = self._hit_from_citdl(self.expr, start_scoperef, defn_only=True)
        return [self._defn_from_hit(hit)]

    # Determine if the hit is valid
    def _return_with_hit(self, hit, nconsumed):
        # Added special attribute __not_yet_defined__ to the PHP ciler,
        # this is used to indicate the variable was made but is not yet
        # assigned a type, i.e. it's not yet defined.
        elem, scoperef = hit
        attributes = elem.get("attributes")
        if attributes:
            attr_split = attributes.split(" ")
            if "__not_yet_defined__" in attr_split:
                self.log(
                    "_return_with_hit:: hit was a not_yet_defined, ignoring it: %r", hit)
                return False
        self.log("_return_with_hit:: hit is okay: %r", hit)
        return True

    def _element_names_from_scope_starting_with_expr(self, expr, scoperef,
                                                     elem_type, scope_names,
                                                     elem_retriever):
        """Return all available elem_type names beginning with expr"""
        self.log(
            "%s_names_from_scope_starting_with_expr:: expr: %r, scoperef: %r for %r",
            elem_type, expr, scoperef, scope_names)
        global_blob = self._elem_from_scoperef(
            self._get_global_scoperef(scoperef))
        # Get all of the imports

        # Start making the list of names
        all_names = set()
        for scope_type in scope_names:
            elemlist = []
            if scope_type == "locals":
                elemlist = [self._elem_from_scoperef(scoperef)]
            elif scope_type == "globals":
                elemlist = [global_blob]
            elif scope_type == "namespace":
                elemlist = []
                namespace = self._namespace_elem_from_scoperef(scoperef)
                if namespace is not None:
                    elemlist.append(namespace)
                    # Note: This namespace may occur across multiple files, so we
                    # iterate over all known libs that use this namespace.
                    fqn = namespace.get("name")
                    lpath = (fqn, )
                    for lib in self.libs:
                        hits = lib.hits_from_lpath(lpath, self.ctlr,
                                                   curr_buf=self.buf)
                        elemlist += [elem for elem, scoperef in hits]
            elif scope_type == "builtins":
                lib = self.buf.stdlib
                # Find the matching names (or all names if no expr)
                # log.debug("Include builtins: elem_type: %s", elem_type)
                names = lib.toplevel_cplns(prefix=expr, ilk=elem_type)
                all_names.update([n for ilk, n in names])
            # "Include everything" includes the builtins already
            elif scope_type == "imports":
                # Iterate over all known libs
                for lib in self.libs:
                    # Find the matching names (or all names if no expr)
                    # log.debug("Include everything: elem_type: %s", elem_type)
                    names = lib.toplevel_cplns(prefix=expr, ilk=elem_type)
                    all_names.update([n for ilk, n in names])
                # Standard imports, specified through normal import semantics
                elemlist = self._get_all_import_blobs_for_elem(global_blob)
            for elem in elemlist:
                names = elem_retriever(elem)
                if expr:
                    if isinstance(names, dict):
                        try:
                            names = names[expr]
                        except KeyError:
                            # Nothing in the dict matches, thats okay
                            names = []
                    else:
                        # Iterate over the names and keep the ones containing
                        # the given prefix.
                        names = [x for x in names if x.startswith(expr)]
                self.log(
                    "%s_names_from_scope_starting_with_expr:: adding %s: %r",
                    elem_type, scope_type, names)
                all_names.update(names)
        return self._convertListToCitdl(elem_type, all_names)

    def _variables_from_scope(self, expr, scoperef):
        """Return all available variable names beginning with expr"""
        # The current scope determines what is visible, see bug:
        #   http://bugs.activestate.com/show_bug.cgi?id=65159
        vars = []
        blob, lpath = scoperef
        if len(lpath) > 0:
            # Inside a function or class, don't get to see globals
            scope_chain = ("locals", "builtins", )
            if len(lpath) > 1:
                # Current scope is inside a class function?
                elem = self._elem_from_scoperef(scoperef)
                if elem is not None and elem.get("ilk") == "function":
                    p_elem = self._elem_from_scoperef((blob, lpath[:-1]))
                    if p_elem is not None and p_elem.get("ilk") == "class":
                        # Include "$this" in the completions.
                        vars = [("variable", "this")]
        else:
            # Already global scope, so get to see them all
            scope_chain = ("locals", "globals", "imports", )
        # XXX - TODO: Move to 3 char trigger (if we want/need to)
        vars += self._element_names_from_scope_starting_with_expr(None,
                                                                  scoperef,
                                                                  "variable",
                                                                  scope_chain,
                                                                  self.variable_names_from_elem)
        if expr:
            # XXX - TODO: Use VARIABLE_TRIGGER_LEN instead of hard coding 1
            expr = expr[:1]
            return [(ilk, name) for ilk, name in vars if name.startswith(expr)]
        else:
            return [(ilk, name) for ilk, name in vars]

    def _comment_variables_from_scope(self, expr, scoperef):
        """Return all available local variable names beginning with expr"""
        blob, lpath = scoperef
        # Only care about the local variables.
        scope_chain = ("locals", )
        vars = self._element_names_from_scope_starting_with_expr(None,
                                                                 scoperef,
                                                                 "variable",
                                                                 scope_chain,
                                                                 self.variable_names_from_elem)
        # XXX - TODO: Use VARIABLE_TRIGGER_LEN instead of hard coding 1
        expr = expr[:1]
        return [(ilk, name) for ilk, name in vars if name.startswith(expr)]

    def _constants_from_scope(self, expr, scoperef):
        """Return all available constant names beginning with expr"""
        # XXX - TODO: Use FUNCTION_TRIGGER_LEN instead of hard coding 3
        return self._element_names_from_scope_starting_with_expr(
            expr and expr[:3] or None,
            scoperef,
            "constant",
            ("globals", "imports", "builtins"),
            self.constant_shortnames_from_elem)

    def _keywords_from_scope(self, expr, scoperef):
        """Return all available keyword names beginning with expr"""
        keyword_completions = []
        keywords = self.langintel.langinfo.keywords
        expr = expr and expr[:3]
        for name in keywords:
            if not expr or name.startswith(expr):
                keyword_completions.append(("keyword", name))
        return keyword_completions

    def _functions_from_scope(self, expr, scoperef):
        """Return all available function names beginning with expr"""
        # XXX - TODO: Use FUNCTION_TRIGGER_LEN instead of hard coding 3
        return self._element_names_from_scope_starting_with_expr(
            expr and expr[:3] or None,
            scoperef,
            "function",
            ("locals", "namespace", "globals", "imports",),
            self.function_shortnames_from_elem)

    def _classes_from_scope(self, expr, scoperef, allowGlobalClasses=False):
        """Return all available class names beginning with expr"""
        lookup_scopes = ("locals", "namespace", "globals", "imports",)
        if not allowGlobalClasses and self._namespace_elem_from_scoperef(scoperef):
            # When inside a namespace, don't include global classes - bug
            # 83192.
            lookup_scopes = ("locals", "namespace",)
        return self._element_names_from_scope_starting_with_expr(expr,
                                                                 scoperef,
                                                                 "class",
                                                                 lookup_scopes,
                                                                 self.class_names_from_elem)

    def _traits_from_scope(self, expr, scoperef, allowGlobalClasses=False):
        """Return all available class names beginning with expr"""
        return self._element_names_from_scope_starting_with_expr(expr,
                                                                 scoperef,
                                                                 "trait",
                                                                ("globals", ),
                                                                 self.trait_names_from_elem)

    def _imported_namespaces_from_scope(self, expr, scoperef):
        """Return all available class names beginning with expr"""
        return self._element_names_from_scope_starting_with_expr(expr,
                                                                 scoperef,
                                                                 "namespace",
                                                                ("namespace",
                                                                 "globals"),
                                                                 self.imported_namespace_names_from_elem)

    def _namespaces_from_scope(self, expr, scoperef):
        """Return all available namespaces beginning with expr"""
        if expr:
            expr = expr.strip("\\")
        namespaces = self._element_names_from_scope_starting_with_expr(expr,
                                                                       scoperef,
                                                                       "namespace",
                                                                      ("globals", "imports",
                                                                       "builtins",),
                                                                      self.namespace_names_from_elem)
        # We only want to see the next sub-namespace, i.e. if the expr is
        #   \mynamespace\<|>
        # then only return the immediate child namespaces, such as:
        #   \mynamespace\foo
        # but not any deeper, i.e. not:
        #   \mynamespace\foo\bar
        if expr:
            namespace_depth = expr.count("\\") + 2
        else:
            namespace_depth = 1
        filtered_namespaces = set()
        for ilk, n in namespaces:
            s = n.split("\\")
            filtered_namespaces.add((ilk, "\\".join(s[:namespace_depth])))
        return list(filtered_namespaces)

    def _interfaces_from_scope(self, expr, scoperef):
        """Return all available interface names beginning with expr"""
        # Need to work from the global scope for this one
        return self._element_names_from_scope_starting_with_expr(expr or None,
                            scoperef,
                            "interface",
                            ("namespace", "globals", "imports",),
                            self.interface_names_from_elem)

    # c.f. tree_python.py::PythonTreeEvaluator

    def _calltips_from_hit(self, hit):
        # TODO: compare with CitadelEvaluator._getSymbolCallTips()
        elem, scoperef = hit
        calltips = []
        if elem.tag == "variable":
            XXX
        elif elem.tag == "scope":
            ilk = elem.get("ilk")
            if ilk == "function":
                calltips.append(self._calltip_from_func(elem, scoperef))
            elif ilk == "class":
                calltips.append(self._calltip_from_class(elem, scoperef))
            else:
                raise NotImplementedError("unexpected scope ilk for "
                                          "calltip hit: %r" % elem)
        elif elem.tag == "alias":
            # Find the resolving function to get the signature, then we replace
            # the function name in the signature with the aliased name.
            funcelem, scoperef = self._hit_from_variable_type_inference(
                elem, scoperef)
            ctip = self._calltip_from_func(funcelem, scoperef)
            ctip = ctip.replace(funcelem.get("name"), elem.get("name"), 1)
            calltips.append(ctip)
        else:
            raise NotImplementedError("unexpected elem for calltip "
                                      "hit: %r" % elem)
        return calltips

    def _calltip_from_class(self, node, scoperef):
        # If the class has a defined signature then use that.
        signature = node.get("signature")
        doc = node.get("doc")
        if signature:
            ctlines = signature.splitlines(0)
            if doc:
                ctlines += doc.splitlines(0)
            return '\n'.join(ctlines)

        # Alternatively we use calltip information on the class'
        # constructor. PHP does not automatically inherit class contructors,
        # so we just return the one on the current class.
        else:
            # In PHP5 our CIX classes may have a special constructor function
            # with the name "__construct".
            ctor = node.names.get("__construct")
            if ctor is not None:
                self.log("_calltip_from_class:: ctor is %r", ctor)
                return self._calltip_from_func(ctor, scoperef)
            # In PHP4 the contructor is a function that has the same name as
            # the class name.
            name = node.get("name")
            ctor = node.names.get(name)
            if ctor is not None:
                self.log("_calltip_from_class:: ctor is %r", ctor)
                return self._calltip_from_func(ctor, scoperef)

            self.log("_calltip_from_class:: no ctor in class %r", name)

            # See if there is a parent class that has a constructor - bug
            # 90156.
            for classref in node.get("classrefs", "").split():
                # TODO: update _hit_from_citdl to accept optional node type,
                #      i.e. to only return classes in this case.
                self.log("_calltip_from_class:: looking for parent class: %r",
                         classref)
                base_elem, base_scoperef \
                    = self._hit_from_citdl(classref, scoperef)
                if base_elem is not None and base_elem.get("ilk") == "class":
                    return self._calltip_from_class(base_elem, base_scoperef)
                else:
                    self.log("_calltip_from_class:: no parent class found: %r",
                             base_elem)

            return "%s()" % (name)

    def _members_from_array_hit(self, hit, trg_char):
        """Retrieve members from the given array element.

        @param hit {tuple} (elem, scoperef)
        @param trg_char {string}  The character that triggered the event.
        """
        self.log("_members_from_array_hit:: %r", hit)
        elem, scoperef = hit
        members = set()
        for child in elem:
            # Should look like:  SERVER_NAME']
            members.add((child.get("ilk") or child.tag,
                          #"%s%s]" % (child.get("name"), trg_char)) )
                          child.get("name")))
        return members

    def _members_from_elem(self, elem, name_prefix=''):
        """Return the appropriate set of autocomplete completions for
        the given element. Typically this is just one, but can be more for
        '*'-imports
        """
        members = set()
        tag = elem.tag
        if tag == "import":
            module_name = elem.get("module")
            cpln_name = module_name.split('.', 1)[0]
            members.add(("module", cpln_name))
        elif tag == "alias":
            members.add(("function",
                          name_prefix + elem.get("name")))
        else:
            members.add((elem.get("ilk") or tag,
                          name_prefix + elem.get("name")))
        return members

    def _isElemInsideScoperef(self, elem, scoperef):
        blob, lpath = scoperef
        i = 0
        # self.log("_isElemInsideScoperef, elem: %r, lpath: %r", elem, lpath)
        for i in range(len(lpath)):
            name = lpath[i]
            if name == elem.get("name"):
                # XXX - It would be nice to confirm that this element is the
                #       actual elem, but this won't work correctly when there
                #       is an alternative match being used. i.e.
                #       http://bugs.activestate.com/show_bug.cgi?id=70015
                # check_elem = self._elem_from_scoperef((blob, lpath[:i+1]))
                # if check_elem == elem:
                    # It's in the scope
                    return True
        return False

    def _members_from_hit(self, hit, allowProtected=None, allowPrivate=None):
        """Retrieve members from the given hit.

        @param hit {tuple} (elem, scoperef)
        """
        elem, scoperef = hit

        # Namespaces completions only show for namespace elements.
        elem_type = elem.get("ilk") or elem.tag
        namespace_cplns = (self.trg.type == "namespace-members")
        if namespace_cplns and elem_type != "namespace":
            raise CodeIntelError("%r resolves to type %r, which is not a "
                                 "namespace" % (self.expr, elem_type, ))

        members = set()
        elem_name = elem.get("name")
        static_cplns = (self.trg.type == "static-members")

        for child in elem:
            # self.debug("_members_from_hit: checking child: %r", child)
            if child.tag == "import":
                continue
            name_prefix = ''   # Used to add "$" for static variable names.
            attributes = child.get("attributes", "").split()
            if "__hidden__" in attributes:
                continue
            if not allowProtected:
                # Protected and private vars can only be shown from inside
                # the class scope
                if "protected" in attributes:
                    if allowProtected is None:
                        # Need to check if it's allowed
                        allowProtected = self._isElemInsideScoperef(
                            elem, self.get_start_scoperef())
                    if not allowProtected:
                        # Checked scope already and it does not allow protected
                        # Thats means it also does not allow private
                        allowPrivate = False
                        self.log("hit '%s.%s' is protected, not including",
                                 elem_name, child.get("name"))
                        continue
            if not allowPrivate:
                # we now know protected is allowed, now check private
                if "private" in attributes:
                    if allowPrivate is None:
                        # Need to check if it's allowed
                        allowPrivate = self._isElemInsideScoperef(
                            elem, self.get_start_scoperef())
                    if not allowPrivate:
                        # Checked scope already and it does not allow private
                        self.log("hit '%s.%s' is private, not including",
                                 elem_name, child.get("name"))
                        continue
            if child.tag == "variable":
                if static_cplns:
                    # Static variables use the '$' prefix, constants do not.
                    if "static" in attributes:
                        name_prefix = '$'
                    elif child.get("ilk") != "constant":
                        continue
                elif "static" in attributes:
                    continue
                # Only namespaces allow access to constants.
                elif child.get("ilk") == "constant" and not namespace_cplns:
                    continue
            # add the element, we've already checked private|protected scopes
            members.update(self._members_from_elem(child, name_prefix))
        elem_ilk = elem.get("ilk")
        if elem_ilk == "class" or elem_ilk == "trait":
            for classref in elem.get("classrefs", "").split() + \
                            elem.get("traitrefs", "").split():
                ns_elem = self._namespace_elem_from_scoperef(scoperef)
                if ns_elem is not None:
                    # For class reference inside a namespace, *always* use the
                    # fully qualified name - bug 85643.
                    classref = "\\" + self._fqn_for_expression(
                        classref, scoperef)
                self.debug(
                    "_members_from_hit: Getting members for inherited %r: %r",
                           elem_ilk, classref)
                try:
                    subhit = self._hit_from_citdl(classref, scoperef)
                except CodeIntelError, ex:
                    # Continue with what we *can* resolve.
                    self.warn(str(ex))
                else:
                    if allowProtected is None:
                        # Need to check if it's allowed
                        allowProtected = self._isElemInsideScoperef(
                            elem, self.get_start_scoperef())
                    # Checking the parent class, private is not allowed for
                    # sure
                    members.update(self._members_from_hit(
                        subhit, allowProtected, allowPrivate=False))
        return members

    def _members_from_hits(self, hits, allowProtected=None, allowPrivate=None):
        """Retrieve members for the given hits.

        @param hits - a list of hits: [(elem, scoperef), ...]
        """
        members = set()
        for hit in hits:
            members.update(self._members_from_hit(hit))
        return members

    def _hit_from_citdl(self, expr, scoperef, defn_only=False):
        """Resolve the given CITDL expression (starting at the given
        scope) down to a non-import/non-variable hit.
        """
        self.eval_depth += 1
        self.log("_hit_from_citdl:: expr: %r, scoperef: %r", expr, scoperef)
        try:
            self._check_infinite_recursion(expr)
        except EvalError:
            # In the case of a recursion error, it is likely due to a class
            # variable having the same name as the class itself, so to try
            # to get better completions for this case we do not abort here,
            # but rather try from the parent scope instead. See bug:
            # http://bugs.activestate.com/show_bug.cgi?id=67774
            scoperef = self.parent_scoperef_from_scoperef(scoperef)
            if scoperef is None:
                # When we run out of scope, raise an error
                raise
            self.debug("_hit_from_citdl: recursion found for '%s', "
                       "moving to parent scope %r",
                       expr, scoperef)

        tokens = list(self._tokenize_citdl_expr(expr))
        self.log("_hit_from_citdl:: expr tokens: %r", tokens)

        # First part...
        hits, nconsumed = self._hits_from_first_part(tokens, scoperef)
        if not hits:
            # TODO: Add the fallback Buffer-specific near-by hunt
            #      for a symbol for the first token. See my spiral-bound
            #      book for some notes.
            if self.trg.type == "namespace-members":
                # If this is a namespace-members completion trigger, then this
                # namespace may not exist, but one of the sub-namespaces may:
                #    namespace foo\bar\bam {}
                #    \foo\<|>     # namespace 'foo' doesn't exist
                # in this case we want to return all namespaces starting with
                # this expr, which is handled in the eval_cplns() method.
                return None, None
            raise CodeIntelError("could not resolve first part of '%s'" % expr)

        self.debug("_hit_from_citdl:: first part: %r -> %r",
                   tokens[:nconsumed], hits)

        # ...the remainder.
        remaining_tokens = tokens[nconsumed:]
        while remaining_tokens:
            new_hits = []
            for hit in hits:
                new_hit = None
                try:
                    self.debug("_hit_from_citdl:: resolve %r on %r in %r",
                               remaining_tokens, *hit)
                    if remaining_tokens[0] == "()":
                        # TODO: impl this function
                        # _hit_from_call(elem, scoperef) -> hit or raise
                        # CodeIntelError("could resolve call on %r: %s",
                        # hit[0], ex)
                        new_hit = self._hit_from_call(*hit)
                        nconsumed = 1
                    else:
                        new_hit, nconsumed \
                            = self._hit_from_getattr(remaining_tokens, *hit)
                    remaining_tokens = remaining_tokens[nconsumed:]
                except CodeIntelError, ex:
                    self.debug("error %s", ex)
                if new_hit:
                    new_hits.append(new_hit)
            if not new_hits:
                break
            hits = new_hits

        if not hits:
            raise CodeIntelError("could not resolve first part of '%s'" % expr)
        if len(hits) > 2:
            self.debug(
                "_hit_from_citdl:: multiple hits found, returning the first hit")
        hit = hits[0]

        # Resolve any variable type inferences.
        # TODO: Need to *recursively* resolve hits.
        elem, scoperef = hit
        if elem.tag == "variable" and not defn_only:
            elem, scoperef = self._hit_from_variable_type_inference(
                elem, scoperef)

        self.info(
            "_hit_from_citdl:: found '%s' => %s on %s", expr, elem, scoperef)
        return (elem, scoperef)

    def _alternative_elem_from_scoperef(self, traversed_items):
        """Find an alternative named element for the given traversal items"""
        for i in range(len(traversed_items)-1, -1, -1):
            elem, lname, failed_elems = traversed_items[i]
            self.log(
                "Checking for alt elem: %r, lpath: %r, failed_elems: %r", elem, lname, failed_elems)
            for child in elem.getchildren():
                if child.attrib.get("name") == lname and child not in failed_elems:
                    return i, child
        return None

    def _elem_from_scoperef(self, scoperef):
        """A scoperef is (<blob>, <lpath>). Return the actual elem in
        the <blob> ciElementTree being referred to.
        """
        elem, lpath = scoperef
        traversed_items = []
        for i in range(len(lpath)):
            lname = lpath[i]
            try:
                child = elem.names[lname]
            except KeyError:
                # There is likely an alternative element that has the same name.
                # Try and find it now.
                # http://bugs.activestate.com/show_bug.cgi?id=70015
                child = None
                if i > 0:
                    # self.log("i now: %r, traversed_items: %r", i,
                    # traversed_items)
                    traversed_items[i-1][2].append(elem)
                    i, child = self._alternative_elem_from_scoperef(
                        traversed_items)
                    traversed_items = traversed_items[:i]
                if child is None:
                    self.info("elem %r is missing lname: %r", elem, lname)
                    raise
                self.info(
                    "elem %r is missing lname: %r, found alternative: %r",
                          elem, lname, child)
            traversed_items.append((elem, lname, []))
            elem = child
        return elem

    def _namespace_elem_from_scoperef(self, scoperef):
        """A scoperef is (<blob>, <lpath>). Return the current namespace in
        the <blob> ciElementTree, walking up the scope as necessary.
        """
        blob, lpath = scoperef
        if len(lpath) >= 1:
            elem_chain = []
            elem = blob
            for i in range(len(lpath)):
                try:
                    elem = elem.names[lpath[i]]
                    elem_chain.append(elem)
                except KeyError:
                    break
            for elem in reversed(elem_chain):
                if elem.tag == "scope" and elem.get("ilk") == "namespace":
                    return elem
        return None

    def _imported_namespace_elements_from_scoperef(self, scoperef):
        namespace_elems = {}
        possible_elems = [self._namespace_elem_from_scoperef(scoperef),
                           self._get_global_scoperef(scoperef)[0]]
        for elem in possible_elems:
            if elem is not None:
                for child in elem:
                    if child.tag == "import":
                        symbol = child.get("symbol")
                        alias = child.get("alias")
                        if symbol is not None:
                            namespace_elems[alias or symbol] = child
        return namespace_elems

    def _fqn_for_expression(self, expr, scoperef):
        expr = expr.rstrip("\\")
        fqn = None
        if expr and not expr.startswith("\\"):
            # Looking up namespaces depends on whether we are already inside a
            # namespace or not. When inside a namespace, we need to lookup:
            #   * aliased namespaces
            #   * subnamespaces of the current namespace
            # When not inside a namespace, we need to lookup:
            #   * global namespaces
            tokens = expr.split("\\")
            first_token = tokens[0]

            used_namespaces = self._imported_namespace_elements_from_scoperef(
                scoperef)
            elem = used_namespaces.get(first_token)
            if elem is not None:
                symbol = elem.get("symbol")
                alias = elem.get("alias")
                self.log(
                    "_fqn_for_expression:: found used namespace: %r", elem)
                fqn = "%s\\%s" % (elem.get("module"), symbol)
                if tokens[1:]:
                    fqn += "\\%s" % ("\\".join(tokens[1:]))
            else:
                # Was not an imported/aliased namespace.
                elem = self._namespace_elem_from_scoperef(scoperef)
                if elem is not None:
                    # We are inside a namespace, work out the fully qualified
                    # name. Treat it as sub-namespace of the current namespace.
                    fqn = "%s\\%s" % (elem.get("name"), expr)
                else:
                    fqn = expr
        else:
            fqn = expr

        fqn = fqn.strip("\\")
        self.log("_fqn_for_expression:: %r => %r", expr, fqn)
        return fqn

    def _hits_from_namespace(self, fqn, scoperef):
        self.log("_hits_from_namespace:: fqn %r, scoperef: %r", fqn, scoperef)

        global_scoperef = self._get_global_scoperef(scoperef)
        global_blob = self._elem_from_scoperef(global_scoperef)

        # self.log("_hits_from_namespace:: globals: %r",
        # global_blob.names.keys())
        hits = []
        elem = global_blob.names.get(fqn)
        if elem is not None:
            self.log("_hits_from_namespace:: found %r locally: %r", fqn, elem)
            hit_scoperef = [global_scoperef[
                0], global_scoperef[1] + [elem.get("name")]]
            hits.append((elem, hit_scoperef))
        else:
            # The last token in the namespace may be a class or a constant, instead
            # of being part of the namespace itself.
            tokens = fqn.split("\\")
            if len(tokens) > 1:
                partial_fqn = "\\".join(tokens[:-1])
                last_token = tokens[-1]
                self.log(
                    "_hits_from_namespace:: checking for sub-namespace match: %r",
                         partial_fqn)

                elem = global_blob.names.get(partial_fqn)
                if elem is not None:
                    self.log(
                        "_hits_from_namespace:: found sub-namespace locally, now find %r",
                             last_token)
                    try:
                        hit_scoperef = [global_scoperef[0], (partial_fqn, )]
                        hits.append((elem.names[last_token], hit_scoperef))
                    except KeyError:
                        # Fall through to other possible library matches (bug
                        # 85643).
                        self.debug(
                            "_hits_from_namespace:: no subsequent hit found locally for %r",
                                   last_token)

        lpath = (fqn, )
        libs = [self.buf.stdlib] + self.libs
        for lib in libs:
            lib_hits = lib.hits_from_lpath(lpath)
            if lib_hits:
                self.log("_hits_from_namespace:: found in lib: %r", lib)
                hits += lib_hits

        return hits

    def _hits_from_first_part(self, tokens, scoperef):
        """Find all hits for the first part of the tokens.

        Returns a tuple ([<hit1>, <hit2>], <num-tokens-consumed>), or
        (None, None) if it could not resolve.

        Example for 'os.sep':
            tokens: ('os', 'sep')
            retval: ([(<variable 'sep'>,  (<blob 'os', []))],   1)
        Example for 'os.path':
            tokens: ('os', 'path')
            retval: ([(<import os.path>,  (<blob 'os', []))],   2)
        """
        first_token = tokens[0]
        self.log("_hits_from_first_part:: find '%s ...' starting at %s:",
                 first_token, scoperef)

        if "\\" in first_token:
            first_token = self._fqn_for_expression(first_token, scoperef)
            # It's a namespace, lookup the correstponding namespace.
            hits = self._hits_from_namespace(first_token, scoperef)
            if hits:
                nconsumed = 1
                return (hits, nconsumed)
            self.log("_hits_from_first_part:: no namespace hits")
            if self.trg.type == "namespace-members":
                return (None, 1)

        if first_token in ("this", "self", "parent", "static"):
            # Special handling for class accessors
            self.log("_hits_from_first_part:: Special handling for %r",
                     first_token)
            elem = self._elem_from_scoperef(scoperef)
            while elem is not None and elem.get("ilk") not in ("class", "trait"):
                # Return the class element
                blob, lpath = scoperef
                if not lpath:
                    return (None, None)
                scoperef = blob, lpath[:-1]
                elem = self._elem_from_scoperef(scoperef)
            if not elem:
                return (None, None)
            self.log(
                "_hits_from_first_part:: need %s for %r", first_token, elem)
            if first_token == "parent":
                first_token = elem.get("classrefs")
                self.log("_hits_from_first_part:: Special handling for parent, "
                         "classref %r", first_token)
                if not first_token:
                    return (None, None)
                tokens = [first_token] + tokens[1:]
                scoperef = self.parent_scoperef_from_scoperef(scoperef)
                # Now go below and find the parent class members
            elif self._return_with_hit((elem, scoperef), 1):
                self.log("_hits_from_first_part:: %s returning scoperef: %r",
                         first_token, scoperef)
                return ([(elem, scoperef)], 1)

        while 1:
            self.log("_hits_from_first_part:: scoperef now %s:", scoperef)
            elem = self._elem_from_scoperef(scoperef)
            if first_token in elem.names:
                first_token_elem = elem.names[first_token]
                if self._return_with_hit((first_token_elem, scoperef), 1):
                    # TODO: skip __hidden__ names
                    self.log("_hits_from_first_part:: pt1: is '%s' accessible on %s? "
                             "yes: %s", first_token, scoperef, first_token_elem)
                    return ([(first_token_elem, scoperef)], 1)

            if first_token == elem.get("name"):
                # The element itself is the thing we wanted...
                if self._return_with_hit((elem, scoperef), 1):
                    self.log("_hits_from_first_part:: pt1: is '%s' accessible on %s? "
                             "yes: %s", first_token, scoperef, elem)
                    return ([(elem, scoperef)], 1)

            if elem.tag == "scope":
                self.log("_hits_from_first_part:: checking namespace aliases")
                imports = [child for child in elem if child.tag == "import"]
                for child in imports:
                    module = child.get("module")
                    symbol = child.get("symbol")
                    alias = child.get("alias")
                    self.log("_hits_from_first_part:: module: %r, symbol: %r"
                             ", alias: %r", module, symbol, alias)
                    if alias == first_token or \
                            (alias is None and symbol == first_token):
                        self.log("_hits_from_first_part:: pt2: is '%s' accessible on "
                                 "%s? yes: %s", first_token, scoperef, child)
                        # Aliases always use a fully qualified namespace.
                        expr = "\\%s\\%s" % (module, symbol)
                        hit = self._hit_from_citdl(expr, scoperef)
                        if hit:
                            return ([hit], 1)
                        break
                else:
                    if "\\" not in first_token and elem.get("ilk") == "namespace":
                        self.log(
                            "_hits_from_first_part:: checking for a FQN hit")
                        # Being in a namespace, we also need to check if this name
                        # is accessable as a FQN - bug 86784.
                        fqn = self._fqn_for_expression(first_token, scoperef)
                        try:
                            hit = self._hit_from_citdl(fqn, scoperef)
                            if hit:
                                return ([hit], 1)
                        except CodeIntelError:
                            pass

            self.log(
                "_hits_from_first_part:: pt3: is '%s' accessible on %s? no",
                     first_token, scoperef)
            # Do not go past the global scope reference
            if len(scoperef[1]) >= 1:
                scoperef = self.parent_scoperef_from_scoperef(scoperef)
                assert scoperef and scoperef[0] is not None, "Something is " \
                        "seriously wrong with our php logic."
            else:
                # We shall fallback to imports then
                break

        # elem and scoperef *are* for the global level
        hit, nconsumed = self._hit_from_elem_imports(tokens, elem)
        if hit is not None and self._return_with_hit(hit, nconsumed):
            self.log("_hits_from_first_part:: pt4: is '%s' accessible on %s? yes, "
                     "imported: %s",
                     '.'.join(tokens[:nconsumed]), scoperef, hit[0])
            return ([hit], nconsumed)
        return None, None

    def _hit_from_elem_imports(self, tokens, elem):
        """See if token is from one of the imports on this <scope> elem.

        Returns (<hit>, <num-tokens-consumed>) or (None, None) if not found.
        """
        # PERF: just have a .import_handler property on the evalr?
        self.debug("_hit_from_elem_imports:: Checking imports, tokens[0]: %r "
                   "... imp_elem: %r", tokens[0], elem)
        import_handler = self.citadel.import_handler_from_lang(self.trg.lang)
        libs = self.buf.libs

        # PERF: Add .imports method to ciElementTree for quick iteration
        #      over them. Or perhaps some cache to speed this method.
        # TODO: The right answer here is to not resolve the <import>,
        #      just return it. It is complicated enough that the
        #      construction of members has to know the original context.
        #      See the "Foo.mypackage.<|>mymodule.yo" part of test
        #      python/cpln/wacky_imports.
        #      XXX Not totally confident that this is the right answer.
        first_token = tokens[0]
        for imp_elem in (i for i in elem if i.tag == "import"):
            self.debug("_hit_from_elem_imports:: import '%s ...' from %r?",
                       tokens[0], imp_elem)
            module_name = imp_elem.get("module")
            try_module_names = [module_name]
            # If a module import is absolute and it fails, try a relative one
            # as well. Example:
            #   include (MYDIR + "/file.php");
            if module_name[0] == "/":
                try_module_names.append(module_name[1:])
            for module_name in try_module_names:
                if module_name not in self._imported_blobs:
                    try:
                        blob = import_handler.import_blob_name(
                                    module_name, libs, self.ctlr)
                    except CodeIntelError:
                        self.debug(
                            "_hit_from_elem_imports:: Failed import: %s",
                                   module_name)
                        pass  # don't freak out: might not be our import anyway
                    else:
                        self._imported_blobs[module_name] = 1
                        try:
                            hit, nconsumed = self._hit_from_getattr(
                                                tokens, blob, (blob, []))
                            if hit:
                                return hit, nconsumed
                        except CodeIntelError, e:
                            self.debug("_hit_from_elem_imports:: "
                                       "_hit_from_getattr could not resolve: "
                                       "%r on %r", tokens, blob)
                            pass  # don't freak out: we'll try the next import
                else:
                    self.debug("_hit_from_elem_imports:: Recursive import: "
                               "Already imported module: %r", module_name)

        # include-everything stuff
        self.log("_hit_from_elem_imports:: trying import everything: tokens: "
                 "%r", tokens)
        # self.log(banner("include-everything stuff", length=50))

        # First check the full lpath, then try for smaller and smaller lengths
        for nconsumed in range(len(tokens), 0, -1):
            lpath = tuple(tokens[:nconsumed])
            self.log("_hit_from_elem_imports:: trying with lpath: %r", lpath)
            # for each directory in all known php file directories
            for lib in self.libs:
                # see if there is a match (or partial match) in this directory
                hits = lib.hits_from_lpath(lpath, self.ctlr,
                                              curr_buf=self.buf)
                self.log("_hit_from_elem_imports:: ie: lookup %r in %s => %r",
                         lpath, lib, hits)
                for hit in hits:
                    (hit_elem, import_scoperef) = hit
                    (hit_blob, hit_lpath) = import_scoperef
                    self.log("_hit_from_elem_imports:: ie: matched %r to %r "
                             "in blob %r", lpath, hit_elem, hit_blob, )
                    unique_import_name = hit_blob.get(
                        "name") + "#" + str(lpath)
                    # print unique_import_name
                    if unique_import_name not in self._imported_blobs:
                        self._imported_blobs[unique_import_name] = 1
                        try:
                            if hit and self._return_with_hit(hit, 1):
                                return hit, nconsumed
                        except CodeIntelError, e:
                            self.debug("_hit_from_elem_imports:: ie: "
                                       "_hit_from_getattr could not resolve: "
                                       "%r on %r", tokens, blob)
                            pass  # don't freak out: we'll try the next import
                    else:
                        self.debug("_hit_from_elem_imports:: ie: Recursive "
                                   "import: Already imported module: %r",
                                   unique_import_name)
            self.log("_hit_from_elem_imports:: ie: no matches found")
            # self.log(banner(None, length=50))

        return None, None

    def _hit_from_getattr(self, tokens, elem, scoperef):
        """Return a hit for a getattr on the given element.

        Returns (<hit>, <num-tokens-consumed>) or raises an EvalError.

        Typically this just does a getattr of tokens[0], but handling
        some multi-level imports can result in multiple tokens being
        consumed.
        """
        # TODO: On failure, call a hook to make an educated guess. Some
        #      attribute names are strong signals as to the object type
        #      -- typically those for common built-in classes.
        first_token = tokens[0]
        self.log("_hit_from_getattr:: resolve '%s' on %r in %r:", first_token,
                 elem, scoperef)
        if elem.tag == "variable":
            elem, scoperef = self._hit_from_variable_type_inference(
                elem, scoperef)

        assert elem.tag == "scope"
        ilk = elem.get("ilk")
        if ilk == "function":
            # Internal function arguments and variable should
            # *not* resolve. And we don't support function
            # attributes.
            pass
        elif ilk == "class" or ilk == "trait":
            static_member = False
            if first_token.startswith("$"):
                # Cix doesn't use "$" in member names, remove it - bug 90968.
                static_member = True
                first_token = first_token[1:]
            attr = elem.names.get(first_token)
            if attr is not None:
                self.log("_hit_from_getattr:: attr is %r in %r", attr, elem)
                if static_member and "static" not in attr.get("attributes", "").split():
                    self.warn(
                        "_hit_from_getattr:: %r in class %r is not marked static",
                              first_token, elem)
                classname = elem.get("name")
                # XXX - This works, but does not feel right.
                # Add the class name if it's not already there
                if len(scoperef[1]) == 0 or scoperef[1][-1] != classname:
                    class_scoperef = (scoperef[0], scoperef[1]+[classname])
                else:
                    class_scoperef = scoperef
                return (attr, class_scoperef), 1
            for classref in elem.get("traitrefs", "").split() + \
                            elem.get("classrefs", "").split():
                # TODO: update _hit_from_citdl to accept optional node type,
                #      i.e. to only return classes in this case.
                self.log("_hit_from_getattr:: is '%s' available on parent "
                         "class: %r?", first_token, classref)
                base_elem, base_scoperef \
                    = self._hit_from_citdl(classref, scoperef)
                if base_elem is not None and base_elem.get("ilk") in ("class", "trait"):
                    self.log("_hit_from_getattr:: is '%s' from %s base %s?",
                             first_token, base_elem, base_elem.get("ilk"))
                    try:
                        hit, nconsumed = self._hit_from_getattr(tokens,
                                                                base_elem,
                                                                base_scoperef)
                        if hit is not None and self._return_with_hit(hit,
                                                                     nconsumed):
                            self.log("_hit_from_getattr:: is '%s' accessible "
                                     "on %s? yes: %s",
                                     '.'.join(tokens[:nconsumed]), scoperef,
                                     hit[0])
                            return hit, nconsumed
                    except CodeIntelError, e:
                        pass  # don't freak out: we'll try the next classref
        elif ilk == "blob":
            attr = elem.names.get(first_token)
            if attr is not None:
                self.log("_hit_from_getattr:: attr is %r in %r", attr, elem)
                return (attr, scoperef), 1

            hit, nconsumed = self._hit_from_elem_imports(tokens, elem)
            if hit is not None:
                return hit, nconsumed
        else:
            raise NotImplementedError("unexpected scope ilk: %r" % ilk)
        raise CodeIntelError("could not resolve '%s' getattr on %r in %r"
                             % (first_token, elem, scoperef))

    def _hit_from_call(self, elem, scoperef):
        """Resolve the function call inference for 'elem' at 'scoperef'."""
        citdl = elem.get("returns")
        if not citdl:
            raise CodeIntelError("no _hit_from_call info for %r" % elem)
        self.log("_hit_from_call: resolve '%s' for %r, lpath: %r",
                 citdl, elem, scoperef[1])
        # Clear the imported blobs, it's a different evaluation - bug 90956.
        self._imported_blobs = {}
        # scoperef has to be on the function called
        func_scoperef = (scoperef[0], scoperef[1]+[elem.get("name")])
        return self._hit_from_citdl(citdl, func_scoperef)

    def _hit_from_variable_type_inference(self, elem, scoperef):
        """Resolve the type inference for 'elem' at 'scoperef'."""
        citdl = elem.get("citdl")
        if not citdl:
            raise CodeIntelError("no type-inference info for %r" % elem)
        if citdl == 'array' and self.trg.type == "array-members":
            self.log("_hit_from_variable_type_inference:: elem %r is an array",
                     elem, )
            return (elem, scoperef)
        self.log(
            "_hit_from_variable_type_inference:: resolve '%s' type inference for %r:", citdl, elem)
        if citdl == elem.get("name") and elem.tag == "variable":
            # We really need an alternative match in this case, such as a class
            # or a function. First see if there are any matching names at the
            # same scope level, else go searching up the parent scopes.
            # http://bugs.activestate.com/show_bug.cgi?id=70015
            parent_elem = self._elem_from_scoperef(scoperef)
            if parent_elem is not None:
                sibling_matches = [x for x in parent_elem.getchildren() if x.get(
                    "name") == citdl and x.tag != "variable"]
                if sibling_matches:
                    return (sibling_matches[0], scoperef)
            scoperef = self.parent_scoperef_from_scoperef(scoperef)

        variable_namespace = elem.get("namespace")
        if variable_namespace and scoperef[0] is not None:
            # Variable was defined inside of a namespace, that means
            # it gets access to the namespace as well even though the
            # variable is defined to the global scope - bug 88964.
            self.log(
                "_hit_from_variable_type_inference:: variable was defined in namespace %r",
                     variable_namespace)
            blob = scoperef[0]
            ns_elem = blob.names.get(variable_namespace)
            if ns_elem is not None:
                try:
                    hit = self._hit_from_citdl(citdl, (
                        blob, [variable_namespace]))
                    if hit is not None:
                        return hit
                except:
                    self.log(
                        "_hit_from_variable_type_inference:: %r not found in namespace %r",
                             citdl, variable_namespace)

        return self._hit_from_citdl(citdl, scoperef)

    def parent_scoperef_from_scoperef(self, scoperef):
        # For PHP, either it's in the current scope or it's in the global scope
        # or last of all, it's in the builtins
        blob, lpath = scoperef
        if blob is self._built_in_blob:
            # Nothin past the builtins
            return None
        elif len(lpath) >= 1:
            if len(lpath) >= 2:
                # Return the namespace if there is one
                elem = blob.names.get(lpath[0])
                if elem is not None and elem.tag == "scope" and \
                   elem.get("ilk") == "namespace":
                    return (blob, lpath[:1])
            # Return the global scope
            return self._get_global_scoperef(scoperef)
        else:
            return (self.built_in_blob, [])

    #--- These method were inherited from JavaScriptTreeEvaluator.
    # If they are generic enough they should be moved to base
    # TreeEvaluator.
    _built_in_blob = None

    @property
    def built_in_blob(self):
        if self._built_in_blob is None:
            self._built_in_blob = self.buf.stdlib.get_blob("*")
        return self._built_in_blob

    _built_in_cache = None

    @property
    def built_in_cache(self):
        if self._built_in_cache is None:
            phpcache = self.built_in_blob.cache.get('php')
            if phpcache is None:
                phpcache = {}
                self.built_in_blob.cache['php'] = phpcache
            self._built_in_cache = phpcache
        return self._built_in_cache

    def _tokenize_citdl_expr(self, expr):
        for tok in expr.split('.'):
            if tok.endswith('()'):
                yield tok[:-2]
                yield '()'
            else:
                yield tok

    def _join_citdl_expr(self, tokens):
        return '.'.join(tokens).replace('.()', '()')

    def _calltip_from_func(self, node, scoperef):
        # See "Determining a Function CallTip" in the spec for a
        # discussion of this algorithm.
        signature = node.get("signature")
        doc = node.get("doc")
        ctlines = []
        if not signature:
            name = node.get("name")
            # XXX Note difference for Tcl in _getSymbolCallTips.
            ctlines = [name + "(...)"]
        else:
            ctlines = signature.splitlines(0)
        if doc:
            ctlines += doc.splitlines(0)
        else:
            # Check if there is a interface that has the docs - bug 83381.
            parent_elem = self._elem_from_scoperef(scoperef)
            if parent_elem.get("ilk") == "class":
                interfacerefs = parent_elem.get("interfacerefs", "").split()
                name = node.get("name")
                for interface in interfacerefs:
                    ielem, iscoperef = self._hit_from_citdl(
                        interface, scoperef)
                    if ielem is not None:
                        # Found and interface, see if it has the info we need:
                        alt_node = ielem.names.get(name)
                        if alt_node is not None and alt_node.get("doc"):
                            ctlines += alt_node.get("doc").splitlines(0)
                            break
        return '\n'.join(ctlines)

    #---- Internal Utility functions for PHP
    def _get_global_scoperef(self, scoperef):
        return (scoperef[0], [])

    def _convertListToCitdl(self, citdl_type, lst):
        return sorted([(citdl_type, v) for v in lst])

    def _make_shortname_lookup_citdl_dict(self, citdl_type, namelist, length=1):
        d = make_short_name_dict(namelist, length=length)
        for key, values in d.items():
            d[key] = self._convertListToCitdl(citdl_type, values)
        return d

    # XXX PERF : Anything below here is in need of performance tweaking

    def _get_all_children_with_details(self, node, tagname, attributes=None, startswith=None):
        """Returns a list of child nodes that have the tag name and attributes.

        @param node {Element} the base node to search from
        @param tagname {str} the child tag name to find
        @param attributes {dict} the child node must have these attributes
        @param startswith {str} the child node name must start with this string
        @returns list of matched Element nodes
        """
        result = []
        for childnode in node.getchildren():
            if childnode.tag == tagname:
                doesMatch = True
                if attributes:
                    for attrname, attrvalue in attributes.items():
                        if childnode.get(attrname) != attrvalue:
                            doesMatch = False
                            break
                if doesMatch and startswith:
                    name = childnode.get("name")
                    if not name or not name.startswith(startswith):
                        doesMatch = False
                if doesMatch:
                    result.append(childnode)
        return result

    def _get_import_blob_with_module_name(self, module_name):
        import_handler = self.citadel.import_handler_from_lang(self.trg.lang)
        libs = self.buf.libs
        try:
            return import_handler.import_blob_name(module_name, libs,
                                                   self.ctlr)
        except CodeIntelError:
            pass  # don't freak out: might not be our import anyway

    # Only used by _get_all_import_blobs_for_elem
    def _get_all_import_blobs_dict_for_elem(self, elem, imported_blobs):
        """Return all imported php blobs for the given element
        @param elem {Element} The element to find imports from.
        @param imported_blobs {dict} key: import name, value: imported blob
        """
        for imp_elem in (i for i in elem if i.tag == "import"):
            module_name = imp_elem.get("module")
            self.debug(
                "_get_all_import_blobs_dict_for_elem:: Getting imports from %r", module_name)
            if module_name and module_name not in imported_blobs:
                import_blob = self._get_import_blob_with_module_name(
                    module_name)
                if import_blob is not None:
                    imported_blobs[module_name] = import_blob
                    # Get imports from imports
                    # Example, foo imports bar, bar imports baz
                    self._get_all_import_blobs_dict_for_elem(
                        import_blob, imported_blobs)
            else:
                self.debug(
                    "_get_all_import_blobs_dict_for_elem:: Recursive import: Already imported module: %r",
                           module_name)

    def _get_all_import_blobs_for_elem(self, elem):
        """Return all imported php blobs for the given element
        @param elem {Element} The element to find imports from.
        """
        # imported_blobs is used to keep track of what we import and to ensure
        # we don't get a recursive import situation
        imported_blobs = {}
        self._get_all_import_blobs_dict_for_elem(elem, imported_blobs)
        blobs = imported_blobs.values()
        self.debug(
            "_get_all_import_blobs_for_elem:: Imported blobs: %r", blobs)
        return blobs

    # _built_in_keyword_names = None
    #@property
    # def built_in_keyword_names(self):
    #    if self._built_in_keyword_names is None:
    #        # Get all class names from the nodes
    #        # XXX - Fix keywords
    #        self._built_in_keyword_names = ["print", "echo", "class", "function"]
    #    return self._built_in_keyword_names

    def _php_cache_from_elem(self, elem):
        cache = elem.cache.get('php')
        if cache is None:
            # Add one in then
            cache = {}
            elem.cache['php'] = cache
        return cache

    def variable_names_from_elem(self, elem, cache_item_name='variable_names'):
        cache = self._php_cache_from_elem(elem)
        variable_names = cache.get(cache_item_name)
        if variable_names is None:
            variables = self._get_all_children_with_details(elem, "variable")
            variable_names = [x.get(
                "name") for x in variables if x.get("ilk") != "constant"]
            cache[cache_item_name] = variable_names
        return variable_names

    def constant_names_from_elem(self, elem, cache_item_name='constant_names'):
        cache = self._php_cache_from_elem(elem)
        constant_names = cache.get(cache_item_name)
        if constant_names is None:
            constants = self._get_all_children_with_details(elem, "variable",
                                                            {"ilk": "constant"})
            constant_names = [x.get("name") for x in constants]
            cache[cache_item_name] = constant_names
        return constant_names

    def constant_shortnames_from_elem(self, elem, cache_item_name='constant_shortnames'):
        cache = self._php_cache_from_elem(elem)
        constant_short_names = cache.get(cache_item_name)
        if constant_short_names is None:
            constant_short_names = make_short_name_dict(
                                    self.constant_names_from_elem(elem),
                                    # XXX - TODO: Use constant_TRIGGER_LEN
                                    # instead of hard coding 3
                                    length=3)
            cache[cache_item_name] = constant_short_names
        return constant_short_names

    def function_names_from_elem(self, elem, cache_item_name='function_names'):
        cache = self._php_cache_from_elem(elem)
        function_names = cache.get(cache_item_name)
        if function_names is None:
            functions = self._get_all_children_with_details(elem, "scope",
                                                            {"ilk": "function"})
            function_names = [x.get("name") for x in functions]
            cache[cache_item_name] = function_names
        return function_names

    def function_shortnames_from_elem(self, elem, cache_item_name='function_shortnames'):
        cache = self._php_cache_from_elem(elem)
        function_short_names = cache.get(cache_item_name)
        if function_short_names is None:
            function_short_names = make_short_name_dict(
                                    self.function_names_from_elem(elem),
                                    # XXX - TODO: Use FUNCTION_TRIGGER_LEN
                                    # instead of hard coding 3
                                    length=3)
            cache[cache_item_name] = function_short_names
        return function_short_names

    def class_names_from_elem(self, elem, cache_item_name='class_names'):
        cache = self._php_cache_from_elem(elem)
        class_names = cache.get(cache_item_name)
        if class_names is None:
            classes = self._get_all_children_with_details(elem, "scope",
                                                            {"ilk": "class"})
            class_names = [x.get("name") for x in classes]
            cache[cache_item_name] = class_names
        return class_names

    def trait_names_from_elem(self, elem, cache_item_name='trait_names'):
        cache = self._php_cache_from_elem(elem)
        trait_names = cache.get(cache_item_name)
        if trait_names is None:
            traits = self._get_all_children_with_details(elem, "scope",
                                                            {"ilk": "trait"})
            trait_names = [x.get("name") for x in traits]
            cache[cache_item_name] = trait_names
        return trait_names

    def imported_namespace_names_from_elem(self, elem, cache_item_name='imported_namespace_names'):
        cache = self._php_cache_from_elem(elem)
        namespace_names = cache.get(cache_item_name)
        if namespace_names is None:
            namespace_names = []
            for child in elem:
                if child.tag == "import":
                    symbol = child.get("symbol")
                    alias = child.get("alias")
                    if symbol is not None:
                        namespace_names.append(alias or symbol)
            cache[cache_item_name] = namespace_names
        return namespace_names

    def namespace_names_from_elem(self, elem, cache_item_name='namespace_names'):
        cache = self._php_cache_from_elem(elem)
        namespace_names = cache.get(cache_item_name)
        if namespace_names is None:
            elems = self._get_all_children_with_details(elem, "scope",
                                                        {"ilk": "namespace"})
            namespace_names = [x.get("name") for x in elems]
            cache[cache_item_name] = namespace_names
        return namespace_names

    def interface_names_from_elem(self, elem, cache_item_name='interface_names'):
        cache = self._php_cache_from_elem(elem)
        interface_names = cache.get(cache_item_name)
        if interface_names is None:
            interfaces = self._get_all_children_with_details(elem, "scope",
                                                            {"ilk": "interface"})
            interface_names = [x.get("name") for x in interfaces]
            cache[cache_item_name] = interface_names
        return interface_names

########NEW FILE########
__FILENAME__ = tree_python
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Completion evaluation code for Python"""

from os.path import basename, dirname, join, exists, isdir
import operator

from codeintel2.common import *
from codeintel2.tree import TreeEvaluator

base_exception_class_completions = [
    ("class", "BaseException"),
    ("class", "Exception"),
    ("class", "StandardError"),
    ("class", "ArithmeticError"),
    ("class", "LookupError"),
    ("class", "EnvironmentError"),
    ("class", "AssertionError"),
    ("class", "AttributeError"),
    ("class", "EOFError"),
    ("class", "FloatingPointError"),
    ("class", "GeneratorExit"),
    ("class", "IOError"),
    ("class", "ImportError"),
    ("class", "IndexError"),
    ("class", "KeyError"),
    ("class", "KeyboardInterrupt"),
    ("class", "MemoryError"),
    ("class", "NameError"),
    ("class", "NotImplementedError"),
    ("class", "OSError"),
    ("class", "OverflowError"),
    ("class", "ReferenceError"),
    ("class", "RuntimeError"),
    ("class", "StopIteration"),
    ("class", "SyntaxError"),
    ("class", "SystemError"),
    ("class", "SystemExit"),
    ("class", "TypeError"),
    ("class", "UnboundLocalError"),
    ("class", "UnicodeError"),
    ("class", "UnicodeEncodeError"),
    ("class", "UnicodeDecodeError"),
    ("class", "UnicodeTranslateError"),
    ("class", "ValueError"),
    ("class", "VMSError"),
    ("class", "WindowsError"),
    ("class", "ZeroDivisionError"),
    # Warning category exceptions.
    ("class", "Warning"),
    ("class", "UserWarning"),
    ("class", "DeprecationWarning"),
    ("class", "PendingDeprecationWarning"),
    ("class", "SyntaxWarning"),
    ("class", "RuntimeWarning"),
    ("class", "FutureWarning"),
    ("class", "ImportWarning"),
    ("class", "UnicodeWarning"),
]


class PythonImportLibGenerator(object):
    """A lazily loading lib generator.

    To be used for Komodo's import lookup handling. This generator will return
    libraries as needed, then when the given set of libraries runs out (i.e.
    when there were no matches in the given libraries), to then try and find
    other possible directories (libraries) that could offer a match."""
    def __init__(self, mgr, lang, bufpath, imp_prefix, libs):
        self.mgr = mgr
        self.lang = lang
        self.imp_prefix = imp_prefix
        self.bufpath = bufpath
        self.libs = libs
        self.index = 0

    def __iter__(self):
        self.index = 0
        return self

    def next(self):
        if self.index < len(self.libs):
            # Return the regular libs.
            try:
                return self.libs[self.index]
            finally:
                self.index += 1
        elif self.index == len(self.libs):
            # Try to find a matching parent directory to use.
            # print "Lazily loading the parent import libs: %r" %
            # (self.imp_prefix, )
            self.index += 1
            lookuppath = dirname(self.bufpath)
            parent_dirs_left = 5
            import_name = self.imp_prefix[0]
            if "." in import_name:
                import_name = import_name.split(".", 1)[0]
            while lookuppath and parent_dirs_left > 0:
                # print '    exists: %r - %r' % (exists(join(lookuppath,
                # import_name, "__init__.py")), join(lookuppath, import_name,
                # "__init__.py"))
                parent_dirs_left -= 1
                if exists(join(lookuppath, import_name, "__init__.py")):
                    # Matching directory - return that as a library.
                    # print "  adding parent dir lib: %r" % (lookuppath)
                    return self.mgr.db.get_lang_lib(self.lang, "parentdirlib",
                                                    [lookuppath])
                lookuppath = dirname(lookuppath)
            # No match found - we're done.
            raise StopIteration
        else:
            raise StopIteration


class PythonTreeEvaluator(TreeEvaluator):

    # Own copy of libs (that shadows the real self.buf.libs) - this is required
    # in order to properly adjust the "reldirlib" libraries as they hit imports
    # from different directories - i.e. to correctly deal with relative
    # imports.
    _libs = None

    @property
    def libs(self):
        if self._libs is None:
            self._libs = self.buf.libs
        return self._libs

    @libs.setter
    def libs(self, value):
        self._libs = value

    def eval_cplns(self):
        self.log_start()
        if self.trg.type == 'available-exceptions':
            # TODO: Should perform a lookup to determine all available exception
            #       classes.
            return base_exception_class_completions
        start_scoperef = self.get_start_scoperef()
        self.info("start scope is %r", start_scoperef)
        if self.trg.type == 'local-symbols':
            return self._available_symbols(start_scoperef, self.expr)
        # if self.trg.type == 'available-classes':
        # return self._available_classes(start_scoperef,
        # self.trg.extra["consumed"])
        hit = self._hit_from_citdl(self.expr, start_scoperef)
        return list(self._members_from_hit(hit))

    def eval_calltips(self):
        self.log_start()
        start_scoperef = self.get_start_scoperef()
        self.info("start scope is %r", start_scoperef)
        hit = self._hit_from_citdl(self.expr, start_scoperef)
        return [self._calltip_from_hit(hit)]

    def eval_defns(self):
        self.log_start()
        start_scoperef = self.get_start_scoperef()
        self.info("start scope is %r", start_scoperef)
        hit = self._hit_from_citdl(self.expr, start_scoperef, defn_only=True)
        return [self._defn_from_hit(hit)]

    def _defn_from_hit(self, hit):
        defn = TreeEvaluator._defn_from_hit(self, hit)
        if not defn.path:
            # Locate the module in the users own Python stdlib,
            # bug 65296.
            langintel = self.buf.langintel
            info = langintel.python_info_from_env(self.buf.env)
            ver, prefix, libdir, sitelibdir, sys_path = info
            if libdir:
                elem, (blob, lpath) = hit
                path = join(libdir, blob.get("name"))
                if exists(path + ".py"):
                    defn.path = path + ".py"
                elif isdir(path) and exists(join(path, "__init__.py")):
                    defn.path = join(path, "__init__.py")
        return defn

    # def _available_classes(self, scoperef, consumed):
    #    matches = set()
    #    blob = scoperef[0] # XXX??
    #    for elem in blob:
    #        if elem.tag == 'scope' and elem.get('ilk') == 'class':
    #            matches.add(elem.get('name'))
    #    matches.difference_update(set(consumed))
    #    matches_list = sorted(list(matches))
    #    return [('class', m) for m in matches_list]

    def _available_symbols(self, scoperef, expr):
        cplns = []
        found_names = set()
        while scoperef:
            elem = self._elem_from_scoperef(scoperef)
            if not elem:
                break
            for child in elem:
                if child.tag == "import":
                    name = child.get("alias") or child.get(
                        "symbol") or child.get("module")
                    # TODO: Deal with "*" imports.
                else:
                    name = child.get("name", "")
                if name.startswith(expr):
                    if name not in found_names:
                        found_names.add(name)
                        ilk = child.get("ilk") or child.tag
                        if ilk == "import":
                            ilk = "module"
                        cplns.append((ilk, name))
            scoperef = self.parent_scoperef_from_scoperef(scoperef)

        # Add keywords, being smart about where they are allowed.
        preceeding_text = self.trg.extra.get("preceeding_text", "")
        for keyword in self.buf.langintel.keywords:
            if len(keyword) < 3 or not keyword.startswith(expr):
                continue
            # Always add None and lambda, otherwise only at the start of lines.
            if not preceeding_text or keyword in ("None", "lambda"):
                cplns.append(("keyword", keyword))

        return sorted(cplns, key=operator.itemgetter(1))

    def _tokenize_citdl_expr(self, citdl):
        for token in citdl.split('.'):
            if token.endswith('()'):
                yield token[:-2]
                yield '()'
            else:
                yield token

    def _join_citdl_expr(self, tokens):
        return '.'.join(tokens)

    def _calltip_from_func(self, elem, scoperef, class_name=None):
        # See "Determining a Function CallTip" in the spec for a
        # discussion of this algorithm.
        signature = elem.get("signature")
        ctlines = []
        if not signature:
            name = class_name or elem.get("name")
            ctlines = [name + "(...)"]
        else:
            ctlines = signature.splitlines(0)
        doc = elem.get("doc")
        if doc:
            ctlines += doc.splitlines(0)
        return '\n'.join(ctlines)

    def _calltip_from_class(self, elem, scoperef):
        # If the class has a defined signature then use that.
        signature = elem.get("signature")
        if signature:
            doc = elem.get("doc")
            ctlines = signature.splitlines(0)
            if doc:
                ctlines += doc.splitlines(0)
            return '\n'.join(ctlines)
        else:
            ctor_hit = self._ctor_hit_from_class(elem, scoperef)
            if ctor_hit and (ctor_hit[0].get("doc")
                             or ctor_hit[0].get("signature")):
                self.log("ctor is %r on %r", *ctor_hit)
                return self._calltip_from_func(ctor_hit[0], ctor_hit[1],
                                               class_name=elem.get("name"))

            else:
                doc = elem.get("doc")
                if doc:
                    ctlines = [ln for ln in doc.splitlines(0) if ln]
                else:
                    ctlines = [elem.get("name") + "()"]
                return '\n'.join(ctlines)

    def _ctor_hit_from_class(self, elem, scoperef):
        """Return the Python ctor for the given class element, or None."""
        if "__init__" in elem.names:
            class_scoperef = (scoperef[0], scoperef[1]+[elem.get("name")])
            return elem.names["__init__"], class_scoperef
        else:
            for classref in elem.get("classrefs", "").split():
                try:
                    basehit = self._hit_from_type_inference(classref, scoperef)
                except CodeIntelError, ex:
                    self.warn(str(ex))
                else:
                    ctor_hit = self._ctor_hit_from_class(*basehit)
                    if ctor_hit:
                        return ctor_hit
        return None

    def _calltip_from_hit(self, hit):
        # TODO: compare with CitadelEvaluator._getSymbolCallTips()
        elem, scoperef = hit
        if elem.tag == "variable":
            XXX
        elif elem.tag == "scope":
            ilk = elem.get("ilk")
            if ilk == "function":
                calltip = self._calltip_from_func(elem, scoperef)
            elif ilk == "class":
                calltip = self._calltip_from_class(elem, scoperef)
            else:
                raise NotImplementedError("unexpected scope ilk for "
                                          "calltip hit: %r" % elem)
        else:
            raise NotImplementedError("unexpected elem for calltip "
                                      "hit: %r" % elem)
        return calltip

    def _members_from_elem(self, elem):
        """Return the appropriate set of autocomplete completions for
        the given element. Typically this is just one, but can be more for
        '*'-imports
        """
        members = set()
        if elem.tag == "import":
            alias = elem.get("alias")
            symbol_name = elem.get("symbol")
            module_name = elem.get("module")
            if symbol_name:
                import_handler = self.citadel.import_handler_from_lang(
                    self.trg.lang)
                blob = import_handler.import_blob_name(
                    module_name, self.libs, self.ctlr)
                if symbol_name == "*":
                    for m_name, m_elem in blob.names.items():
                        m_type = m_elem.get("ilk") or m_elem.tag
                        members.add((m_type, m_name))
                elif symbol_name in blob.names:
                    symbol = blob.names[symbol_name]
                    member_type = (symbol.get("ilk") or symbol.tag)
                    members.add((member_type, alias or symbol_name))
                else:
                    hit, nconsumed \
                        = self._hit_from_elem_imports([symbol_name], blob)
                    if hit:
                        symbol = hit[0]
                        member_type = (symbol.get("ilk") or symbol.tag)
                        members.add((member_type, alias or symbol_name))
                    else:
                        self.warn("could not resolve %r", elem)
            else:
                cpln_name = alias or module_name.split('.', 1)[0]
                members.add(("module", cpln_name))
        else:
            members.add((elem.get("ilk") or elem.tag, elem.get("name")))
        return members

    def _members_from_hit(self, hit):
        elem, scoperef = hit
        members = set()
        for child in elem:
            if "__hidden__" not in child.get("attributes", "").split():
                try:
                    members.update(self._members_from_elem(child))
                except CodeIntelError, ex:
                    self.warn("%s (skipping members for %s)", ex, child)
        if elem.get("ilk") == "class":
            for classref in elem.get("classrefs", "").split():
                try:
                    subhit = self._hit_from_type_inference(classref, scoperef)
                except CodeIntelError, ex:
                    # Continue with what we *can* resolve.
                    self.warn(str(ex))
                else:
                    members.update(self._members_from_hit(subhit))
            # Add special __class__ attribute.
            members.add(("variable", "__class__"))
        # Add special __doc__ attribute.
        members.add(("variable", "__doc__"))
        return members

    def _hit_from_citdl(self, expr, scoperef, defn_only=False):
        """Resolve the given CITDL expression (starting at the given
        scope) down to a non-import/non-variable hit.
        """
        self._check_infinite_recursion(expr)
        tokens = list(self._tokenize_citdl_expr(expr))
        # self.log("expr tokens: %r", tokens)

        # First part...
        hit, nconsumed = self._hit_from_first_part(tokens, scoperef)
        if not hit:
            # TODO: Add the fallback Buffer-specific near-by hunt
            #      for a symbol for the first token. See my spiral-bound
            #      book for some notes.
            raise CodeIntelError("could not resolve first part of '%s'" % expr)
        self.debug("_hit_from_citdl: first part: %r -> %r",
                   tokens[:nconsumed], hit)

        # ...the remainder.
        remaining_tokens = tokens[nconsumed:]
        while remaining_tokens:
            self.debug("_hit_from_citdl: resolve %r on %r in %r",
                       remaining_tokens, *hit)
            if remaining_tokens[0] == "()":
                new_hit = self._hit_from_call(*hit)
                nconsumed = 1
            else:
                new_hit, nconsumed \
                    = self._hit_from_getattr(remaining_tokens, *hit)
            remaining_tokens = remaining_tokens[nconsumed:]
            hit = new_hit

        # Resolve any variable type inferences.
        # TODO: Need to *recursively* resolve hits.
        elem, scoperef = hit
        if elem.tag == "variable" and not defn_only:
            elem, scoperef = self._hit_from_variable_type_inference(
                elem, scoperef)

        self.info("'%s' is %s on %s", expr, elem, scoperef)
        return (elem, scoperef)

    def _hit_from_first_part(self, tokens, scoperef):
        """Find a hit for the first part of the tokens.

        Returns (<hit>, <num-tokens-consumed>) or (None, None) if could
        not resolve.

        Example for 'os.sep':
            tokens: ('os', 'sep')
            retval: ((<variable 'sep'>,  (<blob 'os', [])),   1)
        Example for 'os.path':
            tokens: ('os', 'path')
            retval: ((<import os.path>,  (<blob 'os', [])),   2)
        """
        first_token = tokens[0]
        self.log("find '%s ...' starting at %s:", first_token, scoperef)

        # pythoncile will sometimes give a citdl expression of "__builtins__",
        # check for this now, bug:
        #   http://bugs.activestate.com/show_bug.cgi?id=71972
        if first_token == "__builtins__":
            # __builtins__ is the same as the built_in_blob, return it.
            scoperef = (self.built_in_blob, [])
            return (self.built_in_blob, scoperef), 1

        while 1:
            elem = self._elem_from_scoperef(scoperef)
            if first_token in elem.names:
                # TODO: skip __hidden__ names
                self.log("is '%s' accessible on %s? yes: %s",
                         first_token, scoperef, elem.names[first_token])
                return (elem.names[first_token], scoperef), 1

            if first_token == elem.get("name"):
                # The element itself is the thing we wanted...
                self.log("is '%s' accessible on %s? yes: %s",
                         first_token, scoperef, elem)
                return (elem, scoperef), 1

            hit, nconsumed \
                = self._hit_from_elem_imports(tokens, elem)
            if hit is not None:
                self.log("is '%s' accessible on %s? yes: %s",
                         '.'.join(tokens[:nconsumed]), scoperef, hit[0])
                return hit, nconsumed

            self.log("is '%s' accessible on %s? no", first_token, scoperef)
            scoperef = self.parent_scoperef_from_scoperef(scoperef)
            if not scoperef:
                return None, None

    def _set_reldirlib_from_blob(self, blob):
        """Set the relative import directory to be this blob's location."""
        # See bug 45822 and bug 88971 for examples of why this is necessary.
        if blob is None:
            return
        blob_src = blob.get("src")
        if blob_src and blob.get("ilk") == "blob":
            reldirpath = dirname(blob_src)
            reldirlib = self.mgr.db.get_lang_lib(self.trg.lang, "reldirlib",
                                                 [reldirpath])
            newlibs = self.libs[:]  # Make a copy of the libs.
            if newlibs[0].name == "reldirlib":
                # Update the existing reldirlib location.
                newlibs[0] = reldirlib
            else:
                # Add in the relative directory lib.
                newlibs.insert(0, reldirlib)
            self.log("imports:: setting reldirlib to: %r", reldirpath)
            self.libs = newlibs

    def _add_parentdirlib(self, libs, tokens):
        """Add a lazily loaded parent directory import library."""
        if isinstance(libs, PythonImportLibGenerator):
            # Reset to the original libs.
            libs = libs.libs
        libs = PythonImportLibGenerator(self.mgr, self.trg.lang, self.buf.path,
                                        tokens, libs)
        return libs

    def __hit_from_elem_imports(self, tokens, elem):
        """See if token is from one of the imports on this <scope> elem.

        Returns (<hit>, <num-tokens-consumed>) or (None, None) if not found.
        XXX import_handler.import_blob_name() calls all have potential
            to raise CodeIntelError.
        """
        # PERF: just have a .import_handler property on the evalr?
        import_handler = self.citadel.import_handler_from_lang(self.trg.lang)

        # PERF: Add .imports method to ciElementTree for quick iteration
        #      over them. Or perhaps some cache to speed this method.
        # TODO: The right answer here is to not resolve the <import>,
        #      just return it. It is complicated enough that the
        #      construction of members has to know the original context.
        #      See the "Foo.mypackage.<|>mymodule.yo" part of test
        #      python/cpln/wacky_imports.
        #      XXX Not totally confident that this is the right answer.
        first_token = tokens[0]
        possible_submodule_tokens = []

        self._check_infinite_recursion(first_token)
        orig_libs = self.libs
        for imp_elem in (i for i in elem if i.tag == "import"):
            libs = orig_libs  # reset libs back to the original
            self.debug("'%s ...' from %r?", tokens[0], imp_elem)
            alias = imp_elem.get("alias")
            symbol_name = imp_elem.get("symbol")
            module_name = imp_elem.get("module")
            allow_parentdirlib = True

            if module_name.startswith("."):
                allow_parentdirlib = False
                # Need a different curdirlib.
                lookuppath = self.buf.path
                while module_name.startswith("."):
                    lookuppath = dirname(lookuppath)
                    module_name = module_name[1:]
                libs = [self.mgr.db.get_lang_lib(self.trg.lang, "curdirlib",
                                                 [lookuppath])]
                if not module_name:
                    module_name = symbol_name
                    symbol_name = None

            if symbol_name:
                # from module import symbol, from module import symbol as alias
                # from module import submod, from module import submod as alias
                if (alias and alias == first_token) \
                   or (not alias and symbol_name == first_token):
                    # Try 'from module import symbol/from module import
                    # symbol as alias' first.
                    if allow_parentdirlib:
                        libs = self._add_parentdirlib(
                            libs, module_name.split("."))
                    try:
                        blob = import_handler.import_blob_name(
                            module_name, libs, self.ctlr)
                        if symbol_name in blob.names:
                            return (blob.names[symbol_name], (blob, [])),  1
                        else:
                            self._set_reldirlib_from_blob(blob)
                            hit, nconsumed = self._hit_from_elem_imports(
                                [first_token] + tokens[1:], blob)
                            if hit:
                                return hit, nconsumed
                    except CodeIntelError:
                        pass

                    # That didn't work, try 'from module import
                    # submod/from module import submod as alias'.
                    submodule_name = import_handler.sep.join(
                        [module_name, symbol_name])
                    if allow_parentdirlib:
                        libs = self._add_parentdirlib(
                            libs, submodule_name.split("."))
                    try:
                        subblob = import_handler.import_blob_name(
                            submodule_name, libs, self.ctlr)
                        return (subblob, (subblob, [])), 1
                    except CodeIntelError:
                        # That didn't work either. Give up.
                        self.warn("could not import '%s' from %s",
                                  first_token, imp_elem)

                # from module import *
                elif symbol_name == "*":
                    try:
                        if allow_parentdirlib:
                            libs = self._add_parentdirlib(
                                libs, module_name.split("."))
                        blob = import_handler.import_blob_name(
                            module_name, libs, self.ctlr)
                    except CodeIntelError:
                        pass  # don't freak out: might not be our import anyway
                    else:
                        self._set_reldirlib_from_blob(blob)
                        try:
                            hit, nconsumed = self._hit_from_getattr(
                                tokens, blob, (blob, []))
                        except CodeIntelError:
                            pass
                        else:
                            if hit:
                                return hit, nconsumed

            elif (alias and alias == first_token) \
                    or (not alias and module_name == first_token):
                if allow_parentdirlib:
                    libs = self._add_parentdirlib(libs, module_name.split("."))
                blob = import_handler.import_blob_name(
                    module_name, libs, self.ctlr)
                return (blob, (blob, [])),  1

            elif '.' in module_name:
                # E.g., might be looking up ('os', 'path', ...) and
                # have <import os.path>.
                module_tokens = module_name.split('.')
                if allow_parentdirlib:
                    libs = self._add_parentdirlib(libs, module_tokens)
                if module_tokens == tokens[:len(module_tokens)]:
                    # E.g. tokens:   ('os', 'path', ...)
                    #      imp_elem: <import os.path>
                    #      return:   <blob 'os.path'> for first two tokens
                    blob = import_handler.import_blob_name(
                        module_name, libs, self.ctlr)
                    # XXX Is this correct scoperef for module object?
                    return (blob, (blob, [])),  len(module_tokens)
                elif module_tokens[0] == tokens[0]:
                    # To check later if there are no exact import matches.
                    possible_submodule_tokens.append(module_tokens)

        # No matches, check if there is a partial import match.
        if possible_submodule_tokens:
            libs = orig_libs  # reset libs back to the original
            if allow_parentdirlib:
                libs = self._add_parentdirlib(libs, module_tokens)
            # E.g. tokens:   ('os', 'sep', ...)
            #      imp_elem: <import os.path>
            #      return:   <blob 'os'> for first token
            for i in range(len(module_tokens)-1, 0, -1):
                for module_tokens in possible_submodule_tokens:
                    if module_tokens[:i] == tokens[:i]:
                        blob = import_handler.import_blob_name(
                            '.'.join(module_tokens[:i]),
                            libs, self.ctlr)
                        # XXX Is this correct scoperef for module object?
                        return (blob, (blob, [])),  i

        return None, None

    def _hit_from_elem_imports(self, tokens, elem):
        """See if token is from one of the imports on this <scope> elem.

        Returns (<hit>, <num-tokens-consumed>) or (None, None) if not found.
        XXX import_handler.import_blob_name() calls all have potential
            to raise CodeIntelError.
        """
        # This is a wrapper function around the real __hit_from_elem_imports,
        # that will update the relative dir libs appropriately when an import
        # hit is made - see bug 88971 for why this is necessary.
        hit, nconsumed = self.__hit_from_elem_imports(tokens, elem)
        if hit is not None:
            self._set_reldirlib_from_blob(hit[0])
        return hit, nconsumed

    def _hit_from_call(self, elem, scoperef):
        """Resolve the function call inference for 'elem' at 'scoperef'."""
        # This might be a variable, in that case we keep resolving the variable
        # until we get to the final function/class element that is to be
        # called.
        while elem.tag == "variable":
            elem, scoperef = self._hit_from_variable_type_inference(
                elem, scoperef)
        ilk = elem.get("ilk")
        if ilk == "class":
            # Return the class element.
            self.log(
                "_hit_from_call: resolved to class '%s'", elem.get("name"))
            return (elem, scoperef)
        if ilk == "function":
            citdl = elem.get("returns")
            if citdl:
                self.log("_hit_from_call: function with citdl %r",
                         citdl)
                # scoperef has to be set to the function called
                func_scoperef = (scoperef[0], scoperef[1]+[elem.get("name")])
                return self._hit_from_citdl(citdl, func_scoperef)
        raise CodeIntelError("no return type info for %r" % elem)

    def _hit_from_getattr(self, tokens, elem, scoperef):
        """Return a hit for a getattr on the given element.

        Returns (<hit>, <num-tokens-consumed>) or raises an CodeIntelError.

        Typically this just does a getattr of tokens[0], but handling
        some multi-level imports can result in multiple tokens being
        consumed.
        """
        # TODO: On failure, call a hook to make an educated guess. Some
        #      attribute names are strong signals as to the object type
        #      -- typically those for common built-in classes.
        first_token = tokens[0]
        self.log("resolve getattr '%s' on %r in %r:", first_token,
                 elem, scoperef)
        if elem.tag == "variable":
            elem, scoperef = self._hit_from_variable_type_inference(
                elem, scoperef)

        assert elem.tag == "scope"
        ilk = elem.get("ilk")
        if ilk == "function":
            # Internal function arguments and variable should
            # *not* resolve. And we don't support function
            # attributes.
            pass
        elif ilk == "class":
            attr = elem.names.get(first_token)
            if attr is not None:
                self.log("attr is %r in %r", attr, elem)
                # update the scoperef, we are now inside the class.
                scoperef = (scoperef[0], scoperef[1] + [elem.get("name")])
                return (attr, scoperef), 1

            # When looking for a __class__ on a class instance, we match the
            # class itself - bug .
            if first_token == "__class__":
                self.log("attr is class %r", elem)
                return (elem, scoperef), 1

            self.debug("look for %r from imports in %r", tokens, elem)
            hit, nconsumed \
                = self._hit_from_elem_imports(tokens, elem)
            if hit is not None:
                return hit, nconsumed

            for classref in elem.get("classrefs", "").split():
                try:
                    self.log("is '%s' from base class: %r?", first_token,
                             classref)
                    base_elem, base_scoperef \
                        = self._hit_from_type_inference(classref, scoperef)
                    return self._hit_from_getattr(tokens, base_elem,
                                                  base_scoperef)
                except CodeIntelError, ex:
                    self.log("could not resolve classref '%s' on scoperef %r",
                             classref, scoperef, )
                    # Was not available, try the next class then.
        elif ilk == "blob":
            attr = elem.names.get(first_token)
            if attr is not None:
                self.log("attr is %r in %r", attr, elem)
                return (attr, scoperef), 1

            hit, nconsumed \
                = self._hit_from_elem_imports(tokens, elem)
            if hit is not None:
                return hit, nconsumed
        else:
            raise NotImplementedError("unexpected scope ilk: %r" % ilk)

        raise CodeIntelError("could not resolve '%s' getattr on %r in %r"
                             % (first_token, elem, scoperef))

    def _hit_from_variable_type_inference(self, elem, scoperef):
        """Resolve the type inference for 'elem' at 'scoperef'."""
        citdl = elem.get("citdl")
        if not citdl:
            raise CodeIntelError("no type-inference info for %r" % elem)
        self.log("resolve '%s' type inference for %r:", citdl, elem)
        return self._hit_from_citdl(citdl, scoperef)

    def _hit_from_type_inference(self, citdl, scoperef):
        """Resolve the 'citdl' type inference at 'scoperef'."""
        self.log("resolve '%s' type inference:", citdl)
        return self._hit_from_citdl(citdl, scoperef)

    @property
    def stdlib(self):
        # XXX Presume last lib is stdlib.
        return self.buf.libs[-1]

    _built_in_blob = None

    @property
    def built_in_blob(self):
        if self._built_in_blob is None:
            self._built_in_blob = self.stdlib.get_blob("*")
        return self._built_in_blob

    def parent_scoperef_from_scoperef(self, scoperef):
        blob, lpath = scoperef
        if lpath:
            parent_lpath = lpath[:-1]
            if parent_lpath:
                elem = self._elem_from_scoperef((blob, parent_lpath))
                if elem.get("ilk") == "class":
                    # Python eval shouldn't consider the class-level
                    # scope as a parent scope when resolving from the
                    # top-level. (test python/cpln/skip_class_scope)
                    parent_lpath = parent_lpath[:-1]
            return (blob, parent_lpath)
        elif blob is self._built_in_blob:
            return None
        else:
            return (self.built_in_blob, [])

    def _elem_from_scoperef(self, scoperef):
        """A scoperef is (<blob>, <lpath>). Return the actual elem in
        the <blob> ciElementTree being referred to.
        """
        elem = scoperef[0]
        for lname in scoperef[1]:
            elem = elem.names[lname]
        return elem

########NEW FILE########
__FILENAME__ = tree_ruby
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Completion evaluation code for Ruby"""

import re

from codeintel2.common import *
from codeintel2.tree import TreeEvaluator
from codeintel2.tree_javascript import JavaScriptTreeEvaluator
from codeintel2.database.stdlib import StdLib

# Evaluator
#   CitadelEvaluator
#       PythonCitadelEvaluator
#       ...
#   TreeEvaluator
#       PythonTreeEvaluator

# Global constants

NO_HITS = []  # Any value, as long as it's boolean(False)

_ANY_RESOLUTION = 1
_NAMESPACE_RESOLUTION = 2
_CLASS_RESOLUTION = 3

_OP_TO_RESOLUTION = {"::": _NAMESPACE_RESOLUTION,
                     ".": _CLASS_RESOLUTION}

# Bitmask for completion types

_CPLN_MODULES = 0x0001
_CPLN_METHODS_CLASS = 0x0002
_CPLN_METHODS_INST = 0x0004
_CPLN_METHODS_ALL = _CPLN_METHODS_CLASS | _CPLN_METHODS_INST
_CPLN_METHODS_ALL_FOR_MODULE = 0x0008
    # Look at the left hand side:
    # Module type: accept all methods
    # Class type: accept class methods only
_CPLN_CLASSES = 0x0010
_CPLN_VARIABLES = 0x0020

_CPLN_ALL_BUT_METHODS = _CPLN_MODULES | _CPLN_CLASSES | _CPLN_VARIABLES
_CPLN_ALL = _CPLN_ALL_BUT_METHODS | _CPLN_METHODS_ALL

# Global data

letter_start_re = re.compile('^[a-zA-Z]')
token_splitter_re = re.compile(r'(\.|::)')

_looks_like_constant_re = re.compile(r'[A-Z]\w*(?:::[A-Z]\w*)*$')


class HitHelper:
    """Encapsulate the ElementTree-based represetation
    of Ruby code"""

    def get_name(self, hit):
        return hit[0].get("name")

    def get_type(self, hit):
        elem = hit[0]
        return elem.get("ilk") or elem.tag

    def is_class(self, hit):
        return self.get_type(hit) == "class"

    def is_compound(self, hit):
        return self.get_type(hit) in ("class", "namespace")

    def is_function(self, hit):
        return self.get_type(hit) == "function"

    def is_namespace(self, hit):
        return self.get_type(hit) == "namespace"

    def is_variable(self, hit):
        return self.get_type(hit) == "variable"


class TreeEvaluatorHelper(TreeEvaluator):

    def _elem_from_scoperef(self, scoperef):
        """A scoperef is (<blob>, <lpath>). Return the actual elem in
        the <blob> ciElementTree being referred to.
        """
        elem = scoperef[0]
        for lname in scoperef[1]:
            if lname == elem.get("name", None):
                # This is the lname
                pass
            else:
                elem = elem.names[lname]
        return elem

    # Why is this not done specifically for Ruby?
    def _calltip_from_func(self, node):
        # See "Determining a Function CallTip" in the spec for a
        # discussion of this algorithm.
        signature = node.get("signature")
        doc = node.get("doc")
        ctlines = []
        if not signature:
            name = node.get("name")
            # XXX Note difference for Tcl in _getSymbolCallTips.
            ctlines = [name + "(...)"]
        else:
            ctlines = signature.splitlines(0)
        if doc:
            ctlines += doc.splitlines(0)
        return '\n'.join(ctlines)

    # This code taken from JavaScriptTreeEvaluator

    _langintel = None

    @property
    def langintel(self):
        if self._langintel is None:
            self._langintel = self.mgr.langintel_from_lang(self.trg.lang)
        return self._langintel

    _libs = None

    @property
    def libs(self):
        if self._libs is None:
            self._libs = self.langintel.libs_from_buf(self.buf)
        return self._libs


class RubyTreeEvaluator(TreeEvaluatorHelper):
    """
    scoperef: (<blob>, <lpath>) where <lpath> is list of names
        self._elem_from_scoperef()
    hit: (<elem>, <scoperef>)

    tokens = list(self._tokenize_citdl_expr(expr))   'foo.bar'
    """
    def __init__(self, ctlr, buf, trg, citdl_expr, line,
                 converted_dot_new=False):
        TreeEvaluatorHelper.__init__(self, ctlr, buf, trg, citdl_expr, line)
        # self._did_object = False
        self.converted_dot_new = converted_dot_new
        self.recursion_check_getattr = 0
        self.visited = {}
        self._hit_helper = HitHelper()
        self._get_current_names = trg.type == "names"
        self._framework_role = buf.framework_role or ""

    recursion_check_limit = 10

    def _rec_check_inc_getattr(self):
        self.recursion_check_getattr += 1
        if self.recursion_check_getattr > self.recursion_check_limit:
            raise CodeIntelError("Expression too complex")

    def _rec_check_dec_getattr(self):
        self.recursion_check_getattr -= 1

    _common_classes = {"Kernel": None, "Class": None, "Object": None}

    def _skip_common_ref(self, cls_name):
        return self.trg.implicit and cls_name in self._common_classes

    def _tokenize_citdl_expr(self, expr):
        toks = [x for x in token_splitter_re.split(expr) if x]
        if not toks:
            if self._get_current_names:
                return [""]
            else:
                return []
        elif toks[0] == "::":
            # XXX How does a leading :: affect symbol resolution here?
            # And a leading '.' should be a mistake
            del toks[0]
        return toks

    def eval_cplns(self):
        self.log_start()
        start_scoperef = self.get_start_scoperef()
        self.debug(
            "eval_cplns **************** -- eval(%r), scoperef(%r)", self.expr, start_scoperef)
        self._base_scoperefs = self._calc_base_scoperefs(start_scoperef)
        # This maps blob names to None, but it should map
        # (blob_name, scoperef[0], str(scoperef[1])) to None
        self._visited_blobs = {}
        # And this should be (variable_name, scoperef) => None,
        # Not just variable_name
        self._visited_variables = {}
        hits = self._hits_from_citdl(self.expr)
        hits = self._uniqify(hits)
        # eval_cplns doesn't call itself recursively.
        self._visited_blobs = {}
        self._visited_variables = {}

        trg_type = self.trg.type
        if trg_type == "literal-methods":
            allowed_cplns = _CPLN_METHODS_INST
        elif trg_type == "module-names":
            allowed_cplns = _CPLN_ALL_BUT_METHODS | _CPLN_METHODS_ALL_FOR_MODULE
        elif trg_type == "object-methods":
            if _looks_like_constant_re.match(self.expr):
                allowed_cplns = _CPLN_ALL_BUT_METHODS | _CPLN_METHODS_ALL_FOR_MODULE
                # bug 94237: Are we doing codeintel on a constant class/module or
                # on a constant variable?  Assume class/module, but allow
                # for code like XYZ = [3]; XYZ.<|>
                tokens = self._tokenize_citdl_expr(self.expr)
                if tokens:
                    var_hits = self._hits_from_first_part(tokens[0], None)
                    if var_hits and self._hit_helper.is_variable(var_hits[0]):
                        # Correct the kind of completions we'll do
                        allowed_cplns = _CPLN_METHODS_INST
            else:
                allowed_cplns = _CPLN_METHODS_INST
        elif self._get_current_names:
            allowed_cplns = _CPLN_ALL
            elem = self._elem_from_scoperef(start_scoperef)
            if elem:
                ilk = elem.get("ilk")
                if ilk == "class":
                    allowed_cplns = _CPLN_ALL_BUT_METHODS | _CPLN_METHODS_CLASS
                elif ilk == "function" and not self._framework_role.startswith("rails.models"):
                    # Rails does too much with instance models dynamically
                    # at runtime:
                    # 1.) adds methods based on column names in the model's
                    #     underlying database table
                    # 2.) copies class methods into instance methods

                    parent_scope = self.parent_scoperef_from_scoperef(
                        start_scoperef)
                    parent_elem = self._elem_from_scoperef(parent_scope)
                    if parent_elem.get("ilk") == "class":
                        allowed_cplns = _CPLN_ALL_BUT_METHODS | _CPLN_METHODS_INST
                    # Otherwise allow them all

        else:
            raise CodeIntelError(
                "Failed to handle trigger type '%s'" % trg_type)

        held_get_current_names = self._get_current_names
        self._get_current_names = False
        cplns = self._cplns_from_hits(hits, allowed_cplns)
        if held_get_current_names:
            for kwd in self.langintel.RUBY_KEYWORDS.keys():
                cplns.add(("function", kwd))  # "keyword" would be nice
            cplns = self._filter_by_prefix(cplns, self.expr)
        self.debug("eval_cplns: raw list: %r", cplns)
        cpln_list = list(cplns)
        # Don't bother if they have one more char to type.
        if (held_get_current_names and
            self.trg.implicit and
            len(cpln_list) == 1 and
            (cpln_list[0][1] == self.expr or
             (cpln_list[0][1][0: -1] == self.expr))):
            return []
        return cpln_list

    def _filter_by_prefix(self, cplns, prefix):
        if prefix and len(prefix):
            cplns = [x for x in cplns if x[1].startswith(prefix)]
        return cplns

    def eval_calltips(self):
        self.log_start()
        self.debug("eval_calltip **************** -- eval(%r)" % self.expr)
        start_scoperef = self.get_start_scoperef()
        self._base_scoperefs = self._calc_base_scoperefs(start_scoperef)
        self._visited_blobs = {}
        self._visited_variables = {}
        hits = self._hits_from_citdl(self.expr)
        hits = self._uniqify(hits)
        self._visited_blobs = {}
        self._visited_variables = {}
        return self._calltips_from_hits(hits)

    def eval_defns(self):
        self.log_start()
        start_scoperef = self.get_start_scoperef()
        self._base_scoperefs = self._calc_base_scoperefs(start_scoperef)
        self._visited_blobs = {}
        self._visited_variables = {}
        hits = self._hits_from_citdl(self.expr)
        hits = self._uniqify(hits)
        defns = [self._defn_from_hit(hit) for hit in hits]
        return defns

    def _flatten(self, a):
        return reduce(lambda x, y: x + y, a, [])

    def _calc_base_scoperefs(self, curr_scoperef):
        scoperefs = [curr_scoperef, (self.built_in_blob, [])]
        # Next find the other scoperefs in the current scoperef
        imports = []
        while curr_scoperef:
            elem = self._elem_from_scoperef(curr_scoperef)
            # Are there any import tags here?
            imports.append([x for x in elem if x.tag == "import"])
            curr_scoperef = self.parent_scoperef_from_scoperef(curr_scoperef)
        imports.reverse()
        imports = self._flatten(imports)
        for imp_elem in imports:
            if imp_elem.get("module") is None:
                # include Namespace
                # Look at current scoperefs to resolve it
                namespace_name = imp_elem.get("symbol")
                if namespace_name[0].isupper():
                    # Use new_scoperefs to avoid modifying a list
                    # while we're looping over it
                    new_scoperefs = []
                    for sc in scoperefs:
                        self._visited_blobs = {}
                        sc_hits = self._hits_from_citdl(namespace_name,
                                                        resolve_var=False,
                                                        only_scoperef=sc)
                        for sc_hit in sc_hits:
                            sc_hit_name = sc_hit[0].get("name")
                            if sc_hit_name:
                                new_scoperefs.append((sc_hit[1][0],
                                                      sc_hit[1][1] + sc_hit_name.split("::")))
                    scoperefs += new_scoperefs
            elif imp_elem.get("symbol") == "*":
                # Here we need to import a blob...
                blob = self._get_imported_blob(imp_elem)
                if blob is not None:
                    scoperefs.append((blob, []))

        # Check for blobs in the catalog
        # Note that we're getting closer to implementing
        # a transitive closure for include statements.  With the
        # way Rails is implemented we're safe doing this to
        # one level of inclusion.

        if self._framework_role:
            framework_parts = self._framework_role.split(".")
            try:
                framework_name = framework_parts[0]
                catalog_selections = [framework_name]
                new_lib = self.mgr.db.get_catalog_lib(
                    "Ruby", catalog_selections)
                if new_lib:
                    node = new_lib.get_blob(framework_name)
                    framework_sc = (node, [])
                    scoperefs.append(framework_sc)

                    for imp_elem in imports:
                        if imp_elem.get("module") is None:
                            # include Namespace
                            # Look at current scoperefs to resolve it
                            namespace_name = imp_elem.get("symbol")
                            if namespace_name[0].isupper():
                                # Use new_scoperefs to avoid modifying a list
                                # while we're looping over it
                                new_scoperefs = []
                                self._visited_blobs = {}
                                sc_hits = self._hits_from_citdl(namespace_name,
                                                                resolve_var=False,
                                                                only_scoperef=framework_sc)
                                for sc_hit in sc_hits:
                                    inner_elem = sc_hit[0]
                                    sc_hit_name = inner_elem.get("name")
                                    if sc_hit_name:
                                        new_scoperefs.append((sc_hit[0], []))
                                        inner_imports = inner_elem.findall(
                                            'import')
                                        for import2 in inner_imports:
                                            if import2.get('module') is None:
                                                inner_namespace_name = import2.get(
                                                    'symbol')
                                                if inner_namespace_name[0].isupper():
                                                    sc2_hits = self._hits_from_citdl(
                                                        inner_namespace_name,
                                                        resolve_var=False,
                                                        only_scoperef=framework_sc)
                                                    for sc2_hit in sc2_hits:
                                                        new_scoperefs.append(
                                                            (sc2_hit[0], []))
                                scoperefs += new_scoperefs

            except AttributeError, ex:
                self.debug("_calc_base_scoperefs: %s", ex)
                pass

        kh = self._get_kernel_hit()
        if kh is not None:
            scoperefs.append((kh[0], kh[1][1]))

        return scoperefs

    def _is_rails_application_controller(self, blob):
        for kid in blob.findall("scope"):
            if kid.tag == "scope" and kid.get("ilk") == "class" and kid.get("classrefs") == "ActiveController::Base":
                return True
        return False

    # All following methods initially stolen from tree_python.py,
    # then rewritten

    def _is_alias(self, elem):
        return elem.tag == "variable" and elem.get("attributes", "").find("__alias__") >= 0

    def _calltips_from_hits(self, hits):
        calltips = []
        for hit in hits:
            self.debug("looking for a calltip on hit %r", hit)
            elem, scoperef = hit
            if elem.tag == "scope":
                ilk = elem.get("ilk")
                if ilk == "function":
                    calltips.append(self._calltip_from_func(elem))
                elif ilk != "class":
                    # no calltips on classes
                    # only method and class names are expected here.
                    raise NotImplementedError("unexpected scope ilk for "
                                              "calltip hit: %r" % elem)
            elif self._is_alias(elem):
                # Is it an alias for a function?
                scoperef = self._find_first_scoperef(elem)
                if scoperef:
                    alias_hits = self._hits_from_variable_type_inference(
                        (elem, scoperef),
                        resolve_var=False)
                    for alias_hit in alias_hits:
                        alias_elem = alias_hit[0]
                        if self._hit_helper.is_function(alias_hit):
                            calltip = self._calltip_from_func(alias_elem)\
                                # Hack: Perform surgery on the calltip if
                                # needed
                            if calltip.startswith(alias_elem.get("name")):
                                calltip = elem.get("name") + calltip[
                                    len(alias_elem.get("name")):]
                            calltips.append(calltip)
            else:
                raise NotImplementedError("unexpected elem for calltip "
                                          "hit: %r" % elem)
        return calltips

    def _uniqify(self, lst):
        if not lst:
            return lst
        new_list = []
        for i in range(len(lst) - 1):
            if lst[i] not in lst[i + 1:]:
                new_list.append(lst[i])
        new_list.append(lst[-1])
        return new_list

    def _find_first_scoperef(self, elem):
        blob = self._base_scoperefs[0][0]
        nodes = [node for node in blob.findall(".//variable")
                 if node.get("name") == elem.get("name")]
        for node in nodes:
            line_num = node.get("line")
            if line_num:
                return self.buf.scoperef_from_blob_and_line(blob, int(line_num) + 1)

    def _elem_classification(self, elem):
        if elem.tag == "variable":
            return _CPLN_VARIABLES
        elif elem.tag == "scope":
            ilk = elem.get("ilk")
            if ilk is None:
                return 0
            elif ilk == "namespace":
                return _CPLN_MODULES
            elif ilk == "class":
                return _CPLN_CLASSES
            elif ilk == "function":
                if (elem.get("attributes", "").find("__classmethod__") > -1
                        or elem.get("name").find(".") > -1):
                    return _CPLN_METHODS_CLASS
                else:
                    return _CPLN_METHODS_INST

        self.debug("Can't classify elem '%r'", elem)
        return 0

    def _cplns_from_hits(self, hits, allowed_cplns):
        members = set()
        self.debug("_cplns_from_hits: allowed_cplns %x", allowed_cplns)

        for hit in hits:
            elem, scoperef = hit
            self.debug("elem %r", elem)
            for child in elem:
                # self.debug("child %r", child)
                # child_type = self._hit_helper.get_type([child])
                if child.tag == "variable":
                    if self._is_alias(child):
                        # If the variable resolves to another object:
                        #    If it resolves to a function, use the target only
                        #    Otherwise use both the variable and its hits
                        scoperef = self._find_first_scoperef(child)
                        if scoperef:
                            alias_hits = self._hits_from_variable_type_inference(
                                (child, scoperef),
                                resolve_var=False)
                            include_self = False
                            for alias_hit in alias_hits:
                                alias_elem = alias_hit[0]
                                if self._hit_helper.is_variable(alias_hit):
                                    # Don't point var_lhs to var_rhs
                                    pass
                                elif (self._hit_helper.is_function(alias_hit)
                                      and not include_self
                                      and (allowed_cplns & _CPLN_METHODS_ALL)):
                                    include_self = True
                                    members.add((
                                        "function", child.get("name")))
                                    members.add((alias_elem.get(
                                        "ilk") or alias_elem.tag, alias_elem.get("name")))
                                else:
                                    members.update(self._members_from_elem(
                                        child, allowed_cplns))
                    elif allowed_cplns & _CPLN_VARIABLES:
                        members.update(self._members_from_elem(
                            child, allowed_cplns))
                else:
                    members.update(self._members_from_elem(
                        child, allowed_cplns))
                    # Special case the child w.r.t the parent
                    if allowed_cplns & _CPLN_METHODS_ALL_FOR_MODULE:
                        elem_type = self._elem_classification(elem)
                        if elem_type & (_CPLN_MODULES | _CPLN_CLASSES):
                            child_type = self._elem_classification(child)
                            if ((child_type & _CPLN_METHODS_CLASS) or
                                ((child_type & _CPLN_METHODS_INST) and
                                 (elem_type == _CPLN_MODULES))):
                                members.add(("function", child.get("name")))

            if elem.get("ilk") == "class":
                classref = elem.get("classrefs")
                if classref is not None:
                    if classref not in self._visited_blobs:
                        self._visited_blobs[classref] = None
                        insert_scoperef = True
                        self._base_scoperefs.insert(0, scoperef)
                        try:
                            ref_hits = self._hits_from_classref(classref)
                            del self._base_scoperefs[0]
                            insert_scoperef = False
                            if ref_hits:
                                members.update(self._cplns_from_hits(
                                    ref_hits, allowed_cplns))
                        finally:
                            if insert_scoperef:
                                del self._base_scoperefs[0]

                if ((allowed_cplns & _CPLN_METHODS_CLASS) or
                    ((allowed_cplns & _CPLN_METHODS_ALL_FOR_MODULE) and
                     (self._elem_classification(elem) & _CPLN_CLASSES))):
                    init_method = elem.names.get("initialize")
                    if not init_method or \
                       not init_method.get("attributes") == "private":
                        members.add(("function", "new"))

        return members

    def _members_from_elem(self, elem, allowed_cplns):
        """Return the appropriate set of autocomplete completions for
        the given element. Typically this is just one, but can be more for
        '*'-imports
        """
        members = set()
        if elem.tag == "import":
            symbol_name = elem.get("symbol")
            module_name = elem.get("module")
            if module_name is None:
                if symbol_name in self._visited_blobs:
                    return members
                self._visited_blobs[symbol_name] = None
                hits = self._hits_from_citdl(symbol_name)
                for hit in hits:
                    for child in hit[0]:
                        members.update(self._members_from_elem(
                            child, allowed_cplns))
            elif symbol_name is not None and self.citadel:
                if module_name in self._visited_blobs:
                    return members
                self._visited_blobs[module_name] = None
                import_handler = self.citadel.import_handler_from_lang(
                    self.trg.lang)
                try:
                    self.debug(
                        "_members_from_elem: about to call import_handler.import_blob_name(module_name=%r), symbol_name=%r", module_name, symbol_name)
                    blob = import_handler.import_blob_name(
                        module_name, self.libs, self.ctlr)
                except CodeIntelError:
                    self.warn(
                        "_members_from_elem: limitation in handling imports in imported modules")
                    # It could be an incomplete module name in a require statement in the current buffer,
                    # so don't throw an exception.
                    return members

                # Check all children
                for blob_child in blob.getchildren():
                    imported_name = blob_child.get('name')
                    if imported_name is None:
                        continue
                    if symbol_name == "*" or symbol_name == imported_name:
                        try:
                            member_type = (blob_child.get(
                                "ilk") or blob_child.tag)
                            if symbol_name == "*":
                                if self._elem_classification(blob_child) & allowed_cplns:
                                    members.add((member_type, imported_name))
                            elif (member_type == "class"
                                  and (allowed_cplns & _CPLN_METHODS_INST)):
                                # Burrow if it doesn't match
                                for child_elem in blob_child:
                                    if self._elem_classification(child_elem) & allowed_cplns:
                                        members.add((child_elem.get(
                                            "ilk"), child_elem.get("name")))
                                    else:
                                        self.debug(
                                            "Not adding from %s: %s isn't allowed", imported_name, child_elem.get("name"))
                                        pass
                            else:
                                self.debug(
                                    "Not adding from %s: member_type=%s or not fabricated", imported_name, member_type)
                                pass
                        except CodeIntelError, ex:
                            self.warn(
                                "_members_from_elem: %s (can't look up member %r in blob %r)", ex, imported_name, blob)

            elif allowed_cplns & _CPLN_MODULES:
                cpln_name = module_name.split('/', 1)[0]
                members.add(("module", cpln_name))
        elif self._elem_classification(elem) & allowed_cplns:
            members.add((elem.get("ilk") or elem.tag, elem.get("name")))
        return members

    def _hits_from_classref(self, expr):
        hits = self._hits_from_citdl(expr)
        if hits:
            return hits
        hits = []  # In case they're none
        # Look at the includes in this scoperef
        curr_scoperef = self._base_scoperefs[0]
        imports = []
        blobs = []
        # XXX Look only at includes in the current scope
        while curr_scoperef:
            elem = self._elem_from_scoperef(curr_scoperef)
            imports += self._get_included_modules(elem)
            blobs += [self._get_imported_blob(
                x) for x in self._get_required_modules(elem)]
            curr_scoperef = self.parent_scoperef_from_scoperef(curr_scoperef)

        for blob in blobs:
            # First look for top-level names in each blob
            hit_list = [x for x in blob if x.get("name") == expr]
            if expr in blob.names:
                hits += [(hit, (blob, [])) for hit in hit_list]
            # Now look to see if we've included any modules in blob
            for imp in imports:
                ns_name = imp.get('symbol')
                for ns_blob in blob:
                    if ns_blob.get("ilk") == "namespace" and ns_blob.get("name") == ns_name:
                        for candidate in ns_blob:
                            if candidate.get("ilk") == "class" and candidate.get("name") == expr:
                                hits += [(candidate, (blob, [ns_name]))]
        return hits

    def _hits_from_citdl(self, expr, resolve_var=True, only_scoperef=None):
        """Resolve the given CITDL expression (starting at the given
        scope) down to a non-import/non-variable hit.

        The tokens contain ::'s and .'s so we know when we should have
        a namespace on the left, and when we should have a class or object.
        """
        tokens = self._tokenize_citdl_expr(expr)
        self.debug("_hit_from_citdl: expr tokens: %r, look in %d scopes",
                   tokens, only_scoperef and 1 or len(self._base_scoperefs))
        # Another note: if we only have one token, we assume we're
        # resolving a variable expression, and do the usual name lookups
        # Prefix handling has to be done by a different function that
        # looks only at self._base_scoperefs

        # First part...
        hits = self._hits_from_first_part(tokens[0], only_scoperef)
        if not hits:
            return NO_HITS

        # If we're doing definition-lookup, we don't want to resolve
        # a standalone variable expression to its underlying type.
        # Just use the point its defined at, which is in the
        # hits variable.
        hits_var = []
        prev_tok = first_token = tokens[0]
        if (resolve_var and (len(tokens) > 1 or self.trg.form != TRG_FORM_DEFN)):
            # Either all the hits are possible types for the variable, or they're
            # all just definitions (although that's unlikely).
            first_hit = hits[0]
            if self._hit_helper.is_variable(first_hit):
                hits_var = []
                for h in hits:
                    hits_var += self._hits_from_variable_type_inference(
                        h) or []
                hits = [
                    h for h in hits_var if not self._hit_helper.is_variable(h)]
                if not hits:
                    # They're all variables
                    var_name = self._hit_helper.get_name(first_hit)
                    self.debug(
                        "_hit_from_citdl: failed to resolve variable '%r'",
                        var_name)
                    return NO_HITS
                prev_tok = hits[0][0].get("name", None) or tokens[0]

        hits_final = hits
        # Now walk our list, first culling complete names separated
        # by [::, name] or [., name]
        idx = 1
        lim_sub1 = len(tokens) - 1

        if idx <= lim_sub1:
            if tokens[1] == "::":
                hits = [h for h in hits if self._hit_helper.is_compound(h)]
                if not hits:
                    self.debug(
                        "_hit_from_citdl: trying to do namespace resolution on %s '%r'",
                        self._hit_helper.get_type(hits[0]),
                        self._hit_helper.get_name(hits[0]))
                    return NO_HITS

        while idx <= lim_sub1 and hits:
            tok = tokens[idx]
            if tok == '::':
                filter_type = _NAMESPACE_RESOLUTION
            elif tok == '.':
                filter_type = _CLASS_RESOLUTION
            else:
                self.debug(
                    "_hit_from_citdl: got an unexpected resolution op of '%r'", tok)
                return NO_HITS
            idx += 1
            if idx > lim_sub1:
                break
            tok = tokens[idx]
            # XXX Pull out each name that isn't a prefix
            new_hits = []
            for hit in hits:
                new_hits += self._hits_from_getattr(
                    hit, tok, filter_type) or []
            if not new_hits:
                break
            hits = [(x[0], (x[1][0], x[1][1] + [prev_tok])) for x in new_hits]
            hits_final = hits
            prev_tok = tok
            idx += 1
        return hits_final

    def _hits_from_getattr(self, hit, token, filter_type):
        self._rec_check_inc_getattr()
        try:
            new_hits = self._hits_from_getattr_aux(hit, token, filter_type)
            if not new_hits:
                self.debug(
                    "_hits_from_getattr: couldn't resolve %r.%r", hit[0], token)
            return new_hits
        finally:
            self._rec_check_dec_getattr()

    def _hits_from_getattr_aux(self, hit, first_token, filter_type):
        elem = hit[0]
        self.log(
            "_hits_from_getattr: resolve getattr '%s' on %r, filter_type %d",
            first_token, elem, filter_type)

        if elem.tag == "variable":
            self.log("... failed on %s", elem.tag)
            return None

        assert elem.tag == "scope"
        ilk = elem.get("ilk")
        if ilk == "function":
            self.log("... failed on %s", ilk)
            return None
        elif ilk == "class":
            if first_token == 'new':
                return [hit]
            # XXX - stop allowing variables here.
            if first_token in elem.names:
                self.log(
                    "_hits_from_getattr: name %s is in %r", first_token, elem)
                hits = []
                self._append_hits_from_name(hits, first_token, hit[1], elem)
                return hits
            self.debug(
                "_hits_from_getattr: look for %r from imports in %r", first_token, elem)
            new_hit = self._hit_from_elem_imports(
                elem, first_token, filter_type)
            if new_hit:
                return [new_hit]

            classref = elem.get("classrefs")
            if classref:
                # if self._skip_common_ref(classref):
                #    continue
                if classref not in self._visited_blobs:
                    self._visited_blobs[classref] = True
                    new_hit = self._hit_from_type_inference(
                        classref, first_token, filter_type)
                    if new_hit:
                        return [new_hit]
        elif ilk == "namespace":
            if first_token in elem.names:
                self.log(
                    "_hits_from_getattr: name %s is in %r", first_token, elem)
                hits = []
                self._append_hits_from_name(hits, first_token, hit[1], elem)
                return hits

    def _hit_from_elem_imports(self, elem, first_token, filter_type):
        """See if token is from one of the imports on this <scope> elem.

        Returns a hit
        """
        # XXX Allow multiple hits

        self.debug("_hit_from_elem_imports :")
        # See some comments in the method with the same name in
        # tree_python.
        #
        # This routine recursively follows Ruby include statements,
        # guarding duplicates.

        imports = self._get_included_modules(elem)
        for imp in imports:
            hits = self._hits_from_citdl(imp.get("symbol"))
            for hit in hits:
                new_hits = self._hits_from_getattr(
                    hit, first_token, filter_type)
                if new_hits:
                    return new_hits[0]

    def _hit_from_type_inference(self, classname, first_token, filter_type):
        hits = self._hits_from_citdl(classname)
        for hit in hits:
            new_hits = self._hits_from_getattr(hit, first_token, filter_type)
            if new_hits:
                return new_hits[0]

    def _get_kernel_hit(self):
        try:
            return self.built_in_blob.names["Kernel"], (self.built_in_blob, [])
        except KeyError:
            return None

    def _hits_from_first_part(self, first_token, only_scoperef):
        """Find all possible hits for the first token in the submitted
        scoperefs (normally the current blob and the builtin blob).

        We need to check all required modules as well --
        these look like <import module=lib symbol="*">

        Also check imported names: <import symbol=Namespace />

        Returns a list of <hit> or [] if we could
        not resolve.

        Example for 'String' normally:
            retval: [(<class 'String'>, (<blob '*'>, [])),]

        Let's say they opened it in the source to add a new method:
            retval: [(<class 'String'>, (<blob '*'>, [])),]
                     (<class 'String'>, (<blob 'this'>, ['file', 'class']))]
        """

        if self._get_current_names:
            # Look up the completions later.
            # Like in triggered lookup, move up the first blob only scoperef =
            # self._base_scoperefs[0]
            hits = []
            scoperef = only_scoperef or self._base_scoperefs[0]
            while True:
                elem = self._elem_from_scoperef(scoperef)
                if elem is not None:
                    if only_scoperef is None:
                        hits.append((elem, scoperef))
                    elif first_token in elem.names:
                        self._append_hits_from_name(
                            hits, first_token, scoperef, elem)
                scoperef = self.parent_scoperef_from_scoperef(scoperef)
                if not scoperef:
                    break

            # And put the rest of the blobs on the hit list
            if only_scoperef is None:
                hits += [(sc[0], sc) for sc in self._base_scoperefs[1:]]
            return hits

        # With the first one, we move up.  With others we don't.
        scoperef = only_scoperef or self._base_scoperefs[0]
        hits = []
        self.log("_hit_from_first_part: try to resolve '%s' ...", first_token)
        while scoperef:
            elem = self._elem_from_scoperef(scoperef)
            if elem is not None and first_token in elem.names:
                # TODO: skip __hidden__ names
                self.log(
                    "_hit_from_first_part: is '%s' accessible on %s? yes: %s",
                    first_token, scoperef, elem.names[first_token])
                self._append_hits_from_name(hits, first_token, scoperef, elem)
                break
            self.log(
                "_hit_from_first_part: is '%s' accessible on %s? no", first_token, scoperef)
            scoperef = self.parent_scoperef_from_scoperef(scoperef)
        if only_scoperef or (hits and self._hit_helper.is_variable(hits[0])):
            return hits

        for scoperef in self._base_scoperefs[1:]:
            elem = self._elem_from_scoperef(scoperef)
            if first_token in elem.names:
                # TODO: skip __hidden__ names
                self.log(
                    "_hit_from_first_part: is '%s' accessible on %s? yes: %s",
                    first_token, scoperef, elem.names[first_token])
                self._append_hits_from_name(hits, first_token, scoperef, elem)

        if not hits:
            # Try importing all importable blobs then
            for scoperef in self._base_scoperefs[2:]:
                imports = self._get_required_modules(scoperef[0])
                for imp in imports:
                    blob = self._get_imported_blob(imp)
                    if blob and first_token in blob.names:
                        # Collect all possible hits
                        hits.append((blob.names[
                                    first_token], (blob, [first_token])))

        return hits

    def _append_hits_from_name(self, hits, first_token, scoperef, elem):
        blob, list = scoperef
        new_scoperef = blob, list  # + [first_token]
        # Allow for multiple hits of compound things -- names() returns the
        # last
        hit_list = [x for x in elem.findall(
            "scope") if x.get("name") == first_token]
        if hit_list:
            if len(hit_list) > 1 and not hit_list[-1].get("name")[0].isupper():
                # Keep the last variable or function def
                hits.append((hit_list[-1], new_scoperef))
            else:
                hits += [(x, new_scoperef) for x in hit_list]
        else:
            hits.append((elem.names[first_token], new_scoperef))

    def _get_imported_blob(self, imp_elem):
        return self._get_imported_blob_from_name(imp_elem.get("module"))

    def _get_imported_blob_from_name(self, module_name):
        import_handler = self.citadel.import_handler_from_lang(self.trg.lang)
        self.debug("_get_imported_blob(1): (module %r)?", module_name)
        try:
            blob = import_handler.import_blob_name(
                module_name, self.libs, self.ctlr)
            return blob
        except CodeIntelError, ex:
            # Continue looking
            self.warn("_get_imported_blob(2): %s", str(ex))

    def _get_included_modules(self, elem):
        return [x for x in elem.findall("import") if x.get("module") is None]

    def _get_required_modules(self, elem):
        return [x for x in elem.findall("import") if x.get("symbol") == "*"]

    def _hits_from_variable_type_inference(self, hit, resolve_var=True):
        """Resolve the type inference for 'elem' at 'scoperef'."""
        assert self._hit_helper.is_variable(hit)
        elem, scoperef = hit
        citdl = elem.get("citdl")
        if not citdl:
            raise CodeIntelError(
                "_hit_from_variable_type_inference: no type-inference info for %r" % elem)
        if citdl in self._visited_variables:
            self.log(
                "_hit_from_variable_type_inference: already looked at var '%s'", citdl)
            return NO_HITS
        self._visited_variables[citdl] = None

        self.log(
            "_hit_from_variable_type_inference: resolve '%s' type inference for %r:", citdl, elem)
        # Always insert a scoperef while we're looking for a hit.
        self._base_scoperefs.insert(0, scoperef)
        try:
            hits = self._hits_from_citdl(citdl, resolve_var)
        finally:
            del self._base_scoperefs[0]
        self.debug("_hits_from_variable_type_inference(%s) (citdl '%r') ==> '%r'", elem.get(
            "name"), citdl, hits)
        return hits

    _built_in_blob = None

    @property
    def built_in_blob(self):
        if self._built_in_blob is None:
            # HACK: Presume second-last or last lib is stdlib.
            # TODO: replace this with buf.stdlib.
            if isinstance(self.libs[-1], StdLib):
                stdlib = self.libs[-1]
            elif isinstance(self.libs[-2], StdLib):
                stdlib = self.libs[-2]
            assert isinstance(stdlib, StdLib), \
                "not stdlib, but '%r'" % stdlib
            self._built_in_blob = stdlib.get_blob("*")
        return self._built_in_blob

    def parent_scoperef_from_scoperef(self, scoperef):
        # TODO: compare with CitadelEvaluator.getParentScope()
        blob, lpath = scoperef
        if lpath:
            return (blob, lpath[:-1])
        else:
            return None

    def post_process_cplns(self, cplns):
        self.debug("In RubyTreeEvaluator.post_process_cplns: %r", cplns)
        """Remove completions that don't start with a letter"""
        fixed_cplns = [x for x in cplns if letter_start_re.match(x[1])]
        return TreeEvaluatorHelper.post_process_cplns(self, fixed_cplns)

    _s_initialize_new = re.compile(r'^initialize\(')

    def post_process_calltips(self, calltips):
        # XXX Trent is this test right, or should I always convert?
        # Inside a class 'initialize' is a private class, and while
        # it shouldn't be called, it can be.

        if self.converted_dot_new:
            fixed_calltips = [self._s_initialize_new.sub(
                'new(', x) for x in calltips]
            return fixed_calltips
        return calltips

    # c.f. tree_python.py::PythonTreeEvaluator
    # c.f. citadel.py::CitadelEvaluator

########NEW FILE########
__FILENAME__ = udl
#!python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""UDL (User-Defined Language) support for codeintel."""

import os
from os.path import dirname, join, abspath, normpath, basename, exists
import sys
import re
import logging
import threading
import operator
import traceback
from pprint import pprint, pformat

import SilverCity
from SilverCity import ScintillaConstants
from SilverCity.ScintillaConstants import *  # XXX import only what we need
from SilverCity.Lexer import Lexer

from codeintel2.common import *
from codeintel2.citadel import CitadelBuffer
# from codeintel2.javascript_common import trg_from_pos as
# javascript_trg_from_pos

if _xpcom_:
    from xpcom import components
    from xpcom.server import UnwrapObject
    import directoryServiceUtils

log = logging.getLogger("codeintel.udl")
# log.setLevel(logging.DEBUG)

# XXX We need to have a better mechanism for rationalizing and sharing
#    common lexer style classes. For now we'll just HACKily grab from
#    Komodo's styles.py. Some of this is duplicating logic in
#    KoLanguageServiceBase.py.
_ko_src_dir = normpath(join(dirname(__file__), *([os.pardir]*3)))
sys.path.insert(0, join(_ko_src_dir, "schemes"))
try:
    import styles
finally:
    del sys.path[0]
    del _ko_src_dir


#---- module interface
# Test 'udl/general/is_udl_x_style' tests these.
def is_udl_m_style(style):
    return (ScintillaConstants.SCE_UDL_M_DEFAULT <= style
            <= ScintillaConstants.SCE_UDL_M_COMMENT)


def is_udl_css_style(style):
    return (ScintillaConstants.SCE_UDL_CSS_DEFAULT <= style
            <= ScintillaConstants.SCE_UDL_CSS_OPERATOR)


def is_udl_csl_style(style):
    return (ScintillaConstants.SCE_UDL_CSL_DEFAULT <= style
            <= ScintillaConstants.SCE_UDL_CSL_REGEX)


def is_udl_ssl_style(style):
    return (ScintillaConstants.SCE_UDL_SSL_DEFAULT <= style
            <= ScintillaConstants.SCE_UDL_SSL_VARIABLE)


def is_udl_tpl_style(style):
    return (ScintillaConstants.SCE_UDL_TPL_DEFAULT <= style
            <= ScintillaConstants.SCE_UDL_TPL_VARIABLE)

# XXX Redundant code from koUDLLanguageBase.py::KoUDLLanguage
# Necessary because SilverCity.WordList splits input on white-space

_re_bad_filename_char = re.compile(r'([% 	\x80-\xff])')


def _lexudl_path_escape(m):
    return '%%%02X' % ord(m.group(1))


def _urlescape(s):
    return _re_bad_filename_char.sub(_lexudl_path_escape, s)


class UDLLexer(Lexer):
    """LexUDL wants the path to the .lexres file as the first element of
    the first keywords list.
    """
    _lock = threading.Lock()
    _lexresfile_from_lang = None
    _extra_lexer_dirs = set()

    def __init__(self):
        self._properties = SilverCity.PropertySet()
        self._lexer = SilverCity.find_lexer_module_by_id(
            ScintillaConstants.SCLEX_UDL)
        lexres_path = _urlescape(self._get_lexres_path())
        log.debug("escaped lexres_path: %r", lexres_path)
        self._keyword_lists = [
            SilverCity.WordList(lexres_path),
        ]

    def tokenize_by_style(self, text, call_back=None):
        """LexUDL.cxx currently isn't thread-safe."""
        self._lock.acquire()
        try:
            return Lexer.tokenize_by_style(self, text, call_back)
        finally:
            self._lock.release()

    @staticmethod
    def add_extra_lexer_dirs(dirs):
        UDLLexer._extra_lexer_dirs.update(dirs)
        UDLLexer._lexresfile_from_lang = None

    if _xpcom_:
        # Presume we are running under Komodo. Look in the available
        # lexres dirs from extensions.

        @staticmethod
        def _generate_lexer_mapping():
            """Return dict {name > filename} of all lexer resource files (i.e.
            those ones that can include compiled UDL .lexres files).

            It yields directories that should "win" first.
            """
            from glob import glob
            lexresfile_from_lang = {}
            koDirs = components.classes["@activestate.com/koDirs;1"] \
                .getService(components.interfaces.koIDirs)

            # Find all possible lexer dirs.
            lexer_dirs = []
            lexer_dirs.append(join(koDirs.userDataDir, "lexers"))    # user
            for extensionDir in directoryServiceUtils.getExtensionDirectories():
                lexer_dirs.append(join(
                    extensionDir, "lexers"))      # user-install extensions
            lexer_dirs.append(join(
                koDirs.commonDataDir, "lexers"))  # site/common
            lexer_dirs.append(join(koDirs.supportDir, "lexers"))     # factory
            for extra_dir in UDLLexer._extra_lexer_dirs:
                lexer_dirs.append(extra_dir)

            # Find all .lexeres files in these lexer dirs.
            for d in reversed(lexer_dirs):  # first come, first served
                lexer_files = glob(join(d, "*.lexres"))
                for f in lexer_files:
                    # Get lowered name without the ".lexres" extension.
                    name = basename(f).lower().rsplit(".", 1)[0]
                    lexresfile_from_lang[name] = f
            return lexresfile_from_lang

    else:
        @staticmethod
        def _generate_lexer_mapping():
            """Return dict {name > filename} of all lexer resource files (i.e.
            those ones that can include compiled UDL .lexres files).

            It yields directories that should "win" first.
            """
            from glob import glob
            lexresfile_from_lang = {}

            # Find all possible lexer dirs.
            lexer_dirs = []
            lexer_dirs.append(join(dirname(__file__), "lexers"))
            for extra_dir in UDLLexer._extra_lexer_dirs:
                lexer_dirs.append(extra_dir)

            # Find all .lexeres files in these lexer dirs.
            for d in reversed(lexer_dirs):  # first come, first served
                lexer_files = glob(join(d, "*.lexres"))
                for f in lexer_files:
                    # Get lowered name without the ".lexres" extension.
                    name = basename(f).lower().rsplit(".", 1)[0]
                    lexresfile_from_lang[name] = f
            return lexresfile_from_lang

    def _get_lexres_path(self):
        lexresfile_from_lang = UDLLexer._lexresfile_from_lang
        if lexresfile_from_lang is None:
            # Generate and cache it.
            lexresfile_from_lang = self._generate_lexer_mapping()
            UDLLexer._lexresfile_from_lang = lexresfile_from_lang

        lexres_file = lexresfile_from_lang.get(self.lang.lower())
        if lexres_file is None:
            raise CodeIntelError("could not find lexres file for %s: "
                                 "`%s.lexres' does not exist in any "
                                 "of the lexer dirs"
                                 % (self.lang, self.lang))
        return lexres_file


class UDLBuffer(CitadelBuffer):
    """A CodeIntel Buffer for a UDL-lexer-based language."""
    sce_prefixes = ["SCE_UDL_"]
    # XXX Not sure that this indirection will be useful, but we'll see.

    # Sub-classes must set the following of these that are appropriate:
    m_lang = None
    css_lang = None
    csl_lang = None
    ssl_lang = None
    tpl_lang = None

    def lang_from_style(self, style):
        if (ScintillaConstants.SCE_UDL_M_DEFAULT <= style
           <= ScintillaConstants.SCE_UDL_M_COMMENT):
            return self.m_lang
        elif (ScintillaConstants.SCE_UDL_CSS_DEFAULT <= style
              <= ScintillaConstants.SCE_UDL_CSS_OPERATOR):
            return self.css_lang
        elif (ScintillaConstants.SCE_UDL_CSL_DEFAULT <= style
              <= ScintillaConstants.SCE_UDL_CSL_REGEX):
            return self.csl_lang
        elif (ScintillaConstants.SCE_UDL_SSL_DEFAULT <= style
              <= ScintillaConstants.SCE_UDL_SSL_VARIABLE):
            return self.ssl_lang
        elif (ScintillaConstants.SCE_UDL_TPL_DEFAULT <= style
              <= ScintillaConstants.SCE_UDL_TPL_VARIABLE):
            return self.tpl_lang
        else:
            raise ValueError("unknown UDL style: %r" % style)

    def lang_from_pos(self, pos):
        style = self.accessor.style_at_pos(pos)
        return self.lang_from_style(style)

    _udl_family_from_lang_cache = None

    @property
    def udl_family_from_lang(self):
        if self._udl_family_from_lang_cache is None:
            self._udl_family_from_lang_cache = dict(
                (uf, L) for (uf, L) in [
                    (self.m_lang, "M"),
                    (self.css_lang, "CSS"),
                    (self.csl_lang, "CSL"),
                    (self.ssl_lang, "SSL"),
                    (self.tpl_lang, "TPL"),
                ]
                if L is not None
            )
        return self._udl_family_from_lang_cache

    def text_chunks_from_lang(self, lang):
        """Generate a list of text chunks of the given language content.

        For a single-language buffer this is trivial: 1 chunk of the whole
        buffer. For multi-language buffers, less so.

        Generates 2-tuples:
            (POSITION-OFFSET, TEXT-CHUNK)
        """
        udl_family_from_lang = self.udl_family_from_lang
        if len(udl_family_from_lang) == 1:
            yield 0, self.accessor.text
        elif lang not in udl_family_from_lang:
            pass
        elif hasattr(self.accessor, "udl_family_chunk_ranges"):
            udl_family = self.udl_family_from_lang[lang]
            text = self.accessor.text  # Note: assuming here that `text` is in *bytes*
            for u, start, end in self.accessor.udl_family_chunk_ranges:
                if u == udl_family:
                    yield start, text[start:end]
        else:
            min_style, max_style = {
                self.m_lang:   (ScintillaConstants.SCE_UDL_M_DEFAULT,
                                ScintillaConstants.SCE_UDL_M_COMMENT),
                self.css_lang: (ScintillaConstants.SCE_UDL_CSS_DEFAULT,
                                ScintillaConstants.SCE_UDL_CSS_OPERATOR),
                self.csl_lang: (ScintillaConstants.SCE_UDL_CSL_DEFAULT,
                                ScintillaConstants.SCE_UDL_CSL_REGEX),
                self.ssl_lang: (ScintillaConstants.SCE_UDL_SSL_DEFAULT,
                                ScintillaConstants.SCE_UDL_SSL_VARIABLE),
                self.tpl_lang: (ScintillaConstants.SCE_UDL_TPL_DEFAULT,
                                ScintillaConstants.SCE_UDL_TPL_VARIABLE),
            }[lang]

            in_chunk = False
            pos_offset = None
            text = self.accessor.text
            for token in self.accessor.gen_tokens():
                if in_chunk:
                    if not (min_style <= token["style"] <= max_style):
                        # SilverCity indeces are inclusive at the end.
                        end_index = token["end_index"] + 1
                        yield pos_offset, text[pos_offset:end_index]
                        in_chunk = False
                else:
                    if min_style <= token["style"] <= max_style:
                        in_chunk = True
                        pos_offset = token["start_index"]
            if in_chunk:
                yield pos_offset, text[pos_offset:]

    def scoperef_from_pos(self, pos):
        """Return the scoperef for the given position in this buffer.

        A "scoperef" is a 2-tuple:
            (<blob>, <lpath>)
        where <blob> is the ciElementTree blob for the buffer content
        and <lpath> is an ordered list of names into the blob
        identifying the scope.

        If no relevant scope is found (e.g. for example, in markup
        content in PHP) then None is returned.

        See Buffer.scoperef_from_pos() docstring for more details.
        """
        lang = self.lang_from_pos(pos)
        try:
            blob = self.blob_from_lang[lang]
        except KeyError:
            return None
        line = self.accessor.line_from_pos(pos) + 1  # convert to 1-based
        return self.scoperef_from_blob_and_line(blob, line)

    def trg_from_pos(self, pos, implicit=True):
        if pos == 0:
            return None
        lang = self.lang_from_pos(pos-1)
        if lang is None:
            style = self.accessor.style_at_pos(pos)
            style_names = self.style_names_from_style_num(style)
            raise CodeIntelError("got unexpected style in `%s': %s %s"
                                 % (basename(self.path), style, style_names))
        try:
            langintel = self.mgr.langintel_from_lang(lang)
        except KeyError:
            return None
        return langintel.trg_from_pos(self, pos, implicit=implicit)

    def preceding_trg_from_pos(self, pos, curr_pos):
        if curr_pos == 0:
            return None
        lang = self.lang_from_pos(curr_pos-1)
        try:
            langintel = self.mgr.langintel_from_lang(lang)
        except KeyError:
            return None
        return langintel.preceding_trg_from_pos(self, pos, curr_pos)

    def curr_calltip_arg_range(self, trg_pos, calltip, curr_pos):
        if curr_pos == 0:
            return None
        lang = self.lang_from_pos(curr_pos-1)
        try:
            langintel = self.mgr.langintel_from_lang(lang)
        except KeyError:
            return (-1, -1)
        try:
            return langintel.curr_calltip_arg_range(self, trg_pos, calltip,
                                                    curr_pos)
        except AttributeError:
            # This can happen if we accidentally move into a non-programming
            # language during a calltip. E.g. bug 69529. Cancel the calltip
            # in this case.
            return (-1, -1)

    def async_eval_at_trg(self, trg, ctlr):
        try:
            langintel = self.mgr.langintel_from_lang(trg.lang)
        except KeyError:
            return None
        return langintel.async_eval_at_trg(self, trg, ctlr)

    # Override Citadel.defn_trg_from_pos()
    def defn_trg_from_pos(self, pos, lang=None):
        # Work out the language from the position, as the citadel buffer will
        # use the buffer language, we want a language specific to this pos.
        return CitadelBuffer.defn_trg_from_pos(self, pos,
                                               lang=self.lang_from_pos(pos))

    def libs(self):
        """A simple `.libs' property does not work for multi-lang buffers.
        Use `.libs_from_lang(lang)' instead.
        """
        raise RuntimeError("`.libs' invalid for multi-lang buffers: use "
                           "`mgr.langintel_from_lang(lang).libs_from_buf(buf)' "
                           "directly")

    def style_names_from_style_num(self, style_num):
        # XXX Would like to have python-foo instead of p_foo or SCE_P_FOO, but
        #    that requires a more comprehensive solution for all langs and
        #    multi-langs.
        style_names = []

        # Get the constant name from ScintillaConstants.
        if "UDL" not in self._style_name_from_style_num_from_lang:
            name_from_num \
                = self._style_name_from_style_num_from_lang["UDL"] = {}
            if self.sce_prefixes is None:
                raise CodeIntelError("'sce_prefixes' not set on class %s: cannot "
                                     "determine style constant names"
                                     % self.__class__.__name__)
            for attr in dir(ScintillaConstants):
                for sce_prefix in self.sce_prefixes:
                    if attr.startswith(sce_prefix):
                        name_from_num[getattr(ScintillaConstants, attr)] = attr
        else:
            name_from_num \
                = self._style_name_from_style_num_from_lang["UDL"]
        const_name = name_from_num[style_num]
        style_names.append(const_name)

        # Get a style group from styles.py.
        if "UDL" in styles.StateMap:
            for style_group, const_names in styles.StateMap["UDL"].items():
                if const_name in const_names:
                    style_names.append(style_group)
                    break
        else:
            log.warn("lang '%s' not in styles.StateMap: won't have "
                     "common style groups in HTML output" % "UDL")

        return style_names

    __string_styles = None

    def string_styles(self):
        if self.__string_styles is None:
            state_map = styles.StateMap["UDL"]
            self.__string_styles = [
                getattr(ScintillaConstants, style_name)
                for style_class in ("strings", "stringeol")
                for style_name in state_map.get(style_class, [])
            ]
        return self.__string_styles

    __comment_styles = None

    def comment_styles(self):
        if self.__comment_styles is None:
            state_map = styles.StateMap["UDL"]
            self.__comment_styles = [
                getattr(ScintillaConstants, style_name)
                for style_class in ("comments", "here documents",
                                    "data sections")
                for style_name in state_map.get(style_class, [])
            ]
        return self.__comment_styles

    __number_styles = None

    def number_styles(self):
        if self.__number_styles is None:
            state_map = styles.StateMap["UDL"]
            self.__number_styles = [
                getattr(ScintillaConstants, style_name)
                for style_class in ("numbers",)
                for style_name in state_map.get(style_class, [])
            ]
        return self.__number_styles


class XMLParsingBufferMixin(object):
    """A mixin for UDLBuffer-based buffers of XML-y/HTML-y languages to
    support the following:

    - An "xml_tree" attribute that is a XML parse tree of the document
      (lazily done from koXMLTreeService)
    - An "xml_parse()" method to force a re-parse of the document.

    TODO: locking?
    """
    _xml_tree_cache = None
    _xml_default_dataset_info = None

    @property
    def xml_tree(self):
        if self._xml_tree_cache is None:
            self.xml_parse()
        return self._xml_tree_cache

    def xml_parse(self):
        from koXMLTreeService import getService
        path = self.path
        if isUnsavedPath(self.path):
            # The "<Unsaved>/..." special path can *crash* Python if trying to
            # open it. Besides, the "<Unsaved>" business is an internal
            # codeintel detail.
            path = None
        self._xml_tree_cache = getService().getTreeForURI(
            path, self.accessor.text)

    def xml_default_dataset_info(self, node=None):
        if self._xml_default_dataset_info is None:
            import koXMLDatasetInfo
            datasetSvc = koXMLDatasetInfo.getService()
            self._xml_default_dataset_info = (
                datasetSvc.getDefaultPublicId(self.m_lang, self.env),
                None,
                datasetSvc.getDefaultNamespace(self.m_lang, self.env))
        return self._xml_default_dataset_info

    def xml_tree_handler(self, node=None):
        import koXMLDatasetInfo
        return koXMLDatasetInfo.get_tree_handler(self._xml_tree_cache, node, self.xml_default_dataset_info(node))

    def xml_node_at_pos(self, pos):
        import koXMLTreeService
        self.xml_parse()
        tree = self._xml_tree_cache
        if not tree:
            return None
        line, col = self.accessor.line_and_col_at_pos(pos)
        node = tree.locateNode(line, col)
        # XXX this needs to be worked out better
        last_start = self.accessor.text.rfind('<', 0, pos)
        last_end = self.accessor.text.find('>', last_start, pos)
        if node is None and last_start >= 0:
            node = koXMLTreeService.elementFromText(
                tree, self.accessor.text[last_start:last_end], node)
        if node is None or node.start is None:
            return node
        # elementtree line numbers are 1 based, convert to zero based
        node_pos = self.accessor.pos_from_line_and_col(
            node.start[0]-1, node.start[1])
        if last_end == -1 and last_start != node_pos:
            # print "try parse ls %d le %d np %d pos %d %r" % (last_start, last_end, node_pos, pos, accessor.text[last_start:pos])
            # we have a dirty tree, need to create a current node and add it
            newnode = koXMLTreeService.elementFromText(
                tree, self.accessor.text[last_start:pos], node)
            if newnode is not None:
                return newnode
        return node


class _NotYetSet(object):
    # Used below to distinguish from None.
    pass


class UDLCILEDriver(CILEDriver):
    ssl_lang = None   # Sub-classes must set one or both of these for
    csl_lang = None  # citadel-scanning support.

    _master_cile_driver = None
    slave_csl_cile_driver = _NotYetSet  # to distinguish from None

    @property
    def master_cile_driver(self):
        """The primary CILE driver for this multi-lang lang.

        This is the CILE driver for the SSL lang, if there is one, otherwise
        for the csl_lang.

        Side effect: `self.slave_csl_cile_driver' is determined the
        first time this is called. A little gross, I know, but it
        avoids having a separate property.
        """
        if self._master_cile_driver is None:
            if self.ssl_lang is not None:
                self._master_cile_driver \
                    = self.mgr.citadel.cile_driver_from_lang(self.ssl_lang)
                self.slave_csl_cile_driver \
                    = self.mgr.citadel.cile_driver_from_lang(self.csl_lang)
            else:
                self._master_cile_driver \
                    = self.mgr.citadel.cile_driver_from_lang(self.csl_lang)
                self.slave_csl_cile_driver = None
        return self._master_cile_driver

    def scan_purelang(self, buf):
        log.info("scan_purelang: path: %r lang: %s", buf.path, buf.lang)
        return self.master_cile_driver.scan_multilang(
            buf, self.slave_csl_cile_driver)

########NEW FILE########
__FILENAME__ = util
#!python
# encoding: utf-8
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""Code Intelligence: utility functions"""

import bisect
import os
from os.path import basename
import sys
import re
import stat
import textwrap
import logging
import types
from pprint import pprint, pformat
import time
import codecs

# Global dict for holding specific hotshot profilers
hotshotProfilers = {}

#---- general stuff


def isident(char):
    return "a" <= char <= "z" or "A" <= char <= "Z" or char == "_"


def isdigit(char):
    return "0" <= char <= "9"

# A "safe" language name for the given language where safe generally
# means safe for a file path.
_safe_lang_from_lang_cache = {
    "C++": "cpp",
}


def safe_lang_from_lang(lang):
    global _safe_lang_from_lang_cache
    try:
        return _safe_lang_from_lang_cache[lang]
    except KeyError:
        safe_lang = lang.lower().replace(' ', '_')
        _safe_lang_from_lang_cache[lang] = safe_lang
        return safe_lang


# @deprecated: Manager.buf_from_path now uses textinfo to guess lang.
def guess_lang_from_path(path):
    lang_from_ext = {
        ".py": "Python",
        ".pl": "Perl",
        ".pm": "Perl",
        ".tcl": "Tcl",
        ".php": "PHP",
        ".inc": "PHP",
        ".rb": "Ruby",
        ".rhtml": "RHTML",
        ".html.erb": "RHTML",
        ".js": "JavaScript",
        ".java": "Java",
        ".css": "CSS",
        ".xul": "XUL",
        ".xbl": "XBL",
        ".html": "HTML",
        ".xml": "XML",
        ".tpl": "Smarty",
        ".django.html": "Django",
        ".mason.html": "Mason",
        ".ttkt.html": "TemplateToolkit",
        ".cxx": "C++",
    }
    idx = 0
    base = basename(path)
    while base.find('.', idx) != -1:
        idx = base.find('.', idx)
        if idx == -1:
            break
        ext = base[idx:]
        if ext in lang_from_ext:
            return lang_from_ext[ext]
        idx += 1
    from codeintel2.common import CodeIntelError
    raise CodeIntelError("couldn't guess lang for `%s'" % path)


def gen_dirs_under_dirs(dirs, max_depth, interesting_file_patterns=None,
                        skip_scc_control_dirs=True):
    """Generate all dirs under the given dirs (including the given dirs
    themselves).

        "max_depth" is an integer maximum number of sub-directories that
            this method with recurse.
        "file_patterns", if given, is a sequence of glob patterns for
            "interesting" files. Directories with no interesting files are
            not included (though sub-directories of these may be).
        "skip_scc_control_dirs" is a boolean (default True) indicating if
            svn and cvs control dirs should be skipped.
    """
    from os.path import normpath, abspath, expanduser
    from fnmatch import fnmatch

    dirs_to_skip = (skip_scc_control_dirs
                    and ["CVS", ".svn", ".hg", ".git", ".bzr"] or [])
    # We must keep track of the directories we have walked, as the list of dirs
    # can overlap - bug 90289.
    walked_these_dirs = {}
    for dir in dirs:
        norm_dir = normpath(abspath(expanduser(dir)))
        LEN_DIR = len(norm_dir)
        for dirpath, dirnames, filenames in walk2(norm_dir):
            if dirpath in walked_these_dirs:
                dirnames[:] = []  # Already walked - no need to do it again.
                continue
            if dirpath[LEN_DIR:].count(os.sep) >= max_depth:
                dirnames[:] = []  # hit max_depth
            else:
                walked_these_dirs[dirpath] = True
                for dir_to_skip in dirs_to_skip:
                    if dir_to_skip in dirnames:
                        dirnames.remove(dir_to_skip)
            if interesting_file_patterns:
                for pat, filename in (
                    (p, f) for p in interesting_file_patterns
                        for f in filenames):
                    if fnmatch(filename, pat):
                        break
                else:
                    # No interesting files in this dir.
                    continue

            yield dirpath


#---- standard module/class/function doc parsing
LINE_LIMIT = 5      # limit full number of lines this number
LINE_WIDTH = 60     # wrap doc summaries to this width

# Examples matches to this pattern:
#    foo(args)
#    foo(args) -> retval
#    foo(args) -- description
#    retval = foo(args)
#    retval = foo(args) -- description
_gPySigLinePat = re.compile(
    r"^((?P<retval>[^=]+?)\s*=|class)?\s*(?P<head>[\w\.]+\s?\(.*?\))\s*(?P<sep>[:<>=-]*)\s*(?P<tail>.*)$")
_gSentenceSepPat = re.compile(r"(?<=\.)\s+", re.M)  # split on sentence bndry


def parseDocSummary(doclines, limit=LINE_LIMIT, width=LINE_WIDTH):
    """Parse out a short summary from the given doclines.

        "doclines" is a list of lines (without trailing newlines) to parse.
        "limit" is the number of lines to which to limit the summary.

    The "short summary" is the first sentence limited by (1) the "limit"
    number of lines and (2) one paragraph. If the first *two* sentences fit
    on the first line, then use both. Returns a list of summary lines.
    """
    # Skip blank lines.
    start = 0
    while start < len(doclines):
        if doclines[start].strip():
            break
        start += 1

    desclines = []
    for i in range(start, len(doclines)):
        if len(desclines) >= limit:
            break
        stripped = doclines[i].strip()
        if not stripped:
            break
        sentences = _gSentenceSepPat.split(stripped)
        if sentences and not sentences[-1].endswith('.'):
            del sentences[-1]  # last bit might not be a complete sentence
        if not sentences:
            desclines.append(stripped + ' ')
            continue
        elif i == start and len(sentences) > 1:
            desclines.append(' '.join([s.strip() for s in sentences[:2]]))
        else:
            desclines.append(sentences[0].strip())
        break
    if desclines:
        if desclines[-1][-1] == ' ':
            # If terminated at non-sentence boundary then have extraneous
            # trailing space.
            desclines[-1] = desclines[-1][:-1]
        desclines = textwrap.wrap(''.join(desclines), width)
    return desclines


def parsePyFuncDoc(doc, fallbackCallSig=None, scope="?", funcname="?"):
    """Parse the given Python function/method doc-string into call-signature
    and description bits.

        "doc" is the function doc string.
        "fallbackCallSig" (optional) is a list of call signature lines to
            fallback to if one cannot be determined from the doc string.
        "scope" (optional) is the module/class parent scope name. This
            is just used for better error/log reporting.
        "funcname" (optional) is the function name. This is just used for
            better error/log reporting.

    Examples of doc strings with call-signature info:
        close(): explicitly release resources held.
        x.__repr__() <==> repr(x)
        read([s]) -- Read s characters, or the rest of the string
        recv(buffersize[, flags]) -> data
        replace (str, old, new[, maxsplit]) -> string
        class StringIO([buffer])

    Returns a 2-tuple: (<call-signature-lines>, <description-lines>)
    """
    if doc is None or not doc.strip():
        return ([], [])

    limit = LINE_LIMIT
    if not isinstance(doc, unicode):
        # try to convert from utf8 to unicode; if we fail, too bad.
        try:
            doc = codecs.utf_8_decode(doc)[0]
        except UnicodeDecodeError:
            pass
    doclines = doc.splitlines(0)
    index = 0
    siglines = []
    desclines = []

    # Skip leading blank lines.
    while index < len(doclines):
        if doclines[index].strip():
            break
        index += 1

    # Parse out the call signature block, if it looks like there is one.
    if index >= len(doclines):
        match = None
    else:
        first = doclines[index].strip()
        match = _gPySigLinePat.match(first)
    if match:
        # The 'doc' looks like it starts with a call signature block.
        for i, line in enumerate(doclines[index:]):
            if len(siglines) >= limit:
                index = i
                break
            stripped = line.strip()
            if not stripped:
                index = i
                break
            match = _gPySigLinePat.match(stripped)
            if not match:
                index = i
                break
            # Now parse off what may be description content on the same line.
            #   ":", "-" or "--" separator: tail is description
            #   "-->" or "->" separator: tail if part of call sig
            #   "<==>" separator: tail if part of call sig
            #   other separtor: leave as part of call sig for now
            descSeps = ("-", "--", ":")
            groupd = match.groupdict()
            retval, head, sep, tail = (
                groupd.get("retval"), groupd.get("head"),
                groupd.get("sep"), groupd.get("tail"))
            if retval:
                siglines.append(head + " -> " + retval)
                if tail and sep in descSeps:
                    desclines.append(tail)
            elif tail and sep in descSeps:
                siglines.append(head)
                desclines.append(tail)
            else:
                siglines.append(stripped)
        else:
            index = len(doclines)
    if not siglines and fallbackCallSig:
        siglines = fallbackCallSig

    # Parse out the description block.
    if desclines:
        # Use what we have already. Just need to wrap it.
        desclines = textwrap.wrap(' '.join(desclines), LINE_WIDTH)
    else:
        doclines = doclines[index:]
        # strip leading empty lines
        while len(doclines) > 0 and not doclines[0].rstrip():
            del doclines[0]
        try:
            skip_first_line = (doclines[0][0] not in (" \t"))
        except IndexError:
            skip_first_line = False  # no lines, or first line is empty
        desclines = dedent("\n".join(
            doclines), skip_first_line=skip_first_line)
        desclines = desclines.splitlines(0)

    ## debug logging
    # f = open("parsePyFuncDoc.log", "a")
    # if 0:
    #    f.write("\n---- %s:\n" % funcname)
    #    f.write(pformat(siglines)+"\n")
    #    f.write(pformat(desclines)+"\n")
    # else:
    #    f.write("\n")
    #    if siglines:
    #        f.write("\n".join(siglines)+"\n")
    #    else:
    #        f.write("<no signature for '%s.%s'>\n" % (scope, funcname))
    #    for descline in desclines:
    #        f.write("\t%s\n" % descline)
    # f.close()

    return (siglines, desclines)


#---- debugging utilities

def unmark_text(markedup_text):
    u"""Parse text with potential markup as follows and return
    (<text>, <data-dict>).

        "<|>" indicates the current position (pos), defaults to the end
            of the text.
        "<+>" indicates the trigger position (trg_pos), if present.
        "<$>" indicates the start position (start_pos) for some kind of
            of processing, if present.
        "<N>" is a numbered marker. N can be any of 0-99. These positions
            are returned as the associate number key in <data-dict>.

    Note that the positions are in UTF-8 byte counts, not character counts.
    This matches the behaviour of Scintilla positions.

    E.g.:
        >>> unmark_text('foo.<|>')
        ('foo.', {'pos': 4})
        >>> unmark_text('foo.<|><+>')
        ('foo.', {'trg_pos': 4, 'pos': 4})
        >>> unmark_text('foo.<+>ba<|>')
        ('foo.ba', {'trg_pos': 4, 'pos': 6})
        >>> unmark_text('fo<|>o.<+>ba')
        ('foo.ba', {'trg_pos': 4, 'pos': 2})
        >>> unmark_text('os.path.join<$>(<|>')
        ('os.path.join(', {'pos': 13, 'start_pos': 12})
        >>> unmark_text('abc<3>defghi<2>jk<4>lm<1>nopqrstuvwxyz')
        ('abcdefghijklmnopqrstuvwxyz', {1: 13, 2: 9, 3: 3, 4: 11, 'pos': 26})
        >>> unmark_text('Ůɳíčóďé<|>')
        ('Ůɳíčóďé', {'pos': 14})

    See the matching markup_text() below.
    """
    splitter = re.compile(r"(<(?:[\|\+\$\[\]<]|\d+)>)")
    text = u"" if isinstance(markup_text, unicode) else ""
    data = {}
    posNameFromSymbol = {
        "<|>": "pos",
        "<+>": "trg_pos",
        "<$>": "start_pos",
        "<[>": "start_selection",
        "<]>": "end_selection",
    }

    def byte_length(text):
        if isinstance(text, unicode):
            return len(text.encode("utf-8"))
        return len(text)

    bracketed_digits_re = re.compile(r'<\d+>$')
    for token in splitter.split(markedup_text):
        if token in posNameFromSymbol:
            data[posNameFromSymbol[token]] = byte_length(text)
        elif token == "<<>":  # escape sequence
            text += "<"
        elif bracketed_digits_re.match(token):
            data[int(token[1:-1])] = byte_length(text)
        else:
            text += token
    if "pos" not in data:
        data["pos"] = byte_length(text)
    # sys.stderr.write(">> text:%r, data:%s\n" % (text, data))
    return text, data


def markup_text(text, pos=None, trg_pos=None, start_pos=None):
    """Markup text with position markers.

    See the matching unmark_text() above.
    """
    positions_and_markers = []
    if pos is not None:
        positions_and_markers.append((pos, '<|>'))
    if trg_pos is not None:
        positions_and_markers.append((trg_pos, '<+>'))
    if start_pos is not None:
        positions_and_markers.append((start_pos, '<$>'))
    positions_and_markers.sort()

    text = unicode(text).encode("utf-8")
    m_text = ""
    m_pos = 0
    for position, marker in positions_and_markers:
        m_text += text[m_pos:position] + marker
        m_pos = position
    m_text += text[m_pos:]
    return m_text.decode("utf-8")


def lines_from_pos(unmarked_text, positions):
    """Get 1-based line numbers from positions
        @param unmarked_text {str} The text to examine
        @param positions {dict or list of int} Byte positions to look up
        @returns {dict or list of int} Matching line numbers (1-based)
    Given some text and either a list of positions, or a dict containing
    positions as values, return a matching data structure with positions
    replaced with the line number of the lines the positions are on.  Positions
    after the last line are assumed to be on a hypothetical line.

    E.g.:
        Assuming the following text with \n line endings, where each line is
        exactly 20 characters long:
        >>> text = '''
        ... line            one
        ... line            two
        ... line          three
        ... '''.lstrip()
        >>> lines_from_pos(text, [5, 15, 25, 55, 999])
        [1, 1, 2, 3, 4]
        >>> lines_from_pos(text, {"hello": 10, "moo": 20, "not": "an int"})
        {'moo': 1, 'hello': 1}
    """
    lines = unicode(unmarked_text).splitlines(True)
    offsets = [0]
    for line in lines:
        offsets.append(offsets[-1] + len(line.encode("utf-8")))
    try:
        # assume a dict
        keys = positions.iterkeys()
        values = {}
    except AttributeError:
        # assume a list/tuple
        keys = range(len(positions))
        values = []

    for key in keys:
        try:
            position = positions[key] - 0
        except TypeError:
            continue  # not a number
        line_no = bisect.bisect_left(offsets, position)
        try:
            values[key] = line_no
        except IndexError:
            if key == len(values):
                values.append(line_no)
            else:
                raise

    return values

# Recipe: banner (1.0.1) in C:\trentm\tm\recipes\cookbook


def banner(text, ch='=', length=78):
    """Return a banner line centering the given text.

        "text" is the text to show in the banner. None can be given to have
            no text.
        "ch" (optional, default '=') is the banner line character (can
            also be a short string to repeat).
        "length" (optional, default 78) is the length of banner to make.

    Examples:
        >>> banner("Peggy Sue")
        '================================= Peggy Sue =================================='
        >>> banner("Peggy Sue", ch='-', length=50)
        '------------------- Peggy Sue --------------------'
        >>> banner("Pretty pretty pretty pretty Peggy Sue", length=40)
        'Pretty pretty pretty pretty Peggy Sue'
    """
    if text is None:
        return ch * length
    elif len(text) + 2 + len(ch)*2 > length:
        # Not enough space for even one line char (plus space) around text.
        return text
    else:
        remain = length - (len(text) + 2)
        prefix_len = remain / 2
        suffix_len = remain - prefix_len
        if len(ch) == 1:
            prefix = ch * prefix_len
            suffix = ch * suffix_len
        else:
            prefix = ch * (prefix_len/len(ch)) + ch[:prefix_len % len(ch)]
            suffix = ch * (suffix_len/len(ch)) + ch[:suffix_len % len(ch)]
        return prefix + ' ' + text + ' ' + suffix


# Recipe: dedent (0.1.2) in C:\trentm\tm\recipes\cookbook
def _dedentlines(lines, tabsize=8, skip_first_line=False):
    """_dedentlines(lines, tabsize=8, skip_first_line=False) -> dedented lines

        "lines" is a list of lines to dedent.
        "tabsize" is the tab width to use for indent width calculations.
        "skip_first_line" is a boolean indicating if the first line should
            be skipped for calculating the indent width and for dedenting.
            This is sometimes useful for docstrings and similar.

    Same as dedent() except operates on a sequence of lines. Note: the
    lines list is modified **in-place**.
    """
    DEBUG = False
    if DEBUG:
        print "dedent: dedent(..., tabsize=%d, skip_first_line=%r)"\
              % (tabsize, skip_first_line)
    indents = []
    margin = None
    for i, line in enumerate(lines):
        if i == 0 and skip_first_line:
            continue
        indent = 0
        for ch in line:
            if ch == ' ':
                indent += 1
            elif ch == '\t':
                indent += tabsize - (indent % tabsize)
            elif ch in '\r\n':
                continue  # skip all-whitespace lines
            else:
                break
        else:
            continue  # skip all-whitespace lines
        if DEBUG:
            print "dedent: indent=%d: %r" % (indent, line)
        if margin is None:
            margin = indent
        else:
            margin = min(margin, indent)
    if DEBUG:
        print "dedent: margin=%r" % margin

    if margin is not None and margin > 0:
        for i, line in enumerate(lines):
            if i == 0 and skip_first_line:
                continue
            removed = 0
            for j, ch in enumerate(line):
                if ch == ' ':
                    removed += 1
                elif ch == '\t':
                    removed += tabsize - (removed % tabsize)
                elif ch in '\r\n':
                    if DEBUG:
                        print "dedent: %r: EOL -> strip up to EOL" % line
                    lines[i] = lines[i][j:]
                    break
                else:
                    raise ValueError("unexpected non-whitespace char %r in "
                                     "line %r while removing %d-space margin"
                                     % (ch, line, margin))
                if DEBUG:
                    print "dedent: %r: %r -> removed %d/%d"\
                          % (line, ch, removed, margin)
                if removed == margin:
                    lines[i] = lines[i][j+1:]
                    break
                elif removed > margin:
                    lines[i] = ' '*(removed-margin) + lines[i][j+1:]
                    break
            else:
                if removed:
                    lines[i] = lines[i][removed:]
    return lines


def dedent(text, tabsize=8, skip_first_line=False):
    """dedent(text, tabsize=8, skip_first_line=False) -> dedented text

        "text" is the text to dedent.
        "tabsize" is the tab width to use for indent width calculations.
        "skip_first_line" is a boolean indicating if the first line should
            be skipped for calculating the indent width and for dedenting.
            This is sometimes useful for docstrings and similar.

    textwrap.dedent(s), but don't expand tabs to spaces
    """
    lines = text.splitlines(1)
    _dedentlines(lines, tabsize=tabsize, skip_first_line=skip_first_line)
    return ''.join(lines)


# Recipe: indent (0.2.1) in C:\trentm\tm\recipes\cookbook
def indent(s, width=4, skip_first_line=False):
    """indent(s, [width=4]) -> 's' indented by 'width' spaces

    The optional "skip_first_line" argument is a boolean (default False)
    indicating if the first line should NOT be indented.
    """
    lines = s.splitlines(1)
    indentstr = ' '*width
    if skip_first_line:
        return indentstr.join(lines)
    else:
        return indentstr + indentstr.join(lines)


def walk2(top, topdown=True, onerror=None, followlinks=False,
          ondecodeerror=None):
    """A version of `os.walk` that adds support for handling errors for
    files that cannot be decoded with the default encoding. (See bug 82268.)

    By default `UnicodeDecodeError`s from the os.listdir() call are
    ignored.  If optional arg 'ondecodeerror' is specified, it should be a
    function; it will be called with one argument, the `UnicodeDecodeError`
    instance. It can report the error to continue with the walk, or
    raise the exception to abort the walk.
    """
    from os.path import join, isdir, islink

    # We may not have read permission for top, in which case we can't
    # get a list of the files the directory contains.  os.path.walk
    # always suppressed the exception then, rather than blow up for a
    # minor reason when (say) a thousand readable directories are still
    # left to visit.  That logic is copied here.
    try:
        # Note that listdir and error are globals in this module due
        # to earlier import-*.
        names = os.listdir(top)
    except os.error, err:
        if onerror is not None:
            onerror(err)
        return

    dirs, nondirs = [], []
    for name in names:
        try:
            if isdir(join(top, name)):
                dirs.append(name)
            else:
                nondirs.append(name)
        except UnicodeDecodeError, err:
            if ondecodeerror is not None:
                ondecodeerror(err)

    if topdown:
        yield top, dirs, nondirs
    for name in dirs:
        path = join(top, name)
        if followlinks or not islink(path):
            for x in walk2(path, topdown, onerror, followlinks):
                yield x
    if not topdown:
        yield top, dirs, nondirs


# Decorators useful for timing and profiling specific functions.
#
# timeit usage:
#   Decorate the desired function and you'll get a print for how long
#   each call to the function took.
#
# hotspotit usage:
#   1. decorate the desired function
#   2. run your code
#   3. run:
#       python .../codeintel/support/show_stats.py .../<funcname>.prof
#
def timeit(func):
    clock = (sys.platform == "win32" and time.clock or time.time)

    def wrapper(*args, **kw):
        start_time = clock()
        try:
            return func(*args, **kw)
        finally:
            total_time = clock() - start_time
            print "%s took %.3fs" % (func.func_name, total_time)
    return wrapper


def hotshotit(func):
    def wrapper(*args, **kw):
        import hotshot
        global hotshotProfilers
        prof_name = func.func_name+".prof"
        profiler = hotshotProfilers.get(prof_name)
        if profiler is None:
            profiler = hotshot.Profile(prof_name)
            hotshotProfilers[prof_name] = profiler
        return profiler.runcall(func, *args, **kw)
    return wrapper

_koCProfiler = None


def getProfiler():
    global _koCProfiler
    if _koCProfiler is None:
        class _KoCProfileManager(object):
            def __init__(self):
                import atexit
                import cProfile
                from codeintel2.common import _xpcom_
                self.prof = cProfile.Profile()
                if _xpcom_:
                    from xpcom import components
                    _KoCProfileManager._com_interfaces_ = [
                        components.interfaces.nsIObserver]
                    obsSvc = components.classes["@mozilla.org/observer-service;1"].\
                        getService(
                            components.interfaces.nsIObserverService)
                    obsSvc.addObserver(self, 'xpcom-shutdown', False)
                else:
                    atexit.register(self.atexit_handler)

            def atexit_handler(self):
                self.prof.print_stats(sort="time")

            def observe(self, subject, topic, data):
                if topic == "xpcom-shutdown":
                    self.atexit_handler()
        _koCProfiler = _KoCProfileManager()
    return _koCProfiler.prof


def profile_method(func):
    def wrapper(*args, **kw):
        return getProfiler().runcall(func, *args, **kw)
    return wrapper

# Utility functions to perform sorting the same way as scintilla does it
# for the code-completion list.


def OrdPunctLast(value):
    result = []
    value = value.upper()
    for ch in value:
        i = ord(ch)
        if i >= 0x21 and i <= 0x2F:  # ch >= '!' && ch <= '/'
            result.append(chr(i - ord("!") + ord('[')))    # ch - '!' + '['
        elif i >= 0x3A and i <= 0x40:  # ch >= ':' && ch <= '@'
            result.append(chr(i - ord(":") + ord('[')))    # ch - ':' + '['
        else:
            result.append(ch)
    return "".join(result)


def CompareNPunctLast(value1, value2):
    # value 1 is smaller, return negative
    # value 1 is equal, return 0
    # value 1 is larger, return positive
    return cmp(OrdPunctLast(value1), OrdPunctLast(value2))


# Utility function to make a lookup dictionary
def make_short_name_dict(names, length=3):
    outdict = {}
    for name in names:
        if len(name) >= length:
            shortname = name[:length]
            l = outdict.get(shortname)
            if not l:
                outdict[shortname] = [name]
            else:
                l.append(name)
        # pprint(outdict)
    for values in outdict.values():
        values.sort(CompareNPunctLast)
    return outdict


def makePerformantLogger(logger):
    """Replaces the info() and debug() methods with dummy methods.

    Assumes that the logging level does not change during runtime.
    """
    if not logger.isEnabledFor(logging.INFO):
        def _log_ignore(self, *args, **kwargs):
            pass
        logger.info = _log_ignore
        if not logger.isEnabledFor(logging.DEBUG):
            logger.debug = _log_ignore


#---- mainline self-test

if __name__ == "__main__":
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = ElementInclude
#
# ElementTree
# $Id$
#
# limited xinclude support for element trees
#
# history:
# 2003-08-15 fl   created
# 2003-11-14 fl   fixed default loader
#
# Copyright (c) 2003-2004 by Fredrik Lundh.  All rights reserved.
#
# fredrik@pythonware.com
# http://www.pythonware.com
#
# --------------------------------------------------------------------
# The ElementTree toolkit is
#
# Copyright (c) 1999-2004 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

##
# Limited XInclude support for the ElementTree package.
##

import copy
import ElementTree

XINCLUDE = "{http://www.w3.org/2001/XInclude}"

XINCLUDE_INCLUDE = XINCLUDE + "include"
XINCLUDE_FALLBACK = XINCLUDE + "fallback"

##
# Fatal include error.


class FatalIncludeError(SyntaxError):
    pass

##
# Default loader.  This loader reads an included resource from disk.
#
# @param href Resource reference.
# @param parse Parse mode.  Either "xml" or "text".
# @param encoding Optional text encoding.
# @return The expanded resource.  If the parse mode is "xml", this
#    is an ElementTree instance.  If the parse mode is "text", this
#    is a Unicode string.  If the loader fails, it can return None
#    or raise an IOError exception.
# @throws IOError If the loader fails to load the resource.


def default_loader(href, parse, encoding=None):
    file = open(href)
    if parse == "xml":
        data = ElementTree.parse(file).getroot()
    else:
        data = file.read()
        if encoding:
            data = data.decode(encoding)
    file.close()
    return data

##
# Expand XInclude directives.
#
# @param elem Root element.
# @param loader Optional resource loader.  If omitted, it defaults
#     to {@link default_loader}.  If given, it should be a callable
#     that implements the same interface as <b>default_loader</b>.
# @throws FatalIncludeError If the function fails to include a given
#     resource, or if the tree contains malformed XInclude elements.
# @throws IOError If the function fails to load a given resource.


def include(elem, loader=None):
    if loader is None:
        loader = default_loader
    # look for xinclude elements
    i = 0
    while i < len(elem):
        e = elem[i]
        if e.tag == XINCLUDE_INCLUDE:
            # process xinclude directive
            href = e.get("href")
            parse = e.get("parse", "xml")
            if parse == "xml":
                node = loader(href, parse)
                if node is None:
                    raise FatalIncludeError(
                        "cannot load %r as %r" % (href, parse)
                    )
                node = copy.copy(node)
                if e.tail:
                    node.tail = (node.tail or "") + e.tail
                elem[i] = node
            elif parse == "text":
                text = loader(href, parse, e.get("encoding"))
                if text is None:
                    raise FatalIncludeError(
                        "cannot load %r as %r" % (href, parse)
                    )
                if i:
                    node = elem[i-1]
                    node.tail = (node.tail or "") + text
                else:
                    elem.text = (elem.text or "") + text + (e.tail or "")
                del elem[i]
                continue
            else:
                raise FatalIncludeError(
                    "unknown parse type in xi:include tag (%r)" % parse
                )
        elif e.tag == XINCLUDE_FALLBACK:
            raise FatalIncludeError(
                "xi:fallback tag must be child of xi:include (%r)" % e.tag
            )
        else:
            include(e, loader)
        i = i + 1

########NEW FILE########
__FILENAME__ = ElementPath
#
# ElementTree
# $Id$
#
# limited xpath support for element trees
#
# history:
# 2003-05-23 fl   created
# 2003-05-28 fl   added support for // etc
# 2003-08-27 fl   fixed parsing of periods in element names
#
# Copyright (c) 2003-2004 by Fredrik Lundh.  All rights reserved.
#
# fredrik@pythonware.com
# http://www.pythonware.com
#
# --------------------------------------------------------------------
# The ElementTree toolkit is
#
# Copyright (c) 1999-2004 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

##
# Implementation module for XPath support.  There's usually no reason
# to import this module directly; the <b>ElementTree</b> does this for
# you, if needed.
##

import re

xpath_tokenizer = re.compile(
    "(::|\.\.|\(\)|[/.*:\[\]\(\)@=])|((?:\{[^}]+\})?[^/:\[\]\(\)@=\s]+)|\s+"
).findall


class xpath_descendant_or_self:
    pass

##
# Wrapper for a compiled XPath.


class Path:

    ##
    # Create an Path instance from an XPath expression.

    def __init__(self, path):
        tokens = xpath_tokenizer(path)
        # the current version supports 'path/path'-style expressions only
        self.path = []
        self.tag = None
        if tokens and tokens[0][0] == "/":
            raise SyntaxError("cannot use absolute path on element")
        while tokens:
            op, tag = tokens.pop(0)
            if tag or op == "*":
                self.path.append(tag or op)
            elif op == ".":
                pass
            elif op == "/":
                self.path.append(xpath_descendant_or_self())
                continue
            else:
                raise SyntaxError("unsupported path syntax (%s)" % op)
            if tokens:
                op, tag = tokens.pop(0)
                if op != "/":
                    raise SyntaxError(
                        "expected path separator (%s)" % (op or tag)
                    )
        if self.path and isinstance(self.path[-1], xpath_descendant_or_self):
            raise SyntaxError("path cannot end with //")
        if len(self.path) == 1 and isinstance(self.path[0], type("")):
            self.tag = self.path[0]

    ##
    # Find first matching object.

    def find(self, element):
        tag = self.tag
        if tag is None:
            nodeset = self.findall(element)
            if not nodeset:
                return None
            return nodeset[0]
        for elem in element:
            if elem.tag == tag:
                return elem
        return None

    ##
    # Find text for first matching object.

    def findtext(self, element, default=None):
        tag = self.tag
        if tag is None:
            nodeset = self.findall(element)
            if not nodeset:
                return default
            return nodeset[0].text or ""
        for elem in element:
            if elem.tag == tag:
                return elem.text or ""
        return default

    ##
    # Find all matching objects.

    def findall(self, element):
        nodeset = [element]
        index = 0
        while 1:
            try:
                path = self.path[index]
                index = index + 1
            except IndexError:
                return nodeset
            set = []
            if isinstance(path, xpath_descendant_or_self):
                try:
                    tag = self.path[index]
                    if not isinstance(tag, type("")):
                        tag = None
                    else:
                        index = index + 1
                except IndexError:
                    tag = None  # invalid path
                for node in nodeset:
                    new = list(node.getiterator(tag))
                    if new and new[0] is node:
                        set.extend(new[1:])
                    else:
                        set.extend(new)
            else:
                for node in nodeset:
                    for node in node:
                        if path == "*" or node.tag == path:
                            set.append(node)
            if not set:
                return []
            nodeset = set

_cache = {}

##
# (Internal) Compile path.


def _compile(path):
    p = _cache.get(path)
    if p is not None:
        return p
    p = Path(path)
    if len(_cache) >= 100:
        _cache.clear()
    _cache[path] = p
    return p

##
# Find first matching object.


def find(element, path):
    return _compile(path).find(element)

##
# Find text for first matching object.


def findtext(element, path, default=None):
    return _compile(path).findtext(element, default)

##
# Find all matching objects.


def findall(element, path):
    return _compile(path).findall(element)

########NEW FILE########
__FILENAME__ = ElementTree
#
# ElementTree
# $Id$
#
# light-weight XML support for Python 1.5.2 and later.
#
# history:
# 2001-10-20 fl   created (from various sources)
# 2001-11-01 fl   return root from parse method
# 2002-02-16 fl   sort attributes in lexical order
# 2002-04-06 fl   TreeBuilder refactoring, added PythonDoc markup
# 2002-05-01 fl   finished TreeBuilder refactoring
# 2002-07-14 fl   added basic namespace support to ElementTree.write
# 2002-07-25 fl   added QName attribute support
# 2002-10-20 fl   fixed encoding in write
# 2002-11-24 fl   changed default encoding to ascii; fixed attribute encoding
# 2002-11-27 fl   accept file objects or file names for parse/write
# 2002-12-04 fl   moved XMLTreeBuilder back to this module
# 2003-01-11 fl   fixed entity encoding glitch for us-ascii
# 2003-02-13 fl   added XML literal factory
# 2003-02-21 fl   added ProcessingInstruction/PI factory
# 2003-05-11 fl   added tostring/fromstring helpers
# 2003-05-26 fl   added ElementPath support
# 2003-07-05 fl   added makeelement factory method
# 2003-07-28 fl   added more well-known namespace prefixes
# 2003-08-15 fl   fixed typo in ElementTree.findtext (Thomas Dartsch)
# 2003-09-04 fl   fall back on emulator if ElementPath is not installed
# 2003-10-31 fl   markup updates
# 2003-11-15 fl   fixed nested namespace bug
# 2004-03-28 fl   added XMLID helper
# 2004-06-02 fl   added default support to findtext
# 2004-06-08 fl   fixed encoding of non-ascii element/attribute names
# 2004-08-23 fl   take advantage of post-2.1 expat features
# 2005-02-01 fl   added iterparse implementation
# 2005-03-02 fl   fixed iterparse support for pre-2.2 versions
#
# Copyright (c) 1999-2005 by Fredrik Lundh.  All rights reserved.
#
# fredrik@pythonware.com
# http://www.pythonware.com
#
# --------------------------------------------------------------------
# The ElementTree toolkit is
#
# Copyright (c) 1999-2005 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

__all__ = [
    # public symbols
    "Comment",
    "dump",
    "Element", "ElementTree",
    "fromstring",
    "iselement", "iterparse",
    "parse",
    "PI", "ProcessingInstruction",
    "QName",
    "SubElement",
    "tostring",
    "TreeBuilder",
    "VERSION", "XML",
    "XMLTreeBuilder",
]

##
# The <b>Element</b> type is a flexible container object, designed to
# store hierarchical data structures in memory. The type can be
# described as a cross between a list and a dictionary.
# <p>
# Each element has a number of properties associated with it:
# <ul>
# <li>a <i>tag</i>. This is a string identifying what kind of data
# this element represents (the element type, in other words).</li>
# <li>a number of <i>attributes</i>, stored in a Python dictionary.</li>
# <li>a <i>text</i> string.</li>
# <li>an optional <i>tail</i> string.</li>
# <li>a number of <i>child elements</i>, stored in a Python sequence</li>
# </ul>
#
# To create an element instance, use the {@link #Element} or {@link
# #SubElement} factory functions.
# <p>
# The {@link #ElementTree} class can be used to wrap an element
# structure, and convert it from and to XML.
##

import string
import sys
import re


class _SimpleElementPath:
    # emulate pre-1.2 find/findtext/findall behaviour
    def find(self, element, tag):
        for elem in element:
            if elem.tag == tag:
                return elem
        return None

    def findtext(self, element, tag, default=None):
        for elem in element:
            if elem.tag == tag:
                return elem.text or ""
        return default

    def findall(self, element, tag):
        if tag[:3] == ".//":
            return element.getiterator(tag[3:])
        result = []
        for elem in element:
            if elem.tag == tag:
                result.append(elem)
        return result

try:
    import ElementPath
except ImportError:
    # FIXME: issue warning in this case?
    ElementPath = _SimpleElementPath()

# TODO: add support for custom namespace resolvers/default namespaces
# TODO: add improved support for incremental parsing

VERSION = "1.2.6"
_patched_for_komodo_ = True

##
# Internal element class.  This class defines the Element interface,
# and provides a reference implementation of this interface.
# <p>
# You should not create instances of this class directly.  Use the
# appropriate factory functions instead, such as {@link #Element}
# and {@link #SubElement}.
#
# @see Element
# @see SubElement
# @see Comment
# @see ProcessingInstruction


class _ElementInterface:
    # <tag attrib>text<child/>...</tag>tail

    ##
    # (Attribute) Element tag.

    tag = None

    ##
    # (Attribute) Element attribute dictionary.  Where possible, use
    # {@link #_ElementInterface.get},
    # {@link #_ElementInterface.set},
    # {@link #_ElementInterface.keys}, and
    # {@link #_ElementInterface.items} to access
    # element attributes.

    attrib = None

    ##
    # (Attribute) Text before first subelement.  This is either a
    # string or the value None, if there was no text.

    text = None

    ##
    # (Attribute) Text after this element's end tag, but before the
    # next sibling element's start tag.  This is either a string or
    # the value None, if there was no text.

    tail = None  # text after end tag, if any

    def __init__(self, tag, attrib):
        self.tag = tag
        self.attrib = attrib
        self._children = []

    def __repr__(self):
        return "<Element %s at %x>" % (self.tag, id(self))

    ##
    # Creates a new element object of the same type as this element.
    #
    # @param tag Element tag.
    # @param attrib Element attributes, given as a dictionary.
    # @return A new element instance.

    def makeelement(self, tag, attrib):
        return Element(tag, attrib)

    ##
    # Returns the number of subelements.
    #
    # @return The number of subelements.

    def __len__(self):
        return len(self._children)

    ##
    # Returns the given subelement.
    #
    # @param index What subelement to return.
    # @return The given subelement.
    # @exception IndexError If the given element does not exist.

    def __getitem__(self, index):
        return self._children[index]

    ##
    # Replaces the given subelement.
    #
    # @param index What subelement to replace.
    # @param element The new element value.
    # @exception IndexError If the given element does not exist.
    # @exception AssertionError If element is not a valid object.

    def __setitem__(self, index, element):
        assert iselement(element)
        self._children[index] = element

    ##
    # Deletes the given subelement.
    #
    # @param index What subelement to delete.
    # @exception IndexError If the given element does not exist.

    def __delitem__(self, index):
        del self._children[index]

    ##
    # Returns a list containing subelements in the given range.
    #
    # @param start The first subelement to return.
    # @param stop The first subelement that shouldn't be returned.
    # @return A sequence object containing subelements.

    def __getslice__(self, start, stop):
        return self._children[start:stop]

    ##
    # Replaces a number of subelements with elements from a sequence.
    #
    # @param start The first subelement to replace.
    # @param stop The first subelement that shouldn't be replaced.
    # @param elements A sequence object with zero or more elements.
    # @exception AssertionError If a sequence member is not a valid object.

    def __setslice__(self, start, stop, elements):
        for element in elements:
            assert iselement(element)
        self._children[start:stop] = list(elements)

    ##
    # Deletes a number of subelements.
    #
    # @param start The first subelement to delete.
    # @param stop The first subelement to leave in there.

    def __delslice__(self, start, stop):
        del self._children[start:stop]

    ##
    # Adds a subelement to the end of this element.
    #
    # @param element The element to add.
    # @exception AssertionError If a sequence member is not a valid object.

    def append(self, element):
        assert iselement(element)
        self._children.append(element)

    ##
    # Inserts a subelement at the given position in this element.
    #
    # @param index Where to insert the new subelement.
    # @exception AssertionError If the element is not a valid object.

    def insert(self, index, element):
        assert iselement(element)
        self._children.insert(index, element)

    ##
    # Removes a matching subelement.  Unlike the <b>find</b> methods,
    # this method compares elements based on identity, not on tag
    # value or contents.
    #
    # @param element What element to remove.
    # @exception ValueError If a matching element could not be found.
    # @exception AssertionError If the element is not a valid object.

    def remove(self, element):
        assert iselement(element)
        self._children.remove(element)

    ##
    # Returns all subelements.  The elements are returned in document
    # order.
    #
    # @return A list of subelements.
    # @defreturn list of Element instances

    def getchildren(self):
        return self._children

    ##
    # Finds the first matching subelement, by tag name or path.
    #
    # @param path What element to look for.
    # @return The first matching element, or None if no element was found.
    # @defreturn Element or None

    def find(self, path):
        return ElementPath.find(self, path)

    ##
    # Finds text for the first matching subelement, by tag name or path.
    #
    # @param path What element to look for.
    # @param default What to return if the element was not found.
    # @return The text content of the first matching element, or the
    #     default value no element was found.  Note that if the element
    #     has is found, but has no text content, this method returns an
    #     empty string.
    # @defreturn string

    def findtext(self, path, default=None):
        return ElementPath.findtext(self, path, default)

    ##
    # Finds all matching subelements, by tag name or path.
    #
    # @param path What element to look for.
    # @return A list or iterator containing all matching elements,
    #    in document order.
    # @defreturn list of Element instances

    def findall(self, path):
        return ElementPath.findall(self, path)

    ##
    # Resets an element.  This function removes all subelements, clears
    # all attributes, and sets the text and tail attributes to None.

    def clear(self):
        self.attrib.clear()
        self._children = []
        self.text = self.tail = None

    ##
    # Gets an element attribute.
    #
    # @param key What attribute to look for.
    # @param default What to return if the attribute was not found.
    # @return The attribute value, or the default value, if the
    #     attribute was not found.
    # @defreturn string or None

    def get(self, key, default=None):
        return self.attrib.get(key, default)

    ##
    # Sets an element attribute.
    #
    # @param key What attribute to set.
    # @param value The attribute value.

    def set(self, key, value):
        self.attrib[key] = value

    ##
    # Gets a list of attribute names.  The names are returned in an
    # arbitrary order (just like for an ordinary Python dictionary).
    #
    # @return A list of element attribute names.
    # @defreturn list of strings

    def keys(self):
        return self.attrib.keys()

    ##
    # Gets element attributes, as a sequence.  The attributes are
    # returned in an arbitrary order.
    #
    # @return A list of (name, value) tuples for all attributes.
    # @defreturn list of (string, string) tuples

    def items(self):
        return self.attrib.items()

    ##
    # Creates a tree iterator.  The iterator loops over this element
    # and all subelements, in document order, and returns all elements
    # with a matching tag.
    # <p>
    # If the tree structure is modified during iteration, the result
    # is undefined.
    #
    # @param tag What tags to look for (default is to return all elements).
    # @return A list or iterator containing all the matching elements.
    # @defreturn list or iterator

    def getiterator(self, tag=None):
        nodes = []
        if tag == "*":
            tag = None
        if tag is None or self.tag == tag:
            nodes.append(self)
        for node in self._children:
            nodes.extend(node.getiterator(tag))
        return nodes

# compatibility
_Element = _ElementInterface

##
# Element factory.  This function returns an object implementing the
# standard Element interface.  The exact class or type of that object
# is implementation dependent, but it will always be compatible with
# the {@link #_ElementInterface} class in this module.
# <p>
# The element name, attribute names, and attribute values can be
# either 8-bit ASCII strings or Unicode strings.
#
# @param tag The element name.
# @param attrib An optional dictionary, containing element attributes.
# @param **extra Additional attributes, given as keyword arguments.
# @return An element instance.
# @defreturn Element


def Element(tag, attrib={}, **extra):
    attrib = attrib.copy()
    attrib.update(extra)
    return _ElementInterface(tag, attrib)

##
# Subelement factory.  This function creates an element instance, and
# appends it to an existing element.
# <p>
# The element name, attribute names, and attribute values can be
# either 8-bit ASCII strings or Unicode strings.
#
# @param parent The parent element.
# @param tag The subelement name.
# @param attrib An optional dictionary, containing element attributes.
# @param **extra Additional attributes, given as keyword arguments.
# @return An element instance.
# @defreturn Element


def SubElement(parent, tag, attrib={}, **extra):
    attrib = attrib.copy()
    attrib.update(extra)
    element = parent.makeelement(tag, attrib)
    parent.append(element)
    return element

##
# Comment element factory.  This factory function creates a special
# element that will be serialized as an XML comment.
# <p>
# The comment string can be either an 8-bit ASCII string or a Unicode
# string.
#
# @param text A string containing the comment string.
# @return An element instance, representing a comment.
# @defreturn Element


def Comment(text=None):
    element = Element(Comment)
    element.text = text
    return element

##
# PI element factory.  This factory function creates a special element
# that will be serialized as an XML processing instruction.
#
# @param target A string containing the PI target.
# @param text A string containing the PI contents, if any.
# @return An element instance, representing a PI.
# @defreturn Element


def ProcessingInstruction(target, text=None):
    element = Element(ProcessingInstruction)
    element.text = target
    if text:
        element.text = element.text + " " + text
    return element

PI = ProcessingInstruction

##
# QName wrapper.  This can be used to wrap a QName attribute value, in
# order to get proper namespace handling on output.
#
# @param text A string containing the QName value, in the form {uri}local,
#     or, if the tag argument is given, the URI part of a QName.
# @param tag Optional tag.  If given, the first argument is interpreted as
#     an URI, and this argument is interpreted as a local name.
# @return An opaque object, representing the QName.


class QName:
    def __init__(self, text_or_uri, tag=None):
        if tag:
            text_or_uri = "{%s}%s" % (text_or_uri, tag)
        self.text = text_or_uri

    def __str__(self):
        return self.text

    def __hash__(self):
        return hash(self.text)

    def __cmp__(self, other):
        if isinstance(other, QName):
            return cmp(self.text, other.text)
        return cmp(self.text, other)

##
# ElementTree wrapper class.  This class represents an entire element
# hierarchy, and adds some extra support for serialization to and from
# standard XML.
#
# @param element Optional root element.
# @keyparam file Optional file handle or name.  If given, the
#     tree is initialized with the contents of this XML file.


class ElementTree:

    def __init__(self, element=None, file=None):
        assert element is None or iselement(element)
        self._root = element  # first node
        if file:
            self.parse(file)

    ##
    # Gets the root element for this tree.
    #
    # @return An element instance.
    # @defreturn Element

    def getroot(self):
        return self._root

    ##
    # Replaces the root element for this tree.  This discards the
    # current contents of the tree, and replaces it with the given
    # element.  Use with care.
    #
    # @param element An element instance.

    def _setroot(self, element):
        assert iselement(element)
        self._root = element

    ##
    # Loads an external XML document into this element tree.
    #
    # @param source A file name or file object.
    # @param parser An optional parser instance.  If not given, the
    #     standard {@link XMLTreeBuilder} parser is used.
    # @return The document root element.
    # @defreturn Element

    def parse(self, source, parser=None):
        if not hasattr(source, "read"):
            source = open(source, "rb")
        if not parser:
            parser = XMLTreeBuilder()
        while 1:
            data = source.read(32768)
            if not data:
                break
            parser.feed(data)
        self._root = parser.close()
        return self._root

    ##
    # Creates a tree iterator for the root element.  The iterator loops
    # over all elements in this tree, in document order.
    #
    # @param tag What tags to look for (default is to return all elements)
    # @return An iterator.
    # @defreturn iterator

    def getiterator(self, tag=None):
        assert self._root is not None
        return self._root.getiterator(tag)

    ##
    # Finds the first toplevel element with given tag.
    # Same as getroot().find(path).
    #
    # @param path What element to look for.
    # @return The first matching element, or None if no element was found.
    # @defreturn Element or None

    def find(self, path):
        assert self._root is not None
        if path[:1] == "/":
            path = "." + path
        return self._root.find(path)

    ##
    # Finds the element text for the first toplevel element with given
    # tag.  Same as getroot().findtext(path).
    #
    # @param path What toplevel element to look for.
    # @param default What to return if the element was not found.
    # @return The text content of the first matching element, or the
    #     default value no element was found.  Note that if the element
    #     has is found, but has no text content, this method returns an
    #     empty string.
    # @defreturn string

    def findtext(self, path, default=None):
        assert self._root is not None
        if path[:1] == "/":
            path = "." + path
        return self._root.findtext(path, default)

    ##
    # Finds all toplevel elements with the given tag.
    # Same as getroot().findall(path).
    #
    # @param path What element to look for.
    # @return A list or iterator containing all matching elements,
    #    in document order.
    # @defreturn list of Element instances

    def findall(self, path):
        assert self._root is not None
        if path[:1] == "/":
            path = "." + path
        return self._root.findall(path)

    ##
    # Writes the element tree to a file, as XML.
    #
    # @param file A file name, or a file object opened for writing.
    # @param encoding Optional output encoding (default is US-ASCII).

    def write(self, file, encoding="us-ascii"):
        assert self._root is not None
        if not hasattr(file, "write"):
            file = open(file, "wb")
        if not encoding:
            encoding = "us-ascii"
        elif encoding != "utf-8" and encoding != "us-ascii":
            file.write("<?xml version='1.0' encoding='%s'?>\n" % encoding)
        self._write(file, self._root, encoding, {})

    def _write(self, file, node, encoding, namespaces):
        # write XML to file
        tag = node.tag
        if tag is Comment:
            file.write("<!-- %s -->" % _escape_cdata(node.text, encoding))
        elif tag is ProcessingInstruction:
            file.write("<?%s?>" % _escape_cdata(node.text, encoding))
        else:
            items = node.items()
            xmlns_items = []  # new namespaces in this scope
            try:
                if isinstance(tag, QName) or tag[:1] == "{":
                    tag, xmlns = fixtag(tag, namespaces)
                    if xmlns:
                        xmlns_items.append(xmlns)
            except TypeError:
                _raise_serialization_error(tag)
            file.write("<" + _encode(tag, encoding))
            if items or xmlns_items:
                items.sort()  # lexical order
                for k, v in items:
                    try:
                        if isinstance(k, QName) or k[:1] == "{":
                            k, xmlns = fixtag(k, namespaces)
                            if xmlns:
                                xmlns_items.append(xmlns)
                    except TypeError:
                        _raise_serialization_error(k)
                    try:
                        if isinstance(v, QName):
                            v, xmlns = fixtag(v, namespaces)
                            if xmlns:
                                xmlns_items.append(xmlns)
                    except TypeError:
                        _raise_serialization_error(v)
                    file.write(" %s=\"%s\"" % (_encode(k, encoding),
                                               _escape_attrib(v, encoding)))
                for k, v in xmlns_items:
                    file.write(" %s=\"%s\"" % (_encode(k, encoding),
                                               _escape_attrib(v, encoding)))
            if node.text or len(node):
                file.write(">")
                if node.text:
                    file.write(_escape_cdata(node.text, encoding))
                for n in node:
                    self._write(file, n, encoding, namespaces)
                file.write("</" + _encode(tag, encoding) + ">")
            else:
                file.write(" />")
            for k, v in xmlns_items:
                del namespaces[v]
        if node.tail:
            file.write(_escape_cdata(node.tail, encoding))

# --------------------------------------------------------------------
# helpers

##
# Checks if an object appears to be a valid element object.
#
# @param An element instance.
# @return A true value if this is an element object.
# @defreturn flag


def iselement(element):
    # FIXME: not sure about this; might be a better idea to look
    # for tag/attrib/text attributes
    return isinstance(element, _ElementInterface) or hasattr(element, "tag")

##
# Writes an element tree or element structure to sys.stdout.  This
# function should be used for debugging only.
# <p>
# The exact output format is implementation dependent.  In this
# version, it's written as an ordinary XML file.
#
# @param elem An element tree or an individual element.


def dump(elem):
    # debugging
    if not isinstance(elem, ElementTree):
        elem = ElementTree(elem)
    elem.write(sys.stdout)
    tail = elem.getroot().tail
    if not tail or tail[-1] != "\n":
        sys.stdout.write("\n")


def _encode(s, encoding):
    try:
        return s.encode(encoding)
    except AttributeError:
        return s  # 1.5.2: assume the string uses the right encoding

if sys.version[:3] == "1.5":
    _escape = re.compile(r"[&<>\"\x80-\xff]+")  # 1.5.2
    _escape_attrib_pat = re.compile(r"[&<>\"\n\r\x80-\xff]+")  # 1.5.2
else:
    _escape = re.compile(eval(r'u"[&<>\"\u0080-\uffff]+"'))
    _escape_attrib_pat = re.compile(eval(r'u"[&<>\"\n\r\u0080-\uffff]+"'))

_escape_map = {
    "&": "&amp;",
    "<": "&lt;",
    ">": "&gt;",
    '"': "&quot;",
    "\n": "&#xA;",
    "\r": "&#xD;",
}

_namespace_map = {
    # "well-known" namespace prefixes
    "http://www.w3.org/XML/1998/namespace": "xml",
    "http://www.w3.org/1999/xhtml": "html",
    "http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
    "http://schemas.xmlsoap.org/wsdl/": "wsdl",
}


def _raise_serialization_error(text):
    raise TypeError(
        "cannot serialize %r (type %s)" % (text, type(text).__name__)
    )


def _encode_entity(text, pattern=_escape):
    # map reserved and non-ascii characters to numerical entities
    def escape_entities(m, map=_escape_map):
        out = []
        append = out.append
        for char in m.group():
            text = map.get(char)
            if text is None:
                text = "&#%d;" % ord(char)
            append(text)
        return string.join(out, "")
    try:
        return _encode(pattern.sub(escape_entities, text), "ascii")
    except TypeError:
        _raise_serialization_error(text)

#
# the following functions assume an ascii-compatible encoding
# (or "utf-16")


def _escape_cdata(text, encoding=None, replace=string.replace):
    # escape character data
    try:
        if encoding:
            try:
                text = _encode(text, encoding)
            except UnicodeError:
                return _encode_entity(text)
        text = replace(text, "&", "&amp;")
        text = replace(text, "<", "&lt;")
        text = replace(text, ">", "&gt;")
        return text
    except (TypeError, AttributeError):
        _raise_serialization_error(text)


def _escape_attrib(text, encoding=None, replace=string.replace):
    # escape attribute value
    try:
        if encoding:
            try:
                text = _encode(text, encoding)
            except UnicodeError:
                return _encode_entity(text, _escape_attrib_pat)
        text = replace(text, "&", "&amp;")
        text = replace(text, "'", "&apos;")  # FIXME: overkill
        text = replace(text, "\"", "&quot;")
        text = replace(text, "<", "&lt;")
        text = replace(text, ">", "&gt;")
        text = replace(text, "\n", "&#xA;")
        text = replace(text, "\r", "&#xD;")
        return text
    except (TypeError, AttributeError):
        _raise_serialization_error(text)


def fixtag(tag, namespaces):
    # given a decorated tag (of the form {uri}tag), return prefixed
    # tag and namespace declaration, if any
    if isinstance(tag, QName):
        tag = tag.text
    namespace_uri, tag = string.split(tag[1:], "}", 1)
    prefix = namespaces.get(namespace_uri)
    if prefix is None:
        prefix = _namespace_map.get(namespace_uri)
        if prefix is None:
            prefix = "ns%d" % len(namespaces)
        namespaces[namespace_uri] = prefix
        if prefix == "xml":
            xmlns = None
        else:
            xmlns = ("xmlns:%s" % prefix, namespace_uri)
    else:
        xmlns = None
    return "%s:%s" % (prefix, tag), xmlns

##
# Parses an XML document into an element tree.
#
# @param source A filename or file object containing XML data.
# @param parser An optional parser instance.  If not given, the
#     standard {@link XMLTreeBuilder} parser is used.
# @return An ElementTree instance


def parse(source, parser=None):
    tree = ElementTree()
    tree.parse(source, parser)
    return tree

##
# Parses an XML document into an element tree incrementally, and reports
# what's going on to the user.
#
# @param source A filename or file object containing XML data.
# @param events A list of events to report back.  If omitted, only "end"
#     events are reported.
# @return A (event, elem) iterator.


class iterparse:

    def __init__(self, source, events=None):
        if not hasattr(source, "read"):
            source = open(source, "rb")
        self._file = source
        self._events = []
        self._index = 0
        self.root = self._root = None
        self._parser = XMLTreeBuilder()
        # wire up the parser for event reporting
        parser = self._parser._parser
        append = self._events.append
        if events is None:
            events = ["end"]
        for event in events:
            if event == "start":
                try:
                    parser.ordered_attributes = 1
                    parser.specified_attributes = 1

                    def handler(tag, attrib_in, event=event, append=append,
                                start=self._parser._start_list):
                        append((event, start(tag, attrib_in)))
                    parser.StartElementHandler = handler
                except AttributeError:
                    def handler(tag, attrib_in, event=event, append=append,
                                start=self._parser._start):
                        append((event, start(tag, attrib_in)))
                    parser.StartElementHandler = handler
            elif event == "end":
                def handler(tag, event=event, append=append,
                            end=self._parser._end):
                    append((event, end(tag)))
                parser.EndElementHandler = handler
            elif event == "start-ns":
                def handler(prefix, uri, event=event, append=append):
                    try:
                        uri = _encode(uri, "ascii")
                    except UnicodeError:
                        pass
                    append((event, (prefix or "", uri)))
                parser.StartNamespaceDeclHandler = handler
            elif event == "end-ns":
                def handler(prefix, event=event, append=append):
                    append((event, None))
                parser.EndNamespaceDeclHandler = handler

    def next(self):
        while 1:
            try:
                item = self._events[self._index]
            except IndexError:
                if self._parser is None:
                    self.root = self._root
                    try:
                        raise StopIteration
                    except NameError:
                        raise IndexError
                # load event buffer
                del self._events[:]
                self._index = 0
                data = self._file.read(16384)
                if data:
                    self._parser.feed(data)
                else:
                    self._root = self._parser.close()
                    self._parser = None
            else:
                self._index = self._index + 1
                return item

    try:
        iter

        def __iter__(self):
            return self
    except NameError:
        def __getitem__(self, index):
            return self.next()

##
# Parses an XML document from a string constant.  This function can
# be used to embed "XML literals" in Python code.
#
# @param source A string containing XML data.
# @return An Element instance.
# @defreturn Element


def XML(text):
    parser = XMLTreeBuilder()
    parser.feed(text)
    return parser.close()

##
# Parses an XML document from a string constant, and also returns
# a dictionary which maps from element id:s to elements.
#
# @param source A string containing XML data.
# @return A tuple containing an Element instance and a dictionary.
# @defreturn (Element, dictionary)


def XMLID(text):
    parser = XMLTreeBuilder()
    parser.feed(text)
    tree = parser.close()
    ids = {}
    for elem in tree.getiterator():
        id = elem.get("id")
        if id:
            ids[id] = elem
    return tree, ids

##
# Parses an XML document from a string constant.  Same as {@link #XML}.
#
# @def fromstring(text)
# @param source A string containing XML data.
# @return An Element instance.
# @defreturn Element

fromstring = XML

##
# Generates a string representation of an XML element, including all
# subelements.
#
# @param element An Element instance.
# @return An encoded string containing the XML data.
# @defreturn string


def tostring(element, encoding=None):
    class dummy:
        pass
    data = []
    file = dummy()
    file.write = data.append
    ElementTree(element).write(file, encoding)
    return string.join(data, "")

##
# Generic element structure builder.  This builder converts a sequence
# of {@link #TreeBuilder.start}, {@link #TreeBuilder.data}, and {@link
# #TreeBuilder.end} method calls to a well-formed element structure.
# <p>
# You can use this class to build an element structure using a custom XML
# parser, or a parser for some other XML-like format.
#
# @param element_factory Optional element factory.  This factory
#    is called to create new Element instances, as necessary.


class TreeBuilder:

    def __init__(self, element_factory=None):
        self._data = []  # data collector
        self._elem = []  # element stack
        self._last = None  # last element
        self._tail = None  # true if we're after an end tag
        if element_factory is None:
            element_factory = _ElementInterface
        self._factory = element_factory

    ##
    # Flushes the parser buffers, and returns the toplevel documen
    # element.
    #
    # @return An Element instance.
    # @defreturn Element

    def close(self):
        assert len(self._elem) == 0, "missing end tags"
        assert self._last != None, "missing toplevel element"
        return self._last

    def _flush(self):
        if self._data:
            if self._last is not None:
                text = string.join(self._data, "")
                if self._tail:
                    assert self._last.tail is None, "internal error (tail)"
                    self._last.tail = text
                else:
                    assert self._last.text is None, "internal error (text)"
                    self._last.text = text
            self._data = []

    ##
    # Adds text to the current element.
    #
    # @param data A string.  This should be either an 8-bit string
    #    containing ASCII text, or a Unicode string.

    def data(self, data):
        self._data.append(data)

    ##
    # Opens a new element.
    #
    # @param tag The element name.
    # @param attrib A dictionary containing element attributes.
    # @return The opened element.
    # @defreturn Element

    def start(self, tag, attrs):
        self._flush()
        self._last = elem = self._factory(tag, attrs)
        if self._elem:
            self._elem[-1].append(elem)
        self._elem.append(elem)
        self._tail = 0
        return elem

    ##
    # Closes the current element.
    #
    # @param tag The element name.
    # @return The closed element.
    # @defreturn Element

    def end(self, tag):
        self._flush()
        self._last = self._elem.pop()
        assert self._last.tag == tag,\
            "end tag mismatch (expected %s, got %s)" % (
                self._last.tag, tag)
        self._tail = 1
        return self._last

##
# Element structure builder for XML source data, based on the
# <b>expat</b> parser.
#
# @keyparam target Target object.  If omitted, the builder uses an
#     instance of the standard {@link #TreeBuilder} class.
# @keyparam html Predefine HTML entities.  This flag is not supported
#     by the current implementation.
# @see #ElementTree
# @see #TreeBuilder


class XMLTreeBuilder:

    def __init__(self, html=0, target=None):
        try:
            from xml.parsers import expat
        except ImportError:
            raise ImportError(
                "No module named expat; use SimpleXMLTreeBuilder instead"
            )
        self._parser = parser = expat.ParserCreate(None, "}")
        if target is None:
            target = TreeBuilder()
        self._target = target
        self._names = {}  # name memo cache
        # callbacks
        parser.DefaultHandlerExpand = self._default
        parser.StartElementHandler = self._start
        parser.EndElementHandler = self._end
        parser.CharacterDataHandler = self._data
        # let expat do the buffering, if supported
        try:
            self._parser.buffer_text = 1
        except AttributeError:
            pass
        # use new-style attribute handling, if supported
        try:
            self._parser.ordered_attributes = 1
            self._parser.specified_attributes = 1
            parser.StartElementHandler = self._start_list
        except AttributeError:
            pass
        encoding = None
        if not parser.returns_unicode:
            encoding = "utf-8"
        # target.xml(encoding, None)
        self._doctype = None
        self.entity = {}

    def _fixtext(self, text):
        # convert text string to ascii, if possible
        try:
            return _encode(text, "ascii")
        except UnicodeError:
            return text

    def _fixname(self, key):
        # expand qname, and convert name string to ascii, if possible
        try:
            name = self._names[key]
        except KeyError:
            name = key
            if "}" in name:
                name = "{" + name
            self._names[key] = name = self._fixtext(name)
        return name

    def _start(self, tag, attrib_in):
        fixname = self._fixname
        tag = fixname(tag)
        attrib = {}
        for key, value in attrib_in.items():
            attrib[fixname(key)] = self._fixtext(value)
        return self._target.start(tag, attrib)

    def _start_list(self, tag, attrib_in):
        fixname = self._fixname
        tag = fixname(tag)
        attrib = {}
        if attrib_in:
            for i in range(0, len(attrib_in), 2):
                attrib[fixname(attrib_in[i])] = self._fixtext(attrib_in[i+1])
        return self._target.start(tag, attrib)

    def _data(self, text):
        return self._target.data(self._fixtext(text))

    def _end(self, tag):
        return self._target.end(self._fixname(tag))

    def _default(self, text):
        prefix = text[:1]
        if prefix == "&":
            # deal with undefined entities
            try:
                self._target.data(self.entity[text[1:-1]])
            except KeyError:
                from xml.parsers import expat
                raise expat.error(
                    "undefined entity %s: line %d, column %d" %
                    (text, self._parser.ErrorLineNumber,
                    self._parser.ErrorColumnNumber)
                )
        elif prefix == "<" and text[:9] == "<!DOCTYPE":
            self._doctype = []  # inside a doctype declaration
        elif self._doctype is not None:
            # parse doctype contents
            if prefix == ">":
                self._doctype = None
                return
            text = string.strip(text)
            if not text:
                return
            self._doctype.append(text)
            n = len(self._doctype)
            if n > 2:
                type = self._doctype[1]
                if type == "PUBLIC" and n == 4:
                    name, type, pubid, system = self._doctype
                elif type == "SYSTEM" and n == 3:
                    name, type, system = self._doctype
                    pubid = None
                else:
                    return
                if pubid:
                    pubid = pubid[1:-1]
                self.doctype(name, pubid, system[1:-1])
                self._doctype = None

    ##
    # Handles a doctype declaration.
    #
    # @param name Doctype name.
    # @param pubid Public identifier.
    # @param system System identifier.

    def doctype(self, name, pubid, system):
        pass

    ##
    # Feeds data to the parser.
    #
    # @param data Encoded data.

    def feed(self, data):
        self._parser.Parse(data, 0)

    ##
    # Finishes feeding data to the parser.
    #
    # @return An element structure.
    # @defreturn Element

    def close(self):
        self._parser.Parse("", 1)  # end of data
        tree = self._target.close()
        del self._target, self._parser  # get rid of circular references
        return tree

########NEW FILE########
__FILENAME__ = HTMLTreeBuilder
#
# ElementTree
# $Id$
#
# a simple tree builder, for HTML input
#
# history:
# 2002-04-06 fl   created
# 2002-04-07 fl   ignore IMG and HR end tags
# 2002-04-07 fl   added support for 1.5.2 and later
# 2003-04-13 fl   added HTMLTreeBuilder alias
# 2004-12-02 fl   don't feed non-ASCII charrefs/entities as 8-bit strings
# 2004-12-05 fl   don't feed non-ASCII CDATA as 8-bit strings
#
# Copyright (c) 1999-2004 by Fredrik Lundh.  All rights reserved.
#
# fredrik@pythonware.com
# http://www.pythonware.com
#
# --------------------------------------------------------------------
# The ElementTree toolkit is
#
# Copyright (c) 1999-2004 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

##
# Tools to build element trees from HTML files.
##

import htmlentitydefs
import re
import string
import sys
import mimetools
import StringIO

import ElementTree

AUTOCLOSE = "p", "li", "tr", "th", "td", "head", "body"
IGNOREEND = "img", "hr", "meta", "link", "br"

if sys.version[:3] == "1.5":
    is_not_ascii = re.compile(r"[\x80-\xff]").search  # 1.5.2
else:
    is_not_ascii = re.compile(eval(r'u"[\u0080-\uffff]"')).search

try:
    from HTMLParser import HTMLParser
except ImportError:
    from sgmllib import SGMLParser
    # hack to use sgmllib's SGMLParser to emulate 2.2's HTMLParser

    class HTMLParser(SGMLParser):
        # the following only works as long as this class doesn't
        # provide any do, start, or end handlers
        def unknown_starttag(self, tag, attrs):
            self.handle_starttag(tag, attrs)

        def unknown_endtag(self, tag):
            self.handle_endtag(tag)

##
# ElementTree builder for HTML source code.  This builder converts an
# HTML document or fragment to an ElementTree.
# <p>
# The parser is relatively picky, and requires balanced tags for most
# elements.  However, elements belonging to the following group are
# automatically closed: P, LI, TR, TH, and TD.  In addition, the
# parser automatically inserts end tags immediately after the start
# tag, and ignores any end tags for the following group: IMG, HR,
# META, and LINK.
#
# @keyparam builder Optional builder object.  If omitted, the parser
#     uses the standard <b>elementtree</b> builder.
# @keyparam encoding Optional character encoding, if known.  If omitted,
#     the parser looks for META tags inside the document.  If no tags
#     are found, the parser defaults to ISO-8859-1.  Note that if your
#     document uses a non-ASCII compatible encoding, you must decode
#     the document before parsing.
#
# @see elementtree.ElementTree


class HTMLTreeBuilder(HTMLParser):

    # FIXME: shouldn't this class be named Parser, not Builder?

    def __init__(self, builder=None, encoding=None):
        self.__stack = []
        if builder is None:
            builder = ElementTree.TreeBuilder()
        self.__builder = builder
        self.encoding = encoding or "iso-8859-1"
        HTMLParser.__init__(self)

    ##
    # Flushes parser buffers, and return the root element.
    #
    # @return An Element instance.

    def close(self):
        HTMLParser.close(self)
        return self.__builder.close()

    ##
    # (Internal) Handles start tags.

    def handle_starttag(self, tag, attrs):
        if tag == "meta":
            # look for encoding directives
            http_equiv = content = None
            for k, v in attrs:
                if k == "http-equiv":
                    http_equiv = string.lower(v)
                elif k == "content":
                    content = v
            if http_equiv == "content-type" and content:
                # use mimetools to parse the http header
                header = mimetools.Message(
                    StringIO.StringIO("%s: %s\n\n" % (http_equiv, content))
                )
                encoding = header.getparam("charset")
                if encoding:
                    self.encoding = encoding
        if tag in AUTOCLOSE:
            if self.__stack and self.__stack[-1] == tag:
                self.handle_endtag(tag)
        self.__stack.append(tag)
        attrib = {}
        if attrs:
            for k, v in attrs:
                attrib[string.lower(k)] = v
        self.__builder.start(tag, attrib)
        if tag in IGNOREEND:
            self.__stack.pop()
            self.__builder.end(tag)

    ##
    # (Internal) Handles end tags.

    def handle_endtag(self, tag):
        if tag in IGNOREEND:
            return
        lasttag = self.__stack.pop()
        if tag != lasttag and lasttag in AUTOCLOSE:
            self.handle_endtag(lasttag)
        self.__builder.end(tag)

    ##
    # (Internal) Handles character references.

    def handle_charref(self, char):
        if char[:1] == "x":
            char = int(char[1:], 16)
        else:
            char = int(char)
        if 0 <= char < 128:
            self.__builder.data(chr(char))
        else:
            self.__builder.data(unichr(char))

    ##
    # (Internal) Handles entity references.

    def handle_entityref(self, name):
        entity = htmlentitydefs.entitydefs.get(name)
        if entity:
            if len(entity) == 1:
                entity = ord(entity)
            else:
                entity = int(entity[2:-1])
            if 0 <= entity < 128:
                self.__builder.data(chr(entity))
            else:
                self.__builder.data(unichr(entity))
        else:
            self.unknown_entityref(name)

    ##
    # (Internal) Handles character data.

    def handle_data(self, data):
        if isinstance(data, type('')) and is_not_ascii(data):
            # convert to unicode, but only if necessary
            data = unicode(data, self.encoding, "ignore")
        self.__builder.data(data)

    ##
    # (Hook) Handles unknown entity references.  The default action
    # is to ignore unknown entities.

    def unknown_entityref(self, name):
        pass  # ignore by default; override if necessary

##
# An alias for the <b>HTMLTreeBuilder</b> class.

TreeBuilder = HTMLTreeBuilder

##
# Parse an HTML document or document fragment.
#
# @param source A filename or file object containing HTML data.
# @param encoding Optional character encoding, if known.  If omitted,
#     the parser looks for META tags inside the document.  If no tags
#     are found, the parser defaults to ISO-8859-1.
# @return An ElementTree instance


def parse(source, encoding=None):
    return ElementTree.parse(source, HTMLTreeBuilder(encoding=encoding))

if __name__ == "__main__":
    import sys
    ElementTree.dump(parse(open(sys.argv[1])))

########NEW FILE########
__FILENAME__ = SgmlopXMLTreeBuilder
#
# ElementTree
# $Id$
#
# A simple XML tree builder, based on the sgmlop library.
#
# Note that this version does not support namespaces.  This may be
# changed in future versions.
#
# history:
# 2004-03-28 fl   created
#
# Copyright (c) 1999-2004 by Fredrik Lundh.  All rights reserved.
#
# fredrik@pythonware.com
# http://www.pythonware.com
#
# --------------------------------------------------------------------
# The ElementTree toolkit is
#
# Copyright (c) 1999-2004 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

##
# Tools to build element trees from XML, based on the SGMLOP parser.
# <p>
# The current version does not support XML namespaces.
# <p>
# This tree builder requires the <b>sgmlop</b> extension module
# (available from
# <a href='http://effbot.org/downloads'>http://effbot.org/downloads</a>).
##

import ElementTree

##
# ElementTree builder for XML source data, based on the SGMLOP parser.
#
# @see elementtree.ElementTree


class TreeBuilder:

    def __init__(self, html=0):
        try:
            import sgmlop
        except ImportError:
            raise RuntimeError("sgmlop parser not available")
        self.__builder = ElementTree.TreeBuilder()
        if html:
            import htmlentitydefs
            self.entitydefs.update(htmlentitydefs.entitydefs)
        self.__parser = sgmlop.XMLParser()
        self.__parser.register(self)

    ##
    # Feeds data to the parser.
    #
    # @param data Encoded data.

    def feed(self, data):
        self.__parser.feed(data)

    ##
    # Finishes feeding data to the parser.
    #
    # @return An element structure.
    # @defreturn Element

    def close(self):
        self.__parser.close()
        self.__parser = None
        return self.__builder.close()

    def finish_starttag(self, tag, attrib):
        self.__builder.start(tag, attrib)

    def finish_endtag(self, tag):
        self.__builder.end(tag)

    def handle_data(self, data):
        self.__builder.data(data)

########NEW FILE########
__FILENAME__ = SimpleXMLTreeBuilder
#
# ElementTree
# $Id$
#
# A simple XML tree builder, based on Python's xmllib
#
# Note that due to bugs in xmllib, this builder does not fully support
# namespaces (unqualified attributes are put in the default namespace,
# instead of being left as is).  Run this module as a script to find
# out if this affects your Python version.
#
# history:
# 2001-10-20 fl   created
# 2002-05-01 fl   added namespace support for xmllib
# 2002-08-17 fl   added xmllib sanity test
#
# Copyright (c) 1999-2004 by Fredrik Lundh.  All rights reserved.
#
# fredrik@pythonware.com
# http://www.pythonware.com
#
# --------------------------------------------------------------------
# The ElementTree toolkit is
#
# Copyright (c) 1999-2004 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

##
# Tools to build element trees from XML files, using <b>xmllib</b>.
# This module can be used instead of the standard tree builder, for
# Python versions where "expat" is not available (such as 1.5.2).
# <p>
# Note that due to bugs in <b>xmllib</b>, the namespace support is
# not reliable (you can run the module as a script to find out exactly
# how unreliable it is on your Python version).
##

import xmllib
import string

import ElementTree

##
# ElementTree builder for XML source data.
#
# @see elementtree.ElementTree


class TreeBuilder(xmllib.XMLParser):

    def __init__(self, html=0):
        self.__builder = ElementTree.TreeBuilder()
        if html:
            import htmlentitydefs
            self.entitydefs.update(htmlentitydefs.entitydefs)
        xmllib.XMLParser.__init__(self)

    ##
    # Feeds data to the parser.
    #
    # @param data Encoded data.

    def feed(self, data):
        xmllib.XMLParser.feed(self, data)

    ##
    # Finishes feeding data to the parser.
    #
    # @return An element structure.
    # @defreturn Element

    def close(self):
        xmllib.XMLParser.close(self)
        return self.__builder.close()

    def handle_data(self, data):
        self.__builder.data(data)

    handle_cdata = handle_data

    def unknown_starttag(self, tag, attrs):
        attrib = {}
        for key, value in attrs.items():
            attrib[fixname(key)] = value
        self.__builder.start(fixname(tag), attrib)

    def unknown_endtag(self, tag):
        self.__builder.end(fixname(tag))


def fixname(name, split=string.split):
    # xmllib in 2.0 and later provides limited (and slightly broken)
    # support for XML namespaces.
    if " " not in name:
        return name
    return "{%s}%s" % tuple(split(name, " ", 1))


if __name__ == "__main__":
    import sys
    # sanity check: look for known namespace bugs in xmllib
    p = TreeBuilder()
    text = """\
    <root xmlns='default'>
       <tag attribute='value' />
    </root>
    """
    p.feed(text)
    tree = p.close()
    status = []
    # check for bugs in the xmllib implementation
    tag = tree.find("{default}tag")
    if tag is None:
        status.append("namespaces not supported")
    if tag is not None and tag.get("{default}attribute"):
        status.append("default namespace applied to unqualified attribute")
    # report bugs
    if status:
        print "xmllib doesn't work properly in this Python version:"
        for bug in status:
            print "-", bug
    else:
        print "congratulations; no problems found in xmllib"

########NEW FILE########
__FILENAME__ = SimpleXMLWriter
#
# SimpleXMLWriter
# $Id$
#
# a simple XML writer
#
# history:
# 2001-12-28 fl   created
# 2002-11-25 fl   fixed attribute encoding
# 2002-12-02 fl   minor fixes for 1.5.2
# 2004-06-17 fl   added pythondoc markup
# 2004-07-23 fl   added flush method (from Jay Graves)
# 2004-10-03 fl   added declaration method
#
# Copyright (c) 2001-2004 by Fredrik Lundh
#
# fredrik@pythonware.com
# http://www.pythonware.com
#
# --------------------------------------------------------------------
# The SimpleXMLWriter module is
#
# Copyright (c) 2001-2004 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

##
# Tools to write XML files, without having to deal with encoding
# issues, well-formedness, etc.
# <p>
# The current version does not provide built-in support for
# namespaces. To create files using namespaces, you have to provide
# "xmlns" attributes and explicitly add prefixes to tags and
# attributes.
#
# <h3>Patterns</h3>
#
# The following example generates a small XHTML document.
# <pre>
#
# from elementtree.SimpleXMLWriter import XMLWriter
# import sys
#
# w = XMLWriter(sys.stdout)
#
# html = w.start("html")
#
# w.start("head")
# w.element("title", "my document")
# w.element("meta", name="generator", value="my application 1.0")
# w.end()
#
# w.start("body")
# w.element("h1", "this is a heading")
# w.element("p", "this is a paragraph")
#
# w.start("p")
# w.data("this is ")
# w.element("b", "bold")
# w.data(" and ")
# w.element("i", "italic")
# w.data(".")
# w.end("p")
#
# w.close(html)
# </pre>
##

import re
import sys
import string

try:
    unicode("")
except NameError:
    def encode(s, encoding):
        # 1.5.2: application must use the right encoding
        return s
    _escape = re.compile(r"[&<>\"\x80-\xff]+")  # 1.5.2
else:
    def encode(s, encoding):
        return s.encode(encoding)
    _escape = re.compile(eval(r'u"[&<>\"\u0080-\uffff]+"'))


def encode_entity(text, pattern=_escape):
    # map reserved and non-ascii characters to numerical entities
    def escape_entities(m):
        out = []
        for char in m.group():
            out.append("&#%d;" % ord(char))
        return string.join(out, "")
    return encode(pattern.sub(escape_entities, text), "ascii")

del _escape

#
# the following functions assume an ascii-compatible encoding
# (or "utf-16")


def escape_cdata(s, encoding=None, replace=string.replace):
    s = replace(s, "&", "&amp;")
    s = replace(s, "<", "&lt;")
    s = replace(s, ">", "&gt;")
    if encoding:
        try:
            return encode(s, encoding)
        except UnicodeError:
            return encode_entity(s)
    return s


def escape_attrib(s, encoding=None, replace=string.replace):
    s = replace(s, "&", "&amp;")
    s = replace(s, "'", "&apos;")
    s = replace(s, "\"", "&quot;")
    s = replace(s, "<", "&lt;")
    s = replace(s, ">", "&gt;")
    if encoding:
        try:
            return encode(s, encoding)
        except UnicodeError:
            return encode_entity(s)
    return s

##
# XML writer class.
#
# @param file A file or file-like object.  This object must implement
#    a <b>write</b> method that takes an 8-bit string.
# @param encoding Optional encoding.


class XMLWriter:

    def __init__(self, file, encoding="us-ascii"):
        if not hasattr(file, "write"):
            file = open(file, "w")
        self.__write = file.write
        if hasattr(file, "flush"):
            self.flush = file.flush
        self.__open = 0  # true if start tag is open
        self.__tags = []
        self.__data = []
        self.__encoding = encoding

    def __flush(self):
        # flush internal buffers
        if self.__open:
            self.__write(">")
            self.__open = 0
        if self.__data:
            data = string.join(self.__data, "")
            self.__write(escape_cdata(data, self.__encoding))
            self.__data = []

    ##
    # Writes an XML declaration.

    def declaration(self):
        encoding = self.__encoding
        if encoding == "us-ascii" or encoding == "utf-8":
            self.__write("<?xml version='1.0'?>\n")
        else:
            self.__write("<?xml version='1.0' encoding='%s'?>\n" % encoding)

    ##
    # Opens a new element.  Attributes can be given as keyword
    # arguments, or as a string/string dictionary. You can pass in
    # 8-bit strings or Unicode strings; the former are assumed to use
    # the encoding passed to the constructor.  The method returns an
    # opaque identifier that can be passed to the <b>close</b> method,
    # to close all open elements up to and including this one.
    #
    # @param tag Element tag.
    # @param attrib Attribute dictionary.  Alternatively, attributes
    #    can be given as keyword arguments.
    # @return An element identifier.

    def start(self, tag, attrib={}, **extra):
        self.__flush()
        tag = escape_cdata(tag, self.__encoding)
        self.__data = []
        self.__tags.append(tag)
        self.__write("<%s" % tag)
        if attrib or extra:
            attrib = attrib.copy()
            attrib.update(extra)
            attrib = attrib.items()
            attrib.sort()
            for k, v in attrib:
                k = escape_cdata(k, self.__encoding)
                v = escape_attrib(v, self.__encoding)
                self.__write(" %s=\"%s\"" % (k, v))
        self.__open = 1
        return len(self.__tags)-1

    ##
    # Adds a comment to the output stream.
    #
    # @param comment Comment text, as an 8-bit string or Unicode string.

    def comment(self, comment):
        self.__flush()
        self.__write("<!-- %s -->\n" % escape_cdata(comment, self.__encoding))

    ##
    # Adds character data to the output stream.
    #
    # @param text Character data, as an 8-bit string or Unicode string.

    def data(self, text):
        self.__data.append(text)

    ##
    # Closes the current element (opened by the most recent call to
    # <b>start</b>).
    #
    # @param tag Element tag.  If given, the tag must match the start
    #    tag.  If omitted, the current element is closed.

    def end(self, tag=None):
        if tag:
            assert self.__tags, "unbalanced end(%s)" % tag
            assert escape_cdata(tag, self.__encoding) == self.__tags[-1],\
                "expected end(%s), got %s" % (self.__tags[-1], tag)
        else:
            assert self.__tags, "unbalanced end()"
        tag = self.__tags.pop()
        if self.__data:
            self.__flush()
        elif self.__open:
            self.__open = 0
            self.__write(" />")
            return
        self.__write("</%s>" % tag)

    ##
    # Closes open elements, up to (and including) the element identified
    # by the given identifier.
    #
    # @param id Element identifier, as returned by the <b>start</b> method.

    def close(self, id):
        while len(self.__tags) > id:
            self.end()

    ##
    # Adds an entire element.  This is the same as calling <b>start</b>,
    # <b>data</b>, and <b>end</b> in sequence. The <b>text</b> argument
    # can be omitted.

    def element(self, tag, text=None, attrib={}, **extra):
        apply(self.start, (tag, attrib), extra)
        if text:
            self.data(text)
        self.end()

    ##
    # Flushes the output stream.

    def flush(self):
        pass  # replaced by the constructor

########NEW FILE########
__FILENAME__ = TidyHTMLTreeBuilder
#
# ElementTree
# $Id$
#

from elementtidy.TidyHTMLTreeBuilder import *

########NEW FILE########
__FILENAME__ = TidyTools
#
# ElementTree
# $Id$
#
# tools to run the "tidy" command on an HTML or XHTML file, and return
# the contents as an XHTML element tree.
#
# history:
# 2002-10-19 fl   added to ElementTree library; added getzonebody function
#
# Copyright (c) 1999-2004 by Fredrik Lundh.  All rights reserved.
#
# fredrik@pythonware.com
# http://www.pythonware.com
#

##
# Tools to build element trees from HTML, using the external <b>tidy</b>
# utility.
##

import glob
import string
import os
import sys

from ElementTree import ElementTree, Element

NS_XHTML = "{http://www.w3.org/1999/xhtml}"

##
# Convert an HTML or HTML-like file to XHTML, using the <b>tidy</b>
# command line utility.
#
# @param file Filename.
# @param new_inline_tags An optional list of valid but non-standard
#     inline tags.
# @return An element tree, or None if not successful.


def tidy(file, new_inline_tags=None):

    command = ["tidy", "-qn", "-asxml"]

    if new_inline_tags:
        command.append("--new-inline-tags")
        command.append(string.join(new_inline_tags, ","))

    # FIXME: support more tidy options!

    # convert
    os.system(
        "%s %s >%s.out 2>%s.err" % (string.join(command), file, file, file)
    )
    # check that the result is valid XML
    try:
        tree = ElementTree()
        tree.parse(file + ".out")
    except:
        print "*** %s:%s" % sys.exc_info()[:2]
        print ("*** %s is not valid XML "
               "(check %s.err for info)" % (file, file))
        tree = None
    else:
        if os.path.isfile(file + ".out"):
            os.remove(file + ".out")
        if os.path.isfile(file + ".err"):
            os.remove(file + ".err")

    return tree

##
# Get document body from a an HTML or HTML-like file.  This function
# uses the <b>tidy</b> function to convert HTML to XHTML, and cleans
# up the resulting XML tree.
#
# @param file Filename.
# @return A <b>body</b> element, or None if not successful.


def getbody(file, **options):
    # get clean body from text file

    # get xhtml tree
    try:
        tree = apply(tidy, (file,), options)
        if tree is None:
            return
    except IOError, v:
        print "***", v
        return None

    NS = NS_XHTML

    # remove namespace uris
    for node in tree.getiterator():
        if node.tag.startswith(NS):
            node.tag = node.tag[len(NS):]

    body = tree.getroot().find("body")

    return body

##
# Same as <b>getbody</b>, but turns plain text at the start of the
# document into an H1 tag.  This function can be used to parse zone
# documents.
#
# @param file Filename.
# @return A <b>body</b> element, or None if not successful.


def getzonebody(file, **options):

    body = getbody(file, **options)
    if body is None:
        return

    if body.text and string.strip(body.text):
        title = Element("h1")
        title.text = string.strip(body.text)
        title.tail = "\n\n"
        body.insert(0, title)

    body.text = None

    return body

if __name__ == "__main__":

    import sys
    for arg in sys.argv[1:]:
        for file in glob.glob(arg):
            print file, "...", tidy(file)

########NEW FILE########
__FILENAME__ = XMLTreeBuilder
#
# ElementTree
# $Id$
#
# an XML tree builder
#
# history:
# 2001-10-20 fl   created
# 2002-05-01 fl   added namespace support for xmllib
# 2002-07-27 fl   require expat (1.5.2 code can use SimpleXMLTreeBuilder)
# 2002-08-17 fl   use tag/attribute name memo cache
# 2002-12-04 fl   moved XMLTreeBuilder to the ElementTree module
#
# Copyright (c) 1999-2004 by Fredrik Lundh.  All rights reserved.
#
# fredrik@pythonware.com
# http://www.pythonware.com
#
# --------------------------------------------------------------------
# The ElementTree toolkit is
#
# Copyright (c) 1999-2004 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

##
# Tools to build element trees from XML files.
##

import ElementTree

##
# (obsolete) ElementTree builder for XML source data, based on the
# <b>expat</b> parser.
# <p>
# This class is an alias for ElementTree.XMLTreeBuilder.  New code
# should use that version instead.
#
# @see elementtree.ElementTree


class TreeBuilder(ElementTree.XMLTreeBuilder):
    pass

##
# (experimental) An alternate builder that supports manipulation of
# new elements.


class FancyTreeBuilder(TreeBuilder):

    def __init__(self, html=0):
        TreeBuilder.__init__(self, html)
        self._parser.StartNamespaceDeclHandler = self._start_ns
        self._parser.EndNamespaceDeclHandler = self._end_ns
        self.namespaces = []

    def _start(self, tag, attrib_in):
        elem = TreeBuilder._start(self, tag, attrib_in)
        self.start(elem)

    def _start_list(self, tag, attrib_in):
        elem = TreeBuilder._start_list(self, tag, attrib_in)
        self.start(elem)

    def _end(self, tag):
        elem = TreeBuilder._end(self, tag)
        self.end(elem)

    def _start_ns(self, prefix, value):
        self.namespaces.insert(0, (prefix, value))

    def _end_ns(self, prefix):
        assert self.namespaces.pop(0)[0] == prefix, "implementation confused"

    ##
    # Hook method that's called when a new element has been opened.
    # May access the <b>namespaces</b> attribute.
    #
    # @param element The new element.  The tag name and attributes are,
    #     set, but it has no children, and the text and tail attributes
    #     are still empty.

    def start(self, element):
        pass

    ##
    # Hook method that's called when a new element has been closed.
    # May access the <b>namespaces</b> attribute.
    #
    # @param element The new element.

    def end(self, element):
        pass

########NEW FILE########
__FILENAME__ = HTMLTreeParser
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****


# import htmlentitydefs
import re
import string
import sys
import mimetools
import StringIO
from elementtree import ElementTree


class recollector:
    def __init__(self):
        self.res = {}
        self.regs = {}

    def add(self, name, reg, mods=None):
        self.regs[name] = reg % self.regs
        # print "%s = %s" % (name, self.regs[name])
        if mods:
            self.res[name] = re.compile(self.regs[
                                        name], mods)  # check that it is valid
        else:
            self.res[name] = re.compile(self.regs[
                                        name])  # check that it is valid

collector = recollector()
a = collector.add

a("TextSE", "[^<]+")
a("UntilHyphen", "[^-]*-")
a("Until2Hyphens", "%(UntilHyphen)s(?:[^-]%(UntilHyphen)s)*-")
a("CommentCE", "%(Until2Hyphens)s>?")
a("UntilRSBs", "[^\\]]*](?:[^\\]]+])*]+")
a("CDATA_CE", "%(UntilRSBs)s(?:[^\\]>]%(UntilRSBs)s)*>")
a("S", "[ \\n\\t\\r]+")
a("NameStrt", "[A-Za-z_:]|[^\\x00-\\x7F]")
a("NameChar", "[A-Za-z0-9_:.-]|[^\\x00-\\x7F]")
a("Name", "(?:%(NameStrt)s)(?:%(NameChar)s)*")
a("QuoteSE", "\"[^\"]*\"|'[^']*'")
a("DT_IdentSE", "%(S)s%(Name)s(?:%(S)s(?:%(Name)s|%(QuoteSE)s))*")

# http://bugs.activestate.com/show_bug.cgi?id=28765
# a("MarkupDeclCE" , "(?:[^\\]\"'><]+|%(QuoteSE)s)*>" )
a("MarkupDeclCE", "(?:[^\\]\"'> \\n\\t\\r<]+|%(QuoteSE)s)*>")

a("S1", "[\\n\\r\\t ]")
a("UntilQMs", "[^?]*\\?+")
a("PI_Tail", "\\?>|%(S1)s%(UntilQMs)s(?:[^>?]%(UntilQMs)s)*>")
a("DT_ItemSE",
    "<(?:!(?:--%(Until2Hyphens)s>|[^-]%(MarkupDeclCE)s)|\\?%(Name)s(?:%(PI_Tail)s))|%%%(Name)s;|%(S)s"
  )
a("DocTypeCE",
  "%(DT_IdentSE)s(?:%(S)s)?(?:\\[(?:%(DT_ItemSE)s)*](?:%(S)s)?)?>?")
a("DeclCE",
    "--(?:%(CommentCE)s)?|\\[CDATA\\[(?:%(CDATA_CE)s)?|DOCTYPE(?:%(DocTypeCE)s)?")
a("PI_CE", "%(Name)s(?:%(PI_Tail)s)?")
a("EndTagCE", "(?P<endtag>%(Name)s)(?:%(S)s)?>?")
a("AttValSE", "\"[^<\"]*\"|'[^<']*'")
a("ElemTagCE",
    "(?P<tag>%(Name)s)(?P<attrs>(?:%(S)s%(Name)s(?:%(S)s)?=(?:%(S)s)?(?:%(AttValSE)s))*)(?:%(S)s)?/?>?")

a("MarkupSPE",
    "<(?:!(?:%(DeclCE)s)?|\\?(?:%(PI_CE)s)?|/(?:%(EndTagCE)s)?|(?:%(ElemTagCE)s)?)")
a("XML_SPE", "%(TextSE)s|%(MarkupSPE)s")
a("XML_MARKUP_ONLY_SPE", "%(MarkupSPE)s")

a("DOCTYPE",
  r'<!DOCTYPE\s+(?P<type>\S+)\s+(?P<ident>PUBLIC|SYSTEM)\s+(?P<data1>%(QuoteSE)s)\s*(?P<data2>%(QuoteSE)s)?\s*(?:\[|>)', re.S)

a("attrfinderRE",
  "(?:[\n \t]*)(%(Name)s)(?:%(S)s)?=(?:%(S)s)?(%(AttValSE)s)", re.S | re.U)
attrfinder = collector.res["attrfinderRE"]

is_not_ascii = re.compile(eval(r'u"[\u0080-\uffff]"')).search


def parseiter(data, markuponly=0):
    if markuponly:
        reg = "XML_MARKUP_ONLY_SPE"
    else:
        reg = "XML_SPE"
    regex = collector.res[reg]
    return regex.finditer(data)


def strip_quotes(str):
    if not str:
        return None
    if str[0] in ["'", '"']:
        return str[1:-1]
    return str


# XXX this should realy be done via DTD/Schema, but that would be a major
# pain.  For general purposes, this will work fine and be faster

# these tags are defined to NOT ALLOW end tags at all in html.  They never
# have children and never have end tags
# defined in dtd as ELEMENT NAME - O EMPTY
html_no_close_tags = set([
    "basefont", "br", "area", "link", "img", "param", "hr", "input",
    "col", "frame", "isindex", "base", "meta"
])
# defined in dtd as ELEMENT NAME - O *
html_optional_close_tags = set([
    "p", "dt", "dd", "li", "option", "thead", "tfoot", "colgroup",
    "col", "tr", "th", "td"
])

html_block_tags = set([
    "p", "h1", "h2", "h3", "h4", "h5", "h6", "ul", "ol", "pre", "dl", "div", "noscript",
    "blockquote", "form", "hr", "table", "fieldset", "address"
])

# these are optional end tag and cannot contain other block tags defined above
html_cannot_contain_block_tags = set([
    "p", "dt"
])

html_close_tag_unnecessary = html_no_close_tags.union(html_optional_close_tags)


class HTMLTreeBuilder(ElementTree.TreeBuilder):

    def __init__(self, encoding="iso-8859-1"):
        ElementTree.TreeBuilder.__init__(self)
        self.encoding = encoding
        self.nodes = []
        self.nodemap = {}  # {child_elem: parent_elem, ... }
        self._rootnodes = []
        self.current = None

    def start(self, tag, attrs, loc_start, loc_end):
        if not tag:
            return
        # print loc
        if tag == "meta":
            # look for encoding directives
            http_equiv = content = None
            for k, v in attrs:
                if k == "http-equiv":
                    http_equiv = string.lower(v)
                elif k == "content":
                    content = v
            if http_equiv == "content-type" and content:
                # use mimetools to parse the http header
                header = mimetools.Message(
                    StringIO.StringIO("%s: %s\n\n" % (http_equiv, content))
                )
                encoding = header.getparam("charset")
                if encoding:
                    self.encoding = encoding
        l_tag = tag.lower()
        if self._elem:
            p_tag = self._elem[-1].tag.lower()
            # if the parent and child are the same tag, then close the
            # parent if it uses optional close tags
            if l_tag in html_optional_close_tags and p_tag == l_tag:
                self.end(tag)
            # special case table tags that should be autoclosed only when
            # hitting a new table row
            elif p_tag in ("td", "th") and l_tag == "tr":
                self.end_tag(p_tag)
            # if the parent and child are block tags, close the parent
            elif p_tag in html_cannot_contain_block_tags and l_tag in html_block_tags:
                self.end_tag(p_tag)
        attrib = {}
        for attr in attrs:
            attrib[attr[0]] = strip_quotes(attr[1])
        ElementTree.TreeBuilder.start(self, tag, attrib)
        el = self._elem[-1]
        self.current = el
        el.ns = None
        el.localName = el.tag
        el.start = loc_start
        el.end = None
        self.nodes.append(el)
        if len(self._elem) > 1:
            self.nodemap[el] = self._elem[-2]
        else:
            self.nodemap[el] = None
        if l_tag in html_no_close_tags:
            self.end_tag(tag, loc_end)

    def end(self, tag, loc=None):
        if not self._elem:
            return None
        l_tag = tag
        l_lasttag = lasttag = self._elem[-1].tag
        if l_tag:
            l_tag = l_tag.lower()
        if l_lasttag:
            l_lasttag = lasttag.lower()
        while (l_tag != l_lasttag
               and l_lasttag in html_optional_close_tags
               and len(self._elem) > 1
               and self._last.start[2] < self._elem[-1].start[2]):
            self.end_tag(lasttag)
            if self._elem:
                lasttag = self._elem[-1].tag
                l_lasttag = lasttag.lower()
            else:
                self.current = self._last
                return self._last

        # protect against a previous close of this tag
        if l_tag in html_close_tag_unnecessary and l_tag != self._elem[-1].tag.lower():
            return None
        return self.end_tag(tag, loc)

    def end_tag(self, tag, loc=None):
        if not tag:
            return None
        self._flush()
        # find this tag:
        tags = [e.localName for e in self._elem]
        if tag not in tags:
            # invalid end tag?
            return None
        last = self._elem.pop()
        while last.tag != tag:
            last = self._elem.pop()
        self._last = last
        if not self._elem:
            self._rootnodes.append(self._last)
        if loc:
            self._last.end = loc

        self._tail = 1
        self.current = self._last
        return self._last

    def data(self, data):
        if isinstance(data, type('')) and is_not_ascii(data):
            # convert to unicode, but only if necessary
            data = unicode(data, self.encoding, "ignore")
        ElementTree.TreeBuilder.data(self, data)

    def close(self):
        if self._elem:
            return self._elem[0]
        return self._last


class Parser:
    def __init__(self, builder=None):
        if not builder:
            builder = ElementTree.TreeBuilder()
        self._builder = builder
        self.doctype = None
        self.publicId = None
        self.systemId = None
        self.locator = {}
        self._lastloc = None
        self.data = None

    def parse_doctype(self, data):
        m = collector.res["DOCTYPE"].match(data)
        if m is None:
            return
        result = m.groupdict()
        self.doctype = result
        self.publicId = None
        if result['ident'] == "PUBLIC":
            self.publicId = strip_quotes(result['data1'])
            self.systemId = strip_quotes(result['data2'])
        else:
            self.systemId = strip_quotes(result['data1'])

    def getLocation(self, loc):
        pos = 0
        last_lines = 0
        if self._lastloc:
            pos = self._lastloc
            last_lines = self.locator[pos][0]
        lines = last_lines + self.data.count("\n", pos, loc)
        col = 0
        if lines > last_lines:
            col = loc - self.data.rfind("\n", pos, loc) - 1
        elif pos in self.locator:
            col = loc - pos + self.locator[pos][1]
        self.locator[loc] = [lines, col]
        self._lastloc = loc
        return (lines + 1, col, loc)

    def feed(self, data, markuponly=0):
        no_close_tag = []
        opt_close_tag = []
        self.data = data
        for matchObj in parseiter(data, markuponly):
            x = matchObj.group(0)
            m = matchObj.groupdict()
            if x.startswith("<!"):
                continue
            # XXX
                if x.startswith("<!DOCTYPE"):
                    self.parse_doctype(x)
            elif x.startswith("<?"):
                # processing tag
                continue
            elif x.startswith("</"):
                self._builder.end(m[
                                  "endtag"], self.getLocation(matchObj.end(0)))
            elif x.startswith("<"):
                # get the tag and attrs
                attrs = []
                if "attrs" in m and m["attrs"] is not None:
                    attrs = attrfinder.findall(m["attrs"])
                start = self.getLocation(matchObj.start(0))
                end = self.getLocation(matchObj.end(0))
                self._builder.start(m["tag"], attrs, start, end)
                if x.endswith("/>"):
                    self._builder.end(m["tag"], end)
            else:
                self._builder.data(x)

    def close(self):
        return self._builder.close()

try:
    import sgmlop
    ReParser = Parser

    class SgmlopParser(ReParser):
        def __init__(self, builder=None):
            ReParser.__init__(self, builder)
            self.__parser = sgmlop.XMLParser()
            self.__parser.register(self)

        def finish_starttag(self, tag, attrib, loc_start, loc_end):
            # builder expects a list of tuples
            attrs = list(attrib.items())
            self._builder.start(tag, attrs, self.getLocation(
                loc_start), self.getLocation(loc_end))

        def finish_endtag(self, tag, loc):
            self._builder.end(tag, self.getLocation(loc))

        def handle_data(self, data):
            self._builder.data(data)

        def handle_special(self, data, token_type=None):
            # here's where we figure out if we've got a doctype
            if (token_type == 0x105 or  # from sgmlop.c
                    data and data.startswith("DOCTYPE")):
                # we get everything inside <!...>
                self.parse_doctype("<!%s>" % data)

        def feed(self, data, markuponly=0):
            self.data = data
            return self.__parser.feed(data)

        def close(self):
            if self.__parser:
                self.__parser.close()
                self.__parser = None
            return ReParser.close(self)

    Parser = SgmlopParser
except:
    pass


def HTML(data, ParserClass=Parser):
    p = ParserClass(HTMLTreeBuilder())
    p.feed(data)
    return p.close()

if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        import time
        # read the file and parse it to get a time.
        f = open(sys.argv[1])
        data = f.read()
        f.close()
        t1 = time.time()
        tree = HTML(data, ReParser)
        t2 = time.time()
        print "RE parsing took %s" % (t2-t1)
        t1 = time.time()
        tree = HTML(data, SgmlopParser)
        t2 = time.time()
        print "sgmlop parsing took %s" % (t2-t1)
        sys.exit(0)

    data = """<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head> <title>my title</title> </head>
<body>
    <p>blah blah...
    <img src="somefile.jpg" alt="blah">
    </img>
    </p>
</body>
</html>"""
    tree = HTML(data)
    print ElementTree.tostring(tree)
    sys.exit(0)

    data = """<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
"""
    tree = HTML(data)
    print ElementTree.tostring(tree)
    sys.exit(0)

    data = """<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

    <HTML lang="en">
    <BODY>
    <p>
        <img>
        <p>
            <br>
        </p>
        <hr>
        <p>"""
    #        <br>
    #    <dl>
    #        <li>
    #        <li>
    #        <li>
    #    </dl>
    #    <p>
    #    <hr>
    #</p>
    #</BODY>
    #</HTML>
    #"""
    data = """<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
            "http://www.w3.org/TR/html4/strict.dtd">
<!-- Copyright (c) 2000-2006 ActiveState Software Inc. -->
<!-- See the file LICENSE.txt for licensing information. -->


<html>
<head>
<link rel="stylesheet" type="text/css" href="aspn.css">
<script language="JavaScript" src="displayToc.js"></script>
<script language="JavaScript" src="tocParas.js"></script>
<script language="JavaScript" src="tocTab.js"></script>
<link rel="icon" href="favicon.ico" type="image/x-icon"/>
<link rel="shortcut icon" href="favicon.ico" type="image/x-icon"/>
<title>XML Catalogs</title>
</head>

<body>

<table>
<tr>
<td>



<h1><a name="xml_catalogs_top">XML Catalogs</a></h1>

<p>Komodo can add <a href=komodo-doc-editor.html#XML_AutoComplete">XML
autocompletion</a> support for any XML dialect with a DTD or RelaxNG Schema.
This is done by mapping external identifier entries to local copies of the DTD
or RelaxNG Schema for that document type using <a target="_blank"
href="http://www.oasis-open.org/committees/entity/spec.html">XML
Catalogs</a>.</p>

<p><script>writelinks('xml_catalogs_top');</script>&nbsp;</p>

<h2><a name="using_xml_catalogs">Using an Existing XML Catalog</a></h2>

<p>Some toolkits bundle DTDs or RelaxNG Schemas with their own XML
catalogs. As long as the relative path from the catalog to the .dtd or
.rng file is preserved on the local filesystem, you can add support for
the dialect by specifying the catalog file in Preferences under <a
href="komodo-doc-prefs.html#xml_catalogs">SGML/XML Catalogs</a>.</p>

<p><script>writelinks('using_xml_catalogs');</script>&nbsp;</p>

<h2><a name="creating_xml_catalogs">Creating an XML Catalog</a></h2>

<p>If the DTD or RelaxNG Schema for the dialect does not have a catalog
file, you can create one by mapping the external identifiers and URI
references in the document's namespace declaration to a local filesystem
URI. For example, the <a target="_blank"
href="http://www.xspf.org/specs/">
<acronym title="XML Shareable Playlist Format">XSPF</acronym></a>
playlist format uses the following namespace declaration:</p>

<pre>
  &lt;playlist version="1" xmlns="http://xspf.org/ns/0/"&gt;
</pre>

<p>A simple catalog for this XML dialect would look like this:</p>

<pre>
  &lt;?xml version='1.0'?&gt;
  &lt;catalog xmlns="urn:oasis:names:tc:entity:xmlns:xml:catalog"
  prefer="public"&gt;

    &lt;uri name="http://xspf.org/ns/0/" uri="xspf-draft8.rng"/&gt;

  &lt;/catalog&gt;
</pre>

<p>If your documents use the DOCTYPE declaration, you can add support
for that in the catalog by using the public and system identifier. For
example, <a target="_blank" href="http://www.mozilla.org/projects/xul/">
<acronym title="XML User Interface Language">XUL</acronym></a> uses
DOCTYPE declarations like this one:</p>

<pre>
  &lt;!DOCTYPE overlay PUBLIC "-//MOZILLA//DTD XUL V1.0//EN"
  "http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul"&gt;
</pre>

<p>Komodo's catalog for XUL uses <code>publicId</code> and
<code>systemId</code> in addition to <code>uri</code> for the
mapping.</p>

<pre>
  &lt;?xml version='1.0'?&gt;
  &lt;catalog xmlns="urn:oasis:names:tc:entity:xmlns:xml:catalog" prefer="public"&gt;

      &lt;public publicId="-//MOZILLA//DTD XUL V1.0//EN"
              uri="xul.dtd"/&gt;
      &lt;system systemId="http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul"
              uri="xul.dtd"/&gt;
      &lt;uri name="http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul"
           uri="xul.dtd"/&gt;

  &lt;/catalog&gt;
</pre>

<p><script>writelinks('creating_xml_catalogs');</script>&nbsp;</p>

<h2><a name="xml_catalog_resources">XML Catalog Resources</a></h2>

<p>The XML Catalog specification can be found at:</p>

<ul>
  <li><a target="_blank"
  href="http://www.oasis-open.org/committees/entity/spec.html">
  http://www.oasis-open.org/committees/entity/spec.html</a></li>
</ul>

<p>Examples of XML catalog files can be found in the Komodo installation
under:</p>

<ul>
  <li><em>&lt;komodo-install-directory&gt;\lib\support\catalogs</em>
  (Windows)</li>
  <li><em>/Applications/Komodo.app/Contents/SharedSupport/catalogs/ (OS
  X)</em></li>
  <li><em>&lt;komodo-install-directory&gt;/lib/support/catalogs</em>
  (Linux)</li>
</ul>

<p><script>writelinks('xml_catalog_resources');</script>&nbsp;</p>

<!-- Footer Start -->
<hr>

</td>
</tr>
</table>

</body>
</html>

"""
    tree = HTML(data)
    # print ElementTree.tostring(tree)

    data = """<html>
<HEAD>
<?php print $javascript->link('calendar') ?>

    <?php $othAuth->init($othAuth->data);?>
<!--[if lte IE 6]-->
    <?php echo $html->css{'hack'};?>
        <!--[endif]-->
<script type="text/javascript">
function fadeTableRow(rowid, opts) {
    if (!spts) {
        opts = {};
    }
}
</script>
</head>
<body>"""
    tree = HTML(data)
    # print ElementTree.tostring(tree)

    data = """<%= error_messages_for 'product' %>

<!--[form:product]-->
<p><label for="product_title">Title</label><br/>
<%= text_field 'product', 'title'  %></p>

<p><label for="product_description">Description</label><br/>
<%= text_area 'product', 'description'  %></p>

<p><label for="product_image_url">Image url</label><br/>
<%= text_field 'product', 'image_url'  %></p>

<p><label for="product_price">Price</label><br/>
<%= text_field 'product', 'price'  %></p>

<p><label for="product_date_available">Date available</label><br/>
<%= datetime_select 'product', 'date_available'  %></p>
<!--[eoform:product]-->

"""
    tree = HTML(data)
    print ElementTree.tostring(tree)
    p = Parser(HTMLTreeBuilder())
    p.feed(data)
    p.close()

########NEW FILE########
__FILENAME__ = Inflector
#!/usr/bin/env python

# Copyright (c) 2006 Bermi Ferrer Martinez
# info at bermi dot org
# See the end of this file for the free software, open source license
# (BSD-style).

import re
from Rules.English import English
from Rules.Spanish import Spanish


class Inflector:
    """
    Inflector for pluralize and singularize nouns.

    It also provides method for helping to create programs
    based on naming conventions like on Ruby on Rails.
    """

    def __init__(self, Inflector=English):
        assert callable(Inflector), "Inflector should be a callable obj"
        self.Inflector = apply(Inflector)

    def pluralize(self, word):
        '''Pluralizes nouns.'''
        return self.Inflector.pluralize(word)

    def singularize(self, word):
        '''Singularizes nouns.'''
        return self.Inflector.singularize(word)

    def conditionalPlural(self, numer_of_records, word):
        '''Returns the plural form of a word if first parameter is greater than 1'''
        return self.Inflector.conditionalPlural(numer_of_records, word)

    def titleize(self, word, uppercase=''):
        '''Converts an underscored or CamelCase word into a sentence.
            The titleize function converts text like "WelcomePage",
            "welcome_page" or  "welcome page" to this "Welcome Page".
            If the "uppercase" parameter is set to 'first' it will only
            capitalize the first character of the title.'''
        return self.Inflector.titleize(word, uppercase)

    def camelize(self, word):
        ''' Returns given word as CamelCased
        Converts a word like "send_email" to "SendEmail". It
        will remove non alphanumeric character from the word, so
        "who's online" will be converted to "WhoSOnline"'''
        return self.Inflector.camelize(word)

    def underscore(self, word):
        ''' Converts a word "into_it_s_underscored_version"
        Convert any "CamelCased" or "ordinary Word" into an
        "underscored_word".
        This can be really useful for creating friendly URLs.'''
        return self.Inflector.underscore(word)

    def humanize(self, word, uppercase=''):
        '''Returns a human-readable string from word
        Returns a human-readable string from word, by replacing
        underscores with a space, and by upper-casing the initial
        character by default.
        If you need to uppercase all the words you just have to
        pass 'all' as a second parameter.'''
        return self.Inflector.humanize(word, uppercase)

    def variablize(self, word):
        '''Same as camelize but first char is lowercased
        Converts a word like "send_email" to "sendEmail". It
        will remove non alphanumeric character from the word, so
        "who's online" will be converted to "whoSOnline"'''
        return self.Inflector.variablize(word)

    def tableize(self, class_name):
        ''' Converts a class name to its table name according to rails
        naming conventions. Example. Converts "Person" to "people" '''
        return self.Inflector.tableize(class_name)

    def classify(self, table_name):
        '''Converts a table name to its class name according to rails
        naming conventions. Example: Converts "people" to "Person" '''
        return self.Inflector.classify(table_name)

    def ordinalize(self, number):
        '''Converts number to its ordinal form.
        This method converts 13 to 13th, 2 to 2nd ...'''
        return self.Inflector.ordinalize(number)

    def unaccent(self, text):
        '''Transforms a string to its unaccented version.
        This might be useful for generating "friendly" URLs'''
        return self.Inflector.unaccent(text)

    def urlize(self, text):
        '''Transform a string its unaccented and underscored
        version ready to be inserted in friendly URLs'''
        return self.Inflector.urlize(text)

    def demodulize(self, module_name):
        return self.Inflector.demodulize(module_name)

    def modulize(self, module_description):
        return self.Inflector.modulize(module_description)

    def foreignKey(self, class_name, separate_class_name_and_id_with_underscore=1):
        ''' Returns class_name in underscored form, with "_id" tacked on at the end.
        This is for use in dealing with the database.'''
        return self.Inflector.foreignKey(class_name, separate_class_name_and_id_with_underscore)




# Copyright (c) 2006 Bermi Ferrer Martinez
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software to deal in this software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of this software, and to permit
# persons to whom this software is furnished to do so, subject to the following
# condition:
#
# THIS SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THIS SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THIS SOFTWARE.

########NEW FILE########
__FILENAME__ = Base
#!/usr/bin/env python

# Copyright (c) 2006 Bermi Ferrer Martinez
# info at bermi dot org
# See the end of this file for the free software, open source license
# (BSD-style).

import re


class Base:
    '''Locale inflectors must inherit from this base class inorder to provide
    the basic Inflector functionality'''

    def conditionalPlural(self, numer_of_records, word):
        '''Returns the plural form of a word if first parameter is greater than 1'''

        if numer_of_records > 1:
            return self.pluralize(word)
        else:
            return word

    def titleize(self, word, uppercase=''):
        '''Converts an underscored or CamelCase word into a English sentence.
            The titleize function converts text like "WelcomePage",
            "welcome_page" or  "welcome page" to this "Welcome Page".
            If second parameter is set to 'first' it will only
            capitalize the first character of the title.'''

        if(uppercase == 'first'):
            return self.humanize(self.underscore(word)).capitalize()
        else:
            return self.humanize(self.underscore(word)).title()

    def camelize(self, word):
        ''' Returns given word as CamelCased
        Converts a word like "send_email" to "SendEmail". It
        will remove non alphanumeric character from the word, so
        "who's online" will be converted to "WhoSOnline"'''
        return ''.join(w[0].upper() + w[1:] for w in re.sub('[^A-Z^a-z^0-9^:]+', ' ', word).split(' '))

    def underscore(self, word):
        ''' Converts a word "into_it_s_underscored_version"
        Convert any "CamelCased" or "ordinary Word" into an
        "underscored_word".
        This can be really useful for creating friendly URLs.'''

        return re.sub('[^A-Z^a-z^0-9^\/]+', '_',
                      re.sub('([a-z\d])([A-Z])', '\\1_\\2',
                             re.sub('([A-Z]+)([A-Z][a-z])', '\\1_\\2', re.sub('::', '/', word)))).lower()

    def humanize(self, word, uppercase=''):
        '''Returns a human-readable string from word
        Returns a human-readable string from word, by replacing
        underscores with a space, and by upper-casing the initial
        character by default.
        If you need to uppercase all the words you just have to
        pass 'all' as a second parameter.'''

        if(uppercase == 'first'):
            return re.sub('_id$', '', word).replace('_', ' ').capitalize()
        else:
            return re.sub('_id$', '', word).replace('_', ' ').title()

    def variablize(self, word):
        '''Same as camelize but first char is lowercased
        Converts a word like "send_email" to "sendEmail". It
        will remove non alphanumeric character from the word, so
        "who's online" will be converted to "whoSOnline"'''
        word = self.camelize(word)
        return word[0].lower()+word[1:]

    def tableize(self, class_name):
        ''' Converts a class name to its table name according to rails
        naming conventions. Example. Converts "Person" to "people" '''
        return self.pluralize(self.underscore(class_name))

    def classify(self, table_name):
        '''Converts a table name to its class name according to rails
        naming conventions. Example: Converts "people" to "Person" '''
        return self.camelize(self.singularize(table_name))

    def ordinalize(self, number):
        '''Converts number to its ordinal English form.
        This method converts 13 to 13th, 2 to 2nd ...'''
        tail = 'th'
        if number % 100 == 11 or number % 100 == 12 or number % 100 == 13:
            tail = 'th'
        elif number % 10 == 1:
            tail = 'st'
        elif number % 10 == 2:
            tail = 'nd'
        elif number % 10 == 3:
            tail = 'rd'

        return str(number)+tail

    def unaccent(self, text):
        '''Transforms a string to its unaccented version.
        This might be useful for generating "friendly" URLs'''
        find = u'\u00C0\u00C1\u00C2\u00C3\u00C4\u00C5\u00C6\u00C7\u00C8\u00C9\u00CA\u00CB\u00CC\u00CD\u00CE\u00CF\u00D0\u00D1\u00D2\u00D3\u00D4\u00D5\u00D6\u00D8\u00D9\u00DA\u00DB\u00DC\u00DD\u00DE\u00DF\u00E0\u00E1\u00E2\u00E3\u00E4\u00E5\u00E6\u00E7\u00E8\u00E9\u00EA\u00EB\u00EC\u00ED\u00EE\u00EF\u00F0\u00F1\u00F2\u00F3\u00F4\u00F5\u00F6\u00F8\u00F9\u00FA\u00FB\u00FC\u00FD\u00FE\u00FF'
        replace = u'AAAAAAACEEEEIIIIDNOOOOOOUUUUYTsaaaaaaaceeeeiiiienoooooouuuuyty'
        return self.string_replace(text, find, replace)

    def string_replace(self, word, find, replace):
        '''This function returns a copy of word, translating
        all occurrences of each character in find to the
        corresponding character in replace'''
        for k in range(0, len(find)):
            word = re.sub(find[k], replace[k], word)

        return word

    def urlize(self, text):
        '''Transform a string its unaccented and underscored
        version ready to be inserted in friendly URLs'''
        return re.sub('^_|_$', '', self.underscore(self.unaccent(text)))

    def demodulize(self, module_name):
        return self.humanize(self.underscore(re.sub('^.*::', '', module_name)))

    def modulize(self, module_description):
        return self.camelize(self.singularize(module_description))

    def foreignKey(self, class_name, separate_class_name_and_id_with_underscore=1):
        ''' Returns class_name in underscored form, with "_id" tacked on at the end.
        This is for use in dealing with the database.'''
        if separate_class_name_and_id_with_underscore:
            tail = '_id'
        else:
            tail = 'id'
        return self.underscore(self.demodulize(class_name))+tail



# Copyright (c) 2006 Bermi Ferrer Martinez
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software to deal in this software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of this software, and to permit
# persons to whom this software is furnished to do so, subject to the following
# condition:
#
# THIS SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THIS SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THIS SOFTWARE.

########NEW FILE########
__FILENAME__ = English
#!/usr/bin/env python

# Copyright (c) 2006 Bermi Ferrer Martinez
# info at bermi dot org
# See the end of this file for the free software, open source license
# (BSD-style).

import re
from Base import Base


class English (Base):
    """
    Inflector for pluralize and singularize English nouns.

    This is the default Inflector for the Inflector obj
    """

    def pluralize(self, word):
        '''Pluralizes English nouns.'''

        rules = [
            ['(?i)(quiz)$', '\\1zes'],
            ['^(?i)(ox)$', '\\1en'],
            ['(?i)([m|l])ouse$', '\\1ice'],
            ['(?i)(matr|vert|ind)ix|ex$', '\\1ices'],
            ['(?i)(x|ch|ss|sh)$', '\\1es'],
            ['(?i)([^aeiouy]|qu)ies$', '\\1y'],
            ['(?i)([^aeiouy]|qu)y$', '\\1ies'],
            ['(?i)(hive)$', '\\1s'],
            ['(?i)(?:([^f])fe|([lr])f)$', '\\1\\2ves'],
            ['(?i)sis$', 'ses'],
            ['(?i)([ti])um$', '\\1a'],
            ['(?i)(buffal|tomat)o$', '\\1oes'],
            ['(?i)(bu)s$', '\\1ses'],
            ['(?i)(alias|status)', '\\1es'],
            ['(?i)(octop|vir)us$', '\\1i'],
            ['(?i)(ax|test)is$', '\\1es'],
            ['(?i)s$', 's'],
            ['(?i)$', 's']
        ]

        uncountable_words = [
            'equipment', 'information', 'rice', 'money', 'species', 'series', 'fish', 'sheep']

        irregular_words = {
            'person': 'people',
            'man': 'men',
            'child': 'children',
            'sex': 'sexes',
            'move': 'moves'
        }

        lower_cased_word = word.lower()

        for uncountable_word in uncountable_words:
            if lower_cased_word[-1*len(uncountable_word):] == uncountable_word:
                return word

        for irregular in irregular_words.keys():
            match = re.search('('+irregular+')$', word, re.IGNORECASE)
            if match:
                return re.sub('(?i)'+irregular+'$', match.expand('\\1')[0]+irregular_words[irregular][1:], word)

        for rule in range(len(rules)):
            match = re.search(rules[rule][0], word, re.IGNORECASE)
            if match:
                groups = match.groups()
                for k in range(0, len(groups)):
                    if groups[k] == None:
                        rules[rule][1] = rules[rule][
                            1].replace('\\'+str(k+1), '')

                return re.sub(rules[rule][0], rules[rule][1], word)

        return word

    def singularize(self, word):
        '''Singularizes English nouns.'''

        rules = [
            ['(?i)(quiz)zes$', '\\1'],
            ['(?i)(matr)ices$', '\\1ix'],
            ['(?i)(vert|ind)ices$', '\\1ex'],
            ['(?i)^(ox)en', '\\1'],
            ['(?i)(alias|status)es$', '\\1'],
            ['(?i)([octop|vir])i$', '\\1us'],
            ['(?i)(cris|ax|test)es$', '\\1is'],
            ['(?i)(shoe)s$', '\\1'],
            ['(?i)(o)es$', '\\1'],
            ['(?i)(bus)es$', '\\1'],
            ['(?i)([m|l])ice$', '\\1ouse'],
            ['(?i)(x|ch|ss|sh)es$', '\\1'],
            ['(?i)(m)ovies$', '\\1ovie'],
            ['(?i)(s)eries$', '\\1eries'],
            ['(?i)([^aeiouy]|qu)ies$', '\\1y'],
            ['(?i)([lr])ves$', '\\1f'],
            ['(?i)(tive)s$', '\\1'],
            ['(?i)(hive)s$', '\\1'],
            ['(?i)([^f])ves$', '\\1fe'],
            ['(?i)(^analy)ses$', '\\1sis'],
            ['(?i)((a)naly|(b)a|(d)iagno|(p)arenthe|(p)rogno|(s)ynop|(t)he)ses$',
                '\\1\\2sis'],
            ['(?i)([ti])a$', '\\1um'],
            ['(?i)(n)ews$', '\\1ews'],
            ['(?i)s$', ''],
        ]

        uncountable_words = ['equipment', 'information', 'rice',
                             'money', 'species', 'series', 'fish', 'sheep', 'sms']

        irregular_words = {
            'people': 'person',
            'men': 'man',
            'children': 'child',
            'sexes': 'sex',
            'moves': 'move'
        }

        lower_cased_word = word.lower()

        for uncountable_word in uncountable_words:
            if lower_cased_word[-1*len(uncountable_word):] == uncountable_word:
                return word

        for irregular in irregular_words.keys():
            match = re.search('('+irregular+')$', word, re.IGNORECASE)
            if match:
                return re.sub('(?i)'+irregular+'$', match.expand('\\1')[0]+irregular_words[irregular][1:], word)

        for rule in range(len(rules)):
            match = re.search(rules[rule][0], word, re.IGNORECASE)
            if match:
                groups = match.groups()
                for k in range(0, len(groups)):
                    if groups[k] == None:
                        rules[rule][1] = rules[rule][
                            1].replace('\\'+str(k+1), '')

                return re.sub(rules[rule][0], rules[rule][1], word)

        return word



# Copyright (c) 2006 Bermi Ferrer Martinez
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software to deal in this software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of this software, and to permit
# persons to whom this software is furnished to do so, subject to the following
# condition:
#
# THIS SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THIS SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THIS SOFTWARE.

########NEW FILE########
__FILENAME__ = Spanish
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright (c) 2006 Bermi Ferrer Martinez
# info at bermi dot org
# See the end of this file for the free software, open source license
# (BSD-style).

import re
from Base import Base


class Spanish (Base):
    """
    Inflector for pluralize and singularize Spanish nouns.
    """

    def pluralize(self, word):
        """Pluralizes Spanish nouns."""
        rules = [
            [u"(?i)([aeiou])x$", u"\\1x"],
            # This could fail if the word is oxytone.
            [u"(?i)([áéíóú])([ns])$", u"|1\\2es"],
            [u"(?i)(^[bcdfghjklmnñpqrstvwxyz]*)an$",
                u"\\1anes"],  # clan->clanes
            [u"(?i)([áéíóú])s$", u"|1ses"],
            [u"(?i)(^[bcdfghjklmnñpqrstvwxyz]*)([aeiou])([ns])$",
                u"\\1\\2\\3es"],  # tren->trenes
            [u"(?i)([aeiouáéó])$", u"\\1s"],
            # casa->casas, padre->padres, papá->papás
            [u"(?i)([aeiou])s$", u"\\1s"],  # atlas->atlas, virus->virus, etc.
            [u"(?i)([éí])(s)$", u"|1\\2es"],  # inglés->ingleses
            [u"(?i)z$", u"ces"],  # luz->luces
            [u"(?i)([íú])$", u"\\1es"],  # ceutí->ceutíes, tabú->tabúes
            [u"(?i)(ng|[wckgtp])$", u"\\1s"],
            # Anglicismos como puenting, frac, crack, show (En que casos
            # podría fallar esto?)
            [u"(?i)$", u"es"]   # ELSE +es (v.g. árbol->árboles)
        ]

        uncountable_words = [
            u"tijeras", u"gafas", u"vacaciones", u"víveres", u"déficit"]
        """ In fact these words have no singular form: you cannot say neither
        "una gafa" nor "un vívere". So we should change the variable name to
        onlyplural or something alike."""

        irregular_words = {
            u"país": u"países",
            u"champú": u"champús",
            u"jersey": u"jerséis",
            u"carácter": u"caracteres",
            u"espécimen": u"especímenes",
            u"menú": u"menús",
            u"régimen": u"regímenes",
            u"curriculum": u"currículos",
            u"ultimátum": u"ultimatos",
            u"memorándum": u"memorandos",
            u"referéndum": u"referendos"
        }

        lower_cased_word = word.lower()

        for uncountable_word in uncountable_words:
            if lower_cased_word[-1 * len(uncountable_word):] == uncountable_word:
                return word

        for irregular in irregular_words.keys():
            match = re.search(
                u"(?i)(u" + irregular + u")$", word, re.IGNORECASE)
            if match:
                return re.sub(u"(?i)" + irregular + u"$", match.expand(u"\\1")[0] + irregular_words[irregular][1:], word)

        for rule in range(len(rules)):
            match = re.search(rules[rule][0], word, re.IGNORECASE)

            if match:
                groups = match.groups()
                replacement = rules[rule][1]
                if re.match(u"\|", replacement):
                    for k in range(1, len(groups)):
                        replacement = replacement.replace(u"|" + str(k), self.string_replace(
                            groups[k - 1], u"ÁÉÍÓÚáéíóú", u"AEIOUaeiou"))

                result = re.sub(rules[rule][0], replacement, word)
                # Esto acentua los sustantivos que al pluralizarse se
                # convierten en esdrújulos como esmóquines, jóvenes...
                match = re.search(u"(?i)([aeiou]).{1,3}([aeiou])nes$", result)

                if match and len(match.groups()) > 1 and not re.search(u"(?i)[áéíóú]", word):
                    result = result.replace(match.group(0), self.string_replace(
                        match.group(1), u"AEIOUaeiou", u"ÁÉÍÓÚáéíóú") + match.group(0)[1:])

                return result

        return word

    def singularize(self, word):
        """Singularizes Spanish nouns."""

        rules = [
            [u"(?i)^([bcdfghjklmnñpqrstvwxyz]*)([aeiou])([ns])es$",
                u"\\1\\2\\3"],
            [u"(?i)([aeiou])([ns])es$",  u"~1\\2"],
            [u"(?i)oides$",  u"oide"],  # androides->androide
            [u"(?i)(ces)$/i", u"z"],
            [u"(?i)(sis|tis|xis)+$",  u"\\1"],  # crisis, apendicitis, praxis
            [u"(?i)(é)s$",  u"\\1"],  # bebés->bebé
            [u"(?i)([^e])s$",  u"\\1"],  # casas->casa
            [u"(?i)([bcdfghjklmnñprstvwxyz]{2,}e)s$", u"\\1"],  # cofres->cofre
            [u"(?i)([ghñpv]e)s$", u"\\1"],  # 24-01 llaves->llave
            [u"(?i)es$", u""]  # ELSE remove _es_  monitores->monitor
        ]

        uncountable_words = [
            u"paraguas", u"tijeras", u"gafas", u"vacaciones", u"víveres", u"lunes",
            u"martes", u"miércoles", u"jueves", u"viernes", u"cumpleaños", u"virus", u"atlas", u"sms"]

        irregular_words = {
            u"jersey": u"jerséis",
            u"espécimen": u"especímenes",
            u"carácter": u"caracteres",
            u"régimen": u"regímenes",
            u"menú": u"menús",
            u"régimen": u"regímenes",
            u"curriculum": u"currículos",
            u"ultimátum": u"ultimatos",
            u"memorándum": u"memorandos",
            u"referéndum": u"referendos",
            u"sándwich": u"sándwiches"
        }

        lower_cased_word = word.lower()

        for uncountable_word in uncountable_words:
            if lower_cased_word[-1 * len(uncountable_word):] == uncountable_word:
                return word

        for irregular in irregular_words.keys():
            match = re.search(u"(u" + irregular + u")$", word, re.IGNORECASE)
            if match:
                return re.sub(u"(?i)" + irregular + u"$", match.expand(u"\\1")[0] + irregular_words[irregular][1:], word)

        for rule in range(len(rules)):
            match = re.search(rules[rule][0], word, re.IGNORECASE)
            if match:
                groups = match.groups()
                replacement = rules[rule][1]
                if re.match(u"~", replacement):
                    for k in range(1, len(groups)):
                        replacement = replacement.replace(u"~" + str(
                            k), self.string_replace(groups[k - 1], u"AEIOUaeiou", u"ÁÉÍÓÚáéíóú"))

                result = re.sub(rules[rule][0], replacement, word)
                # Esta es una posible solución para el problema de dobles
                # acentos. Un poco guarrillo pero funciona
                match = re.search(u"(?i)([áéíóú]).*([áéíóú])", result)

                if match and len(match.groups()) > 1 and not re.search(u"(?i)[áéíóú]", word):
                    result = self.string_replace(
                        result, u"ÁÉÍÓÚáéíóú", u"AEIOUaeiou")

                return result

        return word


# Copyright (c) 2006 Bermi Ferrer Martinez
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software to deal in this software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of this software, and to permit
# persons to whom this software is furnished to do so, subject to the following
# condition:
#
# THIS SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THIS SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THIS SOFTWARE.

########NEW FILE########
__FILENAME__ = tests
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright (c) 2006 Bermi Ferrer Martinez

import unittest
from Inflector import Inflector, English, Spanish


class EnglishInflectorTestCase(unittest.TestCase):
    singular_to_plural = {
        "search": "searches",
        "switch": "switches",
        "fix": "fixes",
        "box": "boxes",
        "process": "processes",
        "address": "addresses",
        "case": "cases",
        "stack": "stacks",
        "wish": "wishes",
        "fish": "fish",

        "category": "categories",
        "query": "queries",
        "ability": "abilities",
        "agency": "agencies",
        "movie": "movies",

        "archive": "archives",

        "index": "indices",

        "wife": "wives",
        "safe": "saves",
        "half": "halves",

        "move": "moves",

        "salesperson": "salespeople",
        "person": "people",

        "spokesman": "spokesmen",
        "man": "men",
        "woman": "women",

        "basis": "bases",
        "diagnosis": "diagnoses",

        "datum": "data",
        "medium": "media",
        "analysis": "analyses",

        "node_child": "node_children",
        "child": "children",

        "experience": "experiences",
        "day": "days",

        "comment": "comments",
        "foobar": "foobars",
        "newsletter": "newsletters",

        "old_news": "old_news",
        "news": "news",

        "series": "series",
        "species": "species",

        "quiz": "quizzes",

        "perspective": "perspectives",

        "ox": "oxen",
        "photo": "photos",
        "buffalo": "buffaloes",
        "tomato": "tomatoes",
        "dwarf": "dwarves",
        "elf": "elves",
        "information": "information",
        "equipment": "equipment",
        "bus": "buses",
        "status": "statuses",
        "mouse": "mice",

        "louse": "lice",
        "house": "houses",
        "octopus": "octopi",
        "virus": "viri",
        "alias": "aliases",
        "portfolio": "portfolios",

        "vertex": "vertices",
        "matrix": "matrices",

        "axis": "axes",
        "testis": "testes",
        "crisis": "crises",

        "rice": "rice",
        "shoe": "shoes",

        "horse": "horses",
        "prize": "prizes",
        "edge": "edges"
    }

    def setUp(self):
        self.inflector = Inflector(English)

    def tearDown(self):
        self.inflector = None

    def test_pluralize(self):
        for singular in self.singular_to_plural.keys():
            assert self.inflector.pluralize(singular) == self.singular_to_plural[singular], \
                'English Inlector pluralize(%s) should produce "%s" and NOT "%s"' % (
                singular, self.singular_to_plural[singular], self.inflector.pluralize(singular))

    def test_singularize(self):
        for singular in self.singular_to_plural.keys():
            assert self.inflector.singularize(self.singular_to_plural[singular]) == singular, \
                'English Inlector singularize(%s) should produce "%s" and NOT "%s"' % (self.singular_to_plural[
                                                                                       singular], singular, self.inflector.singularize(self.singular_to_plural[singular]))


InflectorTestSuite = unittest.TestSuite()
InflectorTestSuite.addTest(EnglishInflectorTestCase("test_pluralize"))
InflectorTestSuite.addTest(EnglishInflectorTestCase("test_singularize"))
runner = unittest.TextTestRunner()
runner.run(InflectorTestSuite)

########NEW FILE########
__FILENAME__ = koCatalog
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

import os
import logging
import re
from koSimpleLexer import *
from koDTD import DTD
from koRNGElementTree import rng

log = logging.getLogger("koCatalog")
# log.setLevel(logging.INFO)

from elementtree import XMLTreeBuilder
try:
    import cElementTree as ElementTree  # effbot's C module
except ImportError:
    log.error(
        "using element tree and not cElementTree, performace will suffer")
    import elementtree.ElementTree as ElementTree  # effbot's pure Python module

"""
NOTES:

SGML Catalog URI's
http://www.jclark.com/sp/catalog.htm
http://www.oasis-open.org/specs/tr9401.html (OFFICIAL SPEC)
http://www.oasis-open.org/committees/entity/spec.html (XML CATALOG)

For SGML Catalogs, we want to look at the env var SGML_CATALOG_FILES (see
jclark.com above)

"""

# regular expressions used for DTD parsing
collector = recollector()
a = collector.add

# regular expressions used for SGML Catalog parsing
a("whitespace",    r"\s+", re.S | re.M)
a("QuotedString",  r'(?:")([^"]*?)(?:")|(?:\')([^\']*?)(?:\')', re.S | re.U)
a("single_types", "(OVERRIDE|SGMLDECL|DOCUMENT|CATALOG|BASE)")
a("single",
  r'(?P<type>%(single_types)s)\s+(?P<data1>%(QuotedString)s|\S+)', re.S)
a("double_types", "(PUBLIC|ENTITY|DOCTYPE|LINKTYPE|NOTATION|SYSTEM|DELEGATE)")
a("double",
  r'(?P<type>%(double_types)s)\s+(?P<data1>%(QuotedString)s|\S+)\s+(?P<data2>%(QuotedString)s|\S+)', re.S)
a("COMMENT",       r"<!--(?P<comment>.*?)-->", re.S | re.M)
a("newlines",                   "[ \t]*(\r\n|\r|\n)")


def _cmpLen(a, b):
    al = len(a)
    bl = len(b)
    if al > bl:
        return -1
    if al == bl:
        return cmp(a, b)
    return 1


def strip_quotes(str):
    if not str:
        return None
    if str[0] in ["'", '"']:
        return str[1:-1]
    return str


# XXX a cheap relativize
urimatch = re.compile("(\w+://.*|/.*|\w:\\.*|\w:/.*)")


def relativize(base, fn):
    if urimatch.match(fn):
        return fn
    return os.path.join(base, fn)


class Delegate:
    def __init__(self, catalog=None, node=None):
        self.catalog = catalog
        self.node = node
        if node and not catalog:
            self.catalog = node.attrib.get('catalog')


class PublicID:
    def __init__(self, id=None, uri=None, node=None):
        self.id = id
        self.uri = uri
        self.node = node


class SystemID:
    def __init__(self, id=None, uri=None, node=None):
        self.id = id
        self.uri = uri
        self.node = node


class URI:
    def __init__(self, name=None, uri=None, node=None):
        self.name = name
        self.uri = uri
        self.node = node


class Catalog:
    # subclass and implement the parser to fill in the necessary
    # data elements
    def __init__(self, uri, resolver=None):
        self.uri = uri
        self.dir = os.path.dirname(uri)

        self.prefer = None

        # XMLCatalog
        self.public = {}
        self.system = {}
        self.rewritesystem = {}
        self.delegatepublic = {}
        self.delegatesystem = {}
        self.urimap = {}
        self.rewriteuri = {}
        self.delegateuri = {}
        self.nextcatalog = []

        # TR-9401 support
        self.doctype = {}
        self.document = {}
        self.dtddecl = {}
        self.entity = {}
        self.linktype = {}
        self.notation = {}
        self.sgmldecl = {}

        self.resolver = resolver
        self.parse()

    # Support functions for matching data to a catalog
    def _longestMatch(self, needle, haystack):
        haystack.sort(_cmpLen)
        for straw in haystack:
            if needle.find(straw) == 0:
                return straw
        return None

    def _getRewrite(self, id, ar):
        possible = self._longestMatch(id, ar.keys())
        if possible:
            return "%s%s" % (ar[possible], id[len(possible):])
        return None

    def _getDelegates(self, id, delegates):
        if id not in delegates:
            return None
        entries = delegates[id].keys().sort(_cmpLen)
        return [delegates[id][d].catalog for d in entries]

    def getSystemRewrite(self, systemId):
        return self._getRewrite(systemId, self.rewritesystem)

    def getURIRewrite(self, uri):
        return self._getRewrite(uri, self.rewriteuri)

    def getSystemDelegates(self, systemId):
        # 7.1.2 #4
        return self._getDelegates(systemId, self.delegatesystem)

    def getPublicDelegates(self, publicId):
        # 7.1.2 #6
        return self._getDelegates(publicId, self.delegatepublic)

    def getURIDelegates(self, uri):
        # 7.1.2 #6
        return self._getDelegates(uri, self.delegateuri)


class NamespaceParser(XMLTreeBuilder.FancyTreeBuilder):
    _qname = re.compile("{(.*?)}(.*)")

    def start(self, element):
        element.namespaces = self.namespaces[:]
        qn = self._qname.match(element.tag)
        element.ns = qn.group(1)
        element.tagName = qn.group(2)


class XMLCatalog(Catalog):
    # http://www.oasis-open.org/committees/entity/spec.html
    def __init__(self, uri, resolver):
        self.parent_map = {}
        Catalog.__init__(self, uri, resolver)

    def parse(self):
        # XXX support HTTP URI's
        self.tree = ElementTree.parse(self.uri, NamespaceParser())
        self.root = self.tree.getroot()
        if self.root.tagName != "catalog":
            raise "Invalid catalog file [%s] root tag [%s]" % (
                self.uri, self.root.tagName)
        self.parent_map = dict((
            c, p) for p in self.tree.getiterator() for c in p)
        self._parseNode(self.root)

    def _parseNode(self, node):
        methodName = "_handle_%s" % node.tagName.lower()
        # print methodName
        if hasattr(self, methodName):
            fn = getattr(self, methodName)
            fn(node)
        for child in list(node):
            # print "parsing child %s"%child.tagName
            self._parseNode(child)
        methodName = "_handle_%s_end" % node.tagName.lower()
        # print methodName
        if hasattr(self, methodName):
            fn = getattr(self, methodName)
            fn(node)

    def _handle_catalog(self, node):
        self.prefer = node.attrib.get("prefer", "public")

    def _get_relative_uri(self, uri, node):
        parent = self.parent_map[node]
        if parent.tagName == "group":
            base = parent.attrib.get(
                "{http://www.w3.org/XML/1998/namespace}base", self.dir)
            if base != self.dir and not os.path.isabs(base):
                base = os.path.normpath(os.path.join(self.dir, base))
        else:
            base = self.dir
        return relativize(base, uri)

    def _handle_public(self, node):
        id = node.attrib.get('publicId')
        uri = self._get_relative_uri(node.attrib.get('uri'), node)
        self.public[id] = PublicID(id, uri, node)

    def _handle_system(self, node):
        id = node.attrib.get('systemId')
        uri = self._get_relative_uri(node.attrib.get('uri'), node)
        self.system[id] = SystemID(id, uri, node)

    def _handle_rewritesystem(self, node):
        self.rewritesystem[node.attrib.get(
            "systemIdStartString")] = node.attrib.get("rewritePrefix")

    def _handle_delegatepublic(self, node):
        startId = node.attrib.get("publicIdStartString")
        if startId not in self.delegatepublic:
            self.delegatepublic[startId] = []
        self.delegatepublic[startId].append(Delegate(node=node))

    def _handle_delegatesystem(self, node):
        startId = node.attrib.get("systemIdStartString")
        if startId not in self.delegatesystem:
            self.delegatesystem[startId] = []
        self.delegatesystem[startId].append(Delegate(node=node))

    def _handle_uri(self, node):
        name = node.attrib.get("name")
        uri = self._get_relative_uri(node.attrib.get('uri'), node)
        self.urimap[name] = URI(name, uri, node)

    def _handle_rewriteuri(self, node):
        self.rewriteuri[node.attrib.get(
            "uriStartString")] = node.attrib.get("rewritePrefix")

    def _handle_delegateuri(self, node):
        startId = node.attrib.get("uriStartString")
        if startId not in self.delegateuri:
            self.delegateuri[startId] = []
        self.delegateuri[startId].append(Delegate(node=node))

    def _handle_nextcatalog(self, node):
        catalogURI = self._get_relative_uri(node.attrib.get('catalog'), node)
        if self.resolver:
            try:
                self.resolver.addCatalogURI(catalogURI)
                self.nextcatalog.append(catalogURI)
            except Exception, e:
                log.error(
                    "Unable to read catalog file [%s] [%s]", catalogURI, e)
                # raise

    # XML Catalog support for http://www.oasis-open.org/specs/tr9401.html
    def _handle_doctype(self, node):
        self.doctype[node.attrib.get("name")] = node

    def _handle_document(self, node):
        self.document[node.attrib.get("uri")] = node

    def _handle_dtddecl(self, node):
        self.dtddecl[node.attrib.get("publicId")] = node

    def _handle_entity(self, node):
        self.entity[node.attrib.get("name")] = node

    def _handle_linktype(self, node):
        self.linktype[node.attrib.get("name")] = node

    def _handle_notation(self, node):
        self.notation[node.attrib.get("name")] = node

    def _handle_sgmldecl(self, node):
        self.sgmldecl[node.attrib.get("uri")] = node


class SGMLCatalog(Catalog):
    def parse(self):
        # setup lexer and add token matching regexes
        self.lex_matches = [
            ('whitespace',      self.doMultiLineBlock,  EXECFN | SKIPTOK),
            ('single',          self._handle_entity,
             EXECFN | SKIPTOK),
            ('double',          self._handle_entity,
             EXECFN | SKIPTOK),
        ]

        self.l = Lexer(self.uri)
        for p in self.lex_matches:
            # log.debug("adding %r",p[0])
            attributes = p[2]
            if not attributes:
                attributes = MAPTOK | EXECFN
            self.l.addmatch(collector.res[p[0]], p[1], p[0], attributes)

        self.lineno = 1
        self.ignore = 0
        self.scanData()

    def scanData(self):
        # XXX FIXME support http(s)
        f = open(self.uri)
        data = f.read()
        f.close

        # XXX
        # because of the many issues around comments in dtd files, and since
        # we're doing a sloppy parse, lets just get rid of all comments now.
        data = collector.res["COMMENT"].sub("", data)
        r = re.compile(r"--+.*?--+", re.S | re.U)
        data = r.sub("", data)

        self.l.settext(data)

        # res = []
        while 1:
            try:
                t, v = self.l.scan()
            except:
                # if self.l.textindex < len(self.l.text):
                #    self.l.textindex += 1
                #    continue
                raise
            log.debug("  lex symbol: %r %r", t, v)
            if t == self.l.eof:
                break
            # res.append((t, v))

    def doMultiLineBlock(self, m):
        # log.debug("block start at lineno %d",self.lineno)
        nl = collector.res["newlines"].findall(m.group(0))
        blockLen = len(nl)
        self.lineno = self.lineno + blockLen
        # log.debug("block had %d lines, lineno is %d", blockLen, self.lineno)
        return ""

    # http://www.oasis-open.org/specs/tr9401.html
    # http://www.jclark.com/sp/catalog.htm
    def _handle_entity(self, m):
        # XXX TODO need to understand teh SGML catalog better, we have
        # enough to handle sgml-lib catalogs for now
        m = m.groupdict()
        data1 = strip_quotes(m['data1'])
        if 'data2' in m:
            data2 = strip_quotes(m['data2'])
        else:
            data2 = ""
        if m['type'] == "PUBLIC":
            filename = relativize(self.dir, data2)
            self.public[data1] = PublicID(data1, filename)
        elif m['type'] == "SYSTEM":
            filename = relativize(self.dir, data2)
            self.system[data1] = SystemID(data1, filename)
        elif m['type'] == "DELEGATE":
            self.delegatepublic[data1] = Delegate(data1, data2)
        elif m['type'] == "CATALOG":
            self.nextcatalog.append(data1)
            if self.resolver:
                try:
                    self.resolver.addCatalogURI(data1)
                except Exception, e:
                    log.error("Unable to read catalog file [%s] [%s]", uri, e)
                    # raise
        elif m['type'] == "BASE":
            self.dir = data1
        return ""


class CatalogResolver:
    _urntrans = {
        '+': ' ', ':': '//', ';': '::', '%2B': '+', '%3A': ':',
        '%2F': '/', '%3B': ';', '%27': "'", '%3F': '?', '%23': '#', '%25': '%'
    }

    def __init__(self, catalogURIs=[]):
        self.init(catalogURIs)

    def init(self, catalogURIs=[]):
        # order of catalog entries is important for resolution rules
        # self.catalogs only contains the top level catalogs, but
        # catalogMap contains ALL catalogs (such as those found in
        # nextCatalog tags)
        self.catalogs = []
        self.catalogMap = {}
        self.datasets = {}  # uri to dataset map
        self.resetCatalogs(catalogURIs)

    def resetCatalogs(self, catalogURIs=[]):
        catalogs = []
        for uri in catalogURIs:
            try:
                if uri not in self.catalogMap:
                    catalog = self.addCatalogURI(uri)
                    if not catalog:
                        continue
                catalogs.append(self.catalogMap[uri])
            except Exception, e:
                log.error("Unable to read catalog file [%s] [%s]", uri, e)
                # raise
        self.catalogs = catalogs

    def addCatalogURI(self, uri):
        if uri in self.catalogMap:
            log.info("Catalog already parsed [%s]", uri)
            return None
        # XXX how do we determin what type of catalog we want to open?
        ext = os.path.splitext(uri)[1]
        if ext == ".xml":
            catalog = XMLCatalog(uri, self)
        else:
            catalog = SGMLCatalog(uri, self)

        self.catalogMap[uri] = catalog
        return catalog

    def unwrapURN(self, urn):
        # http://www.oasis-open.org/committees/entity/spec.html#s.xmlcat
        # 6.4. URN "Unwrapping"
        unwrapped = urn
        # remove prefix
        if unwrapped.find('urn:publicid:') != 0:
            return None
        unwrapped = unwrapped[13:]
        # decode
        for i in range(len(unwrapped)):
            if unwrapped[i] in self._urntrans:
                unwrapped[i] = self._urntrans[unwrapped[i]]
        return unwrapped

    def findExternalIdentifierInCatalog(self, catalog, publicId=None, systemId=None):
        # 7.1.2
        if systemId:
            # 7.1.2 #2
            if systemId in catalog.system:
                if catalog.prefer == 'public' and publicId in catalog.public:
                    return catalog.public[publicId].uri
                return catalog.system[systemId].uri
            # 7.1.2 #3
            rewrite = catalog.getSystemRewrite(systemId)
            if rewrite:
                return rewrite
            # 7.1.2 #4
            delegatecatalogs = catalog.getSystemDelegates(systemId)
            if delegatecatalogs:
                return self.findExternalIdentifier(delegatecatalogs, None, systemId)
        # 7.1.2 #5
        if publicId:
            if publicId in catalog.public:
                return catalog.public[publicId].uri
            # 7.1.2 #6
            delegatecatalogs = catalog.getPublicDelegates(publicId)
            if delegatecatalogs:
                return self.findExternalIdentifier(delegatecatalogs, publicId, None)
        for catalogURI in catalog.nextcatalog:
            ident = self.findExternalIdentifierInCatalog(
                self.catalogMap[catalogURI], publicId, systemId)
            if ident:
                return ident
        return None

    def findExternalIdentifier(self, catalogs, publicId=None, systemId=None):
        # http://www.oasis-open.org/committees/entity/spec.html#s.xmlcat

        # 7.1.1 #1
        for catalog in catalogs:
            ident = self.findExternalIdentifierInCatalog(
                catalog, publicId, systemId)
            if ident:
                return ident
        return None

    # e.g. info from doctype declaration
    def resolveExternalIdentifier(self, publicId=None, systemId=None):
        # resolve the dataset declaration to a uri
        if not publicId and not systemId:
            raise "no public or system id provided to the resolver"

        if publicId:
            if publicId.find('urn:publicid:') == 0:
                publicId = self.unwrapURN(publicId)
            if systemId and systemId.find('urn:publicid:') == 0:
                # either the unwrapped sysid is the same as the unwrapped
                # public id, in which case we ignore the systemid, or
                # it is an error, and we ignore the systemid anyway
                systemId = None
        elif systemId and systemId.find('urn:publicid:') == 0:
                publicId = self.unwrapURN(systemId)

        return self.findExternalIdentifier(self.catalogs, publicId, systemId)

    def findURIInCatalog(self, catalog, uri):
        # 7.2.2 #2
        if uri in catalog.urimap:
            return catalog.urimap[uri].uri
        # 7.2.2 #3
        rewrite = catalog.getURIRewrite(uri)
        if rewrite:
            return rewrite
        delegatecatalogs = catalog.getURIDelegates(uri)
        if delegatecatalogs:
            return self.findURI(delegatecatalogs, uri)
        for catalogURI in catalog.nextcatalog:
            ident = self.findURIInCatalog(self.catalogMap[catalogURI], uri)
            if ident:
                return ident
        return None

    def findURI(self, catalogs, uri):
        # 7.2.2 #1
        for catalog in catalogs:
            ident = self.findURIInCatalog(catalog, uri)
            if ident:
                return ident
        return None

    # e.g. an XML namespace
    def resolveURI(self, uri):
        # 7.2.1
        if uri.find('urn:publicid:') == 0:
            uri = self.unwrapURN(uri)
            return self.findExternalIdentifier(self.catalogs, uri, None)
        return self.findURI(self.catalogs, uri)

    def getWellKnownNamspaces(self):
        ns = {}
        for catalog in self.catalogs:
            ns.update(catalog.urimap)
        return ns

    def getDatasetForURI(self, uri, casename=False):
        if uri in self.datasets:
            return self.datasets[uri]
        ext = os.path.splitext(uri)[1]
        if ext == ".dtd":
            dataset = DTD(uri, resolver=self, casename=casename).dataset
        elif ext == ".rng":
            dataset = rng(uri).dataset
        else:
            raise "Unsuported Scheme type (DTD and RelaxNG only)"
        self.datasets[uri] = dataset
        return dataset

    def getDatasetForDoctype(self, publicId=None, systemId=None):
        uri = self.resolveExternalIdentifier(publicId, systemId)
        if not uri:
            return None
        casename = publicId and publicId.find(" HTML ") >= 0
        return self.getDatasetForURI(uri, casename)

    def getDatasetForNamespace(self, uri=None):
        uri = self.resolveURI(uri)
        if not uri:
            return None
        return self.getDatasetForURI(uri)

    def getDataset(self, publicId=None, systemId=None, uri=None):
        dataset = None
        if uri:
            dataset = self.getDatasetForNamespace(uri)
        if not dataset and (publicId or systemId):
            dataset = self.getDatasetForDoctype(publicId, systemId)
        return dataset


if __name__ == "__main__":
    logging.basicConfig()

    import sys
    if len(sys.argv) > 1:
        filename = sys.argv[1]
        catSvc = CatalogResolver([filename])
        ns = catSvc.getWellKnownNamspaces()
        print ns
        print catSvc.resolveExternalIdentifier(systemId=ns.keys()[0])
        ds = catSvc.getDatasetForNamespace(ns.keys()[0])
        ds.dump(sys.stdout)
    else:
        import os
        import sys
        # we're  in src/python-sitelib, we need the contrib dir
        basedir = os.path.dirname(os.path.dirname(os.getcwd()))
        catalogs = os.path.join(basedir, "contrib", "catalogs")
        # parse a single dtd
        # filename = os.path.join(catalogs, "sgml-lib","REC-smil20-20050107","SMIL20Basic.dtd")
        # dtd = DTD(filename)
        # dtd.dataset.dump(sys.stdout)
        # sys.exit(0)

        # parse all dtd files in a catalog
        # filename = os.path.join(catalogs, "sgml-lib","xml.soc")
        # cat = SGMLCatalog(filename)
        # print cat.public
        # print cat.system
        #
        # for pubid in cat.public.values():
        #    ext = os.path.splitext(pubid.uri)[1]
        #    if ext != ".dtd": continue
        #    print "PARSING [%s]"%pubid.uri
        #    try:
        #        dtd = DTD(pubid.uri)
        #    except Exception, e:
        #        print "...FAILED"

        # use the catalog resolver to find a catalog
        catalogFiles = [os.path.join(catalogs, "sgml-lib", "xml.soc"),
                        os.path.join(catalogs, "sgml-lib", "sgml.soc"),
                        #"/Users/shanec/main/Apps/Komodo-devel/test/catalogs/doesnotexist.xml"
                        ]
        catSvc = CatalogResolver(catalogFiles)
        #
        # dtdFile = catSvc.resolveExternalIdentifier(systemId="spec.dtd")
        # print "got dtd %s" % dtdFile
        # assert dtdFile == "http://www.w3.org/XML/1998/06/xmlspec-v20.dtd"
        #
        # dtdFile = catSvc.resolveExternalIdentifier(publicId="-//W3C//DTD Specification V2.0//EN")
        # print "got dtd %s" % dtdFile
        # assert dtdFile == "http://www.w3.org/XML/1998/06/xmlspec-v20.dtd"
        #
        catSvc.init(
            ["/Users/shanec/main/Apps/Komodo-devel/test/catalogs/test1.xml"])
        print catSvc.getWellKnownNamspaces()
        # dtdFile = catSvc.resolveExternalIdentifier(publicId="-//OASIS//DTD DocBook XML V4.4//EN")
        # print "got dtd %s" % dtdFile
        # assert dtdFile == "file:///usr/share/xml/docbook44/docbookx.dtd"

        # testing rewriteURI and rewriteSystem
        # catSvc.init(["/Users/shanec/main/Apps/Komodo-devel/test/catalogs/test2.xml"])
        # dtdFile = catSvc.resolveURI("http://docbook.sourceforge.net/release/xsl/current/thisisatest.xml")
        # print "got dtd %s" % dtdFile
        # assert dtdFile == "file:///usr/share/xml/docbook-xsl-1.68.1/thisisatest.xml"
        # dtdFile = catSvc.resolveExternalIdentifier(systemId="http://www.oasis-open.org/docbook/xml/4.4/thisisatest.xml")
        # print "got dtd %s" % dtdFile
        # assert dtdFile == "file:///usr/share/xml/docbook44/thisisatest.xml"

        catSvc.init([os.path.join(catalogs, "docbook44", "catalog.xml")])
        expect = os.path.join(catalogs, "docbook44", "docbookx.dtd")
        dtdFile = catSvc.resolveExternalIdentifier(
            publicId="-//OASIS//DTD DocBook XML V4.4//EN")
        print "got dtd %s" % dtdFile
        assert dtdFile == expect
        dtdFile = catSvc.resolveExternalIdentifier(
            systemId="http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd")
        print "got dtd %s" % dtdFile
        assert dtdFile == expect
        dtdFile = catSvc.resolveExternalIdentifier(
            systemId="http://docbook.org/xml/4.4/docbookx.dtd")
        print "got dtd %s" % dtdFile
        assert dtdFile == expect
        # catSvc.init(["/Users/shanec/tmp/dtd/DITA-OT1.3/catalog-dita_template.xml"])
        # dtdFile = catSvc.resolveExternalIdentifier(publicId="-//OASIS//DTD DITA Map//EN")
        # print "got dtd %s" % dtdFile

########NEW FILE########
__FILENAME__ = koDTD
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

import os
import logging
import re
import weakref
from koSimpleLexer import *

log = logging.getLogger("koDTD")
# log.setLevel(logging.DEBUG)

# XXX a cheap relativize
urimatch = re.compile("(\w+://.*|/.*|\w:\\.*|\w:/.*)")


def relativize(base, fn):
    if urimatch.match(fn):
        return fn
    return os.path.join(base, fn)

# regular expressions used for DTD parsing
collector = recollector()
a = collector.add

# secondary parsing regex
a("newlines",                   "[ \t]*(\r\n|\r|\n)")
a("groupedNamesSplitter", "[\s\|\*\+\(\)\?&,]+")
# not used in lex_matches
a("NDataDecl",     r"\s*'NDATA'\s*\S+", re.S | re.U)
a("QuotedString",  r'(?:")([^"]*?)(?:")|(?:\')([^\']*?)(?:\')', re.S | re.U)
a("ExternalID",
  r"(?P<type>SYSTEM|PUBLIC)\s*(?P<literal1>%(QuotedString)s)\s*(?P<literal2>%(QuotedString)s)?", re.S | re.U)

# used in lex_matches
a("whitespace",    r"\s+", re.S | re.M)
a("section_ignore", r'<!\[\s*IGNORE\s*\[.*?\]\]>', re.S | re.M)
a("section_start", r'<!\[\s*(?P<name>\S+)\s*\[', re.S | re.M)
a("section_end",   r'\]\]>')
a("PEReference",   r"%%(?P<ref>[^;]+)[;\s]", re.U)
a("PEENTITY",
  r'<!ENTITY\s+%%\s+(?P<name>\S+)\s+(?:--(?P<comment_entity>.*?)--\s+)?(?P<content>%(QuotedString)s|%(ExternalID)s(?:%(NDataDecl)s)?)\s*(?:--(?P<comment>.*?)--)?\s*>', re.S | re.U)
# PEENTITY2: another syntax tweak for xhtml-arch-1.mod
a("PEENTITY2",
  r'<!ENTITY\s+(?P<name>\S+)\s+(?:--(?P<comment_entity>.*?)--\s+)?(?P<content>%(ExternalID)s(?:%(NDataDecl)s)?)\s*(?:--(?P<comment>.*?)--)?\s*>', re.S | re.U)
a("GEENTITY",
  r'<!ENTITY\s+(?P<name>\S+)\s+(?P<type>\w+)\s+(?:--(?P<comment_entity>.*?)--\s+)?(?P<content>%(QuotedString)s)\s*(?:--(?P<comment>.*?)--)?\s*>', re.S | re.U)
a("ATTLIST",
  r'<!ATTLIST\s+(?P<name>\(.*?\)|\S+)\s+(?P<content>.*?)\s*(?:>(?=\s))', re.S | re.U)
a("ELEMENT",
  r'<!ELEMENT\s+(?P<name>\(.*?\)|\S+)\s+(?:(?P<start>\S)\s(?P<end>\S)\s+)?(?P<content>EMPTY|ANY|.*?)\s*(?:--(?P<comment>.*?)--)?\s*>', re.S | re.U)
a("COMMENT",       r"<!--(?P<comment>.*?)-->", re.S | re.M)

# we dont do anything with notations at this time
a("NOTATION",       r"<!NOTATION.*?>", re.S | re.M)

# stuff from HTML3.dtd that we dont use
a("USEMAP",       r"<!USEMAP.*?>", re.S | re.M)
a("SHORTREF",       r"<!SHORTREF.*?>", re.S | re.M)
a("ENTITY",
  r'<!ENTITY\s+(?P<name>\S+)\s+(?P<content>%(QuotedString)s)\s*(?:--(?P<comment>.*?)--)?\s*>', re.S | re.U)

# xhtml-math-svg-flat-20020809.dtd has this, don't know why, I've never seen
# this in any DTD spec:
#   <?doc type="doctype" role="title" { XHTML 1.1 } ?>
a("PROCTAG",       r"<\?.*?\?>", re.S | re.M)


class dtd_dataset:
    def __init__(self):
        self.entities = {}
        self.elements = {}
        self.root = []
        self.attlist = {}
        self.namespace = ""
        self.elements_caseless = {}

    def element_info(self, element_name):
        name = element_name.lower()
        if name in self.elements_caseless:
            return self.elements_caseless[name]
        return None

    def buildRootList(self):
        all_elements = self.elements.keys()
        root = {}
        for el in all_elements:
            found = 0
            for e in self.elements.values():
                if el in e.elements:
                    found = 1
                    break
            if not found:
                root[el] = 1
        self.root = root.keys()

    def possible_children(self, element_name=None):
        if not element_name:
            return self.root
        else:
            name = element_name.lower()
            if name in self.elements_caseless:
                el = self.elements_caseless[name]
                if el.content.lower() == "any":
                    elements = self.elements.keys()
                else:
                    elements = self.elements_caseless[name].elements
                result = set(elements)
                for el_name in elements:
                    ei = self.element_info(el_name)
                    if ei is not None and ei.start == "O":
                        # add the children for this to our list
                        result = result.union(self.possible_children(el_name))
                return result
        return self.root

    def possible_attributes(self, element_name):
        name = element_name.lower()
        if name in self.elements_caseless:
            return self.elements_caseless[name].attributes.keys()
        return []

    def possible_attribute_values(self, element_name, attribute_name):
        el = self.element_info(element_name)
        if el and attribute_name in el.attributes:
            return el.attributes[attribute_name].values
        return []

    def all_element_types(self):
        return self.elements.keys()

    def dump(self, stream):
        for e in self.elements.values():
            e.dump(stream)


def strip_quotes(str):
    if not str:
        return None
    if str[0] in ["'", '"']:
        return str[1:-1]
    return str


class dtd_entity:
    def __init__(self, d):
        self.name = d['name']
        self.data = d
        self.type = d['type']
        if 'literal1' in d:
            self.entity = strip_quotes(d['literal1'])
            self.dtd = strip_quotes(d['literal2'])
        else:
            self.entity = None
            self.dtd = None
        self.content = strip_quotes(d['content'])
        self.entityRe = re.compile(r"%%%s\b;?" % self.name, re.U)

    def applyEntity(self, text):
        if self.type is None:
            # print "replacing text [%s] with %r " % (r"%%%s;?" % self.name,
            # self.content)
            return self.entityRe.sub(self.content, text)
        return text


class dtd_element:
    _top_groups = re.compile(
        r'([+-]\(.*?\)|\(.*?\)[\*\+]|\(.*?\))(?:\s|$)', re.S | re.U)

    def __init__(self, d, casename=False):
        self.name = d['name']
        self.data = d
        self.start = d['start']
        self.end = d['end']
        self.content = d['content']
        self.elements = []  # children names only
        self.attributes = {}
        self.namespace = ""

        if self.content not in ["empty", "any"]:
            matches = self._top_groups.findall(self.content)
            if matches:
                groupedNamesRe = collector.res["groupedNamesSplitter"]
                children = set()
                for match in matches:
                    if match[0] != "-" or match[-1] in ["?", "*", "+", ")"]:
                        # we found the potentially good children, keep them
                        children = children.union([n for n in groupedNamesRe.split(
                            match) if n and n != '#PCDATA'])
                for match in matches:
                    if match[0] == "-":
                        children = children.difference(
                            [n for n in groupedNamesRe.split(match) if n])
                if casename:
                    self.elements = [i.lower() for i in list(children)]
                else:
                    self.elements = list(children)

    def dump(self, stream):
        stream.write("ELEMENT: %s\n" % self.name)
        for a in self.attributes.values():
            a.dump(stream)
        stream.write("    CHILDREN %r\n" % self.elements)


class dtd_attlist:
    _attr_line = re.compile(
        '(?P<name>\w+)\s+(?P<type>[A-Za-z]+|\(.*?\))\s+(?P<default>#REQUIRED|#IMPLIED|\w+|(?:#FIXED)?((?:")([^"]*?)(?:")|(?:\')([^\']*?)(?:\')))\s*(?:--(?P<comment>.*?)--)?', re.S | re.U)

    def __init__(self, d, el=None, casename=False):
        self.name = d['name']
        self.data = d
        self.casename = casename
        if el:
            self.addAttributes(el)

    def addAttributes(self, el):
        for m in self._attr_line.finditer(self.data['content']):
            a = dtd_attr(m.groupdict(), self.casename)
            if a.name not in el.attributes:
                el.attributes[a.name] = a

    def dump(self, stream):
        pass


class dtd_attr:
    def __init__(self, d, casename=False):
        self.name = d['name']
        self.values = []
        self.type = 'CDATA'
        if d['type'][0] == '(':
            groupedNamesRe = collector.res["groupedNamesSplitter"]
            self.values = [n for n in groupedNamesRe.split(d['type']) if n]
            if casename:
                self.values = [v.lower() for v in self.values]
        else:
            self.type = d['type']
        self.default = d['default']
        self.comment = d['comment']

    def dump(self, stream):
        stream.write("ATTR: %s values %r default %s\n" %
                     (self.name, self.values, self.default))


class DTD:

    # states
    TAGEND = 0
    TAGSTART = 1
    ENTITYTAG = 2
    ENTITY = 3
    ELEMENT = 4
    ATTRIBUTE = 5

    def __init__(self, filename, dataset=None, resolver=None, casename=False):
        # hook up the lexical matches to a function that handles the token
        self.lex_matches = [
            ('whitespace',      self.doMultiLineBlock,  EXECFN | SKIPTOK),
            ('COMMENT',         self.doCommentBlock,    EXECFN | SKIPTOK),
            ('section_ignore',  None,                   SKIPTOK),
            ('section_start',   self.section_start,     EXECFN | SKIPTOK),
            ('section_end',     self.section_end,       EXECFN | SKIPTOK),
            ('PEENTITY',        self.entity,            EXECFN | SKIPTOK),
            ('PEENTITY2',       self.entity,            EXECFN | SKIPTOK),
            ('GEENTITY',        self.entity,            EXECFN | SKIPTOK),
            ('PEReference',     self.pereference,       EXECFN | SKIPTOK),
            ('ELEMENT',         self.element,           EXECFN | SKIPTOK),
            ('ATTLIST',         self.attlist,           EXECFN | SKIPTOK),

            # these are formats in some DTD's that we will suppress
            ('USEMAP',          None,           SKIPTOK),
            ('SHORTREF',        None,           SKIPTOK),
            ('NOTATION',        None,           SKIPTOK),
            ('ENTITY',          None,           SKIPTOK),
            ('PROCTAG',         None,           SKIPTOK),
        ]

        self.casename = casename
        self.resolver = resolver
        if dataset is None:
            dataset = dtd_dataset()
        self.dataset = dataset
        self._element_stack = [self.dataset]
        self._includes = []
        self.filename = filename
        self.lineno = 0
        self.parse()
        self.dataset.buildRootList()

    def parse(self):
        # setup lexer and add token matching regexes
        self.l = Lexer(self.filename)
        for p in self.lex_matches:
            # log.debug("adding %r",p[0])
            attributes = p[2]
            if not attributes:
                attributes = MAPTOK | EXECFN
            self.l.addmatch(collector.res[p[0]], p[1], p[0], attributes)

        self.currentTag = None
        self.lineno = 1
        self.ignore = 0
        self.scanData()

    def scanData(self):
        # log.debug("scanData")
        f = open(self.filename)
        data = f.read()
        f.close

        # XXX
        # because of the many issues around comments in dtd files, and since
        # we're doing a sloppy parse, lets just get rid of all comments now.
        data = collector.res["COMMENT"].sub("", data)
        r = re.compile(r"--.*?--", re.S | re.U)
        data = r.sub("", data)

        data = self.applyEntities(data)

        self.l.settext(data)

        # res = []
        while 1:
            t, v = self.l.scan()
            # if t and v:
            #    log.debug("  lex symbol: %r %r", t, v)
            if t == self.l.eof:
                break
            # res.append((t, v))

    def applyEntities(self, text):
        # apply all existing entities to this text
        for e in self.dataset.entities.values():
            text = e.applyEntity(text)
        return text

    def incline(self, m):
        self.lineno = self.lineno + 1
        log.debug("line: %d", self.lineno)
        return ""

    # takes a block, and figures out how many lines it spans, to
    # keep lineno correct
    def doMultiLineBlock(self, m):
        # log.debug("block start at lineno %d",self.lineno)
        nl = collector.res["newlines"].findall(m.group(0))
        blockLen = len(nl)
        self.lineno = self.lineno + blockLen
        # log.debug("block had %d lines, lineno is %d", blockLen, self.lineno)
        return ""

    def doCommentBlock(self, m):
        self.lastComment = [m, self.lineno, 0]
        self.doMultiLineBlock(m)
        self.lastComment[2] = self.lineno
        log.debug("doCommentBlock %r", self.lastComment)
        return ""

    def section_start(self, m):
        if m.group('name') == 'IGNORE':
            self.ignore = 1
        return ""

    def section_end(self, m):
        self.ignore = 0
        return ""

    def entity(self, m):
        log.debug("ENTITY: [%r] on line %d", m.groupdict(), self.lineno)
        # print m.group(0)
        self.doMultiLineBlock(m)
        t = dtd_entity(m.groupdict())
        self.dataset.entities[m.group('name')] = t
        # if this is a peentity, we want to replace text with the entity content
        # we know it is a peentity if there the type is None
        if t.type is None:
            text = t.applyEntity(self.l.text[self.l.textindex:])
            self.l.text = self.l.text[:self.l.textindex-1] + text
        return ""

    def pereference(self, m):
        log.debug("PEReference: [%r] on line %d", m.groupdict(), self.lineno)
        # include the reference fileif any
        if self.ignore:
            return ""
        entity = self.dataset.entities[m.group('ref')]
        if entity.dtd:
            filename = relativize(os.path.dirname(self.filename), entity.dtd)

            if not os.path.exists(filename):
                if self.resolver:
                    filename = self.resolver.resolveURI(filename)
                    if not filename or not os.path.exists(filename):
                        filename = self.resolver.resolveExternalIdentifier(
                            entity.entity, entity.dtd)

            if filename and os.path.exists(filename):
                # log.info("    parsing [%s]", filename)
                d = DTD(filename, self.dataset, self.resolver)
                text = self.applyEntities(self.l.text[self.l.textindex:])
                self.l.text = self.l.text[:self.l.textindex-1] + text
            else:
                log.warn("UNRESOLVED REFERENCE [%s][%s][%s][%s]", m.group(
                    'ref'), entity.type, entity.entity, filename)
        else:
            # XXX we need catalog support to do this
            log.warn("UNRESOLVED REFERENCE [%s][%s][%s]", m.group(
                'ref'), entity.type, entity.entity)
        return ""

    def element(self, m):
        log.debug("ELEMENT: [%r] on line %d", m.groupdict(), self.lineno)
        self.doMultiLineBlock(m)
        if self.ignore:
            return ""
        d = m.groupdict()
        groupedNamesRe = collector.res["groupedNamesSplitter"]
        names = [n for n in groupedNamesRe.split(d['name']) if n]
        for name in names:
            if self.casename:
                name = name.lower()
            d['name'] = name
            t = dtd_element(d, self.casename)
            self.dataset.elements[name] = t
            self.dataset.elements_caseless[name.lower()] = t
            if name in self.dataset.attlist:
                # if attlist was defined before element, get the attributes now
                a = self.dataset.attlist[name]
                a.addAttributes(t)
        return ""

    def attlist(self, m):
        log.debug("ATTLIST: [%r] on line %d", m.groupdict(), self.lineno)
        self.doMultiLineBlock(m)
        if self.ignore:
            return ""
        d = m.groupdict()
        groupedNamesRe = collector.res["groupedNamesSplitter"]
        names = [n for n in groupedNamesRe.split(d['name']) if n]
        for name in names:
            if self.casename:
                name = name.lower()
            d['name'] = name
            if name in self.dataset.elements:
                el = self.dataset.elements[name]
            else:
                el = None
            t = dtd_attlist(d, el, self.casename)
            self.dataset.attlist[name] = t
        return ""

    # def entity_ref(self, m):
    #    log.debug("ENTITY REF: [%s] type [%s] decl [%s] dtd [%s] on line %d", m.group('name'), m.group('type'), self.lineno)
    #    self.doMultiLineBlock(m)
    #    return ""

if __name__ == "__main__":
    logging.basicConfig()

    import sys
    if len(sys.argv) > 1:
        filename = sys.argv[1]
        dtd = DTD(filename)
        dtd.dataset.dump(sys.stdout)
    else:
        # parse a single dtd
        basedir = os.path.dirname(os.path.dirname(os.getcwd()))
        filename = os.path.join(
            basedir, "contrib", "catalogs", "docbook44", "docbookx.dtd")
        filename = os.path.join(
            basedir, "contrib", "catalogs", "sgml-lib", "REC-xhtml11-20010531", "xhtml11-flat.dtd")
        filename = os.path.join(
            basedir, "contrib", "catalogs", "sgml-lib", "REC-html32-19970114", "HTML32.dtd")
        filename = os.path.join(
            basedir, "contrib", "catalogs", "sgml-lib", "IETF", "HTML-2_0.dtd")
        filename = os.path.join(
            basedir, "contrib", "catalogs", "sgml-lib", "REC-html401-19991224", "strict.dtd")
        # filename = os.path.join(basedir, "contrib","catalogs","sgml-lib","ISO-HTML","15445.dtd")
        # dtd = DTD('/Users/shanec/src/dtd/dita/dtd/concept.dtd')
        # print dtd.dataset.root
        # print dtd.dataset.possible_children("related-links")
        dtd = DTD(filename, casename=True)
        print dtd.dataset.root
        # print dtd.dataset.possible_children("table")
        print dtd.dataset.possible_attributes("input")
        print dtd.dataset.possible_attribute_values("input", "type")
        # print dtd.dataset.possible_children("head")
        # dtd.dataset.dump(sys.stdout)
        # sys.exit(0)

########NEW FILE########
__FILENAME__ = koRNGElementTree
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

import os
from xml.dom import pulldom
import logging
import re

log = logging.getLogger("koRNG")
log.setLevel(logging.DEBUG)

from elementtree import XMLTreeBuilder
try:
    import cElementTree as ElementTree  # effbot's C module
except ImportError:
    log.error(
        "using element tree and not cElementTree, performace will suffer")
    import elementtree.ElementTree as ElementTree  # effbot's pure Python module


class NamespaceParser(XMLTreeBuilder.FancyTreeBuilder):
    _qname = re.compile("{(.*?)}(.*)")

    def start(self, element):
        element.namespaces = self.namespaces[:]
        qn = self._qname.match(element.tag)
        element.ns = qn.group(1)
        element.tagName = qn.group(2)


class rng_base_dataset:
    def __init__(self):
        self.name = None
        self.elements = []  # root level elements
        self.attributes = []
        self.values = []
        self.refs = []

    def resolveRefs(self, dataset):
        for ref in self.refs[:]:
            if ref not in dataset.defs.keys():
                if ref not in dataset.ref_unresolved:
                    dataset.ref_unresolved[ref] = []
                dataset.ref_unresolved[ref].append(self)
                continue
            d = dataset.defs[ref]
            del self.refs[self.refs.index(ref)]
            if d.refs:
                d.resolveRefs(dataset)

            # grab what we care about from this definition
            self.attributes += [a for a in d.attributes if a.name]
            self.elements += [e for e in d.elements if e.name]
            self.values += d.values


class rng_dataset(rng_base_dataset):
    def __init__(self):
        rng_base_dataset.__init__(self)
        self.name = "root"
        self.all_elements = {}
        self.elements_caseless = {}
        self.defs = {}
        self.namespace = ""
        self.datatypeLibrary = ""
        self.xmlns = ""

        self.ref_resolving = {}
        self.ref_unresolved = {}

    def resolveRefs(self, dataset=None):
        if not dataset:
            dataset = self
        rng_base_dataset.resolveRefs(self, dataset)

        for d in self.defs.values():
            d.resolveRefs(dataset)

        for e in self.all_elements.values():
            e.resolveRefs(dataset)

        for a in self.attributes[:]:
            a.resolveRefs(dataset)

        self.resolveUnresolvedRefs()

    def resolveCircularRefs(self):
        for ref in self.ref_circular.keys()[:]:
            # print "resolving earlier circular reference %s"%ref
            el = self.ref_circular[ref]
            del self.ref_circular[ref]
            for e in el:
                e.resolveRefs(self)

    def resolveUnresolvedRefs(self):
        for ref in self.ref_unresolved.keys()[:]:
            print "resolving earlier unresolved reference %s" % ref
            el = self.ref_unresolved[ref]
            del self.ref_unresolved[ref]
            for e in el:
                e.resolveRefs(self)

    def element_info(self, element_name):
        name = element_name.lower()
        if name in self.elements_caseless:
            return self.elements_caseless[name]
        return None

    def possible_children(self, element_name=None):
        if not element_name:
            return [el.name for el in self.elements]
        else:
            name = element_name.lower()
            if name not in self.elements_caseless:
                return []
            return [el.name for el in self.elements_caseless[name].elements]

    def possible_attributes(self, element_name):
        name = element_name.lower()
        if name in self.elements_caseless:
            return [a.name for a in self.elements_caseless[name].attributes]
        return []

    def possible_attribute_values(self, element_name, attribute_name):
        el = self.element_info(element_name)
        if el:
            for a in el.attributes:
                if attribute_name == a.name:
                    return a.values
        return []

    def all_element_types(self):
        return self.all_elements.keys()

    def dump(self, stream):
        print "RNG NS: %s" % self.xmlns
        print "Namespace: %s" % self.namespace
        print "datatypeLibrary: %s" % self.datatypeLibrary
        print "-"*60
        for e in self.elements:
            e.dump(stream)
        print "-"*60
        for e in self.all_elements.values():
            e.dump(stream)
        print "-"*60


class rng_node_info(rng_base_dataset):
    def __init__(self, node):
        rng_base_dataset.__init__(self)
        self.name = node.attrib.get("name")
        self._node = node


class element_info(rng_node_info):
    def dump(self, stream):
        attrs = []
        for n, v in self._node.attrib.items():
            attrs.append('%s="%s"' % (n, v))
        stream.write("<element %s>\n" % ' '.join(attrs))
        names = [el.name for el in self.elements]
        stream.write("    children %r\n" % names)
        for attr in self.attributes:
            attr.dump(stream)
        stream.write("    refs remaining: %r\n" % self.refs)


class attribute_info(rng_node_info):
    def dump(self, stream):
        stream.write("    attr %s %r\n" % (self.name, self.values))


class definition(rng_node_info):
    def dump(self, stream):
            stream.write("definition %s has %d refs\n" % (
                self.name, len(self.refs)))
            names = [el.name for el in self.elements]
            stream.write("   has %d elements %r\n" % (
                len(self.elements), names))
            names = [el.name for el in self.attributes]
            stream.write("   has %d attributes %r\n" % (
                len(self.attributes), names))
            stream.write("   has %d values %r\n" % (
                len(self.values), self.values))

    def resolveRefs(self, dataset):
        for e in self.elements[:]:
            e.resolveRefs(dataset)
        for a in self.attributes[:]:
            a.resolveRefs(dataset)
        rng_node_info.resolveRefs(self, dataset)


class rng:
    def __init__(self, filename, dataset=None):
        if dataset is None:
            dataset = rng_dataset()
        self.dataset = dataset
        self._element_stack = [self.dataset]
        self._includes = []
        self.filename = filename
        self.parse()

    def parse(self):
        self.tree = ElementTree.parse(self.filename, NamespaceParser())
        self.root = self.tree.getroot()
        if self.root.tagName != "grammar":
            raise "Invalid RNG file [%s] root tag [%s]" % (
                self.filename, self.root.tagName)
        self.parent_map = dict((
            c, p) for p in self.tree.getiterator() for c in p)
        self.parseNode(self.root)
        self.dataset.resolveRefs()

    def parseNode(self, node):
        methodName = "handle_%s" % node.tagName
        # print methodName
        if hasattr(self, methodName):
            fn = getattr(self, methodName)
            fn(node)
        for child in list(node):
            # print "parsing child %s"%child.tagName
            self.parseNode(child)
        methodName = "handle_%s_end" % node.tagName
        # print methodName
        if hasattr(self, methodName):
            fn = getattr(self, methodName)
            fn(node)

    def handle_include(self, node):
        # XXX handle relative dirs
        path = node.attrib.get("href")
        if not os.path.exists(path):
            path = os.path.join(os.path.dirname(self.filename), path)
        # print "file included [%s]"%path
        rng(path, self.dataset)

    def handle_grammar(self, node):
        if not self.dataset.namespace:
            self.dataset.xmlns = node.attrib.get('xmlns')
            self.dataset.namespace = node.attrib.get('ns')
            self.dataset.datatypeLibrary = node.attrib.get('datatypeLibrary')

    # def handle_start(self, node):
    #    self._element_stack.append(self)
    # def handle_start_end(self, node):
    #    self._element_stack.pop()

    def handle_attribute(self, node):
        self._element_stack.append(attribute_info(node))

    def handle_attribute_end(self, node):
        # attributes get added to the last item in the element stack
        attr = self._element_stack.pop()
        el = self._element_stack[-1]
        el.attributes.append(attr)

    def handle_name_end(self, node):
        # is the parent node an attribute?
        parent = self.parent_map[node]
        if node.text and parent.tagName == "attribute":
            # print "name value...%r"%node.text
            e = self._element_stack[-1]
            e.name = node.text
            self.dataset.all_elements[node.text] = e
            self.dataset.elements_caseless[node.text.lower()] = e

    def handle_element(self, node):
        # print "handle_element %s" %node.attrib.get("name")
        e = element_info(node)
        if e.name:
            self.dataset.all_elements[e.name] = e
            self.dataset.elements_caseless[e.name.lower()] = e
        self._element_stack.append(e)

    def handle_element_end(self, node):
        # print "handle_element_end %s" %node.attrib.get("name")
        el = self._element_stack.pop()
        self._element_stack[-1].elements.append(el)

    def handle_define(self, node):
        d = definition(node)
        # print "definition: %s" % d.name
        self.dataset.defs[d.name] = d
        self._element_stack.append(d)

    def handle_define_end(self, node):
        d = self._element_stack.pop()

    def handle_ref(self, node):
        self._element_stack[-1].refs.append(node.attrib.get("name"))

    def handle_value(self, node):
        self._element_stack[-1].values.append(node.text)


    # def handle_zeroOrMore(self, node):
    #    pass
    # def handle_choice(self, node):
    #    pass
    # def handle_interleave(self, node):
    #    pass
    # def handle_mixed(self, node):
    #    pass
    # def handle_empty(self, node):
    #    pass
    # def handle_notAllowed(self, node):
    #    pass
    # def handle_group(self, node):
    #    pass
    # def handle_optional(self, node):
    #    pass
    # def handle_text(self, node):
    #    pass
    # def handle_div(self, node):
    #    pass
    # def handle_list(self, node):
    #    pass
    # def handle_data(self, node):
    #    pass
    # def handle_except(self, node):
    #    pass
    # def handle_oneOrMore(self, node):
    #    pass
    # def handle_param(self, node):
    #    pass


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        filename = sys.argv[1]
        machine = rng(filename)
    else:
        import os
        import sys
        # we're  in src/python-sitelib, we need the contrib dir
        basedir = os.path.dirname(os.path.dirname(os.getcwd()))
        filename = os.path.join(
            basedir, "contrib", "catalogs", "rng", "xslt.rng")
        machine = rng(filename)
        # assert "template" in machine.possible_children("stylesheet")
        # assert "text" in machine.all_element_types()
        # assert machine.possible_children("text")==[]
        # assert machine.possible_children("garbage")==[]
        # assert "version" in machine.possible_attributes("transform")
        # assert machine.possible_attributes("garbage")==[]
        # assert "upper-first" in machine.possible_attribute_values("sort", "case-order")
        # assert machine.possible_attribute_values("garbage", "garbage") == []
        # assert machine.possible_attribute_values("garbate", "case-order") == []
        ## filename = "..\\languages\\xhtml\\xhtml-state-machine.xml"
        ## machine = state_machine_info(filename)
        ## for element in machine.all_element_types():
            ## if element!="#LITERAL":
                # assert "lang" in machine.possible_attributes(element), "no
                # lang on %s" % element

    machine.dataset.dump(sys.stdout)
    # machine.dataset.element_info("tr").dump(sys.stdout)

########NEW FILE########
__FILENAME__ = koSimpleLexer
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

import os
import logging
import re

log = logging.getLogger("koSimpleLexer")
# XXX duplicated in codeintel.parseutil, present here to make this entirely
# independent

SKIPTOK = 0x01  # don't consider this a token that is to be considered a part of the grammar, like '\n'
MAPTOK = 0x02  # use the token associated with the pattern when it matches
EXECFN = 0x04   # execute the function associated with the pattern when it matches
USETXT = 0x08  # if you match a single character and want its ascii value to be the token

# Lexer class borrowed from the PyLRd project,
# http://starship.python.net/crew/scott/PyLR.html


class Lexer:
    eof = -1

    def __init__(self, filename=None):
        self.filename = filename
        self.tokenmap = {}
        self.prgmap = {}
        self.prglist = []
        self.lasttok = -1
        self.text = ""
        self.textindex = 0
        self.tokennum2name = {}

    def nexttok(self):
        self.lasttok = self.lasttok + 1
        return self.lasttok

    def settext(self, t):
        self.text = t
        self.textindex = 0

    def addmatch(self, prg, func=None, tokname="", attributes=MAPTOK | EXECFN):
        self.prglist.append(prg)
        tok = -2
        if not func:
            attributes = attributes & ~EXECFN
        if not tokname:
            attributes = attributes & ~MAPTOK
        if attributes & MAPTOK:
            self.tokenmap[tokname] = tok = self.nexttok()
        else:
            tok = self.nexttok()
        self.prgmap[prg] = tok, attributes, func
        self.tokennum2name[tok] = tokname

    def scan(self):
        x = ""
        for prg in self.prglist:
            # x = "TEXT TO MATCH {%s<|>%s}"% (self.text[self.textindex-10:self.textindex],self.text[self.textindex:self.textindex+20])
            # print x
            mo = prg.match(self.text, self.textindex)
            if not mo:
                continue
            self.textindex = self.textindex + len(mo.group(0))
            tmpres = mo.group(0)
            t, attributes, fn = self.prgmap[prg]
            # log.info("'%s' token: %r", self.tokennum2name[t], tmpres)
            if attributes & EXECFN:
                try:
                    tmpres = apply(fn, (mo,))
                except Exception, e:
                    log.exception(e)
                    line = len(re.split(
                        '\r|\n|\r\n', self.text[:self.textindex]))
                    raise Exception("Syntax Error in lexer at file %s line %d positon %d text[%s]" % (
                        self.filename, line, self.textindex, self.text[self.textindex:self.textindex+300]))
            if attributes & USETXT:
                t = ord(mo.group(0)[0])
            return (t, tmpres)
        if self.textindex >= len(self.text):
            return (self.eof, "")

        line = len(re.split('\r|\n|\r\n', self.text[:self.textindex]))
        raise Exception("Syntax Error in lexer at file %s line %d positon %d text[%s]" % (
            self.filename, line, self.textindex, self.text[self.textindex-20:self.textindex+300]))


# regular expressions used in parsing SGML related documents
class recollector:
    def __init__(self):
        self.res = {}
        self.regs = {}

    def add(self, name, reg, mods=None):
        self.regs[name] = reg % self.regs
        # print "%s = %s" % (name, self.regs[name])
        if mods:
            self.res[name] = re.compile(self.regs[
                                        name], mods)  # check that it is valid
        else:
            self.res[name] = re.compile(self.regs[
                                        name])  # check that it is valid

########NEW FILE########
__FILENAME__ = koXMLDatasetInfo
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""
koXMLDatasetInfo ties together the use of koXMLTreeService and
XML Catalog/DTD support in koCatalog to supply data handlers for determining
valid elements/attributes for the current position in the tree.

All tree arguments are cElementTree elements and should be the root element
of an XMLDocument from koXMLTreeService.

Note: most of this logic moved out of koXMLCompletionBase.py in order to
allow testing outside of Komodo.
"""

import sys
import os
import logging

import koXMLTreeService
from koCatalog import CatalogResolver


log = logging.getLogger("koXMLDatasetInfo")


class EmptyDatasetHandler:
    def tagnames(self, tree, node=None):
        if node is None:
            node = tree.current
        if node is not None:
            tags = tree.tags.get(tree.namespace(node), {})
        else:
            tags = tree.tags.get("", {})
        return [t for t in tags.keys() if t]

    def attrs(self, tree, node=None):
        if node is None:
            node = tree.current
        attrs = {}
        nodes = [n for n in tree.nodes if n.tag.lower() == node.tag.lower()]
        # now, get all attributes from all the tags
        for n in nodes:
            attrs.update(n.attrib)
        return attrs.keys()

    def values(self, attrname, tree, node=None):
        return []


class DataSetHandler(EmptyDatasetHandler):
    def __init__(self, namespace, dataset):
        self.namespace = namespace
        self.dataset = dataset

    def getnamespace(self, tree):
        """ if we were created without a namespace (eg. doctype only) then
            use the top level namespace for the document we're handling
            don't save the namespace, as it could change from document
            to document.  """
        if not self.namespace and tree.root is not None:
            return tree.root.ns
        return self.namespace

    def tagnames(self, tree, node=None):
        namespace = self.getnamespace(tree)
        if node is None:
            node = tree.current
        if node is None:
            # get root elements
            return self.dataset.possible_children()
        orig_node = node
        while node is not None:
            # print "node [%s] ns [%s]" % (node.localName,
            # tree.namespace(node))
            ns = tree.namespace(node)
            if node.localName and (not ns or ns.lower() == namespace.lower()):
                if self.dataset.element_info(node.localName):
                    return self.dataset.possible_children(node.localName)
            node = tree.parent(node)
        if self.dataset.element_info(orig_node.localName):
            return self.dataset.possible_children(orig_node.localName)
        return self.dataset.all_element_types()

    def attrs(self, tree, node=None):
        if node is None:
            node = tree.current
        return self.dataset.possible_attributes(node.localName)

    def values(self, attrname, tree, node=None):
        if node is None:
            node = tree.current
        return self.dataset.\
            possible_attribute_values(node.localName, attrname)


class DatasetHandlerService:
    handlers = {}  # empty dataset handlers
    resolver = None

    def __init__(self):
        self._default_public_ids = {
            "HTML": "-//W3C//DTD HTML 5//EN",
        }
        self._default_namespace_ids = {}
        self.defaultHandler = EmptyDatasetHandler()
        self.resolver = CatalogResolver()

    def setCatalogs(self, catalogs):
        self.resolver.resetCatalogs(catalogs)
        DatasetHandlerService.handlers = {}

    def getDefaultPublicId(self, lang, env):
        decl = self._default_public_ids.get(lang, None)
        if env:
            decl = env.get_pref("default%sDecl" % (lang,), decl)
        return decl

    def setDefaultPublicId(self, lang, public_id):
        self._default_public_ids[lang] = public_id

    def getDefaultNamespace(self, lang, env):
        namespace = self._default_namespace_ids.get(lang, None)
        if env:
            namespace = env.get_pref("default%sNamespace" % (lang,), namespace)
        return namespace

    def setDefaultNamespace(self, lang, namespace):
        self._default_namespace_ids[lang] = namespace

    def createDatasetHandler(self, publicId, systemId, namespace):
        dataset = self.resolver.getDataset(publicId, systemId, namespace)
        if not dataset:
            handler = EmptyDatasetHandler()
        else:
            handler = DataSetHandler(namespace, dataset)
        if namespace:
            self.handlers[namespace] = handler
        if publicId or systemId:
            self.handlers[(publicId, systemId)] = handler

        return handler

    def getDocumentHandler(self, publicId=None, systemId=None, namespace=None):
        if namespace:
            if namespace not in self.handlers:
                handler = self.createDatasetHandler(
                    publicId, systemId, namespace)
            else:
                handler = self.handlers.get(namespace)
            if handler:
                return handler
        if publicId or systemId:
            key = (publicId, systemId)
            if key not in self.handlers:
                handler = self.createDatasetHandler(
                    publicId, systemId, namespace)
            else:
                handler = self.handlers.get(key)
            if handler:
                return handler
        return EmptyDatasetHandler()

__datasetSvc = None


def getService():
    global __datasetSvc
    if not __datasetSvc:
        __datasetSvc = DatasetHandlerService()
    return __datasetSvc


def get_tree_handler(tree, node=None, default=None):
    # if we have a namespace, use it,  otherwise, fallback to the doctype
    namespace = None
    if node is None:
        node = tree.root
    if node is not None:
        namespace = tree.namespace(node)
    log.info("getting handler for (%s,%s,%s)" %
             (tree.publicId, tree.systemId, namespace))
    # print "getDocumentHandler (%s,%s,%s)"%(tree.publicId, tree.systemId,
    # namespace)
    publicId = tree.publicId
    systemId = tree.systemId
    if not (publicId or systemId or namespace) and default:
        # print "using defaults %r" % (default,)
        publicId = default[0]
        systemId = default[1]
        namespace = default[2]
    return getService().getDocumentHandler(publicId, systemId, namespace)

if __name__ == "__main__":
    import sys
    import os
    # basic logging configuration
    console = logging.StreamHandler()
    console.setLevel(logging.INFO)
    # set a format which is simpler for console use
    formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')
    # tell the handler to use this format
    console.setFormatter(formatter)
    # add the handler to the root logger
    logging.getLogger('').addHandler(console)

    # utility functions for testing, these are *SIMILAR* to codeintel lang_xml
    default_completion = {'HTML': ('-//W3C//DTD XHTML 1.0 Strict//EN',
                                   'http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd',
                                   'http://www.w3.org/1999/xhtml')}

    def getDefaultCompletion(tree, node, lang):
        if lang == "XSLT":
            if node is not None and not tree.namespace(node):
                # do we have an output element, if so, figure out if we're html
                # cheap way to get the output element
                output = tree.tags.get(
                    'http://www.w3.org/1999/XSL/Transform', []).get('output')
                if output is not None:
                    lang = output.attrib.get('method').upper()
                    publicId = output.attrib.get('doctype-public')
                    systemId = output.attrib.get('doctype-system')
                    default_dataset_info = default_completion.get(lang)
                    if publicId or systemId:
                        default_dataset_info = (
                            publicId, systemId, default_dataset_info[2])
                return default_dataset_info
            return None
        return default_completion.get(lang)

    def getValidTagNames(text, uri=None, lang=None):
        """getValidTagNames
        return a list of valid element names that can be inserted at the end
        of the text segment
        """
        tree = koXMLTreeService.getService().getTreeForURI(uri, text)
        default_dataset_info = getDefaultCompletion(tree, tree.current, lang)
        handlerclass = get_tree_handler(
            tree, tree.current, default_dataset_info)
        tagnames = handlerclass.tagnames(tree)
        if not tagnames:
            return None
        tagnames.sort()
        return tagnames

    def getOpenTagName(text, uri=None):
        """getOpenTagName
        return the current tag name
        """
        tree = koXMLTreeService.getService().getTreeForURI(uri, text)
        if tree.current is None:
            return None
        return tree.tagname(tree.current)

    def getValidAttributes(text, uri=None, lang=None):
        """getValidAttributes
        get the current tag, and return the attributes that are allowed in that
        element
        """
        tree = koXMLTreeService.getService().getTreeForURI(uri, text)
        if tree.current is None:
            return None
        already_supplied = tree.current.attrib.keys()
        handlerclass = get_tree_handler(
            tree, tree.current, default_completion.get(lang))
        attrs = handlerclass.attrs(tree)
        if not attrs:
            return None
        attrs = [name for name in attrs if name not in already_supplied]
        attrs.sort()
        return attrs

    def getValidAttributeValues(text, attr, uri=None, lang=None):
        """getValidAttributeValues
        get the current attribute, and return the values that are allowed in that
        attribute
        """
        tree = koXMLTreeService.getService().getTreeForURI(uri, text)
        if tree.current is None:
            return None
        handlerclass = get_tree_handler(
            tree, tree.current, default_completion.get(lang))
        values = handlerclass.values(attr, tree)
        if not values:
            return None
        values.sort()
        return values

    # configure catalogs to use
    basedir = os.path.dirname(os.path.dirname(os.getcwd()))
    catalogs = os.path.join(basedir, "test", "stuff", "xml")
    getService().setCatalogs([os.path.join(catalogs, "testcat.xml")])

    from cElementTree import Element
    tree = koXMLTreeService.XMLDocument()
    tree.root = tree.current = Element('')
    handlerclass = get_tree_handler(tree, tree.current)
    assert handlerclass != None, "no handler class for empty tree"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="html" indent="yes"/>
  <html> <
"""
    tags = getValidTagNames(xml, lang="XSLT")
    assert tags == ['body', 'head'], \
        "invalid output tags for stylesheet"

    xml = "<"
    assert getValidTagNames(xml) == None, "invalid children for html"

    xml = """<html>
    <body>
        <scr"""
    assert "script" in getValidTagNames(
        xml, lang="HTML"), "invalid children for body"

    html = """<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">"""
    # XXX this should only be html, have to figure out why area is there.
    tags = getValidTagNames(html)
    assert tags == ["html"], "invalid children for doc root"

    xml = """<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE window PUBLIC "-//MOZILLA//DTD XUL V1.0//EN" "http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul">
<window xmlns="http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul">
    <popupset id="editorTooltipSet">
        <popup type="tooltip" id="editorTooltip" flex="1">
            <description multiline="true" id="editorTooltip-tooltipText" class="tooltip-label" flex="1"/>
        </popup><
        <popup type="autocomplete" id="popupTextboxAutoComplete"/>
    </popupset>

"""
    tags = getValidTagNames(xml)
    assert tags == ["popup"], "invalid children for popupset %r" % tags

    xml = """<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
"""
    # lets get the next valid element
    assert getValidTagNames(xml) == [
        'body', 'head'], "invalid children for html tag"

    xml = """<

<?php
?>
"""
    tags = getValidTagNames(xml, lang="HTML")
    assert tags == ['html'], "invalid attributes for html tag"

    xml = """<html """
    attrs = getValidAttributes(xml, lang="HTML")
    assert attrs == ['dir', 'id', 'lang'], "invalid attributes for html tag"

    xml = """<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html """
    attrs = getValidAttributes(xml)
    assert attrs == ['dir', 'id', 'lang'], "invalid attributes for html tag"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>
  <xsl:

  <xsl:template/>
"""
    assert getValidTagNames(xml) == ['attribute-set', 'decimal-format', 'import', 'include', 'key', 'namespace-alias', 'output', 'param', 'preserve-space', 'strip-space', 'template', 'variable'], \
        "invalid children tags for stylesheet"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>
  <xsl:template"""
    assert getValidAttributes(xml) == ['match', 'mode', 'name', 'priority'], \
        "invalid attributes for template"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>
  <xsl:"""
    assert getValidTagNames(xml) == ['attribute-set', 'decimal-format', 'import', 'include', 'key', 'namespace-alias', 'output', 'param', 'preserve-space', 'strip-space', 'template', 'variable'], \
        "invalid children for stylesheet"

    # test getting custom tags from the default namespace
    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>
  <mycustomtag>
  <

  <xsl:template/>
"""
    assert getValidTagNames(xml) == ['mycustomtag'], \
        "invalid children for mycustomtag"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/><xsl:
  <xsl:template/>
</xsl:stylesheet>
"""
    assert getValidTagNames(xml) == ['attribute-set', 'decimal-format', 'import', 'include', 'key', 'namespace-alias', 'output', 'param', 'preserve-space', 'strip-space', 'template', 'variable'], \
        "invalid children for stylesheet"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>

  <xsl:template>
  </xsl:template><xsl:

  <xsl:template>
  </xsl:template>
</xsl:stylesheet>
"""
    assert getValidTagNames(xml) == ['attribute-set', 'decimal-format', 'import', 'include', 'key', 'namespace-alias', 'output', 'param', 'preserve-space', 'strip-space', 'template', 'variable'], \
        "invalid children for stylesheet"

########NEW FILE########
__FILENAME__ = koXMLTreeService
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

import time
import re
from cElementTree import TreeBuilder, XMLParser, Element
import logging
log = logging.getLogger("koXMLTreeService")
# log.setLevel(logging.INFO)


class recollector:
    def __init__(self):
        self.res = {}
        self.regs = {}

    def add(self, name, reg, mods=None):
        self.regs[name] = reg % self.regs
        # print "%s = %s" % (name, self.regs[name])
        if mods:
            self.res[name] = re.compile(self.regs[
                                        name], mods)  # check that it is valid
        else:
            self.res[name] = re.compile(self.regs[
                                        name])  # check that it is valid

collector = recollector()
a = collector.add

a("S", "[ \\n\\t\\r]+")
a("NameStrt", "[A-Za-z_:]|[^\\x00-\\x7F]")
a("NameChar", "[A-Za-z0-9_:.-]|[^\\x00-\\x7F]")
a("Name", "(?:%(NameStrt)s)(?:%(NameChar)s)*")
a("AttValSE", "\"[^<\"]*\"|'[^<']*'")
a("attrfinderRE", "(?:[\n \t]*)(%(Name)s)(?:%(S)s)?=(?:%(S)s)?(%(AttValSE)s)")
a("namespaces",
  'xmlns(?::(?P<prefix>\w+))?=(?P<ns>(?:")([^"]*?)(?:")|(?:\')([^\']*?)(?:\'))', re.S | re.U)
a("tagpart",
  '(?:<(?![?!-/>\s]))((?:(?P<prefix>[^\s/>]+):)?(?P<name>[^:\s/>]+)?)(?:\s+(?P<data>[^/<>]*))?', re.S | re.U)
a("tags", '<!--.*?-->|%(tagpart)s(?:/)?>', re.S | re.U)
a("alltags", '<!--.*?-->|(<[^\[!>?-].*?>)', re.S | re.U)
a("QuoteSE", "\"[^\"]*\"|'[^']*'")
a("DOCTYPE",
  r'<!DOCTYPE\s+(?P<type>\S+)\s+(?P<ident>PUBLIC|SYSTEM)\s+(?P<data1>%(QuoteSE)s)\s*(?P<data2>%(QuoteSE)s)?\s*(?:\[|>)', re.S)


def getdoctype(text):
    doctype = None
    regex = collector.res["DOCTYPE"]
    m = regex.search(text)
    if m:
        m = m.groupdict()
        # [1:-1] is to strip quotes
        if m['data1']:
            m['data1'] = m['data1'][1:-1]
        if m['data2']:
            m['data2'] = m['data2'][1:-1]
        if m['ident'] == 'PUBLIC':
            doctype = (m['type'], m['ident'], m['data1'], m['data2'])
        else:
            doctype = (m['type'], m['ident'], "", m['data1'])
    return doctype


def getattrs(text):
    attrs = {}
    regex = collector.res["attrfinderRE"]
    match = regex.findall(text)
    for a in match:
        if a[1]:
            attrs[a[0]] = a[1][1:-1]
        else:
            attrs[a[0]] = ""
    return attrs


def currentTag(text):
    m = collector.res["tagpart"].search(text)
    if not m:
        return None
    td = m.groupdict()
    ad = {}
    if td['data']:
        ad.update(getattrs(td['data']))
    return (td['prefix'], td['name'], ad, m.start(0))


def elementFromTag(tree, tag, parent=None):
    tagName = tag[1]
    if not tagName:
        tagName = ""
    ns = None
    if tag[0]:
        if tag[0] in tree.prefixmap:
            ns = tree.prefixmap[tag[0]]
        else:
            nsattr = "xmlns:%s" % tag[0]
            if nsattr in tag[2]:
                ns = tag[2][nsattr]
                del tag[2][nsattr]
                tree.prefixmap[tag[0]] = ns
    elif "xmlns" in tag[2]:
        ns = tag[2]["xmlns"]
        del tag[2]["xmlns"]
    elif parent is not None:
        ns = parent.ns
    localName = tag
    if ns:
        tagName = "{%s}%s" % (ns, tagName)
    elem = Element(tagName, tag[2])
    try:
        elem.start = tree.err_info
        elem.end = None
    except:
        # will happen when parsing with cElementTree
        pass
    # print elem.localName
    if parent is not None:
        parent.append(elem)
    tree.nodemap[elem] = parent
    tree.nodes.append(elem)
    if elem.ns is not None:
        if elem.ns not in tree.tags:
            tree.tags[elem.ns] = {}
        tree.tags[elem.ns][elem.localName] = elem
    return elem


def elementFromText(tree, text, parent=None):
    current = currentTag(text)
    if current:
        return elementFromTag(tree, current, parent)
    return None


class iterparse:
    """iterparse that catches syntax errors so we can still handle any
    events that happen prior to the syntax error"""
    def __init__(self, content, events=("start", "end", "start-ns", "end-ns")):
        self.content = content
        self._events = events
        self.err = None
        self.err_info = None
        self.root = None

    def __iter__(self):
        events = []
        b = TreeBuilder()
        p = XMLParser(b)
        p._setevents(events, self._events)
        try:
            p.feed(self.content)
        except SyntaxError, e:
            self.err = e
            self.err_info = (
                p.CurrentLineNumber, p.CurrentColumnNumber, p.CurrentByteIndex)

        for event in events:
            yield event
        del events[:]
        try:
            self.root = p.close()
        except SyntaxError, e:
            # if we had a previous syntax error, keep it
            if not self.err:
                self.err = e
                self.err_info = (
                    p.CurrentLineNumber, p.CurrentColumnNumber, p.CurrentByteIndex)
        for event in events:
            yield event


def bisect_left_nodes_start(a, x, lo=0, hi=None):
    """A version of bisect.bisect_left which compares nodes based on their start position.
    """
    if hi is None:
        hi = len(a)
    while lo < hi:
        mid = (lo+hi)//2
        # print "comparing", a[mid].start[:2], "and", x
        if a[mid].start is None:
            return mid
        if a[mid].start[:2] == x: return mid
        if a[mid].start[:2] < x: lo = mid+1
        else:
            hi = mid
    return lo


class XMLDocument(object):

    def __init__(self, content=None):
        self.content = content
        self.reset()
        if self.content:
            self.getDoctype()

    def getDoctype(self):
        self.doctype = getdoctype(self.content)
        if self.doctype:
            self.publicId = self.doctype[2]
            self.systemId = self.doctype[3]

    def reset(self):
        self.doctype = None
        self.publicId = None
        self.systemId = None
        self.err = None
        self.err_info = None
        self.root = None
        self.current = None

        self._rootnodes = []
        self.nodes = []  # flat list of all nodes
        self.tags = {}  # { namespace_uri: { tag_local_name: elem, ...} , ...}
        self.nodemap = {}  # {child_elem: parent_elem, ... }
        self.namespaces = []  # flat list of namespace uri's
        self.nsmap = {}  # { "http:/...": "xslt", ... }
        self.prefixmap = {}  # { "xslt": "http://.....", ... }

    def getRoots(self):
        # return a list of all nodes that have no parent
        if not self._rootnodes:
            self._rootnodes = [
                node for node in self.nodemap if self.nodemap[node] is None]
        return self._rootnodes

    def namespace(self, elem):
        # print "%s:%s xmlns[%s]"%(self.prefix(elem),elem.localName,elem.ns)
        if hasattr(elem, "ns") and elem.ns:
            return elem.ns
        return self.nsmap.get("")

    def parent(self, elem):
        return self.nodemap.get(elem)

    def qname(self, name):
        if name and name[0] == '{':
            ns, ln = name[1:].split('}')
            prefix = self.nsmap.get(ns)
            if prefix:
                return "%s:%s" % (prefix, ln)
            return ln
        return name

    def isAncestorOf(self, node, child):
        """ Return true if child is a descendant of node """
        # print "asking if %r is an ancestor of %r" %( node, child)
        currentParent = self.parent(child)
        while currentParent != child and currentParent is not None:
            # print "\tparent =", currentParent
            if node == currentParent:
                # print "-->is a parent"
                return True
            currentParent = self.parent(currentParent)
        # print "-->isn't a parent"
        return False

    def locateNode(self, line, col):
        # nodes are 1-indexed, so we need to switch our indexing scheme
        line += 1

        # first look for the last node to start at or before the current
        # position
        idx = bisect_left_nodes_start(self.nodes, (line, col))-1
        if idx < 0:
            if self.nodes:
                return self.nodes[0]
            return None
        assert idx < len(self.nodes)
        node = self.nodes[idx]
        # that was easy.  Now we may need to move up the parent chain
        # from this node if we are past the end of a node but before
        # the beginning of another, e.g.  <foo><bar>asd</bar>|</foo>
        # -- the right node is foo, but the current value of node is 'bar'
        startPos = node.start[:2]
        if startPos is None:  # if we're in a partial node, that's it
            return node
        if startPos[:2] == (line, col):  # if it's an exact match, that's it
            return node
        # if idx == 0: return node # if we're at the toplevel, so be it
        while node is not None:
            while node.end:
                # move up the parent chain until you get a parent
                # whose end is after the current location
                last_line, last_col = node.end[:2]
                if (last_line, last_col) < (line, col):
                    node = self.parent(node)
                    if node is None:
                        return node
                    continue
                break

            if node is not None and not node.end:
                # check it's parents and see if they have end markers
                pnode = self.parent(node)
                while pnode:
                    if pnode.end:
                        last_line, last_col = pnode.end[:2]
                        if (last_line, last_col) < (line, col):
                            node = pnode
                            break
                    pnode = self.parent(pnode)
                if node.end:
                    continue
            break

        return node

    def prefixFromNS(self, ns):
        if self.prefixmap.get("") == ns:
            return ""
        prefix = self.nsmap.get(ns)
        if not prefix:
            prefix = self.nsmap.get(self.root.ns)
        return prefix

    def prefix(self, elem):
        if not hasattr(elem, "ns") or not elem.ns:
            return ""
        return self.prefixFromNS(elem.ns)

    def tagname(self, elem):
        prefix = self.prefix(elem)
        if prefix:
            return "%s:%s" % (prefix, elem.localName)
        return elem.localName

    _endtagRe = re.compile(r"(</(\w+:)?\w+>)", re.U)

    def parse(self, content=None):
        self.reset()
        self.content = content
        if content:
            # first, find the doctype decl
            self.getDoctype()
        elif not self.content:
            raise Exception("no content to parse")

        elstack = [None]
        self.current = None
        tags = {}
        last_pos_ok = None
        iter = iterparse(self.content)
        for event, elem in iter:
            if event == "start":
                # print "%r %r %d %d %d" % (event, elem, elem.start[0],
                # elem.start[1], elem.start[2])
                self.nodemap[elem] = self.current
                self.nodes.append(elem)
                if elem.ns not in self.tags:
                    self.tags[elem.ns] = {}
                self.tags[elem.ns][elem.localName] = elem
                elstack.append(elem)
                self.current = elem
            elif event == "end":
                # print "%r %r %r %r" % (event, elem, elem.start, elem.end)
                if elem.end:
                    try:
                        pos = elem.end[2]
                        # print "  len %d pos %d" % (len(self.content), pos)
                        # put the end location at the end of the end tag
                        m = self._endtagRe.match(self.content[pos:])
                        if m and m.groups():
                            pos = pos + m.end(1)
                            if pos > 0:
                                # we want to be after the ">"
                                diff = pos - elem.end[2] + 1
                                elem.end = (elem.end[
                                            0], elem.end[1] + diff, pos)
                    except IndexError, e:
                        # XXX FIXME BUG 56337
                        log.exception(e)
                        pass
                node = elstack.pop()
                if elstack[-1] is None:
                    self._rootnodes.append(node)
                self.current = elstack[-1]
            elif event == "start-ns":
                self.namespaces.append(elem)
                self.prefixmap[elem[0]] = elem[1]
                self.nsmap[elem[1]] = elem[0]
            elif event == "end-ns":
                self.namespaces.pop()
        self.root = iter.root
        self.err = iter.err
        self.err_info = iter.err_info
        # set the root if we can
        if self.root is None and self.nodes:
            self.root = self.nodes[0]
        self.end_error(self.content)
        # if we still do not have a root, do it
        # now, as we should have a node
        if self.root is None and self.nodes:
            self.root = self.nodes[0]
        # release content
        self.content = None

    def end_error(self, content):
        if not self.err_info:
            return
        if not content:
            raise Exception("No content?")
        # create an element for the last part of the parse
        parent = self.current
        if self.err_info[2] >= 0:
            start = self.err_info[2]
        else:
            # slower
            # print self.err_info
            p = 0
            for i in range(self.err_info[0] - 1):
                # use re.search("\r|\n|\r\n")
                p = content.find("\n", p + 1)
            start = p + self.err_info[1] + 1
        end = content.find("<", start+1)
        if end <= start:
            end = len(content)
        # fixup the start position
        start = content.rfind(">", 0, start) + 1
        if start >= end:
            return
        # print self.err_info
        # print content[start:end]
        current = currentTag(content[start:end])
        if not current:
            return

        # print "%s:%s %r %d" % current
        # fix error info
        start = start+current[3]
        line = content.count('\n', 0, start)
        col = start - content.rfind('\n', 0, start)
        self.err_info = (line, col, start)
        self.current = elem = elementFromTag(self, current, parent)

    def dump(self):
        print "error ", self.err
        print "error_info ", self.err_info
        print "%d nodes created" % len(self.nodemap)
        print "doctype ", self.doctype
        print "publicId ", self.publicId
        print "systemId ", self.systemId
        print self.prefixmap
        print self.nsmap
        print "root ", self.root
        if self.root:
            print "root tag ", self.root.tag
            print "root ns ", self.root.ns
            print "root localName ", self.root.localName
            print "root start ", self.root.start
            print "root end ", self.root.end
        print "tree.current ", self.current

import HTMLTreeParser


class HTMLDocument(XMLDocument):

    def parse(self, content=None):
        if content:
            self.reset()
            self.content = content
            # first, find the doctype decl
            self.getDoctype()
        elif not self.content:
            raise Exception("no content to parse")

        p = HTMLTreeParser.Parser(HTMLTreeParser.HTMLTreeBuilder())
        p.feed(content)
        self.root = p.close()
        self.nodes = p._builder.nodes
        self.nodemap = p._builder.nodemap
        self._rootnodes = p._builder._rootnodes
        self.current = p._builder.current


class TreeService:
    __treeMap = {}  # map uri to elementtree

    def __init__(self):
        pass

    def treeFromCache(self, uri):
        if uri in self.__treeMap:
            # print "tree cache hit for [%s]"%uri
            return self.__treeMap[uri]
        return None

    def getTreeForURI(self, uri, content=None):
        if not uri and not content:
            return None
        tree = None
        if uri and uri in self.__treeMap:
            tree = self.__treeMap[uri]
            # if tree is not None:
            #    print "tree cache hit for [%s]"%uri
            if not content:
                return tree

        if not tree:
            if not content:
                # get the content
                try:
                    f = open(uri, 'r')
                    content = f.read(-1)
                    f.close()
                except IOError, e:
                    # ignore file errors and return an empty tree
                    content = ""
            if not content.startswith("<?xml"):
                tree = HTMLDocument()
            if not tree:
                tree = XMLDocument()
                # raise Exception("NOT IMPLEMENTED YET")
        if content:
            tree.parse(content)
        if uri:
            self.__treeMap[uri] = tree
        return tree

    def getTreeForContent(self, content):
        return self.getTreeForURI(None, content)


__treeservice = None


def getService():
    global __treeservice
    if not __treeservice:
        __treeservice = TreeService()
    return __treeservice

if __name__ == "__main__":
    import sys
    # basic logging configuration
    console = logging.StreamHandler()
    console.setLevel(logging.INFO)
    # set a format which is simpler for console use
    formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')
    # tell the handler to use this format
    console.setFormatter(formatter)
    # add the handler to the root logger
    logging.getLogger('').addHandler(console)

    bigfile = "/Users/shanec/main/Apps/Komodo-devel/test/bigfile.xml"
    fn = "/Users/shanec/main/Apps/Komodo-devel/src/samples/xslt_sample.xsl"
    from elementtree.ElementTree import tostring

    if 0:
        # fn = "/Users/shanec/main/Apps/Komodo-devel/src/install/wix/feature-
        # core.wxs"
        t1 = time.clock()
        tree = getService().getTreeForURI(bigfile)
        t2 = time.clock()
        print "cElementTree took ", (t2-t1)
        tree.dump()

    if 0:
        f = open(bigfile, 'r')
        content = f.read(-1)
        f.close()
        t1 = time.clock()
        tree = HTMLDocument()
        tree.parse(content)
        t2 = time.clock()
        print "HTMLBuilder took ", (t2-t1)

    if 0:
        print currentTag("<xsl")
        print currentTag("<xsl:")
        print currentTag("<xsl:tag")
        print currentTag("text><xsl:tag")
        # print nodemap

    html = """<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
"""
    tree = getService().getTreeForURI("Text.html", html)
    print tostring(tree.root)

    html = u"""<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<HEAD>
 <TITLE>Mozilla Cross-Reference</TITLE>
 <link HREF=http://www.activestate.com/global.css rel="stylesheet" type="text/css">
</HEAD>
<BODY   BGCOLOR="#FFFFFF" TEXT="#000000"
	LINK="#0000EE" VLINK="#551A8B" ALINK="#FF0000">

<table width="100%" border="0" cellspacing="0" cellpadding="0">
  <tr>
    <td>
      <table width="100%" border="0" cellspacing="0" cellpadding="0">
        <tr>
          <td width="145"><a href=http://www.activestate.com/index.html><img src=http://www.activestate.com/img/Main_Logo_Border.gif width="167" height="66" border="0" alt="ActiveState Tool Corp."></a></td>
          <td bgcolor="#000000" colspan=2 width="90%" align="center"><img src=http://www.activestate.com/img/Main_Banner.gif alt="Programming for the People."></td>
        </tr>
      </table>
      <table width="100%" bgcolor="#000000" border="0" cellpadding="0" cellspacing="0">
 <tr>
  <td width="600">
    <table width="600" border="0" cellpadding="0" cellspacing="3">
     <tr>
       <td class="mainnav" bgcolor="#C2B266" width="100" align="center"><a href=http://www.activestate.com/Products/index.html>Products</a></td>
       <td class="mainnav" bgcolor="#C2B266" width="100" align="center"><a href=http://www.activestate.com/Support/index.html>Support</a></td>
       <td class="mainnav" bgcolor="#C2B266" width="100" align="center"><a href=http://www.activestate.com/Corporate/index.html>About Us</a></td>
       <td class="mainnav" bgcolor="#C2B266" width="100" align="center"><a href=http://www.activestate.com/Contact_Us.html>Contact</a></td>
       <td class="mainnav" bgcolor="#C2B266" width="100" align="center"><a href=http://www.activestate.com/Site_Map.html>Site Map</a></td>
     </tr>
    </table>
   </td>
   <td class="mainnav" width="100%">
     <table width="100%" border="0" cellpadding="0" cellspacing="0">
       <tr>
         <td class="mainnav" bgcolor="#C2B266" width="100%">&nbsp;</td>
         <td class="mainnav" bgcolor="#000000" width="3">&nbsp;</td>
       </tr>
     </table>
  </td>
 </tr>
</table>
</td>
</tr>
</table>

<I>$treename</I>
<P>

"""
    tree = getService().getTreeForURI("Text.html", html)
    print tostring(tree.root)

    html = """<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<HTML>
    <BODY>

        <FORM><FIELDSET ><SELECT class=""><OPTGROUP >

"""
    tree = getService().getTreeForContent(html)

    tree = getService().getTreeForURI("newfile.txt", "")
    tree = getService().getTreeForURI("newfile.txt", "<html>")
    tree = getService().getTreeForURI("newfile.txt", "<html> <")
    node = tree.locateNode(tree.current.start[0], tree.current.start[1])
    assert node == tree.current, "locateNode returned incorrect node"

    tree = getService().getTreeForURI("newfile.txt", "<table></table>\n\n\n\n")
    node = tree.locateNode(2, 0)
    assert node is None, "locateNode returned incorrect node"
    node = tree.locateNode(0, 7)
    assert node is not None, "locateNode returned incorrect node"
    sys.exit(0)

    xml = """
<c1><c2 a1="1" a2='1' a3='val'><e1 /><e2 f1="1" f2 = '33' /><c3 a='1'>blah</c3></c2  >  </"""
    tree = getService().getTreeForContent(xml)
    node = tree.locateNode(tree.current.start[0], tree.current.start[1])
    assert node == tree.current, "locateNode returned incorrect node"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xxmlns="xyz" xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>
<xsl:template match="Class">
    <html> <xsl:apply-imports/>
    <xsl:
            <xsl:apply-templates select="Order"/>
    </html>
</xsl:template>
"""
    tree = getService().getTreeForContent(xml)
    node = tree.locateNode(tree.current.start[0], tree.current.start[1])
    assert node == tree.current, "locateNode returned incorrect node"

    # ensure we get the correct current node
    xml = """<?xml version="1.0"?>
<!DOCTYPE window PUBLIC "-//MOZILLA//DTD XUL V1.0//EN" "http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul">
<window xmlns="http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul">
    <popupset id="editorTooltipSet">
        <popup type="tooltip" id="editorTooltip" flex="1">
            <description multiline="true" id="editorTooltip-tooltipText" class="tooltip-label" flex="1"/>
        </popup><
        <popup type="autocomplete" id="popupTextboxAutoComplete"/>
    </popupset>

"""
    tree = getService().getTreeForContent(xml)
    assert tree.current.localName == "popupset", "current element is incorrect"

    # ensure we get the correct current node
    xml = """<?xml version="1.0"?>
<!DOCTYPE window PUBLIC "-//MOZILLA//DTD XUL V1.0//EN" "http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul">
<window xmlns="http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul">
    <popupset id="editorTooltipSet">
        <popup type="tooltip" id="editorTooltip" flex="1">
            <description multiline="true" id="editorTooltip-tooltipText" class="tooltip-label" flex="1"/>
        </popup> <
        <popup type="autocomplete" id="popupTextboxAutoComplete"/>
    </popupset>

"""
    tree = getService().getTreeForContent(xml)
    assert tree.current.localName == "popupset", "current element is incorrect"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>
  <

  <xsl:template/>
"""
    tree = getService().getTreeForContent(xml)
    assert tree.current == tree.root, "current element is incorrect"
    assert tree.current.localName == "stylesheet", "current element is incorrect"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>
  <xsl:"""
    tree = getService().getTreeForContent(xml)
    assert tree.current.tag == "{http://www.w3.org/1999/XSL/Transform}", "current element is incorrect"
    assert tree.current.localName == "", "current element is incorrect"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>
"""
    tree = getService().getTreeForContent(xml)
    assert tree.current.localName == "stylesheet", "current element is incorrect"

    xml = """<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html """

    tree = getService().getTreeForContent(xml)
    assert tree.current.localName == "html", "current element is incorrect"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>
  <xsl:template
"""
    tree = getService().getTreeForContent(xml)
    assert tree.current.localName == "template", "current element is incorrect"

    xml = """<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/><xsl:template"""
    tree = getService().getTreeForContent(xml)
    assert tree.current.localName == "template", "current element is incorrect"

    xml = u"""<?xml version="1.0"?>
<xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
  <xsl:output method="xml" indent="yes"/>
  <xsl:

  <xsl:template/>
"""
    tree = getService().getTreeForContent(xml)
    assert tree.current.localName == "", "current element is incorrect"
    assert tree.current.tag == "{http://www.w3.org/1999/XSL/Transform}", "current element is incorrect"

    html = """<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><body><p><ul><li><li><li></ul></body>
"""
    tree = getService().getTreeForContent(html)
    # print tostring(tree.root)
    assert tree.current.localName == "html", "current element is incorrect"

    html = """<!DOCTYPE h:html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<h:html xmlns:h='urn:test'"""
    tree = getService().getTreeForContent(html)
    # print tostring(tree.root)
    assert tree.current.localName == "html", "current element is incorrect"

    # from cElementTree import Element
    # tag = u"{urn:test}test"
    # print tag
    # e = Element(tag, {})
    # print e.localName
    # print e.tag

    xml = """<?xml version="1.0" encoding="UTF-8"?>
<!-- This sample XML file shows you ... -->

<Class>
<Order Name="TINAMIFORMES">
        <Family Name="TINAMIDAE">
            <Species attr="value">content.</Species>
            <![CDATA[
                This is a CDATA section
            ]]>
        </Family>
    </Order>
"""
    tree = getService().getTreeForContent(xml)
    # print tostring(tree.root)
    assert len(tree.root[0][0][0]) == 0, "bad parent/child relationship"

    xml = """<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
    <body
        <!-- a comment -->
    <title>
    </title>
</html>
"""

    tree = getService().getTreeForContent(xml)
    # print tostring(tree.root)
    assert tree.current.localName == "body", "current element is incorrect"
    assert tree.parent(
        tree.current).localName == "html", "current element is incorrect"

    xml = """<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html
    <body
"""

    tree = getService().getTreeForContent(xml)
    # print tostring(tree.root)
    assert tree.current.localName == "html", "current element is incorrect"

########NEW FILE########
__FILENAME__ = langinfo
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

r"""Database of static info for (text) languages (e.g. Python, Perl, ...).

Basic usage:

    >>> import langinfo
    >>> py = langinfo.langinfo_from_lang("Python")
    >>> py.name
    'Python'
    >>> py.exts
    ['.py', '.pyw']
    >>> py.is_text
    True

Advanced usage:

    >>> lidb = langinfo.Database()
    >>> lidb.langinfo_from_lang("HTML")
    <HTML LangInfo>
    >>> db.langinfo_from_filename("Makefile")
    <Makefile LangInfo>
    >>> db.langinfo_from_ext(".pm")
    <Perl LangInfo>
    >>> db.langinfo_from_magic("#!/usr/bin/env ruby")
    <Ruby LangInfo>
    >>> db.langinfo_from_doctype(public_id="-//W3C//DTD HTML 4.01//EN")
    <HTML LangInfo>

The advanced usage allows one to customize how the langinfo database is
built. For example, specified 'dirs' will be searched for
'langinfo_*.py' files that can add to the database. (This can be used to
allow Komodo extensions to add/override language info.)
"""

# TODO:
# - add other Komodo languages
# - langinfo_komodo.py, langinfo_apple.py, langinfo_microsoft.py,
#   langinfo_adobe.py
# - Python: .pth, .egg-info
# - some XML langs to add:  DocBook, Atom, Dita,
#   RDF, RSS (various versions?), RelaxNG, XML Schema, XSLT.
#   ODF, UBL (these mentioned by Tim Bray, http://www.tbray.org/ongoing/When/200x/2006/01/08/No-New-XML-Languages)
#   others?
# TODO: .wiki (for google code)
# TODO: .*rc files?
# TODO: .cvsignore
# TODO: .pyx? .pxd? .pyd?  (see tm/check/contrib/pyyaml/ext/)
# TODO: .deb, .rpm
# - .phpt (in PHP tree)
# TODO: http://en.wikipedia.org/wiki/Adobe_Flash#Related_file_formats_and_extensions
# TODO: text .nib's, .plist, .pbxuser, .pbxproj, .m, .strings,
# TODO: "/Library/Application Support/Apple/Developer Tools/Quartz Composer/Clips/Cubic.qtz"
#      not recognized as "data", but it *is* by `file`.

__version_info__ = (1, 0, 0)
__version__ = '.'.join(map(str, __version_info__))

import os
from os.path import join, dirname, abspath, basename, exists
import sys
import re
from pprint import pprint
from glob import glob
import traceback
import logging
import optparse
import types
import struct
import warnings
import operator


#---- exceptions and warnings
class LangInfoError(Exception):
    pass


class InvalidLangInfoWarning(Warning):
    pass
warnings.simplefilter("once", InvalidLangInfoWarning)


#---- globals

log = logging.getLogger("langinfo")
# log.setLevel(logging.DEBUG)


#---- module API

def langinfo_from_lang(lang):
    return get_default_database().langinfo_from_lang(lang)


#---- base LangInfo definition
class LangInfo(object):
    """Base language info class. A subclass of LangInfo defines static
    information about a particular text language (e.g. Python, Perl,
    CSS, ...).

    The following are the "core" attributes for a LangInfo. Subclasses
    can feel free to define others, as makes sense for that language.
    """
    name = None     # a display name (i.e. appropriate for prose, display)

    # Used for identifying files of this language.
    exts = None
    filename_patterns = None
    magic_numbers = None
    doctypes = None
    specialization_hints_from_lang = None
    # Values for Emacs `mode` var or Vi modeline `ft' or `filetype',
    # other than `name', that identify lang.
    emacs_modes = None
    vi_filetypes = None

    # An optional key for specifying precedence for `magic_numbers`
    # usage. If not given the key is `(name, 0)`. Then, for example,
    # to ensure magic number checks before Python, one could set
    #   _magic_number_precedence = ('Python', -1)
    _magic_number_precedence = None

    # Some languages mandate a default encoding, e.g. for Python it is
    # ASCII, for XML UTF-8.
    default_encoding = None
    encoding_decl_pattern = None  # Regex matching an encoding declaration.

    # A set of lang names to which this language conforms. For example,
    # RDF conforms to XML. See `conforms_to()` below.
    #
    # This is based on the UTI (Uniform Type Identifier) conforms-to
    # idea from Mac OS X:
    #   http://arstechnica.com/reviews/os/macosx-10-4.ars/11
    #   http://developer.apple.com/macosx/uniformtypeidentifiers.html
    # http://developer.apple.com/documentation/Carbon/Conceptual/understanding_utis/understand_utis_intro/chapter_1_section_1.html
    conforms_to_bases = None

    # Misc. properties
    has_significant_trailing_ws = False

    def __init__(self, db):
        self._db = db

    def __repr__(self):
        return "<%s LangInfo>" % self.name

    @property
    def is_text(self):
        """Convenience property to check if this lang is plain text."""
        return self.conforms_to("Text")

    def conforms_to(self, lang):
        """Returns True iff this language conforms to the given `lang`."""
        if lang == self.name:
            return True
        if self.conforms_to_bases:
            if lang in self.conforms_to_bases:
                return True
            for base in self.conforms_to_bases:
                try:
                    base_li = self._db.langinfo_from_lang(base)
                except LangInfoError:
                    pass
                else:
                    if base_li.conforms_to(lang):
                        return True
        return False

    def conformant_attr(self, attr):
        """Returns the value of the given attr, inheriting from the
        `conforms_to_bases` languages if not directly defined for this
        language.
        """
        if hasattr(self, attr):
            val = getattr(self, attr)
            if val is not None:
                return val
        for base in self.conforms_to_bases or []:
            try:
                base_li = self._db.langinfo_from_lang(base)
            except LangInfoError:
                pass
            else:
                val = base_li.conformant_attr(attr)
                if val is not None:
                    return val
        return None


#---- LangInfo classes (most are defined in separate langinfo_*.py files)
class TextLangInfo(LangInfo):
    name = "Text"
    exts = ['.txt', '.text']
    filename_patterns = ["README", "COPYING", "LICENSE", "MANIFEST"]


def _generateFallbackKoLangInfo(langinfo_db, koLangInst):
    """Generate a LangInfo instance from the koILanguage instance."""
    class FallbackKoLangInfo(LangInfo):
        conforms_to_bases = ["Text"]
        default_encoding = "utf-8"

        def __init__(self, db, koLang):
            LangInfo.__init__(self, db)
            self.name = koLang.name
            if koLang.defaultExtension:
                self.exts = [koLang.defaultExtension]
    return FallbackKoLangInfo(langinfo_db, koLangInst)

#---- the Database


class Database(object):
    def __init__(self, dirs=None):
        self._langinfo_from_norm_lang = {}
        self._langinfo_from_ext = None
        self._langinfo_from_filename = None
        self._langinfo_from_filename_re = None
        self._magic_table = None
        self._li_from_doctype_public_id = None
        self._li_from_doctype_system_id = None
        self._li_from_emacs_mode = None
        self._li_from_vi_filetype = None
        self._li_from_norm_komodo_lang = None

        self._load()
        if dirs is None:
            dirs = []
        dirs.insert(0, dirname(__file__) or os.curdir)
        for dir in dirs:
            self._load_dir(dir)
        self.dirs = dirs

    def langinfos(self):
        for li in self._langinfo_from_norm_lang.values():
            yield li

    def langinfo_from_lang(self, lang):
        norm_lang = self._norm_lang_from_lang(lang)
        if norm_lang not in self._langinfo_from_norm_lang:
            raise LangInfoError("no info on %r lang" % lang)
        return self._langinfo_from_norm_lang[norm_lang]

    def langinfo_from_komodo_lang(self, komodo_lang, tryFallback=True):
        """Return a langinfo for the given Komodo language name.

        There are some minor differences in Komodo language names and
        those in langinfo (e.g. "Django" in Komodo vs "Django HTML
        Template" in langinfo).
        """
        if self._li_from_norm_komodo_lang is None:
            self._build_tables()
        norm_komodo_lang = self._norm_lang_from_lang(komodo_lang)
        if norm_komodo_lang in self._li_from_norm_komodo_lang:
            return self._li_from_norm_komodo_lang[norm_komodo_lang]
        elif norm_komodo_lang in self._langinfo_from_norm_lang:
            return self._langinfo_from_norm_lang[norm_komodo_lang]
        elif tryFallback:
            # If a koILanguage exists for this lang, then create a fallback
            # langinfo for it - this occurs when a user has defined an add-on or
            # language, but they haven't made a langinfo.py for it.
            try:
                from xpcom import components
            except ImportError:
                pass  # no xpcom
            else:
                langSvc = components.classes["@activestate.com/koLanguageRegistryService;1"] \
                    .getService(components.interfaces.koILanguageRegistryService)
                # Note: When the language does not exist, we get a fallback of
                #       koILang.Text
                koLang = langSvc.getLanguage(komodo_lang)
                if koLang is not None and koLang.name in (komodo_lang, norm_komodo_lang):
                    # Someone's defined a koILanguage for this lang - create
                    # dummy langinfo for it.
                    log.warn(
                        "no LangInfo class found for %r, creating a fallback for it",
                        komodo_lang)
                    self._langinfo_from_norm_lang[
                        norm_komodo_lang] = _generateFallbackKoLangInfo(self, koLang)
                    self._build_tables()
                    return self.langinfo_from_komodo_lang(komodo_lang, tryFallback=False)
        raise LangInfoError("no info on %r komodo lang" % komodo_lang)

    def langinfo_from_emacs_mode(self, emacs_mode):
        if self._li_from_emacs_mode is None:
            self._build_tables()
        if emacs_mode in self._li_from_emacs_mode:
            return self._li_from_emacs_mode[emacs_mode]
        norm_lang = self._norm_lang_from_lang(emacs_mode)
        if norm_lang in self._langinfo_from_norm_lang:
            return self._langinfo_from_norm_lang[norm_lang]

    def langinfo_from_vi_filetype(self, vi_filetype):
        if self._li_from_vi_filetype is None:
            self._build_tables()
        if vi_filetype in self._li_from_vi_filetype:
            return self._li_from_vi_filetype[vi_filetype]
        norm_lang = self._norm_lang_from_lang(vi_filetype)
        if norm_lang in self._langinfo_from_norm_lang:
            return self._langinfo_from_norm_lang[norm_lang]

    def langinfo_from_ext(self, ext):
        """Return an appropriate LangInfo for the given filename extension,
        or None.
        """
        if self._langinfo_from_ext is None:
            self._build_tables()
        if sys.platform in ("win32", "darwin"):  # Case-insensitive filesystems.
            ext = ext.lower()
        return self._langinfo_from_ext.get(ext)

    def langinfo_from_filename(self, filename):
        """Return an appropriate LangInfo for the given filename, or None."""
        if self._langinfo_from_filename is None:
            self._build_tables()
        if filename in self._langinfo_from_filename:
            return self._langinfo_from_filename[filename]
        else:
            for regex, li in self._langinfo_from_filename_re.items():
                if regex.search(filename):
                    return li

    def langinfo_from_magic(self, head_bytes, shebang_only=False):
        """Attempt to identify the appropriate LangInfo from the magic number
        in the file. This mimics some of the behaviour of GNU file.

        @param head_bytes {string} is a string of 8-bit char bytes or a
            unicode string from the head of the document.
        @param shebang_only {boolean} can be set to true to only process
            magic number records for shebang lines (a minor perf
            improvement).
        """
        if self._magic_table is None:
            self._build_tables()

        for magic_number, li, sort_key in self._magic_table:
            try:
                start, format, pattern = magic_number
            except ValueError:
                # Silently drop bogus magic number decls.
                continue
            if shebang_only and format != "regex":
                continue
            if format == "string":
                end = start + len(pattern)
                if head_bytes[start:end] == pattern:
                    return li
            elif format == "regex":
                if pattern.search(head_bytes, start):
                    return li
            else:  # a struct format
                try:
                    length = struct.calcsize(format)
                except struct.error, ex:
                    warnings.warn("error in %s magic number struct format: %r"
                                  % (li, format),
                                  InvalidLangInfoWarning)
                end = start + length
                bytes = head_bytes[start:end]
                if len(bytes) == length:
                    if struct.unpack(format, bytes)[0] == pattern:
                        return li

    def langinfo_from_doctype(self, public_id=None, system_id=None):
        """Return a LangInfo instance matching any of the specified
        pieces of doctype info, or None if no match is found.

        The behaviour when doctype info from multiple LangInfo classes
        collide is undefined (in the current impl, the last one wins).

        Notes on doctype info canonicalization:
        - I'm not sure if there is specified canonicalization of
          doctype names or public-ids, but matching is done
          case-insensitively here.
        - Technically doctype system-id comparison is of URI (with
          non-trivial but well-defined canonicalization rules). For
          simplicity we just compare case-insensitively.
        """
        if self._li_from_doctype_public_id is None:
            self._build_tables()

        if public_id is not None \
           and public_id in self._li_from_doctype_public_id:
            return self._li_from_doctype_public_id[public_id]
        if system_id is not None \
           and system_id in self._li_from_doctype_system_id:
            return self._li_from_doctype_system_id[system_id]

    def specialized_langinfo_from_content(self, li, text):
        hints, specialized_li = self._specialization_hints_from_lang.get(
            li.name, (None, None))
        if not hints:
            return None
        for hint_str, hint_re in hints:
            if hint_str not in text:
                continue
            if hint_re and not hint_re.search(text):
                continue
            return specialized_li
        return None

    def _build_tables(self):
        self._langinfo_from_ext = {}
        self._langinfo_from_filename = {}
        self._langinfo_from_filename_re = {}
        self._magic_table = []
            # list of (<magic-tuple>, <langinfo>, <sort-key>)
        self._li_from_doctype_public_id = {}
        self._li_from_doctype_system_id = {}
        self._li_from_emacs_mode = {}
        self._li_from_vi_filetype = {}
        self._li_from_norm_komodo_lang = {}
        self._specialization_hints_from_lang = {
        }  # <lang> -> (<hint>, <specialized-langinfo>)

        for li in self._langinfo_from_norm_lang.values():
            if li.exts:
                for ext in li.exts:
                    if not ext.startswith('.'):
                        log.warn("exts must start with '.': ext %r for "
                                 "lang %r", ext, li.name)
                    if sys.platform in ("win32", "darwin"):
                        ext = ext.lower()
                    do_replace = True
                    if ext in self._langinfo_from_ext:
                        current_li = self._langinfo_from_ext[ext]
                        variant = getattr(li, "is_minor_variant", None)
                        if variant is not None:
                            log.debug(
                                "ext update: ext: %s, %r is a minor variant of %r",
                                ext, li, current_li)
                        elif ext.startswith(".py"):
                            log.debug(
                                "ext update: ext: %s, %r is *not* a minor variant of %r",
                                ext, li, current_li)
                        if variant is not None and variant.name == current_li.name:
                            log.debug(
                                "ext update: found variant for ext %s, li:%r, using:%r",
                                ext, li, current_li)
                            do_replace = False
                        else:
                            variant = getattr(
                                current_li, "is_minor_variant", None)
                            if variant is None or variant.name != li.name:
                                log.debug("ext conflict: %r for %r conflicts "
                                          "with the same for %r (%r wins)", ext, li,
                                          self._langinfo_from_ext[ext], li)
                            else:
                                log.debug(
                                    "ext conflict: ext:%s, replace variant %r with %r",
                                    ext, current_li, li)
                    if do_replace:
                        self._langinfo_from_ext[ext] = li
            if li.filename_patterns:
                for pat in li.filename_patterns:
                    if isinstance(pat, basestring):
                        self._langinfo_from_filename[pat] = li
                    else:
                        self._langinfo_from_filename_re[pat] = li
            if li.magic_numbers:
                sort_key = li._magic_number_precedence or (li.name, 0)
                for mn in li.magic_numbers:
                    self._magic_table.append((mn, li, sort_key))
            if li.doctypes:
                for dt in li.doctypes:
                    try:
                        flavour, name, public_id, system_id = dt
                    except ValueError:
                        log.debug("invalid doctype tuple for %r: %r "
                                  "(dropping it)", li, dt)
                        continue
                    if public_id:
                        self._li_from_doctype_public_id[public_id] = li
                    if system_id:
                        self._li_from_doctype_system_id[system_id] = li
            if li.emacs_modes:
                for em in li.emacs_modes:
                    self._li_from_emacs_mode[em] = li
            if li.vi_filetypes:
                for em in li.vi_filetypes:
                    self._li_from_vi_filetypes[em] = li
            if hasattr(li, "komodo_name"):
                norm_komodo_lang = self._norm_lang_from_lang(li.komodo_name)
                self._li_from_norm_komodo_lang[norm_komodo_lang] = li
            if li.specialization_hints_from_lang:
                for lang, hint in li.specialization_hints_from_lang.items():
                    self._specialization_hints_from_lang[lang] = (hint, li)

        self._magic_table.sort(key=operator.itemgetter(2))

    def _norm_lang_from_lang(self, lang):
        return lang.lower()

    def _load(self):
        """Load LangInfo classes in this module."""
        for name, g in globals().items():
            if isinstance(g, (types.ClassType, types.TypeType)) \
               and issubclass(g, LangInfo) and g is not LangInfo:
                norm_lang = self._norm_lang_from_lang(g.name)
                self._langinfo_from_norm_lang[norm_lang] = g(self)

    def _load_dir(self, d):
        """Load LangInfo classes in langinfo_*.py modules in this dir."""
        for path in glob(join(d, "langinfo_*.py")):
            try:
                module = _module_from_path(path)
            except Exception, ex:
                log.warn("could not import `%s': %s", path, ex)
                # import traceback
                # traceback.print_exc()
                continue
            for name in dir(module):
                attr = getattr(module, name)
                if (not name.startswith("_")   # skip internal bases
                    and isinstance(attr, (types.ClassType, types.TypeType))
                    and issubclass(attr, LangInfo)
                        and attr is not LangInfo):
                    norm_lang = self._norm_lang_from_lang(attr.name)
                    self._langinfo_from_norm_lang[norm_lang] = attr(self)


#---- internal support stuff

_g_default_database = None
_g_default_dirs = None


def set_default_dirs(dirs):
    global _g_default_dirs, _g_default_database
    if dirs != _g_default_dirs:
        _g_default_dirs = dirs
        _g_default_database = None


def get_default_database():
    global _g_default_database, _g_default_database
    if _g_default_database is None:
        _g_default_database = Database(dirs=_g_default_dirs)
    return _g_default_database

# Recipe: module_from_path (1.0.1+)


def _module_from_path(path):
    import imp
    import os
    dir = os.path.dirname(path) or os.curdir
    name = os.path.splitext(os.path.basename(path))[0]
    iinfo = imp.find_module(name, [dir])
    return imp.load_module(name, *iinfo)


#---- self-test
def _test():
    import doctest
    doctest.testmod()

if __name__ == "__main__":
    _test()

########NEW FILE########
__FILENAME__ = langinfo_binary
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""LangInfo definitions for some binary file types."""

from langinfo import LangInfo


class ELFLangInfo(LangInfo):
    """ELF-format binary (e.g. a standard executable on Linux)"""
    name = "ELF"

    # From '/usr/share/file/magic':
    #   0	string		\177ELF		ELF
    magic_numbers = [(0, 'string', '\177ELF')]


class ArchiveLibLangInfo(LangInfo):
    """Archive library (ar)"""
    name = "ar"
    exts = [".a"]
    magic_numbers = [(0, 'string', '!<arch>')]


class MachOUniversalLangInfo(LangInfo):
    name = "Mach-O universal"

    # See '/usr/share/file/magic' for the full details on collision
    # between compiled Java class data and Mach-O universal binaries and
    # the hack to distinguish them.
    #   0	belong		0xcafebabe
    # TODO: check with a 64-bit Mach-O universal
    magic_numbers = [(0, '>L', int('0xcafebabe', 16))]


class MachOLangInfo(LangInfo):
    name = "Mach-O"

    # From '/usr/share/file/magic':
    #   0	lelong&0xfffffffe	0xfeedface	Mach-O
    #   0	belong&0xfffffffe	0xfeedface	Mach-O
    # Note: We are not current handling the '&0xfffffffe'.
    #
    # TODO: check with a 64-bit Mach-O
    magic_numbers = [(0, '<L', int('0xfeedface', 16)),
                     (0, '>L', int('0xfeedface', 16))]


class WindowsExeLangInfo(LangInfo):
    name = "Windows executable"
    exts = [".exe", ".dll"]

    # From '/usr/share/file/magic':
    #   0	string	MZ		MS-DOS executable (EXE)
    magic_numbers = [(0, "string", "MZ")]


class CompiledJavaClassLangInfo(LangInfo):
    name = "compiled Java class"
    exts = [".class"]
    # See MachOUniversalLangInfo above. There is a collision in the
    # magic number of Mach-O universal binaries and Java .class files.
    # For now we rely on the '.class' extension to properly identify
    # before magic number checking is done.
    magic_numbers = None


class ZipLangInfo(LangInfo):
    name = "Zip archive"
    exts = [".zip"]
    magic_numbers = [(0, "string", "PK\003\004")]


class GZipLangInfo(LangInfo):
    name = "gzip archive"
    exts = [".gz", ".tgz"]
    magic_numbers = [(0, "string", "\037\213")]


class BZip2LangInfo(LangInfo):
    name = "bzip2 compressed data"
    exts = [".bz2"]
    magic_numbers = [(0, "string", "BZh")]


class MSILangInfo(LangInfo):
    """Microsoft Installer Package"""
    name = "MSI"
    exts = [".msi"]


class JarLangInfo(ZipLangInfo):
    name = "Jar archive"
    exts = [".jar"]


class IcoLangInfo(LangInfo):
    name = "Windows icon"
    exts = [".ico"]


class IcnsLangInfo(LangInfo):
    name = "Mac icon"
    exts = [".icns"]


class XPMLangInfo(LangInfo):
    name = "XPM"
    exts = [".xpm"]
    magic_numbers = [(0, "string", "/* XPM */")]


class PSDLangInfo(LangInfo):
    name = "Adobe Photoshop Document"
    exts = [".psd"]
    magic_numbers = [(0, "string", "8BPS")]


class PNGLangInfo(LangInfo):
    name = "PNG"
    exts = [".png"]
    magic_numbers = [(0, "string", "\x89PNG")]


class GIFLangInfo(LangInfo):
    name = "GIF"
    exts = [".gif"]
    magic_numbers = [(0, "string", "GIF8")]


class JPEGLangInfo(LangInfo):
    name = "JPEG"
    exts = [".jpg", ".jpeg"]
    # From '/usr/share/file/magic':
    #   0	beshort		0xffd8		JPEG image data
    magic_numbers = [(0, ">H", int("0xffd8", 16))]


class BMPLangInfo(LangInfo):
    name = "Bitmap image"
    exts = [".bmp"]
    magic_numbers = [(0, "string", "BM")]


class TIFFLangInfo(LangInfo):
    """TIFF image format"""
    name = "TIFF"
    exts = [".tiff", ".tif"]
    magic_numbers = [
        (0, "string", "MM\x00\x2a"),  # TIFF image data, big-endian
        (0, "string", "II\x2a\x00"),  # TIFF image data, little-endian
    ]


class DSStoreLangInfo(LangInfo):
    """Mac OS X filesystem directory metadata files."""
    name = "DSStore"
    filename_patterns = [".DS_Store"]


class BOMLangInfo(LangInfo):
    """Mac OS X/BSD 'Bill of Materials' file."""
    name = "BOM"
    exts = [".bom"]
    magic_numbers = [(0, "string", "BOMStore")]


class PDFLangInfo(LangInfo):
    name = "PDF"
    exts = [".pdf"]


class RIFFLangInfo(LangInfo):
    """Resource Interchange File Format -- a generic meta-format for
    storing data in tagged chunks.

    http://en.wikipedia.org/wiki/RIFF_(File_format)
    """
    name = "RIFF"
    magic_numbers = [
        (0, "string", "RIFX"),  # RIFF (big-endian) data
        (0, "string", "RIFF"),  # RIFF (little-endian) data
    ]


class WAVLangInfo(LangInfo):
    """Waveform (WAVE) Audio format"""
    name = "WAV"
    conforms_to_bases = ["RIFF"]
    exts = [".wav"]


class AVILangInfo(LangInfo):
    """Audio Video Interleave"""
    name = "AVI"
    conforms_to_bases = ["RIFF"]
    exts = [".avi"]


class MacHelpIndexLangInfo(LangInfo):
    """Mac OS X Help Index"""
    name = "Mac Help Index"
    exts = [".helpindex"]


class AppleBinaryPListLangInfo(LangInfo):
    name = "Apple Binary Property List"
    magic_numbers = [(0, "string", "bplist00")]


class MacOSXDiskImageLangInfo(LangInfo):
    name = "Mac OS X Disk Image"
    exts = [".dmg"]


class OggLangInfo(LangInfo):
    name = "Ogg data"
    exts = [".ogg"]
    magic_numbers = [(0, "string", "OggS")]


class FlashVideoLangInfo(LangInfo):
    """Macromedia Flash FLV Video File Format

    http://www.digitalpreservation.gov/formats/fdd/fdd000131.shtml
    """
    name = "Flash Video"
    exts = [".flv"]
    magic_numbers = [(0, "string", "FLV")]


class FlashSWFLangInfo(LangInfo):
    """Macromedia Flash SWF File Format

    http://www.digitalpreservation.gov/formats/fdd/fdd000248.shtml
    """
    name = "Flash SWF"
    exts = [".swf"]
    magic_numbers = [
        (0, "string", "FWS"),   # uncompressed
        (0, "string", "CWS"),   # compressed
    ]


class MP3LangInfo(LangInfo):
    """MPEG 1.0 Layer 3 audio encoding"""
    name = "MP3"
    exts = [".mp3"]
    magic_numbers = [
        (0, "string", "ID3"),  # MP3 file with ID3 version 2.
    ]


class MPEGLangInfo(LangInfo):
    """MPEG video"""
    name = "MPEG"
    exts = [".mpg", ".mpeg"]
    magic_numbers = [
        (0, '>L', int('0x000001b3', 16)),   # belong; MPEG video stream data
        (0, '>L', int('0x000001ba', 16)),   # belong; MPEG system stream data
    ]


class AACLangInfo(LangInfo):
    """MPEG-4 Advanced Audio Coding file"""
    name = "AAC"
    exts = [".m4a"]
    magic_numbers = [
        (16, "string", "M4A"),
    ]


class QuickTimeMovieLangInfo(LangInfo):
    """Apple QuickTime movie"""
    name = "QuickTime Movie"
    exts = [".mov"]
    # Note: Excluding these checks as an optimization and to avoid possible
    # false positives.
    # magic_numbers = [
    #    (4, "string", "moov"),
    #    (4, "string", "mdat"),
    #    (4, "string", "ftyp"),
    #    (4, "string", "free"),
    #    (4, "string", "junk"),
    #    (4, "string", "pnot"),
    #    (4, "string", "skip"),
    #    (4, "string", "wide"),
    #    (4, "string", "pict"),
    #]


class WindowsThumbnailCacheLangInfo(LangInfo):
    """Microsoft Windows directory thumbnail cache."""
    name = "Windows thumbnail cache"
    filename_patterns = ["Thumbs.db"]


class GettextMOLangInfo(LangInfo):
    """GNU Gettext message catalog

    http://www.gnu.org/software/gettext/manual/gettext.html#MO-Files
    """
    name = "GNU message catalog"
    exts = [".mo"]
    magic_numbers = [
        (0, "string", "\336\22\4\225"),  # GNU message catalog (little endian)
        (0, "string", "\225\4\22\336"),  # GNU message catalog (big endian),
    ]


class MSOfficeDocumentLangInfo(LangInfo):
    name = "MS Office Document"
    magic_numbers = [
        (0, "string", "\376\067\0\043"),
        (0, "string", "\320\317\021\340\241\261\032\341"),
        (0, "string", "\333\245-\0\0\0"),
    ]


class ExcelDocumentLangInfo(MSOfficeDocumentLangInfo):
    name = "MS Excel Document"
    exts = [".xls"]


class MSWordDocumentLangInfo(MSOfficeDocumentLangInfo):
    name = "MS Word Document"
    # TODO: consider extended 'specialization' facility to look at ext as well.
    # Can cause false positives for, e.g., a text document that uses '.doc'.
    # exts = [".doc"]

########NEW FILE########
__FILENAME__ = langinfo_doc
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""LangInfo definitions for some document languages."""

import re
from langinfo import LangInfo


class HTMLLangInfo(LangInfo):
    name = "HTML"
    conforms_to_bases = ["Text"]
    exts = ['.html', '.htm']
    magic_numbers = [
        (0, "string", "<!DOCTYPE html "),
        (0, "string", "<html"),
    ]
    # The default encoding is iso-8859-1 or utf-8 depending on the
    # Content-Type (provided by an HTTP header or defined in a <meta>
    # tag). See here for a good summary:
    #   http://feedparser.org/docs/character-encoding.html#advanced.encoding.intro
    # We'll just use UTF-8. Safer. It is the future.
    default_encoding = "utf-8"
    doctypes = [
        # <flavour>, <common-name>, <public-id>, <system-id>
        ("HTML 4.01 Strict", "HTML",
         "-//W3C//DTD HTML 4.01//EN",
         "http://www.w3.org/TR/html4/strict.dtd"),
        ("HTML 4.01 Transitional", "HTML",
         "-//W3C//DTD HTML 4.01 Transitional//EN",
         "http://www.w3.org/TR/html4/loose.dtd"),
        ("HTML 4.01 Frameset", "HTML",
         "-//W3C//DTD HTML 4.01 Frameset//EN",
         "http://www.w3.org/TR/html4/frameset.dtd"),
        ("HTML 3.2", "HTML",
         "-//W3C//DTD HTML 3.2 Final//EN", None),
        ("HTML 2.0", "HTML",
         "-//IETF//DTD HTML//EN", None),
    ]


class HTML5LangInfo(HTMLLangInfo):
    name = "HTML5"
    magic_numbers = [
        (0, "string", "<!DOCTYPE html>"),
    ]
    _magic_number_precedence = ('HTML', -1)
    doctypes = [
        # <flavour>, <common-name>, <public-id>, <system-id>
        ("HTML 5", "HTML5",
         "-//W3C//DTD HTML 5//EN",
         "http://www.w3.org/TR/html5/html5.dtd"),
    ]


class XHTMLLLangInfo(LangInfo):
    name = "XHTML"
    conforms_to_bases = ["XML", "HTML"]
    exts = ['.xhtml']
    doctypes = [
        # <flavour>, <common-name>, <public-id>, <system-id>
        ("XHTML 1.0 Strict", "html",
         "-//W3C//DTD XHTML 1.0 Strict//EN",
         "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"),
        ("XHTML 1.0 Transitional", "html",
         "-//W3C//DTD XHTML 1.0 Transitional//EN",
         "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"),
        ("XHTML 1.0 Frameset", "html",
         "-//W3C//DTD XHTML 1.0 Frameset//EN",
         "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd"),
    ]


class XMLLangInfo(LangInfo):
    name = "XML"
    conforms_to_bases = ["Text"]
    exts = ['.xml']
    default_encoding = "utf-8"
    magic_numbers = [
        (0, "string", "<?xml"),
    ]


class XSLTLangInfo(LangInfo):
    name = "XSLT"
    conforms_to_bases = ["XML"]
    exts = ['.xsl', '.xslt']
    # PERF: Only want to include this if necessary (for perf), i.e. if
    #      `exts` isn't sufficient.
    # magic_numbers = [
    #    (0, "regex", re.compile(r'^<xsl:stylesheet ', re.M))
    #]


class XULLangInfo(LangInfo):
    name = "XUL"
    conforms_to_bases = ["XML"]
    exts = ['.xul']
    doctypes = [
        # <flavour>, <common-name>, <public-id>, <system-id>
        (None, "window", "-//MOZILLA//DTD XUL V1.0//EN",
         "http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul"),
    ]


class XBLLangInfo(LangInfo):
    """eXtensible Binding Language"""
    name = "XBL"
    conforms_to_bases = ["XML"]
    exts = ['.xbl']
    # doctype:
    #   <!DOCTYPE bindings PUBLIC "-//MOZILLA//DTD XBL V1.0//EN" "http://www.mozilla.org/xbl">
    doctypes = [
        # <flavour>, <common-name>, <public-id>, <system-id>
        (None, "bindings", "-//MOZILLA//DTD XBL V1.0//EN",
         "http://www.mozilla.org/xbl"),
    ]


class SGMLLangInfo(LangInfo):
    name = "SGML"
    conforms_to_bases = ["Text"]
    exts = ['.sgml', '.ent']
    magic_numbers = [
        (0, "string", "<!subdoc"),  # TODO: should be case-insensitive
        # TODO: How to get these to have lower precedence than HTML
        #      doctype
        #(0, "string", "<!doctype"), #TODO: should be case-insensitive
        #(0, "string", "<!--"),
    ]


class YAMLLangInfo(LangInfo):
    name = "YAML"
    conforms_to_bases = ["Text"]
    exts = ['.yaml', '.yml']
    has_significant_trailing_ws = True
    # TODO: default encoding?


class JSONLangInfo(LangInfo):
    name = "JSON"
    conforms_to_bases = ["JavaScript"]
    exts = [".json"]

    section_regexes = [
        ("namespace", re.compile(r'"(?P<name>[^"]*?)"\s*:\s*{', re.M)),
    ]


class DTDLangInfo(LangInfo):
    name = "DTD"
    conforms_to_bases = ["Text"]
    exts = [".dtd"]


class PODLangInfo(LangInfo):
    """Plain Old Documentation format common in the Perl world."""
    name = "POD"
    conforms_to_bases = ["Text"]
    exts = [".pod"]
    # http://search.cpan.org/~nwclark/perl-5.8.8/pod/perlpod.pod
    encoding_decl_pattern = re.compile(
        r"^=encoding\s+(?P<encoding>[-\w.]+)", re.M)


class ASN1LangInfo(LangInfo):
    name = "ASN.1"
    komodo_name = "ASN1"
    conforms_to_bases = ["Text"]
    exts = [".asn1"]


class PostScriptLangInfo(LangInfo):
    name = "PostScript"
    conforms_to_bases = ["Text"]
    exts = [".ps"]


class TeXLangInfo(LangInfo):
    name = "TeX"
    conforms_to_bases = ["Text"]
    # TODO: who should win .tex? TeX or LaTeX?
    # exts = [".tex"]


class LaTeXLangInfo(LangInfo):
    name = "LaTeX"
    conforms_to_bases = ["Text"]
    exts = [".tex"]


class ConTeXLangInfo(LangInfo):
    name = "ConTeX"
    conforms_to_bases = ["Text"]


class GettextPOLangInfo(LangInfo):
    """GNU Gettext PO

    http://www.gnu.org/software/gettext/manual/gettext.html#PO-Files
    """
    name = "PO"
    conforms_to_bases = ["Text"]
    exts = [".po"]
    default_encoding = "utf-8"


class TracWikiLangInfo(LangInfo):
    name = "TracWiki"
    conforms_to_bases = ["Text"]
    exts = [".tracwiki"]
    # Headers consist of the same # of equal signs at the start and end of the line.
    # An optional id is allowed after the closing = (to indicate an id attr)
    # A "!" in the header escapes *all* the immediately following = chars.
    section_regexes = [
        ("header",
         re.compile(r'''
            ^
            \s*
            (={1,5})
            \s*
            (?P<name>(?:!=+|
                        [^=!]+|
                        !)+?
            )
            \s*
            \1
            (?:\s|\#|$)
         ''', re.M | re.X)),
    ]


class ReStructureTextLangInfo(LangInfo):
    name = "reStructuredText"
    conforms_to_bases = ["Text"]
    exts = [".rst"]


class MarkdownLangInfo(LangInfo):
    """'A text-to-HTML conversion tool [and format] for web writers'

    http://daringfireball.net/projects/markdown/
    """
    name = "Markdown"
    conforms_to_bases = ["Text"]
    exts = [
        # from other editors and what Github's markup processing supports
        ".md", ".markdown", ".mdown", ".mkdn", ".mkd",
        # from <http://www.file-extensions.org/mdml-file-extension>
        ".mdml",
    ]


class RichTextFormatLangInfo(LangInfo):
    """Rich Text Format"""
    name = "RTF"
    conforms_to_bases = ["Text"]
    exts = [".rtf"]
    magic_numbers = [
        (0, "string", r"{\rtf"),
    ]


class TroffLangInfo(LangInfo):
    """'the Text Processor for Typesetters'

    This is the format of man pages on Un*x.
    http://www.troff.org/
    """
    name = "troff"
    conforms_to_bases = ["Text"]
    magic_numbers = [
        (0, "string", '.\\"'),
        (0, "string", "'\\\""),
        (0, "string", "'.\\\""),
        (0, "string", "\\\""),
        (0, "string", "'''"),
    ]
    has_significant_trailing_ws = True

########NEW FILE########
__FILENAME__ = langinfo_komodo
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""LangInfo definitions specific to Komodo."""

from langinfo import LangInfo


class KomodoProjectLangInfo(LangInfo):
    name = "Komodo Project"
    exts = [".kpf"]
    conforms_to_bases = ["XML"]


class KomodoColorSchemeLangInfo(LangInfo):
    name = "Komodo Color Scheme"
    exts = [".ksf"]
    conforms_to_bases = ["Python"]


class KomodoKeybindingSchemeLangInfo(LangInfo):
    name = "Komodo Keybinding Scheme"
    exts = [".kkf"]
    conforms_to_bases = ["Text"]


class UDLLangInfo(LangInfo):
    name = "UDL"
    komodo_name = "Luddite"
    exts = [".udl"]
    conforms_to_bases = ["Text"]

########NEW FILE########
__FILENAME__ = langinfo_mozilla
# Copyright (c) 2009 ActiveState Software Inc.
# See the file LICENSE.txt for licensing information.

"""LangInfo definitions for languages coming out of the Mozilla project and
that don't logically fit in the other `langinfo_*.py` files.
"""

import re
from langinfo import LangInfo


class StringPropertiesLangInfo(LangInfo):
    """A properties file commonly used in the Mozilla project with
    `nsIStringBundleService`.

    Note: The Java world also uses ".properties".
        http://java.sun.com/docs/books/tutorial/i18n/resbundle/propfile.html
    This looks to be the same format. I'm guessing that Mozilla's use
    of the extension for string bundles is derived from this.
    """
    name = "String Properties"
    conforms_to_bases = ["Text"]
    exts = [".properties"]


class ChromeManifestLangInfo(LangInfo):
    """A Mozilla chrome manifest file."""
    name = "Chrome Manifest"
    conforms_to_bases = ["Text"]
    # Can't claim ".manifest" extension, because ".manifest" XML files are
    # common on Windows for UAC.
    filename_patterns = [
        "chrome.manifest",
        # These for Komodo's benefit:
        "chrome.p.manifest",    # Suggested usage by 'koext' tool.
        "devbuild.manifest",    # Komodo: in common usage
    ]


class XPTLangInfo(LangInfo):
    """Mozilla XPCOM Type info file.

    XPT files are the result of compiling .idl files with "xpidl".
    http://www.mozilla.org/scriptable/typelib_tools.html
    """
    name = "XPT"
    exts = [".xpt"]

########NEW FILE########
__FILENAME__ = langinfo_other
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""LangInfo definitions for languages that don't fit in the other
langinfo_*.py files.
"""

import re
from langinfo import LangInfo


class MakefileLangInfo(LangInfo):
    name = "Makefile"
    conforms_to_bases = ["Text"]
    exts = [".mak"]
    filename_patterns = [re.compile(r'^[Mm]akefile.*$')]


class _CSSLangInfoCommon(LangInfo):
    conforms_to_bases = ["Text"]
    exts = [".css"]
    default_encoding = "utf-8"
    # http://www.w3.org/International/questions/qa-css-charset
    # http://www.w3.org/TR/CSS21/syndata.html#charset
    # http://www.w3.org/TR/CSS2/syndata.html#q23
    # I.e., look for:
    #   @charset "<IANA defined charset name>";
    # at the start of the CSS document.
    encoding_decl_pattern = re.compile(r'\A@charset "(?P<encoding>[\w-]+)";')


class CSSLangInfo(_CSSLangInfoCommon):
    name = "CSS"
    exts = [".css"]


class SCSSLangInfo(_CSSLangInfoCommon):
    name = "SCSS"
    exts = [".scss", ".css.scss"]


class LessLangInfo(_CSSLangInfoCommon):
    name = "Less"
    exts = [".less", ".css.less"]


class SassLangInfo(_CSSLangInfoCommon):
    name = "Sass"
    exts = [".sass", ".css.sass"]
    section_regexes = [
        ("production", re.compile(r"^(\w\S+?),?", re.M)),
    ]


class CIXLangInfo(LangInfo):
    """Komodo Code Intelligence XML dialect.

    This is used to define the code structure of scanned programming
    language content.
    """
    name = "CIX"
    conforms_to_bases = ["XML"]
    exts = [".cix"]


class DiffLangInfo(LangInfo):
    name = "Diff"
    conforms_to_bases = ["Text"]
    exts = [".patch", ".diff"]
    has_significant_trailing_ws = True


class IDLLangInfo(LangInfo):
    # TODO: clarify if this is the math thing or the COM-IDL thing
    name = "IDL"
    conforms_to_bases = ["Text"]
    exts = [".idl"]


class ApacheConfigLangInfo(LangInfo):
    name = "Apache Config"
    komodo_name = "Apache"
    conforms_to_bases = ["Text"]
    exts = [".conf"]
    filename_patterns = [".htaccess"]


class APDLLangInfo(LangInfo):
    """ANSYS Parametric Design Language

    http://www.mece.ualberta.ca/tutorials/ansys/AT/APDL/APDL.html
    """
    name = "APDL"
    conforms_to_bases = ["Text"]
    exts = [".mac"]


class IniLangInfo(LangInfo):
    name = "Ini"
    conforms_to_bases = ["Text"]
    exts = [".ini"]


class POVRayLangInfo(LangInfo):
    """The "Persistence of Vision Raytracer"
    http://www.povray.org
    """
    name = "POVRay"
    conforms_to_bases = ["Text"]
    exts = [".pov"]


class POGetTextLangInfo(LangInfo):
    name = "GetText"
    conforms_to_bases = ["Text"]
    exts = [".po"]


class MatlabLangInfo(LangInfo):
    """A high-performance language for technical computing.
    http://www.mathworks.com/
    """
    name = "Matlab"
    conforms_to_bases = ["Text"]
    exts = [".m", ".mat"]


class ForthLangInfo(LangInfo):
    """Forth is a structured, imperative, stack-based, computer programming
    language.
    http://en.wikipedia.org/wiki/Forth_(programming_language)
    http://www.forth.org/
    """
    name = "Forth"
    conforms_to_bases = ["Text"]
    exts = [".forth"]


class FlagshipLangInfo(LangInfo):
    """ Flagship is a commercial compiler for Clipper (dBASE III compiler)
    http://www.fship.com/
    http://en.wikipedia.org/wiki/Clipper_(programming_language)
    """
    name = "Flagship"
    conforms_to_bases = ["Text"]
    exts = [".prg"]


class SQLLangInfo(LangInfo):
    # TODO: describe: what SQL spec does this conform to?
    # TODO: should we have other SQL langs? E.g. for PostgreSQL, etc.?
    name = "SQL"
    conforms_to_bases = ["Text"]
    exts = [".sql"]


class PLSQLLangInfo(LangInfo):
    # TODO: describe how different from SQLLangInfo
    name = "PL-SQL"
    conforms_to_bases = ["Text"]
    # exts = [".sql"]
    is_minor_variant = SQLLangInfo


class MSSQLLangInfo(LangInfo):
    # TODO: describe how diff from SQLLangInfo
    name = "MSSQL"
    conforms_to_bases = ["Text"]


class MySQLLangInfo(LangInfo):
    name = "MySQL"
    conforms_to_bases = ["Text"]
    exts = [".sql"]
    is_minor_variant = SQLLangInfo


class NSISLangInfo(LangInfo):
    """Nullsoft Scriptable Install System
    http://nsis.sourceforge.net/
    """
    name = "NSIS"
    komodo_name = "Nsis"
    conforms_to_bases = ["Text"]
    exts = [".nsi"]


class VimLangInfo(LangInfo):
    """Vim configuration"""
    name = "Vim"
    conforms_to_bases = ["Text"]
    exts = [".vim"]
    filename_patterns = [".vimrc"]


class INILangInfo(LangInfo):
    name = "INI"
    conforms_to_bases = ["Text"]
    exts = [".ini"]


class LogLangInfo(LangInfo):
    name = "log"
    conforms_to_bases = ["Text"]
    exts = [".log"]


class CobolLangInfo(LangInfo):
    name = "COBOL"
    conforms_to_bases = ["Text"]
    exts = [".cbl"]


class NimrodLangInfo(LangInfo):
    name = "Nimrod"
    conforms_to_bases = ["Text"]
    exts = [".nim"]


class PowerProLangInfo(LangInfo):
    name = "PowerPro"
    conforms_to_bases = ["Text"]


class SMLLangInfo(LangInfo):
    name = "SML"
    conforms_to_bases = ["Text"]
    exts = [".sml"]


class SorcusLangInfo(LangInfo):
    name = "Sorcus"
    conforms_to_bases = ["Text"]


class TACLLangInfo(LangInfo):
    name = "TACL"
    conforms_to_bases = ["Text"]
    exts = [".tacl"]


class TALLangInfo(LangInfo):
    name = "TAL"
    conforms_to_bases = ["Text"]
    exts = [".tal"]

########NEW FILE########
__FILENAME__ = langinfo_prog
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""LangInfo definitions for some programming languages."""

import re
from langinfo import LangInfo

import logging
log = logging.getLogger("langinfo_prog")
# log.setLevel(logging.DEBUG)


class _PythonCommonLangInfo(LangInfo):
    conforms_to_bases = ["Text"]
    exts = ['.py', '.pyw']
    default_encoding = "ascii"  # TODO: link to ref defining default encoding
    # http://www.python.org/dev/peps/pep-0263/
    encoding_decl_pattern = re.compile(r"coding[:=]\s*(?P<encoding>[-\w.]+)")

# Where there's a conflict in extensions, put the main
# LangInfo entry last.


class PythonLangInfo(_PythonCommonLangInfo):
    name = "Python"
    magic_numbers = [
        (0, "regex", re.compile(r'\A#!.*python(?!3).*$', re.I | re.M))
    ]


class Python3LangInfo(_PythonCommonLangInfo):
    name = "Python3"
    magic_numbers = [
        (0, "regex", re.compile(r'\A#!.*python3.*$', re.I | re.M))
    ]
    is_minor_variant = PythonLangInfo


class CompiledPythonLangInfo(LangInfo):
    name = "Compiled Python"
    exts = ['.pyc', '.pyo']


class PerlLangInfo(LangInfo):
    name = "Perl"
    conforms_to_bases = ["Text"]
    exts = ['.pl', '.pm', '.t']
    magic_numbers = [
        (0, "regex", re.compile(r'\A#!.*perl.*$', re.I | re.M)),
    ]
    filename_patterns = [
        "Construct", "Conscript"]  # Cons make-replacement tool files

    # http://search.cpan.org/~rgarcia/encoding-
    # source-0.02/lib/encoding/source.pm
    default_encoding = "iso8859-1"
    # Perl >= 5.8.0
    #   http://perldoc.perl.org/encoding.html
    #   use encoding "<encoding-name>";
    #   "Somewhat broken."
    # Perl >= 5.9.5
    #   http://search.cpan.org/~rgarcia/encoding-source-0.02/lib/encoding/source.pm
    #   use encoding::source "<encoding-name>";
    #   "This is like the encoding pragma, but done right."
    encoding_decl_pattern = re.compile(
        r"""use\s+encoding(?:::source)?\s+(['"])(?P<encoding>[\w-]+)\1""")


class PHPLangInfo(LangInfo):
    name = "PHP"
    conforms_to_bases = ["Text"]
    exts = [".php", ".inc",
            ".phtml"]  # .phtml commonly used for Zend Framework view files
    magic_numbers = [
        (0, "string", "<?php"),
        (0, "regex", re.compile(r'\A#!.*php.*$', re.I | re.M)),
    ]
    # TODO: PHP files should inherit the HTML "<meta> charset" check
    #      and the XML prolog encoding check.

    keywords = set([
        # new to php 5.5
        "finally", "yield",
        # new to php 5.4
        "insteadof", "trait",
        # new to php 5.3
        "e_deprecated", "e_user_deprecated", "php_maxpathlen",
        # existed in php4
        "bool", "boolean", "catch", "define", "double", "false", "float",
        "int", "integer", "null", "object", "parent", "real",
        "self", "string", "this", "true", "virtual",
        # new to php5
        "abstract", "final", "implements", "instanceof", "interface",
        "public", "private", "protected", "throw", "try",
        # http://www.php.net/manual/en/reserved.php#reserved.keywords
        "__file__", "__line__", "_function_", "_class_",
        "and", "array", "as", "break", "case", "cfunction", "class",
        "const", "continue", "declare", "default", "die", "do", "echo",
        "else", "elseif", "empty", "enddeclare", "endfor", "endforeach",
        "endif", "endswitch", "endwhile", "eval", "exit", "extends",
        "for", "foreach", "function", "global", "if", "include",
        "include_once", "isset", "list", "new", "old_function", "or",
        "print", "require", "require_once", "return", "static",
        "switch", "unset", "use", "var", "while", "xor",
        # new to php 5.3
        "__dir__", "__namespace__", "goto", "namespace",
    ])


class TclLangInfo(LangInfo):
    name = "Tcl"
    conforms_to_bases = ["Text"]
    exts = ['.tcl']
    magic_numbers = [
        (0, "regex", re.compile(r'\A#!.*(tclsh|wish|expect).*$', re.I | re.M)),
        # As suggested here: http://www.tcl.tk/man/tcl8.4/UserCmd/tclsh.htm
        # Make sure we properly catch shebang lines like this:
        #   #!/bin/sh
        #   # the next line restarts using tclsh
        #   exec tclsh "$0" "$@"
        (0, "regex", re.compile(r'\A#!.*^exec [^\r\n|\n|\r]*?(tclsh|wish|expect)',
                                re.I | re.M | re.S)),
    ]
    _magic_number_precedence = (
        "Bourne shell", -1)  # check before "Bourne shell"


class RubyLangInfo(LangInfo):
    name = "Ruby"
    conforms_to_bases = ["Text"]
    exts = ['.rb', '.mab']
    filename_patterns = ["Rakefile"]
    magic_numbers = [
        (0, "regex", re.compile('\A#!.*ruby.*$', re.I | re.M)),
    ]
    # TODO: http://blade.nagaokaut.ac.jp/cgi-bin/scat.rb/ruby/ruby-core/12900
    #      Ruby uses similar (same?) coding decl as Python.


class _JSLikeLangInfo(LangInfo):
    conforms_to_bases = ["Text"]
    # Support for Node (server side JavaScript).
    magic_numbers = [
        (0, "regex", re.compile(r'\A#!.*node.*$', re.I | re.M))
    ]

    # These are the keywords that are used in most JavaScript environments.
    common_keywords = set(["break",
                           "case", "catch", "const", "continue",
                           "debugger", "default", "delete", "do",
                           "else", "export",
                           "false", "finally", "for", "function",
                           "if", "import", "in", "instanceof",
                           "let",
                           "new", "null",
                           "return",
                           "switch",
                           "this", "throw", "true", "try", "typeof",
                           "undefined",
                           "var", "void",
                           "while", "with",
                           "yield",
                           ])
    keywords = common_keywords.union(
        # Additional JavaScript reserved keywords.
        set(["abstract", "boolean", "byte",
                                    "char", "class",
                                    "double",
                                    "enum", "extends",
                                    "float",
                                    "goto",
                                    "implements", "int", "interface",
                                    "long",
                                    "native",
                                    "package", "private", "protected", "public",
                                    "short", "static", "super", "synchronized",
                                    "transient"
             ]))


class JavaScriptLangInfo(_JSLikeLangInfo):
    name = "JavaScript"
    exts = ['.js', '.jsm']


class NodeJSLangInfo(_JSLikeLangInfo):
    name = "Node.js"
    exts = ['.js']


class CoffeeScriptLangInfo(_JSLikeLangInfo):
    name = "CoffeeScript"
    exts = ['.coffee']

    common_keywords = set().union(_JSLikeLangInfo.common_keywords)
    try:
        common_keywords.remove("var")
    except KeyError:
        log.exception("Can't remove 'var'")
    _new_keywords = set(['__bind__indexOf', '__extends', '__hasProp',
                         '__slice', 'and', 'arguments', 'await', 'by', 'defer',
                         'enumexport', 'eval', 'is', 'isnt', 'loop', 'no',
                         'not', 'of', 'onoff', 'or', 'protectedpublic', 'then',
                         'unless', 'until', 'when', 'yes'])
    keywords = common_keywords.union(_new_keywords)


class CLangInfo(LangInfo):
    # TODO: rationalize with C++ and Komodo's usage
    name = "C"
    conforms_to_bases = ["Text"]
    exts = [
        ".c",
        ".xs",  # Perl extension modules. *Are* they legal C?
    ]
    # TODO: Note for Jan:
    # .xs files are *NOT* legal C or C++ code.  However, they are
    # similar enough that I find it useful to edit them using c-mode or
    # c++-mode in Emacs.


class CPlusPlusLangInfo(LangInfo):
    # TODO: consider breaking out headers and have separate
    #      scintilla_lexer attr
    name = "C++"
    conforms_to_bases = ["Text"]
    exts = [
        ".c++", ".cpp", ".cxx",
        ".h", ".h++", ".hpp", ".hxx",
        ".inl",  # Inline C++ files.
        ".xs",  # Perl extension modules. *Are* they legal C++?
    ]


class HLSLLangInfo(LangInfo):
    """High Level Shader Language is a proprietary shading language developed by
    Microsoft for use with the Microsoft Direct3D API.

    http://en.wikipedia.org/wiki/HLSL
    """
    name = "HLSL"
    conforms_to_bases = ["Text"]
    exts = ['.hlsl', '.cg', '.fx']

    # Keywords,etc. from http://www.emeditor.com/pub/hlsl.esy
    _intrinsic_function_names = """asm_fragment
        bool
        column_major
        compile
        compile_fragment
        const
        discard
        do
        double
        else
        extern
        false
        float
        for
        half
        if
        in
        inline
        inout
        int
        matrix
        out
        pixelfragment
        return
        register
        row_major
        sampler
        sampler1D
        sampler2D
        sampler3D
        samplerCUBE
        sampler_state
        shared
        stateblock
        stateblock_state
        static
        string
        struct
        texture
        texture1D
        texture2D
        texture3D
        textureCUBE
        true
        typedef
        uniform
        vector
        vertexfragment
        void
        volatile
        while""".split()
    _keywords_case_insensitive = "asm decl pass technique".split()
    _keywords_case_sensitive = """asm_fragment
        bool
        column_major
        compile
        compile_fragment
        const
        discard
        do
        double
        else
        extern
        false
        float
        for
        half
        if
        in
        inline
        inout
        int
        matrix
        out
        pixelfragment
        return
        register
        row_major
        sampler
        sampler1D
        sampler2D
        sampler3D
        samplerCUBE
        sampler_state
        shared
        stateblock
        stateblock_state
        static
        string
        struct
        texture
        texture1D
        texture2D
        texture3D
        textureCUBE
        true
        typedef
        uniform
        vector
        vertexfragment
        void
        volatile
        while
        """.split()
    _reserved_words = """auto
        break
        case
        catch
        char
        class
        const_cast
        continue
        default
        delete
        dynamic_cast
        enum
        explicit
        friend
        goto
        long
        mutable
        namespace
        new
        operator
        private
        protected
        public
        reinterpret_cast
        short
        signed
        sizeof
        static_cast
        switch
        template
        this
        throw
        try
        typename
        union
        unsigned
        using
        virtual""".split()

    keywords = set(_intrinsic_function_names
                   + _keywords_case_insensitive
                   + _keywords_case_sensitive
                   + _reserved_words)


class ADALangInfo(LangInfo):
    name = "Ada"
    conforms_to_bases = ["Text"]
    exts = [".ada"]


class NTBatchLangInfo(LangInfo):
    name = "Batch"
    conforms_to_bases = ["Text"]
    exts = [".bat", ".cmd"]  # TODO ".com"?


class BashLangInfo(LangInfo):
    name = "Bash"
    conforms_to_bases = ["Text"]
    exts = [".sh"]
    filename_patterns = [".bash_profile", ".bashrc", ".bash_logout"]
    magic_numbers = [
        (0, "regex", re.compile(r'\A#!.*/\bbash\b$', re.I | re.M)),
    ]


class SHLangInfo(LangInfo):
    name = "Bourne shell"
    conforms_to_bases = ["Text"]
    magic_numbers = [
        (0, "regex", re.compile(r'\A#!.*/\bsh\b$', re.I | re.M)),
    ]


class TCSHLangInfo(LangInfo):
    name = "tcsh"
    conforms_to_bases = ["Text"]
    magic_numbers = [
        (0, "regex", re.compile(r'\A#!.*/\btcsh\b$', re.M)),
    ]
    filename_patterns = ["csh.cshrc", "csh.login", "csh.logout",
                         ".tcshrc", ".cshrc", ".login", ".logout"]


class CSharpLangInfo(LangInfo):
    name = "C#"
    conforms_to_bases = ["Text"]
    exts = [".cs"]


class ErlangLangInfo(LangInfo):
    name = "Erlang"
    conforms_to_bases = ["Text"]
    exts = [".erl"]


class Fortran77LangInfo(LangInfo):
    name = "Fortran 77"
    conforms_to_bases = ["Text"]
    exts = [".f"]


class Fortran95LangInfo(LangInfo):
    name = "Fortran"
    conforms_to_bases = ["Text"]
    exts = [".f95"]


class JavaLangInfo(LangInfo):
    name = "Java"
    conforms_to_bases = ["Text"]
    exts = [".java", ".jav", '.groovy']


class LispLangInfo(LangInfo):
    name = "Lisp"
    conforms_to_bases = ["Text"]
    exts = [".lis"]


class LuaLangInfo(LangInfo):
    name = "Lua"
    conforms_to_bases = ["Text"]
    exts = [".lua"]


class PascalLangInfo(LangInfo):
    name = "Pascal"
    conforms_to_bases = ["Text"]
    exts = [".pas"]


class SmalltalkLangInfo(LangInfo):
    name = "Smalltalk"
    conforms_to_bases = ["Text"]
    exts = [".st"]


class ActionScriptLangInfo(LangInfo):
    """ActionScript source code

    http://en.wikipedia.org/wiki/Adobe_Flash#Related_file_formats_and_extensions
    """
    name = "ActionScript"
    conforms_to_bases = ["Text"]
    exts = [".as", ".asc"]


class AssemblerLangInfo(LangInfo):
    name = "Assembler"
    conforms_to_bases = ["Text"]
    exts = [".asm"]


class EiffelLangInfo(LangInfo):
    name = "Eiffel"
    conforms_to_bases = ["Text"]
    exts = [".e"]


class HaskellLangInfo(LangInfo):
    name = "Haskell"
    conforms_to_bases = ["Text"]
    exts = [".hs"]


class PowerShellLangInfo(LangInfo):
    """Windows PowerShell
    http://www.microsoft.com/windowsserver2003/technologies/management/powershell/default.mspx
    """
    name = "PowerShell"
    conforms_to_bases = ["Text"]
    exts = [".ps1"]


class SchemeLangInfo(LangInfo):
    name = "Scheme"
    conforms_to_bases = ["Text"]
    exts = [".scm"]


class VHDLLangInfo(LangInfo):
    """TODO: desc, reference"""
    name = "VHDL"
    conforms_to_bases = ["Text"]
    exts = [".vhdl"]


class VerilogLangInfo(LangInfo):
    """TODO: desc, reference"""
    name = "Verilog"
    conforms_to_bases = ["Text"]


#---- "Basic"-based languages
class _BasicLangInfo(LangInfo):
    conforms_to_bases = ["Text"]


class FreeBasicLangInfo(_BasicLangInfo):
    """http://www.freebasic.net/"""
    name = "FreeBASIC"
    komodo_name = "FreeBasic"
    exts = [".bas"]


class PureBasicLangInfo(_BasicLangInfo):
    """http://www.purebasic.com/"""
    name = "PureBasic"
    exts = [".pb"]


class PowerBasicLangInfo(_BasicLangInfo):
    """TOOD: ref?
    TODO: which if this and PureBasic should win '.pb' ext?
    """
    name = "PowerBasic"
    exts = [".pb"]


class BlitzBasicLangInfo(_BasicLangInfo):
    """http://www.blitzbasic.com/Products/blitzmax.php"""
    name = "BlitzBasic"
    exts = [".bb"]


class VisualBasicLangInfo(_BasicLangInfo):
    name = "VisualBasic"  # TODO: should name be "Visual Basic"?
    exts = [".vb"]


class VBScriptLangInfo(_BasicLangInfo):
    name = "VBScript"
    exts = [".vbs"]


#---- less common languages (AFAICT)
class BaanLangInfo(LangInfo):
    """Baan is the scripting language used for the Baan ERP system
    (currently known as SSA ERP according to the Wikipedia article
    below).

    http://en.wikipedia.org/wiki/Baan
    http://baan.ittoolbox.com/
    """
    name = "Baan"
    conforms_to_bases = ["Text"]
    exts = [".bc"]


class REBOLLangInfo(LangInfo):
    """http://www.rebol.com/"""
    name = "REBOL"
    conforms_to_bases = ["Text"]
    exts = [".r"]


class CamlLangInfo(LangInfo):
    """http://caml.inria.fr/"""
    name = "Caml"
    komodo_name = "Objective Caml"
    conforms_to_bases = ["Text"]
    exts = [".ml", ".mli"]

########NEW FILE########
__FILENAME__ = langinfo_template
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""LangInfo definitions for template languages."""

import re
from langinfo import LangInfo


class RHTMLLangInfo(LangInfo):
    name = "RHTML"
    conforms_to_bases = ["Text"]
    exts = [".rhtml"]


class EJSLangInfo(LangInfo):
    name = "EJS"
    conforms_to_bases = ["Text"]
    exts = [".ejs"]


class KomodoSnippetLangInfo(LangInfo):
    name = "Komodo Snippet"
    conforms_to_bases = ["Text"]
    exts = [".snippet"]


class DjangoTemplateLangInfo(LangInfo):
    name = "Django Template"
    conforms_to_bases = ["Text"]
    exts = [".django.html"]
    section_regexes = [
        ("import", re.compile(r'\{\%[ \t]+(load\b.*?)\%\}')),
        ("class", re.compile(r'\{\%[ \t]+(block\b.*?)\%\}')),
    ]


class DjangoHTMLTemplateLangInfo(DjangoTemplateLangInfo):
    name = "Django HTML Template"
    komodo_name = "Django"
    specialization_hints_from_lang = {
        "HTML": [
            ('{%', re.compile(r'\{\%[ \t]+\b(block|if)\b.*?\%\}')),
            ('{{', re.compile(r'\{\{.*?\}\}')),
        ],
    }


class TwigTemplateLangInfo(DjangoTemplateLangInfo):
    name = "Twig"
    exts = [".twig"]


class DjangoXHTMLTemplateLangInfo(DjangoTemplateLangInfo):
    name = "Django XHTML Template"
    specialization_hints_from_lang = {
        "XHTML": [
            ('{%', re.compile(r'\{\%[ \t]+\b(block|if)\b.*?\%\}')),
            ('{{', re.compile(r'\{\{.*?\}\}')),
        ],
    }


class DjangoTextTemplateLangInfo(DjangoTemplateLangInfo):
    name = "Django Text Template"
    specialization_hints_from_lang = {
        "Text": [
            ('{%', re.compile(r'\{\%[ \t]+\b(block|if)\b.*?\%\}')),
            ('{{', re.compile(r'\{\{.*?\}\}')),
        ],
    }


class DjangoXMLTemplateLangInfo(DjangoTemplateLangInfo):
    name = "Django XML Template"
    specialization_hints_from_lang = {
        "XML": [
            ('{%', re.compile(r'\{\%[ \t]+\b(block|if)\b.*?\%\}')),
            ('{{', re.compile(r'\{\{.*?\}\}')),
        ],
    }


class EpMojoHTMLTemplateLangInfo(LangInfo):
    # TODO: How to best handle relationship with HTML?
    # TODO: How to enable detection?
    name = "ep (Mojo) HTML Template"
    komodo_name = "EpMojo"
    conforms_to_bases = ["Text"]
    # This ext is a Komodo-ism, but helpful for getting codeintel tests
    # working for Template Toolkit.
    exts = [".ep"]


class MasonHTMLTemplateLangInfo(LangInfo):
    # TODO: How to best handle relationship with HTML?
    # TODO: How to enable detection?
    name = "Mason HTML Template"
    komodo_name = "Mason"
    conforms_to_bases = ["Text"]
    # This ext is a Komodo-ism, but helpful for getting codeintel tests
    # working for Template Toolkit.
    exts = [".mason.html"]


class TemplateToolkitLangInfo(LangInfo):
    # TODO: link to lang page
    # TODO: Is template toolkit just for HTML files?
    name = "Template Toolkit HTML Template"  # a little long
    komodo_name = "TemplateToolkit"
    conforms_to_bases = ["Text"]
    # This ext is a Komodo-ism, but helpful for getting codeintel tests
    # working for Template Toolkit.
    exts = [".ttkt.html"]


class SmartyLangInfo(LangInfo):
    """http://www.smarty.net/"""
    name = "Smarty Template"
    komodo_name = "Smarty"
    conforms_to_bases = ["Text"]
    exts = [".tpl"]


class CakePHPTemplate(LangInfo):
    """CakePHP view template files.

    CakePHP is a PHP framework with an MVC system. By convention "view"
    files (they are PHP) use the .ctp extension.
    http://book.cakephp.org/view/22/cakephp-conventions#view-conventions-26
    """
    name = "CakePHP Template"
    conforms_to_bases = ["PHP"]
    exts = [".ctp"]


class LaravelBladeTemplateLangInfo(LangInfo):
    name = "Laravel Blade Template"
    komodo_name = "LaravelBlade"
    conforms_to_bases = ["Text"]
    exts = [".blade.php"]
    section_regexes = [
        ("section", re.compile(r'@section')),
    ]


class GroovyServerPagesLangInfo(LangInfo):
    name = "Groovy Server Pages"
    conforms_to_bases = ["HTML"]
    exts = [".gsp"]
    komodo_name = "HTML"

########NEW FILE########
__FILENAME__ = langinfo_tiny
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

"""LangInfo definitions for some "tiny" languages.

Examples are one-off file types (specific to some software project or something),
specific config files, etc.
"""

from langinfo import LangInfo


class ConsignLangInfo(LangInfo):
    """.consign files used by the Cons build tool."""
    name = "Cons cache"
    conforms_to_bases = ["Text"]
    filename_patterns = [".consign"]

########NEW FILE########
__FILENAME__ = process
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

import os
import sys
import time
import types
if sys.platform != "win32":
    import signal  # used by kill() method on Linux/Mac
import logging
import threading
import warnings

#-------- Globals -----------#

log = logging.getLogger("process")
# log.setLevel(logging.DEBUG)

try:
    from subprocess32 import Popen, PIPE
except ImportError:
    # Not available on Windows - fallback to using regular subprocess module.
    from subprocess import Popen, PIPE
    if sys.platform != "win32":
        log.warn(
            "Could not import subprocess32 module, falling back to subprocess module")


CREATE_NEW_CONSOLE = 0x10  # same as win32process.CREATE_NEW_CONSOLE
CREATE_NEW_PROCESS_GROUP = 0x200  # same as win32process.CREATE_NEW_PROCESS_GROUP
CREATE_NO_WINDOW = 0x8000000  # same as win32process.CREATE_NO_WINDOW
CTRL_BREAK_EVENT = 1  # same as win32con.CTRL_BREAK_EVENT
WAIT_TIMEOUT = 258  # same as win32event.WAIT_TIMEOUT


#-------- Classes -----------#

# XXX - TODO: Work out what exceptions raised by SubProcess and turn into
#       ProcessError?
class ProcessError(Exception):
    def __init__(self, msg, errno=-1):
        Exception.__init__(self, msg)
        self.errno = errno


# Check if this is Windows NT and above.
if sys.platform == "win32" and sys.getwindowsversion()[3] == 2:

    import winprocess
    from subprocess import pywintypes, list2cmdline, STARTUPINFO
    try:
        # These subprocess variables have moved around between Python versions.
        from subprocess import (SW_HIDE,
                                STARTF_USESTDHANDLES, STARTF_USESHOWWINDOW,
                                GetVersion, CreateProcess, TerminateProcess)
    except ImportError:
        import subprocess
        SW_HIDE = subprocess._subprocess.SW_HIDE
        STARTF_USESTDHANDLES = subprocess._subprocess.STARTF_USESTDHANDLES
        STARTF_USESHOWWINDOW = subprocess._subprocess.STARTF_USESHOWWINDOW
        GetVersion = subprocess._subprocess.GetVersion
        CreateProcess = subprocess._subprocess.CreateProcess
        TerminateProcess = subprocess._subprocess.TerminateProcess

    # This fix is for killing child processes on windows, based on:
    #   http://www.microsoft.com/msj/0698/win320698.aspx
    # It works by creating a uniquely named job object that will contain our
    # process(es), starts the process in a suspended state, maps the process
    # to a specific job object, resumes the process, from now on every child
    # it will create will be assigned to the same job object. We can then
    # later terminate this job object (and all of it's child processes).
    #
    # This code is based upon Benjamin Smedberg's killableprocess, see:
    #   http://benjamin.smedbergs.us/blog/2006-12-11/killableprocesspy/

    class WindowsKillablePopen(Popen):

        _job = None

        def _execute_child(self, args, executable, preexec_fn, close_fds,
                           cwd, env, universal_newlines,
                           startupinfo, creationflags, shell,
                           p2cread, p2cwrite,
                           c2pread, c2pwrite,
                           errread, errwrite):
            """Execute program (MS Windows version)"""

            if not isinstance(args, types.StringTypes):
                args = list2cmdline(args)

            # Process startup details
            if startupinfo is None:
                startupinfo = STARTUPINFO()
            if None not in (p2cread, c2pwrite, errwrite):
                startupinfo.dwFlags |= STARTF_USESTDHANDLES
                startupinfo.hStdInput = p2cread
                startupinfo.hStdOutput = c2pwrite
                startupinfo.hStdError = errwrite

            if shell:
                startupinfo.dwFlags |= STARTF_USESHOWWINDOW
                startupinfo.wShowWindow = SW_HIDE
                comspec = os.environ.get("COMSPEC", "cmd.exe")
                args = comspec + " /c " + args
                if (GetVersion() >= 0x80000000L or
                        os.path.basename(comspec).lower() == "command.com"):
                    # Win9x, or using command.com on NT. We need to
                    # use the w9xpopen intermediate program. For more
                    # information, see KB Q150956
                    # (http://web.archive.org/web/20011105084002/http://support.microsoft.com/support/kb/articles/Q150/9/56.asp)
                    w9xpopen = self._find_w9xpopen()
                    args = '"%s" %s' % (w9xpopen, args)
                    # Not passing CREATE_NEW_CONSOLE has been known to
                    # cause random failures on win9x.  Specifically a
                    # dialog: "Your program accessed mem currently in
                    # use at xxx" and a hopeful warning about the
                    # stability of your system.  Cost is Ctrl+C wont
                    # kill children.
                    creationflags |= CREATE_NEW_CONSOLE

                # We create a new job for this process, so that we can kill
                # the process and any sub-processes
                self._job = winprocess.CreateJobObject()
                creationflags |= winprocess.CREATE_SUSPENDED
                # Vista will launch Komodo in a job object itself, so we need
                # to specify that the created process is not part of the Komodo
                # job object, but instead specify that it will be using a
                # separate breakaway job object, bug 83001.
                creationflags |= winprocess.CREATE_BREAKAWAY_FROM_JOB

            # Start the process
            try:
                hp, ht, pid, tid = CreateProcess(executable, args,
                                                 # no special security
                                                 None, None,
                                                 int(not close_fds),
                                                 creationflags,
                                                 env,
                                                 cwd,
                                                 startupinfo)
            except pywintypes.error, e:
                # Translate pywintypes.error to WindowsError, which is
                # a subclass of OSError.  FIXME: We should really
                # translate errno using _sys_errlist (or simliar), but
                # how can this be done from Python?
                raise WindowsError(*e.args)
            except WindowsError:
                log.error(
                    "process.py: can't execute %r (%s)", executable, args)
                raise

            # Retain the process handle, but close the thread handle
            self._child_created = True
            self._handle = hp
            self.pid = pid
            if self._job:
                # Resume the thread.
                winprocess.AssignProcessToJobObject(self._job, int(hp))
                winprocess.ResumeThread(int(ht))
            ht.Close()

            # Child is launched. Close the parent's copy of those pipe
            # handles that only the child should have open.  You need
            # to make sure that no handles to the write end of the
            # output pipe are maintained in this process or else the
            # pipe will not close when the child process exits and the
            # ReadFile will hang.
            if p2cread is not None:
                p2cread.Close()
            if c2pwrite is not None:
                c2pwrite.Close()
            if errwrite is not None:
                errwrite.Close()

        def terminate(self):
            """Terminates the process"""
            if self._job:
                winprocess.TerminateJobObject(self._job, 127)
                self.returncode = 127
            else:
                # Cannot call the parent class, as there is no terminate method
                # defined at the class level (it's added upon instantiation),
                # so this is a copy of subprocess.Popen.terminate() code.
                TerminateProcess(self._handle, 1)

        kill = terminate

    # Use our own killable process instead of the regular Popen.
    Popen = WindowsKillablePopen


class ProcessOpen(Popen):
    def __init__(self, cmd, cwd=None, env=None, flags=None,
                 stdin=PIPE, stdout=PIPE, stderr=PIPE,
                 universal_newlines=True):
        """Create a child process.

        "cmd" is the command to run, either a list of arguments or a string.
        "cwd" is a working directory in which to start the child process.
        "env" is an environment dictionary for the child.
        "flags" are system-specific process creation flags. On Windows
            this can be a bitwise-OR of any of the win32process.CREATE_*
            constants (Note: win32process.CREATE_NEW_PROCESS_GROUP is always
            OR'd in). On Unix, this is currently ignored.
        "stdin", "stdout", "stderr" can be used to specify file objects
            to handle read (stdout/stderr) and write (stdin) events from/to
            the child. By default a file handle will be created for each
            io channel automatically, unless set explicitly to None. When set
            to None, the parent io handles will be used, which can mean the
            output is redirected to Komodo's log files.
        "universal_newlines": On by default (the opposite of subprocess).
        """
        self._child_created = False
        self.__use_killpg = False
        auto_piped_stdin = False
        preexec_fn = None
        shell = False
        if not isinstance(cmd, (list, tuple)):
            # The cmd is the already formatted, ready for the shell. Otherwise
            # subprocess.Popen will treat this as simply one command with
            # no arguments, resulting in an unknown command.
            shell = True
        if sys.platform.startswith("win"):
            # On Windows, cmd requires some special handling of multiple quoted
            # arguments, as this is what cmd will do:
            #    See if the first character is a quote character and if so,
            #    strip the leading character and remove the last quote character
            #    on the command line, preserving any text after the last quote
            #    character.
            if cmd and shell and cmd.count('"') > 2:
                if not cmd.startswith('""') or not cmd.endswith('""'):
                    # Needs to be a re-quoted with additional double quotes.
                    # http://bugs.activestate.com/show_bug.cgi?id=75467
                    cmd = '"%s"' % (cmd, )

            # XXX - subprocess needs to be updated to use the wide string API.
            # subprocess uses a Windows API that does not accept unicode, so
            # we need to convert all the environment variables to strings
            # before we make the call. Temporary fix to bug:
            #   http://bugs.activestate.com/show_bug.cgi?id=72311
            if env:
                encoding = sys.getfilesystemencoding()
                _enc_env = {}
                for key, value in env.items():
                    try:
                        _enc_env[key.encode(encoding)] = value.encode(encoding)
                    except (UnicodeEncodeError, UnicodeDecodeError):
                        # Could not encode it, warn we are dropping it.
                        log.warn("Could not encode environment variable %r "
                                 "so removing it", key)
                env = _enc_env

            if flags is None:
                flags = CREATE_NO_WINDOW

            # If we don't have standard handles to pass to the child process
            # (e.g. we don't have a console app), then
            # `subprocess.GetStdHandle(...)` will return None. `subprocess.py`
            # handles that (http://bugs.python.org/issue1124861)
            #
            # However, if Komodo is started from the command line, then
            # the shell's stdin handle is inherited, i.e. in subprocess.py:
            #      p2cread = GetStdHandle(STD_INPUT_HANDLE)   # p2cread == 3
            # A few lines later this leads to:
            #    Traceback (most recent call last):
            #      ...
            #      File "...\lib\mozilla\python\komodo\process.py", line 130, in __init__
            #        creationflags=flags)
            #      File "...\lib\python\lib\subprocess.py", line 588, in __init__
            #        errread, errwrite) = self._get_handles(stdin, stdout, stderr)
            #      File "...\lib\python\lib\subprocess.py", line 709, in _get_handles
            #        p2cread = self._make_inheritable(p2cread)
            #      File "...\lib\python\lib\subprocess.py", line 773, in _make_inheritable
            #        DUPLICATE_SAME_ACCESS)
            #    WindowsError: [Error 6] The handle is invalid
            #
            # I suspect this indicates that the stdin handle inherited by
            # the subsystem:windows komodo.exe process is invalid -- perhaps
            # because of mis-used of the Windows API for passing that handle
            # through. The same error can be demonstrated in PythonWin:
            #   from _subprocess import *
            #   from subprocess import *
            #   h = GetStdHandle(STD_INPUT_HANDLE)
            #   p = Popen("python -c '1'")
            #   p._make_interitable(h)
            #
            # I don't understand why the inherited stdin is invalid for
            # `DuplicateHandle`, but here is how we are working around this:
            # If we detect the condition where this can fail, then work around
            # it by setting the handle to `subprocess.PIPE`, resulting in
            # a different and workable code path.
            if self._needToHackAroundStdHandles() \
                    and not (flags & CREATE_NEW_CONSOLE):
                if self._checkFileObjInheritable(sys.stdin, "STD_INPUT_HANDLE"):
                    stdin = PIPE
                    auto_piped_stdin = True
                if self._checkFileObjInheritable(sys.stdout, "STD_OUTPUT_HANDLE"):
                    stdout = PIPE
                if self._checkFileObjInheritable(sys.stderr, "STD_ERROR_HANDLE"):
                    stderr = PIPE
        else:
            # Set flags to 0, subprocess raises an exception otherwise.
            flags = 0
            # Set a preexec function, this will make the sub-process create it's
            # own session and process group - bug 80651, bug 85693.
            preexec_fn = os.setsid
            # Mark as requiring progressgroup killing. This will allow us to
            # later kill both the spawned shell and the sub-process in one go
            # (see the kill method) - bug 85693.
            self.__use_killpg = True

        # Internal attributes.
        self.__cmd = cmd
        self.__retval = None
        self.__hasTerminated = threading.Condition()

        # Launch the process.
        # print "Process: %r in %r" % (cmd, cwd)
        Popen.__init__(self, cmd, cwd=cwd, env=env, shell=shell,
                       stdin=stdin, stdout=stdout, stderr=stderr,
                       preexec_fn=preexec_fn,
                       universal_newlines=universal_newlines,
                       creationflags=flags)
        if auto_piped_stdin:
            self.stdin.close()

    __needToHackAroundStdHandles = None

    @classmethod
    def _needToHackAroundStdHandles(cls):
        if cls.__needToHackAroundStdHandles is None:
            if sys.platform != "win32":
                cls.__needToHackAroundStdHandles = False
            else:
                from _subprocess import GetStdHandle, STD_INPUT_HANDLE
                stdin_handle = GetStdHandle(STD_INPUT_HANDLE)
                if stdin_handle is not None:
                    cls.__needToHackAroundStdHandles = True
                    if stdin_handle != 3:
                        log.warn("`GetStdHandle(STD_INPUT_HANDLE)` != 3: "
                                 "something has changed w.r.t. std handle "
                                 "inheritance in Komodo that may affect "
                                 "subprocess launching")
                else:
                    cls.__needToHackAroundStdHandles = False
        return cls.__needToHackAroundStdHandles

    @classmethod
    def _checkFileObjInheritable(cls, fileobj, handle_name):
        """Check if a given file-like object (or whatever else subprocess.Popen
        takes as a handle/stream) can be correctly inherited by a child process.
        This just duplicates the code in subprocess.Popen._get_handles to make
        sure we go down the correct code path; this to catch some non-standard
        corner cases."""
        import _subprocess
        import ctypes
        import msvcrt
        new_handle = None
        try:
            if fileobj is None:
                handle = _subprocess.GetStdHandle(getattr(_subprocess,
                                                          handle_name))
                if handle is None:
                    return True  # No need to check things we create
            elif fileobj == subprocess.PIPE:
                return True  # No need to check things we create
            elif isinstance(fileobj, int):
                handle = msvcrt.get_osfhandle(fileobj)
            else:
                # Assuming file-like object
                handle = msvcrt.get_osfhandle(fileobj.fileno())
            new_handle = self._make_inheritable(handle)
            return True
        except:
            return False
        finally:
            CloseHandle = ctypes.windll.kernel32.CloseHandle
            if new_handle is not None:
                CloseHandle(new_handle)

    # Override the returncode handler (used by subprocess.py), this is so
    # we can notify any listeners when the process has finished.
    def _getReturncode(self):
        return self.__returncode

    def _setReturncode(self, value):
        self.__returncode = value
        if value is not None:
            # Notify that the process is done.
            self.__hasTerminated.acquire()
            self.__hasTerminated.notifyAll()
            self.__hasTerminated.release()
    returncode = property(fget=_getReturncode, fset=_setReturncode)

    # Setup the retval handler. This is a readonly wrapper around returncode.
    def _getRetval(self):
        # Ensure the returncode is set by subprocess if the process is
        # finished.
        self.poll()
        return self.returncode
    retval = property(fget=_getRetval)

    def wait(self, timeout=None):
        """Wait for the started process to complete.

        "timeout" is a floating point number of seconds after
            which to timeout.  Default is None, which is to never timeout.

        If the wait time's out it will raise a ProcessError. Otherwise it
        will return the child's exit value. Note that in the case of a timeout,
        the process is still running. Use kill() to forcibly stop the process.
        """
        if timeout is None or timeout < 0:
            # Use the parent call.
            try:
                return Popen.wait(self)
            except OSError, ex:
                # If the process has already ended, that is fine. This is
                # possible when wait is called from a different thread.
                if ex.errno != 10:  # No child process
                    raise
                return self.returncode

        # We poll for the retval, as we cannot rely on self.__hasTerminated
        # to be called, as there are some code paths that do not trigger it.
        # The accuracy of this wait call is between 0.1 and 1 second.
        time_now = time.time()
        time_end = time_now + timeout
        # These values will be used to incrementally increase the wait period
        # of the polling check, starting from the end of the list and working
        # towards the front. This is to avoid waiting for a long period on
        # processes that finish quickly, see bug 80794.
        time_wait_values = [1.0, 0.5, 0.2, 0.1]
        while time_now < time_end:
            result = self.poll()
            if result is not None:
                return result
            # We use hasTerminated here to get a faster notification.
            self.__hasTerminated.acquire()
            if time_wait_values:
                wait_period = time_wait_values.pop()
            self.__hasTerminated.wait(wait_period)
            self.__hasTerminated.release()
            time_now = time.time()
        # last chance
        result = self.poll()
        if result is not None:
            return result

        raise ProcessError("Process timeout: waited %d seconds, "
                           "process not yet finished." % (timeout,),
                           WAIT_TIMEOUT)

    # For backward compatibility with older process.py
    def close(self):
        pass

    # For backward compatibility with older process.py
    def kill(self, exitCode=-1, gracePeriod=None, sig=None):
        """Kill process.

        "exitCode" this sets what the process return value will be.
        "gracePeriod" [deprecated, not supported]
        "sig" (Unix only) is the signal to use to kill the process. Defaults
            to signal.SIGKILL. See os.kill() for more information.
        """
        if gracePeriod is not None:
            import warnings
            warnings.warn("process.kill() gracePeriod is no longer used",
                          DeprecationWarning)

        # Need to ensure stdin is closed, makes it easier to end the process.
        if self.stdin is not None:
            self.stdin.close()

        if sys.platform.startswith("win"):
            # TODO: 1) It would be nice if we could give the process(es) a
            #       chance to exit gracefully first, rather than having to
            #       resort to a hard kill.
            #       2) May need to send a WM_CLOSE event in the case of a GUI
            #       application, like the older process.py was doing.
            Popen.kill(self)
        else:
            if sig is None:
                sig = signal.SIGKILL
            try:
                if self.__use_killpg:
                    os.killpg(self.pid, sig)
                else:
                    os.kill(self.pid, sig)
            except OSError, ex:
                if ex.errno != 3:
                    # Ignore:   OSError: [Errno 3] No such process
                    raise
            self.returncode = exitCode


class AbortableProcessHelper(object):
    """A helper class that is able to run a process and have the process be
    killed/aborted (possibly by another thread) if it is still running.
    """
    STATUS_INITIALIZED = 0         # Ready to run.
    STATUS_RUNNING = 1             # A process is running.
    STATUS_FINISHED_NORMALLY = 2   # The command/process finished normally.
    STATUS_ABORTED = 3             # The command/process was aborted.

    def __init__(self):
        self._process = None
        self._process_status = self.STATUS_INITIALIZED
        self._process_status_lock = threading.Lock()

    def ProcessOpen(self, *args, **kwargs):
        """Create a new process and return it."""
        self._process_status_lock.acquire()
        try:
            self._process_status = self.STATUS_RUNNING
            self._process = ProcessOpen(*args, **kwargs)
            return self._process
        finally:
            self._process_status_lock.release()

    def ProcessDone(self):
        """Mark the process as being completed, does not need to be aborted."""
        self._process_status_lock.acquire()
        try:
            self._process = None
            self._process_status = self.STATUS_FINISHED_NORMALLY
        finally:
            self._process_status_lock.release()

    def ProcessAbort(self):
        """Kill the process if it is still running."""
        self._process_status_lock.acquire()
        try:
            self._process_status = self.STATUS_ABORTED
            if self._process:
                self._process.kill()
                self._process = None
        finally:
            self._process_status_lock.release()


## Deprecated process classes ##
class Process(ProcessOpen):
    def __init__(self, *args, **kwargs):
        warnings.warn("'process.%s' is now deprecated. Please use 'process.ProcessOpen'." %
                      (self.__class__.__name__))
        ProcessOpen.__init__(self, *args, **kwargs)


class ProcessProxy(Process):
    pass

########NEW FILE########
__FILENAME__ = sgmlop
import sys
import struct

VERSION = sys.version_info[:2]
PLATFORM = sys.platform
ARCH = 'x%d' % (struct.calcsize('P') * 8)

platform = None

if VERSION >= (3, 3):
    try:
        from _local_arch.sgmlop import *
        platform = "Local arch"
    except ImportError:
        if PLATFORM == 'darwin':
            from _macosx_universal_py33.sgmlop import *
            platform = "MacOS X Universal"
        elif PLATFORM.startswith('linux'):
            if ARCH == 'x64':
                from _linux_libcpp6_x86_64_py33.sgmlop import *
                platform = "Linux 64 bits"
            elif ARCH == 'x32':
                from _linux_libcpp6_x86_py33.sgmlop import *
                platform = "Linux 32 bits"
        elif PLATFORM.startswith('win'):
            if ARCH == 'x64':
                from _win64_py33.sgmlop import *
                platform = "Windows 64 bits"
            elif ARCH == 'x32':
                from _win32_py33.sgmlop import *
                platform = "Windows 32 bits"
elif VERSION >= (2, 6):
    try:
        from _local_arch.sgmlop import *
        platform = "Local arch"
    except ImportError:
        if PLATFORM == 'darwin':
            from _macosx_universal_py26.sgmlop import *
            platform = "MacOS X Universal"
        elif PLATFORM.startswith('linux'):
            if ARCH == 'x64':
                from _linux_libcpp6_x86_64_py26.sgmlop import *
                platform = "Linux 64 bits"
            elif ARCH == 'x32':
                from _linux_libcpp6_x86_py26.sgmlop import *
                platform = "Linux 32 bits"
        elif PLATFORM.startswith('win'):
            if ARCH == 'x64':
                from _win64_py26.sgmlop import *
                platform = "Windows 64 bits"
            elif ARCH == 'x32':
                from _win32_py26.sgmlop import *
                platform = "Windows 32 bits"

if not platform:
    raise ImportError("Could not find a suitable sgmlop binary for your platform and architecture.")

########NEW FILE########
__FILENAME__ = CPP
import HTMLGenerator
import Keywords
import Lexer
from DispatchHandler import DispatchHandler
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_CPP
import LanguageInfo


class CPPLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_CPP)
        self._keyword_lists = [
            WordList(Keywords.cpp_keywords),
            WordList(),  # User defined (important functions, constants, etc.)
            WordList(Keywords.doxygen_keywords),
            WordList(),  # "Fold header keywords" - whatever that is
            WordList(),  # Global classes and typedefs
        ]


class CPPHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_C')


class CPPHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, CPPHandler):
    name = 'cpp'
    description = 'C and C++'

    def __init__(self):
        CPPHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_C')

    def generate_html(self, file, buffer, lexer=CPPLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)


cpp_language_info = LanguageInfo.LanguageInfo(
    'C++',
    ['c', 'c+', 'c++', 'cpp', 'cxx', 'h', 'hpp'],
    [],
    [CPPHTMLGenerator]
)

LanguageInfo.register_language(cpp_language_info)

########NEW FILE########
__FILENAME__ = CSS
import HTMLGenerator
import Keywords
import Lexer
from DispatchHandler import DispatchHandler
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_CSS
import LanguageInfo


class _CSSLexerTemplate(Lexer.Lexer):
    def __init__(self, properties):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_CSS)
        self._keyword_lists = [
            WordList(Keywords.css_keywords),
            WordList(Keywords.css_pseudo_classes),
            WordList(Keywords.css_keywords_2),
            WordList(Keywords.css_properties_3),
            WordList(Keywords.css_pseudo_elements),
            WordList(Keywords.css_browser_specific_properties),
            WordList(Keywords.css_browser_specific_pseudo_classes),
            WordList(Keywords.css_browser_specific_pseudo_elements),
        ]


class CSSLexer(_CSSLexerTemplate):
    def __init__(self, properties=PropertySet()):
        _CSSLexerTemplate.__init__(self, properties)


class SCSSLexer(_CSSLexerTemplate):
    def __init__(self, properties=PropertySet()):
        _CSSLexerTemplate.__init__(self, properties)
        properties['lexer.css.scss.language'] = '1'


class LessLexer(_CSSLexerTemplate):
    def __init__(self, properties=PropertySet()):
        _CSSLexerTemplate.__init__(self, properties)
        properties['lexer.css.less.language'] = '1'


class CSSHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_CSS')


class CSSHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, CSSHandler):
    name = 'css'
    description = 'Cascading Style Sheets'

    def __init__(self):
        CSSHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_CSS')

    def generate_html(self, file, buffer, lexer=CSSLexer()):
        self._file = file
        lexer.tokenize_by_style(buffer, self.event_handler)

css_language_info = LanguageInfo.LanguageInfo(
    'css',
    ['css'],
    ['.*?css.*?'],
    [CSSHTMLGenerator]
)

LanguageInfo.register_language(css_language_info)

########NEW FILE########
__FILENAME__ = DispatchHandler
import ScintillaConstants
import Utils


def generate_handler_name(state):
    return 'handle_' + state[4:].lower()


class DispatchHandler:
    def __init__(self, state_prefix):
        self.handlers = {}
        if state_prefix is not None:
            for constant in Utils.list_states(state_prefix):
                self.handlers[getattr(ScintillaConstants, constant)] = \
                    generate_handler_name(constant)

    def event_handler(self, style, **kwargs):
        kwargs.update({'style': style})
        handler = self.handlers.get(style, None)

        if handler is None:
            self.handle_other(**kwargs)
        else:
            getattr(self, handler, self.handle_other)(**kwargs)

########NEW FILE########
__FILENAME__ = HTMLGenerator
import ScintillaConstants
import Utils


def replace(text, *replacements):
    for old, new in replacements:
        text = text.replace(old, new)

    return text


class HTMLGenerator:
    def escape(self, text):
        return replace(text, ('&', '&amp;'), ('<', '&lt;'), ('>', '&gt;'))

    def preformat(self, text):
        text = self.escape(text.expandtabs())
        return replace(text, (' ', '&nbsp;'), ('\n', '<br/>\n'))

    def markup(self, text):
        # XXX This is stolen from pydoc and is way too python-centric
        # there should be some way to extend it
        import re

        results = []
        here = 0
        pattern = re.compile(r'\b((http|ftp)://\S+[\w/]|'
                             r'RFC[- ]?(\d+)|'
                             r'PEP[- ]?(\d+))\b')
        while 1:
            match = pattern.search(text, here)
            if not match:
                break
            start, end = match.span()
            results.append(self.preformat(text[here:start]))

            all, scheme, rfc, pep = match.groups()
            if scheme:
                results.append('<a href="%s">%s</a>' % (
                    all, self.preformat(all)))
            elif rfc:
                url = 'http://www.rfc-editor.org/rfc/rfc%d.txt' % int(rfc)
                results.append('<a href="%s">%s</a>' % (
                    url, self.preformat(all)))
            elif pep:
                url = 'http://www.python.org/peps/pep-%04d.html' % int(pep)
                results.append('<a href="%s">%s</a>' % (
                    url, self.preformat(all)))

            here = end
        results.append(self.preformat(text[here:]))
        return ''.join(results)


def generate_css_name(state):
    return state[4:].lower()


class SimpleHTMLGenerator(HTMLGenerator):
    def __init__(self, state_prefix):
        self.css_classes = {}
        for constant in Utils.list_states(state_prefix):
            self.css_classes[getattr(ScintillaConstants, constant)] = \
                generate_css_name(constant)

    def handle_other(self, style, text, **ignored):
        css_class = self.css_classes.get(style, '')

        if css_class:
            self._file.write('<span class="%s">' % css_class)

        self._file.write(self.markup(text))

        if css_class:
            self._file.write('</span>')

########NEW FILE########
__FILENAME__ = HyperText
import HTMLGenerator
import Lexer
from DispatchHandler import DispatchHandler
import Keywords
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_HTML
import LanguageInfo
import re


class HyperTextLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_HTML)
        self._keyword_lists = [
            WordList(Keywords.hypertext_keywords),
            WordList(Keywords.js_keywords),
            WordList(Keywords.vb_keywords),
            WordList(Keywords.python_keywords),
            WordList(Keywords.php_keywords),
            WordList(Keywords.sgml_keywords)
        ]


class HyperTextHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_H')


class HyperTextHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, HyperTextHandler):
    name = 'html'
    description = 'HTML and PHP [with embedded: JavaScript, VBScript, Python]'

    def __init__(self):
        HyperTextHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_H')

    def generate_html(self, file, buffer, lexer=HyperTextLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)

html_language_info = LanguageInfo.LanguageInfo(
    'html',
    ['html', 'htm', 'xhtml', re.compile(
     '^php(\d)?$', re.IGNORECASE), 'inc'],
    ['.*?\<!DOCTYPE\s+html'],
    [HyperTextHTMLGenerator]
)

LanguageInfo.register_language(html_language_info)

########NEW FILE########
__FILENAME__ = JavaScript
import HTMLGenerator
import Keywords
import Lexer
from DispatchHandler import DispatchHandler
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_CPP
import LanguageInfo


class JavaScriptLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_CPP)
        self._keyword_lists = [
            WordList(Keywords.js_keywords),
            WordList(),
            WordList(),
            WordList(),
            WordList()
        ]


class JavaScriptHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_C')


class JavaScriptHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, JavaScriptHandler):
    name = 'js'
    description = 'JavaScript'

    def __init__(self):
        JavaScriptHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_C')

    def generate_html(self, file, buffer, lexer=JavaScriptLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)

javascript_language_info = LanguageInfo.LanguageInfo(
    'JavaScript',
    ['js', 'javascript'],
    [],
    [JavaScriptHTMLGenerator]
)

LanguageInfo.register_language(javascript_language_info)

########NEW FILE########
__FILENAME__ = Keywords
cpp_keywords = \
    "asm auto bool break case catch char class const const_cast continue "\
    "default delete do double dynamic_cast else enum explicit export extern false float for "\
    "friend goto if inline int long mutable namespace new operator private protected public "\
    "register reinterpret_cast return short signed sizeof static static_cast struct switch "\
    "template this throw true try typedef typeid typename union unsigned using "\
    "virtual void volatile wchar_t while"

doxygen_keywords = \
    "a addindex addtogroup anchor arg attention "\
    "author b brief bug c class code date def defgroup deprecated dontinclude "\
    "e em endcode endhtmlonly endif endlatexonly endlink endverbatim enum example exception "\
    "f$ f[ f] file fn hideinitializer htmlinclude htmlonly "\
    "if image include ingroup internal invariant interface latexonly li line link "\
    "mainpage name namespace nosubgrouping note overload "\
    "p page par param post pre ref relates remarks return retval "\
    "sa section see showinitializer since skip skipline struct subsection "\
    "test throw todo typedef union until "\
    "var verbatim verbinclude version warning weakgroup $ @ \ & < > # { }"


perl_keywords = \
    "__FILE__ __LINE__ __PACKAGE__ __DATA__ __END__ AUTOLOAD "\
    "BEGIN CHECK CORE DESTROY END INIT CHECK UNITCHECK abs accept "\
    "alarm and atan2 bind binmode bless break caller chdir chmod chomp chop "\
    "chown chr chroot close closedir cmp connect continue cos crypt "\
    "dbmclose dbmopen default defined delete die do dump each else elsif endgrent "\
    "endhostent endnetent endprotoent endpwent endservent eof eq eval "\
    "exec exists exit exp fcntl fileno flock for foreach fork format "\
    "formline ge getc getgrent getgrgid getgrnam gethostbyaddr gethostbyname "\
    "gethostent getlogin getnetbyaddr getnetbyname getnetent getpeername "\
    "getpgrp getppid getpriority getprotobyname getprotobynumber getprotoent "\
    "getpwent getpwnam getpwuid getservbyname getservbyport getservent "\
    "getsockname getsockopt given glob gmtime goto grep gt hex if import "\
    "include index "\
    "int ioctl join keys kill last lc lcfirst le length link listen "\
    "local localtime lock log lstat lt m map mkdir msgctl msgget msgrcv "\
    "msgsnd my ne new next no not oct open opendir or ord our pack package "\
    "pipe pop pos print printf prototype push q qq qr quotemeta "\
    "qw qx rand read readdir readline readlink readpipe recv redo "\
    "ref rename require reset return reverse rewinddir rindex rmdir "\
    "s say scalar seek seekdir select semctl semget semop send setgrent "\
    "sethostent setnetent setpgrp setpriority setprotoent setpwent "\
    "setservent setsockopt shift shmctl shmget shmread shmwrite shutdown "\
    "sin sleep socket socketpair sort splice split sprintf sqrt srand "\
    "stat state study sub substr symlink syscall sysopen sysread sysseek "\
    "system syswrite tell telldir tie tied time times tr truncate "\
    "uc ucfirst umask undef unless unlink unpack unshift untie until "\
    "use utime values vec wait waitpid wantarray warn when while write "\
    "x xor y"

# False None True are not strictly keywords in python2... but treat them as so.
python_keywords = \
    "False None True " \
    "and as assert break class continue def del elif else except " \
    "exec finally for from global if import in is lambda not or pass print " \
    "raise return try while with yield"

python3_keywords = \
    "False None True " \
    "and as assert break class continue def del elif else except " \
    "finally for from global if import in is lambda not or pass " \
    "raise return try while with yield"

ruby_keywords = \
    "__FILE__ and def end in or self unless __LINE__ begin "\
    "defined? ensure module redo super until BEGIN break do false next rescue "\
    "then when END case else for nil retry true while alias class elsif if "\
    "not return undef yield"

sql_keywords = \
    "ABSOLUTE ACTION ADD ADMIN AFTER AGGREGATE " \
    "ALIAS ALL ALLOCATE ALTER AND ANY ARE ARRAY AS ASC " \
    "ASSERTION AT AUTHORIZATION "\
    "BEFORE BEGIN BINARY BIT BLOB BOOLEAN BOTH BREADTH BY "\
    "CALL CASCADE CASCADED CASE CAST CATALOG CHAR CHARACTER "\
    "CHECK CLASS CLOB CLOSE COLLATE COLLATION COLUMN COMMIT "\
    "COMPLETION CONNECT CONNECTION CONSTRAINT CONSTRAINTS "\
    "CONSTRUCTOR CONTINUE CORRESPONDING CREATE CROSS CUBE CURRENT "\
    "CURRENT_DATE CURRENT_PATH CURRENT_ROLE CURRENT_TIME CURRENT_TIMESTAMP "\
    "CURRENT_USER CURSOR CYCLE "\
    "DATA DATE DAY DEALLOCATE DEC DECIMAL DECLARE DEFAULT "\
    "DEFERRABLE DEFERRED DELETE DEPTH DEREF DESC DESCRIBE DESCRIPTOR "\
    "DESTROY DESTRUCTOR DETERMINISTIC DICTIONARY DIAGNOSTICS DISCONNECT "\
    "DISTINCT DOMAIN DOUBLE DROP DYNAMIC "\
    "EACH ELSE END END-EXEC EQUALS ESCAPE EVERY EXCEPT "\
    "EXCEPTION EXEC EXECUTE EXTERNAL "\
    "FALSE FETCH FIRST FLOAT FOR FOREIGN FOUND FROM FREE FULL "\
    "FUNCTION "\
    "GENERAL GET GLOBAL GO GOTO GRANT GROUP GROUPING "\
    "HAVING HOST HOUR "\
    "IDENTITY IGNORE IMMEDIATE IN INDICATOR INITIALIZE INITIALLY "\
    "INNER INOUT INPUT INSERT INT INTEGER INTERSECT INTERVAL "\
    "INTO IS ISOLATION ITERATE "\
    "JOIN "\
    "KEY "\
    "LANGUAGE LARGE LAST LATERAL LEADING LEFT LESS LEVEL LIKE "\
    "LIMIT LOCAL LOCALTIME LOCALTIMESTAMP LOCATOR "\
    "MAP MATCH MINUTE MODIFIES MODIFY MODULE MONTH "\
    "NAMES NATIONAL NATURAL NCHAR NCLOB NEW NEXT NO NONE "\
    "NOT NULL NUMERIC "\
    "OBJECT OF OFF OLD ON ONLY OPEN OPERATION OPTION "\
    "OR ORDER ORDINALITY OUT OUTER OUTPUT "\
    "PAD PARAMETER PARAMETERS PARTIAL PATH POSTFIX PRECISION PREFIX "\
    "PREORDER PREPARE PRESERVE PRIMARY "\
    "PRIOR PRIVILEGES PROCEDURE PUBLIC "\
    "READ READS REAL RECURSIVE REF REFERENCES REFERENCING RELATIVE "\
    "RESTRICT RESULT RETURN RETURNS REVOKE RIGHT "\
    "ROLE ROLLBACK ROLLUP ROUTINE ROW ROWS "\
    "SAVEPOINT SCHEMA SCROLL SCOPE SEARCH SECOND SECTION SELECT "\
    "SEQUENCE SESSION SESSION_USER SET SETS SIZE SMALLINT SOME| SPACE "\
    "SPECIFIC SPECIFICTYPE SQL SQLEXCEPTION SQLSTATE SQLWARNING START "\
    "STATE STATEMENT STATIC STRUCTURE SYSTEM_USER "\
    "TABLE TEMPORARY TERMINATE THAN THEN TIME TIMESTAMP "\
    "TIMEZONE_HOUR TIMEZONE_MINUTE TO TRAILING TRANSACTION TRANSLATION "\
    "TREAT TRIGGER TRUE "\
    "UNDER UNION UNIQUE UNKNOWN "\
    "UNNEST UPDATE USAGE USER USING "\
    "VALUE VALUES VARCHAR VARIABLE VARYING VIEW "\
    "WHEN WHENEVER WHERE WITH WITHOUT WORK WRITE "\
    "YEAR "\
    "ZONE"

vxml_elements =\
    "assign audio block break catch choice clear disconnect else elseif "\
    "emphasis enumerate error exit field filled form goto grammar help "\
    "if initial link log menu meta noinput nomatch object option p paragraph "\
    "param phoneme prompt property prosody record reprompt return s say-as "\
    "script sentence subdialog submit throw transfer value var voice vxml"

vxml_attributes =\
    "accept age alphabet anchor application base beep bridge category charset "\
    "classid cond connecttimeout content contour count dest destexpr dtmf dtmfterm "\
    "duration enctype event eventexpr expr expritem fetchtimeout finalsilence "\
    "gender http-equiv id level maxage maxstale maxtime message messageexpr "\
    "method mime modal mode name namelist next nextitem ph pitch range rate "\
    "scope size sizeexpr skiplist slot src srcexpr sub time timeexpr timeout "\
    "transferaudio type value variant version volume xml:lang"

vxml_keywords = vxml_elements + " " + vxml_attributes + " " + "public !doctype"

html4_elements =\
    "a abbr acronym address applet area b base basefont " \
    "bdo big blockquote body br button caption center " \
    "cite code col colgroup dd del dfn dir div dl dt em " \
    "fieldset font form frame frameset h1 h2 h3 h4 h5 h6 " \
    "head hr html i iframe img input ins isindex kbd label " \
    "legend li link map menu meta noframes noscript " \
    "object ol optgroup option p param pre q s samp " \
    "script select small span strike strong style sub sup " \
    "table tbody td textarea tfoot th thead title tr tt u ul " \
    "var xml xmlns"

html5_elements =\
    "article aside audio canvas command datalist details dialog " \
    "embed figcaption figure footer header hgroup keygen mark menu " \
    "meter nav output progress rp rt ruby section source summary " \
    "time video"

# Note: There hypertext_elements are not sorted!
hypertext_elements = html4_elements + " " + html5_elements

hypertext_attributes =\
    "abbr accept-charset accept accesskey action align alink " \
    "alt archive axis background bgcolor border " \
    "cellpadding cellspacing char charoff charset checked cite " \
    "class classid clear codebase codetype color cols colspan " \
    "compact content coords " \
    "data datafld dataformatas datapagesize datasrc datetime " \
    "declare defer dir disabled enctype event " \
    "face for frame frameborder " \
    "headers height href hreflang hspace http-equiv " \
    "id ismap label lang language leftmargin link longdesc " \
    "marginwidth marginheight maxlength media method multiple " \
    "name nohref noresize noshade nowrap " \
    "object onblur onchange onclick ondblclick onfocus " \
    "onkeydown onkeypress onkeyup onload onmousedown " \
    "onmousemove onmouseover onmouseout onmouseup " \
    "onreset onselect onsubmit onunload " \
    "profile prompt readonly rel rev rows rowspan rules " \
    "scheme scope selected shape size span src standby start style " \
    "summary tabindex target text title topmargin type usemap " \
    "valign value valuetype version vlink vspace width " \
    "text password checkbox radio submit reset " \
    "file hidden image"

hypertext_keywords = hypertext_elements + " " + \
    hypertext_attributes + " " + "public !doctype"

php_keywords =\
    "and argv as argc break case cfunction class continue declare default do "\
    "die echo else elseif empty enddeclare endfor endforeach endif endswitch "\
    "endwhile E_ALL E_PARSE E_ERROR E_WARNING eval exit extends FALSE for "\
    "foreach function global HTTP_COOKIE_VARS HTTP_GET_VARS HTTP_POST_VARS "\
    "HTTP_POST_FILES HTTP_ENV_VARS HTTP_SERVER_VARS if include include_once "\
    "list new not NULL old_function or parent PHP_OS PHP_SELF PHP_VERSION "\
    "print require require_once return static switch stdClass this TRUE var "\
    "xor virtual while __FILE__ __LINE__ __sleep __wakeup"

sgml_keywords = "ELEMENT DOCTYPE ATTLIST ENTITY NOTATION"

yaml_keywords = "true false yes no"

xslt_elements = \
    "apply-templates call-template apply-imports for-each value-of copy-of "\
    "number choose if text copy variable message fallback "\
    "processing-instruction comment element attribute import include "\
    "strip-space preserve-space output key decimal-format attribute-set "\
    "variable param template namespace-alias stylesheet transform when "\
    "otherwise"

xslt_attributes = \
    "extension-element-prefixes exclude-result-prefixes id version "\
    "xmlns:xsl href elements method encoding omit-xml-declaration "\
    "standalone doctype-public doctype-system cdata-section-elements "\
    "indent media-type name match use name decimal-separator "\
    "grouping-separator infinity minus-sign NaN percent per-mille "\
    "zero-digit digit pattern-separator stylesheet-prefix "\
    "result-prefix match name priority mode select "\
    "disable-output-escaping level count from value format lang "\
    "letter-value grouping-separator grouping-size lang data-type "\
    "order case-order test use-attribute-sets " \
    "disable-output-escaping namespace terminate"\


xslt_keywords = xslt_elements + " " + xslt_attributes + " " + ' '.join(
    ['xsl:' + word for word in (
     xslt_elements + " " + xslt_attributes).split(' ')]
)

js_keywords = (
    "abstract boolean break byte case catch "
    "char class const continue debugger default "
    "delete do double else enum export "
    "extends false final finally float for function "
    "goto if implements import in instanceof "
    "int interface long native new null package "
    "private protected public return short "
    "static super switch synchronized this throw "
    "throws transient true try typeof var void "
    "while with")

# http://msdn.microsoft.com/library/default.asp?url=/library/en-
# us/vblr7/html/vaorivblangkeywordsall.asp
vb_keywords = (
    "addhandler addressof alias and andalso  ansi as assembly "
    "auto boolean byref byte byval call case catch "
    "cbool cbyte cchar cdate cdec cdbl char cint "
    "class clng cobj const cshort csng cstr ctype "
    "date decimal declare default delegate dim directcast do "
    "double each else elseif end enum erase error "
    "event exit false finally for friend function get "
    "gettype gosub goto handles if implements imports in "
    "inherits integer interface is let lib like long "
    "loop me mod module mustinherit mustoverride mybase myclass "
    "namespace new next not nothing notinheritable notoverridable object "
    "on option optional or orelse overloads overridable overrides "
    "paramarray preserve private property protected public raiseevent "
    "readonly redim rem removehandler resume "
    "return select set shadows step stop string structure "
    "sub synclock then throw to true try typeof "
    "unicode until variant when while with withevents writeonly xor")

css_keywords = \
    """
    background background-attachment background-color background-image
    background-position background-repeat border border-bottom
    border-bottom-width border-color border-left border-left-width
    border-right border-right-width border-style border-top
    border-top-width border-width clear color display float font
    font-family font-size font-style font-variant font-weight height
    letter-spacing line-height list-style list-style-image
    list-style-position list-style-type margin margin-bottom margin-left
    margin-right margin-top padding padding-bottom padding-left
    padding-right padding-top text-align text-decoration text-indent
    text-transform vertical-align white-space width word-spacing
    """
css_pseudo_classes = \
    """
    active after before first first-child first-letter first-line
    focus hover lang left link right visited
    """

css_keywords_2 = \
    """
    ascent azimuth baseline bbox border-bottom-color
    border-bottom-style border-collapse border-color border-left-color
    border-left-style border-right-color border-right-style
    border-spacing border-style border-top-color border-top-style
    bottom cap-height caption-side centerline clip content
    counter-increment counter-reset cue cue-after cue-before cursor
    definition-src descent direction elevation empty-cells
    font-size-adjust font-stretch left marker-offset marks mathline
    max-height max-width min-height min-width orphans outline
    outline-color outline-style outline-width overflow page
    page-break-after page-break-before page-break-inside panose-1
    pause pause-after pause-before pitch pitch-range play-during
    position quotes richness right size slope speak speak-header
    speak-numeral speak-punctuation speech-rate src stemh stemv stress
    table-layout text-shadow top topline unicode-bidi unicode-range
    units-per-em visibility voice-family volume widows widths x-height
    z-index
    """

css_properties_3 = \
    ""

css_pseudo_elements = \
    ""
css_browser_specific_properties = \
    ""
css_browser_specific_pseudo_classes = \
    ""
css_browser_specific_pseudo_elements = \
    ""

postscript_level1_keywords = \
    "$error = == FontDirectory StandardEncoding UserObjects abs add aload " \
    "anchorsearch and arc arcn arcto array ashow astore atan awidthshow begin bind " \
    "bitshift bytesavailable cachestatus ceiling charpath clear cleardictstack " \
    "cleartomark clip clippath closefile closepath concat concatmatrix copy copypage " \
    "cos count countdictstack countexecstack counttomark currentcmykcolor " \
    "currentcolorspace currentdash currentdict currentfile currentflat currentfont " \
    "currentgray currenthsbcolor currentlinecap currentlinejoin currentlinewidth " \
    "currentmatrix currentmiterlimit currentpagedevice currentpoint currentrgbcolor " \
    "currentscreen currenttransfer cvi cvlit cvn cvr cvrs cvs cvx def defaultmatrix " \
    "definefont dict dictstack div dtransform dup echo end eoclip eofill eq " \
    "erasepage errordict exch exec execstack executeonly executive exit exp false " \
    "file fill findfont flattenpath floor flush flushfile for forall ge get " \
    "getinterval grestore grestoreall gsave gt idetmatrix idiv idtransform if ifelse " \
    "image imagemask index initclip initgraphics initmatrix inustroke invertmatrix " \
    "itransform known kshow le length lineto ln load log loop lt makefont mark " \
    "matrix maxlength mod moveto mul ne neg newpath noaccess nor not null nulldevice " \
    "or pathbbox pathforall pop print prompt pstack put putinterval quit rand rcheck " \
    "rcurveto read readhexstring readline readonly readstring rectstroke repeat " \
    "resetfile restore reversepath rlineto rmoveto roll rotate round rrand run save " \
    "scale scalefont search setblackgeneration setcachedevice setcachelimit " \
    "setcharwidth setcolorscreen setcolortransfer setdash setflat setfont setgray " \
    "sethsbcolor setlinecap setlinejoin setlinewidth setmatrix setmiterlimit " \
    "setpagedevice setrgbcolor setscreen settransfer setvmthreshold show showpage " \
    "sin sqrt srand stack start status statusdict stop stopped store string " \
    "stringwidth stroke strokepath sub systemdict token token transform translate " \
    "true truncate type ueofill undefineresource userdict usertime version vmstatus " \
    "wcheck where widthshow write writehexstring writestring xcheck xor " \

postscript_level2_keywords = \
    "GlobalFontDirectory ISOLatin1Encoding SharedFontDirectory UserObject arct " \
    "colorimage cshow currentblackgeneration currentcacheparams currentcmykcolor " \
    "currentcolor currentcolorrendering currentcolorscreen currentcolorspace " \
    "currentcolortransfer currentdevparams currentglobal currentgstate " \
    "currenthalftone currentobjectformat currentoverprint currentpacking " \
    "currentpagedevice currentshared currentstrokeadjust currentsystemparams " \
    "currentundercolorremoval currentuserparams defineresource defineuserobject " \
    "deletefile execform execuserobject filenameforall fileposition filter " \
    "findencoding findresource gcheck globaldict glyphshow gstate ineofill infill " \
    "instroke inueofill inufill inustroke languagelevel makepattern packedarray " \
    "printobject product realtime rectclip rectfill rectstroke renamefile " \
    "resourceforall resourcestatus revision rootfont scheck selectfont serialnumber " \
    "setbbox setblackgeneration setcachedevice2 setcacheparams setcmykcolor setcolor " \
    "setcolorrendering setcolorscreen setcolorspace setcolortranfer setdevparams " \
    "setfileposition setglobal setgstate sethalftone setobjectformat setoverprint " \
    "setpacking setpagedevice setpattern setshared setstrokeadjust setsystemparams " \
    "setucacheparams setundercolorremoval setuserparams setvmthreshold shareddict " \
    "startjob uappend ucache ucachestatus ueofill ufill undef undefinefont " \
    "undefineresource undefineuserobject upath ustroke ustrokepath vmreclaim " \
    "writeobject xshow xyshow yshow"

postscript_level3_keywords = \
    "cliprestore clipsave composefont currentsmoothness findcolorrendering " \
    "setsmoothness shfill"

postscript_ripspecific_keywords = \
    ".begintransparencygroup .begintransparencymask .bytestring .charboxpath " \
    ".currentaccuratecurves .currentblendmode .currentcurvejoin .currentdashadapt " \
    ".currentdotlength .currentfilladjust2 .currentlimitclamp .currentopacityalpha " \
    ".currentoverprintmode .currentrasterop .currentshapealpha " \
    ".currentsourcetransparent .currenttextknockout .currenttexturetransparent " \
    ".dashpath .dicttomark .discardtransparencygroup .discardtransparencymask " \
    ".endtransparencygroup .endtransparencymask .execn .filename .filename " \
    ".fileposition .forceput .forceundef .forgetsave .getbitsrect .getdevice " \
    ".inittransparencymask .knownget .locksafe .makeoperator .namestring .oserrno " \
    ".oserrorstring .peekstring .rectappend .runandhide .setaccuratecurves " \
    ".setblendmode .setcurvejoin .setdashadapt .setdebug .setdefaultmatrix " \
    ".setdotlength .setfilladjust2 .setlimitclamp .setmaxlength .setopacityalpha " \
    ".setoverprintmode .setrasterop .setsafe .setshapealpha .setsourcetransparent " \
    ".settextknockout .settexturetransparent .stringbreak .stringmatch .tempfile " \
    ".type1decrypt .type1encrypt .type1execchar .unread arccos arcsin copydevice " \
    "copyscanlines currentdevice finddevice findlibfile findprotodevice flushpage " \
    "getdeviceprops getenv makeimagedevice makewordimagedevice max min " \
    "putdeviceprops setdevice"

########NEW FILE########
__FILENAME__ = LanguageInfo
import re
import os
import types


class LanguageInfo:
    def __init__(self, language_name, extension_patterns, shebang_patterns, html_generators):
        self.language_name = language_name

        self.extension_patterns = []
        self.extension_patterns = extension_patterns
        self.shebang_patterns = shebang_patterns
        self.html_generators = html_generators

    def known_extension(self, extension):
        for pattern in self.extension_patterns:
            # pattern can either be a regular expression or a
            # string
            if isinstance(pattern, types.StringTypes):
                if extension.lower() == pattern.lower():
                    return 1
            elif pattern.match(extension):
                return 1
        return 0

    def known_shebang(self, shebang):
        for pattern in self.shebang_patterns:
            if re.match(pattern, shebang):
                return 1
        return 0

    def get_default_html_generator(self):
        return self.html_generators[0]


def guess_languages_for_shebang(shebang):
    guesses = []
    for language in registered_languages:
        if language.known_shebang(shebang):
            guesses.append(language)

    return guesses


def guess_languages_for_extension(extension):
    guesses = []
    for language in registered_languages:
        if language.known_extension(extension):
            guesses.append(language)

    return guesses


def guess_language_for_file(filename):
    ext = os.path.splitext(os.path.basename(filename))[1]
    if len(ext) > 1:
        ext = ext[1:]
        extension_guesses = guess_languages_for_extension(ext)
    else:
        extension_guesses = []

    if len(extension_guesses) == 1:
        return extension_guesses[0]
    else:
        shebang = open(filename, 'r').readline()
        shebang_guesses = guess_languages_for_shebang(shebang)

        guesses = [eg for eg in extension_guesses
                   if eg in shebang_guesses]

        if len(guesses) == 1:
            return guesses[0]

        import NULL
        return NULL.null_language_info


def guess_language_for_buffer(buffer):
    shebang = buffer.split('\n')[0]
    guesses = guess_languages_for_shebang(shebang)

    if len(guesses) == 1:
        return guesses[0]

    import NULL
    return NULL.null_language_info


def find_generator_by_name(name):
    for language in registered_languages:
        for generator in language.html_generators:
            if name == generator.name:
                return generator


def get_generator_names():
    names = []
    for language in registered_languages:
        for generator in language.html_generators:
            names.append(generator.name)

    return names


def get_generator_names_descriptions():
    """Return a tuple of the name and description"""
    descs = []
    for language in registered_languages:
        for generator in language.html_generators:
            # if there is no description, use the name
            description = getattr(generator, "description", None)
            if description is None:
                description = generator.name
            descs.append((generator.name, description))

    return descs

registered_languages = []


def register_language(language):
    registered_languages.append(language)


def add_extension(name, ext):
    """Add an extension pattern (in regular expression syntax) to
    the named generator"""

    languages = []
    for language in registered_languages:
        for generator in language.html_generators:
            if name == generator.name:
                language.extension_patterns.append(ext)


def do_registration():
    import CPP
    import CSS
    import HyperText
    import JavaScript
    import NULL
    import Perl
    import Python
    import PostScript
    import Ruby
    import SQL
    import YAML
    import XML
    import XSLT

########NEW FILE########
__FILENAME__ = Lexer
class Lexer:
    def tokenize_by_style(self, buffer, call_back=None):
        if call_back is not None:
            return self._lexer.tokenize_by_style(
                buffer,
                self._keyword_lists,
                self._properties,
                call_back
            )
        else:
            return self._lexer.tokenize_by_style(
                buffer,
                self._keyword_lists,
                self._properties
            )

########NEW FILE########
__FILENAME__ = NULL
import HTMLGenerator
import Lexer
from DispatchHandler import DispatchHandler
import Keywords
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_NULL
import LanguageInfo


class NULLLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_NULL)
        self._keyword_lists = []


class NULLHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, None)


class NULLHTMLGenerator(HTMLGenerator.HTMLGenerator, NULLHandler):
    name = 'null'
    description = 'No styling'

    def __init__(self):
        NULLHandler.__init__(self)

    def generate_html(self, file, buffer, lexer=NULLLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)

    def handle_other(self, style, text, **ignored):
        self._file.write(self.markup(text))

null_language_info = LanguageInfo.LanguageInfo(
    'null',
    ['text', 'txt'],
    [],
    [NULLHTMLGenerator]
)

LanguageInfo.register_language(null_language_info)

########NEW FILE########
__FILENAME__ = Perl
import HTMLGenerator
import Keywords
import Lexer
from DispatchHandler import DispatchHandler
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_PERL
import LanguageInfo


class PerlLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_PERL)
        self._keyword_lists = [
            WordList(Keywords.perl_keywords),
        ]


class PerlHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_PL')


class PerlHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, PerlHandler):
    name = 'perl'
    description = 'Perl'

    def __init__(self):
        PerlHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_PL')

    def generate_html(self, file, buffer, lexer=PerlLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)

perl_language_info = LanguageInfo.LanguageInfo(
    'perl',
    ['pl', 'cgi'],
    ['.*?perl.*?'],
    [PerlHTMLGenerator]
)

LanguageInfo.register_language(perl_language_info)

########NEW FILE########
__FILENAME__ = PostScript
import HTMLGenerator
import Keywords
import Lexer
from DispatchHandler import DispatchHandler
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_PS
import LanguageInfo


class PostScriptLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_PS)
        self._keyword_lists = [
            WordList(Keywords.postscript_level1_keywords),
            WordList(Keywords.postscript_level2_keywords),
            WordList(Keywords.postscript_level3_keywords),
            WordList(Keywords.postscript_ripspecific_keywords),
            WordList()
        ]


class PostScriptHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_PS')


class PostScriptHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, PostScriptHandler):
    name = 'ps'
    description = 'PostScript'

    def __init__(self):
        PostScriptHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_PS')

    def generate_html(self, file, buffer, lexer=PostScriptLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)

postscript_language_info = LanguageInfo.LanguageInfo(
    'PostScript',
    ['ps', 'eps', 'postscript'],
    ['.*?PS-.*?'],
    [PostScriptHTMLGenerator]
)

LanguageInfo.register_language(postscript_language_info)

########NEW FILE########
__FILENAME__ = Python
import HTMLGenerator
import Lexer
import Keywords
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from DispatchHandler import DispatchHandler
from ScintillaConstants import SCLEX_PYTHON
import LanguageInfo


class PythonLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_PYTHON)
        self._keyword_lists = [
            WordList(Keywords.python_keywords)
        ]


class PythonHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_P')

    def event_handler(self, style, **kwargs):
        kwargs.update({'style': style})
        # Mask out tab.timmy.whinge.level for dispatch
        handler = self.handlers.get(style & 63, None)
        if handler is None:
            self.handle_other(**kwargs)

        getattr(self, handler, self.handle_other)(**kwargs)


class PythonHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, PythonHandler):
    name = 'python'
    description = 'Python'

    def __init__(self):
        PythonHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_P')

    def handle_other(self, style, text, **ignored):
        tab_problem = style & 64
        style = style & 63
        css_class = self.css_classes.get(style, '')

        if css_class:
            self._file.write('<span class="%s">' % css_class)

        if tab_problem:
            self._file.write('<span class="p_tabtimmywingylevel">')

        self._file.write(self.markup(text))

        if tab_problem:
            self._file.write('</span>')

        if css_class:
            self._file.write('</span>')

    def generate_html(self, file, buffer, lexer=PythonLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)

import HyperText


class EmbeddedHyperTextHTMLGenerator(HyperText.HyperTextHTMLGenerator):
    def handle_h_tag(self, text, **ignored):
        self._file.write('<span class="python_h_tag">')
        self._file.write(self.markup(text))
        self._file.write('</span>')

    def handle_h_tag_unknown(self, **kwargs):
        self.handle_h_tag(**kwargs)

    def handle_h_attribute(self, text, **ignored):
        self._file.write('<span class="python_h_attribute">')
        self._file.write(self.markup(text))
        self._file.write('</span>')

    def handle_h_attribute_unknown(self, **kwargs):
        self.handle_h_attribute(**kwargs)

    def handle_h_double_string(self, text, **ignored):
        self._file.write('<span class="python_h_string">')
        self._file.write(self.markup(text))
        self._file.write('</span>')

    def handle_h_string_string(self, **kwargs):
        self.handle_h_double_string(**kwargs)

    def handle_other(self, style, text, **ignored):
        self._file.write('<span class="python_string">')
        self._file.write(self.markup(text))
        self._file.write('</span>')


def looks_like_markup(s):
    return s.count('<') and (s.count('/>') or s.count('</'))


def looks_like_xsl(s):
    return s.find('xsl:') != -1


def looks_like_html(s):
    # This is pretty bad...
    return s.count('html')


def guess_generator(s):
    import HyperText
    import XML
    import XSLT

    if looks_like_markup(s):
        if looks_like_xsl(s):
            return XSLT.XSLTHTMLGenerator()
        elif looks_like_html(s):
            return HyperText.HyperTextHTMLGenerator()
        else:
            return XML.XMLHTMLGenerator()

    return None


class SmartPythonHTMLGenerator(PythonHTMLGenerator):
    name = 'smart_python'
    description = 'Python with styled strings'

    def __init__(self):
        PythonHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_P')

    def handle_p_string(self, text, **ignored):
        generator = guess_generator(text)
        if generator is not None:
            generator.generate_html(self._file, text)
        else:
            self.handle_other(text=text, **ignored)

    def handle_p_character(self, **kwargs):
        self.handle_p_string(**kwargs)

    def handle_p_triple(self, **kwargs):
        self.handle_p_string(**kwargs)

    def handle_p_tripledouble(self, **kwargs):
        self.handle_p_string(**kwargs)

    def handle_p_stringeol(self, **kwargs):
        self.handle_p_string(**kwargs)


python_language_info = LanguageInfo.LanguageInfo(
    'python',
    ['py', 'pyw', 'cgi'],
    ['.*?python.*?'],
    [PythonHTMLGenerator, SmartPythonHTMLGenerator]
)

LanguageInfo.register_language(python_language_info)

########NEW FILE########
__FILENAME__ = Ruby
import HTMLGenerator
import Lexer
import Keywords
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from DispatchHandler import DispatchHandler
from ScintillaConstants import SCLEX_RUBY
import LanguageInfo
import Python


class RubyLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_RUBY)
        self._keyword_lists = [
            WordList(Keywords.ruby_keywords)
        ]


class RubyHandler(Python.PythonHandler):
    pass

# This is a hack since we now subclass PythonHandler instead of
# RubyHandler


class RubyHTMLGenerator(Python.PythonHTMLGenerator):
    name = 'ruby'
    description = 'Ruby'

    def __init__(self):
        Python.PythonHTMLGenerator.__init__(self)

    def generate_html(self, file, buffer, lexer=RubyLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)

ruby_language_info = LanguageInfo.LanguageInfo(
    'ruby',
    ['rb', 'cgi'],
    ['.*?ruby.*?'],
    [RubyHTMLGenerator]
)

LanguageInfo.register_language(ruby_language_info)

########NEW FILE########
__FILENAME__ = ScintillaConstants
# The file was automatically generated by write_scintilla.py
# from Scintilla.iface
#
# Do not manually edit!

# LexerModule ids (used in find_lexer_module_by_id)

SCLEX_CONTAINER = 0
SCLEX_NULL = 1
SCLEX_PYTHON = 2
SCLEX_CPP = 3
SCLEX_HTML = 4
SCLEX_XML = 5
SCLEX_PERL = 6
SCLEX_SQL = 7
SCLEX_VB = 8
SCLEX_PROPERTIES = 9
SCLEX_ERRORLIST = 10
SCLEX_MAKEFILE = 11
SCLEX_BATCH = 12
SCLEX_XCODE = 13
SCLEX_LATEX = 14
SCLEX_LUA = 15
SCLEX_DIFF = 16
SCLEX_CONF = 17
SCLEX_PASCAL = 18
SCLEX_AVE = 19
SCLEX_ADA = 20
SCLEX_LISP = 21
SCLEX_RUBY = 22
SCLEX_EIFFEL = 23
SCLEX_EIFFELKW = 24
SCLEX_TCL = 25
SCLEX_NNCRONTAB = 26
SCLEX_BULLANT = 27
SCLEX_VBSCRIPT = 28
SCLEX_BAAN = 31
SCLEX_MATLAB = 32
SCLEX_SCRIPTOL = 33
SCLEX_ASM = 34
SCLEX_CPPNOCASE = 35
SCLEX_FORTRAN = 36
SCLEX_F77 = 37
SCLEX_CSS = 38
SCLEX_POV = 39
SCLEX_LOUT = 40
SCLEX_ESCRIPT = 41
SCLEX_PS = 42
SCLEX_NSIS = 43
SCLEX_MMIXAL = 44
SCLEX_CLW = 45
SCLEX_CLWNOCASE = 46
SCLEX_LOT = 47
SCLEX_YAML = 48
SCLEX_TEX = 49
SCLEX_METAPOST = 50
SCLEX_POWERBASIC = 51
SCLEX_FORTH = 52
SCLEX_ERLANG = 53
SCLEX_OCTAVE = 54
SCLEX_MSSQL = 55
SCLEX_VERILOG = 56
SCLEX_KIX = 57
SCLEX_GUI4CLI = 58
SCLEX_SPECMAN = 59
SCLEX_AU3 = 60
SCLEX_APDL = 61
SCLEX_BASH = 62
SCLEX_ASN1 = 63
SCLEX_VHDL = 64
SCLEX_CAML = 65
SCLEX_BLITZBASIC = 66
SCLEX_PUREBASIC = 67
SCLEX_HASKELL = 68
SCLEX_PHPSCRIPT = 69
SCLEX_TADS3 = 70
SCLEX_REBOL = 71
SCLEX_SMALLTALK = 72
SCLEX_FLAGSHIP = 73
SCLEX_CSOUND = 74
SCLEX_FREEBASIC = 75
SCLEX_INNOSETUP = 76
SCLEX_OPAL = 77
SCLEX_SPICE = 78
SCLEX_D = 79
SCLEX_CMAKE = 80
SCLEX_GAP = 81
SCLEX_PLM = 82
SCLEX_PROGRESS = 83
SCLEX_ABAQUS = 84
SCLEX_ASYMPTOTE = 85
SCLEX_R = 86
SCLEX_MAGIK = 87
SCLEX_POWERSHELL = 88
SCLEX_MYSQL = 89
SCLEX_PO = 90
SCLEX_TAL = 91
SCLEX_COBOL = 92
SCLEX_TACL = 93
SCLEX_SORCUS = 94
SCLEX_POWERPRO = 95
SCLEX_NIMROD = 96
SCLEX_SML = 97
SCLEX_MARKDOWN = 98
SCLEX_TXT2TAGS = 99
SCLEX_A68K = 100
SCLEX_MODULA = 101
SCLEX_COFFEESCRIPT = 102
SCLEX_TCMD = 103
SCLEX_AVS = 104
SCLEX_ECL = 105
SCLEX_OSCRIPT = 106
SCLEX_VISUALPROLOG = 107
SCLEX_LITERATEHASKELL = 108
SCLEX_STTXT = 109
SCLEX_XSLT = 110
SCLEX_UDL = 111
SCLEX_AUTOMATIC = 1000

# Lexical states (style constants returned by tokenize_by_style)


SCE_P_DEFAULT = 0
SCE_P_COMMENTLINE = 1
SCE_P_NUMBER = 2
SCE_P_STRING = 3
SCE_P_CHARACTER = 4
SCE_P_WORD = 5
SCE_P_TRIPLE = 6
SCE_P_TRIPLEDOUBLE = 7
SCE_P_CLASSNAME = 8
SCE_P_DEFNAME = 9
SCE_P_OPERATOR = 10
SCE_P_IDENTIFIER = 11
SCE_P_COMMENTBLOCK = 12
SCE_P_STRINGEOL = 13
SCE_P_WORD2 = 14
SCE_P_DECORATOR = 15
SCE_P_STDIN  =  16
SCE_P_STDOUT  =  17
SCE_P_STDERR  =  18
SCE_P_UPPER_BOUND = 19

SCE_C_DEFAULT = 0
SCE_C_COMMENT = 1
SCE_C_COMMENTLINE = 2
SCE_C_COMMENTDOC = 3
SCE_C_NUMBER = 4
SCE_C_WORD = 5
SCE_C_STRING = 6
SCE_C_CHARACTER = 7
SCE_C_UUID = 8
SCE_C_PREPROCESSOR = 9
SCE_C_OPERATOR = 10
SCE_C_IDENTIFIER = 11
SCE_C_STRINGEOL = 12
SCE_C_VERBATIM = 13
SCE_C_REGEX = 14
SCE_C_COMMENTLINEDOC = 15
SCE_C_WORD2 = 16
SCE_C_COMMENTDOCKEYWORD = 17
SCE_C_COMMENTDOCKEYWORDERROR = 18
SCE_C_GLOBALCLASS = 19
SCE_C_STRINGRAW = 20
SCE_C_TRIPLEVERBATIM = 21
SCE_C_HASHQUOTEDSTRING = 22
SCE_C_PREPROCESSORCOMMENT = 23
SCE_C_PREPROCESSORCOMMENTDOC = 24
SCE_C_STDIN = 25
SCE_C_STDOUT = 26
SCE_C_STDERR = 27

SCE_D_DEFAULT = 0
SCE_D_COMMENT = 1
SCE_D_COMMENTLINE = 2
SCE_D_COMMENTDOC = 3
SCE_D_COMMENTNESTED = 4
SCE_D_NUMBER = 5
SCE_D_WORD = 6
SCE_D_WORD2 = 7
SCE_D_WORD3 = 8
SCE_D_TYPEDEF = 9
SCE_D_STRING = 10
SCE_D_STRINGEOL = 11
SCE_D_CHARACTER = 12
SCE_D_OPERATOR = 13
SCE_D_IDENTIFIER = 14
SCE_D_COMMENTLINEDOC = 15
SCE_D_COMMENTDOCKEYWORD = 16
SCE_D_COMMENTDOCKEYWORDERROR = 17
SCE_D_STRINGB = 18
SCE_D_STRINGR = 19
SCE_D_WORD5 = 20
SCE_D_WORD6 = 21
SCE_D_WORD7 = 22

SCE_TCL_DEFAULT = 0
SCE_TCL_COMMENT = 1
SCE_TCL_VARIABLE = 2
SCE_TCL_ARRAY = 3
SCE_TCL_NUMBER = 4
SCE_TCL_WORD = 5
SCE_TCL_STRING = 6
SCE_TCL_CHARACTER = 7
SCE_TCL_LITERAL = 8
SCE_TCL_IDENTIFIER = 9
SCE_TCL_OPERATOR = 10
SCE_TCL_EOL = 11
SCE_TCL_STDIN = 12
SCE_TCL_STDOUT = 13
SCE_TCL_STDERR = 14
SCE_TCL_UPPER_BOUND = 15

SCE_H_DEFAULT = 0
SCE_H_TAG = 1
SCE_H_TAGUNKNOWN = 2
SCE_H_ATTRIBUTE = 3
SCE_H_ATTRIBUTEUNKNOWN = 4
SCE_H_NUMBER = 5
SCE_H_DOUBLESTRING = 6
SCE_H_SINGLESTRING = 7
SCE_H_OTHER = 8
SCE_H_COMMENT = 9
SCE_H_ENTITY = 10
SCE_H_TAGEND = 11
SCE_H_XMLSTART = 12
SCE_H_XMLEND = 13
SCE_H_SCRIPT = 14
SCE_H_ASP = 15
SCE_H_ASPAT = 16
SCE_H_CDATA = 17
SCE_H_QUESTION = 18
SCE_H_VALUE = 19
SCE_H_XCCOMMENT = 20
SCE_H_SGML_DEFAULT = 21
SCE_H_SGML_COMMAND = 22
SCE_H_SGML_1ST_PARAM = 23
SCE_H_SGML_DOUBLESTRING = 24
SCE_H_SGML_SIMPLESTRING = 25
SCE_H_SGML_ERROR = 26
SCE_H_SGML_SPECIAL = 27
SCE_H_SGML_ENTITY = 28
SCE_H_SGML_COMMENT = 29
SCE_H_SGML_1ST_PARAM_COMMENT = 30
SCE_H_SGML_BLOCK_DEFAULT = 31

SCE_HJ_START = 40
SCE_HJ_DEFAULT = 41
SCE_HJ_COMMENT = 42
SCE_HJ_COMMENTLINE = 43
SCE_HJ_COMMENTDOC = 44
SCE_HJ_NUMBER = 45
SCE_HJ_WORD = 46
SCE_HJ_KEYWORD = 47
SCE_HJ_DOUBLESTRING = 48
SCE_HJ_SINGLESTRING = 49
SCE_HJ_SYMBOLS = 50
SCE_HJ_STRINGEOL = 51
SCE_HJ_REGEX = 52

SCE_HJA_START = 55
SCE_HJA_DEFAULT = 56
SCE_HJA_COMMENT = 57
SCE_HJA_COMMENTLINE = 58
SCE_HJA_COMMENTDOC = 59
SCE_HJA_NUMBER = 60
SCE_HJA_WORD = 61
SCE_HJA_KEYWORD = 62
SCE_HJA_DOUBLESTRING = 63
SCE_HJA_SINGLESTRING = 64
SCE_HJA_SYMBOLS = 65
SCE_HJA_STRINGEOL = 66
SCE_HJA_REGEX = 67

SCE_HB_START = 70
SCE_HB_DEFAULT = 71
SCE_HB_COMMENTLINE = 72
SCE_HB_NUMBER = 73
SCE_HB_WORD = 74
SCE_HB_STRING = 75
SCE_HB_IDENTIFIER = 76
SCE_HB_STRINGEOL = 77

SCE_HBA_START = 80
SCE_HBA_DEFAULT = 81
SCE_HBA_COMMENTLINE = 82
SCE_HBA_NUMBER = 83
SCE_HBA_WORD = 84
SCE_HBA_STRING = 85
SCE_HBA_IDENTIFIER = 86
SCE_HBA_STRINGEOL = 87

SCE_HP_START = 90
SCE_HP_DEFAULT = 91
SCE_HP_COMMENTLINE = 92
SCE_HP_NUMBER = 93
SCE_HP_STRING = 94
SCE_HP_CHARACTER = 95
SCE_HP_WORD = 96
SCE_HP_TRIPLE = 97
SCE_HP_TRIPLEDOUBLE = 98
SCE_HP_CLASSNAME = 99
SCE_HP_DEFNAME = 100
SCE_HP_OPERATOR = 101
SCE_HP_IDENTIFIER = 102

SCE_HPHP_COMPLEX_VARIABLE = 104

SCE_HPA_START = 105
SCE_HPA_DEFAULT = 106
SCE_HPA_COMMENTLINE = 107
SCE_HPA_NUMBER = 108
SCE_HPA_STRING = 109
SCE_HPA_CHARACTER = 110
SCE_HPA_WORD = 111
SCE_HPA_TRIPLE = 112
SCE_HPA_TRIPLEDOUBLE = 113
SCE_HPA_CLASSNAME = 114
SCE_HPA_DEFNAME = 115
SCE_HPA_OPERATOR = 116
SCE_HPA_IDENTIFIER = 117

SCE_HPHP_DEFAULT = 118
SCE_HPHP_HSTRING = 119
SCE_HPHP_SIMPLESTRING = 120
SCE_HPHP_WORD = 121
SCE_HPHP_NUMBER = 122
SCE_HPHP_VARIABLE = 123
SCE_HPHP_COMMENT = 124
SCE_HPHP_COMMENTLINE = 125
SCE_HPHP_HSTRING_VARIABLE = 126
SCE_HPHP_OPERATOR = 127

SCE_PL_DEFAULT = 0
SCE_PL_ERROR = 1
SCE_PL_COMMENTLINE = 2
SCE_PL_POD = 3
SCE_PL_NUMBER = 4
SCE_PL_WORD = 5
SCE_PL_STRING = 6
SCE_PL_CHARACTER = 7
SCE_PL_PUNCTUATION = 8
SCE_PL_PREPROCESSOR = 9
SCE_PL_OPERATOR = 10
SCE_PL_IDENTIFIER = 11
SCE_PL_SCALAR = 12
SCE_PL_ARRAY = 13
SCE_PL_HASH = 14
SCE_PL_SYMBOLTABLE = 15
SCE_PL_VARIABLE_INDEXER = 16
SCE_PL_REGEX = 17
SCE_PL_REGSUBST = 18
SCE_PL_LONGQUOTE = 19
SCE_PL_BACKTICKS = 20
SCE_PL_DATASECTION = 21
SCE_PL_HERE_DELIM = 22
SCE_PL_HERE_Q = 23
SCE_PL_HERE_QQ = 24
SCE_PL_HERE_QX = 25
SCE_PL_STRING_Q = 26
SCE_PL_STRING_QQ = 27
SCE_PL_STRING_QX = 28
SCE_PL_STRING_QR = 29
SCE_PL_STRING_QW = 30
SCE_PL_POD_VERB = 31
SCE_PL_SUB_PROTOTYPE = 40
SCE_PL_FORMAT_IDENT = 41
SCE_PL_FORMAT = 42
SCE_PL_SUB = 43
SCE_PL_SUB_ARGS = 44
SCE_PL_UNKNOWN_FIELD = 45
SCE_PL_STDIN = 46
SCE_PL_STDOUT = 47
SCE_PL_STDERR = 48
SCE_PL_UPPER_BOUND = 49

SCE_RB_DEFAULT = 0
SCE_RB_ERROR = 1
SCE_RB_COMMENTLINE = 2
SCE_RB_POD = 3
SCE_RB_NUMBER = 4
SCE_RB_WORD = 5
SCE_RB_STRING = 6
SCE_RB_CHARACTER = 7
SCE_RB_CLASSNAME = 8
SCE_RB_DEFNAME = 9
SCE_RB_OPERATOR = 10
SCE_RB_IDENTIFIER = 11
SCE_RB_REGEX = 12
SCE_RB_GLOBAL = 13
SCE_RB_SYMBOL = 14
SCE_RB_MODULE_NAME = 15
SCE_RB_INSTANCE_VAR = 16
SCE_RB_CLASS_VAR = 17
SCE_RB_BACKTICKS = 18
SCE_RB_DATASECTION = 19
SCE_RB_HERE_DELIM = 20
SCE_RB_HERE_Q = 21
SCE_RB_HERE_QQ = 22
SCE_RB_HERE_QX = 23
SCE_RB_STRING_Q = 24
SCE_RB_STRING_QQ = 25
SCE_RB_STRING_QX = 26
SCE_RB_STRING_QR = 27
SCE_RB_STRING_QW = 28
SCE_RB_STRING_QI = 29
SCE_RB_WORD_DEMOTED = 30
SCE_RB_STDIN = 31
SCE_RB_STDOUT = 40
SCE_RB_STDERR = 41
SCE_RB_UPPER_BOUND = 42

SCE_B_DEFAULT = 0
SCE_B_COMMENT = 1
SCE_B_NUMBER = 2
SCE_B_KEYWORD = 3
SCE_B_STRING = 4
SCE_B_PREPROCESSOR = 5
SCE_B_OPERATOR = 6
SCE_B_IDENTIFIER = 7
SCE_B_DATE = 8
SCE_B_STRINGEOL = 9
SCE_B_KEYWORD2 = 10
SCE_B_KEYWORD3 = 11
SCE_B_KEYWORD4 = 12
SCE_B_CONSTANT = 13
SCE_B_ASM = 14
SCE_B_LABEL = 15
SCE_B_ERROR = 16
SCE_B_HEXNUMBER = 17
SCE_B_BINNUMBER = 18

SCE_PROPS_DEFAULT = 0
SCE_PROPS_COMMENT = 1
SCE_PROPS_SECTION = 2
SCE_PROPS_ASSIGNMENT = 3
SCE_PROPS_DEFVAL = 4
SCE_PROPS_KEY = 5

SCE_L_DEFAULT = 0
SCE_L_COMMAND = 1
SCE_L_TAG = 2
SCE_L_MATH = 3
SCE_L_COMMENT = 4
SCE_L_TAG2 = 5
SCE_L_MATH2 = 6
SCE_L_COMMENT2 = 7
SCE_L_VERBATIM = 8
SCE_L_SHORTCMD = 9
SCE_L_SPECIAL = 10
SCE_L_CMDOPT = 11
SCE_L_ERROR = 12

SCE_LUA_DEFAULT = 0
SCE_LUA_COMMENT = 1
SCE_LUA_COMMENTLINE = 2
SCE_LUA_COMMENTDOC = 3
SCE_LUA_NUMBER = 4
SCE_LUA_WORD = 5
SCE_LUA_STRING = 6
SCE_LUA_CHARACTER = 7
SCE_LUA_LITERALSTRING = 8
SCE_LUA_PREPROCESSOR = 9
SCE_LUA_OPERATOR = 10
SCE_LUA_IDENTIFIER = 11
SCE_LUA_STRINGEOL = 12
SCE_LUA_WORD2 = 13
SCE_LUA_WORD3 = 14
SCE_LUA_WORD4 = 15
SCE_LUA_WORD5 = 16
SCE_LUA_WORD6 = 17
SCE_LUA_WORD7 = 18
SCE_LUA_WORD8 = 19
SCE_LUA_LABEL = 20

SCE_ERR_DEFAULT = 0
SCE_ERR_PYTHON = 1
SCE_ERR_GCC = 2
SCE_ERR_MS = 3
SCE_ERR_CMD = 4
SCE_ERR_BORLAND = 5
SCE_ERR_PERL = 6
SCE_ERR_NET = 7
SCE_ERR_LUA = 8
SCE_ERR_CTAG = 9
SCE_ERR_DIFF_CHANGED = 10
SCE_ERR_DIFF_ADDITION = 11
SCE_ERR_DIFF_DELETION = 12
SCE_ERR_DIFF_MESSAGE = 13
SCE_ERR_PHP = 14
SCE_ERR_ELF = 15
SCE_ERR_IFC = 16
SCE_ERR_IFORT = 17
SCE_ERR_ABSF = 18
SCE_ERR_TIDY = 19
SCE_ERR_JAVA_STACK = 20
SCE_ERR_VALUE = 21
SCE_ERR_GCC_INCLUDED_FROM = 22

SCE_BAT_DEFAULT = 0
SCE_BAT_COMMENT = 1
SCE_BAT_WORD = 2
SCE_BAT_LABEL = 3
SCE_BAT_HIDE = 4
SCE_BAT_COMMAND = 5
SCE_BAT_IDENTIFIER = 6
SCE_BAT_OPERATOR = 7

SCE_TCMD_DEFAULT = 0
SCE_TCMD_COMMENT = 1
SCE_TCMD_WORD = 2
SCE_TCMD_LABEL = 3
SCE_TCMD_HIDE = 4
SCE_TCMD_COMMAND = 5
SCE_TCMD_IDENTIFIER = 6
SCE_TCMD_OPERATOR = 7
SCE_TCMD_ENVIRONMENT = 8
SCE_TCMD_EXPANSION = 9
SCE_TCMD_CLABEL = 10

SCE_MAKE_DEFAULT = 0
SCE_MAKE_COMMENT = 1
SCE_MAKE_PREPROCESSOR = 2
SCE_MAKE_IDENTIFIER = 3
SCE_MAKE_OPERATOR = 4
SCE_MAKE_TARGET = 5
SCE_MAKE_IDEOL = 9

SCE_DIFF_DEFAULT = 0
SCE_DIFF_COMMENT = 1
SCE_DIFF_COMMAND = 2
SCE_DIFF_HEADER = 3
SCE_DIFF_POSITION = 4
SCE_DIFF_DELETED = 5
SCE_DIFF_ADDED = 6
SCE_DIFF_CHANGED = 7

SCE_CONF_DEFAULT = 0
SCE_CONF_COMMENT = 1
SCE_CONF_NUMBER = 2
SCE_CONF_IDENTIFIER = 3
SCE_CONF_EXTENSION = 4
SCE_CONF_PARAMETER = 5
SCE_CONF_STRING = 6
SCE_CONF_OPERATOR = 7
SCE_CONF_IP = 8
SCE_CONF_DIRECTIVE = 9

SCE_AVE_DEFAULT = 0
SCE_AVE_COMMENT = 1
SCE_AVE_NUMBER = 2
SCE_AVE_WORD = 3
SCE_AVE_STRING = 6
SCE_AVE_ENUM = 7
SCE_AVE_STRINGEOL = 8
SCE_AVE_IDENTIFIER = 9
SCE_AVE_OPERATOR = 10
SCE_AVE_WORD1 = 11
SCE_AVE_WORD2 = 12
SCE_AVE_WORD3 = 13
SCE_AVE_WORD4 = 14
SCE_AVE_WORD5 = 15
SCE_AVE_WORD6 = 16

SCE_ADA_DEFAULT = 0
SCE_ADA_WORD = 1
SCE_ADA_IDENTIFIER = 2
SCE_ADA_NUMBER = 3
SCE_ADA_DELIMITER = 4
SCE_ADA_CHARACTER = 5
SCE_ADA_CHARACTEREOL = 6
SCE_ADA_STRING = 7
SCE_ADA_STRINGEOL = 8
SCE_ADA_LABEL = 9
SCE_ADA_COMMENTLINE = 10
SCE_ADA_ILLEGAL = 11

SCE_BAAN_DEFAULT = 0
SCE_BAAN_COMMENT = 1
SCE_BAAN_COMMENTDOC = 2
SCE_BAAN_NUMBER = 3
SCE_BAAN_WORD = 4
SCE_BAAN_STRING = 5
SCE_BAAN_PREPROCESSOR = 6
SCE_BAAN_OPERATOR = 7
SCE_BAAN_IDENTIFIER = 8
SCE_BAAN_STRINGEOL = 9
SCE_BAAN_WORD2 = 10

SCE_LISP_DEFAULT = 0
SCE_LISP_COMMENT = 1
SCE_LISP_NUMBER = 2
SCE_LISP_KEYWORD = 3
SCE_LISP_KEYWORD_KW = 4
SCE_LISP_SYMBOL = 5
SCE_LISP_STRING = 6
SCE_LISP_STRINGEOL = 8
SCE_LISP_IDENTIFIER = 9
SCE_LISP_OPERATOR = 10
SCE_LISP_SPECIAL = 11
SCE_LISP_MULTI_COMMENT = 12

SCE_EIFFEL_DEFAULT = 0
SCE_EIFFEL_COMMENTLINE = 1
SCE_EIFFEL_NUMBER = 2
SCE_EIFFEL_WORD = 3
SCE_EIFFEL_STRING = 4
SCE_EIFFEL_CHARACTER = 5
SCE_EIFFEL_OPERATOR = 6
SCE_EIFFEL_IDENTIFIER = 7
SCE_EIFFEL_STRINGEOL = 8

SCE_NNCRONTAB_DEFAULT = 0
SCE_NNCRONTAB_COMMENT = 1
SCE_NNCRONTAB_TASK = 2
SCE_NNCRONTAB_SECTION = 3
SCE_NNCRONTAB_KEYWORD = 4
SCE_NNCRONTAB_MODIFIER = 5
SCE_NNCRONTAB_ASTERISK = 6
SCE_NNCRONTAB_NUMBER = 7
SCE_NNCRONTAB_STRING = 8
SCE_NNCRONTAB_ENVIRONMENT = 9
SCE_NNCRONTAB_IDENTIFIER = 10

SCE_FORTH_DEFAULT = 0
SCE_FORTH_COMMENT = 1
SCE_FORTH_COMMENT_ML = 2
SCE_FORTH_IDENTIFIER = 3
SCE_FORTH_CONTROL = 4
SCE_FORTH_KEYWORD = 5
SCE_FORTH_DEFWORD = 6
SCE_FORTH_PREWORD1 = 7
SCE_FORTH_PREWORD2 = 8
SCE_FORTH_NUMBER = 9
SCE_FORTH_STRING = 10
SCE_FORTH_LOCALE = 11

SCE_MATLAB_DEFAULT = 0
SCE_MATLAB_COMMENT = 1
SCE_MATLAB_COMMAND = 2
SCE_MATLAB_NUMBER = 3
SCE_MATLAB_KEYWORD = 4
SCE_MATLAB_STRING = 5
SCE_MATLAB_OPERATOR = 6
SCE_MATLAB_IDENTIFIER = 7
SCE_MATLAB_DOUBLEQUOTESTRING = 8

SCE_SCRIPTOL_DEFAULT = 0
SCE_SCRIPTOL_WHITE = 1
SCE_SCRIPTOL_COMMENTLINE = 2
SCE_SCRIPTOL_PERSISTENT = 3
SCE_SCRIPTOL_CSTYLE = 4
SCE_SCRIPTOL_COMMENTBLOCK = 5
SCE_SCRIPTOL_NUMBER = 6
SCE_SCRIPTOL_STRING = 7
SCE_SCRIPTOL_CHARACTER = 8
SCE_SCRIPTOL_STRINGEOL = 9
SCE_SCRIPTOL_KEYWORD = 10
SCE_SCRIPTOL_OPERATOR = 11
SCE_SCRIPTOL_IDENTIFIER = 12
SCE_SCRIPTOL_TRIPLE = 13
SCE_SCRIPTOL_CLASSNAME = 14
SCE_SCRIPTOL_PREPROCESSOR = 15

SCE_ASM_DEFAULT = 0
SCE_ASM_COMMENT = 1
SCE_ASM_NUMBER = 2
SCE_ASM_STRING = 3
SCE_ASM_OPERATOR = 4
SCE_ASM_IDENTIFIER = 5
SCE_ASM_CPUINSTRUCTION = 6
SCE_ASM_MATHINSTRUCTION = 7
SCE_ASM_REGISTER = 8
SCE_ASM_DIRECTIVE = 9
SCE_ASM_DIRECTIVEOPERAND = 10
SCE_ASM_COMMENTBLOCK = 11
SCE_ASM_CHARACTER = 12
SCE_ASM_STRINGEOL = 13
SCE_ASM_EXTINSTRUCTION = 14
SCE_ASM_COMMENTDIRECTIVE = 15

SCE_F_DEFAULT = 0
SCE_F_COMMENT = 1
SCE_F_NUMBER = 2
SCE_F_STRING1 = 3
SCE_F_STRING2 = 4
SCE_F_STRINGEOL = 5
SCE_F_OPERATOR = 6
SCE_F_IDENTIFIER = 7
SCE_F_WORD = 8
SCE_F_WORD2 = 9
SCE_F_WORD3 = 10
SCE_F_PREPROCESSOR = 11
SCE_F_OPERATOR2 = 12
SCE_F_LABEL = 13
SCE_F_CONTINUATION = 14

SCE_CSS_DEFAULT = 0
SCE_CSS_TAG = 1
SCE_CSS_CLASS = 2
SCE_CSS_PSEUDOCLASS = 3
SCE_CSS_UNKNOWN_PSEUDOCLASS = 4
SCE_CSS_OPERATOR = 5
SCE_CSS_IDENTIFIER = 6
SCE_CSS_UNKNOWN_IDENTIFIER = 7
SCE_CSS_VALUE = 8
SCE_CSS_COMMENT = 9
SCE_CSS_ID = 10
SCE_CSS_IMPORTANT = 11
SCE_CSS_DIRECTIVE = 12
SCE_CSS_DOUBLESTRING = 13
SCE_CSS_SINGLESTRING = 14
SCE_CSS_IDENTIFIER2 = 15
SCE_CSS_ATTRIBUTE = 16
SCE_CSS_IDENTIFIER3 = 17
SCE_CSS_PSEUDOELEMENT = 18
SCE_CSS_EXTENDED_IDENTIFIER = 19
SCE_CSS_EXTENDED_PSEUDOCLASS = 20
SCE_CSS_EXTENDED_PSEUDOELEMENT = 21
SCE_CSS_MEDIA = 22
SCE_CSS_VARIABLE = 23
SCE_CSS_NUMBER = 24
SCE_CSS_STRINGEOL = 25
SCE_CSS_MIXIN = 26

SCE_POV_DEFAULT = 0
SCE_POV_COMMENT = 1
SCE_POV_COMMENTLINE = 2
SCE_POV_NUMBER = 3
SCE_POV_OPERATOR = 4
SCE_POV_IDENTIFIER = 5
SCE_POV_STRING = 6
SCE_POV_STRINGEOL = 7
SCE_POV_DIRECTIVE = 8
SCE_POV_BADDIRECTIVE = 9
SCE_POV_WORD2 = 10
SCE_POV_WORD3 = 11
SCE_POV_WORD4 = 12
SCE_POV_WORD5 = 13
SCE_POV_WORD6 = 14
SCE_POV_WORD7 = 15
SCE_POV_WORD8 = 16

SCE_LOUT_DEFAULT = 0
SCE_LOUT_COMMENT = 1
SCE_LOUT_NUMBER = 2
SCE_LOUT_WORD = 3
SCE_LOUT_WORD2 = 4
SCE_LOUT_WORD3 = 5
SCE_LOUT_WORD4 = 6
SCE_LOUT_STRING = 7
SCE_LOUT_OPERATOR = 8
SCE_LOUT_IDENTIFIER = 9
SCE_LOUT_STRINGEOL = 10

SCE_ESCRIPT_DEFAULT = 0
SCE_ESCRIPT_COMMENT = 1
SCE_ESCRIPT_COMMENTLINE = 2
SCE_ESCRIPT_COMMENTDOC = 3
SCE_ESCRIPT_NUMBER = 4
SCE_ESCRIPT_WORD = 5
SCE_ESCRIPT_STRING = 6
SCE_ESCRIPT_OPERATOR = 7
SCE_ESCRIPT_IDENTIFIER = 8
SCE_ESCRIPT_BRACE = 9
SCE_ESCRIPT_WORD2 = 10
SCE_ESCRIPT_WORD3 = 11

SCE_PS_DEFAULT = 0
SCE_PS_COMMENT = 1
SCE_PS_DSC_COMMENT = 2
SCE_PS_DSC_VALUE = 3
SCE_PS_NUMBER = 4
SCE_PS_NAME = 5
SCE_PS_KEYWORD = 6
SCE_PS_LITERAL = 7
SCE_PS_IMMEVAL = 8
SCE_PS_PAREN_ARRAY = 9
SCE_PS_PAREN_DICT = 10
SCE_PS_PAREN_PROC = 11
SCE_PS_TEXT = 12
SCE_PS_HEXSTRING = 13
SCE_PS_BASE85STRING = 14
SCE_PS_BADSTRINGCHAR = 15

SCE_NSIS_DEFAULT = 0
SCE_NSIS_COMMENT = 1
SCE_NSIS_STRINGDQ = 2
SCE_NSIS_STRINGLQ = 3
SCE_NSIS_STRINGRQ = 4
SCE_NSIS_FUNCTION = 5
SCE_NSIS_VARIABLE = 6
SCE_NSIS_LABEL = 7
SCE_NSIS_USERDEFINED = 8
SCE_NSIS_SECTIONDEF = 9
SCE_NSIS_SUBSECTIONDEF = 10
SCE_NSIS_IFDEFINEDEF = 11
SCE_NSIS_MACRODEF = 12
SCE_NSIS_STRINGVAR = 13
SCE_NSIS_NUMBER = 14
SCE_NSIS_SECTIONGROUP = 15
SCE_NSIS_PAGEEX = 16
SCE_NSIS_FUNCTIONDEF = 17
SCE_NSIS_COMMENTBOX = 18

SCE_MMIXAL_LEADWS = 0
SCE_MMIXAL_COMMENT = 1
SCE_MMIXAL_LABEL = 2
SCE_MMIXAL_OPCODE = 3
SCE_MMIXAL_OPCODE_PRE = 4
SCE_MMIXAL_OPCODE_VALID = 5
SCE_MMIXAL_OPCODE_UNKNOWN = 6
SCE_MMIXAL_OPCODE_POST = 7
SCE_MMIXAL_OPERANDS = 8
SCE_MMIXAL_NUMBER = 9
SCE_MMIXAL_REF = 10
SCE_MMIXAL_CHAR = 11
SCE_MMIXAL_STRING = 12
SCE_MMIXAL_REGISTER = 13
SCE_MMIXAL_HEX = 14
SCE_MMIXAL_OPERATOR = 15
SCE_MMIXAL_SYMBOL = 16
SCE_MMIXAL_INCLUDE = 17

SCE_CLW_DEFAULT = 0
SCE_CLW_LABEL = 1
SCE_CLW_COMMENT = 2
SCE_CLW_STRING = 3
SCE_CLW_USER_IDENTIFIER = 4
SCE_CLW_INTEGER_CONSTANT = 5
SCE_CLW_REAL_CONSTANT = 6
SCE_CLW_PICTURE_STRING = 7
SCE_CLW_KEYWORD = 8
SCE_CLW_COMPILER_DIRECTIVE = 9
SCE_CLW_RUNTIME_EXPRESSIONS = 10
SCE_CLW_BUILTIN_PROCEDURES_FUNCTION = 11
SCE_CLW_STRUCTURE_DATA_TYPE = 12
SCE_CLW_ATTRIBUTE = 13
SCE_CLW_STANDARD_EQUATE = 14
SCE_CLW_ERROR = 15
SCE_CLW_DEPRECATED = 16

SCE_LOT_DEFAULT = 0
SCE_LOT_HEADER = 1
SCE_LOT_BREAK = 2
SCE_LOT_SET = 3
SCE_LOT_PASS = 4
SCE_LOT_FAIL = 5
SCE_LOT_ABORT = 6

SCE_YAML_DEFAULT = 0
SCE_YAML_COMMENT = 1
SCE_YAML_IDENTIFIER = 2
SCE_YAML_KEYWORD = 3
SCE_YAML_NUMBER = 4
SCE_YAML_REFERENCE = 5
SCE_YAML_DOCUMENT = 6
SCE_YAML_TEXT = 7
SCE_YAML_ERROR = 8
SCE_YAML_OPERATOR = 9

SCE_TEX_DEFAULT = 0
SCE_TEX_SPECIAL = 1
SCE_TEX_GROUP = 2
SCE_TEX_SYMBOL = 3
SCE_TEX_COMMAND = 4
SCE_TEX_TEXT = 5

SCE_METAPOST_DEFAULT = 0
SCE_METAPOST_SPECIAL = 1
SCE_METAPOST_GROUP = 2
SCE_METAPOST_SYMBOL = 3
SCE_METAPOST_COMMAND = 4
SCE_METAPOST_TEXT = 5
SCE_METAPOST_EXTRA = 6

SCE_ERLANG_DEFAULT = 0
SCE_ERLANG_COMMENT = 1
SCE_ERLANG_VARIABLE = 2
SCE_ERLANG_NUMBER = 3
SCE_ERLANG_KEYWORD = 4
SCE_ERLANG_STRING = 5
SCE_ERLANG_OPERATOR = 6
SCE_ERLANG_ATOM = 7
SCE_ERLANG_FUNCTION_NAME = 8
SCE_ERLANG_CHARACTER = 9
SCE_ERLANG_MACRO = 10
SCE_ERLANG_RECORD = 11
SCE_ERLANG_PREPROC = 12
SCE_ERLANG_NODE_NAME = 13
SCE_ERLANG_COMMENT_FUNCTION = 14
SCE_ERLANG_COMMENT_MODULE = 15
SCE_ERLANG_COMMENT_DOC = 16
SCE_ERLANG_COMMENT_DOC_MACRO = 17
SCE_ERLANG_ATOM_QUOTED = 18
SCE_ERLANG_MACRO_QUOTED = 19
SCE_ERLANG_RECORD_QUOTED = 20
SCE_ERLANG_NODE_NAME_QUOTED = 21
SCE_ERLANG_BIFS = 22
SCE_ERLANG_MODULES = 23
SCE_ERLANG_MODULES_ATT = 24
SCE_ERLANG_UNKNOWN = 31

SCE_MSSQL_DEFAULT = 0
SCE_MSSQL_COMMENT = 1
SCE_MSSQL_LINE_COMMENT = 2
SCE_MSSQL_NUMBER = 3
SCE_MSSQL_STRING = 4
SCE_MSSQL_OPERATOR = 5
SCE_MSSQL_IDENTIFIER = 6
SCE_MSSQL_VARIABLE = 7
SCE_MSSQL_COLUMN_NAME = 8
SCE_MSSQL_STATEMENT = 9
SCE_MSSQL_DATATYPE = 10
SCE_MSSQL_SYSTABLE = 11
SCE_MSSQL_GLOBAL_VARIABLE = 12
SCE_MSSQL_FUNCTION = 13
SCE_MSSQL_STORED_PROCEDURE = 14
SCE_MSSQL_DEFAULT_PREF_DATATYPE = 15
SCE_MSSQL_COLUMN_NAME_2 = 16

SCE_V_DEFAULT = 0
SCE_V_COMMENT = 1
SCE_V_COMMENTLINE = 2
SCE_V_COMMENTLINEBANG = 3
SCE_V_NUMBER = 4
SCE_V_WORD = 5
SCE_V_STRING = 6
SCE_V_WORD2 = 7
SCE_V_WORD3 = 8
SCE_V_PREPROCESSOR = 9
SCE_V_OPERATOR = 10
SCE_V_IDENTIFIER = 11
SCE_V_STRINGEOL = 12
SCE_V_USER = 19

SCE_KIX_DEFAULT = 0
SCE_KIX_COMMENT = 1
SCE_KIX_STRING1 = 2
SCE_KIX_STRING2 = 3
SCE_KIX_NUMBER = 4
SCE_KIX_VAR = 5
SCE_KIX_MACRO = 6
SCE_KIX_KEYWORD = 7
SCE_KIX_FUNCTIONS = 8
SCE_KIX_OPERATOR = 9
SCE_KIX_IDENTIFIER = 31

SCE_GC_DEFAULT = 0
SCE_GC_COMMENTLINE = 1
SCE_GC_COMMENTBLOCK = 2
SCE_GC_GLOBAL = 3
SCE_GC_EVENT = 4
SCE_GC_ATTRIBUTE = 5
SCE_GC_CONTROL = 6
SCE_GC_COMMAND = 7
SCE_GC_STRING = 8
SCE_GC_OPERATOR = 9

SCE_SN_DEFAULT = 0
SCE_SN_CODE = 1
SCE_SN_COMMENTLINE = 2
SCE_SN_COMMENTLINEBANG = 3
SCE_SN_NUMBER = 4
SCE_SN_WORD = 5
SCE_SN_STRING = 6
SCE_SN_WORD2 = 7
SCE_SN_WORD3 = 8
SCE_SN_PREPROCESSOR = 9
SCE_SN_OPERATOR = 10
SCE_SN_IDENTIFIER = 11
SCE_SN_STRINGEOL = 12
SCE_SN_REGEXTAG = 13
SCE_SN_SIGNAL = 14
SCE_SN_USER = 19

SCE_AU3_DEFAULT = 0
SCE_AU3_COMMENT = 1
SCE_AU3_COMMENTBLOCK = 2
SCE_AU3_NUMBER = 3
SCE_AU3_FUNCTION = 4
SCE_AU3_KEYWORD = 5
SCE_AU3_MACRO = 6
SCE_AU3_STRING = 7
SCE_AU3_OPERATOR = 8
SCE_AU3_VARIABLE = 9
SCE_AU3_SENT = 10
SCE_AU3_PREPROCESSOR = 11
SCE_AU3_SPECIAL = 12
SCE_AU3_EXPAND = 13
SCE_AU3_COMOBJ = 14
SCE_AU3_UDF = 15

SCE_APDL_DEFAULT = 0
SCE_APDL_COMMENT = 1
SCE_APDL_COMMENTBLOCK = 2
SCE_APDL_NUMBER = 3
SCE_APDL_STRING = 4
SCE_APDL_OPERATOR = 5
SCE_APDL_WORD = 6
SCE_APDL_PROCESSOR = 7
SCE_APDL_COMMAND = 8
SCE_APDL_SLASHCOMMAND = 9
SCE_APDL_STARCOMMAND = 10
SCE_APDL_ARGUMENT = 11
SCE_APDL_FUNCTION = 12

SCE_SH_DEFAULT = 0
SCE_SH_ERROR = 1
SCE_SH_COMMENTLINE = 2
SCE_SH_NUMBER = 3
SCE_SH_WORD = 4
SCE_SH_STRING = 5
SCE_SH_CHARACTER = 6
SCE_SH_OPERATOR = 7
SCE_SH_IDENTIFIER = 8
SCE_SH_SCALAR = 9
SCE_SH_PARAM = 10
SCE_SH_BACKTICKS = 11
SCE_SH_HERE_DELIM = 12
SCE_SH_HERE_Q = 13

SCE_ASN1_DEFAULT = 0
SCE_ASN1_COMMENT = 1
SCE_ASN1_IDENTIFIER = 2
SCE_ASN1_STRING = 3
SCE_ASN1_OID = 4
SCE_ASN1_SCALAR = 5
SCE_ASN1_KEYWORD = 6
SCE_ASN1_ATTRIBUTE = 7
SCE_ASN1_DESCRIPTOR = 8
SCE_ASN1_TYPE = 9
SCE_ASN1_OPERATOR = 10

SCE_VHDL_DEFAULT = 0
SCE_VHDL_COMMENT = 1
SCE_VHDL_COMMENTLINEBANG = 2
SCE_VHDL_NUMBER = 3
SCE_VHDL_STRING = 4
SCE_VHDL_OPERATOR = 5
SCE_VHDL_IDENTIFIER = 6
SCE_VHDL_STRINGEOL = 7
SCE_VHDL_KEYWORD = 8
SCE_VHDL_STDOPERATOR = 9
SCE_VHDL_ATTRIBUTE = 10
SCE_VHDL_STDFUNCTION = 11
SCE_VHDL_STDPACKAGE = 12
SCE_VHDL_STDTYPE = 13
SCE_VHDL_USERWORD = 14

SCE_CAML_DEFAULT = 0
SCE_CAML_IDENTIFIER = 1
SCE_CAML_TAGNAME = 2
SCE_CAML_KEYWORD = 3
SCE_CAML_KEYWORD2 = 4
SCE_CAML_KEYWORD3 = 5
SCE_CAML_LINENUM = 6
SCE_CAML_OPERATOR = 7
SCE_CAML_NUMBER = 8
SCE_CAML_CHAR = 9
SCE_CAML_WHITE = 10
SCE_CAML_STRING = 11
SCE_CAML_COMMENT = 12
SCE_CAML_COMMENT1 = 13
SCE_CAML_COMMENT2 = 14
SCE_CAML_COMMENT3 = 15

SCE_HA_DEFAULT = 0
SCE_HA_IDENTIFIER = 1
SCE_HA_KEYWORD = 2
SCE_HA_NUMBER = 3
SCE_HA_STRING = 4
SCE_HA_CHARACTER = 5
SCE_HA_CLASS = 6
SCE_HA_MODULE = 7
SCE_HA_CAPITAL = 8
SCE_HA_DATA = 9
SCE_HA_IMPORT = 10
SCE_HA_OPERATOR = 11
SCE_HA_INSTANCE = 12
SCE_HA_COMMENTLINE = 13
SCE_HA_COMMENTBLOCK = 14
SCE_HA_COMMENTBLOCK2 = 15
SCE_HA_COMMENTBLOCK3 = 16
SCE_HA_PRAGMA = 17
SCE_HA_PREPROCESSOR = 18
SCE_HA_STRINGEOL = 19
SCE_HA_RESERVED_OPERATOR = 20
SCE_HA_LITERATE_COMMENT = 21
SCE_HA_LITERATE_CODEDELIM = 22

SCE_T3_DEFAULT = 0
SCE_T3_X_DEFAULT = 1
SCE_T3_PREPROCESSOR = 2
SCE_T3_BLOCK_COMMENT = 3
SCE_T3_LINE_COMMENT = 4
SCE_T3_OPERATOR = 5
SCE_T3_KEYWORD = 6
SCE_T3_NUMBER = 7
SCE_T3_IDENTIFIER = 8
SCE_T3_S_STRING = 9
SCE_T3_D_STRING = 10
SCE_T3_X_STRING = 11
SCE_T3_LIB_DIRECTIVE = 12
SCE_T3_MSG_PARAM = 13
SCE_T3_HTML_TAG = 14
SCE_T3_HTML_DEFAULT = 15
SCE_T3_HTML_STRING = 16
SCE_T3_USER1 = 17
SCE_T3_USER2 = 18
SCE_T3_USER3 = 19
SCE_T3_BRACE = 20

SCE_REBOL_DEFAULT = 0
SCE_REBOL_COMMENTLINE = 1
SCE_REBOL_COMMENTBLOCK = 2
SCE_REBOL_PREFACE = 3
SCE_REBOL_OPERATOR = 4
SCE_REBOL_CHARACTER = 5
SCE_REBOL_QUOTEDSTRING = 6
SCE_REBOL_BRACEDSTRING = 7
SCE_REBOL_NUMBER = 8
SCE_REBOL_PAIR = 9
SCE_REBOL_TUPLE = 10
SCE_REBOL_BINARY = 11
SCE_REBOL_MONEY = 12
SCE_REBOL_ISSUE = 13
SCE_REBOL_TAG = 14
SCE_REBOL_FILE = 15
SCE_REBOL_EMAIL = 16
SCE_REBOL_URL = 17
SCE_REBOL_DATE = 18
SCE_REBOL_TIME = 19
SCE_REBOL_IDENTIFIER = 20
SCE_REBOL_WORD = 21
SCE_REBOL_WORD2 = 22
SCE_REBOL_WORD3 = 23
SCE_REBOL_WORD4 = 24
SCE_REBOL_WORD5 = 25
SCE_REBOL_WORD6 = 26
SCE_REBOL_WORD7 = 27
SCE_REBOL_WORD8 = 28

SCE_SQL_DEFAULT = 0
SCE_SQL_COMMENT = 1
SCE_SQL_COMMENTLINE = 2
SCE_SQL_COMMENTDOC = 3
SCE_SQL_NUMBER = 4
SCE_SQL_WORD = 5
SCE_SQL_STRING = 6
SCE_SQL_CHARACTER = 7
SCE_SQL_SQLPLUS = 8
SCE_SQL_SQLPLUS_PROMPT = 9
SCE_SQL_OPERATOR = 10
SCE_SQL_IDENTIFIER = 11
SCE_SQL_SQLPLUS_COMMENT = 13
SCE_SQL_COMMENTLINEDOC = 15
SCE_SQL_WORD2 = 16
SCE_SQL_COMMENTDOCKEYWORD = 17
SCE_SQL_COMMENTDOCKEYWORDERROR = 18
SCE_SQL_USER1 = 19
SCE_SQL_USER2 = 20
SCE_SQL_USER3 = 21
SCE_SQL_USER4 = 22
SCE_SQL_QUOTEDIDENTIFIER = 23

SCE_ST_DEFAULT = 0
SCE_ST_STRING = 1
SCE_ST_NUMBER = 2
SCE_ST_COMMENT = 3
SCE_ST_SYMBOL = 4
SCE_ST_BINARY = 5
SCE_ST_BOOL = 6
SCE_ST_SELF = 7
SCE_ST_SUPER = 8
SCE_ST_NIL = 9
SCE_ST_GLOBAL = 10
SCE_ST_RETURN = 11
SCE_ST_SPECIAL = 12
SCE_ST_KWSEND = 13
SCE_ST_ASSIGN = 14
SCE_ST_CHARACTER = 15
SCE_ST_SPEC_SEL = 16

SCE_FS_DEFAULT = 0
SCE_FS_COMMENT = 1
SCE_FS_COMMENTLINE = 2
SCE_FS_COMMENTDOC = 3
SCE_FS_COMMENTLINEDOC = 4
SCE_FS_COMMENTDOCKEYWORD = 5
SCE_FS_COMMENTDOCKEYWORDERROR = 6
SCE_FS_KEYWORD = 7
SCE_FS_KEYWORD2 = 8
SCE_FS_KEYWORD3 = 9
SCE_FS_KEYWORD4 = 10
SCE_FS_NUMBER = 11
SCE_FS_STRING = 12
SCE_FS_PREPROCESSOR = 13
SCE_FS_OPERATOR = 14
SCE_FS_IDENTIFIER = 15
SCE_FS_DATE = 16
SCE_FS_STRINGEOL = 17
SCE_FS_CONSTANT = 18
SCE_FS_WORDOPERATOR = 19
SCE_FS_DISABLEDCODE = 20
SCE_FS_DEFAULT_C = 21
SCE_FS_COMMENTDOC_C = 22
SCE_FS_COMMENTLINEDOC_C = 23
SCE_FS_KEYWORD_C = 24
SCE_FS_KEYWORD2_C = 25
SCE_FS_NUMBER_C = 26
SCE_FS_STRING_C = 27
SCE_FS_PREPROCESSOR_C = 28
SCE_FS_OPERATOR_C = 29
SCE_FS_IDENTIFIER_C = 30
SCE_FS_STRINGEOL_C = 31

SCE_CSOUND_DEFAULT = 0
SCE_CSOUND_COMMENT = 1
SCE_CSOUND_NUMBER = 2
SCE_CSOUND_OPERATOR = 3
SCE_CSOUND_INSTR = 4
SCE_CSOUND_IDENTIFIER = 5
SCE_CSOUND_OPCODE = 6
SCE_CSOUND_HEADERSTMT = 7
SCE_CSOUND_USERKEYWORD = 8
SCE_CSOUND_COMMENTBLOCK = 9
SCE_CSOUND_PARAM = 10
SCE_CSOUND_ARATE_VAR = 11
SCE_CSOUND_KRATE_VAR = 12
SCE_CSOUND_IRATE_VAR = 13
SCE_CSOUND_GLOBAL_VAR = 14
SCE_CSOUND_STRINGEOL = 15

SCE_INNO_DEFAULT = 0
SCE_INNO_COMMENT = 1
SCE_INNO_KEYWORD = 2
SCE_INNO_PARAMETER = 3
SCE_INNO_SECTION = 4
SCE_INNO_PREPROC = 5
SCE_INNO_INLINE_EXPANSION = 6
SCE_INNO_COMMENT_PASCAL = 7
SCE_INNO_KEYWORD_PASCAL = 8
SCE_INNO_KEYWORD_USER = 9
SCE_INNO_STRING_DOUBLE = 10
SCE_INNO_STRING_SINGLE = 11
SCE_INNO_IDENTIFIER = 12

SCE_OPAL_SPACE = 0
SCE_OPAL_COMMENT_BLOCK = 1
SCE_OPAL_COMMENT_LINE = 2
SCE_OPAL_INTEGER = 3
SCE_OPAL_KEYWORD = 4
SCE_OPAL_SORT = 5
SCE_OPAL_STRING = 6
SCE_OPAL_PAR = 7
SCE_OPAL_BOOL_CONST = 8
SCE_OPAL_DEFAULT = 32

SCE_SPICE_DEFAULT = 0
SCE_SPICE_IDENTIFIER = 1
SCE_SPICE_KEYWORD = 2
SCE_SPICE_KEYWORD2 = 3
SCE_SPICE_KEYWORD3 = 4
SCE_SPICE_NUMBER = 5
SCE_SPICE_DELIMITER = 6
SCE_SPICE_VALUE = 7
SCE_SPICE_COMMENTLINE = 8

SCE_CMAKE_DEFAULT = 0
SCE_CMAKE_COMMENT = 1
SCE_CMAKE_STRINGDQ = 2
SCE_CMAKE_STRINGLQ = 3
SCE_CMAKE_STRINGRQ = 4
SCE_CMAKE_COMMANDS = 5
SCE_CMAKE_PARAMETERS = 6
SCE_CMAKE_VARIABLE = 7
SCE_CMAKE_USERDEFINED = 8
SCE_CMAKE_WHILEDEF = 9
SCE_CMAKE_FOREACHDEF = 10
SCE_CMAKE_IFDEFINEDEF = 11
SCE_CMAKE_MACRODEF = 12
SCE_CMAKE_STRINGVAR = 13
SCE_CMAKE_NUMBER = 14

SCE_GAP_DEFAULT = 0
SCE_GAP_IDENTIFIER = 1
SCE_GAP_KEYWORD = 2
SCE_GAP_KEYWORD2 = 3
SCE_GAP_KEYWORD3 = 4
SCE_GAP_KEYWORD4 = 5
SCE_GAP_STRING = 6
SCE_GAP_CHAR = 7
SCE_GAP_OPERATOR = 8
SCE_GAP_COMMENT = 9
SCE_GAP_NUMBER = 10
SCE_GAP_STRINGEOL = 11

SCE_PLM_DEFAULT = 0
SCE_PLM_COMMENT = 1
SCE_PLM_STRING = 2
SCE_PLM_NUMBER = 3
SCE_PLM_IDENTIFIER = 4
SCE_PLM_OPERATOR = 5
SCE_PLM_CONTROL = 6
SCE_PLM_KEYWORD = 7

SCE_4GL_DEFAULT = 0
SCE_4GL_NUMBER = 1
SCE_4GL_WORD = 2
SCE_4GL_STRING = 3
SCE_4GL_CHARACTER = 4
SCE_4GL_PREPROCESSOR = 5
SCE_4GL_OPERATOR = 6
SCE_4GL_IDENTIFIER = 7
SCE_4GL_BLOCK = 8
SCE_4GL_END = 9
SCE_4GL_COMMENT1 = 10
SCE_4GL_COMMENT2 = 11
SCE_4GL_COMMENT3 = 12
SCE_4GL_COMMENT4 = 13
SCE_4GL_COMMENT5 = 14
SCE_4GL_COMMENT6 = 15
SCE_4GL_DEFAULT_ = 16
SCE_4GL_NUMBER_ = 17
SCE_4GL_WORD_ = 18
SCE_4GL_STRING_ = 19
SCE_4GL_CHARACTER_ = 20
SCE_4GL_PREPROCESSOR_ = 21
SCE_4GL_OPERATOR_ = 22
SCE_4GL_IDENTIFIER_ = 23
SCE_4GL_BLOCK_ = 24
SCE_4GL_END_ = 25
SCE_4GL_COMMENT1_ = 26
SCE_4GL_COMMENT2_ = 27
SCE_4GL_COMMENT3_ = 28
SCE_4GL_COMMENT4_ = 29
SCE_4GL_COMMENT5_ = 30
SCE_4GL_COMMENT6_ = 31

SCE_ABAQUS_DEFAULT = 0
SCE_ABAQUS_COMMENT = 1
SCE_ABAQUS_COMMENTBLOCK = 2
SCE_ABAQUS_NUMBER = 3
SCE_ABAQUS_STRING = 4
SCE_ABAQUS_OPERATOR = 5
SCE_ABAQUS_WORD = 6
SCE_ABAQUS_PROCESSOR = 7
SCE_ABAQUS_COMMAND = 8
SCE_ABAQUS_SLASHCOMMAND = 9
SCE_ABAQUS_STARCOMMAND = 10
SCE_ABAQUS_ARGUMENT = 11
SCE_ABAQUS_FUNCTION = 12

SCE_ASY_DEFAULT = 0
SCE_ASY_COMMENT = 1
SCE_ASY_COMMENTLINE = 2
SCE_ASY_NUMBER = 3
SCE_ASY_WORD = 4
SCE_ASY_STRING = 5
SCE_ASY_CHARACTER = 6
SCE_ASY_OPERATOR = 7
SCE_ASY_IDENTIFIER = 8
SCE_ASY_STRINGEOL = 9
SCE_ASY_COMMENTLINEDOC = 10
SCE_ASY_WORD2 = 11

SCE_R_DEFAULT = 0
SCE_R_COMMENT = 1
SCE_R_KWORD = 2
SCE_R_BASEKWORD = 3
SCE_R_OTHERKWORD = 4
SCE_R_NUMBER = 5
SCE_R_STRING = 6
SCE_R_STRING2 = 7
SCE_R_OPERATOR = 8
SCE_R_IDENTIFIER = 9
SCE_R_INFIX = 10
SCE_R_INFIXEOL = 11

SCE_MAGIK_DEFAULT = 0
SCE_MAGIK_COMMENT = 1
SCE_MAGIK_HYPER_COMMENT = 16
SCE_MAGIK_STRING = 2
SCE_MAGIK_CHARACTER = 3
SCE_MAGIK_NUMBER = 4
SCE_MAGIK_IDENTIFIER = 5
SCE_MAGIK_OPERATOR = 6
SCE_MAGIK_FLOW = 7
SCE_MAGIK_CONTAINER = 8
SCE_MAGIK_BRACKET_BLOCK = 9
SCE_MAGIK_BRACE_BLOCK = 10
SCE_MAGIK_SQBRACKET_BLOCK = 11
SCE_MAGIK_UNKNOWN_KEYWORD = 12
SCE_MAGIK_KEYWORD = 13
SCE_MAGIK_PRAGMA = 14
SCE_MAGIK_SYMBOL = 15

SCE_POWERSHELL_DEFAULT = 0
SCE_POWERSHELL_COMMENT = 1
SCE_POWERSHELL_STRING = 2
SCE_POWERSHELL_CHARACTER = 3
SCE_POWERSHELL_NUMBER = 4
SCE_POWERSHELL_VARIABLE = 5
SCE_POWERSHELL_OPERATOR = 6
SCE_POWERSHELL_IDENTIFIER = 7
SCE_POWERSHELL_KEYWORD = 8
SCE_POWERSHELL_CMDLET = 9
SCE_POWERSHELL_ALIAS = 10
SCE_POWERSHELL_FUNCTION = 11
SCE_POWERSHELL_USER1 = 12
SCE_POWERSHELL_COMMENTSTREAM = 13
SCE_POWERSHELL_HERE_STRING = 14
SCE_POWERSHELL_HERE_CHARACTER = 15
SCE_POWERSHELL_COMMENTDOCKEYWORD = 16

SCE_MYSQL_DEFAULT = 0
SCE_MYSQL_COMMENT = 1
SCE_MYSQL_COMMENTLINE = 2
SCE_MYSQL_VARIABLE = 3
SCE_MYSQL_SYSTEMVARIABLE = 4
SCE_MYSQL_KNOWNSYSTEMVARIABLE = 5
SCE_MYSQL_NUMBER = 6
SCE_MYSQL_MAJORKEYWORD = 7
SCE_MYSQL_KEYWORD = 8
SCE_MYSQL_DATABASEOBJECT = 9
SCE_MYSQL_PROCEDUREKEYWORD = 10
SCE_MYSQL_STRING = 11
SCE_MYSQL_SQSTRING = 12
SCE_MYSQL_DQSTRING = 13
SCE_MYSQL_OPERATOR = 14
SCE_MYSQL_FUNCTION = 15
SCE_MYSQL_IDENTIFIER = 16
SCE_MYSQL_QUOTEDIDENTIFIER = 17
SCE_MYSQL_USER1 = 18
SCE_MYSQL_USER2 = 19
SCE_MYSQL_USER3 = 20
SCE_MYSQL_HIDDENCOMMAND = 21
SCE_MYSQL_PLACEHOLDER = 22

SCE_PO_DEFAULT = 0
SCE_PO_COMMENT = 1
SCE_PO_MSGID = 2
SCE_PO_MSGID_TEXT = 3
SCE_PO_MSGSTR = 4
SCE_PO_MSGSTR_TEXT = 5
SCE_PO_MSGCTXT = 6
SCE_PO_MSGCTXT_TEXT = 7
SCE_PO_FUZZY = 8
SCE_PO_PROGRAMMER_COMMENT = 9
SCE_PO_REFERENCE = 10
SCE_PO_FLAGS = 11
SCE_PO_MSGID_TEXT_EOL = 12
SCE_PO_MSGSTR_TEXT_EOL = 13
SCE_PO_MSGCTXT_TEXT_EOL = 14
SCE_PO_ERROR = 15

SCE_PAS_DEFAULT = 0
SCE_PAS_IDENTIFIER = 1
SCE_PAS_COMMENT = 2
SCE_PAS_COMMENT2 = 3
SCE_PAS_COMMENTLINE = 4
SCE_PAS_PREPROCESSOR = 5
SCE_PAS_PREPROCESSOR2 = 6
SCE_PAS_NUMBER = 7
SCE_PAS_HEXNUMBER = 8
SCE_PAS_WORD = 9
SCE_PAS_STRING = 10
SCE_PAS_STRINGEOL = 11
SCE_PAS_CHARACTER = 12
SCE_PAS_OPERATOR = 13
SCE_PAS_ASM = 14

SCE_SORCUS_DEFAULT = 0
SCE_SORCUS_COMMAND = 1
SCE_SORCUS_PARAMETER = 2
SCE_SORCUS_COMMENTLINE = 3
SCE_SORCUS_STRING = 4
SCE_SORCUS_STRINGEOL = 5
SCE_SORCUS_IDENTIFIER = 6
SCE_SORCUS_OPERATOR = 7
SCE_SORCUS_NUMBER = 8
SCE_SORCUS_CONSTANT = 9

SCE_POWERPRO_DEFAULT = 0
SCE_POWERPRO_COMMENTBLOCK = 1
SCE_POWERPRO_COMMENTLINE = 2
SCE_POWERPRO_NUMBER = 3
SCE_POWERPRO_WORD = 4
SCE_POWERPRO_WORD2 = 5
SCE_POWERPRO_WORD3 = 6
SCE_POWERPRO_WORD4 = 7
SCE_POWERPRO_DOUBLEQUOTEDSTRING = 8
SCE_POWERPRO_SINGLEQUOTEDSTRING = 9
SCE_POWERPRO_LINECONTINUE = 10
SCE_POWERPRO_OPERATOR = 11
SCE_POWERPRO_IDENTIFIER = 12
SCE_POWERPRO_STRINGEOL = 13
SCE_POWERPRO_VERBATIM = 14
SCE_POWERPRO_ALTQUOTE = 15
SCE_POWERPRO_FUNCTION = 16

SCE_SML_DEFAULT = 0
SCE_SML_IDENTIFIER = 1
SCE_SML_TAGNAME = 2
SCE_SML_KEYWORD = 3
SCE_SML_KEYWORD2 = 4
SCE_SML_KEYWORD3 = 5
SCE_SML_LINENUM = 6
SCE_SML_OPERATOR = 7
SCE_SML_NUMBER = 8
SCE_SML_CHAR = 9
SCE_SML_STRING = 11
SCE_SML_COMMENT = 12
SCE_SML_COMMENT1 = 13
SCE_SML_COMMENT2 = 14
SCE_SML_COMMENT3 = 15

SCE_MARKDOWN_DEFAULT = 0
SCE_MARKDOWN_LINE_BEGIN = 1
SCE_MARKDOWN_STRONG1 = 2
SCE_MARKDOWN_STRONG2 = 3
SCE_MARKDOWN_EM1 = 4
SCE_MARKDOWN_EM2 = 5
SCE_MARKDOWN_HEADER1 = 6
SCE_MARKDOWN_HEADER2 = 7
SCE_MARKDOWN_HEADER3 = 8
SCE_MARKDOWN_HEADER4 = 9
SCE_MARKDOWN_HEADER5 = 10
SCE_MARKDOWN_HEADER6 = 11
SCE_MARKDOWN_PRECHAR = 12
SCE_MARKDOWN_ULIST_ITEM = 13
SCE_MARKDOWN_OLIST_ITEM = 14
SCE_MARKDOWN_BLOCKQUOTE = 15
SCE_MARKDOWN_STRIKEOUT = 16
SCE_MARKDOWN_HRULE = 17
SCE_MARKDOWN_LINK = 18
SCE_MARKDOWN_CODE = 19
SCE_MARKDOWN_CODE2 = 20
SCE_MARKDOWN_CODEBK = 21

SCE_TXT2TAGS_DEFAULT = 0
SCE_TXT2TAGS_LINE_BEGIN = 1
SCE_TXT2TAGS_STRONG1 = 2
SCE_TXT2TAGS_STRONG2 = 3
SCE_TXT2TAGS_EM1 = 4
SCE_TXT2TAGS_EM2 = 5
SCE_TXT2TAGS_HEADER1 = 6
SCE_TXT2TAGS_HEADER2 = 7
SCE_TXT2TAGS_HEADER3 = 8
SCE_TXT2TAGS_HEADER4 = 9
SCE_TXT2TAGS_HEADER5 = 10
SCE_TXT2TAGS_HEADER6 = 11
SCE_TXT2TAGS_PRECHAR = 12
SCE_TXT2TAGS_ULIST_ITEM = 13
SCE_TXT2TAGS_OLIST_ITEM = 14
SCE_TXT2TAGS_BLOCKQUOTE = 15
SCE_TXT2TAGS_STRIKEOUT = 16
SCE_TXT2TAGS_HRULE = 17
SCE_TXT2TAGS_LINK = 18
SCE_TXT2TAGS_CODE = 19
SCE_TXT2TAGS_CODE2 = 20
SCE_TXT2TAGS_CODEBK = 21
SCE_TXT2TAGS_COMMENT = 22
SCE_TXT2TAGS_OPTION = 23
SCE_TXT2TAGS_PREPROC = 24
SCE_TXT2TAGS_POSTPROC = 25

SCE_A68K_DEFAULT = 0
SCE_A68K_COMMENT = 1
SCE_A68K_NUMBER_DEC = 2
SCE_A68K_NUMBER_BIN = 3
SCE_A68K_NUMBER_HEX = 4
SCE_A68K_STRING1 = 5
SCE_A68K_OPERATOR = 6
SCE_A68K_CPUINSTRUCTION = 7
SCE_A68K_EXTINSTRUCTION = 8
SCE_A68K_REGISTER = 9
SCE_A68K_DIRECTIVE = 10
SCE_A68K_MACRO_ARG = 11
SCE_A68K_LABEL = 12
SCE_A68K_STRING2 = 13
SCE_A68K_IDENTIFIER = 14
SCE_A68K_MACRO_DECLARATION = 15
SCE_A68K_COMMENT_WORD = 16
SCE_A68K_COMMENT_SPECIAL = 17
SCE_A68K_COMMENT_DOXYGEN = 18

SCE_MODULA_DEFAULT = 0
SCE_MODULA_COMMENT = 1
SCE_MODULA_DOXYCOMM = 2
SCE_MODULA_DOXYKEY = 3
SCE_MODULA_KEYWORD = 4
SCE_MODULA_RESERVED = 5
SCE_MODULA_NUMBER = 6
SCE_MODULA_BASENUM = 7
SCE_MODULA_FLOAT = 8
SCE_MODULA_STRING = 9
SCE_MODULA_STRSPEC = 10
SCE_MODULA_CHAR = 11
SCE_MODULA_CHARSPEC = 12
SCE_MODULA_PROC = 13
SCE_MODULA_PRAGMA = 14
SCE_MODULA_PRGKEY = 15
SCE_MODULA_OPERATOR = 16
SCE_MODULA_BADSTR = 17

SCE_COFFEESCRIPT_DEFAULT = 0
SCE_COFFEESCRIPT_COMMENT = 1
SCE_COFFEESCRIPT_COMMENTLINE = 2
SCE_COFFEESCRIPT_COMMENTDOC = 3
SCE_COFFEESCRIPT_NUMBER = 4
SCE_COFFEESCRIPT_WORD = 5
SCE_COFFEESCRIPT_STRING = 6
SCE_COFFEESCRIPT_CHARACTER = 7
SCE_COFFEESCRIPT_UUID = 8
SCE_COFFEESCRIPT_PREPROCESSOR = 9
SCE_COFFEESCRIPT_OPERATOR = 10
SCE_COFFEESCRIPT_IDENTIFIER = 11
SCE_COFFEESCRIPT_STRINGEOL = 12
SCE_COFFEESCRIPT_VERBATIM = 13
SCE_COFFEESCRIPT_REGEX = 14
SCE_COFFEESCRIPT_COMMENTLINEDOC = 15
SCE_COFFEESCRIPT_WORD2 = 16
SCE_COFFEESCRIPT_COMMENTDOCKEYWORD = 17
SCE_COFFEESCRIPT_COMMENTDOCKEYWORDERROR = 18
SCE_COFFEESCRIPT_GLOBALCLASS = 19
SCE_COFFEESCRIPT_STRINGRAW = 20
SCE_COFFEESCRIPT_TRIPLEVERBATIM = 21
SCE_COFFEESCRIPT_HASHQUOTEDSTRING = 22
SCE_COFFEESCRIPT_VERBOSE_REGEX = 23
SCE_COFFEESCRIPT_VERBOSE_REGEX_COMMENT = 24
SCE_COFFEESCRIPT_COMMENTBLOCK = 25

SCE_AVS_DEFAULT = 0
SCE_AVS_COMMENTBLOCK = 1
SCE_AVS_COMMENTBLOCKN = 2
SCE_AVS_COMMENTLINE = 3
SCE_AVS_NUMBER = 4
SCE_AVS_OPERATOR = 5
SCE_AVS_IDENTIFIER = 6
SCE_AVS_STRING = 7
SCE_AVS_TRIPLESTRING = 8
SCE_AVS_KEYWORD = 9
SCE_AVS_FILTER = 10
SCE_AVS_PLUGIN = 11
SCE_AVS_FUNCTION = 12
SCE_AVS_CLIPPROP = 13
SCE_AVS_USERDFN = 14

SCE_ECL_DEFAULT = 0
SCE_ECL_COMMENT = 1
SCE_ECL_COMMENTLINE = 2
SCE_ECL_NUMBER = 3
SCE_ECL_STRING = 4
SCE_ECL_WORD0 = 5
SCE_ECL_OPERATOR = 6
SCE_ECL_CHARACTER = 7
SCE_ECL_UUID = 8
SCE_ECL_PREPROCESSOR = 9
SCE_ECL_UNKNOWN = 10
SCE_ECL_IDENTIFIER = 11
SCE_ECL_STRINGEOL = 12
SCE_ECL_VERBATIM = 13
SCE_ECL_REGEX = 14
SCE_ECL_COMMENTLINEDOC = 15
SCE_ECL_WORD1 = 16
SCE_ECL_COMMENTDOCKEYWORD = 17
SCE_ECL_COMMENTDOCKEYWORDERROR = 18
SCE_ECL_WORD2 = 19
SCE_ECL_WORD3 = 20
SCE_ECL_WORD4 = 21
SCE_ECL_WORD5 = 22
SCE_ECL_COMMENTDOC = 23
SCE_ECL_ADDED = 24
SCE_ECL_DELETED = 25
SCE_ECL_CHANGED = 26
SCE_ECL_MOVED = 27

SCE_OSCRIPT_DEFAULT = 0
SCE_OSCRIPT_LINE_COMMENT = 1
SCE_OSCRIPT_BLOCK_COMMENT = 2
SCE_OSCRIPT_DOC_COMMENT = 3
SCE_OSCRIPT_PREPROCESSOR = 4
SCE_OSCRIPT_NUMBER = 5
SCE_OSCRIPT_SINGLEQUOTE_STRING = 6
SCE_OSCRIPT_DOUBLEQUOTE_STRING = 7
SCE_OSCRIPT_CONSTANT = 8
SCE_OSCRIPT_IDENTIFIER = 9
SCE_OSCRIPT_GLOBAL = 10
SCE_OSCRIPT_KEYWORD = 11
SCE_OSCRIPT_OPERATOR = 12
SCE_OSCRIPT_LABEL = 13
SCE_OSCRIPT_TYPE = 14
SCE_OSCRIPT_FUNCTION = 15
SCE_OSCRIPT_OBJECT = 16
SCE_OSCRIPT_PROPERTY = 17
SCE_OSCRIPT_METHOD = 18

SCE_VISUALPROLOG_DEFAULT = 0
SCE_VISUALPROLOG_KEY_MAJOR = 1
SCE_VISUALPROLOG_KEY_MINOR = 2
SCE_VISUALPROLOG_KEY_DIRECTIVE = 3
SCE_VISUALPROLOG_COMMENT_BLOCK = 4
SCE_VISUALPROLOG_COMMENT_LINE = 5
SCE_VISUALPROLOG_COMMENT_KEY = 6
SCE_VISUALPROLOG_COMMENT_KEY_ERROR = 7
SCE_VISUALPROLOG_IDENTIFIER = 8
SCE_VISUALPROLOG_VARIABLE = 9
SCE_VISUALPROLOG_ANONYMOUS = 10
SCE_VISUALPROLOG_NUMBER = 11
SCE_VISUALPROLOG_OPERATOR = 12
SCE_VISUALPROLOG_CHARACTER = 13
SCE_VISUALPROLOG_CHARACTER_TOO_MANY = 14
SCE_VISUALPROLOG_CHARACTER_ESCAPE_ERROR = 15
SCE_VISUALPROLOG_STRING = 16
SCE_VISUALPROLOG_STRING_ESCAPE = 17
SCE_VISUALPROLOG_STRING_ESCAPE_ERROR = 18
SCE_VISUALPROLOG_STRING_EOL_OPEN = 19
SCE_VISUALPROLOG_STRING_VERBATIM = 20
SCE_VISUALPROLOG_STRING_VERBATIM_SPECIAL = 21
SCE_VISUALPROLOG_STRING_VERBATIM_EOL = 22

SCE_STTXT_DEFAULT = 0
SCE_STTXT_COMMENT = 1
SCE_STTXT_COMMENTLINE = 2
SCE_STTXT_KEYWORD = 3
SCE_STTXT_TYPE = 4
SCE_STTXT_FUNCTION = 5
SCE_STTXT_FB = 6
SCE_STTXT_NUMBER = 7
SCE_STTXT_HEXNUMBER = 8
SCE_STTXT_PRAGMA = 9
SCE_STTXT_OPERATOR = 10
SCE_STTXT_CHARACTER = 11
SCE_STTXT_STRING1 = 12
SCE_STTXT_STRING2 = 13
SCE_STTXT_STRINGEOL = 14
SCE_STTXT_IDENTIFIER = 15
SCE_STTXT_DATETIME = 16
SCE_STTXT_VARS = 17
SCE_STTXT_PRAGMAS = 18

SCE_XML_DEFAULT = 0
SCE_XML_PROLOG = 0
SCE_XML_START_TAG_OPEN = 1
SCE_XML_START_TAG_NAME = 2
SCE_XML_START_TAG_CLOSE = 3
SCE_XML_START_TAG_EMPTY_CLOSE = 4
SCE_XML_START_TAG_ATTR_NAME = 5
SCE_XML_START_TAG_ATTR_EQUALS = 6
SCE_XML_START_TAG_ATTR_QUOT_OPEN = 7
SCE_XML_START_TAG_ATTR_QUOT_CONTENT = 8
SCE_XML_START_TAG_ATTR_QUOT_CLOSE = 9
SCE_XML_START_TAG_ATTR_APOS_OPEN = 10
SCE_XML_START_TAG_ATTR_APOS_CONTENT = 11
SCE_XML_START_TAG_ATTR_APOS_CLOSE = 12
SCE_XML_END_TAG_OPEN = 13
SCE_XML_END_TAG_NAME = 14
SCE_XML_END_TAG_CLOSE = 15
SCE_XML_START_TAG_ATTR_NUMBER = 16
SCE_XML_ENTITY_REF = 17
SCE_XML_CHAR_REF = 18
SCE_XML_DATA_NEWLINE = 19
SCE_XML_DATA_CHARS = 20
SCE_XML_CDATA_SECT_OPEN = 21
SCE_XML_CDATA_SECT_CONTENT = 22
SCE_XML_CDATA_SECT_CLOSE = 23
SCE_XML_COMMENT_OPEN = 24
SCE_XML_COMMENT_CONTENT = 25
SCE_XML_COMMENT_CLOSE = 26
SCE_XML_PI_OPEN = 27
SCE_XML_PI_CONTENT = 28
SCE_XML_PI_CLOSE = 29
SCE_XML_XML_DECL_OPEN = 30
SCE_XML_XML_DECL_CONTENT = 31
SCE_XML_XML_DECL_CLOSE = 40
SCE_XML_BOM = 41

SCE_XPATH_TAG_NAME = 42
SCE_XPATH_ATTR_NAME = 43
SCE_XPATH_OPEN = 44
SCE_XPATH_CONTENT_QUOT = 45
SCE_XPATH_CONTENT_APOS = 46
SCE_XPATH_CLOSE = 47

SCE_XML_START_TAG_WHITE_SPACE = 48
SCE_XML_START_TAG_ATTR_UNQUOTED = 49
SCE_XML_END_TAG_WHITE_SPACE = 50
SCE_XML_DECLARATION_OPEN = 51
SCE_XML_DECLARATION_TYPE = 52
SCE_XML_DECLN_WHITE_SPACE = 53
SCE_XML_DECLN_NAME = 54
SCE_XML_DECLN_CLOSE = 55
SCE_XML_DECLN_QUOT_CONTENT = 56
SCE_XML_DECLN_APOS_CONTENT = 57
SCE_XML_DECLN_DATA_CHARS = 58
SCE_XML_UPPER_BOUND = 59

SCE_UDL_M_DEFAULT = 0
SCE_UDL_M_STAGO = 1
SCE_UDL_M_TAGNAME = 2
SCE_UDL_M_TAGSPACE = 3
SCE_UDL_M_ATTRNAME = 4
SCE_UDL_M_OPERATOR = 5
SCE_UDL_M_STAGC = 6
SCE_UDL_M_EMP_TAGC = 7
SCE_UDL_M_STRING = 8
SCE_UDL_M_ETAGO = 9
SCE_UDL_M_ETAGC = 10
SCE_UDL_M_ENTITY = 11
SCE_UDL_M_PI = 12
SCE_UDL_M_CDATA = 13
SCE_UDL_M_COMMENT = 14
SCE_UDL_CSS_DEFAULT = 15
SCE_UDL_CSS_COMMENT = 16
SCE_UDL_CSS_NUMBER = 17
SCE_UDL_CSS_STRING = 18
SCE_UDL_CSS_WORD = 19
SCE_UDL_CSS_IDENTIFIER = 20
SCE_UDL_CSS_OPERATOR = 21
SCE_UDL_CSL_DEFAULT = 22
SCE_UDL_CSL_COMMENT = 23
SCE_UDL_CSL_COMMENTBLOCK = 24
SCE_UDL_CSL_NUMBER = 25
SCE_UDL_CSL_STRING = 26
SCE_UDL_CSL_WORD = 27
SCE_UDL_CSL_IDENTIFIER = 28
SCE_UDL_CSL_OPERATOR = 29
SCE_UDL_CSL_REGEX = 30
SCE_UDL_SSL_DEFAULT = 31
SCE_UDL_SSL_COMMENT = 40
SCE_UDL_SSL_COMMENTBLOCK = 41
SCE_UDL_SSL_NUMBER = 42
SCE_UDL_SSL_STRING = 43
SCE_UDL_SSL_WORD = 44
SCE_UDL_SSL_IDENTIFIER = 45
SCE_UDL_SSL_OPERATOR = 46
SCE_UDL_SSL_REGEX = 47
SCE_UDL_SSL_VARIABLE = 48
SCE_UDL_TPL_DEFAULT = 49
SCE_UDL_TPL_COMMENT = 50
SCE_UDL_TPL_COMMENTBLOCK = 51
SCE_UDL_TPL_NUMBER = 52
SCE_UDL_TPL_STRING = 53
SCE_UDL_TPL_WORD = 54
SCE_UDL_TPL_IDENTIFIER = 55
SCE_UDL_TPL_OPERATOR = 56
SCE_UDL_TPL_VARIABLE = 57
SCE_UDL_UPPER_BOUND = 57

########NEW FILE########
__FILENAME__ = SQL
import HTMLGenerator
import Keywords
import Lexer
from DispatchHandler import DispatchHandler
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_SQL
import LanguageInfo


class SQLLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_SQL)
        self._keyword_lists = [
            WordList(Keywords.sql_keywords),
        ]


class SQLHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_C')


class SQLHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, SQLHandler):
    name = 'sql'
    description = 'SQL'

    def __init__(self):
        SQLHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_C')

    def generate_html(self, file, buffer, lexer=SQLLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)

sql_language_info = LanguageInfo.LanguageInfo(
    'sql',
    ['sql'],
    [],
    [SQLHTMLGenerator]
)

LanguageInfo.register_language(sql_language_info)

########NEW FILE########
__FILENAME__ = Utils
import ScintillaConstants


def list_states(state_prefix):
    """list_states("SCE_P_") => ['SCE_P_DEFAULT', 'SCE_P_COMMENTLINE', ...]

    Return a list of Scintilla constants beginning with the given prefix.
    """
    return [constant for constant in dir(ScintillaConstants)
            if constant.startswith(state_prefix)]

########NEW FILE########
__FILENAME__ = XML
import HTMLGenerator
import Lexer
from DispatchHandler import DispatchHandler
import Keywords
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_XML
import LanguageInfo


class XMLLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_XML)
        self._keyword_lists = [
            WordList(),
            WordList(),
            WordList(),
            WordList(),
            WordList(),
            WordList(Keywords.sgml_keywords)
        ]


class XMLHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_H')


class XMLHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, XMLHandler):
    name = 'xml'
    description = 'XML'

    def __init__(self):
        XMLHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_H')

    def generate_html(self, file, buffer, lexer=XMLLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)

xml_language_info = LanguageInfo.LanguageInfo(
    'xml',
    ['xml', 'dtd'],
    [r'.*?\<\?xml.*?'],
    [XMLHTMLGenerator]
)

LanguageInfo.register_language(xml_language_info)

########NEW FILE########
__FILENAME__ = XSLT
import HTMLGenerator
import Lexer
from DispatchHandler import DispatchHandler
import Keywords
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_XML
import LanguageInfo


class XSLTLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_XML)
        self._keyword_lists = [
            WordList(Keywords.xslt_keywords),
            WordList(Keywords.js_keywords),
            WordList(Keywords.vb_keywords),
            WordList(Keywords.python_keywords),
            WordList(Keywords.php_keywords),
            WordList(Keywords.sgml_keywords)
        ]


class XSLTHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_H')


class XSLTHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, XSLTHandler):
    name = 'xslt'
    description = 'XSLT'

    def __init__(self):
        XSLTHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_H')

    def generate_html(self, file, buffer, lexer=XSLTLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)

xslt_language_info = LanguageInfo.LanguageInfo(
    'xslt',
    ['xsl', 'xslt'],
    [],
    [XSLTHTMLGenerator]
)

LanguageInfo.register_language(xslt_language_info)

########NEW FILE########
__FILENAME__ = YAML
import HTMLGenerator
import Keywords
import Lexer
from DispatchHandler import DispatchHandler
from _SilverCity import find_lexer_module_by_id, PropertySet, WordList
from ScintillaConstants import SCLEX_YAML
import LanguageInfo


class YAMLLexer(Lexer.Lexer):
    def __init__(self, properties=PropertySet()):
        self._properties = properties
        self._lexer = find_lexer_module_by_id(SCLEX_YAML)
        self._keyword_lists = [
            WordList(Keywords.yaml_keywords),
        ]


class YAMLHandler(DispatchHandler):
    def __init__(self):
        DispatchHandler.__init__(self, 'SCE_YAML')


class YAMLHTMLGenerator(HTMLGenerator.SimpleHTMLGenerator, YAMLHandler):
    name = 'yaml'
    description = 'YAML'

    def __init__(self):
        YAMLHandler.__init__(self)
        HTMLGenerator.SimpleHTMLGenerator.__init__(self, 'SCE_YAML')

    def generate_html(self, file, buffer, lexer=YAMLLexer()):
        self._file = file

        lexer.tokenize_by_style(buffer, self.event_handler)


yaml_language_info = LanguageInfo.LanguageInfo(
    'YAML',
    ['yml', 'yaml'],
    [],
    [YAMLHTMLGenerator]
)

LanguageInfo.register_language(yaml_language_info)

########NEW FILE########
__FILENAME__ = styles
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
# 
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
# 
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
# 
# The Original Code is Komodo code.
# 
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
# 
# Contributor(s):
#   ActiveState Software Inc
# 
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
# 
# ***** END LICENSE BLOCK *****

CommonStates = [
    'default', 'comments', 'numbers', 'strings', 'keywords',
    'classes', 'functions', 'operators', 'identifiers',
    'stringeol', 'preprocessor', 'bracebad', 'bracehighlight',
    'control characters', 'linenumbers', 'fold markers', 'indent guides',
    'stdin', 'stdout', 'stderr'
]

# We could move this to the languages
StateMap = {
    'Rx': {
        'default': (0,),
        'breakpoints': (1,),
        'children': (2,),
        'parents': (3,),
    },
    'Regex': {
        #XXX Should I be using 'default'=32? My reading of the Scintilla
        #    docs says that I should, but every Scintilla lexer uses 0.
        "default": (0,),
        # XXX Should I use the common "comments" (i.e. plural) here?
        "comment": (1,), # (?#...)
        "text": (2,),
        "special": (3,), # standalone (. ^ $ |), in charset (^ -)
        "charset_operator": (4,),
        "operator": (5,), # open/close paren (use operator for paren matching by scintilla)
        "groupref": (6,), 
        "quantifier": (7,),
        "grouptag": (8,),
        "charclass": (9,),
        "charescape": (10,),
        "eol": (11,), #XXX not currently used
        "match_highlight": (12,),
    },
    'Python': {
        'default': ('SCE_P_DEFAULT',),
        'comments' : ('SCE_P_COMMENTLINE',
                      'SCE_P_COMMENTBLOCK'),
        'numbers': ('SCE_P_NUMBER',),
        'strings': ('SCE_P_STRING',
                    'SCE_P_CHARACTER', 
                    'SCE_P_TRIPLE',
                    'SCE_P_TRIPLEDOUBLE'),
        'keywords': ('SCE_P_WORD',),
        'keywords2': ('SCE_P_WORD2',),
        'classes': ('SCE_P_CLASSNAME',),
        'functions': ('SCE_P_DEFNAME',),
        'operators': ('SCE_P_OPERATOR',),
        'identifiers': ('SCE_P_IDENTIFIER',),
        'stringeol' : ('SCE_P_STRINGEOL',),
        'decorators' : ('SCE_P_DECORATOR',),
        'stdin': ('SCE_P_STDIN',),
        'stdout': ('SCE_P_STDOUT',),
        'stderr' : ('SCE_P_STDERR',),
        },
    'C++': {
        'default': ('SCE_C_DEFAULT',),
        'comments': ('SCE_C_COMMENT',
                     'SCE_C_COMMENTLINE',
                     'SCE_C_COMMENTDOC',
                     'SCE_C_COMMENTLINEDOC',
                     'SCE_C_COMMENTDOCKEYWORD',
                     'SCE_C_COMMENTDOCKEYWORDERROR',
                     ),
        'numbers': ('SCE_C_NUMBER',),
        'strings': ('SCE_C_STRING',
                    'SCE_C_CHARACTER',
                    ),
        'keywords': ('SCE_C_WORD',),
        'keywords2': ('SCE_C_WORD2',),
        'operators': ('SCE_C_OPERATOR',),
        'identifiers': ('SCE_C_IDENTIFIER',),
        'stringeol': ('SCE_C_STRINGEOL',),
        'preprocessor': ('SCE_C_PREPROCESSOR',),
        # these are specific to this lexer
        'UUIDs': ('SCE_C_UUID',),
        'verbatim': ('SCE_C_VERBATIM',),
        'regex': ('SCE_C_REGEX',),
        'commentdockeyword': ('SCE_C_COMMENTDOCKEYWORD',),
        'commentdockeyworderror': ('SCE_C_COMMENTDOCKEYWORDERROR',),
        'globalclass': ('SCE_C_GLOBALCLASS',),
        'stringeol' : ('SCE_C_STRINGEOL',),
        'stdin': ('SCE_C_STDIN',),
        'stdout': ('SCE_C_STDOUT',),
        'stderr' : ('SCE_C_STDERR',),
    },
    'VisualBasic': {
        'default': ('SCE_B_DEFAULT',),
        'comments': ('SCE_B_COMMENT',),
        'numbers': ('SCE_B_NUMBER',),
        'keywords': ('SCE_B_KEYWORD',),
        'strings': ('SCE_B_STRING',),
        'preprocessor': ('SCE_B_PREPROCESSOR',),
        'operators': ('SCE_B_OPERATOR',),
        'identifiers': ('SCE_B_IDENTIFIER',),
        # specific to VB
        'dates': ('SCE_B_DATE',),
        },
    'LaTex': {
        'default': ('SCE_L_DEFAULT',),
        'comments': ('SCE_L_COMMENT',),

        'commands': ('SCE_L_COMMAND',),
        'tags': ('SCE_L_TAG',),
        'math': ('SCE_L_MATH',),
    },
    'Lua': {
        'default': ('SCE_LUA_DEFAULT',),
        'comments': ('SCE_LUA_COMMENT',
                     'SCE_LUA_COMMENTLINE',
                     'SCE_LUA_COMMENTDOC',),
        'numbers': ('SCE_LUA_NUMBER',),
        'strings': ('SCE_LUA_STRING',
                    'SCE_LUA_CHARACTER',
                    'SCE_LUA_LITERALSTRING',
                    ),
        'preprocessor': ('SCE_LUA_PREPROCESSOR',),
        'operators': ('SCE_LUA_OPERATOR',),
        'identifiers': ('SCE_LUA_IDENTIFIER',),
        'stringeol': ('SCE_LUA_STRINGEOL',),
        'keywords': ('SCE_LUA_WORD',),
        'keywords2': ('SCE_LUA_WORD2',
                      'SCE_LUA_WORD3',
                      'SCE_LUA_WORD4',
                      'SCE_LUA_WORD5',
                      'SCE_LUA_WORD6',),
    },
    'Tcl': {
        'default': ('SCE_TCL_DEFAULT',),
        'comments': ('SCE_TCL_COMMENT',),
        'variables': ('SCE_TCL_VARIABLE',),
        'arrays': ('SCE_TCL_ARRAY',),
        'numbers': ('SCE_TCL_NUMBER',),
        'keywords': ('SCE_TCL_WORD',),
        'strings': ('SCE_TCL_STRING',
                    'SCE_TCL_CHARACTER',
                    'SCE_TCL_LITERAL',),
        'identifiers': ('SCE_TCL_IDENTIFIER',),
        'operators': ('SCE_TCL_OPERATOR',),
        'stringeol': ('SCE_TCL_EOL',),
        'stdin': ('SCE_TCL_STDIN',),
        'stdout': ('SCE_TCL_STDOUT',),
        'stderr' : ('SCE_TCL_STDERR',),
    },
    'UDL' : {
        'default': ('SCE_UDL_M_TAGSPACE',
                    'SCE_UDL_M_DEFAULT',
                    'SCE_UDL_CSS_DEFAULT',
                    'SCE_UDL_CSL_DEFAULT',
                    'SCE_UDL_SSL_DEFAULT',
                    'SCE_UDL_TPL_DEFAULT',
                    ),
        'identifiers': ('SCE_UDL_CSS_IDENTIFIER',
                        'SCE_UDL_CSL_IDENTIFIER',
                        'SCE_UDL_SSL_IDENTIFIER',
                        'SCE_UDL_TPL_IDENTIFIER',
                        ),
        'numbers': ('SCE_UDL_CSS_NUMBER',
                    'SCE_UDL_CSL_NUMBER',
                    'SCE_UDL_SSL_NUMBER',
                    'SCE_UDL_TPL_NUMBER',
                    ),
        'strings': ('SCE_UDL_M_STRING',
                    'SCE_UDL_CSS_STRING',
                    'SCE_UDL_CSL_STRING',
                    'SCE_UDL_SSL_STRING',
                    'SCE_UDL_TPL_STRING',
                    ),
        'comments': ('SCE_UDL_M_COMMENT',
                     'SCE_UDL_CSS_COMMENT',
                     'SCE_UDL_CSL_COMMENT',
                     'SCE_UDL_CSL_COMMENTBLOCK',
                     'SCE_UDL_SSL_COMMENT',
                     'SCE_UDL_SSL_COMMENTBLOCK',
                     'SCE_UDL_TPL_COMMENT',
                     'SCE_UDL_TPL_COMMENTBLOCK',
                     ),
        'keywords': ('SCE_UDL_CSS_WORD',
                     'SCE_UDL_CSL_WORD',
                     'SCE_UDL_SSL_WORD',
                     'SCE_UDL_TPL_WORD',
                    ),
        'operators': ('SCE_UDL_M_OPERATOR',
                      'SCE_UDL_CSS_OPERATOR',
                      'SCE_UDL_CSL_OPERATOR',
                      'SCE_UDL_SSL_OPERATOR',
                      'SCE_UDL_TPL_OPERATOR',
                      ),
        'variables': ('SCE_UDL_SSL_VARIABLE',
                      'SCE_UDL_TPL_VARIABLE',
                      ),
        'regex': ('SCE_UDL_CSL_REGEX',
                  'SCE_UDL_SSL_REGEX',
                  ),
        'pi content': ('SCE_UDL_M_PI',
                       ),
        'tags': ('SCE_UDL_M_STAGO',
                 'SCE_UDL_M_TAGNAME',
                 'SCE_UDL_M_STAGC',
                 'SCE_UDL_M_EMP_TAGC',
                 'SCE_UDL_M_ETAGO',
                 'SCE_UDL_M_ETAGC',
                 ),
        'attribute value': ('SCE_UDL_M_STRING',),
        'attribute name': ('SCE_UDL_M_ATTRNAME',),
        'entity references': ('SCE_UDL_M_ENTITY',
                              ),
        'cdata' : ('SCE_UDL_M_CDATA', )
    },
    'Text': {},
    'Perl': {
        'default':('SCE_PL_DEFAULT',
                   'SCE_PL_UNKNOWN_FIELD',
                   'SCE_PL_SUB_ARGS',),
        'errors': ('SCE_PL_ERROR',),
        'comments': ('SCE_PL_COMMENTLINE',
                     'SCE_PL_POD'),
        'numbers': ('SCE_PL_NUMBER',),
        'keywords': ('SCE_PL_WORD',),
        'strings': ('SCE_PL_STRING',
                    'SCE_PL_CHARACTER',
                    'SCE_PL_STRING_Q',
                    'SCE_PL_STRING_QQ',
                    'SCE_PL_STRING_QX',
                    'SCE_PL_STRING_QR',
                    'SCE_PL_STRING_QW',
                    'SCE_PL_LONGQUOTE',
                    'SCE_PL_FORMAT',
                    ),
        'identifiers': ('SCE_PL_IDENTIFIER',),
        'operators': ('SCE_PL_OPERATOR',
                      'SCE_PL_BACKTICKS',
                      'SCE_PL_VARIABLE_INDEXER'),
        'functions': ('SCE_PL_SUB',),
        'here documents': ('SCE_PL_HERE_DELIM',
                           'SCE_PL_HERE_Q',
                           'SCE_PL_HERE_QQ',
                           'SCE_PL_HERE_QX'),
        'arrays': ('SCE_PL_ARRAY',),
        'hashes': ('SCE_PL_HASH',),
        'symbol tables': ('SCE_PL_SYMBOLTABLE',),
        'regex': ('SCE_PL_REGEX',
                  'SCE_PL_REGSUBST',),
        'preprocessor': ('SCE_PL_PREPROCESSOR',),
        'variables': ('SCE_PL_SCALAR',),
        'data sections': ('SCE_PL_DATASECTION',),
        'stdin': ('SCE_PL_STDIN',),
        'stdout': ('SCE_PL_STDOUT',),
        'stderr' : ('SCE_PL_STDERR',),
    },
    'Properties': {
        'default': ('SCE_PROPS_DEFAULT',),
        'comments': ('SCE_PROPS_COMMENT',),
        'sections': ('SCE_PROPS_SECTION',),
        'assignments': ('SCE_PROPS_ASSIGNMENT',),
        'defvals': ('SCE_PROPS_DEFVAL',),
    },
    'Batch': {
        'default': ('SCE_BAT_DEFAULT',),
        'comments': ('SCE_BAT_COMMENT',),
        'keywords': ('SCE_BAT_WORD',),
        'functions': ('SCE_BAT_LABEL',),
        'hide': ('SCE_BAT_HIDE',),
        'commands': ('SCE_BAT_COMMAND',),
        'identifiers': ('SCE_BAT_IDENTIFIER',),
        'operators': ('SCE_BAT_OPERATOR',),
    },
    'CSS': {
        'default': ('SCE_CSS_DEFAULT',),
        'tags': ('SCE_CSS_TAG',
                 'SCE_CSS_PSEUDOELEMENT',
                 'SCE_CSS_EXTENDED_PSEUDOELEMENT',
                 ),
        'classes': ('SCE_CSS_CLASS',
                    'SCE_CSS_PSEUDOCLASS',
                    'SCE_CSS_EXTENDED_PSEUDOCLASS',
                    'SCE_CSS_UNKNOWN_PSEUDOCLASS',
                    ),
        'operators': ('SCE_CSS_OPERATOR',),
        'identifiers': ('SCE_CSS_IDENTIFIER',
                        'SCE_CSS_UNKNOWN_IDENTIFIER',
                        'SCE_CSS_IDENTIFIER2',
                        'SCE_CSS_IDENTIFIER3',
                        'SCE_CSS_EXTENDED_IDENTIFIER',
                        ),
        'values': ('SCE_CSS_VALUE',),
        'comments': ('SCE_CSS_COMMENT',),
        'ids': ('SCE_CSS_ID',),
        'important': ('SCE_CSS_IMPORTANT',),
        'directives': ('SCE_CSS_DIRECTIVE',),
        'strings': ('SCE_CSS_DOUBLESTRING', 'SCE_CSS_SINGLESTRING',),
        'numbers': ('SCE_CSS_NUMBER',),
        'stringeol': ('SCE_CSS_STRINGEOL',),
        'attribute name': ('SCE_CSS_ATTRIBUTE',),
    },
    'Makefile': {
        'default': ('SCE_MAKE_DEFAULT',),
        'comments': ('SCE_MAKE_COMMENT',),
        'preprocessor': ('SCE_MAKE_PREPROCESSOR',),
        'identifiers': ('SCE_MAKE_IDENTIFIER',),
        'operators': ('SCE_MAKE_OPERATOR',),
        'targets': ('SCE_MAKE_TARGET',),
        'stringeol': ('SCE_MAKE_IDEOL',),
        },
    'Diff': {
        'default': ('SCE_DIFF_DEFAULT',),
        'comments': ('SCE_DIFF_COMMENT',),
        'commands': ('SCE_DIFF_COMMAND',),
        'chunkheader': ('SCE_DIFF_HEADER',),
        'diffline': ('SCE_DIFF_POSITION',),
        'deletionline': ('SCE_DIFF_DELETED',),
        'additionline': ('SCE_DIFF_ADDED',),
    },
    'LaTeX': {},
    'Lisp': {
        'comments': ('SCE_LISP_COMMENT',),
        'strings': ('SCE_LISP_STRING',),
        'stringeol': ('SCE_LISP_STRINGEOL',),
    },
    'Ada': {
        'default': ('SCE_ADA_DEFAULT',),
        'keywords': ('SCE_ADA_WORD',),
        'identifiers': ('SCE_ADA_IDENTIFIER',),
        'comments': ('SCE_ADA_COMMENTLINE',),
        'numbers': ('SCE_ADA_NUMBER',),
        'strings': ('SCE_ADA_CHARACTER',
                    'SCE_ADA_STRING',),
        'stringeol': ('SCE_ADA_CHARACTEREOL',
                      'SCE_ADA_STRINGEOL',),
        'illegals': ('SCE_ADA_ILLEGAL',),
        'delimiters': ('SCE_ADA_DELIMITER',),
        'labels': ('SCE_ADA_LABEL',),
        },
    'Apache': {
        'directives': ('SCE_CONF_DIRECTIVE',),
        'parameters': ('SCE_CONF_PARAMETER',),
        'extensions': ('SCE_CONF_EXTENSION',),
        'default': ('SCE_CONF_DEFAULT',),
        'numbers': ('SCE_CONF_NUMBER',),
        'identifiers': ('SCE_CONF_IDENTIFIER',),
        'strings': ('SCE_CONF_STRING',),
        'comments': ('SCE_CONF_COMMENT',),
        'ip_addresses': ('SCE_CONF_IP',),
        },
    'Fortran 77': {
        'comments': ('SCE_F_COMMENT',),
        'default': ('SCE_F_DEFAULT',),
        'keywords': ('SCE_F_WORD',
                     'SCE_F_WORD2',
                     'SCE_F_WORD3',
                     ),
        'preprocessor': ('SCE_F_PREPROCESSOR',),
        'identifiers': ('SCE_F_IDENTIFIER',),
        'operators': ('SCE_F_OPERATOR',
                      'SCE_F_OPERATOR2',
                      ),
        'numbers': ('SCE_F_NUMBER',),
        'strings': ('SCE_F_STRING1',
                    'SCE_F_STRING2',
                    ),
        'stringeol': ('SCE_F_STRINGEOL',),
        'labels': ('SCE_F_LABEL',),
        'delimiters': ('SCE_F_CONTINUATION',),
    },
    'SQL': {
        'comments': ('SCE_C_COMMENTLINE',
                     'SCE_C_COMMENT',
                     ),
    },
    'Eiffel': {
        'comments': ('SCE_EIFFEL_COMMENTLINE',),
        'default': ('SCE_EIFFEL_DEFAULT',),
        'keywords': ('SCE_EIFFEL_WORD',),
        'identifiers': ('SCE_EIFFEL_IDENTIFIER',),
        'operators': ('SCE_EIFFEL_OPERATOR',
                      ),
        'numbers': ('SCE_EIFFEL_NUMBER',),
        'strings': ('SCE_EIFFEL_STRING',
                    'SCE_EIFFEL_CHARACTER',
                    ),
        'stringeol': ('SCE_EIFFEL_STRINGEOL',),
    },
    'Baan': {
        'comments': ('SCE_BAAN_COMMENT', 'SCE_BAAN_COMMENTDOC'),
    },
    'nnCrontab': {
        'comments': ('SCE_NNCRONTAB_COMMENT',),
    },
    'Matlab': {
        'comments': ('SCE_MATLAB_COMMENT',),
        'strings': ('SCE_MATLAB_STRING',
                    'SCE_MATLAB_DOUBLEQUOTESTRING'),
        'operators': ('SCE_MATLAB_OPERATOR',),
        'keywords': ('SCE_MATLAB_KEYWORD',),
        'commands': ('SCE_MATLAB_COMMAND',),
        'identifiers': ('SCE_MATLAB_IDENTIFIER',),
        'numbers': ('SCE_MATLAB_NUMBER',),
    },
    'Bullant': {
        'comments': ('SCE_C_COMMENTLINE', 'SCE_C_COMMENT'),
    },
    'Errors': {
        'Default': ('SCE_ERR_DEFAULT',),
        'Error lines':
            (# 'SCE_ERR_CMD', # too brittle - see http://bugs.activestate.com/show_bug.cgi?id=26605
             'SCE_ERR_PYTHON',
             # 'SCE_ERR_GCC', # too brittle - see http://bugs.activestate.com/show_bug.cgi?id=26605
             'SCE_ERR_MS',
             'SCE_ERR_CTAG',
             'SCE_ERR_ELF',
             'SCE_ERR_NET',
             'SCE_ERR_PERL',
             'SCE_ERR_LUA',
             'SCE_ERR_BORLAND',
             'SCE_ERR_IFC',
             'SCE_ERR_PHP')
    },
    'Ruby': {
        'default':('SCE_RB_DEFAULT',),
        'errors': ('SCE_RB_ERROR',),
        'comments': ('SCE_RB_COMMENTLINE',
                     'SCE_RB_POD'),
        'numbers': ('SCE_RB_NUMBER',),
        'keywords': ('SCE_RB_WORD',
                     'SCE_RB_WORD_DEMOTED'
                     ),
        'strings': ('SCE_RB_STRING',
                    'SCE_RB_CHARACTER',
                    'SCE_RB_STRING_Q',
                    'SCE_RB_STRING_QQ',
                    'SCE_RB_STRING_QX',
                    'SCE_RB_STRING_QR',
                    'SCE_RB_STRING_QW',
                    'SCE_RB_BACKTICKS',
                    ),
        'classes': ('SCE_RB_CLASSNAME',),
        'modules': ('SCE_RB_MODULE_NAME',),
        'functions': ('SCE_RB_DEFNAME',),
        'identifiers': ('SCE_RB_IDENTIFIER',),
        'operators': ('SCE_RB_OPERATOR',),
        'global variables' : ('SCE_RB_GLOBAL',),
        'class variables' : ('SCE_RB_CLASS_VAR',),
        'instance variables' : ('SCE_RB_INSTANCE_VAR',),
        'here documents': ('SCE_RB_HERE_DELIM',
                           'SCE_RB_HERE_Q',
                           'SCE_RB_HERE_QQ',
                           'SCE_RB_HERE_QX'),
        'symbols': ('SCE_RB_SYMBOL',),
        'regex': ('SCE_RB_REGEX',),
        'data sections': ('SCE_RB_DATASECTION',),
        'stdin': ('SCE_RB_STDIN',),
        'stdout': ('SCE_RB_STDOUT',),
        'stderr' : ('SCE_RB_STDERR',),
    },
    'CoffeeScript': {
        'default': ('SCE_COFFEESCRIPT_DEFAULT',),
        'comments': ('SCE_COFFEESCRIPT_COMMENT',
                     'SCE_COFFEESCRIPT_COMMENTLINE',
                     'SCE_COFFEESCRIPT_COMMENTDOC',
                     'SCE_COFFEESCRIPT_COMMENTLINEDOC',
                     'SCE_COFFEESCRIPT_COMMENTDOCKEYWORD',
                     'SCE_COFFEESCRIPT_COMMENTDOCKEYWORDERROR',
                     'SCE_COFFEESCRIPT_COMMENTBLOCK',
                     'SCE_COFFEESCRIPT_VERBOSE_REGEX_COMMENT',
                     ),
        'numbers': ('SCE_COFFEESCRIPT_NUMBER',),
        'strings': ('SCE_COFFEESCRIPT_STRING',
                    'SCE_COFFEESCRIPT_CHARACTER',
                    'SCE_COFFEESCRIPT_STRINGRAW',
                    'SCE_COFFEESCRIPT_HASHQUOTEDSTRING',
                    ),
        'keywords': ('SCE_COFFEESCRIPT_WORD',),
        'keywords2': ('SCE_COFFEESCRIPT_WORD2',),
        'operators': ('SCE_COFFEESCRIPT_OPERATOR',),
        'identifiers': ('SCE_COFFEESCRIPT_IDENTIFIER',),
        'stringeol': ('SCE_COFFEESCRIPT_STRINGEOL',),
        'preprocessor': ('SCE_COFFEESCRIPT_PREPROCESSOR',),
        # these are specific to this lexer
        'UUIDs': ('SCE_COFFEESCRIPT_UUID',),
        'verbatim': ('SCE_COFFEESCRIPT_VERBATIM',
                     'SCE_COFFEESCRIPT_TRIPLEVERBATIM'),
        'regex': ('SCE_COFFEESCRIPT_REGEX',
                  'SCE_COFFEESCRIPT_VERBOSE_REGEX'),
        'commentdockeyword': ('SCE_COFFEESCRIPT_COMMENTDOCKEYWORD',),
        'commentdockeyworderror': ('SCE_COFFEESCRIPT_COMMENTDOCKEYWORDERROR',),
        'globalclass': ('SCE_COFFEESCRIPT_GLOBALCLASS',),
        'stringeol' : ('SCE_COFFEESCRIPT_STRINGEOL',),
    }
}

#Derivatives (Shared lexers)
StateMap['JavaScript'] = StateMap['C++'].copy()
StateMap['Node.js'] = StateMap['JavaScript'].copy()
StateMap['JSON'] = StateMap['C++'].copy()
StateMap['Java'] = StateMap['C++'].copy()
StateMap['C#'] = StateMap['C++'].copy()
StateMap['HLSL'] = StateMap['C++'].copy()
StateMap['IDL'] = StateMap['C++'].copy()
StateMap['VBScript'] = StateMap['VisualBasic'].copy()
StateMap['Fortran'] = StateMap['Fortran 77'].copy()
StateMap['Python3'] = StateMap['Python'].copy()
StateMap['SCSS'] = StateMap['CSS'].copy()
StateMap['Sass'] = StateMap['SCSS'].copy()
StateMap['Less'] = StateMap['CSS'].copy()
StateMap['Less']['mixins'] = ('SCE_CSS_MIXIN',)
StateMap['Octave'] = StateMap['Matlab'].copy()

SharedStates = {
    'bracebad' : ('STYLE_BRACEBAD',),
    'bracehighlight' : ('STYLE_BRACELIGHT',),
    'control characters' : ('STYLE_CONTROLCHAR',),
    'linenumbers': ('STYLE_LINENUMBER',),
    'indent guides': ('STYLE_INDENTGUIDE',),
}

# A map of the indicator name to the koILintResult/SciMoz indicator value used.
IndicatorNameMap = {
    'linter_error': 'DECORATOR_ERROR',
    'linter_warning': 'DECORATOR_WARNING',
    'soft_characters': 'DECORATOR_SOFT_CHAR',
    'tabstop_current': 'DECORATOR_TABSTOP_TSC',
    'tabstop_pending': 'DECORATOR_TABSTOP_TS1',
    'find_highlighting': 'DECORATOR_FIND_HIGHLIGHT',
    'tag_matching': 'DECORATOR_TAG_MATCH_HIGHLIGHT',
}

def addSharedStyles(langMap):
    langMap.update(SharedStates)

for languageName in StateMap:
    addSharedStyles(StateMap[languageName])

def addNewUDLLanguage(languageName):
    if languageName in StateMap:
        import logging
        log = logging.getLogger("language styles")
        log.warn("addNewUDLLanguage: overwriting statemap for lang %s",
                 languageName)
        # Make sure the state-map inherits from UDL
        tmp = StateMap['UDL'].copy()
        tmp.update(StateMap[languageName])
        StateMap[languageName] = tmp
    else:
        StateMap[languageName] = StateMap['UDL']
    addSharedStyles(StateMap[languageName])


########NEW FILE########
__FILENAME__ = textinfo
#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is Komodo code.
#
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
# Contributor(s):
#   ActiveState Software Inc
#
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
#
# ***** END LICENSE BLOCK *****

r"""Determine information about text files.

This module efficiently determines the encoding of text files (see
_classify_encoding for details), accurately identifies binary files, and
provides detailed meta information of text files.

    >>> import textinfo
    >>> path = __file__
    >>> if path.endswith(".pyc"): path = path[:-1]
    >>> ti = textinfo.textinfo_from_path(path)
    >>> ti.__class__
    <class 'textinfo.TextInfo'>
    >>> ti.encoding
    'utf-8'
    >>> ti.file_type_name
    'regular file'
    >>> ti.is_text
    True
    >>> ti.lang
    'Python'
    >>> ti.langinfo
    <Python LangInfo>

...plus a number of other useful information gleaned from the file. To see
a list of all useful attributes see

    >> list(ti.as_dict().keys())
    ['encoding', 'file_type', ...]

Note: This module requires at least Python 2.5 to use
`codecs.lookup(<encname>).name`.
"""

_cmdln_doc = """Determine information about text files.
"""

# TODO:
# - [high prio] prefs integration
# - aggegrate "is there an explicit encoding decl in this file" from XML, HTML,
#   lang-specific, emacs and vi vars decls (as discussed with Shane)
# - fix ti with unicode paths Windows (check on Linux too)
# - '-L|--dereference' option a la `file` and `ls`
# - See: http://webblaze.cs.berkeley.edu/2009/content-sniffing/
# - Shift-JIS encoding is not detected for
#   http://public.activestate.com/pub/apc/perl-current/lib/Pod/Simple/t/corpus/s2763_sjis.txt
#   [Jan wrote]
#   > While the document isn't identified by filename extension as POD,
#   > it does contain POD and a corresponding =encoding directive.
#   Could potentially have a content heuristic check for POD.
#

# ----------------
# Current Komodo (4.2) Encoding Determination Notes (used for reference,
# but not absolutely followed):
#
# Working through koDocumentBase._detectEncoding:
#   encoding_name = pref:encodingDefault (on first start is set
#       to encoding from locale.getdefaultlocale() typically,
#       fallback to iso8859-1; default locale typically ends up being:
#           Windows: cp1252
#           Mac OS X: mac-roman
#           (modern) Linux: UTF-8)
#   encoding = the python name for this
#   tryencoding = pref:encoding (no default, explicitly set
#       encoding) -- i.e. if there are doc prefs for this
#       path, then give this encoding a try. If not given,
#       then utf-8 for XML/XSLT/VisualBasic and
#       pref:encodingDefault for others (though this is
#       all prefable via the 'languages' pref struct).
#   tryxmldecl
#   trymeta (HTML meta)
#   trymodeline
#   autodetect (whether to try at all)
#
#   if autodetect or tryencoding:
#       koUnicodeEncoding.autoDetectEncoding()
#   else:
#       if encoding.startswith('utf'): # note this is pref:encodingDefault
#           check bom
#           presume encoding is right (give up if conversion fails)
#       else:
#           presume encoding is right (given up if fails)
#
# Working through koUnicodeEncoding.autoDetectEncoding:
#   if tryxmldecl: ...
#   if tryhtmlmeta: ...
#   if trymodeline: ...
#   use bom: ...
# ----------------

__version_info__ = (0, 1, 0)
__version__ = '.'.join(map(str, __version_info__))

import os
from os.path import join, dirname, abspath, basename, exists
import sys
import re
from pprint import pprint
import traceback
import warnings
import logging
import optparse
import codecs
import locale

import langinfo


#---- exceptions and warnings
class TextInfoError(Exception):
    pass


class TextInfoConfigError(TextInfoError):
    pass


class ChardetImportWarning(ImportWarning):
    pass
warnings.simplefilter("once", ChardetImportWarning)


#---- globals
log = logging.getLogger("textinfo")

# For debugging:
DEBUG_CHARDET_INFO = False  # gather chardet info


#---- module API
def textinfo_from_filename(path):
    """Determine test info for the given path **using the filename only**.

    No attempt is made to stat or read the file.
    """
    return TextInfo.init_from_filename(path)


def textinfo_from_path(path, encoding=None, follow_symlinks=False,
                       quick_determine_lang=False):
    """Determine text info for the given path.

    This raises EnvironmentError if the path doesn't not exist or could
    not be read.
    """
    return TextInfo.init_from_path(path, encoding=encoding,
                                   follow_symlinks=follow_symlinks,
                                   quick_determine_lang=quick_determine_lang)


#---- main TextInfo class
class TextInfo(object):
    path = None
    file_type_name = None  # e.g. "regular file", "directory", ...
    file_type = None      # stat.S_IFMT(os.stat(path).st_mode)
    file_mode = None      # stat.S_IMODE(os.stat(path).st_mode)
    is_text = None

    encoding = None
    has_bom = None   # whether the text has a BOM (Byte Order Marker)
    encoding_bozo = False
    encoding_bozo_reasons = None

    lang = None         # e.g. "Python", "Perl", ...
    langinfo = None     # langinfo.LangInfo instance or None

    # Enable chardet-based heuristic guessing of encoding as a last
    # resort for file types known to not be binary.
    CHARDET_ENABLED = True
    CHARDET_THRESHHOLD = 0.9  # >=90% confidence to avoid false positives.

    @classmethod
    def init_from_filename(cls, path, lidb=None):
        """Create an instance using only the filename to initialize."""
        if lidb is None:
            lidb = langinfo.get_default_database()
        self = cls()
        self.path = path
        self._classify_from_filename(lidb)
        return self

    @classmethod
    def init_from_path(cls, path, encoding=None, lidb=None,
                       follow_symlinks=False,
                       quick_determine_lang=False,
                       env=None):
        """Create an instance using the filename and stat/read info
        from the given path to initialize.

        @param follow_symlinks {boolean} can be set to True to have
            the textinfo returned for a symlink be for linked-to file. By
            default the textinfo is for the symlink itself.
        @param quick_determine_lang {boolean} can be set to True to have
            processing stop as soon as the language has been determined.
            Note that this means some fields will not be populated.
        @param env {runtime environment} A "runtime environment" class
            whose behaviour is used to influence processing. Currently
            it is just used to provide a hook for lang determination
            by filename (for Komodo).
        """
        if lidb is None:
            lidb = langinfo.get_default_database()
        self = cls()
        self.path = path
        self._accessor = PathAccessor(path, follow_symlinks=follow_symlinks)
        try:
            # TODO: pref: Is a preference specified for this path?

            self._classify_from_stat(lidb)
            if self.file_type_name != "regular file":
                # Don't continue if not a regular file.
                return self

            # TODO: add 'pref:treat_as_text' a la TextMate (or
            #      perhaps that is handled in _classify_from_filename())

            self._classify_from_filename(lidb, env)
            if self.is_text is False:
                return self
            if self.lang and quick_determine_lang:
                return self

            if not self.lang:
                self._classify_from_magic(lidb)
                if self.is_text is False:
                    return self
            if self.lang and quick_determine_lang:
                return self

            self._classify_encoding(lidb, suggested_encoding=encoding)
            if self.is_text is None and self.encoding:
                self.is_text = True
            if self.is_text is False:
                return self
            self.text = self._accessor.text

            if self.text:  # No `self.text' with current UTF-32 hack.
                self._classify_from_content(lidb)
            return self
        finally:
            # Free the memory used by the accessor.
            del self._accessor

    def __repr__(self):
        if self.path:
            return "<TextInfo %r>" % self.path
        else:
            return "<TextInfo %r>"\
                   % _one_line_summary_from_text(self.content, 30)

    def as_dict(self):
        return dict((k, v) for k, v in self.__dict__.items()
                    if not k.startswith('_'))

    def as_summary(self):
        """One-liner string summary of text info."""
        d = self.as_dict()
        info = []
        if self.file_type_name and self.file_type_name != "regular file":
            info.append(self.file_type_name)
        else:
            info.append(self.lang or "???")
            if not self.is_text:
                info.append("binary")
            elif self.encoding:
                enc = self.encoding
                if self.has_bom:
                    enc += " (bom)"
                info.append(enc)
            if DEBUG_CHARDET_INFO and hasattr(self, "chardet_info") \
               and self.chardet_info["encoding"]:
                info.append("chardet:%s/%.1f%%"
                            % (self.chardet_info["encoding"],
                               self.chardet_info["confidence"] * 100.0))
        return "%s: %s" % (self.path, ', '.join(info))

    def _classify_from_content(self, lidb):

        # TODO: Plan:
        # - eol_* attrs (test cases for this!)

        head = self.text[:self._accessor.HEAD_SIZE]
        tail = self.text[-self._accessor.TAIL_SIZE:]

        # If lang is unknown, attempt to guess from XML prolog or
        # shebang now that we've successfully decoded the buffer.
        if self.langinfo is None:
            (self.has_xml_prolog, xml_version,
             xml_encoding) = self._get_xml_prolog_info(head)
            if self.has_xml_prolog:
                self.xml_version = xml_version
                self.xml_encoding = xml_encoding
                self.langinfo = lidb.langinfo_from_lang("XML")
                self.lang = self.langinfo.name
            elif self.text.startswith("#!"):
                li = lidb.langinfo_from_magic(self.text, shebang_only=True)
                if li:
                    self.langinfo = li
                    self.lang = li.name

        # Extract Emacs local vars and Vi(m) modeline info and, if the
        # lang is still unknown, attempt to use them to determine it.
        self.emacs_vars = self._get_emacs_head_vars(head)
        self.emacs_vars.update(self._get_emacs_tail_vars(tail))
        self.vi_vars = self._get_vi_vars(head)
        if not self.vi_vars:
            self.vi_vars = self._get_vi_vars(tail)
        if self.langinfo is None and "mode" in self.emacs_vars:
            li = lidb.langinfo_from_emacs_mode(self.emacs_vars["mode"])
            if li:
                self.langinfo = li
                self.lang = li.name
        if self.langinfo is None and "filetype" in self.vi_vars \
           or "ft" in self.vi_vars:
            vi_filetype = self.vi_vars.get(
                "filetype") or self.vi_vars.get("ft")
            li = lidb.langinfo_from_vi_filetype(vi_filetype)
            if li:
                self.langinfo = li
                self.lang = li.name

        if self.langinfo is not None:
            if self.langinfo.conforms_to("XML"):
                if not hasattr(self, "has_xml_prolog"):
                    (self.has_xml_prolog, self.xml_version,
                     self.xml_encoding) = self._get_xml_prolog_info(head)
                (self.has_doctype_decl, self.doctype_decl,
                 self.doctype_name, self.doctype_public_id,
                 self.doctype_system_id) = self._get_doctype_decl_info(head)

                # If this is just plain XML, we try to use the doctype
                # decl to choose a more specific XML lang.
                if self.lang == "XML" and self.has_doctype_decl:
                    li = lidb.langinfo_from_doctype(
                        public_id=self.doctype_public_id,
                        system_id=self.doctype_system_id)
                    if li and li.name != "XML":
                        self.langinfo = li
                        self.lang = li.name

            elif self.langinfo.conforms_to("HTML"):
                (self.has_doctype_decl, self.doctype_decl,
                 self.doctype_name, self.doctype_public_id,
                 self.doctype_system_id) = self._get_doctype_decl_info(head)

                # Allow promotion to XHTML (or other HTML flavours) based
                # on doctype.
                if self.lang == "HTML" and self.has_doctype_decl:
                    li = lidb.langinfo_from_doctype(
                        public_id=self.doctype_public_id,
                        system_id=self.doctype_system_id)
                    if li and li.name != "HTML":
                        self.langinfo = li
                        self.lang = li.name

                # Look for XML prolog and promote HTML -> XHTML if it
                # exists. Note that this wins over a plain HTML doctype.
                (self.has_xml_prolog, xml_version,
                 xml_encoding) = self._get_xml_prolog_info(head)
                if self.has_xml_prolog:
                    self.xml_version = xml_version
                    self.xml_encoding = xml_encoding
                    if self.lang == "HTML":
                        li = lidb.langinfo_from_lang("XHTML")
                        self.langinfo = li
                        self.lang = li.name

        # Attempt to specialize the lang.
        if self.langinfo is not None:
            li = lidb.specialized_langinfo_from_content(
                self.langinfo, self.text)
            if li:
                self.langinfo = li
                self.lang = li.name

    def _classify_from_magic(self, lidb):
        """Attempt to classify from the file's magic number/shebang
        line, doctype, etc.

        Note that this is done before determining the encoding, so we are
        working with the *bytes*, not chars.
        """
        self.has_bom, bom, bom_encoding = self._get_bom_info()
        if self.has_bom:
            # If this file has a BOM then, unless something funny is
            # happening, this will be a text file encoded with
            # `bom_encoding`. We leave that to `_classify_encoding()`.
            return

        # Without a BOM we assume this is an 8-bit encoding, for the
        # purposes of looking at, e.g. a shebang line.
        #
        # UTF-16 and UTF-32 without a BOM is rare; we won't pick up on,
        # e.g. Python encoded as UCS-2 or UCS-4 here (but
        # `_classify_encoding()` should catch most of those cases).
        head_bytes = self._accessor.head_bytes
        li = lidb.langinfo_from_magic(head_bytes)
        if li:
            log.debug("lang from magic: %s", li.name)
            self.langinfo = li
            self.lang = li.name
            self.is_text = li.is_text
            return

        (has_doctype_decl, doctype_decl, doctype_name, doctype_public_id,
         doctype_system_id) = self._get_doctype_decl_info(head_bytes)
        if has_doctype_decl:
            li = lidb.langinfo_from_doctype(public_id=doctype_public_id,
                                            system_id=doctype_system_id)
            if li:
                log.debug("lang from doctype: %s", li.name)
                self.langinfo = li
                self.lang = li.name
                self.is_text = li.is_text
                return

    def _classify_encoding(self, lidb, suggested_encoding=None):
        """To classify from the content we need to separate text from
        binary, and figure out the encoding. This is an imperfect task.
        The algorithm here is to go through the following heroics to attempt
        to determine an encoding that works to decode the content. If all
        such attempts fail, we presume it is binary.

        1. Use the BOM, if it has one.
        2. Try the given suggested encoding (if any).
        3. Check for EBCDIC encoding.
        4. Lang-specific (if we know the lang already):
            * if this is Python, look for coding: decl and try that
            * if this is Perl, look for use encoding decl and try that
            * ...
        5. XML: According to the XML spec the rule is the XML prolog
           specifies the encoding, or it is UTF-8.
        6. HTML: Attempt to use Content-Type meta tag. Try the given
           charset, if any.
        7. Emacs-style "coding" local var.
        8. Vi[m]-style "fileencoding" local var.
        9. Heuristic checks for UTF-16 without BOM.
        10. Give UTF-8 a try, it is a pretty common fallback.
            We must do this before a possible 8-bit
            `locale.getpreferredencoding()` because any UTF-8 encoded
            document will decode with an 8-bit encoding (i.e. will decode,
            just with bogus characters).
        11. Lang-specific fallback. E.g., UTF-8 for XML, ascii for Python.
        12. chardet (http://chardet.feedparser.org/), if CHARDET_ENABLED == True
        13. locale.getpreferredencoding()
        14. iso8859-1 (in case `locale.getpreferredencoding()` is UTF-8
            we must have an 8-bit encoding attempt).
            TODO: Is there a worry for a lot of false-positives for
            binary files.

        Notes:
        - A la Universal Feed Parser, if some
          supposed-to-be-authoritative encoding indicator is wrong (e.g.
          the BOM, the Python 'coding:' decl for Python),
          `self.encoding_bozo` is set True and a reason is appended to
          the `self.encoding_bozo_reasons` list.
        """
        # 1. Try the BOM.
        if self.has_bom is not False:  # Was set in `_classify_from_magic()`.
            self.has_bom, bom, bom_encoding = self._get_bom_info()
            if self.has_bom:
                self._accessor.strip_bom(bom)
                # Python doesn't currently include a UTF-32 codec. For now
                # we'll *presume* that a UTF-32 BOM is correct. The
                # limitation is that `self.text' will NOT get set
                # because we cannot decode it.
                if bom_encoding in ("utf-32-le", "utf-32-be") \
                   or self._accessor.decode(bom_encoding):
                    log.debug("encoding: encoding from BOM: %r", bom_encoding)
                    self.encoding = bom_encoding
                    return
                else:
                    log.debug("encoding: BOM encoding (%r) was *wrong*",
                              bom_encoding)
                    self._encoding_bozo(
                        u"BOM encoding (%s) could not decode %s"
                        % (bom_encoding, self._accessor))

        head_bytes = self._accessor.head_bytes
        if DEBUG_CHARDET_INFO:
            sys.path.insert(0, os.path.expanduser(
                "~/tm/check/contrib/chardet"))
            import chardet
            del sys.path[0]
            self.chardet_info = chardet.detect(head_bytes)

        # 2. Try the suggested encoding.
        if suggested_encoding is not None:
            norm_suggested_encoding = _norm_encoding(suggested_encoding)
            if self._accessor.decode(suggested_encoding):
                self.encoding = norm_suggested_encoding
                return
            else:
                log.debug("encoding: suggested %r encoding didn't work for %s",
                          suggested_encoding, self._accessor)

        # 3. Check for EBCDIC.
        # TODO: Not sure this should be included, chardet may be better
        #      at this given different kinds of EBCDIC.
        EBCDIC_MAGIC = '\x4c\x6f\xa7\x94'
        if self._accessor.head_4_bytes == EBCDIC_MAGIC:
            # This is EBCDIC, but I don't know if there are multiple kinds
            # of EBCDIC. Python has a 'ebcdic-cp-us' codec. We'll use
            # that for now.
            norm_ebcdic_encoding = _norm_encoding("ebcdic-cp-us")
            if self._accessor.decode(norm_ebcdic_encoding):
                log.debug("EBCDIC encoding: %r", norm_ebcdic_encoding)
                self.encoding = norm_ebcdic_encoding
                return
            else:
                log.debug("EBCDIC encoding didn't work for %s",
                          self._accessor)

        # 4. Lang-specific (if we know the lang already).
        if self.langinfo and self.langinfo.conformant_attr("encoding_decl_pattern"):
            m = self.langinfo.conformant_attr("encoding_decl_pattern") \
                    .search(head_bytes)
            if m:
                lang_encoding = m.group("encoding")
                norm_lang_encoding = _norm_encoding(lang_encoding)
                if self._accessor.decode(norm_lang_encoding):
                    log.debug("encoding: encoding from lang-spec: %r",
                              norm_lang_encoding)
                    self.encoding = norm_lang_encoding
                    return
                else:
                    log.debug("encoding: lang-spec encoding (%r) was *wrong*",
                              lang_encoding)
                    self._encoding_bozo(
                        u"lang-spec encoding (%s) could not decode %s"
                        % (lang_encoding, self._accessor))

        # 5. XML prolog
        if self.langinfo and self.langinfo.conforms_to("XML"):
            has_xml_prolog, xml_version, xml_encoding \
                = self._get_xml_prolog_info(head_bytes)
            if xml_encoding is not None:
                norm_xml_encoding = _norm_encoding(xml_encoding)
                if self._accessor.decode(norm_xml_encoding):
                    log.debug("encoding: encoding from XML prolog: %r",
                              norm_xml_encoding)
                    self.encoding = norm_xml_encoding
                    return
                else:
                    log.debug("encoding: XML prolog encoding (%r) was *wrong*",
                              norm_xml_encoding)
                    self._encoding_bozo(
                        u"XML prolog encoding (%s) could not decode %s"
                        % (norm_xml_encoding, self._accessor))

        # 6. HTML: Attempt to use Content-Type meta tag.
        if self.langinfo and self.langinfo.conforms_to("HTML"):
            has_http_content_type_info, http_content_type, http_encoding \
                = self._get_http_content_type_info(head_bytes)
            if has_http_content_type_info and http_encoding:
                norm_http_encoding = _norm_encoding(http_encoding)
                if self._accessor.decode(norm_http_encoding):
                    log.debug("encoding: encoding from HTTP content-type: %r",
                              norm_http_encoding)
                    self.encoding = norm_http_encoding
                    return
                else:
                    log.debug(
                        "encoding: HTTP content-type encoding (%r) was *wrong*",
                        norm_http_encoding)
                    self._encoding_bozo(
                        u"HTML content-type encoding (%s) could not decode %s"
                        % (norm_http_encoding, self._accessor))

        # 7. Emacs-style local vars.
        emacs_head_vars = self._get_emacs_head_vars(head_bytes)
        emacs_encoding = emacs_head_vars.get("coding")
        if not emacs_encoding:
            tail_bytes = self._accessor.tail_bytes
            emacs_tail_vars = self._get_emacs_tail_vars(tail_bytes)
            emacs_encoding = emacs_tail_vars.get("coding")
        if emacs_encoding:
            norm_emacs_encoding = _norm_encoding(emacs_encoding)
            if self._accessor.decode(norm_emacs_encoding):
                log.debug("encoding: encoding from Emacs coding var: %r",
                          norm_emacs_encoding)
                self.encoding = norm_emacs_encoding
                return
            else:
                log.debug("encoding: Emacs coding var (%r) was *wrong*",
                          norm_emacs_encoding)
                self._encoding_bozo(
                    u"Emacs coding var (%s) could not decode %s"
                    % (norm_emacs_encoding, self._accessor))

        # 8. Vi[m]-style local vars.
        vi_vars = self._get_vi_vars(head_bytes)
        vi_encoding = vi_vars.get("fileencoding") or vi_vars.get("fenc")
        if not vi_encoding:
            vi_vars = self._get_vi_vars(self._accessor.tail_bytes)
            vi_encoding = vi_vars.get("fileencoding") or vi_vars.get("fenc")
        if vi_encoding:
            norm_vi_encoding = _norm_encoding(vi_encoding)
            if self._accessor.decode(norm_vi_encoding):
                log.debug("encoding: encoding from Vi[m] coding var: %r",
                          norm_vi_encoding)
                self.encoding = norm_vi_encoding
                return
            else:
                log.debug("encoding: Vi[m] coding var (%r) was *wrong*",
                          norm_vi_encoding)
                self._encoding_bozo(
                    u"Vi[m] coding var (%s) could not decode %s"
                    % (norm_vi_encoding, self._accessor))

        # 9. Heuristic checks for UTF-16 without BOM.
        utf16_encoding = None
        head_odd_bytes = head_bytes[0::2]
        head_even_bytes = head_bytes[1::2]
        head_markers = ["<?xml", "#!"]
        for head_marker in head_markers:
            length = len(head_marker)
            if head_odd_bytes.startswith(head_marker) \
               and head_even_bytes[0:length] == '\x00'*length:
                utf16_encoding = "utf-16-le"
                break
            elif head_even_bytes.startswith(head_marker) \
                    and head_odd_bytes[0:length] == '\x00'*length:
                utf16_encoding = "utf-16-be"
                break
        internal_markers = ["coding"]
        for internal_marker in internal_markers:
            length = len(internal_marker)
            try:
                idx = head_odd_bytes.index(internal_marker)
            except ValueError:
                pass
            else:
                if head_even_bytes[idx:idx+length] == '\x00'*length:
                    utf16_encoding = "utf-16-le"
            try:
                idx = head_even_bytes.index(internal_marker)
            except ValueError:
                pass
            else:
                if head_odd_bytes[idx:idx+length] == '\x00'*length:
                    utf16_encoding = "utf-16-be"
        if utf16_encoding:
            if self._accessor.decode(utf16_encoding):
                log.debug("encoding: guessed encoding: %r", utf16_encoding)
                self.encoding = utf16_encoding
                return

        # 10. Give UTF-8 a try.
        norm_utf8_encoding = _norm_encoding("utf-8")
        if self._accessor.decode(norm_utf8_encoding):
            log.debug("UTF-8 encoding: %r", norm_utf8_encoding)
            self.encoding = norm_utf8_encoding
            return

        # 11. Lang-specific fallback (e.g. XML -> utf-8, Python -> ascii, ...).
        # Note: A potential problem here is that a fallback encoding here that
        # is a pre-Unicode Single-Byte encoding (like iso8859-1) always "works"
        # so the subsequent heuristics never get tried.
        fallback_encoding = None
        fallback_lang = None
        if self.langinfo:
            fallback_lang = self.langinfo.name
            fallback_encoding = self.langinfo.conformant_attr(
                "default_encoding")
        if fallback_encoding:
            if self._accessor.decode(fallback_encoding):
                log.debug("encoding: fallback encoding for %s: %r",
                          fallback_lang, fallback_encoding)
                self.encoding = fallback_encoding
                return
            else:
                log.debug("encoding: %s fallback encoding (%r) was *wrong*",
                          fallback_lang, fallback_encoding)
                self._encoding_bozo(
                    u"%s fallback encoding (%s) could not decode %s"
                    % (fallback_lang, fallback_encoding, self._accessor))

        # 12. chardet (http://chardet.feedparser.org/)
        # Note: I'm leary of using this b/c (a) it's a sizeable perf
        # hit and (b) false positives -- for example, the first 8kB of
        # /usr/bin/php on Mac OS X 10.4.10 is ISO-8859-2 with 44%
        # confidence. :)
        # Solution: (a) Only allow for content we know is not binary
        # (from langinfo association); and (b) can be disabled via
        # CHARDET_ENABLED class attribute.
        if self.CHARDET_ENABLED and self.langinfo and self.langinfo.is_text:
            try:
                import chardet
            except ImportError:
                warnings.warn("no chardet module to aid in guessing encoding",
                              ChardetImportWarning)
            else:
                chardet_info = chardet.detect(head_bytes)
                if chardet_info["encoding"] \
                   and chardet_info["confidence"] > self.CHARDET_THRESHHOLD:
                    chardet_encoding = chardet_info["encoding"]
                    norm_chardet_encoding = _norm_encoding(chardet_encoding)
                    if self._accessor.decode(norm_chardet_encoding):
                        log.debug("chardet encoding: %r", chardet_encoding)
                        self.encoding = norm_chardet_encoding
                        return

        # 13. locale.getpreferredencoding()
        # Typical values for this:
        #   Windows:    cp1252 (aka windows-1252)
        #   Mac OS X:   mac-roman
        #   Linux:      UTF-8 (modern Linux anyway)
        #   Solaris 8:  464 (aka ASCII)
        locale_encoding = locale.getpreferredencoding()
        if locale_encoding:
            norm_locale_encoding = _norm_encoding(locale_encoding)
            if self._accessor.decode(norm_locale_encoding):
                log.debug("encoding: locale preferred encoding: %r",
                          locale_encoding)
                self.encoding = norm_locale_encoding
                return

        # 14. iso8859-1
        norm_fallback8bit_encoding = _norm_encoding("iso8859-1")
        if self._accessor.decode(norm_fallback8bit_encoding):
            log.debug(
                "fallback 8-bit encoding: %r", norm_fallback8bit_encoding)
            self.encoding = norm_fallback8bit_encoding
            return

        # We couldn't find an encoding that works. Give up and presume
        # this is binary content.
        self.is_text = False

    def _encoding_bozo(self, reason):
        self.encoding_bozo = True
        if self.encoding_bozo_reasons is None:
            self.encoding_bozo_reasons = []
        self.encoding_bozo_reasons.append(reason)

    # c.f. http://www.xml.com/axml/target.html#NT-prolog
    _xml_prolog_pat = re.compile(
        r'''<\?xml
            (   # strict ordering is reqd but we'll be liberal here
                \s+version=['"](?P<ver>.*?)['"]
            |   \s+encoding=['"](?P<enc>.*?)['"]
            )+
            .*? # other possible junk
            \s*\?>
        ''',
        re.VERBOSE | re.DOTALL
    )

    def _get_xml_prolog_info(self, head_bytes):
        """Parse out info from the '<?xml version=...' prolog, if any.

        Returns (<has-xml-prolog>, <xml-version>, <xml-encoding>). Examples:

            (False, None, None)
            (True, "1.0", None)
            (True, "1.0", "UTF-16")
        """
        # Presuming an 8-bit encoding. If it is UTF-16 or UTF-32, then
        # that should have been picked up by an earlier BOM check or via
        # the subsequent heuristic check for UTF-16 without a BOM.
        if not head_bytes.startswith("<?xml"):
            return (False, None, None)

        # Try to extract more info from the prolog.
        match = self._xml_prolog_pat.match(head_bytes)
        if not match:
            if log.isEnabledFor(logging.DEBUG):
                log.debug("`%s': could not match XML prolog: '%s'", self.path,
                          _one_line_summary_from_text(head_bytes, 40))
            return (False, None, None)
        xml_version = match.group("ver")
        xml_encoding = match.group("enc")
        return (True, xml_version, xml_encoding)

    _html_meta_tag_pat = re.compile("""
        (<meta
        (?:\s+[\w-]+\s*=\s*(?:".*?"|'.*?'))+  # attributes
        \s*/?>)
        """,
                                    re.IGNORECASE | re.VERBOSE
                                    )
    _html_attr_pat = re.compile(
        # Currently requiring XML attrs (i.e. quoted value).
        '''(?:\s+([\w-]+)\s*=\s*(".*?"|'.*?'))'''
    )
    _http_content_type_splitter = re.compile(";\s*")

    def _get_http_content_type_info(self, head_bytes):
        """Returns info extracted from an HTML content-type meta tag if any.
        Returns (<has-http-content-type-info>, <content-type>, <charset>).

        For example:
            <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
        yields:
            (True, "text/html", "utf-8")
        """
        # Presuming an 8-bit encoding. If it is UTF-16 or UTF-32, then
        # that should have been picked up by an earlier BOM check.
        # Otherwise we rely on `chardet` to cover us.

        # Parse out '<meta ...>' tags, then the attributes in them.
        for meta_tag in self._html_meta_tag_pat.findall(head_bytes):
            meta = dict((k.lower(), v[1:-1])
                        for k, v in self._html_attr_pat.findall(meta_tag))
            if "http-equiv" in meta \
               and meta["http-equiv"].lower() == "content-type":
                content = meta.get("content", "")
                break
        else:
            return (False, None, None)

        # We found a http-equiv="Content-Type" tag, parse its content
        # attribute value.
        parts = [
            p.strip() for p in self._http_content_type_splitter.split(content)]
        if not parts:
            return (False, None, None)
        content_type = parts[0] or None
        for p in parts[1:]:
            if p.lower().startswith("charset="):
                charset = p[len("charset="):]
                if charset and charset[0] in ('"', "'"):
                    charset = charset[1:]
                if charset and charset[-1] in ('"', "'"):
                    charset = charset[:-1]
                break
        else:
            charset = None

        return (True, content_type, charset)

    # TODO: Note that this isn't going to catch the current HTML 5
    #      doctype:  '<!DOCTYPE html>'
    _doctype_decl_re = re.compile(r'''
        <!DOCTYPE
        \s+(?P<name>[a-zA-Z_:][\w:.-]*)
        \s+(?:
            SYSTEM\s+(["'])(?P<system_id_a>.*?)\2
            |
            PUBLIC
            \s+(["'])(?P<public_id_b>.*?)\4
            # HTML 3.2 and 2.0 doctypes don't include a system-id.
            (?:\s+(["'])(?P<system_id_b>.*?)\6)?
        )
        (\s*\[.*?\])?
        \s*>
        ''', re.IGNORECASE | re.DOTALL | re.UNICODE | re.VERBOSE)

    def _get_doctype_decl_info(self, head):
        """Parse out DOCTYPE info from the given XML or HTML content.

        Returns a tuple of the form:
            (<has-doctype-decl>, <doctype-decl>,
             <name>, <public-id>, <system-id>)

        The <public-id> is normalized as per this comment in the XML 1.0
        spec:
            Before a match is attempted, all strings of white space in the
            public identifier must be normalized to single space
            characters (#x20), and leading and trailing white space must
            be removed.

        Examples:
            (False, None, None, None, None)
            (True, '<!DOCTYPE greeting SYSTEM "hello.dtd">',
             'greeting', None, 'hello.dtd'),
            (True,
             '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">',
             'html',
             '-//W3C//DTD XHTML 1.0 Transitional//EN',
             'http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd')

        Here is the spec for DOCTYPE decls in XML:
            http://www.xml.com/axml/target.html#NT-doctypedecl
        We loosely follow this to allow for some decls in HTML that isn't
        proper XML. As well, we are only parsing out decls that reference
        an external ID, as opposed to those that define entities locally.
        """
        if "<!DOCTYPE" not in head:  # quick out
            return (False, None, None, None, None)
        m = self._doctype_decl_re.search(head)
        if not m:
            return (False, None, None, None, None)

        d = m.groupdict()
        name = d.get("name")
        system_id = d.get("system_id_a") or d.get("system_id_b")
        public_id = d.get("public_id_b")
        if public_id:
            public_id = re.sub("\s+", ' ', public_id.strip())  # normalize
        return (True, m.group(0), name, public_id, system_id)

    _emacs_vars_head_pat = re.compile("-\*-\s*(.*?)\s*-\*-")

    _emacs_head_vars_cache = None

    def _get_emacs_head_vars(self, head_bytes):
        """Return a dictionary of emacs-style local variables in the head.

        "Head" emacs vars on the ones in the '-*- ... -*-' one-liner.

        Parsing is done loosely according to this spec (and according to
        some in-practice deviations from this):
        http://www.gnu.org/software/emacs/manual/html_node/emacs/Specifying-File-Variables.html#Specifying-File-Variables
        """
        # Presuming an 8-bit encoding. If it is UTF-16 or UTF-32, then
        # that should have been picked up by an earlier BOM check.
        # Otherwise we rely on `chardet` to cover us.

        if self._emacs_head_vars_cache is not None:
            return self._emacs_head_vars_cache

        # Search the head for a '-*-'-style one-liner of variables.
        emacs_vars = {}
        if "-*-" in head_bytes:
            match = self._emacs_vars_head_pat.search(head_bytes)
            if match:
                emacs_vars_str = match.group(1)
                if '\n' in emacs_vars_str:
                    raise ValueError("local variables error: -*- not "
                                     "terminated before end of line")
                emacs_var_strs = [s.strip() for s in emacs_vars_str.split(';')
                                  if s.strip()]
                if len(emacs_var_strs) == 1 and ':' not in emacs_var_strs[0]:
                    # While not in the spec, this form is allowed by emacs:
                    #   -*- Tcl -*-
                    # where the implied "variable" is "mode". This form
                    # is only allowed if there are no other variables.
                    emacs_vars["mode"] = emacs_var_strs[0].strip()
                else:
                    for emacs_var_str in emacs_var_strs:
                        try:
                            variable, value = emacs_var_str.strip().split(
                                ':', 1)
                        except ValueError:
                            log.debug("emacs variables error: malformed -*- "
                                      "line: %r", emacs_var_str)
                            continue
                        # Lowercase the variable name because Emacs allows "Mode"
                        # or "mode" or "MoDe", etc.
                        emacs_vars[variable.lower()] = value.strip()

        # Unquote values.
        for var, val in emacs_vars.items():
            if len(val) > 1 and (val.startswith('"') and val.endswith('"')
               or val.startswith('"') and val.endswith('"')):
                emacs_vars[var] = val[1:-1]

        self._emacs_head_vars_cache = emacs_vars
        return emacs_vars

    # This regular expression is intended to match blocks like this:
    #    PREFIX Local Variables: SUFFIX
    #    PREFIX mode: Tcl SUFFIX
    #    PREFIX End: SUFFIX
    # Some notes:
    # - "[ \t]" is used instead of "\s" to specifically exclude newlines
    # - "(\r\n|\n|\r)" is used instead of "$" because the sre engine does
    #   not like anything other than Unix-style line terminators.
    _emacs_vars_tail_pat = re.compile(r"""^
        (?P<prefix>(?:[^\r\n|\n|\r])*?)
        [\ \t]*Local\ Variables:[\ \t]*
        (?P<suffix>.*?)(?:\r\n|\n|\r)
        (?P<content>.*?\1End:)
        """, re.IGNORECASE | re.MULTILINE | re.DOTALL | re.VERBOSE)

    _emacs_tail_vars_cache = None

    def _get_emacs_tail_vars(self, tail_bytes):
        r"""Return a dictionary of emacs-style local variables in the tail.

        "Tail" emacs vars on the ones in the multi-line "Local
        Variables:" block.

        >>> TextInfo()._get_emacs_tail_vars('# Local Variables:\n# foo: bar\n# End:')
        {'foo': 'bar'}
        >>> TextInfo()._get_emacs_tail_vars('# Local Variables:\n# foo: bar\\\n#  baz\n# End:')
        {'foo': 'bar baz'}
        >>> TextInfo()._get_emacs_tail_vars('# Local Variables:\n# quoted: "bar "\n# End:')
        {'quoted': 'bar '}

        Parsing is done according to this spec (and according to some
        in-practice deviations from this):
            http://www.gnu.org/software/emacs/manual/html_chapter/emacs_33.html#SEC485
        """
        # Presuming an 8-bit encoding. If it is UTF-16 or UTF-32, then
        # that should have been picked up by an earlier BOM check.
        # Otherwise we rely on `chardet` to cover us.

        if self._emacs_tail_vars_cache is not None:
            return self._emacs_tail_vars_cache

        emacs_vars = {}
        if "Local Variables" not in tail_bytes:
            self._emacs_tail_vars_cache = emacs_vars
            return emacs_vars

        match = self._emacs_vars_tail_pat.search(tail_bytes)
        if match:
            prefix = match.group("prefix")
            suffix = match.group("suffix")
            lines = match.group("content").splitlines(0)
            # print "prefix=%r, suffix=%r, content=%r, lines: %s"\
            #      % (prefix, suffix, match.group("content"), lines)

            # Validate the Local Variables block: proper prefix and suffix
            # usage.
            for i, line in enumerate(lines):
                if not line.startswith(prefix):
                    log.debug("emacs variables error: line '%s' "
                              "does not use proper prefix '%s'"
                              % (line, prefix))
                    return {}
                # Don't validate suffix on last line. Emacs doesn't care,
                # neither should we.
                if i != len(lines)-1 and not line.endswith(suffix):
                    log.debug("emacs variables error: line '%s' "
                              "does not use proper suffix '%s'"
                              % (line, suffix))
                    return {}

            # Parse out one emacs var per line.
            continued_for = None
            for line in lines[:-1]:  # no var on the last line ("PREFIX End:")
                if prefix:
                    line = line[len(prefix):]  # strip prefix
                if suffix:
                    line = line[:-len(suffix)]  # strip suffix
                line = line.strip()
                if continued_for:
                    variable = continued_for
                    if line.endswith('\\'):
                        line = line[:-1].rstrip()
                    else:
                        continued_for = None
                    emacs_vars[variable] += ' ' + line
                else:
                    try:
                        variable, value = line.split(':', 1)
                    except ValueError:
                        log.debug("local variables error: missing colon "
                                  "in local variables entry: '%s'" % line)
                        continue
                    # Do NOT lowercase the variable name, because Emacs only
                    # allows "mode" (and not "Mode", "MoDe", etc.) in this
                    # block.
                    value = value.strip()
                    if value.endswith('\\'):
                        value = value[:-1].rstrip()
                        continued_for = variable
                    else:
                        continued_for = None
                    emacs_vars[variable] = value

        # Unquote values.
        for var, val in emacs_vars.items():
            if len(val) > 1 and (val.startswith('"') and val.endswith('"')
               or val.startswith('"') and val.endswith('"')):
                emacs_vars[var] = val[1:-1]

        self._emacs_tail_vars_cache = emacs_vars
        return emacs_vars

    # Note: It might nice if parser also gave which of 'vi, vim, ex' and
    # the range in the accessor.
    _vi_vars_pats_and_splitters = [
        (re.compile(r'[ \t]+(vi|vim([<>=]?\d{3})?|ex):\s*set? (?P<rhs>.*?)(?<!\\):', re.M),
         re.compile(r'[ \t]+')),
        (re.compile(r'[ \t]+(vi|vim([<>=]?\d{3})?|ex):\s*(?P<rhs>.*?)$', re.M),
         re.compile(r'[ \t:]+')),
        (re.compile(r'^(vi|vim([<>=]?\d{3})?):\s*set? (?P<rhs>.*?)(?<!\\):', re.M),
         re.compile(r'[ \t]+')),
    ]
    _vi_vars_cache = None

    def _get_vi_vars(self, bytes):
        r"""Return a dict of Vi[m] modeline vars.

        See ":help modeline" in Vim for a spec.

            >>> TextInfo()._get_vi_vars("/* vim: set ai tw=75: */")
            {'ai': None, 'tw': 75}
            >>> TextInfo()._get_vi_vars("vim: set ai tw=75: bar")
            {'ai': None, 'tw': 75}

            >>> TextInfo()._get_vi_vars("vi: set foo:bar")
            {'foo': None}
            >>> TextInfo()._get_vi_vars(" vi: se foo:bar")
            {'foo': None}
            >>> TextInfo()._get_vi_vars(" ex: se foo:bar")
            {'foo': None}

            >>> TextInfo()._get_vi_vars(" vi:noai:sw=3 tw=75")
            {'tw': 75, 'sw': 3, 'noai': None}
            >>> TextInfo()._get_vi_vars(" vi:noai:sw=3 tw=75")
            {'tw': 75, 'sw': 3, 'noai': None}

            >>> TextInfo()._get_vi_vars("ex: se foo:bar")
            {}

        Some edge cases:

            >>> TextInfo()._get_vi_vars(r"/* vi:set dir=c\:\tmp: */")
            {'dir': 'c:\\tmp'}
        """
        # Presume 8-bit encoding... yada yada.

        if self._vi_vars_cache is not None:
            return self._vi_vars_cache

        vi_vars = {}

        # TODO: Consider reducing support to just "vi:" for speed. This
        #      function takes way too much time.
        if "vi:" not in bytes and "ex:" not in bytes and "vim:" not in bytes:
            self._vi_vars_cache = vi_vars
            return vi_vars

        for pat, splitter in self._vi_vars_pats_and_splitters:
            match = pat.search(bytes)
            if match:
                for var_str in splitter.split(match.group("rhs")):
                    if '=' in var_str:
                        name, value = var_str.split('=', 1)
                        try:
                            vi_vars[name] = int(value)
                        except ValueError:
                            vi_vars[name] = value.replace('\\:', ':')
                    else:
                        vi_vars[var_str] = None
                break
        self._vi_vars_cache = vi_vars
        return vi_vars

    def _get_bom_info(self):
        r"""Returns (<has-bom>, <bom>, <bom-encoding>). Examples:

            (True, '\xef\xbb\xbf', "utf-8")
            (True, '\xff\xfe', "utf-16-le")
            (False, None, None)
        """
        boms_and_encodings = [  # in order from longest to shortest
            (codecs.BOM_UTF32_LE, "utf-32-le"),
            (codecs.BOM_UTF32_BE, "utf-32-be"),
            (codecs.BOM_UTF8, "utf-8"),
            (codecs.BOM_UTF16_LE, "utf-16-le"),
            (codecs.BOM_UTF16_BE, "utf-16-be"),
        ]
        head_4 = self._accessor.head_4_bytes
        for bom, encoding in boms_and_encodings:
            if head_4.startswith(bom):
                return (True, bom, encoding)
                break
        else:
            return (False, None, None)

    def _classify_from_filename(self, lidb, env):
        """Classify from the path *filename* only.

        Sets `lang' and `langinfo', if can be determined.
        """
        filename = basename(self.path)

        if env is not None:
            li = env.langinfo_from_filename(filename)
            if li:
                log.debug("lang from env: `%s' -> `%s'", filename, li.name)
                self.langinfo = li
                self.lang = li.name
                self.is_text = li.is_text
                return

        # ...from the ext
        idx = 0
        while True:
            idx = filename.find('.', idx)
            if idx == -1:
                break
            ext = filename[idx:]
            li = lidb.langinfo_from_ext(ext)
            if li:
                log.debug("lang from ext: `%s' -> `%s'", ext, li.name)
                self.langinfo = li
                self.lang = li.name
                self.is_text = li.is_text
                return
            idx += 1

        # ...from file basename
        li = lidb.langinfo_from_filename(filename)
        if li:
            log.debug("lang from filename: `%s' -> `%s'", filename, li.name)
            self.langinfo = li
            self.lang = li.name
            self.is_text = li.is_text
            return

    def _classify_from_stat(self, lidb):
        """Set some `file_*' attributes from stat mode."""
        from stat import S_ISREG, S_ISDIR, S_ISLNK, S_ISFIFO, S_ISSOCK, \
            S_ISBLK, S_ISCHR, S_IMODE, S_IFMT
        stat = self._accessor.stat
        st_mode = stat.st_mode
        self.file_type = S_IFMT(st_mode)
        self.file_mode = S_IMODE(st_mode)
        self.file_stat = stat
        if S_ISREG(st_mode):
            self.file_type_name = "regular file"
        elif S_ISDIR(st_mode):
            self.file_type_name = "directory"
        elif S_ISLNK(st_mode):
            self.file_type_name = "symbolic link"
        elif S_ISFIFO(st_mode):
            self.file_type_name = "fifo"
        elif S_ISSOCK(st_mode):
            self.file_type_name = "socket"
        elif S_ISBLK(st_mode):
            self.file_type_name = "block special"
        elif S_ISCHR(st_mode):
            self.file_type_name = "character special"


def _norm_encoding(encoding):
    """Normalize the encoding name -- where "normalized" is what
    Python's codec's module calls it.

    Interesting link:
        The IANA-registered set of character sets.
        http://www.iana.org/assignments/character-sets
    """
    try:
        # This requires Python >=2.5.
        return codecs.lookup(encoding).name
    except LookupError:
        return encoding


#---- accessor API
# The idea here is to abstract accessing the text file content being
# classified to allow, e.g. classifying content without a file, from
# a Komodo buffer, etc.

class Accessor(object):
    """Virtual base class defining Accessor API for accessing
    text content.
    """
    # API:
    #   prop head_bytes -> head 8k bytes
    #   prop head_4_bytes -> head 4 bytes (useful for BOM detection)
    #   prop tail_bytes -> tail 8k bytes
    #   def bytes_range(start, end) -> bytes in that range

    HEAD_SIZE = pow(2, 13)  # 8k
    TAIL_SIZE = pow(2, 13)  # 8k

    encoding = None
    text = None

    _unsuccessful_encodings = None

    def decode(self, encoding):
        """Decodes bytes with the given encoding and, if successful,
        sets `self.text` with the decoded result and returns True.
        Otherwise, returns False.

        Side-effects: On success, sets `self.text` and `self.encoding`.

        Optimization: First an attempt is made to decode
        `self.head_bytes` instead of all of `self.bytes`. This allows
        for the normal usage in `TextInfo._classify_encoding()` to *not*
        bother fully reading binary files that could not be decoded.

        Optimization: Decoding attempts are cached to not bother
        attempting a failed decode twice.
        """
        if self._unsuccessful_encodings is None:
            self._unsuccessful_encodings = set()
        if encoding in self._unsuccessful_encodings:
            return False
        elif encoding == self.encoding:
            return True

        head_bytes = self.head_bytes
        try:
            head_bytes.decode(encoding, 'strict')
        except LookupError, ex:
            log.debug("encoding lookup error: %r", encoding)
            self._unsuccessful_encodings.add(encoding)
            return False
        except UnicodeError, ex:
            # If the decode failed in the last few bytes, it might be
            # because a multi-surrogate was cutoff by the head. Ignore
            # the error here, if it is truly not of this encoding, the
            # full file decode will fail.
            if ex.start >= self.HEAD_SIZE - 5:
                # '5' because the max num bytes to encode a single char
                # in any encoding is 6 bytes (in UTF-8).
                pass
            else:
                self._unsuccessful_encodings.add(encoding)
                return False
        try:
            self.text = self.bytes.decode(encoding, 'strict')
        except UnicodeError, ex:
            self._unsuccessful_encodings.add(encoding)
            return False
        self.encoding = encoding
        return True


class PathAccessor(Accessor):
    """Accessor API for a path."""
    (READ_NONE,             # _file==None, file not opened yet
     READ_HEAD,             # _bytes==<head bytes>
     READ_TAIL,             # _bytes==<head>, _bytes_tail==<tail>
     READ_ALL) = range(4)   # _bytes==<all>, _bytes_tail==None, _file closed
    _read_state = READ_NONE  # one of the READ_* states
    _file = None
    _bytes = None
    _bytes_tail = None

    def __init__(self, path, follow_symlinks=False):
        self.path = path
        self.follow_symlinks = follow_symlinks

    def __str__(self):
        return "path `%s'" % self.path

    _stat_cache = None

    @property
    def stat(self):
        if self._stat_cache is None:
            if self.follow_symlinks:
                self._stat_cache = os.stat(self.path)
            else:
                self._stat_cache = os.lstat(self.path)
        return self._stat_cache

    @property
    def size(self):
        return self.stat.st_size

    def __del__(self):
        self.close()

    def close(self):
        if self._file and not self._file.closed:
            self._file.close()

    def _read(self, state):
        """Read up to at least `state`."""
        # TODO: If `follow_symlinks` is False and this is a symlink we
        #      must use os.readlink() here.
        # It is the job of the caller to only call _read() if necessary.
        assert self._read_state < state

        try:
            if self._read_state == self.READ_NONE:
                assert self._file is None and self._bytes is None
                self._file = open(self.path, 'rb')
                if state == self.READ_HEAD:
                    self._bytes = self._file.read(self.HEAD_SIZE)
                    self._read_state = (self.size <= self.HEAD_SIZE
                                        and self.READ_ALL or self.READ_HEAD)
                elif state == self.READ_TAIL:
                    if self.size <= self.HEAD_SIZE + self.TAIL_SIZE:
                        self._bytes = self._file.read()
                        self._read_state = self.READ_ALL
                    else:
                        self._bytes = self._file.read(self.HEAD_SIZE)
                        self._file.seek(
                            -self.TAIL_SIZE, 2)  # 2 == relative to end
                        self._bytes_tail = self._file.read(self.TAIL_SIZE)
                        self._read_state = self.READ_TAIL
                elif state == self.READ_ALL:
                    self._bytes = self._file.read()
                    self._read_state = self.READ_ALL

            elif self._read_state == self.READ_HEAD:
                if state == self.READ_TAIL:
                    if self.size <= self.HEAD_SIZE + self.TAIL_SIZE:
                        self._bytes += self._file.read()
                        self._read_state = self.READ_ALL
                    else:
                        self._file.seek(
                            -self.TAIL_SIZE, 2)  # 2 == relative to end
                        self._bytes_tail = self._file.read(self.TAIL_SIZE)
                        self._read_state = self.READ_TAIL
                elif state == self.READ_ALL:
                    self._bytes += self._file.read()
                    self._read_state = self.READ_ALL

            elif self._read_state == self.READ_TAIL:
                assert state == self.READ_ALL
                self._file.seek(self.HEAD_SIZE, 0)  # 0 == relative to start
                remaining_size = self.size - self.HEAD_SIZE - self.TAIL_SIZE
                assert remaining_size > 0, \
                    "negative remaining bytes to read from '%s': %d" \
                    % (self.path, self.size)
                self._bytes += self._file.read(remaining_size)
                self._bytes += self._bytes_tail
                self._bytes_tail = None
                self._read_state = self.READ_ALL

            if self._read_state == self.READ_ALL:
                self.close()
        except Exception, ex:
            log.warn("Could not read file: %r due to: %r", self.path, ex)
            raise

    def strip_bom(self, bom):
        """This should be called by the user of this class to strip a
        detected BOM from the bytes for subsequent decoding and
        analysis.
        """
        assert self._bytes[:len(bom)] == bom
        self._bytes = self._bytes[len(bom):]

    @property
    def head_bytes(self):
        """The first 8k raw bytes of the document."""
        if self._read_state < self.READ_HEAD:
            self._read(self.READ_HEAD)
        return self._bytes[:self.HEAD_SIZE]

    @property
    def head_4_bytes(self):
        if self._read_state < self.READ_HEAD:
            self._read(self.READ_HEAD)
        return self._bytes[:4]

    @property
    def tail_bytes(self):
        if self._read_state < self.READ_TAIL:
            self._read(self.READ_TAIL)
        if self._read_state == self.READ_ALL:
            return self._bytes[-self.TAIL_SIZE:]
        else:
            return self._bytes_tail

    def bytes_range(self, start, end):
        if self._read_state < self.READ_ALL:
            self._read(self.READ_ALL)
        return self._bytes[start:end]

    @property
    def bytes(self):
        if self._read_state < self.READ_ALL:
            self._read(self.READ_ALL)
        return self._bytes


#---- internal support stuff
# Recipe: regex_from_encoded_pattern (1.0)
def _regex_from_encoded_pattern(s):
    """'foo'    -> re.compile(re.escape('foo'))
       '/foo/'  -> re.compile('foo')
       '/foo/i' -> re.compile('foo', re.I)
    """
    if s.startswith('/') and s.rfind('/') != 0:
        # Parse it: /PATTERN/FLAGS
        idx = s.rfind('/')
        pattern, flags_str = s[1:idx], s[idx+1:]
        flag_from_char = {
            "i": re.IGNORECASE,
            "l": re.LOCALE,
            "s": re.DOTALL,
            "m": re.MULTILINE,
            "u": re.UNICODE,
        }
        flags = 0
        for char in flags_str:
            try:
                flags |= flag_from_char[char]
            except KeyError:
                raise ValueError("unsupported regex flag: '%s' in '%s' "
                                 "(must be one of '%s')"
                                 % (char, s, ''.join(flag_from_char.keys())))
        return re.compile(s[1:idx], flags)
    else:  # not an encoded regex
        return re.compile(re.escape(s))

# Recipe: text_escape (0.2)


def _escaped_text_from_text(text, escapes="eol"):
    r"""Return escaped version of text.

        "escapes" is either a mapping of chars in the source text to
            replacement text for each such char or one of a set of
            strings identifying a particular escape style:
                eol
                    replace EOL chars with '\r' and '\n', maintain the actual
                    EOLs though too
                whitespace
                    replace EOL chars as above, tabs with '\t' and spaces
                    with periods ('.')
                eol-one-line
                    replace EOL chars with '\r' and '\n'
                whitespace-one-line
                    replace EOL chars as above, tabs with '\t' and spaces
                    with periods ('.')
    """
    # TODO:
    # - Add 'c-string' style.
    # - Add _escaped_html_from_text() with a similar call sig.
    import re

    if isinstance(escapes, basestring):
        if escapes == "eol":
            escapes = {'\r\n': "\\r\\n\r\n", '\n': "\\n\n", '\r': "\\r\r"}
        elif escapes == "whitespace":
            escapes = {'\r\n': "\\r\\n\r\n", '\n': "\\n\n", '\r': "\\r\r",
                       '\t': "\\t", ' ': "."}
        elif escapes == "eol-one-line":
            escapes = {'\n': "\\n", '\r': "\\r"}
        elif escapes == "whitespace-one-line":
            escapes = {'\n': "\\n", '\r': "\\r", '\t': "\\t", ' ': '.'}
        else:
            raise ValueError("unknown text escape style: %r" % escapes)

    # Sort longer replacements first to allow, e.g. '\r\n' to beat '\r' and
    # '\n'.
    escapes_keys = escapes.keys()
    try:
        escapes_keys.sort(key=lambda a: len(a), reverse=True)
    except TypeError:
        # Python 2.3 support: sort() takes no keyword arguments
        escapes_keys.sort(lambda a, b: cmp(len(a), len(b)))
        escapes_keys.reverse()

    def repl(match):
        val = escapes[match.group(0)]
        return val
    escaped = re.sub("(%s)" % '|'.join([re.escape(k) for k in escapes_keys]),
                     repl,
                     text)

    return escaped


def _one_line_summary_from_text(text, length=78,
                                escapes={'\n': "\\n", '\r': "\\r", '\t': "\\t"}):
    r"""Summarize the given text with one line of the given length.

        "text" is the text to summarize
        "length" (default 78) is the max length for the summary
        "escapes" is a mapping of chars in the source text to
            replacement text for each such char. By default '\r', '\n'
            and '\t' are escaped with their '\'-escaped repr.
    """
    if len(text) > length:
        head = text[:length-3]
    else:
        head = text
    escaped = _escaped_text_from_text(head, escapes)
    if len(text) > length:
        summary = escaped[:length-3] + "..."
    else:
        summary = escaped
    return summary


# Recipe: paths_from_path_patterns (0.5)
def _should_include_path(path, includes, excludes):
    """Return True iff the given path should be included."""
    from os.path import basename
    from fnmatch import fnmatch

    base = basename(path)
    if includes:
        for include in includes:
            if fnmatch(base, include):
                try:
                    log.debug("include `%s' (matches `%s')", path, include)
                except (NameError, AttributeError):
                    pass
                break
        else:
            try:
                log.debug("exclude `%s' (matches no includes)", path)
            except (NameError, AttributeError):
                pass
            return False
    for exclude in excludes:
        if fnmatch(base, exclude):
            try:
                log.debug("exclude `%s' (matches `%s')", path, exclude)
            except (NameError, AttributeError):
                pass
            return False
    return True


def _walk(top, topdown=True, onerror=None, follow_symlinks=False):
    """A version of `os.walk()` with a couple differences regarding symlinks.

    1. follow_symlinks=False (the default): A symlink to a dir is
       returned as a *non*-dir. In `os.walk()`, a symlink to a dir is
       returned in the *dirs* list, but it is not recursed into.
    2. follow_symlinks=True: A symlink to a dir is returned in the
       *dirs* list (as with `os.walk()`) but it *is conditionally*
       recursed into (unlike `os.walk()`).

       A symlinked dir is only recursed into if it is to a deeper dir
       within the same tree. This is my understanding of how `find -L
       DIR` works.

    TODO: put as a separate recipe
    """
    from os.path import join, isdir, islink, abspath

    # We may not have read permission for top, in which case we can't
    # get a list of the files the directory contains.  os.path.walk
    # always suppressed the exception then, rather than blow up for a
    # minor reason when (say) a thousand readable directories are still
    # left to visit.  That logic is copied here.
    try:
        names = os.listdir(top)
    except OSError, err:
        if onerror is not None:
            onerror(err)
        return

    dirs, nondirs = [], []
    if follow_symlinks:
        for name in names:
            if isdir(join(top, name)):
                dirs.append(name)
            else:
                nondirs.append(name)
    else:
        for name in names:
            path = join(top, name)
            if islink(path):
                nondirs.append(name)
            elif isdir(path):
                dirs.append(name)
            else:
                nondirs.append(name)

    if topdown:
        yield top, dirs, nondirs
    for name in dirs:
        path = join(top, name)
        if follow_symlinks and islink(path):
            # Only walk this path if it links deeper in the same tree.
            top_abs = abspath(top)
            link_abs = abspath(join(top, os.readlink(path)))
            if not link_abs.startswith(top_abs + os.sep):
                continue
        for x in _walk(path, topdown, onerror, follow_symlinks=follow_symlinks):
            yield x
    if not topdown:
        yield top, dirs, nondirs

_NOT_SPECIFIED = ("NOT", "SPECIFIED")


def _paths_from_path_patterns(path_patterns, files=True, dirs="never",
                              recursive=True, includes=[], excludes=[],
                              skip_dupe_dirs=False,
                              follow_symlinks=False,
                              on_error=_NOT_SPECIFIED):
    """_paths_from_path_patterns([<path-patterns>, ...]) -> file paths

    Generate a list of paths (files and/or dirs) represented by the given path
    patterns.

        "path_patterns" is a list of paths optionally using the '*', '?' and
            '[seq]' glob patterns.
        "files" is boolean (default True) indicating if file paths
            should be yielded
        "dirs" is string indicating under what conditions dirs are
            yielded. It must be one of:
              never             (default) never yield dirs
              always            yield all dirs matching given patterns
              if-not-recursive  only yield dirs for invocations when
                                recursive=False
            See use cases below for more details.
        "recursive" is boolean (default True) indicating if paths should
            be recursively yielded under given dirs.
        "includes" is a list of file patterns to include in recursive
            searches.
        "excludes" is a list of file and dir patterns to exclude.
            (Note: This is slightly different than GNU grep's --exclude
            option which only excludes *files*.  I.e. you cannot exclude
            a ".svn" dir.)
        "skip_dupe_dirs" can be set True to watch for and skip
            descending into a dir that has already been yielded. Note
            that this currently does not dereference symlinks.
        "follow_symlinks" is a boolean indicating whether to follow
            symlinks (default False). To guard against infinite loops
            with circular dir symlinks, only dir symlinks to *deeper*
            are followed.
        "on_error" is an error callback called when a given path pattern
            matches nothing:
                on_error(PATH_PATTERN)
            If not specified, the default is look for a "log" global and
            call:
                log.error("`%s': No such file or directory")
            Specify None to do nothing.

    Typically this is useful for a command-line tool that takes a list
    of paths as arguments. (For Unix-heads: the shell on Windows does
    NOT expand glob chars, that is left to the app.)

    Use case #1: like `grep -r`
      {files=True, dirs='never', recursive=(if '-r' in opts)}
        script FILE     # yield FILE, else call on_error(FILE)
        script DIR      # yield nothing
        script PATH*    # yield all files matching PATH*; if none,
                        # call on_error(PATH*) callback
        script -r DIR   # yield files (not dirs) recursively under DIR
        script -r PATH* # yield files matching PATH* and files recursively
                        # under dirs matching PATH*; if none, call
                        # on_error(PATH*) callback

    Use case #2: like `file -r` (if it had a recursive option)
      {files=True, dirs='if-not-recursive', recursive=(if '-r' in opts)}
        script FILE     # yield FILE, else call on_error(FILE)
        script DIR      # yield DIR, else call on_error(DIR)
        script PATH*    # yield all files and dirs matching PATH*; if none,
                        # call on_error(PATH*) callback
        script -r DIR   # yield files (not dirs) recursively under DIR
        script -r PATH* # yield files matching PATH* and files recursively
                        # under dirs matching PATH*; if none, call
                        # on_error(PATH*) callback

    Use case #3: kind of like `find .`
      {files=True, dirs='always', recursive=(if '-r' in opts)}
        script FILE     # yield FILE, else call on_error(FILE)
        script DIR      # yield DIR, else call on_error(DIR)
        script PATH*    # yield all files and dirs matching PATH*; if none,
                        # call on_error(PATH*) callback
        script -r DIR   # yield files and dirs recursively under DIR
                        # (including DIR)
        script -r PATH* # yield files and dirs matching PATH* and recursively
                        # under dirs; if none, call on_error(PATH*)
                        # callback

    TODO: perf improvements (profile, stat just once)
    """
    from os.path import basename, exists, isdir, join, normpath, abspath, \
        lexists, islink, realpath
    from glob import glob

    assert not isinstance(path_patterns, basestring), \
        "'path_patterns' must be a sequence, not a string: %r" % path_patterns
    GLOB_CHARS = '*?['

    if skip_dupe_dirs:
        searched_dirs = set()

    for path_pattern in path_patterns:
        # Determine the set of paths matching this path_pattern.
        for glob_char in GLOB_CHARS:
            if glob_char in path_pattern:
                paths = glob(path_pattern)
                break
        else:
            if follow_symlinks:
                paths = exists(path_pattern) and [path_pattern] or []
            else:
                paths = lexists(path_pattern) and [path_pattern] or []
        if not paths:
            if on_error is None:
                pass
            elif on_error is _NOT_SPECIFIED:
                try:
                    log.error("`%s': No such file or directory", path_pattern)
                except (NameError, AttributeError):
                    pass
            else:
                on_error(path_pattern)

        for path in paths:
            if (follow_symlinks or not islink(path)) and isdir(path):
                if skip_dupe_dirs:
                    canon_path = normpath(abspath(path))
                    if follow_symlinks:
                        canon_path = realpath(canon_path)
                    if canon_path in searched_dirs:
                        continue
                    else:
                        searched_dirs.add(canon_path)

                # 'includes' SHOULD affect whether a dir is yielded.
                if (dirs == "always"
                    or (dirs == "if-not-recursive" and not recursive)
                    ) and _should_include_path(path, includes, excludes):
                    yield path

                # However, if recursive, 'includes' should NOT affect
                # whether a dir is recursed into. Otherwise you could
                # not:
                #   script -r --include="*.py" DIR
                if recursive and _should_include_path(path, [], excludes):
                    for dirpath, dirnames, filenames in _walk(path,
                            follow_symlinks=follow_symlinks):
                        dir_indeces_to_remove = []
                        for i, dirname in enumerate(dirnames):
                            d = join(dirpath, dirname)
                            if skip_dupe_dirs:
                                canon_d = normpath(abspath(d))
                                if follow_symlinks:
                                    canon_d = realpath(canon_d)
                                if canon_d in searched_dirs:
                                    dir_indeces_to_remove.append(i)
                                    continue
                                else:
                                    searched_dirs.add(canon_d)
                            if dirs == "always" \
                               and _should_include_path(d, includes, excludes):
                                yield d
                            if not _should_include_path(d, [], excludes):
                                dir_indeces_to_remove.append(i)
                        for i in reversed(dir_indeces_to_remove):
                            del dirnames[i]
                        if files:
                            for filename in sorted(filenames):
                                f = join(dirpath, filename)
                                if _should_include_path(f, includes, excludes):
                                    yield f

            elif files and _should_include_path(path, includes, excludes):
                yield path


class _NoReflowFormatter(optparse.IndentedHelpFormatter):
    """An optparse formatter that does NOT reflow the description."""
    def format_description(self, description):
        return description or ""

# Recipe: pretty_logging (0.1) in C:\trentm\tm\recipes\cookbook


class _PerLevelFormatter(logging.Formatter):
    """Allow multiple format string -- depending on the log level.

    A "fmtFromLevel" optional arg is added to the constructor. It can be
    a dictionary mapping a log record level to a format string. The
    usual "fmt" argument acts as the default.
    """
    def __init__(self, fmt=None, datefmt=None, fmtFromLevel=None):
        logging.Formatter.__init__(self, fmt, datefmt)
        if fmtFromLevel is None:
            self.fmtFromLevel = {}
        else:
            self.fmtFromLevel = fmtFromLevel

    def format(self, record):
        record.lowerlevelname = record.levelname.lower()
        if record.levelno in self.fmtFromLevel:
            # XXX This is a non-threadsafe HACK. Really the base Formatter
            #    class should provide a hook accessor for the _fmt
            #    attribute. *Could* add a lock guard here (overkill?).
            _saved_fmt = self._fmt
            self._fmt = self.fmtFromLevel[record.levelno]
            try:
                return logging.Formatter.format(self, record)
            finally:
                self._fmt = _saved_fmt
        else:
            return logging.Formatter.format(self, record)


def _setup_logging(stream=None):
    """Do logging setup:

    We want a prettier default format:
         do: level: ...
    Spacing. Lower case. Skip " level:" if INFO-level.
    """
    hdlr = logging.StreamHandler(stream)
    defaultFmt = "%(name)s: %(levelname)s: %(message)s"
    infoFmt = "%(name)s: %(message)s"
    fmtr = _PerLevelFormatter(fmt=defaultFmt,
                              fmtFromLevel={logging.INFO: infoFmt})
    hdlr.setFormatter(fmtr)
    logging.root.addHandler(hdlr)
    log.setLevel(logging.INFO)


#---- mainline

def main(argv):
    usage = "usage: %prog PATHS..."
    version = "%prog "+__version__
    parser = optparse.OptionParser(usage=usage,
        version=version, description=_cmdln_doc,
        formatter=_NoReflowFormatter())
    parser.add_option("-v", "--verbose", dest="log_level",
                      action="store_const", const=logging.DEBUG,
                      help="more verbose output")
    parser.add_option("-q", "--quiet", dest="log_level",
                      action="store_const", const=logging.WARNING,
                      help="quieter output")
    parser.add_option("-r", "--recursive", action="store_true",
                      help="recursively descend into given paths")
    parser.add_option("-L", "--dereference", dest="follow_symlinks",
                      action="store_true",
                      help="follow symlinks, i.e. show info about linked-to "
                           "files and descend into linked dirs when recursive")
    parser.add_option("-Q", "--quick-determine-lang", action="store_true",
                      help="Skip some processing to attempt to determine "
                           "language. Things like specialization, emacs/vi "
                           "local vars, full decoding, are skipped.")
    parser.add_option("--encoding", help="suggested encoding for input files")
    parser.add_option("-f", "--format",
                      help="format of output: summary (default), dict")
    parser.add_option("-x", "--exclude", dest="excludes", action="append",
        metavar="PATTERN",
        help="path pattern to exclude for recursive search (by default SCC "
             "control dirs are skipped)")
    parser.set_defaults(log_level=logging.INFO, encoding=None, recursive=False,
                        follow_symlinks=False, format="summary",
                        excludes=[".svn", "CVS", ".hg", ".git", ".bzr"],
                        quick_determine_lang=False)
    opts, args = parser.parse_args()
    log.setLevel(opts.log_level)
    if opts.log_level > logging.INFO:
        warnings.simplefilter("ignore", ChardetImportWarning)

    if args:
        path_patterns = args
    elif sys.stdin.isatty():
        parser.print_help()
        return 0
    else:
        def args_from_stdin():
            for line in sys.stdin:
                yield line.rstrip("\r\n")
        path_patterns = args_from_stdin()

    for path in _paths_from_path_patterns(
        path_patterns, excludes=opts.excludes,
                    recursive=opts.recursive,
                    dirs="if-not-recursive",
                    follow_symlinks=opts.follow_symlinks):
        try:
            ti = textinfo_from_path(path, encoding=opts.encoding,
                                    follow_symlinks=opts.follow_symlinks,
                                    quick_determine_lang=opts.quick_determine_lang)
        except OSError, ex:
            log.error("%s: %s", path, ex)
            continue
        if opts.format == "summary":
            print ti.as_summary()
        elif opts.format == "dict":
            d = ti.as_dict()
            if "text" in d:
                del d["text"]
            pprint(d)
        else:
            raise TextInfoError("unknown output format: %r" % opts.format)


if __name__ == "__main__":
    _setup_logging()
    try:
        if "--self-test" in sys.argv:
            import doctest
            retval = doctest.testmod()[0]
        else:
            retval = main(sys.argv)
    except SystemExit:
        pass
    except KeyboardInterrupt:
        sys.exit(1)
    except:
        exc_info = sys.exc_info()
        if log.isEnabledFor(logging.DEBUG):
            import traceback
            print
            traceback.print_exception(*exc_info)
        else:
            if hasattr(exc_info[0], "__name__"):
                # log.error("%s: %s", exc_info[0].__name__, exc_info[1])
                log.error(exc_info[1])
            else:  # string exception
                log.error(exc_info[0])
        sys.exit(1)
    else:
        sys.exit(retval)

########NEW FILE########
__FILENAME__ = which
#!/usr/bin/env python
# Copyright (c) 2002-2007 ActiveState Software Inc.
# See LICENSE.txt for license details.
# Author:
#   Trent Mick (TrentM@ActiveState.com)
# Home:
#   http://trentm.com/projects/which/

r"""Find the full path to commands.

which(command, path=None, verbose=0, exts=None)
    Return the full path to the first match of the given command on the
    path.

whichall(command, path=None, verbose=0, exts=None)
    Return a list of full paths to all matches of the given command on
    the path.

whichgen(command, path=None, verbose=0, exts=None)
    Return a generator which will yield full paths to all matches of the
    given command on the path.

By default the PATH environment variable is searched (as well as, on
Windows, the AppPaths key in the registry), but a specific 'path' list
to search may be specified as well.  On Windows, the PATHEXT environment
variable is applied as appropriate.

If "verbose" is true then a tuple of the form
    (<fullpath>, <matched-where-description>)
is returned for each match. The latter element is a textual description
of where the match was found. For example:
    from PATH element 0
    from HKLM\SOFTWARE\...\perl.exe
"""

_cmdlnUsage = """
    Show the full path of commands.

    Usage:
        which [<options>...] [<command-name>...]

    Options:
        -h, --help      Print this help and exit.
        -V, --version   Print the version info and exit.

        -a, --all       Print *all* matching paths.
        -v, --verbose   Print out how matches were located and
                        show near misses on stderr.
        -q, --quiet     Just print out matches. I.e., do not print out
                        near misses.

        -p <altpath>, --path=<altpath>
                        An alternative path (list of directories) may
                        be specified for searching.
        -e <exts>, --exts=<exts>
                        Specify a list of extensions to consider instead
                        of the usual list (';'-separate list, Windows
                        only).

    Show the full path to the program that would be run for each given
    command name, if any. Which, like GNU's which, returns the number of
    failed arguments, or -1 when no <command-name> was given.

    Near misses include duplicates, non-regular files and (on Un*x)
    files without executable access.
"""

__revision__ = "$Id$"
__version_info__ = (1, 1, 3)
__version__ = '.'.join(map(str, __version_info__))
__all__ = ["which", "whichall", "whichgen", "WhichError"]

import os
import sys
import getopt
import stat


#---- exceptions

class WhichError(Exception):
    pass


#---- internal support stuff
def _getRegisteredExecutable(exeName):
    """Windows allow application paths to be registered in the registry."""
    registered = None
    if sys.platform.startswith('win'):
        if os.path.splitext(exeName)[1].lower() != '.exe':
            exeName += '.exe'
        import _winreg
        try:
            key = "SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\App Paths\\" +\
                  exeName
            value = _winreg.QueryValue(_winreg.HKEY_LOCAL_MACHINE, key)
            registered = (value, "from HKLM\\"+key)
        except _winreg.error:
            pass
        if registered and not os.path.exists(registered[0]):
            registered = None
    return registered


def _samefile(fname1, fname2):
    if sys.platform.startswith('win'):
        return (os.path.normpath(os.path.normcase(fname1)) ==
                os.path.normpath(os.path.normcase(fname2)))
    else:
        return os.path.samefile(fname1, fname2)


def _cull(potential, matches, verbose=0):
    """Cull inappropriate matches. Possible reasons:
        - a duplicate of a previous match
        - not a disk file
        - not executable (non-Windows)
    If 'potential' is approved it is returned and added to 'matches'.
    Otherwise, None is returned.
    """
    for match in matches:  # don't yield duplicates
        if _samefile(potential[0], match[0]):
            if verbose:
                sys.stderr.write("duplicate: %s (%s)\n" % potential)
            return None
    else:
        is_darwin_app = (sys.platform == "darwin"
                         and potential[0].endswith(".app"))
        if not is_darwin_app \
           and not stat.S_ISREG(os.stat(potential[0]).st_mode):
            if verbose:
                sys.stderr.write("not a regular file: %s (%s)\n" % potential)
        elif not is_darwin_app and sys.platform != "win32" \
                and not os.access(potential[0], os.X_OK):
            if verbose:
                sys.stderr.write("no executable access: %s (%s)\n"
                                 % potential)
        else:
            matches.append(potential)
            return potential


#---- module API

def whichgen(command, path=None, verbose=0, exts=None):
    """Return a generator of full paths to the given command.

    "command" is a the name of the executable to search for.
    "path" is an optional alternate path list to search. The default it
        to use the PATH environment variable.
    "verbose", if true, will cause a 2-tuple to be returned for each
        match. The second element is a textual description of where the
        match was found.
    "exts" optionally allows one to specify a list of extensions to use
        instead of the standard list for this system. This can
        effectively be used as an optimization to, for example, avoid
        stat's of "foo.vbs" when searching for "foo" and you know it is
        not a VisualBasic script but ".vbs" is on PATHEXT. This option
        is only supported on Windows.

    This method returns a generator which yields either full paths to
    the given command or, if verbose, tuples of the form (<path to
    command>, <where path found>).
    """
    matches = []
    if path is None:
        usingGivenPath = 0
        path = os.environ.get("PATH", "").split(os.pathsep)
        if sys.platform.startswith("win"):
            path.insert(0, os.curdir)  # implied by Windows shell
        if sys.platform == "darwin":
            path.insert(0, "/Network/Applications")
            path.insert(0, "/Applications")
    else:
        usingGivenPath = 1

    # Windows has the concept of a list of extensions (PATHEXT env var).
    if sys.platform.startswith("win"):
        if exts is None:
            exts = os.environ.get("PATHEXT", "").split(os.pathsep)
            # If '.exe' is not in exts then obviously this is Win9x and
            # or a bogus PATHEXT, then use a reasonable default.
            for ext in exts:
                if ext.lower() == ".exe":
                    break
            else:
                exts = ['.COM', '.EXE', '.BAT']
        elif not isinstance(exts, list):
            raise TypeError("'exts' argument must be a list or None")
    elif sys.platform == "darwin":
        if exts is None:
            exts = [".app"]
    else:
        if exts is not None:
            raise WhichError("'exts' argument is not supported on "
                             "platform '%s'" % sys.platform)
        exts = []

    # File name cannot have path separators because PATH lookup does not
    # work that way.
    if os.sep in command or os.altsep and os.altsep in command:
        if os.path.exists(command):
            match = _cull((command, "explicit path given"), matches, verbose)
            if verbose:
                yield match
            else:
                yield match[0]
    else:
        for i in range(len(path)):
            dirName = path[i]
            # On windows the dirName *could* be quoted, drop the quotes
            if sys.platform.startswith("win") and len(dirName) >= 2\
               and dirName[0] == '"' and dirName[-1] == '"':
                dirName = dirName[1:-1]
            for ext in ['']+exts:
                absName = os.path.abspath(
                    os.path.normpath(os.path.join(dirName, command+ext)))
                if os.path.isfile(absName) \
                   or (sys.platform == "darwin" and absName.endswith(".app")
                       and os.path.isdir(absName)):
                    if usingGivenPath:
                        fromWhere = "from given path element %d" % i
                    elif not sys.platform.startswith("win"):
                        fromWhere = "from PATH element %d" % i
                    elif i == 0:
                        fromWhere = "from current directory"
                    else:
                        fromWhere = "from PATH element %d" % (i-1)
                    match = _cull((absName, fromWhere), matches, verbose)
                    if match:
                        if verbose:
                            yield match
                        else:
                            yield match[0]
        match = _getRegisteredExecutable(command)
        if match is not None:
            match = _cull(match, matches, verbose)
            if match:
                if verbose:
                    yield match
                else:
                    yield match[0]


def which(command, path=None, verbose=0, exts=None):
    """Return the full path to the first match of the given command on
    the path.

    "command" is a the name of the executable to search for.
    "path" is an optional alternate path list to search. The default it
        to use the PATH environment variable.
    "verbose", if true, will cause a 2-tuple to be returned. The second
        element is a textual description of where the match was found.
    "exts" optionally allows one to specify a list of extensions to use
        instead of the standard list for this system. This can
        effectively be used as an optimization to, for example, avoid
        stat's of "foo.vbs" when searching for "foo" and you know it is
        not a VisualBasic script but ".vbs" is on PATHEXT. This option
        is only supported on Windows.

    If no match is found for the command, a WhichError is raised.
    """
    try:
        match = whichgen(command, path, verbose, exts).next()
    except StopIteration:
        raise WhichError("Could not find '%s' on the path." % command)
    return match


def whichall(command, path=None, verbose=0, exts=None):
    """Return a list of full paths to all matches of the given command
    on the path.

    "command" is a the name of the executable to search for.
    "path" is an optional alternate path list to search. The default it
        to use the PATH environment variable.
    "verbose", if true, will cause a 2-tuple to be returned for each
        match. The second element is a textual description of where the
        match was found.
    "exts" optionally allows one to specify a list of extensions to use
        instead of the standard list for this system. This can
        effectively be used as an optimization to, for example, avoid
        stat's of "foo.vbs" when searching for "foo" and you know it is
        not a VisualBasic script but ".vbs" is on PATHEXT. This option
        is only supported on Windows.
    """
    return list(whichgen(command, path, verbose, exts))


#---- mainline
def main(argv):
    all = 0
    verbose = 0
    altpath = None
    exts = None
    try:
        optlist, args = getopt.getopt(argv[1:], 'haVvqp:e:',
                                      ['help', 'all', 'version', 'verbose', 'quiet', 'path=', 'exts='])
    except getopt.GetoptError, msg:
        sys.stderr.write("which: error: %s. Your invocation was: %s\n"
                         % (msg, argv))
        sys.stderr.write("Try 'which --help'.\n")
        return 1
    for opt, optarg in optlist:
        if opt in ('-h', '--help'):
            print _cmdlnUsage
            return 0
        elif opt in ('-V', '--version'):
            print "which %s" % __version__
            return 0
        elif opt in ('-a', '--all'):
            all = 1
        elif opt in ('-v', '--verbose'):
            verbose = 1
        elif opt in ('-q', '--quiet'):
            verbose = 0
        elif opt in ('-p', '--path'):
            if optarg:
                altpath = optarg.split(os.pathsep)
            else:
                altpath = []
        elif opt in ('-e', '--exts'):
            if optarg:
                exts = optarg.split(os.pathsep)
            else:
                exts = []

    if len(args) == 0:
        return -1

    failures = 0
    for arg in args:
        # print "debug: search for %r" % arg
        nmatches = 0
        for match in whichgen(arg, path=altpath, verbose=verbose, exts=exts):
            if verbose:
                print "%s (%s)" % match
            else:
                print match
            nmatches += 1
            if not all:
                break
        if not nmatches:
            failures += 1
    return failures


if __name__ == "__main__":
    sys.exit(main(sys.argv))

########NEW FILE########
__FILENAME__ = winprocess
# A module to expose various thread/process/job related structures and
# methods from kernel32.
#
# http://benjamin.smedbergs.us/blog/2006-12-11/killableprocesspy/
#
# The MIT License
#
# Copyright (c) 2006 the Mozilla Foundation <http://www.mozilla.org>
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the "Software"),
# to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense,
# and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.

from ctypes import c_void_p, POINTER, sizeof, Structure, windll, WinError, WINFUNCTYPE
from ctypes.wintypes import BOOL, BYTE, DWORD, HANDLE, LPCWSTR, LPWSTR, UINT, WORD

LPVOID = c_void_p
LPBYTE = POINTER(BYTE)
LPDWORD = POINTER(DWORD)


def ErrCheckBool(result, func, args):
    """errcheck function for Windows functions that return a BOOL True
    on success"""
    if not result:
        raise WinError()
    return args

# CloseHandle()

CloseHandleProto = WINFUNCTYPE(BOOL, HANDLE)
CloseHandle = CloseHandleProto(("CloseHandle", windll.kernel32))
CloseHandle.errcheck = ErrCheckBool

# AutoHANDLE


class AutoHANDLE(HANDLE):
    """Subclass of HANDLE which will call CloseHandle() on deletion."""
    def Close(self):
        if self.value:
            CloseHandle(self)
            self.value = 0

    def __del__(self):
        self.Close()

    def __int__(self):
        return self.value


def ErrCheckHandle(result, func, args):
    """errcheck function for Windows functions that return a HANDLE."""
    if not result:
        raise WinError()
    return AutoHANDLE(result)

# PROCESS_INFORMATION structure


class PROCESS_INFORMATION(Structure):
    _fields_ = [("hProcess", HANDLE),
                ("hThread", HANDLE),
                ("dwProcessID", DWORD),
                ("dwThreadID", DWORD)]

    def __init__(self):
        Structure.__init__(self)

        self.cb = sizeof(self)

LPPROCESS_INFORMATION = POINTER(PROCESS_INFORMATION)

# STARTUPINFO structure


class STARTUPINFO(Structure):
    _fields_ = [("cb", DWORD),
                ("lpReserved", LPWSTR),
                ("lpDesktop", LPWSTR),
                ("lpTitle", LPWSTR),
                ("dwX", DWORD),
                ("dwY", DWORD),
                ("dwXSize", DWORD),
                ("dwYSize", DWORD),
                ("dwXCountChars", DWORD),
                ("dwYCountChars", DWORD),
                ("dwFillAttribute", DWORD),
                ("dwFlags", DWORD),
                ("wShowWindow", WORD),
                ("cbReserved2", WORD),
                ("lpReserved2", LPBYTE),
                ("hStdInput", HANDLE),
                ("hStdOutput", HANDLE),
                ("hStdError", HANDLE)
                ]
LPSTARTUPINFO = POINTER(STARTUPINFO)

STARTF_USESHOWWINDOW = 0x01
STARTF_USESIZE = 0x02
STARTF_USEPOSITION = 0x04
STARTF_USECOUNTCHARS = 0x08
STARTF_USEFILLATTRIBUTE = 0x10
STARTF_RUNFULLSCREEN = 0x20
STARTF_FORCEONFEEDBACK = 0x40
STARTF_FORCEOFFFEEDBACK = 0x80
STARTF_USESTDHANDLES = 0x100

# EnvironmentBlock


class EnvironmentBlock:
    """An object which can be passed as the lpEnv parameter of CreateProcess.
    It is initialized with a dictionary."""

    def __init__(self, dict):
        if not dict:
            self._as_parameter_ = None
        else:
            values = ["%s=%s" % (key, value)
                      for (key, value) in dict.iteritems()]
            values.append("")
            self._as_parameter_ = LPCWSTR("\0".join(values))

# CreateProcess()

CreateProcessProto = WINFUNCTYPE(BOOL,                  # Return type
                                 LPCWSTR,               # lpApplicationName
                                 LPWSTR,                # lpCommandLine
                                 LPVOID,                # lpProcessAttributes
                                 LPVOID,                # lpThreadAttributes
                                 BOOL,                  # bInheritHandles
                                 DWORD,                 # dwCreationFlags
                                 LPVOID,                # lpEnvironment
                                 LPCWSTR,               # lpCurrentDirectory
                                 LPSTARTUPINFO,         # lpStartupInfo
                                 LPPROCESS_INFORMATION  # lpProcessInformation
                                 )

CreateProcessFlags = ((1, "lpApplicationName", None),
                      (1, "lpCommandLine"),
                      (1, "lpProcessAttributes", None),
                      (1, "lpThreadAttributes", None),
                      (1, "bInheritHandles", True),
                      (1, "dwCreationFlags", 0),
                      (1, "lpEnvironment", None),
                      (1, "lpCurrentDirectory", None),
                      (1, "lpStartupInfo"),
                      (2, "lpProcessInformation"))


def ErrCheckCreateProcess(result, func, args):
    ErrCheckBool(result, func, args)
    # return a tuple (hProcess, hThread, dwProcessID, dwThreadID)
    pi = args[9]
    return AutoHANDLE(pi.hProcess), AutoHANDLE(pi.hThread), pi.dwProcessID, pi.dwThreadID

CreateProcess = CreateProcessProto(("CreateProcessW", windll.kernel32),
                                   CreateProcessFlags)
CreateProcess.errcheck = ErrCheckCreateProcess

CREATE_BREAKAWAY_FROM_JOB = 0x01000000
CREATE_DEFAULT_ERROR_MODE = 0x04000000
CREATE_NEW_CONSOLE = 0x00000010
CREATE_NEW_PROCESS_GROUP = 0x00000200
CREATE_NO_WINDOW = 0x08000000
CREATE_SUSPENDED = 0x00000004
CREATE_UNICODE_ENVIRONMENT = 0x00000400
DEBUG_ONLY_THIS_PROCESS = 0x00000002
DEBUG_PROCESS = 0x00000001
DETACHED_PROCESS = 0x00000008

# CreateJobObject()

CreateJobObjectProto = WINFUNCTYPE(HANDLE,             # Return type
                                   LPVOID,             # lpJobAttributes
                                   LPCWSTR             # lpName
                                   )

CreateJobObjectFlags = ((1, "lpJobAttributes", None),
                        (1, "lpName", None))

CreateJobObject = CreateJobObjectProto(("CreateJobObjectW", windll.kernel32),
                                       CreateJobObjectFlags)
CreateJobObject.errcheck = ErrCheckHandle

# AssignProcessToJobObject()

AssignProcessToJobObjectProto = WINFUNCTYPE(BOOL,      # Return type
                                            HANDLE,    # hJob
                                            HANDLE     # hProcess
                                            )
AssignProcessToJobObjectFlags = ((1, "hJob"),
                                 (1, "hProcess"))
AssignProcessToJobObject = AssignProcessToJobObjectProto(
    ("AssignProcessToJobObject", windll.kernel32),
    AssignProcessToJobObjectFlags)
AssignProcessToJobObject.errcheck = ErrCheckBool

# ResumeThread()


def ErrCheckResumeThread(result, func, args):
    if result == -1:
        raise WinError()

    return args

ResumeThreadProto = WINFUNCTYPE(DWORD,      # Return type
                                HANDLE      # hThread
                                )
ResumeThreadFlags = ((1, "hThread"),)
ResumeThread = ResumeThreadProto(("ResumeThread", windll.kernel32),
                                 ResumeThreadFlags)
ResumeThread.errcheck = ErrCheckResumeThread

# TerminateJobObject()

TerminateJobObjectProto = WINFUNCTYPE(BOOL,   # Return type
                                      HANDLE,  # hJob
                                      UINT    # uExitCode
                                      )
TerminateJobObjectFlags = ((1, "hJob"),
                           (1, "uExitCode", 127))
TerminateJobObject = TerminateJobObjectProto(
    ("TerminateJobObject", windll.kernel32),
    TerminateJobObjectFlags)
TerminateJobObject.errcheck = ErrCheckBool

# WaitForSingleObject()

WaitForSingleObjectProto = WINFUNCTYPE(DWORD,  # Return type
                                       HANDLE,  # hHandle
                                       DWORD,  # dwMilliseconds
                                       )
WaitForSingleObjectFlags = ((1, "hHandle"),
                            (1, "dwMilliseconds", -1))
WaitForSingleObject = WaitForSingleObjectProto(
    ("WaitForSingleObject", windll.kernel32),
    WaitForSingleObjectFlags)

INFINITE = -1
WAIT_TIMEOUT = 0x0102
WAIT_OBJECT_0 = 0x0
WAIT_ABANDONED = 0x0080

# GetExitCodeProcess()

GetExitCodeProcessProto = WINFUNCTYPE(BOOL,    # Return type
                                      HANDLE,  # hProcess
                                      LPDWORD,  # lpExitCode
                                      )
GetExitCodeProcessFlags = ((1, "hProcess"),
                           (2, "lpExitCode"))
GetExitCodeProcess = GetExitCodeProcessProto(
    ("GetExitCodeProcess", windll.kernel32),
    GetExitCodeProcessFlags)
GetExitCodeProcess.errcheck = ErrCheckBool

########NEW FILE########
__FILENAME__ = method
##############################################################################
# Copyright (c) 2007 Zope Foundation and Contributors.
# All Rights Reserved.
# 
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED "AS IS" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE.
##############################################################################
"""Cached Methods
"""

class cachedIn(object):
    """Cached method with given cache attribute."""

    def __init__(self, attribute_name, factory=dict):
        self.attribute_name = attribute_name
        self.factory = factory

    def __call__(self, func):

        def decorated(instance, *args, **kwargs):
            cache = self.cache(instance)
            key = self._get_cache_key(*args, **kwargs)
            try:
                v = cache[key]
            except KeyError:
                v = cache[key] = func(instance, *args, **kwargs)
            return v

        decorated.invalidate = self.invalidate
        return decorated

    def invalidate(self, instance, *args, **kwargs):
        cache = self.cache(instance)
        key = self._get_cache_key(*args, **kwargs)
        try:
            del cache[key]
        except KeyError:
            pass

    def cache(self, instance):
        try:
            cache = getattr(instance, self.attribute_name)
        except AttributeError:
            cache = self.factory()
            setattr(instance, self.attribute_name, cache)
        return cache

    @staticmethod
    def _get_cache_key(*args, **kwargs):
        kw = kwargs.items()
        key = (args, tuple(sorted(kw)))
        return key

########NEW FILE########
__FILENAME__ = property
##############################################################################
# Copyright (c) 2003 Zope Foundation and Contributors.
# All Rights Reserved.
# 
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED "AS IS" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE.
##############################################################################
"""Cached properties

See the CachedProperty class.
"""

ncaches = 0


class CachedProperty(object):
    """Cached Properties.
    """

    def __init__(self, func, *names):
        global ncaches
        ncaches += 1
        self.data = (func, names,
                     "_v_cached_property_key_%s" % ncaches,
                     "_v_cached_property_value_%s" % ncaches)

    def __get__(self, inst, class_):
        if inst is None:
            return self

        func, names, key_name, value_name = self.data

        key = names and [getattr(inst, name) for name in names]
        value = getattr(inst, value_name, self)

        if value is not self:
            # We have a cached value
            if key == getattr(inst, key_name, self):
                # Cache is still good!
                return value

        # We need to compute and cache the value

        value = func(inst)
        setattr(inst, key_name, key)
        setattr(inst, value_name, value)

        return value


class Lazy(object):
    """Lazy Attributes.
    """

    def __init__(self, func, name=None):
        if name is None:
            name = func.__name__
        self.data = (func, name)

    def __get__(self, inst, class_):
        if inst is None:
            return self

        func, name = self.data
        value = func(inst)
        inst.__dict__[name] = value

        return value


class readproperty(object):

    def __init__(self, func):
        self.func = func

    def __get__(self, inst, class_):
        if inst is None:
            return self

        func = self.func
        return func(inst)


class cachedIn(object):
    """Cached property with given cache attribute."""

    def __init__(self, attribute_name):
        self.attribute_name = attribute_name

    def __call__(self, func):

        def get(instance):
            try:
                value = getattr(instance, self.attribute_name)
            except AttributeError:
                value = func(instance)
                setattr(instance, self.attribute_name, value)
            return value

        return property(get)

########NEW FILE########
__FILENAME__ = tests
##############################################################################
#
# Copyright (c) 2004 Zope Foundation and Contributors.
# All Rights Reserved.
#
# This software is subject to the provisions of the Zope Public License,
# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.
# THIS SOFTWARE IS PROVIDED "AS IS" AND ANY AND ALL EXPRESS OR IMPLIED
# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS
# FOR A PARTICULAR PURPOSE.
#
##############################################################################
"""Test hookup
"""

import doctest


def test_suite():
    return doctest.DocFileSuite(
        'property.txt', 'method.txt',
        optionflags=doctest.ELLIPSIS)

########NEW FILE########
__FILENAME__ = _SilverCity
import sys
import struct

VERSION = sys.version_info[:2]
PLATFORM = sys.platform
ARCH = 'x%d' % (struct.calcsize('P') * 8)

platform = None

if VERSION >= (3, 3):
    try:
        from _local_arch._SilverCity import *
        platform = "Local arch"
    except ImportError:
        if PLATFORM == 'darwin':
            from _macosx_universal_py33._SilverCity import *
            platform = "MacOS X Universal"
        elif PLATFORM.startswith('linux'):
            if ARCH == 'x64':
                from _linux_libcpp6_x86_64_py33._SilverCity import *
                platform = "Linux 64 bits"
            elif ARCH == 'x32':
                from _linux_libcpp6_x86_py33._SilverCity import *
                platform = "Linux 32 bits"
        elif PLATFORM.startswith('win'):
            if ARCH == 'x64':
                from _win64_py33._SilverCity import *
                platform = "Windows 64 bits"
            elif ARCH == 'x32':
                from _win32_py33._SilverCity import *
                platform = "Windows 32 bits"
elif VERSION >= (2, 6):
    try:
        from _local_arch._SilverCity import *
        platform = "Local arch"
    except ImportError:
        if PLATFORM == 'darwin':
            from _macosx_universal_py26._SilverCity import *
            platform = "MacOS X Universal"
        elif PLATFORM.startswith('linux'):
            if ARCH == 'x64':
                from _linux_libcpp6_x86_64_py26._SilverCity import *
                platform = "Linux 64 bits"
            elif ARCH == 'x32':
                from _linux_libcpp6_x86_py26._SilverCity import *
                platform = "Linux 32 bits"
        elif PLATFORM.startswith('win'):
            if ARCH == 'x64':
                from _win64_py26._SilverCity import *
                platform = "Windows 64 bits"
            elif ARCH == 'x32':
                from _win32_py26._SilverCity import *
                platform = "Windows 32 bits"

if not platform:
    raise ImportError("Could not find a suitable _SilverCity binary for your platform and architecture.")

########NEW FILE########
__FILENAME__ = SublimeCodeIntel
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
#
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
#
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
#
# The Original Code is SublimeCodeIntel code.
#
# The Initial Developer of the Original Code is German M. Bravo (Kronuz).
# Portions created by German M. Bravo (Kronuz) are Copyright (C) 2011
# German M. Bravo (Kronuz). All Rights Reserved.
#
# Contributor(s):
#   German M. Bravo (Kronuz)
#   ActiveState Software Inc
#
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
#
"""
CodeIntel is a plugin intended to display "code intelligence" information.
The plugin is based in code from the Open Komodo Editor and has a MPL license.
Port by German M. Bravo (Kronuz). May 30, 2011

For Manual autocompletion:
    User Key Bindings are setup like this:
        { "keys": ["super+j"], "command": "code_intel_auto_complete" }

For "Jump to symbol declaration":
    User Key Bindings are set up like this
        { "keys": ["super+f3"], "command": "goto_python_definition" }
    ...and User Mouse Bindings as:
        { "button": "button1", "modifiers": ["alt"], "command": "goto_python_definition", "press_command": "drag_select" }

Configuration files (`~/.codeintel/config' or `project_root/.codeintel/config'). All configurations are optional. Example:
    {
        "PHP": {
            "php": "/usr/bin/php",
            "phpConfigFile": "php.ini",
            "phpExtraPaths": []
        },
        "JavaScript": {
            "javascriptExtraPaths": []
        },
        "Perl": {
            "perl": "/usr/bin/perl",
            "perlExtraPaths": []
        },
        "Ruby": {
            "ruby": "/usr/bin/ruby",
            "rubyExtraPaths": []
        },
        "Python": {
            "python": "/usr/bin/python",
            "pythonExtraPaths": []
        },
        "Python3": {
            "python": "/usr/bin/python3",
            "pythonExtraPaths": []
        }
    }
"""
from __future__ import print_function

VERSION = "2.0.6"

import os
import re
import sys
import stat
import time
import datetime
import collections
import sublime
import sublime_plugin
import threading
import logging
from cStringIO import StringIO

CODEINTEL_HOME_DIR = os.path.expanduser(os.path.join('~', '.codeintel'))
__file__ = os.path.normpath(os.path.abspath(__file__))
__path__ = os.path.dirname(__file__)

libs_path = os.path.join(__path__, 'libs')
if libs_path not in sys.path:
    sys.path.insert(0, libs_path)

arch_path = os.path.join(__path__, 'arch')
if arch_path not in sys.path:
    sys.path.insert(0, arch_path)

from codeintel2.common import CodeIntelError, EvalTimeout, LogEvalController, TRG_FORM_CPLN, TRG_FORM_CALLTIP, TRG_FORM_DEFN
from codeintel2.manager import Manager
from codeintel2.environment import SimplePrefsEnvironment
from codeintel2.util import guess_lang_from_path


QUEUE = {}  # views waiting to be processed by codeintel


# Setup the complex logging (status bar gets stuff from there):
class NullHandler(logging.Handler):
    def emit(self, record):
        pass

codeintel_hdlr = NullHandler()
codeintel_hdlr.setFormatter(logging.Formatter("%(name)s: %(levelname)s: %(message)s"))
stderr_hdlr = logging.StreamHandler(sys.stderr)
stderr_hdlr.setFormatter(logging.Formatter("%(name)s: %(levelname)s: %(message)s"))
codeintel_log = logging.getLogger("codeintel")
condeintel_log_filename = ''
condeintel_log_file = None
log = logging.getLogger("SublimeCodeIntel")
codeintel_log.handlers = [codeintel_hdlr]
log.handlers = [stderr_hdlr]
codeintel_log.setLevel(logging.INFO)  # INFO
for logger in ('codeintel.db', 'codeintel.pythoncile'):
    logging.getLogger(logger).setLevel(logging.WARNING)  # WARNING
for logger in ('css', 'django', 'html', 'html5', 'javascript', 'mason', 'nodejs',
             'perl', 'php', 'python', 'python3', 'rhtml', 'ruby', 'smarty',
             'tcl', 'templatetoolkit', 'xbl', 'xml', 'xslt', 'xul'):
    logging.getLogger("codeintel." + logger).setLevel(logging.INFO)  # WARNING
log.setLevel(logging.ERROR)  # ERROR

cpln_fillup_chars = {
    'Ruby': "~`@#$%^&*(+}[]|\\;:,<>/ ",
    'Python': "~`!@#$%^&()-=+{}[]|\\;:'\",.<>?/ ",
    'PHP': "~`%^&*()-+{}[]|;'\",.< ",
    'Perl': "~`!@#$%^&*(=+}[]|\\;'\",.<>?/ ",
    'CSS': " '\";},/",
    'JavaScript': "~`!#%^&*()-=+{}[]|\\;:'\",.<>?/",
}

cpln_stop_chars = {
    'Ruby': "~`@#$%^&*(+}[]|\\;:,<>/ '\".",
    'Python': "~`!@#$%^&*()-=+{}[]|\\;:'\",.<>?/ ",
    'PHP': "~`@%^&*()=+{}]|\\;:'\",.<>?/ ",
    'Perl': "-~`!@#$%^&*()=+{}[]|\\;:'\",.<>?/ ",
    'CSS': " ('\";{},.>/",
    'JavaScript': "~`!@#%^&*()-=+{}[]|\\;:'\",.<>?/ ",
}

old_pos = None
despair = 0
despaired = False

completions = {}
languages = {}

status_msg = {}
status_lineno = {}
status_lock = threading.Lock()

HISTORY_SIZE = 64
jump_history_by_window = {}  # map of window id -> collections.deque([], HISTORY_SIZE)


def pos2bytes(content, pos):
    return len(content[:pos].encode('utf-8'))


class TooltipOutputCommand(sublime_plugin.TextCommand):
    def run(self, edit, output='', clear=True):
        if clear:
            region = sublime.Region(0, self.view.size())
            self.view.erase(edit, region)
        self.view.insert(edit, 0, output)


def tooltip_popup(view, snippets):
    vid = view.id()
    completions[vid] = snippets
    view.run_command('auto_complete', {
        'disable_auto_insert': True,
        'api_completions_only': True,
        'next_completion_if_showing': False,
        'auto_complete_commit_on_tab': True,
    })


def tooltip(view, calltips, original_pos):
    view_settings = view.settings()
    codeintel_snippets = view_settings.get('codeintel_snippets', True)
    codeintel_tooltips = view_settings.get('codeintel_tooltips', 'popup')

    snippets = []
    for calltip in calltips:
        tip_info = calltip.split('\n')
        text = ' '.join(tip_info[1:])
        snippet = None
        # Insert parameters as snippet:
        m = re.search(r'([^\s]+)\(([^\[\(\)]*)', tip_info[0])
        if m:
            params = [p.strip() for p in m.group(2).split(',')]
            if params:
                snippet = []
                for i, p in enumerate(params):
                    if p:
                        var, _, _ = p.partition('=')
                        var = var.strip()
                        if ' ' in var:
                            var = var.split(' ')[1]
                        if var[0] == '$':
                            var = var[1:]
                        snippet.append('${%s:%s}' % (i + 1, var))
                snippet = ', '.join(snippet)
            text += ' - ' + tip_info[0]  # Add function to the end
        else:
            text = tip_info[0] + ' ' + text  # No function match, just add the first line
        if not codeintel_snippets:
            snippet = None
        snippets.extend((('  ' if i > 0 else '') + l, snippet or '${0}') for i, l in enumerate(tip_info))

    if codeintel_tooltips == 'popup':
        tooltip_popup(view, snippets)
    elif codeintel_tooltips in ('status', 'panel'):
        if codeintel_tooltips == 'status':
            set_status(view, 'tip', text, timeout=15000)
        else:
            window = view.window()
            output_panel = window.get_output_panel('tooltips')
            output_panel.set_read_only(False)
            text = '\n'.join(list(zip(*snippets))[0])
            output_panel.run_command('tooltip_output', {'output': text})
            output_panel.set_read_only(True)
            window.run_command('show_panel', {'panel': 'output.tooltips'})
            sublime.set_timeout(lambda: window.run_command('hide_panel', {'panel': 'output.tooltips'}), 15000)

        if snippets and codeintel_snippets:
            # Insert function call snippets:
            # func = m.group(1)
            # scope = view.scope_name(pos)
            # view.run_command('new_snippet', {'contents': snippets[0][0], 'tab_trigger': func, 'scope': scope})  # FIXME: Doesn't add the new snippet... is it possible to do so?
            def _insert_snippet():
                # Check to see we are still at a position where the snippet is wanted:
                view_sel = view.sel()
                if not view_sel:
                    return
                sel = view_sel[0]
                pos = sel.end()
                if not pos or pos != original_pos:
                    return
                view.run_command('insert_snippet', {'contents': snippets[0][0]})
            sublime.set_timeout(_insert_snippet, 500)  # Delay snippet insertion a bit... it's annoying some times


def set_status(view, ltype, msg=None, timeout=None, delay=0, lid='CodeIntel', logger=None):
    if timeout is None:
        timeout = {'error': 3000, 'warning': 5000, 'info': 10000,
                    'event': 10000}.get(ltype, 3000)

    if msg is None:
        msg, ltype = ltype, 'debug'
    msg = msg.strip()

    status_lock.acquire()
    try:
        status_msg.setdefault(lid, [None, None, 0])
        if msg == status_msg[lid][1]:
            return
        status_msg[lid][2] += 1
        order = status_msg[lid][2]
    finally:
        status_lock.release()

    def _set_status():
        view_sel = view.sel()
        lineno = view.rowcol(view_sel[0].end())[0] if view_sel else 0
        status_lock.acquire()
        try:
            current_type, current_msg, current_order = status_msg.get(lid, [None, None, 0])
            if msg != current_msg and order == current_order:
                print("+", "%s: %s" % (ltype.capitalize(), msg), file=condeintel_log_file)
                (logger or log.info)(msg)
                if ltype != 'debug':
                    view.set_status(lid, "%s: %s" % (ltype.capitalize(), msg))
                    status_msg[lid] = [ltype, msg, order]
                if 'warning' not in lid:
                    status_lineno[lid] = lineno
        finally:
            status_lock.release()

    def _erase_status():
        status_lock.acquire()
        try:
            if msg == status_msg.get(lid, [None, None, 0])[1]:
                view.erase_status(lid)
                status_msg[lid][1] = None
                if lid in status_lineno:
                    del status_lineno[lid]
        finally:
            status_lock.release()

    if msg:
        sublime.set_timeout(_set_status, delay or 0)
        sublime.set_timeout(_erase_status, timeout)
    else:
        sublime.set_timeout(_erase_status, delay or 0)


def logger(view, ltype, msg=None, timeout=None, delay=0, lid='CodeIntel'):
    if msg is None:
        msg, ltype = ltype, 'info'
    set_status(view, ltype, msg, timeout=timeout, delay=delay, lid=lid + '-' + ltype, logger=getattr(log, ltype, None))


def guess_lang(view=None, path=None):
    if not view or not codeintel_enabled(view):
        return None

    syntax = None
    if view:
        syntax = os.path.splitext(os.path.basename(view.settings().get('syntax')))[0]

    vid = view.id()
    _k_ = '%s::%s' % (syntax, path)
    try:
        return languages[vid][_k_]
    except KeyError:
        pass
    languages.setdefault(vid, {})

    lang = None
    _codeintel_syntax_map = dict((k.lower(), v) for k, v in view.settings().get('codeintel_syntax_map', {}).items())
    _lang = lang = syntax and _codeintel_syntax_map.get(syntax.lower(), syntax)

    folders = getattr(view.window(), 'folders', lambda: [])()  # FIXME: it's like this for backward compatibility (<= 2060)
    folders_id = str(hash(frozenset(folders)))
    mgr = codeintel_manager(folders_id)

    if not mgr.is_citadel_lang(lang) and not mgr.is_cpln_lang(lang):
        lang = None
        if mgr.is_citadel_lang(syntax) or mgr.is_cpln_lang(syntax):
            _lang = lang = syntax
        else:
            if view and not path:
                path = view.file_name()
            if path:
                try:
                    _lang = lang = guess_lang_from_path(path)
                except CodeIntelError:
                    languages[vid][_k_] = None
                    return

    _codeintel_enabled_languages = [l.lower() for l in view.settings().get('codeintel_enabled_languages', [])]
    if lang and lang.lower() not in _codeintel_enabled_languages:
        languages[vid][_k_] = None
        return None

    if not lang and _lang and _lang in ('Console', 'Plain text'):
        if mgr:
            logger(view, 'debug', "Invalid language: %s. Available: %s" % (_lang, ', '.join(set(mgr.get_citadel_langs() + mgr.get_cpln_langs()))))
        else:
            logger(view, 'debug', "Invalid language: %s" % _lang)

    languages[vid][_k_] = lang
    return lang


def autocomplete(view, timeout, busy_timeout, forms, preemptive=False, args=[], kwargs={}):
    def _autocomplete_callback(view, path, original_pos, lang):
        view_sel = view.sel()
        if not view_sel:
            return

        sel = view_sel[0]
        pos = sel.end()
        if not pos or pos != original_pos:
            return

        lpos = view.line(sel).begin()
        text = view.substr(sublime.Region(lpos, pos + 1))
        next = text[-1] if len(text) == pos + 1 - lpos else None

        if not next or next != '_' and not next.isalnum():
            vid = view.id()

            def _trigger(calltips, cplns=None):
                if cplns is not None or calltips is not None:
                    codeintel_log.info("Autocomplete called (%s) [%s]", lang, ','.join(c for c in ['cplns' if cplns else None, 'calltips' if calltips else None] if c))

                if cplns is not None:
                    function = None if 'import ' in text else 'function'
                    _completions = sorted(
                        [('%s  (%s)' % (n, t), n + ('($0)' if t == function else '')) for t, n in cplns],
                        key=lambda o: o[1]
                    )
                    if _completions:
                        # Show autocompletions:
                        completions[vid] = _completions
                        view.run_command('auto_complete', {
                            'disable_auto_insert': True,
                            'api_completions_only': True,
                            'next_completion_if_showing': False,
                            'auto_complete_commit_on_tab': True,
                        })
                if calltips:
                    tooltip(view, calltips, original_pos)

            content = view.substr(sublime.Region(0, view.size()))
            codeintel(view, path, content, lang, pos, forms, _trigger)
    # If it's a fill char, queue using lower values and preemptive behavior
    queue(view, _autocomplete_callback, timeout, busy_timeout, preemptive, args=args, kwargs=kwargs)


_ci_envs_ = {}
_ci_next_scan_ = {}
_ci_mgr_ = {}

_ci_next_savedb_ = 0
_ci_next_cullmem_ = 0

################################################################################
# Queue dispatcher system:

MAX_DELAY = -1  # Does not apply
queue_thread_name = "codeintel callbacks"


def queue_dispatcher(force=False):
    """
    Default implementation of queue dispatcher (just clears the queue)
    """
    __lock_.acquire()
    try:
        QUEUE.clear()
    finally:
        __lock_.release()


def queue_loop():
    """An infinite loop running the codeintel in a background thread meant to
        update the view after user modifies it and then does no further
        modifications for some time as to not slow down the UI with autocompletes."""
    global __signaled_, __signaled_first_
    while __loop_:
        #print 'acquire...'
        __semaphore_.acquire()
        __signaled_first_ = 0
        __signaled_ = 0
        #print 'DISPATCHING!', len(QUEUE)
        queue_dispatcher()


def queue(view, callback, timeout, busy_timeout=None, preemptive=False, args=[], kwargs={}):
    global __signaled_, __signaled_first_
    now = time.time()
    __lock_.acquire()
    try:
        QUEUE[view.id()] = (view, callback, args, kwargs)
        if now < __signaled_ + timeout * 4:
            timeout = busy_timeout or timeout

        __signaled_ = now
        _delay_queue(timeout, preemptive)
        if not __signaled_first_:
            __signaled_first_ = __signaled_
            #print 'first',
        #print 'queued in', (__signaled_ - now)
    finally:
        __lock_.release()


def _delay_queue(timeout, preemptive):
    global __signaled_, __queued_
    now = time.time()
    if not preemptive and now <= __queued_ + 0.01:
        return  # never delay queues too fast (except preemptively)
    __queued_ = now
    _timeout = float(timeout) / 1000
    if __signaled_first_:
        if MAX_DELAY > 0 and now - __signaled_first_ + _timeout > MAX_DELAY:
            _timeout -= now - __signaled_first_
            if _timeout < 0:
                _timeout = 0
            timeout = int(round(_timeout * 1000, 0))
    new__signaled_ = now + _timeout - 0.01
    if __signaled_ >= now - 0.01 and (preemptive or new__signaled_ >= __signaled_ - 0.01):
        __signaled_ = new__signaled_
        #print 'delayed to', (preemptive, __signaled_ - now)

        def _signal():
            if time.time() < __signaled_:
                return
            __semaphore_.release()
        sublime.set_timeout(_signal, timeout)


def delay_queue(timeout):
    __lock_.acquire()
    try:
        _delay_queue(timeout, False)
    finally:
        __lock_.release()


# only start the thread once - otherwise the plugin will get laggy
# when saving it often.
__semaphore_ = threading.Semaphore(0)
__lock_ = threading.Lock()
__queued_ = 0
__signaled_ = 0
__signaled_first_ = 0

# First finalize old standing threads:
__loop_ = False
__pre_initialized_ = False


def queue_finalize(timeout=None):
    global __pre_initialized_
    for thread in threading.enumerate():
        if thread.isAlive() and thread.name == queue_thread_name:
            __pre_initialized_ = True
            thread.__semaphore_.release()
            thread.join(timeout)
queue_finalize()

# Initialize background thread:
__loop_ = True
__active_codeintel_thread = threading.Thread(target=queue_loop, name=queue_thread_name)
__active_codeintel_thread.__semaphore_ = __semaphore_
__active_codeintel_thread.start()

################################################################################

if not __pre_initialized_:
    # Start a timer
    def _signal_loop():
        __semaphore_.release()
        sublime.set_timeout(_signal_loop, 20000)
    _signal_loop()


def codeintel_callbacks(force=False):
    global _ci_next_savedb_, _ci_next_cullmem_
    __lock_.acquire()
    try:
        views = QUEUE.values()
        QUEUE.clear()
    finally:
        __lock_.release()
    for view, callback, args, kwargs in views:
        def _callback():
            callback(view, *args, **kwargs)
        sublime.set_timeout(_callback, 0)
    # saving and culling cached parts of the database:
    for folders_id in _ci_mgr_.keys():
        mgr = codeintel_manager(folders_id)
        now = time.time()
        if now >= _ci_next_savedb_ or force:
            if _ci_next_savedb_:
                log.debug('Saving database')
                mgr.db.save()  # Save every 6 seconds
            _ci_next_savedb_ = now + 6
        if now >= _ci_next_cullmem_ or force:
            if _ci_next_cullmem_:
                log.debug('Culling memory')
                mgr.db.cull_mem()  # Every 30 seconds
            _ci_next_cullmem_ = now + 30
queue_dispatcher = codeintel_callbacks


def codeintel_cleanup(id):
    if id in _ci_envs_:
        del _ci_envs_[id]
    if id in _ci_next_scan_:
        del _ci_next_scan_[id]


def codeintel_manager(folders_id):
    folders_id = None
    global _ci_mgr_, condeintel_log_filename, condeintel_log_file
    mgr = _ci_mgr_.get(folders_id)
    if mgr is None:
        for thread in threading.enumerate():
            if thread.name == "CodeIntel Manager":
                thread.finalize()  # this finalizes the index, citadel and the manager and waits them to end (join)
        mgr = Manager(
            extra_module_dirs=None,
            db_base_dir=None,  # os.path.expanduser(os.path.join('~', '.codeintel', 'databases', folders_id)),
            db_catalog_dirs=[],
            db_import_everything_langs=None,
        )
        mgr.upgrade()
        mgr.initialize()

        # Connect the logging file to the handler
        condeintel_log_filename = os.path.join(mgr.db.base_dir, 'codeintel.log')
        condeintel_log_file = open(condeintel_log_filename, 'w', 1)
        codeintel_log.handlers = [logging.StreamHandler(condeintel_log_file)]
        msg = "Starting logging SublimeCodeIntel v%s rev %s (%s) on %s" % (VERSION, get_revision()[:12], os.stat(__file__)[stat.ST_MTIME], datetime.datetime.now().ctime())
        print("%s\n%s" % (msg, "=" * len(msg)), file=condeintel_log_file)

        _ci_mgr_[folders_id] = mgr
    return mgr


def codeintel_scan(view, path, content, lang, callback=None, pos=None, forms=None):
    global despair
    for thread in threading.enumerate():
        if thread.isAlive() and thread.name == "scanning thread":
            logger(view, 'info', "Updating indexes... The first time this can take a while. Do not despair!", timeout=20000, delay=despair)
            despair = 0
            return
    logger(view, 'info', "processing `%s': please wait..." % lang)
    is_scratch = view.is_scratch()
    is_dirty = view.is_dirty()
    vid = view.id()
    folders = getattr(view.window(), 'folders', lambda: [])()  # FIXME: it's like this for backward compatibility (<= 2060)
    folders_id = str(hash(frozenset(folders)))
    view_settings = view.settings()
    codeintel_config = view_settings.get('codeintel_config', {})
    _codeintel_max_recursive_dir_depth = view_settings.get('codeintel_max_recursive_dir_depth', 10)
    _codeintel_scan_files_in_project = view_settings.get('codeintel_scan_files_in_project', True)
    _codeintel_selected_catalogs = view_settings.get('codeintel_selected_catalogs', [])

    def _codeintel_scan():
        global despair, despaired
        env = None
        mtime = None
        catalogs = []
        now = time.time()

        mgr = codeintel_manager(folders_id)
        mgr.db.event_reporter = lambda m: logger(view, 'event', m)

        try:
            env = _ci_envs_[vid]
            if env._folders != folders:
                raise KeyError
            if now > env._time:
                mtime = max(tryGetMTime(env._config_file), tryGetMTime(env._config_default_file))
                if env._mtime < mtime:
                    raise KeyError
        except KeyError:
            if env is not None:
                config_default_file = env._config_default_file
                project_dir = env._project_dir
                project_base_dir = env._project_base_dir
                config_file = env._config_file
            else:
                config_default_file = os.path.join(CODEINTEL_HOME_DIR, 'config')
                if not (config_default_file and os.path.exists(config_default_file)):
                    config_default_file = None
                project_dir = None
                project_base_dir = None
                for folder_path in folders + [path]:
                    if folder_path:
                        # Try to find a suitable project directory (or best guess):
                        for folder in ['.codeintel', '.git', '.hg', '.svn', 'trunk']:
                            project_dir = find_back(folder_path, folder)
                            if project_dir:
                                if folder == '.codeintel':
                                    if project_dir == CODEINTEL_HOME_DIR or os.path.exists(os.path.join(project_dir, 'databases')):
                                        continue
                                if folder.startswith('.'):
                                    project_base_dir = os.path.abspath(os.path.join(project_dir, '..'))
                                else:
                                    project_base_dir = project_dir
                                break
                        if project_base_dir:
                            break
                if not (project_dir and os.path.exists(project_dir)):
                    project_dir = None
                config_file = project_dir and folder == '.codeintel' and os.path.join(project_dir, 'config')
                if not (config_file and os.path.exists(config_file)):
                    config_file = None

            valid = True
            if not mgr.is_citadel_lang(lang) and not mgr.is_cpln_lang(lang):
                if lang in ('Console', 'Plain text'):
                    msg = "Invalid language: %s. Available: %s" % (lang, ', '.join(set(mgr.get_citadel_langs() + mgr.get_cpln_langs())))
                    log.debug(msg)
                    codeintel_log.warning(msg)
                valid = False

            codeintel_config_lang = codeintel_config.get(lang, {})
            codeintel_max_recursive_dir_depth = codeintel_config_lang.get('codeintel_max_recursive_dir_depth', _codeintel_max_recursive_dir_depth)
            codeintel_scan_files_in_project = codeintel_config_lang.get('codeintel_scan_files_in_project', _codeintel_scan_files_in_project)
            codeintel_selected_catalogs = codeintel_config_lang.get('codeintel_selected_catalogs', _codeintel_selected_catalogs)

            avail_catalogs = mgr.db.get_catalogs_zone().avail_catalogs()

            # Load configuration files:
            all_catalogs = []
            for catalog in avail_catalogs:
                all_catalogs.append("%s (for %s: %s)" % (catalog['name'], catalog['lang'], catalog['description']))
                if catalog['lang'] == lang:
                    if catalog['name'] in codeintel_selected_catalogs:
                        catalogs.append(catalog['name'])
            msg = "Avaliable catalogs: %s" % ', '.join(all_catalogs) or None
            log.debug(msg)
            codeintel_log.debug(msg)

            config = {
                'codeintel_max_recursive_dir_depth': codeintel_max_recursive_dir_depth,
                'codeintel_scan_files_in_project': codeintel_scan_files_in_project,
                'codeintel_selected_catalogs': catalogs,
            }
            config.update(codeintel_config_lang)

            _config = {}
            try:
                tryReadDict(config_default_file, _config)
            except Exception as e:
                msg = "Malformed configuration file '%s': %s" % (config_default_file, e)
                log.error(msg)
                codeintel_log.error(msg)
            try:
                tryReadDict(config_file, _config)
            except Exception as e:
                msg = "Malformed configuration file '%s': %s" % (config_default_file, e)
                log.error(msg)
                codeintel_log.error(msg)
            config.update(_config.get(lang, {}))

            for conf in ['pythonExtraPaths', 'rubyExtraPaths', 'perlExtraPaths', 'javascriptExtraPaths', 'phpExtraPaths']:
                v = [p.strip() for p in config.get(conf, []) + folders if p.strip()]
                config[conf] = os.pathsep.join(set(p if p.startswith('/') else os.path.expanduser(p) if p.startswith('~') else os.path.abspath(os.path.join(project_base_dir, p)) if project_base_dir else p for p in v if p.strip()))
            for conf, p in config.items():
                if isinstance(p, basestring) and p.startswith('~'):
                    config[conf] = os.path.expanduser(p)

            # Setup environment variables
            env = config.get('env', {})
            _environ = dict(os.environ)
            for k, v in env.items():
                _old = None
                while '$' in v and v != _old:
                    _old = v
                    v = os.path.expandvars(v)
                _environ[k] = v
            config['env'] = _environ

            env = SimplePrefsEnvironment(**config)
            env._valid = valid
            env._mtime = mtime or max(tryGetMTime(config_file), tryGetMTime(config_default_file))
            env._folders = folders
            env._config_default_file = config_default_file
            env._project_dir = project_dir
            env._project_base_dir = project_base_dir
            env._config_file = config_file
            env.__class__.get_proj_base_dir = lambda self: project_base_dir
            _ci_envs_[vid] = env
        env._time = now + 5  # don't check again in less than five seconds

        msgs = []
        if env._valid:
            if forms:
                set_status(view, 'tip', "")
                set_status(view, 'event', "")
                msg = "CodeIntel(%s) for %s@%s [%s]" % (', '.join(forms), path, pos, lang)
                msgs.append(('info', "\n%s\n%s" % (msg, "-" * len(msg))))

            if catalogs:
                msg = "New env with catalogs for '%s': %s" % (lang, ', '.join(catalogs) or None)
                log.debug(msg)
                codeintel_log.warning(msg)
                msgs.append(('info', msg))

            buf = mgr.buf_from_content(content, lang, env, path or "<Unsaved>", 'utf-8')

            if mgr.is_citadel_lang(lang):
                now = datetime.datetime.now()
                if not _ci_next_scan_.get(vid) or now > _ci_next_scan_[vid]:
                    _ci_next_scan_[vid] = now + datetime.timedelta(seconds=10)
                    despair = 0
                    despaired = False
                    msg = "Updating indexes for '%s'... The first time this can take a while." % lang
                    print(msg, file=condeintel_log_file)
                    logger(view, 'info', msg, timeout=20000, delay=1000)
                    if not path or is_scratch:
                        buf.scan()  # FIXME: Always scanning unsaved files (since many tabs can have unsaved files, or find other path as ID)
                    else:
                        if is_dirty:
                            mtime = 1
                        else:
                            mtime = os.stat(path)[stat.ST_MTIME]
                        buf.scan(mtime=mtime, skip_scan_time_check=is_dirty)
        else:
            buf = None
        if callback:
            msg = "Doing CodeIntel for '%s' (hold on)..." % lang
            print(msg, file=condeintel_log_file)
            logger(view, 'info', msg, timeout=20000, delay=1000)
            callback(buf, msgs)
        else:
            logger(view, 'info', "")
    threading.Thread(target=_codeintel_scan, name="scanning thread").start()


def codeintel(view, path, content, lang, pos, forms, callback=None, timeout=7000):
    start = time.time()

    def _codeintel(buf, msgs):
        cplns = None
        calltips = None
        defns = None

        if not buf:
            logger(view, 'warning', "`%s' (%s) is not a language that uses CIX" % (path, lang))
            return [None] * len(forms)

        try:
            trg = getattr(buf, 'preceding_trg_from_pos', lambda p: None)(pos2bytes(content, pos), pos2bytes(content, pos))
            defn_trg = getattr(buf, 'defn_trg_from_pos', lambda p: None)(pos2bytes(content, pos))
        except (CodeIntelError):
            codeintel_log.exception("Exception! %s:%s (%s)" % (path or '<Unsaved>', pos, lang))
            logger(view, 'info', "Error indexing! Please send the log file: '%s" % condeintel_log_filename)
            trg = None
            defn_trg = None
        except:
            codeintel_log.exception("Exception! %s:%s (%s)" % (path or '<Unsaved>', pos, lang))
            logger(view, 'info', "Error indexing! Please send the log file: '%s" % condeintel_log_filename)
            raise
        else:
            eval_log_stream = StringIO()
            _hdlrs = codeintel_log.handlers
            hdlr = logging.StreamHandler(eval_log_stream)
            hdlr.setFormatter(logging.Formatter("%(name)s: %(levelname)s: %(message)s"))
            codeintel_log.handlers = list(_hdlrs) + [hdlr]
            ctlr = LogEvalController(codeintel_log)
            try:
                if 'cplns' in forms and trg and trg.form == TRG_FORM_CPLN:
                    cplns = buf.cplns_from_trg(trg, ctlr=ctlr, timeout=20)
                if 'calltips' in forms and trg and trg.form == TRG_FORM_CALLTIP:
                    calltips = buf.calltips_from_trg(trg, ctlr=ctlr, timeout=20)
                if 'defns' in forms and defn_trg and defn_trg.form == TRG_FORM_DEFN:
                    defns = buf.defns_from_trg(defn_trg, ctlr=ctlr, timeout=20)
            except EvalTimeout:
                logger(view, 'info', "Timeout while resolving completions!")
            finally:
                codeintel_log.handlers = _hdlrs
            logger(view, 'warning', "")
            logger(view, 'event', "")
            result = False
            merge = ''
            for msg in reversed(eval_log_stream.getvalue().strip().split('\n')):
                msg = msg.strip()
                if msg:
                    try:
                        name, levelname, msg = msg.split(':', 2)
                        name = name.strip()
                        levelname = levelname.strip().lower()
                        msg = msg.strip()
                    except:
                        merge = (msg + ' ' + merge) if merge else msg
                        continue
                    merge = ''
                    if not result and msg.startswith('evaluating '):
                        set_status(view, 'warning', msg)
                        result = True

        ret = []
        for f in forms:
            if f == 'cplns':
                ret.append(cplns)
            elif f == 'calltips':
                ret.append(calltips)
            elif f == 'defns':
                ret.append(defns)

        total = (time.time() - start) * 1000
        if total > 1000:
            timestr = "~%ss" % int(round(total / 1000))
        else:
            timestr = "%sms" % int(round(total))
        if not despaired or total < timeout:
            msg = "Done '%s' CodeIntel! Full CodeIntel took %s" % (lang, timestr)
            print(msg, file=condeintel_log_file)

            def _callback():
                view_sel = view.sel()
                if view_sel and view.line(view_sel[0]) == view.line(pos):
                    callback(*ret)
            logger(view, 'info', "")
            sublime.set_timeout(_callback, 0)
        else:
            msg = "Just finished indexing '%s'! Please try again. Full CodeIntel took %s" % (lang, timestr)
            print(msg, file=condeintel_log_file)
            logger(view, 'info', msg, timeout=3000)
    codeintel_scan(view, path, content, lang, _codeintel, pos, forms)


def find_back(start_at, look_for):
    root = os.path.realpath('/')
    start_at = os.path.abspath(start_at)
    if not os.path.isdir(start_at):
        start_at = os.path.dirname(start_at)
    if start_at == root:
        return None
    while True:
        if look_for in os.listdir(start_at):
            return os.path.join(start_at, look_for)
        continue_at = os.path.abspath(os.path.join(start_at, '..'))
        if continue_at == start_at or continue_at == root:
            return None
        start_at = continue_at


def updateCodeIntelDict(master, partial):
    for key, value in partial.items():
        if isinstance(value, dict):
            master.setdefault(key, {}).update(value)
        elif isinstance(value, (list, tuple)):
            master.setdefault(key, []).extend(value)


def tryReadDict(filename, dictToUpdate):
    if filename:
        file = open(filename, 'r')
        try:
            updateCodeIntelDict(dictToUpdate, eval(file.read()))
        finally:
            file.close()


def tryGetMTime(filename):
    if filename:
        return os.stat(filename)[stat.ST_MTIME]
    return 0


def _get_git_revision(path):
    path = os.path.join(path, '.git')
    if os.path.exists(path):
        revision_file = os.path.join(path, 'refs', 'heads', 'master')
        if os.path.isfile(revision_file):
            fh = open(revision_file, 'r')
            try:
                return fh.read().strip()
            finally:
                fh.close()


def get_revision(path=None):
    """
    :returns: Revision number of this branch/checkout, if available. None if
        no revision number can be determined.
    """
    path = os.path.abspath(os.path.normpath(__path__ if path is None else path))
    while path and path != '/' and path != '\\':
        rev = _get_git_revision(path)
        if rev:
            return u'GIT-%s' % rev
        uppath = os.path.abspath(os.path.join(path, '..'))
        if uppath != path:
            path = uppath
        else:
            break
    return u'GIT-unknown'


ALL_SETTINGS = [
    'codeintel',
    'codeintel_snippets',
    'codeintel_tooltips',
    'codeintel_enabled_languages',
    'codeintel_live',
    'codeintel_live_enabled_languages',
    'codeintel_max_recursive_dir_depth',
    'codeintel_scan_files_in_project',
    'codeintel_selected_catalogs',
    'codeintel_syntax_map',
    'codeintel_scan_exclude_dir',
    'codeintel_config',
    'sublime_auto_complete',
]


def settings_changed():
    for window in sublime.windows():
        for view in window.views():
            reload_settings(view)


def reload_settings(view):
    '''Restores user settings.'''
    settings_name = 'SublimeCodeIntel'
    settings = sublime.load_settings(settings_name + '.sublime-settings')
    settings.clear_on_change(settings_name)
    settings.add_on_change(settings_name, settings_changed)

    view_settings = view.settings()

    for setting_name in ALL_SETTINGS:
        if settings.get(setting_name) is not None:
            setting = settings.get(setting_name)
            view_settings.set(setting_name, setting)

    if view_settings.get('codeintel') is None:
        view_settings.set('codeintel', True)

    path = view.file_name()
    lang = guess_lang(view, path)
    if lang and lang.lower() in [l.lower() for l in view.settings().get('codeintel_live_enabled_languages', [])]:
        if not view_settings.get('sublime_auto_complete'):
            view_settings.set('auto_complete', False)

    return view_settings


def codeintel_enabled(view, default=None):
    if view.settings().get('codeintel') is None:
        reload_settings(view)
    return view.settings().get('codeintel', default)


class PythonCodeIntel(sublime_plugin.EventListener):
    def on_close(self, view):
        vid = view.id()
        if vid in completions:
            del completions[vid]
        if vid in languages:
            del languages[vid]
        codeintel_cleanup(view.file_name())

    def on_modified(self, view):
        if not view.settings().get('codeintel_live', True):
            return

        path = view.file_name()
        lang = guess_lang(view, path)
        if not lang or lang.lower() not in [l.lower() for l in view.settings().get('codeintel_live_enabled_languages', [])]:
            return

        view_sel = view.sel()
        if not view_sel:
            return

        sel = view_sel[0]
        pos = sel.end()
        text = view.substr(sublime.Region(pos - 1, pos))
        is_fill_char = (text and text[-1] in cpln_fillup_chars.get(lang, ''))

        # print('on_modified', view.command_history(1), view.command_history(0), view.command_history(-1))
        if (not hasattr(view, 'command_history') or view.command_history(1)[1] is None and (
                view.command_history(0)[0] == 'insert' or
                view.command_history(-1)[0] in ('insert', 'paste') and (
                    view.command_history(0)[0] == 'commit_completion' or
                    view.command_history(0)[0] == 'insert_snippet' and view.command_history(0)[1]['contents'] == '($0)'
                )
        )):
            if view.command_history(0)[0] == 'commit_completion':
                forms = ('calltips',)
            else:
                forms = ('calltips', 'cplns')
            autocomplete(view, 0 if is_fill_char else 200, 50 if is_fill_char else 600, forms, is_fill_char, args=[path, pos, lang])
        else:
            view.run_command('hide_auto_complete')

    def on_selection_modified(self, view):
        global despair, despaired, old_pos
        delay_queue(600)  # on movement, delay queue (to make movement responsive)
        view_sel = view.sel()
        if not view_sel:
            return
        rowcol = view.rowcol(view_sel[0].end())
        if old_pos != rowcol:
            vid = view.id()
            old_pos = rowcol
            despair = 1000
            despaired = True
            status_lock.acquire()
            try:
                slns = [sid for sid, sln in status_lineno.items() if sln != rowcol[0]]
            finally:
                status_lock.release()
            for vid in slns:
                set_status(view, "", lid=vid)

    def on_query_completions(self, view, prefix, locations):
        vid = view.id()
        if vid in completions:
            _completions = completions[vid]
            del completions[vid]
            return _completions
        return []


class CodeIntelAutoComplete(sublime_plugin.TextCommand):
    def run(self, edit, block=False):
        view = self.view
        view_sel = view.sel()
        if not view_sel:
            return
        sel = view_sel[0]
        pos = sel.end()
        path = view.file_name()
        lang = guess_lang(view, path)
        if lang:
            autocomplete(view, 0, 0, ('calltips', 'cplns'), True, args=[path, pos, lang])


class GotoPythonDefinition(sublime_plugin.TextCommand):
    def run(self, edit, block=False):
        view = self.view
        path = view.file_name()
        lang = guess_lang(view, path)
        if lang:
            view_sel = view.sel()
            if not view_sel:
                return
            sel = view_sel[0]
            pos = sel.end()
            content = view.substr(sublime.Region(0, view.size()))
            file_name = view.file_name()

            def _trigger(defns):
                if defns is not None:
                    defn = defns[0]
                    if defn.name and defn.doc:
                        msg = "%s: %s" % (defn.name, defn.doc)
                        logger(view, 'info', msg, timeout=3000)

                    if defn.path and defn.line:
                        if defn.line != 1 or defn.path != file_name:
                            path = defn.path + ':' + str(defn.line)
                            msg = 'Jumping to: %s' % path
                            log.debug(msg)
                            codeintel_log.debug(msg)

                            window = sublime.active_window()
                            if window.id() not in jump_history_by_window:
                                jump_history_by_window[window.id()] = collections.deque([], HISTORY_SIZE)
                            jump_history = jump_history_by_window[window.id()]

                            # Save current position so we can return to it
                            row, col = view.rowcol(view_sel[0].begin())
                            current_location = "%s:%d" % (file_name, row + 1)
                            jump_history.append(current_location)

                            window.open_file(path, sublime.ENCODED_POSITION)
                            window.open_file(path, sublime.ENCODED_POSITION)
                    elif defn.name:
                        msg = 'Cannot find jumping point to: %s' % defn.name
                        log.debug(msg)
                        codeintel_log.debug(msg)

            codeintel(view, path, content, lang, pos, ('defns',), _trigger)


class BackToPythonDefinition(sublime_plugin.TextCommand):
    def run(self, edit, block=False):

        window = sublime.active_window()
        if window.id() in jump_history_by_window:
            jump_history = jump_history_by_window[window.id()]

            if len(jump_history) > 0:
                previous_location = jump_history.pop()
                window = sublime.active_window()
                window.open_file(previous_location, sublime.ENCODED_POSITION)


class CodeintelCommand(sublime_plugin.TextCommand):
    """command to interact with codeintel"""

    def __init__(self, view):
        self.view = view
        self.help_called = False

    def run_(self, action):
        """method called by default via view.run_command;
           used to dispatch to appropriate method"""
        if not action:
            return

        try:
            lc_action = action.lower()
        except AttributeError:
            return
        if lc_action == 'reset':
            self.reset()
        elif lc_action == 'enable':
            self.enable(True)
        elif lc_action == 'disable':
            self.enable(False)
        elif lc_action == 'on':
            self.on_off(True)
        elif lc_action == 'off':
            self.on_off(False)
        elif lc_action == 'lang-on':
            self.on_off(True, guess_lang(self.view, self.view.file_name()))
        elif lc_action == 'lang-off':
            self.on_off(False, guess_lang(self.view, self.view.file_name()))

    def reset(self):
        """Restores user settings."""
        reload_settings(self.view)
        logger(self.view, 'info', "SublimeCodeIntel Reseted!")

    def enable(self, enable):
        self.view.settings().set('codeintel', enable)
        logger(self.view, 'info', "SublimeCodeIntel %s" % ("Enabled!" if enable else "Disabled",))

    def on_off(self, enable, lang=None):
        """Turns live autocomplete on or off."""
        if lang:
            _codeintel_live_enabled_languages = self.view.settings().get('codeintel_live_enabled_languages', [])
            if lang.lower() in [l.lower() for l in _codeintel_live_enabled_languages]:
                if not enable:
                    _codeintel_live_enabled_languages = [l for l in _codeintel_live_enabled_languages if l.lower() != lang.lower()]
                    self.view.settings().set('codeintel_live_enabled_languages', _codeintel_live_enabled_languages)
                    logger(self.view, 'info', "SublimeCodeIntel Live Autocompletion for %s %s" % (lang, "Enabled!" if enable else "Disabled"))
            else:
                if enable:
                    _codeintel_live_enabled_languages.append(lang)
                    self.view.settings().set('codeintel_live_enabled_languages', _codeintel_live_enabled_languages)
                    logger(self.view, 'info', "SublimeCodeIntel Live Autocompletion for %s %s" % (lang, "Enabled!" if enable else "Disabled"))
        else:
            self.view.settings().set('codeintel_live', enable)
            logger(self.view, 'info', "SublimeCodeIntel Live Autocompletion %s" % ("Enabled!" if enable else "Disabled",))
            # logger(view, 'info', "skip `%s': disabled language" % lang)


class SublimecodeintelWindowCommand(sublime_plugin.WindowCommand):
    def is_enabled(self):
        view = self.window.active_view()
        return bool(view)

    def run_(self, args):
        pass


class SublimecodeintelCommand(SublimecodeintelWindowCommand):
    def is_enabled(self, active=None):
        enabled = super(SublimecodeintelCommand, self).is_enabled()

        if active is not None:
            view = self.window.active_view()
            enabled = enabled and codeintel_enabled(view, True) == active

        return bool(enabled)

    def run_(self, args={}):
        view = self.window.active_view()
        action = args.get('action', '')

        if view and action:
            view.run_command('codeintel', action)


class SublimecodeintelEnableCommand(SublimecodeintelCommand):
    def is_enabled(self):
        return super(SublimecodeintelEnableCommand, self).is_enabled(False)


class SublimecodeintelDisableCommand(SublimecodeintelCommand):
    def is_enabled(self):
        return super(SublimecodeintelDisableCommand, self).is_enabled(True)


class SublimecodeintelResetCommand(SublimecodeintelCommand):
    def is_enabled(self):
        return super(SublimecodeintelResetCommand, self).is_enabled()


class SublimecodeintelLiveCommand(SublimecodeintelCommand):
    def is_enabled(self, active=True, onlylang=False):
        enabled = super(SublimecodeintelLiveCommand, self).is_enabled(True)

        if active is not None:
            view = self.window.active_view()

            if onlylang:
                enabled = enabled and view.settings().get('codeintel_live', True) is True
                lang = guess_lang(view)
                enabled = enabled and lang and (lang.lower() in [l.lower() for l in view.settings().get('codeintel_live_enabled_languages', [])]) == active
            else:
                enabled = enabled and view.settings().get('codeintel_live', True) == active

        return bool(enabled)


class SublimecodeintelEnableLiveCommand(SublimecodeintelLiveCommand):
    def is_enabled(self):
        return super(SublimecodeintelEnableLiveCommand, self).is_enabled(False, False)


class SublimecodeintelDisableLiveCommand(SublimecodeintelLiveCommand):
    def is_enabled(self):
        return super(SublimecodeintelDisableLiveCommand, self).is_enabled(True, False)


class SublimecodeintelEnableLiveLangCommand(SublimecodeintelLiveCommand):
    def is_enabled(self):
        return super(SublimecodeintelEnableLiveLangCommand, self).is_enabled(False, True)


class SublimecodeintelDisableLiveLangCommand(SublimecodeintelLiveCommand):
    def is_enabled(self):
        return super(SublimecodeintelDisableLiveLangCommand, self).is_enabled(True, True)

########NEW FILE########
