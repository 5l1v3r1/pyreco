__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# funcy documentation build configuration file, created by
# sphinx-quickstart on Tue Dec 18 21:32:23 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os
on_rtd = os.environ.get('READTHEDOCS', None) == 'True'

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.coverage', 'sphinx.ext.intersphinx']

intersphinx_mapping = {
    'py': ('http://docs.python.org/2', None),
    'py3': ('http://docs.python.org/3', None),
}

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'funcy'
copyright = u'2012-2014, Alexander Schepanovski'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = open('../VERSION').read().strip()
# The full version, including alpha/beta/rc tags.
release = version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

if not on_rtd:  # only import and set the theme if we're building docs locally
    import sphinx_rtd_theme
    html_theme = "sphinx_rtd_theme"
    html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
# html_style = 'overrides.css'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
# html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'funcydoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'funcy.tex', u'funcy Documentation',
   u'Alexander Schepanovski', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'funcy', u'funcy Documentation',
     [u'Alexander Schepanovski'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'funcy', u'funcy Documentation',
   u'Alexander Schepanovski', 'funcy', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = bench_decorators
# -*- coding: utf-8 -*-
import gc, time, sys
sys.path.insert(0, '/home/suor/projects/funcy')
from funcy import *
# import funcy

@decorator
def empty_f(call):
    return call()

from functools import wraps

def empty_f2(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        return func(*args, **kwargs)
    return wrapper

import wrapt

@wrapt.decorator
def empty_wrapt(wrapped, instance, args, kwargs):
    return wrapped(*args, **kwargs)


f = lambda x: x
f1 = empty_f(f)
f2 = empty_f2(f)
fw = empty_wrapt(f)

l = range(100)

def undecorated():
    return map(f, l)
def old_school_decorated():
    return map(f2, l)
def funcy_decorated():
    return map(f1, l)
def wrapt_decorated():
    return map(fw, l)

def bench_test(test):
    print 'Benchmarking %s ...' % test.__name__
    real, clock = 0, 0
    n = 1
    while real < 1:
        gc.disable()
        real, clock = bench_once(test, n)
        gc.enable()
        n *= 2

    n /= 2
    # min_time = min(r[0] for r in l)
    # min_clock = min(r[1] for r in l)

    # return total * 2 / n # Or use normalized?
    # return min_clock
    print '%d loops, time %s, clock %s' % (n, format_time(real/n), format_time(clock/n))

def bench_once(test, n):
    start = time.time()
    clock = time.clock()
    for _ in xrange(n):
        test()
    return (time.time() - start, time.clock() - clock)

def format_time(sec):
    if sec < 1e-6:
        return '%s ns' % (sec * 1e9)
    elif sec < 1e-3:
        return '%s µs' % (sec * 1e6)
    elif sec < 1:
        return '%s ms' % (sec * 1e3)
    else:
        return '%s s' % sec


bench_test(undecorated)
bench_test(old_school_decorated)
bench_test(funcy_decorated)
bench_test(wrapt_decorated)

########NEW FILE########
__FILENAME__ = examples
has_comment = re_tester(r'#')

value.value = walk_values(prepare, value.value)

json_field = partial(field, json=True)

re = lambda pattern: lambda value: re_test(pattern, value)
re = curry(re_test)

def translate_dict(d):
    lines = ('%s: %s' % (k, v) for k, v in walk_values(translate, d).items())
    return '{%s}' % ','.join(lines)

def _locals(func):
    if func.__closure__:
        names = func.__code__.co_freevars
        values = [cell.cell_contents for cell in func.__closure__]
        return zipdict(names, values)
    else:
        return {}

names = _code_names(code)
return merge(project(__builtins__, names), project(func.__globals__, names))

def closure(func):
    return merge(_globals(func), _locals(func))


class namespace_meta(type):
    def __new__(cls, name, bases, attrs):
        attrs = walk_values(iffy(callable, staticmethod), attrs)
        return super(namespace_meta, cls).__new__(cls, name, bases, attrs)

class namespace(object):
    __metaclass__ = namespace_meta


names = chain.from_iterable(get_all_names(color))
try:
    return ifilter(None, imap(COLOR_BY_NAME.get, names)).next()
except StopIteration:
    return unknown()

etags = map(etag_from_response, responses)
etags = filter(None, etags)

phones = filter(None, map(stub_to_phone, _extract_stubs(text)))

return reduce(concat, map(extract_updates, rows))

op_js = ' %s ' % node.op.js
node.js = op_js.join(v.js for v in node.values)

' '.join(n.js for n in interpose(node.op, node.values))

mapcat(translate, interpose(node.op, node.values))
translate_items(interpose(node.op, node.values))

35:         while self.exists(name):
36              name = name_fmt % i
37              i += 1

users_cond = str_join(',', users)
tests = fetch_named('''
    select user_id, full_min, full_max, datetime from player_testtracking
    where %s and user_id in %s
    order by user_id, datetime
''' % (USEFUL_TEST_COND, users_cond))
get_pairs = partial(partition, 2, 1)
return mapcat(get_pairs, ipartition_by(itemgetter(0), tests))

########NEW FILE########
__FILENAME__ = flatten
def iflatten(seq, follow=is_seqcont):
    for item in seq:
        if follow(item):
            for sub in iflatten(item, is_seqcont):
                yield sub
        else:
            yield item

def iflatten2(seq, follow=is_seqcont):
    iters = [iter(seq)]
    while iters:
        try:
            item = next(iters[-1])
        except StopIteration:
            iters.pop()
            continue
        if follow(item):
            iters.append(iter(item))
        else:
            yield item

# This one is faster when deep nesting is involved
def iflatten3(seq, follow=is_seqcont):
    def _yield_chunks():
        for key, group in groupby(seq, key=follow):
            if key:
                yield iflatten3(icat(group), follow)
            else:
                yield group

    return icat(_yield_chunks())

########NEW FILE########
__FILENAME__ = floats
"""
A couple of floating point utilities.

Not sure they should go into funcy.
"""

import math


def fround(value, base):
    return math.floor(value / base) * base

def frange(start, end, step):
    int_start = int(round(start / step))
    int_end = int(round(end / step))
    for i in xrange(int_start, int_end):
        yield i * step


from itertools import count

def frange2(start, end, step):
    for i in count():
        value = start + i * step
        if value > end: break
        yield value

########NEW FILE########
__FILENAME__ = func_spec
def check_spec(types, args):
    if len(args) != len(types):
        raise TypeError('%s() takes exactly %d arguments (%d given)'
                            % (func.__name__, len(types), len(args)))
    for a, t in zip(args, types):
        if not isinstance(a, t):
            argtypes = ', '.join(type(a).__name__ for a in args)
            raise TypeError('Unsupported argument types for %s(): (%s)'
                                % (func.__name__, argtypes))

########NEW FILE########
__FILENAME__ = intro
dict_of = lambda o: {k:getattr(o,k) for k in dir(o) if 'globals' not in k and not callable(getattr(o,k))}

from django.db import connections

def fetch(query, params=[], db='default'):
    cursor = connections[db].cursor()
    cursor.execute(query, params)
    return cursor.fetchall()

########NEW FILE########
__FILENAME__ = makeseq
# (start)
# (start, step)
# (*start, succ)
# (start, end)
# (start, step, end)
# (*start, succ, end)
# (start, stop)
# (start, step, stop)
# (*start, succ, stop)


from collections import deque

def iseq(*args):
    start, succ, stop = args[:-2], args[-2], args[-1]

    for x in start:
        if stop(x): break
        yield x

    items = deque(start)
    while True:
        x = succ(*items)
        if stop(x): break
        yield x
        items.popleft()
        items.append(x)


from whatever import _

def test_iseq():
    assert list(iseq(1, _+1, _>10)) == [1,2,3,4,5,6,7,8,9,10]
    assert list(iseq(1, _*2, _>10)) == [1,2,4,8]

# def overload(*args):
#     pass

# @overload(Ellipsis, callable, callable)
# def iseq(start, succ, stop):
#     pass

########NEW FILE########
__FILENAME__ = partition
def partitioni(n, step, seq=EMPTY):
    if seq is EMPTY:
        step, seq = n, step

    it = iter(seq)
    pool_limit = max(n * 2, 512)
    pool = take(n-1, it)
    for i, item in enumerate(it, start=n):
        pool.append(item)
        if len(pool) > pool_limit:
            pool = pool[-n:]
        if i % step == 0:
            yield pool[-n:]


from collections import deque
from itertools import islice


def partitionid(n, step, seq=EMPTY):
    if seq is EMPTY:
        step, seq = n, step

    it = iter(seq)
    queue = deque(take(n-1, it), maxlen=n)

    for i, item in enumerate(it, start=n):
        queue.append(item)
        if i % step == 0:
            yield list(queue)

def partitionid2(n, step, seq=EMPTY):
    if seq is EMPTY:
        step, seq = n, step

    queue = deque([], maxlen=n)
    for i, item in enumerate(seq, start=1):
        queue.append(item)
        if i % step == 0:
            yield list(queue)


def partitionid3(n, step, seq=EMPTY):
    if seq is EMPTY:
        step, seq = n, step

    it = iter(seq)
    queue = deque(take(n, it), maxlen=n)
    while True:
        yield list(queue)
        new = take(step, it)
        if len(new) < step: break
        queue.extend(new)


def partitionis(n, step, seq=EMPTY):
    if seq is EMPTY:
        step, seq = n, step

    it = iter(seq)
    pool_len = max(n, step)

    i = 0
    pool = []
    while True:
        # chunk = take(pool_len, it)
        # if not chunk: break
        # pool += chunk
        pool.extend(islice(it, pool_len))
        if len(pool) - i < n: break
        for i in range(i, len(pool)-n+1, step):
            # print 'ii', i
            yield pool[i:i+n]

        pool = pool[i:]
        i = step


def partitionis3(n, step, seq=EMPTY):
    if seq is EMPTY:
        step, seq = n, step

    it = iter(seq)
    pool = take(n, it)
    while True:
        if len(pool) < n: break
        yield pool
        pool = pool[step:] + take(step, it)


def partitionis3a(n, step, seq=EMPTY):
    if seq is EMPTY:
        step, seq = n, step

    it = iter(seq)
    pool = take(n, it)
    while True:
        if len(pool) < n: break
        yield pool
        pool = pool[step:]
        pool.extend(islice(it, step))


def partitionis2(n, step, seq=EMPTY):
    if seq is EMPTY:
        step, seq = n, step

    it = iter(seq)
    while True:
        pool = take(n, it)
        if len(pool) == n:
            yield pool
        else:
            break

########NEW FILE########
__FILENAME__ = seqmaker
from itertools import groupby

inc = lambda x: x + 1
dec = lambda x: x - 1

def partition_by(f, coll):
    for _, group in groupby(coll, key=f):
        yield list(group)


def is_arithmetic(items):
    return len(items) == 2 \
        or len(items) >= 3 and items[-1] - items[-2] == items[-2] - items[-3]

def is_geometric(items):
    return len(items) >= 3 and items[-1] / items[-2] == items[-2] / items[-3]

def guess_succ(items, end):
    if is_geometric(items):
        koef = items[-1] / items[-2]
        return lambda x: x * koef
    elif is_arithmetic(items):
        step = items[-1] - items[-2]
        return lambda x: x + step
    else:
        return inc if end >= items[-1] else dec

def parse_key(key):
    is_ellipsis = lambda x: x is Ellipsis
    items, _, end = partition_by(is_ellipsis, key)
    assert len(items) >= 1
    assert len(end) == 1
    end = end[0]

    if callable(items[-1]) and len(items) > 1 and not callable(items[-2]):
        succ = items.pop()
    else:
        succ = guess_succ(items, end)

    assert len(items) >= 1
    return items, succ, end

def get_arity(succ, items):
    try:
        return int(succ.__code__.co_argcount)
    except (AttributeError, ValueError, TypeError):
        for n in range(len(items)):
            try:
                succ(*items[n:])
                return len(items) - n
            except TypeError:
                pass
        else:
            succ(*items) # reraise

class SeqMaker(object):
    def __getitem__(self, key):
        if isinstance(key, int):
            return range(1, key + 1)
        else:
            items, succ, end = parse_key(key)

            arity = get_arity(succ, items)
            while True:
                x = succ(*items[-arity:])
                if items[-1] < end < x or items[-1] > end > x:
                    break
                items.append(x)
                if x == end:
                    break

            return items

seq = SeqMaker()


from operator import __add__
from whatever import _

def test_seq():
    assert seq[1, ..., 3] == [1,2,3]
    assert seq[1, 3, ..., 9] == [1, 3, 5, 7, 9]
    assert seq[1, 2, 4, ..., 10] == [1, 2, 4, 8]
    assert seq[1, _ + 3, ..., 10] == [1, 4, 7, 10]
    assert seq[1, 1, _ + _, ..., 10] == [1, 1, 2, 3, 5, 8]
    assert seq[1, 1, __add__, ..., 10] == [1, 1, 2, 3, 5, 8]

    assert seq[3, ..., 1] == [3, 2, 1]
    assert seq[1, -2, 4, ..., 10] == [1, -2, 4, -8]
    assert seq[-1, 2, -4, ..., 10] == [-1, 2, -4, 8, -16]

    # seq[1, 10]
    # seq[10]

########NEW FILE########
__FILENAME__ = calc
from datetime import datetime, timedelta
from functools import wraps
import inspect


__all__ = ['memoize', 'make_lookuper', 'silent_lookuper', 'cache']


# TODO: guard from keyword arguments in memoize, cache and make_lookuper.
#       For now it's complicated to do in python 2/3 compatible mode,
#       thanks getargspec/getfullargspec/signature mess.


class SkipMemoization(Exception):
    pass

def memoize(func):
    cache = {}

    @wraps(func)
    def wrapper(*args):
        try:
            return cache[args]
        except KeyError:
            try:
                cache[args] = func(*args)
            except SkipMemoization as e:
                return e.args[0] if e.args else None

        return cache[args]
    return wrapper
memoize.skip = SkipMemoization


def _make_lookuper(silent):
    def make_lookuper(func):
        spec = inspect.getargspec(func)
        assert not spec.keywords, \
               'Lookup table building function should not have keyword arguments'

        if spec.args or spec.varargs:
            @memoize
            def wrapper(*args):
                f = lambda: func(*args)
                f.__name__ = '%s(%s)' % (func.__name__, ', '.join(map(str, args)))
                return make_lookuper(f)
        else:
            memory = {}

            def wrapper(arg):
                if not memory:
                    memory[object()] = None # prevent continuos memory refilling
                    memory.update(func())

                if silent:
                    return memory.get(arg)
                elif arg in memory:
                    return memory[arg]
                else:
                    raise LookupError("Failed to look up %s(%s)" % (func.__name__, arg))

        return wraps(func)(wrapper)
    return make_lookuper

make_lookuper = _make_lookuper(False)
silent_lookuper = _make_lookuper(True)


def cache(timeout):
    if isinstance(timeout, int):
        timeout = timedelta(seconds=timeout)

    def decorator(func):
        cache = {}

        @wraps(func)
        def wrapper(*args):
            if args in cache:
                result, timestamp = cache[args]
                if datetime.now() - timestamp < timeout:
                    return result
                else:
                    del cache[args]

            result = func(*args)
            cache[args] = result, datetime.now()
            return result

        def invalidate(*args):
            cache.pop(args)
        wrapper.invalidate = invalidate

        def invalidate_all():
            cache.clear()
        wrapper.invalidate_all = invalidate_all

        return wrapper
    return decorator


########NEW FILE########
__FILENAME__ = colls
import sys
try:
    from __builtin__ import all as _all, any as _any
except ImportError:
    from builtins import all as _all, any as _any
from operator import itemgetter, methodcaller
from collections import Mapping, Set, Iterable, Iterator, defaultdict
from itertools import chain, tee
from functools import reduce

from .cross import basestring, xrange, izip
from .primitives import EMPTY
from .funcs import identity, partial, compose, complement
from .funcmakers import wrap_mapper, wrap_selector
from .seqs import take, imap, ifilter


__all__ = ['empty', 'iteritems',
           'join', 'merge',
           'walk', 'walk_keys', 'walk_values', 'select', 'select_keys', 'select_values', 'compact',
           'is_distinct', 'all', 'any', 'none', 'one', 'some',
           'zipdict', 'flip', 'project', 'izip_values', 'izip_dicts',
           'where', 'pluck', 'invoke']


### Generic ops
def _factory(coll, mapper=None):
    # Hack for defaultdicts overriden constructor
    if isinstance(coll, defaultdict):
        item_factory = compose(mapper, coll.default_factory) if mapper else coll.default_factory
        return partial(defaultdict, item_factory)
    elif isinstance(coll, Iterator):
        return identity
    elif isinstance(coll, basestring):
        return ''.join
    else:
        return coll.__class__

def empty(coll):
    return _factory(coll)()

if sys.version_info[0] == 2:
    def iteritems(coll):
        return coll.iteritems() if hasattr(coll, 'iteritems') else coll
else:
    def iteritems(coll):
        return coll.items() if hasattr(coll, 'items') else coll


def join(colls):
    colls, colls_copy = tee(colls)
    it = iter(colls_copy)
    try:
        dest = next(it)
    except StopIteration:
        return None
    cls = dest.__class__

    if isinstance(dest, basestring):
        return ''.join(colls)
    elif isinstance(dest, Mapping):
        result = dest.copy()
        for d in it:
            result.update(d)
        return result
    elif isinstance(dest, Set):
        return dest.union(*it)
    elif isinstance(dest, (Iterator, xrange)):
        return chain.from_iterable(colls)
    elif isinstance(dest, Iterable):
        return cls(chain.from_iterable(colls)) # could be reduce(concat, ...)
                                               # more effective for low count
    else:
        raise TypeError("Don't know how to join %s" % cls.__name__)

def merge(*colls):
    return join(colls)

# postponed
# def conj(coll, *xs):
#     return merge(coll, xs)


def walk(f, coll):
    """
    Walk coll transforming it's elements with f.
    Same as map, but preserves coll type.
    """
    return _factory(coll)(imap(f, iteritems(coll)))

@wrap_mapper
def walk_keys(f, coll):
    # NOTE: we use this awkward construct instead of lambda to be Python 3 compatible
    def pair_f(pair):
        k, v = pair
        return f(k), v

    return walk(pair_f, coll)

@wrap_mapper
def walk_values(f, coll):
    # NOTE: we use this awkward construct instead of lambda to be Python 3 compatible
    def pair_f(pair):
        k, v = pair
        return k, f(v)

    return _factory(coll, mapper=f)(imap(pair_f, iteritems(coll)))

# TODO: prewalk, postwalk and friends

def select(pred, coll):
    """Same as filter but preserves coll type."""
    return _factory(coll)(ifilter(pred, iteritems(coll)))

@wrap_selector
def select_keys(pred, coll):
    return select(lambda pair: pred(pair[0]), coll)

@wrap_selector
def select_values(pred, coll):
    return select(lambda pair: pred(pair[1]), coll)


def compact(coll):
    if isinstance(coll, Mapping):
        return select_values(bool, coll)
    else:
        return select(bool, coll)


### Content tests

def is_distinct(coll, key=EMPTY):
    if key is EMPTY:
        return len(coll) == len(set(coll))
    else:
        return len(coll) == len(set(imap(key, coll)))


def all(pred, seq=EMPTY):
    if seq is EMPTY:
        return _all(pred)
    return _all(imap(pred, seq))

def any(pred, seq=EMPTY):
    if seq is EMPTY:
        return _any(pred)
    return _any(imap(pred, seq))

none = complement(any)

def one(pred, seq=EMPTY):
    if seq is EMPTY:
        return one(bool, pred)
    return len(take(2, ifilter(pred, seq))) == 1

# Not same as in clojure! returns value found not pred(value)
def some(pred, seq=EMPTY):
    if seq is EMPTY:
        return some(bool, pred)
    return next(ifilter(pred, seq), None)

# TODO: a variant of some that returns mapped value,
#       one can use some(imap(f, seq)) or first(ikeep(f, seq)) for now.

# TODO: vector comparison tests - ascending, descending and such
# def chain_test(compare, seq):
#     return all(compare, izip(seq, rest(seq))

def zipdict(keys, vals):
    return dict(izip(keys, vals))

def flip(mapping):
    def flip_pair(pair):
        k, v = pair
        return v, k
    return walk(flip_pair, mapping)

def project(mapping, keys):
    return _factory(mapping)((k, mapping[k]) for k in keys if k in mapping)

def izip_values(*dicts):
    if len(dicts) < 1:
        raise TypeError('izip_values expects at least one argument')
    keys = set.intersection(*map(set, dicts))
    for key in keys:
        yield tuple(d[key] for d in dicts)

def izip_dicts(*dicts):
    if len(dicts) < 1:
        raise TypeError('izip_dicts expects at least one argument')
    keys = set.intersection(*map(set, dicts))
    for key in keys:
        yield key, tuple(d[key] for d in dicts)


def where(mappings, **cond):
    match = lambda m: all(m[k] == v for k, v in cond.items())
    return filter(match, mappings)

def pluck(key, mappings):
    return map(itemgetter(key), mappings)

def invoke(objects, name, *args, **kwargs):
    return map(methodcaller(name, *args, **kwargs), objects)


if sys.version_info[0] == 3:
    def lwhere(mappings, **cond):
        return list(where(mappings, **cond))

    def lpluck(key, mappings):
        return list(pluck(key, mappings))

    def linvoke(objects, name, *args, **kwargs):
        return list(invoke(objects, name, *args, **kwargs))

########NEW FILE########
__FILENAME__ = cross
try:
    from itertools import ifilter, imap, izip, ifilterfalse
    xrange = xrange
    basestring = basestring
    map = map
    filter = filter
except ImportError:
    ifilter, imap, izip = filter, map, zip
    from itertools import filterfalse as ifilterfalse
    xrange = range
    basestring = (bytes, str)

    from builtins import map as _map, filter as _filter

    def map(f, seq):
        return list(_map(f, seq))

    def filter(f, seq):
        return list(_filter(f, seq))

########NEW FILE########
__FILENAME__ = debug
# -*- coding: utf-8 -*-
from __future__ import print_function
import time
from itertools import chain

from .cross import imap, basestring
from .decorators import decorator


__all__ = ['tap',
           'log_calls', 'print_calls',
           'log_errors', 'print_errors',
           'log_durations', 'print_durations']


def tap(x):
    print(x)
    return x


@decorator
def log_calls(call, print_func, errors=True):
    signature = signature_repr(call)
    try:
        print_func('Call %s' % signature)
        result = call()
        print_func('-> %s from %s' % (smart_repr(result), signature))
        return result
    except BaseException as e:
        if errors:
            print_func('-> raised %s: %s in %s' % (e.__class__.__name__, e, signature))
        raise

print_calls = log_calls(print)


@decorator
def log_errors(call, print_func):
    try:
        return call()
    except Exception as e:
        print_func('%s: %s in %s' % (e.__class__.__name__, e, signature_repr(call)))
        raise

print_errors = log_errors(print)


@decorator
def log_durations(call, print_func):
    start = time.time()
    result = call()
    end = time.time()

    print_func("%s in %s" % (format_time(end - start), signature_repr(call)))
    return result

print_durations = log_durations(print)


def format_time(sec):
    if sec < 1e-6:
        return '%6.2f ns' % (sec * 1e9)
    elif sec < 1e-3:
        return '%6.2f µs' % (sec * 1e6)
    elif sec < 1:
        return '%6.2f ms' % (sec * 1e3)
    else:
        return '%6.2f s' % sec


### Call signature stringification utils

def signature_repr(call):
    args_repr = imap(smart_repr, call._args)
    kwargs_repr = ('%s=%s' % (key, smart_repr(value)) for key, value in call._kwargs.items())
    return '%s(%s)' % (call._func.__name__, ', '.join(chain(args_repr, kwargs_repr)))

def smart_repr(value):
    if isinstance(value, basestring):
        return repr(value)
    else:
        return str(value)

########NEW FILE########
__FILENAME__ = decorators
import sys, inspect
from functools import partial


__all__ = ['decorator']


def decorator(deco):
    # Any arguments after first become decorator arguments
    args = argcounts(deco) != (1, False, False)

    if args:
        # A decorator with arguments is essentialy a decorator fab
        def decorator_fab(*dargs, **dkwargs):
            return make_decorator(deco, dargs, dkwargs)
        return wraps(deco)(decorator_fab)
    else:
        return wraps(deco)(make_decorator(deco))


def make_decorator(deco, dargs=(), dkwargs={}):
    def _decorator(func):
        def wrapper(*args, **kwargs):
            call = Call(func, args, kwargs)
            return deco(call, *dargs, **dkwargs)
        return wraps(func)(wrapper)
    return _decorator


class Call(object):
    """
    A call object to pass as first argument to decorator.
    Call object is just a proxy for decorated function with call arguments saved in its attributes.
    """
    def __init__(self, func, args, kwargs):
        self._func, self._args, self._kwargs = func, args, kwargs
        self._introspected = False

    def __call__(self, *a, **kw):
        return self._func(*(self._args + a), **dict(self._kwargs, **kw))

    def __getattr__(self, name):
        if not self._introspected:
            # Find real func to call getcallargs() on it
            # We need to do it since our decorators don't preserve signature
            func = unwrap(self._func)
            self.__dict__.update(getcallargs(func, *self._args, **self._kwargs))
            self._introspected = True
        try:
            return self.__dict__[name]
        except KeyError:
            raise AttributeError('Function %s does not have argument %s' \
                                 % (self._func.__name__, name))


def argcounts(func):
    spec = inspect.getargspec(func)
    return (len(spec.args), bool(spec.varargs), bool(spec.keywords))


### Fix functools.wraps to make it safely work with callables without all the attributes

# These are already safe in python 3.2
if sys.version_info >= (3, 2):
    from functools import update_wrapper, wraps
else:
    # These are for python 2, so list of attributes is far shorter.
    # Python 3.2 and ealier will get reduced functionality, but we don't support it :)
    WRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__doc__')
    WRAPPER_UPDATES = ('__dict__',)
    # Copy-pasted these two from python 3.3 functools source code
    def update_wrapper(wrapper,
                       wrapped,
                       assigned = WRAPPER_ASSIGNMENTS,
                       updated = WRAPPER_UPDATES):
        wrapper.__wrapped__ = wrapped
        for attr in assigned:
            try:
                value = getattr(wrapped, attr)
            except AttributeError:
                pass
            else:
                setattr(wrapper, attr, value)
        for attr in updated:
            getattr(wrapper, attr).update(getattr(wrapped, attr, {}))
        # Return the wrapper so this can be used as a decorator via partial()
        return wrapper

    def wraps(wrapped,
              assigned = WRAPPER_ASSIGNMENTS,
              updated = WRAPPER_UPDATES):
        return partial(update_wrapper, wrapped=wrapped,
                       assigned=assigned, updated=updated)


### Backport of python 3.4 inspect.unwrap utility

try:
    from inspect import unwrap
except ImportError:
    # A simplified version, no stop keyword-only argument
    def unwrap(func):
        f = func  # remember the original func for error reporting
        memo = set([id(f)]) # Memoise by id to tolerate non-hashable objects
        while hasattr(func, '__wrapped__'):
            func = func.__wrapped__
            id_func = id(func)
            if id_func in memo:
                raise ValueError('wrapper loop when unwrapping {!r}'.format(f))
            memo.add(id_func)
        return func


### Backport of inspect.getcallargs for python 2.6

try:
    from inspect import getcallargs
except ImportError:
    def getcallargs(func, *positional, **named):
        """Get the mapping of arguments to values.
        A dict is returned, with keys the function argument names (including the
        names of the * and ** arguments, if any), and values the respective bound
        values from 'positional' and 'named'."""
        args, varargs, varkw, defaults = inspect.getargspec(func)
        f_name = func.__name__
        arg2value = {}

        # The following closures are basically because of tuple parameter unpacking.
        assigned_tuple_params = []
        def assign(arg, value):
            if isinstance(arg, str):
                arg2value[arg] = value
            else:
                assigned_tuple_params.append(arg)
                value = iter(value)
                for i, subarg in enumerate(arg):
                    try:
                        subvalue = next(value)
                    except StopIteration:
                        raise ValueError('need more than %d %s to unpack' %
                                         (i, 'values' if i > 1 else 'value'))
                    assign(subarg,subvalue)
                try:
                    next(value)
                except StopIteration:
                    pass
                else:
                    raise ValueError('too many values to unpack')

        def is_assigned(arg):
            if isinstance(arg,str):
                return arg in arg2value
            return arg in assigned_tuple_params

        if inspect.ismethod(func) and func.im_self is not None:
            # implicit 'self' (or 'cls' for classmethods) argument
            positional = (func.im_self,) + positional
        num_pos = len(positional)
        num_total = num_pos + len(named)
        num_args = len(args)
        num_defaults = len(defaults) if defaults else 0
        for arg, value in zip(args, positional):
            assign(arg, value)
        if varargs:
            if num_pos > num_args:
                assign(varargs, positional[-(num_pos-num_args):])
            else:
                assign(varargs, ())
        elif 0 < num_args < num_pos:
            raise TypeError('%s() takes %s %d %s (%d given)' % (
                f_name, 'at most' if defaults else 'exactly', num_args,
                'arguments' if num_args > 1 else 'argument', num_total))
        elif num_args == 0 and num_total:
            raise TypeError('%s() takes no arguments (%d given)' %
                            (f_name, num_total))
        for arg in args:
            if isinstance(arg, str) and arg in named:
                if is_assigned(arg):
                    raise TypeError("%s() got multiple values for keyword "
                                    "argument '%s'" % (f_name, arg))
                else:
                    assign(arg, named.pop(arg))
        if defaults:    # fill in any missing values with the defaults
            for arg, value in zip(args[-num_defaults:], defaults):
                if not is_assigned(arg):
                    assign(arg, value)
        if varkw:
            assign(varkw, named)
        elif named:
            unexpected = next(iter(named))
            if isinstance(unexpected, unicode):
                unexpected = unexpected.encode(sys.getdefaultencoding(), 'replace')
            raise TypeError("%s() got an unexpected keyword argument '%s'" %
                            (f_name, unexpected))
        unassigned = num_args - len([arg for arg in args if is_assigned(arg)])
        if unassigned:
            num_required = num_args - num_defaults
            raise TypeError('%s() takes %s %d %s (%d given)' % (
                f_name, 'at least' if defaults else 'exactly', num_required,
                'arguments' if num_required > 1 else 'argument', num_total))
        return arg2value

########NEW FILE########
__FILENAME__ = flow
from datetime import datetime, timedelta

from .cross import imap, xrange
from .decorators import decorator, wraps


__all__ = ['raiser', 'ignore', 'silent', 'retry', 'fallback',
           'limit_error_rate', 'ErrorRateExceeded',
           'post_processing', 'collecting', 'joining']


### Error handling utilities

def raiser(exception_or_class=Exception, *args, **kwargs):
    def _raiser(*a, **kw):
        if args or kwargs:
            raise exception_or_class(*args, **kwargs)
        else:
            raise exception_or_class
    return _raiser


# Not using @decorator here for speed,
# since @ignore and @silent should be used for very simple and fast functions
def ignore(errors, default=None):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except errors:
                return default
        return wrapper
    return decorator

silent = ignore(Exception) # Ignore all real exceptions


@decorator
def retry(call, tries, errors=Exception):
    for attempt in xrange(tries):
        try:
            return call()
        except errors:
            # Reraise error on last attempt
            if attempt + 1 == tries:
                raise


def fallback(*approaches):
    for approach in approaches:
        func, catch = (approach, Exception) if callable(approach) else approach
        try:
            return func()
        except catch:
            pass


class ErrorRateExceeded(Exception):
    pass

def limit_error_rate(fails, timeout, exception=ErrorRateExceeded):
    """
    If function fails to complete `fails` times in a row,
    calls to it will be intercepted for `timeout` with `exception` raised instead.
    """
    if isinstance(timeout, int):
        timeout = timedelta(seconds=timeout)

    def decorator(func):
        func.fails = 0
        func.blocked = None

        @wraps(func)
        def wrapper(*args, **kwargs):
            if func.blocked:
                if datetime.now() - func.blocked < timeout:
                    raise exception
                else:
                    func.blocked = None

            try:
                result = func(*args, **kwargs)
            except:
                func.fails += 1
                if func.fails >= fails:
                    func.blocked = datetime.now()
                raise
            else:
                func.fails = 0
                return result
        return wrapper
    return decorator


### Post processing decorators

@decorator
def post_processing(call, func):
    return func(call())

collecting = post_processing(list)

@decorator
def joining(call, sep):
    return sep.join(imap(sep.__class__, call()))

########NEW FILE########
__FILENAME__ = funcmakers
from inspect import isbuiltin
from functools import wraps
from operator import itemgetter
from collections import Mapping, Set

from .cross import ifilter, ifilterfalse, basestring
from .simple_funcs import identity
from .strings import re_tester, re_finder, _re_type


__all__ = ('make_func', 'make_pred', 'wrap_mapper', 'wrap_selector')


def make_func(f, builtin=False, test=False):
    if callable(f):
        return f
    elif f is None:
        # pass None to builtin as predicate or mapping function for speed
        return None if builtin else \
               bool if test else identity
    elif isinstance(f, (basestring, _re_type)):
        return re_tester(f) if test else re_finder(f)
    elif isinstance(f, (int, slice)):
        return itemgetter(f)
    elif isinstance(f, Mapping):
        return f.__getitem__
    elif isinstance(f, Set):
        return f.__contains__
    else:
        raise TypeError("Can't make a func from %s" % f.__class__.__name__)

def make_pred(pred, builtin=False):
    return make_func(pred, builtin=builtin, test=True)


def _wrap_higher_order(func, test):
    # NOTE: builtin housekeeping is optimization:
    #       map(None, ...) is much faster than map(identity, ...)
    builtin = isbuiltin(func) or func in set([ifilter, ifilterfalse])
    return wraps(func)(lambda f, *seqs: func(make_func(f, builtin=builtin, test=test), *seqs))

def wrap_mapper(func):
    return _wrap_higher_order(func, test=False)

def wrap_selector(func):
    return _wrap_higher_order(func, test=True)

########NEW FILE########
__FILENAME__ = funcolls
from .funcs import compose, ijuxt
from .colls import some, none, one


__all__ = ['all_fn', 'any_fn', 'none_fn', 'one_fn', 'some_fn']


def all_fn(*fs):
    return compose(all, ijuxt(*fs))

def any_fn(*fs):
    return compose(any, ijuxt(*fs))

def none_fn(*fs):
    return compose(none, ijuxt(*fs))

def one_fn(*fs):
    return compose(one, ijuxt(*fs))

def some_fn(*fs):
    return compose(some, ijuxt(*fs))

########NEW FILE########
__FILENAME__ = funcs
from operator import __not__
from functools import reduce

from .cross import map, imap
from .simple_funcs import *
from .funcmakers import make_func


__all__ = ['identity', 'constantly', 'caller',
           'partial', 'func_partial', 'curry', 'autocurry', 'compose', 'complement',
           'juxt', 'ijuxt',
           'iffy']


def compose(*fs):
    if fs:
        pair = lambda f, g: lambda *a, **kw: f(g(*a, **kw))
        return reduce(pair, imap(make_func, fs))
    else:
        return identity

def complement(pred):
    return compose(__not__, pred)


# NOTE: using lazy map in these two will result in empty list/iterator
#       from all calls to i?juxt result since map iterator will be depleted

def juxt(*fs):
    extended_fs = map(make_func, fs)
    return lambda *a, **kw: [f(*a, **kw) for f in extended_fs]

def ijuxt(*fs):
    extended_fs = map(make_func, fs)
    return lambda *a, **kw: (f(*a, **kw) for f in extended_fs)


########NEW FILE########
__FILENAME__ = namespaces
from .colls import walk_values
from .funcs import iffy


class namespace_meta(type):
    def __new__(cls, name, bases, attrs):
        attrs = walk_values(iffy(callable, staticmethod), attrs)
        return super(namespace_meta, cls).__new__(cls, name, bases, attrs)

class namespace(object):
    __metaclass__ = namespace_meta


########NEW FILE########
__FILENAME__ = objects
from inspect import isclass, ismodule

from .strings import cut_prefix


__all__ = ['cached_property', 'monkey']


class cached_property(object):
    """
    Decorator that converts a method with a single self argument into a
    property cached on the instance.

    NOTE: implementation borrowed from Django.
    NOTE: we use fget, fset and fdel attributes to mimic @property.
    """
    fset = fdel = None

    def __init__(self, fget):
        self.fget = fget

    def __get__(self, instance, type=None):
        if instance is None:
            return self
        res = instance.__dict__[self.fget.__name__] = self.fget(instance)
        return res


def monkey(cls):
    assert isclass(cls) or ismodule(cls), "Attempting to monkey patch non-class and non-module"

    def decorator(value):
        func = getattr(value, 'fget', value) # Support properties
        name = cut_prefix(func.__name__, '%s__' % cls.__name__)

        func.__name__ = name
        func.original = getattr(cls, name, None)

        setattr(cls, name, value)
        return value
    return decorator


# TODO: monkey_mix()?

########NEW FILE########
__FILENAME__ = primitives
__all__ = ['isnone', 'notnone', 'inc', 'dec', 'even', 'odd']


EMPTY = object() # Used as unique default for optional arguments


def isnone(x):
    return x is None

def notnone(x):
    return x is not None


def inc(x):
    return x + 1

def dec(x):
    return x - 1

def even(x):
    return x % 2 == 0

def odd(x):
    return x % 2 == 1


########NEW FILE########
__FILENAME__ = py2
from .primitives import *
from .calc import *
from .colls import *
from .decorators import *
from .funcolls import *
from .funcs import *
from .seqs import *
from .types import *
from .strings import *
from .flow import *
from .objects import *
from .namespaces import namespace
from .debug import *
from .primitives import *


# Python 2 style zip() for Python 3
import sys

if sys.version_info[0] == 3:
    _zip = zip
    def zip(*seqs):
        return list(_zip(*seqs))


########NEW FILE########
__FILENAME__ = py3
"""
Rewrite function names to represent Python 3 iterator-by-default interface.
List versions go with l prefix.
"""
from .py2 import *

# colls
del iteritems
zip_values = izip_values; del izip_values
zip_dicts = izip_dicts; del izip_dicts

# seqs
lmap, map = map, imap; del imap
lfilter, filter = filter, ifilter; del ifilter
lremove, remove = remove, iremove; del iremove
lkeep, keep = keep, ikeep; del ikeep
lwithout, without = without, iwithout; del iwithout

lconcat, concat = concat, iconcat; del iconcat
lcat, cat = cat, icat; del icat
lflatten, flatten = flatten, iflatten; del iflatten
lmapcat, mapcat = mapcat, imapcat; del imapcat

ldistinct, distinct = distinct, idistinct; del idistinct
lsplit, split = split, isplit; del isplit
lsplit_at, split_at = split_at, isplit_at; del isplit_at
lsplit_by, split_by = split_by, isplit_by; del isplit_by
lpartition, partition = partition, ipartition; del ipartition
lchunks, chunks = chunks, ichunks; del ichunks
lpartition_by, partition_by = partition_by, ipartition_by; del ipartition_by

lreductions, reductions = reductions, ireductions; del ireductions
lsums, sums = sums, isums; del isums

# py2 re-exports izip, so py3 exports lzip
zip = izip; del izip
def lzip(*seqs):
    return list(zip(*seqs))

# funcs
ljuxt, juxt = juxt, ijuxt; del ijuxt

########NEW FILE########
__FILENAME__ = seqs
import sys
from operator import add
from itertools import islice, chain, tee, dropwhile, takewhile, groupby
from collections import defaultdict, deque, Sequence

from .cross import ifilter, imap, izip, ifilterfalse, xrange
from .primitives import EMPTY
from .types import is_seqcont
from .funcs import partial
from .funcmakers import wrap_mapper, wrap_selector, make_func


__all__ = [
    'count', 'cycle', 'repeat', 'repeatedly', 'iterate',
    'take', 'drop', 'first', 'second', 'nth', 'last', 'rest', 'butlast', 'ilen',
    'map', 'filter', 'imap', 'ifilter', 'remove', 'iremove', 'keep', 'ikeep', 'without', 'iwithout',
    'concat', 'iconcat', 'chain', 'cat', 'icat', 'flatten', 'iflatten', 'mapcat', 'imapcat',
    'izip', 'interleave', 'interpose', 'distinct', 'idistinct',
    'dropwhile', 'takewhile', 'split', 'isplit', 'split_at', 'isplit_at', 'split_by', 'isplit_by',
    'group_by', 'group_by_keys', 'count_by',
    'partition', 'ipartition', 'chunks', 'ichunks', 'ipartition_by', 'partition_by',
    'with_prev', 'pairwise',
    'ireductions', 'reductions', 'isums', 'sums',
]


# Re-export
from itertools import count, cycle, repeat

def repeatedly(f, n=EMPTY):
    _repeat = repeat(None) if n is EMPTY else repeat(None, n)
    return (f() for _ in _repeat)

def iterate(f, x):
    while True:
        yield x
        x = f(x)


def take(n, seq):
    return list(islice(seq, n))

def drop(n, seq):
    return islice(seq, n, None)

def first(seq):
    return next(iter(seq), None)

def second(seq):
    return first(rest(seq))

# TODO: decide how negative indexes should work - count from end or just return None?
#       it raises ValueError for now
def nth(n, seq):
    return next(islice(seq, n, n+1), None)

def last(seq):
    try:
        return first(reversed(seq))
    except TypeError:
        item = None
        for item in iter(seq):
            pass
        return item

def rest(seq):
    return drop(1, seq)

def butlast(seq):
    it = iter(seq)
    try:
        prev = next(it)
    except StopIteration:
        pass
    else:
        for item in it:
            yield prev
            prev = item

def ilen(seq):
    """
    Consume an iterable not reading it into memory; return the number of items.
    Implementation borrowed from http://stackoverflow.com/a/15112059/753382
    """
    counter = count()
    deque(izip(seq, counter), maxlen=0)  # (consume at C speed)
    return next(counter)


# TODO: tree-seq equivalent


imap = wrap_mapper(imap)
ifilter = wrap_selector(ifilter)

if sys.version_info[0] == 2:
    map = wrap_mapper(map)
    filter = wrap_selector(filter)
else:
    def map(f, *seqs):
        return list(imap(f, *seqs))
    def filter(pred, seq):
        return list(ifilter(pred, seq))


def remove(pred, seq):
    return list(iremove(pred, seq))
iremove = wrap_selector(ifilterfalse)

def keep(f, seq=EMPTY):
    if seq is EMPTY:
        return filter(bool, f)
    else:
        return filter(bool, imap(f, seq))

def ikeep(f, seq=EMPTY):
    if seq is EMPTY:
        return ifilter(bool, f)
    else:
        return ifilter(bool, imap(f, seq))

def iwithout(seq, *items):
    for value in seq:
        if value not in items:
            yield value

def without(seq, *items):
    return list(iwithout(seq, *items))


def concat(*seqs):
    return list(chain(*seqs))
iconcat = chain

def cat(seqs):
    return list(icat(seqs))
icat = chain.from_iterable

def iflatten(seq, follow=is_seqcont):
    for item in seq:
        if follow(item):
            for sub in iflatten(item, is_seqcont):
                yield sub
        else:
            yield item

def flatten(seq, follow=is_seqcont):
    return list(iflatten(seq, follow))

def mapcat(f, *seqs):
    return cat(imap(f, *seqs))

def imapcat(f, *seqs):
    return icat(imap(f, *seqs))

def interleave(*seqs):
    return icat(izip(*seqs))

def interpose(sep, seq):
    return drop(1, interleave(repeat(sep), seq))

dropwhile = wrap_selector(dropwhile)
takewhile = wrap_selector(takewhile)


def distinct(seq, key=EMPTY):
    "Order preserving distinct"
    return list(idistinct(seq, key))

def idistinct(seq, key=EMPTY):
    seen = set()
    # check if key is supplied out of loop for efficiency
    if key is EMPTY:
        for item in seq:
            if item not in seen:
                seen.add(item)
                yield item
    else:
        key = make_func(key)
        for item in seq:
            k = key(item)
            if k not in seen:
                seen.add(k)
                yield item


@wrap_selector
def isplit(pred, seq):
    yes, no = deque(), deque()
    splitter = (yes.append(item) if pred(item) else no.append(item) for item in seq)

    def _isplit(q):
        while True:
            while q:
                yield q.popleft()
            next(splitter)

    return _isplit(yes), _isplit(no)

@wrap_selector
def split(pred, seq):
    yes, no = [], []
    for item in seq:
        if pred(item):
            yes.append(item)
        else:
            no.append(item)
    return yes, no


def isplit_at(n, seq):
    a, b = tee(seq)
    return islice(a, n), islice(b, n, None)

def split_at(n, seq):
    a, b = isplit_at(n, seq)
    return list(a), list(b)

def isplit_by(pred, seq):
    a, b = tee(seq)
    return takewhile(pred, a), dropwhile(pred, b)

def split_by(pred, seq):
    a, b = isplit_by(pred, seq)
    return list(a), list(b)


@wrap_mapper
def group_by(f, seq):
    result = defaultdict(list)
    for item in seq:
        result[f(item)].append(item)
    return result

# TODO: better name? group_by_multi? multi_group? group_by_features?
@wrap_mapper
def group_by_keys(get_keys, seq):
    result = defaultdict(list)
    for item in seq:
        for k in get_keys(item):
            result[k].append(item)
    return result

# TODO: group_by_values()? better name?
#       - group_by_second()
#       - group_keys()
#       - group_first()
#       - flipgroup() / groupflip() / flip_n_group() # should these treat dicts specially?
# def group_by_values(seq_or_dict):
#     result = defaultdict(list)
#     for key, value in iteritems(seq_or_dict):
#         result[value].append(key)
#     return result
#
# TODO: a generalization:
# def group_something_by_something(key, extract, seq):
#     result = defaultdict(list)
#     for item in seq:
#         result[key(item)].append(extract(item))
#     return result
#
# def group_custom(seq, key=..., extract=..., keys=...): # custom_group()?
#                                                        # extract -> value, permits values
#     result = defaultdict(list)
#     for item in seq:
#         result[key(item)].append(extract(item))
#     return result
#
# NOTE: furter generalization is possible with multiple keys per item
#       and, probably, even multiple extracts.

@wrap_mapper
def count_by(f, seq):
    result = defaultdict(int)
    for item in seq:
        result[f(item)] += 1
    return result


# For efficiency we use separate implementation for cutting sequences (those capable of slicing)
def _icut_seq(drop_tail, n, step, seq):
    limit = len(seq)-n+1 if drop_tail else len(seq)
    return (seq[i:i+n] for i in xrange(0, limit, step))

def _icut_iter(drop_tail, n, step, seq):
    it = iter(seq)
    pool = take(n, it)
    while True:
        if len(pool) < n:
            break
        yield pool
        pool = pool[step:]
        pool.extend(islice(it, step))
    if not drop_tail:
        for item in _icut_seq(drop_tail, n, step, pool):
            yield item

def _icut(drop_tail, n, step, seq=EMPTY):
    if seq is EMPTY:
        step, seq = n, step
    # NOTE: range() is capable of slicing in python 3,
    #       so this implementation could be updated
    if isinstance(seq, Sequence) and not isinstance(seq, xrange):
        return _icut_seq(drop_tail, n, step, seq)
    else:
        return _icut_iter(drop_tail, n, step, seq)

def ipartition(n, step, seq=EMPTY):
    return _icut(True, n, step, seq)

def partition(n, step, seq=EMPTY):
    return list(ipartition(n, step, seq))

def ichunks(n, step, seq=EMPTY):
    return _icut(False, n, step, seq)

def chunks(n, step, seq=EMPTY):
    return list(ichunks(n, step, seq))

@wrap_selector
def ipartition_by(f, seq):
    for g, items in groupby(seq, f):
        yield items

def partition_by(f, seq):
    return map(list, ipartition_by(f, seq))


def with_prev(seq, fill=None):
    a, b = tee(seq)
    return izip(a, chain([fill], b))

# An itertools recipe
# NOTE: this is the same as ipartition(2, 1, seq) only faster and with distinct name
def pairwise(seq):
    a, b = tee(seq)
    next(b, None)
    return izip(a, b)


def ireductions(f, seq, acc=EMPTY):
    it = iter(seq)
    if acc is EMPTY:
        last = next(it)
        yield last
    else:
        last = acc
    for x in it:
        last = f(last, x)
        yield last

def reductions(f, seq, acc=EMPTY):
    return list(ireductions(f, seq, acc))

isums = partial(ireductions, add)
sums = partial(reductions, add)

########NEW FILE########
__FILENAME__ = simple_funcs
from functools import partial

from .primitives import EMPTY


def identity(x):
    return x

def constantly(x):
    return lambda *a, **kw: x

# an operator.methodcaller() brother
def caller(*a, **kw):
    return lambda f: f(*a, **kw)

# not using functools.partial to get real function
def func_partial(func, *args, **kwargs):
    """
    A functools.partial alternative, which returns a real function.
    Can be used to construct methods.
    """
    return lambda *a, **kw: func(*(args + a), **dict(kwargs, **kw))


def curry(func, n=EMPTY):
    if n is EMPTY:
        n = func.__code__.co_argcount

    if n <= 1:
        return func
    elif n == 2:
        return lambda x: lambda y: func(x, y)
    else:
        return lambda x: curry(partial(func, x), n - 1)


def autocurry(func, n=EMPTY, _args=(), _kwargs={}):
    if n is EMPTY:
        n = func.__code__.co_argcount

    def autocurried(*a, **kw):
        args = _args + a
        kwargs = _kwargs.copy()
        kwargs.update(kw)

        if len(args) + len(kwargs) >= n:
            return func(*args, **kwargs)
        else:
            return autocurry(func, n, _args=args, _kwargs=kwargs)

    return autocurried


def iffy(pred, action=EMPTY, default=identity):
    if action is EMPTY:
        return iffy(bool, pred)
    else:
        return lambda v: action(v)  if pred(v) else           \
                         default(v) if callable(default) else \
                         default

########NEW FILE########
__FILENAME__ = strings
import re
from operator import methodcaller

from .cross import imap
from .primitives import EMPTY
from .simple_funcs import identity, iffy


__all__ = ['re_iter', 're_all', 're_find', 're_finder', 're_test', 're_tester',
           'str_join',
           'cut_prefix', 'cut_suffix']


def _make_getter(regex):
    if regex.groups == 0:
        return methodcaller('group')
    elif regex.groups == 1 and regex.groupindex == {}:
        return methodcaller('group', 1)
    elif regex.groupindex == {}:
        return methodcaller('groups')
    elif regex.groups == len(regex.groupindex):
        return methodcaller('groupdict')
    else:
        return identity

_re_type = type(re.compile(r''))

def _prepare(regex, flags):
    if not isinstance(regex, _re_type):
        regex = re.compile(regex, flags)
    return regex, _make_getter(regex)


def re_iter(regex, s, flags=0):
    regex, getter = _prepare(regex, flags)
    return imap(getter, regex.finditer(s))

def re_all(regex, s, flags=0):
    return list(re_iter(regex, s, flags))

def re_find(regex, s, flags=0):
    return re_finder(regex, flags)(s)

def re_test(regex, s, flags=0):
    return re_tester(regex, flags)(s)


def re_finder(regex, flags=0):
    regex, getter = _prepare(regex, flags)
    return lambda s: iffy(getter)(regex.search(s))

def re_tester(regex, flags=0):
    return lambda s: bool(re.search(regex, s, flags))


def str_join(sep, seq=EMPTY):
    if seq is EMPTY:
        return str_join('', sep)
    else:
        return sep.join(imap(sep.__class__, seq))

def cut_prefix(s, prefix):
    return s[len(prefix):] if s.startswith(prefix) else s

def cut_suffix(s, suffix):
    return s[:-len(suffix)] if s.endswith(suffix) else s

########NEW FILE########
__FILENAME__ = types
from collections import Mapping, Sequence, Iterator, Iterable

from .cross import xrange


__all__ = ('isa', 'is_mapping', 'is_seq', 'is_list', 'is_tuple',
           'is_seqcoll', 'is_seqcont',
           'iterable', 'is_iter')


def isa(*types):
    return lambda x: isinstance(x, types)

is_mapping = isa(Mapping)
is_seq = isa(Sequence)
is_list = isa(list)
is_tuple = isa(tuple)

is_seqcoll = isa(list, tuple)
is_seqcont = isa(list, tuple, Iterator, xrange)

iterable = isa(Iterable)
is_iter = isa(Iterator)

########NEW FILE########
__FILENAME__ = test_calc
from math import sin, cos
import pytest

from funcy.calc import *


def test_memoize():
    calls = []

    @memoize
    def inc(x):
        calls.append(x)
        return x + 1

    assert inc(0) == 1
    assert inc(1) == 2
    assert inc(0) == 1
    assert calls == [0, 1]


def test_make_lookuper():
    @make_lookuper
    def letter_index():
        return ((c, i) for i, c in enumerate('abcdefghij'))

    assert letter_index('c') == 2
    with pytest.raises(LookupError): letter_index('_')


def test_make_lookuper_nested():
    tables_built = [0]

    @make_lookuper
    def function_table(f):
        tables_built[0] += 1
        return ((x, f(x)) for x in range(10))

    assert function_table(sin)(5) == sin(5)
    assert function_table(cos)(3) == cos(3)
    assert function_table(sin)(3) == sin(3)
    assert tables_built[0] == 2

    with pytest.raises(LookupError): function_table(cos)(-1)


def test_silent_lookuper():
    @silent_lookuper
    def letter_index():
        return ((c, i) for i, c in enumerate('abcdefghij'))

    assert letter_index('c') == 2
    assert letter_index('_') is None


def test_silnent_lookuper_nested():
    @silent_lookuper
    def function_table(f):
        return ((x, f(x)) for x in range(10))

    assert function_table(sin)(5) == sin(5)
    assert function_table(cos)(-1) is None


def test_cache():
    calls = []

    @cache(timeout=60)
    def inc(x):
        calls.append(x)
        return x + 1

    assert inc(0) == 1
    assert inc(1) == 2
    assert inc(0) == 1
    inc.invalidate(0)
    assert inc(0) == 1
    assert calls == [0, 1, 0]


def test_cache_timedout():
    calls = []

    @cache(timeout=0)
    def inc(x):
        calls.append(x)
        return x + 1

    assert inc(0) == 1
    assert inc(0) == 1
    assert calls == [0, 0]

########NEW FILE########
__FILENAME__ = test_colls
import pytest
from itertools import chain
from collections import Iterator, defaultdict
from whatever import _

from funcy.colls import *


# Utilities
def eq(a, b):
    return type(a) is type(b) and a == b \
       and (a.default_factory == b.default_factory if isinstance(a, defaultdict) else True)

def S(*args):
    """"Set literal" for the poor python 2.6"""
    return set(args)

def inc(x):
    return x + 1

def hinc(xs):
    return map(inc, xs)


def test_empty():
    assert eq(empty({'a': 1}), {})
    assert eq(empty(defaultdict(int)), defaultdict(int))
    assert empty(defaultdict(int)).default_factory == defaultdict(int).default_factory

def test_iteritems():
    assert list(iteritems([1,2])) == [1,2]
    assert list(iteritems((1,2))) == [1,2]
    assert list(iteritems({'a': 1})) == [('a', 1)]

def test_merge():
    assert eq(merge({1: 2}, {3: 4}), {1: 2, 3: 4})

def test_join():
    assert join([]) is None
    with pytest.raises(TypeError): join([1])
    assert eq(join(['ab', '', 'cd']), 'abcd')
    assert eq(join([['a', 'b'], 'c']), list('abc'))
    assert eq(join([('a', 'b'), ('c',)]), tuple('abc'))
    assert eq(join([{'a': 1}, {'b': 2}]), {'a': 1, 'b': 2})
    assert eq(join([{'a': 1}, {'a': 2}]), {'a': 2})
    assert eq(join([S(1,2), S(3)]), S(1,2,3))

    it1 = (x for x in range(2))
    it2 = (x for x in range(5, 7))
    joined = join([it1, it2])
    assert isinstance(joined, Iterator) and list(joined) == [0,1,5,6]

    dd1 = defaultdict(int, a=1)
    dd2 = defaultdict(int, b=2)
    assert eq(join([dd1, dd2]), defaultdict(int, a=1, b=2))

def test_join_iter():
    assert join(iter('abc')) == 'abc'
    assert join(iter([[1], [2]])) == [1, 2]
    assert eq(join(iter([{'a': 1}, {'b': 2}])), {'a': 1, 'b': 2})
    assert eq(join(iter([S(1,2), S(3)])), S(1,2,3))

    it1 = (x for x in range(2))
    it2 = (x for x in range(5, 7))
    chained = join(iter([it1, it2]))
    assert isinstance(chained, Iterator) and list(chained) == [0,1,5,6]


def test_walk():
    assert eq(walk(inc, [1,2,3]), [2,3,4])
    assert eq(walk(inc, (1,2,3)), (2,3,4))
    assert eq(walk(inc, S(1,2,3)), S(2,3,4))
    assert eq(walk(hinc, {1:1,2:2,3:3}), {2:2,3:3,4:4})

def test_walk_iter():
    it = walk(inc, chain([0], [1, 2]))
    assert isinstance(it, Iterator) and list(it) == [1,2,3]

    it = walk(inc, (i for i in [0,1,2]))
    assert isinstance(it, Iterator) and list(it) == [1,2,3]

def test_walk_extended():
    assert walk(None, S(2, 3)) == S(2, 3)
    assert walk(r'\d+', S('a2', '13b')) == S('2', '13')
    assert walk({'a': '1', 'b': '2'}, 'ab') == '12'
    assert walk(S(1, 2, 3), (0, 1, 2)) == (False, True, True)

def test_walk_keys():
    assert walk_keys(str.upper, {'a': 1, 'b':2}) == {'A': 1, 'B': 2}

def test_walk_values():
    assert walk_values(_ * 2, {'a': 1, 'b': 2}) == {'a': 2, 'b': 4}

def test_walk_values_defaultdict():
    dd = defaultdict(lambda: 'hey', {1: 'a', 2: 'ab'})
    walked_dd = walk_values(len, dd)
    assert walked_dd == {1: 1, 2: 2}
    # resulting default factory should be compose(len, lambda: 'hey')
    assert walked_dd[0] == 3


def test_select():
    assert eq(select(_>1, [1,2,3]), [2,3])
    assert eq(select(_>1, (1,2,3)), (2,3))
    assert eq(select(_>1, S(1,2,3)), S(2,3))
    assert eq(select(_[1]>1, {'a':1,'b':2,'c':3}), {'b':2,'c':3})
    assert select(_[1]>1, defaultdict(int)) == {}

def test_select_extended():
    assert select(None, [2, 3, 0]) == [2, 3]
    assert select(r'\d', 'a23bn45') == '2345'
    assert select(S(1,2,3), (0, 1, 2, 4, 1)) == (1, 2, 1)

def test_select_keys():
    assert select_keys(_[0] == 'a', {'a':1, 'b':2, 'ab':3}) == {'a': 1, 'ab':3}
    assert select_keys(r'^a', {'a':1, 'b':2, 'ab':3, 'ba': 4}) == {'a': 1, 'ab':3}

def test_select_values():
    assert select_values(_ % 2, {'a': 1, 'b': 2}) == {'a': 1}


def test_compact():
    assert eq(compact([0, 1, None, 3]), [1, 3])
    assert eq(compact((0, 1, None, 3)), (1, 3))
    assert eq(compact({'a': None, 'b': 0, 'c': 1}), {'c': 1})


def test_is_distinct():
    assert is_distinct('abc')
    assert not is_distinct('aba')
    assert is_distinct(['a', 'ab', 'abc'], key=len)
    assert not is_distinct(['ab', 'cb', 'ad'], key=0)


def test_all():
    assert all([1,2,3])
    assert not all([1,2,''])
    assert all(callable, [abs, open, int])
    assert not all(_ < 3, [1,2,5])

def test_all_extended():
    assert all(None, [1,2,3])
    assert not all(None, [1,2,''])
    assert all(r'\d', '125')
    assert not all(r'\d', '12.5')

def test_any():
    assert any([0, False, 3, ''])
    assert any([0, False, '']) == False
    assert any(_ > 0, [1,2,0])
    assert any(_ < 0, [1,2,0]) == False

def test_one():
    assert one([0, False, 3, ''])
    assert not one([0, False, ''])
    assert not one([1, False, 'a'])
    assert one(_ > 0, [0,1])
    assert not one(_ < 0, [0,1,2])
    assert not one(_ > 0, [0,1,2])

def test_none():
    assert none([0, False])
    assert none(_ < 0, [0, -1]) == False

def test_some():
    assert some([0, '', 2, 3]) == 2
    assert some(_ > 3, range(10)) == 4


def test_zipdict():
    assert zipdict([1, 2], 'ab') == {1:'a', 2:'b'}

def test_flip():
    assert flip({'a':1, 'b':2}) == {1:'a', 2:'b'}

def test_project():
    assert project({'a':1, 'b':2, 'c': 3}, 'ac') == {'a':1, 'c': 3}
    dd = defaultdict(int, {'a':1, 'b':2, 'c': 3})
    assert eq(project(dd, 'ac'), defaultdict(int, {'a':1, 'c': 3}))

def test_izip_values():
    assert list(izip_values({1: 10}, {1: 20, 2: 30})) == [(10, 20)]
    with pytest.raises(TypeError): list(izip_values())

def test_izip_dicts():
    assert list(izip_dicts({1: 10}, {1: 20, 2: 30})) == [(1, (10, 20))]
    with pytest.raises(TypeError): list(izip_dicts())


# These things are named differently in python 3
try:
    from funcy.colls import lwhere as where, lpluck as pluck, linvoke as invoke
except ImportError:
    pass

def test_where():
    data = [{'a': 1, 'b': 2}, {'a': 10, 'b': 2}]
    assert where(data, a=1) == [{'a': 1, 'b': 2}]
    assert where(data, a=1, b=2) == [{'a': 1, 'b': 2}]
    assert where(data, b=2) == data

def test_pluck():
    data = [{'a': 1, 'b': 2}, {'a': 10, 'b': 2}]
    assert pluck('a', data) == [1, 10]

def test_invoke():
    assert invoke(['abc', 'def', 'b'], 'find', 'b') == [1, -1, 0]

########NEW FILE########
__FILENAME__ = test_debug
import re, time

from funcy.debug import *


def test_log_calls():
    log = []

    @log_calls(log.append)
    def f(x, y):
        return x + y

    f(1, 2)
    f('a', 'b')
    assert log == [
        "Call f(1, 2)",
        "-> 3 from f(1, 2)",
        "Call f('a', 'b')",
        "-> 'ab' from f('a', 'b')",
    ]


def test_log_calls_raise():
    log = []

    @log_calls(log.append)
    def f():
        raise Exception('something bad')

    try:
        f()
    except:
        pass
    assert log == [
        "Call f()",
        "-> raised Exception: something bad in f()",
    ]


def test_log_durations():
    log = []

    @log_durations(log.append)
    def f():
        time.sleep(0.010)

    f()
    m = re.search(r'^\s*(\d+\.\d+) ms in f\(\)$', log[0])
    assert m
    assert 10 <= float(m.group(1)) < 20

########NEW FILE########
__FILENAME__ = test_decorators
import pytest
from funcy.decorators import *


def test_decorator_no_args():
    @decorator
    def inc(call):
        return call() + 1

    @inc
    def ten():
        return 10

    assert ten() == 11


def test_decorator_with_args():
    @decorator
    def add(call, n):
        return call() + n

    @add(2)
    def ten():
        return 10

    assert ten() == 12


def test_decorator_access_arg():
    @decorator
    def multiply(call):
        return call() * call.n

    @multiply
    def square(n):
        return n

    assert square(5) == 25


def test_decorator_access_nonexistent_arg():
    @decorator
    def return_x(call):
        return call.x

    @return_x
    def f():
        pass

    with pytest.raises(AttributeError): f()


def test_decorator_with_method():
    @decorator
    def inc(call):
        return call() + 1

    class A(object):
        def ten(self):
            return 10

        @classmethod
        def ten_cls(cls):
            return 10

        @staticmethod
        def ten_static():
            return 10

    assert inc(A().ten)() == 11
    assert inc(A.ten_cls)() == 11
    assert inc(A.ten_cls)() == 11
    assert inc(A.ten_static)() == 11


def test_decorator_with_method_descriptor():
    @decorator
    def exclaim(call):
        return call() + '!'

    assert exclaim(str.upper)('hi') == 'HI!'


def test_chain_arg_access():
    @decorator
    def decor(call):
        return call.x + call()

    @decor
    @decor
    def func(x):
        return x

    assert func(2) == 6

########NEW FILE########
__FILENAME__ = test_flow
import pytest
from funcy.flow import *


def test_silent():
    assert silent(int)(1) == 1
    assert silent(int)('1') == 1
    assert silent(int)('hello') is None

    assert silent(str.upper)('hello') == 'HELLO'


class MyError(Exception):
    pass


def test_raiser():

    with pytest.raises(Exception) as e: raiser()()
    assert e.type is Exception

    with pytest.raises(MyError): raiser(MyError)()
    with pytest.raises(MyError) as e: raiser(MyError, 'some message')()
    assert e.value.args == ('some message',)

    with pytest.raises(MyError): raiser(MyError('some message'))()
    with pytest.raises(MyError): raiser(MyError)('junk', keyword='junk')


def test_retry():
    calls = []

    def failing(n=1):
        if len(calls) < n:
            calls.append(1)
            raise MyError
        return 1

    with pytest.raises(MyError): failing()
    calls = []
    assert retry(2, MyError)(failing)() == 1
    calls = []
    with pytest.raises(MyError): retry(2, MyError)(failing)(2)


def test_fallback():
    assert fallback(raiser(), lambda: 1) == 1
    with pytest.raises(Exception): fallback((raiser(), MyError), lambda: 1)
    assert fallback((raiser(MyError), MyError), lambda: 1) == 1


def test_limit_error_rate():
    calls = []

    @limit_error_rate(2, 60, MyError)
    def limited(x):
        calls.append(x)
        raise TypeError

    with pytest.raises(TypeError): limited(1)
    with pytest.raises(TypeError): limited(2)
    with pytest.raises(MyError): limited(3)
    assert calls == [1, 2]


def test_post_processing():
    @post_processing(max)
    def my_max(l):
        return l

    assert my_max([1, 3, 2]) == 3


def test_collecting():
    @collecting
    def doubles(l):
        for i in l:
            yield i * 2

    assert doubles([1, 2]) == [2, 4]

########NEW FILE########
__FILENAME__ = test_funcmakers
import pytest
from collections import defaultdict
from funcy.funcmakers import *


def test_callable():
    assert make_func(lambda x: x + 42)(0) == 42


def test_int():
    assert make_func(0)('abc') == 'a'
    assert make_func(2)([1,2,3]) == 3
    assert make_func(1)({1: 'a'}) == 'a'
    with pytest.raises(IndexError): make_func(1)('a')
    with pytest.raises(TypeError): make_func(1)(42)


def test_slice():
    assert make_func(slice(1, None))('abc') == 'bc'


def test_str():
    assert make_func('\d+')('ab42c') == '42'
    assert make_func('\d+')('abc') is None
    assert make_pred('\d+')('ab42c') == True
    assert make_pred('\d+')('abc') == False


def test_dict():
    assert make_func({1: 'a'})(1) == 'a'
    with pytest.raises(KeyError): make_func({1: 'a'})(2)

    d = defaultdict(int, a=42)
    assert make_func(d)('a') == 42
    assert make_func(d)('b') == 0


def test_set():
    s = set([1,2,3])
    assert make_func(s)(1) == True
    assert make_func(s)(4) == False

########NEW FILE########
__FILENAME__ = test_funcolls
from whatever import _

from funcy.cross import filter
from funcy.funcolls import *


def test_all_fn():
    assert filter(all_fn(_ > 3, _ % 2), range(10)) == [5, 7, 9]

def test_any_fn():
    assert filter(any_fn(_ > 3, _ % 2), range(10)) == [1, 3, 4, 5, 6, 7, 8, 9]

def test_none_fn():
    assert filter(none_fn(_ > 3, _ % 2), range(10)) == [0, 2]

def test_one_fn():
    assert filter(one_fn(_ > 3, _ % 2), range(10)) == [1, 3, 4, 6, 8]

def test_some_fn():
    assert some_fn(_-1, _*0, _+1, _*2)(1) == 2


def test_extended_fns():
    f = any_fn(None, set([1,2,0]))
    assert f(1)
    assert f(0)
    assert f(10)
    assert not f('')

########NEW FILE########
__FILENAME__ = test_funcs
from operator import __add__, __sub__
import pytest
from whatever import _

from funcy.cross import map
from funcy.funcs import *


def test_caller():
    assert caller([1, 2])(sum) == 3

def test_constantly():
    assert constantly(42)() == 42
    assert constantly(42)('hi', 'there', volume='shout') == 42

def test_partial():
    assert partial(__add__, 10)(1) == 11
    assert partial(__add__, 'abra')('cadabra') == 'abracadabra'

    merge = lambda a=None, b=None: a + b
    assert partial(merge, a='abra')(b='cadabra') == 'abracadabra'
    assert partial(merge, b='abra')(a='cadabra') == 'cadabraabra'

def test_func_partial():
    class A(object):
        f = func_partial(lambda x, self: x + 1, 10)

    assert A().f() == 11

def test_curry():
    assert curry(lambda: 42)() == 42
    assert curry(_ * 2)(21) == 42
    assert curry(_ * _)(6)(7) == 42
    assert curry(__add__, 2)(10)(1) == 11
    assert curry(lambda x,y,z: x+y+z)('a')('b')('c') == 'abc'

def test_autocurry():
    at = autocurry(lambda a, b, c: (a, b, c))

    assert at(1)(2)(3) == (1, 2, 3)
    assert at(1, 2)(3) == (1, 2, 3)
    assert at(1)(2, 3) == (1, 2, 3)
    assert at(1, 2, 3) == (1, 2, 3)
    with pytest.raises(TypeError): at(1, 2, 3, 4)
    with pytest.raises(TypeError): at(1, 2)(3, 4)

    assert at(a=1, b=2, c=3) == (1, 2, 3)
    assert at(c=3)(1, 2) == (1, 2, 3)
    assert at(c=4)(c=3)(1, 2) == (1, 2, 3)
    with pytest.raises(TypeError): at(a=1)(1, 2, 3)


def test_compose():
    double = _ * 2
    inc    = _ + 1
    assert compose()(10) == 10
    assert compose(double)(10) == 20
    assert compose(inc, double)(10) == 21
    assert compose(str, inc, double)(10) == '21'
    assert compose(int, r'\d+')('abc1234xy') == 1234

def test_complement():
    assert complement(identity)(0) == True
    assert complement(identity)([1, 2]) == False

def test_juxt():
    assert juxt(__add__, __sub__)(10, 2) == [12, 8]
    assert map(juxt(_ + 1, _ - 1), [2, 3]) == [[3, 1], [4, 2]]

def test_iffy():
    assert map(iffy(_ % 2, _ * 2, _ / 2), [1,2,3,4]) == [2,1,6,2]
    assert map(iffy(_ % 2, _ * 2), [1,2,3,4]) == [2,2,6,4]
    assert map(iffy(_ * 2), [1, '', None, '2']) == [2, '', None, '22']
    assert map(iffy(_ % 2, _ * 2, None), [1,2,3,4]) == [2, None, 6, None]

########NEW FILE########
__FILENAME__ = test_objects
import sys
from funcy.objects import *


### @cached_property

def test_cached_property():
    calls = [0]

    class A(object):
        @cached_property
        def prop(self):
            calls[0] += 1
            return 7

    a = A()
    assert a.prop == 7
    assert a.prop == 7
    assert calls == [1]

    a.prop = 42
    assert a.prop == 42

    del a.prop
    assert a.prop == 7
    assert calls == [2]


### Monkey tests

def test_monkey():
    class A(object):
        def f(self):
            return 7

    @monkey(A)
    def f(self):
        return f.original(self) * 6

    assert A().f() == 42


def test_monkey_property():
    class A(object):
        pass

    @monkey(A)
    @property
    def prop(self):
        return 42

    assert A().prop == 42


def f(x):
    return x

def test_monkey_module():
    this_module = sys.modules[__name__]

    @monkey(this_module)
    def f(x):
        return f.original(x) * 2

    assert f(21) == 42

########NEW FILE########
__FILENAME__ = test_seqs
import sys
from collections import Iterator
from operator import add
import re
import pytest
from whatever import _

from funcy.cross import xrange
from funcy.seqs import *


def test_repeatedly():
    counter = count()
    c = lambda: next(counter)
    assert take(2, repeatedly(c)) == [0, 1]

def test_iterate():
    assert take(4, iterate(_ * 2, 1)) == [1, 2, 4, 8]


def test_take():
    assert take(2, [3, 2, 1]) == [3, 2]
    assert take(2, count(7)) == [7, 8]

def test_drop():
    dropped = drop(2, [5, 4, 3, 2])
    assert isinstance(dropped, Iterator)
    assert list(dropped) == [3, 2]

    assert take(2, drop(2, count())) == [2, 3]

def test_first():
    assert first('xyz') == 'x'
    assert first(count(7)) == 7
    assert first([]) is None

def test_second():
    assert second('xyz') == 'y'
    assert second(count(7)) == 8
    assert second('x') is None

def test_last():
    assert last('xyz') == 'z'
    assert last(xrange(1, 10)) == 9
    assert last([]) is None
    assert last(x for x in 'xyz') == 'z'

def test_nth():
    assert nth(0, 'xyz') == 'x'
    assert nth(2, 'xyz') == 'z'
    assert nth(3, 'xyz') is None
    assert nth(3, count(7)) == 10

def test_butlast():
    assert list(butlast('xyz')) == ['x', 'y']
    assert list(butlast([])) == []

def test_ilen():
    assert ilen('xyz') == 3
    assert ilen(xrange(10)) == 10


def test_map():
    assert map(_ * 2, [2, 3]) == [4, 6]
    assert map(None, [2, 3]) == [2, 3]
    assert map(r'\d+', ['a2', '13b']) == ['2', '13']
    assert map({'a': 1, 'b': 2}, 'ab') == [1, 2]
    assert map(set([1,2,3]), [0, 1, 2]) == [False, True, True]
    assert map(1, ['abc', '123']) == ['b', '2']
    assert map(slice(2), ['abc', '123']) == ['ab', '12']

@pytest.mark.skipif(sys.version_info[0] == 3,
                    reason="map(None, ...) with multiple sequences doesn't work in python 3")
def test_map_multi():
    assert map(None, [1, 2, 3], 'abc') == [(1, 'a'), (2, 'b'), (3, 'c')]

def test_filter():
    assert filter(None, [2, 3, 0]) == [2, 3]
    assert filter(r'\d+', ['a2', '13b', 'c']) == ['a2', '13b']
    assert filter(set([1,2,3]), [0, 1, 2, 4, 1]) == [1, 2, 1]

def test_remove():
    assert remove(_ > 3, range(10)) == [0, 1, 2, 3]

def test_keep():
    assert keep(_ % 3, range(5)) == [1, 2, 1]
    assert keep(range(5)) == [1, 2, 3, 4]
    assert keep(mapcat(range, range(4))) == [1, 1, 2]

def test_concat():
    assert concat('ab', 'cd') == list('abcd')
    assert concat() == []

def test_cat():
    assert cat('abcd') == list('abcd')
    assert cat(range(x) for x in range(3)) == [0, 0, 1]

def test_flatten():
    assert flatten([1, [2, 3]]) == [1, 2, 3]
    assert flatten([[1, 2], 3]) == [1, 2, 3]
    assert flatten([(2, 3)]) == [2, 3]
    assert flatten([iter([2, 3])]) == [2, 3]

def test_mapcat():
    assert mapcat(lambda x: [x, x], 'abc') == list('aabbcc')

def test_interleave():
    assert list(interleave('ab', 'cd')) == list('acbd')
    assert list(interleave('ab_', 'cd')) == list('acbd')

def test_iterpose():
    assert list(interpose('.', 'abc')) == list('a.b.c')


def test_distinct():
    assert distinct('abcbad') == list('abcd')
    assert distinct([{}, {}, {'a': 1}, {'b': 2}], key=len) == [{}, {'a': 1}]
    assert distinct(['ab', 'cb', 'ad'], key=0) == ['ab', 'cb']

# Separate test as split() is not implemented via it.
def test_isplit():
    assert map(list, isplit(_ % 2, range(5))) == [[1, 3], [0, 2, 4]]

def test_split():
    assert split(_ % 2, range(5)) == ([1, 3], [0, 2, 4])
    # This behaviour moved to split_at()
    with pytest.raises(TypeError): split(2, range(5))

def test_split_at():
    assert split_at(2, range(5)) == ([0, 1], [2, 3, 4])

def test_split_at_pred():
    # This behaviour moved to split_by()
    with pytest.raises(ValueError): split_at(_ % 2, range(5))

def test_split_by():
    assert split_by(_ % 2, [1, 2, 3]) == ([1], [2, 3])

def test_group_by():
    assert group_by(_ % 2, range(5)) == {0: [0, 2, 4], 1: [1, 3]}
    assert group_by(r'\d', ['a1', 'b2', 'c1']) == {'1': ['a1', 'c1'], '2': ['b2']}

def test_group_by_keys():
    assert group_by_keys(r'(\d)(\d)', ['12', '23']) == {'1': ['12'], '2': ['12', '23'], '3': ['23']}

def test_count_by():
    assert count_by(_ % 2, range(5)) == {0: 3, 1: 2}
    assert count_by(r'\d', ['a1', 'b2', 'c1']) == {'1': 2, '2': 1}

def test_count_by_is_defaultdict():
    cnts = count_by(len, [])
    assert cnts[1] == 0

def test_partition():
    assert partition(2, range(5)) == [[0, 1], [2, 3]]
    assert partition(2, 1, range(4)) == [[0, 1], [1, 2], [2, 3]]
    # test iters
    assert partition(2, iter(range(5))) == [[0, 1], [2, 3]]
    assert partition(2, xrange(5)) == [[0, 1], [2, 3]]

def test_chunks():
    assert chunks(2, range(5)) == [[0, 1], [2, 3], [4]]
    assert chunks(2, 1, range(4)) == [[0, 1], [1, 2], [2, 3], [3]]
    assert chunks(3, 1, iter(range(3))) == [[0, 1, 2], [1, 2], [2]]

def test_partition_by():
    assert partition_by(lambda x: x == 3, [1,2,3,4,5]) == [[1,2], [3], [4,5]]
    assert partition_by('x', 'abxcd') == [['a', 'b'], ['x'], ['c', 'd']]


def test_with_prev():
    assert list(with_prev(range(3))) == [(0, None), (1, 0), (2, 1)]

def test_pairwise():
    assert list(pairwise(range(3))) == [(0, 1), (1, 2)]


def test_reductions():
    assert reductions(add, []) == []
    assert reductions(add, [None]) == [None]
    assert reductions(add, [1, 2, 3, 4]) == [1, 3, 6, 10]
    assert reductions(lambda x, y: x + [y], [1,2,3], []) == [[1], [1, 2], [1, 2, 3]]

def test_sums():
    assert sums([]) == []
    assert sums([1, 2, 3, 4]) == [1, 3, 6, 10]
    assert sums([[1],[2],[3]]) == [[1], [1, 2], [1, 2, 3]]

def test_without():
    assert without([]) == []
    assert without([1, 2, 3, 4]) == [1, 2, 3, 4]
    assert without([1, 2, 1, 0, 3, 1, 4], 0, 1) == [2, 3, 4]

########NEW FILE########
__FILENAME__ = test_strings
from funcy.strings import *


def test_re_find():
    assert re_find(r'\d+', 'x34y12') == '34'
    assert re_find(r'y(\d+)', 'x34y12') == '12'
    assert re_find(r'([a-z]+)(\d+)', 'x34y12') == ('x', '34')
    assert re_find(r'(?P<l>[a-z]+)(?P<d>\d+)', 'x34y12') == {'l': 'x', 'd': '34'}


def test_re_all():
    assert re_all(r'\d+', 'x34y12') == ['34', '12']
    assert re_all(r'([a-z]+)(\d+)', 'x34y12') == [('x', '34'), ('y', '12')]
    assert re_all(r'(?P<l>[a-z]+)(?P<d>\d+)', 'x34y12') \
                    == [{'l': 'x', 'd': '34'}, {'l': 'y', 'd': '12'}]

def test_str_join():
    assert str_join([1, 2, 3]) == '123'
    assert str_join('_', [1, 2, 3]) == '1_2_3'
    assert isinstance(str_join(u'_', [1, 2, 3]), type(u''))


def test_cut_prefix():
    assert cut_prefix('name:alex', 'name:') == 'alex'
    assert cut_prefix('alex', 'name:') == 'alex'

def test_cut_suffix():
    assert cut_suffix('name.py', '.py') == 'name'
    assert cut_suffix('name', '.py') == 'name'

########NEW FILE########
__FILENAME__ = test_types
from funcy.cross import xrange
from funcy.types import *


def test_iterable():
    assert iterable([])
    assert iterable({})
    assert iterable('abc')
    assert iterable(iter([]))
    assert iterable(x for x in range(10))
    assert iterable(xrange(10))

    assert not iterable(1)


def test_is_iter():
    assert is_iter(iter([]))
    assert is_iter(x for x in range(10))

    assert not is_iter([])
    assert not is_iter(xrange(10))

########NEW FILE########
